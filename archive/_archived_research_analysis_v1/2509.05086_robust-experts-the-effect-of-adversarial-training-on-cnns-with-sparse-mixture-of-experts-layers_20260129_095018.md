# Robust Experts: the Effect of Adversarial Training on CNNs with Sparse Mixture-of-Experts Layers

*Svetlana Pavlitska; Haixi Fan; Konstantin Ditschuneit; J. Marius Z√∂llner*

---

> ### üìä Quick Facts
>
> *   **Quality Score:** 8/10
> *   **Dataset:** CIFAR-100
> *   **Architectures:** ResNet-18, ResNet-50
> *   **Core Innovation:** BlockMoE (Sparse Mixture-of-Experts)
> *   **Attacks Analyzed:** PGD, AutoPGD
> *   **Optimal Config:** Top-2 routing, Entropy loss, GAP-FC gating
> *   **Key Metric:** PGD Robust Acc ~17-22% (under Adversarial Training)

---

## üìù Executive Summary

This research addresses the inherent trade-off between adversarial robustness and computational efficiency in Convolutional Neural Networks (CNNs). While adversarial training is the standard defense against attacks like Projected Gradient Descent (PGD), it traditionally requires significant increases in model capacity to be effective, leading to higher inference latency and resource consumption. This paper investigates how to decouple robustness from computational overhead, posing the question of whether sparse, conditional computation architectures can provide the defensive benefits of large-scale models without the associated inference costs.

The core innovation is the integration of a sparse Mixture-of-Experts (MoE) layer, termed **"BlockMoE,"** into the deeper stages of ResNet architectures (specifically the `conv5_x` stage). By replacing standard residual blocks with a conditional computation layer using Top-k routing, the authors increase effective model capacity‚Äîtheoretically allowing the model to learn more complex defensive features‚Äîwhile keeping the computational cost constant at inference time, as only a subset of experts (*k*) is activated per input. The study further innovates by analyzing the mechanistic effects of auxiliary load-balancing losses, specifically comparing **"Switch loss,"** **"Entropy loss,"** and **"KL loss"** on expert routing behavior.

Experiments conducted on CIFAR-100 using ResNet-18 and ResNet-50 demonstrated that MoE-modified models achieve **"Efficient Robustness,"** maintaining clean accuracy while significantly outperforming standard networks against PGD and AutoPGD attacks. The optimal configuration utilized Top-2 routing with Entropy-based auxiliary loss and GAP-FC gating, achieving Clean Accuracy of ~49-53% and PGD Robust Accuracy of ~17-22% under adversarial training (compared to 0-10% robustness for normally trained baselines).

A counter-intuitive finding emerged regarding **Switch loss**: while it caused "routing collapse" (where inputs concentrate on a small subset of experts), this collapse inadvertently fostered "robust subpaths," with individual experts sometimes achieving higher robustness than the fully gated aggregated model. This work validates sparse MoE layers as a practical method for scaling adversarial robustness without sacrificing inference efficiency and suggests future research should explore the explicit exploitation or regularization of these specialized robust subpaths.

---

## üîë Key Findings

*   **Efficient Robustness:** Inserting a single sparse Mixture-of-Experts (MoE) layer into the deeper stages of ResNet architectures consistently improves robustness against PGD and AutoPGD attacks when combined with adversarial training.
*   **Cost Efficiency:** The use of MoE layers increases model capacity without incurring additional inference costs, as only a sparse subset of experts is activated during forward passes.
*   **Routing Collapse:** Employing "switch loss" for load balancing causes routing to collapse onto a small subset of experts, which concentrates adversarial training on these specific paths.
*   **Robust Subpaths:** This routing collapse inadvertently fosters "robust subpaths," causing some individual experts to achieve higher robustness than the full gated MoE model.

---

## üõ† Methodology

The study involved modifying ResNet architectures by replacing selected residual blocks or convolutional layers with sparse Mixture-of-Experts (MoE) layers. The research methodology followed these key steps:

1.  **Architecture Modification:** Standard blocks in ResNet-18 and ResNet-50 were replaced with the proposed `BlockMoE` layer in the `conv5_x` stage.
2.  **Training Protocol:** The modified models were trained using adversarial training on the CIFAR-100 dataset.
3.  **Evaluation:** Robustness was rigorously assessed using PGD (Projected Gradient Descent) and AutoPGD attacks.
4.  **Routing Analysis:** The research analyzed the impact of auxiliary losses, specifically "switch loss," on expert routing patterns.
5.  **Comparative Analysis:** The resulting robustness of individual expert paths was compared against the aggregated model performance.

---

## ‚öôÔ∏è Technical Details

| Component | Specification |
| :--- | :--- |
| **Base Architectures** | ResNet-18, ResNet-50 |
| **MoE Layer Name** | BlockMoE |
| **Insertion Point** | `conv5_x` stage |
| **Expert Count** | Range between 2 and 32 |
| **Routing Mechanism** | Top-k routing (Sparsity *k* varied) |
| **Gating Mechanisms** | GAP-FC (Global Average Pooling - Fully Connected), Conv-GAP |
| **Auxiliary Losses** | Switch loss, Entropy loss, KL loss |
| **Training Dataset** | CIFAR-100 |
| **Attack Methods** | PGD, AutoPGD |

---

## üìà Results

### Performance Metrics
The performance of the models was evaluated based on Clean Accuracy and PGD Robust Accuracy under both Normal and Adversarial Training conditions on CIFAR-100.

| Training Method | Clean Accuracy | PGD Robust Accuracy |
| :--- | :--- | :--- |
| **Normal Training** | ~65-73% | ~0-10% |
| **Adversarial Training** | ~49-53% | ~17-22% |

### Configuration Analysis
*   **Optimal Configuration:** Best performance was achieved with **Top-2 routing**, **Entropy-based auxiliary loss**, and **GAP-FC gating**. This setup improved robustness while maintaining clean accuracy.
*   **Loss Comparison:** Entropy loss outperformed Switch and KL losses in adversarial settings.
*   **Sparsity Impact:** Increasing routing sparsity (*k*) improves robustness up to **k=2**.
*   **Switch Loss Behavior:** Switch loss leads to routing collapse, which creates robust subpaths but negatively impacts load diversity.

---

## üöÄ Contributions

The study makes three primary contributions to the field of adversarial machine learning:

1.  **Efficient Robustness:** Demonstrates a method to enhance adversarial robustness in CNNs by increasing model capacity via MoE layers without increasing inference costs.
2.  **Mechanistic Insight:** Reveals a specific side-effect of switch loss balancing where routing collapse leads to the specialization of highly robust experts.
3.  **Subpath Discovery:** Identifies that the most robust components of the gated MoE system can be the individual expert subpaths themselves, challenging the assumption that the aggregated model is always the most robust.

---
**Quality Score:** 8/10 | **References:** 34 citations