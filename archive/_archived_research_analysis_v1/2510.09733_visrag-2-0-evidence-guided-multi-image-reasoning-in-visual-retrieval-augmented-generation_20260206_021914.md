---
title: 'VisRAG 2.0: Evidence-Guided Multi-Image Reasoning in Visual Retrieval-Augmented
  Generation'
arxiv_id: '2510.09733'
source_url: https://arxiv.org/abs/2510.09733
generated_at: '2026-02-06T02:19:14'
quality_score: 9
citation_count: 35
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# VisRAG 2.0: Evidence-Guided Multi-Image Reasoning in Visual Retrieval-Augmented Generation

*Yubo Sun; Chunyi Peng; Yukun Yan; Shi Yu; Zhenghao Liu; Chi Chen; Zhiyuan Liu; Maosong Sun*

---

> ### **Quick Facts**
>
> *   **Performance Gain:** +27.45% F1 improvement over backbone VLMs.
> *   **Model Size:** 7B parameters (outperforming 32B baselines).
> *   **Average Accuracy:** 75.01%
> *   **Key Innovation:** Reward-Scoped Group Relative Policy Optimization (RS-GRPO).
> *   **Primary Benchmark:** MP-DocVQA (85.45% Accuracy).

---

## Executive Summary

This research addresses a critical limitation in current Visual Retrieval-Augmented Generation (VRAG) systems: their inability to reliably reason across multiple images. While standard Vision-Language Models (VLMs) excel at single-image tasks, they often struggle to synthesize information from several distinct visual sources, leading to ungrounded answers and hallucinations. This deficiency is a significant barrier to applications requiring complex document understanding, such as analyzing multi-page reports or presentation decks.

The authors propose **EVisRAG**, an end-to-end framework that introduces a "detective-style" reasoning process. The methodology operates in two distinct phases:
1.  **Evidence Perception and Recording:** Observing retrieved images and explicitly recording specific, question-relevant evidence.
2.  **Evidence Aggregation and Reasoning:** Synthesizing these recordings to derive a final answer.

Crucially, the researchers developed **Reward-Scoped Group Relative Policy Optimization (RS-GRPO)**, a novel reinforcement learning technique that binds fine-grained rewards to specific token scopes (format, perception, and derivation). This allows for the simultaneous optimization of visual perception and logical reasoning.

EVisRAG demonstrates substantial performance gains, achieving an average **27.45% improvement in F1 score** over the Qwen2.5-VL-7B backbone across multiple benchmarks. Evaluated on datasets including ChartQA, InfographicsVQA, MP-DocVQA, and SlideVQA, the 7B parameter EVisRAG model outperformed a significantly larger Qwen2.5-VL-32B model by a margin of **+15.49% F1**. This work represents a paradigm shift in visual reasoning by moving from simple retrieval to evidence-guided synthesis, significantly mitigating hallucinations in multi-image scenarios.

---

## Key Findings

*   **Substantial Performance Gains:** EVisRAG delivers an average performance increase of **27%** over backbone Vision-Language Models (VLMs) across multiple visual question answering benchmarks.
*   **Superior Multi-Image Handling:** Unlike current VRAG systems, EVisRAG reliably perceives and integrates evidence across multiple images, resulting in stronger grounding and fewer hallucinations.
*   **Precision in Localization:** The model improves answer accuracy by precisely perceiving and localizing question-relevant evidence within individual images before aggregating it.
*   **Optimized Training Strategy:** The proposed training strategy, RS-GRPO, successfully optimizes both visual perception and reasoning abilities simultaneously.

---

## Methodology

The researchers propose EVisRAG as an end-to-end solution designed to facilitate evidence-guided multi-image reasoning. The framework moves beyond simple retrieval to evidence-guided synthesis through two primary operational phases:

1.  **Evidence Perception and Recording:** The model observes retrieved images and explicitly records specific evidence for each image individually.
2.  **Evidence Aggregation and Reasoning:** The model derives the final answer by aggregating the recorded per-image evidence.

To optimize this framework, the authors introduced **Reward-Scoped Group Relative Policy Optimization (RS-GRPO)**. This training algorithm binds fine-grained rewards to scope-specific tokens, allowing for the joint optimization of the VLM's visual perception and reasoning capabilities.

---

## Technical Details

The EVisRAG framework utilizes a "detective-style" reasoning architecture divided into four specific scopes:

### 1. Information Gathering
Retrieves top-$k$ document page snapshots via VisRAG-Ret.

### 2. Visual Perception
Generates coarse page descriptions and per-image evidence sequences to localize relevant regions.

### 3. Answer Reasoning
Distills evidence, formulates hypotheses, and generates the answer.

### Training Algorithm: RS-GRPO
The model utilizes Reward-Scoped Group Relative Policy Optimization to route supervision signals via specific Reward Scopes:
*   **$R_{format}$:** Ensures order adherence.
*   **$R_{perception}$:** Evaluates localization accuracy.
*   **$R_{derivation}$:** Checks for logical consistency.

Token-level advantages are computed by group-normalizing scope-aggregated rewards to stabilize training.

---

## Results

The 7B EVisRAG model was evaluated on ChartQA, InfographicsVQA, MP-DocVQA, SlideVQA, and ViDoSeek using Accuracy and F1 Score.

### Performance Overview
*   **Average Accuracy:** 75.01%
*   **Average F1 Score:** 77.86%

### Comparative Improvements
*   **vs. Qwen2.5-VL-7B:** +27.45% F1
*   **vs. OpenVLThinker-7B:** +10.73% F1
*   **vs. Qwen2.5-VL-32B:** +15.49% F1

### Benchmark Highlights
| Dataset | Accuracy | F1 Score |
| :--- | :--- | :--- |
| **MP-DocVQA** | 85.45% | 86.82% |
| **SlideVQA** | 81.29% | 80.28% |
| **InfographicsVQA** | 79.39% | 79.80% |

Ablation studies confirm that the method effectively mitigates hallucination and that RS-GRPO efficiently optimizes both perception and reasoning.

---

## Contributions

*   **End-to-End Solution:** Introduced EVisRAG to address the failure mode of current VRAG systems in handling multi-image reasoning by shifting from simple retrieval to evidence-guided synthesis.
*   **Advanced Training Algorithm:** Developed RS-GRPO, a specialized RLHF variant that aligns rewards with specific token scopes for precise fine-tuning of perception and reasoning skills.
*   **State-of-the-Art Performance:** Empirical validation through comprehensive benchmarking establishes a new standard for grounded, multi-image visual question answering.
*   **Paradigm Shift:** Promoted a grounded, evidence-first approach that reduces hallucinations by ensuring answers are derived strictly from observed, localized evidence.

---

**Paper Quality Score:** 9/10
**References:** 35 citations