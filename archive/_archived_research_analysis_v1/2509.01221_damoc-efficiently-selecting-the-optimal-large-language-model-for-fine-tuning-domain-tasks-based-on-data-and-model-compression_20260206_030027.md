---
title: 'DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning
  Domain Tasks Based on Data and Model Compression'
arxiv_id: '2509.01221'
source_url: https://arxiv.org/abs/2509.01221
generated_at: '2026-02-06T03:00:27'
quality_score: 9
citation_count: 26
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning Domain Tasks Based on Data and Model Compression

*Wei Huang; Huang Wei; Yinggui Wang*

---

> ### üìä Quick Facts
>
> *   **Efficiency Gain:** ~20-fold reduction in training time
> *   **Validation Scope:** 4 distinct datasets (Medical, Financial, General, Reading Comp)
> *   **Core Strategy:** Dual-level compression (Data filtering & Model pruning)
> *   **Quality Score:** 9/10
> *   **References:** 26 citations

---

## üìë Executive Summary

Identifying the optimal open-source Large Language Model (LLM) for specific domain tasks presents a significant computational bottleneck. Current methods require either full fine-tuning of every candidate model‚Äîwhich is prohibitively expensive and time-consuming‚Äîor reliance on few-shot performance metrics, which often fail to correlate with actual fine-tuned results. This misalignment is critical because model rankings can shift drastically after training; for instance, a model performing poorly in a zero-shot setting may become top-tier after fine-tuning. Consequently, organizations lack an efficient mechanism to select the best model for their domain without expending massive computational resources.

The paper introduces **DaMoC (Data and Model Compression)**, a framework that accelerates the model selection process by optimizing both the training data and the candidate models. At the data level, DaMoC implements a rigorous pipeline involving distribution-aware and quality-aware filtering, token compression to enhance key token density via perplexity scoring, and iterative rewriting to optimize text expression. At the model level, the framework employs layer pruning based on the cosine similarity of layer input and output activations, removing less important layers while preserving core capabilities. Crucially, it utilizes a sparse merging paradigm for task vectors to mitigate distribution shifts. By compressing both the input data and the model architecture, DaMoC creates a proxy environment that accurately predicts full fine-tuning outcomes at a fraction of the computational cost.

Experimental validation across four distinct datasets‚ÄîMedical (PubMedQA), Financial (BillSum), General Q&A, and Reading Comprehension‚Äîdemonstrates that DaMoC achieves approximately a **20-fold reduction in training time** compared to standard fine-tuning while maintaining consistent performance results. The analysis highlighted the inadequacy of few-shot selection, noting specific instances such as Llama3.1-8B, which ranked 8th in zero-shot evaluations but rose to 2nd after fine-tuning. DaMoC successfully navigated these ranking shifts, identifying the optimal model with accuracy comparable to full training.

The DaMoC framework significantly alters the workflow for domain-specific LLM deployment by decoupling model selection from massive computational overhead. By reducing training time by ~20x without sacrificing the ability to identify the highest-performing model, this research makes high-quality domain adaptation accessible to resource-constrained environments.

---

## üîë Key Findings

*   **Optimal Selection:** The DaMoC framework effectively identifies the optimal Large Language Model (LLM) for domain-specific fine-tuning tasks.
*   **Significant Efficiency:** The proposed methodology achieves significant computational efficiency, reducing training time by approximately **20-fold**.
*   **Broad Applicability:** The framework was validated across four distinct datasets‚Äîmedical Q&A, financial Q&A, general Q&A, and reading comprehension.
*   **Resource Reduction:** By combining data compression (token density enhancement) and model compression (layer removal), the approach maintains the ability to select high-quality models while drastically lowering resource requirements.

---

## üõ†Ô∏è Methodology

The DaMoC framework operates on two distinct levels to optimize the LLM selection process:

### 1. Data Level
*   **Data Filtering Categorization:** Utilizes distribution-aware, quality-aware, and hybrid filtering methods.
*   **Token Compression:** Enhances key token density to streamline the input data.
*   **Iterative Rewriting:** Uses an LLM to optimize text expression and improve data quality iteratively.

### 2. Model Level
*   **Layer Pruning:** Uses similarity scores to remove less important layers from the network.
*   **Sparse Merging Paradigm:** Employs a sparse merging technique to preserve the original model's capability during compression.

---

## ‚öôÔ∏è Technical Details

The DaMoC framework utilizes a three-pronged strategy comprising data filtering, token compression, and model pruning.

### Data Processing Strategy
*   **Filtering Methods:** Evaluates 12 methods across three paradigms:
    *   *Distribution-Aware:* DQ, GraphCut, KCenterGreedy
    *   *Quality-Aware:* AlphaGasus, Superfiltering, LESS
    *   *Hybrid:* MoDS, Cherry, Deita
*   **Token Compression:** Performed during training using Baichuan2-7B-Chat-4bits to compress questions via perplexity and answers via question-related perplexity.
*   **Quality Control:** Maintained via BERTScore checks and rewriting by Baichuan2-13B-Chat if thresholds are not met.

### Model Compression Strategy
*   **Pruning Logic:** Employs layer-wise pruning (avoiding MHA, MLP, and Hidden Sizes) based on Importance Scores calculated via the cosine similarity of layer input and output activations.
*   **Merging Technique:** Uses sparse merging of task vectors to mitigate distribution shifts.
*   **Candidate Models:** Validated on 8 candidates, including Llama3.1-8B and Qwen2.5-7B.

---

## üìà Experimental Results

**Datasets & Scope**
Experiments were conducted on PubMedQA and BillSum datasets, with validation extending to Medical, Financial, General, and Reading Comprehension datasets.

**Critical Findings**
*   **Few-shot Ineffectiveness:** Few-shot selection is unreliable. For example, *Llama3.1-8B* ranked 8th in zero-shot performance but jumped to 2nd after fine-tuning.
*   **Efficiency:** DaMoC achieves a **~20-fold reduction** in training time compared to standard fine-tuning.
*   **Performance Consistency:** Matches full fine-tuning results without sacrificing accuracy.

**Metrics Used**
*   Accuracy/Ranking
*   BERTScore (for semantic preservation)
*   Cosine Similarity (for layer importance)
*   Perplexity (for token importance)

---

## üåü Research Contributions

*   **Framework Introduction:** Introduced DaMoC, a comprehensive framework that addresses the challenge of efficiently selecting the optimal open-source LLM for downstream domain tasks from a vast pool of candidates.
*   **Data Processing Pipeline:** Contributed a new data processing pipeline that goes beyond simple filtering by categorizing methodologies, implementing token compression, and applying iterative text rewriting to optimize training inputs.
*   **Compression Strategy:** Developed a model-level compression strategy that utilizes layer similarity scoring for pruning and employs a sparse merging paradigm to maintain model integrity, offering a new approach to evaluating model architecture without full training.
*   **Validation of Efficiency:** Demonstrated that the selection and fine-tuning process can be significantly accelerated (achieving ~20x time savings) without sacrificing the ability to identify the best-performing model for specific domains.