---
title: Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems
arxiv_id: '2601.1056'
source_url: https://arxiv.org/abs/2601.10560
generated_at: '2026-02-03T13:04:24'
quality_score: 9
citation_count: 4
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems

*Xi Shi; Mengxin Zheng; Qian Lou*

---

> ### ðŸ“‹ Quick Facts
>
> *   **Framework Name:** LAMaS (Latency-Aware Multi-agent System)
> *   **Core Innovation:** Explicit optimization of the Critical Execution Path
> *   **Latency Reduction:** 38â€“46% reduction compared to SOTA baselines
> *   **Execution Mode:** Parallel Query-level
> *   **Quality Score:** 9/10

---

## Executive Summary

This research addresses the fundamental inefficiency of current orchestration strategies in multi-agent systems, which largely rely on sequential execution assumptions. In real-world deployments where agents operate concurrently, these traditional methods introduce artificial synchronization barriers that prevent true parallelism, resulting in suboptimal wall-clock latency. The problem is critical because optimizing solely for task accuracy or total computational costâ€”standard metrics in existing literatureâ€”fails to capture the temporal bottlenecks inherent in parallel environments. Consequently, there is a need for a framework that shifts focus from aggregate cost to the specific dependencies that dictate the speed of execution in concurrent systems.

The authors introduce **LAMaS (Latency-Aware Multi-agent System)**, the first learning-based orchestration framework designed explicitly for parallel query-level execution. The core technical innovation is the optimization of the "critical execution path"â€”the longest sequence of dependent tasksâ€”rather than total computational cost. LAMaS utilizes an "Agentic Supernet" architecture modeled as a probabilistic Directed Acyclic Graph (DAG). It employs a policy network for autoregressive topology construction, using threshold-based sampling to dynamically adjust the graph's width and depth. By incorporating explicit latency supervision into the learning process and decoupling dependencies to remove synchronization barriers, LAMaS effectively separates latency optimization from computational cost.

Empirical validation demonstrates that LAMaS achieves substantial improvements in efficiency without sacrificing task quality. The framework reduces the critical execution path length by **38% to 46%** compared to state-of-the-art baselines, including sequential, cost-optimization, and static parallel methods. Furthermore, these latency gains do not compromise system capability; LAMaS maintains or improves overall task performance (accuracy) across all tested benchmarks. The results highlight that methods assuming sequential execution are significantly outperformed by LAMaS in terms of both flexibility and latency control.

This work signifies a paradigm shift in multi-agent system design, moving the optimization focus from sequential inference costs to parallel execution constraints. By proving that explicit critical path optimization is essential for efficient concurrency, the authors establish a new standard for future research in latency-sensitive agentic workflows. The release of the source code alongside the paper facilitates reproducibility and further innovation. Ultimately, LAMaS provides the architectural foundation necessary to deploy scalable, responsive multi-agent systems in real-world applications where time-efficiency is paramount.

---

## Key Findings

*   **Significant Latency Reduction:** The proposed approach reduces the critical execution path length by **38â€“46%** compared to state-of-the-art baselines.
*   **Performance Preservation:** Maintains or improves overall task performance (accuracy) across all benchmarks.
*   **Sequential Inefficiency:** Identifies that existing methods assuming sequential execution are suboptimal for parallel latency control.
*   **Critical Path Importance:** Demonstrates that explicitly optimizing the critical execution path is essential for efficient multi-agent systems under parallel execution constraints.

---

## Methodology

The authors propose **LAMaS (Latency-Aware Multi-agent System)**, a learning-based orchestration framework designed specifically for parallel multi-agent environments. The methodology is built upon three core pillars:

1.  **Explicit Latency Supervision:** Incorporating direct latency signals into the learning process, moving away from implicit sequential execution assumptions.
2.  **Parallel Processing:** Enabling true parallel processing capabilities rather than forcing concurrent tasks into sequential queues.
3.  **Topology Graph Construction:** Designing execution topology graphs specifically engineered to minimize the critical execution path, thereby reducing wall-clock time.

---

## Technical Details

| Component | Description |
| :--- | :--- |
| **System Name** | LAMaS (Latency-Aware Multi-agent System) |
| **Execution Mode** | Parallel Query-level |
| **Architecture Type** | Agentic Supernet (probabilistic DAG) |
| **Optimization Mechanism** | Optimizes the Critical Execution Path rather than total cost; decouples latency from computational cost; removes artificial synchronization barriers via dependency decoupling. |
| **Controller Strategy** | Uses a policy network for autoregressive topology construction with threshold-based sampling to dynamically adjust width and depth. |

---

## Contributions

*   **Novel Framework:** Introduction of LAMaS, the first latency-aware multi-agent orchestration framework that enables parallel execution while explicitly optimizing the critical execution path.
*   **Paradigm Shift:** A shift in the optimization paradigm from purely task performance and inference cost (under sequential assumptions) to latency optimization for parallel execution scenarios.
*   **Validation & Reproducibility:** Empirical validation providing comprehensive evidence of latency gains (38-46%) without degrading task accuracy, alongside the release of source code for reproducibility.

---

## Results

| Metric | Outcome |
| :--- | :--- |
| **Primary Metric** | Critical execution path length (wall-clock latency proxy) |
| **Secondary Metric** | Overall task performance (accuracy) |
| **Latency Reduction** | 38â€“46% reduction compared to state-of-the-art baselines |
| **Task Performance** | Maintained or improved performance across benchmarks |
| **Comparative Analysis** | Identified as superior to sequential methods, cost-optimization methods, and static parallel methods in flexibility and latency control |

---

**Quality Score:** 9/10  
**References:** 4 citations