# Flexible Mixed Precision Quantization for Learned Image Compression
*Md Adnan Faisal Hossain; Zhihao Duan; Fengqing Zhu*

---

> ### ðŸ“Š Quick Facts
> *   **Quality Score:** 8/10
> *   **References:** 30 Citations
> *   **BD-Rate Savings:** 3.1% â€“ 4.5% (vs. uniform quantization)
> *   **Search Speedup:** >100x faster than baselines
> *   **Time Reduction:** From several hours/days to **< 1 hour**

---

## Executive Summary

**Problem**
Traditional Learned Image Compression (LIC) models rely on fixed-precision quantization, applying uniform bit-widths across all network layers. This "one-size-fits-all" strategy is fundamentally sub-optimal; it fails to recognize that specific layers significantly impact reconstruction quality when quantized, while others are robust. Consequently, uniform quantization leads to inefficient resource utilization, forcing a trade-off where model size is reduced only at the cost of disproportionate losses in coding performance.

**Innovation**
The paper introduces the **Flexible Mixed Precision Quantization (FMPQ)** framework, which optimizes performance by assigning heterogeneous bit-widths to different layers. The core innovation is a bit-assignment criterion defined by the "fractional change in rate-distortion loss," prioritizing higher bit-widths for layers where quantization causes the highest RD degradation. To manage combinatorial complexity, the authors developed an **adaptive search algorithm** that efficiently identifies optimal bit-width distributions without exhaustive brute-force computation.

**Results**
Empirical validation demonstrates that FMPQ consistently outperforms traditional baselines. Under model size constraints targeting ~25% of the original floating-point size, the method achieves BD-Rate savings of roughly **3.1% to 4.5%** on the Kodak dataset. Furthermore, the adaptive search algorithm reduces search time from several hours (or days) to **less than an hour**, representing a speedup factor of over **100x**.

**Impact**
This research establishes that layer-aware, mixed-precision strategies are strictly superior to uniform quantization. By shifting the focus to intelligent, sensitivity-based resource allocation, the FMPQ framework facilitates the deployment of high-efficiency LIC on resource-constrained edge devices. The release of the source code ensures reproducibility and broader community adoption.

---

## Key Findings

*   **Optimized Resource Utilization:** Traditional fixed-precision quantization is sub-optimal due to neglecting layer sensitivity; the proposed FMPQ achieves superior BD-Rate performance under similar model size constraints.
*   **Heterogeneous Assignment:** A heterogeneous bit-width assignment strategy optimizes the trade-off between model size and coding performance.
*   **Algorithmic Efficiency:** An adaptive search algorithm significantly reduces time complexity for finding optimal quantization bit-widths compared to standard search methods.

---

## Methodology

The research introduces the **Flexible Mixed Precision Quantization (FMPQ)** framework, designed to overcome the limitations of uniform quantization.

*   **Layer-wise Bit Assignment:** The framework employs a specific bit-assignment strategy based on the *fractional change in rate-distortion loss*. This metric prioritizes assigning bits to layers where they yield the highest efficiency.
*   **Adaptive Search:** To handle the complexity of mixed precision, the authors utilize an adaptive search algorithm. This rapidly determines the optimal distribution of bit-widths that satisfies specific model size constraints, avoiding the computational expense of exhaustive search.

---

## Technical Details

| Component | Description |
| :--- | :--- |
| **Core Strategy** | **Flexible Mixed Precision Quantization (FMPQ)** utilizing a heterogeneous bit-width assignment strategy. |
| **Differentiation** | Unlike fixed-precision methods, FMPQ assigns different quantization bit-widths to different network layers to balance model size constraints against coding performance. |
| **Optimization** | An adaptive search algorithm is used to determine optimal bit-widths while effectively reducing time complexity. |
| **Metric** | Bit-assignment is driven by the sensitivity of the rate-distortion loss, quantified as the fractional change in loss. |

---

## Contributions

*   **Novel Strategy:** Introduction of FMPQ, a new mixed-precision quantization strategy specifically designed for Learned Image Compression.
*   **Theoretical Criterion:** Establishment of a mathematically defined bit-assignment criterion grounded in rate-distortion loss sensitivity.
*   **Algorithmic Efficiency:** Development of an adaptive search algorithm to efficiently solve the combinatorial challenge of bit-width configuration.
*   **Validation:** Empirical evidence validating superior BD-Rate metrics compared to existing works.
*   **Reproducibility:** Release of source code to support further research and application.

---

## Performance Results

The FMPQ method demonstrates significant improvements in both coding efficiency and computational load:

*   **Coding Performance:** The method achieves better BD-Rate performance compared to traditional fixed-precision quantization while operating under similar model size constraints.
*   **Search Efficiency:** The adaptive search algorithm demonstrates a significant reduction in time complexity for identifying optimal bit-widths relative to baseline methods, reducing search times by over 100x.

---
**References:** 30 citations