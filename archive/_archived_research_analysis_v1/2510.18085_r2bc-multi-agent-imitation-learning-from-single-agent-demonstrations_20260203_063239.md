---
title: 'R2BC: Multi-Agent Imitation Learning from Single-Agent Demonstrations'
arxiv_id: '2510.18085'
source_url: https://arxiv.org/abs/2510.18085
generated_at: '2026-02-03T06:32:39'
quality_score: 8
citation_count: 38
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# R2BC: Multi-Agent Imitation Learning from Single-Agent Demonstrations

*Connor Mattson; Varun Raveendra; Ellen Novoseller; Nicholas Waytowich; Vernon J. Lawhern; Daniel S. Brown*

---

> ### üìä Quick Facts
> *   **Quality Score:** 8/10
> *   **References:** 38 Citations
> *   **Validation Environments:** 4 Simulated Tasks (VMAS), 2 Physical Robot Tasks
> *   **Core Methodology:** Round-Robin Behavior Cloning (R2BC)
> *   **Key Advantage:** Eliminates need for synchronized multi-agent demonstrations

---

## Executive Summary

### üö® Problem
Training multi-agent systems via imitation learning is bottlenecked by the requirement for synchronized demonstrations in the joint multi-agent action space. Standard approaches assume access to data where all agents act optimally simultaneously‚Äîa scenario that is practically infeasible to collect. Coordinating multiple human demonstrators is resource-intensive, while a single human operator cannot teleoperate multiple robots at once. This research addresses this scalability challenge by aiming to train coordinated multi-agent teams using only data feasible for a single human to collect.

### üí° Innovation
The authors introduce **Round-Robin Behavior Cloning (R2BC)**, a decentralized imitation learning framework that synthesizes global multi-agent policies from sequential, single-agent demonstrations. The core mechanism involves a human operator teleoperating one agent at a time in a round-robin cycle, while remaining agents execute policies derived from previously collected observations. Crucially, the system operates online during data collection: as the human demonstrates behavior for one agent, others actively interact with the environment. This simultaneous execution increases demonstration diversity and enhances resilience against distribution shift, bypassing the need for centralized, synchronized joint action data.

### üìà Results
The efficacy of R2BC was validated in the **Vectorized Multi-Agent Simulator (VMAS)** across four distinct cooperative tasks (*Navigation, Balance, Buzz Wire, Transport*) involving 2‚Äì3 robots. Benchmarking against privileged "oracle" baselines (Joint Behavior Cloning, DAgger, DART), R2BC matched or surpassed performance across all tasks. Performance was measured using normalized scores (0.0‚Äì1.0) and loss gap metrics, averaged over 10 seeds with 99% confidence intervals. Furthermore, the framework was successfully deployed on two physical robot tasks using real human demonstrations, confirming its sim-to-real transfer capabilities.

### üåç Impact
This research establishes a paradigm shift in multi-agent learning by demonstrating that high-level synchronous collaborative behavior can emerge from heterogeneous, sequential single-agent data. By proving that decentralized, sequential training can achieve parity with centralized methods requiring privileged synchronized information, R2BC eliminates the dependency on multi-operator demonstrations. This drastically reduces the cost and complexity of data collection, lowering the barrier to deploying multi-robot systems and enabling new possibilities for human-in-the-loop robotics.

---

## Key Findings

*   **Oracle-Level Performance:** R2BC matches or surpasses the performance of "oracle" behavior cloning approaches that rely on privileged, synchronized demonstrations, despite using only sequential single-agent data.
*   **Robust Validation:** The method was validated across four distinct multi-agent simulated tasks, demonstrating robustness in various environments.
*   **Sim-to-Reality Transfer:** The approach successfully transitions from simulation to reality, having been deployed on two physical robot tasks trained with real human demonstrations.
*   **Decentralized Learning:** Effective multi-agent behavior can be learned without requiring demonstrations in the complex joint multi-agent action space.

---

## Methodology

The researchers introduce **Round-Robin Behavior Cloning (R2BC)**, a novel imitation learning framework designed to train multi-agent systems using data from a single human operator.

The approach operates as follows:
1.  **Sequential Operation:** A human teleoperates one agent at a time, providing sequential, single-agent demonstrations.
2.  **Incremental Learning:** The system incrementally learns multi-agent collaborative behaviors by cycling through agents in a round-robin fashion.
3.  **Bottleneck Resolution:** This method bypasses the technical difficulty of capturing demonstrations in the joint multi-agent action space, allowing the team to learn coordinated behaviors from individual, isolated interactions.

---

## Contributions

*   **Solves Data Bottleneck:** Addresses the gap in imitation learning literature by providing a viable method for a single human to train a team of collaborating robots, solving the data collection bottleneck in multi-agent settings.
*   **Novel Algorithm:** Proposes the R2BC algorithm that enables the synthesis of global multi-agent policies from local, single-agent demonstrations.
*   **Performance Parity:** Establishes that sequential, decentralized training can achieve performance levels comparable to or better than centralized methods requiring synchronized data.
*   **Empirical Validation:** Provides comprehensive empirical evidence of the method's efficacy through both high-fidelity simulation and physical robot hardware experiments.

---

## Technical Details

R2BC is a decentralized imitation learning framework that learns multi-agent behavior using sequential single-agent demonstrations instead of centralized joint action demonstrations.

**Key Features:**
*   **Decentralization:** Features policy and demonstration decentralization to address constraints like limited bandwidth and partial observability.
*   **Online Operation:** The method operates online, where demonstrations are provided while other agents execute policies cloned from previous observations.
*   **Resilience:** This online approach increases demonstration diversity and resilience against distribution shift.
*   **Ablation Confirmation:** Ablation studies confirm that both decentralization and online policy learning are essential for success.

---

## Results

**Experimental Setup:**
*   **Environment:** Vectorized Multi-Agent Simulator (VMAS)
*   **Tasks:** Navigation, Balance, Buzz Wire, Transport
*   **Agents:** 2‚Äì3 robots per task

**Baselines:**
*   R2BC was compared against privileged oracle baselines: **JBC** (Joint Behavior Cloning), **DAgger**, and **DART**.

**Outcomes:**
*   **Superior Performance:** R2BC outperformed or achieved parity with these baselines across all tasks based on normalized performance (0.0 to 1.0) and loss gap metrics.
*   **Statistical Significance:** Results were averaged over 10 seeds with 99% confidence intervals.
*   **Scalability:** Performance improved consistently as more demonstrations were added.
*   **Hardware Deployment:** The method was successfully deployed on two physical robot tasks using real human demonstrations.

---

**Quality Score:** 8/10 | **References:** 38 citations