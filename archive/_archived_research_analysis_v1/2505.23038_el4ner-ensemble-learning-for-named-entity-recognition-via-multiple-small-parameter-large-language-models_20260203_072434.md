---
title: 'EL4NER: Ensemble Learning for Named Entity Recognition via Multiple Small-Parameter
  Large Language Models'
arxiv_id: '2505.23038'
source_url: https://arxiv.org/abs/2505.23038
generated_at: '2026-02-03T07:24:34'
quality_score: 9
citation_count: 30
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# EL4NER: Ensemble Learning for Named Entity Recognition via Multiple Small-Parameter Large Language Models

*Yuzhen Xiao; Jiahe Song; Yongxin Xu; Ruizhe Zhang; Yiqi Xiao; Xin Lu; Runchuan Zhu; Bowen Jiang; Junfeng Zhao*

---

> ### ðŸ“Š Quick Facts
>
> *   **Quality Score:** 9/10
> *   **Total Parameters:** < 40B
> *   **Methodology:** Ensemble Learning / In-Context Learning (ICL)
> *   **Key Metric (CoNLL-2003):** F1 Score of **82.8%** (vs GPT-3.5 at 74.4%)
> *   **Key Advantage:** State-of-the-art performance with significantly lower deployment costs and no need for massive computational resources.

---

## Executive Summary

Named Entity Recognition (NER) is a foundational component of information extraction systems, yet current implementations face a critical trade-off between accuracy and computational cost. Achieving state-of-the-art performance typically necessitates massive, closed-source Large Language Models (LLMs) like the GPT series. While these models offer superior reasoning, they incur prohibitive API expenses, high latency, and significant data privacy risks. Conversely, open-source, small-parameter models offer resource efficiency and privacy but generally lack the individual reasoning capacity to match proprietary benchmarks. This paper addresses the challenge of bridging this performance gap without relying on expensive or proprietary infrastructure.

The authors introduce **EL4NER**, a framework that leverages ensemble learning to aggregate In-Context Learning (ICL) outputs from multiple open-source, small-parameter LLMs. The system decomposes NER into a four-stage pipeline: Demonstration Retrieval, Span Extraction, Span Classification, and Type Verification. A key technical contribution is the **Span-Level Sentence Similarity Algorithm**, which optimizes demonstration retrieval by focusing on NER-specific task features rather than general sentence semantics. The framework employs a non-cascade, unsupervised aggregation strategyâ€”using Union for extraction and Voting for classificationâ€”followed by a **Self-Validation Mechanism** to filter noise and verify entity types. This design allows the collective intelligence of smaller models to mimic the reasoning of larger singular architectures.

EL4NER achieves state-of-the-art results among In-Context Learning based methods across multiple benchmarks. Specifically, on the CoNLL-2003 dataset, the framework attains an F1 score of **82.8%**, significantly outperforming the GPT-3.5 baseline (74.4%). It also demonstrates superior performance on the Few-NERD (INTRA and INTER) and OntoNotes 5.0 datasets, surpassing individual small-parameter baselines such as Llama-2-7B and Vicuna-7B. Crucially, EL4NER achieves these results with a total ensemble parameter count of less than 40B, offering massive efficiency gains compared to the 175B+ parameters typical of closed-source models. Qualitative evaluations confirm that the self-validation mechanism effectively mitigates the noise typically associated with aggregating predictions from diverse sources.

This research represents a significant advancement for deploying NLP systems by demonstrating that high-performance NER is attainable without massive computational resources or proprietary dependencies. By providing a resource-optimized, open-source solution, EL4NER enhances data privacy and facilitates greater collaboration by removing reliance on external APIs. The drastic reduction in parameter countâ€”totaling less than 40B compared to monolithic giantsâ€”translates to substantially lower deployment and inference costs. This democratizes access to high-quality entity recognition, offering organizations a scalable, cost-effective alternative for implementing advanced NLP capabilities.

---

## Key Findings

*   **Superior Performance:** EL4NER outperforms most closed-source, large-parameter LLM-based methods (specifically GPT-series models) in NER tasks.
*   **Cost Efficiency:** Maintains significantly lower parameter costs (total < 40B) while achieving high accuracy, reducing deployment and API expenses.
*   **SOTA for ICL:** Achieves state-of-the-art results among In-Context Learning (ICL) based methods on various datasets, including CoNLL-2003, Few-NERD, and OntoNotes 5.0.
*   **Resource Optimization:** Demonstrates that high performance in NER is attainable without massive computational resources by utilizing open-source, small-parameter LLMs.
*   **Noise Reduction:** The self-validation mechanism effectively mitigates noise, ensuring the reliability of aggregating predictions from diverse models.

---

## Methodology

The proposed EL4NER framework utilizes an **ensemble learning strategy** to aggregate In-Context Learning (ICL) outputs from multiple open-source, small-parameter LLMs. The methodology is built upon three core components:

1.  **Task Decomposition Pipeline:** Designed for the deep integration of NER sub-tasks.
2.  **Span-Level Sentence Similarity Algorithm:** Optimizes demonstration retrieval specifically for NER, moving beyond general semantic similarity.
3.  **Self-Validation Mechanism:** A noise mitigation strategy to verify the consistency of aggregated predictions.

The approach is non-cascade and unsupervised, aggregating full results from candidate models rather than relying on a sequential processing chain.

---

## Technical Details

EL4NER employs a task decomposition strategy that splits the problem into **Span Extraction** and **Span Classification**. The process is implemented through a structured four-stage pipeline:

1.  **Demonstration Retrieval:**
    *   Utilizes a **span-level sentence similarity algorithm** tailored for In-Context Learning to retrieve the most relevant examples.
2.  **Span Extraction:**
    *   Uses ICL with **Union aggregation** to identify potential entity spans from the ensemble of models.
3.  **Span Classification:**
    *   Uses ICL with **Voting aggregation** to determine the specific entity type for the extracted spans.
4.  **Type Verification (Self-Validation):**
    *   A final filtering step designed to remove noise and verify that the predicted types are consistent.

**Framework Constraints:**
*   **Model Type:** Ensemble of multiple open-source, small-parameter LLMs.
*   **Total Parameter Count:** Below 40B.
*   **Training Requirement:** Unsupervised aggregation (no fine-tuning required for the aggregation logic).

---

## Results

*   **Benchmark Performance:** EL4NER achieved State-of-the-Art (SOTA) performance among In-Context Learning based methods across multiple datasets.
*   **CoNLL-2003:** Attained an F1 score of **82.8%**, significantly beating the GPT-3.5 baseline of 74.4%.
*   **Generalizability:** Demonstrated strong performance across diverse domains, including Few-NERD (INTRA and INTER) and OntoNotes 5.0.
*   **Efficiency Metrics:**
    *   Total parameter count remains under 40B.
    *   Significantly lower deployment and inference costs compared to large open-source and closed-source models (e.g., 175B+ parameters).
*   **Qualitative Analysis:** Confirmed that the self-validation mechanism is crucial for maintaining high reliability by filtering out incorrect predictions from the ensemble.

---

## Core Contributions

*   **Resource-Optimized Solution:** Provides a high-performance NER solution that drastically reduces computing demands and manual labeling overhead.
*   **Privacy & Collaboration:** By relying on open-source models, the framework enhances data privacy and removes the dependency on external, proprietary APIs.
*   **Novel Similarity Metric:** Introduces a specialized **span-level sentence similarity metric** for demonstration retrieval, improving upon standard semantic search methods.
*   **Noise-Reduction Strategy:** Develops a self-validation mechanism to improve the reliability of aggregating predictions from multiple smaller models.

---
**References:** 30 citations