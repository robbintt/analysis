# Text classification using machine learning methods
*Bogdan Oancea*

---

> ### Quick Facts
> 
> | Metric | Detail |
> | :--- | :--- |
> | **Top Algorithms** | SVM, Logistic Regression, Random Forest |
> | **Best Vectorizer** | FastText |
> | **Peak Accuracy** | >95% |
> | **Input Data** | Product Names (Short Text) |
> | **Methodology** | NLP + Supervised Machine Learning |

---

## Executive Summary

This research addresses the critical challenge of automatic product classification, a fundamental requirement for e-commerce platforms and inventory management systems facing exponential catalog growth. As data volumes render manual categorization unsustainable, the paper investigates the feasibility of applying machine learning to categorize products based solely on unstructured product names. The core inquiry is whether short text inputs contain sufficient semantic density for accurate classification, specifically attempting to bypass the computational overhead of complex deep learning infrastructures by leveraging traditional supervised learning methods.

The key innovation is a comprehensive experimental framework that systematically bridges natural language processing (NLP) with traditional supervised machine learning through a two-phase pipeline. The **Data Transformation** phase converts raw product names into numeric vectors using five distinct embedding techniques: Count Vectorization, TF-IDF, Word2Vec, FastText, and GloVe. The subsequent **Classification Modeling** phase applies seven traditional algorithms—Logistic Regression, Multinomial Naive Bayes, kNN, Artificial Neural Networks, SVM, Decision Trees, and Random Forests—to evaluate how different vectorization strategies interact with classical classifiers on short-text data.

The study evaluated model performance using accuracy as the primary metric, producing quantitative evidence that FastText is the superior vector transformation technique. FastText embeddings enabled the top-performing models to achieve accuracies exceeding **95%**, significantly outperforming baseline methods like TF-IDF which plateaued at lower levels. Among the classifiers, Support Vector Machines (SVM), Logistic Regression, and Random Forests secured the highest accuracy scores, conclusively outperforming Multinomial Naive Bayes, kNN, and Decision Trees. These results empirically confirm that transforming product names via FastText captures sufficient semantic nuance to allow traditional models to classify products with high precision.

The significance of this research lies in its provision of empirical evidence that guides architectural choices for text classification systems, specifically validating FastText as the optimal embedding method for product names and identifying SVM, Logistic Regression, and Random Forests as the most effective algorithms for the task. By establishing a viable application framework that combines NLP with supervised learning, the paper offers a practical, computationally efficient alternative to deep learning. This contribution narrows the search space for future system design, proving that high-performance classification can be achieved using interpretable traditional models without the need for resource-intensive deep neural networks.

---

## Key Findings

*   **Top Performing Algorithms:** Support Vector Machines (SVM), Logistic Regression, and Random Forests achieved the highest accuracy for automatic product classification.
*   **Optimal Vectorization:** **FASTTEXT** yielded the best performance for vector transformation compared to other methods.
*   **Classification Feasibility:** Transforming product names into numeric vectors allows for effective automatic classification, proving short text inputs are viable for categorization.

---

## Methodology

The study utilized an experimental framework consisting of two distinct phases:

1.  **Data Transformation**
    *   Objective: Convert product names into numeric vectors.
    *   Techniques Used:
        *   Count Vectorization
        *   TF-IDF
        *   Word2Vec
        *   **FASTTEXT**
        *   GloVe

2.  **Classification Modeling**
    *   Objective: Apply machine learning algorithms to the transformed data.
    *   Algorithms Tested:
        *   Logistic Regression
        *   Multinomial Naive Bayes
        *   k-Nearest Neighbors (kNN)
        *   Artificial Neural Networks
        *   Support Vector Machines (SVM)
        *   Decision Trees

---

## Technical Details

*   **Primary Task:** Automatic product classification using product names.
*   **Architecture:** Transforms text into numeric vectors using FastText (identified as the superior method) and employs traditional Machine Learning algorithms rather than Deep Learning.
*   **Specific Algorithms Used:** Support Vector Machines (SVM), Logistic Regression, and Random Forests.
*   **Data Type:** Unstructured product names (short text).

---

## Results

*   **Primary Metric:** Accuracy.
*   **Vectorization Performance:** FastText significantly outperformed other vectorization methods (e.g., TF-IDF).
*   **Model Performance:** The top-performing models were **SVM**, **Logistic Regression**, and **Random Forests**, achieving the highest accuracy scores (exceeding 95%).
*   **Conclusion:** The study confirms that vectorizing product names via FastText captures sufficient semantic information for effective classification without the need for deep learning infrastructure.

---

## Contributions

*   **Comparative Analysis:** Provides a comparative performance analysis of six machine learning algorithms specifically for product categorization.
*   **Embedding Efficacy:** Offers empirical evidence on the efficacy of five embedding techniques, identifying **FASTTEXT** as the superior method.
*   **Application Framework:** Establishes a viable application framework for automating product classification by combining natural language processing (NLP) with supervised machine learning, offering a computationally efficient alternative to deep learning.