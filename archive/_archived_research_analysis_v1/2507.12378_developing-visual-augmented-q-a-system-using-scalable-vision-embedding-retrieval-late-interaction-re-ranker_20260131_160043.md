# Developing Visual Augmented Q&A System using Scalable Vision Embedding Retrieval & Late Interaction Re-ranker

*Rachna Saxena; Abhijeet Kumar; Suresh Shanmugam*

---

> **QUICK FACTS**
>
> *   **Vision Model:** ColPali (based on PaliGemma)
> *   **Reader Model:** Claude Sonnet 3.5
> *   **Vector Database:** OpenSearch (HNSW)
> *   **Embedding Config:** 128 dimensions per patch
> *   **Processing:** 1,030 patches per page
> *   **Threshold:** 0.9 similarity score
> *   **Metric:** Cosine Similarity

---

## Executive Summary

This research addresses a critical infrastructure bottleneck preventing the enterprise adoption of advanced visual retrieval systems: the incompatibility of state-of-the-art Multimodal Large Language Models (MLLMs) and late interaction models (like ColPali) with standard vector databases. While these models excel at analyzing complex visual elements such as charts, tables, and infographics, they output multi-vector embeddings that are not natively supported by ubiquitous production databases like OpenSearch. Additionally, the high computational footprint and memory requirements of these models create prohibitive costs and latency issues. This disconnect prevents organizations from solving the "needle in a haystack" problem within large, visually rich document sets using existing, scalable infrastructure.

The authors propose a two-stage architecture that decouples retrieval from re-ranking to enable advanced visual retrieval on standard infrastructure. The system first utilizes a hybrid search strategy, combining metadata filtering with standard semantic embedding retrieval to efficiently narrow the candidate pool. To handle the multi-vector output of the Vision Embedding Model (ColPali/PaliGemma), the architecture implements a specific "flattening" technique that converts 2D page embeddings into individual row entries within OpenSearch. This allows the system to utilize Hierarchical Navigable Small World (HWS) indexing for approximate nearest neighbor search on individual patches. A subsequent late interaction re-ranker then reconstructs full page embedding matrices for the top candidates to perform precise MaxSim calculations before passing the context to a reader model (Claude Sonnet 3.5).

Although the paper does not provide exhaustive benchmark tables, it validates the systemâ€™s operational efficiency through specific quantitative configuration parameters necessary for maintaining performance. The implementation processes page embeddings split into 1,030 patches of 128 dimensions each. To manage computational load, the system employs a strict candidate filtering mechanism using a 0.9 similarity threshold relative to the top score and utilizes cosine similarity metrics. These constraints enable the system to leverage HNSW indexing to bypass the performance penalties of brute-force late interaction, achieving significant retrieval speedups required for enterprise scalability while preserving the high Recall@1 capabilities inherent to the ColPali architecture.

This work provides a validated framework for Visual Augmented Q&A by demonstrating that late interaction mechanisms can effectively run on widely adopted, off-the-shelf vector databases without custom development or infrastructure overhauls. By successfully bridging the gap between theoretical visual analysis models and practical enterprise constraints, the authors remove a major barrier to entry for organizations seeking to implement visual retrieval. The research validates a scalable RAG architecture where MLLMs function effectively as "readers" of context-rich visual data, establishing a viable path for reasoning over complex infographics in real-world production environments.

---

## Key Findings

*   **Scalability without Performance Loss:** The proposed multi-step custom implementation achieves significant speedups in retrieval, making the system scalable for enterprise use without degrading the quality of performance.
*   **Bridging Infrastructure Gaps:** The design successfully overcomes the limitation of widely adopted vector databases that lack native multi-vector retrieval support, enabling the use of advanced late interaction mechanisms in production environments.
*   **Solution to the "Need in a Haystack" Problem:** By combining hybrid search with a late interaction re-ranker, the system effectively handles the complexity of finding relevant information within large document sets or long contexts, specifically for visual elements like infographics.
*   **Effective Enterprise RAG Pipeline:** The validation of using Multimodal LLMs (MLLM) as "readers" to generate answers from refined, context-rich pages demonstrates a stable architecture for production-grade multimodal Q&A systems.

---

## Methodology

The researchers propose a multi-step custom implementation designed to balance efficiency with accuracy:

1.  **Retrieval Stage:** Utilization of a widely adopted hybrid search strategy, combining both metadata filtering and standard embedding retrieval.
2.  **Refinement Stage:** Application of a state-of-the-art late interaction re-ranker to process the initial retrieval results and select the best-matching pages. This step bridges the gap between standard vector databases and advanced visual retrieval.
3.  **Generation Stage:** Deployment of a Multimodal Large Language Model (MLLM) acting as a "reader," which is prompted to generate answers based on the contextualized pages retrieved in the previous steps.

---

## Technical Details

The system proposes a two-stage 'Retriever-Re-ranker' pipeline using a Hybrid Retrieval & Late Interaction Re-ranking architecture.

**Component 1: Vision Embedding Model (ColPali)**
*   Based on PaliGemma.
*   Splits document pages into patches.
*   Generates multi-vector embeddings (1,030 patches per page, 128 dimensions per patch).

**Component 2: Scalable Indexing (OpenSearch)**
*   Handles multi-vector storage by "flattening" 2D page embeddings into individual row entries.
*   Metadata tagged with `file_name`, `page_number`, and `patch_number`.
*   Utilizes HNSW (Hierarchical Navigable Small World) with Cosine Similarity.

**Component 3: Token-Level Retrieval**
*   The query is embedded into a matrix.
*   Search is performed for each token against the patch embeddings.
*   Candidates are filtered based on a threshold (>= 0.9 relative to top score).
*   Page numbers are aggregated for candidate selection.

**Component 4: Late Interaction Re-ranking**
*   Full page embedding matrices for candidates are reconstructed.
*   Matched against the query using a maximum similarity operation (MaxSim).

**Component 5: Reader (Claude Sonnet 3.5)**
*   Generates answers from the re-ranked pages.

---

## Contributions

*   **Identification of Technical Bottlenecks:** The paper explicitly identifies three critical barriers to adopting late interaction mechanisms in enterprise RAG: the lack of native multi-vector support in standard vector databases, the high computational space footprint, and the inability to leverage approximate neighbor search for speed optimization.
*   **Pragmatic Architecture Design:** The authors contribute a pragmatic system design that decouples hybrid search filtering from late interaction re-ranking. This allows enterprises to leverage state-of-the-art visual retrieval performance without requiring infrastructure overhauls or accepting prohibitive computational costs.
*   **Advancement in Visual Augmented Q&A:** The work advances the field by moving beyond text-only extraction, providing a validated solution for retrieving and reasoning over complex visual infographics (tables, charts, images) within a scalable, production-ready framework.

---

## Results

The text notes that specific experimental result tables were not included, but provides quantitative configuration parameters defined in the methodology: patch embeddings are 128 dimensions, there are 1,030 patches per page, the similarity threshold for candidate filtering is 0.9, and the search metric is Cosine Similarity.

**Qualitative findings indicate:**
*   The implementation achieves significant speedups enabling enterprise-scale use.
*   It preserves high-quality retrieval (referencing ColPali's strong Recall@1).
*   It successfully bridges the infrastructure gap to enable late interaction mechanisms on standard vector databases like OpenSearch.

---

**References:** 19 citations | **Quality Score:** 7/10