---
title: Securing Agentic AI Systems -- A Multilayer Security Framework
arxiv_id: '2512.18043'
source_url: https://arxiv.org/abs/2512.18043
generated_at: '2026-02-03T06:50:30'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Securing Agentic AI Systems -- A Multilayer Security Framework

*Sunil Arora; John Hastings*

---

## üìã Executive Summary

Existing cybersecurity frameworks are insufficient for securing Agentic AI systems because they fail to address the unique risks introduced by autonomous, decision-making, and adaptive behaviors. Unlike traditional AI models, agentic systems interact dynamically with environments and can execute unauthorized actions, making them vulnerable to adversarial manipulation and complex operational failures. As enterprises increasingly deploy these autonomous agents, the lack of a specialized governance model creates a critical security gap where current standards cannot adequately mitigate the specific threats posed by independent software actors.

To bridge this gap, the authors introduce the **Multilayer Agentic AI Security (MAAIS)** framework, developed using Design Science Research (DSR) to ensure a rigorous, artifact-based approach. The core technical innovation of MAAIS is the evolution of the traditional CIA triad into "**Agentic AI CIAA**," which adds **Accountability** as a fourth pillar to specifically trace and govern autonomous decisions. This lifecycle-aware architecture integrates multiple defense layers across the agent's entire operational span, providing tailored controls that address the nuances of agency rather than relying on static, reactive security measures.

The efficacy of the MAAIS framework was validated through a structural mapping exercise against the **MITRE ATLAS** matrix, a comprehensive knowledge base of adversarial tactics targeting AI systems. The study successfully demonstrated that MAAIS covers known AI threat vectors by aligning its defensive layers with established tactics. However, the validation was qualitative in nature; the authors explicitly note that quantitative performance metrics, such as detection rates or comparative benchmarks against other frameworks, were not available for this study.

This research significantly advances the field by establishing a standardized, lifecycle-aware approach to securing agentic AI. The introduction of the Agentic AI CIAA concept provides a new foundational vocabulary and governance model for security professionals. For enterprises, the MAAIS framework offers actionable, step-by-step operational guidance for CISOs and engineering teams, facilitating the safe deployment of autonomous agents while ensuring that accountability is maintained throughout the system's lifecycle.

> ### üìä Quick Facts
> *   **Quality Score:** 8/10
> *   **Total Citations:** 40
> *   **Methodology:** Design Science Research (DSR)
> *   **Validation Method:** Structural mapping against MITRE ATLAS
> *   **Core Innovation:** Introduction of "Accountability" to the CIA triad (CIAA)

---

## üîë Key Findings

*   **Security Gap:** Existing AI security frameworks fail to adequately address the unique cyber risks introduced by the autonomous, decision-making, and adaptive behaviors of Agentic AI systems.
*   **Distinct Challenges:** Agentic AI introduces distinct security challenges, including unauthorized actions, adversarial manipulation, and complex interactions with dynamic environments.
*   **MAAIS Framework:** The research introduces **MAAIS** (Multilayer Agentic AI Security), a lifecycle-aware security framework that integrates multiple defense layers.
*   **Evolved Triad:** The study proposes an evolution of the traditional CIA triad into **'Agentic AI CIAA'**, adding Accountability as a critical fourth pillar.
*   **Validation:** The framework's efficacy was validated by successfully mapping its structure against the established tactics within the MITRE ATLAS.

---

## ‚öôÔ∏è Technical Details

**Framework Name:** MAAIS (Multilayer Agentic AI Security)

**Architecture Type:** Lifecycle-aware, multilayer security architecture.

**Core Innovation:**
*   **Agentic AI CIAA:** Extends the traditional CIA triad by adding a fourth pillar, **Accountability**, to specifically address autonomous decision-making.

**Target Risk Areas:**
*   Unauthorized actions
*   Adversarial manipulation
*   Interactions within dynamic environments

---

## üß™ Methodology

*   **Design Science Research (DSR):** The authors utilized DSR to construct the security framework, ensuring a rigorous and artifact-based approach.
*   **Structural Validation:** The proposed framework was validated by mapping its defensive layers and controls against the known adversarial tactics outlined in the MITRE ATLAS matrix.

---

## üìù Contributions

1.  **The MAAIS Framework:** A standardized, multilayer security framework specifically designed for the governance and deployment of agentic AI systems across their entire lifecycle.
2.  **The Agentic AI CIAA Concept:** The introduction and definition of the Confidentiality, Integrity, Availability, and Accountability (CIAA) concept tailored to the nuances of autonomous agents.
3.  **Operational Guidance for Enterprises:** A detailed, step-by-step security approach intended for practical use by CISOs, security teams, AI platform owners, and engineering teams.

---

## üìà Results

The framework was validated through structural mapping against the MITRE ATLAS matrix. The study successfully mapped MAAIS against established MITRE ATLAS tactics, demonstrating coverage of known AI threat vectors.

*Note:* The provided text notes that quantitative metrics (e.g., detection rates) and comparative benchmarks were not available.

---
*References: 40 citations*