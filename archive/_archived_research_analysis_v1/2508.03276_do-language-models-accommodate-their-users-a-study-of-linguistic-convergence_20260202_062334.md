# Do language models accommodate their users? A study of linguistic convergence

*Terra Blevins; Susanne Schmalwieser; Benjamin Roth*

---

### üìù Executive Summary

This research addresses the critical gap in understanding "linguistic convergence" within Large Language Models (LLMs)‚Äîthe adaptation of conversational style to match an interlocutor. While essential for natural human-computer interaction, this accommodation poses a risk of inducing sycophancy or excessive mimicry. The study aims to determine whether LLMs genuinely simulate human pragmatic adaptation or merely exploit statistical patterns, a distinction vital for developing socially aware AI that engages naturally without compromising reliability or autonomy.

The authors introduce a rigorous experimental paradigm to benchmark linguistic accommodation across sixteen models, including Llama (1 and 2), PaLM, and Pythia, in both Pretrained (PT) and Instruction-Tuned (IT) configurations. To ensure robustness, the study utilizes three distinct dialogue corpora: DailyDialog, Movie Corpus, and NPR. The methodology implements a human-model experimental paradigm where models complete turns based on a context window of five prior turns (`m=5`), replacing a speaker at turn `t=6` and continuing on even turns. Convergence is quantified using specific stylometric features, comparing results against both human and random baselines.

The findings reveal that LLMs demonstrate strong linguistic adaptation but frequently **"overconverge,"** exaggerating accommodation beyond the human baseline. Crucially, the study identifies that both instruction-tuning and larger model size contribute to reduced convergence; IT models and larger architectures exhibit less accommodation than their smaller or pretrained counterparts, bringing behavior closer to human norms. This paper provides the first comprehensive empirical benchmark of pragmatic adaptation in LLMs, offering critical evidence that while current alignment training mitigates excessive mimicry, it does not fully align models with human social behavior.

---

> ### üìä Quick Facts
> *   **Quality Score:** 9/10
> *   **Models Analyzed:** 16
> *   **Datasets Used:** 3
> *   **Total Citations:** 18
> *   **Key Variables:** Pretrained (PT) vs. Instruction-Tuned (IT), Model Scale

---

## üîë Key Findings

*   **Strong Convergence & Overfitting:** Language models strongly converge to the linguistic style of conversation, often "overfitting" compared to the human baseline.
*   **Impact of Training:** Instruction-tuned and larger models exhibit **less convergence** than their pretrained and smaller counterparts.
*   **Feature Variance:** Convergence patterns vary significantly by specific stylometric features (e.g., length vs. function words).
*   **Divergent Mechanisms:** The mechanisms driving convergence are fundamentally distinct between humans and models.

## üõ†Ô∏è Methodology

Researchers conducted a systematic comparison between model-generated completions of dialogues and original human responses. The study employed the following approach:

1.  **Corpus Analysis:** Analyzed sixteen different language models across three distinct dialogue corpora.
2.  **Stylometric Quantification:** Used stylometric features to quantify and measure the degree of linguistic convergence.
3.  **Benchmarking:** Compared generated responses directly against human and random baselines to establish normative behavior.

## ‚öôÔ∏è Technical Details

The study utilizes a specific human-model experimental paradigm designed to isolate stylistic adaptation.

**Experimental Setup**
*   **Context Window:** Models are provided a context window of `m=5` prior turns.
*   **Turn Replacement:** The model replaces a speaker at turn `t=6` and continues the dialogue on even turns.
*   **Datasets:**
    *   DailyDialog
    *   Movie Corpus
    *   *NPR* (filtered for specific turn and speaker counts)

**Models Evaluated**
*   **Architectures:** Gemma 3 (1B‚Äì27B) and Llama 3 (1B‚Äì70B).
*   **Configurations:** Both Pretrained (PT) and Instruction-Tuned (IT).

**Evaluation Metrics**
Convergence was measured using a variety of linguistic features, including:
*   **Language Style Matching (LSM):** Specifically for utterance length.
*   **LIWC 2007 Agreement:** Analyzing 9 function word classes.
*   **PROPN Overlap:** Utilizing spaCy for proper noun detection.
*   **Token Novelty:** Measuring the uniqueness of the generated vocabulary.

## üìà Results

The empirical analysis yielded significant insights into how LLMs handle linguistic accommodation:

*   **Overconvergence:** LLMs demonstrate strong linguistic adaptation, with pretrained models frequently "overconverging" relative to the human baseline. This suggests an exaggerated accommodation that differs fundamentally from human mechanisms.
*   **Tuning & Scale:** Instruction-tuned models exhibit less convergence than pretrained models, bringing behavior closer to the human baseline. Similarly, larger models generally show less convergence than smaller models, indicating that scaling moderates stylistic adaptation.
*   **Feature Specificity:** Convergence varies significantly across stylometric features (e.g., length vs. LIWC), with patterns differing from human variance.

## üèÜ Contributions

This paper makes several significant contributions to the field of NLP and AI pragmatics:

*   **Pragmatic Investigation:** It investigates the understudied pragmatic area of 'linguistic convergence' in LLMs.
*   **Benchmarking Overfitting:** It benchmarks model adaptation, providing empirical evidence of style overfitting relative to human norms.
*   **Architectural Insights:** It offers insights into how architectural factors and training phases influence a model's tendency to mimic human accommodation.

---

**ÂèÇËÄÉÊñáÁåÆ | References:** 18 citations