---
title: Zero-Shot Event Causality Identification via Multi-source Evidence Fuzzy Aggregation
  with Large Language Models
arxiv_id: '2506.05675'
source_url: https://arxiv.org/abs/2506.05675
generated_at: '2026-02-03T07:06:03'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Zero-Shot Event Causality Identification via Multi-source Evidence Fuzzy Aggregation with Large Language Models

*Zefan Zeng; Xingchen Hu; Qing Cheng; Weiping Ding; Wentao Li; Zhong Liu*

---

> ### **Quick Facts: Key Metrics**
> *   **Framework:** MEFA (Multi-source Evidence Fuzzy Aggregation)
> *   **Primary Improvement:** +6.2% F1-score / +9.3% Precision
> *   **Approach:** Zero-Shot Learning with LLMs
> *   **Key Innovation:** Fuzzy Aggregation to mitigate hallucination
> *   **Quality Score:** 8/10
> *   **References:** 40 Citations

---

## Executive Summary

**Problem**
Event Causality Identification (ECI) is a critical task in natural language processing that traditionally requires expensive, large-scale annotated datasets to train supervised models. While Large Language Models (LLMs) offer a promising alternative for zero-shot learning, they frequently suffer from "causal hallucination"—the tendency to generate plausible but factually incorrect or spurious causal links. This unreliability limits the application of LLMs in domains requiring rigorous causal reasoning. This paper addresses the challenge of achieving high-performance ECI without labeled data while specifically mitigating the issue of causal hallucinations inherent in generative models.

**Innovation**
The authors introduce **MEFA (Multi-source Evidence Fuzzy Aggregation)**, a novel zero-shot framework that refines LLM reasoning through a structured three-step process. First, the complex problem of causality identification is decomposed into granular sub-tasks: temporality determination, necessity analysis, and sufficiency verification. Second, specialized prompt engineering guides the LLM to produce both "uncertain responses" (reflecting probability) and "deterministic outputs." The core technical innovation lies in the Fuzzy Aggregation mechanism, which quantifies these multi-source responses and fuses them non-linearly—likely utilizing operators such as Ordered Weighted Averaging (OWA) or Choquet Integrals—to compute a robust final causality score that effectively handles reasoning uncertainty.

**Results**
MEFA demonstrated significant performance superiority over existing unsupervised methods. In comparative evaluations, the framework achieved a **6.2% improvement in F1-score** and a **9.3% improvement in precision** relative to the strongest unsupervised baseline. Furthermore, ablation studies validated the efficacy of the specific components, confirming that decomposing the reasoning process and employing fuzzy aggregation are critical to success. The results explicitly show that MEFA successfully reduces errors associated with spurious causal links, thereby validating its zero-shot viability.

**Impact**
This research makes a substantial contribution by establishing MEFA as the first framework to utilize Multi-source Evidence Fuzzy Aggregation for zero-shot ECI. It offers a cost-effective alternative to supervised models, removing the barrier of data annotation. More importantly, by providing a concrete mechanism to resolve LLM hallucinations in causal reasoning, the work enhances the reliability of generative models for complex logic tasks. This approach introduces a new methodological paradigm for combining granular task decomposition with fuzzy logic, potentially influencing future research on uncertainty handling in zero-shot learning environments.

---

## Key Findings

*   **Performance Superiority:** The MEFA framework outperforms the second-best unsupervised baselines with a **6.2% improvement in F1-score** and a **9.3% improvement in precision**.
*   **Hallucination Mitigation:** Successfully addresses 'causal hallucination' in LLMs by significantly reducing errors stemming from spurious causal links.
*   **Component Efficacy:** Analysis confirms that decomposing the causality reasoning process and using fuzzy aggregation are highly effective strategies for zero-shot performance.
*   **Zero-Shot Viability:** Demonstrates that high-performance Event Causality Identification can be achieved without the need for large-scale annotated data.

---

## Methodology

The researchers introduced **MEFA (Multi-source Evidence Fuzzy Aggregation)**, a zero-shot framework designed through a structured three-step process:

1.  **Task Decomposition**
    Breaking down the complex causality reasoning process into granular sub-tasks to improve interpretability and accuracy:
    *   Temporality determination
    *   Necessity analysis
    *   Sufficiency verification

2.  **Prompt Engineering**
    Utilizing meticulously designed prompts to guide Large Language Models (LLMs) in generating two distinct types of outputs:
    *   *Uncertain responses:* Capturing probabilistic reasoning.
    *   *Deterministic outputs:* Capturing binary or definitive judgments.

3.  **Fuzzy Aggregation**
    Quantifying LLM responses and employing a fuzzy aggregation mechanism to integrate multi-source evidence into a single, robust final causality score.

---

## Technical Details

*   **Framework Name:** MEFA (Multi-source Evidence Fuzzy Aggregation)
*   **Learning Paradigm:** Zero-Shot Learning using Large Language Models (LLMs).
*   **Core Mechanism:** Fuzzy Aggregation.
    *   Function: Fuses multi-source evidence non-linearly.
    *   Purpose: To handle reasoning uncertainty and mitigate causal hallucination.
    *   Operators: Likely utilizes **Ordered Weighted Averaging (OWA)** operators or **Choquet Integrals**.
*   **Process Strategy:** Decomposes complex reasoning into smaller, manageable steps to reduce error rates.

---

## Contributions

*   **Novel Framework for Zero-Shot ECI:** Presents MEFA, the first framework to use Multi-source Evidence Fuzzy Aggregation for zero-shot Event Causality Identification, offering a viable alternative to expensive supervised models.
*   **Resolution of LLM Hallucination:** Provides a specific, technical solution to 'causal hallucination' in LLMs, significantly enhancing the reliability of generative models for causal reasoning tasks.
*   **Methodological Innovation:** Contributes a unique approach combining granular task decomposition with fuzzy logic to effectively handle uncertainty and aggregate evidence.

---

## Results & Analysis

The evaluation of the MEFA framework yielded the following outcomes:

*   **Metric Improvement:** Compared to the strongest unsupervised baselines, MEFA achieved a **6.2% improvement in F1-score** and a **9.3% improvement in precision**.
*   **Error Reduction:** The framework successfully reduced errors associated with causal hallucination, specifically minimizing the generation of spurious causal links.
*   **Validation:** Ablation studies confirmed that both the decomposition of the reasoning process and the fuzzy aggregation technique are essential to the framework's success.
*   **Conclusion:** The study confirms the viability of high-performance event causality identification in a zero-shot setting.

---

## Document Evaluation

*   **Quality Score:** 8/10
*   **Citations:** 40 references