# Large Language Models as Oracles for Ontology Alignment
*Sviatoslav Lushnei; Dmytro Shumskyi; Severyn Shykula; Ernesto Jimenez-Ruiz; Artur d'Avila Garcez*

---

## üìä Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **Evaluation** | OAEI Campaigns (Anatomy, LargeBio, Bio-ML) |
| **Avg. Latency** | < 3 seconds per query |
| **Token Usage** | 100‚Äì250 tokens per request |
| **Cost Estimate** | $0.01 ‚Äì $0.04 per 1,000 requests |
| **Max Throughput** | Up to 2,000 requests/minute (Gemini) |
| **References** | 40 Citations |

---

## üìù Executive Summary

> Ontology alignment is essential for semantic interoperability across heterogeneous knowledge graphs, yet automated systems frequently struggle with ambiguous correspondences, resulting in low-confidence mappings. Resolving these uncertainties has historically required manual review by human domain experts ("Oracles"), a process that introduces prohibitive time constraints and costs at scale.
>
> This paper addresses the critical bottleneck of validating these uncertain edge cases, seeking to preserve high alignment quality without the logistical overhead of exhaustive human verification. The authors introduce a novel approach that deploys Large Language Models (LLMs) not as general-purpose matchers, but as **specialized oracles** designed exclusively to validate mappings where traditional systems exhibit low confidence.
>
> The architecture utilizes a simulated Human-in-the-Loop (HITL) workflow, where an extended LogMap system performs an initial alignment and isolates a subset of uncertain mappings ($M_{\ask}$) for binary validation (True/False) by the LLM. Technically, the method employs ontology-driven prompt templates dynamically populated with entity labels, synonyms, and hierarchical context. The solution integrates multiple cost-efficient models (OpenAI GPT-4o Mini, Google Gemini Flash/2.0) and incorporates robustness mechanisms such as structured output enforcement and retry loops to minimize hallucinations.
>
> Evaluation of 30 distinct LLM configurations across OAEI benchmark campaigns demonstrated that the LLM-augmented system significantly improves alignment efficacy over the baseline LogMap system. By correctly resolving high-uncertainty correspondences, the approach achieved higher overall F-measure scores. Operationally, the system maintained high efficiency and economic scalability. This research advances the field by establishing a viable, cost-reduction strategy that automates the most labor-intensive phase of ontology alignment, setting a new standard for future benchmarking efforts.

---

## üîç Key Findings

*   **Viable Oracle Alternatives:** LLMs are effective substitutes for human domain experts in validating ontology alignments, particularly for specific subsets of correspondences.
*   **Targeted Uncertainty Resolution:** The proposed method focuses on cases where traditional systems exhibit high uncertainty rather than processing entire datasets, increasing efficiency.
*   **Prompt Engineering Impact:** Performance is heavily influenced by specific prompt engineering strategies and the use of ontology-driven template structures.
*   **Benchmarked Success:** State-of-the-art LLMs were successfully benchmarked against simulated Oracles, demonstrating the ability to mimic human fallibility within acceptable error rates.

---

## üî¨ Methodology

The researchers implemented a **simulated Human-in-the-loop (HITL) workflow** where the LLM functions as an Oracle to validate mappings.

1.  **Uncertainty Filtering:** The system employs uncertainty filtering to present the LLM only with cases where the alignment system showed low confidence.
2.  **Evaluation Protocol:** The method was evaluated using matching tasks from the **OAEI** (Ontology Alignment Evaluation Initiative).
3.  **Model & Template Testing:** Multiple LLMs and various prompt templates were tested to determine optimal configurations.
4.  **Validation:** Outputs were rigorously compared against simulated Oracles with specific error rates to accurately mimic human fallibility.

---

## ‚öôÔ∏è Technical Details

*   **System Extension:** The approach extends the **LogMap** ontology alignment system to support interaction with an external LLM-as-Oracle.
*   **Workflow:**
    1.  LogMap performs an initial alignment.
    2.  Identifies uncertain mappings ($M_{\ask}$).
    3.  Sends uncertain mappings to LLM for binary validation (True/False).
*   **Models Utilized:**
    *   OpenAI GPT-4o Mini
    *   Google Gemini Flash v1.5, 2.0, 2.0 Lite, and 2.5 Preview
*   **Prompting Strategy:**
    *   Employs ontology-driven prompts dynamically populated with labels, synonyms, and hierarchical context.
    *   Uses six distinct templates combining NLF, EC, and S characteristics.
*   **Robustness Features:**
    *   Structured output enforcement.
    *   Validation and retry mechanisms to minimize hallucinations.
    *   Unified API interface.

---

## üìà Results & Performance

**Evaluation Scope**
*   **Datasets:** Anatomy, LargeBio, and Bio-ML datasets from OAEI.
*   **Scale:** 9 matching tasks involving large-scale biomedical ontologies.
*   **Dataset Size:** Ranged from ~2.7k to 122k entities.
*   **Reference Alignments:** Ranged from 1,516 to 18,844 mappings.

**Operational Metrics**
*   **Configurations Tested:** 30 distinct LLM-based Oracle configurations.
*   **Latency:** Average of **< 3 seconds** per query.
*   **Token Usage:** **100‚Äì250** input tokens per request.
*   **Costs:** Estimated between **$0.01 and $0.04** per 1,000 requests.
*   **Throughput Constraints:**
    *   Gemini: Up to 2,000 requests per minute.
    *   OpenAI: Up to 500 requests per minute.

---

## üöÄ Contributions

*   **Cost-Reduction Strategy:** Provided a method to automate the validation of difficult correspondence cases, significantly reducing the need for expensive human review.
*   **Novel Application:** Proposed using LLMs as specialized oracles for validating uncertain mappings rather than acting as general matchers.
*   **Extensive Benchmarking:** Contributed a comprehensive benchmarking analysis of LLMs on standard OAEI datasets using ontology-specific prompts.
*   **Evaluation Framework:** Introduced a framework using simulated Oracles to assess error tolerance and utility in a realistic setting.