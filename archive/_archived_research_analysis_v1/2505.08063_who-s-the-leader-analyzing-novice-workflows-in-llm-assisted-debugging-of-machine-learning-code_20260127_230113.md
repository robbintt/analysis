---
title: Who's the Leader? Analyzing Novice Workflows in LLM-Assisted Debugging of Machine
  Learning Code
arxiv_id: '2505.08063'
source_url: https://arxiv.org/abs/2505.08063
generated_at: '2026-01-27T23:01:13'
quality_score: 8
citation_count: 39
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Who's the Leader? Analyzing Novice Workflows in LLM-Assisted Debugging of Machine Learning Code

* Emma Zhuang, Ashton Anderson, Jessica Y. Bo, Majeed Kazemitabaar

> ### ðŸ“Š Quick Facts
>
> *   **Participants:** 8 Novice ML Engineers
> *   **Task:** Debug a Random Forest Script (Python/Google Colab)
> *   **Tool:** ChatGPT 4o-mini
> *   **Method:** Formative, in-person study (Think-aloud protocol)
> *   **Key Metric Correlation:** Pearson's r = 0.93 (Domain Knowledge vs. Performance)
> *   **Quality Score:** 8/10
> *   **References:** 39 Citations

---

## Executive Summary

The widespread integration of Large Language Models (LLMs) into software development workflows has introduced significant risks regarding how novice engineers learn and verify code, particularly in complex domains like Machine Learning (ML). Unlike general programming, ML tasks often suffer from high complexity and low verifiability, where bugs are conceptual (e.g., data distribution shifts) rather than syntactic. This paper addresses the critical challenge of how novice users interact with LLMs during the debugging process. It specifically investigates the tension between gaining assistance and maintaining cognitive engagement, highlighting the risk that LLMs may predispose users to either over-reliance (blind trust) or under-reliance, ultimately hindering the acquisition of debugging skills and domain understanding.

The key innovation of this research is the empirical identification and definition of two distinct interaction archetypes: "Leading the LLM" (user-directed) and "Led-by the LLM" (tool-directed). Technical evaluation was conducted through a formative, in-person study with eight novice participants utilizing a think-aloud protocol. The study tasked participants with debugging a faulty Random Forest training script in Python using ChatGPT 4o-mini. The technical rigor was established by injecting three specific, realistic faults: E1 (Overfitting due to unset hyperparameters), E2 (Data Distribution Shift due to unshuffled splits), and E3 (Class Imbalance). This design allowed the researchers to qualitatively analyze reliance behaviors not just in code generation, but specifically in the context of high-stakes, concept-heavy debugging scenarios.

The study revealed a strong link between domain knowledge and successful debugging performance. While all participants solved at least one problem, 50% solved two, and only 25% solved all three faults. Performance was measured by the F1 Score against a held-out dataset; the baseline faulty code scored 0.16, the optimal fix was 0.32, and participants achieved a range of 0 to 0.28. Crucially, the study found a strong positive correlation between pre-task domain knowledge (quiz scores) and performance (Pearson's r = 0.93, p < .001), whereas self-reported experience showed no correlation. The qualitative analysis confirmed that users exhibiting "Led-by the LLM" behaviors were prone to passivity, whereas those who "Led the LLM" maintained higher cognitive engagement and better outcomes.

This research significantly influences the field of Human-Computer Interaction (HCI) and AI-assisted education by exposing the cognitive vulnerabilities associated with using generative AI in low-verifiability domains. By demonstrating that high-performing users are those who actively direct the AI rather than passively accept its suggestions, the paper establishes a framework for evaluating the efficacy of AI coding assistants. These findings challenge current design paradigms, suggesting that future tools must be engineered to foster "leading" behaviors and support cognitive engagement. The study provides a foundational argument that without specific design augmentations intended to guide novices, LLM assistance may inadvertently degrade the learning process in complex technical fields like Machine Learning.

---

## Key Findings

*   **Interaction Modes:** Novice interactions with LLMs during debugging can be categorized into two distinct modes:
    *   **Leading the LLM (User-directed):** The user actively guides the tool.
    *   **Led-by the LLM (Tool-directed):** The user passively follows the tool's suggestions.
*   **Reliance Risks:** These interaction modes directly influence reliance outcomes, creating a predisposition toward **over-reliance** or **under-reliance**.
*   **Cognitive Impact:** In complex domains like Machine Learning, LLM assistance poses significant risks to novices' cognitive engagement.
*   **Learning Implications:** Passive reliance on LLMs may negatively impact the overall learning process and the acquisition of debugging skills.

---

## Methodology

The researchers conducted a formative study aimed at understanding how novices navigate high-complexity, low-verifiability domains with AI assistance.

*   **Participants:** 8 novice machine learning engineers.
*   **Procedure:** Participants were tasked with debugging a buggy Machine Learning script while having open access to ChatGPT.
*   **Analysis Focus:** The study focused on qualitatively analyzing:
    *   Reliance behaviors
    *   Interaction patterns
    *   User perceptions

---

## Technical Details

This section outlines the specific protocols and metrics used in the study design.

*   **Study Design:** Formative, in-person study utilizing a think-aloud protocol.
*   **Participants:** 8 students familiar with ML basics.
*   **Environment:** Python/Google Colab.
*   **Dataset:** UCI Adult Income dataset.
*   **Tooling:** ChatGPT 4o-mini.
*   **The Task:** Participants debugged a faulty Random Forest training script with three injected faults:
    *   **E1:** Overfitting (due to unset hyperparameters).
    *   **E2:** Data Distribution Shift (due to unshuffled split).
    *   **E3:** Class Imbalance.
*   **Evaluation Metrics:**
    *   Pre-task ML knowledge quiz.
    *   Performance scoring based on **F1 Score** against a held-out dataset.
    *   Accepted conceptually sound fixes.

---

## Results

*   **Problem Solving Success:**
    *   100% solved at least one problem.
    *   50% solved two problems.
    *   25% solved all three problems.
*   **Performance Scores (F1):**
    *   **Optimal Score:** 0.32
    *   **Faulty Baseline:** 0.16
    *   **Participant Range:** 0 to 0.28
*   **Correlations:**
    *   **Domain Knowledge:** Strong positive correlation between quiz scores and performance (Pearson's r = 0.93, p < .001).
    *   **Self-Reported Experience:** No correlation with performance found.
*   **Qualitative Insights:** Confirmed the distinction between "Leading the LLM" (higher engagement) and "Led-by the LLM" (passive) modes.

---

## Contributions

*   **Archetype Identification:** Defined and identified interaction archetypes by distinguishing between 'leading the LLM' and 'led-by the LLM' workflows.
*   **Contextual Analysis:** Provided a detailed analysis of AI assistance challenges in Machine Learning, explicitly contrasting it with general programming tasks.
*   **Linkage to Outcomes:** Connected interaction modes directly to cognitive engagement and learning outcomes.
*   **Design Proposals:** Proposed design augmentations intended to better support novice-LLM interactions and foster positive reliance behaviors.