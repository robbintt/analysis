---
title: Quantitative Analysis of Deeply Quantized Tiny Neural Networks Robust to Adversarial
  Attacks
arxiv_id: '2503.08973'
source_url: https://arxiv.org/abs/2503.08973
generated_at: '2026-02-03T20:16:11'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Quantitative Analysis of Deeply Quantized Tiny Neural Networks Robust to Adversarial Attacks

*Idris Zakariyya; Ferheen Ayaz; Mounia Kharbouche-Harrari; Jeremy Singer; Sye Loong Keoh; Danilo Pau; Jos√© Cano*

***

### üìä Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **Focus Area** | Edge AI / TinyML Security |
| **Key Datasets** | CIFAR-10, Google Speech Commands |
| **Quantization** | Stochastic Ternary (STQ) |
| **Memory Footprint** | ~322 KB |
| **Robust Accuracy (CIFAR-10)** | **33.59%** (vs 12.54% baseline) |
| **References** | 40 Citations |

***

## üìù Executive Summary

Deploying Deep Neural Networks (DNNs) on resource-constrained edge devices, such as Microcontroller Units (MCUs), requires navigating a complex triad of constraints: **high inference accuracy**, **resilience against adversarial attacks**, and **strict adherence to memory (KiB) and power (¬µW) limitations**. While deep quantization is the standard technique for reducing model footprints to meet these hardware constraints, it frequently degrades a model's robustness, leaving it vulnerable to malicious perturbations.

This paper addresses a critical gap in TinyML research, demonstrating that existing state-of-the-art models, such as those in the MLCommons/TinyML benchmarks, struggle to maintain security defenses when subjected to the extreme compression required for untrusted, real-world environments.

The authors propose a **co-optimization strategy** that integrates Quantization-Aware Training (QAT) using the QKeras framework with adversarial robustness techniques. The core technical innovation is the application of **Stochastic Ternary Quantization (STQ)**, which quantizes parameters incrementally based on a probability inversely proportional to quantization error. To mitigate the loss of robustness typically associated with this aggressive compression, the methodology employs **per-layer Jacobian Regularization (JR)**.

This research establishes a new quantitative baseline for secure TinyML, demonstrating that adversarial robustness can be preserved against both white-box and black-box attacks in deeply quantized, ultra-low-power environments.

***

## üîë Key Findings

*   **Resilience:** The proposed compact DNN model demonstrates resilience against both **black-box** and **white-box** adversarial attacks while maintaining a small memory footprint.
*   **Benchmark Superiority:** The model outperforms established MLCommons/TinyML (MLC/T) benchmarks, specifically **Quanos** and **DS-CNN**, when subjected to adversarial attacks.
*   **Cross-Dataset Performance:** Achieved superior performance on average across two distinct datasets: **CIFAR-10** (image) and **Google Speech Commands** (audio).
*   **Validation:** The study validates the effectiveness of combining **quantization-aware training** with **adversarial robustness** techniques to optimize models for resource-constrained edge environments.

***

## üõ†Ô∏è Methodology

The study employs a co-optimization strategy designed to balance compression with security.

*   **Framework Integration:** Utilizes the **QKeras** quantization-aware training framework combined with **Jacobian Regularization (JR)**.
*   **Regularization Strategy:** A **per-layer JR** methodology is applied to enhance the model's robustness against adversarial perturbations.
*   **Quantization Technique:** The model employs **Stochastic Ternary Quantization (STQ)** to achieve deep quantization and significantly reduce memory footprint.
*   **Benchmarking:** Performance was benchmarked against existing DNN models (Quanos and DS-CNN) using various white-box and black-box attack scenarios on both image and audio data.

***

## ‚öôÔ∏è Technical Details

### Core Technologies
*   **Deployment Context:** Edge AI on Microcontroller Units (MCUs) with strict power (¬µW) and memory (KiB) limits.
*   **Quantization-Aware Training (QAT):** Implemented via the QKeras framework.
*   **Stochastic Quantization:** Quantizes parameters incrementally based on a probability inversely proportional to quantization error, supporting very low bit depths (potentially down to a single bit).

### Defensive Mechanisms
The research utilizes a modified loss function to smooth the model's output landscape:

$$L_{joint} = L(\theta, x, y) + \lambda L_{reg}$$

*   **Adversarial Training:** Incorporated to harden the model against attacks.
*   **Regularization:** A regularization term is added to the loss function to improve robustness.

### Attack Vectors Analyzed
The model's security was tested against a comprehensive suite of attacks:

*   **White-Box Attacks:** FGSM, PGD, C&W.
*   **Black-Box Attacks:** Square Attack, Boundary Attack, Zeroth Order Optimization.

***

## ‚ú® Contributions

1.  **Architecture Design:** Development of a DNN architecture specifically designed to address the triad of constraints in edge computing: **accuracy**, **resilience**, and **compact memory footprint**.
2.  **Co-Optimization Methodology:** Introduction of a methodology to co-optimize DNN architectures using per-layer Jacobian Regularization alongside quantization-aware training.
3.  **Performance Baseline:** Presentation of a quantized model (based on STQ) that sets a new performance baseline for adversarial robustness compared to current MLCommons/TinyML benchmarks.

***

## üìà Results

The proposed compact DNN was evaluated on CIFAR-10 and Google Speech Commands datasets.

### CIFAR-10 (Image Dataset)
*   **Proposed Model:**
    *   Clean Accuracy: **82.44%**
    *   Robust Accuracy (vs PGD): **33.59%**
*   **Baseline (DS-CNN):**
    *   Robust Accuracy (vs PGD): **12.54%**
*   **Outcome:** The proposed model significantly outperformed the baseline under attack.

### Google Speech Commands (Audio Dataset)
*   **Proposed Model:**
    *   Clean Accuracy: **91.64%**
    *   Robust Accuracy: **84.29%**

### Resource Efficiency
*   **Memory Footprint:** Approximately **322 KB**, compliant with the strict KiB constraints of edge MCUs.
*   **Conclusion:** The improved robustness was accomplished while maintaining a memory footprint suitable for ¬µW/KiB constraints, validating the hypothesis that combining quantization-aware training with adversarial robustness optimizes models for resource-constrained environments without compromising security.

---
**Quality Score:** 8/10 | **References:** 40 citations