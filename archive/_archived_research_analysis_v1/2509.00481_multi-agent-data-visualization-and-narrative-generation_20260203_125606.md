---
title: Multi-Agent Data Visualization and Narrative Generation
arxiv_id: '2509.00481'
source_url: https://arxiv.org/abs/2509.00481
generated_at: '2026-02-03T12:56:06'
quality_score: 8
citation_count: 19
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Multi-Agent Data Visualization and Narrative Generation

*Anton Wolter; Georgios Vidalakis; Michael Yu; Ankit Grover; Vaishali Dhanoa*

---

### ðŸ“Š Quick Facts

| Metric | Value |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **References** | 19 Citations |
| **Runtime** | 6â€“11 seconds/story |
| **Story Retention** | ~75% |
| **Dataset Scale** | 418 â€“ 4,111 rows |

---

## Executive Summary

> **Problem**  
> This research addresses the critical challenge of automating the end-to-end pipeline from raw data exploration to the creation of coherent visual narratives. As data volumes grow, the ability to rapidly generate insights and communicate them effectively becomes bottlenecked by the manual effort required to analyze data and craft accompanying stories. While Large Language Models (LLMs) offer potential for automation, relying on them as "black boxes" for the entire workflow introduces significant risks regarding transparency, reliability, and computational cost. Furthermore, existing automated systems often lack modularity, forcing users to regenerate entire outputs when making minor adjustments, which hinders sustainable human-AI collaboration.

> **Innovation**  
> The core innovation is a lightweight, hybrid multi-agent architecture that strategically decouples critical logic from LLM reasoning to enhance system control. Instead of relying solely on generative AI, the system integrates deterministic components with six specialized agentsâ€”Data Analysis, Visualization Generation, Code Generation, Visualization Execution, Story Generation, and Story Executionâ€”operating in parallel via multiprocessing. LLMs are reserved exclusively for high-level reasoning tasks, while deterministic components handle specific logic execution. This design produces granular, modular outputs, enabling users to perform surgical edits on specific visualizations or narrative segments without triggering a computationally expensive full regeneration of the project.

> **Results**  
> Evaluated across four diverse datasets ranging from 418 to 4,111 rows, the system demonstrated strong performance in both efficiency and output quality. The architecture achieved a runtime of 6 to 11 seconds per story and approximately 75% story retention. Qualitative analysis confirmed the system's generalizability across different data types and highlighted the robustness of its error handling and retry mechanisms. Additionally, the implementation includes monitoring for LLM API calls and token usage, providing clear visibility into resource consumption.

> **Impact**  
> This work significantly advances the field of automated data communication by proving that a hybrid approach can mitigate the reliability issues often associated with pure LLM reliance. By externalizing critical logic, the system achieves a level of transparency and trustworthiness essential for professional environments. The modular framework facilitates a more sustainable collaboration between humans and AI, allowing users to maintain agency over the final output. This architecture sets a precedent for future systems seeking to balance the creative power of generative models with the precision and determinism required for robust data analysis.

---

## Methodology

The researchers developed a **lightweight, hybrid multi-agent system** designed to automate the end-to-end data-to-communication pipeline. The architecture combines AI agents with deterministic components, strategically offloading critical logic from Large Language Models (LLMs) to enhance system control. This approach manages the workflow from initial data exploration through to the generation of coherent visual narratives.

---

## Key Findings

*   **Generalizability:** The system demonstrated strong generalizability and narrative quality across an evaluation of four diverse datasets.
*   **Efficiency:** The architecture achieves computational efficiency while operating with minimal dependencies.
*   **Modularity:** The use of a hybrid architecture allows for granular, modular outputs, enabling specific modifications to the visualization or narrative without requiring full regeneration.
*   **Transparency:** Externalizing critical logic from LLMs significantly improves the transparency and reliability of the automated workflow.

---

## Contributions

*   **Comprehensive Automation:** Introduction of a multi-agent system capable of managing the entire data analysis workflow, specifically bridging the gap between data exploration and insight communication.
*   **Architectural Innovation:** A hybrid design that integrates deterministic components with agent-based logic to increase transparency and reliability, mitigating common issues associated with pure LLM reliance.
*   **Enhanced Collaboration:** A modular output framework that supports sustainable human-AI collaboration by allowing users to make surgical edits to the data narrative without triggering a computationally expensive full regeneration.

---

## Technical Details

**Architecture & Processing**
*   **Type:** Role-based multi-agent architecture with multiprocessing.
*   **Strategy:** Hybrid approach; LLMs handle high-level reasoning, while deterministic components handle logic.
*   **Agents:** Six specialized agents processing data in parallel:
    1.  Data Analysis
    2.  Visualization Generation
    3.  Code Generation
    4.  Visualization Execution
    5.  Story Generation
    6.  Story Execution

**Technology Stack**
*   **Visualization:** Plotly 5.3.x
*   **Data Models:** Pydantic
*   **Templating:** Jinja2
*   **Instructions:** Dataset-agnostic

---

## Results

Evaluated on four diverse datasets (418 to 4,111 rows), the system achieved approximately **75% story retention** with a runtime of **6 to 11 seconds per story**.

*   **Monitoring:** Includes tracking for LLM API calls and token usage.
*   **Qualitative Outcomes:** Confirmed generalizability across all datasets, modularity in outputs, and robustness through error handling and retry mechanisms.

---

**References:** 19 citations  
**Quality Score:** 8/10