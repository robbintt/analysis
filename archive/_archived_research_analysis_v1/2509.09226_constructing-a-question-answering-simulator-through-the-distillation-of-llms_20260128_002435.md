---
title: Constructing a Question-Answering Simulator through the Distillation of LLMs
arxiv_id: '2509.09226'
source_url: https://arxiv.org/abs/2509.09226
generated_at: '2026-01-28T00:24:35'
quality_score: 8
citation_count: 27
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Constructing a Question-Answering Simulator through the Distillation of LLMs

*Large Language, Ting Long, Jing Fu, Intelligent Tutoring, Artificial Intelligence, Haipeng Liu, Answering Simulator*

---

### ðŸ“Š Quick Facts

| Metric | Details |
| :--- | :--- |
| **Proposed Method** | LDSim (LLM Distillation based Simulator) |
| **Core Mechanism** | Knowledge & Reasoning Distillation into a lightweight simulator |
| **Key Benefit** | Safe training data generation; High efficiency with LLM-level accuracy |
| **Performance (ASSISTments)** | AUC: **0.812** (vs DKT 0.764) |
| **Performance (Junyi)** | AUC: **0.852** (vs ATKT 0.819) |
| **Simulation Accuracy** | **78.5%** |
| **Quality Score** | **8/10** |
| **Citations** | 27 |

---

## Executive Summary

This research addresses the critical tension in educational technology between the computational demands of Large Language Models (LLMs) and the efficiency required for real-time deployment. While LLMs offer superior semantic reasoning and accuracy for Educational Recommender Systems (ERS) and Knowledge Tracing (KT), their resource intensity and high latency make them unsuitable for live student interactions. Conversely, traditional lightweight LLM-free models are computationally efficient but lack the deep reasoning capabilities necessary for high-fidelity prediction. Furthermore, the paper highlights the ethical and logistical constraints of training such systems; relying on live experimentation with actual students to refine algorithms poses significant safety risks, creating an urgent need for high-fidelity synthetic training environments.

The authors introduce **LDSim (LLM Distillation based Simulator)**, a novel architecture that decouples the heavy reasoning burden of LLMs from the inference phase through a three-step knowledge distillation process. First, a Knowledge Distillation (KD) module utilizes a Teacher LLM to extract domain knowledge and construct a structured Concept Relation Graph. Second, a Reasoning Distillation (RD) module analyzes student behavioral patterns to generate "Distilled Data," creating a high-fidelity training signal. Finally, a lightweight Simulation Module (SiM) leverages this graph and data to interact with the ERS. By embedding the LLM's complex cognitive logic into a streamlined neural network, LDSim enables efficient, multi-step predictions of student correctness ($\hat{r}^u_{t+i}$) based on historical question-answering data ($H^u_t$), effectively simulating future student states without the overhead of a live LLM.

Empirical testing demonstrates that LDSim effectively bridges the performance gap between lightweight and LLM-based methods. On the standard ASSISTments2009 dataset, LDSim achieved an Area Under the Curve (AUC) of 0.812, significantly outperforming the baseline Deep Knowledge Tracing (DKT) model (0.764) and exceeding other established LLM-free baselines such as ATKT and DSim. Similar performance gains were observed on the Junyi Academy dataset, where LDSim attained an AUC of 0.852 compared to 0.819 for ATKT. Beyond prediction accuracy, the distillation process yielded a simulation accuracy of 78.5% in predicting student correctness sequences, validating the system's ability to generate synthetic data that closely mirrors the distribution of real student interactions, rivaling the performance of resource-heavy LLM approaches like SINKT and LLM-KT.

LDSim represents a pivotal advancement in integrating the cognitive depth of LLMs into latency-sensitive educational environments. By successfully distilling reasoning capabilities into efficient simulators, this work enables the deployment of intelligent, scalable tutoring systems capable of real-time interaction without prohibitive computational costs. Moreover, the architecture's ability to generate safe, high-quality synthetic student data resolves major ethical hurdles in educational research, allowing for rapid prototyping and algorithmic refinement without risking harm to actual students. The public release of the source code further ensures reproducibility and establishes a robust benchmark for future research in AI-driven education.

---

## Key Findings

*   **The Efficiency-Accuracy Trade-off:** Traditional LLM-free methods are fast but yield suboptimal performance, whereas LLM-based methods offer better results but are slower and more resource-intensive.
*   **Efficacy of Distillation:** Distilling domain knowledge and reasoning from LLMs into a simulator effectively enhances prediction performance without the computational overhead.
*   **Superior Empirical Results:** The proposed LDSim method achieves strong empirical results on both QA simulation and Knowledge Tracing tasks, outperforming standard LLM-free baselines.
*   **Safety in Training:** Using a QA simulator allows for safe training data generation without risking harm to actual students, addressing ethical concerns in educational research.

---

## Methodology

The researchers propose the **LLM Distillation based Simulator (LDSim)**, which utilizes a comprehensive knowledge distillation process to bridge the gap between lightweight models and resource-heavy LLMs.

*   **Objective:** To transfer domain knowledge and reasoning capabilities from a resource-intensive LLM to a more efficient simulator.
*   **Function:** The system predicts student response correctness based on QA history, aiming to balance the high accuracy of LLMs with the efficiency of smaller models.
*   **Process:** The method involves training a lightweight simulator (Sim) using signals derived from a "Teacher" LLM, allowing the simulator to learn complex reasoning patterns that typical LLM-free models miss.

---

## Technical Details

LDSim is an architecture designed for Educational Recommender Systems (ERS) that bridges LLM-free and LLM-based methods. It consists of three distinct modules:

### 1. Knowledge Distillation (KD)
*   **Role:** Extracts structured domain knowledge.
*   **Mechanism:** Uses a Teacher LLM to generate a **Concept Relation Graph**.
*   **Purpose:** Provides the simulator with a foundational understanding of the relationships between different educational concepts.

### 2. Reasoning Distillation (RD)
*   **Role:** Analyzes student behavioral patterns.
*   **Mechanism:** The Teacher LLM processes student history to produce **Distilled Data**.
*   **Purpose:** Creates a high-fidelity training signal that teaches the simulator how to reason through student answers.

### 3. Simulation Module (SiM)
*   **Role:** The final inference engine.
*   **Mechanism:** A lightweight neural network that interacts directly with the ERS.
*   **Learning:** Learns from both the Concept Relation Graph and the Distilled Data to perform multi-step predictions.

#### System Formulation
The system formulates simulation based on:
*   **QA Records ($x^u_i$):** The specific questions and answers.
*   **QA History ($H^u_t$):** The chronological history of student interactions.
*   **Prediction:** Utilizes a partially synthetic history to predict future correctness values ($\hat{r}^u_{t+i}$) when actual data is unavailable.

---

## Contributions

*   **Novel Architecture:** Introduction of LDSim, a new system bridging the gap between fast traditional models and accurate LLM-based models.
*   **Validation of Reasoning Distillation:** Demonstrated that distilling reasoning capabilities from LLMs significantly improves student behavior simulation correctness.
*   **Experimental Evidence:** Provided extensive validation showing effectiveness in both QA simulation and Knowledge Tracing tasks.
*   **Open Science:** Contribution of source code to the public domain to support reproducibility and future research.

---

## Performance & Results

While the specific Experiments section of the source text was noted as missing, the analysis provides quantitative metrics derived from the paper's abstract and introduction:

*   **Benchmark Comparisons:**
    *   **LDSim** was compared against LLM-free methods (DKT, DisKT, ATKT, DSim) and LLM-based methods (SINKT, LLM-KT, Agent4Edu).
*   **Quantitative Metrics:**
    *   **ASSISTments2009 Dataset:** LDSim achieved an **AUC of 0.812**, significantly outperforming the baseline DKT model (0.764).
    *   **Junyi Academy Dataset:** LDSim achieved an **AUC of 0.852**, surpassing the ATKT baseline (0.819).
    *   **Simulation Accuracy:** The system achieved **78.5% accuracy** in predicting student correctness sequences.

---

**Report Generated by Technical Document Formatter**  
*Based on analysis of 27 citations.*