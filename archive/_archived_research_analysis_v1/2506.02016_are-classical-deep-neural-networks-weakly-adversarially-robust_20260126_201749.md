---
title: Are classical deep neural networks weakly adversarially robust?
arxiv_id: '2506.02016'
source_url: https://arxiv.org/abs/2506.02016
generated_at: '2026-01-26T20:17:49'
quality_score: 9
citation_count: 16
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Are classical deep neural networks weakly adversarially robust?

*Information Engineering, Nuolin Sun, Dongyang Li, Progressive Feedforward, Bin Yan, Linyuan Wang, Lei Li*

---

> ### ðŸ“ Executive Summary
>
> Standard adversarial training (AT) remains the dominant method for securing Deep Neural Networks (DNNs), yet it imposes a critical trade-off: it enhances robustness at the expense of significant clean accuracy and requires high computational overhead due to adversarial sample generation. Furthermore, the prevailing consensus suggests that classical DNNs are inherently weak and lack natural defensive capabilities against adversarial threats.
>
> This paper challenges these assumptions by introducing a defense mechanism based on "**Progressive Feedforward Collapse**" (PFC) and the construction of layer-wise feature paths. The core technical insight is that while adversarial examples cause features to diverge drastically in final classification layers, they maintain strong correlation with clean samples in intermediate layers. To exploit this, the system constructs feature paths for inputs and compares them to pre-computed class-centered paths using Cosine Similarity. Detection utilizes Otsu's method for thresholding, while classification is performed via an intermediate-layer weighted voting mechanism.
>
> Evaluated on CIFAR-10 against AutoPGD attacks, the method demonstrates a distinct efficiency-robustness profile. On ResNet-20, the approach achieved **82.77% clean accuracy** and **44.17% adversarial accuracy**, marking a **5.13% improvement in clean accuracy** over the AT baseline (77.64%). The method's generalizability was confirmed on ResNet-18, where it achieved **80.01% clean accuracy** and **46.1% adversarial accuracy**, validating that the approach works effectively on standard architectures.
>
> This research challenges the established consensus that classical DNNs are inherently weak, empirically demonstrating that latent robustness can be extracted through internal feature analysis. By providing a cost-effective alternative to standard AT, the authors open new avenues for lightweight defense strategies.

---

### ðŸ“Š Quick Facts

| Metric | Details |
| :--- | :--- |
| **Core Method** | Progressive Feedforward Collapse (PFC) & Feature Paths |
| **Dataset** | CIFAR-10 |
| **Attack Model** | AutoPGD ($\epsilon=8/255$) |
| **ResNet-20 Clean Acc** | 82.77% |
| **ResNet-20 Adv Acc** | 44.17% |
| **ResNet-18 Clean Acc** | 80.01% |
| **ResNet-18 Adv Acc** | 46.1% |
| **Quality Score** | **9/10** |

---

## ðŸ” Key Findings

*   **High Clean Accuracy**: The proposed recognition method achieved a clean accuracy of **82.77%** on ResNet-20, outperforming standard adversarial training (77.64%).
*   **Robustness Maintenance**: The method maintained an adversarial accuracy of **44.17%** (ResNet-20) and **46.1%** (ResNet-18), offering a favorable trade-off without the computational cost of AT.
*   **Detection Efficacy**: Achieved over **80% detection accuracy**, effectively identifying adversarial inputs via layer-wise analysis.
*   **Challenging Consensus**: Empirical results suggest that classical DNNs possess inherent adversarial robustness, contradicting the belief that they are naturally weak in this regard.

## ðŸ› ï¸ Methodology

The proposed system operates by analyzing the behavior of DNNs across different layers rather than relying solely on the final output.

*   **Feature Path Construction**: The method constructs 'feature paths' using layer-wise features extracted from the network at various stages of processing.
*   **Correlation Analysis**: It detects adversarial examples and performs image recognition by calculating the correlation (Cosine Similarity) between the feature path of the input example and pre-computed class-centered feature paths.
*   **PFC Inspiration**: The approach draws inspiration from the clustering properties of DNN output features and the Progressive Feedforward Collapse (PFC) phenomenon.

## ðŸ’¡ Contributions

*   **Cost-Effective Defense**: Provided a computationally efficient alternative to adversarial training that avoids significant overhead while maintaining competitive accuracy metrics.
*   **New Analysis Technique**: Introduced a novel method for analyzing adversarial robustness through the correlation of layer-wise feature paths, moving beyond input perturbations and gradient-based methods.
*   **Paradigm Shift**: Challenged the established consensus that classical DNNs are weakly adversarially robust by empirically demonstrating the existence of inherent robustness properties in standard architectures.

## âš™ï¸ Technical Details

*   **Core Mechanism**: Defense and recognition based on layer-wise feature paths and Progressive Feedforward Collapse (PFC).
*   **Theoretical Premise**: Adversarial examples deviate significantly in the final layers but retain correlation with clean samples in intermediate layers.
*   **Detection Algorithm**:
    *   Utilizes **Cosine Similarity** to measure path alignment.
    *   Applies **Otsu's method** for thresholding to separate adversarial and clean samples.
*   **Recognition Algorithm**:
    *   Employs an **Intermediate-Layer Weighted Voting Mechanism**.
    *   Relies on the top-performing layers for final classification, bypassing potentially corrupted final layers.
*   **Experimental Setup**:
    *   **Attacks**: Generated via AutoPGD ($\epsilon=8/255$).
    *   **Architectures**: ResNet-20 and ResNet-18.
    *   **Optimization**: SGD.
    *   **Dataset**: CIFAR-10.

## ðŸ“ˆ Results

**ResNet-20 Performance**
*   **Clean Accuracy**: 82.77% (vs. 77.64% for Standard AT).
*   **Adversarial Accuracy**: 44.17% (vs. 52.94% for Standard AT).
*   **trade-off**: The method offers a distinct advantage in clean accuracy (+5.13%) while dropping in adversarial accuracy compared to heavy AT training.
*   **Detection Accuracy**: >80%.

**ResNet-18 Performance**
*   **Clean Accuracy**: 80.01%.
*   **Adversarial Accuracy**: 46.1%.
*   **Significance**: Indicates the method generalizes well to standard architectures without the need for specialized PFC training protocols.

---
**References:** 16 citations