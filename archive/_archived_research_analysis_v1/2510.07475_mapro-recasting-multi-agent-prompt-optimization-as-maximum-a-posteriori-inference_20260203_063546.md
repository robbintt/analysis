---
title: 'MAPRO: Recasting Multi-Agent Prompt Optimization as Maximum a Posteriori Inference'
arxiv_id: '2510.07475'
source_url: https://arxiv.org/abs/2510.07475
generated_at: '2026-02-03T06:35:46'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# MAPRO: Recasting Multi-Agent Prompt Optimization as Maximum a Posteriori Inference

*Zheyuan Zhang; Lin Ge; Hongjiang Li; Weicheng Zhu; Chuxu Zhang; Yanfang Ye*

---

### ðŸ“Š Quick Facts

| Metric | Details |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **Total Citations** | 40 |
| **Avg. Success Rate** | **0.77** (vs. 0.60 MetaGPT, 0.55 AutoGen) |
| **Convergence Speed** | 3â€“4 Iterations |
| **Core Algorithm** | Language-guided Max-Product Belief Propagation (LMPBP) |

---

> ### ðŸ“ Executive Summary
>
> Designing effective multi-agent systems (MAS) presents a formidable optimization challenge, primarily due to the complexity of coordinating prompts across multiple interacting agents. As the number of agents increases, the search space for optimal configurations expands exponentially (reaching $K^N$ combinations), rendering manual engineering infeasible. Furthermore, multi-agent environments suffer from ambiguous credit assignment; when a system fails, it is difficult to determine which specific agent's prompt contributed to the error. This paper addresses these fundamental issues by moving away from heuristic, single-agent design methods to tackle the unexplored domain of systematic, automated multi-agent prompt optimization.
>
> The core innovation is **MAPRO** (Multi-Agent PRompt Optimization), a framework that recasts the design of multi-agent prompts as a **Maximum a Posteriori (MAP)** inference problem. The authors model the MAS as a directed graph where vertices represent agents and edges represent information flow, with the objective of maximizing a **Joint Quality Score**. To solve this, MAPRO employs a **Language-guided Max-Product Belief Propagation (LMPBP)** algorithm. This method utilizes a reward model to score individual agents and their interactions, performing message passing and junction-tree transformations to efficiently navigate the search space. Additionally, a topology-aware refinement mechanism integrates execution feedback and downstream blame attribution to iteratively update prompts, effectively resolving the credit assignment challenge.
>
> MAPRO achieves state-of-the-art performance on the **LLM-Agent-Bench**, consistently outperforming manually engineered prompts and recent automated baselines. Specifically, MAPRO achieves an average success rate of **0.77**, significantly outperforming MetaGPT (0.60) and AutoGen (0.55). The framework demonstrates high efficiency in terms of optimization speed, typically converging to stable, coordinated agent-specific prompt policies within **3 to 4 iterations**. Quantitative analysis confirms that performance improves monotonically over successive updates, with the Joint Quality Score plateauing as the topology-aware mechanism successfully isolates and refines specific agents, allowing MAPRO to surpass global update methods with superior computational efficiency.

---

## Key Findings

*   **State-of-the-Art Performance:** MAPRO consistently outperforms both manually engineered prompts and recent automated alternatives across various task benchmarks.
*   **Effective Optimization Formulation:** The study demonstrates that multi-agent prompt optimization can be successfully reframed as a Maximum a Posteriori (MAP) inference problem.
*   **Resolution of Credit Assignment:** The proposed framework effectively overcomes the challenge of ambiguous credit assignment in multi-agent systems through a topology-aware refinement mechanism.
*   **Progressive Convergence:** MAPRO is capable of iteratively converging on a coordinated set of agent-specific prompt policies by integrating execution feedback and downstream blame attribution.

---

## Methodology

The authors propose **MAPRO** (Multi-Agent PRompt Optimization), a four-stage framework designed to automate the design of multi-agent systems (MAS).

1.  **Problem Formulation**
    It recasts the optimization of agent prompts as a Maximum a Posteriori (MAP) inference problem.
2.  **Algorithmic Solution**
    The framework utilizes a language-guided variant of the max-product belief propagation algorithm to solve the inference problem.
3.  **Refinement Mechanism**
    To handle credit assignment and prompt updates, MAPRO employs a topology-aware refinement mechanism.
4.  **Iterative Update**
    This mechanism integrates execution feedback and downstream blames to selectively update specific agent prompts, allowing the system to iteratively improve and stabilize.

---

## Technical Details

### System Modeling
*   **Graph Structure:** The Multi-Agent System is modeled as a directed graph $G=(V, E)$.
    *   $V$: Vertices represent agents.
    *   $E$: Edges represent information flow.
*   **Search Space:** Each agent maintains a prompt candidate pool of size $K$, creating a total search space of $K^N$ combinations.

### Optimization Objective
*   **Goal:** Maximize the **Joint Quality Score** $T(\tilde{P})$.
*   **Calculation:** The score is defined as the product of:
    *   **Agent Scores:** $g(p^k_i)$
    *   **Edge Scores:** $g(p^k_i, p^l_j)$
*   **Framework:** This is framed explicitly as a Maximum a Posteriori (MAP) inference problem.

### The MAPRO Framework Stages
1.  **Initialization:** Generating prompt variants and a reward model.
2.  **Language-based MAP Selection (LMPBP):**
    *   Utilizes a Reward Model to score nodes and edges.
    *   Employs a Max-Product Belief Propagation algorithm with junction-tree transformation and message passing.
    *   **Message Passing Formula:**
        $$m_{i \to j}(p_j) = \max_{p_i}[ g(p_i)g(p_i, p_j) \prod_{k \in Child(i)} m_{k \to i}(p_i) ]$$
    *   This efficiently finds the global optimum.
3.  **Preference-based Policy Update:** Updating the agent policies based on the selected prompts.
4.  **Termination:** Stopping criteria are met once convergence is achieved.

---

## Results

*   **Benchmark Dominance:** MAPRO reportedly outperforms manually engineered prompts and recent automated alternatives across various task benchmarks.
*   **Iterative Convergence:** The method iteratively converges on coordinated agent-specific prompt policies.
*   **Credit Assignment:** The framework effectively addresses the challenge of ambiguous credit assignment in multi-agent systems via topology-aware refinement.
*   **Visual Performance:** Visual evidence indicates performance improves over iterations, eventually surpassing hand-tuned prompting.
*   **Quantitative Metrics:**
    *   Achieved an average success rate of **0.77**.
    *   Significantly outperformed MetaGPT (**0.60**) and AutoGen (**0.55**).
    *   Convergence typically achieved within **3 to 4 iterations**.

---

## Research Contributions

*   **Bridging the Gap in Multi-Agent Optimization:** The paper addresses a largely unexplored area by moving beyond single-agent prompt design to tackle the complexities of multi-agent prompt optimization.
*   **Principled Theoretical Framework:** It provides a principled mathematical foundation for MAS design by applying probabilistic inference (MAP) to prompt engineering, moving away from heuristic approaches.
*   **Solving Search Space and Credit Assignment:** The research offers a concrete solution to the specific challenges of exponentially expanding search spaces and ambiguous credit assignment that previously made systematic MAS design intractable.
*   **Guidelines for Future Systems:** Beyond the specific algorithm, the MAP-based formulation offers general theoretical guidelines for constructing more reliable and principled multi-agent systems in future research.