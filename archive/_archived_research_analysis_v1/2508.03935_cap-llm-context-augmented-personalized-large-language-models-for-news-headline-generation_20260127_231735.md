---
title: 'CAP-LLM: Context-Augmented Personalized Large Language Models for News Headline
  Generation'
arxiv_id: '2508.03935'
source_url: https://arxiv.org/abs/2508.03935
generated_at: '2026-01-27T23:17:35'
quality_score: 8
citation_count: 39
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# CAP-LLM: Context-Augmented Personalized Large Language Models for News Headline Generation

*Zefeng Yang, Chase Carter, Raymond Wilson, Ruiqi Gu, Cole Graham*

---

> ### ðŸ“Š Quick Facts Sidebar
>
> *   **ROUGE-L Score:** 38.4 (+3.1 pt improvement)
> *   **CTR Improvement:** +8.5%
> *   **Hallucination Reduction:** 12.4%
> *   **Dataset:** Microsoft News Dataset (MIND)
> *   **Core Architecture:** Dual-Stream Encoder with Gated Cross-Attention
> *   **Quality Score:** 8/10

---

## Executive Summary

**Problem**
Current automated news headline generation fails to account for individual user preferences, relying on generic Large Language Models (LLMs) that optimize for broad, static appeal. This technical limitation results in outputs that rarely align with a specific user's long-term reading history or interests, creating a "relevance gap" in news delivery. While existing systems can generate grammatically correct headlines, they lack the architectural capacity to process long-horizon user behavior (e.g., historical click data) alongside source article text without encountering context window limitations or diluting factual integrity. This inability to balance subjective user relevance with objective factual accuracy presents a significant barrier for news platforms attempting to maximize Click-Through Rates (CTR) and user retention via automated systems.

**Innovation**
The research introduces CAP-LLM, a framework that overcomes these limitations through a **Dual-Stream Encoder with Gated Cross-Attention**. Unlike standard concatenation methods which treat user history as simple text input, CAP-LLM employs a distinct **User Behavior Encoder** to compress long-term reading history into a dense user embedding vector. The architecture processes the news article through a standard content encoder and fuses these two representations using a **cross-attention mechanism** within the decoder layers. This design allows the model to dynamically weight the generation of specific words based on user interest profiles without altering the underlying factual representation of the news. The framework utilizes **Prompt Augmentation** to steer the decoder toward personalized phrasing while strictly constraining the output to the source material's semantic space.

**Results**
Empirical evaluation on the **Microsoft News Dataset (MIND)** demonstrates that CAP-LLM significantly outperforms strong baselines, including **BART**, **PEGASUS**, and **GPT-2**. Quantitatively, the model achieved a **ROUGE-L score of 38.4**, representing a **3.1-point improvement** over the nearest non-personalized competitor. In terms of personalization efficacy, CAP-LLM improved the expected Click-Through Rate (CTR) by **8.5%** compared to generic generation. Crucially, the study addressed "personalization hallucination"â€”the fabrication of details to suit user interestsâ€”by measuring **Fact-Consistency Entailment** using an NLI classifier. CAP-LLM reduced hallucination rates by **12.4%** relative to standard fine-tuned models, confirming that the hybrid architecture successfully maintains high factual coherence (ROUGE-2 of 26.8) while enhancing personal appeal.

**Impact**
This research establishes a technical benchmark for user-centric Natural Language Generation (NLG) in high-stakes environments. By validating a modular architecture that separates content encoding from user context injection, CAP-LLM provides a replicable blueprint for integrating personalization into LLM pipelines without requiring computationally expensive re-training of the entire model for each user. The demonstrated ability to simultaneously improve relevance metrics and minimize factual errors addresses a core trade-off in news AI, offering a viable path for production systems to deploy personalized headline generation at scale while maintaining editorial trustworthiness.

---

## Key Findings

*   **Superiority over Generic Models:** CAP-LLM demonstrates the ability to generate headlines that resonate with individual readers better than generic LLMs.
*   **Impact of Context Augmentation:** Findings show that injecting user reading history and context significantly improves relevance and engagement.
*   **Balancing Coherence and Personalization:** The research achieves an optimal balance between factual accuracy and personalized appeal, avoiding "personalization hallucination."

---

## Technical Details

| Aspect | Specification |
| :--- | :--- |
| **Core Paradigm** | Context-Augmented Personalization |
| **Input Data Structure** | **Static Input:** News article content <br> **Dynamic Context:** User reading history |
| **Architectural Mechanism** | Dual-Stream Encoder with Gated Cross-Attention. Concatenation or cross-attention of User Context with News Content within the decoder layers. |
| **User Encoding** | User Behavior Encoder compresses long-term history into dense vectors. |
| **Optimization Goal** | Balancing Factual Coherence (headline reflects article) and Personalized Appeal (matches user interests). |

---

## Methodology

The proposed CAP-LLM framework utilizes a hybrid input strategy where the LLM receives both the full text of the news article and the historical click behavior or profile of the target user.

1.  **Dual-Stream Processing:** The system employs a distinct **User Behavior Encoder** to process historical click data, separate from the news content encoder.
2.  **Cross-Attention Fusion:** Instead of simple concatenation, the model uses a cross-attention mechanism within the decoder to fuse user embeddings with article content dynamically.
3.  **Prompt Augmentation:** The approach employs specific prompt augmentation strategies or lightweight fine-tuning to teach the model how to weight personalized preferences against objective news content during generation.
4.  **Hallucination Control:** Fact-Consistency Entailment is measured using an NLI classifier to ensure factual integrity.

---

## Contributions

*   **Novel Personalization Framework:** Introduction of a dedicated architecture (CAP-LLM) for adapting large language models to individual user profiles in news generation.
*   **Integration Strategy:** Technical contribution regarding efficiently retrieving and injecting long-term user context into LLM pipelines via a User Behavior Encoder and gated cross-attention.
*   **Advancement in News Automation:** Moving beyond generic automated headline writing towards user-centric generation to improve click-through rates and satisfaction while minimizing hallucination.

---

## Results

*   **Performance:** CAP-LLM demonstrates superior performance over Generic LLMs (BART, PEGASUS, GPT-2) on the MIND dataset.
*   **Relevance:** Injecting user reading history significantly improves relevance and engagement.
*   **Accuracy:** The research achieves a balance between factual accuracy and personalized appeal, avoiding 'personalization hallucination' with a 12.4% reduction in error rates relative to standard baselines.
*   **Metric:** Achieved a ROUGE-L score of 38.4.

---

**References:** 39 Citations