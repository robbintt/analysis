---
title: 'A2AS: Agentic AI Runtime Security and Self-Defense'
arxiv_id: '2510.13825'
source_url: https://arxiv.org/abs/2510.13825
generated_at: '2026-02-03T13:35:21'
quality_score: 9
citation_count: 38
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# A2AS: Agentic AI Runtime Security and Self-Defense

*Eugene Neelou; Ivan Novikov; Max Moroz; Om Narayan; Tiffany Saade; Mika Ayenson; Ilya Kabanov; Jen Ozmen; Edward Lee; Vineeth Sai Narajala; Emmanuel Guilherme Junior; Ken Huang; Huseyin Gulsin; Jason Ross; Marat Vyshegorodtsev; Adelin Travers; Idan Habler; Rahul Jadav*

---

> ### ðŸ“Œ Quick Facts
> | Metric | Detail |
> | :--- | :--- |
> | **Quality Score** | 9/10 |
> | **References** | 38 Citations |
> | **Latency Impact** | Zero |
> | **Dependencies** | Zero |
> | **Core Model** | BASIC Security Model |

---

## Executive Summary

This research addresses the escalating security vulnerabilities facing Large Language Models (LLMs) and autonomous AI agents, particularly the threat of prompt injection and the compromise of context window integrity during runtime. As AI systems transition from passive tools to agentic actors capable of executing actions, the attack surface expands, making them susceptible to malicious inputs that can manipulate behavior.

The critical challenge identified is that existing security solutions often require costly architectural overhauls or resource-intensive model retraining, creating a barrier to implementing robust defenses for dynamic, real-time AI applications.

The authors propose **A2AS (Agentic AI Runtime Security and Self-Defense)**, a security framework designed to function as a wrapper for AI agents, analogous to how HTTPS secures web traffic. This layer operates at the runtime level, meaning it secures the system without requiring modifications to the underlying model architecture or the need for retraining. Technically, the framework utilizes the **BASIC Security Model**â€”comprising Behavior certificates, Authenticated prompts, Security boundaries, In-context defenses, and Codified policiesâ€”to enforce a defense-in-depth strategy. This mechanism maintains context window integrity by strictly authenticating prompts and isolating untrusted inputs before they reach the model.

While the paper presents a conceptual framework rather than a traditional empirical study containing benchmark datasets or specific attack mitigation rates, it asserts distinct performance advantages regarding operational efficiency. The authors claim that the A2AS framework achieves **zero operational overhead**, **zero added latency**, and requires **zero external dependencies**.

The significance of this work lies in its potential to establish a standardized, architecturally efficient approach to AI security that decouples safety measures from model development. By proposing a solution that integrates seamlessly into existing workflows without latency penalties or retraining, A2AS lowers the barrier to entry for securing high-risk agentic AI deployments.

---

## Key Findings

*   **A2AS Framework:** Introduces a security layer for AI agents and LLMs analogous to **HTTPS**, providing runtime security without architectural changes or retraining.
*   **Performance Efficiency:** Achieves **zero operational overhead** with no latency or external dependencies.
*   **BASIC Security Model:** Built on this model to ensure context window integrity by authenticating prompts and isolating untrusted inputs.

---

## Technical Details

The approach introduces **A2AS (Agentic AI Runtime Security and Self-Defense)** as a comprehensive security wrapper for AI agents and LLMs.

### Architecture & Operation
*   **Analogy:** Operates similarly to **HTTPS** as a security wrapper.
*   **Function:** Functions as a runtime security layer that requires no architectural changes or model retraining.
*   **Core Mechanism:** Maintains context window integrity by authenticating prompts and isolating untrusted inputs.

### The BASIC Security Model
The framework is built upon the BASIC taxonomy, which categorizes defenses into five pillars:

1.  **B**ehavior certificates
2.  **A**uthenticated prompts
3.  **S**ecurity boundaries
4.  **I**n-context defenses
5.  **C**odified policies

---

## Methodology

The methodology proposes a conceptual framework design based on a **'defense-in-depth'** strategy.

*   **Runtime Layering:** Involves inserting a security layer (A2AS) at the runtime level rather than modifying underlying models.
*   **Enforcement:** This layer enforces strict security boundaries and authenticates inputs to prevent prompt injection.
*   **Policy Application:** Applies codified policies using the BASIC model structure to categorize and organize defenses systematically.

---

## Contributions

*   **Standard Proposal:** Proposes the A2AS framework as a potential industry standard for securing agentic AI.
*   **Taxonomy Definition:** Defines the **BASIC taxonomy** to provide a structured approach to security.
*   **Architectural Efficiency:** Provides an architecturally efficient solution offering robust self-defense without latency increases or the need for model retraining.

---

## Results

The text does not provide specific experimental data such as benchmarks or attack success rates. However, the claimed performance metrics are significant:

*   **Zero** operational overhead
*   **Zero** added latency
*   **Zero** external dependencies

---

**Quality Score:** 9/10  
**References:** 38 citations