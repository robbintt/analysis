# Filtering with Confidence: When Data Augmentation Meets Conformal Prediction

*Zixuan Wu; So Won Jeong; Yating Liu; Yeo Jin Jung; Claire Donnat*

---

> ### ❖ QUICK FACTS
> | Metric | Details |
> | :--- | :--- |
> | **Quality Score** | 9/10 |
> | **Citations** | 37 References |
> | **F1 Improvement** | Up to 40% (vs. unaugmented) / 4% (vs. existing baselines) |
> | **Domains** | NLP, Computer Vision, Tabular Data |
> | **Key Requirement** | No internal model logits or large-scale retraining needed |

---

## Executive Summary

The research addresses the persistent challenge of **distributional bias** and **low-quality sample generation** inherent in synthetic data augmentation. While augmentation is vital for data-scarce environments, synthetic data often shifts the underlying distribution or introduces noise/hallucinations. Existing solutions typically rely on heuristics or intrusive access to model internals (logits), limiting scalability.

**Innovation**
The authors propose **"Filtering with Confidence,"** a framework for Conformal Data Augmentation (CDA). This method rigorously filters synthetic data using Conditional Conformal Risk Control, replacing heuristic assessments with a mathematically grounded mechanism. The two-step process involves calibrating rejection thresholds based on "false discoveries" and employing Reproducing Kernel Hilbert Space (RKHS) techniques to handle sample heterogeneity. Crucially, it is implementation-agnostic and requires no access to model logits or expensive retraining.

**Results**
The framework was validated across NLP, Computer Vision, and Tabular tasks. It achieved **F1 score improvements of up to 40%** compared to unaugmented baselines and outperformed existing filtered augmentation baselines by **up to 4%**. Experiments confirmed the method effectively filters hallucinations while preserving sample diversity, successfully balancing bias reduction and variance preservation.

**Impact**
This work shifts data filtering from ad-hoc practices to a rigorous probabilistic framework with provable risk control. By lowering the barrier to entry for high-quality augmentation—requiring neither deep model introspection nor retraining—it offers a robust, general-purpose solution for improving data reliability in production environments.

---

## Key Findings

*   **Consistent Performance:** Demonstrated improvements across diverse tasks including topic prediction, sentiment analysis, image classification, and fraud detection.
*   **Significant Metrics:** Achieved F1 score improvements of up to **40%** compared to unaugmented baselines and up to **4%** compared to existing filtered augmentation baselines.
*   **Quality Maintenance:** Successfully validated that the method filters out poor-quality synthetic generations (e.g., hallucinations) while strictly maintaining sample diversity.
*   **Deployment Efficiency:** Established that effective data filtering can be achieved without accessing internal model logits or performing large-scale model retraining.

---

## Methodology

The research proposes **Conformal Data Augmentation**, a principled framework designed to standardize the filtering of synthetic data. The core methodology relies on leveraging conformal prediction to create a mechanism that identifies and removes low-quality samples.

*   **Provable Risk Control:** The approach integrates risk control to ensure synthetic data remains faithful to the underlying training distribution, thereby minimizing bias.
*   **Implementation-Agnostic:** Designed to be lightweight and deployable, the method does not require access to model logits or the retraining of large-scale models.

---

## Technical Details

The paper introduces **"Filtering with Confidence,"** a two-step framework utilizing Conditional Conformal Risk Control.

*   **Core Framework:**
    *   Utilizes a pretrained generative model conditioned on observed data and temperature to generate alternative versions.
    *   Balances bias and variance through controlled generation.

*   **Calibration Step:**
    *   Defines a loss function based on "false discoveries" using a calibration dataset.
    *   Establishes a rejection threshold to filter low-quality data.

*   **Adaptation Step:**
    *   Uses Reproducing Kernel Hilbert Space (**RKHS**) to handle sample heterogeneity.
    *   Ensures conditional coverage relative to input difficulty.

*   **Operational Workflow:**
    1.  Train a quality predictor.
    2.  Calibrate the rejection threshold.
    3.  Filter augmentations without requiring internal model logits.

---

## Results

Validated across NLP, Computer Vision, and Tabular tasks:

*   **Vs. Unaugmented Baselines:** Up to **40%** improvement in F1 score.
*   **Vs. Filtered Baselines:** Up to **4%** improvement in F1 score.
*   **Quality Assurance:** Successfully filtered poor-quality generations (e.g., hallucinations) while maintaining sample diversity.
*   **Operational Success:** Demonstrated effectiveness without requiring internal model logits or large-scale retraining.

---

## Contributions

*   **Addressing Distributional Bias:** Introduces a rigorous filtering mechanism that minimizes shifts from the underlying data distribution.
*   **Mathematical Grounding:** Provides a mathematically grounded approach to data filtering with provable risk control, moving beyond heuristic quality assessment.
*   **Domain Versatility:** Validated across multiple domains (NLP and Computer Vision), suggesting a general-purpose solution for data-scarce environments.
*   **Lowered Barrier to Entry:** Eliminates the need for deep model introspection (logits) or expensive retraining processes, making high-quality augmentation accessible.

---
*References: 37 citations | Quality Score: 9/10*