---
title: Visual Agentic Reinforcement Fine-Tuning
arxiv_id: '2505.14246'
source_url: https://arxiv.org/abs/2505.14246
generated_at: '2026-02-03T06:28:04'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Visual Agentic Reinforcement Fine-Tuning
*Ziyu Liu; Yuhang Zang; Yushan Zou; Zijian Liang; Xiaoyi Dong; Yuhang Cao; Haodong Duan; Dahua Lin; Jiaqi Wang*

---

### ðŸ“Š Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Method** | Visual-ARFT (Reinforcement Learning with Verifiable Rewards) |
| **Top Performance Gain** | **+18.6% F1** (MAT-Coding) |
| **Benchmark** | MAT (Multi-modal Agentic Tool Bench) |
| **Capabilities** | Web Browsing (Serper API) & Code Execution (cv2) |
| **Key Achievement** | Surpasses proprietary GPT-4o on agentic tasks |
| **Training Resources** | 8 GPUs |
| **Quality Score** | 9/10 |

---

> ### ðŸ“ Executive Summary
>
> Current Large Vision-Language Models (LVLMs) possess strong perceptual capabilities but lack the sophisticated agentic reasoning required to interact dynamically with the environment. They struggle to natively utilize external toolsâ€”such as web browsing for real-time information retrieval or code execution for precise image manipulationâ€”to solve complex, multi-step visual tasks. This deficiency creates a significant gap between open-source models and proprietary systems, limiting the deployment of autonomous visual agents in real-world scenarios where static knowledge is insufficient.
>
> The authors introduce **Visual Agentic Reinforcement Fine-Tuning (Visual-ARFT)**, a training paradigm designed to instill flexible reasoning and tool-use capabilities in LVLMs. The method employs Reinforcement Learning with Verifiable Rewards (RLVR) utilizing Group Relative Policy Optimization (GRPO) with 8 sampled generations per update. The objective function maximizes expected reward based on deterministic exact matches while constraining policy drift via KL divergence. Specifically, the framework trains models to perform Agentic Search (autonomous query decomposition using the Serper API) and Agentic Coding (generating Python code via cv2 to handle image degradation), supported by the newly introduced Multi-modal Agentic Tool Bench (MAT) for evaluation.
>
> Visual-ARFT delivers substantial performance gains over baseline models across the proposed benchmarks. On the MAT-Coding benchmark, the method achieved an **+18.6%** improvement in F1 score and **+13.0%** in Exact Match (EM), while MAT-Search saw gains of **+10.3%** F1 and **+8.7%** EM. Significantly, this fine-tuning enabled open-source Qwen2.5-VL models (3B and 7B parameters) to surpass the proprietary GPT-4o in agentic search and coding tasks. Additionally, the approach demonstrated strong generalization on multi-hop Question Answering benchmarks, with **+29.3%** F1 and **+25.9%** EM improvements on 2Wiki and HotpotQA.
>
> This research successfully bridges the gap between language-only agentic abilities and robust multi-modal agent capabilities within the open-source ecosystem. By demonstrating that specialized reinforcement fine-tuning allows smaller open-source models to exceed the performance of state-of-the-art proprietary systems in visual tool-use tasks, the paper challenges current market dominance assumptions. The introduction of the MAT benchmark establishes a critical new standard for evaluating agentic search and coding, providing the field with a rigorous framework to drive future development in autonomous visual agents.

---

## Key Findings

*   **Significant Performance Improvement:** Visual-ARFT significantly outperforms baseline models on MAT benchmarks.
    *   **MAT-Coding:** +18.6% F1 / +13.0% EM
    *   **MAT-Search:** +10.3% F1 / +8.7% EM
*   **Surpasses Proprietary Models:** Enables open-source LVLMs (Qwen2.5-VL-3B and 7B) to surpass proprietary GPT-4o in agentic search and coding tasks.
*   **Strong Generalization:** Demonstrates robust performance on multi-hop QA benchmarks:
    *   **2Wiki and HotpotQA:** +29.3% F1 / +25.9% EM
*   **Tool Use Capabilities:** Effectively equips LVLMs with:
    *   **Web Browsing:** For retrieving real-time updates.
    *   **Code Writing:** For image manipulation.

---

## Methodology

The authors propose **Visual Agentic Reinforcement Fine-Tuning (Visual-ARFT)**, a training paradigm designed to bridge the gap between language-only agentic abilities and multi-modal agentic capabilities in open-source LVLMs.

The core methodology focuses on instilling flexible reasoning by enabling the native use of external tools:

1.  **Web Browsing:** For retrieving real-time information.
2.  **Code Execution:** For writing and executing code to manipulate images.

**Evaluation Framework:**
The methodology is evaluated using the introduced **Multi-modal Agentic Tool Bench (MAT)**, which includes two primary settings:
*   **MAT-Search:** Evaluating agentic search capabilities.
*   **MAT-Coding:** Evaluating agentic coding capabilities.

---

## Technical Details

**Training Algorithm:**
*   **Reinforcement Learning with Verifiable Rewards (RLVR)**
*   **Optimization Strategy:** Group Relative Policy Optimization (GRPO) with 8 sampled generations per update.

**Objective Function:**
The objective maximizes expected reward while constraining policy drift via KL divergence:

$$R_{RLVR}(q,o) = [R(q, o)] - \beta \cdot KL (\pi_\theta(o|q)||\pi_{ref}(o|q))$$

*   $R(q, o)$: The reward signal.
*   $\beta$: KL divergence constraint coefficient.
*   $\pi_\theta$: The current policy.
*   $\pi_{ref}$: The reference policy.

**Reward Signals:**
*   **Deterministic Exact Match:** $I [o = \text{ground-truth}(q)]$
*   **Format Reward:** For step-by-step reasoning.
*   **Verifiable Reward:** For correctness of the final output.

**Agentic Capabilities Supported:**
1.  **Agentic Search:** Autonomous decomposition of queries using the Serper API for Google search.
2.  **Agentic Coding:** Generating Python code using `cv2` to handle image degradation.

---

## Results

| Benchmark | F1 Improvement | Exact Match (EM) Improvement |
| :--- | :---: | :---: |
| **MAT-Coding** | **+18.6%** | **+13.0%** |
| **MAT-Search** | **+10.3%** | **+8.7%** |
| **2Wiki / HotpotQA** | **+29.3%** | **+25.9%** |

*   **Model Scale:** Qwen2.5-VL-3B and Qwen2.5-VL-7B (Open-source).
*   **Comparison:** Outperformed proprietary GPT-4o.
*   **Infrastructure:** Training performed on 8 GPUs.

---

## Contributions

1.  **Novel Framework:** Introduction of Visual-ARFT to bridge the gap between language-only agentic abilities and multi-modal agentic capabilities in open-source LVLMs.
2.  **Benchmarking Standard:** Development of the Multi-modal Agentic Tool Bench (MAT) to establish a new standard for evaluating agentic search and coding in multimodal models.
3.  **Empirical Validation:** Proof that specialized fine-tuning allows open-source models to exceed the performance of state-of-the-art proprietary models (like GPT-4o) in multi-modal agent tasks.

---

**Quality Score:** 9/10  
**References:** 40 citations