---
title: Large Language Models as Proxies for Theories of Human Linguistic Cognition
arxiv_id: '2502.07687'
source_url: https://arxiv.org/abs/2502.07687
generated_at: '2026-01-26T20:23:02'
quality_score: 3
citation_count: 11
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Large Language Models as Proxies for Theories of Human Linguistic Cognition

*Linguistic Cognition, Roni Katzir, Normale Sup, Emmanuel Chemla, Large Language, Imry Ziv, Tel Aviv, Nur Lan, Following Fox*

---

### ‚ö° Quick Facts

| **Metric** | **Details** |
| :--- | :--- |
| **Quality Score** | 3/10 |
| **Study Type** | Conceptual & Theoretical Framework |
| **Architectures Analyzed** | LSTM, Transformer, BERT, GPT-2, LLaMA-3.2-3b |
| **Phenomena Tested** | Across-the-board (ATB) movement, Parasitic gaps (PG), That-trace effects (TTE) |
| **Training Scale** | 10 months to 821,250 human-years |
| **References** | 11 Citations |

---

> ## üìù Executive Summary
>
> This paper addresses the fundamental question of whether Large Language Models (LLMs) can serve as valid proxies for human linguistic cognition, specifically regarding the **Argument from the Poverty of the Stimulus (APS)**. This inquiry is critical because if LLMs can learn language patterns using statistical mechanisms comparable to humans, they would support "linguistically-neutral" theories of cognition. Conversely, if LLMs fail to mirror human learning trajectories, it suggests that human language acquisition relies on innate architectural constraints absent in current neural networks. The authors aim to determine if LLMs, which process data significantly differently from children, can effectively act as experimental testbeds for validating theories of human learnability.
>
> **Key Innovation:** The study introduces a conceptual framework grounded in literature synthesis, re-positioning LLMs not merely as functional text generators, but as experimental proxies for testing cognitive theories. Technically, the paper proposes a **"probabilistic success criterion"** for evaluating model performance, requiring a model to assign a higher probability to grammatical sentences over ungrammatical ones within minimal pairs.
>
> **Outcomes:** The analysis demonstrates that current LLMs struggle to function as effective proxies. When evaluated against the probabilistic success criterion, models consistently failed to prefer grammatical structures. Specifically, regarding That-trace effects (TTE), all models except LLaMA overwhelmingly preferred ungrammatical elements. This work significantly undermines the argument that current LLMs serve as adequate proxies for linguistically-neutral theories, urging a reconsideration of the architectural assumptions used to model linguistic understanding.

---

## üîç Key Findings

*   **Proxy Potential:** Current Large Language Models (LLMs) hold potential to function as proxies for theories of human linguistic cognition.
*   **Theory Testing:** LLMs can be utilized to investigate whether a specific cognitive theory effectively accounts for the acquisition of linguistic patterns.
*   **Typological Comparison:** These models offer a mechanism to compare the learnability of typologically-attested patterns against typologically-unattested patterns.
*   **Current Limitations:** The practical utility of current LLMs in serving as effective proxies for cognitive theories remains quite limited at this stage.

---

## üî¨ Methodology

The research employs a conceptual and theoretical framework analysis rather than strictly experimental intervention. The approach involves three primary components:

1.  **Conceptualization:** Defining LLMs as proxies distinct from their own architecture.
2.  **Problem Framing:** Structuring inquiry around acquisition and typological learnability.
3.  **Literature Synthesis:** Building on recent literature to evaluate LLMs against cognitive questions.

---

## ‚öôÔ∏è Technical Details

### Architecture & Training
*   **Models Used:** 8 models including LSTM, Transformer, BERT, GPT-2, and LLaMA-3.2-3b.
*   **Training Scale:** Ranged from 10 months (CHILDES) to 821,250 human years (LLaMA).
*   **Data Metric:** Token counts converted to human-years based on a consumption rate of ~30,000 words/day.

### Framework & Testing
*   **Theory Tested:** LLMs analyzed as proxies for a 'linguistically-neutral' theory to test the Argument from the Poverty of the Stimulus (APS).
*   **Success Criterion:** A probabilistic success criterion was employed, where a model must assign a higher probability to the grammatical sentence in a minimal pair, focusing on the **critical region token**.
*   **Phenomena Analyzed:**
    *   Across-the-board (ATB) movement
    *   Parasitic gaps (PG)
    *   That-trace effects (TTE)

---

## üìä Results

*   **Data Efficiency:** Training datasets ranged from 10 months (approx. child-directed speech) to 821,250 human years (massive web datasets).
*   **That-trace Effects (TTE):**
    *   All models except LLaMA overwhelmingly preferred **ungrammatical** elements.
    *   This failure persisted even with hundreds of years of training data.
*   **Syntactic Complexity:** Results for Across-the-board (ATB) movement and Parasitic gaps (PG) were similar to TTE, showing consistent failure to prefer grammatical structures in minimal pairs.
*   **Conclusion:** LLMs require data inputs orders of magnitude larger than human experience to master complex syntax. This undermines the argument for using linguistically-neutral learning proxies to simulate human cognition.

---

## üöÄ Contributions

*   **Theoretical Framing:** Introduces the theoretical framing of using LLMs as proxies to simulate human cognition theories distinct from their own architecture.
*   **Cross-Disciplinary Bridge:** Bridges computational LLM capabilities with linguistic questions regarding pattern acquisition and typological constraints.
*   **Critical Assessment:** Provides a critical assessment of the field's state, balancing potential benefits against current limitations of LLM technology.