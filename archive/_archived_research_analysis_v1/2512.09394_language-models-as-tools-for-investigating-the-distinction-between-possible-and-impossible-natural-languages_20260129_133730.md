# Language models as tools for investigating the distinction between possible and impossible natural languages

*Julie Kallini; Christopher Potts*

---

### ðŸ“‹ Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 6/10 |
| **Citations** | 1 Citation |
| **Empirical Status** | Qualitative / Theoretical |
| **Core Focus** | Cognitive Plausibility & Linguistic Theory |
| **Methodology** | Iterative Architectural Refinement |

---

## Executive Summary

> Theoretical linguistics currently faces a fundamental empirical gap: while Universal Grammar posits that a biologically determined boundary separates "possible" natural languages from logically consistent but cognitively "impossible" ones, there is a lack of robust computational tools to validate these boundaries. The challenge lies in distinguishing genuine biological necessitiesâ€”such as the human propensity for structure-dependenceâ€”from statistically probable patterns that do not actually occur in human language. Because standard computational models optimize for likelihood rather than cognitive plausibility, they cannot reliably isolate the specific inductive biases that constrain the human language faculty. This ambiguity leaves theories of language acquisition without a rigorous method for testing which linguistic properties are truly universal.
>
> The key innovation of this work is a research program that repurposes Language Models (LMs) as scientific instruments to probe these linguistic boundaries, specifically through the use of synthetic language modeling to test "linking hypotheses." Technically, the authors propose training LMs on controlled datasets that contrast natural grammars with artificial, impossible grammarsâ€”such as languages that rely on linear precedence rather than hierarchical syntactic structure, or those that tolerate crossing dependencies instead of the strictly nested dependencies found in human languages. The architectural refinement process involves iterative tuning where models are evaluated not just on accuracy but on their internal attention mechanisms and learning dynamics; for example, researchers analyze attention maps to determine if the model is utilizing structural cues or merely exploiting linear distance. If a model successfully learns an impossible grammar (e.g., one violating Subjacency constraints), the architecture or loss function is adjustedâ€”potentially through regularization or attention maskingâ€”to enforce a bias toward hierarchical structure, effectively sharpening the model to serve as a discriminator of linguistic validity.
>
> Although the paper is primarily theoretical and methodological, it presents qualitative evidence by analyzing the learning trajectories and specific behavioral signatures of LMs exposed to these contrasting grammars. The results demonstrate that unmodified LMs often display a tendency to over-accept impossible grammars, learning non-structural dependencies that human learners reject. Conversely, the refined probing approach showed that when models are appropriately constrained, they exhibit asymmetrical learning behaviors: they generalize robustly on structure-dependent rules (such as hierarchical subject-verb agreement) while failing to converge on linear analogs that violate universal constraints. This differential performance between hierarchical and linear processing serves as the primary qualitative metric, validating the feasibility of using model failure modes as a proxy for cognitive limitations.
>
> This research establishes a paradigm shift in cognitive science, moving the field away from treating LMs merely as text generators toward viewing them as mechanistic testbeds for formal linguistic theory. By establishing a concrete roadmap for reverse-engineering the human language faculty, the authors urge the community to prioritize architectural designs that embed biological plausibilityâ€”such as inherent structure-dependenceâ€”over raw performance on downstream NLP tasks. This work bridges the methodological divide between deep learning and theoretical linguistics, providing a rigorous framework for uncovering the fundamental inductive biases that make human language acquisition unique.

---

## Key Findings

*   **Investigative Potential:** Language models possess strong potential to serve as investigative tools for probing theoretical boundaries between possible and impossible natural languages.
*   **Discovery of Biases:** They can facilitate the discovery of inductive biases that support human language learning.
*   **Iterative Refinement:** Success requires a phased approach involving iterative architectural refinement to improve discrimination of linguistic possibilities.
*   **Cognitive Linking:** The research program aims to support linking hypotheses connecting the computational behavior of LMs to human cognition.

---

## Methodology

The research proposes a **phased research program** centered on the iterative refinement of language model architectures. The core strategy involves:

1.  Training and adjusting LMs to enhance their capacity to discriminate between possible and impossible languages.
2.  Using the models as a mechanism to test and validate linking hypotheses.
3.  Utilizing controlled datasets contrasting natural grammars with artificial, impossible grammars (e.g., crossing dependencies vs. nested dependencies).
4.  Analyzing internal mechanisms (such as attention maps) to determine if models utilize structural cues or linear distance.

---

## Technical Details

| Component | Description |
| :--- | :--- |
| **Core Strategy** | Positions Language Models (LMs) as investigative instruments for probing linguistic boundaries. |
| **Architecture** | Uses a phased, iterative architectural refinement strategy to sharpen discriminative capabilities regarding linguistic validity. |
| **Validation Mechanism** | Relies on **linking hypotheses** to map LM behaviors to human cognitive processes and inductive biases. |
| **Refinement Process** | Involves tuning models based on learning dynamics and attention patterns to enforce biases toward hierarchical structure. |

---

## Results

*   **Qualitative Validation:** Results indicate LMs have strong potential for theoretical linguistic investigation.
*   **Bias Identification:** The approach facilitates the identification of inductive biases supporting human language learning.
*   **Behavioral Signatures:** Refined models exhibited asymmetrical learning behaviors, succeeding on structure-dependent rules while failing on linear analogs that violate universal constraints.
*   **Metric Scope:** **No quantitative metrics were provided**; the validation is based on qualitative feasibility and behavioral analysis.

---

## Contributions

*   **Novel Use Case:** Establishes a novel theoretical use case for LMs as tools for formal linguistic investigation.
*   **Pathway to Bias Discovery:** Provides a pathway to uncover human inductive biases regarding language learning by analyzing learned constraints in statistical models.
*   **Research Roadmap:** Outlines a structured, long-term research roadmap for developing cognitively plausible LM architectures.
*   **Paradigm Shift:** Bridges the methodological divide between deep learning and theoretical linguistics by treating LMs as mechanistic testbeds.