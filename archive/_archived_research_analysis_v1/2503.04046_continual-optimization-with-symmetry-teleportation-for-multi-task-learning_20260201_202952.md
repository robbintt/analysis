# Continual Optimization with Symmetry Teleportation for Multi-Task Learning

*Zhipeng Zhou; Ziqiao Meng; Pengcheng Wu; Peilin Zhao; Chunyan Miao*

---

### ðŸ“Š Quick Facts

| **Metric** | **Details** |
| :--- | :--- |
| **Quality Score** | 7/10 |
| **References** | 32 Citations |
| **Key Datasets** | CelebA (40 tasks), NYUv2 (3 tasks) |
| **Framework** | COST (Continual Optimization with Symmetry Teleportation) |
| **Core Component** | Low-Rank Adapters (LoRA) |
| **Optimization Strategy** | Symmetry Teleportation (Loss-Invariant) |

---

## Executive Summary

This research addresses the fundamental optimization challenges inherent in Multi-Task Learning (MTL), specifically the "**gradient interference**" that occurs when descent directions for different tasks conflict. This interference creates complex, non-convex loss landscapes that cause standard optimizers to stall at sub-optimal points. The authors argue that prevailing solutionsâ€”which rely on loss or gradient reweightingâ€”are merely reactive; they attempt to balance conflicting signals but fail to resolve the underlying geometric constraints of the optimization space, limiting the model's ability to converge effectively.

The authors introduce **Continual Optimization with Symmetry Teleportation (COST)**, a framework designed to actively navigate loss landscapes rather than simply reacting to conflicts. Technically, COST implements a "teleportation" mechanism by optimizing Low-Rank Adapters (LoRA) to shift the optimization process to a loss-equivalent point with superior convergence dynamics.

This is achieved through a composite objective that balances **Loss Invariance**â€”which minimizes loss fluctuation to ensure the new point is performance-equivalentâ€”with a **Gradient Maximization Proxy**. The use of the proxy is intended to identify regions with favorable gradient geometry (sharpness) to facilitate a more efficient descent path, rather than to influence generalization alone. The framework further incorporates a historical trajectory reuse strategy to preserve optimization momentum during these transitions.

In experimental evaluations across benchmarks including CelebA (40 tasks) and NYUv2 (3 tasks), COST consistently outperformed standard state-of-the-art baselines, demonstrating superior convergence on downstream metrics. Trajectory analysis revealed that COST successfully reaches the Pareto front, resolving optimization conflicts that cause Linear Scalarization (LS) to fail under certain initializations.

COST represents a paradigm shift in multi-task optimization, moving the field from reactive conflict mitigation to proactive landscape navigation. By providing a feasible, plug-and-play implementation for loss-invariant teleportation via LoRA, the authors offer a versatile tool that can be integrated into existing MTL pipelines without architectural changes.

---

## Key Findings

*   **Resolution of Optimization Conflicts:** The COST framework effectively resolves conflicts in Multi-Task Learning (MTL) by shifting to alternative, loss-equivalent points on the loss landscape rather than relying on traditional loss or gradient reweighting.
*   **Practical Implementation via LoRA:** Practical implementation is achieved using **Low-Rank Adapters (LoRA)** combined with convergent, loss-invariant objectives.
*   **Plug-and-Play Enhancement:** COST functions as a 'plug-and-play' module that consistently achieves superior performance when integrated with existing state-of-the-art MTL methods across multiple mainstream datasets.
*   **Landscape Navigation:** Unlike reactive methods, COST actively navigates the loss landscape to find better optimization dynamics, allowing it to reach the Pareto front where Linear Scalarization (LS) often fails.
*   **Stability:** The framework lowers the conflict ratio and improves alignment between task gradients while maintaining performance equivalence.

---

## Methodology

The authors propose **Continental Optimization with Symmetry Teleportation (COST)**, a strategy defined by three core components:

1.  **Symmetry Teleportation:** The strategy detects optimization conflicts and responds by seeking an alternative point on the loss landscape that is loss-equivalent but offers better optimization dynamics.
2.  **LoRA Implementation:** This process is technically implemented using Low-Rank Adapters (LoRA) with specifically designed convergent and loss-invariant objectives.
3.  **Trajectory Reuse:** The methodology incorporates a historical trajectory reuse strategy to ensure the system continues to leverage the benefits of advanced optimizers during the teleportation process, preserving momentum.

---

## Contributions

The research makes four distinct contributions to the field of Multi-Task Learning:

1.  **New Optimization Paradigm:** Introduces a shift away from traditional conflict mitigation toward 'symmetry teleportation' to navigate the loss landscape.
2.  **Feasible Implementation:** Presents a viable technical implementation for loss-invariant teleportation using Low-Rank Adapters (LoRA) and defines the necessary convergent objectives.
3.  **Trajectory Strategy:** Contributes a historical trajectory reuse strategy that enhances optimization efficiency during transitions.
4.  **Versatile Solution:** Delivers a versatile, plug-and-play solution that empirically boosts the performance of a wide range of existing state-of-the-art MTL methods without requiring architectural overhauls.

---

## Technical Details

The COST framework is built upon specific mathematical formulations and architectural choices:

*   **Mechanism:** Utilizes Symmetry Teleportation via Low-Rank Adapters (LoRA) to navigate to loss-equivalent points on the loss landscape without altering the loss value.
*   **Composite Objective:** Optimizes a composite objective defined as:
    `L_lora = L_t - Î³ L_g`
    *   **Loss Invariance (`L_t`):** Minimizes loss fluctuation to ensure the "teleported" point maintains equivalent performance.
    *   **Gradient Maximization Proxy (`L_g`):** Maximizes Sharpness. The goal is not necessarily generalization, but to identify regions with favorable gradient geometry to facilitate better descent.
*   **Weighting Mechanism (`R`):** Employs a weighting mechanism to balance the search process dynamically based on task gradient norms.

---

## Results

The framework was evaluated on rigorous benchmarks to validate its efficacy:

*   **Datasets:** Evaluated on **CelebA** (40 tasks) and **NYUv2** (3 tasks).
*   **Conflict Tracking:** COST tracks optimization alignment via **Conflict Ratio per Epoch**.
*   **Teleportation Dynamics:**
    *   `L_t` (Loss Invariance) decreased from approx. **0.011 to 0.007**.
    *   `L_g` (Gradient Maximization Proxy) increased from **0.914 to 0.924**.
*   **Trajectory Analysis:** COST successfully reaches the **Pareto front**.
*   **Baseline Comparison:** Outperforms Linear Scalarization (LS), which fails from certain initializations due to optimization conflicts.