---
title: 'FATE: A Prompt-Tuning-Based Semi-Supervised Learning Framework for Extremely
  Limited Labeled Data'
arxiv_id: '2504.09828'
source_url: https://arxiv.org/abs/2504.09828
generated_at: '2026-02-03T18:59:42'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# FATE: A Prompt-Tuning-Based Semi-Supervised Learning Framework for Extremely Limited Labeled Data

*Hezhao Liu; Yang Lu; Mengke Li; Yiqun Zhang; Shreyank N Gowda; Chen Gong; Hanzi Wang*

---

> ### ðŸ“Š Quick Facts
>
> *   **Performance Improvement:** 33.74% over state-of-the-art SSL methods
> *   **Data Efficiency:** Effective with as few as one labeled sample per class
> *   **Modalities:** Compatible with Vision (ViT) and Vision-Language (CLIP) models
> *   **Quality Score:** 9/10
> *   **References:** 40 Citations

---

## Executive Summary

This research addresses the critical challenge of semi-supervised learning (SSL) in "extreme low-label" regimes, where labeled data is exceptionally scarce (e.g., a single sample per class). Traditional SSL methods typically rely on a substantial volume of labeled data to effectively guide the learning process; as the number of labeled samples decreases, these methods often suffer catastrophic performance drops. The paper highlights that while pre-trained models possess vast prior knowledge, existing fine-tuning and SSL strategies fail to adequately leverage this knowledge when labeled supervision is minimal, creating a barrier for deploying AI in data-constrained environments.

The authors propose **FATE** (Firstly Adapt, Then catEgorize), a novel two-stage prompt-tuning framework that decouples feature distribution adaptation from class categorization. Unlike conventional methods that attempt to learn features and classifiers simultaneously, FATE freezes the pre-trained backbone and operates in two distinct phases. In Stage 1 (Adaptation), the framework optimizes Distribution-adaptive Prompts ($P_d$) using only unlabeled data to align the model with downstream feature distributions. In Stage 2 (Categorization), FATE freezes $P_d$ and optimizes Classification Prompts ($P_c$) using a modified FixMatch algorithm that utilizes both the limited labeled data and the adapted unlabeled data to perform the final classification.

FATE demonstrates exceptional efficacy in resource-constrained settings, achieving a **33.74% improvement** over state-of-the-art SSL methods. The framework exhibits robustness even under the most extreme conditions, performing effectively with only one labeled sample per class. Comparatively, while classical SSL methods like SoftMatch experienced nearly a 50% performance drop as labels decreased, FATE maintained its stability. Furthermore, the framework outperformed existing Parameter-Efficient Fine-Tuning (PEFT) baselines such as Visual Prompt Tuning (VPT) and CoOp across multiple benchmarks, validating its superiority on both pure vision (ViT) and vision-language (CLIP) architectures.

The significance of FATE lies in establishing a new paradigm for utilizing massive pre-trained models in scenarios where data annotation is prohibitively expensive or impractical. By successfully decoupling adaptation from categorization via prompt tuning, the research offers a highly parameter-efficient solution that maximizes the utility of unlabeled data.

---

## Key Findings

*   **Superior Performance:** Achieved a 33.74% improvement over state-of-the-art SSL methods in low-resource regimes.
*   **Extreme Scarcity Handling:** Demonstrated high effectiveness even when limited to a single labeled sample per class.
*   **Data Balance:** Successfully balances the utilization of limited labeled data with abundant unlabeled data.
*   **Cross-Modal Compatibility:** Validated effectiveness across both vision and vision-language models.

---

## Methodology

The proposed framework, FATE, utilizes a two-stage prompt tuning paradigm specifically designed for pre-trained models. This approach is unique in that it keeps the pre-trained backbone frozen throughout the process.

*   **Stage 1 (Adaptation):** The model is adapted to the downstream feature distribution using *only* unlabeled samples. This stage focuses on aligning the pre-trained knowledge with the specific structure of the new data without label supervision.
*   **Stage 2 (Categorization):** A semi-supervised learning method is applied to perform classification using the limited labeled data. This stage builds upon the adaptations made in the first stage to fine-tune the classifier.

---

## Technical Details

FATE is a two-stage prompt-tuning framework for semi-supervised learning in low-label regimes.

### Architecture & Strategy
*   **Backbone:** Kept frozen to maintain pre-trained knowledge.
*   **Stage 1 (Adaptation):** Optimizes **Distribution-adaptive Prompts ($P_d$)** on unlabeled data using unsupervised loss.
    *   *ViT:* Uses Contrastive Learning.
    *   *CLIP:* Uses Zero-shot pseudo-labeling.
*   **Stage 2 (Classification):** Optimizes **Classification Prompts ($P_c$)** using a modified FixMatch algorithm on both labeled and unlabeled data. During this stage, $P_d$ is frozen.

### Loss Functions & Specifics
*   **ViT Implementation:** Utilizes InfoNCE style loss.
*   **CLIP Implementation:** Employs the CoOp (Context Optimization) strategy for text prompts.

---

## Contributions

*   **Novel Framework:** Introduction of a tailored SSL framework specifically designed for extremely limited labeled data scenarios.
*   **Decoupled Strategy:** Development of a two-stage prompt tuning strategy that decouples feature adaptation from class categorization.
*   **Broad Applicability:** Demonstration of the framework's effectiveness across both vision and vision-language modalities.

---

## Results

*   **Performance:** FATE achieves a **33.74% improvement** over state-of-the-art SSL methods in low-resource settings.
*   **Few-Shot Capability:** Works effectively with only one labeled sample per class.
*   **Comparative Analysis:**
    *   Significantly outperforms classical SSL methods like **SoftMatch**, which dropped nearly 50% when labels decreased.
    *   Outperforms PEFT methods like **VPT** and **CoOp**.
*   **Validation:** The framework is validated on both vision (ViT) and vision-language (CLIP) models.
*   **Efficiency:** Maintains parameter efficiency by only updating prompt vectors.

---

**Quality Score:** 9/10 | **References:** 40 citations