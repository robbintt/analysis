---
title: 'Causal MAS: A Survey of Large Language Model Architectures for Discovery and
  Effect Estimation'
arxiv_id: '2509.00987'
source_url: https://arxiv.org/abs/2509.00987
generated_at: '2026-02-03T07:14:59'
quality_score: 9
citation_count: 31
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Causal MAS: A Survey of Large Language Model Architectures for Discovery and Effect Estimation

*Adib Bazgir; Amir Habibdoust; Yuwen Zhang; Xing Song*

---

> ### üìä Quick Facts
>
> *   **Quality Score:** 9/10
> *   **Total Citations:** 31
> *   **Core Focus:** Intersection of Causal AI and LLM-based Multi-Agent Systems
> *   **Key Paradigms:** Causal Reasoning, Causal Discovery, Causal Estimation
> *   **Primary Domains:** Healthcare, Scientific Discovery, Fact-checking

---

## üìã Executive Summary

This research addresses the fundamental inability of single Large Language Models (LLMs) to perform reliable causal inference. While LLMs excel at pattern matching, they struggle with complex causal tasks‚Äîsuch as discovery and effect estimation‚Äîdue to tendencies toward hallucination and reliance on spurious correlations rather than true cause-and-effect mechanisms. This limitation is a critical bottleneck for high-stakes fields requiring rigorous reasoning, including scientific discovery, healthcare decision-making, and automated fact-checking, where understanding *why* something happens is as important as predicting *what* happens next.

The core innovation presented is the paradigm shift from monolithic LLMs to Multi-Agent Systems (MAS), which offer superior performance in causal domains. The authors provide a technical taxonomy categorizing "Causal Multi-Agent LLMs" into three distinct architectural paradigms: (1) Causal Reasoning and Counterfactuals, utilizing specialized agents like "Faithful Reasoners" and "Causal Evaluators" (e.g., LoCal, CaCo-CoT); (2) Multi-Agent Causal Discovery, employing interaction protocols such as adversarial debates (e.g., MAC) and embodied simulations (e.g., ADAM in Minecraft) to construct causal graphs; and (3) Agentic Causal Estimation, which uses orchestrator agents to integrate external algorithmic tools, such as Double Machine Learning (DML) or Propensity Score Matching (PSM), as seen in systems like Causal-Copilot and TrialGenie.

The survey synthesizes evaluation metrics across these diverse architectures, revealing task-specific performance benchmarks. For Causal Discovery, efficacy is measured via graph reconstruction accuracy using Structural Hamming Distance (SHD), Normalized Hamming Distance (NHD), Precision, Recall, and F1-scores. In Causal Reasoning, systems like LoCal are evaluated on benchmarks such as HOVER and FEVEROUS using Accuracy and F1-scores, while social reasoning agents utilize Belief-Desire-Intention (BDI) metrics. For Causal Effect Estimation, results are grounded in clinical and statistical validity; for instance, TrialGenie is assessed by comparing Average Treatment Effects (ATEs) and Hazard Ratios against ground truth. Evaluation methodologies increasingly combine human oversight with LLM-as-a-Judge protocols.

This work is significant as it provides the first comprehensive structural overview of the intersection between Causal AI and LLM-based agents. By aggregating evaluation methodologies and delineating architectural patterns, the paper establishes a framework for standardizing assessment in a rapidly evolving field. The findings highlight the broad utility of causal MAS across domains, suggesting that multi-agent architectures are poised to become the standard for robust, explainable AI in scientific and medical applications, while simultaneously identifying open challenges regarding robustness and standardization that must be addressed to enable future adoption.

---

## üîë Key Findings

*   **Limitations of Single LLMs:** Individual models struggle with complex causal tasks due to hallucinations and an over-reliance on spurious correlations.
*   **Efficacy of Multi-Agent Systems (MAS):** MAS are emerging as a superior paradigm for causal inference, outperforming monolithic approaches.
*   **Architectural Diversity:** The field utilizes diverse interaction protocols and designs, including pipelines, debates, and simulations.
*   **Broad Application Impact:** Causal MAS demonstrates significant utility across high-value domains like scientific discovery, healthcare, and fact-checking.
*   **Evolving Landscape:** Despite progress, critical challenges regarding standardization, evaluation robustness, and architectural consistency remain.

---

## üõ†Ô∏è Methodology

The authors employ a systematic survey methodology comprising four main analytical pillars:

1.  **Categorical Analysis:** Based on causal facets to segment the problem space.
2.  **Taxonomic Review:** A detailed review of architectural patterns and interaction protocols used in current systems.
3.  **Evaluation Synthesis:** Aggregation of benchmarks and metrics to assess performance.
4.  **Domain Mapping:** Mapping application areas to understand the practical reach of the technology.

---

## üìù Contributions

*   **Comprehensive Overview:** Provides the first major overview of the intersection between Causal AI and LLM-based MAS.
*   **Structural Taxonomy:** Delineates a clear structural taxonomy of architectural patterns used for causal integration.
*   **Evaluation Aggregation:** Aggregates evaluation methodologies and benchmarks to promote standardized assessment across the field.
*   **Future Roadmap:** Identifies critical open challenges and proposes a roadmap for future research.

---

## ‚öôÔ∏è Technical Details

The paper categorizes **Causal Multi-Agent LLMs** into three primary architectural paradigms:

### 1. Causal Reasoning & Counterfactuals
Focuses on logical deduction and "what-if" scenarios.
*   **LoCal:** Utilizes *Decomposing*, *Logically Evaluating*, and *Counterfactually Evaluating* Agents.
*   **CaCo-CoT:** Employs a *Faithful Reasoner* agent and a *Causal Evaluator* agent.

### 2. Multi-Agent Causal Discovery
Focuses on identifying cause-and-effect relationships from data.
*   **MAC (Multi-Agent Causal Discovery):** Utilizes a *Debate-Coding Module* and *Meta-Debate Module* featuring adversarial debaters.
*   **Agent4Rec:** Uses a *user simulator* for indirect discovery via interaction logs.
*   **ADAM:** An embodied agent that constructs causal graphs within a *Minecraft* simulation environment.

### 3. Agentic Causal Estimation
Focuses on calculating the magnitude of causal effects.
*   **Causal-Copilot:** Features an *LLM Orchestrator* and an *Algorithm Selection Module* that integrates external tools like Double Machine Learning (DML) and Propensity Score Matching (PSM).
*   **TrialGenie:** A multi-agent system involving *Statistician* and *Clinician* agents for Target Trial Emulation.

---

## üìà Results & Evaluation

Evaluation metrics are highly task-specific, varying significantly between discovery, reasoning, and estimation.

| Domain | Primary Metrics | Benchmarks & Context |
| :--- | :--- | :--- |
| **Causal Discovery** | Structural Hamming Distance (SHD), Normalized Hamming Distance (NHD), Precision, Recall, F1-score | Graph reconstruction accuracy |
| **Causal Reasoning** | Accuracy, F1-score, CEQ Score, BDI Assessment | **HOVER & FEVEROUS** (LoCal), **ScienceQA** (CausalGPT), **WIKIWHY** (LEGO), **e-CARE**, **ToM-agent** (Social Reasoning) |
| **Causal Estimation** | Hazard Ratios, Average Treatment Effects (ATE), Mean Glucose Reduction (MGR), Runtime | **TrialGenie** (ATE vs Ground Truth), Personalized Graphs (MGR), **Causal-Copilot** (F1-score & Runtime) |

**Evaluation Methodologies:**
*   Human Evaluation
*   LLM-as-a-Judge protocols