# Capacity-Constrained Continual Learning

*Zheng Wen; Doina Precup; Benjamin Van Roy; Satinder Singh*

---

> ### **Quick Facts**
> *   **Quality Score:** 8/10
> *   **Total Citations:** 27
> *   **Core Problem:** Continual Learning under strict resource constraints
> *   **Methodology:** Mathematical derivation (LQG framework)

## Executive Summary

This paper addresses the fundamental challenge of Continual Learning (CL) under strict resource constraints. While humans learn continuously over a lifetime, artificial agents often struggle due to finite memory and computational budgets, leading to issues like catastrophic forgetting. The authors identify a critical lack of theoretical frameworks for how an agent should optimally allocate limited resources (measured in bits of mutual information) over time when learning a sequence of tasks. This problem matters because it moves beyond empirical approaches to resource management, providing a rigorous mathematical basis for deploying agents in power-constrained or memory-limited real-world environments.

The key innovation is the derivation of an exact mathematical solution to the capacity-constrained Linear-Quadratic-Gaussian (LQG) sequential prediction problem. The authors formulate the problem (**C3L-LQG**) by introducing a mutual information constraint, $I(S_t; H_t) \leq B$, which limits the information flow from the history to the current state. The solution utilizes a two-stage approach involving a relaxed prediction model (**C2P-LQG**) followed by a rigorous continual learning formulation. Technically, the optimal architecture is defined by a linear prediction model $\hat{\theta}_t = F_t\bar{\theta}_t + \epsilon_t$, where a "water-filling" algorithm is employed to allocate finite capacity across different dimensions. This algorithm distributes bits based on the eigenvalues of the covariance matrix ($\lambda_i$), with the bits per dimension calculated as $B_i = \frac{1}{2} [\log(2\lambda_i/\eta)]_+$.

The study derives an explicit formula for the optimal asymptotic cost: $\text{Cost} = \text{tr}(M) + \sum_{i=1}^d \exp(-2B_i)\lambda_i$. The authors rigorously verified that this solution behaves correctly at critical boundary conditions. When capacity is infinite ($B \to \infty$), the cost converges to that of the unconstrained Kalman filter ($\text{tr}(M)$). Conversely, at zero capacity ($B = 0$), the cost matches the prior variance ($\text{tr}(\Sigma)$). Furthermore, in the scalar case, the authors proved that optimality conditions hold for any $B > 0$, providing an explicit scaling factor where $F = 1 - \exp(-2B)$.

This paper significantly advances the field by establishing one of the first systematic theoretical frameworks for analyzing learning under capacity constraints, bridging the gap between engineering heuristics and information theory. By demonstrating that optimal performance is contingent upon the strategic allocation of memory and compute resources via water-filling, the work provides a foundational logic for managing continual learning tasks. This theoretical grounding is essential for the future development of efficient AI systems, offering a principled approach to decomposing complex problems and managing resources in environments where agents cannot store or process infinite historical data.

---

## Key Findings

*   **Mathematical Solution:** The researchers successfully derived a mathematical solution to the capacity-constrained Linear-Quadratic-Gaussian (LQG) sequential prediction problem under specific technical conditions.
*   **Optimal Allocation:** It was demonstrated that for complex problems decomposable into sub-problems, there exists a method to optimally allocate finite capacity across these sub-problems in the steady state.
*   **Resource Strategy:** The study establishes that optimal performance for agents with finite resources relies heavily on how memory and compute resources are strategically allocated over time.

## Methodology

The authors employed a theoretical and analytical approach, focusing on a simplified but relevant model of continual learning: the capacity-constrained Linear-Quadratic-Gaussian (LQG) sequential prediction problem. They utilized mathematical derivation to establish a solution framework and performed steady-state analysis to determine resource allocation strategies for decomposable problem sets.

## Contributions

*   **Bridging the research gap:** The paper addresses the under-explored area of resource allocation for agents operating under strict memory and compute constraints.
*   **Theoretical foundation:** It provides one of the first systematic theoretical frameworks for analyzing learning under capacity constraints, moving beyond empirical observations to established solutions.
*   **Practical framework for decomposition:** By establishing how to optimally allocate capacity across sub-problems, the work offers a foundational logic for managing continual learning tasks in resource-constrained environments.

## Technical Details

The paper formalizes Capacity-Constrained Continual Learning (**C3L-LQG**) in an LQG framework with a mutual information constraint:

$$I(S_t; H_t) \leq B$$

The solution involves a two-stage approach:
1.  **C2P-LQG:** Relaxed prediction based on full history.
2.  **C3L-LQG:** Continual learning with incremental updates.

**Optimal Prediction Architecture:**
$$\hat{\theta}_t = F_t\bar{\theta}_t + \epsilon_t$$

**Water-Filling Algorithm:**
A 'water-filling' algorithm allocates capacity across dimensions using eigenvalues of the covariance matrix. Bits per dimension are calculated as:

$$B_i = \frac{1}{2} [\log(2\lambda_i/\eta)]_+$$

This is used to construct the scaling matrix $F$ and noise covariance $\Psi$.

## Results

The authors derived an exact formula for the optimal asymptotic cost:

$$\text{Cost} = \text{tr}(M) + \sum_{i=1}^d \exp(-2B_i)\lambda_i$$

**Boundary Conditions Verified:**
*   **Infinite Capacity ($B \to \infty$):** The cost matches the unconstrained Kalman filter ($\text{tr}(M)$).
*   **Zero Capacity ($B = 0$):** The cost matches the prior variance ($\text{tr}(\Sigma)$).

**Scalar Case:**
It was proven that optimality conditions hold for $B > 0$, with the scaling factor explicitly defined as:

$$F = 1 - \exp(-2B)$$