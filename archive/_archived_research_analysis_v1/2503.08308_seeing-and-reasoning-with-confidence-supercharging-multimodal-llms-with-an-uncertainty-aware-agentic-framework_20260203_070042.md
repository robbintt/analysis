---
title: 'Seeing and Reasoning with Confidence: Supercharging Multimodal LLMs with an
  Uncertainty-Aware Agentic Framework'
arxiv_id: '2503.08308'
source_url: https://arxiv.org/abs/2503.08308
generated_at: '2026-02-03T07:00:42'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Seeing and Reasoning with Confidence: Supercharging Multimodal LLMs with an Uncertainty-Aware Agentic Framework

*Zhuo Zhi; Chen Feng; Adam Daneshmend; Mine Orlu; Andreas Demosthenous; Lu Yin; Da Li; Ziquan Liu; Miguel R. D. Rodrigues*

---

> ### ðŸ“Š Quick Facts
>
> *   **Average Performance Gain:** +4.6% over base MLLMs
> *   **Training Requirement:** None (Training-free)
> *   **Core Mechanism:** Uncertainty Quantification (UQ) & Conformal Prediction
> *   **Datasets Evaluated:** 5 distinct datasets
> *   **Key Advantage:** Eliminates costly data annotation and fine-tuning

---

## Executive Summary

Current Multimodal Large Language Models (MLLMs) face a critical trade-off between achieving high performance and managing computational costs. Enhancing reasoning capabilities typically requires expensive fine-tuning with extensive data annotations, particularly for Chain-of-Thought processes. Conversely, employing agentic frameworks that utilize external tools offers a training-free alternative but introduces significant reliability risks; the unvetted outputs of these external tools can lead to hallucinations or errors that degrade the overall trustworthiness of the system.

The researchers introduce **SRICE (Seeing and Reasoning with Confidence)**, a novel, training-free agentic framework designed to integrate Uncertainty Quantification (UQ) directly into multimodal reasoning pipelines. Technically, SRICE operates by allowing the MLLM to autonomously select Regions of Interest (ROIs) without manual supervision. Its core innovation lies in a conformal prediction-based approach that calibrates the outputs of external vision models. By dynamically estimating the uncertainty of both the MLLMâ€™s internal reasoning and the external tools, SRICE can intelligently select the optimal tool for a given task while filtering out low-confidence or unreliable predictions.

SRICE demonstrated substantial empirical efficacy across five distinct datasets, achieving an average performance improvement of 4.6% over base MLLM models. Crucially, the framework matched or outperformed state-of-the-art methods that rely on costly fine-tuning, realizing these gains with zero training overhead. The integration of uncertainty-aware mechanisms successfully mitigated the risks associated with external tool usage, validating the framework's ability to maintain high accuracy while eliminating the need for costly data annotation and fine-tuning.

This work significantly influences the field by bridging the gap between resource-intensive fine-tuning strategies and the often-risky deployment of agentic tools. By demonstrating that uncertainty-aware, tool-augmented inference can rival fine-tuned state-of-the-art methods, SRICE offers a scalable and cost-effective pathway to enhancing MLLM capabilities. The research establishes a new standard for reliable agentic systems, emphasizing that uncertainty quantification is essential for the safe and effective advancement of multimodal AI agents.

---

## Methodology

The researchers proposed **SRICE**, a training-free multimodal reasoning framework designed to integrate external vision models with Uncertainty Quantification (UQ) into MLLMs. The methodology operates through a distinct multi-stage interaction process:

1.  **Autonomous Selection:** The MLLM autonomously selects Regions of Interest (ROIs) without human intervention.
2.  **Calibration:** It utilizes a **conformal prediction-based approach** to calibrate the output of external tools, ensuring statistical validity.
3.  **Dynamic Tool Selection:** The system estimates the uncertainty of the MLLM's own output to dynamically select the optimal tool for the specific task at hand.

---

## Key Findings

*   **Performance Boost:** The SRICE framework achieves an average performance improvement of **4.6%** over base Multimodal Large Language Models (MLLMs) across five datasets.
*   **Cost Efficiency:** On specific datasets, it outperforms methods that rely on costly fine-tuning **without requiring extensive training**.
*   **Risk Mitigation:** By incorporating uncertainty quantification, the framework successfully addresses the risk of unreliable outputs from external tools.
*   **Elimination of Overhead:** The approach eliminates the need for costly data annotation and fine-tuning typically required by Chain-of-Thought reasoning methods.

---

## Technical Specifications

**Framework Name:** SRICE (Seeing and Reasoning with Confidence)

**Classification:** Uncertainty-Aware Agentic Framework for Multimodal Large Language Models (MLLMs)

**Core Components:**
*   **Uncertainty Quantification (UQ):** Evaluates the confidence of the model's reasoning.
*   **External Tool Integration:** Utilizes external tools while filtering outputs to ensure reliability.
*   **Training-Free Architecture:** Requires no fine-tuning or costly data annotations.

**Operational Logic:**
*   Employs conformal prediction for calibration.
*   Filters low-confidence predictions to maintain system integrity.

---

## Performance Results

SRICE achieved robust results in testing scenarios:

*   **Average Improvement:** **4.6%** improvement over base MLLM models across five distinct datasets.
*   **Comparison vs. Fine-Tuning:** Outperformed methods relying on costly fine-tuning by achieving comparable or superior results **without training overhead**.
*   **Reliability:** Successfully mitigated the risk of unreliable outputs from external tools, proving the efficacy of the uncertainty-aware design.

---

## Research Contributions

*   **Novel Framework:** Introduction of a novel training-free agentic framework that bridges the gap between expensive Chain-of-Thought fine-tuning and risky agentic tool usage.
*   **UQ Integration:** Successful integration of Uncertainty Quantification (UQ) into multimodal agents to ensure reliable tool use, specifically using conformal prediction for calibration.
*   **Autonomous ROI:** Enhancement of MLLM capabilities by enabling autonomous region-of-interest selection, reducing the need for manual supervision.
*   **Empirical Validation:** Provision of empirical evidence demonstrating that uncertainty-aware, tool-augmented inference can rival fine-tuning-based state-of-the-art methods.

---

**Document Quality Score:** 8/10
**References:** 40 citations