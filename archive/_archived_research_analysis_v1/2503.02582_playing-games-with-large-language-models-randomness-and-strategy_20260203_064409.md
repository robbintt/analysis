---
title: 'Playing games with Large language models: Randomness and strategy'
arxiv_id: '2503.02582'
source_url: https://arxiv.org/abs/2503.02582
generated_at: '2026-02-03T06:44:09'
quality_score: 6
citation_count: 10
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Playing games with Large language models: Randomness and strategy

*Alicia Vidler; Toby Walsh*

### ðŸ“Š Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Model Analyzed** | GPT-4o-Mini |
| **Framework** | LangChain |
| **Games Tested** | Rock Paper Scissors (RPS), Prisoner's Dilemma (PD) |
| **Quality Score** | 6/10 |
| **References** | 10 Citations |

---

## Executive Summary

> This research addresses the critical question of Large Language Model (LLM) reliability in game-theoretic environments, specifically challenging the "stochastic parrot" discourse which assumes these models generate truly random, independent outputs. While LLMs are theoretically probabilistic, this study investigates whether they can function as truly stochastic agents capable of executing unbiased randomization required for optimal mixed-strategy equilibria.

The authors introduce a rigorous experimental framework utilizing the `GPT-4o-Mini-2024-08-17` snapshot, deployed via the LangChain framework to facilitate autonomous agent interactions. The methodology technically distinguishes itself by isolating model behaviors through two distinct sampling proceduresâ€”independent versus batch API callsâ€”and testing both simultaneous and sequential game modes.

The results provide empirical evidence that LLMs exhibit significant biases, failing to act as truly stochastic agents. The study quantified specific performance metrics, finding a marked deviation from the theoretical uniform distribution in simulations. In Rock Paper Scissors, agents displayed a pronounced tendency toward loss-averse strategies, causing games to converge on stalemate conditions. In the Prisoner's Dilemma, models showed systematic shifts between cooperation and competition, with outcomes heavily dependent on specific prompt designs rather than consistent rational logic.

This work exposes fundamental behavioral limitations in current LLM architectures, specifically their propensity for risk-averse behaviors and inability to achieve optimal mixed strategies. The findings suggest that current LLMs cannot be reliably deployed in environments requiring unbiased randomization or sophisticated strategic adaptation without significant intervention.

---

## Key Findings

*   **Failure of Stochasticity:** Contrary to the "stochastic parrot" label, LLMs exhibit significant bias when prompted to generate random outputs, proving they are not truly stochastic agents.
*   **Loss Aversion Dominance:** In repeated game scenarios, specifically Rock Paper Scissors, LLMs demonstrate a tendency toward loss aversion strategies, leading to convergence on stalemate conditions rather than mixed-strategy equilibria.
*   **Prompt Sensitivity:** In strategic games like the Prisoner's Dilemma, models show systematic shifts between cooperation and competition. These outcomes are heavily influenced by specific prompt designs rather than rational game theory.
*   **Poor Strategic Performance:** While LLMs possess the functional capability to participate in games, their overall performance in strategic decision-making is rated as poor compared to theoretical benchmarks.
*   **Comparison to Humans:** Literature context indicates that LLMs struggle to sample from specific distributions (e.g., normal, uniform) and may produce results with greater systemic bias than human counterparts.

---

## Methodology

The study employed a controlled experimental design to evaluate LLM behavior in game-theoretic contexts.

*   **Model Focus:** The study focused exclusively on the **GPT-4o-Mini-2024-08-17** model.
*   **Agent Interaction:** Researchers utilized programmatic tools to facilitate independent agent interactions, testing LLMs against one another autonomously.
*   **Game Selection:** Two distinct games were employed to test different capabilities:
    *   **Rock Paper Scissors (RPS):** Used to evaluate randomization capabilities and uniform distribution adherence.
    *   **Prisoner's Dilemma (PD):** Used to evaluate strategic adaptation and cooperation versus competition.
*   **Interaction Modes:** The experiments covered both **simultaneous** and **sequential** game interactions to fully assess model adaptability.

---

## Technical Details

The research relies on specific technical implementations to ensure valid interaction between independent agents.

**Architecture & Tools**
*   **Framework:** The study utilizes the **LangChain** framework to deploy independent agents interacting in game-theoretic environments.
*   **Sampling Methods:** The approach investigates various prompt engineering designs and distinguishes between **independent** and **batch API** sampling methods.

**Model Specification**
*   **Primary Model:** `GPT-4o-Mini-2024-07-18`
    *   *Note: Selected for its prior success in random sampling tasks over other models like GPT-3.5 and LLAMA 7B.*

**Game Theoretic Implementation**
*   **Rock Paper Scissors (RPS):** Designed to evaluate uniform distribution strategies.
*   **Prisoner's Dilemma (PD):** Designed to assess dominant versus Pareto optimal strategies.
*   **Modes:** Testing included both **one-shot** and **repeated** game modes to observe learning and strategy shifts over time.

---

## Contributions

This paper makes several meaningful contributions to the field of LLM research and multi-agent systems:

*   **Empirical Behavioral Evidence:** Provides concrete evidence regarding specific behavioral traits in LLMs, specifically their inability to generate true randomness and their propensity for risk-averse (loss aversion) behaviors.
*   **Technical Tooling:** Details programmatic tools for independent agent interactions, contributing to the technical understanding of implementing multi-agent LLM systems.
*   **Limitation Analysis:** Highlights critical limitations in current model outputs that impact the reliability of LLMs in multi-agent environments and strategic decision-making applications.
*   **Benchmarking:** By detailing specific performance deficits of the GPT-4o-Mini snapshot, the paper provides a critical benchmark for future model development.

---

## Results Summary

The experimental data revealed consistent deviations from expected rational agent behavior:

1.  **Randomization Failure:** LLMs exhibit significant bias when generating random outputs, failing to act as truly stochastic agents and limiting optimal mixed strategies in zero-sum games.
2.  **Stalemate Conditions:** In Rock Paper Scissors, agents demonstrated a tendency toward loss aversion strategies, causing games to converge on stalemate conditions rather than the expected random distribution.
3.  **Systematic Strategy Shifts:** In Prisoner's Dilemma, models showed systematic shifts between cooperation and competition heavily influenced by prompt designs.
4.  **Distribution Sampling Issues:** The data indicates that LLMs struggle to sample from target distributions effectively, often producing results with greater systemic bias than human counterparts.