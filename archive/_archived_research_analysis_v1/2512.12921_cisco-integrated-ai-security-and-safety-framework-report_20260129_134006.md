# Cisco Integrated AI Security and Safety Framework Report

*Amy Chang; Tiffany Saade; Sanket Mendapara; Adam Swanda; Ankit Garg*

---

> ### üìä Quick Facts
>
> *   **Quality Score:** 8/10
> *   **References:** 32 Citations
> *   **Industry Priority:** 69% of companies rank AI as a top IT priority
> *   **Threat Readiness:** Only 29% feel fully equipped against AI threats
> *   **Change Management:** Only 33% have formal change management plans
> *   **Adoption vs. Regulation Friction:** AI capabilities double in months; processes take years

---

## üìë Executive Summary

The rapid integration of Artificial Intelligence has expanded the attack surface significantly, introducing complex threats that range from content safety failures and model compromises to runtime manipulations and ecosystem risks. A critical challenge identified in this research is that current industry defense mechanisms operate in silos; prevailing frameworks such as MITRE ATLAS, NIST AI 100-2, and OWASP provide valuable but disparate perspectives, failing to bridge the gap between technical security exploits and ethical safety harms. This fragmentation leaves organizations vulnerable to evolving threats, particularly as the industry shifts toward complex, multi-modal environments including humanoids, wearables, and sensory infrastructures. The paper addresses the urgent need for a unified risk management approach that spans the entire AI lifecycle‚Äîfrom data collection to incident response‚Äîrather than treating security and safety as separate domains.

To resolve these fragmentation issues, the authors performed a comprehensive gap analysis against existing taxonomies (MITRE ATLAS, NIST, OWASP) to identify specific coverage deficiencies. Their key innovation is the **Cisco Integrated AI Security and Safety Framework**, a unified taxonomy designed through a rigorous comparative process to integrate AI security threats, safety content harms, and supply chain threats. Technically, the framework expands the traditional CIA triad by adding a fourth pillar, **Accountability**, and extends coverage to support the Model Context Protocol (MCP), agentic workflows, and multi-agent systems. This architecture is lifecycle-aware, enabling the classification of systemic failures and adversary exploits and ensuring that safety is defined not merely as the absence of errors, but as the assurance of ethical, reliable, and transparent system behavior.

The research applied this unified methodology to assess industry readiness, revealing a stark disparity between adoption rates and defensive preparedness. While 69% of companies rank AI as a top IT priority, the study found that only **29%** feel fully equipped to defend against AI threats, and a mere **33%** have formal change management plans in place. The analysis highlights a critical temporal friction: AI capabilities are doubling in months, whereas organizational and regulatory processes operate on timescales of years. By operationalizing the framework to structure system failures, the authors demonstrate that while the speed of AI evolution outpaces current governance, the proposed taxonomy offers a mechanism for immediate risk classification and prioritization where specific performance metrics for other frameworks are often lacking.

The significance of this work lies in the provision of a forward-looking, extensible taxonomy that remains applicable as AI capabilities and deployment scenarios evolve. By offering a practical defense architecture that supports specific activities like red-teaming and holistic risk classification, the framework moves organizations from theoretical risk models to actionable defense strategies. Its explicit inclusion of future domains‚Äîsuch as humanoids, wearables, and sensory infrastructures‚Äîensures that the scope of protection extends beyond current software models to the broader physical and ecosystem risks. Consequently, this framework acts as a foundational tool for establishing robust defenses, enabling the industry to address the widening gap between rapid AI innovation and necessary safety and security controls.

---

## üö® Key Findings

*   **Expanded Attack Surface:** Rapid AI integration has broadened threats to include content safety failures, model compromises, runtime manipulations, and ecosystem risks.
*   **Limitations of Current Frameworks:** Prevailing frameworks like MITRE ATLAS, NIST AI 100-2, and OWASP provide valuable but siloed perspectives, failing to cover the full spectrum of AI risks.
*   **Need for Integration:** Effective AI risk management requires a unified approach bridging the gap between AI security and safety across various modalities and ecosystems.
*   **Future-Proofing Requirements:** A robust framework must be extensible enough to address emerging deployments in complex environments such as humanoids, wearables, and sensory infrastructures.

---

## ‚öôÔ∏è Technical Details

The framework is a unified taxonomy integrating AI security threats, safety content harms, and supply chain threats, designed to bridge the gap between technical exploits (e.g., prompt injection) and safety failures.

*   **Architecture Scope:** Covers the entire AI lifecycle from Data Collection to Incident Response.
*   **Protocol Support:** Incorporates the Model Context Protocol (MCP) and agentic workflows.
*   **System Support:** Designed for multi-agent systems and multi-modal data types.
*   **CIA Triad Expansion:** Expands the traditional triad to include a fourth pillar: **Accountability**.
*   **Safety Definition:** Defines AI Safety as ensuring ethical, reliable, and transparent system behavior.

---

## üî¨ Methodology

*   **Gap Analysis:** Conducted a comparative analysis of existing taxonomies (MITRE ATLAS, NIST, OWASP) to identify limitations and coverage gaps.
*   **Framework Design:** Established design principles to develop a unified, lifecycle-aware taxonomy.
*   **Operationalization and Demonstration:** Demonstrated the framework's utility by structuring system failures and adversary exploits for practical threat identification and risk prioritization.

---

## ‚ú® Contributions

*   **Cisco‚Äôs Integrated AI Security and Safety Framework:** A comprehensive, unified taxonomy integrating AI security and safety across the entire lifecycle.
*   **Holistic Risk Classification:** A mechanism to classify the full range of AI risks, including runtime manipulations and ecosystem risks.
*   **Practical Defense Architecture:** A structure designed to help organizations build defenses and support activities like red-teaming.
*   **Extensible Taxonomy:** A forward-looking framework designed to remain applicable as AI capabilities evolve.

---

## üìà Results & Industry Readiness

Industry readiness metrics show a significant disconnect between prioritization and preparedness:

*   **High Priority, Low Readiness:** 69% of companies rank AI as a top IT priority, yet only 29% feel fully equipped against AI threats.
*   **Governance Gap:** Only 33% have formal change management plans in place.
*   **Velocity Friction:** AI capabilities are reported to double in months, creating friction with organizational and regulatory processes that operate on timescales of months or years.
*   **Framework Utility:** Specific framework performance metrics are noted as unavailable in the provided text, though the operationalization demonstrates utility in structuring failures.

---

**Quality Score:** 8/10 | **Total References:** 32