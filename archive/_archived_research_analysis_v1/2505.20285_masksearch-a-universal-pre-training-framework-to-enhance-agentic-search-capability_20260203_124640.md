---
title: 'MaskSearch: A Universal Pre-Training Framework to Enhance Agentic Search Capability'
arxiv_id: '2505.20285'
source_url: https://arxiv.org/abs/2505.20285
generated_at: '2026-02-03T12:46:40'
quality_score: 7
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# MaskSearch: A Universal Pre-Training Framework to Enhance Agentic Search Capability

*Weiqi Wu; Xin Guan; Shen Huang; Yong Jiang; Pengjun Xie; Fei Huang; Jiuxin Cao; Hai Zhao; Jingren Zhou*

---

### üìä Quick Facts & Metrics

| Metric | Details |
| :--- | :--- |
| **Training Dataset** | 10 million Chain-of-Thought trajectories |
| **Total Tokens** | 14 billion tokens |
| **Masking Constraints** | 1 to 4 spans per sample (Curriculum) |
| **Optimization Strategy** | SFT (Multi-agent) + RL (DAPO) |
| **Core Task** | Retrieval Augmented Mask Prediction (RAMP) |
| **Quality Score** | 7/10 |
| **Citations** | 40 references |

---

> ### üìù Executive Summary
>
> Current Large Language Models (LLMs) deployed as autonomous agents lack generalized agentic search capabilities, which limits their effectiveness in complex, multi-step reasoning tasks. Existing training methodologies typically fail to instill the foundational skills necessary to leverage external search tools across diverse, unseen downstream scenarios, leaving models effective only within narrow, specific domains. This paper addresses the critical need for a universal pre-training approach that equips LLMs with robust, transferable skills for information retrieval and reasoning, ensuring they can adapt to new tasks without task-specific fine-tuning.
>
> The authors introduce **MaskSearch**, a universal pre-training framework centered on the **Retrieval Augmented Mask Prediction (RAMP)** task. This innovation requires models to reconstruct masked "salient spans"‚Äîsuch as entities or dates‚Äîby actively utilizing external search tools, thereby forcing the simultaneous learning of retrieval and reasoning. The framework employs a curriculum learning strategy that progressively scales difficulty based on the number of masked spans (from 1 to 4). Additionally, the pipeline utilizes a sophisticated two-stage training strategy: Supervised Fine-Tuning (SFT) driven by a multi-agent system and self-evolving distillation, followed by Reinforcement Learning via Dynamic Sampling Policy Optimization (DAPO) to optimize for answer accuracy and formatting compliance.
>
> The study validates the MaskSearch framework through extensive experiments in open-domain multi-hop question answering, demonstrating significant enhancements in both in-domain and out-of-domain performance. A key quantitative outcome of this research is the construction and utilization of a massive training dataset comprising **10 million Chain-of-Thought (CoT) trajectories**, totaling **14 billion tokens**, synthesized using three distinct agents. Results confirm that the curriculum learning strategy effectively enabled the model to master search tasks of varying complexity. While specific numerical benchmark metrics are detailed in the full experimental appendices, the reported findings establish that the integration of tool usage during the pre-training phase yields substantial improvements in the model's ability to generalize across unseen domains.

---

## üîë Key Findings

*   **Enhanced Performance:** The MaskSearch framework significantly boosts the performance of LLM-based search agents on both in-domain and out-of-domain downstream tasks.
*   **RAMP Effectiveness:** The Retrieval Augmented Mask Prediction (RAMP) task successfully enables models to acquire universal retrieval and reasoning capabilities by learning to utilize search tools to fill masked spans during pre-training.
*   **Training Strategy Success:** A comprehensive training strategy combining Supervised Fine-tuning (SFT) using multi-agent data generation and Reinforcement Learning (RL) using DAPO yields substantial improvements in agentic capabilities.
*   **Curriculum Learning:** Scaling complexity based on the number of masked spans effectively allows the model to progressively master search tasks.
*   **Validation:** Extensive experiments in open-domain multi-hop question answering scenarios validate the effectiveness of the approach in generalizing across different domains.

---

## ‚öôÔ∏è Technical Details

*   **Framework Name:** MaskSearch
*   **Core Mechanism:** Retrieval-Augmented Mask Prediction (RAMP).
    *   Involves predicting masked "salient spans" (entities, dates, etc.).
    *   Requires the active utilization of external search tools to reconstruct text.
*   **Training Pipeline:**
    *   **Stage 1: Supervised Fine-Tuning (SFT)**
        *   Employs a hybrid data generation strategy (agent-based + distillation-based).
        *   Utilizes a multi-agent system: Planner, Rewriter, and Observer.
        *   Features Self-Evolve Distillation using a self-evolving teacher model.
    *   **Stage 2: Reinforcement Learning (RL)**
        *   Utilizes the **DAPO** (Dynamic Sampling Policy Optimization) framework.
        *   Optimized by a hybrid reward system evaluating answer accuracy and formatting compliance.
*   **Curriculum Learning:**
    *   Implements a progressive difficulty curve.
    *   Scales complexity by varying the number of masked spans from 1 to 4.
*   **Dataset Specifications:**
    *   Source: Wikipedia
    *   Size: 10 million CoT trajectories
    *   Volume: 14 billion tokens

---

## üß¨ Methodology

The researchers introduced **MaskSearch**, centered around the **Retrieval Augmented Mask Prediction (RAMP)** task. In this task, the model is pre-trained on large-scale data to use search tools to reconstruct masked text spans. The training process follows a **curriculum learning strategy** with a progressive difficulty curve based on the number of masked spans.

The Supervised Fine-tuning (SFT) phase employs a hybrid data generation strategy combining agent-based and distillation-based methods, utilizing a multi-agent system and a self-evolving teacher model. Finally, the model is refined using Reinforcement Learning (RL) with the **DAPO** framework, optimized by a hybrid reward system evaluating answer accuracy and formatting compliance.

---

## üìÅ Contributions

The paper makes four primary contributions to the field of agentic AI:

1.  **Universal Framework:** Addresses the limitation of existing training-based methods by proposing a universal pre-training framework that improves general agentic search capabilities.
2.  **Novel Task Introduction:** Introduces the **RAMP** task as a novel mechanism for teaching LLMs to leverage external search tools during the foundational pre-training phase.
3.  **Advanced Training Methodology:** Contributes an advanced downstream training methodology that integrates:
    *   Multi-agent data generation
    *   Knowledge distillation via self-evolving teachers
    *   Hybrid-reward reinforcement learning
4.  **Generalization Proof:** Demonstrates that pre-training agents for search tool usage results in robust performance improvements across diverse, unseen downstream tasks.

---

## üìà Results

The provided text notes that specific experimental metrics are not included as the Experiments section was omitted from the source text. However, the findings can be summarized as follows:

*   **Qualitative Performance:** The framework significantly enhances performance on both in-domain and out-of-domain downstream tasks and enables universal retrieval and reasoning capabilities.
*   **Validation:** Effectiveness was validated in open-domain multi-hop question answering scenarios.
*   **Quantitative Technical Metrics:**
    *   Construction of a 10 million CoT trajectory dataset.
    *   Processing of 14 billion tokens.
    *   Utilization of 3 distinct agents for data synthesis.
    *   Implementation of masking constraints of up to 4 spans per sample.

---

**Analysis Quality Score:** 7/10 | **References:** 40 citations