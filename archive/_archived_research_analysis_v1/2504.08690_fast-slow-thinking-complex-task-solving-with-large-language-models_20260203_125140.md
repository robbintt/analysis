---
title: 'Fast-Slow-Thinking: Complex Task Solving with Large Language Models'
arxiv_id: '2504.0869'
source_url: https://arxiv.org/abs/2504.08690
generated_at: '2026-02-03T12:51:40'
quality_score: 7
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Fast-Slow-Thinking: Complex Task Solving with Large Language Models

*Yiliu Sun; Yanfang Zhang; Zicheng Zhao; Sheng Wan; Dacheng Tao; Chen Gong*

---

> ### **Quick Facts**
> *   **Quality Score:** 7/10
> *   **References:** 40 Citations
> *   **Base Model Used:** GPT-3.5-turbo
> *   **Framework:** Fast-Slow-Thinking (FST)
> *   **Key Performance Metrics:**
>     *   **Story Generation:** 86.4% constraint satisfaction (vs 38.6% CoT)
>     *   **Travel Planning:** 92.5% success rate (vs 45.0% CoT)
>     *   **Logic Inference:** 46.9% accuracy (vs 42.1% CoT)

---

## Executive Summary

### **Problem**
Large Language Models (LLMs) frequently struggle to solve complex tasks that require balancing intricate logical structures with strict, multifaceted constraints. Existing task decomposition methods, such as Chain-of-Thought (CoT) or Tree-of-Thoughts (ToT), often perform suboptimally in these scenarios because they attempt to handle logic generation and constraint enforcement simultaneously. This coupled approach frequently leads to outputs that contain logical fallacies or fail to adhere to specific requirements (e.g., word counts or stylistic rules).

### **Innovation**
To address this, the paper introduces the **Fast-Slow-Thinking (FST)** framework, a novel prompting strategy inspired by human cognitive systems (System 1 and System 2) that decouples problem-solving into a cooperative process. FST is implemented as a rigorous three-step pipeline:
1.  **Fast Thinking (FT):** "Coarse Graining" strips away complex constraints to generate a general framework.
2.  **Slow Thinking (ST):** "Fine Refinement" recalls specific constraints to refine the draft.
3.  **Output Inspection (OI):** A verification phase iteratively inspects and refines the solution.

### **Results**
The researchers validated the FST framework across three distinct task types, demonstrating statistically significant improvements over established baselines including Zero-Shot CoT, Plan-and-Solve (PS), and Tree of Thoughts (ToT).
*   **Constrained Story Generation:** FST achieved **86.4%** constraint satisfaction vs. **38.6%** for Zero-Shot CoT.
*   **Travel Planning:** FST attained a **92.5%** success rate vs. **45.0%** for Zero-Shot CoT.
*   **Logic Inference:** FST improved accuracy to **46.9%** vs. **42.1%** for the standard CoT baseline.

### **Impact**
The significance of this research lies in its empirical demonstration that mimicking human cognitive cooperation can substantially enhance LLM performance without modifying the underlying model architecture. The FST framework offers a new paradigm for task decomposition, providing practitioners with a cost-effective strategy to extract higher-fidelity outputs from standard models.

---

## Key Findings

*   **Suboptimal Existing Methods:** Current task decomposition methods struggle with complex tasks featuring intricate logic and constraints.
*   **Cognitive Mimicry:** The proposed Fast-Slow-Thinking (FST) method successfully stimulates LLMs by mimicking human cognitive cooperation (System 1 and System 2).
*   **Coarse-to-Fine Processing:** The method enables LLMs to handle complex problems through a coarse-to-fine process, separating general logic from specific constraints.
*   **Validation:** Experiments across three distinct task types validated the effectiveness of FST in improving LLM performance over baselines.

---

## Methodology

The paper proposes the **Fast-Slow-Thinking (FST)** framework, a two-step cooperative process inspired by human cognitive systems:

*   **Fast Thinking (FT):** This phase prompts the LLM to focus on general and concise aspects by actively removing task constraints. It allows the model to establish a high-level structure.
*   **Slow Thinking (ST):** This phase recalls the specific constraints and refines the initial answer generated in the FT phase to ensure strict compliance with the original task requirements.

---

## Technical Details

The FST method is a task decomposition framework designed to enhance LLM performance on complex tasks. It operates as a prompt-based pipeline using a standard LLM (e.g., GPT-3.5-turbo) guided by a three-step process:

1.  **Fast Thinking (FT) — Coarse Graining:**
    *   Simplifies the task by removing complex constraints.
    *   Goal: Generate a structural framework.
2.  **Slow Thinking (ST) — Fine Refinement:**
    *   Reintegrates the original task constraints.
    *   Goal: Refine the solution to meet specific requirements.
3.  **Output Inspection (OI) — Verification:**
    *   The model inspects the output against strict and auxiliary requirements.
    *   Iteratively refines the output if checks fail.

---

## Contributions

*   **Novel Framework:** Introduction of the FST method, a new decomposition framework specifically for complex logical constraints.
*   **Cognitive Strategy:** Development of a cognitive-inspired prompting strategy that decouples problem-solving into general and detailed steps.
*   **Quality Enhancement:** Improvement of solution quality by separating constraint removal from enforcement to mitigate redundancy and errors.
*   **Empirical Evidence:** Provision of empirical evidence showing that human-like coarse-to-fine processing enhances LLM capabilities.

---

## Results

The paper claims experiments were conducted across three distinct task types, asserting that FST successfully improves LLM performance on complex tasks compared to existing decomposition methods.

*   **Qualitative Findings:** FST outperforms baselines like Zero-Shot-CoT in constrained story generation by avoiding illogical content and limited word usage. This is achieved by separating logic generation from constraint satisfaction.
*   **Baselines Compared:** The method was compared against:
    *   Zero-Shot Chain-of-Thought
    *   Plan-and-Solve (PS)
    *   Tree of Thoughts (ToT)
    *   Graph-of-Thoughts (GoT)
    *   Branch-Solve-Merge (BSM)

---

**References:** 40 citations