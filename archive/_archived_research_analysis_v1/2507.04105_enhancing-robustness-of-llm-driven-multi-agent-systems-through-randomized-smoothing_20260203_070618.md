---
title: Enhancing Robustness of LLM-Driven Multi-Agent Systems through Randomized Smoothing
arxiv_id: '2507.04105'
source_url: https://arxiv.org/abs/2507.04105
generated_at: '2026-02-03T07:06:18'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Enhancing Robustness of LLM-Driven Multi-Agent Systems through Randomized Smoothing

*Jinwei Hu; Yi Dong; Zhengtao Ding; Xiaowei Huang*

***

> ### ðŸ“Š Quick Facts
> *   **Quality Score:** 8/10
> *   **References:** 40 Citations
> *   **Deviation Reduction:** 90.24%
> *   **Application Domain:** Aerospace / UAVs
> *   **Core Technique:** Randomized Smoothing
> *   **Mechanism:** Two-stage Adaptive Sampling

***

## Executive Summary

This research addresses the critical vulnerability of Large Language Model (LLM)-driven Multi-Agent Systems (MAS) to adversarial attacks and hallucinations. In safety-critical domains, such as aerospace or autonomous navigation, the propagation of malicious inputs or erroneous reasoning from a single agent can compromise the consensus and cooperative integrity of the entire network. Because LLMs often function as black boxes, ensuring reliable decision-making under adversarial influence is a significant challenge. Without robust certification mechanisms, these systems are prone to persistent oscillations and deviation from their objectives, making their deployment in high-stakes environments risky.

The authors introduce a defense framework that adapts randomized smoothingâ€”a statistical technique traditionally used for classification robustnessâ€”to the domain of MAS consensus. This approach provides probabilistic certification for agent decisions in black-box settings, mathematically bounding the impact of perturbations to guarantee system stability. To address the high computational costs typically associated with randomized smoothing, the team developed a two-stage adaptive sampling mechanism. This mechanism balances the need for robustness certification with computational efficiency by smoothing state trajectories, thereby preventing the propagation of malicious inputs and forcing the group's average state to approximate the ideal baseline.

In a 3D aerospace simulation utilizing LLM-driven UAVs, the framework demonstrated significant efficacy in maintaining system stability under adversarial conditions. When compared to a vulnerable system that exhibited an average deviation of 0.1251 to 0.1323 units with persistent oscillations, the defended system achieved a deviation of only 0.0129 units. This represents a **90.24% average reduction in deviation**. Furthermore, the simulations confirmed that the defense layer successfully maintained safe separation and effective coordination among agents, validating the framework's ability to preserve consensus performance without compromising the system's primary operational goals.

This work establishes a vital pathway for the trustworthy deployment of LLM-based multi-agent systems in real-world, safety-critical applications. By providing probabilistic guarantees regarding agent decisions, the research moves beyond empirical defense to offer certifiable robustness. The successful adaptation of randomized smoothing to MAS consensus, combined with the scalable two-stage sampling mechanism, resolves a key computational bottleneck. Consequently, this study significantly influences the field by offering a rigorous, practical solution to the problem of adversarial susceptibility in autonomous swarms and cooperative AI systems.

***

## Key Findings

*   **Propagation Prevention:** The framework successfully prevents the propagation of adversarial behaviors and hallucinations throughout the multi-agent network.
*   **Consensus Integrity:** The method maintains consensus performance without compromising the system's primary objective.
*   **Probabilistic Guarantees:** Randomized smoothing enables probabilistic guarantees regarding agent decisions under adversarial influence.
*   **Safety-Critical Efficacy:** Simulation results confirm the framework's efficacy in safety-critical scenarios, specifically in aerospace applications.

***

## Methodology

The research employs a statistical robustness certification technique adapted specifically for Multi-Agent System (MAS) consensus in black-box settings.

*   **Core Technique:** Utilization of **Randomized Smoothing** to defend against adversarial inputs.
*   **Optimization:** A **two-stage adaptive sampling mechanism** is employed to balance robustness certification with computational efficiency.

***

## Technical Details

*   **Framework:** Utilizes Randomized Smoothing to defend against adversarial behaviors and hallucinations in LLM-driven MAS.
*   **Certification:** Relies on probabilistic certification to bound the impact of perturbations, providing guarantees regarding agent decisions.
*   **Primary Goal:** Maintain consensus performance and cooperative decision-making integrity.
*   **Defense Mechanism:** The defense layer smooths state trajectories to prevent propagation of malicious inputs and forces the group's average state to approximate the ideal baseline.
*   **Validation Environment:** Validated in a 3D aerospace context with LLM-driven UAVs.

***

## Results

The evaluation compared three scenarios: "Ideal Baseline", "Vulnerable System", and "Defended System". The primary metric used was "Average Deviation".

| Scenario | Deviation (Units) | Observations |
| :--- | :--- | :--- |
| **Vulnerable System** | 0.1251 / 0.1323 | Persistent oscillations observed. |
| **Defended System** | 0.0129 | Stabilized trajectories. |
| **Improvement** | **90.24% Reduction** | Significant decrease in deviation. |

*   **3D Simulation:** UAV simulations confirmed effective coordination under adversarial conditions while maintaining safe separation.

***

## Contributions

*   **Specialized Framework:** Introduction of a specialized defense framework for LLM-empowered MAS in safety-critical domains.
*   **Technique Adaptation:** Adaptation of randomized smoothing to MAS consensus for robustness certification.
*   **Computational Efficiency:** Development of a two-stage adaptive sampling mechanism to address computational challenges.
*   **Scalability:** Establishment of a practical and scalable pathway for real-world deployment of LLM-based multi-agent systems.