---
title: 'R2BC: Multi-Agent Imitation Learning from Single-Agent Demonstrations'
arxiv_id: '2510.18085'
source_url: https://arxiv.org/abs/2510.18085
generated_at: '2026-02-03T06:31:52'
quality_score: 8
citation_count: 38
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# R2BC: Multi-Agent Imitation Learning from Single-Agent Demonstrations

*Connor Mattson; Varun Raveendra; Ellen Novoseller; Nicholas Waytowich; Vernon J. Lawhern; Daniel S. Brown*

---

### Quick Facts

| Metric | Details |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **References** | 38 Citations |
| **Environment** | VMAS (Simulation) & Physical Hardware |
| **Validation Tasks** | Navigation, Balance, Buzz Wire, Transport |
| **Training Paradigm** | Sequential Single-Agent (Round-Robin) |

---

## Executive Summary

### Problem
This paper addresses the critical data acquisition bottleneck in Multi-Agent Imitation Learning (MAIL). Traditional MAIL methods require demonstrations in the joint action space, necessitating a team of human operators to control every agent simultaneously during data collection. As the number of agents scales, gathering synchronized, high-quality multi-agent demonstrations becomes logistically infeasible and computationally prohibitive due to the exponential growth of the joint action space. This limitation prevents the practical application of imitation learning to complex, real-world multi-robot systems where a single human expert is typically the only available source of supervision.

### Innovation
The authors introduce **Round-Robin Behavior Cloning (R2BC)**, a novel framework that enables the training of decentralized multi-agent policies using data from a single human operator. R2BC employs an iterative, sequential learning process where the operator teleoperates one agent at a time while the remaining agents execute their currently learned autonomous policies. This approach creates a curriculum where agents learn to act alongside non-stationary teammates, effectively bypassing the need for joint-state demonstrations. By treating the training as a sequence of single-agent interactions, R2BC incrementally accumulates team-level behavior without requiring complex, synchronized multi-agent datasets.

### Results
In empirical evaluations across four simulated tasks in the VMAS environment (Navigation, Balance, Buzz Wire, and Transport), R2BC consistently outperformed privileged baselines. When compared to Joint Behavior Cloning (JBC)—an "oracle" method with access to ground-truth joint actions—R2BC achieved superior normalized scores:

| Task | R2BC Score | Oracle (JBC) Score |
| :--- | :---: | :---: |
| **Transport** | 0.92 | 0.82 |
| **Buzz Wire** | 0.85 | 0.75 |

The algorithm demonstrated strong sample efficiency, approaching optimal performance with approximately 400 demonstrations. Furthermore, the method was successfully validated on two distinct physical robot platforms, confirming robust sim-to-real transfer capabilities.

### Impact
The significance of R2BC lies in its elimination of the "multi-teacher" requirement that has traditionally constrained the deployment of multi-agent systems. By empirically proving that sequential single-agent demonstrations can compete with or exceed synchronized joint-action data, this work establishes a more accessible and scalable paradigm for training multi-robot teams. This shift allows researchers and practitioners to leverage the expertise of a single operator to train complex cooperative systems, significantly lowering the barrier to entry for real-world applications by removing the logistical bottlenecks associated with multi-agent data collection.

---

## Key Findings

*   **Single-Operator Training:** The Round-Robin Behavior Cloning (R2BC) method enables a single human operator to effectively train an entire multi-robot system.
*   **Joint Space Independence:** The approach successfully learns multi-agent behaviors without requiring demonstrations in the complex joint multi-agent action space.
*   **Benchmark Performance:** In four simulated multi-agent tasks, R2BC matched or surpassed the performance of an 'oracle' behavior cloning approach.
*   **Real-World Validation:** The method was successfully deployed and validated on two physical robot tasks using real human demonstrations.

---

## Methodology

The researchers propose **Round-Robin Behavior Cloning (R2BC)**, a framework designed to facilitate multi-agent imitation learning from a single human source. The methodology operates as follows:

1.  **Sequential Demonstrations:** A human operator teleoperates one agent at a time within the system.
2.  **Incremental Learning:** The system incrementally learns multi-agent behavior across the team.
3.  **Bypassing Complexity:** This approach bypasses the technical difficulty of providing simultaneous demonstrations for all agents.
4.  **Round-Robin Accumulation:** It relies on a round-robin style accumulation of single-agent data to build comprehensive team behaviors.

---

## Technical Details

**Architecture**
*   **Name:** Round-Robin Behavior Cloning (R2BC)
*   **Goal:** Train multi-agent systems using only single-agent demonstrations.

**Operational Mechanics**
*   **Decentralized Demonstrations:** A single operator demonstrates behavior for one agent at a time while others execute autonomous policies.
*   **Curriculum Creation:** The online iterative learning process creates a curriculum for agents to act alongside non-stationary teammates.
*   **Core Pillars:** The method relies on **Decentralization** and **Online Policy Learning** to produce fully decentralized policies suitable for real-world deployment.

---

## Contributions

*   **Novel Algorithm:** Introduction of the novel R2BC algorithm that solves the bottleneck of applying Imitation Learning to multi-agent systems where only a single human teacher is available.
*   **Paradigm Shift:** A shift away from requiring complex, synchronized multi-agent datasets toward a more practical, sequential training paradigm.
*   **Empirical Evidence:** Establishment of empirical evidence showing that methods relying on sequential single-agent data can compete with or exceed methods trained on idealized, synchronized data.
*   **Hardware Validation:** Validation of the approach in physical hardware, demonstrating sim-to-real transfer robustness.

---

## Results Overview

Experiments were conducted in the **VMAS environment** on Navigation, Balance, Buzz Wire, and Transport tasks, using a normalized performance score (0.0 to 1.0) averaged over 10 seeds.

*   **Benchmarking:** R2BC outperformed or achieved parity with privileged oracle baselines (JBC, DAgger, DART) across all tasks.
*   **Efficiency:** The method demonstrated sample efficiency, approaching optimal performance with up to 400 demonstrations.
*   **Analysis:** Showed downward trends in loss gap analysis.
*   **Physical Deployment:** R2BC was successfully validated on two physical robot tasks.