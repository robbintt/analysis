# StableMTL: Repurposing Latent Diffusion Models for Multi-Task Learning from Partially Annotated Synthetic Datasets

***Authors: Anh-Quan Cao; Ivan Lopes; Raoul de Charette***

---

> ### ðŸ“Š Quick Facts
>
> *   **Tasks Evaluated:** 7 Dense Prediction Tasks
> *   **Benchmarks:** 8 Real-world Datasets
> *   **Training Data:** ~79k Samples (3 Synthetic Datasets)
> *   **Methodology:** Latent Regression / Single-step Diffusion
> *   **Quality Score:** 8/10
> *   **Citations:** 40

---

## Executive Summary

Multi-task learning (MTL) in computer vision faces significant hurdles regarding data efficiency and computational complexity. Training models to perform simultaneous dense prediction tasks typically requires large, fully annotated datasets, which are expensive and labor-intensive to curate. Furthermore, standard MTL approaches suffer from the "gradients conflict" problem, necessitating manual and often suboptimal tuning of loss weights to balance different tasks. The challenge is further compounded when attempting to scale to a large number of tasks, where the computational cost of managing inter-task interactions increases non-linearly, and when leveraging partially annotated synthetic data, which often leads to poor generalization in real-world zero-shot scenarios.

The authors propose **StableMTL**, a novel framework that repurposes pre-trained Latent Diffusion Models (LDMs)â€”specifically Stable Diffusionâ€”for regression tasks rather than generative image synthesis. By operating in the latent space of a pre-trained VAE, the method frames dense prediction as a deterministic single-step diffusion process, mapping both input images and annotations into this shared latent representation. The architecture utilizes a unified latent loss function for optimization, effectively removing the need for manual per-task loss balancing. To handle scaling, StableMTL implements a multi-stream architecture featuring an N-to-1 Task Attention mechanism; this converts complex N-to-N task interactions into a streamlined 1-to-N relationship where a trainable "main" stream attends to features from frozen auxiliary streams, thereby decoupling gradients and reducing computational complexity.

StableMTL was evaluated on 7 dense prediction tasks using training data derived from 3 partially annotated synthetic datasets (~79k samples) and tested zero-shot on 8 real-world benchmarks. The model demonstrated superior performance across standard metrics, including mIoU, AbsRel, mAE, EPE-2D/3D, and RMSE. In direct comparisons with existing baselines like DiffusionMTL and JTR, StableMTL outperformed both, particularly highlighting weaknesses in competing methods when handling multi-dataset setups. Notably, while the JTR* baseline suffered severe performance degradation with a delta of -106.87% in mixed-dataset conditions, StableMTL maintained robust results, confirming its stability and effectiveness in complex training environments.

This research significantly shifts the paradigm for using diffusion models, establishing them as powerful tools for discriminative regression and multi-task learning beyond simple image generation. By enabling high-performance zero-shot transfer from synthetic to real-world data, StableMTL offers a viable solution to the data annotation bottleneck, drastically reducing the cost of developing sophisticated vision systems. The elimination of manual loss balancing and the introduction of an efficient attention mechanism for task scaling provide a blueprint for future MTL architectures.

---

## Key Findings

*   **Superior Performance:** StableMTL outperforms existing baselines across **7 tasks** and **8 benchmarks**.
*   **Automated Balancing:** Eliminates the need for manual per-task loss balancing through a unified latent loss function.
*   **Zero-Shot Scalability:** Enables effective zero-shot scaling from partially annotated synthetic datasets to real-world data.
*   **Cross-Task Synergy:** Enhances interaction between tasks using specialized attention mechanisms.

---

## Methodology

The paper proposes **StableMTL**, a framework designed to repurpose Latent Diffusion Models (LDMs) for latent regression in dense prediction tasks.

*   **Framework Adaptation:** The method adapts the standard denoising framework by integrating **task encoding** and **per-task conditioning**.
*   **Optimization:** It utilizes a unified latent loss to optimize the model, simplifying the training process.
*   **Architecture:** Implements a multi-stream model featuring a **task-attention mechanism**.
*   **Interaction Scaling:** Converts complex N-to-N interactions into a streamlined 1-to-N attention structure to facilitate better scaling.

---

## Technical Details

**Reframing MTL as Latent Regression**
StableMTL reframes multi-task learning as a latent regression problem within the latent space ($Z$) of a pre-trained Stable Diffusion VAE. It employs a deterministic single-step diffusion approach rather than iterative denoising.

**Data Processing**
*   **Input Images:** Encoded directly into latents.
*   **Annotations:** Mapped to RGB-compatible formats before being encoded into the latent space.

**Training Strategy**

*   **Stage 1:**
    *   Fine-tunes a UNet using a unified MSE latent loss.
    *   Implements task-specific token embeddings.
    *   Utilizes gradient decoupling to manage competing objectives.

*   **Stage 2:**
    *   Introduces a trainable "main" UNet while keeping auxiliary streams frozen.
    *   Utilizes an **N-to-1 Task Attention mechanism**, where the main stream attends to features extracted by the auxiliary streams.

---

## Contributions

1.  **Annotation Efficiency:** Drastically improves annotation efficiency by successfully utilizing partially annotated synthetic datasets.
2.  **Novel Application:** Introduces the novel repurposing of diffusion modelsâ€”typically used for generationâ€”for regression tasks in multi-task learning.
3.  **Computational Optimization:** Solves computational complexity problems by converting N-to-N task interactions to 1-to-N attention, facilitating better scaling to larger numbers of tasks.

---

## Results

**Experimental Setup**
*   **Tasks:** 7 dense prediction tasks.
*   **Training Data:** 3 synthetic datasets (~79k samples).
*   **Testing Data:** Zero-shot evaluation on 8 real-world benchmarks.
*   **Metrics:** mIoU, AbsRel, mAE, EPE-2D/3D, RMSE, and $\delta$.

**Performance Overview**
*   **Baseline Comparison:** StableMTL outperformed baselines like DiffusionMTL and JTR.
*   **Robustness:** Competing methods suffered significant degradation in multi-dataset setups (e.g., JTR* showed a $\delta$ of **-106.87%**).
*   **Outcome:** StableMTL demonstrated superior performance across all tasks, effective zero-shot scaling capabilities, and successful elimination of manual loss balancing.

---

**Paper Quality Score:** 8/10 | **References:** 40 citations