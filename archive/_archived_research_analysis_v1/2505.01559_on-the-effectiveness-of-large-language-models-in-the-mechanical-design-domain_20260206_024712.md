---
title: On the effectiveness of Large Language Models in the mechanical design domain
arxiv_id: '2505.01559'
source_url: https://arxiv.org/abs/2505.01559
generated_at: '2026-02-06T02:47:12'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# On the effectiveness of Large Language Models in the mechanical design domain

*Daniele Grandi; Fabian Riquelme*

***

> ### ðŸ“Š Quick Facts
> *   **Quality Score:** 8/10
> *   **References:** 40 citations
> *   **Dataset:** ABC Dataset (~61k cleaned assemblies)
> *   **Top Metrics:**
>     *   Binary Classification Accuracy: **0.62**
>     *   Zero-Shot Top-1 Accuracy: **0.386**
> *   **Core Focus:** LLM application in mechanical engineering semantic data.

***

## Executive Summary

This research addresses the critical gap in understanding how Large Language Models (LLMs) perform when applied to the specialized, data-scarce domain of mechanical engineering. While LLMs have demonstrated proficiency in general language tasks, their ability to interpret semantic data specific to mechanical designâ€”such as the relationship between assembly and part names derived from CAD modelsâ€”remains largely unverified. Quantifying this capability is essential for integrating AI into engineering workflows, as it determines whether these models can reliably process the technical vocabulary and structural relationships inherent in mechanical design.

The studyâ€™s primary innovation is the development and validation of unsupervised evaluation tasks specifically tailored to semantic mechanical data. The authors constructed a binary sentence-pair classification task to predict part-assembly relationships and a zero-shot classification task to test generalization on unseen data. Technically, the architecture utilizes a pre-trained BERT transformer augmented with a multi-head attention layer and a Dense layer. To address the persistent challenge of over-fitting and catastrophic forgetting when training on smaller, domain-specific datasets, the researchers implemented rigorous regularization techniques, systematically optimizing hyperparameters including learning rates, dropout values, and sequence lengths.

The implementation of these regularization strategies yielded measurable improvements in model performance on the ABC dataset (comprising ~61,000 cleaned assemblies). The fine-tuned model achieved an accuracy of 0.62 on the binary sentence-pair classification task, effectively learning part-assembly relations. In the zero-shot classification task, the modelâ€”utilizing a contrastively pre-trained text encoderâ€”achieved a top-1 accuracy of 0.386, a result that outperformed established baselines. While these scores demonstrate distinct capabilities in processing semantic design data, the analysis also revealed specific failure modes that LLMs encounter when learning the nuances of mechanical engineering language.

This paper provides a structured framework for evaluating LLM efficacy within mechanical design, shifting the focus from anecdotal usage to quantitative benchmarking. By demonstrating effective regularization techniques for fine-tuning on technical datasets, the authors offer a blueprint for mitigating over-fitting in domain-specific AI applications. These findings are significant for the field as they delineate the current boundaries of NLP in engineering, highlighting both the potential for automated design assistance and the specific limitations that future research must address to achieve robust semantic understanding in mechanical contexts.

***

## Key Findings

*   **Fine-Tuning Success:** Fine-tuned models achieved an accuracy of **0.62** on binary sentence-pair classification. This was accomplished by implementing specific strategies to combat over-fitting, such as adjusting learning rates, dropout values, sequence length, and adding a multi-head attention layer.
*   **Zero-Shot Superiority:** The model demonstrated superior performance in the zero-shot classification task with a top-1 classification accuracy of **0.386**, effectively outperforming established baselines.
*   **Failure Modes Identified:** The study identified specific failure modes that occur when large language models attempt to learn from language within the mechanical engineering domain.
*   **Semantic Capabilities:** Large language models show measurable but distinct performance capabilities when processing semantic data (assembly and part names) in a mechanical design context.

## Methodology

The study utilized semantic data from the **ABC dataset**, specifically designer-assigned assembly names and individual semantic names for parts. The data underwent a rigorous pre-processing phase. Two primary unsupervised tasks were developed for evaluation:

1.  **Binary Sentence-Pair Classification:** To predict part-assembly relations.
2.  **Zero-Shot Classification:** To test generalization on unseen data.

To mitigate over-fitting in the fine-tuned model, the researchers optimized the architecture by modifying hyperparameters. This included adjusting learning rates, dropout values, and sequence length, as well as architectural changes like adding a multi-head attention layer.

## Technical Details

*   **Dataset Utilization**
    *   **Source:** ABC Dataset
    *   **Volume:** ~1 million CAD models, ~90,000 assemblies
    *   **Pre-processing:** Cleaned via deduplication and regex
    *   **Final Count:** 61,725 assemblies

*   **Task 1: Binary Sentence-Pair Classification**
    *   **Objective:** Predicting part-assembly relation
    *   **Input Format:** `An assembly named '[Name]', containing...`
    *   **Architecture:** Pre-trained BERT Transformer augmented with a multi-head attention layer and Dense layer.
    *   **Regularization:** Fine-tuning addressed catastrophic forgetting by tuning learning rates (1e-2 to 1e-4), dropout, and sequence length.

*   **Task 2: Zero-Shot Classification**
    *   **Mechanism:** A contrastively pre-trained text encoder creates embeddings for unseen part and assembly names.

## Results

*   **Binary Sentence-Pair Classification:** Achieved an accuracy of **0.62**.
*   **Zero-Shot Classification:** Achieved a Top-1 accuracy of **0.386**, outperforming established baselines.
*   **General Findings:** While LLMs face distinct failure modes with mechanical engineering language, they show measurable capabilities in processing semantic design data.

## Contributions

*   **Structured Evaluation:** Provided a structured evaluation of Large Language Model (LLM) performance specifically within the mechanical engineering and mechanical design domains.
*   **Task Development:** Developed and validated unsupervised evaluation tasks (binary sentence-pair and zero-shot classification) tailored to semantic mechanical data.
*   **Regularization Techniques:** Demonstrated effective regularization techniques (learning rate, dropout, sequence length, multi-head attention) for fine-tuning LLMs on technical datasets to prevent over-fitting.
*   **Understanding Limitations:** Contributed to the understanding of LLM limitations by shedding light on specific failure modes that arise when learning domain-specific mechanical language.