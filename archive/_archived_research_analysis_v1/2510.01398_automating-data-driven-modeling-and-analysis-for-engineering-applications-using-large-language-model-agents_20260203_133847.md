---
title: Automating Data-Driven Modeling and Analysis for Engineering Applications using
  Large Language Model Agents
arxiv_id: '2510.01398'
source_url: https://arxiv.org/abs/2510.01398
generated_at: '2026-02-03T13:38:47'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents

*Yang Liu; Zaid Abulawi; Abhiram Garimidi; Doyeong Lim*

---

> ### ðŸ“Š Quick Facts
> *   **Dataset:** OECD/NEA (~25,000 experimental data points)
> *   **Application:** Critical Heat Flux (CHF) Prediction
> *   **Top Performer:** Multi-agent System (RMSE: 0.29 MW/mÂ²)
> *   **Key Milestone:** Matched performance of expert-tuned Bayesian Neural Networks
> *   **Citations:** 40 references
> *   **Quality Score:** 8/10

---

## Executive Summary

**Problem**
Engineering data-driven modeling faces a critical scalability bottleneck due to its reliance on manual, expert-driven processes for data preprocessing, architecture selection, and hyperparameter tuning. While traditional methods like Critical Heat Flux (CHF) lookup tables are widely used, they frequently lack the predictive accuracy of modern machine learning techniques. However, developing high-performance deep neural networks requires specialized expertise in optimization and uncertainty quantification (UQ), creating a high barrier to entry that limits the adoption of advanced data-driven methods in complex engineering applications.

**Innovation**
The authors introduce an automated pipeline powered by Large Language Model (LLM) agents designed to execute the end-to-end machine learning workflow autonomously, minimizing the need for human intervention. The study evaluates and compares two distinct technical architectures: a **Multi-agent system** utilizing specialized collaborative agents and a **Single-agent system** based on the Reasoning and Acting (ReAct) paradigm. These agents manage the full modeling lifecycleâ€”including data preprocessing, neural network architecture generation, training, hyperparameter optimization, and the integration of UQâ€”effectively replicating the decision-making process of human data scientists.

**Results**
The proposed framework was rigorously validated on a large-scale benchmark comprising approximately 25,000 experimental data points from the OECD/NEA dataset for CHF prediction. The Multi-agent system achieved a Root Mean Square Error (RMSE) of **0.29 MW/mÂ²** and an RÂ² score of **0.93**, directly matching the performance of state-of-the-art Bayesian optimized deep neural networks developed by human experts (RMSE: 0.29 MW/mÂ², RÂ²: 0.93). The Single-agent system yielded slightly lower performance with an RMSE of 0.34 MW/mÂ² and an RÂ² of 0.91. Both LLM-generated models significantly surpassed the traditional CHF lookup table baseline, which recorded an RMSE of 0.58 MW/mÂ² and an RÂ² of 0.65.

**Impact**
This research marks a pivotal advancement in the automation of scientific computing, offering empirical evidence that LLM-based agents can replace manual workflows in high-stakes engineering environments. By demonstrating that the Multi-agent architecture can match expert-level performance in rigorous regression tasks while outperforming single-agent alternatives, the study addresses the generalization and scalability limitations of traditional data-driven methods. The successful integration of advanced modeling componentsâ€”such as hyperparameter optimization and UQâ€”into a self-directed workflow establishes a new blueprint for applying autonomous agents to complex engineering challenges, potentially democratizing access to state-of-the-art modeling capabilities.

---

## Key Findings

*   **Full Autonomy Achieved:** The proposed LLM-agent frameworks successfully autonomized the complete data-driven modeling pipeline, including data preprocessing, neural network development, training, hyperparameter optimization, and uncertainty quantification (UQ).
*   **Superior to Traditional Methods:** The models generated by the LLM agents surpassed the performance of traditional Critical Heat Flux (CHF) lookup tables.
*   **Parity with Human Experts:** The automated approach delivered predictive accuracy and UQ capabilities on par with state-of-the-art Bayesian optimized deep neural networks developed by human experts.
*   **Rigorous Validation:** The system was validated effectively on a large-scale benchmark comprising approximately 25,000 experimental data points from the OECD/NEA dataset.

---

## Methodology

The researchers developed an automated pipeline utilizing Large Language Model (LLM) agents to address regression tasks in engineering, specifically focusing on minimizing manual intervention.

*   **Framework Comparison:** The study evaluated and compared two distinct LLM-agent frameworks:
    1.  **Multi-agent System:** Utilizes specialized agents that collaborate.
    2.  **Single-agent System:** Based on the Reasoning and Acting (ReAct) paradigm.
*   **Workflow Scope:** Both frameworks were designed to handle the end-to-end machine learning workflow autonomously.
*   **Validation Benchmark:** The methodology was validated using a Critical Heat Flux (CHF) prediction benchmark, relying on approximately 25,000 experimental data points from the OECD/NEA dataset.

---

## Technical Details

The system utilizes autonomous LLM-agent frameworks to automate the end-to-end machine learning pipeline without human intervention.

### Pipeline Components
*   **Data Preprocessing:** Automated cleaning and preparation of raw data.
*   **Neural Network Development:** Automatic architecture selection and generation.
*   **Training:** Self-directed model training procedures.
*   **Hyperparameter Optimization:** Automated tuning of model parameters.
*   **Uncertainty Quantification (UQ):** Integration of probabilistic modeling to estimate prediction confidence.

### Capabilities
The agents are designed to generate models comparable to sophisticated human-developed baselines like Bayesian optimized deep neural networks, employing complex optimization strategies and probabilistic modeling.

---

## Results

The system was validated on a Critical Heat Flux (CHF) prediction benchmark using the OECD/NEA dataset (approximately 25,000 data points).

### Performance Comparison

| Model Type | RMSE (MW/mÂ²) | RÂ² Score | Notes |
| :--- | :---: | :---: | :--- |
| **Multi-agent System** | **0.29** | **0.93** | Matches expert-level performance |
| **Bayesian DNN (Human)** | **0.29** | **0.93** | State-of-the-art baseline |
| **Single-agent System** | 0.34 | 0.91 | Slightly lower performance |
| **Traditional Lookup Table** | 0.58 | 0.65 | Significant performance gap |

**Outcome:**
The LLM-generated models surpassed traditional CHF lookup tables and achieved predictive accuracy and uncertainty quantification capabilities on par with state-of-the-art Bayesian optimized deep neural networks developed by human experts.

---

## Contributions

*   **Advancement in Automation:** The study presents a significant advancement in automating complex engineering modeling tasks, offering a solution to the scalability and generalization limitations of traditional, manual data-driven methods.
*   **Empirical Evidence:** It provides empirical evidence that LLM-based agents can replace traditional lookup tables and match the performance of expert-tuned state-of-the-art models on a rigorous scientific benchmark.
*   **Architectural Evaluation:** It contributes a technical evaluation of two different architectural approaches (multi-agent vs. single-agent ReAct) for executing scientific modeling tasks.
*   **Integration of Advanced Components:** The work demonstrates the successful integration of advanced modeling componentsâ€”specifically hyperparameter optimization and uncertainty quantificationâ€”into an automated agent-based workflow.

---

*Report generated based on analysis of provided research paper.*