# Black-box Adversarial Attacks on CNN-based SLAM Algorithms

*Maria Rafaela Gkeka; Bowen Sun; Evgenia Smirni; Christos D. Antonopoulos; Spyros Lalis; Nikolaos Bellas*

---

### üìä Quick Facts

| Metric | Value | Details |
| :--- | :--- | :--- |
| **Max RGB Tracking Failure** | 76% | Frames failed under attack |
| **Depth Pose Success Rate** | 0% | Single-frame estimation |
| **ATE Increase (RGB)** | +30% | At $\epsilon=0.005$ (low perturbation) |
| **Transferability (DXSLAM)** | Up to 100% | Failure rate on specific sequences |
| **Dataset** | TUM | Monocular visual data |
| **Target Algorithms** | GCN-SLAM, DXSLAM (ORB-SLAM2 back-end) |

---

## üìÑ Executive Summary

> **Abstract Analysis**
>
> As CNN-based Simultaneous Localization and Mapping (SLAM) algorithms become integral to the operation of autonomous agents, their security against adversarial interference remains a critical concern. This paper addresses the vulnerability of CNN-based feature detectors within SLAM systems to black-box adversarial attacks. This matters because a failure in tracking or mapping can lead to catastrophic navigation errors in safety-critical environments.
>
> Unlike white-box attacks that require full knowledge of the target model, this study focuses on realistic threat scenarios where an attacker only has access to the system's inputs and outputs. The study introduces an **architecture-agnostic, black-box attack methodology** capable of generating transferable adversarial perturbations for both RGB and Depth modalities. To overcome the lack of access to the target model's gradients, the approach employs substitute networks‚Äîsuch as MobileNetV2, DenseNet, and InceptionResNetV2‚Äîto approximate gradients and generate perturbations.
>
> A core technical innovation is the use of a **targeted attack strategy with randomized labels**; by assigning distinct target labels to each input frame, the method introduces diverse noise patterns that effectively degrade feature detection. The attack specifically exploits vulnerabilities in the SLAM back-end (e.g., ORB-SLAM2) by disrupting the matching process between current frames and previously established 3D map points.
>
> Empirical validation on the TUM dataset using GCN-SLAM reveals high susceptibility to these attacks. Black-box perturbations on RGB inputs caused tracking failure in up to **76% of frames**. Compared to untargeted attacks, targeted RGB attacks increased Absolute Trajectory Error (ATE) by **30%** even at low perturbation magnitudes ($\epsilon=0.005$). Attacks on depth inputs were even more severe, resulting in a **0% success rate** for single-frame pose estimation.
>
> This research bridges a significant gap in the literature by providing the first comprehensive comparative assessment of black-box adversarial vulnerabilities across RGB and Depth input modalities in SLAM. The findings underscore a severe security challenge: standard SLAM back-ends are highly sensitive to subtle input perturbations, posing substantial risks for the deployment of autonomous agents in untrusted environments.

---

## üîë Key Findings

*   **High Impact on RGB:** Black-box adversarial perturbations on RGB inputs can cause tracking failure in up to **76% of frames**.
*   **Catastrophic Depth Failure:** Targeting depth inputs results in a **0% success rate** for single-frame pose estimation, indicating catastrophic system impact.
*   **Empirical Validation:** Vulnerabilities were rigorously validated using the **GCN-SLAM** algorithm on the **TUM dataset**.
*   **Targeted Superiority:** Targeted attacks on RGB inputs are significantly more effective than untargeted ones, increasing Absolute Trajectory Error (ATE) by 30% even at minimal perturbation levels.

---

## üî¨ Research Methodology

The study followed a rigorous empirical approach to evaluate the robustness of SLAM systems against adversarial interference:

**1. Target Selection**
*   Primary Algorithm: **GCN-SLAM**.
*   Back-end Focus: ORB-SLAM2 architecture logic.

**2. Attack Implementation**
*   **Modality:** Implemented black-box adversarial perturbations on both **RGB** and **Depth** input images.
*   **Strategy:** Utilized a targeted approach with randomized labels to create diverse noise patterns.

**3. Evaluation Protocol**
*   **Dataset:** TUM RGB-D dataset.
*   **Metric:** Robustness evaluated by measuring **tracking failure rates** and Absolute Trajectory Error (ATE).
*   **Transferability:** Tested perturbations generated on substitute networks against the **DXSLAM** system.

---

## ‚öôÔ∏è Technical Details

### Attack Strategy
*   **Randomized Labels:** The approach uses a targeted strategy where distinct target labels are selected for each input frame. This introduces diverse noise, enhancing effectiveness against feature detectors.

### Exploit Mechanism
*   **Matching Disruption:** The method exploits the vulnerability of the SLAM back-end (specifically the matching process in systems like ORB-SLAM2).
*   **Depth Vulnerability:** By disrupting the matching process between current frames and previous 3D points, the attack severs the link necessary for accurate localization.

### Architecture and Transferability
*   **Architecture-Agnostic:** The method is not dependent on the specific internal architecture of the target SLAM system.
*   **Substitute Networks:** To generate gradients without access to the target model, the system employs substitute networks including:
    *   MobileNetV2
    *   DenseNet
    *   InceptionResNetV2

---

## üìà Results

### Absolute Trajectory Error (ATE)
*   **RGB Attacks:** Targeted attacks increased ATE by **30%** at a low perturbation magnitude of $\epsilon=0.005$ compared to untargeted attacks.
*   **Depth Attacks:** Resulted in a complete system failure with a **0% success rate** in single-frame pose estimation.

### Transferability Tests (DXSLAM)
The following table illustrates the severe degradation of performance when adversarial perturbations were transferred to the DXSLAM algorithm:

| Sequence | Baseline Failure Rate | Final Failure Rate | Perturbation ($\epsilon$) |
| :--- | :---: | :---: | :---: |
| **fr1_360** | 9.3% | 98.7% | 0.30 |
| **fr1_floor** | 12.8% | 100.0% | 0.30 |
| **fr1_desk** | 65.8% | 97.2% | 0.10 |
| **fr1_room** | 51.7% | 97.0% | 0.10 |

---

## üöÄ Contributions

*   **Bridged Research Gap:** Provided the first comprehensive examination of adversarial attacks specifically on **CNN-based feature detectors** within SLAM systems.
*   **Security Awareness:** Highlighted critical security challenges and reliability risks facing autonomous agents operating in untrusted environments.
*   **Comparative Assessment:** Delivered a detailed comparative analysis of vulnerabilities between **RGB and Depth** input modalities.

---

**Document Statistics**
*   **References:** 40 Citations
*   **Quality Score:** 9/10