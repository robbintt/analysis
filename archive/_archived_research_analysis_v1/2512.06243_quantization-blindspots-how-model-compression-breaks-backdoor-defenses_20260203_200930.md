---
title: 'Quantization Blindspots: How Model Compression Breaks Backdoor Defenses'
arxiv_id: '2512.06243'
source_url: https://arxiv.org/abs/2512.06243
generated_at: '2026-02-03T20:09:30'
quality_score: 9
citation_count: 7
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Quantization Blindspots: How Model Compression Breaks Backdoor Defenses

*Rohan Pandey; Eric Ye*

> ### ðŸ“Š Quick Facts
> | Metric | Finding |
> | :--- | :--- |
> | **Quality Score** | 9/10 |
> | **Impact Level** | Critical |
> | **INT8 Defense Rate** | 0% (All defenses) |
> | **INT8 Attack Success** | > 99% |
> | **INT4 Attack Success** | > 90% |
> | **Primary Datasets** | GTSRB, CIFAR-10 |

---

## Executive Summary

This research addresses a critical vulnerability in the current machine learning security pipeline regarding the deployment of backdoored models. While state-of-the-art defenses effectively detect malicious triggers in high-precision (FP32) environments, the industry standard for deploying models on edge devices involves aggressive model compression techniques, specifically quantization to INT8 or INT4.

The authors highlight a dangerous disconnect: security is typically validated in FP32, yet deployment occurs in low-precision environments. This gap renders production systems vulnerable, as the paper demonstrates that the very process of optimizing a model for efficiency can inadvertently neutralize its security mechanisms without mitigating the underlying threat.

The key innovation is the identification and characterization of **"Quantization Blindspots"**â€”a phenomenon where standard Post-Training Quantization (PTQ) pipelines disrupt the statistical signatures that backdoor defenses rely on. The empirical results reveal a catastrophic failure of current security measures under compression: when models are quantized to INT8, the detection rate of all five evaluated backdoor defenses drops to **0%**, while backdoor attacks remain robust with an Attack Success Rate (ASR) exceeding **99%**.

This study fundamentally alters the landscape of ML security by exposing that reliance on FP32-based evaluation provides a false sense of safety. The findings establish quantization robustness as a necessary axis for the design and evaluation of future backdoor defenses.

---

## Key Findings

*   **Complete Defense Failure at INT8:** INT8 quantization reduces the detection rate of all five evaluated backdoor defenses to **0%**.
*   **Robust Attack Retention:** Despite compression, backdoor attacks maintain a success rate exceeding **99%** at INT8 and **90%** at INT4.
*   **Dataset Variance:** Defense effectiveness at INT4 varies significantly depending on the specific dataset (GTSRB vs. CIFAR-10).
*   **Evaluation Gap:** There is a critical discrepancy between traditional FP32 evaluation and quantized production deployment, rendering current security assessments potentially invalid.

---

## Methodology

The researchers conducted a systematic empirical study to evaluate the resilience of backdoor defenses under model compression. The study design included the following elements:

*   **Defenses Evaluated:** Five representative mechanisms were tested: Neural Cleanse (NC), Activation Clustering (AC), Spectral Signatures (SS), STRIP, and Fine-Pruning (FP).
*   **Attack Model:** The canonical BadNet attack was used as the baseline threat.
*   **Precision Settings:** Performance was compared across FP32 (baseline), INT8 (dynamic quantization), and INT4 (simulated quantization).
*   **Benchmarks:** The GTSRB and CIFAR-10 vision datasets served as the primary benchmarks for the experiments.

---

## Technical Details

### Deployment Pipeline & Threat Model
The study analyzes a realistic deployment pipeline where a defender receives a potentially backdoored pre-trained model. The defender applies Post-Training Quantization (PTQ) and executes backdoor defenses on the **quantized model** rather than the FP32 baseline.

*   **Attack Definition:** Defined via trigger injection $\tau(x)$ and target class $y_t$.
*   **Requirements:**
    *   Clean Accuracy $\geq 1 - \epsilon_c$
    *   Attack Success Rate (ASR) $\geq 1 - \epsilon_a$

### Quantization Protocol
The study utilizes uniform symmetric quantization defined by:

$$Q_b(r; s) = s \cdot \text{clamp}\left(\left\lfloor\frac{r}{s}\right\rceil, -2^{b-1}, 2^{b-1}-1\right)$$

This is evaluated at three precision levels:
1.  **FP32** (Floating Point 32-bit)
2.  **INT8** (Integer 8-bit)
3.  **INT4** (Integer 4-bit)

### Evaluation Protocol
1.  **Attack Injection:** A trigger is injected into the model (valid only if ASR > 0.95).
2.  **Quantization:** The model is compressed to the target precision.
3.  **Defense Execution:** Defenses are run on the quantized model using a clean reference dataset.

---

## Results

The study utilized Detection Rate (True Positive Rate) as the primary metric for defense effectiveness and an attack validity threshold of ASR $\geq$ 95%.

*   **INT8 Results:**
    *   **Defense Detection Rate:** 0% across all five defenses.
    *   **Attack ASR:** > 99%.
*   **INT4 Results:**
    *   **Defense Detection Rate:** Varies significantly by dataset.
    *   **Attack ASR:** > 90%.
*   **Conclusion:** Quantization destroys the subtle statistical anomalies that defenses rely on for detection, while the "saliency" of the backdoor trigger remains sufficient to fool the classifier. Security assessments valid in FP32 environments fail completely in quantized production environments.

---

## Contributions

1.  **Identification of 'Quantization Blindspots':** The research reveals that standard model compression pipelines neutralize state-of-the-art backdoor defenses without mitigating the underlying threats.
2.  **Re-definition of Evaluation Standards:** The authors establish quantization robustness as a necessary axis for the design and evaluation of future backdoor defenses, specifically for low-precision environments.

---

**Quality Score:** 9/10  
**References:** 7 citations