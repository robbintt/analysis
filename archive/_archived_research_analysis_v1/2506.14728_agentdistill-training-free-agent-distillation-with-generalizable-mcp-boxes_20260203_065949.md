---
title: 'AgentDistill: Training-Free Agent Distillation with Generalizable MCP Boxes'
arxiv_id: '2506.14728'
source_url: https://arxiv.org/abs/2506.14728
generated_at: '2026-02-03T06:59:49'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# AgentDistill: Training-Free Agent Distillation with Generalizable MCP Boxes

*Jiahao Qiu; Xinzhe Juan; Yimin Wang; Ling Yang; Xuan Qi; Tongcheng Zhang; Jiacheng Guo; Yifu Lu; Zixin Yao; Hongru Wang; Shilong Liu; Xun Jiang; Liu Leqi; Mengdi Wang*

---

> ### ðŸ’¡ Quick Facts
>
> *   **Quality Score:** 8/10
> *   **Training Cost:** Zero (Training-Free)
> *   **References:** 40 Citations
> *   **Teacher Models:** GPT-4o
> *   **Student Models:** Llama-3.1-8B, Qwen3-8B
> *   **Key Benchmark:** Comparable performance to OctoTools (GPT-4o) on Biomedical and Mathematical tasks.

---

## Executive Summary

The deployment of Large Language Model (LLM)-based agents is often constrained by high computational costs and latency, limiting their practical scalability. While model distillation offers a potential solution by compressing capabilities into smaller models, existing methods primarily focus on static knowledge transfer and struggle with complex agentic behaviors. Traditional approaches typically require resource-intensive fine-tuning or step-by-step trajectory imitation to teach reasoning and tool use. These methods often fail to enable dynamic planning in novel environments and incur significant computational overhead.

**AgentDistill** addresses the critical gap of distilling full agentic capabilitiesâ€”including planning, reasoning, and tool usageâ€”into Small Language Models (SLMs) without the need for expensive training phases. It introduces a training-free agent distillation framework that diverges from traditional output alignment or trajectory replay.

The core innovation lies in the direct reuse of **Model-Context-Protocols (MCPs)**, which are structured, reusable task-solving modules autonomously generated by teacher agents (e.g., GPT-4o). Instead of learning to imitate the teacher's step-by-step actions, the student agent integrates these pre-constructed protocols directly. This mechanism allows the student agent to inherit sophisticated reasoning and tool-using capabilities dynamically, bypassing the need for gradient updates, parameter updates, or human intervention.

The framework was evaluated across rigorous Biomedical and Mathematical benchmarks, where Student agents built on Llama-3.1-8B and Qwen3-8B achieved performance comparable to advanced systems powered by GPT-4o. Specifically, AgentDistill-enabled SLMs matched the capabilities of the OctoTools system, marking a significant improvement over the baseline performance of small models. This advancement suggests a future where intelligent agents are both scalable and economically viable.

---

## Key Findings

*   **High Performance on Small Models:** Student agents built on small language models (SLMs) using AgentDistill achieved performance comparable to advanced systems utilizing large LLMs.
*   **Cross-Domain Generalization:** The distilled student agents effectively generalized their capabilities to solve new problems across different domains, specifically validated on biomedical and mathematical benchmarks.
*   **Effective Dynamic Planning:** The proposed approach successfully enables student agents to dynamically plan and act without requiring step-by-step imitation or full trajectory replays.
*   **Operational Efficiency:** The framework allows for the creation of intelligent agents that are both scalable and cost-efficient, requiring minimal supervision or human intervention.

---

## Methodology

AgentDistill proposes a **training-free agent distillation framework** that diverges from traditional methods relying on output alignment or trajectory replay.

*   **Core Mechanism:** The direct reuse of Model-Context-Protocols (MCPs).
*   **Protocol Definition:** MCPs are structured, reusable task-solving modules autonomously generated by teacher agents.
*   **Knowledge Transfer:** Knowledge is transferred to the student agent via these pre-constructed protocols, bypassing the need for extensive training phases or step-by-step tool usage imitation.

---

## Technical Details

**Framework Overview**
AgentDistill is a lightweight, training-free framework designed to distill capabilities from Large Language Model (LLM) agents to Small Language Model (SLM) agents.

**Key Components**

| Component | Description |
| :--- | :--- |
| **Model-Context-Protocols (MCPs)** | Standardized two-way interfaces for context provision and external data access. |
| **Teacher Agents** | High-level models (e.g., GPT-4o) that generate self-contained, reusable MCP boxes encapsulating problem-solving skills. |
| **Student Agents** | Smaller models (e.g., Llama-3.1-8B, Qwen3-8B) that integrate these boxes directly to inherit sophisticated capabilities. |

**Operational Workflow**
1.  Teacher agents generate MCP boxes for specific tasks.
2.  Student agents ingest these boxes without additional training or fine-tuning.
3.  Student agents utilize the embedded protocols to dynamically plan and act independently.

---

## Contributions

*   **Advancement in Agent Distillation:** Addresses the underexplored challenge of distilling LLM-based agents rather than just static language models.
*   **Training-Free Paradigm:** Introduces a novel, training-free approach to agent compression, reducing computational overhead.
*   **Enhanced Generalization:** Provides a solution to the limitation of dynamic planning in novel environments by utilizing distilled MCPs.
*   **Cost-Effective Scalability:** Demonstrates that it is possible to build high-performance, domain-generalizable agents using smaller, more cost-efficient models.

---

## Results

The framework was evaluated across **Biomedical** and **Mathematical** benchmarks.

*   **Performance Parity:** Student agents using AgentDistill achieved performance comparable to advanced large LLMs, specifically matching OctoTools powered by GPT-4o.
*   **Baseline Improvement:** The approach significantly enhanced small model performance from a baseline state to rival the teacher's performance.
*   **Zero Cost Efficiency:** It operates with zero training cost, is described as scalable and cost-efficient, and generalizes to new problems without requiring the replication of fixed trajectories.

---
*Quality Score: 8/10 | References: 40 citations*