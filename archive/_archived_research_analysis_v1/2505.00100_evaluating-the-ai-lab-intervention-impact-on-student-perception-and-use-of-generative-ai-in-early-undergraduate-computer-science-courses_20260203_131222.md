---
title: 'Evaluating the AI-Lab Intervention: Impact on Student Perception and Use of
  Generative AI in Early Undergraduate Computer Science Courses'
arxiv_id: '2505.001'
source_url: https://arxiv.org/abs/2505.00100
generated_at: '2026-02-03T13:12:22'
quality_score: 8
citation_count: 25
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Evaluating the AI-Lab Intervention: Impact on Student Perception and Use of Generative AI in Early Undergraduate Computer Science Courses

*Ethan Dickey; Andres Bejarano; Rhianna Kuperus; B√°rbara Fagundes*

***

### üìä Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **References** | 25 Citations |
| **Sample Size** | 831 Matched Pre/Post Responses |
| **Total Responses** | 1,662 Perception; 1,652 Usage |
| **Duration** | 3 Semesters |
| **Institution** | Purdue University |
| **Significance Level** | $p < 0.05$ |

***

## üìù Executive Summary

As Generative AI (GenAI) tools become ubiquitous in computer science education, institutions face a critical challenge: integrating these powerful technologies without undermining students' fundamental computing competencies or fostering academic dishonesty. The pedagogical landscape currently lacks empirical evidence regarding how formal, structured guidance influences student behavior, perception, and skill acquisition. Educators are thus caught between banning AI tools or allowing unregulated use, both of which carry significant risks to learning outcomes. This paper addresses the urgent need for evidence-based strategies that facilitate the transition from naive, potentially detrimental reliance on AI to active, skill-building engagement.

The authors introduce and evaluate the **'AI-Lab' framework**, a structured intervention grounded in Vygotsky‚Äôs "More Knowledgeable Other" theory. Technically, the framework utilizes a 4-stage architecture: Instructor Preparation, Prelab, In-class Lab, and Post-Lab. This model employs guided scaffolding to reposition GenAI as a collaborative partner for "mindful engagement" rather than a mere solution generator. By explicitly structuring the student-AI interaction, the intervention aims to foster reflective integration, ensuring that students utilize AI for conceptual understanding and debugging while maintaining agency over their learning process.

The study utilized a mixed-methods approach across three semesters and four courses at Purdue University, analyzing 831 matched pre- and post-intervention survey responses. Quantitative analysis revealed that while the overall frequency of GenAI usage remained stable, there were **"large effect sizes" ($r_b > 0.50$)** in student comfort and openness regarding the use of AI for conceptual understanding, debugging, and homework. Statistically significant results ($p < 0.05$) indicated a distinct shift in debugging behavior toward a "mindful and deliberate" approach. Qualitative data corroborated these findings, highlighting a transition from "naive usage" to "reflective integration" and an increased student awareness of their own skill development.

This research provides critical empirical validation that scaffolded interventions enable students to harness the benefits of GenAI without compromising their technical abilities. By demonstrating that structured guidance significantly alters student behavior toward mindful application, the AI-Lab model offers concrete, evidence-based guidelines for educators seeking to integrate AI responsibly into computing curricula. This work fills a vital gap in the literature, shifting the focus from restricting access to designing pedagogical structures that support skill acquisition in the era of artificial intelligence.

***

## üîë Key Findings

*   **Stable Usage Frequency:** Overall frequency of Generative AI usage remained largely stable, indicating the intervention changed *how* students used tools rather than *how often*.
*   **Improved Attitudes:** Large effect sizes ($r_b > 0.50$) were observed regarding increases in student comfort and openness to using GenAI for:
    *   Conceptual understanding
    *   Debugging
    *   Homework problems
*   **Shift in Debugging Behavior:** A statistically significant shift indicating students adopted a more **mindful and deliberate** approach to debugging.
*   **Transition to Reflective Use:** Qualitative data suggests the intervention successfully bridged the gap between naive usage and reflective integration, increasing awareness of skill development.

***

## ‚öôÔ∏è Technical Details

### Framework Architecture
The study evaluates the 'AI-Lab' framework, which is grounded in Vygotsky‚Äôs **"More Knowledgeable Other"** theory. It integrates Generative AI into computer science education through a distinct 4-stage architecture:

1.  **Instructor Preparation**
2.  **Prelab**
3.  **In-class Lab**
4.  **Post-Lab**

### Statistical Methodology
The mixed-methods design combines quantitative pre/post surveys and qualitative focus groups. The statistical analysis protocol included:

*   **Normality Testing:** Shapiro-Wilk testing utilized to determine data distribution.
*   **Hypothesis Testing:**
    *   Paired Sample t-test (for normal distributions)
    *   Paired Wilcoxon Signed-Rank Test (for non-normal distributions)
*   **Significance Threshold:** $p < 0.05$
*   **Effect Size Measurement:** Rank-Biserial Correlation ($r_b$)

***

## üî¨ Methodology

The research employed a **mixed-methods approach** to analyze both quantitative shifts in usage patterns and attitudes, alongside qualitative student narratives.

*   **Context:** Conducted over three semesters across four mandatory and elective courses at Purdue University.
*   **Intervention:** Implemented 'AI-Lab' modules emphasizing guided scaffolding and mindful engagement.
*   **Data Collection:**
    *   **Quantitative:** 831 matched pre- and post-intervention survey responses.
    *   **Qualitative:** Focus group discussions to gather narrative data.

***

## üìà Results

The analysis included a substantial dataset of **1,662 perception** and **1,652 usage** survey responses (paired data). The core results indicate:

*   **No significant increase** in usage frequency.
*   **Large effect sizes** ($r_b > 0.50$) in student comfort and openness regarding conceptual understanding, debugging, and homework.
*   A statistically significant shift toward a **"mindful and deliberate"** debugging approach.
*   Qualitative findings demonstrated a clear transition from **"naive usage"** to **"reflective integration"**, alongside increased awareness of skill development.

***

## üèÜ Contributions

*   **Validation of Scaffolded Interventions:** Provides empirical evidence that structured interventions enable students to harness GenAI benefits without undermining computing competencies.
*   **Pedagogical Recommendations:** Offers evidence-based guidelines for educators to integrate GenAI responsibly into computing curricula.
*   **Addressing Research Gaps:** Fills a critical gap in research concerning how formal guidance influences student learning, skill development, and perceptions of AI tools in CS education.