---
title: How Not to Detect Prompt Injections with an LLM
arxiv_id: '2507.05630'
source_url: https://arxiv.org/abs/2507.05630
generated_at: '2026-01-28T00:38:16'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# How Not to Detect Prompt Injections with an LLM

*Somesh Jha, Nils Palumbo, Divyam Anshumaan, Sarthak Choudhary*

---

### ðŸ“Š Quick Facts
> **Quality Score:** 9/10  
> **Total Citations:** 40  
> **Detection Evasion Rate:** 0%  
> **Attack Success Rate:** 91%  
> **Attack Type:** Black-box / Adaptive / Low-resource  

---

## Executive Summary

This research addresses the critical security challenge of defending Large Language Model (LLM)-integrated applications against prompt injection attacks, specifically targeting the efficacy of Known-Answer Detection (KAD) schemes. KAD is a popular defense strategy that operates on the premise that embedding a secret key within the input and verifying its presence in the output can reliably distinguish between safe and malicious instructions. The significance of this paper lies in its demonstration that this widely adopted premise is fundamentally flawed.

The authors argue that KAD possesses a structural vulnerability that invalidates its security utility, leaving applications reliant on it exposed to adversarial manipulation. The key innovation of the paper is **"DataFlip,"** a novel adaptive attack designed to exploit the structural limitations of KAD. Technically, the authors formalize the environment of LLM-integrated applications using task tuples and employ an Instruction-Following Oracle to model the conflict between target instructions and injected adversarial instructions.

Based on this formal analysis, DataFlip manipulates input data to bypass the detection logic of the KAD architecture. Unlike optimization-heavy or white-box attacks, DataFlip operates as a low-resource, black-box attack. It systematically alters input triggers to deceive the Detection LLM, causing it to prioritize the malicious instruction over the detection instruction that requires revealing the secret key.

The empirical evaluation of the DataFlip attack reveals a catastrophic failure of KAD defenses. In experimental settings, DataFlip achieved a Detection Evasion rate resulting in a **0% detection rate** by the defender, meaning the attack successfully bypassed the security mechanism in every instance. Furthermore, the attack demonstrated a **91% Attack Success Rate**, indicating that the malicious instructions were not only hidden from the detector but also successfully executed by the target model.

This work establishes a new, more difficult baseline for the feasibility of detecting prompt injections via output analysis, urging the research community to abandon reliance on simple verification schemes.

---

## Key Findings

*   **Fundamental Vulnerability:** Known-answer detection (KAD) schemes possess a fundamental structural vulnerability that invalidates their security premise.
*   **DataFlip Attack:** The proposed 'DataFlip' adaptive attack can consistently evade KAD defenses.
*   **Zero Detection:** DataFlip results in detection rates as low as **0%** in experimental settings.
*   **High Subversion Rate:** The attack is highly effective at subverting LLM behavior, achieving a **91% success rate**.
*   **Zero-Requirement Execution:** DataFlip executes successfully without white-box access to the model or complex optimization processes.

---

## Technical Details

The paper formalizes the theoretical underpinnings of LLM-integrated applications and the attack mechanics:

*   **Task Representation:** LLM-integrated applications are represented as tasks using tuples $(s, x, y)$.
    *   $s$: Instructions
    *   $x$: Input data
    *   $y$: Output
*   **Attack Mechanism:** Attacks involve embedding malicious prompts into target data using a specific trigger ($z$).
*   **KAD Architecture:**
    *   Utilizes a Detection LLM ($g$).
    *   Tests for contamination by verifying if the model follows a detection instruction $s_d(k)$ to output a secret key $k$.
*   **Instruction-Following Oracle:** The analysis employs an Oracle ($E$) to mathematically model behavior, distinguishing between:
    *   Following target instructions ($s_t$)
    *   Following injected instructions ($s_e$)

---

## Methodology

The research follows a three-step process to validate the vulnerability:

1.  **Formal Definition:** The authors formally define the KAD scheme to theoretically analyze its structure and identify inherent weaknesses.
2.  **Attack Design:** Based on the identified structural flaw, they design 'DataFlip,' an adaptive attack specifically crafted to manipulate input data and bypass detection logic.
3.  **Efficacy Evaluation:** The attack is evaluated strictly through output observation using a black-box approach, mimicking a real-world external attacker scenario.

---

## Contributions

*   **Critical Reassessment:** The paper provides a critical reassessment of KAD, formally exposing its structural limitations as a standalone defense mechanism.
*   **Novel Attack Vector:** Introduces 'DataFlip,' a novel, low-resource adaptive attack that successfully subverts LLM protections without internal access.
*   **Baseline Establishment:** By achieving near-perfect evasion with high malicious efficacy, the work establishes a new baseline for the difficulty of detecting prompt injections via output analysis.

---

## Results

The authors evaluated the **DataFlip** attack against KAD defenses with significant outcomes:

*   **Detection Evasion:** 0% (The defender failed to detect the attack in any instance).
*   **Attack Success Rate:** 91% (The malicious prompt successfully hijacked the model's behavior).
*   **Conclusion:** These metrics characterize KAD schemes as possessing a 'fundamental structural vulnerability' that cannot be mitigated through simple output verification.