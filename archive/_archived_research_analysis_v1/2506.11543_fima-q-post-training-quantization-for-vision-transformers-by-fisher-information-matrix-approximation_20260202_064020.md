# FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation

*Zhuguanyu Wu; Shihe Wang; Jiayi Zhang; Jiaxin Chen; Yunhong Wang*

---

> ### ðŸ“Š Quick Facts
> *   **Core Innovation:** Uses Fisher Information Matrix (FIM) via KL divergence instead of conventional Hessian approximations.
> *   **Key Method:** DPLR-FIM (Diagonal Plus Low-Rank FIM) for efficient computation.
> *   **Top Performance:** +23.04% accuracy gain for ViT-S in W3/A3 quantization.
> *   **Efficiency:** Runtime ranges from ~100 mins (DeiT-T) to ~480 mins (Swin-B) on RTX 4090.

---

> ### ðŸ“ Executive Summary
> Current Post-Training Quantization (PTQ) methods for Vision Transformers (ViTs) face severe accuracy degradation when compressing models to aggressive low-bit precisions (e.g., 3-bit weights and activations). While existing methods often rely on Hessian approximations to guide weight reconstruction, this paper identifies that these approximations are fundamentally flawed for ViTs. They frequently discard critical off-diagonal information within the curvature matrix, a loss that disproportionately affects the structural stability of ViTs compared to other architectures. Without accurately capturing these second-order statistics, current PTQ methods fail to maintain model fidelity, creating a barrier to deploying the computationally expensive ViT models on resource-constrained edge devices.
>
> The authors introduce **FIMA-Q**, a PTQ algorithm that replaces conventional Hessian guidance with the Fisher Information Matrix (FIM). The core technical contribution is establishing that the FIM is linearly proportional to the gradient of the Kullback-Leibler (KL) divergence; this allows quantization loss to be formulated via the gradient of KL divergence rather than Hessian approximations. To address the computational intractability of calculating the full FIM for large-scale models, the authors propose **DPLR-FIM** (Diagonal Plus Low-Rank FIM). This approximation reconstructs the necessary information by integrating diagonal components with a low-rank factor, specifically targeting the class token. The method operates within a block-wise reconstruction framework to optimize network parts sequentially without full retraining.
>
> FIMA-Q achieves state-of-the-art accuracy on ImageNet-1k, significantly outperforming Mean Squared Error (MSE) baselines in challenging low-bit scenarios. In the aggressive W3/A3 quantization setting, the method delivers substantial improvements: **+23.04%** for ViT-S and **+18.18%** for DeiT-S, contributing to an average accuracy gain of 8.74% across W3/A3 configurations. However, these accuracy gains come with a notable computational cost. On an RTX 4090, processing times range from 100 minutes for DeiT-T (Rank 1) to 480 minutes for Swin-B (Rank 15). Ablation studies confirm that while lower ranks suffice for W4/A4 scenarios, the higher ranksâ€”and associated longer runtimesâ€”are strictly necessary to preserve accuracy in the most difficult W3/A3 configurations.
>
> This research challenges the prevailing reliance on diagonal Hessian approximations in PTQ, demonstrating that superior model compression requires capturing full second-order information via the Fisher Information Matrix. By providing a mathematically rigorous link between KL divergence and FIM, FIMA-Q offers a theoretically robust solution for preserving ViT performance at low bit-widths. While the computational overhead is significant, the method effectively solves the accuracy degradation problem for aggressive quantization, making it a valuable approach for applications where model fidelity is critical.

---

## Key Findings

*   **Limitations of Current Methods:** Conventional Hessian approximations in Post-Training Quantization (PTQ) suffer from specific limitations that cause significant accuracy degradation in Vision Transformers (ViTs).
*   **Theoretical Link:** There is a direct mathematical connection between Kullback-Leibler (KL) divergence and the Fisher Information Matrix (FIM). This connection facilitates the rapid computation of quantization loss.
*   **Efficient Approximation:** The proposed **DPLR-FIM** (Diagonal Plus Low-Rank FIM) method provides an efficient approximation technique that successfully balances computational cost with reconstruction accuracy.
*   **State-of-the-Art Performance:** FIMA-Q achieves superior accuracy compared to existing approaches, with substantial performance gains observed specifically in low-bit quantization scenarios.

---

## Methodology

The proposed framework operates through a sequential and theoretically grounded process:

1.  **Block-wise Reconstruction:** The method operates within a block-wise reconstruction framework. It reconstructs parts of the network sequentially to avoid the prohibitive computational costs associated with full network retraining.
2.  **Loss Formulation:** The authors establish a theoretical link between Kullback-Leibler (KL) divergence and the Fisher Information Matrix (FIM). Using this connection, they define and quickly compute the quantization loss during the reconstruction phase.
3.  **DPLR-FIM Approximation:** An efficient FIM approximation method, termed **DPLR-FIM** (Diagonal Plus Low-Rank FIM), is developed. This utilizes the diagonal plus low-rank principle to make the computation feasible for large ViT models.
4.  **Optimization:** The final quantization loss is formulated based on the DPLR-FIM approximation to guide the weight quantization process effectively.

---

## Contributions

*   **Critical Analysis:** The paper provides a rigorous analysis of Hessian-guided quantization loss, formally identifying the limitations of traditional Hessian approximations in the context of ViTs.
*   **Novel Algorithm:** Introduction of **FIMA-Q**, a new PTQ method specifically optimized for Vision Transformers that leverages the Fisher Information Matrix instead of standard Hessian guidance.
*   **Efficient Scheme:** Proposal of **DPLR-FIM**, a technique that approximates the FIM efficiently using a diagonal plus low-rank decomposition, solving the computational bottleneck of using FIM in large-scale models.
*   **Comprehensive Validation:** Extensive empirical validation across various vision tasks, public datasets, and representative ViT architectures, proving the method's superiority, particularly under the challenging constraints of low-bit quantization.

---

## Technical Details

*   **Problem Addressed:** Accuracy degradation in Vision Transformer (ViT) Post-Training Quantization (PTQ) caused by limitations in Hessian approximations.
*   **FIM and KL Divergence:** The paper theoretically links Kullback-Leibler (KL) divergence and Fisher Information Matrix (FIM), asserting that FIM is linearly proportional to the gradient of KL divergence.
*   **Critique of Diagonal Approximations:** The approach critiques conventional diagonal approximations for discarding critical off-diagonal information essential for ViT stability.
*   **DPLR-FIM Composition:** The proposed **DPLR-FIM** (Diagonal Plus Low-Rank FIM) integrates Diag-FIM and LR-FIM to reconstruct the complete FIM, specifically for the class token.
*   **Complexity:** The computational complexity for the reconstruction loss is calculated as **O(ak)**.

---

## Results

**Quantization Accuracy (W3/A3)**
In aggressive W3/A3 quantization, DPLR-FIM achieved significant accuracy gains over the MSE baseline:
*   **ViT-S:** +23.04%
*   **DeiT-S:** +18.18%
*   **Average Improvement:** 8.74%
*   **Overall Low-bit Gain:** 5.31%

**Ablation Studies**
*   **W4/A4:** Accuracy remains steady across different ranks.
*   **W3/A3:** Accuracy shows an upward trend with higher ranks, indicating the necessity of higher complexity for difficult low-bit tasks.

**Computational Efficiency (RTX 4090)**
*   **Fastest:** DeiT-T, Rank 1 (~100 mins)
*   **Slowest:** Swin-B, Rank 15 (~480 mins)
*   **Trend:** Larger models show steeper time increases at higher ranks.

---

**Paper Quality Score:** 7/10  
**References:** 40 citations