---
title: 'Assessing LLM Text Detection in Educational Contexts: Does Human Contribution
  Affect Detection?'
arxiv_id: '2508.08096'
source_url: https://arxiv.org/abs/2508.08096
generated_at: '2026-01-27T22:53:05'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Assessing LLM Text Detection in Educational Contexts
## Does Human Contribution Affect Detection?

*Authors: Large Language, Benjamin Paa, Bielefeld University, Lukas Gehring, Essay Detection*

---

> ### âš¡ Quick Facts
> *   **Dataset:** GEDE (Generative Essay Detection in Education)
> *   **Volume:** 916 human essays & >12,500 LLM-generated essays
> *   **Max Token Length:** 320 words
> *   **Models Used:** GPT-4o-mini, Llama-3.3-70b, DIPPER
> *   **Benchmark Spectrum:** 6-level Contribution Framework
> *   **Evaluation Focus:** Zero-Shot DetectGPT & Fast-DetectGPT

---

## ðŸ“„ Executive Summary

This research addresses the critical unreliability of current state-of-the-art Large Language Model (LLM) text detectors within educational environments. As students increasingly incorporate AI tools into their workflowsâ€”ranging from grammar assistance to full-text generationâ€”detection systems must navigate complex scenarios involving mixed human and AI contributions. The paper highlights that existing detectors, largely designed to distinguish between purely human and purely machine-generated text, fail in nuanced real-world applications. This failure manifests as high false positive rates, where human-written work is incorrectly flagged as AI-generated. This poses severe risks to academic integrity, potentially leading to false accusations of dishonesty against students who have not actually violated policies.

The key innovation presented is the **Generative Essay Detection in Education (GEDE) dataset** and a novel **Spectrum of Contribution Levels** framework. Technically, the researchers moved beyond binary classification by establishing a 6-level taxonomy that captures the continuum of student-AI interaction, from purely human-written text to fully LLM-generated content with adversarial "humanizing" applied. The dataset aggregates text from existing educational corpora (AAE, PERSUADE 2.0, BAWE) and synthesizes variations using models such as GPT-4o-mini, Llama-3.3-70b, and DIPPER. To ensure compatibility with current detector token limits, texts are preprocessed to a maximum of 320 words. This benchmarking framework allows for a granular assessment of how detectors handle intermediate levels of contribution, effectively simulating realistic editing behaviors rather than just wholesale generation.

The study benchmarked Zero-Shot DetectGPT and Fast-DetectGPT, revealing that these state-of-the-art detectors struggle significantly with texts containing intermediate levels of student contribution. Specifically, the researchers found that detection accuracy plummets when human edits are introduced, and systems are highly vulnerable to adversarial "humanizing" attacks. The benchmark utilized a comprehensive dataset comprising **916 human essays** and over **12,500 LLM-generated essays**. While supervised models like RoBERTa were noted to achieve >99% accuracy in-domain on datasets like ArguGPT, the results demonstrate that both supervised and zero-shot detectors struggle out-of-distribution.

The significance of this work lies in its cautionary empirical evidence against the reliance on automated detection tools for academic misconduct adjudication. By releasing the GEDE dataset, source code, and supplementary materials publicly, the authors provide a vital resource for the research community to develop more robust evaluation metrics that account for the spectrum of AI usage. This research urges the field to shift away from binary "guilty/innocent" detection models toward frameworks that can quantify the level of AI contribution. Ultimately, these findings suggest that current detection methodologies are unsuitable for high-stakes educational decisions and call for a re-evaluation of how institutions approach academic integrity in the era of generative AI.

---

## ðŸ”‘ Key Findings

*   **Inaccuracy with Mixed Contributions:** Most state-of-the-art LLM detectors struggle to accurately classify texts with intermediate levels of student contribution (mixed human and LLM inputs).
*   **High False Positive Rates:** Detectors exhibit a high rate of false positives, often incorrectly identifying human-written text as AI-generated.
*   **Educational Risks:** The prevalence of false positives poses severe educational risks, including detrimental impacts from false accusations of academic dishonesty.
*   **Vulnerability to Humanizing:** Detection capabilities are vulnerable to 'humanizing' attacks where generated text is manipulated to resemble human writing, bypassing security measures.

---

## Methodology

The researchers benchmarked the performance of various state-of-the-art LLM detectors using the **GEDE dataset**, a novel dataset curated specifically for educational contexts. To provide a granular analysis, they employed a 'contribution levels' framework to categorize data. This framework allows for the assessment of a spectrum of inputs, ranging from:
1.  Purely human-written texts
2.  Slightly LLM-improved texts
3.  Fully LLM-generated texts
4.  Adversarial 'humanized' texts

This methodology moves beyond binary classification to simulate the actual ways students interact with AI tools in academic settings.

---

## âš™ï¸ Technical Details

### Benchmarking Framework
*   **Dataset:** GEDE (Generative Essay Detection in Education)
*   **Spectrum of Contribution:** A 6-level taxonomy (Human-Written to LLM Humanize) designed to simulate educational usage.
*   **Data Sources:** AAE, PERSUADE 2.0, and BAWE corpora.

### Synthesis & Processing
*   **Synthesis Models:** GPT-4o-mini, Llama-3.3-70b, and DIPPER.
*   **Text Length:** Data is truncated/preprocessed to a maximum of 320 words to accommodate detector token limits.

### Evaluation Models
*   **Zero-Shot DetectGPT:** Compares the log probability of input text against perturbed samples.
*   **Fast-DetectGPT:** Utilizes conditional probability for computational optimization.

---

## ðŸ“¦ Contributions

*   **GEDE Dataset:** The public release of the Generative Essay Detection in Education dataset, containing:
    *   Over 900 student-written essays
    *   12,500 LLM-generated essays
*   **Contribution Levels Taxonomy:** A conceptual tool proposed to better capture and assess the diversity of student interactions with LLMs in writing assignments.
*   **Open Resources:** The public availability of the dataset, source code, and supplementary materials to support further research and reproducibility.

---

## ðŸ“Š Results

State-of-the-art detectors struggle significantly with intermediate contribution texts (mixed human and LLM inputs) and exhibit high false positive rates on purely human-written text. Detection is notably weak against humanizing attacks.

*   **Dataset Scope:** The final GEDE dataset comprises **916 human essays** and over **12,500 LLM essays** (truncated to 320 words).
*   **Comparative Performance:** Cited benchmarks indicate that supervised models like RoBERTa can achieve >99% accuracy in-domain on ArguGPT but struggle significantly when applied out-of-distribution.
*   **Human Evaluation:** Similarly, human evaluators (teachers) cannot reliably distinguish between human and AI text, highlighting the difficulty of the task even for non-automated systems.

---

*Quality Score: 8/10 | References: 40 citations*