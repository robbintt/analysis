---
title: 'Visual Graph Arena: Evaluating Visual Conceptualization of Vision and Multimodal
  Large Language Models'
arxiv_id: '2506.06242'
source_url: https://arxiv.org/abs/2506.06242
generated_at: '2026-02-06T03:42:45'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Visual Graph Arena: Evaluating Visual Conceptualization of Vision and Multimodal Large Language Models

*Authors: Zahra Babaiee; Peyman M. Kiasari; Daniela Rus; Radu Grosu*

---

> ### ðŸ“Š Quick Facts
>
> *   **Quality Score:** 9/10
> *   **Citations:** 40
> *   **Top Human Performance:** >90% aggregate accuracy
> *   **Top Vision Model:** ConvNeXt Base (82.4% on Shortest Path Kawai)
> *   **Top MLLM:** GPT-o1 (67% on Hamiltonian Cycle, though attributed to spurious correlation)
> *   **Benchmark Scope:** 6 distinct graph-based tasks across varied layouts

---

## Executive Summary

This research addresses the fundamental question of whether state-of-the-art vision models and multimodal large language models (MLLMs) possess genuine visual understanding or merely rely on pseudo-intelligent pattern matching. The authors identify a critical gap in current AI capabilities: the lack of "visual conceptualization," or the ability to perform representation-invariant reasoning. This limitation means that while models may excel at recognizing specific visual patterns, they fail to grasp abstract concepts that remain constant despite changes in visual form. Addressing this is vital for moving AI towards human-like reasoning, as current systems often struggle to generalize knowledge across varying visual presentations of the same underlying structure.

The key innovation is the introduction of the "Visual Graph Arena" (VGA), a specialized benchmark designed to isolate and evaluate visual abstraction and conceptualization. Technically, VGA employs graph-structured data presented through six distinct tasksâ€”ranging from Isomorphism detection to Path and Cycle Metricsâ€”rendered in diverse layouts such as Kamada-Kawai and planar forms. By varying the visual layout while keeping the underlying graph structure constant, the framework tests whether a model can identify the concept independent of its representation. This methodology allows researchers to rigorously benchmark both fine-tuned vision models (like ConvNeXt and ViT) and zero-shot MLLMs (like GPT-4o and Claude 3.5) against human performance to distinguish true reasoning from spurious correlations.

The study reveals a striking performance deficit between humans and AI models. Human baselines achieved >90% aggregate accuracy, including 100% on Shortest Path tasks, whereas current models demonstrated significant failures. Among vision models, ConvNeXt outperformed Transformer-based architectures (e.g., ViT, Swin-T), achieving 82.4% accuracy on Shortest Path (Kawai layout) and 36.3% on Chordless Cycles, while most Transformers failed Isomorphism tasks entirely. Most MLLMs performed randomly, with the notable exception of GPT-o1, which reached 67% accuracy on Hamiltonian Cycle. However, diagnostic analysis revealed that GPT-o1â€™s success was due to a spurious correlationâ€”detecting visual leaf nodes rather than understanding the graph logicâ€”evidenced by its performance dropping to random levels when those visual cues were removed.

The significance of this work lies in its exposure of "pseudo-intelligence" in high-performing models and its isolation of conceptualization as a distinct, necessary component of visual understanding. By proving that current models rely on superficial pattern matching rather than logical reasoning, the VGA benchmark provides a critical diagnostic tool for the AI community. This challenges existing evaluation paradigms and redirects future research toward developing systems capable of true representation-invariant reasoning, offering a clearer path toward achieving robust, human-like visual conceptualization in artificial intelligence.

---

## Key Findings

*   **Significant Performance Gap:** There is a striking performance deficit between state-of-the-art vision models/multimodal LLMs and humans. While humans achieved near-perfect accuracy, models failed drastically on specific reasoning tasks.
*   **Specific Task Failures:** Current models demonstrated a total inability to solve **isomorphism detection** tasks and showed only limited success in path and cycle detection tasks.
*   **Pseudo-Intelligence vs. Understanding:** The study identified behavioral anomalies suggesting models rely on **pseudo-intelligent pattern matching** rather than genuine conceptual understanding.
*   **Limitations in Representation-Invariant Reasoning:** Fundamental limitations exist in current AI systems' ability to perform visual conceptualizationâ€”specifically, reasoning about the same concept despite variations in visual form.

---

## Methodology

The researchers introduced the **'Visual Graph Arena' (VGA)**, a dataset comprising six distinct graph-based tasks designed to test visual abstraction.

To evaluate reasoning independent of visual form (**representation-invariant reasoning**), the methodology employs diverse graph layouts (e.g., Kamada-Kawai vs. planar) for the same underlying graph structures. The approach involves benchmarking state-of-the-art vision models and multimodal LLMs against human performance across these varied layouts to isolate the capability for visual conceptualization.

---

## Technical Details

### Benchmark Structure
The Visual Graph Arena (VGA) evaluates visual conceptualization on graph-structured data across varying layouts.

| Task Category | Specific Tasks | Notes |
| :--- | :--- | :--- |
| **Isomorphism** | Easy / Hard | Tests ability to identify structurally identical graphs. |
| **Path Detection** | Hamiltonian Path / Cycle | Involves finding specific paths through nodes. |
| **Path Metrics** | Shortest Path | Layouts: Random, Kawai, Planar. |
| **Cycle Metrics** | Biggest Chordless Cycle | Identifying the largest cycle without chords. |

### Models Evaluated

**Vision Models (Fine-tuned via Best Validation Accuracy)**
*   ConvNeXt Base
*   ViT Base
*   Swin-T Base
*   SigLIP
*   DINov2

**Multimodal LLMs (Zero-shot, 100 samples/task)**
*   GPT-4o
*   Claude 3.5 Sonnet
*   GPT-3 Opus
*   Gemini
*   GPT-o1

---

## Results

### Human vs. AI Performance
*   **Human Baselines:** Achieved **>90%** aggregate accuracy (100% on Shortest Path; 88.2% on Biggest Chordless Cycle).
*   **Vision Models:**
    *   **ConvNeXt** consistently outperformed Transformers (ViT, Swin-T).
    *   **ViT / Swin-T / DINov2** failed Isomorphism tasks entirely.
    *   **SigLIP** reached 54.4% on Easy Isomorphism.
    *   ConvNeXt was top performer on Chordless Cycle (36.3%) and Shortest Path Kawai (82.4%).
*   **Multimodal LLMs:**
    *   Most MLLMs performed at random levels.
    *   **GPT-o1** achieved 55% on Shortest Path and 67% on Hamiltonian Cycle.

### The Case of GPT-o1: Spurious Correlation
Analysis indicated GPT-o1's 67% accuracy on Hamiltonian Cycle was **not** due to logic, but rather a spurious correlation: it learned to detect visual "leaf nodes." When leaf nodes were excluded from the visual representation, performance dropped immediately to random levels.

---

## Contributions

*   **The VGA Benchmark:** The release of a specialized evaluation framework designed to assess and improve the capacity for visual abstraction and conceptualization in AI systems.
*   **Isolation of Conceptualization:** The work isolates and defines 'conceptualization' (representation-invariant reasoning) as a distinct and necessary component of visual understanding that current models lack.
*   **Diagnostic Insight:** The research provides critical evidence that current high-performing models may be mimicking intelligence through pattern matching rather than understanding concepts, offering a new direction for developing human-like visual reasoning in AI.