---
title: LLM-based Query Expansion Fails for Unfamiliar and Ambiguous Queries
arxiv_id: '2505.12694'
source_url: https://arxiv.org/abs/2505.12694
generated_at: '2026-01-27T21:40:37'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# LLM-based Query Expansion Fails for Unfamiliar and Ambiguous Queries

*Authors: Kunihiro Takeoka, Kenya Abe, Makoto P. Kato, Masafumi Oyamada*

---

> ### üìä Quick Facts
> *   **Quality Score:** 8/10
> *   **Total Citations:** 40
> *   **Primary Models:** GPT-3.5-turbo, Meta-Llama-3-8B-Instruct
> *   **Retrieval Architectures:** Sparse (BM25), Dense (Contriever, E5-base-v2)
> *   **Key Datasets:** MS MARCO, BioASQ, NQ, TriviaQA
> *   **Core Limitation Identified:** **Knowledge Deficiency** (vs. Hallucination)

---

## üìÑ Executive Summary

This research addresses the critical reliability issues of using Large Language Models (LLMs) for Query Expansion (QE) within information retrieval systems. While LLMs are increasingly adopted to refine user queries and improve search results, this paper challenges the prevailing assumption that their primary failure mode is generic "hallucination." Instead, the authors identify that the fundamental limitation is the **"deficiency in the LLM's internal knowledge base."**

This distinction is crucial because it highlights that LLM-based QE fails systematically when handling queries regarding unfamiliar topics or ambiguous terms. Without addressing these specific deficiencies, integrating LLMs into search pipelines risks significantly degrading retrieval performance rather than enhancing it, particularly in scenarios requiring specific factual grounding or neutral interpretation of search intent.

The study introduces a novel diagnostic framework designed to isolate and categorize QE failures into two distinct modes: **"incorrect expansion"** due to knowledge insufficiency and **"biased refinement"** due to query ambiguity. By applying this structured taxonomy across both sparse (BM25) and dense (Contriever, E5-base-v2) retrieval architectures, the research provides a controlled experimental environment that attributes performance degradation directly to specific LLM knowledge gaps.

Empirical findings reveal that LLM-based QE significantly impairs retrieval effectiveness, with dense retrieval models demonstrating higher sensitivity to expansion failures than sparse models. In conditions of knowledge insufficiency, performance on the MS MARCO dataset using Contriever and Llama-8B resulted in substantial decreases in NDCG@10 (up to -14.10%). Furthermore, for high-ambiguity queries, the study observed consistent reductions in Recall@100 and a distinct "interpretation bias," where LLMs disproportionately favored popular interpretations, artificially narrowing the search scope.

Ultimately, this work compels researchers and practitioners to develop more robust, knowledge-aware retrieval architectures that can recognize when an LLM lacks the specific understanding required to expand a query without introducing bias or error.

---

## üîë Key Findings

*   **Root Cause Identification:** The primary limitation of LLM-based query expansion (QE) is identified as deficiencies in the LLM's internal knowledge rather than mere hallucination.
*   **Impact of Unfamiliarity:** Unfamiliar queries result in incorrect expansions and degraded search performance when the LLM lacks specific knowledge.
*   **Ambiguity Risks:** Ambiguous queries produce biased refinements that artificially narrow search coverage instead of resolving the ambiguity.
*   **Performance Degradation:** LLM-based QE significantly impairs retrieval effectiveness across both sparse and dense retrieval models under conditions of knowledge insufficiency or high ambiguity.

---

## üî¨ Methodology

The research employed a systematic approach to examine two distinct failure scenarios:
1.  **Queries involving unknown knowledge**
2.  **Ambiguous queries**

Controlled experiments were conducted across multiple datasets to isolate the effects of LLM knowledge and query ambiguity. The study evaluated the impact on both sparse and dense retrieval architectures using a specialized framework developed specifically for this assessment.

---

## ‚öôÔ∏è Technical Details

### Evaluation Setup
| Component | Specification |
| :--- | :--- |
| **Failure Modes** | Knowledge Insufficiency, Query Ambiguity |
| **Sparse Retrieval** | BM25 (k1=0.9, b=0.4) |
| **Dense Retrieval** | Contriever, E5-base-v2 (256 token length) |
| **QE Methods** | Keyword (Q2E), Answer (Q2D), Question (GaQR) |
| **LLMs Used** | GPT-3.5-turbo-0125, Meta-Llama-3-8B-Instruct |
| **Prompting** | Zero-shot prompting |
| **Framework** | GaQR modified to use GPT-3.5 as teacher and Llama-3 as student |

### Metrics & Verification
*   **Primary Metrics:** NDCG@10, Recall@100.
*   **Knowledge Sufficiency:** Determined by exact match (NQ, TriviaQA) or GPT-4-turbo evaluation (MS MARCO, BioASQ).
*   **Ambiguity Categorization:** Quantified by the number of valid interpretations.

---

## üìà Results

The study yielded significant quantitative evidence regarding the failure of LLM-based QE in specific contexts:

### Impact of Knowledge Insufficiency
Knowledge insufficiency leads to significant performance degradation, particularly in Dense Retrieval models:

*   **MS MARCO (Contriever + Llama8b):**
    *   **Q2E:** -8.63% NDCG@10
    *   **Q2D:** -14.10% NDCG@10
*   **BioASQ (E5-base-v2):**
    *   **Q2D:** -11.25% NDCG@10
    *   **Q2E:** -10.30% NDCG@10

### Model Sensitivity
*   **Dense vs. Sparse:** Dense retrieval models showed **higher sensitivity** to expansion failures compared to sparse models.
*   **LLM Consistency:** GPT-3.5 and Llama8b exhibited similar failure patterns across the board.

### Ambiguity Effects
*   High ambiguity resulted in consistently lower **Recall@100**.
*   **Interpretation Bias:** LLMs demonstrated a bias favoring popular interpretations, which artificially narrowed search coverage and excluded relevant, less common documents.

---

## üöÄ Contributions

*   **Diagnostic Framework:** Provided a new diagnostic framework for assessing QE limitations specifically regarding knowledge and ambiguity.
*   **Failure Mode Taxonomy:** Explicitly defined a failure mode taxonomy encompassing incorrect expansion and biased refinement.
*   **Paradigm Shift:** Shifted the research focus from the general concept of 'hallucination' to the specific underlying cause of **'LLM knowledge deficiencies'**.

---

*Report Generated based on analysis of 40 citations.*