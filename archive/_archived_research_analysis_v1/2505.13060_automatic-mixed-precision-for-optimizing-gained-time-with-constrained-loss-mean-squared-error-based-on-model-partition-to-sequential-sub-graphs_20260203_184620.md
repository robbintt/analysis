---
title: Automatic mixed precision for optimizing gained time with constrained loss
  mean-squared-error based on model partition to sequential sub-graphs
arxiv_id: '2505.1306'
source_url: https://arxiv.org/abs/2505.13060
generated_at: '2026-02-03T18:46:20'
quality_score: 7
citation_count: 31
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs

*Shmulik Markovich-Golan; Daniel Ohayon; Itay Niv; Yair Hanani*

---

> ### ðŸ“Š Quick Facts
>
> *   **Target Model:** LLAMA-3.1-8B
> *   **Hardware Accelerator:** Intel Gaudi 2
> *   **Core Methodology:** Integer Programming (IP) & Post-Training Quantization (PTQ)
> *   **Optimization Goal:** Maximize empirical time gain vs. theoretical MAC counts
> *   **Constraint:** Strict loss Mean Squared Error (MSE) threshold
> *   **Quality Score:** 7/10
> *   **References:** 31 citations

---

## Executive Summary

Deploying Large Language Models (LLMs) on modern hardware accelerators like Intel Gaudi 2 requires navigating a difficult trade-off between computational efficiency and numerical accuracy. Existing Automatic Mixed Precision (AMP) methods typically rely on theoretical operation counts (MACs) to estimate speed, which fail to capture real-world latency impacted by compiler optimizations, operator fusion, and parallelism. Furthermore, current approaches often require computationally expensive weight optimization during calibration, creating a significant bottleneck that hinders rapid deployment.

The authors introduce a hardware-aware Integer Programming (IP) framework that formulates bit-width selection as a constrained optimization problem. The objective is to maximize empirical inference time gain while strictly constraining the loss Mean Squared Error (MSE). To estimate accuracy without weight optimization, the method derives a layer-wise sensitivity metric using a first-order Taylor series expansion, calculated via high-precision forward and backward passes on a small calibration dataset. To address performance prediction, the model graph is partitioned into sequential sub-graphs. This allows the system to empirically measure "Empirical Time Gain" ($c_{ET}$) on the target hardware, accounting for non-additive effects like operator fusion, and models the total gain as an additive sum across these sub-graphs.

Validated on the LLAMA-3.1-8B model using the Intel Gaudi 2 accelerator, the study demonstrated that summing per-layer time measurements is an inaccurate predictor of execution time due to hardware concurrency. The proposed IP-ET method successfully generated a Pareto frontier balancing loss MSE against empirical time gain, producing a non-uniform quantization pattern mixing BF16 and FP8 that outperformed naive "Prefix" and "Random" baselines. Experiments confirmed that both loss MSE and empirical time gain behave effectively as additive properties across the defined sub-graphs, enabling the IP solver to predict performance accurately without full model retraining.

This research bridges the gap between theoretical quantization strategies and the physical realities of modern AI accelerators. By replacing theoretical MAC counts with empirical hardware measurements and eliminating the need for weight optimization during calibration, the method significantly reduces the overhead and complexity of deploying low-precision LLMs. The framework provides a rigorous, reproducible approach for maximizing inference throughput on specific hardware architectures, offering engineers a practical tool to optimize model performance without the cost of full retraining.

---

## Key Findings

*   **Efficient Optimization:** The proposed method successfully optimizes inference time for Large Language Models (LLMs) on the **Intel Gaudi 2** accelerator without requiring full model retraining.
*   **Balanced Trade-offs:** An Integer Programming (IP) formulation effectively balances computational efficiency and accuracy by maximizing time gain while strictly constraining the loss Mean Squared Error (MSE).
*   **Accurate Predictions:** Modeling time gain as an additive property of sequential sub-graphs allows for accurate hardware-aware predictions of inference speed-up.
*   **Low Overhead:** The sensitivity metric requires low memory overhead as it eliminates the need for weight optimization during the calibration phase.

---

## Methodology

### Sensitivity Analysis
The method derives a novel sensitivity metric using a first-order Taylor series expansion of the loss function with respect to quantization errors in weights and activations. This metric, based on the Mean Squared Error (MSE), is calculated per layer using high-precision forward and backward passes on a small calibration dataset.

### Hardware-Aware Partitioning
The model graph is partitioned into sequential sub-graphs. Time gain is measured for each configuration using a few samples, modeling the total time gain as an additive sum across these sub-graphs.

### Constrained Optimization
The approach formulates an Integer Programming (IP) problem. This optimization uses the calculated sensitivity and time gain data to select a Mixed Precision (MP) configuration that maximizes time gain (and considers memory/MAC gains) subject to a user-defined threshold on the loss MSE.

---

## Technical Details

The research optimizes Automatic Mixed Precision (AMP) for LLMs on Intel Gaudi 2 by formulating bit-width selection as an Integer Programming (IP) problem.

*   **Objective:** Maximize inference time gain while strictly constraining loss MSE degradation.
*   **Loss Estimation:** Loss MSE is estimated using a First-Order Taylor Approximation based on a sensitivity metric derived from the element-wise product of inputs and loss gradients. It assumes statistical independence of quantization noise across layers.
*   **Performance Modeling:** To accurately predict performance, the computation graph is partitioned into sequential sub-graphs to account for compiler fusion and parallelism.
*   **Empirical Measurement:** The system utilizes Empirical Time Gain ($c_{ET}$) measured on hardware rather than theoretical operation counts.
*   **Calibration Process:** Requires forward and backward passes on a dataset without weight optimization.

---

## Experimental Results

Experiments conducted on the **LLAMA-3.1-8B** model yielded the following insights:

*   **Sub-graph Validation:** The sub-graph partitioning strategy was validated, revealing that summing per-layer time measurements fails to predict actual sub-graph execution time due to hardware concurrency and fusion.
*   **Quantization Patterns:** The proposed IP-ET approach produced a non-uniform quantization pattern (mixing BF16 and FP8) distinct from 'Prefix' and 'Random' baselines.
*   **Model Accuracy:** The study confirmed the accuracy of the loss MSE estimation model.
*   **Additivity:** Both loss MSE and empirical time gain were confirmed to behave as additive properties across defined groups.
*   **Pareto Frontier:** Successfully demonstrated a Pareto frontier balancing loss MSE against Empirical Time Gain on the Intel Gaudi 2 accelerator.

---

## Research Contributions

*   **Efficient Sensitivity Metric:** A computationally efficient, additive metric for estimating layer-wise sensitivity to quantization errors derived from Taylor series expansion, requiring only high-precision passes over a calibration set.
*   **Sequential Sub-graph Time Modeling:** A hardware-aware technique for predicting time gain by partitioning the model into sequential sub-graphs, enabling precise measurement of configuration performance with minimal sampling.
*   **Optimization Framework for PTQ:** A comprehensive Integer Programming framework for Post-Training Quantization (PTQ) that jointly optimizes for theoretical (MAC-based) and practical (hardware-measured) time gains while enforcing accuracy constraints.

---

**Quality Score:** 7/10  
**References:** 31 citations