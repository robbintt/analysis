# GABFusion: Rethinking Feature Fusion for Low-Bit Quantization of Multi-Task Networks

*Zhaoyang Wang; Dong Wang*

***

> **ðŸ“Š Quick Facts: Key Metrics & Details**
>
> *   **Performance Gain:** +3.3% mAP (PASCAL VOC) / +1.6% mAP (COCO)
> *   **Efficiency:** Reduces accuracy gap to full-precision model to just **1.7%** (YOLOv5s W4A4)
> *   **Low-Bit Support:** Effective at **W4A4** and **W3A3** configurations
> *   **Compatibility:** Plug-and-play with N2UQ, PACT, LSQ, LSQ+
> *   **Hardware:** Validated on NVIDIA RTX 4090 GPUs
> *   **Architecture:** Tested on YOLOv5s and YOLOv11s

***

## Executive Summary

**Problem**
This research addresses the significant performance degradation that occurs when applying low-bit quantization to multi-task networks, particularly object detection architectures like YOLO. As the demand for deploying deep learning models on edge devices grows, minimizing model size through quantization (e.g., 4-bit or 3-bit weights and activations) is essential. However, existing Quantization-Aware Training (QAT) methods struggle in multi-task scenarios due to gradient conflicts between tasks and the collapse of feature representations under extreme quantization noise. This limitation creates a substantial accuracy gap between quantized and full-precision models, hindering the practical adoption of efficient multi-task vision systems.

**Innovation**
The authors propose **GABFusion**, a modular, plug-and-play framework designed to optimize feature fusion specifically for low-bit environments. The core innovation consists of two synergistic components:
*   **Gradient-Aware Balanced Feature Fusion (GABFusion):** Dynamically balances gradient magnitudes and fuses task-specific features to be quantization-friendly.
*   **Attention Distribution Alignment (ADA):** A specialized feature-level distillation strategy aligning quantized student models with full-precision teachers.

Crucially, this framework integrates into existing pipelines without requiring architectural changes to the backbone network.

**Results**
The methodology demonstrates significant empirical improvements across standard benchmarks and varying bit-widths:
*   **PASCAL VOC:** +3.3% average mAP improvement.
*   **YOLOv5s (W4A4):** AP50 increased from 82.1% to 84.2%, narrowing the gap to full precision (85.9%) to just 1.7%.
*   **YOLOv5s (W3A3):** Recovered LSQ+ performance by +8.3% (from 54.2% to 62.5%).
*   **COCO:** Achieved a consistent average mAP improvement of 1.6%.

**Impact**
The significance of this work lies in its broad generalizability and theoretical validation of gradient bias reduction. By delivering a "plug-and-play" solution compatible with dominant QAT methods and architectures, GABFusion offers a versatile tool for deploying high-performance, low-bit multi-task networks on resource-constrained hardware without sacrificing accuracy.

***

## Key Findings

*   **Significant Performance Boosts:** The proposed strategy achieved an average mean Average Precision (mAP) improvement of approximately **3.3%** on the PASCAL VOC dataset and **1.6%** on the COCO dataset.
*   **Effective Low-Bit Quantization:** When applied to YOLOv5 under 4-bit quantization, the method narrowed the accuracy gap with the full-precision model to just **1.7%** on VOC, demonstrating high efficiency in preserving performance.
*   **Broad Generalizability:** The framework consistently enhanced a wide variety of existing Quantization-Aware Training (QAT) methods across different network architectures and varying bit-widths.
*   **Theoretical Validation:** The method provides theoretical guarantees regarding the reduction of gradient bias, validating the mechanism behind its effectiveness.

***

## Methodology

The research proposes a **modular framework** designed to optimize multi-task networks for low-bit quantization without altering the original network architecture. The core methodology consists of two novel components:

1.  **Gradient-Aware Balanced Feature Fusion (GABFusion):** This component dynamically balances gradient magnitudes and fuses task-specific features to be quantization-friendly, specifically addressing gradient conflicts inherent in multi-task learning.
2.  **Attention Distribution Alignment (ADA):** A feature-level distillation strategy tailored for quantized models. ADA maintains high-quality feature representations by aligning the attention distributions of the quantized model with its full-precision counterpart.

***

## Contributions

*   **Novel Fusion Mechanism:** Introduction of **GABFusion** to solve specific degradation issues in multi-task quantization by managing gradient conflicts and feature fusion in a quantization-aware manner.
*   **Specialized Distillation Strategy:** Development of **ADA**, a targeted distillation approach for aligning attention distributions in low-bit environments.
*   **Universal Compatibility:** Delivery of a 'plug-and-play' solution that integrates seamlessly with existing QAT techniques, enhancing their performance without requiring architectural changes.

***

## Technical Specifications & Results

### Implementation Details
*   **Nature of Approach:** Plug-and-play enhancement for feature fusion in multi-task networks.
*   **Objective:** Balance feature gradient distributions and mitigate quantization noise.
*   **Settings:** Low-bit configurations (W4A4, W3A3).
*   **Integration:** Validated on N2UQ, PACT, LSQ, and LSQ+ pipelines.
*   **Tested Architectures:** YOLOv5s and YOLOv11s.
*   **Hardware:** NVIDIA RTX 4090 GPUs.

### Performance Breakdown

| Dataset | Model / Quantization | Metric | Improvement | Result |
| :--- | :--- | :--- | :--- | :--- |
| **PASCAL VOC** | Average | AP50 (W4A4) | **+2.4%** | â€“ |
| | Average | AP50 (W3A3) | **+3.9%** | â€“ |
| | **Abstract Average** | mAP | **+3.3%** | â€“ |
| **YOLOv5s (W4A4)** | N2UQ Method | AP50 | **+2.1%** | 82.1% $\to$ 84.2% |
| | vs. Full Precision | Gap | **Reduced to** | **1.7%** |
| **YOLOv11s (W4A4)** | N2UQ Method | AP50 | **+1.2%** | 86.2% $\to$ 87.4% |
| **YOLOv5s (W3A3)** | LSQ+ Method | AP50 | **+8.3%** | 54.2% $\to$ 62.5% |
| **COCO** | **Abstract Average** | mAP | **+1.6%** | â€“ |

***

**Quality Score:** 9/10  
**References:** 10 citations