# Self-Composing Policies for Scalable Continual Reinforcement Learning
*Mikel Malag√≥n; Josu Ceberio; Jose A. Lozano*

---

<div align="center">

### üìä Quick Facts & Metrics

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | **9/10** |
| **References** | 40 Citations |
| **Architecture Type** | Growable Modular Neural Network |
| **Optimization** | Soft Actor-Critic (SAC) |
| **Hardware** | AMD EPYC 7252 CPUs; NVIDIA A5000 GPUs |
| **Benchmarks** | Meta-World (20 tasks), Arcade Learning Environment (ALE) |
| **Key Innovation** | Self-composing policies via Cascading Graph Structure |

</div>

---

## üìù Executive Summary

Continual Reinforcement Learning (CRL) faces a fundamental challenge known as the **stability-plasticity dilemma**: agents must maintain high performance on previously learned tasks (stability) while successfully acquiring new skills (plasticity). In standard neural network architectures, this typically leads to **catastrophic forgetting**, where the optimization process for a new task overwrites the knowledge required for old ones. Furthermore, existing continual learning solutions often rely on computationally expensive regularization techniques or suffer from inefficient parameter expansion, scaling quadratically or exponentially with the number of tasks.

This paper addresses this bottleneck by introducing an architecture designed specifically to mitigate interference and memory constraints. The authors introduce a growable, modular neural network architecture that utilizes **"self-composing policies"** to manage knowledge transfer dynamically. Unlike static networks, this system constructs a cascading graph structure with dynamic depth, adding a distinct policy module for each new task encountered.

The proposed method was evaluated using Soft Actor-Critic (SAC) optimization on continuous control and visual benchmarks. The architecture achieved **linear parameter growth**, significantly outperforming ProgressiveNet in efficiency while scaling to over 200 tasks. This research significantly advances the field of continual learning by resolving the long-standing trade-off between model scalability and knowledge retention, establishing a new standard for efficient CRL architectures.

---

## üîë Key Findings

*   **Mitigation of Catastrophic Forgetting:** The proposed architecture naturally mitigates catastrophic forgetting and interference *without* requiring specific regularization techniques.
*   **Accelerated Learning:** The system demonstrates accelerated learning on new tasks by selectively combining and reusing knowledge from previous policies.
*   **Parameter Efficiency:** Achieves parameter efficiency with **linear growth** relative to the number of tasks, explicitly avoiding exponential or unbounded expansion.
*   **Sustained Plasticity:** The model retains high plasticity (the ability to learn new information) even as it scales to accommodate a larger number of tasks.
*   **Benchmark Superiority:** In tests involving continuous control (Meta-World) and visual problems (ALE), the method outperformed alternative approaches in both knowledge transfer and overall performance.

---

## üõ†Ô∏è Methodology

The authors propose a **growable and modular neural network architecture** designed specifically for continual reinforcement learning.

*   **Selective Combination:** Each module within the network is structured to perform a selective combination of policies. It integrates the agent's internal policy for the current task with relevant previous policies.
*   **Dynamic Expansion:** This self-composing capability allows the network to dynamically expand and leverage historical knowledge to solve new tasks efficiently.
*   **Architecture:** The system employs a **cascading graph structure** with dynamic depth. A new policy module is added for each task $k$.
*   **Recursive Definition:** Policies are defined recursively using a matrix $\Phi_{k;s}$ that aggregates outputs from preceding modules.

---

## üöÄ Contributions

1.  **Scalable Architecture:**
    Introduction of a modular neural network design that scales **linearly** with the number of tasks, solving a critical bottleneck in parameter efficiency for growing networks.

2.  **Stability-Plasticity Balance:**
    A novel solution that maintains model plasticity (learning capability) while ensuring stability (avoiding catastrophic forgetting), addressing the central challenge in continual learning.

3.  **Enhanced Knowledge Transfer:**
    A mechanism for policy composition that facilitates greater knowledge transfer between tasks compared to existing state-of-the-art methods, validated on continuous control and visual benchmarks.

---

## ‚öôÔ∏è Technical Specifications

### Architecture Components
Each module in the cascading graph consists of three primary components:
*   **Output Attention Head:** Manages the integration of outputs.
*   **Input Attention Head:** Manages the integration of inputs.
*   **Internal Policy:** The specific policy learned for the current task.

### State Encoding Strategies
The system utilizes distinct encoding strategies based on input dimensionality:
*   **Low-dimensional vectors:** No encoder used.
*   **Standard Images (ALE):** A per-module CNN is employed.
*   **High-dimensional tasks:** A shared frozen encoder is used.

### Configuration & Hyperparameters
*   **Encoder Dimension:** 64
*   **Model Dimension:** 256
*   **Batch Size:** 8
*   **Tasks Tested:** Up to 200+ tasks in comparison tests.

---

## üìà Experimental Results

Experiments utilized **Soft Actor-Critic (SAC)** optimization to validate the approach.

**Benchmarks:**
*   **Continuous Control:** 20 Meta-World robotic arm tasks.
*   **Visual Control:** Arcade Learning Environment (ALE) tasks.

**Metrics:**
*   **Forward Transfer ($FTr$)**
*   **Reference Forward Transfer ($RT$)**
*   **Average Performance**
*   **Matching Rate:** Used to quantify reliance on internal policies.

**Outcomes:**
*   **Efficiency:** Achieved lower total parameters and inference time compared to ProgressiveNet.
*   **Scalability:** Successfully maintained linear parameter growth up to 200+ tasks.
*   **Performance:** Demonstrated superior knowledge transfer while maintaining high plasticity and stability.