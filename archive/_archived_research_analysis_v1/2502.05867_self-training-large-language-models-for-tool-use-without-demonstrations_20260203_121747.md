---
title: Self-Training Large Language Models for Tool-Use Without Demonstrations
arxiv_id: '2502.05867'
source_url: https://arxiv.org/abs/2502.05867
generated_at: '2026-02-03T12:17:47'
quality_score: 8
citation_count: 30
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Self-Training Large Language Models for Tool-Use Without Demonstrations

*Ne Luo; Aryo Pradipta Gema; Xuanli He; Emile van Krieken; Pietro Lesci; Pasquale Minervini*

---

> ### ðŸ“Š Quick Facts
>
> *   **Base Model Used:** Llama-3-8B-Instruct
> *   **Primary Gain:** +3.7% improvement on PopQA
> *   **Core Technique:** Self-training via Synthetic Traces
> *   **Fine-Tuning Methods:** Supervised Fine-Tuning (SFT) & Direct Preference Optimization (DPO)
> *   **Tools Integrated:** Calculator, Wikipedia Search, Machine Translator
> *   **Quality Score:** 8/10

---

## Executive Summary

### The Problem
A significant bottleneck in developing tool-augmented Large Language Models (LLMs) is the dependency on expensive, human-annotated "gold" demonstrations to teach models how to effectively utilize external tools. As LLMs are increasingly integrated with APIs and search engines to mitigate hallucinations and access real-time information, the cost and effort required to curate high-quality training data for these interactions become unsustainable. This paper addresses the challenge of scaling tool-use capabilities by investigating whether LLMs can learn to utilize tools without relying on these manually crafted demonstrations.

### The Innovation
The authors introduce a self-training framework that enables LLMs to autonomously synthesize their own tool-use traces, removing the need for human intervention. The pipeline utilizes a base Llama-3-8B-Instruct model to generate training data by interacting with a suite of toolsâ€”including a Calculator, a BM25-based Wikipedia Search Engine, and a Machine Translatorâ€”using Zero-Shot Tool-Use and Chain-of-Thought prompting. To ensure data quality, the system filters these self-generated traces based on the correctness of the final answer. The study further compares the efficacy of two fine-tuning approaches on this synthetic data: standard Supervised Fine-Tuning (SFT) and Preference Fine-Tuning via Direct Preference Optimization (DPO).

### The Results
Empirical evaluation demonstrates that self-synthesized traces are a viable substitute for human-curated data, particularly for tasks involving long-tail knowledge retrieval. The proposed method achieved a **3.7% improvement on the PopQA dataset**, a benchmark specifically designed to test knowledge on less popular entities. However, the impact of tool-use was not uniform across all domains; the study reported mixed results on other standard benchmarks, including TriviaQA, GSM8K, and NQ-Open. These findings suggest that while self-training effectively enhances the model's ability to retrieve obscure facts, the benefits for general mathematical or common-sense reasoning are less consistent.

### The Impact
This research significantly influences the field by validating a scalable, automated alternative to the labor-intensive process of creating tool-use demonstrations. By proving that LLMs can successfully bootstrap their own tool-using capabilities through self-training and correctness-based filtering, the work lowers the barrier to developing advanced tool-augmented systems. Furthermore, the paper provides critical insight into the specific utility of tools, highlighting that they are most effective for long-tail knowledge retrieval while offering variable gains in broader reasoning tasks. This distinction helps guide future research in targeting tool integration where it delivers the highest marginal value.

---

## Key Findings

*   **Demonstration-Free Learning:** LLMs possess the capability to learn tool utilization without the need for curated gold tool-use demonstrations.
*   **Performance Boost:** The integration of external tools significantly enhances performance on long-tail knowledge tasks, yielding a **3.7% improvement on the PopQA dataset**.
*   **Mixed General Results:** The tool-use approach led to mixed results on other standard benchmarks, including TriviaQA, GSM8K, and NQ-Open.
*   **Viable Self-Training:** The proposed method of synthesizing tool-use traces via self-training proves to be a viable strategy for enabling tool integration without human annotation.

---

## Methodology

The research methodology followed a multi-step process to validate the efficacy of self-trained tool usage:

1.  **Zero-Shot Analysis:** Researchers first analyzed zero-shot prompting strategies to determine how well LLMs can utilize tools based solely on instructions, without prior examples.
2.  **Self-Training Proposal:** A self-training method was proposed where the LLM autonomously synthesizes its own tool-use traces, removing the dependency on human-annotated demonstrations.
3.  **Fine-Tuning Comparison:** The study compared two specific fine-tuning techniques applied to the self-trained data:
    *   Supervised Fine-Tuning (SFT)
    *   Preference Fine-Tuning (PFT)
4.  **Dataset Construction:** Training datasets were constructed by augmenting existing Question Answering datasets (TriviaQA and GSM8K) with tool interactions. Notably, PopQA was used solely for evaluation purposes to test generalization.

---

## Technical Details

**Framework & Pipeline**
The paper proposes a self-training framework designed to eliminate the need for curated demonstrations. The pipeline involves four distinct stages:
*   Tool collection
*   QA data selection
*   Data generation (using a base LLM)
*   Data filtering (based on answer correctness)

**Tool Suite**
The model was integrated with the following external tools:
*   **Calculator:** For mathematical operations.
*   **Search Engine:** A BM25-based Wikipedia Search Engine using the `wikipedia-kilt-doc` resource.
*   **Translator:** A Machine Translator utilizing the Distilled NLLB model (`facebook/nllb-200-distilled-600M`).

**Training Configuration**
*   **Base Model:** Llama-3-8B-Instruct
*   **Optimization Techniques:** Supervised Fine-Tuning (SFT) and Preference Fine-Tuning (PFT) via Direct Preference Optimization (DPO).

**Prompting Strategy**
The system employs a structured prompting strategy requiring a specific response format containing:
*   **Thought**
*   **Action**
*   **Rationale**
*   **Answer**

This utilized both Zero-Shot Tool-Use and Zero-Shot Chain-of-Thought (CoT) techniques.

---

## Contributions

*   **Eliminating Bottlenecks:** Addresses a major bottleneck in tool-augmented LLMs by proving that expensive, curated gold demonstrations are not strictly necessary for learning tool-use.
*   **Scalable Framework:** Introduces a framework for tool-use that relies on the model's ability to generate synthetic training data (traces), offering a scalable alternative to manual annotation.
*   **Empirical Analysis:** Provides a detailed empirical analysis of how tool-use impacts different types of reasoning (factual vs. mathematical), highlighting that benefits are pronounced in long-tail knowledge retrieval but less consistent in general domains.

---

## Results Summary

The evaluation of the proposed self-training framework yielded the following conclusions:

*   **PopQA Success:** The approach yielded a **+3.7% improvement** on PopQA, highlighting significant gains in long-tail knowledge retrieval.
*   **Benchmark Variability:** Results on other standard benchmarks like TriviaQA, GSM8K, and NQ-Open were mixed, indicating the method is not universally applicable across all reasoning types.
*   **Validation of Self-Training:** The study confirmed that synthesizing tool-use traces via self-training is a viable strategy that removes the need for manually curated gold demonstrations.
*   **Filtering Effectiveness:** It was determined that final answer correctness is an effective proxy for filtering valid traces during the training generation phase.

---

## Report Metadata

*   **Quality Score:** 8/10
*   **References:** 30 citations