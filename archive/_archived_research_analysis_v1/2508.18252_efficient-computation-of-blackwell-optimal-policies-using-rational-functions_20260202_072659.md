# Efficient Computation of Blackwell Optimal Policies using Rational Functions

*Dibyangshu Mukherjee; Shivaram Kalyanakrishnan*

***

### üìä Quick Facts

| Metric | Details |
| :--- | :--- |
| **Quality Score** | 9/10 |
| **References** | 40 Citations |
| **Algorithm Type** | Symbolic / Rational Functions |
| **Key Result** | First strongly polynomial-time algorithm for Deterministic MDPs & first subexponential-time algorithm for general MDPs |

***

## Executive Summary

### üö® Problem
Blackwell optimality identifies policies that maximize rewards for all discount factors simultaneously, representing the "true" long-term optimal solution. However, computing these policies has been hindered by the limitations of standard numerical algorithms like Value Iteration and Policy Iteration. These methods face a critical dual limitation: their runtimes scale geometrically with the planning horizon (inversely proportional to $1-\gamma$), and they suffer from numerical instability as the discount factor $\gamma$ approaches 1. Specifically, numerical precision issues cause these algorithms to fail to distinguish between policies when $\gamma$ exceeds a threshold of approximately $1 - 10^{-17}$. Furthermore, prior theoretical bounds on the threshold $\gamma_{bw}$ required to identify Blackwell optimal policies have been excessively conservative‚Äîranging as low as $1 - O(10^{-66})$‚Äîrendering exact computation theoretically intractable due to bit-complexity dependence.

### üí° Innovation
The authors address these limitations by introducing a novel **symbolic framework** that abandons scalar numerical evaluation in favor of symbolic algebra. The methodology treats value functions not as numbers, but as **rational functions** of the discount factor $\gamma$. By applying Cramer's rule, these functions are expressed as ratios of determinants, allowing the authors to establish a rational ordering that precisely compares policies without evaluating them at specific scalar values. This symbolic manipulation eliminates the numerical instabilities associated with finite precision. Building on this foundation, the authors generalize existing algorithms: they adapt the Max-Gain simplex method for deterministic MDPs and the Random-Facet algorithm for general MDPs, replacing their standard numerical components with these robust symbolic operations to navigate the policy space.

### üìà Results
This research establishes the **first strongly polynomial-time algorithm** for computing Blackwell optimal policies in deterministic MDPs, achieving a complexity of $O(n^5 k^2 \log^2 n)$ or $O(n^2 k)$ depending on the adaptation. For general MDPs, the paper presents the **first subexponential-time algorithm**, with an expected bound of $poly(n, k) \cdot \exp(O(\sqrt{n \log n}))$. Crucially, these complexity bounds are derived independently of bit complexity, resolving the theoretical bottleneck associated with numerical precision. The authors prove an exponential lower bound on the threshold discount factor, $\gamma_{bw} \ge 1 - O(2^{-n/3})$. This demonstrates that the symbolic approach remains effective in problem domains where standard numerical methods fail completely, whereas prior theoretical bounds were as conservative as $1 - O(10^{-66})$ and practical numerical methods fail around $1 - 10^{-17}$.

### üåç Impact
This work represents a significant theoretical breakthrough in the complexity theory of Markov Decision Processes, successfully narrowing the gap between the complexity of the discounted reward criterion and the Blackwell criterion. By establishing strongly polynomial and subexponential bounds independent of bit complexity, the study resolves the long-standing question of whether Blackwell optimal policies can be computed without succumbing to the precision constraints of numerical methods. While the approach is primarily a theoretical advancement rather than an immediate practical tool for large-scale systems, it fundamentally changes the understanding of computational limits in optimal control, proving that exact Blackwell optimality is computationally feasible within rigorous, precision-independent time bounds.

***

## Key Findings

*   **Algorithmic Breakthrough:** Established the first **strongly polynomial-time algorithm** for computing Blackwell Optimal (BO) policies in deterministic Markov Decision Problems (MDPs).
*   **General MDP Solution:** Presented the first **subexponential-time algorithm** for computing BO policies in general (stochastic) MDPs.
*   **Independence from Bit Complexity:** Derived bounds independent of bit complexity by utilizing symbolic operations on rational functions, avoiding pitfalls of finite-precision arithmetic.
*   **Generalized Iteration:** Generalized policy iteration algorithms, extending the best known upper bounds from the discounted reward criterion to the Blackwell criterion.

***

## Methodology

The proposed methodology shifts away from traditional numerical evaluations in favor of a **symbolic approach**.

*   **Core Technique:** Computing Blackwell Optimal policies through the ordering of rational functions in the vicinity of 1.
*   **Adaptation:** The authors adapt existing state-of-the-art algorithms for both deterministic and general MDPs.
*   **Implementation:** Replacing standard numerical calculations with symbolic operations on these rational functions to ensure robustness against numerical instability.

***

## Contributions

*   **Computational Feasibility:** Addressed the computational intractability of Blackwell optimality by providing the first strongly polynomial (for deterministic) and subexponential (for general) time algorithms.
*   **Framework Generalization:** Extended policy iteration algorithms, specifically adapting the Max-Gain simplex and Random-Facet algorithms to support the Blackwell criterion.
*   **Complexity Gap Narrowing:** Narrowed the theoretical gap in complexity bounds between discounted and Blackwell optimality frameworks, proving that BO policies can be computed efficiently.

***

## Technical Details

The paper introduces a framework for computing Blackwell Optimal (BO) policies by treating value functions as symbolic rational functions of the discount factor $\gamma$, rather than as scalar values.

**Mathematical Foundation**
*   Uses **Cramer's rule** to represent value functions as ratios of determinants ($v_s = n_s / d$) and expresses Q-values vectorially.
*   The core innovation involves establishing a **rational ordering** over these functions to determine optimality without numerical evaluation.

**Algorithmic Adaptations**
*   **Deterministic MDPs:** Extended the Max-Gain simplex algorithm and Madani et al.'s algorithm to achieve strongly polynomial time bounds.
    *   *Complexity:* $O(n^5 k^2 \log^2 n)$ or $O(n^2 k)$.
*   **General MDPs:** Developed a direct policy improvement procedure combined with the **Random-Facet** algorithm.
    *   *Complexity:* Subexponential expected bound of $poly(n, k) \cdot \exp(O(\sqrt{n \log n}))$.

**Threshold Definitions**
*   Defined threshold discount factors $\gamma_{bw}$ and $\gamma_Q$.
*   Constructed a lower bound: $\gamma_{bw} \ge 1 - O(2^{-n/3})$.

***

## Results

The study highlights the failures of standard numerical methods and validates the proposed symbolic approach:

*   **Failure of Numerical Methods:** Standard methods (Value Iteration, Policy Iteration, Linear Programming) fail to converge when the discount factor exceeds a failure threshold $\gamma_{fail} \approx 1 - 10^{-17}$.
*   **Runtime Scaling:** Value iteration runtime scales roughly as $1 / (1 - \gamma)$, making it practically useless for $\gamma$ close to 1.
*   **Conservative Previous Bounds:** Existing theoretical bounds were shown to be excessively conservative. In one instance, the actual threshold was $0.8541$, while the previous bound was $1 - O(10^{-66})$.
*   **Exponential Lower Bound:** The paper establishes an exponential lower bound on the threshold discount factor, $\gamma_{bw} \ge 1 - O(2^{-n/3})$.
*   **Solvability:** Demonstrates that the proposed rational function approach succeeds in solving problems that are intractable for standard numerical algorithms.