---
title: 'SpatialScore: Towards Comprehensive Evaluation for Spatial Intelligence'
arxiv_id: '2505.17012'
source_url: https://arxiv.org/abs/2505.17012
generated_at: '2026-02-03T12:33:14'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# SpatialScore: Towards Comprehensive Evaluation for Spatial Intelligence

*Haoning Wu; Xiao Huang; Yaohui Chen; Ya Zhang; Yanfeng Wang; Weidi Xie*

---

> ### üìä Quick Facts
>
> * **Quality Score:** 8/10
> * **Total Citations:** 40
> * **Models Evaluated:** 40 Representative MLLMs
> * **Benchmark Scale:** 5,000 manually verified samples across 30 tasks
> * **Training Dataset:** 331,000 multimodal QA samples

---

## üìã Executive Summary

This research addresses the critical deficiency in spatial intelligence within current Multimodal Large Language Models (MLLMs). While MLLMs have achieved parity with humans in many linguistic and general visual tasks, they struggle significantly to understand and reason about spatial relationships‚Äîsuch as depth, orientation, and relative position‚Äîwhich is fundamental for real-world applications like robotics, autonomous navigation, and complex scene understanding. The authors identify that the field's progress is hindered by fragmented and limited evaluation standards, which fail to provide a holistic view of model capabilities, thereby obscuring the true extent of the performance gap between state-of-the-art models and human-level intelligence.

The paper proposes a holistic ecosystem to evaluate and enhance spatial reasoning through three integrated components:

1.  **SpatialScore:** A rigorous benchmark comprising 5,000 manually verified samples across 30 distinct tasks and multiple visual data types.
2.  **SpatialCorpus:** A large-scale dataset of 331,000 multimodal question-answer pairs designed for Supervised Fine-Tuning (SFT) to embed spatial knowledge directly into model weights.
3.  **SpatialAgent:** A training-free solution utilizing a multi-agent system equipped with 12 specialized spatial perception tools, employing Plan-Execute and ReAct reasoning paradigms to solve problems dynamically without requiring model weight updates.

The study conducted an extensive evaluation of 40 representative MLLMs, confirming a substantial disparity between current model capabilities and human-level spatial intelligence. The results demonstrate that existing evaluations are indeed fragmented, failing to capture the breadth of spatial reasoning deficits. However, the proposed interventions proved effective: fine-tuning models with the SpatialCorpus (e.g., Qwen3-VL) yielded significant improvements on spatial tasks, while the SpatialAgent framework achieved substantial gains in reasoning accuracy purely through tool utilization and agentic workflows, circumventing the need for costly additional training.

This work significantly advances the field by establishing the most comprehensive and diverse benchmark for multimodal spatial intelligence to date. By releasing the SpatialScore benchmark and the SpatialCorpus dataset, the authors provide the community with essential, standardized resources for future research and model development. The introduction of SpatialAgent further offers a novel, cost-effective pathway to enhance spatial reasoning without retraining, suggesting that agentic frameworks are vital for closing the gap between artificial and human spatial understanding. Collectively, these contributions lay a foundational framework for the evolution of spatially intelligent AI systems.

---

## üîç Key Findings

*   **Significant Performance Gap:** Extensive evaluation of 40 representative Multimodal Large Language Models (MLLMs) revealed a substantial gap between current model capabilities and human-level spatial intelligence.
*   **Efficacy of Fine-Tuning:** Fine-tuning existing models using the proposed **SpatialCorpus** significantly improves performance on spatial reasoning tasks.
*   **Training-Free Optimization:** The **SpatialAgent** framework achieves substantial gains in spatial reasoning without requiring additional model training.
*   **Fragmented Evaluations:** Existing evaluations of MLLMs on spatial intelligence were found to be fragmented and limited in scope.

---

## ‚öôÔ∏è Technical Details

The paper proposes an ecosystem for evaluating spatial intelligence in MLLMs consisting of three distinct components:

*   **SpatialScore**
    *   **Type:** Benchmark
    *   **Scale:** ~5,000 manually verified samples
    *   **Scope:** Covers 30 distinct tasks and multiple visual data types.

*   **SpatialCorpus**
    *   **Type:** Training Resource
    *   **Scale:** 331,000 multimodal QA samples
    *   **Application:** Used for Supervised Fine-tuning (SFT) of models (e.g., Qwen3-VL).

*   **SpatialAgent**
    *   **Type:** Multi-Agent System
    *   **Mechanism:** Training-free system equipped with 12 specialized spatial perception tools.
    *   **Reasoning:** Supports Plan-Execute and ReAct reasoning strategies.

---

## üõ†Ô∏è Methodology

The research adopts a three-pronged holistic methodology:

1.  **Comprehensive Benchmarking**
    *   Involves the construction of **SpatialScore**.
    *   Utilizes 5K manually verified samples.
    *   Covers 30 distinct tasks to ensure diversity and rigor.

2.  **Data-Driven Enhancement**
    *   Creation of **SpatialCorpus**.
    *   A large-scale training resource consisting of 331K multimodal QA samples.
    *   Designed to improve model intrinsic knowledge via fine-tuning.

3.  **Agent-Based Optimization**
    *   Development of **SpatialAgent**.
    *   A training-free multi-agent system.
    *   Equipped with 12 specialized tools utilizing Plan-Execute and ReAct reasoning paradigms.

---

## üìà Results

*   **Evaluation Scope:** The study evaluated 40 representative MLLMs.
*   **Human Comparison:** Found a substantial gap between current model capabilities and human-level spatial intelligence.
*   **Evaluation Critique:** Results indicate that existing evaluations are fragmented.
*   **SpatialCorpus Impact:** Significantly improves performance on spatial reasoning tasks when used for fine-tuning (e.g., Qwen3-VL).
*   **SpatialAgent Impact:** Achieves substantial gains in spatial reasoning without the need for additional model training.

---

## ‚ú® Contributions

*   **SpatialScore Benchmark:** Introduction of the most comprehensive and diverse benchmark for multimodal spatial intelligence to date.
*   **SpatialCorpus Release:** Release of a large-scale 331K sample multimodal QA dataset for fine-tuning.
*   **SpatialAgent Framework:** Development of a novel training-free multi-agent system integrating specialized tools with advanced reasoning strategies.
*   **Critical Insights:** Extensive evaluation of 40 state-of-the-art MLLMs, providing critical insights into current limitations and progression relative to human performance.