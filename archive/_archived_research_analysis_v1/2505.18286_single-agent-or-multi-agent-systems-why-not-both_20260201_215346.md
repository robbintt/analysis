# Single-agent or Multi-agent Systems? Why Not Both?

*Mingyan Gao; Yanzi Li; Banruo Liu; Yifan Yu; Phillip Wang; Ching-Yu Lin; Fan Lai*

| **Quick Facts** | |
|:---|:---|
| **Quality Score** | 6/10 |
| **References** | 40 citations |
| **Models Evaluated** | GPT-4, GPT-4o, Gemini-2.5-Pro, Gemini-2.5-Flash, Gemini-2.0-Flash, Gemini-2.0-Pro, Gemini-1.5-Flash, Llama-3-70B-Instruct, Llama-4 |
| **Experimental Scope** | 15 tasks across 7 domains (Code Generation, Software Engineering, Mathematical Reasoning, Travel Planning, Financial Analysis, RAG-based QA, Scientific Discovery) |
| **Key Innovation** | **Request Cascading** — Dynamic hybrid routing between SAS and MAS |
| **Performance Impact** | **1.1–12%** accuracy improvement over pure implementations |
| **Cost Efficiency** | **Up to 20%** deployment cost reduction |
| **Critical Threshold** | MAS advantages diminish to **<3%** when base models achieve ~90% single-agent accuracy |

---

## Executive Summary

Frontier large language models (LLMs) such as OpenAI-o3 and Gemini-2.5-Pro now possess native long-context reasoning, persistent memory, and autonomous tool use—capabilities previously achievable only through multi-agent system (MAS) architectures. While MAS offered substantial accuracy gains over single-agent systems (SAS) on older models like GPT-4—improving performance by **10.7–16.0%** on coding tasks—these advantages collapse to marginal improvements of merely **1.2–3.0%** when using frontier models. 

This creates a significant efficiency concern: organizations now face **5–220× higher token costs** and increased architectural overhead for accuracy gains that often fall below 3%, suggesting that static MAS deployments may no longer justify their operational expenses for many production workloads.

To address this misalignment, the authors propose **request cascading**, a hybrid routing paradigm that dynamically dispatches tasks to either SAS or MAS based on real-time complexity assessment. By modeling execution as a directed graph and leveraging **error attribution engineering**—a diagnostic technique that isolates failures to specific individual agents—the architecture enables targeted remediation of defective sub-components without holistic system redesign. Empirical evaluation confirms this approach simultaneously achieves superior accuracy while resolving the traditionally antagonistic relationship between performance and efficiency.

---

## Key Findings

- **Diminishing Returns of Multi-Agent Architectures**  
  The accuracy advantages of MAS over SAS attenuate significantly as frontier LLMs (e.g., OpenAI-o3, Gemini-2.5-Pro) advance in native long-context reasoning, memory retention, and autonomous tool usage—capabilities that originally necessitated decomposed multi-agent designs.

- **Cost-Accuracy Tradeoff Intensification**  
  While MAS enables superior long-horizon context tracking and error correction through role-specific delegation, these benefits incur substantially higher architectural complexity and runtime costs compared to SAS, creating an increasingly unfavorable efficiency-capability tradeoff as base model capabilities improve.

- **Error Localization Feasibility**  
  Systematic mechanisms can efficiently pinpoint specific error-prone agents within complex MAS workflows, enabling targeted remediation of individual sub-components rather than necessitating holistic system redesign.

- **Hybrid Superiority Over Pure Paradigms**  
  A request cascading approach—dynamically routing tasks between MAS and SAS based on complexity and error profiles—outperforms pure implementations of either architecture, simultaneously achieving accuracy improvements of **1.1–12%** while reducing deployment costs by up to **20%** across diverse agentic applications.

---

## Methodology

The study employed four main analytical approaches:

1. **Large-Scale Empirical Comparative Analysis**  
   Extensive benchmarking of MAS versus SAS performance across multiple real-world agentic application domains to quantify capability differentials under current frontier LLM conditions.

2. **Capability Obsolescence Assessment**  
   Analysis of state-of-the-art frontier model specifications (OpenAI-o3, Gemini-2.5-Pro) to evaluate whether traditional MAS design motivations—specifically limitations in context windows, memory persistence, and tool-use reliability—remain valid constraints or have been mitigated by base model advances.

3. **Error Attribution Engineering**  
   Development of diagnostic techniques to attribute system-level failures to specific individual agents within multi-agent architectures, facilitating granular error profiling.

4. **Hybrid Architecture Design & Validation**  
   Engineering and evaluation of a request cascading system implementing dynamic task decomposition strategies, selectively applying MAS for complex, error-sensitive subtasks while defaulting to SAS for straightforward operations.

---

## Technical Details

### Graph-Based Formalization of Agentic Systems

Execution is modeled as a directed graph $G = (V, E)$ where:

- **Vertices**: $V = V_{llm} \cup V_{tool}$ (nodes represent LLM agents or external tools)
- **Edges**: $e_{i,j} = (v_i, v_j, w_{i,j})$ represent dependencies with message $w_{i,j}$ passed from $v_i$ to $v_j$
- **Self-reflection**: Loops represented as $e_{i,i}$

**System Definitions:**
- **SAS**: $\{G(V,E) : |V_{llm}| = 1\}$
- **MAS**: $\{G(V,E) : |V_{llm}| > 1\}$

### Cost Modeling Framework

**Deployment Cost Function:**
$$C(r) = \sum_{e_{i,j} \in E} |w_{i,j}| \times (c_{out}(i) + c_{in}(j))$$

Where:
- $c_{out}$: Output/decoding token costs
- $c_{in}$: Input/prefilling token costs  
- $|w_{i,j}|$: Message length in tokens

**Optimization Objective:** Maximize quality metric $f(G(r))$ (binary $\{0,1\}$ or continuous accuracy) while minimizing $C(r)$.

### Defect Taxonomy (Multi-Agent Failure Analysis)

| **Level** | **Description** | **Empirical Observation** |
|:---|:---|:---|
| **Node-Level** | Performance bottlenecked by capability of critical agent assigned to most challenging subtask | ~80% of cases result in ties (both systems pass/fail together) |
| **Edge-Level** | Coordination breakdowns between agents | Referenced in introduction regarding MAS degradation |
| **Path-Level** | Systemic workflow path failures | Referenced in system overview (Figure 1) |

### Multi-Agent Architectures Evaluated

- **MetaGPT**: Meta-programming framework formalizing human workflows (roles: product manager, architect, developer, tester)
- **ChatDev**: Business-role agents (CEO, CTO, programmer, reviewer, tester) utilizing structured chat chains and "communicative dehallucination"
- **MathDebate**: Multi-agent debate protocols for mathematical reasoning
- **SelfCol**: Self-collaboration frameworks for code generation

### Proposed Hybrid Architecture

**Request Cascading**: Dynamic routing system dispatching tasks to either MAS or SAS based on complexity assessment and error profiles.

**Error Localization**: Systematic mechanisms to identify specific error-prone agents within MAS workflows, enabling targeted remediation of sub-components.

---

## Results

### Experimental Scope
- **15 agentic tasks** across **7 application domains**: Code Generation (4 datasets), Software Engineering (2), Mathematical Reasoning (3), Travel Planning (1), Financial Analysis (3), RAG-based QA (1), Scientific Discovery (1)

### Diminishing Returns of Multi-Agent Systems

Accuracy improvement of MAS over SAS attenuates with stronger base models:

| Dataset | ChatGPT (Legacy) Improvement | Gemini-2.0-Flash (Frontier) Improvement |
|---------|------------------------------|-----------------------------------------|
| **MetaGPT-HumanEval** | **+10.7%** (67.0% → 87.7%) | **+3.0%** (90.2% → 93.2%) |
| **SelfCol-MBPP** | **+16.0%** (52.2% → 68.2%) | **+1.2%** (79.6% → 80.8%) |
| **MathDebate-GSM8K** | **+9.0%** (77% → 85%) | **+0.8%** (93.8% → 94.6%) |

### Token Cost Overhead (MAS vs. SAS Ratios)

MAS incurs substantial efficiency penalties:

| Dataset | Input (Prefill) Token Multiplier | Output (Decode) Token Multiplier | Absolute Tokens (MAS) |
|---------|----------------------------------|----------------------------------|----------------------|
| **AIME** | **220.22×** | **11.05×** | 38,787 input / 21,185 output |
| **GSM8K** | **34.66×** | **12.77×** | 3,351 input / 2,743 output |
| **B.C.B-H** | **14.82×** | **2.51×** | 1,958 input / 593 output |
| **FinRobot** | **9.00×** | **21.64×** | 5,665 input / 1,168 output |
| **MBPP** | **5.05×** | **5.56×** | 907 input / 532 output |

### Error Distribution Analysis

Per-example correctness comparison reveals:
- **~80% of cases** are "ties" (Both Pass or Both Fail), indicating task decomposition often has limited impact on capability boundaries
- **Non-negligible SAS Wins**: Cases where single-agent succeeds while multi-agent fails (e.g., GPT-4o on B.C.B-H: ~12% SAS Win vs ~5% MAS Win)
- **Scaling Effect**: Upgrading from Gemini-1.5-Flash to Gemini-2.0-Flash increases "Both Pass" rate significantly without proportionally increasing MAS-specific wins

### Key Quantitative Conclusions

- **Critical Threshold**: When base models reach ~90% accuracy on single-agent execution (e.g., Gemini-2.0-Flash on HumanEval: 90.2%), multi-agent decomposition returns diminish below **3%** absolute improvement
- **Cost-Accuracy Tradeoff**: MAS provides **0.8–3%** accuracy benefits on frontier models at **5–220×** token cost increase
- **Node-Level Defect**: ~80% of performance variance explained by base model capability rather than architectural decomposition

---

## Contributions

1. **Paradigm-Challenging Empirical Evidence**  
   Provides the first systematic evidence that the performance gap between MAS and SAS narrows with frontier LLM advancements, challenging the prevailing assumption that multi-agent decomposition is universally superior for complex task execution.

2. **Diagnostic Framework for Multi-Agent Debugging**  
   Introduces novel error-localization mechanisms that enable precise identification of culpable agents within distributed MAS workflows, addressing a critical operational challenge in debugging complex agent interactions.

3. **Hybrid Agentic Architecture Innovation**  
   Proposes **request cascading**, a novel paradigm synthesizing MAS and SAS into a unified processing pipeline, strategically exploiting accuracy benefits of multi-agent collaboration while minimizing overhead through single-agent delegation.

4. **Practical Deployment Optimization**  
   Demonstrates the viability of simultaneous multi-objective optimization in agentic systems, providing actionable architectural guidance that achieves both superior accuracy (**1.1-12%** gains) and significant cost efficiency (**up to 20%** reduction), resolving the traditionally antagonistic relationship between these metrics.

---

## Implications for Enterprise Deployment

For production AI systems—such as financial services platforms where 80% of queries involve routine data retrieval but 20% require complex multi-step analysis—migrating from static MAS architectures to **request cascading** offers immediate operational benefits:

- **Default to Single-Agent**: Deploy SAS as the standard execution paradigm for straightforward operations
- **Selective Multi-Agent Collaboration**: Reserve MAS only for subtasks where granular error profiling justifies the 5–220× cost premium
- **Targeted Remediation**: Utilize error localization to repair specific defective agents without system-wide redesign

This adaptive approach eliminates architectural over-engineering while preserving collaborative benefits solely for genuinely complex, error-sensitive operations.