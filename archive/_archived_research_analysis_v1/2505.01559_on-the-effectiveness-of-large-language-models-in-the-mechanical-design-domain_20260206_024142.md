---
title: On the effectiveness of Large Language Models in the mechanical design domain
arxiv_id: '2505.01559'
source_url: https://arxiv.org/abs/2505.01559
generated_at: '2026-02-06T02:41:42'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# On the effectiveness of Large Language Models in the mechanical design domain

*Daniele Grandi; Fabian Riquelme*

---

> ### ðŸ“Š Quick Facts
>
> *   **Dataset:** ABC Dataset (61,725 assemblies processed from ~1M CAD models).
> *   **Model Architecture:** BERT-based Transformer with Multi-Head Attention.
> *   **Peak Accuracy:** 0.62 (Binary Sentence-Pair Classification).
> *   **Zero-Shot Accuracy:** 0.386 (Top-1).
> *   **Key Strategy:** Regularization via architectural modifications and hyperparameter tuning.

---

## Executive Summary

This research addresses the challenge of effectively applying Large Language Models (LLMs) to the specialized domain of mechanical design. While LLMs have shown success in general natural language processing, they often struggle with the technical vocabulary and semantic relationships inherent to engineering, such as the complex dependencies between assemblies and parts in Computer-Aided Design (CAD) data. Furthermore, the mechanical engineering domain suffers from a scarcity of large, labeled datasets, making standard fine-tuning prone to overfitting and catastrophic forgetting. Bridging this gap is essential for enabling automated semantic understanding and intelligent design tools that can interpret unstructured engineering data.

The study introduces a domain-specific adaptation of a BERT-based Transformer architecture designed to handle the nuances of mechanical engineering language. Utilizing the ABC datasetâ€”refined from approximately 1 million CAD models down to 61,725 unique assembliesâ€”the authors constructed a framework for evaluating semantic understanding. The technical innovation involves an architectural modification that adds a Multi-Head Attention layer to the output layer, alongside an input layer designed to construct auxiliary sentences. To counter the limitations of a small domain-specific corpus, the researchers employed rigorous regularization strategies, including tuning learning rates, dropout values, sequence lengths, and layer selection, while also utilizing contrastive pre-training for zero-shot classification capabilities.

The fine-tuned model demonstrated measurable improvements over established baselines, validating the efficacy of the proposed architectural and hyperparameter optimizations. In the binary sentence-pair classification taskâ€”designed to determine part-assembly relationshipsâ€”the model achieved an accuracy of 0.62. Additionally, in the zero-shot classification task, the model attained a top-1 accuracy of 0.386. The experiments also revealed that specific regularization techniques were critical in mitigating overfitting, while simultaneously highlighting specific failure modes where standard NLP techniques fail to capture domain-specific mechanical engineering concepts.

This work establishes a foundational benchmarking framework for semantic understanding within mechanical engineering using the ABC dataset. By identifying the specific limitations and failure modes of standard LLMs in technical domains, the study provides a roadmap for future research into domain-specific artificial intelligence. The optimization insights regarding architectural modifications and hyperparameter tuning offer a reproducible methodology for training robust models on small, specialized corpora, ultimately advancing the potential for intelligent automation in mechanical design and CAD analysis.

---

## Key Findings

*   **Performance Metrics:** The fine-tuned model achieved an accuracy of **0.62** on binary sentence-pair classification and **0.386** top-1 accuracy on zero-shot classification.
*   **Benchmarking:** The model successfully outperformed established baselines in the targeted tasks.
*   **Over-fitting Mitigation:** Effective strategies to combat over-fitting were identified, including:
    *   Modifying learning rates.
    *   Adjusting dropout values.
    *   Tuning sequence length.
    *   Incorporating a multi-head attention layer.
*   **Failure Modes:** The study identified and categorized specific failure modes inherent to learning within the mechanical engineering domain, particularly where general NLP techniques struggle with technical semantics.

---

## Methodology

The research methodology focused on evaluating semantic understanding in mechanical design through the following approach:

1.  **Data Source:** Utilized semantic data from the ABC dataset, specifically designer-assigned assembly names and part names.
2.  **Pre-processing:** Implemented rigorous data cleaning and preparation.
3.  **Task Design:** Constructed two primary evaluation tasks:
    *   **Binary Sentence-Pair Classification:** To determine relationships between parts and assemblies.
    *   **Zero-Shot Classification:** To test generalization capabilities.
4.  **Optimization:** Focused on regularization techniques to handle the specific constraints of the domain corpus.

---

## Technical Details

### Dataset Processing
*   **Source:** ABC dataset (~1 million CAD models).
*   **Processing Pipeline:** Extraction, cleaning (via Python RegEx), and deduplication.
*   **Final Corpus:** 61,725 assemblies (48,644 with unique names).

### Model Architecture
*   **Base Model:** BERT-based Transformer for binary classification.
*   **Input Layer:** Constructs auxiliary sentences to frame the classification task.
*   **Encoder:** Pre-trained BERT Encoder.
*   **Output Layer:** Utilizes **Multi-Head Attention** followed by a Dense Layer to capture complex semantic relationships.

### Training & Optimization
*   **Methodology:** Binary Sentence-Pair Classification and Zero-Shot Classification via contrastive pre-training.
*   **Regularization:** Strategies to mitigate catastrophic forgetting and overfitting.
*   **Hyperparameters Tuned:**
    *   Learning rates ($1e-2$, $1e-3$, $1e-4$)
    *   Dropout values
    *   Sequence length
    *   Layer selection

---

## Results

The experimental validation of the proposed model yielded the following outcomes:

*   **Binary Sentence-Pair Classification:** Achieved an accuracy of **0.62**.
*   **Zero-Shot Classification:** Achieved a Top-1 accuracy of **0.386**.
*   **Baselines:** The model outperformed established baseline models in both tasks.
*   **Auxiliary Sentence Experiments:** Tested five different cases of auxiliary sentence creation to optimize input representation.
*   **Overfitting Analysis:** Confirmed that addressing overfitting is critical in small, domain-specific mechanical engineering corpora.
*   **Failure Analysis:** Identified specific challenges where domain-specific language presents difficulties for standard NLP techniques.

---

## Contributions

*   **Domain-Specific Evaluation:** Provides a rigorous evaluation of LLMs specifically within the mechanical engineering domain.
*   **Benchmarking Framework:** Establishes a standardized framework using the ABC dataset for semantic understanding in engineering.
*   **Optimization Insights:** Contributes actionable strategies for mitigating over-fitting in domain-specific LLMs, focusing on architectural modifications (Multi-Head Attention) and hyperparameter tuning.

---

**Quality Score:** 8/10
**References:** 40 citations