# Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology

*Sabine Felde; Rüdiger Buchkremer; Gamal Chehab; Christian Thielscher; Jörg HW Distler; Matthias Schneider; Jutta G. Richter*

---

> ### **Quick Facts**
> *   **Architecture Evaluated:** Small Language Models (SLMs) + Retrieval-Augmented Generation (RAG) vs. Large Language Models (LLMs)
> *   **Dominant Configuration:** Mistral-7B + RAG
> *   **Hardware Requirements:** Consumer-grade (NVIDIA GeForce RTX 3090, 24GB VRAM)
> *   **Deployment:** Local/On-premise (Edge computing)
> *   **Key Outcome:** SLM+RAG outperformed proprietary LLMs (GPT-3.5/4) in clinical tasks while drastically reducing cost and energy.
> *   **Safety Limitation:** No model reached specialist-level accuracy; human oversight remains essential.

---

## Executive Summary

The integration of Large Language Models (LLMs) into clinical decision support (CDS) workflows faces a critical bottleneck: the tension between the high reasoning capabilities of massive models and the practical constraints of healthcare environments, such as data privacy, infrastructure costs, and energy consumption. Specifically in rheumatology, where specialized and up-to-date knowledge is paramount, reliance on cloud-hosted LLMs introduces significant privacy risks and operational overhead.

This paper addresses whether smaller, parameter-efficient architectures, when paired with external knowledge retrieval, can match or exceed the clinical utility of state-of-the-art LLMs while enabling secure, on-premise deployment. To bridge the gap between model efficiency and clinical accuracy, the study introduces an architecture pairing **Small Language Models (SLMs)**, specifically **Mistral-7B** and **Llama-2-7B**, with **Retrieval-Augmented Generation (RAG)**.

Unlike standalone LLMs that depend solely on internalized training weights, the SLM+RAG framework connects these compact models to a local, curated medical knowledge base, allowing the retrieval of specific clinical guidelines (e.g., ACR/EULAR criteria) during inference. This technical approach ensures that the model's reasoning is grounded in current evidence, compensating for the SLMs' limited parameter count. Crucially, this configuration is optimized for local execution on **consumer-grade hardware**, specifically a single **NVIDIA GeForce RTX 3090 GPU** (24GB VRAM), facilitating integration into resource-limited clinical settings without cloud dependency.

The results demonstrated that the **Mistral-7B + RAG** configuration outperformed the larger LLMs in diagnostic accuracy and therapeutic recommendation quality, achieving higher alignment with specialist consensus. While LLMs like GPT-4 also showed high performance, the SLM+RAG setup achieved comparable or superior clinical output with a drastic reduction in resource intensity. Specifically, the local SLM+RAG inference on the RTX 3090 reduced energy consumption and operational costs by orders of magnitude compared to cloud-based API calls for GPT-4, validating the feasibility of high-performance, low-latency CDS at the edge.

However, despite these gains, neither the SLMs nor the larger LLMs achieved full consistency with specialist-level accuracy, underscoring persistent limitations in handling highly nuanced clinical reasoning. These findings fundamentally challenge the assumption that "bigger is better" for specialized medical AI applications, establishing a new paradigm for democratizing access to advanced CDS tools while reinforcing the necessity of specialist oversight.

---

## Key Findings

*   **Superior Performance:** Smaller language models (SLMs) paired with retrieval-augmented generation (RAG) achieve better diagnostic and therapeutic performance than larger language models (LLMs).
*   **Energy Efficiency:** The SLM + RAG architecture requires substantially less energy consumption compared to large, cloud-based models.
*   **Cost & Accessibility:** SLMs enable cost-efficient, local deployment suitable for resource-limited healthcare environments.
*   **The Human Gap:** No model consistently reached specialist-level accuracy, highlighting that current AI cannot replace human expertise.

---

## Methodology

The study conducted a comparative evaluation of Large Language Models (LLMs) versus Smaller Language Models (SLMs) within the context of rheumatology. 

*   **Assessment:** The study measured SLMs integrated with Retrieval-Augmented Generation (RAG) against larger models to determine diagnostic and therapeutic performance.
*   **Metrics:** In addition to clinical accuracy, the study analyzed practical metrics including energy requirements, cost implications, and deployment feasibility.

---

## Technical Details

| Component | Description |
| :--- | :--- |
| **Core Technology** | Small Language Models (SLMs) vs. Large Language Models (LLMs) |
| **Architecture** | SLMs paired with Retrieval-Augmented Generation (RAG) |
| **Models Tested** | **SLMs:** Mistral-7B, Llama-2-7B <br> **LLMs:** GPT-3.5-turbo, GPT-4 |
| **Application** | Clinical Decision Support (CDS) focusing on diagnostic and therapeutic tasks in Rheumatology |
| **Deployment Strategy** | Local deployment on edge/on-premise devices with limited resources |
| **Knowledge Integration** | Connection to local, curated medical knowledge base (e.g., ACR/EULAR criteria) during inference |
| **Hardware Target** | Consumer-grade hardware (NVIDIA GeForce RTX 3090, 24GB VRAM) |

---

## Results

The study found that the SLM + RAG combination outperformed standalone LLMs in diagnostic accuracy and therapeutic recommendations. 

*   **Efficiency:** This was achieved while demonstrating substantially lower energy consumption and high cost-efficiency for local execution.
*   **Limitations:** However, neither SLM + RAG nor LLMs consistently reached specialist-level accuracy. This indicates a performance gap that prevents the replacement of human expertise.

---

## Contributions

*   **Challenges Assumptions:** Challenges the "bigger is better" narrative by demonstrating that SLMs enhanced with RAG can outperform LLMs in specialized clinical tasks.
*   **Democratization:** Provides evidence supporting the use of SLMs to make advanced clinical decision support tools accessible in resource-limited settings through lower energy costs and local deployment options.
*   **Safety Standards:** Establishes that while these tools are useful, a performance gap remains between AI and human specialists, reinforcing the absolute necessity of expert oversight in clinical workflows.

---

**Document Quality Score:** 8/10  
**References:** 0 citations