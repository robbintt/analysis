---
title: 'PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online
  Learning'
arxiv_id: '2507.12305'
source_url: https://arxiv.org/abs/2507.12305
generated_at: '2026-02-06T03:46:18'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning

*M. Anwar Ma'sum; Mahardhika Pratama; Savitha Ramasamy; Lin Liu; Habibullah Habibullah; Ryszard Kowalczyk*

> ### ðŸ“Š Quick Facts
> *   **Quality Score:** 8/10
> *   **Total Citations:** 40
> *   **Storage Requirement:** Near-zero (Rehearsal-free / 0 exemplars)
> *   **Parameter Efficiency:** 0.3M â€“ 0.5M trainable parameters (<1% of total model)
> *   **Benchmarks:** CIFAR-100, ImageNet-R, ImageNet-A, CUB-200

---

## Executive Summary

Online Continual Learning (OCL) faces a critical dilemma where traditional methods often rely on "rehearsal"â€”storing past data exemplarsâ€”to mitigate catastrophic forgetting. This approach is frequently infeasible in real-world streaming scenarios due to strict data privacy regulations and memory constraints. Conversely, while prompt-based methods have emerged as a solution to adapt pre-trained models without replay, they often suffer from low computational throughput. This paper addresses the need for a high-performance OCL framework that can handle streaming data efficiently without violating privacy constraints or requiring extensive computational resources.

The authors introduce **PROL ("Prompt Online Learning")**, a rehearsal-free framework that utilizes a novel dual-knowledge prompt architecture. Instead of relying on a static prompt pool, PROL employs a dynamic "Prompt Generator"â€”a lightweight shallow Transformer or MLPâ€”that synthesizes visual prompts on the fly. This architecture separates general knowledge (handled by the generator) from specific knowledge (handled by a trainable scaler-and-shifter) while keeping the Vision Transformer (ViT) backbone frozen. The method is stabilized in streaming environments through a hard-soft update mechanism and optimized using a combined loss function of Cross-Entropy and "Knowledge Distillation (KD)" to prevent forgetting.

PROL demonstrates superior performance compared to state-of-the-art baselines like L2P and DER++ across rigorous benchmarks including CIFAR-100, ImageNet-R, ImageNet-A, and CUB-200. On CIFAR-100, the method achieved approximately 86% to 88% average accuracy and exceeded 70% on ImageNet-R. Furthermore, PROL is highly parameter-efficient, requiring only 0.3M to 0.5M trainable parameters (less than 1% of the 86M ViT-B/16 backbone). It also offers near-zero storage requirements and faster training times, successfully validating the efficacy of a generative prompting approach in a zero-exemplar setting.

This research resolves the fundamental trade-off between the inapplicability of rehearsal-based methods and the low throughput of existing prompt-based techniques. By demonstrating that generative prompting outperforms retrieval-based methods in streaming scenarios, PROL establishes a new standard for privacy-preserving continual learning. The framework enables the deployment of robust, adaptive AI systems in resource-constrained and latency-sensitive environments, ensuring that models can evolve with streaming data without compromising data privacy or computational efficiency.

---

## Key Findings

*   **Superior Benchmark Performance:** PROL significantly outperforms State-of-the-Art (SOTA) approaches on benchmarks such as CIFAR100, ImageNet-R, ImageNet-A, and CUB.
*   **Optimized Resource Usage:** The method maintains a smaller number of trainable parameters compared to traditional prompt-based approaches, optimizing resource usage.
*   **Computational Efficiency:** PROL achieves a practical balance in computational efficiency, offering moderate training and inference times to address latency issues.
*   **Privacy & Constraint Handling:** PROL successfully handles data privacy and 'single-pass' constraints without relying on rehearsal memory.

---

## Methodology

The researchers propose PROL (Prompt Online Learning), a prompt-based framework designed for rehearsal-free online continual learning. The architecture consists of four integrated components designed to handle streaming data effectively:

1.  **Single Lightweight Prompt Generator:** Captures general knowledge.
2.  **Trainable Scaler-and-Shifter:** Handles specific knowledge.
3.  **PTM Generalization Preserving Strategy:** Ensures the pre-trained model's capabilities are retained.
4.  **Hard-Soft Updates Mechanism:** Stabilizes the training process within dynamic streaming environments.

---

## Technical Details

The technical implementation of PROL leverages a frozen Pre-trained Vision Transformer (ViT) backbone within an Online Continual Learning (OCL) framework to maximize efficiency.

*   **Core Architecture:** Utilizes a ViT-B/16 backbone (86M parameters) that remains frozen.
*   **Dynamic Prompting:** Introduces a dynamic **"Prompt Generator"** (a lightweight shallow Transformer or MLP) to synthesize visual prompts on the fly rather than using a static prompt pool. These generated prompts are concatenated with input image patch embeddings.
*   **Rehearsal-Free Policy:** The method operates with 0 exemplars, strictly adhering to single-pass constraints.
*   **Optimization Scope:** Only the Prompt Generator and the Classification Head are trained, keeping the trainable parameters between 0.3M and 0.5M.
*   **Loss Function:** Combines standard Cross-Entropy with **"Knowledge Distillation (KD)"** to mitigate catastrophic forgetting.

---

## Results

Evaluated against rigorous baselines such as L2P and DER++, PROL demonstrated strong performance across multiple datasets:

*   **Accuracy Metrics:**
    *   **CIFAR-100:** Achieved ~86% - 88% average accuracy.
    *   **ImageNet-R:** Exceeded 70% accuracy.
*   **Efficiency Metrics:**
    *   **Parameter Efficiency:** Trains only 0.3M - 0.5M parameters (less than 1% of the total backbone).
    *   **Storage:** Near-zero storage requirements compared to rehearsal-based methods.
    *   **Speed:** Offers faster training times due to the generative approach.
*   **Conclusion:** The study demonstrates that generative prompting outperforms retrieval-based prompting in streaming scenarios, particularly where privacy and memory are constraints.

---

## Contributions

1.  **Trade-off Resolution:** Resolves the fundamental trade-off in Online Continual Learning (OCL) by addressing the inapplicability of rehearsal-based methods and the low throughput of existing prompt-based methods.
2.  **Novel Architecture:** Introduces a novel dual-knowledge prompt architecture that separates general and specific knowledge via generators and scaler-shifters, tailored for high-throughput streaming data.
3.  **Validation of Rehearsal-Free Learning:** Validates that a rehearsal-free prompt-based approach, optimized with mechanisms like hard-soft updates, can effectively handle catastrophic forgetting without violating data privacy constraints.