# Volatility in Certainty (VC): A Metric for Detecting Adversarial Perturbations During Inference in Neural Network Classifiers

*Vahid Hemmati; Ahmad Mohammadi; Abdul-Rauf Nuhu; Reza Ahmari; Parham Kebria; Abdollah Homaifar*

***

> ### ðŸ“Š Quick Facts
>
> *   **Quality Score:** 9/10
> *   **Key Correlation:** $\rho < -0.90$ (Strong negative correlation between accuracy and log(VC))
> *   **Models Tested:** ANN, CNN, VGG-like (on MNIST & CIFAR-10)
> *   **Attack Method:** FGSM (Fast Gradient Sign Method)
> *   **References:** 29 Citations
> *   **Novelty:** Fully label-free anomaly detection metric

***

## Executive Summary

**Problem**
The deployment of neural networks in safety-critical environments necessitates robust mechanisms to detect performance degradation caused by adversarial perturbations or distribution shifts. A primary challenge in this domain is the inability to rely on ground-truth labels during real-time inference to validate model predictions. This paper addresses the need for a reliable, label-free metric that can serve as an early-warning system for adversarial drift, ensuring that operators can identify and mitigate model compromise in production environments where validation data is unavailable.

**Innovation**
The authors introduce "Volatility in Certainty" (VC), a novel metric designed to detect anomalies by quantifying the irregularities in a model's internal confidence without requiring external labels. Technically, VC is calculated as the average squared log-ratio of adjacent certainty values derived from sorted softmax outputs. This measure captures local fluctuations in output smoothness; as a model encounters adversarial inputs, its prediction distribution typically becomes more volatile. By monitoring this volatility, the method establishes a proxy for model health that is computationally efficient and architecture agnostic.

**Results**
The study validates VC through rigorous testing on ANNs, CNNs, and VGG-like models across MNIST and CIFAR-10 datasets using FGSM adversarial attacks. The results demonstrate a remarkably strong negative correlation between classification accuracy and the logarithm of VC. In mixed contamination scenarios, the correlation coefficient reached $\rho \approx -0.94$ for MNIST models and $\rho \approx -0.89$ for CIFAR-10. Under fine-grained perturbation scenarios, sensitivity further increased, with the CNN model achieving $\rho = -0.994$ and the VGG model $\rho = -0.850$, confirming the metricâ€™s effectiveness even at low perturbation magnitudes.

**Impact**
This research significantly advances the field of operational AI safety by providing a scalable, real-time solution for monitoring neural network robustness. By demonstrating that VC provides an accurate proxy for accuracy across diverse architectures and varying levels of adversarial contamination, the authors establish a practical tool for automated anomaly detection. The ability to detect performance degradation without ground-truth labels paves the way for more resilient deployment strategies in uncontrolled environments, offering a critical safeguard for mission-critical applications.

***

## Key Findings

*   **Strong Negative Correlation with Accuracy**
    There is a remarkably strong negative correlation (**correlation rho < -0.90**) between classification accuracy and the logarithm of Volatility in Certainty (**log(VC)**), validating VC as a reliable proxy for model performance.

*   **Effective Label-Free Anomaly Detection**
    VC successfully detects adversarial drift and reflects performance degradation **without requiring access to ground-truth labels** during inference.

*   **Sensitivity to Distribution Shifts**
    The metric is sensitive to incremental distribution shifts, as demonstrated by its robust response to mixed test sets with gradual adversarial contamination.

*   **Architecture Agnostic Efficacy**
    The experiments confirm that VC is effective across different neural network architectures, including ANNs, CNNs, and regularized VGG-like models, on diverse datasets like MNIST and CIFAR-10.

***

## Methodology

**Metric Definition**
The study utilizes Volatility in Certainty (VC), defined as the **average squared log-ratio of adjacent certainty values**. This quantifies local fluctuations in model output smoothness by analyzing the dispersion of sorted softmax outputs.

**Experimental Models**
*   **MNIST:** Artificial Neural Networks (ANNs) and Convolutional Neural Networks (CNNs).
*   **CIFAR-10:** A regularized VGG-like model.

**Adversarial Generation**
Adversarial examples were generated using the **Fast Gradient Sign Method (FGSM)** across varying perturbation magnitudes.

**Validation Protocol**
Researchers created mixed test sets by gradually introducing adversarial contamination to rigorously assess VC's sensitivity under incremental distribution shifts and its correlation with classification accuracy.

***

## Technical Details

### Metric Formulation
*   **VC Calculation:** Derived from softmax outputs where Accuracy correlates inversely with log(VC).
*   **Monitoring:** Suitable for real-time monitoring.

### Model Architectures & Training

| Model | Dataset | Architecture Details | Optimizer | Label Smoothing | Epochs |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **VGG-Style** | CIFAR-10 | 3 Conv blocks, BN, ReLU, Dropout | SGD (lr 0.05, Mom 0.9) | 0.1 | 100 |
| **ANN/CNN** | MNIST | Standard / Regularized | Adam (lr 0.001) | 0.1 | 20-30 |

### Adversarial Scenarios
*   **Scenario A (Mixed Contamination):**
    *   Mixed perturbed samples into test sets (n=0-100 of 1000).
    *   Epsilon ($\epsilon$): 0.10.
*   **Scenario B (Fine-Grained Perturbation):**
    *   Applied fine-grained perturbation to the full test set.
    *   Epsilon ($\epsilon$): 0.000 â€“ 0.030.

***

## Results

**Scenario A (Mixed Contamination)**
Demonstrated strong negative correlations between accuracy and log(VC) with statistical significance ($p < 0.05$) even at low contamination:
*   **ANN/CNN (MNIST):** $\rho \approx -0.94$
*   **VGG (CIFAR-10):** $\rho \approx -0.89$

**Scenario B (Fine-Grained Perturbation)**
Revealed stronger correlations under low-intensity noise:
*   **CNN:** $\rho = -0.994$
*   **ANN:** $\rho = -0.952$
*   **VGG:** $\rho = -0.850$

**Training Dynamics Analysis (VGG)**
The study observed distinct regimes during training:
*   **Overall Correlation:** $r = -0.775$
*   **High Accuracy Regime ($Acc \ge 0.5$):** Strong inverse correlation ($r = -0.874$).
*   **Low Accuracy Regime ($Acc < 0.5$):** Positive correlation ($r = 0.700$).

***

## Contributions

*   **Introduction of VC Metric:** The paper investigates "Volatility in Certainty," a novel, label-free metric that captures irregularities in model confidence through the dispersion of sorted softmax outputs.
*   **Real-Time Robustness Monitoring:** It positions VC as a scalable, real-time performance indicator suitable for early-warning systems in safety-critical applications where ground-truth data is unavailable during deployment.
*   **Validation of Drift Detection:** The work provides empirical evidence that VC serves as an effective indicator of adversarial drift and performance degradation across varying architectures and perturbation levels.