---
title: 'MIMIR: Masked Image Modeling for Mutual Information-based Adversarial Robustness'
arxiv_id: '2312.0496'
source_url: https://arxiv.org/abs/2312.04960
generated_at: '2026-02-04T15:43:35'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# MIMIR: Masked Image Modeling for Mutual Information-based Adversarial Robustness

*Xiaoyun Xu; Shujian Yu; Zhuoran Liu; Stjepan Picek*

---

### ðŸ“Š Quick Facts

| Metric | Value |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **References** | 40 Citations |
| **CIFAR-10 Robust Acc.** | 60% (PGD20) |
| **ViT-B Training Time** | 263.77 hours (vs 451.39h baseline) |
| **Swin-L Training Time** | 231.14 hours (vs 363.42h baseline) |
| **Primary Datasets** | CIFAR-10, Tiny-ImageNet, ImageNet-1K |

---

> ### ðŸ“ Executive Summary
>
> State-of-the-art Adversarial Training (AT) strategies, such as Generalist and DBAT, exhibit significant incompatibilities when applied to Vision Transformer (ViT) architectures, creating a critical security gap as ViTs become the standard for modern computer vision. The paper addresses this by providing a systematic investigation into why these standard methods fail, identifying through theoretical Mutual Information (MI) analysis that robustness in ViTs specifically requires constraining the MI between adversarial examples and their latent representations. Unlike existing approaches, current AT methods do not account for these specific representational dynamics, leaving transformer-based models vulnerable to adversarial perturbations.
>
> The authors introduce **MIMIR**, a self-supervised adversarial training framework grounded in Information Bottleneck theory, which proves that robustness can be achieved by implementing an MI penalty to limit information leakage from adversarial examples into the latent space. Technically, MIMIR converts Masked Image Modeling (MIM) into an adversarial pre-training method using a two-stage process: self-supervised pre-training followed by supervised fine-tuning. The framework generates adversarial images, masks 75% of the patches, and forces the model to reconstruct the image using a loss calculated against the natural (clean) input. This approach integrates MIM with MI penalties to compel the model to learn inherently robust features and is adaptable to various architectures, including standard ViTs (MAE), Swin (Group Window Attention), and ConvNext (SparK).
>
> MIMIR achieves state-of-the-art performance on ImageNet-1K (RobustBench with AutoAttack) for both small and large models. On CIFAR-10, the method demonstrated incremental improvements, delivering a 1% increase in both natural and robust accuracy metrics over increased training epochs. Beyond accuracy, MIMIR offers substantial computational efficiency gains compared to end-to-end baselines. For instance, training a Swin-L model required 231.14 hours (versus 363.42 hours for the baseline), while training a ViT-B model took 263.77 hours (versus 451.39 hours for the baseline). Additionally, the method demonstrated superior resilience against unforeseen attacks, data corruption, and adaptive white-box attacks across diverse architectures.

---

## Key Findings

*   **Incompatibility of Standard AT:** State-of-the-art Adversarial Training strategies (Generalist and DBAT) exhibit significant incompatibilities when applied to Vision Transformer architectures.
*   **Mutual Information (MI) Analysis:** Theoretical analysis reveals that MI between adversarial examples and latent representations must be constrained for robustness.
*   **Superior Performance:** The MIMIR method achieves improved natural and robust accuracy on CIFAR-10, Tiny-ImageNet, and ImageNet-1K, outperforming SOTA results.
*   **Enhanced Resilience:** MIMIR demonstrates superior resilience against unforeseen attacks, data corruption, and adaptive white-box attacks.

## Methodology

The paper proposes **MIMIR**, a self-supervised adversarial training framework for Vision Transformers grounded in theoretical analysis of autoencoder-based pre-training.

*   **Theoretical Foundation:** Deriving Mutual Information bounds for adversarial robustness.
*   **Optimization Strategy:** Implementing an MI penalty to constrain information between adversarial examples and latent representations.
*   **Training Mechanism:** Utilizing adversarial pre-training with masked image modeling to learn robust features.

## Technical Details

### Framework Architecture
MIMIR converts Masked Image Modeling (MIM) into an adversarial pre-training method using a two-stage process:
1.  **Self-supervised Pre-training**
2.  **Supervised Fine-tuning**

### Theoretical Basis
Grounded in **Information Bottleneck theory**, it constrains Mutual Information between adversarial examples and latent representations.

### Operational Mechanism
*   **Input Generation:** Generating adversarial images.
*   **Masking:** Masking **75%** of patches.
*   **Reconstruction:** Reconstructing the image where the loss is calculated against the **natural (clean) input**.

### Architecture Support
The framework includes adaptations for:
*   **Standard ViTs:** (MAE)
*   **Swin:** (Group Window Attention)
*   **ConvNext:** (SparK with sparse convolution)

## Performance Results

### Accuracy Metrics
*   **ImageNet-1K:** MIMIR outperforms State-of-the-Art AT methods on RobustBench (with AutoAttack) for both small and large models.
*   **CIFAR-10:**
    *   **Natural Accuracy:** Improved from 52% to **53%**.
    *   **Robust Accuracy (PGD20):** Improved from 59% to **60%** (over increased epochs).

### Training Efficiency
Significant improvements in training time compared to End2End baselines:
*   **ViT-B:** 263.77 hours (vs. 451.39 hours)
*   **Swin-L:** 231.14 hours (vs. 363.42 hours)

### Generalization
The method generalizes effectively across ViT, Swin, and ConvNext architectures and remains resilient against unforeseen attacks, data corruption, and adaptive white-box attacks.

## Research Contributions

1.  **Failure Analysis:** Provides a systematic investigation into why standard AT methods fail with ViTs.
2.  **Theoretical Perspective:** Introduces a novel theoretical perspective linking adversarial robustness to Mutual Information bounds in ViT autoencoders.
3.  **Framework Development:** Develops the MIMIR framework, integrating masked image modeling with MI penalties.
4.  **Validation:** Validates the method through extensive experimentation on standard benchmarks, establishing new SOTA performance against both standard and adaptive attacks.