---
title: 'AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System
  Need'
arxiv_id: '2506.15451'
source_url: https://arxiv.org/abs/2506.15451
generated_at: '2026-02-03T13:42:21'
quality_score: 9
citation_count: 10
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System Need

*Zhouhong Gu; Xiaoxuan Zhu; Yin Cai; Hao Shen; Xingzhou Chen; Qingyi Wang; Jialin Li; Xiaoran Shi; Haoran Guo; Wenxuan Huang; Hongwei Feng; Yanghua Xiao; Zheyu Ye; Yao Hu; Shaosheng Cao*

---

> ### ðŸ“Š Quick Facts
> *   **Optimal Configuration:** Width=3, Depth=3
> *   **MATH-100 (Level 5):** 52.1% Accuracy (+11.8% vs. Debate)
> *   **GSM8K:** 91.50% Accuracy
> *   **HumanEval:** 79.20% Pass@1
> *   **Architecture:** Fully Parallel Divide-and-Conquer
> *   **Quality Score:** 9/10

---

## Executive Summary

Current Large Language Model (LLM)-based multi-agent systems struggle with scalability and generalizability, particularly when facing complex, structured tasks. As task complexity increases, these systems often suffer from "context explosion"â€”where the volume of information overwhelms the context windowâ€”and inefficient sequential processing that hinders performance. The paper addresses the critical need for a robust framework capable of decomposing intricate queries and managing distributed resources effectively without sacrificing accuracy or speed.

AgentGroupChat-V2 introduces a novel "divide-and-conquer" framework utilizing a fully parallel architecture to maximize efficiency. Technically, the system employs Hierarchical Task Decomposition to transform user queries into "task forests," allowing for the concurrent processing of sub-tasks rather than sequential execution. Key components include an Adaptive Collaboration Engine, which dynamically selects appropriate LLMs and interaction modes, and an Agent Organization Optimization module for distributed processing. The architecture is tunable via Width (Number of Agents: 2-5) and Depth (Dialogue Rounds: 2-5), with optimal performance observed at Width=3 and Depth=3.

The framework demonstrates superior performance across mathematical, coding, and domain-specific benchmarks, with its advantage growing alongside task difficulty. On high-complexity MATH-100 Level 5 problems, AgentGroupChat-V2 achieved 52.1% accuracy, significantly outperforming baselines like Multi-Agent Debate (40.3%) and Naive-CoT (42.3%). It also secured 91.50% accuracy on GSM8K, 30.4% on AIME, and a 79.20% pass@1 rate on HumanEval. In domain-specific applications, the model scored 90.20% on medical reasoning tasks (MedmcQA) and outperformed AutoGen in commonsense reasoning, achieving 85.6% on WinoGrande.

AgentGroupChat-V2 establishes new performance standards for multi-agent systems by validating that structural task decomposition and parallel execution are essential for handling complex reasoning. By demonstrating a performance margin exceeding 11 percentage points on the most difficult problems, this work shifts the paradigm from reasoning-intensive methods to scalable, divide-and-conquer strategies. This advancement has significant implications for the field, offering a generalizable solution that mitigates context management issues and enables the effective application of multi-agent systems to highly specialized domains such as finance, law, and medicine.

---

## Key Findings

*   **Superior Benchmark Performance:** Achieved **91.50%** accuracy on GSM8K, **30.4%** on AIME, and a **79.20%** pass@1 rate on HumanEval, significantly outperforming established baselines.
*   **Scaling with Difficulty:** The framework's performance advantage increases as task difficulty rises, exceeding **11 percentage points** on Level 5 MATH problems compared to other methods.
*   **Cross-Domain Efficacy:** Experiments confirm superior performance across various domains, including Finance, Medicine, and Law.
*   **Context Management:** Successfully mitigates "context explosion" challenges better than reasoning-intensive methods through structural decomposition.

---

## Methodology

AgentGroupChat-V2 employs a **divide-and-conquer strategy** integrated with a fully parallel architecture. This approach moves away from sequential processing to maximize efficiency and manage complex information flows.

### Core Components

1.  **Hierarchical Task Decomposition:** Transforms user queries into "task forests," breaking down complex problems into manageable sub-tasks for concurrent processing.
2.  **Adaptive Collaboration Engine:** Dynamically selects the appropriate Large Language Models (LLMs) and interaction modes based on the specific requirements of the sub-tasks.
3.  **Agent Organization Optimization:** A module designed to manage distributed processing efficiently, ensuring that the multi-agent system operates cohesively.

---

## Technical Details

The framework is built to handle complex structured information while managing resource allocation effectively.

*   **Task Strategy:** Utilizes a "Divide-and-Conquer" approach to decompose tasks, specifically addressing "context explosion" common in reasoning-intensive methods.
*   **Configuration Tuning:**
    *   **Width (Number of Agents):** Range 2â€“5
    *   **Depth (Dialogue Rounds):** Range 2â€“5
    *   **Optimal Performance:** Observed at **Width=3, Depth=3**.
*   **Role Configuration:** Employs distinct role configuration strategies to facilitate specialized multi-agent collaboration.

---

## Performance Results

### Mathematical Reasoning
*   **MATH-100 (Level 5):** Achieved **52.1%** accuracy (W=3, D=3).
    *   *Comparison:* Multi-Agent Debate (40.3%), Naive-CoT (42.3%), Direct Naive (45.0%), ReAct (<1.2%).
*   **GSM8K:** **91.50%** accuracy.
*   **AIME:** **30.4%** accuracy.

### Coding & General Reasoning
*   **HumanEval:** Reached **79.20%** pass@1 rate.
*   **HellaSwag (Commonsense):**
    *   Qwen: 70.3% (V2) vs 73.7% (Naive Baseline).
    *   Llama: 66.0% (V2).
*   **WinoGrande:**
    *   Qwen: 82.7% (V2).
    *   Llama: **85.6%** (V2).
    *   *Note:* V2 significantly outperforms AutoGen on commonsense tasks.

### Domain-Specific Benchmarks
*   **Medical (MedmcQA - Llama-3.1-70B):** **90.20%**
*   **Finance (FinQual):** 80.20% (using Multi-Agent Debate configuration)
*   **Legal (JEC-QA):** Max **42.56%**

---

## Contributions

*   **Novel Framework:** Introduces a new framework specifically addressing scalability and generalizability in multi-agent systems.
*   **Architectural Innovation:** Innovates a divide-and-conquer fully parallel architecture utilizing "task forests" for concurrent processing.
*   **Dynamic Resource Allocation:** Proposes an adaptive collaboration engine capable of dynamically allocating resources.
*   **New Standards:** Establishes new performance standards across mathematical and coding benchmarks, proving the efficacy of structural decomposition.

---

**References:** 10 citations