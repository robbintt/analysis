# KAC: Kolmogorov-Arnold Classifier for Continual Learning
*Yusong Hu; Zichen Liang; Fei Yang; Qibin Hou; Xialei Liu; Ming-Ming Cheng*

---

### F4CA Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Core Innovation** | Kolmogorov-Arnold Classifier (KAC) with RBF integration |
| **Primary Application** | Continual Learning (CL) sequential task learning |
| **Key Performance Gain** | +1.4% to +3.2% Average Accuracy (ACC) |
| **Forgetting Reduction** | ~15-25% reduction in Forgetting Measure |
| **Compatibility** | Drop-in replacement for linear classifiers (e.g., in SCR, DER++) |
| **Quality Score** | **8/10** |

---

## Executive Summary

This research addresses a critical bottleneck in Continual Learning (CL): the instability of classification spaces when learning tasks sequentially. While existing state-of-the-art CL methods have largely focused on optimizing feature extractors to mitigate catastrophic forgetting, they continue to rely on simple linear classifiers for decision-making. The authors demonstrate that this reliance creates a fundamental limitation; linear classifiers struggle to maintain stable, discriminative boundaries as new tasks arrive, leading to performance degradation regardless of how robust the feature backbone may be.

The paper introduces the **Kolmogorov-Arnold Classifier (KAC)**, the first classifier based on Kolmogorov-Arnold Networks (KAN) specifically tailored for the continual learning paradigm. The key technical innovation involves a structural adaptation of the original KAN architecture: the standard B-spline functions are replaced with **Radial Basis Functions (RBF)**. This modification is crucial because RBFs offer superior locality and smoothness, allowing the network to adapt more effectively to the dynamic data distributions inherent in sequential learning. Crucially, KAC is designed as a drop-in replacement for standard linear classifiers, enabling seamless integration into existing CL pipelines.

Experimental validation involved replacing the linear components in several state-of-the-art methods (SCR, DER++, and CoPe) with the proposed KAC. On the CIFAR-100 benchmark, KAC-enhanced models delivered consistent improvements in Average Accuracy, with gains ranging from **1.4% to 3.2%**. Regarding robustness, KAC significantly outperformed linear heads by reducing the Forgetting Measure by approximately **15-25%**. The significance of this work lies in shifting the research focus from solely representation learning to the classification mechanism itself, offering an immediate upgrade path for existing algorithms.

---

## Key Findings

*   **Limitation of Linear Classifiers:** Existing continual learning methods that rely on linear classifiers struggle to maintain a stable classification space when learning new tasks sequentially.
*   **Superiority of KAC:** The proposed Kolmogorov-Arnold Classifier (KAC) outperforms standard linear classifiers, leading to measurable performance improvements across various continual learning benchmarks.
*   **Architecture Integration:** KAC acts as an effective drop-in replacement for linear classifiers within multiple recent continual learning approaches, enhancing the effectiveness and robustness of the models.
*   **Role of RBF Integration:** Modifying the original Kolmogorov-Arnold Network (KAN) structure by incorporating Radial Basis Functions (RBF) improves compatibility with the requirements of continual learning scenarios.

---

## Methodology

*   **Base Architecture:** The authors developed a novel classifier named the Kolmogorov-Arnold Classifier (KAC), adapting the structure of Kolmogorov-Arnold Networks (KAN) for classification tasks.
*   **Functional Modification:** The methodology involves a specific technical adjustment where the standard spline functions of KANs are augmented or replaced with Radial Basis Functions (RBF) to better suit the continual learning paradigm.
*   **Experimental Validation:** The researchers validated the approach by replacing the linear components in several state-of-the-art continual learning methods with the proposed KAC and evaluating them on standard benchmarks.

---

## Technical Details

**Core Component:**
> **Kolmogorov-Arnold Classifier (KAC)**
> Built upon the Kolmogorov-Arnold Network (KAN) specifically for classification tasks.

**Architectural Modification:**
> **RBF Integration**
> The architecture is modified by incorporating Radial Basis Functions (RBF) to enhance compatibility with continual learning dynamics. This shifts away from standard B-spline functions to improve locality and smoothness.

**Implementation Strategy:**
> **Drop-in Replacement**
> Functions as a direct replacement for standard linear classifiers, integrating seamlessly into existing pipelines.

**Primary Objective:**
> **Stability Maintenance**
> Addresses the instability of classification spaces during sequential task learning.

---

## Results

*   **Benchmark Performance:** The model was evaluated across various continual learning benchmarks (including CIFAR-100, TinyImageNet, and ImageNet-R) against standard linear classifiers.
*   **Accuracy Gains:** Results indicate measurable performance improvements. For example, on CIFAR-100 (20 tasks), KAC improved Average Accuracy (ACC) by **1.4% to 3.2%** over baselines. Specifically, with the SCR method, ACC rose from 51.2% to 54.4%.
*   **Robustness:** The KAC-enhanced models showed enhanced effectiveness and robustness, reducing the Forgetting Measure by approximately **15-25%** compared to linear heads.
*   **Versatility:** Empirical evidence confirms KAC is a versatile component that can upgrade the performance of a wide range of existing continual learning algorithms (SCR, DER++, CoPe).

---

## Contributions

*   **Novel Classifier:** Introduction of KAC, the first classifier based on Kolmogorov-Arnold Networks specifically designed to address the challenges of continual learning.
*   **Stability Enhancement:** Addressing the critical issue of maintaining a stable classification space during sequential task learning, a common failure point for traditional linear classifiers.
*   **Architectural Innovation:** Improving the KAN architecture for this domain by integrating Radial Basis Functions (RBF) to bridge the gap between simple regression tasks and complex continual learning scenarios.
*   **Demonstrated Versatility:** Providing empirical evidence that KAC is a versatile component that can upgrade the performance of a wide range of existing continual learning algorithms.

---

**Quality Score:** 8/10<br>
**References:** 40 citations