---
title: Exposing Weak Links in Multi-Agent Systems under Adversarial Prompting
arxiv_id: '2511.10949'
source_url: https://arxiv.org/abs/2511.10949
generated_at: '2026-02-03T12:26:37'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Exposing Weak Links in Multi-Agent Systems under Adversarial Prompting

*Nirmit Arora; Sathvik Joel; Ishan Kavathekar; Palak; Rohan Gandhi; Yash Pandya; Tanuja Ganu; Aditya Kanade; Akshay Nambi*

---

> **ðŸ“Š Quick Facts**
> *   **Quality Score:** 8/10
> *   **References:** 40 Citations
> *   **Architectures Evaluated:** 5 (Centralized, Decentralized, Hybrid)
> *   **Datasets:** 4 (RedCode, SafeArena, AgentHarm, Agent Security Bench)
> *   **Novel Metrics:** Dharma, ARIA
> *   **Tools Released:** SafeAgents Codebase

---

> ### ðŸ“ Executive Summary
>
> This research addresses a critical gap in AI security: the vulnerability of Multi-Agent Systems (MAS) to adversarial prompting, which is largely overlooked by current evaluation standards. As MAS architectures become widely adopted for complex tasks, this paper reveals that specific design patternsâ€”particularly centralized systems that delegate atomic instructionsâ€”can obscure harmful objectives. By decomposing malicious tasks into smaller, benign-looking sub-tasks, these systems inadvertently bypass safety safeguards, creating systemic "weak links." The problem is compounded by the fact that existing security evaluations focus predominantly on single-agent interactions, failing to account for the emergent risks introduced by inter-agent communication, planning, and delegation protocols.
>
> To overcome these limitations, the authors introduce **SafeAgents**, a unified, extensible framework designed for the fine-grained security assessment of multi-agent pipelines. Technically, SafeAgents integrates the **Dharma** diagnostic measure to identify specific weak links within a system's architecture. The paper further proposes the **Agent Risk Assessment (ARIA)** framework, a 4-level categorical metric that classifies agent behavior into Immediate Refusal (ARIA-1), Delayed Refusal (ARIA-2), Incorrect Execution (ARIA-3), and Critical Risk (ARIA-4). This methodological innovation allows for a nuanced analysis of how failures propagate through planning, delegation, and aggregation stages, moving beyond the binary pass/fail nature of traditional evaluations.
>
> The study rigorously evaluated **five** widely adopted MAS architectures (spanning centralized, decentralized, and hybrid models) across **four** distinct datasets. The results demonstrate that while standard metrics like Attack Success Rate (ASR) lack the granularity to localize failures, the ARIA framework effectively categorized vulnerabilities into **four** distinct severity levels. This granular analysis provided concrete evidence that security breaches often originate from specific architectural componentsâ€”such as the planner or communication protocolsâ€”rather than general system failure. By isolating these vectors, the study quantified how centralized delegation strategies and fallback behaviors specifically contribute to ARIA-4 (Critical Risk) classifications.
>
> This work significantly influences the field by establishing that architectural choices in MASâ€”such as plan construction strategies and delegation protocolsâ€”directly dictate security susceptibility. By releasing the SafeAgents codebase as an open-source tool, the authors provide the community with a standardized method to test and diagnose multi-agent vulnerabilities. These insights drive the industry toward "security-aware design," urging developers to consider adversarial robustness not just at the individual agent level, but as a systemic property of the entire multi-agent workflow, fundamentally changing how these complex systems are benchmarked and secured.

---

## Key Findings

*   **Inherent Design Vulnerabilities:** Widely adopted design patterns in Multi-Agent Systems (MAS) carry significant security risks.
*   **The Deception of Centralization:** Centralized systems that delegate only atomic instructions can obscure harmful objectives, inadvertently reducing robustness against attacks.
*   **Architectural Weak Links:** Specific elementsâ€”plan construction strategies, inter-agent context sharing, and fallback behaviorsâ€”directly influence susceptibility to adversarial prompting.
*   **Insufficient Current Evaluations:** Existing security evaluations are inadequate for MAS, as they predominantly focus on single-agent security and miss emergent risks.

---

## Technical Details

### Architecture Analysis
The paper distinguishes between two primary architectural models, identifying weak links in both:

*   **Centralized Architectures:** Features a single orchestrator handling decomposition, delegation, and aggregation.
    *   *Frameworks:* OpenAI Agents, Magentic-One, LangGraph.
*   **Decentralized Architectures:** Utilizes distributed peer-to-peer decision-making models.

### Vulnerability Vectors
*   **Delegation Strategies:** How tasks are broken down and assigned.
*   **Sub-Agent Autonomy:** The level of independent decision-making granted to individual agents.
*   **Aggregation Mechanisms:** How results from multiple agents are combined.
*   **Task Decomposition Blind Spots:** The hypothesis suggests that decomposition can bypass safeguards because sub-tasks may appear benign in isolation.

### Evaluation Benchmarks
The study utilized four distinct datasets to test robustness:
1.  **RedCode:** Low-level code execution.
2.  **SafeArena:** High-level decision-making.
3.  **AgentHarm:** Jailbreak robustness.
4.  **Agent Security Bench:** Prompt injection resistance.

---

## Methodology

The researchers employed a rigorous framework to assess security vulnerabilities:

1.  **Framework Utilization:** Leveraged the **SafeAgents** framework for fine-grained security assessment.
2.  **Diagnostic Measurement:** Employed the **Dharma** diagnostic measure to pinpoint weak links within multi-agent pipelines.
3.  **Comprehensive Evaluation:** Tested five widely adopted multi-agent architectures (covering centralized, decentralized, and hybrid models).
4.  **Dataset Scope:** Conducted evaluations across four datasets involving web tasks, tool use, and code generation.

---

## Results & Analysis

### Metric Limitations
*   **Standard Metrics:** The study critiques standard metrics like Attack Success Rate (ASR) and Refusal Rate (RR) for lacking the necessary granularity to diagnose complex failures.
*   **Localization Challenges:** Current metrics often fail to isolate whether failures stem from planning, delegation, or communication protocols.

### The ARIA Framework
To address these limitations, the paper proposes the **Agent Risk Assessment (ARIA)** framework, a 4-level categorical metric:

*   **ARIA-1:** Immediate Refusal (Safe)
*   **ARIA-2:** Delayed Refusal
*   **ARIA-3:** Incorrect Execution
*   **ARIA-4:** Critical Risk

*Note: While ARIA categorizes severity, it currently lacks the ability to localize failures to specific components (e.g., planner vs. sub-agent).*

### Methodological Challenges
*   High integration complexity between MAS frameworks and benchmark backends.
*   Difficulty in isolating failure sources within the communication pipeline.

---

## Core Contributions

1.  **SafeAgents Framework:** A unified, extensible framework designed to assess the security of Multi-Agent Systems.
2.  **Dharma Metric:** A novel diagnostic measure to identify and analyze weak links within multi-agent pipelines.
3.  **Security-Aware Design Insights:** Empirical analysis exposing how specific MAS design choices affect security.
4.  **Open-Source Tools:** Release of the SafeAgents codebase to facilitate further research and community testing.