# Mapping Neural Signals to Agent Performance, A Step Towards Reinforcement Learning from Neural Feedback

*Julia Santaniello; Matthew Russell; Benson Jiang; Donatello Sassaroli; Robert Jacob; Jivko Sinapov*

---

### ðŸ“Š Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **Participants** | 25 (Ages 19â€“27) |
| **Technology** | fNIRS (ISS OxiplexTS) |
| **Domains** | 3 OpenAI Gymnasium (Fetch/Place, Lunar Lander, Flappy Bird) |
| **Top Model** | MLP (Classification), Random Forest (Regression) |
| **Peak F1 Score** | 86.3% (Feature Optimized) |
| **Citations** | 12 |

---

## Executive Summary

### Problem
Current Human-in-the-Loop Reinforcement Learning (HITL-RL) systems rely on explicit, active instruction from human operators. This requirement imposes a high cognitive workload and necessitates unnatural actions (e.g., button presses, scalar ratings), which interrupts the user's primary tasks and limits the scalability of human-agent interaction. This paper addresses the bottleneck by removing the requirement for active instruction, investigating whether the intrinsic human reward system can provide implicit feedback.

### Innovation
The core innovation is the **NEURO-LOOP framework**, a paradigm shift utilizing passive Brain-Computer Interfaces (BCIs) to map neural signals directly to agent performance. The study employed functional near-infrared spectroscopy (fNIRS) to monitor prefrontal cortex hemodynamic responses. Data was processed using a 4th-order Butterworth filter, with features extracted via a sliding window. Task performance was labeled using Multi-Policy Action Agreement and Kullback-Leibler (KL) Divergence, allowing classical ML models (SVM, KNN, Random Forest, MLP) to correlate fNIRS features with agent optimality values.

### Results
The study successfully demonstrated a statistically significant relationship between fNIRS data and agent performance. ML models consistently predicted performance better than random chance. Feature optimization was critical, improving the MLP F1 Score from **72%** (non-optimized) to **86.3%** (using mean, skewness, and standard deviation). In cross-condition classification, MLP achieved **76.7%** accuracy (Binary) and **72.2%** (Discrete). While Random Forest and KNN excelled in regression, limitations were noted regarding cross-participant and cross-domain transferability.

### Impact
This research establishes a foundational proof-of-concept for implicit feedback in HITL-RL, validating that passive neural monitoring can track agent performance without active input. By transitioning to implicit reward signals, NEURO-LOOP significantly reduces human workload. The publication of the novel fNIRS dataset provides a valuable community resource, offering a roadmap for future assistive AI and human-agent interaction technologies capable of intuitively adapting to human cognitive states in real-time.

---

## Key Findings

*   **NEURO-LOOP Framework:** Introduction of an implicit feedback framework that utilizes the intrinsic human reward system for human-agent interaction, contrasting sharply with existing methods requiring active, unnatural instruction.
*   **Feasibility Established:** Researchers successfully demonstrated the feasibility of mapping brain signals to reinforcement learning agent performance, a critical foundational step for the NEURO-LOOP framework.
*   **Statistical Significance:** A statistically significant relationship was found between functional near-infrared spectroscopy (fNIRS) data and agent performance, validated through classical machine learning techniques.
*   **Workload Reduction:** The study establishes that passive Brain-Computer Interfaces (BCIs) can integrate human feedback into autonomous agent training while significantly reducing the human workload.

---

## Methodology

The research followed a structured approach using fNIRS technology and classical machine learning:

*   **Data Acquisition:** Utilized functional near-infrared spectroscopy (fNIRS) to monitor neural signals specifically from the prefrontal cortex of participants.
*   **Experimental Design:** Participants observed or guided a reinforcement learning agent navigating an environment. This setup allowed for the simultaneous collection of neural data and agent performance metrics.
*   **Dataset Creation:** A novel dataset was generated to serve as a resource for future research into passive Brain-Computer Interfaces within Human-in-the-Loop Reinforcement Learning (HITL-RL).
*   **Analysis Strategy:** Applied classical machine learning techniques to the collected fNIRS data to determine correlations and map neural signals to the agent's performance metrics.

---

## Technical Details

### Data Representation
*   **Neural Data ($N_k$):** Represented as an $M \times T$ matrix.
*   **Task Data ($H_k$):** Represented as a $P \times T$ matrix containing variables such as State, Action, Reward, and Agent Optimality Values ($V_t, B_t, E_t$).

### Hardware & Signal Processing
*   **Device:** ISS OxiplexTS fNIRS device.
*   **Target:** Measurement of prefrontal cortex hemodynamic responses.
*   **Filtering:** 4th order Butterworth filter.
*   **Calibration:** 20-second baseline calibration.

### Feature Engineering
*   **Extraction:** Derived using a 5â€“7 second sliding window.
*   **Initial Statistics:** Mean, standard deviation, slope, intercept, skewness, kurtosis.
*   **Optimization:** Reduced to primarily **mean**, **skewness**, and **standard deviation** for improved performance.

### Experimental Setup
*   **Domains:** 3 OpenAI Gymnasium domains:
    1.  Robot Fetch/Place
    2.  Lunar Lander
    3.  Flappy Bird
*   **Conditions:** Passive (observation) vs. Active (control).

### Labeling & Algorithms
*   **Labeling Method:** Multi-Policy Action Agreement against 10 near-optimal policies; error calculation used Kullback-Leibler (KL) Divergence.
*   **Algorithms:** SVM, KNN, Decision Tree, Random Forest, MLP.
*   **Validation:** Tested via cross-condition strategies without fine-tuning.

---

## Results

### Model Performance
*   **Predictive Capability:** Classical machine learning models (Random Forest, MLP, KNN) predicted agent performance better than random chance.
*   **Regression:** Random Forest and KNN generally outperformed other models in regression tasks.

### Classification Accuracy (MLP)
*   **Cross-Condition:**
    *   Binary-Class Accuracy: **76.7%**
    *   Discrete-Class Accuracy: **72.2%**
*   **Granularity (Discrete Class):**
    *   Optimal Performance: **76%**
    *   Sub-Optimal Performance: **67%**
    *   Worst-Case Performance: **72%**

### Feature Optimization Impact
*   Feature optimization significantly boosted results.
*   MLP F1 Score increased from **72%** (non-optimized features) to **86.3%** (optimized features: mean, skewness, standard deviation).

### Limitations
*   **Transferability:** Struggles with cross-participant and cross-domain transfer.
*   **Signal Artifacts:** Potential issues with latency and noise.
*   **Data Balance:** Dataset imbalances were identified.

---

## Contributions

*   **Framework Innovation:** Introduction of the NEURO-LOOP framework, a paradigm shift in Human-in-the-Loop RL moving from active instruction to implicit feedback based on the human reward system.
*   **Resource Generation:** Creation and publication of a specialized fNIRS dataset, providing a valuable resource for advancing passive BCI applications in machine learning.
*   **Technical Validation:** Provided empirical evidence that passive neural monitoring can effectively track agent performance, laying the technical groundwork for adaptive autonomous systems.
*   **Future Application Roadmap:** Identification of high-potential applications in human-agent interaction, assistive AI, and adaptive systems.

---

**Quality Score:** 8/10  
**References:** 12 citations