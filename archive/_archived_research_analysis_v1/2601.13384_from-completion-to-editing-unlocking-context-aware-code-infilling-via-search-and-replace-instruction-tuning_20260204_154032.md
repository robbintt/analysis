---
title: 'From Completion to Editing: Unlocking Context-Aware Code Infilling via Search-and-Replace
  Instruction Tuning'
arxiv_id: '2601.13384'
source_url: https://arxiv.org/abs/2601.13384
generated_at: '2026-02-04T15:40:32'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# From Completion to Editing: Unlocking Context-Aware Code Infilling via Search-and-Replace Instruction Tuning

*Jiajun Zhang; Zeyu Cui; Jiaxi Yang; Lei Zhang; Yuheng Jing; Zeyao Ma; Tianyi Bai; Zilei Wang; Qiang Liu; Liang Wang; Binyuan Hui; Junyang Lin*

---

> ### ðŸ“Š Quick Facts
>
> *   **Quality Score:** 9/10
> *   **References:** 40 Citations
> *   **Training Efficiency:** Surpasses Base models using only **20k samples**
> *   **Latency Impact:** Comparable to standard FIM (No speed loss)
> *   **Security Impact:** Reduces >99% attack success rate
> *   **Model Series:** Qwen3-Coder (Open Source)

---

## ðŸ“ Executive Summary

This research addresses the critical performance degradation that Large Language Models (LLMs) optimized for chat experience when performing Fill-In-the-Middle (FIM) or code infilling tasks. While Base coding models excel at static text completion, Chat modelsâ€”which are aligned for safety and instruction followingâ€”often suffer severe capability loss in this domain, with performance dropping by as much as **59.0%**. This creates a "safety-latency dilemma" for developers who must choose between the raw speed and proficiency of unaligned Base models or the safety of Chat models that are ill-equipped for efficient code editing. Furthermore, existing solutions to bridge this gap often require expensive multi-step agentic loops or compromise the model's broader coding abilities, failing to provide a viable holistic solution.

To bridge this gap, the authors introduce the **Search-and-Replace Infilling (SRI)** framework, which fundamentally shifts code generation from static text completion to dynamic, context-aware editing. Technically, SRI internalizes agentic verification into a unified, single-pass inference process comprising a "**SEARCH**" phase, where the model replicates and verifies the target code segment to establish structural grounding, and a "**REPLACE**" phase, where the model generates the corrected code. Unlike Diff or Patch formats that rely on brittle line numbers, SRI utilizes a specific identifier and considers an editable region of 10 surrounding lines. The framework is underpinned by a synthesized SRI-200K dataset and a harmonization process that aligns completion tasks with the model's instruction-following priors.

Empirical validation demonstrates that standard Chat models struggle significantly with FIM tasks; for instance, the Qwen2.5-Coder-Instruct model scored **38.5%** on the CrossCodeEval benchmark compared to **79.6%** for its Base counterpart. In contrast, the proposed **SRI-Coder** enables Chat models to surpass Base model performance using only 20k training samples. Crucially, this performance boost is achieved without sacrificing speed or versatility: the framework maintains inference latency comparable to standard FIM methods and, unlike traditional FIM tuning, **preserves general coding competencies**. Additionally, SRI addresses critical security vulnerabilities by harmonizing completion tasks with Chat LLM safety alignments, significantly reducing the >99% attack success rate typically associated with standard FIM tools.

The significance of this work lies in its resolution of the trade-off between Chat LLM alignment and Base model speed, establishing a new standard for dynamic code editing. By demonstrating that state-of-the-art results can be achieved with minimal data requirements while maintaining the model's general-purpose coding skills, the authors provide a highly efficient path for enhancing code generation capabilities. The successful application of the SRI framework to the Qwen3-Coder series, released as an open-source resource, empowers the broader development community to build tools that are both fast and safe. This shift from static completion to context-aware editing represents a fundamental advancement in how LLMs approach code modification and repair.

---

## ðŸ”‘ Key Findings

*   **Superior Performance with Minimal Data:** SRI-Coder enables Chat LLMs to surpass Base model performance using only **20k samples**.
*   **Preservation of General Capabilities:** SRI preserves general coding competencies unlike traditional FIM tuning, which often degrades other skills.
*   **Efficiency in Latency:** The framework maintains inference latency comparable to standard FIM, avoiding the slowdown typical of agentic approaches.
*   **Dynamic Error Correction:** SRI shifts the paradigm from static infilling to dynamic, context-aware editing.

---

## ðŸ§ª Methodology

The authors propose the **Search-and-Replace Infilling (SRI)** framework, designed to internalize agentic verification-and-editing mechanisms into a unified single-pass inference process. The methodology consists of three core components:

1.  **Structural Grounding:** An explicit search phase where the model verifies the code segment.
2.  **Harmonization:** Aligning the completion tasks with the model's instruction-following priors.
3.  **Data Synthesis:** Creating the **SRI-200K** dataset to fine-tune the SRI-Coder models.

---

## âš™ï¸ Technical Details

**The SRI Framework**
The framework shifts code generation from static text completion to dynamic, context-aware editing using a unified, single-pass inference process.

**Workflow Components**
*   **SEARCH Phase:** Replicates and verifies the code segment to ensure structural grounding.
*   **REPLACE Phase:** Generates the new code based on the verification.

**Context & Format**
*   **Context Handling:** Utilizes a specific identifier and an editable region of **10 surrounding lines**.
*   **Format:** Uses a Search-and-Replace format rather than Diff/Patch formats to avoid reliance on precise line numbers.

**Implementation**
*   **Dataset:** Utilizes a synthesized dataset named **SRI-200K**.
*   **Application:** Applied to the **Qwen3-Coder** series to create the SRI-Coder models.

---

## ðŸ“ˆ Results

*   **Performance Degradation in Standard Models:** Standard Chat LLMs experience severe performance degradation (up to **59.0%**) on FIM tasks compared to Base models.
    *   *Benchmark Example (CrossCodeEval):* Qwen2.5-Coder Base scored **79.6%**, while the Instruct version dropped to **38.5%**.
*   **SRI-Coder Efficacy:** SRI-Coder enables Chat models to surpass Base completion performance using only 20k samples while preserving general coding skills.
*   **Latency:** The framework maintains latency comparable to standard FIM.
*   **Security:** Addresses security concerns by harmonizing completion tasks with Chat LLM safety alignments, reducing the >99% attack success rate typical of FIM tools.

---

## ðŸš€ Contributions

*   **Resolution of the Safety-Latency Dilemma:** Addresses the trade-off between Chat LLM alignment and Base model speed.
*   **Introduction of SRI Framework:** Establishes a new standard for dynamic code editing without speed loss.
*   **Empirical Validation of Data Efficiency:** Demonstrates state-of-the-art results with minimal data.
*   **Open-Source Empowerment:** Applies SRI to the Qwen3-Coder series and releases it as an open-source resource.