---
title: Emergent effects of scaling on the functional hierarchies within large language
  models
arxiv_id: '2501.07359'
source_url: https://arxiv.org/abs/2501.07359
generated_at: '2026-02-04T15:40:35'
quality_score: 8
citation_count: 7
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Emergent effects of scaling on the functional hierarchies within large language models

*Paul C. Bogdan*

> ### **Quick Facts**
>
> *   **Quality Score:** 8/10
> *   **References:** 7 citations
> *   **Models Analyzed:** Llama-3.2-3b, Llama-3.3-70b-Instruct
> *   **Technique:** Linear Probing (SVMs, Ridge Regressions)
> *   **Key Metric:** Adjacent Layer Coordination

---

## Executive Summary

Current understanding of Large Language Model (LLM) internals relies heavily on the "functional hierarchy" theory, which posits a steady, monotonic progression from low-level lexical processing in early layers to high-level abstraction in deeper layers. However, it is unclear how this architectural theory holds up under significant parameter scaling. This paper addresses the critical gap in understanding whether increasing model size simply reinforces this linear hierarchy or introduces emergent, non-linear dynamics that complicate our interpretation of layer specialization and information flow.

The key innovation is a comparative scaling analysis that isolates the effects of parameter count on internal representations by contrasting Llama-3.2-3b (baseline) against Llama-3.3-70b-Instruct. Technically, the authors utilize linear probing—specifically Support Vector Machines (SVMs) and ridge regressions—on activations extracted from Attention Outputs, FFN Outputs, and the Residual Stream. By submitting simple text prompts involving buried concepts and long-context filler text (approx. 100 words), the researchers apply z-score normalization and derivative analysis to layer accuracies to detect non-monotonic fluctuations and adjacent layer coordination that standard probing might miss.

The analysis reveals that while the 3b model largely supports the traditional functional hierarchy—showing a clear progression from item-level semantics to two-item relations and finally to four-item analogies—it also demonstrates that deep layers often compress information from the early context window without generating meaningful abstraction. In contrast, the 70b model exhibits distinct emergent behaviors, including a "double peak" phenomenon for relations and analogies at layers 12–16 and 25–33. Regarding attention dynamics, the 70b model demonstrated a correlation matrix mean of $\rho = 0.31$, indicating consistent adjacent layer coordination, whereas the 3b model showed anti-persistence ($\rho = -0.41$) and low consistency ($\rho = 0.06$).

This research significantly refines functional hierarchy theory by validating it for smaller models while identifying that scaling introduces complex, non-linear dynamics in larger architectures. It challenges the prevailing view that deep layers consistently perform high-level integration, providing counter-evidence that deep layers often function as mechanisms for context compression rather than abstraction.

---

## Key Findings

*   **Validation for Small Models:** Analysis of the Llama-3.2-3b model largely supports the traditional functional hierarchy, showing a progression from item-level semantics to two-item relations and four-item analogies.
*   **Deep Layer Compression:** Deep layers in the analyzed models often compress information from the early context window without generating meaningful abstraction.
*   **Non-Monotonic Dynamics in Large Models:** The Llama-3.3-70b-Instruct model representation exhibits non-monotonic fluctuations rather than steady progression.
*   **Emergent Coordination:** Scaling leads to emergent adjacent layer coordination where adjacent layers fluctuate in specialization.

---

## Methodology

The research approach focuses on isolating the effects of parameter scaling on internal model representations.

*   **Data Collection:** Submission of simple text prompts to language models to extract internal activations.
*   **Analysis Technique:** Linear probing using Support Vector Machines (SVMs) and ridge regressions performed on each layer's activations.
*   **Objective:** To predict text labels and identify encoded information at each layer.
*   **Comparative Analysis:** A direct scaling analysis was conducted across Llama-3.2-3b and Llama-3.3-70b-Instruct models to isolate the effects of scaling.

---

## Technical Details

| Component | Description |
| :--- | :--- |
| **Models Analyzed** | Llama-3.2-3b (Baseline), Llama-3.3-70b-Instruct (Scaling Focus) |
| **Analyzed Components** | Attention Outputs, FFN Outputs, Residual Stream |
| **Methods** | Linear probing with SVMs, z-score normalization, derivative analysis of accuracies |
| **Experimental Setup** | ~100 words of filler text used to test long-context persistence |
| **Tasks Tested** | Animal/food classification, analogies, grammar, buried-concept identification |

---

## Results

*   **Double Peak Phenomenon:** The Llama-3.3-70b-Instruct model exhibited an emergent 'double peak' for relations and analogies at layers **12–16** and **25–33**, which was absent in the 3b model.
*   **Attention Dynamics:**
    *   **70b Model:** Showed consistency (correlation matrix mean $\rho = 0.31$).
    *   **3b Model:** Showed anti-persistence ($\rho = -0.41$) but low consistency ($\rho = 0.06$).
*   **Buried Concept Representation:** In the residual stream, buried concept representation peaked at **layer 35**.
*   **Grammar and Syntax:** Peaked early (layers **3–5**) or sustained late (layer **14**).
*   **Overall Performance:** The 70b model achieved higher accuracy than the 3b model on specific tasks.

---

## Contributions

*   **Refinement of Theory:** The study refines the functional hierarchy theory by validating it for small models while identifying where deep layers fail to abstract.
*   **Identification of Scaling Emergences:** Highlights non-linear dynamics and adjacent layer coordination that deviate from assumed steady complexity progression.
*   **Context Compression Evidence:** Offers a counter-perspective to high-level integration views by providing evidence of context compression in deep layers.