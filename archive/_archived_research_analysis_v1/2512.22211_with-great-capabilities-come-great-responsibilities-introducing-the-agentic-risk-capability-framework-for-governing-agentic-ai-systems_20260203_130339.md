---
title: 'With Great Capabilities Come Great Responsibilities: Introducing the Agentic
  Risk & Capability Framework for Governing Agentic AI Systems'
arxiv_id: '2512.22211'
source_url: https://arxiv.org/abs/2512.22211
generated_at: '2026-02-03T13:03:39'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# With Great Capabilities Come Great Responsibilities: Introducing the Agentic Risk & Capability Framework for Governing Agentic AI Systems

*Shaun Khoo; Jessica Foo; Roy Ka-Wei Lee*

---

> ### **Quick Facts**
>
> *   **Quality Score:** 9/10
> *   **Total References:** 40 Citations
> *   **Document Type:** Theoretical Framework / Governance
> *   **Core Focus:** Agentic AI Risk Management
> *   **Approach:** Capability-Centric Analysis

---

## Executive Summary

Agentic AI systems—defined by their ability to autonomously execute code, interact with the internet, and modify files—present a distinct set of governance challenges that traditional passive models do not. The core problem addressed is that these autonomous capacities introduce intrinsic risks stemming from system components, design, and capabilities, which existing governance frameworks are ill-equipped to handle. As these systems move from theoretical constructs to deployment, the lack of a structured mechanism to identify and link technical sources of risk to materialized safety hazards creates a critical security gap, making it difficult for organizations to balance rapid innovation with operational safety.

The authors introduce the **Agentic Risk & Capability (ARC) Framework**, a robust, open-sourced technical governance structure that shifts the analytical perspective from model-centric to capability-centric. Technically, the framework decomposes agentic systems into three primary sources of intrinsic risk: **Components** (LLM, Tools, Instructions, Memory), **Design** (Architecture, Access Controls), and **Capabilities** (Autonomous Actions). The key innovation is the "Risk-Control Nexus," a model that explicitly maps these intrinsic sources to specific failure modes (such as Agent Failure, External Manipulation, or Tool Malfunction) and connects them to precise technical controls. This allows for a granular analysis of how specific technical elements contribute to broader security and safety hazards.

As this paper establishes a theoretical and structural framework rather than conducting empirical experiments, it does not present quantitative performance metrics or benchmark results. Instead, the primary results are conceptual: the successful operationalization of a comprehensive risk taxonomy and the creation of a structured Risk Register. The authors demonstrate the framework's utility by synthesizing 40 citations to define failure modes and hazards, providing a reproducible method for risk identification. The "result" is the validation of the ARC Framework as a logical tool capable of bridging the gap between abstract risks and concrete technical governance strategies.

The significance of the ARC Framework lies in its potential to standardize the governance of agentic AI at a critical inflection point in the technology's development. By offering a capability-centric viewpoint, it provides organizations with the necessary guidance to manage the complex risks of autonomous systems without stifling innovation. This work influences the field by moving beyond high-level principles to actionable implementation guidance, establishing a foundational open-source resource that developers, safety teams, and policymakers can utilize to ensure agentic systems operate securely and responsibly.

---

## Key Findings

*   **Distinct Governance Challenges:** Agentic AI systems introduce unique challenges due to autonomous capacities such as code execution, internet interaction, and file modification.
*   **Intrinsic Risk Sources:** Risks in agentic AI are intrinsic and originate from three primary sources: **components**, **design**, and **capabilities**.
*   **Capability-Centric Shift:** Effective governance requires shifting from a model-centric to a **capability-centric perspective** to properly analyze and manage these systems.
*   **The Risk-Control Nexus:** There is a critical need to establish a nexus linking risk sources to materialized risks and their specific technical controls.

---

## Methodology

The authors developed the **Agentic Risk & Capability (ARC) Framework** utilizing a capability-centric analytical perspective. The methodology involves:

1.  **Distilling Risks:** Breaking down risks into three intrinsic sources (Components, Design, Capabilities).
2.  **Mapping a Nexus:** Creating a connection model that links these sources to materialized risks and technical controls.
3.  **Operationalizing:** Providing a structured approach that organizations can adopt to implement the framework practically.

---

## Technical Details

The paper proposes the **ARC Framework**, a capability-centric governance structure designed to identify and mitigate risks in agentic AI systems.

### Framework Structure

The framework analyzes three primary elements:

*   **Components**
    *   Includes: LLM, Tools, Instructions, Memory
*   **Design**
    *   Includes: Architecture, Access Controls, Monitoring
*   **Capabilities**
    *   Includes: Autonomous actions (e.g., code execution, file modification)

### Risk Identification Process

*   **Mapping:** The framework maps the primary elements (Components, Design, Capabilities) to Failure Modes.
*   **Failure Modes:** Identified modes include Agent Failure, External Manipulation, and Tool Malfunction.
*   **Hazards:** These failures are then analyzed for Security and Safety impacts.
*   **Governance Tools:** The primary tool for implementation is a structured **Risk Register**.

---

## Contributions

*   **ARC Framework:** Introduction of a robust, open-sourced technical governance framework specifically for agentic AI risks.
*   **Capability-Centric Viewpoint:** Development of a new analytical lens to examine a broad spectrum of agentic AI systems.
*   **Risk Taxonomy:** Identification of three primary sources of intrinsic risk: components, design, and capabilities.
*   **Risk-Control Nexus Model:** A model that explicitly links risk sources to materialized risks and technical controls.
*   **Implementation Guidance:** Practical advice to help organizations balance rapid innovation with safe, secure, and responsible operations.

---

## Results

The provided text focuses on the theoretical definition of the framework, literature review, and categorization of system elements and risks. It does not contain experimental results or quantitative metrics. No performance metrics, benchmark results, or comparative analyses are presented in the excerpt.