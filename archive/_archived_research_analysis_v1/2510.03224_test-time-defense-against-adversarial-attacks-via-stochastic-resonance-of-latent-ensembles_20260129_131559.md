# Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles

*Dong Lao; Yuxiang Zhang; Haniyeh Ehsani Oskouie; Yangchao Wu; Alex Wong; Stefano Soatto*

---

> ###  Quick Facts
>
> *   **Approach:** Stochastic Resonance via Latent Ensembles
> *   **Training Requirement:** None (Training-free)
> *   **Architecture:** Agnostic (works on CNNs & ViTs)
> *   **Key Performance:**
>     *   **Image Classification:** Recovers **68.1%** of accuracy loss
>     *   **Stereo Matching:** Recovers **71.9%** of accuracy loss
>     *   **Optical Flow:** Recovers **29.2%** of accuracy loss
> *   **Defense Type:** Test-time only

---

## Executive Summary

Deep neural networks remain highly susceptible to adversarial attackssubtle, often imperceptible perturbations to input data that can drastically degrade model performance. Existing defense strategies frequently suffer from critical limitations: many require computationally expensive adversarial training or architectural modifications, while others rely on feature filtering that inadvertently discards high-frequency semantic information, leading to accuracy degradation on clean samples. Furthermore, the vast majority of prior research has focused narrowly on image classification, leaving dense prediction taskssuch as stereo matching and optical flow estimationwhich are vital for applications like autonomous driving, largely without effective protection against these threats.

This paper introduces **"Stochastic Resonance via Latent Ensembles,"** a training-free, test-time defense mechanism that leverages the principle of "combating noise with noise." Unlike input transformation or preprocessing methods, this approach operates by introducing small, random integer-pixel translations to input images and aggregating the resulting feature representations in the latent space. The technical process involves transforming the input, encoding it through the network, applying an inverse geometric transformation in the latent space to align features back to the original reference coordinate system, and then averaging these embeddings. This closed-form solution disrupts high-frequency adversarial perturbations through aggregation while preserving semantic details, offering an architecture-agnostic and attack-agnostic solution that does not require retraining or additional network modules.

The proposed method demonstrates robust recovery of performance across both classification and dense prediction tasks without requiring network retraining. On the ImageNet dataset using a ViT-Small model ($\epsilon=8/255$), the defense restored Top-1 accuracy from 4.51% to 25.77%, recovering 55.8% of the accuracy loss relative to clean performance. Similarly, on CIFAR-10 (ResNet-18 + AT), accuracy against strong PGD-20 attacks improved from 46.37% to 56.08%. Most notably, in dense prediction tasks, the method reduced the Mean Absolute Error (MAE) on KITTI stereo matching (PSMNet) by 71.89% against PGD attacks (dropping from 63.97 to 17.98 MAE). Overall, the technique successfully recovers approximately 68.1% of accuracy loss on classification, 71.9% on stereo matching, and 29.2% on optical flow relative to clean performance baselines.

This research establishes the first generic test-time defense specifically applicable to dense prediction domains, filling a critical gap in the field of adversarial robustness. Its practical significance lies in its deployability; because the method is entirely training-free and architecture-agnostic, it can be instantly applied to pre-trained models without necessitating access to training data or expensive retraining pipelines. By achieving state-of-the-art robustness while minimizing the information loss inherent in traditional feature filtering defenses, this work offers a viable, efficient strategy for securing safety-critical vision systems against a wide spectrum of adversarial attacks.

---

## Key Findings

*   **High Recovery Rates:** The method successfully recovers up to **68.1%** of accuracy loss on image classification, **71.9%** on stereo matching, and **29.2%** on optical flow relative to clean performance.
*   **Dense Prediction Breakthrough:** Establishes the first generic test-time defense specifically designed for dense prediction tasks.
*   **Minimized Information Loss:** leverages stochastic resonance ("combating noise with noise") rather than feature filtering to enhance robustness without sacrificing high-frequency semantic details.

---

## Methodology

The core mechanism relies on **stochastic resonance** to enhance robustness without information loss. The process follows a closed-form formula implementation:

1.  **Perturbation:** Small translational perturbations are introduced to input images.
2.  **Encoding:** The transformed images are passed through the network to generate feature embeddings.
3.  **Alignment:** The transformed feature embeddings are mapped back to the original reference image coordinates.
4.  **Aggregation:** The aligned features are aggregated to form a robust final representation.

---

## Technical Details

**Core Concept:** Stochastic Resonance via Latent Ensembles

**Perturbation Strategy:**
*   Controlled, purposeful perturbations using random integer-pixel translations.

**Operational Pipeline:**
1.  **Input Transformation:** Apply translations to the source input.
2.  **Latent Encoding:** Pass transformed inputs through the neural network.
3.  **Inverse Transformation:** Apply inverse geometric transformations in the latent space to align features with the original coordinate system.
4.  **Feature Aggregation:** Average the aligned embeddings.

**Key Characteristics:**
*   **Test-Time Only:** Requires no training or architectural changes.
*   **Noise Disruption:** Disrupts high-frequency adversarial noise via input averaging.
*   **Detail Preservation:** Preserves semantic details through the use of inverse transformations.

---

## Experimental Results

The proposed defense was evaluated across multiple benchmarks and architectures, showing significant improvements in robustness against strong attacks like PGD and FGSM.

### Image Classification

| Dataset / Model | Attack Strength | Attack Metric | Original Accuracy | Defended Accuracy | Recovery |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **CIFAR-10** (ResNet-18 + AT) | FGSM | Accuracy | 56.21% | **61.02%** | +4.81% |
| **CIFAR-10** (ResNet-18 + AT) | PGD-20 | Accuracy | 46.37% | **56.08%** | +9.71% |
| **ImageNet** (ViT-Small) | $\epsilon=8/255$ | Top-1 Accuracy | 4.51% | **25.77%** | +21.26% (55.8% loss recovered) |

### Dense Prediction

| Task / Dataset | Model | Attack | Metric | Original Error | Defended Error | Improvement |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Stereo Matching** (KITTI) | PSMNet | PGD | MAE | 63.97 | **17.98** | **71.89% reduction** |
| **Stereo Matching** (KITTI) | PSMNet | FGSM | MAE | N/A | N/A | **37.82% reduction** |

---

## Core Contributions

*   **Training-Free Defense:** Presents a defense mechanism requiring no additional network modules, retraining, or access to training data.
*   **Agnostic Solution:** Offers an architecture-agnostic and attack-agnostic solution deployable on diverse existing networks (CNNs and Vision Transformers).
*   **SOTA Robustness:** Achieves state-of-the-art robustness by extending adversarial defense to dense prediction domains (stereo matching and optical flow), a previously under-explored area.

***

**Quality Score:** 9/10
**References:** 20 citations