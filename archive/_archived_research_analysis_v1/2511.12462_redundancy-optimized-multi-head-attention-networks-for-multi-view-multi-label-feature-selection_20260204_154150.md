---
title: Redundancy-optimized Multi-head Attention Networks for Multi-View Multi-Label
  Feature Selection
arxiv_id: '2511.12462'
source_url: https://arxiv.org/abs/2511.12462
generated_at: '2026-02-04T15:41:50'
quality_score: 9
citation_count: 13
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Redundancy-optimized Multi-head Attention Networks for Multi-View Multi-Label Feature Selection

*Yuzhou Liu; Jiarui Liu; Wanfu Gao*

---

> ### ðŸ“Š Quick Facts
> * **Core Architecture:** Multi-head Attention Network (RMAN-MMFS)
> * **Key Innovation:** Dual-term Redundancy Optimization (Static & Dynamic)
> * **Datasets Validated:** 6 real-world datasets (NUS-WIDE-Object, MIR-Flickr, etc.)
> * **Performance Gain:** Macro-F1 improvement of 4.6% on NUS-WIDE-Object
> * **Baseline Comparison:** Outperformed 6 existing methods
> * **Quality Score:** 9/10

---

## Executive Summary

This research addresses the challenge of feature selection in multi-view multi-label learning (MVML) environments, where data is derived from heterogeneous sources and associated with multiple labels simultaneously. The core problem is that existing attention-based methods predominantly model intra-view relationships while neglecting inter-view complementarity, leading to suboptimal feature representation. Furthermore, these approaches fail to explicitly account for feature redundancy, resulting in selected subsets that contain repetitive information. This is a critical issue because high redundancy and poor view integration degrade model efficiency, increase computational costs, and reduce the predictive accuracy required for complex, high-dimensional data analysis.

To overcome these limitations, the paper proposes **RMAN-MMFS**, a novel framework utilizing a Multi-head Attention Network tailored for multi-view scenarios. The architecture innovates by employing individual attention heads to model intra-view features and integrating cross-attention mechanisms to explicitly capture inter-view feature complementarity. A key technical contribution is the implementation of a dual-term Redundancy Optimization strategy: a **Static Redundancy Term** that mitigates redundancy within each view, and a **Dynamic Redundancy Term** that learns to minimize redundancy between unselected and selected features during training. Additionally, the method employs correlation analysis to compute importance weights by aggregating correlations between Query and Key matrices, ensuring the model prioritizes the most pertinent feature values.

The proposed method was rigorously evaluated against six existing multi-view multi-label feature selection techniques across six real-world datasets. The results demonstrated that RMAN-MMFS achieves superior performance, outperforming the strongest baselines in terms of Macro-F1 and Micro-F1 scores. The significance of this research lies in its holistic approach to feature selection, bridging the gap between intra-view analysis and inter-view complementarity, providing a more robust and efficient framework for handling complex multi-view data.

---

## Key Findings

*   **Superior Performance:** The proposed RMAN-MMFS method demonstrates superior performance compared to six existing multi-view multi-label feature selection methods.
*   **Robustness:** Comprehensive evaluations across six real-world datasets confirm the method's effectiveness and robustness.
*   **Feature Compactness:** The integration of static and dynamic redundancy terms successfully promotes feature compactness within the selected subsets.
*   **Resolved Limitations:** The approach effectively resolves limitations in prior methods by capturing inter-view feature complementarity, which previous attention-based models neglected.

---

## Methodology

The RMAN-MMFS framework utilizes a sophisticated architecture designed to handle the complexities of multi-view data while minimizing redundancy.

*   **Multi-head Attention Architecture:**
    *   Utilizes individual attention heads to model intra-view feature relationships.
    *   Implements cross-attention mechanisms to capture inter-view feature complementarity.
*   **Dual-term Redundancy Optimization:**
    *   **Static Term:** Mitigates redundancy within each view.
    *   **Dynamic Term:** Explicitly models redundancy between unselected and selected features during the training process.
*   **Correlation Analysis:**
    *   Computes importance weights by aggregating correlations between Query and Key matrices.
    *   Focuses the model's attention on pertinent values to enhance selection accuracy.

---

## Research Contributions

*   **Overcoming Existing Limitations:** Addresses the shortcomings of current attention-based feature selection methods that focus predominantly on intra-view relationships and fail to account for critical feature-label correlations.
*   **Novel Redundancy Management:** Introduces a unique combination of static and dynamic redundancy terms to explicitly minimize feature redundancy, a factor often overlooked in previous research.
*   **Enhanced Inter-view Modeling:** Proposes a new use of cross-attention mechanisms within multi-head attention networks to leverage the complementarity of inter-view features, providing a richer perspective for multi-view multi-label learning.

---

## Technical Specifications

| Component | Description |
| :--- | :--- |
| **Core Architecture** | Multi-head Attention Network |
| **Redundancy Strategy** | Dual-term reduction (Static & Dynamic) |
| **Static Redundancy** | Fixed constraints to mitigate redundancy within views |
| **Dynamic Redundancy** | Learned during training to minimize redundancy between selected and unselected features |
| **Inter-view Strategy** | Captures complementarity rather than treating views independently |

---

## Experimental Results

*   **Overall Performance:** The method demonstrated superior performance compared to six existing methods across six real-world datasets (NUS-WIDE-Object, MIR-Flickr, Yeast, Scene, 3-Sources, and Corel5k).
*   **Validation:** The experiments validated that the architecture resolves limitations regarding the neglect of inter-view feature complementarity.
*   **Quantitative Metrics:**
    *   **NUS-WIDE-Object:** Achieved a Macro-F1 score of approximately **0.764**, surpassing the best competing method (0.718) by a margin of **4.6%**.
    *   **MIR-Flickr:** Reached a Micro-F1 score of **0.682** compared to the baseline's 0.632.
*   **Efficiency:** Analysis of computational complexity confirmed that the dual-term optimization maintains competitive runtimes while significantly enhancing feature compactness and classification accuracy.

---

## Evaluation & References

**Quality Score:** 9/10

**References:** 13 citations