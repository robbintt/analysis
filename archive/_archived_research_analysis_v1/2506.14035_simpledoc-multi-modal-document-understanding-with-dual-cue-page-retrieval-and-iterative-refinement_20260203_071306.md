---
title: 'SimpleDoc: Multi-Modal Document Understanding with Dual-Cue Page Retrieval
  and Iterative Refinement'
arxiv_id: '2506.14035'
source_url: https://arxiv.org/abs/2506.14035
generated_at: '2026-02-03T07:13:06'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# SimpleDoc: Multi-Modal Document Understanding with Dual-Cue Page Retrieval and Iterative Refinement

*Chelsi Jain; Yiran Wu; Yifan Zeng; Jiale Liu; Shengyu Dai; Zhenwen Shao; Qingyun Wu; Huazheng Wang*

***

> ### üìã QUICK FACTS
>
> * **Quality Score:** 8/10
> * **References:** 40 Citations
> * **Performance Gain:** +3.2% Average Improvement
> * **Core Innovation:** Dual-Cue Retrieval & Agentic Iterative Refinement
> * **Key Efficiency:** State-of-the-art results with significantly fewer page retrievals

***

## üìù Executive Summary

This research addresses the challenge of multi-modal Document Visual Question Answering (DocVQA) within complex, multi-page documents. As documents grow in length and contain diverse data types‚Äîsuch as text, images, and tables‚Äîtraditional retrieval-augmented generation (RAG) methods often struggle to efficiently locate and synthesize relevant evidence. The problem is critical because answering questions over such documents requires understanding spatial and semantic relationships across scattered pages; existing approaches frequently suffer from high computational costs due to excessive page retrievals or fail to accurately integrate visual context, leading to suboptimal accuracy.

The core innovation is the **SimpleDoc framework**, which introduces a "Dual-Cue Retrieval" strategy and an "Iterative Refinement" workflow to enhance precision. Technically, the system operates by first generating "Dual-Cue" representations for each page, combining visual vector embeddings using specific models such as ColPali or ColQwen with semantic textual summaries. A crucial aspect of this strategy is a filtering and re-ranking step: candidate pages are initially identified through embedding similarity and subsequently refined using the generated page summaries. During the online query phase, a VLM-based reasoning agent enters a dynamic loop where it retrieves top-k candidates, evaluates the gathered evidence in working memory, and autonomously decides whether to answer or generate a refined query to fetch additional pages. This agentic feedback loop allows the system to actively distinguish between relevant and irrelevant information, moving beyond static, single-pass retrieval methods.

SimpleDoc demonstrated superior performance across four DocVQA datasets, achieving an average performance improvement of **3.2% in ANLS** (Average Normalized Levenshtein Similarity) over previous baselines. It attained state-of-the-art (SOTA) results on benchmarks including MP-DocVQA and MMLongBench-Doc. Notably, the framework achieved these higher accuracy scores while requiring significantly fewer page retrievals compared to competitors such as Vanilla RAG with VLM, M3DocRAG, and MDocAgent. This reduction in retrieval volume underscores the model's precision, as it outperforms adapted text-RAG methods like Chain-of-Notes and Plan*RAG in handling complex, cross-referencing queries.

The significance of this work lies in demonstrating that a lightweight, retrieval-augmented framework can effectively handle the intricacies of multi-modal document understanding without the computational overhead typical of large-scale models. By successfully balancing the volume of information retrieved with answer accuracy, SimpleDoc establishes a new standard for agentic workflows in document AI.

***

## üîë Key Findings

*   **Performance Boost:** SimpleDoc achieves an average performance improvement of **3.2%** over previous baselines across four Document Visual Question Answering (DocVQA) datasets.
*   **High Efficiency:** The framework operates with high efficiency, requiring significantly fewer page retrievals to achieve state-of-the-art results.
*   **Multi-Modal Handling:** The approach effectively handles the complexity of multi-modal information (such as images and tables) within multi-page documents.
*   **Dynamic Evidence Gathering:** The iterative retrieval mechanism allows the system to confidently answer complex questions by dynamically gathering necessary evidence.

***

## üõ†Ô∏è Methodology

SimpleDoc utilizes a Retrieval Augmented Generation (RAG) pipeline designed specifically for Document Visual Question Answering. The methodology is defined by two primary components:

1.  **Dual-Cue Retrieval Strategy:**
    *   First, the system identifies candidate pages through **embedding similarity**.
    *   Second, it filters and re-ranks these candidates using **generated page summaries**.
2.  **Iterative Refinement:**
    *   A single Visual Language Model (VLM)-based reasoner agent repeatedly invokes the dual-cue retriever.
    *   The agent pulls fresh pages into a working memory loop until sufficient evidence is gathered to answer the question.

***

## ‚öôÔ∏è Technical Details

SimpleDoc is a dual-stage framework for multi-page, multi-modal Document Visual Question Answering (DocVQA) that integrates Retrieval-Augmented Generation (RAG) with an agentic iterative loop.

### Stage 1: Offline Document Processing
Treats individual pages as retrieval units, generating **'Dual-Cue'** representations:
*   **Visual Vector Embeddings:** Generated using VLMs like **ColPali** or **ColQwen**.
*   **Semantic Summaries:** 3-5 sentence text summaries generated by a general VLM.

### Stage 2: Online Iterative Retrieval-Augmented QA
Involves a reasoning loop with memory and dynamic query refinement:
*   **Text-only Reasoning Agent:** Selects relevant summaries.
*   **Retriever:** Fetches Top-k page images based on embedding matching.
*   **VLM Reasoning Agent:** Iteratively updates memory and decides whether to answer the query or generate a new query to retrieve additional pages.
    *   *Distinction:* This active feedback loop differentiates it from standard 'Vanilla RAG'.

***

## üìä Research Contributions

*   **SimpleDoc Framework:** Introduction of a lightweight yet powerful retrieval-augmented framework specifically tailored for multi-modal DocVQA tasks.
*   **Advanced Retrieval Strategy:** Development of a dual-cue page retrieval mechanism that enhances evidence gathering by combining visual embedding similarity with textual summary-based filtering.
*   **Iterative Agent Workflow:** Implementation of a dynamic reasoning loop where a VLM agent autonomously decides when to retrieve more information, optimizing the balance between information retrieval volume and answer accuracy.

***

## üèÜ Results & Performance

SimpleDoc achieves an average performance gain of **+3.2%** over previous baselines across four DocVQA datasets, including **MP-DocVQA** and **MMLongBench-Doc**.

*   **State-of-the-Art (SOTA):** Attains SOTA results with significantly fewer page retrievals, indicating higher precision and reduced computational load.
*   **Baseline Comparison:** The system outperforms baselines such as:
    *   Vanilla RAG with VLM
    *   M3DocRAG
    *   MDocAgent
    *   Adapted text-RAG methods (Chain-of-Notes, Plan*RAG)
*   **Robustness:** Demonstrates superior capability in handling complex queries requiring cross-referencing and synthesis of multi-modal information.