# A Safety and Security Framework for Real-World Agentic Systems

*Shaona Ghosh; Barnaby Simkin; Kyriacos Shiarlis; Soumili Nandi; Dan Zhao; Matthew Fiedler; Julia Bazinska; Nikki Pope; Roopa Prabhu; Daniel Rohrer; Michael Demoret; Bartley Richardson*

---

> ### **Quick Facts & Key Metrics**
>
> *   **Dataset Size:** >10,000 attack and defense execution traces.
> *   **Case Study:** NVIDIA AI-Q Research Assistant (AIRA blueprint).
> *   **Core Focus:** Enterprise agentic systems and emergent risks.
> *   **Novel Risks Identified:** Tool misuse, cascading action chains, unintended control amplification.
> *   **Resource Release:** Nemotron-AIQ-Agentic-Safety-Dataset-1.0.

---

## Executive Summary

This research addresses the critical challenge of securing agentic AI systems—where large language models (LLMs) autonomously interact with tools and data—which introduces complexities that render traditional static safety measures ineffective. Unlike isolated LLMs, agentic systems exhibit safety and security as emergent properties arising from dynamic interactions between models, orchestrators, and external environments. This distinction is vital because it creates novel risk categories such as tool misuse, cascading action chains, and unintended control amplification, all of which occur in enterprise settings where safety and security protocols are inextricably linked.

The authors propose a dynamic safety framework that utilizes auxiliary AI models and agents under human oversight to perform contextual risk discovery and mitigation throughout the system lifecycle. Technically, the framework operates by first mapping a unified "Agentic Risk Taxonomy" to identify specific multi-step vulnerabilities unique to autonomous agents. It then executes a two-phase operational workflow: a Discovery Phase featuring sandboxed, AI-driven red teaming where Attacker and Evaluator agents simulate complex attacks, followed by a Mitigation Phase that deploys embedded defenses and Defender Agents to contextually block unauthorized actions in real-time.

The framework was validated through an end-to-end evaluation of NVIDIA's AI-Q Research Assistant, generating the Nemotron-AIQ-Agentic-Safety-Dataset-1.0, a benchmark comprising over 10,000 realistic traces of attack and defense executions. While the paper notes qualitative success in identifying novel agentic risks that isolated LLM red teaming misses, it also analyzes behavior through metrics such as Attack Propagation Patterns and the Effect of Guardrails. The results demonstrate that the system successfully contextualizes and mitigates risks within a complex enterprise workflow, handling thousands of execution cycles without compromising the agentic utility.

This work significantly advances the field by shifting the focus from static content filtering to dynamic interaction-based security, providing enterprises with a practical blueprint for deploying autonomous agents safely. By unifying traditional safety protocols with agentic-specific defense mechanisms, the study establishes a new operational standard for securing AI systems that operate with high degrees of autonomy. Furthermore, the release of a comprehensive dataset of over 10,000 traces offers the research community a valuable resource for future benchmarking, encouraging the development of more robust safety architectures for real-world agentic applications.

---

## Key Findings

*   **Emergent Properties:** In agentic systems, safety and security are emergent properties arising from dynamic interactions between models, orchestrators, tools, and data, rather than static attributes.
*   **Inextricable Link:** Safety and security are inextricably linked in enterprise agentic systems, unlike in isolated LLMs where they are distinct.
*   **Novel Risk Categories:** The research identifies novel risk categories specific to agentic systems, including tool misuse, cascading action chains, and unintended control amplification.
*   **Validation:** The proposed framework effectively discovers and contextually mitigates these novel risks in complex enterprise workflows, as demonstrated by the NVIDIA AI-Q Research Assistant case study.

---

## Methodology

The authors utilized a conceptual framework that treats agentic systems as holistic environments where risks emerge from component interactions. They constructed a taxonomy integrating traditional and agentic-specific risks and employed a dynamic operational framework involving auxiliary AI models and agents under human oversight.

The methodology included:
*   **Operational Strategy:** Utilization of auxiliary AI models and agents.
*   **Testing:** Automated, sandboxed, AI-driven red teaming.
*   **Validation:** An end-to-end evaluation of NVIDIA's AI-Q Research Assistant involving over 10,000 attack and defense executions.

---

## Technical Details

**Framework Architecture**
The paper proposes a dynamic safety and security framework for enterprise agentic systems, treating safety and security as emergent properties from interactions between four key components:
*   Models
*   Orchestrators
*   Tools
*   Data

**Risk Taxonomy**
The framework defines an *Agentic Risk Taxonomy* identifying novel risks unique to these systems:
*   **Tool Misuse**
*   **Cascading Action Chains**
*   **Unintended Control Amplification**

**Operational Mechanism**
*   **Components:** Relies on auxiliary AI models and agents for contextual risk discovery, evaluation, and mitigation, combined with human oversight.
*   **Phases of Operation:**
    1.  **Discovery Phase:** Sandboxed AI-driven red teaming utilizing Attacker and Evaluator Agents.
    2.  **Mitigation Phase:** Embedded defenses and Defender Agents.

**Implementation**
*   Demonstrated using the NVIDIA AI-Q Research Assistant on the AIRA blueprint.

---

## Results

*   **Dataset Generation:** The study generated the *Nemotron-AIQ-Agentic-Safety-Dataset-1.0* consisting of >10,000 realistic traces covering attack and defense executions.
*   **Qualitative Outcomes:** The framework successfully discovered novel agentic risks specific to these systems (risks not found in isolated LLMs) and demonstrated contextual mitigation in an end-to-end enterprise workflow.
*   **Metrics:** Analysis included *Attack Propagation Patterns* and the *Effect of Guardrails*. Specific numerical values were not provided in the text.

---

## Contributions

*   A comprehensive, actionable dynamic safety framework specifically designed for securing agentic AI systems in enterprise deployments.
*   A unified operational taxonomy that bridges the gap between traditional safety protocols and the unique challenges of autonomous agents.
*   A practical contextual risk management strategy using a combination of auxiliary AI agents, human oversight, and AI-driven red teaming in sandboxed environments.
*   A benchmark dataset containing traces of over 10,000 attack and defense executions from the AI-Q Research Assistant case study.

---

## Quality Score

**8/10**

---

## References

0