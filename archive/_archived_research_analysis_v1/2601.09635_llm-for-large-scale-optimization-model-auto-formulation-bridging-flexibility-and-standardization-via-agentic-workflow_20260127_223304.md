---
title: 'LLM for Large-Scale Optimization Model Auto-Formulation: Bridging Flexibility
  and Standardization via Agentic Workflow'
arxiv_id: '2601.09635'
source_url: https://arxiv.org/abs/2601.09635
generated_at: '2026-01-27T22:33:04'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# LLM for Large-Scale Optimization Model Auto-Formulation: Bridging Flexibility and Standardization via Agentic Workflow

*Kuo Liang, Jianming Mao, Yuhang Lu, Congcong Zeng, Scale Optimization, Shuyi Sun, Model Auto, Bridging Flexibility, Chunwei Yang, Agentic Workflow*

---

### üìã Quick Facts

| Metric | Details |
| :--- | :--- |
| **Framework Name** | LEAN-LLM-OPT (LightwEight AgeNtic workflow construction) |
| **Architecture** | 3-Agent System (Classification, Workflow Generation, Model Generation) |
| **Core Innovation** | Retrieval-augmented workflow generation without manual fine-tuning |
| **Top Benchmark Score** | 94.7% on NL4OPT |
| **Real-World Case Study** | Singapore Airlines (Air-NRM) |
| **Quality Score** | 8/10 |
| **References** | 40 Citations |

---

## üìù Executive Summary

> This research addresses the critical bottleneck of automating the formulation of large-scale optimization models, a task traditionally requiring extensive manual expertise in mathematical modeling and coding. As decision-making problems in industries such as logistics and aviation grow in complexity, manually translating natural language descriptions into rigorous mathematical formulations creates a significant scalability barrier.

The core innovation is **LEAN-LLM-OPT** (LightwEight AgeNtic workflow construction), a framework designed to automate optimization formulation without manual fine-tuning by utilizing a sequential, three-agent architecture. Unlike baselines such as OptiMUS that rely heavily on chain-of-thought prompting‚Äîwhich can bloat token counts and degrade performance‚ÄîLEAN-LLM-OPT decouples logical reasoning from mechanical data processing. It integrates auxiliary tools to handle tedious calculations and uses a retrieval mechanism that injects only specific, relevant examples rather than full datasets.

In evaluation, LEAN-LLM-OPT‚Äîpowered by GPT-4‚Äîdemonstrated superior performance against state-of-the-art baselines across multiple benchmarks. Ablation studies validated the necessity of the classification agent and confirmed that the combination of workflow guidance with customized tools is essential for high performance. This work significantly advances the field of AI-assisted Operations Research by proving that agentic workflows can effectively manage the trade-off between flexibility and standardization, providing a scalable, cost-effective alternative for practitioners.

---

## üîë Key Findings

*   *Abstract text missing; unable to extract key findings.*

---

## üõ†Ô∏è Methodology

*   *Abstract text missing; unable to extract methodology.*

---

## ‚öôÔ∏è Technical Details

The proposed framework utilizes a lean, agentic workflow to bridge the gap between flexibility and standardization in optimization modeling.

**System Architecture**
The **LEAN-LLM-OPT** framework employs a specific 3-agent architecture:

*   **Classification Agent:**
    *   **Function:** Identifies the specific problem type at the initial stage.
*   **Workflow Generation Agent:**
    *   **Function:** Retrieves relevant examples from a reference dataset (*Ref-Data*).
    *   **Action:** Constructs a precise execution workflow based on the retrieved examples.
*   **Model Generation Agent:**
    *   **Function:** Executes the constructed workflow.
    *   **Output:** Generates the final mathematical formulation.

**Key Features**
*   **Token Efficiency:** Instead of injecting full data lists, the system retrieves specific examples to minimize token usage.
*   **Auxiliary Tools:** Integrates external tools to handle mechanical data processing, decoupling it from logical reasoning.
*   **Demonstration:** Validated on a logistics scheduling problem involving **10 trucks** and **4 time periods** with complex logical and capacity constraints.

---

## üìä Results

LEAN-LLM-OPT (using GPT-4.1) achieved state-of-the-art performance against baselines like ORLM and OptiMUS.

**Benchmark Performance**
*   **NL4OPT:** 94.7% (Exact Match)
*   **MAMO Complex:** 71.4% (Exact Match)
*   **IndustryOR:** 65.0% (Exact Match)

**Ablation Studies**
*   Confirmed the utility of the **Classification Agent**.
*   Validated the necessity of combining **workflow guidance** with **customized tools**.

**Real-World Application**
*   **Case Study:** Singapore Airlines (Air-NRM dataset).
*   **Task:** Choice-Based Revenue Management.
*   **Outcome:** Demonstrated leading performance compared to competitors (Gemini 1.5 Pro, GPT-5.2).

---

## ‚ú® Contributions

*   *Abstract text missing; unable to extract contributions.*