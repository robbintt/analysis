---
title: 'David vs. Goliath: Can Small Models Win Big with Agentic AI in Hardware Design?'
arxiv_id: '2512.05073'
source_url: https://arxiv.org/abs/2512.05073
generated_at: '2026-02-03T06:52:31'
quality_score: 7
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# David vs. Goliath: Can Small Models Win Big with Agentic AI in Hardware Design?

*Shashwat Shankar; Subhranshu Pandey; Innocent Dengkhw Mochahari; Bhabesh Mali; Animesh Basak Chowdhury; Sukanta Bhattacharjee; Chandan Karfa*

---

### ðŸ“Š Quick Facts

| Metric | Details |
| :--- | :--- |
| **Benchmark** | NVIDIA Comprehensive Verilog Design Problems (CVDP) |
| **Dataset Size** | 336 problems (derived from production IP blocks) |
| **Model Parameters** | <20B (SLMs: Phi-3.5, DeepSeek-R1, Qwen-Coder, SmolLM2) |
| **Energy Efficiency** | ~13Ã— lower consumption than GPT-4o-mini |
| **Cost Comparison** | Medium SoC processing: $15kâ€“$45k (LLMs) vs. significantly lower (SLMs) |
| **Pass Rate (Baseline)** | Generic SLM: 35â€“45% \| Framework Goal: Rivaling ChipNeMo (72.3%) |

---

## Executive Summary

This research addresses the prohibitive computational and monetary costs associated with deploying Large Language Models (LLMs) for specialized engineering tasks, specifically Register Transfer Level (RTL) hardware design. While LLMs have demonstrated proficiency in generating Verilog code, their massive scale results in unsustainable energy footprints and high inference costsâ€”often ranging from $15,000 to $45,000 for medium-scale System-on-Chip (SoC) processing. The paper challenges the prevailing industry assumption that scaling up foundation models is the only viable path to high performance, highlighting the urgent need for efficient alternatives that can maintain design integrity without the significant resource burden of "Goliath"-sized models.

The core innovation is an **"SLM-aware Agentic Framework"** designed to empower Small Language Models (SLMs) with fewer than 20 billion parameters to perform complex reasoning typically reserved for larger models. The architecture orchestrates five cooperating agents in a "senior mentor" and "junior engineer" dynamic, utilizing scaffolding mechanisms such as task decomposition, iterative refinement loops, and autonomous error correction. This workflow fosters adaptive behavior by allowing agents to dynamically adjust strategies based on intermediate verification feedback, effectively compensating for the inherent limitations of SLMs by optimizing for **"intelligence per watt"** rather than raw parameter scale.

Experimental validation on the CVDP benchmark demonstrates that the agentic approach significantly narrows the performance gap between SLMs and state-of-the-art LLMs. While generic single-shot SLMs typically achieve a pass rate of only 35â€“45%, the proposed framework enables SLMs to achieve performance levels rivaling advanced baselines like ChipNeMo (72.3%) and RTLCoder (82.3%). Crucially, energy consumption tests revealed that DeepSeek-7B utilized only **0.55 Â± 0.06 Wh** compared to GPT-4o-miniâ€™s **7.24 Â± 1.67 Wh**â€”a roughly **13Ã— reduction** in energy usage. This efficiency translates to massive potential monetary savings, reducing the operational costs that traditionally reach $15,000â€“$45,000 per SoC design by an order of magnitude.

---

## Key Findings

*   **Cost & Efficiency:** Small Language Models (SLMs) integrated with an agentic AI framework achieve performance comparable to Large Language Models (LLMs) at a significantly lower computational and monetary cost.
*   **Critical Mechanisms:** The study confirms that specific agentic mechanismsâ€”**task decomposition**, **iterative feedback loops**, and **correction**â€”are critical in bridging the performance gap between small and large models.
*   **Validation:** The proposed approach was successfully validated on NVIDIA's Comprehensive Verilog Design Problems (CVDP) benchmark, demonstrating viability for complex hardware design tasks.
*   **Sustainability:** The research challenges the necessity of scaling foundation models for domain-specific tasks, presenting a sustainable alternative that reduces energy and compute demands.
*   **Adaptive Learning:** Beyond immediate task completion, the agentic workflow creates learning opportunities for the agents, fostering adaptive behavior in complex design scenarios.

---

## Methodology

The researchers employed a comparative evaluation strategy using Small Language Models (SLMs) enhanced by a curated agentic AI framework.

*   **Domain Focus:** Hardware design, specifically Verilog coding problems.
*   **Benchmarking:** Models were tested against NVIDIA's Comprehensive Verilog Design Problems (CVDP) benchmark.
*   **Agentic Strategies:** The 'agentic' component utilized specific operational strategies:
    *   **Task Decomposition:** Breaking complex problems into smaller, manageable steps.
    *   **Iterative Feedback:** Refining outputs based on intermediate results.
    *   **Correction:** Fixing errors autonomously without human intervention.

---

## Technical Details

### System Architecture
The paper proposes an **'SLM-aware Agentic Framework'** designed to enable Small Language Models (SLMs, <20B parameters) to perform complex Register Transfer Level (RTL) hardware design tasks.

*   **Target Models:** Phi-3.5, DeepSeek-R1, Qwen-Coder, and SmolLM2.
*   **Agent Structure:** The system consists of five cooperating agents acting as a **'senior mentor'** to the **'junior engineer'** (SLM).
*   **Scaffolding Mechanisms:** To compensate for SLM limitations, the framework utilizes:
    *   Task decomposition
    *   Iterative refinement with feedback loops
    *   Context preparation
*   **Workflow:** Transforms design intent from the CVDP dataset into verified RTL code through:
    1.  **Planning**
    2.  **Coding**
    3.  **Verification**
*   **Optimization Goal:** Optimizing for 'intelligence per watt' rather than raw scaling.

---

## Results & Performance

Experimental analysis indicates that SLMs offer significant cost and energy advantages over Large Language Models.

### Energy Consumption
*(Tests based on 10k input / 1.5k output tokens)*
*   **DeepSeek-7B:** 0.55 Â± 0.06 Wh
*   **GPT-4o-mini:** 7.24 Â± 1.67 Wh
*   **Result:** DeepSeek-7B demonstrated **~13Ã— lower energy usage**.

### Inference Costs
*   **GPT-4:** ~$0.03 per 1K output tokens.
*   **Medium SoC Processing:** $15,000â€“$45,000 (Traditional LLM approach).

### Performance Baselines (CVDP Benchmark)
*   **Generic Single-shot SLMs:** 35â€“45% pass rate.
*   **ChipNeMo:** 72.3% pass rate.
*   **RTLCoder:** 82.3% pass rate.
*   **Proposed Framework:** Aims to bridge the gap between single-shot SLMs and Large LLMs while maintaining the low compute profile of SLMs.

---

## Contributions

1.  **Challenging Assumptions:** The work challenges the prevailing assumption that 'bigger is always better' for hardware design, providing evidence that smaller, efficient models can rival LLMs when augmented correctly.
2.  **Framework Innovation:** The introduction and validation of a curated agentic AI framework that unlocks high-level reasoning capabilities in smaller parameter models.
3.  **Sustainability:** A practical contribution towards reducing the massive compute and energy footprint typically associated with LLM inference in specialized engineering domains.
4.  **Foundation for Adaptive AI:** Establishes a foundation for developing efficient, adaptive AI solutions that can learn and improve within complex design workflows without relying on massive-scale infrastructure.

---

**Quality Score:** 7/10
**References:** 40 citations