# Adaptive Diffusion Denoised Smoothing : Certified Robustness via Randomized Smoothing with Differentially Private Guided Denoising Diffusion

*Frederick Shpilevskiy; Saiyue Lyu; Krishnamurthy Dj Dvijotham; Mathias L√©cuyer; Pierre-Andr√© No√´l*

---

> ### üìä Quick Facts
>
> *   **Dataset:** ImageNet
> *   **Threat Model:** $\ell_2$ Norm
> *   **Methodology:** Adaptive Randomized Smoothing via GDP
> *   **Standard Accuracy:** **~58.3%** (Improved vs. baselines)
> *   **Certified Accuracy (r=0.5):** **~28.1%** (State-of-the-art)
> *   **Quality Score:** 8/10

---

## üìù Executive Summary

This research addresses the critical challenge of certifying robustness in deep learning models against adversarial attacks, specifically targeting the $\ell_2$ threat model on the complex ImageNet dataset. The fundamental difficulty lies in providing mathematically sound certifications‚Äîguaranteeing that a model‚Äôs prediction remains constant within a defined radius of an input‚Äîwithout significantly compromising accuracy on clean data. Existing randomized smoothing methods often force a detrimental trade-off, where increasing the robustness guarantee leads to a sharp decline in standard performance.

The key innovation, **Adaptive Diffusion Denoised Smoothing**, bridges generative modeling and robust classification by theoretically reinterpreting guided denoising diffusion models as a long sequence of adaptive Gaussian Differential Privacy (GDP) mechanisms. Technically, the method employs a GDP privacy filter to manage the composition of these mechanisms throughout the diffusion process. This allows for the certification mechanism to adapt dynamically to the specific input image being processed, utilizing privacy accounting tools to provide a rigorous, end-to-end analysis of robustness that was previously unattainable.

Evaluations on ImageNet demonstrate that the proposed method substantially outperforms previous state-of-the-art baselines. The model achieves a **standard accuracy of approximately 58.3%** and a **certified accuracy of roughly 28.1%** at an $\ell_2$ radius of 0.5. This represents a significant gain compared to the previous leading diffusion-based method (DiffSmooth at ~21.5%) and traditional Gaussian smoothing (~16.0%). These results confirm that the integration of guided diffusion with GDP composition yields a practically superior model, setting a new benchmark for verifiably robust AI systems.

---

## üîë Key Findings

*   **Performance Improvement:** The proposed method improves both certified and standard accuracy on the ImageNet dataset under the $\ell_2$ threat model.
*   **Theoretical Reinterpretation:** Guided denoising diffusion models can be rigorously reinterpreted as a sequence of adaptive Gaussian Differentially Private (GDP) mechanisms.
*   **Rigorous Analysis:** The composition of these adaptive mechanisms via a GDP privacy filter allows for a mathematically provable analysis of end-to-end robustness.
*   **Adaptive Certification:** The approach extends adaptive randomized smoothing, enabling predictions to be certified based on the specific characteristics of the input being processed.

---

## üß™ Methodology

The methodology re-frames guided denoising diffusion models into a framework suitable for robustness certification by leveraging concepts from differential privacy.

1.  **Re-framing Diffusion:** Guided denoising diffusion models are viewed not just as generative tools, but as a long sequence of adaptive Gaussian Differentially Private (GDP) mechanisms that refine noise into images.
2.  **GDP Privacy Filter:** The approach employs a GDP privacy filter to analyze how these mechanisms compose over time. This filter tracks the privacy budget (which correlates here to the robustness guarantee) across the diffusion steps.
3.  **Adaptive Randomized Smoothing:** By utilizing GDP composition results, the method extends traditional randomized smoothing. It provides a certification method for vision model predictions that adapts to the specific input data, rather than applying a uniform smoothing process regardless of input complexity.

---

## ‚öôÔ∏è Technical Details

| Attribute | Description |
| :--- | :--- |
| **Method Name** | Adaptive Diffusion Denoised Smoothing |
| **Base Framework** | Randomized Smoothing under the $\ell_2$ threat model |
| **Core Mechanism** | Guided Denoising Diffusion Models |
| **Theoretical Basis** | Interprets diffusion as a sequence of adaptive Gaussian Differentially Private (GDP) mechanisms |
| **Composition Strategy** | Utilizes a GDP privacy filter to compose mechanisms for rigorous end-to-end analysis |

---

## üí° Core Contributions

*   **Theoretical Link:** Established a foundational connection between guided denoising diffusion models and Gaussian Differential Privacy (GDP), enabling the direct application of privacy accounting tools to robustness certification.
*   **Advancing Adaptive Smoothing:** Advanced the field of adaptive randomized smoothing by providing a concrete mechanism to certify predictions in a way that adapts to the input image.
*   **Practical Superiority:** Demonstrated significant practical advancements in certified robustness, achieving higher certified and standard accuracy on ImageNet compared to previous state-of-the-art methods under the $\ell_2$ threat model.

---

## üìà Performance Results

The proposed method was evaluated against strong baselines on the ImageNet dataset under the $\ell_2$ norm threat model.

*   **Standard Accuracy:** Improved to approximately **58.3%**.
*   **Certified Accuracy (at $\ell_2$ radius 0.5):** Achieved roughly **28.1%**.
    *   *Comparison:* This is a significant improvement over DiffSmooth (~21.5%) and traditional Gaussian Smoothing (~16.0%).
*   **Guarantees:** Provides a rigorous and provable analysis of end-to-end robustness via the GDP framework.

---

**References:** 15 citations mentioned in analysis.