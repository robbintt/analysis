---
title: What Affects the Effective Depth of Large Language Models?
arxiv_id: '2512.14064'
source_url: https://arxiv.org/abs/2512.14064
generated_at: '2026-02-03T18:46:46'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# What Affects the Effective Depth of Large Language Models?
*Yi Hu; Cai Zhou; Muhan Zhang*

---

> ### üìä Quick Facts
> ---
> *   **Quality Score:** 9/10
> *   **References:** 40 Citations
> *   **Models Analyzed:** Qwen-2.5 (1.5B‚Äì32B), DeepSeek-R1-Distill
> *   **Benchmarks:** HellaSwag, GSM8K, AIME24
> *   **Key Insight:** Effective Depth Ratio remains constant (~0.61‚Äì0.73) regardless of model scale.

---

## üìù Executive Summary

As Large Language Models (LLMs) scale, architectures rely on increased depth to boost performance, raising the critical question of whether added layers translate to proportional computational utility. This paper addresses the pervasive issue of **depth underutilization**, investigating whether added parameters are actually engaged during inference.

The authors define **"Effective Depth" (ED)** as the specific layer index where the model transitions from feature composition to output refinement, and **"Effective Depth Ratio" (EDR)** as the normalized metric $(ED + 1) / L$. Understanding this transition is vital for optimizing efficiency; if models consistently rely on only a fraction of their layers, current scaling strategies may be computationally wasteful.

The study introduces a rigorous diagnostic framework utilizing mechanistic interpretability techniques to quantify effective depth across various scales and training paradigms. The methodology analyzes Pre-norm Transformer architectures, specifically the Qwen-2.5 family (1.5B‚Äì32B) and DeepSeek-R1-Distill models.

**Major Highlights:**
*   **Static Utilization:** Experiments reveal that while absolute effective depth increases with model scale, the EDR remains constant across the Qwen-2.5 family (approximately 0.61‚Äì0.73). Larger models do not proportionally utilize their added depth.
*   **Probing Discrepancy:** A notable discrepancy was observed between probing methods: Residual Cosine Similarity indicated EDRs of 0.6‚Äì0.7, whereas Logit Lens suggested significantly higher ratios of 0.9‚Äì0.97. This suggests internal features stabilize earlier than output probabilities.
*   **Reasoning & Context:** Comparisons between base models and long Chain-of-Thought (long-CoT) models (DeepSeek-R1) showed no increase in EDR. Reasoning improvements are attributed to longer *generated reasoning traces* rather than deeper per-token computation.
*   **Fixed Budget:** Layer utilization is static, failing to adapt to task difficulty, suggesting the model's depth budget is fixed during training rather than dynamically allocated.

This research fundamentally shifts the understanding of LLM efficiency by demonstrating that depth underutilization is a systemic issue. It highlights opportunities for model optimization through layer pruning and early exiting mechanisms.

---

## üîç Key Findings

*   **Scale Invariance:** The effective depth ratio remains constant across the Qwen-2.5 family (1.5B‚Äì32B parameters). Larger models do not proportionally utilize their added depth.
*   **Long-CoT Misconception:** Models trained for long Chain-of-Thought (long-CoT) do **not** exhibit increased effective depth compared to base models. Their reasoning improvement is attributed to longer context lengths rather than deeper per-token computation.
*   **Static Utilization:** LLMs exhibit static layer utilization and do not dynamically adapt their layer usage based on task complexity.
*   **Systemic Underutilization:** Current LLMs consistently underutilize the available depth across different scales, training paradigms, and task difficulties.

---

## üõ†Ô∏è Methodology

The study employed a systematic approach to isolate factors influencing depth utilization:

1.  **Scale Analysis:** Conducted analysis on the Qwen-2.5 model family, ranging from 1.5 billion to 32 billion parameters, to observe correlations between model size and effective depth.
2.  **Paradigm Comparison:** Performed comparative evaluations between standard base models and long-CoT models to isolate the impact of reasoning-specific training on layer utilization.
3.  **Difficulty Assessment:** Assessed model behavior across a spectrum of tasks with varying difficulty levels to determine if layer utilization is dynamic or static relative to problem complexity.

---

## ‚öôÔ∏è Technical Details

*   **Architecture:** Pre-norm Transformer with RMSNorm.
*   **Core Mechanism:** The residual stream $h_l$ is updated via self-attention and MLP layers.
*   **Diagnostic Tools:**
    *   Residual Cosine Similarity (calculating cosim of layer outputs vs. residual states)
    *   Logit Lens (KL Divergence & Overlap)
    *   Layer Effects
    *   Residual Erasure
    *   Integrated Gradients
*   **Key Metrics:**
    *   **Effective Depth (ED):** The transition point from feature composition to refinement.
    *   **Effective Depth Ratio:** Calculated as $(ED + 1) / L$.

---

## üìà Results

*   **Constant Ratios:** Across models ranging from 1.5B to 32B parameters (HellaSwag, GSM8K, AIME24), the effective depth ratio remained constant (approx. 0.61‚Äì0.73) despite increases in absolute effective depth.
*   **Long-CoT Performance:** Long Chain-of-Thought models (DeepSeek-R1) showed no higher effective depth ratio than base models, confirming performance gains derive from context length, not depth.
*   **Task Difficulty Independence:** Effective depth remains static regardless of task difficulty.
*   **Methodological Variance:** There is a notable discrepancy between probing methods: Cosine Similarity indicates ratios of 0.6‚Äì0.7, whereas Logit Lens indicates ratios of 0.9‚Äì0.97.

---

## üåü Contributions

*   **Diagnostic Framework:** Provided a framework analyzing factors influencing effective depth (scale, training, and difficulty), establishing depth underutilization as a pervasive issue.
*   **Clarified Reasoning Gains:** Clarified that reasoning gains in long-CoT models come from longer context lengths rather than deeper computation, dispelling previous assumptions.
*   **Future Directions:** Identified research directions aimed at increasing layer utilization rates, optimizing model pruning, and improving early exiting mechanisms.
*   **Open Source:** Released the code used for analysis to facilitate further research.