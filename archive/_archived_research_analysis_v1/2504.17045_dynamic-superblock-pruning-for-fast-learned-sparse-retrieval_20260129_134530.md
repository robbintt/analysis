# Dynamic Superblock Pruning for Fast Learned Sparse Retrieval

*Parker Carlson; Wentai Xie; Shanxiu He; Tao Yang*

---

> ### ðŸ’¡ Quick Facts
> *   **Dataset:** MS MARCO Passage (8.8M passages)
> *   **Test Environment:** Single-threaded Intel i7-1260P
> *   **Key Models:** SPLADE
> *   **Peak Speedup:** 7.5x faster than ASC (Approximate, Top-10)
> *   **Exact Search Speedup:** 12x faster than MaxScore (Top-1000)
> *   **Quality Score:** 9/10

---

## Executive Summary

Learned sparse retrieval (LSR) models like SPLADE offer a compelling blend of neural effectiveness and term-based interpretability, but their industrial adoption is frequently hindered by high computational costs and latency. While these models generate high-quality sparse representations, standard indexing methods often struggle to process them efficiently on commodity hardware, typically requiring expensive GPU acceleration to achieve acceptable query speeds. This paper addresses the fundamental challenge of accelerating LSR to make it viable for deployment in CPU-constrained environments.

The authors introduce **Superblock Pruning (SP)**, a dynamic two-level hierarchical indexing framework designed specifically for learned sparse models. SP organizes document collections into base blocks and aggregated "superblocks," precomputing three key metadata statistics for every term: *Block Max*, *Superblock Max*, and *Superblock Average Max*. The retrieval algorithm operates top-down, first utilizing these statistics to prune entire superblocks that cannot meet score thresholds before descending to evaluate individual blocks. This structure allows the system to aggressively skip large portions of the index early in the retrieval process, moving beyond the limitations of flat or cluster-based pruning techniques.

Evaluations using SPLADE models on the MS MARCO Passage dataset with a single-threaded CPU demonstrate that SP delivers substantial speedups in both approximate and rank-safe (exact) retrieval modes. In approximate mode with a 99% recall budget, SP achieved a mean response time of 0.629 ms, outperforming Block Max Pruning (BMP) by 2.3x, Seismic by 3.3x, and Adaptive Conjunctive Selection (ASC) by 7.5x. Crucially, the method also accelerates exact retrieval, achieving speeds 1.3x faster than BMP for top-10 search and 12x faster than MaxScore for top-1000 search, proving that the efficiency gains are not limited to approximate results.

This research establishes that high-performance LSR is feasible on standard, single-threaded CPUs without the need for GPU acceleration, effectively removing a major barrier to deployment. By successfully supporting both rigorous exact search and highly efficient approximate search within a single framework, SP sets a new standard for LSR indexing latency.

---

## Key Findings

*   **Superior Performance:** The proposed Superblock Pruning (SP) scheme significantly outperforms state-of-the-art baselines on the MS MARCO passages dataset.
*   **CPU Efficiency:** The method achieves impressive speed improvements on a **single-threaded CPU**, demonstrating high computational efficiency without requiring parallel hardware acceleration.
*   **Dual Mode Capability:** SP is capable of accelerating sparse retrieval in both a **rank-safe (exact) manner** and an **approximate manner**, offering flexibility for different use cases.
*   **Early Pruning:** The approach effectively identifies groups of documents that are unlikely to appear in the final top-k results early in the process, minimizing unnecessary calculations.

---

## Methodology

The paper proposes **Superblock Pruning (SP)**, a method applied during top-k online document retrieval for learned sparse representations.

*   **Hierarchical Structuring:** The methodology involves structuring the sparse index hierarchically as a set of superblocks positioned over a sequence of document blocks.
*   **Top-Down Selection:** The core mechanism performs a superblock-level selection process where the system evaluates whether a superblock can be pruned **entirely** before descending to visit child blocks.
*   **Dynamic Pruning:** This dynamic approach allows the system to skip large sections of the index data that are irrelevant to the query, significantly reducing the search space.

---

## Technical Details

The paper proposes Superblock Pruning (SP), a two-level hierarchical index pruning mechanism for accelerating sparse retrieval on CPUs.

### Index Structure
*   **Base Layer:** The collection is divided into blocks ($B_i$) containing $b$ documents. These documents are reordered via clustering.
*   **Superblock Layer:** This layer aggregates $c$ consecutive blocks (typical parameters: $b=8$ or $16$, $c=64$).

### Metadata Statistics
The system precomputes three metadata statistics for every term:
1.  **Block Max ($W_{B,t}$)**
2.  **Superblock Max ($W_{X,t}$)**
3.  **Superblock Average Max ($\bar{W}_{X,t}$)**

### Pruning Algorithm
The dynamic pruning algorithm operates top-down with the following logic:
1.  **Superblock Pruning:** Prunes superblocks if:
    $$SB_{Max}(X) \le \theta/\mu \quad \text{and} \quad SB_{Avg}(X) \le \theta/\eta \quad (\text{where } \mu \le \eta)$$
2.  **Block Pruning:** Prunes individual blocks if:
    $$BoundSum(B) \le \theta/\eta$$

### Differentiation
*   **Vs. ASC:** SP uses consecutive blocks without randomness.
*   **Vs. BMP:** SP adds a superblock layer to skip large groups of blocks before evaluating block bounds.

---

## Results

The method was evaluated on the MS MARCO Passage dataset (8.8M passages) using SPLADE models on a single-threaded Intel i7-1260P.

### Approximate Retrieval Performance (k=10)

| Recall Budget | Mean Response Time (MRT) | Comparison |
| :--- | :--- | :--- |
| **99% Recall** | **0.629 ms** | 2.3x faster than BMP<br>3.3x faster than Seismic<br>7.5x faster than ASC |
| **99.9% Recall** | **0.785 ms** | Significant maintenance of speed at high recall |

### Large Scale Retrieval (k=1000)

| Recall Budget | Mean Response Time (MRT) |
| :--- | :--- |
| **99% Recall** | **1.74 ms** |

### Rank-Safe (Exact) Search Performance

| Metric | Result | Comparison |
| :--- | :--- | :--- |
| **Top-10 (k=10)** | **2.15 ms** | 1.3x faster than BMP |
| **Top-1000 (k=1000)** | **10.5 ms** | 12x faster than MaxScore |

---

## Contributions

*   **Novel Framework:** Introduction of a novel pruning framework designed specifically for learned sparse retrieval models called **Superblock Pruning (SP)**.
*   **Indexing Advancement:** Advancement of the state of indexing by moving beyond flat or cluster-based pruning to a dynamic superblock structure.
*   **Efficiency Balance:** Provision of a solution that maintains high-relevance competitiveness while reducing retrieval latency, offering a balance between computational speed and ranking accuracy.

---
**References:** 40 citations