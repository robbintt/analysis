---
ver: rpa2
title: Are LLMs Rational Investors? A Study on Detecting and Reducing the Financial
  Bias in LLMs
arxiv_id: '2402.12713'
source_url: https://arxiv.org/abs/2402.12713
tags:
- financial
- figure
- bias
- llms
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates financial irrationality in Large Language
  Models (LLMs) by introducing the Financial Bias Indicators (FBI) framework, which
  assesses models across two dimensions: belief bias (e.g., anchoring effects, representativeness
  bias) and risk-preference bias (e.g., loss aversion, situational dependence). The
  authors evaluate 19 leading LLMs on 600 Chinese companies across 16 event types
  and 40 risk scenarios, revealing varying degrees of financial irrationality influenced
  by model scale, training data, and input forms.'
---

# Are LLMs Rational Investors? A Study on Detecting and Reducing the Financial Bias in LLMs

## Quick Facts
- arXiv ID: 2402.12713
- Source URL: https://arxiv.org/abs/2402.12713
- Authors: Yuhang Zhou; Yuchen Ni; Yunhui Gan; Zhangyue Yin; Xiang Liu; Jian Zhang; Sen Liu; Xipeng Qiu; Guangnan Ye; Hongfeng Chai
- Reference count: 18
- One-line primary result: The FBI framework reveals varying degrees of financial irrationality across 19 leading LLMs, with larger models not necessarily more rational than smaller ones.

## Executive Summary
This paper introduces the Financial Bias Indicators (FBI) framework to systematically assess financial irrationality in Large Language Models (LLMs). The framework evaluates models across belief bias (cognitive biases like anchoring and representativeness) and risk-preference bias (loss aversion and framing effects) using 600 Chinese companies across 16 event types and 40 risk scenarios. The study finds that models trained on financial datasets may exhibit greater irrationality, and larger models are not necessarily more rational than smaller ones. Prompt engineering strategies like Chain-of-Thought reasoning can effectively reduce financial biases in LLMs.

## Method Summary
The FBI framework combines behavioral finance principles with bias detection methods to evaluate 19 leading LLMs on financial decision-making tasks. The evaluation uses 600 Chinese A-share companies across 16 event types and 40 risk scenarios, including 300 news pieces and 10 interaction pairs. Models are assessed for belief bias (anchoring, representativeness, overconfidence, limited attention) and risk-preference bias (situational dependence, loss aversion, framing effect) using prompt-based methods with direct, instructional, and Chain of Thought approaches. Results are analyzed using variance, correlation, ANOVA, and violin plots to identify bias patterns and evaluate mitigation strategies.

## Key Results
- Models trained on financial datasets exhibit greater irrationality and score variability compared to general models
- Larger models do not consistently show more rationality than smaller ones, contradicting scaling law expectations
- Chain-of-Thought prompting effectively moderates belief bias by encouraging deliberative reasoning
- Risk-preference biases show strong situational dependence, with models' choices varying significantly across gain/loss framings

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Behavioral finance theories provide a rigorous foundation for identifying and quantifying cognitive and risk-preference biases in LLMs.
- **Mechanism**: By grounding bias evaluation in well-established behavioral finance concepts—such as anchoring effect, loss aversion, and framing effect—the framework maps observable LLM output patterns onto known investor irrationalities, enabling structured bias detection.
- **Core assumption**: The biases exhibited by human investors in behavioral finance are analogous to the systematic errors made by LLMs in financial reasoning tasks.
- **Evidence anchors**:
  - [abstract]: "We introduce Financial Bias Indicators (FBI), a framework with components like Bias Unveiler, Bias Detective, Bias Tracker, and Bias Antidote to identify, detect, analyze, and eliminate irrational biases in LLMs."
  - [section 3.1]: "We adopt the classification proposed by (Barberis and Thaler, 2003), segmenting behavioral finance into Cognitive Bias and Limits to Arbitrage..."
  - [corpus]: "Found 25 related papers... Top related titles: From Bias to Behavior: Learning Bull-Bear Market Dynamics with Contrastive Modeling..."
- **Break condition**: If LLMs do not exhibit bias patterns that map cleanly onto human behavioral finance categories, the framework's diagnostic power diminishes.

### Mechanism 2
- **Claim**: Larger model size correlates with improved financial rationality, but this effect is not monotonic and can be offset by training data biases.
- **Mechanism**: Scaling law principles suggest larger models capture more nuanced patterns, but if trained on biased financial corpora, they may amplify certain irrationalities rather than reduce them.
- **Core assumption**: Model scale improves reasoning capacity, but the quality and bias of training data critically modulates this benefit.
- **Evidence anchors**:
  - [abstract]: "Models trained specifically on financial datasets may exhibit greater irrationality, and it’s possible that even larger financial language models (FinLLMs) could display more biases than smaller, more generalized models."
  - [section 6.2]: "Models trained on financial datasets are prone to heightened score variability and an increased inclination towards risk..."
  - [corpus]: Weak—no direct citations on training data bias effects in the corpus; this is an assumption based on general ML literature.
- **Break condition**: If larger models consistently outperform smaller ones regardless of training data, the dataset quality effect would be negligible.

### Mechanism 3
- **Claim**: Prompt engineering strategies such as Chain-of-Thought (COT) and instructional framing can systematically reduce financial biases in LLMs.
- **Mechanism**: COT encourages "slow thinking" reasoning, reducing reliance on immediate heuristic responses; instructional prompts align model behavior with desired risk profiles.
- **Core assumption**: Structured reasoning prompts can override or correct learned biases by enforcing deliberative processing.
- **Evidence anchors**:
  - [abstract]: "We utilize four prompt-based methods incorporating causal debiasing, effectively reducing financial biases in these models."
  - [section 5.1]: "Implementing the COT method to emulate a 'slow thinking' process effectively moderates the models’ susceptibility to belief bias."
  - [corpus]: Weak—no direct evidence in corpus about prompt-based debiasing; relies on internal findings.
- **Break condition**: If prompts do not consistently improve rationality across diverse models and scenarios, the debiasing effect is unreliable.

## Foundational Learning

- **Concept**: Behavioral finance and cognitive bias taxonomy
  - **Why needed here**: Provides the theoretical lens for categorizing LLM biases and designing targeted tests.
  - **Quick check question**: Can you name three cognitive biases relevant to financial decision-making and explain their impact?
- **Concept**: Expected utility theory and risk preference modeling
  - **Why needed here**: Underpins the construction of risk-preference scenarios and the interpretation of model choices.
  - **Quick check question**: How does the curvature of a utility function relate to risk aversion or seeking behavior?
- **Concept**: Prompt engineering and Chain-of-Thought reasoning
  - **Why needed here**: Enables controlled manipulation of model reasoning processes to mitigate biases.
  - **Quick check question**: What is the difference between a "fast" and "slow" thinking approach in LLM outputs?

## Architecture Onboarding

- **Component map**: Data Collector → Bias Evaluator (Belief Bias + Risk-Preference Bias modules) → Analyzer (Statistical + Topic Clustering) → Debiaser (Prompt-based interventions)
- **Critical path**: Data Collection → Bias Detection → Root Cause Analysis → Debiaser Application → Validation
- **Design tradeoffs**: Balancing comprehensiveness of bias detection with computational cost; using real-world event data vs. synthetic scenarios.
- **Failure signatures**: High variance in scores across identical events; strong industry or company size bias; failure to improve with COT prompts.
- **First 3 experiments**:
  1. Run the Bias Unveiler on a small set of news events to validate anchoring effect detection.
  2. Test risk-preference prompts on a single model and compare direct vs. instructional vs. COT outputs.
  3. Apply topic clustering to reasoning texts to identify thematic drivers of score instability.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the financial irrationality observed in LLMs stem primarily from training data biases or from model architecture limitations?
- Basis in paper: [inferred] The paper notes that models trained on financial datasets may exhibit more irrationality, but also that larger models are not necessarily more rational, suggesting both data and architecture factors.
- Why unresolved: The study compares models but doesn't isolate the impact of training data versus model architecture in a controlled experiment.
- What evidence would resolve it: A controlled experiment training identical models on different datasets (financial vs. general) and comparing their financial rationality scores.

### Open Question 2
- Question: How do the Financial Bias Indicators (FBI) framework's results translate to real-world financial decision-making performance?
- Basis in paper: [explicit] The paper acknowledges that deploying biased models in financial quantification tasks could cause market disturbances, but doesn't test real-world performance.
- Why unresolved: The FBI framework measures theoretical financial rationality, but doesn't validate whether these metrics predict actual financial decision quality.
- What evidence would resolve it: A study where models with different FBI scores are used for actual financial predictions or trading decisions, measuring their real-world performance and market impact.

### Open Question 3
- Question: What is the optimal balance between model size and training data specificity for achieving maximum financial rationality?
- Basis in paper: [explicit] The paper finds that larger models generally show more rationality but models trained on financial datasets may be more irrational, suggesting a complex relationship.
- Why unresolved: The study examines these factors separately but doesn't explore their interaction or optimal combination.
- What evidence would resolve it: A systematic study varying both model size and training data specificity to find the configuration that minimizes financial irrationality scores.

## Limitations
- Evaluation relies on proprietary Chinese financial datasets that may not be publicly accessible, limiting reproducibility
- Prompt engineering methods lack full specification, making exact replication challenging
- Study focuses on Chinese markets and companies, which may not generalize to other financial systems or languages
- Observed effects of model scale on rationality are context-dependent and may not hold across different domains

## Confidence

- **High Confidence**: The theoretical framework linking behavioral finance concepts to LLM bias detection is well-grounded and methodologically sound. The identification of belief and risk-preference biases as distinct dimensions is consistent with established financial psychology literature.
- **Medium Confidence**: The empirical findings about model size effects and training data influence are supported by the data but may be sensitive to the specific dataset composition and evaluation methodology used. The prompt-based debiasing interventions show promise but require further validation across diverse scenarios.
- **Low Confidence**: Claims about the superiority of generalized models over FinLLMs in terms of rationality are based on limited comparisons and may not hold when controlling for model architecture differences or domain-specific fine-tuning quality.

## Next Checks

1. **Cross-market validation**: Replicate the FBI framework evaluation on Western stock markets and English-language LLMs to test generalizability beyond Chinese financial contexts.
2. **Prompt engineering ablation study**: Systematically vary and test individual components of the Bias Antidote prompt strategies to isolate which elements most effectively reduce specific types of financial biases.
3. **Longitudinal stability assessment**: Track the same models' bias scores over time as they encounter new financial events to determine whether identified biases are persistent or evolve with continued exposure to market data.