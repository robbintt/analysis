---
ver: rpa2
title: 'Combining T-learning and DR-learning: a framework for oracle-efficient estimation
  of causal contrasts'
arxiv_id: '2402.01972'
source_url: https://arxiv.org/abs/2402.01972
tags:
- risk
- function
- estimator
- lemma
- ep-learner
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces efficient plug-in (EP) learning, a novel
  framework for estimating heterogeneous causal contrasts like conditional average
  treatment effects and conditional relative risks. EP-learners construct efficient
  plug-in estimators of the population risk function for the causal contrast, inheriting
  the stability and robustness of plug-in estimation while enjoying the oracle-efficiency
  of Neyman-orthogonal learning strategies.
---

# Combining T-learning and DR-learning: a framework for oracle-efficient estimation of causal contrasts

## Quick Facts
- arXiv ID: 2402.01972
- Source URL: https://arxiv.org/abs/2402.01972
- Authors: Lars van der Laan; Marco Carone; Alex Luedtke
- Reference count: 40
- This paper introduces efficient plug-in (EP) learning, a novel framework for estimating heterogeneous causal contrasts like conditional average treatment effects and conditional relative risks.

## Executive Summary
This paper introduces efficient plug-in (EP) learning, a novel framework for estimating heterogeneous causal contrasts such as conditional average treatment effects (CATE) and conditional relative risks (CRR). EP-learners combine the stability and robustness of plug-in estimation with the oracle-efficiency of Neyman-orthogonal learning strategies. The framework constructs efficient plug-in estimators of the population risk function for causal contrasts, achieving asymptotic equivalence to oracle-efficient one-step debiased estimators under reasonable conditions. Simulation experiments demonstrate that EP-learners outperform state-of-the-art methods including T-learner, R-learner, and DR-learner.

## Method Summary
EP-learners estimate heterogeneous causal contrasts by constructing efficient plug-in estimators of the population risk function. The method uses cross-fitted estimates of the propensity score and outcome regression, refined through a sieve-based adjustment to ensure double robustness and negligible debiasing terms. The algorithm minimizes a convex loss function based on the refined estimator to obtain causal contrast estimates. Cross-validation selects optimal sieve dimensions, and the framework inherits desirable properties from both plug-in estimation and orthogonal learning strategies.

## Key Results
- EP-learners achieve asymptotic equivalence to oracle-efficient one-step debiased estimators under reasonable conditions
- In simulations, EP-learners outperform state-of-the-art methods including T-learner, R-learner, and DR-learner for both CATE and CRR estimation
- The method provides double robustness and stability properties inherited from plug-in estimation strategies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EP-learner achieves oracle efficiency by constructing a debiased plug-in estimator that implicitly corrects for nuisance estimation error.
- Mechanism: EP-learner builds an outcome regression estimator μ*_n refined from μ_n using a sieve-based adjustment. This ensures the debiasing term in the efficient influence function is negligible across θ values.
- Core assumption: ∥μ*_n - μ_0∥ = Op(n^(-β/(2β+1)) + √(k(n)log n/n)), where β is the rate exponent of the initial outcome regression estimator.
- Evidence anchors: [abstract] and [section 2.3] describe the sieve-based adjustment and its role in achieving oracle efficiency.

### Mechanism 2
- Claim: EP-learner avoids nonconvexity and instability issues of Neyman-orthogonal learning strategies.
- Mechanism: EP-learner uses a convex loss function based on refined estimator μ*_n, which always produces bounded pseudo-outcomes within valid ranges.
- Core assumption: The refined estimator μ*_n respects outcome variable bounds, ensuring pseudo-outcomes remain valid.
- Evidence anchors: [section 3.2] confirms the convex loss function, and [section 3.1] demonstrates stable fitting behavior.

### Mechanism 3
- Claim: EP-learner is doubly robust, consistent if either outcome regression or propensity score is estimated consistently.
- Mechanism: The sieve-based adjustment incorporates inverse propensity weighting, providing double robustness when either nuisance component is estimated well.
- Core assumption: The sieve-based adjustment is designed to achieve double robustness as shown in Lemmas 12 and 14 of the Supplement.
- Evidence anchors: [section 5.1] establishes consistency conditions, and [section 2.3] describes the double robustness design.

## Foundational Learning

- **Pathwise differentiability and efficient influence functions**: Essential for understanding how EP-learner uses the efficient influence function to construct debiased estimators. Quick check: What is the efficient influence function of a pathwise differentiable parameter, and how is it used to construct an efficient estimator?

- **Sieve-based approximation and uniform entropy integrals**: Critical for analyzing EP-learner's convergence rates and complexity control. Quick check: What role does the uniform entropy integral play in controlling sieve space complexity and affecting estimator convergence rates?

- **Cross-fitting and data-splitting techniques**: Necessary for proper implementation to avoid overfitting and ensure nuisance estimators don't influence causal contrast estimation. Quick check: How does cross-fitting prevent overfitting in EP-learner, and what are key implementation considerations?

## Architecture Onboarding

- **Component map**: Initial nuisance estimators (μ_n, π_n) → Sieve-based adjustment → Refined estimator μ*_n → Convex loss function → Cross-validation → Causal contrast estimate

- **Critical path**: 
  1. Estimate initial nuisance functions (μ_n, π_n) using cross-fitting
  2. Construct refined outcome regression estimator μ*_n using sieve-based adjustment
  3. Compute EP-learner risk estimator based on μ*_n
  4. Minimize EP-learner risk estimator to obtain causal contrast estimate

- **Design tradeoffs**:
  - Sieve dimension k(n): Larger values improve approximation accuracy but increase computational complexity and overfitting risk
  - Cross-fitting splits J: More splits reduce bias but increase variance and computational cost
  - Initial nuisance estimator library: More diverse libraries improve robustness but increase computational complexity

- **Failure signatures**:
  - Poor propensity score overlap: Leads to high variance in EP-learner estimates
  - Slow nuisance estimator convergence: Causes bias in EP-learner estimates
  - Inappropriate sieve choice: Results in poor approximation accuracy and slow convergence rates

- **First 3 experiments**:
  1. Compare EP-learner with DR-learner and R-learner on simulated dataset with known CATE function
  2. Evaluate impact of sieve dimension k(n) on EP-learner performance using cross-validation
  3. Assess EP-learner robustness to different initial nuisance estimator library choices

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can EP-learners be extended to handle continuous or longitudinal treatments?
- Basis in paper: [explicit] The authors state the framework can be extended to contexts involving continuous or longitudinal treatments.
- Why unresolved: The paper only briefly mentions the possibility without providing details or implementation strategies.
- What evidence would resolve it: A concrete algorithm or framework for adapting EP-learners to continuous or longitudinal treatment settings, along with theoretical guarantees or empirical results demonstrating its effectiveness.

### Open Question 2
- Question: What is the optimal choice of basis functions and sieve dimensions for constructing EP-learners in high-dimensional settings?
- Basis in paper: [inferred] The authors discuss sieve specifications and mention additive sieves based on univariate trigonometric series performed well, but note that tensor-product sieves with higher interaction degrees could potentially improve performance.
- Why unresolved: The paper does not provide a definitive answer on the best choice, and optimal choice likely depends on specific problem and data characteristics.
- What evidence would resolve it: A comprehensive study comparing different basis functions and sieve dimensions across various problem settings, along with theoretical insights into conditions under which certain choices are optimal.

### Open Question 3
- Question: How can the calibration of EP-learner predictors for the CATE be improved through causal isotonic calibration?
- Basis in paper: [explicit] The authors mention EP-learner's potential to improve CATE calibration through causal isotonic calibration and discuss how this could mitigate issues with isotonic regression overfitting.
- Why unresolved: The paper does not provide a concrete method or implementation details for using EP-learners in causal isotonic calibration.
- What evidence would resolve it: A detailed algorithm for incorporating EP-learners into causal isotonic calibration, along with theoretical analysis of benefits and empirical results demonstrating improved calibration compared to existing methods.

### Open Question 4
- Question: How can penalization be incorporated into the EP-learner framework to improve performance in high-dimensional settings?
- Basis in paper: [explicit] The authors mention that adapting their approach to incorporate penalization would be an interesting area for future work, citing related work on penalized sieve methods.
- Why unresolved: The paper does not provide a specific method for incorporating penalization, and optimal way may depend on specific problem and data characteristics.
- What evidence would resolve it: A concrete algorithm for incorporating penalization into the EP-learner framework, along with theoretical analysis of benefits and empirical results demonstrating improved performance in high-dimensional settings compared to non-penalized versions.

## Limitations

- Theoretical guarantees rely on technical conditions (uniform entropy integral bounds, nuisance estimator convergence rates) that are stated but not fully verified in empirical evaluation
- Simulation experiments demonstrate practical performance but do not rigorously test asymptotic properties under stated assumptions
- The paper does not address potential issues with treatment overlap or high-dimensional covariates that could affect practical applicability

## Confidence

- **High confidence**: The core theoretical framework combining plug-in estimation with Neyman-orthogonality is well-established and the proposed EP-learning algorithm is a logical extension of existing methods
- **Medium confidence**: Simulation results showing superior performance of EP-learners over T-learner, R-learner, and DR-learner are compelling but limited to specific data generating processes
- **Medium confidence**: The claim of oracle efficiency and double robustness is supported by theoretical arguments but requires more extensive empirical validation

## Next Checks

1. Implement EP-learning on benchmark causal inference datasets (e.g., IHDP, ACIC) to evaluate performance on real-world data beyond the simulated experiments

2. Conduct sensitivity analyses to assess the impact of different sieve specifications and cross-fitting configurations on EP-learner performance

3. Test EP-learning under various degrees of treatment overlap and confounding strength to evaluate robustness to realistic violations of the assumptions