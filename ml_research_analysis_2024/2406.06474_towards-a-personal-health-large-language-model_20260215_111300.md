---
ver: rpa2
title: Towards a Personal Health Large Language Model
arxiv_id: '2406.06474'
source_url: https://arxiv.org/abs/2406.06474
tags:
- sleep
- case
- data
- fitness
- health
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper introduces Personal Health Large Language Model (PH-LLM),
  a fine-tuned version of Gemini for interpreting personal health data from wearables
  to provide insights and recommendations for sleep and fitness. PH-LLM was evaluated
  on three tasks: generating personalized insights and recommendations from case studies,
  answering multiple-choice questions on sleep medicine and fitness, and predicting
  patient-reported sleep outcomes.'
---

# Towards a Personal Health Large Language Model

## Quick Facts
- arXiv ID: 2406.06474
- Source URL: https://arxiv.org/abs/2406.06474
- Authors: Justin Cosentino, Anastasiya Belyaeva, Xin Liu, Nicholas A. Furlotte, Zhun Yang, Chace Lee, Erik Schenck, Yojan Patel, Jian Cui, Logan Douglas Schneider, Robby Bryant, Ryan G. Gomes, Allen Jiang, Roy Lee, Yun Liu, Javier Perez, Jameson K. Rogers, Cathy Speed, Shyam Tailor, Megan Walker, Jeffrey Yu, Tim Althoff, Conor Heneghan, John Hernandez, Mark Malhotra, Leor Stern, Yossi Matias, Greg S. Corrado, Shwetak Patel, Shruthi Prabhakara, Daniel McDuff, Cory Y. McLean
- Reference count: 40
- Primary result: PH-LLM achieves expert-level performance on fitness coaching, improves sleep insights through fine-tuning, and matches specialized models in predicting subjective sleep outcomes using multimodal sensor encoding.

## Executive Summary
This paper introduces PH-LLM, a fine-tuned version of Google's Gemini Ultra 1.0 model specifically adapted for personal health applications. The model is trained to interpret wearable sensor data and provide personalized insights and recommendations for sleep and fitness. PH-LLM demonstrates strong performance on professional examinations in both domains and shows promise in predicting subjective health outcomes from multimodal physiological data. While the results are encouraging, the authors acknowledge that further development is needed for safe deployment in real-world health applications.

## Method Summary
PH-LLM is built by fine-tuning Gemini Ultra 1.0 on three distinct datasets: case studies in sleep and fitness, professional examination questions, and patient-reported outcomes (PROs) from sleep. The fine-tuning uses prompt-response pairs for each section of case studies, with a 1:1 mixture of sleep and fitness data. For predicting PROs, the model employs a multimodal encoder that integrates time-series health behavior data as input tokens by computing mean and variance across days and z-scoring results using training data as reference. Expert evaluations using rubrics assess the quality of generated insights and recommendations, while automatic evaluations provide additional performance metrics.

## Key Results
- PH-LLM achieves 79% on sleep medicine questions and 88% on fitness questions, exceeding average human expert scores
- Fine-tuning significantly improves PH-LLM's ability to generate personalized sleep insights and recommendations
- When using multimodal sensor encoding, PH-LLM matches specialized discriminative models in predicting subjective sleep outcomes

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning Gemini Ultra 1.0 on domain-specific case studies significantly improves PH-LLM's ability to generate personalized health insights and recommendations. The fine-tuning process allows PH-LLM to learn domain-specific language patterns, data interpretation strategies, and reasoning approaches used by human sleep and fitness experts. By training on real-world case studies, PH-LLM develops an understanding of how to contextualize individual health data and provide relevant, personalized guidance. The core assumption is that the fine-tuned model retains the general capabilities of the base Gemini Ultra 1.0 while gaining domain-specific expertise through the training process. Evidence shows significant improvements in using relevant domain knowledge and personalizing information for sleep insights after fine-tuning.

### Mechanism 2
PH-LLM's multimodal capabilities enable it to effectively integrate and interpret physiological data from wearables to predict subjective health outcomes. By encoding time-series sensor data into the token embedding space of PH-LLM, the model can natively process and reason over both the raw numerical data and the associated textual context. This allows PH-LLM to capture complex relationships between objective measurements and subjective experiences. The core assumption is that the multimodal adapter can effectively project high-dimensional sensor data into the semantic space of the language model without losing critical information. Evidence includes the model's ability to predict self-reported sleep disruption and sleep impairment outcomes from textual and multimodal encoding representations of wearable sensor data.

### Mechanism 3
PH-LLM's performance on professional examinations demonstrates its broad knowledge base and ability to reason over complex health concepts. The strong performance on multiple-choice questions in sleep medicine and fitness suggests that PH-LLM has effectively learned the underlying principles and relationships in these domains. This knowledge enables the model to answer novel questions by applying its understanding of the relevant concepts. The core assumption is that success on professional examinations correlates with the ability to provide accurate and useful health insights and recommendations in real-world scenarios. Evidence shows PH-LLM achieved 79% on sleep (N=629 questions) and 88% on fitness (N=99 questions), both of which exceed average scores from a sample of human experts.

## Foundational Learning

- **Large Language Models and Fine-tuning**: Understanding how LLMs like Gemini can be adapted to specific domains through fine-tuning is crucial for grasping the approach used to develop PH-LLM. *Quick check: What is the primary benefit of fine-tuning a pre-trained LLM like Gemini Ultra 1.0 for a specific domain like personal health?*

- **Multimodal Learning and Sensor Data Processing**: Comprehending how multimodal models can integrate and reason over different data types (text, numerical sensor data) is key to understanding PH-LLM's capabilities. *Quick check: How does PH-LLM's multimodal approach differ from traditional methods of processing wearable sensor data?*

- **Expert Evaluation and Rubric-based Assessment**: Grasping the importance of rigorous evaluation methods, including expert grading and rubric-based assessment, is essential for understanding how PH-LLM's performance was measured. *Quick check: What are the advantages and limitations of using expert raters and evaluation rubrics to assess the quality of LLM-generated health insights and recommendations?*

## Architecture Onboarding

- **Component map**: Base Model (Gemini Ultra 1.0) → Fine-tuning (case studies, exams, PROs) → Multimodal Adapter (sensor data encoding) → Expert Evaluation (human raters with rubrics) → Automatic Evaluation (LLM-based rating proxy) → Deployment

- **Critical path**: Base Model → Fine-tuning → Multimodal Adapter → Expert Evaluation → Deployment

- **Design tradeoffs**:
  - Fine-tuning vs. Prompting: Fine-tuning allows for deeper integration of domain knowledge but requires more data and computational resources
  - Multimodal vs. Text-only: Multimodal approach captures richer relationships but adds complexity and potential data quality issues
  - Expert vs. Automatic Evaluation: Expert evaluation is more reliable but slower and more expensive; automatic evaluation is faster but potentially less accurate

- **Failure signatures**:
  - Overfitting during fine-tuning: Model performs well on training data but poorly on new case studies
  - Multimodal adapter issues: Sensor data representation loses critical information or fails to capture meaningful relationships
  - Expert evaluation bias: Raters may be influenced by non-material factors (e.g., writing style) when assessing model responses

- **First 3 experiments**:
  1. Compare PH-LLM's performance on a subset of case studies against human experts using the established rubrics
  2. Evaluate the effectiveness of the multimodal adapter by comparing PH-LLM's predictions of subjective outcomes against specialized discriminative models
  3. Assess the correlation between PH-LLM's performance on professional examinations and its ability to generate useful health insights and recommendations in real-world scenarios

## Open Questions the Paper Calls Out

### Open Question 1
The paper calls out the need for further development and evaluation in the safety-critical personal health domain, acknowledging that "further development and evaluation are necessary" but doesn't detail specific safety mechanisms or compare performance in real-world versus controlled settings. The authors note that "confabulations or incorrect referencing of user data still occasionally occurred" and that "Some Mistakes Could be Harmful." What specific safety mechanisms could be implemented to mitigate potential harms from confabulations or incorrect recommendations, and how does PH-LLM's performance compare to human experts in real-world deployment scenarios?

### Open Question 2
The paper acknowledges that "A primary overarching goal for developing models specific to personal health is to be able to improve long-term health outcomes through effective behavior change and maintenance of healthy habits. Neither of these tasks is explicitly evaluated here, and remain important areas for future work." This highlights the gap between model performance on controlled tasks and actual health impact. How can we measure whether PH-LLM actually improves health outcomes beyond just providing accurate insights, and what are the long-term effects of using PH-LLM for personal health recommendations on user behavior change and health outcomes?

### Open Question 3
The paper mentions limitations including "the limited size of the existing dataset" and "our purposeful restriction to samples with nearly complete sensor data." It also notes that "further exploration of self-supervised pre-training on raw waveforms and granularly aggregated sensor features may yield richer representations." How can PH-LLM be adapted to handle the full heterogeneity of personal health data, including data from different wearable devices, apps, and user input formats, and what are the technical challenges in creating a truly universal personal health LLM?

## Limitations

- **Safety and Reliability Concerns**: The paper acknowledges that LLMs are prone to confabulations and incorrect referencing of user data, which is particularly concerning in health applications, but does not provide concrete solutions for deployment in safety-critical scenarios.

- **Data Quality and Representativeness**: The training data for fine-tuning comes from a "large set of publicly available data sources," but the paper does not provide details about demographic diversity, geographic distribution, or potential biases in this data.

- **Evaluation Scope**: While the model demonstrates strong performance on controlled tasks (examinations, case studies), the evaluation does not include real-world deployment testing with actual users, limiting generalizability.

## Confidence

- **High Confidence**: The technical implementation of the multimodal adapter and the fine-tuning methodology are well-described and follow established practices in the field.

- **Medium Confidence**: The performance improvements demonstrated on the evaluation tasks are likely valid, but the generalizability to real-world scenarios remains uncertain due to the limitations mentioned above.

- **Low Confidence**: Claims about the model's ability to provide safe and reliable health recommendations for general deployment are not yet substantiated, given the acknowledged safety challenges and lack of real-world testing.

## Next Checks

1. **Demographic Fairness Audit**: Conduct a systematic evaluation of PH-LLM's performance across different demographic groups using publicly available health datasets to identify potential biases or disparities in recommendations.

2. **Real-world Deployment Pilot**: Implement a controlled pilot study with volunteer users tracking their actual health outcomes over 3-6 months to assess the practical utility and safety of PH-LLM's recommendations compared to baseline approaches.

3. **Adversarial Testing for Safety**: Design and execute a comprehensive safety audit using both automated adversarial testing frameworks and expert human reviewers to identify potential failure modes, confabulations, and harmful recommendation patterns.