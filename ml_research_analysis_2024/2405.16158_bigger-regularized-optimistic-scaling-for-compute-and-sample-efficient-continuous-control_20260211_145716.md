---
ver: rpa2
title: 'Bigger, Regularized, Optimistic: scaling for compute and sample-efficient
  continuous control'
arxiv_id: '2405.16158'
source_url: https://arxiv.org/abs/2405.16158
tags:
- performance
- step
- tasks
- learning
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: BRO demonstrates that scaling model capacity combined with regularization
  enables state-of-the-art sample efficiency in continuous control. The algorithm
  scales critic networks to ~5M parameters using a novel BroNet architecture with
  layer normalization, weight decay, and full-parameter resets, paired with optimistic
  exploration via dual actors and non-pessimistic Q-values.
---

# Bigger, Regularized, Optimistic: scaling for compute and sample-efficient continuous control

## Quick Facts
- **arXiv ID**: 2405.16158
- **Source URL**: https://arxiv.org/abs/2405.16158
- **Reference count**: 40
- **Primary result**: BRO achieves 90%+ success rates on 40 challenging continuous control tasks using large-scale critics with regularization

## Executive Summary
BRO (Bigger, Regularized, Optimistic) demonstrates that scaling model capacity combined with regularization enables state-of-the-art sample efficiency in continuous control. The algorithm scales critic networks to ~5M parameters using a novel BroNet architecture with layer normalization, weight decay, and full-parameter resets, paired with optimistic exploration via dual actors and non-pessimistic Q-values. BRO achieves 90%+ success rates on 40 challenging tasks across DeepMind Control, MetaWorld, and MyoSuite, outperforming model-based and model-free baselines, and is the first model-free method to solve Dog and Humanoid locomotion tasks within 1M steps.

## Method Summary
BRO is a model-free actor-critic algorithm that scales critic networks to 5M parameters while maintaining stability through three key innovations. First, it introduces BroNet - a critic architecture with layer normalization that scales efficiently. Second, it employs weight decay to regularize the large critics and prevent overfitting. Third, it implements full-parameter resets during training to maintain exploration capabilities. The algorithm uses optimistic exploration through dual actors and non-pessimistic Q-values, enabling efficient learning even with large networks that would typically suffer from overfitting in off-policy settings.

## Key Results
- Achieves 90%+ success rates across 40 tasks spanning DeepMind Control, MetaWorld, and MyoSuite
- Solves previously intractable Dog and Humanoid locomotion tasks within 1M steps, being the first model-free method to do so
- Outperforms both model-based and model-free baselines on sample efficiency and final performance metrics

## Why This Works (Mechanism)
BRO works by addressing the fundamental tension in continuous control between model capacity and sample efficiency. Traditional RL algorithms face a trade-off: small networks generalize well but lack representational power, while large networks overfit to limited data. BRO breaks this trade-off through regularization - weight decay prevents overfitting even with 5M-parameter critics, while layer normalization stabilizes training. The optimistic exploration mechanism, implemented through dual actors and non-pessimistic Q-values, ensures sufficient exploration despite the large, regularized critics. Full-parameter resets periodically refresh the exploration capabilities, preventing the algorithm from getting stuck in suboptimal policies. This combination enables BRO to learn effectively from limited samples while leveraging the representational power of large networks.

## Foundational Learning
- **Actor-critic methods**: Why needed - Provide the baseline framework for continuous control; Quick check - Understand policy and value function interaction
- **Off-policy learning**: Why needed - Enables efficient use of past experiences; Quick check - Recognize replay buffer usage
- **Weight decay regularization**: Why needed - Prevents overfitting in large networks; Quick check - Understand L2 penalty effects
- **Layer normalization**: Why needed - Stabilizes training of deep networks; Quick check - Know normalization across feature dimensions
- **Optimistic exploration**: Why needed - Encourages sufficient exploration; Quick check - Understand the role of exploration bonuses

## Architecture Onboarding
**Component map**: Environment -> Observations/Rewards -> BRO Agent -> Actions -> Environment
**Critical path**: Observation → BroNet critic → Q-value estimation → Policy update → Action sampling
**Design tradeoffs**: Large critics (5M params) vs stability, achieved through weight decay and normalization
**Failure signatures**: Instability without weight decay, poor exploration without optimistic mechanism, overfitting without regularization
**First experiments**: 1) Test BRO with varying weight decay strengths, 2) Compare single vs dual actor performance, 3) Evaluate BroNet vs standard architectures on simple tasks

## Open Questions the Paper Calls Out
The paper highlights several open questions regarding the theoretical foundations of optimistic exploration in large-scale settings, the optimal architecture design for different task families, and the scalability of the approach to even more complex environments with sparse rewards or high-dimensional observations.

## Limitations
- Performance depends on careful tuning of weight decay hyperparameters across different environments
- Theoretical grounding for the optimistic exploration mechanism remains incomplete
- Claims about being "first model-free method" depend on specific evaluation protocols and baselines used

## Confidence
- **High**: Claims regarding improved sample efficiency and performance on standard benchmarks (DMControl, MetaWorld, MyoSuite)
- **Medium**: Broader claims about scalability principles and architectural innovations
- **Low**: Theoretical claims about why specific architectural choices (particularly BroNet design) are optimal

## Next Checks
1. Test BRO's performance on more diverse control tasks outside standard benchmark suites, particularly domains with high-dimensional observations or complex dynamics
2. Conduct systematic ablation studies isolating the contribution of each architectural component (layer normalization, weight decay, full-parameter resets)
3. Evaluate BRO's robustness to hyperparameter variations, particularly weight decay strength and temperature parameter, across different environment classes