---
ver: rpa2
title: 'Unraveling the Dominance of Large Language Models Over Transformer Models
  for Bangla Natural Language Inference: A Comprehensive Study'
arxiv_id: '2405.02937'
source_url: https://arxiv.org/abs/2405.02937
tags:
- language
- llms
- performance
- bangla
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study comprehensively evaluates Large Language Models (LLMs)
  and Transformer-based models for Bangla Natural Language Inference (NLI). The authors
  compare zero-shot and few-shot performance of GPT-3.5 Turbo and Gemini 1.5 Pro against
  fine-tuned models like BanglaBERT and DistilBERT on the XNLI dataset.
---

# Unraveling the Dominance of Large Language Models Over Transformer Models for Bangla Natural Language Inference: A Comprehensive Study

## Quick Facts
- arXiv ID: 2405.02937
- Source URL: https://arxiv.org/abs/2405.02937
- Reference count: 14
- Primary result: GPT-3.5 Turbo achieved 92.05% accuracy in few-shot Bangla NLI, exceeding fine-tuned transformer models

## Executive Summary
This study evaluates Large Language Models (LLMs) and Transformer-based models for Bangla Natural Language Inference (NLI). The authors compare zero-shot and few-shot performance of GPT-3.5 Turbo and Gemini 1.5 Pro against fine-tuned models like BanglaBERT and DistilBERT on the XNLI dataset. While LLMs generally underperform in zero-shot settings compared to fine-tuned models, their performance improves significantly with few-shot examples—exceeding even state-of-the-art models in some cases. GPT-3.5 Turbo achieved the highest accuracy (92.05%) in few-shot scenarios. The findings highlight both the promise and current limitations of LLMs for low-resource languages, emphasizing the need for further research to enhance their effectiveness in Bangla NLI tasks.

## Method Summary
The study fine-tuned several Bangla-specific PLMs (BanglaBERT, Bangla BERT Base, DistilBERT, mBERT, sahajBERT) on the XNLI dataset using AdamW optimizer and CrossEntropyLoss. LLMs (GPT-3.5 Turbo, Gemini 1.5 Pro) were evaluated using zero-shot and few-shot learning with specific prompts. Performance was measured using accuracy, precision, recall, and F1-score on a subset of the dataset. The study focused on comparing the effectiveness of few-shot learning versus zero-shot learning for LLMs and their performance relative to fine-tuned PLMs.

## Key Results
- LLMs showed significant performance improvement with few-shot examples (5-15 shots), achieving 92.05% accuracy with GPT-3.5 Turbo
- Zero-shot LLM performance lagged behind fine-tuned transformer models in Bangla NLI tasks
- GPT-3.5 Turbo outperformed Gemini 1.5 Pro in few-shot scenarios while showing lower hallucination rates
- Hallucinations were more frequent in low-resource languages like Bangla due to training data scarcity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs outperform fine-tuned transformer models in few-shot Bangla NLI due to their strong generalization from pre-training on large multilingual datasets.
- Mechanism: During few-shot prompting, LLMs leverage their learned linguistic patterns to infer the logical relationship between premise and hypothesis without extensive fine-tuning, effectively adapting to the task with minimal examples.
- Core assumption: The pre-training corpus of LLMs includes sufficient Bangla text to form reliable language representations.
- Evidence anchors:
  - [abstract] "While LLMs generally underperform in zero-shot settings compared to fine-tuned models, their performance improves significantly with few-shot examples—exceeding even state-of-the-art models in some cases."
  - [section] "We find it noteworthy that LLMs demonstrate impressive performance in zero-shot scenarios within the English language. However, their performance in languages with fewer resources, such as Bengali, falls short."
- Break condition: If the multilingual pre-training corpus lacks adequate Bangla data, few-shot performance will degrade to match or fall below fine-tuned models.

### Mechanism 2
- Claim: Few-shot prompting provides contextual guidance that helps LLMs overcome zero-shot limitations in low-resource languages.
- Mechanism: By providing 5-15 examples during prompting, the model receives explicit demonstrations of the entailment, contradiction, and neutral patterns specific to Bangla, effectively compensating for limited task-specific fine-tuning.
- Core assumption: The few-shot examples are representative of the task distribution and clearly illustrate the relationship patterns.
- Evidence anchors:
  - [abstract] "Our findings reveal that while LLMs can achieve comparable or superior performance to fine-tuned SOTA models in few-shot scenarios..."
  - [section] "Furthermore, our findings reveal that the performance of LLMs significantly enhances with just a few shots (5 shot, 10 shot, 15 shot) compared to zero-shot scenarios."
- Break condition: If few-shot examples are unrepresentative or noisy, the improvement over zero-shot performance will be minimal or negative.

### Mechanism 3
- Claim: Hallucinations in LLMs are more frequent in low-resource languages like Bangla due to training data scarcity.
- Mechanism: With limited Bangla training data compared to English, the model has less exposure to valid linguistic patterns, leading to generation of factually incorrect or nonsensical outputs when uncertain.
- Core assumption: The frequency of hallucinations correlates with the relative scarcity of training data for a language.
- Evidence anchors:
  - [abstract] "Despite their impressive capabilities, LLMs are prone to producing erroneous data, necessitating the use of techniques such as Reinforcement Learning from Human Feedback (RLHF)..."
  - [section] "Hallucinations in LLMs refer to instances where the model generates responses that are factually incorrect, nonsensical, or disconnected from the input prompt... The limited training data for Bangla compared to more well-resourced languages like English may contribute to these hallucinations..."
- Break condition: If hallucination frequency remains high even with increased Bangla training data, other factors like model architecture or prompt quality may be the primary cause.

## Foundational Learning

- Concept: Natural Language Inference (NLI) task structure
  - Why needed here: Understanding the three-way classification (entailment, contradiction, neutral) is fundamental to evaluating model performance and designing appropriate prompts.
  - Quick check question: What distinguishes a "neutral" label from "entailment" or "contradiction" in NLI?

- Concept: Few-shot learning mechanics
  - Why needed here: The performance differential between zero-shot and few-shot scenarios is a central finding, requiring understanding of how in-context learning works.
  - Quick check question: How does the model use 5-shot examples differently than zero-shot examples when making predictions?

- Concept: Evaluation metrics in classification tasks
  - Why needed here: Accuracy, precision, recall, and F1-score each capture different aspects of model performance, critical for interpreting results across different models.
  - Quick check question: When would a model have high accuracy but low F1-score in an imbalanced dataset?

## Architecture Onboarding

- Component map: Data preprocessing -> Model initialization -> Fine-tuning (PLMs) OR Prompting (LLMs) -> Evaluation -> Analysis
- Critical path: Data selection -> Prompt design -> API calls (LLMs) OR Training loop (PLMs) -> Metric computation
- Design tradeoffs: Cost vs. coverage (using 300 samples instead of full dataset), manual prompt engineering vs. automated optimization, multilingual generalization vs. language-specific fine-tuning
- Failure signatures: Low zero-shot performance indicates insufficient pre-training data; poor few-shot improvement suggests prompt quality issues; high hallucination rates point to data scarcity
- First 3 experiments:
  1. Compare zero-shot performance across all models using the same 300-sample subset to establish baseline
  2. Test 5-shot prompting with carefully crafted examples for each relationship type to identify optimal example count
  3. Implement CoT prompting for one LLM to assess impact on hallucination frequency and reasoning transparency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific mechanisms cause LLMs to underperform in zero-shot Bangla NLI compared to English?
- Basis in paper: [explicit] "Despite demonstrating robust zero-shot performance across various NLP tasks in English and other languages, their application in the Bengali language domain... remains largely unexplored"
- Why unresolved: The paper identifies the performance gap but doesn't investigate underlying causes specific to Bangla.
- What evidence would resolve it: Comparative analysis of training data distribution, linguistic feature coverage, and attention patterns between Bangla and English in LLMs.

### Open Question 2
- Question: How do hallucinations in Bangla text differ from those in other languages for LLMs?
- Basis in paper: [explicit] "The frequency of hallucinations appears to be higher in Gemini 1.5 Pro compared to GPT 3.5 Turbo" and "limited training data for Bangla compared to more well-resourced languages like English may contribute to these hallucinations"
- Why unresolved: The paper notes differences in hallucination frequency but doesn't characterize the nature of Bangla-specific hallucinations.
- What evidence would resolve it: Detailed classification of hallucination types in Bangla outputs versus other languages, and correlation with training data characteristics.

### Open Question 3
- Question: What is the optimal number of few-shot examples for maximizing Bangla NLI performance across different LLM architectures?
- Basis in paper: [explicit] "Our findings reveal that the performance of LLMs significantly enhances with just a few shots (5 shot, 10 shot, 15 shot) compared to zero-shot scenarios" but doesn't test beyond 15 shots
- Why unresolved: The study only tests up to 15-shot learning, leaving open questions about whether performance plateaus or continues improving.
- What evidence would resolve it: Systematic evaluation of LLM performance across a broader range of few-shot examples (e.g., 20, 30, 50 shots) to identify optimal training efficiency.

## Limitations

- Evaluation conducted on a subset of the XNLI dataset (300 samples) rather than the full test set, potentially limiting generalization assessment
- Study focuses specifically on Bangla language inference without examining other low-resource languages, limiting generalizability
- Limited investigation into the underlying causes of performance gaps and hallucination patterns, relying on plausible correlations rather than causal evidence

## Confidence

- **High confidence**: The comparative performance patterns between zero-shot and few-shot scenarios for LLMs are well-supported by the empirical results
- **Medium confidence**: The claim that LLMs can exceed state-of-the-art fine-tuned models in few-shot scenarios is supported by the data, but the specific superiority of GPT-3.5 Turbo may be context-dependent
- **Low confidence**: The assertion that hallucinations are primarily caused by Bangla training data scarcity lacks direct causal evidence

## Next Checks

1. **Full dataset validation**: Evaluate all models on the complete XNLI test set (4,895 instances) to confirm whether the observed performance trends hold with larger sample sizes and to assess statistical significance

2. **Cross-lingual hallucination analysis**: Design experiments to systematically compare hallucination rates across multiple languages (high-resource like English, medium-resource like Spanish, low-resource like Bangla) using identical prompts to establish the relationship between training data availability and hallucination frequency

3. **Prompt optimization study**: Conduct an ablation study varying prompt structure, example selection, and example ordering in few-shot settings to determine which factors most significantly impact LLM performance in Bangla NLI tasks