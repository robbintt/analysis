---
ver: rpa2
title: 'Chameleon: Foundation Models for Fairness-aware Multi-modal Data Augmentation
  to Enhance Coverage of Minorities'
arxiv_id: '2402.01071'
source_url: https://arxiv.org/abs/2402.01071
tags: []
core_contribution: This paper addresses the problem of under-representation of minorities
  in multi-modal training data, which can lead to unfairness in machine learning models.
  The authors propose Chameleon, a system that uses foundation models for fairness-aware
  data augmentation to enhance coverage of minorities.
---

# Chameleon: Foundation Models for Fairness-aware Multi-modal Data Augmentation to Enhance Coverage of Minorities

## Quick Facts
- **arXiv ID**: 2402.01071
- **Source URL**: https://arxiv.org/abs/2402.01071
- **Reference count**: 40
- **Primary result**: Reduces F1-score disparity for minority groups by 52 percentage points using foundation model-based augmentation

## Executive Summary
This paper introduces Chameleon, a system designed to address minority under-representation in multi-modal training data through foundation model-based data augmentation. The approach targets the problem of model unfairness stemming from skewed training data by generating synthetic data points that enhance coverage of minority groups while maintaining data quality and distribution fidelity. Chameleon employs a rejection sampling framework to ensure generated tuples are both high-quality and representative of the underlying data distribution. The system defines and solves a Combination-Selection problem to minimize the number of synthetic tuples needed, and uses contextual multi-armed bandit methods for selecting guide tuples during augmentation.

## Method Summary
Chameleon uses foundation models for fairness-aware multi-modal data augmentation to enhance coverage of minority groups in training data. The system follows a rejection sampling approach where synthetic data tuples are generated and then evaluated against data distribution and quality metrics to ensure they adhere to the original data characteristics. The method defines the Combination-Selection problem, which aims to minimize the total number of synthetic tuples needed to resolve coverage gaps. Chameleon employs a greedy approximation algorithm to solve this problem efficiently. For guide tuple selection, the system models the problem as a contextual multi-armed bandit scenario, balancing exploration and exploitation to identify the most informative samples for augmentation. The approach is validated through experiments on both real and synthetic datasets, demonstrating significant improvements in model fairness metrics.

## Key Results
- F1-score disparity for Black group decreased from 79% to 27% on FERETDB dataset after data repair
- Generated 307 images at a cost of $4.91 with 75% passing rejection sampling tests
- Demonstrated effectiveness across both real and synthetic datasets in reducing model unfairness

## Why This Works (Mechanism)
The mechanism works by using foundation models to generate synthetic data that fills representation gaps for minority groups, while rejection sampling ensures quality and distribution fidelity. The Combination-Selection problem formulation minimizes the number of synthetic tuples needed, making the approach efficient. The contextual multi-armed bandit framework for guide tuple selection enables intelligent sampling that balances exploration of underrepresented regions with exploitation of known effective augmentation strategies.

## Foundational Learning
- **Rejection Sampling**: Why needed - To ensure generated data maintains quality and follows original distribution; Quick check - Verify acceptance rate and compare statistics between original and generated data
- **Combination-Selection Problem**: Why needed - To minimize augmentation cost while maximizing coverage; Quick check - Compare number of synthetic tuples needed versus baseline approaches
- **Contextual Multi-armed Bandits**: Why needed - To intelligently select guide tuples for augmentation; Quick check - Measure improvement in coverage efficiency versus random selection
- **Foundation Models**: Why needed - To generate high-quality synthetic data across multiple modalities; Quick check - Evaluate quality metrics on generated samples
- **Fairness Metrics**: Why needed - To quantify model bias and measure improvement; Quick check - Track disparity metrics across multiple fairness definitions

## Architecture Onboarding

**Component Map**: Foundation Models -> Rejection Sampler -> Quality Evaluator -> Combination Selector -> Guide Selector

**Critical Path**: Guide Selector identifies minority regions → Foundation Models generate candidates → Rejection Sampler filters → Quality Evaluator validates → Combination Selector optimizes tuple selection

**Design Tradeoffs**: Quality vs quantity (rejection sampling may reduce output but ensures fidelity) | Exploration vs exploitation (bandit approach balances coverage needs)

**Failure Signatures**: Low acceptance rate in rejection sampling indicates distribution mismatch; High disparity metrics after augmentation suggests poor minority representation; Excessive synthetic tuple generation indicates inefficient combination selection

**3 First Experiments**: 1) Baseline comparison without rejection sampling to measure quality impact, 2) Random guide selection versus bandit approach to measure efficiency gains, 3) Single modality versus multi-modal augmentation to quantify coverage improvements

## Open Questions the Paper Calls Out
None identified in provided content.

## Limitations
- Assumes foundation models adequately capture minority characteristics, but these models may contain their own biases
- Cost-effectiveness ($4.91 for 307 images) lacks scalability context for real-world deployment
- Evaluation focuses primarily on F1-score disparity without examining other fairness metrics

## Confidence

**High Confidence**: Rejection sampling methodology is well-established and sound for maintaining data quality

**Medium Confidence**: Greedy approximation algorithm is reasonable but lacks detailed performance bounds validation

**Medium Confidence**: Contextual multi-armed bandit formulation is appropriate but sensitive to hyperparameter choices

## Next Checks
1. Test system robustness when foundation models have varying degrees of minority representation, measuring impact on generated sample quality and fairness

2. Conduct ablation studies comparing Chameleon against simpler augmentation techniques (basic oversampling, class-weighted loss) to quantify added value

3. Evaluate long-term stability of fairness improvements by retraining models after multiple augmentation rounds and measuring persistence of fairness gains