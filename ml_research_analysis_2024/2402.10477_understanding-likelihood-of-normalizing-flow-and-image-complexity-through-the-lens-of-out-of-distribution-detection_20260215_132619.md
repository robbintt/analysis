---
ver: rpa2
title: Understanding Likelihood of Normalizing Flow and Image Complexity through the
  Lens of Out-of-Distribution Detection
arxiv_id: '2402.10477'
source_url: https://arxiv.org/abs/2402.10477
tags: []
core_contribution: This paper investigates why Normalizing Flow models sometimes assign
  higher likelihoods to out-of-distribution (OOD) inputs than in-distribution data,
  a phenomenon that undermines OOD detection reliability. The authors propose that
  less complex images concentrate in high-density regions of the latent space, leading
  to inflated likelihood values.
---

# Understanding Likelihood of Normalizing Flow and Image Complexity through the Lens of Out-of-Distribution Detection

## Quick Facts
- arXiv ID: 2402.10477
- Source URL: https://arxiv.org/abs/2402.10477
- Reference count: 40
- Primary result: Image complexity correlates with likelihood values in normalizing flow latent spaces, enabling improved OOD detection

## Executive Summary
This paper addresses a fundamental challenge in normalizing flow (NF) models: their tendency to assign higher likelihoods to out-of-distribution (OOD) data than to in-distribution data, undermining their reliability for OOD detection tasks. The authors propose that this counterintuitive behavior stems from the relationship between image complexity and likelihood in the latent space. They demonstrate that less complex images tend to concentrate in high-density regions of the latent space, leading to inflated likelihood values that can mislead OOD detection. By quantifying image complexity and incorporating it into a Gaussian mixture model (GMM) framework alongside likelihood scores, the proposed approach successfully detects all tested OOD datasets while maintaining computational efficiency.

## Method Summary
The authors introduce a novel framework for OOD detection that combines image complexity measures with likelihood scores from normalizing flow models. The method first computes likelihood values using standard NF architectures, then quantifies image complexity using various metrics including total variation, JPEG compression ratio, and pixel intensity variance. These two signals are then jointly modeled using a Gaussian mixture model, where the likelihood and complexity are treated as correlated variables. The GMM parameters are learned from in-distribution data, and OOD detection is performed by computing the likelihood ratio of a test sample under the in-distribution versus out-of-distribution components of the mixture. This approach effectively separates simple OOD images (which would otherwise receive high likelihoods) from complex in-distribution images.

## Key Results
- Image complexity correlates with likelihood values in the latent space of five different NF architectures
- The GMM-based approach successfully detects all tested OOD datasets, including CIFAR-10, CIFAR-100, and Tiny ImageNet when SVHN is the in-distribution data
- The method shows promise for autoregressive models like PixelCNN++, suggesting broader applicability beyond NFs
- Standard NF models without the complexity correction consistently fail to distinguish between simple OOD images and complex in-distribution images

## Why This Works (Mechanism)
The mechanism underlying this approach is rooted in the geometry of the latent space induced by normalizing flows. When complex images are mapped to the latent space, they tend to spread out across the space due to their diverse features and fine details. In contrast, simple images, which contain fewer distinct features, concentrate in specific high-density regions of the latent space. This concentration effect causes simple images to receive artificially high likelihood values, even when they are OOD. By explicitly modeling this relationship through a GMM that incorporates both likelihood and complexity, the method can distinguish between high-likelihood in-distribution images (which are typically complex) and high-likelihood OOD images (which are typically simple).

## Foundational Learning

1. **Normalizing Flow Fundamentals**
   - Why needed: Understanding how NFs transform data through invertible mappings to a latent space where likelihood is tractable
   - Quick check: Can you explain how the change of variables formula enables exact likelihood computation in NFs?

2. **Latent Space Geometry**
   - Why needed: Recognizing that the structure of latent representations affects likelihood values and clustering behavior
   - Quick check: How do simple versus complex images distribute differently in the latent space according to this paper?

3. **Gaussian Mixture Models**
   - Why needed: GMMs provide a probabilistic framework for modeling the joint distribution of complexity and likelihood
   - Quick check: What advantage does a GMM offer over a single Gaussian for modeling the complexity-likelihood relationship?

4. **Image Complexity Metrics**
   - Why needed: Quantifying image complexity is essential for distinguishing between in-distribution and OOD samples
   - Quick check: Which complexity metrics were evaluated, and why might JPEG compression ratio be informative?

5. **OOD Detection Fundamentals**
   - Why needed: Understanding the unique challenges of detecting data that falls outside the training distribution
   - Quick check: Why do standard likelihood-based methods fail for OOD detection in NFs?

## Architecture Onboarding

Component Map: Image -> NF Encoder -> Latent Space -> Likelihood + Complexity Features -> GMM Classifier -> OOD Score

Critical Path: Image → NF → Latent Space → Likelihood Computation → Complexity Quantification → GMM Inference → OOD Decision

Design Tradeoffs:
- The method requires additional complexity computation but maintains NF's exact likelihood property
- Using multiple complexity metrics provides robustness but increases computational overhead
- The GMM approach adds flexibility but requires careful parameter tuning and sufficient in-distribution data

Failure Signatures:
- Poor separation in the GMM when OOD data shares similar complexity characteristics with in-distribution data
- Overfitting of GMM parameters when in-distribution dataset is small
- Degraded performance if chosen complexity metrics poorly correlate with likelihood in the latent space

First Experiments to Run:
1. Verify the correlation between complexity metrics and likelihood values on a held-out in-distribution validation set
2. Test GMM parameter sensitivity by varying the number of mixture components
3. Evaluate OOD detection performance across different combinations of complexity metrics to identify the most effective ones

## Open Questions the Paper Calls Out

None

## Limitations

- The analysis of image complexity as a determinant of likelihood values remains a compelling but not fully resolved explanation for OOD detection failures
- The precise relationship between image complexity metrics and likelihood scores across diverse data distributions needs further validation, particularly for natural images with varying structural complexity
- The GMM-based solution assumes reliable quantification and separation of complexity from likelihood signals, but optimal complexity measures may vary across different OOD scenarios
- Computational overhead introduced by the GMM component and its impact on real-time OOD detection applications is not addressed

## Confidence

- Medium confidence in the core hypothesis linking image complexity to likelihood values, as experimental results support this relationship but alternative explanations cannot be ruled out
- High confidence in the empirical observation that standard NFs assign higher likelihoods to OOD data than in-distribution data
- Medium confidence in the GMM-based solution's effectiveness, given validation on a limited set of OOD datasets

## Next Checks

1. Test the complexity-likelihood correlation across a broader range of natural image datasets with varying semantic complexity (e.g., CIFAR-100, ImageNet subsets) to verify generalizability
2. Evaluate the GMM approach's robustness when OOD data shares similar complexity characteristics with in-distribution data
3. Measure computational overhead and inference time impact of the GMM component compared to standard NF OOD detection