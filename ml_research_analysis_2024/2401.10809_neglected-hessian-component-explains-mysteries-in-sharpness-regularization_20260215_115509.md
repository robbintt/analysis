---
ver: rpa2
title: Neglected Hessian component explains mysteries in Sharpness regularization
arxiv_id: '2401.10809'
source_url: https://arxiv.org/abs/2401.10809
tags:
- gradient
- second
- hessian
- information
- derivative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the structure of the Hessian matrix in
  deep learning to explain why some second-order regularization methods succeed while
  others fail. The authors decompose the Hessian into Gauss-Newton (GN) and Nonlinear
  Modeling Error (NME) components, showing that the NME captures information about
  feature exploration while the GN captures feature exploitation.
---

# Neglected Hessian component explains mysteries in Sharpness regularization

## Quick Facts
- arXiv ID: 2401.10809
- Source URL: https://arxiv.org/abs/2401.10809
- Authors: Yann N. Dauphin; Atish Agarwala; Hossein Mobahi
- Reference count: 23
- Primary result: Shows that neglecting the Hessian's Nonlinear Modeling Error component explains performance differences between second-order regularization methods

## Executive Summary
This paper investigates the structure of the Hessian matrix in deep learning to explain why some second-order regularization methods succeed while others fail. The authors decompose the Hessian into Gauss-Newton (GN) and Nonlinear Modeling Error (NME) components, showing that the NME captures information about feature exploration while the GN matrix captures feature exploitation. Through theoretical analysis and experiments on ImageNet and CIFAR-10, they demonstrate that the NME significantly affects gradient penalties and weight noise regularization methods. Their key findings show that gradient penalties are sensitive to activation functions due to NME sparsity, with GELU outperforming ReLU, and that weight noise regularization implicitly regularizes the NME, which can be detrimental.

## Method Summary
The authors train ResNet-50 on ImageNet and WideResNet 28-10 on CIFAR-10 with various regularization methods including gradient penalties, weight noise, and Sharpness Aware Minimization (SAM), using different activation functions (ReLU, GELU, β-GELU). They implement custom automatic differentiation operators to compute and manipulate the NME component of the Hessian. The experiments vary regularization strength and β parameters to compare test accuracy across different settings, with a focus on understanding how the NME structure affects regularization effectiveness.

## Key Results
- The NME significantly affects gradient penalties and weight noise regularization methods
- GELU outperforms ReLU in gradient penalty regularization due to NME sparsity differences
- Weight noise regularization implicitly regularizes the NME, which can be detrimental to generalization
- Augmented ReLU can improve gradient penalty performance by adding information related to the second derivative
- The second derivative of activation functions controls the sparsity and magnitude of information encoded in the NME

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The NME captures information about feature exploration in neural networks while the GN matrix captures feature exploitation.
- Mechanism: During training, the GN matrix encodes second-order information about the loss landscape around the current model parameters, which corresponds to exploiting existing linear structure in the data. The NME, which contains second derivatives of the model outputs with respect to parameters, encodes information about exploring different piecewise-linear regions of the activation function, particularly relevant for networks with saturating nonlinearities.
- Core assumption: The decomposition of the Hessian into GN and NME components is valid and meaningful for understanding learning dynamics.
- Evidence anchors:
  - [abstract]: "we show that a common decomposition of the Hessian can be quantitatively interpreted as separating the feature exploitation from feature exploration."
  - [section 2]: "we can see the GN matrix as the result of a linearization of the model and the NME as the part that takes into account the non-linear part of the model."
  - [corpus]: Weak evidence - no directly comparable decomposition papers found in corpus.
- Break condition: If the activation functions are linear or the network operates entirely in the lazy regime where feature learning is negligible, the NME may not provide meaningful information about feature exploration.

### Mechanism 2
- Claim: The second derivative of activation functions controls the sparsity and magnitude of information encoded in the NME, which affects gradient penalty regularization effectiveness.
- Mechanism: Activation functions with well-defined second derivatives (like GELU) produce non-trivial NME matrices with dense, meaningful information about feature learning. Activation functions with zero or undefined second derivatives (like ReLU) produce sparse or zero NME matrices. Gradient penalties that involve Hessian-vector products are sensitive to this structure, leading to different generalization performance.
- Core assumption: The NME's structure directly impacts the effectiveness of regularization methods that involve Hessian information.
- Evidence anchors:
  - [abstract]: "we demonstrate that the NME significantly affects gradient penalties and weight noise regularization methods."
  - [section 4.3]: "the second derivative of the activation function is key to controlling the statistics of the NME."
  - [section 4.4]: "augmented ReLU and the diminished GELU...lets us test if gradient penalty with ReLU can be rescued by adding information related to the second derivative piece of the NME."
  - [corpus]: Weak evidence - no directly comparable activation function studies found in corpus.
- Break condition: If the network is very shallow or if feature learning is minimal throughout training, the second derivative structure may not significantly impact regularization effectiveness.

### Mechanism 3
- Claim: Weight noise regularization implicitly regularizes the NME, which can be detrimental to generalization, while explicitly regularizing only the GN component (via Gauss-Newton trace penalty) can improve performance.
- Mechanism: Weight noise adds Gaussian noise to parameters, which to second order approximates a penalty on the full Hessian trace. This includes both GN and NME components. Regularizing the NME directly through the loss function can reduce its beneficial effects on feature exploration during training. The Gauss-Newton trace penalty, which excludes the NME from the regularization term, achieves better generalization by allowing the NME to influence learning dynamics while still regularizing curvature.
- Core assumption: The NME has a positive influence on learning dynamics even though direct regularization of it through the loss is detrimental.
- Evidence anchors:
  - [abstract]: "we also provide evidence that challenges the long held equivalence of weight noise and gradient penalties."
  - [section 5.1]: "the same analysis can be applied to weight noise...Eϵ[L(θ + ϵ)] ≈ L(θ) + σ2tr(H)"
  - [section 5.2]: "Figure 5 shows that the methods perform quite differently as σ2 increases - confirming the influence of the NME."
  - [corpus]: Weak evidence - no directly comparable weight noise studies found in corpus.
- Break condition: If the training dynamics are dominated by first-order effects or if the model is already in a regime where feature exploration is unnecessary, the distinction between GN and NME regularization may become negligible.

## Foundational Learning

- Concept: Hessian matrix decomposition into Gauss-Newton and Nonlinear Modeling Error components
  - Why needed here: Understanding this decomposition is fundamental to grasping why different second-order regularization methods have varying effectiveness.
  - Quick check question: What is the key difference between the Gauss-Newton and NME components of the Hessian in terms of the information they encode?

- Concept: Neural Tangent Kernel (NTK) and lazy training regime
  - Why needed here: The paper contrasts the linearized NTK dynamics (controlled by GN) with feature learning dynamics (captured by NME), making understanding of NTK essential.
  - Quick check question: In the lazy training regime, which Hessian component (GN or NME) primarily controls the learning dynamics?

- Concept: Automatic differentiation and custom derivative operators
  - Why needed here: The paper introduces augmented ReLU and diminished GELU using custom AD derivatives to manipulate the NME structure.
  - Quick check question: How does defining custom derivative operators in automatic differentiation frameworks allow manipulation of the NME component?

## Architecture Onboarding

- Component map:
  - Hessian decomposition module -> Computes GN and NME components from model parameters and loss
  - Activation function analyzer -> Evaluates second derivative properties of activation functions
  - Regularization method selector -> Chooses appropriate regularization based on NME structure
  - Experimental comparison framework -> Runs ablation studies across different architectures and datasets

- Critical path: Data -> Model forward pass -> Jacobian/second derivative computation -> Hessian decomposition -> Regularization application -> Training loop -> Evaluation

- Design tradeoffs: Balancing computational cost of NME computation against potential generalization benefits; choosing activation functions that balance forward/backward pass efficiency with NME informativeness.

- Failure signatures: Gradient penalties perform poorly with ReLU despite theoretical equivalence to other methods; weight noise regularization shows unexpected degradation in performance.

- First 3 experiments:
  1. Implement Hessian decomposition and verify GN/NME separation on a simple MLP with ReLU and GELU activations.
  2. Add gradient penalty regularization and compare performance across different activation functions.
  3. Implement weight noise regularization and compare against Gauss-Newton trace penalty ablation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the sparsity of the NME change with different architectural choices beyond activation functions?
- Basis in paper: [explicit] The paper shows that the NME is sensitive to the second derivative of activation functions, but also mentions that "there are many architectural changes that can affect the NME matrix."
- Why unresolved: The experiments focus on activation functions as the primary architectural variable affecting NME sparsity.
- What evidence would resolve it: Systematic experiments varying network depth, width, skip connections, and other architectural components while measuring NME sparsity and its impact on gradient penalties.

### Open Question 2
- Question: Can we design activation functions that optimize both forward/backward pass properties and second-order regularization compatibility?
- Basis in paper: [explicit] The discussion section suggests "Designing activation functions for compatibility with second order methods may also be an interesting avenue of future research."
- Why unresolved: Current activation functions are designed primarily for first-order optimization properties.
- What evidence would resolve it: New activation functions that maintain good first-order properties while reducing NME sparsity, validated through improved gradient penalty performance across multiple architectures.

### Open Question 3
- Question: What is the relationship between NME information and feature learning effectiveness?
- Basis in paper: [inferred] The paper suggests NME encodes information about "the benefits of switching to a different multilinear region where different neurons are active" and that augmented ReLU "acts over the totality of training to affect generalization."
- Why unresolved: While the paper shows NME affects learning dynamics, it doesn't establish a clear link to feature learning quality.
- What evidence would resolve it: Experiments correlating NME magnitude/structure during training with downstream task performance and feature quality metrics.

## Limitations

- The analysis is primarily empirical with theoretical derivations showing mathematical correctness but lacking rigorous proofs about why NME's influence on learning dynamics is beneficial
- The connection between NME structure and feature learning remains somewhat speculative rather than rigorously established
- The paper doesn't address whether the observed effects persist across different architectures beyond ResNets

## Confidence

- Medium confidence in the theoretical decomposition correctness and empirical observations about activation function differences
- Low confidence in the broader claims about NME being beneficial for feature exploration without more theoretical justification
- Medium confidence in the practical implications for choosing activation functions and regularization methods

## Next Checks

1. Replicate the core experiments with additional architectures (Vision Transformers, MLPs) to test if the NME-activation function relationship generalizes beyond ResNets
2. Conduct ablation studies isolating the contribution of NME from other factors by training with linearized models (zero NME) versus full nonlinear models
3. Test whether the proposed augmented ReLU activation maintains its advantages when training with first-order methods alone, isolating the Hessian-specific effects