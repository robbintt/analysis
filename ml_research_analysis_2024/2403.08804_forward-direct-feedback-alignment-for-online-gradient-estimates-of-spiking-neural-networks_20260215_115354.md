---
ver: rpa2
title: Forward Direct Feedback Alignment for Online Gradient Estimates of Spiking
  Neural Networks
arxiv_id: '2403.08804'
source_url: https://arxiv.org/abs/2403.08804
tags:
- gradient
- local
- sfdfa
- feedback
- spike
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel neuromorphic algorithm, the Spiking
  Forward Direct Feedback Alignment (SFDFA), for training Spiking Neural Networks
  (SNNs). The main contribution is the derivation of how exact local gradients of
  spikes can be computed in an online manner while considering intra-neuron dependencies
  between post-synaptic spikes.
---

# Forward Direct Feedback Alignment for Online Gradient Estimates of Spiking Neural Networks

## Quick Facts
- arXiv ID: 2403.08804
- Source URL: https://arxiv.org/abs/2403.08804
- Reference count: 13
- Primary result: SFDFA outperforms previous neuromorphic algorithms on benchmark datasets while addressing critical point gradient divergence

## Executive Summary
This paper introduces the Spiking Forward Direct Feedback Alignment (SFDFA) algorithm for training Spiking Neural Networks (SNNs) on neuromorphic hardware. The key innovation is a method to compute exact local gradients of spikes in an online manner while handling intra-neuron dependencies between post-synaptic spikes. SFDFA adapts Forward Direct Feedback Alignment to SNNs by estimating feedback weights between output and hidden neurons. The algorithm addresses critical point issues where gradients diverge by modifying the local gradient computation, replacing the unstable factor τ/(I(t)−ϑ) with τ/I(t). Empirical results on MNIST, EMNIST, Fashion MNIST, and SHD datasets demonstrate SFDFA outperforms previous neuromorphic algorithms in performance and convergence rates, though it still falls short of backpropagation.

## Method Summary
SFDFA is a neuromorphic algorithm that enables efficient training of Spiking Neural Networks by computing local gradients during inference. The method operates on LIF neurons with multiple spike capability and uses spike grades (directional derivatives) to estimate feedback weights between hidden and output layers. Instead of using random fixed feedback matrices like standard DFA, SFDFA learns these feedback weights through spike grade propagation. The algorithm computes local gradients using an eligibility trace formulation implemented as ordinary differential equations, making it compatible with neuromorphic hardware constraints. A key modification is the ad-hoc adjustment of the local gradient to remove the term ϑ, preventing gradient explosion at critical points where the membrane potential approaches the firing threshold.

## Key Results
- SFDFA achieves higher classification accuracy than previous neuromorphic algorithms on MNIST, EMNIST, and Fashion MNIST datasets
- The algorithm demonstrates faster convergence rates compared to Direct Feedback Alignment
- SFDFA successfully mitigates gradient divergence at critical points while maintaining reasonable performance
- Performance gap remains between SFDFA and backpropagation, especially on temporal datasets like SHD

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SFDFA mitigates gradient divergence by replacing the unstable factor τ/(I(t)−ϑ) with τ/I(t) in the local gradient computation.
- Mechanism: The original local gradient includes a term that diverges when the neuron's input current I(t) approaches the spiking threshold ϑ. By removing ϑ from this term, the modified factor τ/I(t) remains bounded, preventing gradient explosion.
- Core assumption: The modified factor τ/I(t) still provides a useful approximation of the gradient direction despite removing ϑ.
- Evidence anchors: The paper proposes this ad-hoc modification to remove the cause of critical points, noting that τ·ak_i·exp(−tk_i/τs) ≤ τ·ϑ has an upper bound and does not diverge towards infinity.

### Mechanism 2
- Claim: SFDFA estimates feedback weights between hidden and output layers, improving gradient alignment compared to random feedback in DFA.
- Mechanism: Instead of using random fixed feedback matrices, SFDFA learns feedback weights by propagating "spike grades" (directional derivatives) from output to hidden neurons. This creates a learned alignment between feedback and forward weights, reducing the bias in gradient estimates.
- Core assumption: The spike grade propagation provides an unbiased estimate of the forward weight between output and hidden neurons.
- Evidence anchors: The paper shows that feedback matrices become over time similar to the forward weights wij, and observes that output weight and feedback connections trained with SFDFA align faster and better than those trained with DFA.

### Mechanism 3
- Claim: SFDFA enables online gradient computation compatible with neuromorphic hardware constraints.
- Mechanism: By computing local gradients during inference using an eligibility trace formulation (differential equations), SFDFA avoids storing past states and performing backward passes, making it suitable for neuromorphic hardware.
- Core assumption: The eligibility trace formulation accurately captures the local gradient at spike times while being implementable with simple differential equations.
- Evidence anchors: The paper derives an eligibility trace that can be evaluated with ordinary differential equations on hardware, noting that this expression can be implemented on neuromorphic hardware using a LIF model at each synapse and locally used at post-synaptic spike times.

## Foundational Learning

- Concept: Leaky Integrate-and-Fire (LIF) neuron model with multiple spikes
  - Why needed here: SFDFA operates on LIF neurons, and the exact gradient computation depends on the neuron's membrane potential dynamics and multiple spike times
  - Quick check question: How does the membrane potential reset after each spike, and how does this affect the computation of subsequent spike times?

- Concept: Direct Feedback Alignment (DFA) and its limitations
  - Why needed here: SFDFA builds upon DFA by modifying the feedback mechanism to learn feedback weights instead of using random fixed matrices
  - Quick check question: Why does DFA typically perform worse than backpropagation, and how does the random feedback matrix introduce bias in gradient estimates?

- Concept: Gradient computation for spiking neurons and critical points
  - Why needed here: SFDFA addresses the issue of gradient divergence in spiking neural networks by modifying the local gradient computation
  - Quick check question: What causes the local gradient to diverge in spiking neural networks, and how does the modified factor τ/I(t) prevent this divergence?

## Architecture Onboarding

- Component map: LIF neurons -> Spike grade computation -> Eligibility trace computation -> Feedback weight estimation -> Weight update mechanism

- Critical path:
  1. During inference: Compute membrane potential, detect spikes, calculate spike grades, update eligibility traces
  2. After inference: Compute local gradients using eligibility traces, update forward and feedback weights using estimated gradients

- Design tradeoffs:
  - Modified gradient (removing ϑ) vs. exact gradient: stability vs. accuracy
  - Spike grade-based feedback weight estimation vs. direct derivative computation: compatibility with neuromorphic hardware vs. potential bias
  - Single error signal projection vs. continuous error projection: energy efficiency vs. potential slower convergence

- Failure signatures:
  - Gradient explosion: suggests critical points not properly handled
  - Poor convergence: suggests feedback weights not aligning properly with forward weights
  - Inconsistent performance across datasets: suggests limitations in handling temporal vs. static data

- First 3 experiments:
  1. Test critical point mitigation: Train a simple two-layer SNN on MNIST with both exact and modified gradients, compare convergence and stability
  2. Test feedback weight alignment: Train a two-layer SNN on MNIST with DFA and SFDFA, measure angle between forward and feedback weights
  3. Test online computation: Implement eligibility trace computation on neuromorphic hardware simulator, verify local gradients computed during inference

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise mechanism by which the modified local gradient (Equation 18) avoids gradient explosion at critical points, and how does this compare to alternative methods like gradient clipping in terms of bias and convergence speed?
- Basis in paper: [explicit] The paper describes the ad-hoc modification of dropping the term ϑ from the original gradient equation to prevent divergence, and compares this approach to gradient clipping.
- Why unresolved: While the paper shows that the modified gradient improves stability and convergence, a detailed mathematical analysis of the trade-off between bias and stability compared to other methods is not provided.
- What evidence would resolve it: A rigorous theoretical analysis of the bias introduced by the modified gradient and a comparative study with other gradient stabilization techniques on a variety of benchmark tasks.

### Open Question 2
- Question: How does the SFDFA algorithm perform on more complex temporal tasks, such as continuous control or natural language processing, where the current performance gap with BP is more pronounced?
- Basis in paper: [inferred] The paper acknowledges a performance gap between SFDFA and BP, especially on the temporal SHD dataset, suggesting limitations of the direct feedback learning approach for highly temporal data.
- Why unresolved: The paper only tests SFDFA on a limited set of benchmark datasets, and the performance on more complex temporal tasks remains unexplored.
- What evidence would resolve it: Empirical results of SFDFA on a wider range of temporal tasks, including continuous control and natural language processing benchmarks, compared to BP and other neuromorphic algorithms.

### Open Question 3
- Question: What are the underlying reasons for the observed decrease in gradient alignment in deeper layers when using SFDFA, and what modifications to the algorithm could improve this alignment?
- Basis in paper: [explicit] The paper observes that the gradient alignment between SFDFA and BP diminishes in deeper layers, suggesting that the benefits of SFDFA are more pronounced in layers close to the outputs.
- Why unresolved: The paper does not provide a detailed explanation for the decrease in gradient alignment in deeper layers or propose specific modifications to address this issue.
- What evidence would resolve it: A theoretical analysis of the factors contributing to the decrease in gradient alignment in deeper layers, along with empirical results of modified SFDFA algorithms designed to improve gradient alignment in these layers.

## Limitations
- The modified gradient may introduce approximation errors that could affect accuracy in complex tasks
- Spike grade-based feedback weight estimation requires further validation for accuracy across diverse network architectures
- Energy efficiency claims are theoretical as neuromorphic hardware implementation was not physically validated
- Performance gap remains between SFDFA and backpropagation, especially on temporal datasets

## Confidence

- **High confidence**: SFDFA outperforms DFA and shows improved convergence rates on benchmark datasets
- **Medium confidence**: The critical point mitigation mechanism effectively prevents gradient divergence
- **Low confidence**: Energy efficiency benefits on actual neuromorphic hardware

## Next Checks

1. Implement a controlled experiment comparing exact vs. modified gradients on a simple two-layer SNN to quantify the accuracy trade-off from removing ϑ

2. Measure feedback weight alignment by computing the angle between forward and feedback weights during training across different network depths and widths

3. Deploy the eligibility trace computation on an actual neuromorphic hardware platform (e.g., Intel Loihi) to verify the claimed energy efficiency benefits and identify any implementation challenges