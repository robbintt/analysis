---
ver: rpa2
title: One-shot Active Learning Based on Lewis Weight Sampling for Multiple Deep Models
arxiv_id: '2405.14121'
source_url: https://arxiv.org/abs/2405.14121
tags:
- instances
- learning
- lewis
- sampling
- weights
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a one-shot active learning method for training
  multiple deep models concurrently. The key idea is to sample and reweight unlabeled
  instances based on their maximum Lewis weights across different network representations.
---

# One-shot Active Learning Based on Lewis Weight Sampling for Multiple Deep Models

## Quick Facts
- arXiv ID: 2405.14121
- Source URL: https://arxiv.org/abs/2405.14121
- Reference count: 40
- Key outcome: Proposes one-shot active learning method for multiple deep models using Lewis weight sampling

## Executive Summary
This paper introduces a novel one-shot active learning approach for training multiple deep models concurrently by leveraging Lewis weight sampling. The method samples and reweights unlabeled instances based on their maximum Lewis weights across different network representations, enabling efficient querying of informative instances without the need for repeated model training. Theoretical analysis demonstrates that the approach achieves constant-factor approximations for multiple models with sample complexity depending on the sum of maximum Lewis weights. Experimental results on 11 datasets with 50 deep models show competitive performance compared to state-of-the-art iterative active learning methods while significantly reducing computational cost.

## Method Summary
The proposed method samples and reweights unlabeled instances based on their maximum Lewis weights across different network representations of multiple deep models. By computing Lewis weights for each instance across all models, the approach identifies the most informative samples for active learning queries. This one-shot approach eliminates the need for iterative retraining cycles typical in traditional active learning, as the sampling process can be performed once using multiple pre-trained or concurrently trained models. The theoretical framework establishes that the sample complexity depends on the sum of maximum Lewis weights across all models, with empirical evidence showing that this sum grows slowly as the number of models increases, indicating strong correlation among deep representations.

## Key Results
- Achieved competitive performance with state-of-the-art iterative active learning methods while significantly reducing computational cost
- Demonstrated that sum of maximum Lewis weights grows slowly as number of models increases, suggesting strong correlation among deep representations
- Validated approach across 11 datasets using 50 deep models, showing effectiveness of one-shot sampling strategy

## Why This Works (Mechanism)
The method works by exploiting the structural properties of Lewis weights in linear regression to approximate instance importance across multiple deep models. Lewis weights capture the influence of each data point on the solution of a least-squares problem, and by taking the maximum Lewis weight across different model representations, the approach identifies instances that are most informative for multiple models simultaneously. The one-shot nature eliminates the computational overhead of iterative retraining, while the weighted sampling ensures that diverse and informative instances are selected efficiently. The theoretical guarantee of constant-factor approximation ensures that the selected samples provide near-optimal information gain for model training.

## Foundational Learning

**Lewis Weights**
- Why needed: Provide principled measure of instance importance in regression problems
- Quick check: Verify that Lewis weights sum to 1 and reflect leverage scores

**Active Learning Sampling**
- Why needed: Enables selection of most informative instances for labeling
- Quick check: Confirm sampling reduces labeling cost while maintaining performance

**Multiple Model Correlation**
- Why needed: Understanding how different models share informative instances
- Quick check: Measure similarity of Lewis weight distributions across models

## Architecture Onboarding

**Component Map**
Pre-trained Models -> Lewis Weight Computation -> Instance Weight Aggregation -> Sampling -> Labeled Dataset

**Critical Path**
The critical computational path involves Lewis weight computation across all models, which requires matrix operations on model representations. This step dominates the computational complexity and determines the overall efficiency of the one-shot approach.

**Design Tradeoffs**
- One-shot vs iterative: Computational efficiency versus potential for adaptive refinement
- Maximum vs average Lewis weights: Sensitivity to outliers versus robustness across models
- Sample complexity: Number of queries versus approximation quality

**Failure Signatures**
- Poor performance when model representations are highly uncorrelated
- Computational bottlenecks when handling very large model ensembles
- Suboptimal sampling when Lewis weights poorly reflect true instance importance

**First Experiments**
1. Compare Lewis weight sampling against random sampling baseline on simple datasets
2. Evaluate sensitivity to number of models in the ensemble
3. Test computational efficiency gains on large-scale datasets

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical framework assumes linear models while applied to deep neural networks, introducing approximation errors
- Requires access to multiple pre-trained models or ability to train them concurrently, limiting practical applicability
- Experimental validation focuses primarily on image classification, leaving uncertainty about effectiveness in other domains

## Confidence

**Theoretical framework and sample complexity analysis:** High
**Computational efficiency claims:** Medium
**Cross-model generalization:** Medium
**Domain applicability beyond image classification:** Low

## Next Checks

1. Evaluate the method across diverse deep learning architectures including transformers, recurrent networks, and attention-based models to assess generalization capabilities

2. Conduct ablation studies comparing Lewis weight sampling against alternative importance sampling methods (e.g., Fisher information, gradient-based methods) under varying computational budgets

3. Test the approach on non-image datasets including text classification, speech recognition, and tabular data to evaluate domain transferability and identify potential limitations in different data modalities