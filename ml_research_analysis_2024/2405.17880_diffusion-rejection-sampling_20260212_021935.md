---
ver: rpa2
title: Diffusion Rejection Sampling
arxiv_id: '2405.17880'
source_url: https://arxiv.org/abs/2405.17880
tags:
- uni00000013
- diffusion
- sampling
- uni00000003
- uni00000014
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Diffusion Rejection Sampling (DiffRS), a
  method to improve sampling quality in pre-trained diffusion models by applying rejection
  sampling at each timestep. The approach uses a time-dependent discriminator to estimate
  the acceptance probability, refining poor samples through re-initialization.
---

# Diffusion Rejection Sampling

## Quick Facts
- arXiv ID: 2405.17880
- Source URL: https://arxiv.org/abs/2405.17880
- Reference count: 40
- Primary result: Achieves state-of-the-art FID of 1.59 on CIFAR-10 using diffusion rejection sampling with time-dependent discriminators

## Executive Summary
Diffusion Rejection Sampling (DiffRS) introduces a novel approach to improve sampling quality in pre-trained diffusion models by applying rejection sampling at each timestep. The method employs a time-dependent discriminator to estimate acceptance probabilities, allowing poor samples to be re-initialized for refinement. DiffRS theoretically tightens sampling error bounds compared to pre-trained models and demonstrates superior empirical performance on benchmark datasets, achieving state-of-the-art results on CIFAR-10 and competitive results on ImageNet 64×64. The approach shows particular promise for fast diffusion samplers and large-scale text-to-image models like Stable Diffusion.

## Method Summary
DiffRS enhances pre-trained diffusion models by integrating rejection sampling into the denoising process. At each timestep, a time-dependent discriminator estimates the likelihood ratio between the model's current output and the true data distribution, computing an acceptance probability. Samples that fail this test are re-initialized, allowing for iterative refinement. The method theoretically tightens sampling error bounds and demonstrates practical improvements across multiple datasets. The approach is particularly effective for fast samplers and scales to large models like Stable Diffusion while requiring fewer network evaluations than competing methods.

## Key Results
- Achieves state-of-the-art FID of 1.59 on CIFAR-10
- Near state-of-the-art FID of 1.26 on ImageNet 64×64
- Demonstrates scalability to large-scale text-to-image models like Stable Diffusion
- Requires fewer network function evaluations than competing approaches

## Why This Works (Mechanism)
DiffRS works by introducing a principled rejection mechanism into the diffusion sampling process. The time-dependent discriminator provides a theoretically sound way to estimate the acceptance probability at each timestep, ensuring that samples progressively converge toward the true data distribution. By allowing poor samples to be re-initialized rather than propagated, the method effectively reduces the impact of accumulated errors during sampling. This approach maintains the computational efficiency of fast diffusion samplers while achieving the sampling quality typically associated with more expensive methods.

## Foundational Learning

1. **Diffusion Models**: Generative models that denoise data through a Markov chain process
   - Why needed: Forms the baseline architecture DiffRS builds upon
   - Quick check: Understand forward noising and reverse denoising processes

2. **Rejection Sampling**: A technique for generating samples from a target distribution by accepting or rejecting proposals
   - Why needed: Core mechanism for improving sample quality in DiffRS
   - Quick check: Verify understanding of acceptance probability computation

3. **Likelihood Ratio Estimation**: Computing the ratio between model and true data distributions
   - Why needed: Enables the discriminator to estimate acceptance probabilities
   - Quick check: Confirm ability to differentiate between model and data distributions

4. **Time-dependent Discriminators**: Discriminators that adapt to different timesteps in the diffusion process
   - Why needed: Allows for timestep-specific acceptance criteria
   - Quick check: Understand how discriminator conditioning varies across timesteps

5. **Sample Error Bounds**: Theoretical guarantees on the quality of generated samples
   - Why needed: Provides mathematical justification for DiffRS improvements
   - Quick check: Review convergence properties of rejection sampling

6. **Fast Diffusion Samplers**: Efficient variants of diffusion models that reduce sampling steps
   - Why needed: Target application domain where DiffRS shows particular benefit
   - Quick check: Compare sampling efficiency trade-offs between different diffusion variants

## Architecture Onboarding

Component Map: Pre-trained Diffusion Model -> Time-dependent Discriminator -> Rejection Module -> Re-initialization Module

Critical Path: Input -> Diffusion Denoising Steps -> Discriminator Evaluation -> Acceptance Decision -> (Re-initialization if rejected) -> Output

Design Tradeoffs: DiffRS balances sampling quality against computational cost by selectively re-initializing poor samples rather than always requiring full re-sampling. The time-dependent discriminator adds overhead but provides more accurate acceptance probabilities compared to time-agnostic alternatives.

Failure Signatures: Poor performance may manifest as either excessive rejection rates (indicating discriminator miscalibration) or insufficient improvement over baseline (suggesting weak discriminator or acceptance criteria). Overfitting of the discriminator to training data can also degrade generalization.

First Experiments:
1. Test DiffRS on CIFAR-10 with a pre-trained diffusion model to verify the claimed FID improvement
2. Compare rejection rates across different timesteps to understand discriminator behavior
3. Evaluate computational overhead by measuring network function evaluations per sample

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided context.

## Limitations
- Scalability to high-resolution datasets beyond ImageNet 64×64 remains uncertain
- Time-dependent discriminator may overfit to training conditions
- Computational overhead of discriminator evaluation at each timestep could be prohibitive in resource-constrained settings

## Confidence
- **High**: Theoretical improvements in sampling error bounds are mathematically derived and verifiable
- **Medium**: Empirical performance gains on CIFAR-10 and ImageNet 64×64 are well-documented but may not generalize
- **Low**: Scalability and efficiency claims for large-scale models like Stable Diffusion lack sufficient experimental evidence

## Next Checks
1. Evaluate DiffRS on higher-resolution datasets (e.g., ImageNet 256×256 or 512×512) to assess scalability
2. Conduct ablation studies varying discriminator architectures and training strategies to test robustness
3. Test DiffRS in practical applications with Stable Diffusion to quantify real-world trade-offs between quality, cost, and speed