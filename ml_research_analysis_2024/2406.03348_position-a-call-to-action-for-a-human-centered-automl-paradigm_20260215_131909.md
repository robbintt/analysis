---
ver: rpa2
title: 'Position: A Call to Action for a Human-Centered AutoML Paradigm'
arxiv_id: '2406.03348'
source_url: https://arxiv.org/abs/2406.03348
tags:
- automl
- learning
- machine
- data
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This position paper argues for a more human-centered approach to
  automated machine learning (AutoML) research. The authors identify that current
  AutoML systems focus primarily on optimizing predictive performance but have neglected
  the interaction between users and AutoML systems.
---

# Position: A Call to Action for a Human-Centered AutoML Paradigm

## Quick Facts
- arXiv ID: 2406.03348
- Source URL: https://arxiv.org/abs/2406.03348
- Reference count: 40
- Position paper arguing for more human-centered approach to AutoML

## Executive Summary
This position paper argues for a fundamental shift in automated machine learning (AutoML) research toward a more human-centered paradigm. The authors contend that current AutoML systems have become overly focused on optimizing predictive performance while neglecting the crucial interaction between users and these systems. They identify that different user groups - domain experts, data scientists, and ML researchers - have distinct needs and expectations that are not adequately addressed by existing AutoML tools.

The paper proposes five key hypotheses for human-centered AutoML, emphasizing the importance of transparency, interpretability, customizability, flexibility, and iterative user interaction. By calling for future research directions that integrate these aspects into AutoML systems, the authors aim to empower users and improve the democratization of machine learning, ultimately creating tools that better serve the diverse needs of real-world practitioners.

## Method Summary
This position paper presents a conceptual framework and argument rather than empirical research or experiments. The authors synthesize observations from the current state of AutoML research and practice to identify gaps in human-centered design. Through analysis of user diversity and existing system limitations, they formulate five hypotheses for future research directions. The paper serves as a call to action for the research community to reconsider the fundamental goals and design principles of AutoML systems.

## Key Results
- Current AutoML systems prioritize predictive performance over user interaction and experience
- Different user groups (domain experts, data scientists, ML researchers) have diverse, unmet needs in existing AutoML tools
- Five key hypotheses proposed for human-centered AutoML focusing on transparency, interpretability, customizability, flexibility, and iterative interaction
- Call for research community to integrate human-centered aspects into future AutoML system development

## Why This Works (Mechanism)
The paper's argument works by identifying a fundamental mismatch between how AutoML systems are currently designed and how different users actually need to interact with machine learning tools. By recognizing that users have varying levels of expertise, different goals, and diverse contexts of use, the authors demonstrate why a one-size-fits-all approach to optimization fails to serve real-world needs. The proposed human-centered approach addresses this gap by emphasizing user agency, understanding, and adaptability in the AutoML process.

## Foundational Learning
1. **User Diversity in ML Systems**
   - Why needed: Different user groups have fundamentally different goals, expertise levels, and interaction patterns
   - Quick check: Can identify at least three distinct user personas and their specific needs

2. **Transparency in Automated Decision-Making**
   - Why needed: Users need to understand why certain models or configurations were selected
   - Quick check: Can explain the reasoning behind automated choices in accessible terms

3. **Interpretability vs Performance Trade-offs**
   - Why needed: Highly optimized models may sacrifice user understanding for marginal performance gains
   - Quick check: Can articulate when interpretability should take precedence over pure performance

## Architecture Onboarding
Component Map: User Interface -> Model Selection Engine -> Configuration Space -> Search Algorithm -> Performance Evaluation -> Feedback Loop -> User Interface

Critical Path: User Requirements -> Custom Configuration -> Model Search -> Result Interpretation -> User Feedback -> Iterative Refinement

Design Tradeoffs:
- Performance optimization vs user control
- Computational efficiency vs transparency
- Generic automation vs customizable workflows
- Speed of results vs depth of explanation

Failure Signatures:
- Users cannot understand why certain models were chosen
- System recommendations don't align with user domain knowledge
- Inability to modify automated decisions or incorporate expert insights
- Overwhelming complexity for non-expert users

First Experiments:
1. User study comparing satisfaction with black-box vs explainable AutoML recommendations
2. Task completion time analysis for domain experts using customizable vs fixed AutoML pipelines
3. Error analysis of user trust when provided with varying levels of model interpretability

## Open Questions the Paper Calls Out
The paper identifies several open questions for future research, including how to effectively balance automated optimization with user control, what level of transparency is optimal for different user groups, how to design interfaces that accommodate diverse user expertise levels, and what evaluation metrics should be used to assess human-centered AutoML systems beyond traditional performance measures.

## Limitations
- Conceptual framework lacks empirical validation through user studies or system implementations
- Generalized characterization of current AutoML systems may not reflect diversity of existing tools
- Does not address potential computational trade-offs of implementing human-centered features
- Limited discussion of technical challenges in creating truly customizable and interpretable AutoML systems

## Confidence
High confidence: The identification of user diversity as an important consideration in AutoML design
Medium confidence: The proposed five key hypotheses as valuable research directions
Low confidence: The characterization of current AutoML systems as universally neglecting human-centered aspects

## Next Checks
1. Conduct systematic user studies across the identified user groups to empirically validate the claimed diverse needs and expectations for AutoML systems
2. Implement and evaluate prototype AutoML systems incorporating the five proposed hypotheses to assess practical feasibility and user impact
3. Perform systematic literature review to map the current state of human-centered design in existing AutoML tools and identify specific gaps between theory and practice