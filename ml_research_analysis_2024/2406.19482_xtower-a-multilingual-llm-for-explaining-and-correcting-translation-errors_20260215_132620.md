---
ver: rpa2
title: 'xTower: A Multilingual LLM for Explaining and Correcting Translation Errors'
arxiv_id: '2406.19482'
source_url: https://arxiv.org/abs/2406.19482
tags: []
core_contribution: This paper introduces XTOWER, a multilingual large language model
  (LLM) designed to provide free-text explanations for translation errors and generate
  corrected translations. Built on top of TowerBase, XTOWER leverages human-annotated
  translation error spans and GPT-4-generated explanations to produce accurate and
  helpful explanations.
---

# xTower: A Multilingual LLM for Explaining and Correcting Translation Errors

## Quick Facts
- arXiv ID: 2406.19482
- Source URL: https://arxiv.org/abs/2406.19482
- Reference count: 29
- Key outcome: XTOWER improves translation quality by explaining and correcting errors, outperforming GPT-3.5 Turbo and Mixtral 8x7B across multiple language pairs

## Executive Summary
This paper introduces XTOWER, a multilingual large language model designed to explain and correct translation errors. Built on TowerBase, XTOWER leverages human-annotated translation error spans and GPT-4-generated explanations to produce accurate and helpful explanations. The model is evaluated on two dimensions: the relatedness of explanations to error spans and their helpfulness in understanding and improving translation quality. Extrinsically, XTOWER demonstrates significant improvements in translation quality by generating corrected translations, outperforming strong baselines like GPT-3.5 Turbo and Mixtral 8x7B across various language pairs. A hybrid approach that dynamically selects between using the original translation or querying XTOWER for a correction further enhances translation performance.

## Method Summary
XTOWER is built on top of TowerBase and trained using human-annotated translation error spans combined with GPT-4-generated explanations. The model learns to produce free-text explanations for translation errors and generate corrected translations. Evaluation is conducted through human assessment on two dimensions: relatedness to the error span and helpfulness in understanding and improving translation quality. The extrinsic evaluation measures improvements in translation quality by comparing corrected translations against strong baselines. A hybrid approach dynamically selects between the original translation and XTOWER's corrected version to optimize overall translation performance.

## Key Results
- XTOWER outperforms GPT-3.5 Turbo and Mixtral 8x7B in generating corrected translations across multiple language pairs
- Human evaluation shows XTOWER explanations are both related to error spans and helpful for understanding translation issues
- The hybrid approach that dynamically selects between original and corrected translations further improves translation quality

## Why This Works (Mechanism)
XTOWER works by leveraging human-annotated error spans to ground its explanations in actual translation mistakes, ensuring relevance. The use of GPT-4-generated explanations provides high-quality training data that captures nuanced error descriptions. By fine-tuning on this specialized dataset, XTOWER learns to identify and explain translation errors in a way that is both accurate and actionable. The model's ability to generate corrected translations directly addresses identified errors, leading to measurable quality improvements. The hybrid selection mechanism ensures that corrections are only applied when beneficial, optimizing the trade-off between accuracy and computational efficiency.

## Foundational Learning
- **Human-annotated error spans**: Why needed - To provide ground truth for what constitutes a translation error; Quick check - Verify annotation consistency across annotators
- **GPT-4 explanation generation**: Why needed - To create high-quality training data at scale; Quick check - Assess explanation accuracy and relevance through human evaluation
- **Fine-tuning on specialized data**: Why needed - To adapt the base model to the specific task of error explanation and correction; Quick check - Measure performance improvement over the base model
- **Hybrid selection mechanism**: Why needed - To balance correction benefits against computational costs; Quick check - Evaluate impact on overall translation quality and latency
- **Human evaluation dimensions**: Why needed - To assess both technical accuracy and practical usefulness of explanations; Quick check - Ensure inter-annotator agreement on evaluation criteria
- **Baseline comparison**: Why needed - To establish the relative performance of XTOWER; Quick check - Verify baseline implementations match reported results

## Architecture Onboarding

**Component Map**: Human-annotated errors -> GPT-4 explanations -> XTOWER training -> Translation correction -> Hybrid selection

**Critical Path**: Error span annotation → GPT-4 explanation generation → XTOWER fine-tuning → Translation correction generation → Human evaluation of explanations → Extrinsic evaluation of corrected translations

**Design Tradeoffs**: Using GPT-4 for explanation generation provides high-quality data but introduces potential biases; fine-tuning on specialized data improves task performance but may reduce general capabilities; the hybrid approach optimizes quality but increases computational complexity

**Failure Signatures**: Poor explanation quality may result from inadequate error span annotations or biased GPT-4 outputs; ineffective corrections may occur when the model overfits to training data patterns; the hybrid approach may fail to select corrections when the confidence threshold is set too conservatively

**First Experiments**:
1. Evaluate explanation quality on a held-out set of error spans not seen during training
2. Compare corrected translations against human references to measure absolute quality improvement
3. Test the hybrid selection mechanism on a diverse set of translation pairs to assess its generalization

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on human-annotated error spans may not capture the full complexity of translation errors across different language pairs
- Evaluation focuses on specific dimensions of explanation quality without addressing potential biases in GPT-4-generated explanations
- Reported improvements are based on comparisons with specific baselines and may not generalize to all translation scenarios
- The hybrid approach requires additional computational resources and may introduce latency in practical applications

## Confidence
- High confidence in technical implementation and evaluation methodology
- Medium confidence in effectiveness for improving translation quality across various language pairs
- Low confidence in generalizability to other language pairs or diverse translation tasks

## Next Checks
1. Evaluate XTOWER's performance on a broader range of language pairs, including low-resource languages, to assess generalizability
2. Conduct comprehensive analysis of GPT-4-generated explanation quality and potential biases across different error types
3. Implement and evaluate the hybrid approach in a real-world translation pipeline to measure impact on quality, efficiency, and user experience