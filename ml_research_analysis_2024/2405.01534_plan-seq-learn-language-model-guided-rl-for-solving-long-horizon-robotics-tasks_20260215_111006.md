---
ver: rpa2
title: 'Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics
  Tasks'
arxiv_id: '2405.01534'
source_url: https://arxiv.org/abs/2405.01534
tags: []
core_contribution: The paper introduces Plan-Seq-Learn (PSL), a modular approach that
  combines large language models (LLMs) for high-level planning, motion planning for
  skill sequencing, and reinforcement learning (RL) for low-level control to solve
  long-horizon robotics tasks from scratch. PSL uses an LLM to generate a sequence
  of sub-goals, motion planning to achieve robot poses for each sub-goal, and RL to
  learn local control policies.
---

# Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks

## Quick Facts
- arXiv ID: 2405.01534
- Source URL: https://arxiv.org/abs/2405.01534
- Authors: Murtaza Dalal; Tarun Chiruvolu; Devendra Chaplot; Ruslan Salakhutdinov
- Reference count: 40
- Primary result: Achieves >85% success on 25+ long-horizon robotics tasks with up to 10 stages

## Executive Summary
Plan-Seq-Learn (PSL) introduces a modular approach that combines large language models (LLMs) for high-level planning, motion planning for skill sequencing, and reinforcement learning (RL) for low-level control to solve complex long-horizon robotics tasks. The system decomposes tasks into sub-goals using LLM reasoning, generates intermediate robot poses via motion planning, and learns local control policies through RL. PSL demonstrates state-of-the-art performance on over 25 challenging robotics tasks with up to 10 stages, achieving success rates exceeding 85% while outperforming language-based, classical, and end-to-end approaches.

## Method Summary
PSL operates through a three-stage modular architecture that integrates LLM planning with traditional robotics components. First, an LLM analyzes task descriptions and generates a sequence of sub-goals representing intermediate milestones toward task completion. Second, a motion planner uses these sub-goals to determine intermediate robot poses that will accomplish each milestone while respecting kinematic constraints. Third, RL algorithms learn local control policies to execute the planned motions and achieve each sub-goal sequentially. This decomposition allows PSL to handle complex tasks by breaking them into manageable components while leveraging the reasoning capabilities of LLMs for planning and the precision of RL for execution.

## Key Results
- Achieves state-of-the-art performance on 25+ long-horizon robotics tasks
- Success rates exceed 85% on tasks with up to 10 stages
- Outperforms language-based, classical, and end-to-end approaches
- Demonstrates effective generalization across diverse manipulation tasks

## Why This Works (Mechanism)
PSL's effectiveness stems from its modular decomposition of complex tasks into complementary strengths of different AI paradigms. The LLM component provides flexible, generalizable high-level reasoning that can adapt to new task descriptions without retraining. Motion planning translates abstract goals into concrete, feasible robot trajectories while respecting physical constraints. RL fine-tunes low-level control policies for precise execution in the specific environment. This hierarchical approach allows each component to operate within its optimal domain while the overall system benefits from their combined capabilities.

## Foundational Learning
- **Large Language Models for Planning**: LLMs can parse natural language task descriptions and generate logical sub-goal sequences
  - Why needed: Provides flexible task understanding without task-specific programming
  - Quick check: Verify LLM generates coherent sub-goal sequences for novel tasks

- **Motion Planning Fundamentals**: Algorithms that find collision-free paths while respecting robot kinematics
  - Why needed: Translates abstract goals into executable robot motions
  - Quick check: Validate planned trajectories avoid obstacles and respect joint limits

- **Reinforcement Learning for Control**: Algorithms that learn optimal actions through trial-and-error interaction
  - Why needed: Enables precise execution of planned motions in the specific environment
- **Hierarchical Task Decomposition**: Breaking complex tasks into manageable sub-components
  - Why needed: Makes long-horizon tasks tractable for current AI systems
  - Quick check: Verify each sub-goal contributes meaningfully to overall task completion

## Architecture Onboarding

**Component Map**: LLM (task parsing) -> Motion Planning (pose generation) -> RL (control execution)

**Critical Path**: Task description → LLM sub-goal generation → Motion planning for poses → RL policy execution → Task completion

**Design Tradeoffs**: 
- Modular design enables specialization but introduces potential integration challenges
- LLM reasoning provides flexibility but may generate infeasible plans
- RL fine-tuning enables precision but requires environment interaction
- System complexity increases with task horizon length

**Failure Signatures**:
- LLM generates incoherent or incorrect sub-goals
- Motion planner fails to find feasible paths for valid sub-goals
- RL policies converge to suboptimal local minima
- Integration failures between sequential components

**3 First Experiments**:
1. Test LLM sub-goal generation on novel task descriptions outside training distribution
2. Validate motion planner can handle edge cases like narrow passages or complex constraints
3. Evaluate RL policy performance when executed in isolation versus integrated pipeline

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy reliance on language models may introduce brittleness in planning
- Performance evaluation limited to table-top manipulation domain
- Computational overhead of running LLMs for every task instance
- Integration assumes reliable pose estimation and scene understanding

## Confidence

**High confidence**: Modular architecture design and core components are well-validated within experimental domain

**Medium confidence**: State-of-the-art performance claims relative to baselines for specific task set

**Low confidence**: Generalizability claims to broader robotics applications beyond studied manipulation tasks

## Next Checks
1. Evaluate PSL's performance on tasks requiring cross-domain generalization to different robot platforms
2. Test system robustness to perceptual noise by introducing controlled disturbances in object pose detection
3. Conduct ablation studies systematically removing each module to quantify LLM contribution