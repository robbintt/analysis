---
ver: rpa2
title: Evaluating the role of `Constitutions' for learning from AI feedback
arxiv_id: '2411.10168'
source_url: https://arxiv.org/abs/2411.10168
tags:
- feedback
- patient
- constitutions
- constitution
- doctor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study investigates how different constitutions affect the
  quality of AI feedback in improving patient-centered communication in medical interviews.
  Four constitutions were tested: a detailed "Best Practices" constitution based on
  established clinical guidelines, an "Empathetic" constitution focused on emotional
  responses, a generic "Doctor" constitution, and a baseline with no constitution.'
---

# Evaluating the role of `Constitutions' for learning from AI feedback

## Quick Facts
- arXiv ID: 2411.10168
- Source URL: https://arxiv.org/abs/2411.10168
- Reference count: 31
- Primary result: Detailed constitutions significantly improve emotionally-oriented communication skills in AI feedback systems, but show limited effectiveness for practically-oriented skills like information gathering and provision.

## Executive Summary
This study investigates how different constitutions affect the quality of AI feedback in improving patient-centered communication in medical interviews. Four constitutions were tested: a detailed "Best Practices" constitution based on established clinical guidelines, an "Empathetic" constitution focused on emotional responses, a generic "Doctor" constitution, and a baseline with no constitution. Using an iterative in-context learning approach with LLM agents (Patient, Doctor, Moderator, Critic), dialogues were generated and evaluated by 215 human raters across six dimensions of patient-centered communication. The detailed "Best Practices" constitution significantly outperformed others in emotionally-oriented dimensions (Fostering Relationship, Decision Making, Responding to Emotions), while no constitution showed clear advantages in practically-oriented dimensions (Gathering/Providing Information, Enabling Treatment Behavior). The generic "Doctor" constitution performed no better than the no-constitution baseline, suggesting detailed guidelines are crucial for effective AI feedback in this domain.

## Method Summary
The study employed an iterative in-context learning approach using four LLM agents (Patient, Doctor, Moderator, Critic) with Claude 3.5 Sonnet API. Two medical vignettes from the AgentClinic dataset served as patient profiles. Four constitutions were tested: Best Practices (detailed clinical guidelines), Empathetic (emotional focus), Doctor (generic), and No Constitution (baseline). The critic provided feedback based on the constitution, which the doctor incorporated into subsequent responses. Final dialogues were evaluated by 215 human raters using pairwise comparisons across six dimensions of patient-centered communication, with results analyzed using the Bradley-Terry model to estimate quality parameters.

## Key Results
- Detailed "Best Practices" constitution significantly outperformed other constitutions in emotionally-oriented dimensions (Fostering Relationship, Decision Making, Responding to Emotions)
- Generic "Doctor" constitution performed no better than no-constitution baseline, indicating detailed guidelines are essential
- No constitution showed clear advantages for practically-oriented communication skills (Gathering/Providing Information, Enabling Treatment Behavior)
- Iterative in-context learning with constitutional feedback produced measurable improvements in specific communication dimensions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Detailed constitutions improve emotionally-oriented communication skills in AI feedback systems.
- Mechanism: Constitutions provide explicit behavioral guidelines that AI critics can use to generate targeted feedback, enabling iterative refinement of model responses. The "Best Practices" constitution with six detailed categories outperformed generic alternatives in dimensions like fostering relationships and responding to emotions.
- Core assumption: AI models can effectively parse and apply detailed constitutional guidelines to improve specific socio-communicative behaviors.
- Evidence anchors:
  - [abstract] "detailed constitutions led to better results regarding emotive qualities"
  - [section] "The Best Practices constitution is preferred to the other constitutions for 'Fostering the Relationship', 'Decision Making', and 'Responding to Emotions'"
  - [corpus] Weak evidence - corpus lacks direct studies on constitutional effectiveness
- Break condition: If constitutions become too lengthy or complex for AI models to process effectively, or if the critic model cannot reliably interpret the guidelines.

### Mechanism 2
- Claim: AI feedback methods show limited effectiveness for practically-oriented communication skills.
- Mechanism: Information gathering and provision require planning and theory of mind that current AI feedback mechanisms cannot adequately teach through iterative refinement alone.
- Core assumption: Language models struggle to learn complex planning and theory-of-mind tasks through constitutional feedback alone.
- Evidence anchors:
  - [abstract] "none of the constitutions outperformed the baseline in learning more practically-oriented skills related to information gathering and provision"
  - [section] "We do not see the same improvements for the more practically-oriented dimensions, where the LLM needs to manage information exchange with the patient"
  - [corpus] No direct corpus evidence for this specific mechanism
- Break condition: If the critic model develops better capabilities for evaluating and providing feedback on complex information management tasks.

### Mechanism 3
- Claim: In-context learning through iterative feedback loops is the primary mechanism for constitutional AI improvement.
- Mechanism: The critic provides feedback based on the constitution, which the doctor model incorporates into subsequent responses, creating a closed-loop learning system that refines outputs over multiple iterations.
- Core assumption: Each iteration of feedback meaningfully improves the model's responses in the direction specified by the constitution.
- Evidence anchors:
  - [section] "These methods often rely on 'constitutions', written guidelines which a critic model uses to provide feedback and improve generations"
  - [section] "We use iterative in-context learning to guide model generations based upon these constitutions"
  - [corpus] Limited evidence - corpus lacks detailed studies of in-context learning mechanisms
- Break condition: If the feedback loop fails to converge on improved responses, or if the model cannot effectively incorporate feedback into subsequent generations.

## Foundational Learning

- Concept: Constitutional AI framework
  - Why needed here: Understanding how constitutions guide AI feedback is central to interpreting the study's results
  - Quick check question: What is the primary role of a constitution in AI feedback systems?

- Concept: In-context learning
  - Why needed here: The study relies on iterative in-context learning rather than fine-tuning, which affects how improvements are achieved
  - Quick check question: How does in-context learning differ from traditional fine-tuning approaches?

- Concept: Patient-centered communication framework
  - Why needed here: The evaluation dimensions are based on this established medical communication framework
  - Quick check question: What are the six dimensions of patient-centered communication used in this study?

## Architecture Onboarding

- Component map: Patient agent -> Doctor agent -> Moderator agent -> Critic agent -> Feedback loop -> Human evaluation
- Critical path: Doctor model generations -> Critic feedback based on constitution -> Doctor model incorporation of feedback -> Final dialogue generation
- Design tradeoffs: Detailed constitutions provide better guidance but may be harder for models to process; simpler constitutions are easier to apply but less effective
- Failure signatures: Poor convergence in iterative feedback loops; critic providing vague or unhelpful feedback; doctor model failing to incorporate feedback
- First 3 experiments:
  1. Test constitution effectiveness with single-turn conversations to isolate immediate feedback impact
  2. Vary constitution specificity while keeping all other parameters constant to measure granularity effects
  3. Implement a multi-round feedback loop with different constitution types to observe convergence patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does iterative fine-tuning based on AI feedback with detailed constitutions outperform simple in-context learning for improving patient-centered communication skills?
- Basis in paper: [inferred] The paper notes that "fine-tuning based on a collection of examples would allow a model to learn behaviours which are not present in every example" and suggests this could achieve better results than single in-context learning interactions
- Why unresolved: The study only examined single-turn in-context learning improvements rather than comparing with fine-tuned models trained on multiple constitution-guided dialogues
- What evidence would resolve it: A controlled experiment comparing constitution-guided in-context learning versus constitution-guided fine-tuning across the same dimensions of patient-centered communication, measuring which approach produces more consistently preferred outputs

### Open Question 2
- Question: How do constitution-guided AI feedback systems perform across different medical specialties and cultural contexts?
- Basis in paper: [explicit] The paper states "We focused on comparing four specific constitutions in the case of patient-centered communication in medicine" and notes limitations in generalizability
- Why unresolved: The study used only two general medical vignettes without testing specialty-specific scenarios or cross-cultural communication challenges
- What evidence would resolve it: Testing the same constitution comparison methodology across diverse medical specialties (pediatrics, oncology, mental health) and with patient vignettes from different cultural backgrounds to assess performance variation

### Open Question 3
- Question: What is the optimal level of detail for constitutions in AI feedback systems - is there a point of diminishing returns?
- Basis in paper: [inferred] The study compared a highly detailed constitution with a moderately detailed one and a generic one, finding the detailed one superior, but didn't test intermediate levels of specificity
- Why unresolved: The paper only tested three extremes (highly detailed, moderately detailed, and no guidelines) without exploring intermediate specificity levels
- What evidence would resolve it: A systematic comparison testing constitutions with varying levels of detail (e.g., 10%, 25%, 50%, 75%, 100% of the most detailed constitution's content) to identify whether performance plateaus or declines with excessive detail

## Limitations
- Evaluation relied on pairwise comparisons of complete dialogues rather than analyzing individual conversational turns, limiting understanding of how constitutions affect specific communication moments
- Study used a single LLM model (Claude 3.5 Sonnet) and limited set of two medical vignettes, raising questions about generalizability across different models and clinical scenarios
- Human evaluation only assessed final outputs rather than tracking improvement trajectories, making it difficult to quantify the learning process itself

## Confidence
- **High confidence**: The finding that detailed "Best Practices" constitutions significantly outperform generic alternatives for emotionally-oriented communication dimensions
- **Medium confidence**: The observation that no constitution shows advantages for practically-oriented skills like information gathering and provision
- **Low confidence**: Claims about the relative performance of individual constitutions in specific dimensions due to limited sample size and vignette diversity

## Next Checks
1. **Cross-model validation**: Replicate the study using multiple LLM architectures (e.g., GPT-4, Llama) to assess whether constitutional effectiveness depends on specific model capabilities.

2. **Granular turn-level analysis**: Break down dialogues into individual conversational turns and evaluate how constitution application affects communication quality at each interaction point, rather than only assessing complete dialogues.

3. **Iterative improvement tracking**: Implement a system to measure quality changes after each feedback iteration, rather than only evaluating final outputs, to quantify the learning rate and convergence patterns for different constitutions.