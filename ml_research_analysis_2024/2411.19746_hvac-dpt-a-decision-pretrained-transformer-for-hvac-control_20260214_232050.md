---
ver: rpa2
title: 'HVAC-DPT: A Decision Pretrained Transformer for HVAC Control'
arxiv_id: '2411.19746'
source_url: https://arxiv.org/abs/2411.19746
tags:
- buildings
- building
- energy
- control
- ac-dpt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HVAC-DPT is a Decision-Pretrained Transformer for HVAC control
  that addresses the challenge of energy-efficient building management. It frames
  HVAC control as a sequential prediction task, training a causal transformer on interaction
  histories generated by diverse RL agents.
---

# HVAC-DPT: A Decision Pretrained Transformer for HVAC Control

## Quick Facts
- arXiv ID: 2411.19746
- Source URL: https://arxiv.org/abs/2411.19746
- Authors: Anaïs Berkes
- Reference count: 24
- Primary result: Reduces HVAC energy consumption by 45% compared to baseline in unseen buildings

## Executive Summary
HVAC-DPT is a Decision-Pretrained Transformer that addresses energy-efficient building management by framing HVAC control as a sequential prediction task. The model trains a causal transformer on interaction histories generated by diverse reinforcement learning agents and can refine its policy in-context without modifying network parameters. This enables deployment across different buildings without additional training or data collection. In year-long EnergyPlus evaluations, HVAC-DPT achieved 45% energy reduction compared to baseline operations in unseen buildings, outperforming other controllers while requiring no prior building knowledge.

## Method Summary
HVAC-DPT trains a GPT-2 transformer on interaction datasets collected from diverse PPO agents controlling various buildings in EnergyPlus simulations. The model learns to predict HVAC actions from query states and context histories through supervised learning. During deployment, it performs in-context learning by conditioning predictions on building-specific histories without updating weights. The approach uses a multi-agent MARL formulation where each agent controls a single zone, enabling scalability across buildings with different zone counts. The transformer architecture (3 layers, 8 attention heads, 128 embedding dimension) is trained using MSE loss to predict minimum damper positions for VAV systems.

## Key Results
- 45% reduction in HVAC energy consumption compared to baseline controller in unseen buildings
- Outperforms other controllers without requiring prior building knowledge or additional training
- Enables deployment across buildings with different numbers of zones through per-zone independent control

## Why This Works (Mechanism)

### Mechanism 1
- Claim: HVAC-DPT achieves in-context learning by training a transformer to predict actions conditioned on historical interaction data from diverse RL agents.
- Mechanism: The model learns a mapping from query states and context histories to actions during pretraining. At deployment, it uses the same mapping without updating weights, effectively adapting to new buildings through the provided context.
- Core assumption: The pretraining dataset contains sufficient diversity in building types and control policies to enable generalization to unseen buildings.
- Evidence anchors:
  - [abstract] "HVAC-DPT frames HVAC control as a sequential prediction task, training a causal transformer on interaction histories generated by diverse RL agents."
  - [section] "A query state si query is sampled for each zone and a label a⋆ is sampled from an agent in the policy library. The in-context dataset D and query state squery are used to train a model to predict the RL-labeled action a⋆ via supervised learning."
- Break condition: If the pretraining data lacks diversity in building types, climate zones, or control strategies, the model may fail to generalize to new buildings.

### Mechanism 2
- Claim: The multi-agent MARL formulation allows HVAC-DPT to scale across buildings with different numbers of zones without retraining.
- Mechanism: Each agent controls a single zone independently, with the transformer receiving zone-specific query states and context histories. This decouples the control problem from building-specific state-action space sizes.
- Core assumption: The transformer can effectively condition its predictions on zone-specific information while maintaining performance across buildings with varying zone counts.
- Evidence anchors:
  - [section] "Consequently, we model HV AC control as a multi-agent reinforcement learning (MARL) task, where each agent controls a single zone, enabling independent management across zones"
  - [section] "Each agent's action spaceAi corresponds to the minimum damper position in their V A V system, ranging from 0 (closed) to 1 (fully open)."
- Break condition: If the number of zones in a target building significantly exceeds those seen during training, the model may struggle to maintain performance due to limited context window capacity.

### Mechanism 3
- Claim: The pretraining on diverse PPO policies creates a robust action space representation that generalizes across buildings.
- Mechanism: By training on rollouts from multiple PPO agents with different exploration behaviors and policy architectures, the transformer learns a rich action space representation that captures the solution space for HVAC control across building types.
- Core assumption: PPO policies trained with sufficient diversity in building configurations will explore a representative portion of the action space relevant for HVAC control.
- Evidence anchors:
  - [section] "The control agents in the policy library are trained following the approach outlined in [6]. We use PPO with a clipping parameter ϵ = 0.2"
  - [section] "Both policy and environment diversity are used during training, as in [6]."
- Break condition: If PPO policies converge to similar suboptimal behaviors or if the diversity in training buildings is insufficient, the action space representation may be too narrow for effective generalization.

## Foundational Learning

- Concept: Transformer architecture and attention mechanisms
  - Why needed here: Understanding how transformers process sequential data and use attention to weigh context information is crucial for grasping how HVAC-DPT makes predictions based on historical interactions.
  - Quick check question: How does multi-head attention in transformers enable the model to focus on different aspects of the context history when making predictions?

- Concept: Reinforcement learning fundamentals and policy gradients
  - Why needed here: The pretraining process relies on interaction data from RL agents, and understanding RL concepts helps explain why diverse policies are needed for effective pretraining.
  - Quick check question: Why is policy diversity important when collecting training data for a model that will perform in-context learning?

- Concept: Building thermal dynamics and HVAC systems
  - Why needed here: Understanding how HVAC systems work and how building thermal dynamics respond to control actions is essential for interpreting the state variables and reward structures used in the model.
  - Quick check question: What building state variables would be most critical for predicting the optimal damper position in a VAV system?

## Architecture Onboarding

- Component map: EnergyPlus simulations -> PPO agent training -> Interaction dataset collection -> GPT-2 transformer training -> Inference engine -> EnergyPlus evaluation
- Critical path: Data collection → Transformer pretraining → Deployment → Performance evaluation
- Design tradeoffs:
  - Context length vs. computational efficiency: Longer contexts enable better performance but increase inference time
  - Pretraining diversity vs. sample efficiency: More diverse pretraining data improves generalization but requires more computation
  - Fixed architecture vs. adaptability: Using a fixed transformer architecture enables deployment without retraining but may limit optimal performance for specific building types
- Failure signatures:
  - Degraded performance in buildings with zone counts significantly different from training
  - Sensitivity to context history quality or length
  - Performance degradation in extreme weather conditions not well-represented in pretraining data
- First 3 experiments:
  1. Ablation study on context length: Measure performance with context histories of 10, 50, and 100 time steps to find optimal tradeoff
  2. Diversity analysis: Train separate models with varying levels of policy diversity in pretraining and measure generalization performance
  3. Architecture scaling: Test performance with transformer variants (more layers, attention heads) to identify optimal architecture for the HVAC control task

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but based on the limitations and scope of the work, several important questions emerge regarding the model's adaptability, scalability, and real-world deployment considerations.

## Limitations
- Evaluation limited to EnergyPlus simulations without field validation in actual buildings
- Performance claims based on single year-long simulation in buildings matching pretraining configurations
- Limited exploration of adaptability to buildings with significantly different thermal dynamics or zone counts

## Confidence
- **High confidence**: The transformer architecture can learn to predict HVAC actions from historical data
- **Medium confidence**: In-context learning enables deployment across different buildings without retraining
- **Medium confidence**: 45% energy reduction claim based on simulation results

## Next Checks
1. **Cross-climate validation**: Test the deployed model across buildings in different climate zones (tropical, temperate, continental) to verify generalization beyond the training climate distributions
2. **Field trial comparison**: Deploy HVAC-DPT in an actual building and compare performance against both baseline controllers and state-of-the-art RL controllers under identical conditions
3. **Context sensitivity analysis**: Systematically vary context history length and quality to determine the minimum viable context requirements and identify failure modes when context is limited or noisy