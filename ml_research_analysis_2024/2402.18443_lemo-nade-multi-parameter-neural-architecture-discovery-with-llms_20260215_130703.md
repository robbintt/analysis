---
ver: rpa2
title: 'LeMo-NADe: Multi-Parameter Neural Architecture Discovery with LLMs'
arxiv_id: '2402.18443'
source_url: https://arxiv.org/abs/2402.18443
tags:
- e-06
- neural
- training
- accuracy
- etrics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LeMo-NADe, a novel framework for neural architecture
  discovery using large language models (LLMs) without relying on predefined search
  spaces. The method employs an expert system to guide the LLM through iterative neural
  network generation, allowing for the creation of architectures optimized for various
  edge device constraints including power consumption, model size, inferencing speed,
  and CO2 emissions.
---

# LeMo-NADe: Multi-Parameter Neural Architecture Discovery with LLMs

## Quick Facts
- arXiv ID: 2402.18443
- Source URL: https://arxiv.org/abs/2402.18443
- Authors: Md Hafizur Rahman; Prabuddha Chakraborty
- Reference count: 40
- Key outcome: Novel LLM-based framework discovers neural architectures without predefined search spaces, achieving near-SOTA results on CIFAR-10 (89.41%) and CIFAR-100 (67.90%) while being highly energy-efficient

## Executive Summary
LeMo-NADe introduces a novel approach to neural architecture search (NAS) that leverages large language models (LLMs) without requiring predefined search spaces. The framework uses an expert system to guide LLMs through iterative architecture generation, allowing for optimization across multiple edge device constraints including power consumption, model size, and CO2 emissions. Tested on CIFAR-10, CIFAR-100, and ImageNet16-120 datasets, LeMo-NADe achieves competitive performance while dramatically reducing computational overhead compared to traditional NAS methods.

## Method Summary
LeMo-NADe employs a closed-loop discovery process where an expert system evaluates LLM-generated neural network architectures using multiple metrics, then issues targeted refinement instructions. The system iteratively improves architectures without requiring explicit search space enumeration, instead relying on the LLM's implicit knowledge of neural architectures. The framework optimizes for accuracy, FPS, power consumption, and CO2 emissions through a combined model effectiveness metric that balances these competing objectives. Architecture generation and training complete within hours while consuming minimal energy.

## Key Results
- Achieved 89.41% test accuracy on CIFAR-10 and 67.90% on CIFAR-100
- Generated competitive architectures for ImageNet16-120 (31.02% test accuracy)
- Completed discovery process within hours with minimal energy consumption and low CO2 emissions
- Demonstrated ability to optimize for multiple edge device constraints simultaneously

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LeMo-NADe achieves architecture discovery without predefined search spaces by iteratively refining neural network designs through LLM-generated responses guided by an expert system.
- Mechanism: The expert system evaluates generated architectures using user-defined and evaluation-based metrics, then issues targeted instructions to the LLM to modify the architecture. This creates a closed-loop discovery process that progressively improves architectures without requiring an explicit search space enumeration.
- Core assumption: The LLM possesses sufficient implicit knowledge about neural architectures and their performance characteristics to generate viable architectures from scratch, and can follow iterative refinement instructions.
- Evidence anchors:
  - [abstract] "The introduced framework (LeMo-NADe) is tailored to be used by non-AI experts, does not require a predetermined neural architecture search space"
  - [section] "LeMo-NADe was able to create highly effective (accuracy, FPS, power consumption) neural networks for different applications/requirements and for different datasets (CIFAR-10, CIFAR-100, and ImageNet16-120) in an efficient manner"
  - [corpus] Weak evidence - corpus papers focus on search-based or differentiable architecture search rather than LLM-driven discovery without search spaces
- Break condition: If the LLM lacks sufficient implicit architectural knowledge or cannot follow iterative refinement instructions, the discovery process will fail to generate viable architectures.

### Mechanism 2
- Claim: The expert system's instruction generation and conflict resolution enable effective navigation of the architectural design space by balancing multiple competing objectives.
- Mechanism: The expert system generates instructions based on metric evaluations and resolves conflicts between contradictory instructions, allowing the LLM to explore architectural variations while maintaining coherence toward optimization goals.
- Core assumption: The rule-based expert system can effectively translate metric evaluations into actionable architectural modifications that guide the LLM toward optimal solutions.
- Evidence anchors:
  - [abstract] "The introduced framework (LeMo-NADe) ... considers a large set of edge device-specific parameters"
  - [section] "To store the best network architecture, we calculate a metric called the combined model effectiveness (CM ) which we define as: CM = AW · (Ta + Va) + (F W · N F) − EW · (TN E + VN E)"
  - [corpus] Weak evidence - corpus focuses on search-based NAS rather than expert-system guided LLM instruction generation
- Break condition: If the expert system rules are poorly calibrated or conflict resolution is inadequate, the LLM may receive contradictory or ineffective instructions that prevent convergence to optimal architectures.

### Mechanism 3
- Claim: LeMo-NADe's efficiency stems from its ability to generate and evaluate architectures within hours while consuming minimal energy and producing low CO2 emissions.
- Mechanism: By leveraging pre-trained LLMs and avoiding exhaustive search space enumeration, LeMo-NADe dramatically reduces computational overhead compared to traditional NAS approaches while still discovering competitive architectures.
- Core assumption: The computational efficiency gains from using LLMs and avoiding search spaces outweigh the overhead of iterative LLM interactions and architecture evaluations.
- Evidence anchors:
  - [abstract] "The discovery process was highly efficient, with model generation and training completed within hours while consuming minimal energy and producing low CO2 emissions"
  - [section] "LeMo-NADe is also very efficient (time, energy consumption, and CO2 Emissions) in terms of model generation/training"
  - [corpus] Weak evidence - corpus papers focus on search efficiency but not on LLM-driven approaches without search spaces
- Break condition: If LLM API costs or iterative evaluation overhead become prohibitive, the claimed efficiency advantages may not materialize in practice.

## Foundational Learning

- Concept: Neural Architecture Search (NAS) fundamentals
  - Why needed here: Understanding traditional NAS approaches and their limitations is essential for appreciating why LeMo-NADe's search-space-agnostic approach is innovative
  - Quick check question: What are the primary computational bottlenecks in traditional differentiable NAS approaches like DARTS?

- Concept: Expert systems and rule-based decision making
  - Why needed here: The expert system is central to LeMo-NADe's operation, translating metric evaluations into actionable LLM instructions
  - Quick check question: How does conflict resolution between contradictory instructions affect the quality of architectural modifications?

- Concept: Large Language Model capabilities and limitations
  - Why needed here: LeMo-NADe's success depends on the LLM's ability to generate valid neural architectures and follow iterative refinement instructions
  - Quick check question: What factors determine whether an LLM can successfully generate syntactically and semantically valid neural network code?

## Architecture Onboarding

- Component map: User Interface -> Expert System -> LLM Backend -> Evaluation Pipeline -> Conflict Resolution -> Model Effectiveness Calculator
- Critical path: User input → Expert System → LLM generation → Architecture evaluation → Metric calculation → Expert System refinement → Best model selection
- Design tradeoffs:
  - Search space freedom vs. LLM knowledge limitations
  - Iterative refinement depth vs. computational efficiency
  - Rule complexity vs. expert system maintainability
  - Temperature settings vs. architectural diversity
- Failure signatures:
  - LLM generates invalid architectures (syntax errors, shape mismatches)
  - Expert system provides contradictory instructions
  - Metrics fail to converge toward optimal values
  - Computational costs exceed efficiency claims
- First 3 experiments:
  1. Implement LeMo-NADe with a simple expert system and test on CIFAR-10 with fixed temperature settings
  2. Evaluate the impact of different temperature values on architecture quality and diversity
  3. Test conflict resolution effectiveness by introducing contradictory metric priorities and observing architectural outcomes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LeMo-NADe consistently generate novel architectures that outperform those found by traditional NAS methods across diverse datasets and applications?
- Basis in paper: [explicit] The paper claims LeMo-NADe "can rapidly discover intricate neural network models that perform extremely well across a diverse set of application settings" and shows competitive results on CIFAR-10, CIFAR-100, and ImageNet16-120 datasets.
- Why unresolved: The experimental results show LeMo-NADe performs competitively but not consistently better than traditional NAS methods across all tested datasets. Further extensive testing on more diverse datasets and applications is needed.
- What evidence would resolve it: Comprehensive experiments comparing LeMo-NADe's generated architectures against state-of-the-art NAS methods on a wide range of datasets (including those outside image classification) and applications (including non-vision tasks).

### Open Question 2
- Question: How does the quality and novelty of architectures generated by LeMo-NADe vary with different LLM choices and configurations?
- Basis in paper: [explicit] The paper tests LeMo-NADe with GPT-4 Turbo and Gemini, finding different performance characteristics, but notes this is "an important research question for future exploration."
- Why unresolved: The paper only tests two LLM options and doesn't systematically explore how different LLM choices, prompts, or configurations affect the quality and novelty of generated architectures.
- What evidence would resolve it: Systematic experiments varying LLM choice (including smaller or specialized models), prompt engineering strategies, temperature settings, and other configurations to determine their impact on architecture quality and novelty.

### Open Question 3
- Question: What is the theoretical basis for why LLMs can generate effective neural architectures without predefined search spaces?
- Basis in paper: [inferred] The paper hypothesizes that LLMs trained on "a large volume of open-domain data will inevitably also have the knowledge about different neural architectures" but doesn't provide theoretical justification for this claim.
- Why unresolved: The paper demonstrates empirical success but doesn't explain why or how LLMs can generate effective architectures without explicit training on neural architecture data or search space constraints.
- What evidence would resolve it: Theoretical analysis or experiments investigating what aspects of LLM pretraining enable architecture generation, including ablation studies on training data composition and analysis of architectural patterns in LLM training corpora.

## Limitations
- Limited architectural diversity evaluation - focuses on accuracy rather than architectural innovation
- Expert system rule dependency - success heavily relies on quality of rule design
- Generalizability across domains - only tested on image classification tasks

## Confidence
- High confidence in computational efficiency claims - concrete measurements of energy consumption and CO2 emissions
- Medium confidence in architectural effectiveness - competitive accuracy but limited architectural diversity assessment
- Low confidence in expert system robustness - minimal detail on rule design and conflict resolution mechanisms

## Next Checks
1. Implement systematic measurement of architectural diversity across multiple LeMo-NADe runs to quantify whether the framework truly explores novel architectures or converges to similar designs.
2. Apply LeMo-NADe to a non-image domain (e.g., time series forecasting or text classification) to evaluate its effectiveness beyond the demonstrated image classification tasks.
3. Systematically remove or modify expert system rules to quantify their individual contributions to architectural quality and identify potential brittleness in the framework's operation.