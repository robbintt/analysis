---
ver: rpa2
title: 'Infant Agent: A Tool-Integrated, Logic-Driven Agent with Cost-Effective API
  Usage'
arxiv_id: '2411.01114'
source_url: https://arxiv.org/abs/2411.01114
tags:
- agent
- task
- infant
- reasoning
- file
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: INFANT AGENT is a tool-integrated, logic-driven agent that addresses
  the limitations of large language models in autonomous real-world engineering problem-solving
  and complex logical reasoning. It introduces a hierarchical agent collaboration
  system and memory retrieval mechanism to improve task execution efficiency and reduce
  API costs.
---

# Infant Agent: A Tool-Integrated, Logic-Driven Agent with Cost-Effective API Usage

## Quick Facts
- **arXiv ID:** 2411.01114
- **Source URL:** https://arxiv.org/abs/2411.01114
- **Reference count:** 10
- **Primary result:** 30% accuracy on SWE-bench-lite, surpassing OpenHands CodeActAgent by 8 percentage points

## Executive Summary
INFANT AGENT is a tool-integrated, logic-driven agent designed to address the limitations of large language models in autonomous real-world engineering problem-solving and complex logical reasoning. It introduces a hierarchical agent collaboration system and memory retrieval mechanism to improve task execution efficiency and reduce API costs. The agent achieves 30% accuracy on SWE-bench-lite, surpassing OpenHands CodeActAgent by 8 percentage points, and reaches 37% accuracy on the AIME-2024 dataset, matching o1-preview. The memory retrieval mechanism reduces API token costs by nearly 80%, while the hierarchical structure improves command accuracy and minimizes errors in tool invocation.

## Method Summary
INFANT AGENT implements a hierarchical agent collaboration system with brain-level agents for reasoning and hand-level agents for task execution. The architecture includes a memory retrieval mechanism that segments memory modules for different tasks to reduce API token costs, and enhanced file-editing commands with string matching parameters to improve accuracy. The agent uses chain-of-thought prompting, tool invocation, and memory retrieval to handle complex multi-step tasks while minimizing API costs through intelligent memory management.

## Key Results
- Achieves 30% accuracy on SWE-bench-lite, outperforming OpenHands CodeActAgent by 8 percentage points
- Matches o1-preview accuracy (37%) on AIME-2024 dataset for complex mathematical reasoning
- Reduces API token costs by nearly 80% through memory retrieval mechanism
- Improves file-editing command accuracy from 72.9% to 96.8% with enhanced string matching

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical agent collaboration reduces ineffective outputs by preventing overly long few-shot examples and excessive built-in commands.
- Mechanism: The hierarchical structure divides agents into brain-level and hand-level agents, where brain-level agents handle reasoning and hand-level agents execute tasks using specialized tools.
- Core assumption: Specialized agents with task-specific prompts reduce token usage and command invocation errors compared to a flat, general-purpose agent.
- Evidence anchors:
  - [abstract] "We proposed a hierarchical agent collaboration system, which mitigates issues of ineffective outputs caused by an excessive number of built-in commands or overly long few-shot examples."
  - [section] "To address this issue, INFANT AGENT employs a hierarchical collaboration structure... Each hand-level agent can be designed with prompts or trained on carefully curated datasets specifically tailored to its task, which not only significantly reduces token usage but also nearly eliminates all incorrect command invocations."
  - [corpus] Weak - no direct corpus evidence for this specific mechanism.

### Mechanism 2
- Claim: Memory retrieval mechanism reduces API token costs by nearly 80% compared to using full memory for each inference.
- Mechanism: The memory retrieval mechanism segments memory modules for different tasks and extracts memory in various situations, rather than using the full memory for each inference.
- Core assumption: Extracting and retrieving relevant memory segments is more efficient than using the full memory for each inference.
- Evidence anchors:
  - [abstract] "The memory retrieval mechanism reduces API token costs by nearly 80%, while the hierarchical structure improves command accuracy and minimizes errors in tool invocation."
  - [section] "We implemented a memory retrieval mechanism, which reduces API token costs by nearly 80% compared to using the full memory inference each time."
  - [corpus] Weak - no direct corpus evidence for this specific mechanism.

### Mechanism 3
- Claim: Enhanced file-editing commands improve accuracy from 72.9% to 96.8% by addressing LLM misalignment issues with line numbers.
- Mechanism: The enhanced file-editing commands add two new parameters, start line string and end line string, which require the line number to correspond to the specified string, and automatically adjust the command if they do not match.
- Core assumption: LLMs have strong text understanding but struggle with discriminating numbers, so requiring string-line correspondence improves accuracy.
- Evidence anchors:
  - [section] "To address this issue, we first enhanced the original file-editing commands... These parameters require that the line number of start line must correspond to start line string, and the line number of end line must match end line string. If they do not match, the Agent will automatically issue prompt commands to guide the LLM in adjusting the original edit file() command until it matches correctly."
  - [experiment] "This enhancement to the file-editing command improved the accuracy of SWE-Agent's file-editing function from 72.9% to 96.8%."
  - [corpus] Weak - no direct corpus evidence for this specific mechanism.

## Foundational Learning

- Concept: Chain-of-thought prompting
  - Why needed here: It enables the agent to perform step-by-step reasoning and analysis, which is crucial for handling complex multi-step tasks.
  - Quick check question: What is the primary benefit of using chain-of-thought prompting in the context of this agent?

- Concept: Tool invocation
  - Why needed here: It allows the agent to interact with the physical world and perform specific tasks, which is essential for solving real-world engineering problems.
  - Quick check question: How does tool invocation contribute to the agent's ability to solve real-world engineering problems?

- Concept: Memory retrieval
  - Why needed here: It reduces API token costs by extracting and retrieving relevant memory segments, rather than using the full memory for each inference.
  - Quick check question: What is the primary benefit of using memory retrieval in the context of this agent?

## Architecture Onboarding

- Component map: User input -> Brain-level agent (reasoning) -> Task scheduling -> Hand-level agent (execution) -> Memory retrieval -> Evaluation -> Summarization -> Stop
- Critical path: User input -> Reasoning -> Task scheduling -> Task execution -> Evaluation -> Summarization -> Stop
- Design tradeoffs: Hierarchical structure vs. flat structure (communication overhead vs. command accuracy), memory retrieval vs. full memory usage (efficiency vs. comprehensiveness), enhanced file-editing commands vs. original commands (accuracy vs. complexity)
- Failure signatures: Ineffective outputs (hierarchical structure), high API token costs (memory retrieval), file-editing misalignment errors (enhanced file-editing commands)
- First 3 experiments:
  1. Test the hierarchical agent collaboration system on a simple task to verify command accuracy improvements.
  2. Test the memory retrieval mechanism on a complex task to verify token cost reductions.
  3. Test the enhanced file-editing commands on a code task to verify accuracy improvements.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the hierarchical agent collaboration system scale with increasing complexity and number of commands, and what are the theoretical limits of this approach?
- Basis in paper: [explicit] The paper mentions that the hierarchical structure reduces incorrect command invocations from 13.9% to 0%, but doesn't discuss scalability limits.
- Why unresolved: The paper only demonstrates effectiveness on a single task type (code tasks) and doesn't explore how the system performs with hundreds or thousands of commands across multiple domains.
- What evidence would resolve it: A systematic study testing the system with increasing numbers of commands (10, 50, 100, 500+) across different task domains, measuring accuracy, response time, and token usage.

### Open Question 2
- Question: What is the theoretical maximum API cost reduction achievable through the memory retrieval mechanism, and how does this scale with different task complexities and memory sizes?
- Basis in paper: [explicit] The paper claims 79.81% input token savings and 83.06% output token savings, but doesn't establish theoretical limits or explore edge cases.
- Why unresolved: The paper only tests the mechanism on a limited dataset (50 SWE-bench-lite samples) and doesn't explore scenarios where memory retrieval might become less effective.
- What evidence would resolve it: A comprehensive analysis across multiple task types and memory sizes, including tasks with highly variable vs. highly repetitive patterns, to establish theoretical upper bounds on cost reduction.

### Open Question 3
- Question: How does the file-editing command enhancement (adding start_line_str and end_line_str) perform with increasingly complex file structures and edge cases?
- Basis in paper: [explicit] The paper shows improvement from 72.9% to 96.8% accuracy, but only tests on SWE-bench-lite and doesn't explore edge cases like nested structures, binary files, or highly fragmented edits.
- Why unresolved: The evaluation focuses on functional correctness but doesn't examine robustness across diverse file types and complex editing scenarios.
- What evidence would resolve it: Testing on diverse file types (binary, nested JSON, XML with namespaces, fragmented edits) and measuring accuracy, edit latency, and error recovery rates across edge cases.

## Limitations

- The memory retrieval mechanism's effectiveness depends heavily on the quality of memory segmentation and retrieval algorithms, which are not fully detailed in the paper.
- The hierarchical structure's performance gain is demonstrated but the communication overhead between brain-level and hand-level agents is not quantified.
- The enhanced file-editing commands show improved accuracy, but the complexity introduced by automatic adjustment mechanisms could impact real-world usability.

## Confidence

- **High confidence:** The hierarchical agent collaboration structure and its basic implementation are well-defined. The memory retrieval mechanism's concept and API cost reduction goal are clearly stated.
- **Medium confidence:** The 30% SWE-bench-lite accuracy and 37% AIME-2024 accuracy claims are supported by experimental results but may not generalize to other datasets or problem types.
- **Low confidence:** The specific implementation details of the memory retrieval mechanism and the exact prompts used for hierarchical agent collaboration are not fully disclosed, making independent verification difficult.

## Next Checks

1. **Memory Retrieval Mechanism Validation:** Implement and test the memory retrieval mechanism on a diverse set of tasks to verify the claimed 80% token cost reduction and assess its impact on task accuracy.
2. **Hierarchical Structure Overhead Analysis:** Measure the communication overhead between brain-level and hand-level agents in the hierarchical structure and quantify its impact on overall task execution time and efficiency.
3. **Enhanced File-Editing Commands Stress Test:** Test the enhanced file-editing commands on a large codebase with complex editing requirements to verify their accuracy improvements and assess the effectiveness of the automatic adjustment mechanism under real-world conditions.