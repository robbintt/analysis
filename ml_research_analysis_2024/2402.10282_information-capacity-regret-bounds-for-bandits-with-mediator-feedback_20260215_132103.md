---
ver: rpa2
title: Information Capacity Regret Bounds for Bandits with Mediator Feedback
arxiv_id: '2402.10282'
source_url: https://arxiv.org/abs/2402.10282
tags: []
core_contribution: This paper addresses the mediator feedback problem in multi-armed
  bandits, where policies are associated with probability distributions over outcomes.
  The key contribution is introducing the chi-squared capacity as a measure of the
  effective size or complexity of the policy set, which can be interpreted as the
  information capacity of a hypothetical communication channel induced by the policy
  set.
---

# Information Capacity Regret Bounds for Bandits with Mediator Feedback

## Quick Facts
- arXiv ID: 2402.10282
- Source URL: https://arxiv.org/abs/2402.10282
- Reference count: 12
- Introduces chi-squared capacity as a measure of policy set complexity

## Executive Summary
This paper introduces the chi-squared capacity as a new measure of complexity for policy sets in multi-armed bandit problems with mediator feedback. The authors develop regret bounds for the EXP4 algorithm that scale with this capacity measure rather than the number of policies, providing tighter bounds than previous approaches. The work establishes both upper and lower bounds showing that capacity is the fundamental quantity controlling regret in this setting.

## Method Summary
The paper presents the EXP4 algorithm with adaptive learning rates for the adversarial setting and proves regret bounds scaling with policy set capacity. For the stochastic setting, they analyze EXP4 with a specific learning rate schedule to achieve improved bounds. The capacity C(Θ) is defined using chi-squared mutual information between the policy-induced distributions and the uniform distribution over policies.

## Key Results
- EXP4 achieves regret O(√(C(Θ)T log N)) in adversarial setting
- EXP4 achieves regret O(C(Θ) log T log(NT)/∆) in stochastic setting
- Lower bounds show these regret bounds are near-optimal for certain policy families
- Proves separation between mediator feedback and linear bandit models

## Why This Works (Mechanism)
The chi-squared capacity captures the effective size of the policy set by measuring how distinguishable the distributions induced by different policies are. This provides a more refined measure of complexity than simply counting policies, allowing for better regret bounds when policies are similar or redundant.

## Foundational Learning
- **Chi-squared mutual information**: Measures distinguishability between distributions - needed to define policy set capacity
- **EXP4 algorithm**: Extends exponential weights to bandit feedback with expert advice - core algorithmic approach
- **Mediator feedback**: Bandit setting where actions select probability distributions over outcomes - problem setting
- **Regret bounds**: Measures performance relative to best fixed policy - primary performance metric
- **Policy set capacity**: Novel complexity measure based on chi-squared information - key theoretical contribution

## Architecture Onboarding

### Component Map
EXP4 algorithm -> Chi-squared capacity computation -> Regret analysis -> Lower bound constructions

### Critical Path
1. Compute policy set capacity C(Θ)
2. Run EXP4 with learning rate ηt = min(1, √(log N/(eC(Θ)t)))
3. Analyze regret bound RT ≤ 2 max(√eC(Θ)T log N, log N)

### Design Tradeoffs
- Capacity vs. cardinality: Using capacity provides tighter bounds when policies are redundant
- Adaptive vs. fixed learning rates: Adaptive rates provide optimal worst-case performance
- Mediator vs. linear feedback: Mediator feedback allows better exploitation of policy structure

### Failure Signatures
- Incorrect capacity calculation leading to sub-optimal regret bounds
- Poor performance on policy sets with high redundancy (low capacity but large cardinality)
- Failure to exploit policy similarity structure in linear bandit setting

### First 3 Experiments
1. Verify capacity calculation on a small policy set with known structure
2. Compare EXP4 regret with cardinality-based bounds on synthetic data
3. Test separation between mediator and linear feedback on conditional single-bit policies

## Open Questions the Paper Calls Out
None

## Limitations
- Capacity computation may be challenging for arbitrary policy sets
- Lower bounds rely on specific policy set families that may not be representative
- Separation result assumes non-interactive linear bandit feedback

## Confidence

### High confidence: Theorem 1 (adversarial regret bound), Theorem 2 (stochastic regret bound), and Theorem 5 (separation result)
### Medium confidence: Theorem 3 and 4 (lower bounds), Capacity definition and computation

## Next Checks
1. Implement capacity calculation C(Θ) for a small policy set and verify against the explicit formula Qτ(Θ) = Σθ τ(θ)χ2(θ||Σθ′τ(θ′)θ′)
2. Run EXP4 with adaptive learning rate on a synthetic problem with known capacity and verify the regret bound RT ≤ 2 max(√eC(Θ)T log N, log N) empirically
3. Test the separation result by attempting to construct a linear bandit algorithm that matches the mediator feedback regret bound for the conditional single-bit policy set