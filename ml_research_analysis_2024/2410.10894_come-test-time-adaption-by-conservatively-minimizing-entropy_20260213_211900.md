---
ver: rpa2
title: 'COME: Test-time adaption by Conservatively Minimizing Entropy'
arxiv_id: '2410.10894'
source_url: https://arxiv.org/abs/2410.10894
tags:
- uncertainty
- come
- learning
- which
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a test-time adaptation method called COME that
  addresses the overconfidence issue of entropy minimization (EM) in test-time adaptation.
  COME models uncertainty using subjective logic and introduces a data-adaptive lower
  bound on entropy to regularize model predictions.
---

# COME: Test-time adaption by Conservatively Minimizing Entropy

## Quick Facts
- arXiv ID: 2410.10894
- Source URL: https://arxiv.org/abs/2410.10894
- Authors: Qingyang Zhang; Yatao Bian; Xinke Kong; Peilin Zhao; Changqing Zhang
- Reference count: 40
- Primary result: Improves test-time adaptation accuracy by up to 34.5% and reduces false positive rate by up to 15.1%

## Executive Summary
COME introduces a test-time adaptation method that addresses the overconfidence problem of entropy minimization by using subjective logic to model uncertainty. The method constrains model predictions to maintain a data-adaptive lower bound on entropy, preventing overconfidence while preserving adaptation capability. COME is model-agnostic and doesn't require architectural changes, making it a simple drop-in replacement for existing entropy minimization approaches in test-time adaptation.

## Method Summary
COME works by treating pretrained softmax outputs as implicitly predicting a Dirichlet distribution over class probabilities. During test-time adaptation, it minimizes the entropy of the resulting subjective opinion while constraining the uncertainty mass to remain close to the pretrained model's level. This constraint is implemented by detaching the norm of the logits during optimization, preventing the model from becoming overconfident on unreliable samples. The method can be applied to any existing entropy minimization-based TTA method without architectural modifications.

## Key Results
- Achieves up to 34.5% accuracy improvement over baseline entropy minimization methods
- Reduces false positive rate by up to 15.1% in uncertainty quantification
- Maintains stability across standard, open-world, and lifelong test-time adaptation settings
- Outperforms existing methods on ImageNet-C and other corruption benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: COME stabilizes TTA by introducing a data-adaptive upper bound on model confidence, preventing overconfidence and model collapse.
- Mechanism: COME uses subjective logic to model uncertainty via a Dirichlet prior over model predictions. By constraining the uncertainty mass to not diverge far from the pretrained model, it limits the maximum class probability (confidence) for each test sample.
- Core assumption: The model's uncertainty at test time correlates with its trustworthiness; samples with high uncertainty should not be assigned high confidence.
- Evidence anchors:
  - [abstract]: "Theoretically, we provide a preliminary analysis to reveal the ability of COME in enhancing the optimization stability by introducing a data-adaptive lower bound on the entropy."
  - [section]: Theorem 1 shows that max_k p(y=k|x) ≤ 1 / (1 + (K-1) exp(-K/u0-δ)), proving an upper bound on confidence.
  - [corpus]: Weak. No direct evidence in corpus papers for Dirichlet-based upper bounds in TTA.
- Break condition: If the uncertainty estimation fails (e.g., u0 is inaccurate), the upper bound may not reflect true trustworthiness, leading to either underconfidence or overconfidence.

### Mechanism 2
- Claim: COME improves uncertainty quantification by using subjective logic instead of softmax probabilities, leading to more reliable detection of unreliable samples.
- Mechanism: Subjective logic explicitly models both belief masses for each class and an overall uncertainty mass. This dual modeling allows the system to express "I do not know" via high uncertainty rather than forcing a confident but potentially wrong prediction.
- Core assumption: Softmax probabilities are prone to overconfidence, especially on out-of-distribution or corrupted data, while subjective logic can better capture uncertainty.
- Evidence anchors:
  - [abstract]: "Compared to entropy minimization on softmax probability which ultimately assigns all the probability to one certain class, the above learning principle offers the model with an additional option, i.e., express high overall uncertainty and reject to classify when the observed total evidence is insufficient."
  - [section]: "It has been widely recognized that using the softmax output as the confidence often leads to overconfidence phenomenon."
  - [corpus]: Weak. No corpus papers specifically test Dirichlet/SL uncertainty against softmax in TTA.
- Break condition: If the subjective logic implementation does not accurately reflect the evidence from the model (e.g., wrong exponential scaling), uncertainty estimates become unreliable.

### Mechanism 3
- Claim: COME achieves stability without modifying model architecture or training strategy, making it a simple drop-in replacement for entropy minimization.
- Mechanism: By treating the pretrained softmax model as implicitly predicting a Dirichlet distribution, COME can directly compute uncertainty from the existing logits. The constraint on the norm of logits ensures uncertainty doesn't diverge.
- Core assumption: Pretrained models with softmax outputs already encode sufficient evidence structure to be interpreted as Dirichlet parameters.
- Evidence anchors:
  - [abstract]: "Our COME leverages subjective logic... without altering the original model architecture or training strategy."
  - [section]: "Given an opinion, the final predicted probability is calculated by taking the expectation of the corresponding Dirichlet distribution... standard DNNs for classification with a softmax output function can be viewed as predicting the expected categorical distribution under a Dirichlet prior."
  - [corpus]: Weak. No corpus papers validate this architectural compatibility assumption.
- Break condition: If the pretrained model's output distribution deviates significantly from the assumed Dirichlet form, the uncertainty modeling breaks down.

## Foundational Learning

- Concept: Dirichlet distribution and subjective logic
  - Why needed here: COME relies on modeling predictions as a Dirichlet distribution to capture both class probabilities and uncertainty in a principled way.
  - Quick check question: What is the relationship between the parameters α of a Dirichlet distribution and the evidence e in subjective logic?

- Concept: Entropy minimization and its limitations
  - Why needed here: Understanding why standard EM leads to overconfidence is key to appreciating COME's motivation.
  - Quick check question: Why does minimizing entropy on softmax probabilities tend to cause overconfidence on unreliable samples?

- Concept: Bayesian uncertainty estimation (e.g., MC dropout, ensembles)
  - Why needed here: COME offers a simpler alternative to these methods; understanding their trade-offs clarifies COME's advantages.
  - Quick check question: How does COME's uncertainty estimation differ computationally from MC dropout?

## Architecture Onboarding

- Component map:
  - Input: Test images
  - Backbone: Frozen pretrained ViT/ResNet
  - Logits: Model output (f(x))
  - Evidence: exp(f(x)) - 1
  - Dirichlet parameters: α = evidence + 1
  - Belief masses: b_k = e_k / S
  - Uncertainty mass: u = K / S
  - Loss: Negative entropy of [b_1, ..., b_K, u]
  - Constraint: ||f(x)||_2 norm kept constant via detach()

- Critical path:
  1. Forward pass to get logits
  2. Convert logits to evidence (exp - 1)
  3. Compute Dirichlet parameters, belief masses, uncertainty
  4. Calculate entropy of subjective opinion
  5. Apply constraint (detach norm)
  6. Backward pass and parameter update

- Design tradeoffs:
  - Simplicity vs. potential loss of precision: COME is model-agnostic and easy to implement but may not capture all uncertainty nuances compared to Bayesian methods.
  - Computational overhead: Minimal (one extra forward pass step), but may still matter in real-time systems.
  - Hyperparameter sensitivity: The detach norm magnitude (τ) and uncertainty threshold (δ) can affect performance.

- Failure signatures:
  - High variance in accuracy across corruption types: Suggests uncertainty estimation is not consistent.
  - Sudden drops in performance during lifelong TTA: May indicate constraint is too weak or evidence scaling is off.
  - Accuracy improves but FPR worsens: Implies model is becoming overconfident again.

- First 3 experiments:
  1. Replace entropy loss with COME on Tent baseline on ImageNet-C (Gaussian noise, severity 3) and compare accuracy and FPR.
  2. Test COME with different norm constraints (L1 vs L2) to see effect on stability.
  3. Evaluate COME's uncertainty estimates by plotting confidence histograms for correct vs incorrect predictions on a corrupted validation set.

## Open Questions the Paper Calls Out

### Open Question 1  
- Question: How does COME perform when applied to different model architectures beyond ViT and ResNet, such as models with layer normalization or group normalization?  
- Basis in paper: [inferred] The paper mentions that TTA performance can vary significantly depending on the model architecture, especially the type of normalization layers used. However, experiments were only conducted on ViT and ResNet-50-BN.  
- Why unresolved: The paper does not provide results for other architectures like those with layer normalization or group normalization, which could behave differently under COME.  
- What evidence would resolve it: Experiments comparing COME's performance across a wider range of model architectures, including those with layer normalization or group normalization, would clarify its generalizability.

### Open Question 2  
- Question: What is the theoretical relationship between overconfidence in entropy minimization and model collapse, and how does COME's uncertainty modeling address this?  
- Basis in paper: [explicit] The paper discusses the overconfidence issue in EM and suggests that COME's uncertainty modeling provides a principled solution, but it does not provide a detailed theoretical analysis of the relationship between overconfidence and model collapse.  
- Why unresolved: While the paper introduces COME as a solution, it does not fully explain the theoretical underpinnings of why overconfidence leads to model collapse and how COME's approach prevents this.  
- What evidence would resolve it: A rigorous theoretical analysis connecting overconfidence, model collapse, and COME's uncertainty modeling would provide deeper insights into its effectiveness.

### Open Question 3  
- Question: How does COME's performance compare to other uncertainty quantification methods like MC-dropout or deep ensembles in terms of computational efficiency and accuracy?  
- Basis in paper: [explicit] The paper mentions that COME is model-agnostic and computationally efficient, unlike methods like MC-dropout or deep ensembles, but does not provide a direct comparison of their performance.  
- Why unresolved: The paper does not benchmark COME against other uncertainty quantification methods, leaving questions about its relative performance in terms of accuracy and computational efficiency.  
- What evidence would resolve it: Comparative experiments measuring COME's accuracy and computational efficiency against MC-dropout or deep ensembles would clarify its strengths and weaknesses.

## Limitations

- The theoretical analysis relies on assumptions about the relationship between uncertainty mass and model trustworthiness that lack empirical validation.
- The evaluation focuses primarily on ViT models, limiting generalizability to other architectures.
- The claim that COME's uncertainty estimates are more reliable than softmax-based approaches lacks direct comparison with established uncertainty quantification methods.

## Confidence

- **High Confidence:** The core mechanism of using subjective logic to introduce uncertainty quantification (Mechanism 1) is well-supported by the theoretical analysis and ablation studies showing performance degradation when this component is removed.
- **Medium Confidence:** The claim that COME improves over standard entropy minimization across diverse corruption types (Mechanisms 2-3) is supported by extensive experiments, though the exact magnitude of improvement may vary with implementation details.
- **Low Confidence:** The assertion that COME's uncertainty estimates are more reliable than softmax-based approaches lacks direct comparison with established uncertainty quantification methods like MC dropout or ensembles.

## Next Checks

1. Test COME on ResNet architectures beyond ViT to verify architectural compatibility claims.
2. Compare COME's uncertainty quantification against MC dropout using proper scoring rules (e.g., expected calibration error) on corrupted data.
3. Evaluate COME's performance when the pretrained model has been trained with different objectives (e.g., contrastive learning) to test the Dirichlet assumption.