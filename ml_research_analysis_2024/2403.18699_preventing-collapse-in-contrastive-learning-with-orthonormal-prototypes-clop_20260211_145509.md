---
ver: rpa2
title: Preventing Collapse in Contrastive Learning with Orthonormal Prototypes (CLOP)
arxiv_id: '2403.18699'
source_url: https://arxiv.org/abs/2403.18699
tags:
- learning
- contrastive
- collapse
- class
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses neural collapse in contrastive learning, where
  embeddings converge into lower-dimensional spaces, reducing their spatial utility
  and making classes indistinguishable. The authors theoretically analyze the effect
  of large learning rates on contrastive losses relying solely on cosine similarity,
  deriving an upper bound of sqrt(2) + O(1/k) to avoid collapse for k classes.
---

# Preventing Collapse in Contrastive Learning with Orthonormal Prototypes (CLOP)

## Quick Facts
- arXiv ID: 2403.18699
- Source URL: https://arxiv.org/abs/2403.18699
- Authors: Huanran Li; Manh Nguyen; Daniel Pimentel-AlarcÃ³n
- Reference count: 34
- Primary result: Introduces CLOP to prevent neural collapse in contrastive learning by promoting orthogonal subspaces among class embeddings

## Executive Summary
This paper addresses neural collapse in contrastive learning, where embeddings converge into lower-dimensional spaces, reducing their spatial utility and making classes indistinguishable. The authors theoretically analyze the effect of large learning rates on contrastive losses relying solely on cosine similarity, deriving an upper bound of sqrt(2) + O(1/k) to avoid collapse for k classes. They propose CLOP (Contrastive Learning with Orthonormal Prototypes), a novel semi-supervised loss function that prevents neural collapse by promoting orthogonal linear subspaces among class embeddings. Unlike prior approaches that enforce simplex ETF structure, CLOP focuses on subspace separation, leading to more distinguishable embeddings.

## Method Summary
CLOP introduces a semi-supervised loss function that promotes orthogonal linear subspaces among class embeddings. The method operates by enforcing orthonormal prototype vectors for each class, which guide the embeddings to maintain separation in the feature space. This approach differs from traditional contrastive learning methods that rely solely on pairwise comparisons. The loss function combines standard contrastive objectives with a regularization term that encourages embeddings to align with their class-specific orthonormal prototypes while maintaining orthogonality between different classes. This mechanism prevents the convergence of embeddings into collapsed subspaces while preserving discriminative power.

## Key Results
- CLOP achieves significantly greater stability across different learning rates and batch sizes compared to standard contrastive learning approaches
- Performance comparable to large batch sizes (2048) can be achieved with small batch sizes (32) when using CLOP
- Extensive experiments on CIFAR-100 and Tiny-ImageNet demonstrate CLOP's effectiveness in preventing neural collapse

## Why This Works (Mechanism)
The key insight is that neural collapse occurs when embeddings converge to a low-dimensional subspace due to the optimization dynamics of contrastive loss functions. By introducing orthonormal prototypes for each class, CLOP creates a structural constraint that prevents this collapse. The orthonormal prototypes act as anchors that guide embeddings to maintain separation while still allowing the contrastive learning process to function effectively. This approach addresses the fundamental limitation of cosine-based similarity measures when learning rates become large.

## Foundational Learning

### Cosine Similarity and Angular Collapse
- **Why needed**: Understanding how cosine similarity can lead to angular collapse when embeddings become too aligned
- **Quick check**: Verify that as embeddings become more similar, their cosine similarity approaches 1, reducing discriminative power

### Orthonormal Bases in High-Dimensional Spaces
- **Why needed**: Grasping how orthonormal vectors can span maximally separated subspaces
- **Quick check**: Confirm that orthonormal vectors have unit length and zero pairwise dot products

### Contrastive Loss Dynamics
- **Why needed**: Understanding how standard contrastive losses can drive embeddings toward collapse
- **Quick check**: Examine how the gradient of contrastive loss behaves as embeddings become aligned

### Semi-Supervised Learning Integration
- **Why needed**: Recognizing how limited labeled data can be leveraged to prevent collapse
- **Quick check**: Verify that prototype assignment requires only minimal supervision

## Architecture Onboarding

### Component Map
Input -> Encoder Network -> Embedding Space -> Orthonormal Prototype Projection -> Loss Computation (Contrastive + Orthogonality) -> Gradients -> Encoder Update

### Critical Path
1. Forward pass through encoder to obtain embeddings
2. Projection of embeddings onto orthonormal prototype subspaces
3. Computation of combined contrastive and orthogonality loss
4. Backpropagation to update encoder parameters

### Design Tradeoffs
- **Prototype dimensionality**: Higher dimensions provide more capacity but increase computational overhead
- **Orthogonality strength**: Stronger orthogonality constraints prevent collapse better but may reduce flexibility
- **Learning rate scheduling**: Requires careful tuning to balance convergence and stability

### Failure Signatures
- **Over-orthonormalization**: Embeddings become too rigid and lose discriminative power
- **Under-orthonormalization**: Insufficient prevention of collapse, leading to low-dimensional embedding spaces
- **Gradient instability**: Large learning rates causing oscillations around the orthonormal constraints

### First Experiments
1. Train CLOP on CIFAR-100 with varying learning rates (0.1 to 1.0) and compare embedding dimensionality
2. Evaluate CLOP's performance with batch sizes ranging from 32 to 2048 on Tiny-ImageNet
3. Ablation study: Remove the orthogonality constraint to measure its contribution to preventing collapse

## Open Questions the Paper Calls Out

None

## Limitations

The paper presents a theoretically grounded approach to preventing neural collapse in contrastive learning, but several uncertainties warrant attention. The theoretical analysis assumes perfect convergence and relies heavily on cosine similarity, which may not fully capture the complexity of real-world embedding spaces where additional distance metrics and regularization terms are common. The claim that CLOP's subspace separation approach is inherently superior to simplex ETF structures needs more rigorous comparison across diverse architectures beyond the tested ResNet-based models. The experimental validation, while extensive, primarily focuses on CIFAR-100 and Tiny-ImageNet datasets - the performance generalization to larger, more complex datasets like ImageNet or domain-specific applications remains uncertain.

## Confidence

**Theoretical analysis of collapse prevention**: High - The mathematical derivation of the upper bound and the relationship between learning rates and collapse is well-established

**CLOP's effectiveness in preventing collapse**: Medium - While experimental results are strong, the mechanism's robustness across diverse architectures needs further validation

**Performance stability across batch sizes**: Medium - Results show promise, but real-world scenarios with varying data distributions may yield different outcomes

## Next Checks

1. Test CLOP's performance on larger-scale datasets (e.g., ImageNet) and compare against state-of-the-art collapse prevention methods under identical training conditions

2. Evaluate the computational efficiency and memory overhead of CLOP across different batch sizes and class numbers to assess practical scalability

3. Conduct ablation studies isolating the contribution of the orthonormal prototype mechanism versus other components of the loss function to verify the claimed advantages