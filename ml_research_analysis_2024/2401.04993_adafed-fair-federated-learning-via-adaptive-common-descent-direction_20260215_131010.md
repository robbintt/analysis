---
ver: rpa2
title: 'AdaFed: Fair Federated Learning via Adaptive Common Descent Direction'
arxiv_id: '2401.04993'
source_url: https://arxiv.org/abs/2401.04993
tags:
- adafed
- learning
- clients
- local
- different
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses fairness in federated learning by proposing
  AdaFed, an algorithm that adaptively tunes a common descent direction to ensure
  both descent for all clients and higher decrease rates for those with larger losses.
  AdaFed orthogonalizes and scales local gradients to find a closed-form solution
  for the optimal direction, satisfying two conditions: (I) being a descent direction
  for all clients, and (II) having larger directional derivatives for clients with
  larger losses.'
---

# AdaFed: Fair Federated Learning via Adaptive Common Descent Direction

## Quick Facts
- arXiv ID: 2401.04993
- Source URL: https://arxiv.org/abs/2401.04993
- Reference count: 40
- Primary result: An adaptive common descent direction algorithm that ensures fairness across federated learning clients while maintaining or improving accuracy

## Executive Summary
AdaFed addresses fairness in federated learning by proposing an algorithm that adaptively tunes a common descent direction to ensure both descent for all clients and higher decrease rates for those with larger losses. The method orthogonalizes and scales local gradients to find a closed-form solution for the optimal direction, satisfying two conditions: (I) being a descent direction for all clients, and (II) having larger directional derivatives for clients with larger losses. The approach is evaluated on seven datasets, showing superior fairness compared to state-of-the-art methods while maintaining similar or improved accuracy.

## Method Summary
AdaFed tackles the fairness problem in federated learning by treating it as a multi-objective optimization problem where the goal is to minimize all clients' loss functions simultaneously. The algorithm works by having clients perform local training and send pseudo-gradients to the server. The server then orthogonalizes and scales these local gradients based on their norms and the corresponding loss function values, computes the minimum-norm vector in the convex hull of the scaled gradients, and uses this as the common descent direction to update the global model. This process ensures that all clients' loss functions decrease while clients with larger losses experience faster decreases, achieving better fairness across the network.

## Key Results
- Outperforms state-of-the-art methods (FedAvg, q-FFL, FedMGDA+) in fairness metrics while maintaining similar or improved accuracy
- Proven convergence to Pareto-stationary solutions under different federated learning setups
- Computational cost is negligible compared to alternatives like FedMGDA+
- Shows consistent performance across seven diverse datasets including CIFAR-10, CIFAR-100, FEMNIST, and Shakespeare

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AdaFed finds a common descent direction that is descent for all clients and favors clients with larger losses.
- Mechanism: AdaFed orthogonalizes and scales local gradients, then finds the minimum-norm vector in the convex hull of these scaled gradients. This process ensures both conditions are satisfied.
- Core assumption: The K gradient vectors are linearly independent, which is reasonable given the high dimensionality of modern deep networks and the non-iid nature of client data.
- Evidence anchors:
  - [abstract]: "AdaFed adaptively tunes this common direction based on the values of local gradients and loss functions."
  - [section]: "To satisfy Condition (I), it is enough to find d(G) using MGDA algorithm... Yet, we aim to further satisfy Condition (II) on top of Condition (I)."
  - [corpus]: Weak evidence - no direct mention of orthogonalization or scaling in the corpus.
- Break condition: If the gradient vectors are not linearly independent, the orthogonalization process may fail, and the method may not find a suitable common descent direction.

### Mechanism 2
- Claim: The scaling factor for the gradients is inversely proportional to the square of the gradient norm and the loss function value raised to a power γ.
- Mechanism: The scaling factor is determined by the formula λ* = 1 / (||gk||^2 * sum(1 / ||gi||^2)), where γ > 0 is a hyperparameter.
- Core assumption: The loss functions are Lipschitz continuous and smooth, which allows for the derivation of the scaling factor.
- Evidence anchors:
  - [abstract]: "The goal of AdaFed is to find an updating direction for the server along which (i) all the clients' loss functions are decreasing; and (ii) more importantly, the loss functions for the clients with larger values decrease with a higher rate."
  - [section]: "Based on these observations, the gradient vectors should be somehow scaled if one aims to also satisfy Condition (II)."
  - [corpus]: Weak evidence - no direct mention of the specific scaling formula in the corpus.
- Break condition: If the loss functions are not Lipschitz continuous or smooth, the scaling factor may not be valid, and the method may not find a suitable common descent direction.

### Mechanism 3
- Claim: The convergence of AdaFed is guaranteed under certain conditions, including the step-size and the number of local epochs.
- Mechanism: The convergence is analyzed using different scenarios, such as local SGD with e=1, local GD with e>1, and local GD with e=1.
- Core assumption: The loss functions are convex or σ-convex, which allows for the derivation of convergence guarantees.
- Evidence anchors:
  - [abstract]: "Convergence to a Pareto-stationary solution is proven under different FL setups."
  - [section]: "In the following, we prove the convergence guarantee of AdaFed based on how the clients update the local models."
  - [corpus]: Weak evidence - no direct mention of the specific convergence guarantees in the corpus.
- Break condition: If the loss functions are not convex or σ-convex, the convergence guarantees may not hold, and the method may not converge to a Pareto-stationary solution.

## Foundational Learning

- Concept: Multi-objective optimization (MOO) and Pareto-stationary solutions.
  - Why needed here: AdaFed treats the FL task as a MOO problem, where the goal is to minimize the loss functions of all clients simultaneously.
  - Quick check question: What is a Pareto-stationary solution, and how is it different from a Pareto-optimal solution?

- Concept: Directional derivatives and descent directions.
  - Why needed here: AdaFed uses directional derivatives to ensure that the common descent direction is indeed a descent direction for all clients.
  - Quick check question: What is a directional derivative, and how is it used to determine if a direction is a descent direction?

- Concept: Orthogonalization and convex hulls.
  - Why needed here: AdaFed uses orthogonalization to find the minimum-norm vector in the convex hull of the scaled gradients.
  - Quick check question: What is the purpose of orthogonalization in this context, and how does it help find the minimum-norm vector?

## Architecture Onboarding

- Component map: Clients -> Server (AdaFed algorithm) -> Global model
- Critical path:
  1. Clients perform local training and send pseudo-gradients to the server.
  2. Server orthogonalizes and scales the local gradients.
  3. Server finds the minimum-norm vector in the convex hull of the scaled gradients.
  4. Server computes the common descent direction and updates the global model.

- Design tradeoffs:
  - The choice of the hyperparameter γ affects the fairness and accuracy tradeoff.
  - The number of local epochs affects the convergence speed and the robustness to label noise.
  - The choice of the loss functions (convex or σ-convex) affects the convergence guarantees.

- Failure signatures:
  - If the gradient vectors are not linearly independent, the orthogonalization process may fail.
  - If the loss functions are not Lipschitz continuous or smooth, the scaling factor may not be valid.
  - If the loss functions are not convex or σ-convex, the convergence guarantees may not hold.

- First 3 experiments:
  1. Test the orthogonalization process on synthetic data with known gradients.
  2. Evaluate the scaling factor on a simple MOO problem with two objectives.
  3. Test the convergence of AdaFed on a convex optimization problem with multiple objectives.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does AdaFed's performance scale with the number of clients (K) and gradient dimensions (d)?
- Basis in paper: [explicit] The paper discusses the computational cost and notes that AdaFed's overhead is negligible compared to FedMGDA+, but doesn't provide a detailed scalability analysis.
- Why unresolved: While the paper mentions that the orthogonalization process requires O(2dK²) operations, it doesn't explore how this scales with very large K or d values typical in real-world FL scenarios.
- What evidence would resolve it: Experiments showing AdaFed's performance and computational cost with varying K (e.g., 10, 100, 1000) and d (e.g., small models vs. large language models) would provide insights into its scalability.

### Open Question 2
- Question: What is the theoretical impact of the hyperparameter γ on the convergence rate of AdaFed?
- Basis in paper: [inferred] The paper shows that different γ values yield different levels of fairness and mentions that a moderate γ enforces larger directional derivatives for worse-performing devices. However, it doesn't provide a theoretical analysis of how γ affects convergence speed.
- Why unresolved: While the experimental results show the effect of γ on fairness, there's no theoretical framework explaining how γ influences the rate at which AdaFed converges to a Pareto-stationary solution.
- What evidence would resolve it: A theoretical analysis deriving the relationship between γ and convergence rate, potentially including convergence bounds that explicitly depend on γ, would clarify this relationship.

### Open Question 3
- Question: How does AdaFed perform when integrated with other personalization techniques beyond the ones mentioned in the paper?
- Basis in paper: [explicit] The paper states that AdaFed is orthogonal to popular FL methods like Fedprox and q-FFL, and could be combined with existing algorithms, especially those using personalization. However, it only demonstrates integration with FedCorr for label noise correction.
- Why unresolved: The paper provides limited exploration of AdaFed's integration with personalization techniques, focusing mainly on its standalone performance and one specific integration (with FedCorr).
- What evidence would resolve it: Experiments demonstrating AdaFed's performance when combined with various personalization techniques (e.g., Ditto, FedPer, LG-FedAvg) on diverse datasets would show its versatility in personalization scenarios.

## Limitations
- The orthogonalization mechanism assumes linear independence of gradient vectors, which may not hold in all federated settings
- Convergence guarantees are proven only under convex or σ-convex assumptions, not typical of deep learning tasks
- The scaling formula depends on strong assumptions about loss function properties (Lipschitz continuity, smoothness)

## Confidence
- Mechanism 1 (Descent direction): Medium - theoretical justification exists but empirical validation of gradient independence is missing
- Mechanism 2 (Scaling formula): Medium - derivation appears sound but depends on strong assumptions about loss functions
- Mechanism 3 (Convergence): Medium - convergence is proven but only under restrictive assumptions not typical of deep learning

## Next Checks
1. Test the orthogonalization process on synthetic data with known gradients across varying dimensions and client distributions to verify that K gradient vectors remain linearly independent in realistic federated settings.

2. Systematically evaluate the Lipschitz continuity and smoothness of common FL loss functions (cross-entropy, etc.) on real datasets to validate the scaling formula assumptions.

3. Design experiments to empirically assess AdaFed's performance on non-convex objectives, comparing convergence behavior and fairness metrics against theoretical predictions under convex assumptions.