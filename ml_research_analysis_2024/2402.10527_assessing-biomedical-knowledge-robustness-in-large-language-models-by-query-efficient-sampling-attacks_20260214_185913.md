---
ver: rpa2
title: Assessing biomedical knowledge robustness in large language models by query-efficient
  sampling attacks
arxiv_id: '2402.10527'
source_url: https://arxiv.org/abs/2402.10527
tags:
- adversarial
- language
- which
- entity
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the vulnerability of large language models
  (LLMs) to adversarial attacks in high-stakes, knowledge-intensive domains like biomedical
  question answering. The authors propose a novel method called powerscaled distance-weighted
  sampling (DWS) in embedding space to efficiently generate adversarial entities as
  distractors.
---

# Assessing biomedical knowledge robustness in large language models by query-efficient sampling attacks

## Quick Facts
- arXiv ID: 2402.10527
- Source URL: https://arxiv.org/abs/2402.10527
- Reference count: 40
- Primary result: Powerscaled distance-weighted sampling (DWS) efficiently generates adversarial entities that reveal brittleness in biomedical knowledge of LLMs

## Executive Summary
This paper addresses the vulnerability of large language models (LLMs) to adversarial attacks in high-stakes, knowledge-intensive domains like biomedical question answering. The authors propose a novel method called powerscaled distance-weighted sampling (DWS) in embedding space to efficiently generate adversarial entities as distractors. They demonstrate that this approach outperforms random sampling and is more query-efficient than gradient-guided search. The method reveals two distinct regimes of adversarial entities: those semantically close to or far from the correct answer, with different characteristics. The attacks successfully manipulate token-wise Shapley value explanations, rendering them deceptive in the adversarial setting.

## Method Summary
The authors introduce powerscaled distance-weighted sampling (DWS) as an efficient method for generating adversarial entities in embedding space. The approach leverages distance-weighted sampling with power scaling to select entities that can effectively serve as distractors in biomedical question answering tasks. This method aims to balance query efficiency with adversarial effectiveness, providing a practical alternative to more computationally expensive gradient-guided search methods. The evaluation focuses on biomedical domain knowledge, where robustness is particularly critical.

## Key Results
- DWS method achieves superior query efficiency compared to random sampling for generating adversarial entities
- The approach outperforms gradient-guided search methods in terms of computational efficiency while maintaining adversarial effectiveness
- Two distinct regimes of adversarial entities are identified: those semantically close to correct answers and those semantically distant
- Adversarial entities successfully manipulate token-wise Shapley value explanations, making them deceptive in the adversarial setting

## Why This Works (Mechanism)
The powerscaled distance-weighted sampling method works by exploiting the semantic structure of the embedding space to identify entities that can effectively serve as adversarial distractors. By weighting distances with power scaling, the method can efficiently sample entities that are likely to be semantically relevant to the correct answer, making them more effective at confusing the model. This approach leverages the fact that embeddings capture semantic relationships, allowing for targeted sampling of entities that could plausibly be confused with the correct answer.

## Foundational Learning
- **Embedding spaces and semantic similarity**: Understanding how LLMs represent concepts in continuous vector spaces and how semantic relationships are encoded in these embeddings is crucial for comprehending the DWS method.
- **Adversarial attacks in NLP**: Familiarity with how adversarial examples are generated and their impact on model performance provides context for evaluating the significance of the DWS approach.
- **Knowledge robustness in LLMs**: Understanding the challenges of maintaining robust domain knowledge in LLMs, particularly in high-stakes domains like biomedicine, helps contextualize the research problem.

## Architecture Onboarding

**Component map**: LLM -> Embedding space -> DWS sampling -> Adversarial entity generation -> QA task evaluation

**Critical path**: The method relies on the LLM's embedding space as the foundation for generating adversarial entities, with DWS sampling as the core innovation that enables efficient entity selection.

**Design tradeoffs**: The approach trades some potential adversarial effectiveness for significant gains in query efficiency compared to gradient-guided methods, making it more practical for real-world applications.

**Failure signatures**: If the embedding space does not adequately capture semantic relationships relevant to the domain, the DWS method may fail to generate effective adversarial entities.

**Exactly 3 first experiments**:
1. Compare DWS-generated adversarial entities against human-curated distractors to assess semantic quality
2. Test the method's effectiveness across multiple biomedical question-answering datasets
3. Evaluate the persistence of adversarial effects when models are fine-tuned on adversarial examples

## Open Questions the Paper Calls Out
None

## Limitations
- The generalizability of DWS beyond biomedical domains remains unproven, as evaluation focuses specifically on biomedical knowledge
- Results are demonstrated only against GPT-3.5, with unclear robustness across different model architectures and sizes
- The semantic characterization of adversarial entities (close vs. far regimes) is based on qualitative observations requiring more rigorous validation
- Practical implications for real-world biomedical decision-making are not fully explored

## Confidence

**High confidence**:
- LLMs exhibit brittleness in domain knowledge when exposed to adversarial entities
- DWS method achieves superior query efficiency compared to random sampling

**Medium confidence**:
- Superiority of DWS over gradient-guided search methods
- Characterization of two distinct regimes of adversarial entities

## Next Checks
1. Evaluate the DWS method's performance across multiple model families (e.g., Claude, Llama, PaLM) and sizes to assess generalizability beyond GPT-3.5
2. Conduct human expert evaluation of the semantic proximity of adversarial entities to determine if the observed "close" vs "far" regimes hold under expert judgment
3. Test the persistence of adversarial effects under fine-tuning with adversarial examples to assess potential defenses and the long-term robustness of domain knowledge