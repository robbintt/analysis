---
ver: rpa2
title: 'From Movements to Metrics: Evaluating Explainable AI Methods in Skeleton-Based
  Human Activity Recognition'
arxiv_id: '2402.12790'
source_url: https://arxiv.org/abs/2402.12790
tags:
- class
- data
- metrics
- which
- grad-cam
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the lack of evaluation metrics for explainable
  AI (XAI) methods in skeleton-based human activity recognition (HAR). It tests established
  metrics faithfulness and stability on CAM and Grad-CAM, introducing a perturbation
  method that respects human biomechanical constraints.
---

# From Movements to Metrics: Evaluating Explainable AI Methods in Skeleton-Based Human Activity Recognition

## Quick Facts
- arXiv ID: 2402.12790
- Source URL: https://arxiv.org/abs/2402.12790
- Reference count: 0
- This paper addresses the lack of evaluation metrics for explainable AI (XAI) methods in skeleton-based human activity recognition (HAR)

## Executive Summary
This paper addresses a critical gap in skeleton-based human activity recognition by evaluating explainable AI methods using established metrics. The researchers tested faithfulness and stability metrics on CAM and Grad-CAM explanations for an EfficientGCN model trained on the NTU RGB+D-60 dataset. Through introducing a perturbation method that respects human biomechanical constraints, they discovered that faithfulness may not be reliable in certain contexts, while stability emerges as more dependable. Notably, CAM and Grad-CAM were found to produce nearly identical explanations, highlighting the need for more diverse XAI methods in this domain.

## Method Summary
The researchers evaluated CAM and Grad-CAM explanations for an EfficientGCN-B4 model trained on NTU RGB+D-60 skeleton data. They introduced a perturbation method using spherical coordinates with radius r (2.5cm to 80cm) that respects biomechanical constraints. Evaluation metrics included PGI (Prediction Gap on Important feature perturbation), PGU (Prediction Gap on Unimportant feature perturbation), RIS (Relative Input Stability), ROS (Relative Output Stability), and RRS (Relative Representation Stability). The method compared explanation quality against a random baseline while testing different perturbation magnitudes.

## Key Results
- Faithfulness metric showed unreliable performance with the EfficientGCN model, as the random baseline outperformed CAM/Grad-CAM in PGI
- Stability metric demonstrated robustness across all perturbation levels, showing CAM and Grad-CAM produce nearly identical results
- CAM and Grad-CAM explanations were found to be functionally equivalent in skeleton-based HAR, yielding very similar metric performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Faithfulness metric performance is unreliable for skeleton-based HAR models when input perturbations are small.
- Mechanism: Faithfulness measures how much prediction changes when top-k important features are perturbed. If the model's prediction remains stable despite perturbations to supposedly important features, the faithfulness metric will show low values, suggesting the explanation is not aligned with the model's reasoning.
- Core assumption: The EfficientGCN model's predictions should change meaningfully when important skeletal joints are perturbed.
- Evidence anchors:
  - [abstract] "Our findings indicate that faithfulness may not be a reliable metric in certain contexts, such as with the EfficientGCN model."
  - [section] "Unexpectedly, the random method appears to outperform both in PGI in the weakest class" and "PGI results consistently give unexpected outcomes."
  - [corpus] Weak evidence - only mentions XAI methods in HAR without specific faithfulness testing results.
- Break condition: If the model's predictions are inherently stable or if perturbations don't meaningfully affect the model's internal representations, faithfulness will fail to provide useful information about explanation quality.

### Mechanism 2
- Claim: Stability metric is more reliable than faithfulness for evaluating XAI methods in skeleton-based HAR.
- Mechanism: Stability measures how much explanations change when input data is slightly perturbed. If explanations remain consistent despite small perturbations, the stability metric will show low values, indicating robust explanations.
- Core assumption: Explanations from CAM and Grad-CAM should remain consistent when skeletal data undergoes minor perturbations that respect biomechanical constraints.
- Evidence anchors:
  - [abstract] "stability emerges as a more dependable metric when there is slight input data perturbations."
  - [section] "Stability assessments for CAM and Grad-CAM yield nearly identical values" and "Stability test results, contrary to faithfulness, demonstrate robustness against increased perturbation."
  - [corpus] Weak evidence - mentions XAI methods in HAR but lacks specific stability testing details.
- Break condition: If the model's explanations are inherently unstable or if perturbations cause significant changes in the model's internal representations, stability will fail to provide useful information about explanation quality.

### Mechanism 3
- Claim: CAM and Grad-CAM produce nearly identical explanations for skeleton-based HAR, making them functionally equivalent in this domain.
- Mechanism: Both CAM and Grad-CAM generate feature attribution maps by highlighting important body points for specific actions. If both methods converge on similar attributions after normalization, they will produce equivalent explanation quality metrics.
- Core assumption: The EfficientGCN model's internal representations should lead both CAM and Grad-CAM to identify the same important skeletal joints for activity recognition.
- Evidence anchors:
  - [abstract] "CAM and Grad-CAM are also found to produce almost identical explanations, leading to very similar XAI metric performance."
  - [section] "Stability assessments for CAM and Grad-CAM yield nearly identical values, diverging only in less significant decimal places."
  - [corpus] Weak evidence - mentions comparison of SHAP and GradCAM but not CAM vs Grad-CAM specifically.
- Break condition: If the model's architecture or the specific implementation details cause CAM and Grad-CAM to diverge significantly in their attributions, they will no longer be functionally equivalent.

## Foundational Learning

- Concept: Biomechanical constraints in human movement
  - Why needed here: The perturbation method must respect how human bodies actually move to ensure realistic variations in skeletal data
  - Quick check question: Why can't we simply add random noise to joint positions when testing XAI methods for HAR?

- Concept: Graph Convolutional Networks (GCNs) for skeleton data
  - Why needed here: Understanding how ST-GCNs process skeletal graphs is crucial for interpreting why certain XAI methods work better than others
  - Quick check question: How does the spatial-temporal graph structure in ST-GCNs differ from standard CNNs when processing skeleton data?

- Concept: Evaluation metrics for XAI methods
  - Why needed here: Faithfulness and stability measure different aspects of explanation quality, and understanding their differences is key to interpreting the results
  - Quick check question: What's the fundamental difference between measuring explanation quality through prediction changes versus explanation consistency?

## Architecture Onboarding

- Component map: Dataset → Data Preprocessing (perturbation) → EfficientGCN model → CAM/Grad-CAM explanations → XAI metrics calculation
- Critical path: Skeleton data perturbation → model prediction → explanation generation → metric computation
- Design tradeoffs: CAM uses static post-training weights (lower computational cost) vs Grad-CAM requires gradient computation per instance (higher computational cost)
- Failure signatures: Faithfulness metric failure indicates model prediction stability; identical CAM/Grad-CAM results suggest limited XAI method diversity
- First 3 experiments:
  1. Test faithfulness and stability metrics on a simple ST-GCN model with synthetic skeleton data
  2. Compare CAM vs Grad-CAM explanations on a small subset of NTU RGB+D-60 with varying perturbation magnitudes
  3. Implement the biomechanically-constrained perturbation method and verify joint position changes stay within Kinect v2 accuracy tolerance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do other XAI methods like LIME or SHAP perform on skeleton-based HAR compared to CAM and Grad-CAM?
- Basis in paper: [explicit] The paper mentions that adaptations of model-agnostic methods like LIME and SHAP for this specific domain could be valuable for future research.
- Why unresolved: The paper only tested CAM and Grad-CAM, and found their performance to be nearly identical. Comparative studies with other XAI methods are scarce.
- What evidence would resolve it: A study implementing and testing multiple XAI methods (including LIME and SHAP) on skeleton-based HAR datasets, comparing their performance using established metrics.

### Open Question 2
- Question: Are there XAI evaluation metrics that are more reliable than faithfulness for skeleton-based HAR models like EfficientGCN?
- Basis in paper: [explicit] The paper found that faithfulness may not be a reliable metric in certain contexts, such as with the EfficientGCN model. Stability emerged as a more dependable metric, but this leaves only a single metric which offers a limited view.
- Why unresolved: The paper tested established metrics (faithfulness and stability) but found limitations with faithfulness. More diverse metrics and new testing approaches are needed.
- What evidence would resolve it: Development and testing of new XAI evaluation metrics specifically designed for skeleton-based HAR, validated through comparative studies across multiple HAR models.

### Open Question 3
- Question: How does the perturbation magnitude affect the reliability of XAI evaluation metrics in skeleton-based HAR?
- Basis in paper: [explicit] The paper tested metrics with increasing perturbation magnitudes (2.5cm to 80cm) and found that faithfulness results were inconsistent, while stability tests remained robust.
- Why unresolved: While the paper observed effects of perturbation magnitude on metrics, the relationship between perturbation scale and metric reliability requires further investigation across different HAR models and perturbation methods.
- What evidence would resolve it: A comprehensive study varying perturbation magnitudes and methods across multiple HAR models, analyzing how these factors affect different XAI evaluation metrics' reliability.

## Limitations

- The findings are based on testing with a single EfficientGCN model architecture and one dataset, limiting generalizability
- The perturbation method's biomechanical constraints may not fully capture the complexity of human movement across all activity types
- The stability metric's superiority is demonstrated only through one type of perturbation, leaving open whether different perturbation approaches would yield different results

## Confidence

**High Confidence:** The observation that CAM and Grad-CAM produce nearly identical explanations in skeleton-based HAR. The mathematical similarity between these methods and their convergence in this domain is well-supported by the stability metric results.

**Medium Confidence:** The claim that faithfulness metrics are unreliable for skeleton-based HAR. While the results show unexpected behavior with the random baseline outperforming CAM/Grad-CAM in PGI, this finding is specific to the EfficientGCN model and may not generalize to other architectures.

**Low Confidence:** The assertion that stability is universally more dependable than faithfulness. The evidence is limited to one perturbation method and one model type, making broader claims premature without additional validation.

## Next Checks

1. **Cross-Architecture Validation:** Test faithfulness and stability metrics across multiple HAR model architectures (ST-GCN, Shift-GCN, MS-G3D) to determine if the observed patterns hold beyond EfficientGCN.

2. **Perturbation Method Diversification:** Implement and test alternative perturbation strategies including joint rotation perturbations, temporal displacement variations, and noise patterns that simulate sensor errors to assess metric robustness.

3. **Metric Correlation Analysis:** Conduct ablation studies to examine the relationship between faithfulness/stability metrics and actual model decision-making processes, potentially using gradient-based attribution analysis to validate whether important features identified by XAI methods actually influence predictions.