---
ver: rpa2
title: Probabilistic Shapley Value Modeling and Inference
arxiv_id: '2402.04211'
source_url: https://arxiv.org/abs/2402.04211
tags: []
core_contribution: This paper introduces a novel probabilistic framework for modeling
  and inferring Shapley values with uncertainty quantification. The proposed Variational
  Shapley Network (VSN) uses a masked neural network architecture and variational
  inference to learn distributions over input-to-output attributions, capturing both
  expected Shapley values and their uncertainty.
---

# Probabilistic Shapley Value Modeling and Inference

## Quick Facts
- arXiv ID: 2402.04211
- Source URL: https://arxiv.org/abs/2402.04211
- Reference count: 40
- Primary result: Introduces VSN for uncertainty-aware Shapley value attribution with competitive predictive performance

## Executive Summary
This paper presents a novel probabilistic framework for modeling Shapley values with uncertainty quantification. The Variational Shapley Network (VSN) treats Shapley values as latent random variables and uses variational inference to learn their distributions. By employing a masked neural network architecture, VSN can efficiently handle variable-length input subsets required for Shapley value computation. The method is evaluated on 11 datasets, showing improvements over self-explaining baselines like EBM while providing meaningful uncertainty estimates for feature attributions, particularly demonstrated in ICU mortality prediction.

## Method Summary
VSN introduces a probabilistic approach to Shapley value computation by treating them as stochastic latent variables. The method uses a masked neural network architecture that generates parallel embeddings for each feature, replacing marginalized features with learnable baseline embeddings in a latent space. Variational inference is employed to learn the parameters of the Shapley value distributions, with regularization ensuring the learned distributions center around expected values. This enables simultaneous predictive modeling and uncertainty-aware feature attribution.

## Key Results
- VSN achieves competitive predictive performance compared to strong baselines like EBM
- The method provides meaningful uncertainty estimates for feature attributions
- Shows improvements over self-explaining baselines on 11 datasets
- Demonstrates medically relevant explanations for ICU mortality prediction

## Why This Works (Mechanism)

### Mechanism 1
Treating Shapley values as latent random variables enables principled uncertainty quantification for feature attributions. By defining stochastic Shapley values (SSVs) φj ~ p(φj | x) and learning their conditional prior parameters through variational inference, the model captures both expected attributions and their uncertainty. The variational regularization ensures the learned distributions center around the expected Shapley values (ESVs).

### Mechanism 2
Masked neural network architecture enables efficient processing of variable-length input subsets required for Shapley value computation. The masked network uses binary masking matrices to control information flow between input features and output neurons, allowing parallel computation of embeddings for each feature. When marginalizing features, their embeddings are replaced with learnable baseline vectors in the latent space rather than the input space.

### Mechanism 3
Variational inference with regularization ensures learned Shapley value distributions are centered around true expected values while maintaining predictive performance. The KL-divergence regularization term in the variational objective pulls the variational solution toward the prior, which is designed to have mean equal to the ESV. This creates a self-explaining property where the learned distributions naturally center around the correct attributions.

## Foundational Learning

- **Concept**: Shapley values and their four key axioms (Efficiency, Null Player, Symmetry, Linearity)
  - Why needed here: Understanding these axioms is crucial because VSN builds directly on the Shapley value framework and aims to satisfy these same principles while adding uncertainty quantification
  - Quick check question: Can you explain why the Efficiency axiom is important for feature attribution and how it would be violated if ignored?

- **Concept**: Variational inference and the evidence lower bound (ELBO)
  - Why needed here: VSN uses variational inference to learn the parameters of the Shapley value distributions, optimizing a lower bound on the marginal likelihood while regularizing the learned distributions
  - Quick check question: What is the role of the KL-divergence term in the ELBO, and how does it differ from standard maximum likelihood estimation?

- **Concept**: Cooperative game theory and marginal contribution
  - Why needed here: Shapley values are fundamentally based on marginal contributions of features to coalitions, and understanding this concept is essential for grasping how VSN computes attributions
  - Quick check question: How does the marginal contribution concept in game theory relate to feature importance in machine learning models?

## Architecture Onboarding

- **Component map**: Input features -> parallel embeddings via masked network -> replace marginalized features with baseline embeddings -> linear combination -> feedforward network -> ESV parameters -> detached features + ESV -> variance network -> uncertainty estimates -> variational inference

- **Critical path**: 
  1. Input features → parallel embeddings via masked network
  2. Replace marginalized features with baseline embeddings
  3. Linear combination → feedforward network → ESV parameters
  4. Detached features + ESV → variance network → uncertainty estimates
  5. Variational inference → optimize ELBO with surrogate regularization

- **Design tradeoffs**:
  - Masked architecture vs. vanilla feedforward: Better marginalization quality but more complex implementation
  - Latent embedding space vs. input space baselines: More flexible but requires learning additional parameters
  - Variational regularization strength (β): Higher values ensure better centering around ESVs but may hurt predictive performance

- **Failure signatures**:
  - ESVs not converging to zero average (indicates poor regularization or model misspecification)
  - High divergence between model marginals and empirical data (suggests embedding space issues)
  - Uncertainty estimates not correlating with prediction reliability (indicates variance network problems)

- **First 3 experiments**:
  1. Train on synthetic1 dataset with known ESVs and verify that learned ESVs match analytical values
  2. Compare marginalization quality between masked and vanilla architectures using JS-divergence
  3. Test uncertainty quantification by evaluating prediction reliability on data points with high attribution variance

## Open Questions the Paper Calls Out
- How does the uncertainty in Shapley values correlate with the actual prediction uncertainty in VSN?
- How does the choice of masking network architecture affect the quality of learned marginal distributions?
- How does the regularization parameter β influence the trade-off between predictive accuracy and uncertainty quantification?

## Limitations
- Limited experimental validation to relatively small datasets (11 in total)
- Lacks head-to-head comparisons with more recent uncertainty-aware explanation methods
- Clinical relevance claims for ICU mortality prediction rely on qualitative assessment rather than systematic validation

## Confidence

- **High confidence**: The mathematical framework for probabilistic Shapley values and variational inference is well-grounded and internally consistent
- **Medium confidence**: The masked neural network architecture effectively handles marginalization, though alternative architectures could potentially achieve similar results
- **Medium confidence**: The uncertainty quantification provides meaningful information, but the clinical relevance claims need further validation

## Next Checks

1. Evaluate VSN on larger-scale datasets (e.g., ImageNet, large-scale tabular benchmarks) to assess scalability and performance under different data regimes
2. Conduct a systematic ablation study removing the variational regularization component to quantify its impact on both predictive performance and attribution quality
3. Perform a user study with medical experts to systematically evaluate whether VSN's uncertainty estimates improve clinical decision-making compared to deterministic Shapley values