---
ver: rpa2
title: Collective Innovation in Groups of Large Language Models
arxiv_id: '2407.05377'
source_url: https://arxiv.org/abs/2407.05377
tags:
- llms
- task
- groups
- agents
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates collective innovation in groups of large
  language models (LLMs) by having them play Little Alchemy 2, a creative game where
  players combine items to create new ones. The researchers examine how LLMs perform
  individually and how social connectivity affects their collective behavior.
---

# Collective Innovation in Groups of Large Language Models

## Quick Facts
- arXiv ID: 2407.05377
- Source URL: https://arxiv.org/abs/2407.05377
- Authors: Eleni Nisioti; Sebastian Risi; Ida Momennejad; Pierre-Yves Oudeyer; Clément Moulin-Frier
- Reference count: 14
- Primary result: Groups with dynamic connectivity outperform fully-connected groups in collective innovation tasks

## Executive Summary
This study investigates collective innovation in groups of large language models (LLMs) by having them play Little Alchemy 2, a creative game where players combine items to create new ones. The researchers examine how LLMs perform individually and how social connectivity affects their collective behavior. They find that while GPT-3.5 turbo can leverage semantic knowledge, it struggles with multi-step reasoning and open-ended exploration. When examining groups, they observe that LLMs imperfectly copy their neighbors' actions, and groups with dynamic connectivity outperform fully-connected ones. This result aligns with previous human and computational studies, suggesting that partial connectivity may be advantageous for exploring innovation landscapes.

## Method Summary
The study uses the Wordcraft environment with Little Alchemy 2's knowledge graph containing 720 items. Researchers create task prompts with intro and state sections for LLM agents, comparing single-agent and multi-agent settings. They vary social connectivity between fully-connected and dynamic configurations with sub-groups and visits. The experiments compare GPT-3.5 turbo and Llama 2 against baselines like random and empowerment approaches on targeted tasks with varying complexity (w, d parameters) and open-ended tasks.

## Key Results
- GPT-3.5 turbo leverages semantic knowledge but struggles with multi-step reasoning and open-ended exploration
- Groups with dynamic connectivity out-compete fully-connected groups in collective innovation performance
- LLMs learn imperfectly from social information, showing delays between neighbor actions and copying

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Social connectivity structure (dynamic vs fully-connected) affects collective innovation performance in LLM groups.
- Mechanism: Dynamic groups allow subgroups to explore different innovation paths, then recombine solutions via member visits. Fully-connected groups cause all agents to converge on a single path, limiting exploration breadth.
- Core assumption: The innovation landscape is tree-like with multiple branching paths; exploration diversity improves collective performance.
- Evidence anchors:
  - [abstract] "groups with dynamic connectivity out-compete fully-connected groups"
  - [section] "subgroups of a dynamic group may explore different paths and, then, manage to recombine their solutions"
  - [corpus] Weak - corpus neighbors don't address innovation group dynamics specifically
- Break condition: If innovation landscape is flat without distinct paths, connectivity structure becomes irrelevant.

### Mechanism 2
- Claim: LLMs imperfectly copy social information from neighbors, affecting learning efficiency.
- Mechanism: When an agent sees a neighbor craft an item, there's a delay before the agent itself crafts it. This imperfect copying reduces the benefit of social learning.
- Core assumption: Social information sharing through prompts is sufficient for learning but not perfect.
- Evidence anchors:
  - [section] "we observe that: a) LLMs learn imperfectly from social information, as there is some delay between the moment a neighbour of the LLM crafts an item and the LLM crafts it itself"
  - [section] "Agents in fully-connected groups take more time to copy their neighbors"
  - [corpus] Weak - corpus neighbors don't discuss social learning dynamics
- Break condition: If LLMs had perfect copying mechanisms, connectivity effects would dominate over exploration effects.

### Mechanism 3
- Claim: GPT-3.5 turbo can leverage semantic knowledge but struggles with multi-step reasoning and open-ended exploration.
- Mechanism: Semantic understanding helps predict immediate crafting outcomes but breaks down when planning multi-step sequences or exploring without specific targets.
- Core assumption: LLMs have some semantic understanding but limited planning capabilities.
- Evidence anchors:
  - [section] "a) LLMs leverage factual/ knowledge, as removing the natural language semantics degrades performance b) multi-step reasoning is challenging as performance significantly drops when increasing the depth of the task"
  - [section] "GPT-3.5 turbo performs on par with random" in open-ended tasks
  - [corpus] Weak - corpus neighbors don't address LLM reasoning limitations specifically
- Break condition: If LLMs had stronger planning capabilities, they would outperform random exploration in open-ended tasks.

## Foundational Learning

- Concept: Innovation landscapes and tree structures
  - Why needed here: Understanding why dynamic connectivity outperforms fully-connected groups requires grasping that innovations branch like trees
  - Quick check question: If an innovation task has multiple independent paths, what happens when all agents follow the same path versus when subgroups explore different paths?

- Concept: Social learning and information diffusion
  - Why needed here: The paper's key finding about connectivity effects depends on how agents share and learn from each other's discoveries
  - Quick check question: If agent A crafts item X and agent B copies it after 5 steps, what does this tell us about the efficiency of social learning?

- Concept: Semantic understanding vs. planning capabilities
  - Why needed here: The paper distinguishes between LLMs' ability to use semantic knowledge for immediate predictions versus planning multi-step sequences
  - Quick check question: If removing semantic meaning from items causes performance to drop, what does this tell us about how LLMs solve the task?

## Architecture Onboarding

- Component map: LLM agents -> Knowledge graph (Little Alchemy 2 items) -> Task prompts (intro + state) -> Social connectivity structures (fully-connected vs dynamic)
- Critical path: Task generation → Prompt construction (intro + state) → LLM action selection → State update → Social information sharing → Next step
- Design tradeoffs: Perfect copying (fully-connected) vs exploration diversity (dynamic connectivity); semantic knowledge usage vs computational efficiency; prompt size limits vs complete history tracking
- Failure signatures: LLMs getting stuck repeating combinations; agents failing to copy neighbor discoveries; poor performance in multi-step tasks; inability to explore efficiently in open-ended tasks
- First 3 experiments:
  1. Compare single LLM performance on targeted tasks with varying depths (1 vs 2) to confirm multi-step reasoning limitations
  2. Test semantic knowledge by running the same tasks with and without word semantics to measure performance impact
  3. Compare dynamic vs fully-connected groups on the same open-ended task to verify connectivity effect

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of LLM groups change when using larger, more advanced models like GPT-4 instead of GPT-3.5 turbo?
- Basis in paper: [explicit] The authors note that smaller, open-source models like Llama 2 fail to learn the task sufficiently well, and suggest that larger models like GPT-4 may be required to reveal interesting emergent behaviors in collective innovation studies.
- Why unresolved: The study only tested GPT-3.5 turbo and Llama 2, leaving the performance of larger models unexplored.
- What evidence would resolve it: Empirical results comparing the performance of groups using GPT-4 or other advanced models against the current findings with GPT-3.5 turbo and Llama 2.

### Open Question 2
- Question: What is the impact of different social connectivity configurations on the collective innovation performance of LLM groups?
- Basis in paper: [explicit] The study compares fully-connected groups with dynamic connectivity but suggests that a larger-scale analysis is necessary to reveal the effect of different hyperparameters of the model, such as the configuration of the dynamic connectivity.
- Why unresolved: The study only examined two types of connectivity and did not explore the full range of possible configurations.
- What evidence would resolve it: Experimental results showing the performance of LLM groups under various social connectivity configurations, including different subgroup sizes, visit probabilities, and durations.

### Open Question 3
- Question: How do LLMs explore and innovate in open-ended tasks without explicit targets?
- Basis in paper: [explicit] The authors found that GPT-3.5 turbo performs on par with random exploration in open-ended tasks, suggesting that it does not leverage its knowledge for efficient exploration. They also note that the ability of LLMs to exhibit exploration strategies, such as empowerment, has not been studied before.
- Why unresolved: The study did not examine the exploration strategies employed by LLMs in open-ended tasks, leaving their ability to explore and innovate in such settings unclear.
- What evidence would resolve it: Analysis of the exploration patterns and innovation strategies used by LLMs in open-ended tasks, comparing them to established exploration strategies like empowerment and random exploration.

## Limitations
- The findings about connectivity effects rely heavily on the specific task structure of Little Alchemy 2, which may not generalize to other innovation domains
- The imperfect copying mechanism could be an artifact of specific prompt engineering or LLM models rather than a fundamental property
- Temperature values differ between model comparisons (0.8 vs 0.4), making direct performance comparisons difficult to interpret

## Confidence

- **High Confidence**: The finding that dynamic connectivity groups outperform fully-connected groups is well-supported by multiple experiments and aligns with established literature on innovation networks. The observation that LLMs imperfectly copy neighbors is directly observable from the copy time data.
- **Medium Confidence**: The claim that GPT-3.5 turbo leverages semantic knowledge but struggles with multi-step reasoning is supported by experimental comparisons, though the specific mechanisms could use more detailed analysis.
- **Low Confidence**: The assertion that these results provide insights into human cultural evolution is speculative and not directly tested in the paper.

## Next Checks

1. **Connectivity Generalization Test**: Replicate the dynamic vs fully-connected comparison on a different innovation task (e.g., recipe creation or puzzle solving) to verify that connectivity effects are task-independent.

2. **Copying Mechanism Isolation**: Test LLMs with perfect copying enabled (forcing immediate replication of neighbor discoveries) to determine if imperfect copying is the primary driver of connectivity differences.

3. **Semantic Knowledge Dissection**: Conduct ablation studies where semantic meaning is progressively reduced (e.g., replacing item names with random tokens while preserving relationship structure) to quantify exactly how much semantic knowledge contributes to performance.