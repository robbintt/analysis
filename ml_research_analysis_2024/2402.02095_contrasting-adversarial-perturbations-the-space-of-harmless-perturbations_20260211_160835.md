---
ver: rpa2
title: 'Contrasting Adversarial Perturbations: The Space of Harmless Perturbations'
arxiv_id: '2402.02095'
source_url: https://arxiv.org/abs/2402.02095
tags:
- harmless
- perturbations
- layer
- perturbation
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper reveals the existence of harmless perturbation spaces
  within deep neural networks (DNNs), where perturbations drawn from these spaces,
  regardless of magnitude, leave network outputs unchanged. These harmless perturbations
  arise from the usage of non-injective functions in DNNs, particularly in linear
  layers where input dimensions exceed output dimensions.
---

# Contrasting Adversarial Perturbations: The Space of Harmless Perturbations

## Quick Facts
- **arXiv ID:** 2402.02095
- **Source URL:** https://arxiv.org/abs/2402.02095
- **Reference count:** 38
- **Primary result:** Identified harmless perturbation spaces within DNNs that preserve outputs regardless of perturbation magnitude

## Executive Summary
This paper reveals the existence of harmless perturbation spaces within deep neural networks (DNNs), where perturbations drawn from these spaces, regardless of magnitude, leave network outputs unchanged. These harmless perturbations arise from the usage of non-injective functions in DNNs, particularly in linear layers where input dimensions exceed output dimensions. The paper demonstrates that harmless perturbations can be used for privacy-preserving data and model fingerprinting, while highlighting the distinctive robustness of DNNs to large magnitude perturbations compared to adversarial examples.

## Method Summary
The authors theoretically analyze DNN architectures to identify harmless perturbation spaces, focusing on linear transformations where input dimensionality exceeds output dimensionality. They derive mathematical conditions under which perturbations become harmless and develop methods to construct such perturbations for specific layers. The study combines theoretical analysis with empirical validation on image classification tasks, examining how harmless perturbations affect model performance and privacy preservation. The methodology involves computing null spaces of linear transformations, generating perturbations within these spaces, and evaluating their impact on classification accuracy and data privacy.

## Key Results
- Harmless perturbations can be constructed for DNN layers where input dimensions exceed output dimensions
- These perturbations maintain classification accuracy while obscuring sensitive image features
- Harmless perturbations provide privacy preservation comparable to Gaussian noise without degrading model performance

## Why This Works (Mechanism)

The mechanism behind harmless perturbations relies on the non-injective nature of certain linear transformations within DNNs. When a linear layer maps from a higher-dimensional space to a lower-dimensional space, the transformation cannot be one-to-one, creating a non-trivial null space. Perturbations within this null space are mapped to zero in the output space, making them "harmless" to the network's subsequent computations. This property emerges from the fundamental mathematical structure of linear algebra rather than from any learned characteristics of the network.

## Foundational Learning

- **Null space of linear transformations**: The set of vectors that map to zero under a linear transformation. Why needed: Essential for understanding where harmless perturbations exist. Quick check: Verify that if x is in the null space, then Ax = 0.

- **Non-injective functions**: Functions that map multiple distinct inputs to the same output. Why needed: Explains why harmless perturbations exist in overparameterized layers. Quick check: Confirm that a function f is non-injective when dim(input) > dim(output).

- **Linear layer dimensionality**: The relationship between input and output dimensions in fully connected layers. Why needed: Determines whether harmless perturbation spaces exist. Quick check: Check if input dimension exceeds output dimension in each linear layer.

## Architecture Onboarding

Component map: Input -> Linear layers (non-injective) -> Activation functions -> Output layers
Critical path: Image input -> Feature extraction layers -> Classification layer
Design tradeoffs: Overparameterization enables harmless perturbations but may increase computational cost
Failure signatures: Harmless perturbations only exist when input dimension > output dimension
First experiments: 1) Identify layers with harmless perturbation spaces, 2) Generate harmless perturbations for test images, 3) Measure classification accuracy under harmless perturbations

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but implicit questions include how harmless perturbations behave in recurrent networks, transformers, and other non-standard architectures, as well as the potential for adaptive attacks that could distinguish between harmless and adversarial perturbations.

## Limitations

- Theoretical analysis focuses primarily on linear layers, with limited exploration of nonlinear activation functions
- Privacy preservation claims lack comprehensive evaluation across diverse datasets and threat models
- Experimental validation is limited in scope and generalizability across different DNN architectures

## Confidence

- **High**: Core theoretical foundation regarding linear transformations and their null spaces
- **Medium**: Practical applications for privacy preservation and fingerprinting
- **High**: Claims about contrasting robustness to harmless versus adversarial perturbations

## Next Checks

1. Evaluate harmless perturbation effectiveness across diverse DNN architectures (CNNs, transformers) and datasets to assess generalizability
2. Test resistance of harmless perturbations to potential adversarial attacks that could compromise privacy guarantees
3. Conduct user studies to verify that obscured images maintain sufficient privacy while preserving downstream utility in real-world applications