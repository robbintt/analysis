---
ver: rpa2
title: Large Language Models as Minecraft Agents
arxiv_id: '2402.08392'
source_url: https://arxiv.org/abs/2402.08392
tags:
- builder
- architect
- language
- arxiv
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper examines the use of large language models (LLMs) as
  agents in the Minecraft Collaborative Builder Task, where an architect provides
  instructions to a builder to construct a target structure. The authors implement
  LLM-based builder and architect agents using models such as GPT-4, GPT-3.5, Llama2,
  and Vicuna, and evaluate their performance against previous baselines.
---

# Large Language Models as Minecraft Agents

## Quick Facts
- arXiv ID: 2402.08392
- Source URL: https://arxiv.org/abs/2402.08392
- Authors: Chris Madge; Massimo Poesio
- Reference count: 8
- Primary result: GPT-4 achieves 37.6% accuracy in Minecraft building task, outperforming IGLU NLP baseline

## Executive Summary
This paper investigates the use of large language models (LLMs) as agents in the Minecraft Collaborative Builder Task, where an architect provides instructions to a builder to construct a target structure. The authors implement LLM-based builder and architect agents using models such as GPT-4, GPT-3.5, Llama2, and Vicuna, and evaluate their performance against previous baselines. Results show that GPT-4 and GPT-3.5 outperform the IGLU NLP baseline, with GPT-4 achieving 37.6% accuracy, while smaller models like Llama2-13b-chat and Vicuna-13b struggle with the structured response format. The study highlights the potential of LLMs for embodied AI tasks and introduces a web-based platform for future experimentation.

## Method Summary
The paper implements LLM-based builder and architect agents for the Minecraft Collaborative Builder Task. The builder agent interprets natural language instructions and outputs structured JSON responses containing block coordinates and colors, while the architect agent generates instructions and responds to clarification questions. The authors use GPT-4, GPT-3.5, Llama2, and Vicuna models with carefully crafted prompts, comparing their performance to the IGLU NLP baseline. The evaluation uses target structures from the Minecraft Dialogue Corpus and a web-based platform for testing.

## Key Results
- GPT-4 achieves 37.6% accuracy, outperforming IGLU NLP baseline in Minecraft building task
- GPT-3.5 also outperforms IGLU baseline, while Llama2-13b-chat and Vicuna-13b struggle with structured JSON format
- Smaller models frequently generate invalid JSON or responses in incorrect formats
- Architect agent struggles with complex structures, requiring multiple exchanges for correct instructions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can directly interpret natural language instructions and produce structured JSON responses containing block coordinates and colors for Minecraft building tasks.
- Mechanism: The LLM receives a carefully crafted prompt specifying the world coordinate system, color options, and required JSON output format. On each turn, it consumes the natural language instruction and outputs a structured JSON with "add", "remove", "confidence", and optional "question" fields.
- Core assumption: The LLM has sufficient world knowledge and spatial reasoning capability to map natural language descriptions to 3D coordinates within the specified Minecraft-like grid.
- Evidence anchors:
  - [abstract] "The builder agent interprets natural language instructions and outputs structured JSON responses with block coordinates and colors"
  - [section] "The builder agent operates as follows: The initial prompt to the LLM contains instructions for the task, constraints of the world (min/max for x, y, z), coordinate mappings (east/south/west/north) and requests that the LLM respond in a specified JSON format only"
  - [corpus] Weak evidence - related papers focus on embodied agents and crash bug reproduction, not structured language-to-coordinate translation
- Break condition: The LLM fails to consistently adhere to the structured response format, as observed with smaller models like Llama2-13b-chat and Vicuna-13b.

### Mechanism 2
- Claim: LLMs can engage in clarification dialogue when instructions are ambiguous or incomplete.
- Mechanism: The LLM is prompted to optionally include a "question" field in its JSON output when the instruction lacks sufficient detail. The architect model can then respond to these clarification questions, creating an interactive dialogue loop.
- Core assumption: The LLM has sufficient common sense reasoning to identify missing information in instructions and formulate appropriate clarifying questions.
- Evidence anchors:
  - [abstract] "introduce clarification questions and examining the challenges and opportunities for improvement"
  - [section] "We can see GPT-4 identifies the missing properties, asking for clarification on the colour and position with the question: 'What color should the block be and where specifically should I place it?'"
  - [corpus] Weak evidence - no related papers specifically address clarification question generation in this context
- Break condition: The LLM fails to identify ambiguous instructions or generates inappropriate clarifying questions that don't help resolve the ambiguity.

### Mechanism 3
- Claim: The architect LLM can generate appropriate building instructions based on a target world state description.
- Mechanism: The architect LLM receives a prompt containing the target world state in JSON format along with instructions for the task. It generates natural language instructions that the builder can follow, updating the current world state after each builder response.
- Core assumption: The LLM can understand the spatial relationships described in the target world state and generate coherent step-by-step instructions that progressively build toward that target.
- Evidence anchors:
  - [abstract] "The architect agent generates instructions and responds to clarification questions"
  - [section] "The architect differs slightly from the builder. The prompt, along with architect specific instructions, contains the target state of the world"
  - [section] "In Figure 3, for the purpose of illustrating the example, the target structure is shown... We can see, for simpler structures, the architect gives accurate instructions"
  - [corpus] Weak evidence - related papers focus on general agent capabilities, not architect-specific instruction generation
- Break condition: The architect struggles with complex structures, requiring multiple exchanges to arrive at the correct instruction, as observed in the paper's results.

## Foundational Learning

- Concept: Understanding the Minecraft-like voxel coordinate system (x, y, z with specific min/max bounds and directional mappings)
  - Why needed here: The builder must translate natural language instructions into precise 3D coordinates within this bounded grid
  - Quick check question: Given the coordinate system where northernly is 0,0,-5 and eastern is 5,0,0, what would be the coordinate for a block placed one step east and one step north from the center?

- Concept: JSON structured output format with specific fields ("add", "remove", "confidence", "question")
  - Why needed here: The LLM must output responses in this exact format for the system to parse and execute the building actions
  - Quick check question: What JSON structure should the LLM output to add a blue block at coordinates (1,2,3) with 90% confidence and no question?

- Concept: Clarification dialogue patterns in task-oriented conversations
  - Why needed here: Both architect and builder need to identify when information is missing and ask appropriate clarifying questions
  - Quick check question: Given the instruction "place a block on the ground", what would be an appropriate clarifying question to ask about the missing information?

## Architecture Onboarding

- Component map: Architect LLM -> Natural language instruction -> Builder LLM -> JSON actions -> System execution -> Updated world state -> Architect LLM
- Critical path: Architect receives target state → generates instruction → builder interprets instruction → outputs JSON actions → system updates world state → architect receives updated state and responds to any questions
- Design tradeoffs: Using large LLMs provides better natural language understanding but increases computational cost; structured JSON output ensures system compatibility but may limit conversational flexibility
- Failure signatures: Builder fails to adhere to JSON format (especially smaller models), architect struggles with complex structures requiring multiple exchanges, both agents fail to identify or resolve ambiguous instructions
- First 3 experiments:
  1. Test builder with simple single-block placement instructions across all LLM models to verify JSON output format adherence
  2. Test clarification capability by providing intentionally ambiguous instructions and checking if builder asks appropriate questions
  3. Test architect with simple target structures (single column, basic shapes) to verify instruction generation quality before moving to complex structures

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can smaller LLM models like Llama2-13b-chat and Vicuna-13b be improved to consistently adhere to the structured response format required by the Minecraft Collaborative Builder Task?
- Basis in paper: [explicit] The paper notes that smaller models struggle with the structured response format, with Vicuna-13b often generating responses in other languages/formats.
- Why unresolved: The study does not explore methods to improve smaller models' adherence to the JSON format.
- What evidence would resolve it: Experiments testing various fine-tuning techniques, prompt engineering strategies, or model architectures to enhance smaller LLMs' ability to produce valid JSON responses.

### Open Question 2
- Question: What are the limitations of using LLMs as architect agents in complex Minecraft building tasks, and how can these be addressed?
- Basis in paper: [explicit] The paper shows that the architect agent struggles with complex structures, requiring repeated exchanges to arrive at the correct instruction.
- Why unresolved: The study does not provide a quantitative evaluation of the architect agent's performance or explore methods to improve its ability to generate accurate instructions for complex structures.
- What evidence would resolve it: A systematic evaluation of the architect agent's performance on a range of complex structures, along with experiments testing techniques to improve its instruction generation capabilities.

### Open Question 3
- Question: How can the performance gap between open-source LLMs and closed-source models like GPT-4 be closed for the Minecraft Collaborative Builder Task?
- Basis in paper: [explicit] The paper notes that GPT-4 outperforms open-source models like Llama2 and Vicuna, suggesting a performance gap.
- Why unresolved: The study does not explore methods to improve open-source models' performance, such as fine-tuning or prompt engineering.
- What evidence would resolve it: Experiments comparing the performance of open-source models before and after applying various improvement techniques, such as fine-tuning on Minecraft-specific data or using advanced prompt engineering strategies.

## Limitations

- The paper doesn't provide detailed analysis of why specific models fail or succeed, particularly regarding the structured JSON output requirement
- The experimental setup uses a synthetic task with fixed target structures, which may not fully represent real-world complexity
- The comparison to the IGLU NLP baseline is somewhat limited and doesn't include ablation studies to understand which components drive the improvement

## Confidence

- **High confidence**: LLMs can interpret natural language instructions and produce structured JSON responses for simple Minecraft building tasks
- **Medium confidence**: LLMs can engage in clarification dialogue when instructions are ambiguous
- **Low confidence**: Architect LLMs can generate appropriate building instructions for complex structures

## Next Checks

1. **Format Adherence Study**: Systematically test all LLM models with increasingly complex instructions to identify the exact point where models fail to adhere to the structured JSON format, documenting the failure patterns and error messages.

2. **Ablation Analysis**: Conduct controlled experiments removing the structured output requirement to determine if smaller models perform better with free-form responses, helping isolate whether the format constraint is the primary limitation.

3. **Real-World Transfer Test**: Evaluate the builder agent on open-ended Minecraft tasks from platforms like CrafterDojo or Odyssey to assess whether the synthetic task performance generalizes to more realistic building scenarios.