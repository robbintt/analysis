---
ver: rpa2
title: 'Demonstration Notebook: Finding the Most Suited In-Context Learning Example
  from Interactions'
arxiv_id: '2406.10878'
source_url: https://arxiv.org/abs/2406.10878
tags:
- demonstration
- demonstrations
- question
- questions
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a novel prompt engineering workflow called
  the "demonstration notebook" to automatically construct and select the most suitable
  in-context learning examples for large language models (LLMs). The key innovation
  is leveraging the LLM's past interactions to identify which demonstrations are most
  effective for different types of reasoning questions.
---

# Demonstration Notebook: Finding the Most Suited In-Context Learning Example from Interactions

## Quick Facts
- arXiv ID: 2406.10878
- Source URL: https://arxiv.org/abs/2406.10878
- Reference count: 34
- Key outcome: Introduces "demonstration notebook" method that automatically constructs and selects in-context learning examples, achieving state-of-the-art results on reasoning benchmarks

## Executive Summary
This paper introduces a novel approach for automatic construction and selection of in-context learning examples for large language models. The key innovation is a "demonstration notebook" that leverages an LLM's past interactions to identify which demonstrations are most effective for different types of reasoning questions. Through an iterative collection phase involving demonstration expansion, on-policy collection, off-policy collection, and pruning, the system builds associations between demonstrations and the questions they effectively solve. The method is demonstrated to outperform existing automatic demonstration construction methods on arithmetic, commonsense, and symbolic reasoning benchmarks, and is also shown to work well for text summarization and prompt compression tasks.

## Method Summary
The demonstration notebook method constructs and selects in-context learning examples through a three-phase process. First, during the collection phase, it iteratively builds a demonstration set, interaction record set, and noted question set through four procedures: demonstration expansion (constructing new demonstrations from successful problem-solving records), on-policy collection (gathering records with selected demonstrations), off-policy collection (exploring new demonstrations), and pruning (removing redundant demonstrations and records). Second, a prompter (trained on the interaction records) learns to select the most suitable demonstration for each incoming question. Finally, during inference, the prompter uses the learned associations to select demonstrations that are most likely to help solve new questions. The method characterizes "demonstrative regimes" - the sets of questions each demonstration is effective for - which the authors visualize and analyze.

## Key Results
- Achieves state-of-the-art results on reasoning benchmarks (GSM8K, CommonsenseQA, Last Letter Concatenation) compared to existing automatic demonstration construction methods
- Visual analysis shows demonstrative regimes form low-dimensional manifolds in embedding space rather than random distributions
- Demonstrates effectiveness beyond reasoning tasks, working well for text summarization (ROUGE scores) and prompt compression
- Provides the first rigorous analysis and visualization of demonstration regimes for different demonstrations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Demonstration notebook improves performance by collecting interaction records that identify which demonstrations work for which questions
- Mechanism: The system maintains three sets - demonstration set, interaction record set, and noted question set. Through iterative collection procedures (demonstration expansion, on-policy collection, off-policy collection, pruning), it builds associations between demonstrations and the questions they are effective for
- Core assumption: Questions within a dataset have heterogeneous effectiveness patterns for different demonstrations, and these patterns can be learned through interaction history
- Evidence anchors:
  - [abstract] "This notebook helps identify the most suitable in-context learning example for a question by gathering and reusing information from the LLM's past interactions"
  - [section 3.1] "The interaction record set serves as the supervised training data for the prompter. It accumulates successful problem-solving records from three collection procedures"
  - [corpus] Weak - no direct corpus evidence provided, though related papers on ICL exist
- Break condition: If demonstration effectiveness patterns are too random or dataset is too small to establish meaningful associations

### Mechanism 2
- Claim: The demonstration notebook achieves state-of-the-art results by selecting demonstrations tailored to each question rather than using fixed demonstrations
- Mechanism: A prompter trained on interaction records scores and selects the most appropriate demonstration for each incoming question, creating question-specific prompts
- Core assumption: A trained prompter can effectively learn the mapping from question embeddings to effective demonstrations
- Evidence anchors:
  - [abstract] "Our experiments show that this approach outperforms all existing methods for automatic demonstration construction and selection"
  - [section 3.6] "During the testing phase, when encountering a new question, the prompter infers and selects the most suited demonstration from the demonstration set"
  - [corpus] Moderate - related papers like "In-context Demonstration Matters" discuss prompt optimization for demonstration selection
- Break condition: If the prompter cannot learn meaningful patterns from interaction records or if demonstration space is too large relative to training data

### Mechanism 3
- Claim: Demonstration regimes (the set of questions each demonstration is effective for) tend to form low-dimensional manifolds in embedding space
- Mechanism: Visualization of demonstrative regimes shows that effective question sets for demonstrations occupy small, structured regions rather than random distributions
- Core assumption: The relationship between demonstrations and their effective question sets has geometric structure that can be characterized
- Evidence anchors:
  - [abstract] "We also contribute a rigorous analysis method to reveal the 'demonstrative regime' of a demonstration"
  - [section 4.3] "Our visualizations show that the demonstrative regimes of demonstrations are often in the form of low dimensional manifolds in the embedding space"
  - [corpus] Weak - no corpus evidence for low-dimensional manifold structure, though related work exists on ICL analysis
- Break condition: If demonstrative regimes are truly random or high-dimensional, making pattern learning ineffective

## Foundational Learning

- Concept: In-context learning with demonstrations
  - Why needed here: The entire method builds on using demonstrations as in-context examples for LLMs
  - Quick check question: What is the difference between zero-shot and few-shot (in-context) learning?

- Concept: Chain-of-thought prompting
  - Why needed here: Demonstrations in the notebook include step-by-step reasoning, which is crucial for the method's effectiveness
  - Quick check question: How does chain-of-thought prompting differ from standard prompting approaches?

- Concept: Embedding spaces and similarity measures
  - Why needed here: The method uses embeddings to represent questions and demonstrations, and the analysis of demonstrative regimes occurs in embedding space
  - Quick check question: What are common distance metrics used in embedding space for similarity?

## Architecture Onboarding

- Component map:
  - Demonstration set -> stores automatically constructed demonstrations
  - Interaction record set -> stores (question, demonstration) pairs indicating successful associations
  - Noted question set -> stores "hard" questions that need further exploration
  - Prompter -> adapter module that selects demonstrations based on question embeddings
  - LLM -> the target model being prompted

- Critical path:
  1. Collection phase: Build demonstration set, interaction record set, and noted question set through iterative procedures
  2. Prompter training: Train adapter on interaction records
  3. Inference: Use prompter to select demonstrations for new questions

- Design tradeoffs:
  - Collection cost vs. inference quality: More collection iterations improve prompter but increase setup time
  - Demonstration diversity vs. redundancy: More demonstrations provide coverage but may include redundancy that needs pruning
  - Adapter complexity vs. data efficiency: Larger adapters may capture more complex patterns but require more training data

- Failure signatures:
  - Low diversity in interaction records (prompter cannot learn meaningful patterns)
  - Rapid growth of noted question set (collection strategy failing to find effective demonstrations)
  - No improvement over baseline methods (fundamental approach not working for task)

- First 3 experiments:
  1. Verify basic functionality: Run collection phase on small dataset and check if interaction records are being created correctly
  2. Baseline comparison: Compare performance of notebook-selected demonstrations vs. random selection on simple task
  3. Regime visualization: Generate embeddings and visualize demonstrative regimes to verify they form structured patterns rather than random distributions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the specific low-dimensional manifold structures that demonstrative regimes take in the embedding space, and how do they relate to the demonstrations themselves?
- Basis in paper: [explicit] The paper states "Our visualizations show that the demonstrative regimes of demonstrations are often in the form of low dimensional manifolds in the embedding space, which might not be even close to the embeddings of the demonstration itself."
- Why unresolved: While the paper mentions that demonstrative regimes form low-dimensional manifolds, it doesn't provide a detailed analysis of their specific structures or how they relate to the demonstrations. This is a complex mathematical question that would require further research and visualization techniques.
- What evidence would resolve it: Detailed mathematical analysis and visualizations showing the exact structure of these manifolds and their relationship to the demonstrations would be needed to fully understand this phenomenon.

### Open Question 2
- Question: How can we develop more effective retrieval-based methods for prompt engineering that leverage the insights about demonstrative regimes being low-dimensional manifolds?
- Basis in paper: [explicit] The paper suggests that "This experimental finding holds the potential to revolutionize retrieval and generate(RAG) based prompt engineering methods."
- Why unresolved: While the paper hints at the potential for revolutionizing retrieval methods, it doesn't provide specific guidance on how to implement such methods. This is an open area for further research and development.
- What evidence would resolve it: Successful implementation and testing of retrieval-based methods that explicitly account for the low-dimensional manifold structure of demonstrative regimes would demonstrate the practical application of this insight.

### Open Question 3
- Question: How can the demonstration notebook approach be extended to other types of tasks beyond reasoning, prompt compression, and article summarization?
- Basis in paper: [explicit] The paper states "Our work offers the first rigorous analysis and visualization of demonstration regimes for different demonstrations, promoting more intuitive uses in-context examples."
- Why unresolved: While the paper demonstrates success on several task types, it doesn't explore the full potential of the demonstration notebook approach. There may be many other task types where this approach could be beneficial, but this remains to be explored.
- What evidence would resolve it: Successful application and evaluation of the demonstration notebook approach on a wide variety of task types, demonstrating its versatility and effectiveness across different domains.

## Limitations

- The method requires multiple interaction cycles with the LLM, which can be computationally expensive and time-consuming for complex tasks
- Effectiveness depends on having sufficient interaction records, which may be challenging for rare or highly specialized question types
- The low-dimensional manifold hypothesis for demonstrative regimes lacks rigorous mathematical proof and extensive cross-domain validation

## Confidence

- High Confidence: The core mechanism of using interaction history to identify effective demonstrations (Mechanism 1) is well-supported by experimental results
- Medium Confidence: The state-of-the-art performance claims (Mechanism 2) are convincing but could be affected by specific benchmark characteristics
- Medium Confidence: The low-dimensional manifold hypothesis for demonstrative regimes (Mechanism 3) is supported by visualizations but lacks rigorous proof

## Next Checks

1. **Robustness testing**: Apply the demonstration notebook method to a completely different domain (e.g., medical reasoning or legal analysis) to verify the generalizability of demonstrative regime patterns across diverse tasks

2. **Data efficiency analysis**: Systematically vary the number of interaction records used to train the prompter and measure the performance trade-off to identify minimum viable training data requirements

3. **Baseline ablation study**: Implement and compare against more sophisticated baseline methods like learned prompt selection with continuous prompt embeddings or gradient-based prompt optimization to establish the relative contribution of the demonstration notebook approach versus alternative in-context learning optimization strategies