---
ver: rpa2
title: 'REXEL: An End-to-end Model for Document-Level Relation Extraction and Entity
  Linking'
arxiv_id: '2404.12788'
source_url: https://arxiv.org/abs/2404.12788
tags: []
core_contribution: The paper introduces REXEL, an end-to-end model for document-level
  closed information extraction (DocIE). REXEL addresses the limitations of existing
  approaches that are prone to error propagation and restricted to sentence level
  by jointly performing mention detection, entity typing, entity disambiguation, coreference
  resolution, and document-level relation classification in a single forward pass.
---

# REXEL: An End-to-end Model for Document-Level Relation Extraction and Entity Linking

## Quick Facts
- arXiv ID: 2404.12788
- Source URL: https://arxiv.org/abs/2404.12788
- Authors: Nacime Bouziani, Shubhi Tyagi, Joseph Fisher, Jens Lehmann, Andrea Pierleoni
- Reference count: 16
- Primary result: Improves end-to-end relation extraction by 6 F1 points over SOTA while being 11x faster

## Executive Summary
REXEL is an end-to-end model that performs document-level closed information extraction by jointly handling mention detection, entity typing, entity disambiguation, coreference resolution, and document-level relation classification in a single forward pass. The model uses a modular architecture where intermediate embeddings from each subtask inform subsequent tasks, enabling efficient extraction of facts fully linked to a reference knowledge graph. REXEL addresses the limitations of existing approaches that suffer from error propagation and are restricted to sentence-level processing by leveraging cross-task information flow and a coarse-to-fine approach for relation classification.

## Method Summary
REXEL employs a modular architecture built on RoBERTa encoder, with each subtask implemented as a distinct module that shares intermediate representations. The model uses a weighted sum of task-specific losses with predefined lambda values (λ1=0.1, λ2=0.005, λ3=0.1, λ4=0.02, λ5=0.775) optimized via Adam with learning rate 5e-5. For relation classification, REXEL implements a cross-attention transformer that captures interactions between entity pairs and their context. The model also introduces a coarse-to-fine approach for relation classification and uses a clustering approach for coreference resolution. To facilitate benchmarking, the authors release DocRED-IE, an extension of the DocRED dataset with silver standard entity linking annotations.

## Key Results
- Achieves 6+ F1 point improvement over state-of-the-art models on DWIE and DocRED-E2E datasets for end-to-end relation extraction
- Processes documents 11x faster than competitive approaches while maintaining or improving accuracy
- Demonstrates effectiveness across all subtasks including mention detection, entity typing, entity disambiguation, coreference resolution, and relation classification

## Why This Works (Mechanism)
REXEL's effectiveness stems from its ability to jointly optimize multiple interdependent subtasks through shared intermediate representations, rather than treating each task as an isolated pipeline step. The coarse-to-fine approach for relation classification reduces computational complexity by first filtering unlikely relations before performing detailed classification. The cross-attention transformer captures rich interactions between entity pairs and their context, enabling more accurate relation extraction. The weighted loss function balances the contributions of different subtasks, preventing any single task from dominating the learning process.

## Foundational Learning
- **Cross-attention mechanisms**: Why needed - to capture interactions between entity pairs and their context; Quick check - verify that entity representations are properly attended to relevant context tokens
- **Coarse-to-fine classification**: Why needed - to reduce computational complexity while maintaining accuracy; Quick check - ensure the coarse filter effectively eliminates most negative relations before fine classification
- **Weighted multi-task learning**: Why needed - to balance contributions from different subtasks; Quick check - verify that loss weights are appropriate and no single task dominates training
- **Silver standard annotations**: Why needed - to extend existing datasets with entity linking information; Quick check - evaluate the quality and accuracy of silver annotations through manual verification

## Architecture Onboarding
- **Component map**: Document text -> RoBERTa encoder -> Mention detection -> Entity typing -> Entity disambiguation -> Coreference resolution -> Relation classification (with cross-attention) -> Output facts
- **Critical path**: The relation classification module is the critical path as it depends on successful completion of all preceding subtasks and uses the most computationally expensive cross-attention mechanism
- **Design tradeoffs**: Joint training enables cross-task information flow but increases model complexity; coarse-to-fine approach improves speed but may miss rare relations; silver annotations enable larger-scale training but introduce noise
- **Failure signatures**: Poor mention detection propagates errors to all downstream tasks; incorrect entity disambiguation leads to wrong KG links; coreference resolution errors merge or split entities incorrectly
- **First experiments**: 1) Evaluate individual subtask performance in isolation to establish baselines; 2) Test the cross-attention mechanism with simplified relation classification; 3) Measure inference speed with and without the coarse-to-fine approach

## Open Questions the Paper Calls Out
- How does REXEL's performance scale with document length and number of entities?
- What is the impact of the coarse-to-fine approach on REXEL's performance compared to a purely fine-grained approach?
- How does REXEL handle entities with multiple types, and what is the impact on downstream tasks?

## Limitations
- Implementation details of the cross-attention transformer and coreference resolution approach are not fully specified
- Silver standard entity linking annotations in DocRED-IE may contain noise and errors from automated pipelines
- Model performance may degrade with very long documents due to RoBERTa's context length limitations

## Confidence
**High Confidence Claims:**
- Modular architecture design with intermediate embedding representations
- Weighted loss function formulation with specific lambda values
- Overall task formulation and objective metrics

**Medium Confidence Claims:**
- 11x faster inference speed compared to competitive approaches
- Average 6 F1 point improvement over state-of-the-art models

**Low Confidence Claims:**
- Specific implementation details of cross-attention transformer
- Exact coreference resolution methodology
- Quality assessment of silver standard annotations

## Next Checks
1. **Cross-attention transformer implementation verification**: Implement and test the relation classification component with cross-attention transformer architecture, focusing on the cross-attention mechanism between entity pair representations and context embeddings.

2. **Coreference resolution methodology validation**: Test different coreference resolution approaches (span-based, graph-based, latent variable) on the DocRED dataset to determine which method yields best performance in the REXEL pipeline, and verify the clustering approach used.

3. **Silver annotation quality assessment**: Conduct manual evaluation of a random sample of silver standard entity linking annotations in DocRED-IE to estimate accuracy rate and determine potential impact on downstream task performance.