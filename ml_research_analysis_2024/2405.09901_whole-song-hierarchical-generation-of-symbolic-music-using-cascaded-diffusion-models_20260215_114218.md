---
ver: rpa2
title: Whole-Song Hierarchical Generation of Symbolic Music Using Cascaded Diffusion
  Models
arxiv_id: '2405.09901'
source_url: https://arxiv.org/abs/2405.09901
tags:
- music
- generation
- lead
- time
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a cascaded diffusion model for whole-song symbolic
  music generation, using a four-level hierarchical music language. The model generates
  structured music with recognizable verse-chorus patterns and cadences.
---

# Whole-Song Hierarchical Generation of Symbolic Music Using Cascaded Diffusion Models

## Quick Facts
- arXiv ID: 2405.09901
- Source URL: https://arxiv.org/abs/2405.09901
- Authors: Ziyu Wang; Lejun Min; Gus Xia
- Reference count: 40
- Key outcome: Cascaded diffusion model generates structured symbolic music with verse-chorus patterns, outperforming baselines in objective and subjective evaluations, with flexible external control via pre-trained embeddings

## Executive Summary
This paper proposes a novel cascaded diffusion model for whole-song symbolic music generation that operates on a four-level hierarchical music language. The model generates music by progressively refining representations from coarse structural form down to detailed accompaniment, capturing recognizable verse-chorus patterns and cadences. The approach demonstrates significant improvements over baseline models in both objective metrics (Inter-Phrase Latent Similarity) and subjective evaluations for music quality and structural coherence.

## Method Summary
The method uses cascaded diffusion models operating on a four-level hierarchical music language: Form (phrase structure and key progression), Reduced Lead Sheet (melody with reduced resolution), Lead Sheet (full melody and chords), and Accompaniment (full piano arrangement). Four diffusion models are trained sequentially, with each level conditioned on outputs from higher levels. The architecture incorporates cross-attention layers to enable external control via pre-trained music embeddings for chord progression, rhythm patterns, and texture. The entire system is trained on the POP909 dataset of MIDI files, with music representations converted to multi-channel piano-roll images at different resolutions for each hierarchical level.

## Key Results
- Significant improvement in ILS scores over baselines for phrase content similarity in chords and accompaniment generation
- Subjective evaluations show the model outperforms baselines on 8-measure and 32-measure samples in music quality and structural metrics
- Accompaniment generation demonstrates particularly strong performance with coherent local patterns and texture
- External control via pre-trained embeddings enables flexible manipulation of musical features at appropriate hierarchical levels

## Why This Works (Mechanism)

### Mechanism 1
The cascaded diffusion architecture allows generation of entire songs by progressively refining music representations from coarse to fine. Four diffusion models operate in sequence, each generating a different hierarchical level of music representation. Higher-level models (e.g., Form) provide structural guidance to lower-level models (e.g., Accompaniment), enabling coherent long-term structure.

### Mechanism 2
The hierarchical music language decomposes compositional structure into interpretable levels that align with human music cognition. Four levels (Form, Reduced Lead Sheet, Lead Sheet, Accompaniment) represent music at increasing levels of detail, mirroring how humans perceive and compose music from abstract form to concrete notes.

### Mechanism 3
External control via pre-trained latent representations enables flexible, interpretable manipulation of generated music. Cross-attention layers incorporate pre-trained embeddings (chord, rhythm, texture) as conditions at appropriate hierarchical levels, allowing users to guide specific musical aspects without retraining.

## Foundational Learning

- Concept: Diffusion models
  - Why needed here: The paper uses cascaded diffusion models to generate music. Understanding how diffusion models work (forward noising process, reverse denoising process, classifier-free guidance) is essential to grasp the architecture.
  - Quick check question: What are the two main processes in a diffusion model, and how do they work together to generate samples?

- Concept: Hierarchical representations
  - Why needed here: The paper defines a four-level hierarchical music language. Understanding how hierarchical representations work in other domains (e.g., image generation with sketch-to-image models) helps contextualize the approach.
  - Quick check question: Why might decomposing music into hierarchical levels improve generation quality compared to modeling music as a flat sequence?

- Concept: Cross-attention in diffusion models
  - Why needed here: The paper uses cross-attention to incorporate external conditions (pre-trained embeddings) into the diffusion process. Understanding how cross-attention works in diffusion models is necessary to understand the control mechanism.
  - Quick check question: How does cross-attention differ from standard attention in transformers, and why is it useful for incorporating external conditions in diffusion models?

## Architecture Onboarding

- Component map: POP909 MIDI files -> Preprocessing (quantization, key extraction, phrase labeling) -> Four diffusion models (Form, Reduced Lead Sheet, Lead Sheet, Accompaniment) -> Cross-attention layers for external conditions -> Four levels of hierarchical music representations

- Critical path: 1. Generate Form (top level, unconditional) 2. Generate Reduced Lead Sheet conditioned on Form 3. Generate Lead Sheet conditioned on Reduced Lead Sheet 4. Generate Accompaniment conditioned on Lead Sheet

- Design tradeoffs: Hierarchical decomposition vs. end-to-end generation (cascaded approach reduces parameter count and training complexity but requires careful design of hierarchical levels); Resolution vs. scope (higher-resolution levels have smaller musical scope, requiring autoregressive generation); Pre-trained vs. learned controls (using pre-trained embeddings for external control avoids additional training but depends on quality of pre-trained models)

- Failure signatures: Loss of long-term structure (if conditioning between levels is weak, generated music may lack coherent form); Incoherent local details (if lower-level models don't respect higher-level constraints, generated notes/chords may contradict the intended structure); Ineffective external control (if pre-trained embeddings don't align with model's latent space, user controls may have little effect)

- First 3 experiments: 1. Generate Form only: Verify unconditional generation produces reasonable phrase structures and key progressions. 2. Generate Reduced Lead Sheet conditioned on fixed Form: Verify hierarchical conditioning works and produces musically coherent results. 3. Apply external chord control to Reduced Lead Sheet generation: Verify external control mechanism works and produces expected harmonic changes.

## Open Questions the Paper Calls Out

### Open Question 1
How can the proposed hierarchical language be extended to support longer musical forms beyond pop songs, such as classical symphonies or progressive rock compositions? The paper mentions that the current model supports a maximum generation scope of 256 measures, which is typically adequate for pop songs but insufficient for other genres (e.g., classical music), which may require longer lengths. This remains unresolved as the paper does not provide a clear methodology for scaling the hierarchical language to accommodate longer musical forms.

### Open Question 2
What are the potential improvements to the model's architecture and data training that could address the issue of imperfect endings in generated music? The paper notes that the generated endings are sometimes not ideal, such as failing to resolve on the tonic harmony, and suspects this issue is related to imprecise quantization in the POP909 dataset's outro sections. The paper does not provide specific architectural or training modifications to address this issue.

### Open Question 3
How can the model's control over external representations be further refined to allow for more nuanced and diverse musical outputs? The paper demonstrates the use of pre-trained music embeddings (chord, rhythm, texture) for external control at each hierarchy level, but does not explore the full potential of these controls or discuss methods for creating more granular or diverse controls. This remains unresolved as the paper provides limited examples of external control.

## Limitations

- The specific four-level hierarchy may not represent the optimal decomposition for all musical styles and genres
- Reliance on pre-trained external representations introduces dependencies on third-party models whose compatibility is assumed but not rigorously tested
- The model's maximum generation scope of 256 measures limits its applicability to longer musical forms like classical symphonies

## Confidence

- High confidence: The cascaded diffusion architecture can generate coherent music at multiple hierarchical levels when properly trained
- Medium confidence: The specific four-level hierarchy represents the optimal decomposition for music generation
- Medium confidence: External control via pre-trained embeddings provides meaningful, interpretable manipulation of generated music

## Next Checks

1. Ablation study on hierarchy levels: Remove one or more hierarchical levels and evaluate impact on generation quality to determine if the proposed four-level decomposition is necessary and sufficient

2. Cross-encoder compatibility analysis: Systematically test external control efficacy across different pre-trained encoders to establish which feature representations provide effective steering of generation

3. Long-term coherence evaluation: Generate complete songs (full 256-measure pieces) and analyze structural consistency across all four levels to verify that the top-level Form conditioning maintains coherence throughout the entire piece