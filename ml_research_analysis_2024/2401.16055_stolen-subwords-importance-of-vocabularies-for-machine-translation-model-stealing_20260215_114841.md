---
ver: rpa2
title: 'Stolen Subwords: Importance of Vocabularies for Machine Translation Model
  Stealing'
arxiv_id: '2401.16055'
source_url: https://arxiv.org/abs/2401.16055
tags:
- vocabulary
- victim
- data
- translation
- machine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates whether knowing the victim's subword vocabulary
  in machine translation model stealing scenarios is advantageous, and whether it
  is possible to recover this vocabulary given black-box or gray-box access. The authors
  conduct experiments on English-to-German translation using various datasets and
  show that the choice of subword vocabulary does not significantly impact the performance
  of the stolen model.
---

# Stolen Subwords: Importance of Vocabularies for Machine Translation Model Stealing

## Quick Facts
- arXiv ID: 2401.16055
- Source URL: https://arxiv.org/abs/2401.16055
- Authors: Vilém Zouhar
- Reference count: 16
- Primary result: Gray-box access enables near-complete recovery of victim's subword vocabulary in MT model stealing

## Executive Summary
This paper investigates whether knowledge of a victim's subword vocabulary provides advantages in machine translation model stealing attacks and whether such vocabulary can be recovered through black-box or gray-box access. Through experiments on English-to-German translation across multiple datasets, the authors find that vocabulary choice has minimal impact on stealing performance (average 0.1 BLEU difference), but demonstrate that gray-box access allows for highly accurate vocabulary recovery. The unique-words method achieves up to 98.4% vocabulary overlap with low translation budgets, while black-box access yields significantly lower recovery rates (13.2-33.4%).

## Method Summary
The study explores model stealing scenarios where a local model attempts to replicate a victim model's behavior. Experiments compare student models trained with various vocabulary choices: the victim's actual vocabulary, BPE vocabularies trained on authentic data, and BPE vocabularies trained on the victim's outputs. Vocabulary recovery is tested under black-box conditions (only translations available) and gray-box conditions (subword outputs accessible). The unique-words method involves translating all words that appear only once in a large corpus, while the cyclic backtranslation method starts from a single sentence and iteratively backtranslates to generate new training data.

## Key Results
- Vocabulary choice has minimal impact on model stealing performance (0.1 BLEU difference on average)
- Gray-box access enables highly accurate vocabulary recovery (98.4% overlap for low budgets)
- Black-box access yields significantly lower recovery rates (13.2-33.4% overlap)
- Training on the victim's vocabulary is marginally worse than using domain-specific vocabularies
- Vocabulary recovery effectiveness scales with translation budget in gray-box scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gray-box access to subword outputs enables near-complete vocabulary recovery
- Mechanism: Collecting all subwords from victim's outputs reveals the BPE vocabulary because BPE merges most frequent pairs into the vocabulary
- Core assumption: The victim model outputs subwords directly (not detokenized text)
- Evidence anchors:
  - [abstract] "Given gray-box model access, it is possible to collect the victim's vocabulary by collecting the outputs (detokenized subwords on the output)"
  - [section] "Assuming that the model produces subword outputs (see Table 6), we can simply collect all the subwords that appear in the victim output"
  - [corpus] Weak - no direct corpus evidence provided for this mechanism
- Break condition: If victim outputs detokenized text instead of subwords, or uses different tokenization

### Mechanism 2
- Claim: Training BPE on victim's translated outputs yields vocabulary close to victim's original
- Mechanism: BPE trained on synthetic data (victim's translations) approximates original BPE because both are trained on similar linguistic distributions
- Core assumption: Synthetic data distribution is similar enough to original training data
- Evidence anchors:
  - [section] "We can also train a BPE model on the victims' output... It is only marginally better (57.7%) than training on authentic data"
  - [abstract] "training on the victim's vocabulary is marginally worse than using a BPE vocabulary trained on the relevant domain"
  - [corpus] Weak - no corpus evidence for similarity of distributions
- Break condition: If synthetic data distribution differs significantly from original training data

### Mechanism 3
- Claim: BPE vocabulary choice has minimal impact on model stealing performance
- Mechanism: The subword tokenization method is domain-independent enough that different vocabularies yield similar performance
- Core assumption: Domain-specificity matters more than exact vocabulary matching
- Evidence anchors:
  - [abstract] "we find that the vocabulary itself does not have a large effect on the local model's performance"
  - [section] "training on the victim's vocabulary is marginally worse than using a BPE vocabulary trained on the relevant domain"
  - [corpus] Weak - no corpus evidence for domain independence
- Break condition: If tokenization becomes more domain-sensitive or if exact vocabulary matching becomes critical

## Foundational Learning

- Concept: Byte-Pair Encoding (BPE) tokenization
  - Why needed here: Understanding BPE is crucial as the paper's main focus is on vocabulary recovery and its impact
  - Quick check question: How does BPE reduce vocabulary size and what determines which subwords are added to the vocabulary?

- Concept: Model stealing in NLP
  - Why needed here: The paper explores whether vocabulary knowledge affects model stealing success
  - Quick check question: What distinguishes black-box from gray-box access in model stealing scenarios?

- Concept: BLEU score evaluation
  - Why needed here: BLEU is used to measure translation quality and compare different vocabulary choices
  - Quick check question: How does BLEU score work and what range indicates good translation quality?

## Architecture Onboarding

- Component map: Victim model → Translation query → Output collection → BPE training → Student model training → Performance evaluation
- Critical path: Query budget → Vocabulary recovery → Student model training → BLEU evaluation
- Design tradeoffs: Query budget vs. vocabulary completeness vs. model performance
- Failure signatures: Low vocabulary overlap → Poor student model performance; High BLEU variance across domains
- First 3 experiments:
  1. Train student model with victim's vocabulary vs. domain-specific vocabulary on authentic data
  2. Test vocabulary recovery with black-box access using authentic data
  3. Test vocabulary recovery with gray-box access using both whole sentences and unique words

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of subword vocabulary affect model stealing performance when using different languages or translation tasks?
- Basis in paper: [inferred] The paper focuses on English-to-German translation and mentions plans to replicate findings for other languages and evaluation metrics.
- Why unresolved: The study only explores English-to-German translation, leaving open the question of how results might generalize to other language pairs or translation tasks.
- What evidence would resolve it: Conducting experiments with different language pairs and translation tasks to compare the impact of vocabulary choice on model stealing performance.

### Open Question 2
- Question: What is the impact of using different subword algorithms, such as Byte-level BPE, on model stealing and vocabulary recovery?
- Basis in paper: [explicit] The paper mentions that while it believes other subwording methods would yield similar results, more tokenization-sensitive tasks could show higher dependency on the victim's vocabulary.
- Why unresolved: The study only explores BPE and does not examine the effects of other subword algorithms on model stealing and vocabulary recovery.
- What evidence would resolve it: Conducting experiments with different subword algorithms to compare their impact on model stealing and vocabulary recovery.

### Open Question 3
- Question: How does the size of the subword vocabulary influence the effectiveness of model stealing and vocabulary recovery?
- Basis in paper: [inferred] The paper does not discuss the impact of vocabulary size on model stealing or vocabulary recovery, despite Ding et al. (2019) and Gowda and May (2020) examining the effect of BPE vocabulary size.
- Why unresolved: The study does not explore how varying the size of the subword vocabulary affects model stealing and vocabulary recovery.
- What evidence would resolve it: Conducting experiments with different vocabulary sizes to determine their impact on model stealing and vocabulary recovery.

### Open Question 4
- Question: Can the techniques for inferring the victim's vocabulary be extended to other types of models beyond machine translation?
- Basis in paper: [explicit] The paper focuses on machine translation and subword vocabularies, but does not discuss the applicability of its techniques to other types of models.
- Why unresolved: The study does not explore whether the methods for inferring the victim's vocabulary can be applied to other types of models, such as text classification or summarization.
- What evidence would resolve it: Conducting experiments with different types of models to determine if the techniques for inferring the victim's vocabulary are applicable and effective.

### Open Question 5
- Question: What are the limitations of the cyclic backtranslation approach for vocabulary recovery when starting from a single sentence?
- Basis in paper: [explicit] The paper describes a cyclic backtranslation approach starting from a single sentence but does not provide a detailed analysis of its limitations or performance.
- Why unresolved: The study presents the approach but does not thoroughly analyze its limitations or how well it performs in recovering the victim's vocabulary.
- What evidence would resolve it: Conducting a detailed analysis of the cyclic backtranslation approach, including its limitations, performance metrics, and comparison with other methods.

## Limitations

- Experiments limited to English-to-German translation, raising questions about generalizability to other language pairs
- Focus on low-resource datasets (Europarl, Tatoeba) may not reflect production-scale translation systems
- Assumes victim models output detokenized subwords directly, which may not hold in all deployment scenarios

## Confidence

**High confidence**: The feasibility of vocabulary recovery with gray-box access using the unique-words method. The experimental results show consistent high overlap percentages (98.4% for low budgets) with relatively small standard deviations across multiple trials.

**Medium confidence**: The claim that vocabulary choice has minimal impact on stealing performance. While statistically supported within the tested datasets, the practical significance may vary with domain complexity and translation quality requirements.

**Low confidence**: The generalizability of results to other language pairs, larger datasets, and production-scale models. The paper's scope is limited to specific experimental conditions that may not reflect real-world deployment scenarios.

## Next Checks

1. **Cross-linguistic validation**: Replicate experiments with high-resource language pairs (e.g., English-French, English-Chinese) and morphologically rich languages to assess vocabulary recovery effectiveness across different linguistic structures.

2. **Defense mechanism testing**: Evaluate simple countermeasures like output tokenization variations, subword masking, or rate limiting to quantify their effectiveness against vocabulary recovery attacks.

3. **Scalability assessment**: Test vocabulary recovery and stealing performance on larger datasets (millions of sentence pairs) and larger model architectures (e.g., 100M+ parameters) to determine if results hold at production scales.