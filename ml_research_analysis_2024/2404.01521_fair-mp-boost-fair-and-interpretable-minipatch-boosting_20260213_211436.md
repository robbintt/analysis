---
ver: rpa2
title: 'Fair MP-BOOST: Fair and Interpretable Minipatch Boosting'
arxiv_id: '2404.01521'
source_url: https://arxiv.org/abs/2404.01521
tags:
- fairness
- accuracy
- feature
- features
- fair
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper develops Fair MP-Boost, a fair and interpretable minipatch
  boosting algorithm that adaptively learns features and observations during training
  to balance fairness and accuracy. The method introduces adaptive sampling schemes
  for both observations and features based on loss functions and feature importance
  scores, allowing the algorithm to prioritize important and fair features along with
  challenging instances.
---

# Fair MP-BOOST: Fair and Interpretable Minipatch Boosting

## Quick Facts
- **arXiv ID**: 2404.01521
- **Source URL**: https://arxiv.org/abs/2404.01521
- **Authors**: Camille Olivia Little; Genevera I. Allen
- **Reference count**: 18
- **Primary result**: Develops Fair MP-Boost, a fair and interpretable minipatch boosting algorithm that adaptively learns features and observations during training to balance fairness and accuracy.

## Executive Summary
This paper introduces Fair MP-Boost, a novel boosting algorithm designed to simultaneously achieve high accuracy and fairness while maintaining interpretability. The method uses adaptive sampling of both observations and features based on loss functions and feature importance scores, allowing dynamic prioritization of important and fair features along with challenging instances. By learning probability distributions for sampling, the algorithm provides intrinsic interpretations of feature importance and important observations. The approach is evaluated on both simulated and benchmark datasets, demonstrating superior performance compared to state-of-the-art bias mitigation algorithms in terms of both fairness metrics and accuracy, particularly when fairness is prioritized.

## Method Summary
Fair MP-Boost is a minipatch boosting algorithm for binary classification that adaptively learns observation and feature sampling probabilities during training. The algorithm maintains two probability distributions: p for observation sampling and q for feature sampling. At each iteration, p is updated based on a weighted combination of accuracy loss (LA) and fairness loss (LF), controlled by hyperparameter α. Similarly, q is updated using a weighted combination of TreeFIS (MDI) for accuracy and FairTreeFIS for fairness, with a learning rate µ controlling the exploration-exploitation tradeoff. After a burn-in phase, the average feature and observation sampling probabilities provide intrinsic interpretations of feature importance and important observations.

## Key Results
- Fair MP-Boost achieves high accuracy and fairness while maintaining interpretability through learned probability distributions.
- When fairness is prioritized (α = 0.9), the algorithm significantly outperforms state-of-the-art bias mitigation methods in fairness metrics while maintaining comparable accuracy.
- The learned probability distributions provide intrinsic interpretations of feature importance and important observations in the model.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Adaptive sampling of observations and features based on loss functions and feature importance scores allows Fair MP-Boost to balance fairness and accuracy dynamically during training.
- **Mechanism**: The algorithm maintains two probability distributions: p for observation sampling and q for feature sampling. At each iteration, p is updated based on a weighted combination of accuracy loss (LA) and fairness loss (LF), where the weights are controlled by hyperparameter α. Similarly, q is updated using a weighted combination of TreeFIS (MDI) for accuracy and FairTreeFIS for fairness, with a learning rate µ controlling the exploration-exploitation tradeoff.
- **Core assumption**: The observation and feature importance metrics (LA, LF, TreeFIS, FairTreeFIS) accurately reflect the contribution of each observation and feature to the overall fairness and accuracy of the model.
- **Evidence anchors**:
  - [abstract]: "We devise these probabilities by combining loss functions, or by combining feature importance scores to address accuracy and fairness simultaneously."
  - [section]: "Let LA : R × R → R+ be a function that measures the similarity between the ensemble outputs and labels... The fairness-focused observation update is a bit trickier because the fairness of a single observation cannot explicitly be measured using common group fairness measures."
  - [corpus]: Weak - no direct evidence in the corpus about adaptive sampling mechanisms.
- **Break condition**: If the loss functions or feature importance metrics do not accurately capture the contribution to fairness and accuracy, the adaptive sampling may prioritize suboptimal observations or features.

### Mechanism 2
- **Claim**: The learned probability distributions yield intrinsic interpretations of feature importance and important observations.
- **Mechanism**: After a burn-in phase when the probabilities have stabilized, the average feature and observation sampling probabilities are calculated. These averages represent the intrinsic importance of each feature and observation for balancing fairness and accuracy in the model.
- **Core assumption**: The stabilized sampling probabilities after the burn-in phase accurately reflect the long-term importance of each feature and observation.
- **Evidence anchors**:
  - [abstract]: "The learned probability distributions also yield intrinsic interpretations of feature importance and important observations in Fair MP-Boost."
  - [section]: "Finally, our novel adaptively learned observation and feature sampling probabilities also yield intrinsic interpretations of leverage points and feature importance scores respectively."
  - [corpus]: Weak - no direct evidence in the corpus about using probability distributions for interpretation.
- **Break condition**: If the burn-in phase is not long enough or the probabilities do not stabilize, the average probabilities may not accurately reflect the true importance of features and observations.

### Mechanism 3
- **Claim**: Fair MP-Boost outperforms state-of-the-art bias mitigation algorithms in terms of both fairness metrics and accuracy, particularly when fairness is prioritized.
- **Mechanism**: The algorithm achieves this by adaptively learning which features and observations to prioritize based on their contribution to fairness and accuracy. When α is set to prioritize fairness, the algorithm focuses on sampling features and observations that improve fairness metrics while maintaining reasonable accuracy.
- **Core assumption**: The adaptive learning of features and observations based on fairness and accuracy metrics leads to better overall performance compared to other methods that do not dynamically adjust their sampling.
- **Evidence anchors**:
  - [abstract]: "Compared to state-of-the-art bias mitigation algorithms, Fair MP-Boost outperforms in terms of both fairness metrics and accuracy, particularly when fairness is prioritized."
  - [section]: "When fairness is prioritized ( α = 0 .9), FAIR MP-B OOST significantly outperforms all other methods in terms of fairness, while still achieving comparable accuracy in comparison to other methods."
  - [corpus]: Weak - no direct evidence in the corpus about comparative performance.
- **Break condition**: If the adaptive learning mechanism does not effectively prioritize the right features and observations, or if other methods have superior bias mitigation techniques, Fair MP-Boost may not outperform them.

## Foundational Learning

- **Concept**: Group fairness and Demographic Parity
  - **Why needed here**: The paper focuses on achieving Demographic Parity, a specific form of group fairness, by ensuring predictions are independent of the protected attribute.
  - **Quick check question**: What is the mathematical definition of Demographic Parity, and how does it relate to the independence of predictions and the protected attribute?

- **Concept**: Adaptive sampling and probability distributions
  - **Why needed here**: Fair MP-Boost uses adaptive sampling of observations and features based on learned probability distributions to balance fairness and accuracy during training.
  - **Quick check question**: How are the observation and feature sampling probabilities updated at each iteration, and what role does the hyperparameter α play in this process?

- **Concept**: Feature importance metrics (MDI and FairTreeFIS)
  - **Why needed here**: The algorithm uses TreeFIS (MDI) for accuracy and FairTreeFIS for fairness to determine the importance of each feature in contributing to the model's performance.
  - **Quick check question**: What is the difference between TreeFIS (MDI) and FairTreeFIS, and how do they contribute to the adaptive feature sampling in Fair MP-Boost?

## Architecture Onboarding

- **Component map**: Input dataset -> Minipatch Sampling (adaptive) -> Tree Learning -> Ensemble Update -> Probability Update -> Output model with interpretability
- **Critical path**:
  1. Initialize uniform observation and feature sampling probabilities
  2. Iteratively sample minipatches, fit trees, update ensemble, and update probabilities
  3. Calculate average feature and observation sampling probabilities after burn-in phase
  4. Output the final ensemble model and interpretability results
- **Design tradeoffs**:
  - Accuracy vs. Fairness: The hyperparameter α controls the tradeoff between prioritizing accuracy and fairness in the adaptive sampling process
  - Exploration vs. Exploitation: The learning rate µ determines the balance between exploring new features and exploiting known important features
  - Minipatch Size: The size of the sampled subsets (n and m) affects the strength of the weak learners and the computational efficiency
- **Failure signatures**:
  - If the model fails to improve fairness without sacrificing accuracy, the adaptive sampling mechanism may not be effectively prioritizing the right features and observations
  - If the interpretability results do not align with known feature importance, the learned probability distributions may not accurately reflect the true importance of features and observations
  - If the model overfits or underfits, the burn-in phase or minipatch size may need adjustment
- **First 3 experiments**:
  1. Run Fair MP-Boost on a simple simulated dataset with known feature importance and fairness characteristics to validate the adaptive sampling and interpretability mechanisms
  2. Compare the performance of Fair MP-Boost with different α values on a benchmark dataset to assess the tradeoff between accuracy and fairness
  3. Analyze the learned feature and observation sampling probabilities on a real-world dataset to interpret the model's decision-making process and identify potential biases

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the choice of the hyperparameter α impact the trade-off between accuracy and fairness across different datasets and application domains?
- **Basis in paper**: [explicit] The paper discusses α as a hyperparameter controlling the balance between accuracy and fairness, with α = 0 prioritizing accuracy and α = 1 prioritizing fairness.
- **Why unresolved**: The paper provides empirical results for specific values of α but does not systematically explore the full range of α values or their effects across diverse datasets and domains.
- **What evidence would resolve it**: Comprehensive experiments varying α across multiple datasets and domains, analyzing the resulting accuracy-fairness trade-offs, and identifying optimal α values for different scenarios.

### Open Question 2
- **Question**: How does the size of the minipatches (m and n) affect the performance and interpretability of Fair MP-Boost in terms of accuracy, fairness, and computational efficiency?
- **Basis in paper**: [explicit] The paper mentions that the minipatch size is a critical hyperparameter, with n = √N and m = √M suggested based on boosting inspiration.
- **Why unresolved**: The paper does not provide a systematic analysis of how different minipatch sizes impact the algorithm's performance, interpretability, or computational requirements.
- **What evidence would resolve it**: Empirical studies varying minipatch sizes across datasets, evaluating the resulting accuracy, fairness, interpretability, and computational costs to determine optimal minipatch sizes for different scenarios.

### Open Question 3
- **Question**: How does Fair MP-Boost compare to other fairness-aware ensemble methods, such as fairness-aware random forests or fairness-aware gradient boosting machines, in terms of accuracy, fairness, and interpretability?
- **Basis in paper**: [inferred] The paper compares Fair MP-Boost to several boosting and bias mitigation methods but does not include comparisons to fairness-aware ensemble methods like fairness-aware random forests or gradient boosting machines.
- **Why unresolved**: The paper's empirical comparisons are limited to a subset of existing methods, leaving the relative performance of Fair MP-Boost compared to other fairness-aware ensemble methods unexplored.
- **What evidence would resolve it**: Comprehensive experiments comparing Fair MP-Boost to fairness-aware random forests and gradient boosting machines across multiple datasets and fairness metrics, analyzing their respective accuracy, fairness, and interpretability.

## Limitations
- The core adaptive sampling mechanism relies on the assumption that loss functions and feature importance metrics accurately capture the contribution of observations and features to fairness and accuracy, but this assumption is not directly validated.
- The hyperparameter tuning procedure for µ and minipatch sizes is not fully specified, which could impact reproducibility.
- While comparative performance is claimed, detailed ablations showing the individual contribution of each mechanism to the overall results are lacking.

## Confidence

- **Mechanism 1 (Adaptive sampling based on loss functions)**: Medium - Core assumption about metric accuracy not directly validated
- **Mechanism 2 (Interpretability through probability distributions)**: Medium - Burn-in phase effectiveness not empirically demonstrated
- **Mechanism 3 (Superior performance vs state-of-the-art)**: Low - Comparative results mentioned but detailed analysis missing

## Next Checks

1. Validate that the learned feature sampling probabilities align with known feature importance on datasets with ground truth feature relevance.
2. Conduct an ablation study to isolate the contribution of adaptive sampling versus fixed sampling strategies to overall fairness and accuracy.
3. Perform a sensitivity analysis on hyperparameter α to quantify the precise tradeoff between accuracy and fairness improvements.