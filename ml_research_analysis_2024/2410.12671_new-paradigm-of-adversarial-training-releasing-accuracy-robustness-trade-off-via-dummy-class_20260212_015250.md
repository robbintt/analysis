---
ver: rpa2
title: 'New Paradigm of Adversarial Training: Releasing Accuracy-Robustness Trade-Off
  via Dummy Class'
arxiv_id: '2410.12671'
source_url: https://arxiv.org/abs/2410.12671
tags:
- adversarial
- ducat
- training
- robustness
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new adversarial training (AT) paradigm
  by incorporating dummy classes, addressing the accuracy-robustness trade-off inherent
  in conventional AT methods. The core idea is that the assumption of assigning adversarial
  samples to the same class as their benign counterparts is overly strict.
---

# New Paradigm of Adversarial Training: Releasing Accuracy-Robustness Trade-Off via Dummy Class

## Quick Facts
- **arXiv ID**: 2410.12671
- **Source URL**: https://arxiv.org/abs/2410.12671
- **Reference count**: 40
- **Primary result**: Introduces DUCAT method using dummy classes and two-hot soft labels to relax hard label assignment, achieving 88.81% clean accuracy and 58.61% robustness on CIFAR-10 under Auto-Attack

## Executive Summary
This paper proposes a novel adversarial training paradigm that addresses the accuracy-robustness trade-off by introducing dummy classes and a two-hot soft label strategy. The core insight is that conventional adversarial training's assumption of assigning adversarial samples to their original class is overly strict. By relaxing this constraint through dummy classes, the method achieves significant improvements in both clean accuracy and adversarial robustness. The DUCAT framework demonstrates state-of-the-art performance on standard benchmarks, challenging the traditional view that adversarial robustness must come at the cost of clean accuracy.

## Method Summary
The proposed DUCAT method introduces dummy classes into the adversarial training framework to relax the hard label assignment assumption. During training, benign samples maintain their original one-hot labels while adversarial samples are assigned using a two-hot soft label strategy that includes both the original class and dummy classes. This approach allows the model to learn more flexible decision boundaries that can accommodate both clean and adversarial samples without forcing adversarial examples into their original class space. The method is compatible with existing adversarial training techniques like PGD-AT and Cons-AT, and demonstrates significant improvements in the accuracy-robustness trade-off.

## Key Results
- DUCAT with PGD-AT achieves 88.81% clean accuracy and 58.61% robustness on CIFAR-10 under Auto-Attack
- DUCAT with Cons-AT shows similar improvements, demonstrating the method's compatibility with different adversarial training approaches
- The method consistently outperforms state-of-the-art adversarial training techniques on both CIFAR-10 and CIFAR-100 datasets
- DUCAT successfully releases the traditional accuracy-robustness trade-off observed in conventional adversarial training

## Why This Works (Mechanism)
The fundamental mechanism behind DUCAT's success lies in relaxing the overly strict assumption that adversarial samples must be classified into their original benign class. In conventional adversarial training, this constraint forces the model to learn decision boundaries that are too rigid, leading to the accuracy-robustness trade-off. By introducing dummy classes and using two-hot soft labels, DUCAT allows the model to learn more flexible decision boundaries that can accommodate both clean samples (assigned to their true classes) and adversarial samples (assigned to dummy classes or their original classes based on proximity). This flexibility enables the model to achieve both high clean accuracy and strong adversarial robustness simultaneously.

## Foundational Learning
- **Adversarial Training (AT)**: Training neural networks to be robust against adversarial attacks by incorporating adversarial examples during training. Why needed: Provides the foundation for understanding the accuracy-robustness trade-off that DUCAT addresses.
- **Hard vs. Soft Labels**: Hard labels use one-hot encoding while soft labels allow probability distributions. Why needed: DUCAT's two-hot soft label strategy is central to its mechanism.
- **Decision Boundary Flexibility**: The ability of a model to adapt its classification boundaries based on different input types. Why needed: DUCAT's core innovation is creating more flexible decision boundaries through dummy classes.

## Architecture Onboarding
**Component Map**: Benign Samples -> One-Hot Labels -> Original Classes; Adversarial Samples -> Two-Hot Soft Labels -> Original Classes + Dummy Classes

**Critical Path**: During each training iteration, benign samples are processed with standard one-hot labels, while adversarial samples (generated via attack method) are assigned two-hot soft labels that include both the original class and dummy classes. The model is trained on both types of samples simultaneously, learning to distinguish between clean and adversarial patterns.

**Design Tradeoffs**: The number and placement of dummy classes represent a key design decision. Too few dummy classes may not sufficiently relax the hard label constraint, while too many may dilute the learning signal. The optimal configuration likely depends on dataset complexity and model architecture.

**Failure Signatures**: If dummy classes are poorly placed or too few in number, the model may still struggle with the accuracy-robustness trade-off. If too many dummy classes are used, the model may become confused about classification boundaries, leading to decreased performance on both clean and adversarial samples.

**First Experiments**: 1) Test different numbers of dummy classes (1, 2, 3, 5) to find optimal configuration. 2) Compare performance when dummy classes are initialized randomly vs. strategically placed. 3) Evaluate DUCAT on a simple binary classification task before scaling to complex datasets.

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- The theoretical justification for dummy class placement and optimal number selection across different datasets remains underdeveloped
- Experimental validation is limited to small-scale image datasets (CIFAR-10 and CIFAR-100), with performance on larger or non-image datasets unexplored
- Computational overhead from additional dummy classes and two-hot soft label strategy is not extensively analyzed

## Confidence
- **High Confidence**: The core concept of relaxing hard label assignment in adversarial training is theoretically sound and well-motivated
- **Medium Confidence**: Empirical results on CIFAR-10 and CIFAR-100 demonstrate significant improvements, but performance on larger or non-image datasets is uncertain
- **Low Confidence**: Optimal configuration of dummy classes (number, placement, initialization) for different tasks is not well-established

## Next Checks
1. Evaluate DUCAT on larger-scale datasets (e.g., ImageNet) and non-image domains (e.g., text or tabular data) to assess scalability and generalizability
2. Conduct detailed analysis of computational overhead including memory usage and training time impact
3. Perform ablation studies to determine optimal number and placement of dummy classes for different datasets and model architectures