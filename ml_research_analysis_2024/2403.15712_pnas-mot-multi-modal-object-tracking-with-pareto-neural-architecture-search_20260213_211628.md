---
ver: rpa2
title: 'PNAS-MOT: Multi-Modal Object Tracking with Pareto Neural Architecture Search'
arxiv_id: '2403.15712'
source_url: https://arxiv.org/abs/2403.15712
tags:
- tracking
- latency
- object
- search
- ieee
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of efficient multiple object
  tracking (MOT) in autonomous driving by proposing a latency-constrained neural architecture
  search (NAS) method that jointly optimizes accuracy and real-time performance. The
  approach uses a Pareto optimization scheme to search for efficient network architectures
  that balance tracking accuracy with low latency, while also integrating multi-modal
  fusion of image and LiDAR data to improve robustness.
---

# PNAS-MOT: Multi-Modal Object Tracking with Pareto Neural Architecture Search

## Quick Facts
- arXiv ID: 2403.15712
- Source URL: https://arxiv.org/abs/2403.15712
- Reference count: 40
- Achieves 89.59% MOTA accuracy with latency below 80ms on edge devices

## Executive Summary
This paper addresses the challenge of efficient multiple object tracking (MOT) in autonomous driving by proposing a latency-constrained neural architecture search (NAS) method that jointly optimizes accuracy and real-time performance. The approach uses a Pareto optimization scheme to search for efficient network architectures that balance tracking accuracy with low latency, while also integrating multi-modal fusion of image and LiDAR data to improve robustness. Experiments on the KITTI benchmark demonstrate that the proposed method achieves state-of-the-art accuracy while maintaining real-time performance on resource-constrained edge devices.

## Method Summary
The method employs a two-stage Pareto optimization framework for latency-constrained NAS, searching for optimal network architectures that balance tracking accuracy with real-time performance requirements. It integrates a multi-modal fusion approach combining image and LiDAR data through a learned weighted feature mechanism that dynamically assigns importance based on sensor reliability. The tracking pipeline follows a tracking-by-detection paradigm with correlation features and adjacency estimation, solved via linear programming optimization. The entire framework is designed to run efficiently on edge devices like the Jetson Nano with minimal memory footprint.

## Key Results
- Achieves 89.59% MOTA accuracy close to state-of-the-art while maintaining latency below 80ms
- Runs efficiently on resource-constrained devices (Jetson Nano with 2GB memory)
- Demonstrates significant latency reduction compared to existing multi-modal MOT approaches
- Maintains competitive accuracy across various hardware platforms including Jetson Orin Nano, GTX, Quadro, and TITAN

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pareto optimization effectively balances latency and accuracy by finding the optimal trade-off frontier.
- Mechanism: The method searches for network architectures that lie on the Pareto frontier, ensuring no other architecture can improve accuracy without increasing latency, or vice versa.
- Core assumption: The search space contains architectures that can achieve acceptable accuracy-latency trade-offs.
- Evidence anchors:
  - [abstract]: "We propose a Pareto optimization scheme to find the optimal Pareto frontier for the best trade-off between latency and accuracy."
  - [section]: "We aim to find an optimal DNN that suits the latency accuracy trade-off. To achieve this trade-off, we design a two-stage Pareto optimization scheme."
  - [corpus]: Weak evidence. No directly relevant papers found in corpus.
- Break condition: If the search space is too limited or the Pareto frontier doesn't contain architectures meeting both latency and accuracy requirements.

### Mechanism 2
- Claim: Multi-modal fusion improves robustness by combining complementary sensor information.
- Mechanism: The framework integrates features from both image and LiDAR sensors, assigning greater significance to LiDAR when cameras fail and vice versa, enhancing tracking reliability in challenging conditions.
- Core assumption: Image and LiDAR sensors provide complementary information that can compensate for each other's weaknesses.
- Evidence anchors:
  - [abstract]: "we propose a multi-modal framework to improve the robustness. Through a learned weighted feature fusion mechanism, the framework assigns greater significance to LiDAR point cloud features when cameras encounter difficulties or fail, and vice versa."
  - [section]: "By combining features derived from diverse modalities, it offers a potent strategy to mitigate the limitations inherent in single-modality approaches in Multiple Object Tracking (MOT) tasks, including issues related to mismatching and unreliability."
  - [corpus]: Weak evidence. No directly relevant papers found in corpus.
- Break condition: If the sensors fail simultaneously or the fusion mechanism cannot effectively weight the modalities based on their reliability.

### Mechanism 3
- Claim: Hardware latency estimation enables efficient NAS by predicting network performance on target devices.
- Mechanism: The method estimates latency for different network configurations on specific hardware platforms, allowing the search to focus on architectures that meet real-time constraints.
- Core assumption: Latency can be accurately estimated from operation-level measurements and network architecture.
- Evidence anchors:
  - [section]: "To enable efficient NAS, we need to estimate the latency of the network architecture on specific hardware platforms. We test the latency of different operations... The time spent is recorded by a preset timer... we obtain a dictionary of the average latency per iteration for every operation with different configurations."
  - [section]: "The architecture encoding αi for each operation opi... can be obtained through a Softmax function, then the estimated latency can be obtained from a weighted sum."
  - [corpus]: Weak evidence. No directly relevant papers found in corpus.
- Break condition: If the latency estimation is inaccurate or the hardware platform changes significantly from the one used for measurements.

## Foundational Learning

- Concept: Neural Architecture Search (NAS)
  - Why needed here: NAS automates the design of efficient neural networks for the MOT task, balancing accuracy and latency without manual heuristic design.
  - Quick check question: What are the main categories of NAS methods mentioned in the related work?

- Concept: Multi-modal sensor fusion
  - Why needed here: Combining image and LiDAR data improves tracking robustness by compensating for individual sensor limitations.
  - Quick check question: What are the advantages and disadvantages of using only image or only LiDAR data for MOT?

- Concept: Pareto optimization
  - Why needed here: Pareto optimization finds the optimal trade-off between competing objectives (latency and accuracy) by identifying the Pareto frontier.
  - Quick check question: What is the Pareto frontier in the context of multi-objective optimization?

## Architecture Onboarding

- Component map:
  Input → Detector → Image/LiDAR Encoders → Fusion Module → Correlation → Adjacent Estimator → Linear Programming → Output

- Critical path:
  Input → Detector → Image/LiDAR Encoders → Fusion Module → Correlation → Adjacent Estimator → Linear Programming → Output

- Design tradeoffs:
  - Accuracy vs. Latency: The Pareto optimization balances these competing objectives.
  - Sensor Modality Weighting: The fusion module learns to weight image and LiDAR features based on their reliability.
  - Network Architecture Complexity: The NAS searches for efficient architectures that meet latency constraints.

- Failure signatures:
  - High latency on target device: Indicates the architecture is too complex or the latency estimation is inaccurate.
  - Poor tracking accuracy: Suggests the fusion mechanism is not effectively combining sensor information or the architecture search is not finding suitable networks.
  - Memory issues on edge devices: Implies the searched architecture is too large for the target device's memory.

- First 3 experiments:
  1. Run the pretrained model on the Jetson Nano to verify it meets the <80ms latency constraint.
  2. Evaluate the model's tracking accuracy on the KITTI validation set to confirm the ~90% MOTA performance.
  3. Analyze the latency breakdown on different hardware platforms to understand where optimizations can be made.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the proposed latency-constrained NAS approach perform on more diverse and challenging autonomous driving datasets beyond KITTI, such as nuScenes or Waymo Open Dataset?
- Basis in paper: [inferred] The paper primarily evaluates the method on the KITTI benchmark and mentions potential for broader application but does not explore performance on other datasets.
- Why unresolved: The paper does not provide empirical evidence or discussion on how the method scales or adapts to different datasets with varying sensor modalities, object densities, or environmental conditions.
- What evidence would resolve it: Experiments and comparative results on additional autonomous driving datasets like nuScenes or Waymo Open Dataset, demonstrating performance, latency, and robustness across diverse scenarios.

### Open Question 2
- Question: What is the impact of different sensor fusion strategies (e.g., early fusion vs. late fusion) on the accuracy-latency trade-off in the proposed multi-modal MOT framework?
- Basis in paper: [inferred] The paper describes a learned weighted feature fusion mechanism but does not extensively compare it with alternative fusion strategies or analyze their impact on the accuracy-latency trade-off.
- Why unresolved: The paper does not provide a systematic comparison of different fusion strategies or their effects on the model's performance and efficiency.
- What evidence would resolve it: Ablation studies or experiments comparing various sensor fusion strategies (early, late, or intermediate fusion) and their influence on accuracy, latency, and resource utilization.

### Open Question 3
- Question: How does the proposed method handle scenarios with significant occlusions or sensor failures, and what are the limitations of the multi-modal fusion approach in such cases?
- Basis in paper: [explicit] The paper mentions the integration of multi-modal fusion to improve robustness but does not provide detailed analysis or empirical evidence on handling occlusions or sensor failures.
- Why unresolved: The paper does not discuss specific strategies or limitations for dealing with challenging scenarios like occlusions or sensor malfunctions, nor does it provide quantitative results on performance under such conditions.
- What evidence would resolve it: Detailed experiments and analysis on the model's performance in scenarios with significant occlusions or sensor failures, including metrics on accuracy, latency, and robustness under these conditions.

## Limitations
- The hardware latency estimation method lacks detailed implementation specifications, making exact reproduction challenging
- The correlation feature calculation and adjacency estimator components are referenced from external work without full algorithmic details
- The method's performance on datasets beyond KITTI has not been evaluated, limiting generalizability claims

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Multi-modal fusion mechanism effectiveness | High |
| Pareto optimization framework soundness | Medium |
| Hardware latency estimation implementation | Low |
| Correlation and adjacency estimation components | Low |

## Next Checks

1. **Latency Estimation Validation**: Implement the latency estimation method and verify its accuracy on multiple hardware platforms by comparing estimated vs. measured latencies for various network architectures.

2. **Search Space Analysis**: Examine the search space used in the NAS to ensure it contains architectures capable of achieving the desired accuracy-latency trade-off, and verify the convergence of the Pareto optimization.

3. **Multi-Modal Fusion Effectiveness**: Conduct ablation studies to quantify the contribution of each sensor modality to the overall tracking performance, and test the system's robustness under different failure scenarios (e.g., camera occlusion, LiDAR dropout).