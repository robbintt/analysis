---
ver: rpa2
title: Verification of Neural Networks' Global Robustness
arxiv_id: '2402.19322'
source_url: https://arxiv.org/abs/2402.19322
tags:
- vhagar
- bound
- robustness
- input
- network
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of verifying global robustness
  properties for neural network classifiers. The authors propose a new global robustness
  property for classifiers and introduce VHAGaR, an anytime verifier for computing
  the minimal globally robust bound.
---

# Verification of Neural Networks' Global Robustness

## Quick Facts
- arXiv ID: 2402.19322
- Source URL: https://arxiv.org/abs/2402.19322
- Authors: Anan Kabaha; Dana Drachsler-Cohen
- Reference count: 14
- Key outcome: Introduces VHAGaR, an anytime verifier for computing minimal globally robust bounds, achieving 1.9 average gap between lower/upper bounds vs 154.7 for existing approaches

## Executive Summary
This paper addresses the challenge of verifying global robustness properties for neural network classifiers - ensuring that a classifier maintains robustness across all possible inputs, not just specific examples. The authors introduce VHAGaR, a novel verifier that computes the minimal globally robust bound by combining mixed-integer programming (MIP) encoding with pruning strategies and hyper-adversarial attacks. VHAGaR significantly outperforms existing approaches in both accuracy and efficiency, with an average gap between lower and upper bounds of 1.9 compared to 154.7 for previous methods.

## Method Summary
VHAGaR computes the minimal globally robust bound for neural network classifiers by encoding the verification problem as a mixed-integer programming (MIP) task. The method employs three key innovations: encoding the network twice (input and perturbed) with linear/quadratic constraints to reduce complexity, computing dependencies between input and perturbed networks to prune the search space, and generalizing adversarial attacks to unknown inputs through hyper-adversarial attacks. The approach is evaluated on MNIST, Fashion-MNIST, and CIFAR-10 datasets with various semantic perturbations including brightness, contrast, occlusion, patches, translation, and rotation.

## Key Results
- VHAGaR achieves an average gap of 1.9 between lower and upper bounds compared to 154.7 for existing verifiers
- Computation time is significantly reduced, with VHAGaR running 36.4x faster than existing approaches on average
- The method scales to networks with up to 2730 neurons while maintaining practical verification times

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MIP encoding with two network copies reduces complexity via linear and quadratic constraints
- Mechanism: VHAGaR encodes the network twice (input and perturbed) and adds constraints from perturbations that relate corresponding variables, reducing the number of boolean variables
- Core assumption: Dependencies identified from perturbations can be expressed as linear/quadratic constraints and added to the MIP encoding
- Evidence anchors: [abstract] "encoding the problem as a mixed-integer programming and pruning the search space by identifying dependencies stemming from the perturbation or network computation"; [section] "Many perturbations impose relations expressible as linear or quadratic constraints over the input and its perturbed example."

### Mechanism 2
- Claim: Hyper-adversarial attacks provide feasible solutions and optimization hints to guide the MIP solver
- Mechanism: VHAGaR runs a PGD-based attack over a hyper-input (set of inputs with diverse confidences) to find inputs with adversarial examples, providing lower bounds and boolean variable hints
- Core assumption: Inputs with a wide range of class confidences allow the attack to converge faster to high-confidence feasible solutions
- Evidence anchors: [abstract] "generalizing adversarial attacks to unknown inputs"; [section] "Unlike existing adversarial attacks, a hyper-adversarial attack does not look for a perturbation that causes misclassification but rather for inputs that have perturbations that cause misclassification."

### Mechanism 3
- Claim: Anytime optimization via MIP solver enables tight upper/lower bounds within practical timeouts
- Mechanism: VHAGaR formulates Problem 2 (maximizing non-robust bound) as a MIP and uses Gurobi's bound tightening to compute [δL, δU] intervals
- Core assumption: The MIP solver can handle the exponential complexity via bound propagation and pruning
- Evidence anchors: [abstract] "VHAGaR relies on three main ideas: encoding the problem as a mixed-integer programming and pruning the search space by identifying dependencies stemming from the perturbation or network computation and generalizing adversarial attacks to unknown inputs."; [section] "VHAGaR solves Problem 2 by encoding the problem as a MIP problem (the exact encoding is provided in Section 5.1) and then submitting it to a MIP solver."

## Foundational Learning

- Concept: Mixed-Integer Programming (MIP) and bound propagation
  - Why needed here: VHAGaR relies on MIP solvers to encode and solve the global robustness problem efficiently
  - Quick check question: What is the role of boolean variables in the MIP encoding of neural network verification?

- Concept: Adversarial attacks and PGD optimization
  - Why needed here: VHAGaR uses a hyper-adversarial attack to find feasible solutions and optimization hints for the MIP solver
  - Quick check question: How does a hyper-adversarial attack differ from standard adversarial attacks in terms of input handling?

- Concept: Local vs. global robustness in neural networks
  - Why needed here: VHAGaR extends the concept of local robustness to global robustness over all inputs
  - Quick check question: Why does local robustness fail to guarantee robustness for unseen inputs?

## Architecture Onboarding

- Component map:
  - MIP Encoding: Encodes network computation and perturbations as linear constraints
  - Dependency Computation: Identifies and adds constraints between input and perturbed networks
  - Hyper-Adversarial Attack: Generates feasible solutions and optimization hints
  - MIP Solver: Solves the MIP problem and tightens bounds

- Critical path:
  1. Encode network and perturbations as MIP
  2. Compute dependencies to prune search space
  3. Run hyper-adversarial attack for lower bound and hints
  4. Submit MIP to solver with bounds and hints
  5. Return tightened [δL, δU] interval

- Design tradeoffs:
  - Accuracy vs. runtime: Tightening bounds requires more solver time
  - Completeness vs. scalability: Encoding all dependencies is expensive; VHAGaR selectively computes them
  - Parallelization: Hyper-adversarial attack runs on GPU while MIP encoding runs on CPU

- Failure signatures:
  - MIP solver times out without tightening bounds
  - Hyper-adversarial attack fails to find feasible solutions
  - Dependencies are too sparse to prune effectively

- First 3 experiments:
  1. Run VHAGaR on a small fully-connected MNIST network with L∞ perturbation; verify that δL ≈ δU
  2. Disable dependency computation and compare runtime to full VHAGaR; check if bounds degrade
  3. Disable hyper-adversarial attack and verify that lower bounds are looser; check impact on solver convergence

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does VHAGaR scale to larger, more complex neural networks like those used in state-of-the-art computer vision tasks?
- Basis in paper: [explicit] The paper evaluates VHAGaR on small networks (e.g., MNIST conv1 with 550 neurons) and notes that these are an order of magnitude larger than those analyzed by Reluplex, but much smaller than networks analyzed by existing local robustness verifiers
- Why unresolved: The paper does not provide empirical evidence or theoretical analysis of VHAGaR's scalability to larger networks
- What evidence would resolve it: Experiments evaluating VHAGaR on larger, state-of-the-art networks would provide empirical evidence. Theoretical analysis of the algorithm's complexity and potential optimizations would also help

### Open Question 2
- Question: How does VHAGaR perform on real-world datasets beyond MNIST, Fashion-MNIST, and CIFAR-10, which are commonly used in research but may not fully represent the complexity of real-world data?
- Basis in paper: [explicit] The paper evaluates VHAGaR on MNIST, Fashion-MNIST, and CIFAR-10 datasets
- Why unresolved: The paper does not evaluate VHAGaR on real-world datasets with higher complexity and noise
- What evidence would resolve it: Experiments evaluating VHAGaR on real-world datasets, such as ImageNet or medical imaging data, would provide insights into its performance on more complex data

### Open Question 3
- Question: How can VHAGaR be extended to handle other types of perturbations beyond the ones currently supported (e.g., adversarial patches, generative adversarial network-based attacks)?
- Basis in paper: [explicit] The paper supports six semantic feature perturbations and the L∞ perturbation, but mentions that the approach is easily extensible to other layers such as max pooling layers and residual layers
- Why unresolved: The paper does not provide a detailed analysis of how VHAGaR can be extended to handle other types of perturbations
- What evidence would resolve it: A detailed analysis of the challenges and potential solutions for extending VHAGaR to handle other types of perturbations would provide insights into its extensibility

## Limitations
- Dependency computation relies on perturbations having expressible linear or quadratic constraints, which may not hold for all transformation types
- Hyper-adversarial attack effectiveness depends on the diversity of confidences in the hyper-input, which may be limited in practice
- MIP solver performance is highly dependent on specific solver implementation and hardware configuration

## Confidence
- **High Confidence**: The overall problem formulation and the fundamental approach of combining MIP encoding with hyper-adversarial attacks are well-established and validated through extensive experiments
- **Medium Confidence**: The effectiveness of dependency pruning and the hyper-adversarial attack mechanism are supported by experiments but could benefit from deeper theoretical analysis of convergence and failure modes
- **Low Confidence**: The scalability claims to larger networks and more complex perturbations need further validation, as the paper focuses primarily on small to medium-sized networks

## Next Checks
1. **Dependency Computation Validation**: Implement VHAGaR without dependency pruning and compare the runtime and bound quality against the full version. This would validate whether the dependency computation mechanism provides meaningful pruning benefits across different perturbation types.

2. **Hyper-Adversarial Attack Diversity Analysis**: Systematically vary the confidence diversity in the hyper-input and measure the impact on attack convergence speed and bound quality. This would validate the assumption that diverse confidences lead to better optimization hints.

3. **Scalability Stress Test**: Apply VHAGaR to larger networks (e.g., ResNet-18) and more complex perturbations (e.g., affine transformations combining rotation, scaling, and translation) to validate the scalability claims and identify potential bottlenecks in the MIP encoding or solver performance.