---
ver: rpa2
title: Proxy-informed Bayesian transfer learning with unknown sources
arxiv_id: '2411.03263'
source_url: https://arxiv.org/abs/2411.03263
tags:
- source
- learner
- data
- information
- transfer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces PROMPT, a Bayesian transfer learning method\
  \ designed to address negative transfer\u2014where learning from source data harms\
  \ target task performance. The key insight is that negative transfer stems from\
  \ misspecified prior information about non-transferable source task parameters."
---

# Proxy-informed Bayesian transfer learning with unknown sources

## Quick Facts
- arXiv ID: 2411.03263
- Source URL: https://arxiv.org/abs/2411.03263
- Authors: Sabina J. Sloman; Julien Martinelli; Samuel Kaski
- Reference count: 0
- Primary result: Introduces PROMPT, a Bayesian transfer learning method that eliminates negative transfer by using proxy information about target tasks rather than potentially incorrect source task priors.

## Executive Summary
PROMPT addresses negative transfer in Bayesian transfer learning by replacing reliance on potentially incorrect source task priors with proxy information about target tasks and a relevance function. The method works by learning target task parameters from proxy data, then constructing an r-weighted likelihood that downweights source observations irrelevant to the target task. Theoretically, PROMPT's success depends on the fidelity of the relevance function rather than the informativeness of proxy information, making it robust to noisy proxy data. Empirically, PROMPT significantly reduces negative transfer across synthetic linear regression examples and a real-world smoking behavior dataset.

## Method Summary
PROMPT is a three-step Bayesian transfer learning method that eliminates negative transfer by using proxy information about target tasks instead of prior knowledge about source task parameters. First, it learns the target task parameter ψn+1 using proxy information z to form a posterior P(Ψn+1|z). Second, it constructs a relevance function R that weights source observations based on their relevance to the target task, forming an r-weighted likelihood LR. Third, it combines these to produce a final r-weighted posterior predictive distribution. The method operates without requiring knowledge of source task parameters or assuming similarity between source and target tasks.

## Key Results
- PROMPT significantly reduces negative transfer compared to classic Bayesian transfer learning across synthetic linear regression and Gaussian process regression examples.
- The method is robust to noisy proxy information, maintaining its advantage even with contaminated proxy data.
- PROMPT successfully applies to a real-world smoking behavior dataset, demonstrating practical utility in complex settings.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PROMPT avoids negative transfer by removing reliance on prior information about source task parameters.
- Mechanism: It uses proxy information and a relevance function to construct an r-weighted likelihood that doesn't depend on a prior over source task parameters.
- Core assumption: The relevance function can be specified to correlate with the pseudo-intervention consequences even without knowing the true shared parameter.
- Evidence anchors:
  - [abstract]: "PROMPT avoids this by using proxy (indirect) information about the target task and a relevance function to weight source data, eliminating reliance on potentially incorrect source task priors."
  - [section]: "PROMPT operates in a setting that differs from... PROMPT requires neither the availability of prior information about the source tasks nor that the target task resembles the source tasks."
- Break condition: If the relevance function cannot be specified to correlate with the pseudo-intervention consequences (e.g., if θ and ψ interact such that the direction of the gradient of predictions with respect to ψ depends on θ).

### Mechanism 2
- Claim: The threat of negative transfer depends on the fidelity of the relevance function, not the informativeness of proxy information.
- Mechanism: The relevance function corrects for mismatches between source and target tasks through pseudo-intervention weighting, with higher fidelity leading to reduced negative transfer.
- Core assumption: The relevance function can be iteratively refined to improve its fidelity.
- Evidence anchors:
  - [abstract]: "Our theoretical results show that the threat of negative transfer does not depend on the informativeness of the proxy information, highlighting the usefulness of PROMPT in cases where only noisy indirect information, such as human feedback, is available."
  - [section]: "Proposition 4.5 shows that ∆R does not depend on the accuracy of the learner's inferences about ψ⋆n+1, i.e., on the informativeness of the proxy information."
- Break condition: If the iterative refinement procedure doesn't converge or if proxy information is insufficient to satisfy Assumption B.8.

### Mechanism 3
- Claim: PROMPT's advantage is robust to noisy and misleading proxy information.
- Mechanism: The r-weighted posterior is formed using proxy information for the target task parameter and relevance-weighted source data for the shared parameter, making it less sensitive to proxy noise.
- Core assumption: Some proxy information is available to satisfy the smoothness condition in the theoretical analysis.
- Evidence anchors:
  - [abstract]: "Our theoretical results show that the threat of negative transfer does not depend on the informativeness of the proxy information, highlighting the usefulness of PROMPT in cases where only noisy indirect information, such as human feedback, is available."
  - [section]: "Figure 2b shows that noisy proxy information does not affect the relative advantage of the r-weighted learner: Regardless of the degree of proxy contamination, the r-weighted learner tends to outperform the classic learner."
- Break condition: If proxy information is completely uninformative or if the proxy contamination is so extreme that it violates the conditions in Assumption B.8.

## Foundational Learning

- Concept: Bayesian inference with nuisance parameters
  - Why needed here: The paper frames negative transfer as a special case of inference in the presence of nuisance parameters, using results from this broader class of problems.
  - Quick check question: How does the presence of nuisance parameters affect the posterior distribution of parameters of interest?

- Concept: Likelihood weighting
  - Why needed here: PROMPT uses likelihood weighting to assign higher weights to observations relevant to the target task, effectively performing a pseudo-intervention on the source data.
  - Quick check question: How does likelihood weighting modify the standard likelihood function in Bayesian inference?

- Concept: Kullback-Leibler divergence
  - Why needed here: The paper uses KL divergence to measure the degree of misspecification between the true and assumed data-generating distributions.
  - Quick check question: What does KL divergence measure between two probability distributions?

## Architecture Onboarding

- Component map: Proxy information processing -> Relevance function -> R-weighted likelihood -> Posterior computation -> Predictive distribution

- Critical path:
  1. Process proxy information to get P(Ψn+1|z)
  2. Compute relevance function R(d, ψn+1)
  3. Form r-weighted likelihood LR(d, θ, ψn+1)
  4. Compute r-weighted posterior P(Θ, Ψn+1|d, z)
  5. Generate predictions from r-weighted posterior predictive

- Design tradeoffs:
  - Reliance on proxy information vs. direct target task data
  - Fidelity of relevance function vs. computational complexity
  - Iterative refinement of relevance function vs. convergence guarantees

- Failure signatures:
  - Poor performance when relevance function has low fidelity
  - Sensitivity to proxy contamination when iterative refinement fails
  - Computational issues when relevance function requires many iterations

- First 3 experiments:
  1. Implement linear regression example with varying degrees of multicollinearity to verify negative transfer reduction
  2. Test robustness to proxy contamination by adding noise to synthetic proxy information
  3. Apply to Gaussian process regression with composite kernel to verify performance across different simulation parameters

## Open Questions the Paper Calls Out

- Question: Under what specific conditions does PROMPT's iterative relevance function refinement procedure converge?
  - Basis in paper: [inferred] The paper mentions an iterative refinement procedure in Section 3.2 but states "an important direction for future work is establishing the conditions under which it converges"
  - Why unresolved: The authors propose the iterative procedure but do not provide theoretical guarantees for its convergence, only demonstrating empirical effectiveness in synthetic examples.
  - What evidence would resolve it: Mathematical proof showing sufficient conditions for convergence, or empirical demonstration across diverse problem settings showing consistent convergence behavior.

- Question: How does PROMPT perform in high-dimensional, non-linear transfer learning settings compared to classic Bayesian transfer learning?
  - Basis in paper: [explicit] The discussion section states "Many transfer learning applications leverage high-dimensional, non-linear datasets" and "future work should in particular look to the development of a scalable framework for applying and evaluating PROMPT in such contexts"
  - Why unresolved: All examples in the paper use relatively simple linear and GP regression settings; the authors acknowledge this as a limitation.
  - What evidence would resolve it: Comparative experiments using high-dimensional datasets (e.g., image or text data) showing PROMPT's performance advantage or limitations in complex settings.

- Question: When is it more reliable to specify the relevance function versus the prior over source task parameters?
  - Basis in paper: [explicit] The discussion states "Ultimately, however, there may exist situations where such a relevance function is unavailable...the practitioner must make a choice about whether they can more confidently specify the prior over source task parameters or the relevance function"
  - Why unresolved: The paper identifies this as a practical challenge but does not provide guidance on when one approach is preferable over the other.
  - What evidence would resolve it: Framework or decision criteria that help practitioners determine which approach (relevance function vs. source task prior) is more reliable for a given problem domain.

## Limitations

- PROMPT requires some proxy information about the target task to be available - it cannot operate in complete absence of target task information.
- The method's performance is sensitive to the choice of proxy information and the specification of the relevance function, though theoretical results suggest robustness to noisy proxy data.
- PROMPT may face challenges in complex models where θ and ψ interact in non-additive ways, making relevance function specification difficult.

## Confidence

- **High Confidence**: The theoretical framework showing negative transfer as a special case of nuisance parameter misspecification is well-established and rigorously proven. The core claim that PROMPT reduces negative transfer by eliminating reliance on misspecified source task priors is strongly supported by both theory and experiments.

- **Medium Confidence**: The claim that PROMPT is robust to noisy proxy information, while supported by theoretical results showing independence from proxy informativeness, requires more extensive empirical validation across diverse real-world scenarios. The convergence properties of the relevance function refinement procedure are not fully characterized.

- **Low Confidence**: The general applicability of PROMPT across all transfer learning scenarios, particularly for highly complex models with non-additive interactions between θ and ψ, remains to be thoroughly tested. The method's performance when proxy information is severely limited or highly contaminated is not fully characterized.

## Next Checks

1. **Convergence Diagnostics**: Implement monitoring of relevance function fidelity ρR across iterations in Algorithm 1 to empirically verify convergence conditions and identify scenarios where iterative refinement fails or oscillates.

2. **Model Complexity Scaling**: Test PROMPT on increasingly complex hierarchical models (e.g., non-linear interactions, non-Gaussian likelihoods) to identify the boundary conditions where the relevance function specification breaks down or computational complexity becomes prohibitive.

3. **Extreme Proxy Conditions**: Systematically evaluate PROMPT's performance under varying degrees of proxy information quality - from highly informative to completely uninformative, including scenarios where proxy information is adversarially misleading rather than just noisy.