---
ver: rpa2
title: Text clustering applied to data augmentation in legal contexts
arxiv_id: '2404.08683'
source_url: https://arxiv.org/abs/2404.08683
tags: []
core_contribution: This study proposes a clustering-based data augmentation method
  to enhance legal text classification performance, particularly for classifying cases
  into the UN Sustainable Development Goals (SDGs) in the Brazilian Supreme Federal
  Court context. The method uses clustering to assign synthetic labels to initially
  unlabeled legal texts, thereby increasing training examples for machine learning
  models.
---

# Text clustering applied to data augmentation in legal contexts

## Quick Facts
- arXiv ID: 2404.08683
- Source URL: https://arxiv.org/abs/2404.08683
- Reference count: 11
- This study proposes a clustering-based data augmentation method that increases positive examples for SDGs from fewer than 100 to around 500 per goal, improving classification accuracy and sensitivity metrics by up to 17%

## Executive Summary
This study addresses the challenge of classifying legal texts into UN Sustainable Development Goals (SDGs) by proposing a clustering-based data augmentation method. The approach uses k-means clustering on doc2vec embeddings to assign synthetic labels to unlabeled legal texts, thereby increasing training examples for machine learning models. The method was tested on Brazilian Supreme Federal Court cases, demonstrating significant improvements in classification performance, particularly for SDGs with limited original labels. By propagating labels within clusters, the approach effectively balances class distribution and enhances LSTM network performance for legal text classification tasks.

## Method Summary
The method combines clustering and label propagation to augment labeled datasets for legal text classification. It begins with text preprocessing and doc2vec embedding generation for both labeled and unlabeled legal documents. K-means clustering is then applied to group similar texts, with label propagation used to assign synthetic labels to unlabeled texts based on the proportion of original labels within each cluster. The augmented dataset, containing significantly more positive examples for each SDG, is then used to train LSTM neural networks. The approach effectively increases positive examples for underrepresented SDGs from fewer than 100 to around 500 per goal, improving classification accuracy and sensitivity metrics by up to 17%.

## Key Results
- Increased positive examples for SDGs from fewer than 100 to around 500 per goal through clustering-based label propagation
- Improved classification accuracy and sensitivity metrics by up to 17% when using augmented datasets with LSTM networks
- Demonstrated effectiveness particularly for SDGs with limited original labels, showing significant performance gains in the Brazilian Supreme Federal Court context

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Clustering augments labeled datasets by propagating labels to nearby unlabeled texts
- Mechanism: The method uses k-means clustering on combined labeled and unlabeled embeddings. Unlabeled texts within a cluster radius receive synthetic labels based on the proportion of original labels in that region, increasing positive examples for underrepresented classes
- Core assumption: Texts with similar embeddings (from doc2vec) are likely to share the same SDG label
- Evidence anchors:
  - [abstract] "The method uses clustering to assign synthetic labels to initially unlabeled legal texts, thereby increasing training examples for machine learning models"
  - [section] "The clustering mechanism is employed to create clusters of processes with similar textual content within this new framework. Disregarding the cluster boundaries, processes initially lacking labels are assigned artificial labels based on the presence or absence of labeled processes in their proximity (label propagation)"
- Break condition: If cluster radii include texts with very different content, synthetic labels may be inaccurate, reducing model performance

### Mechanism 2
- Claim: Data augmentation improves LSTM classification performance by balancing label distribution
- Mechanism: After clustering and label propagation, the augmented dataset contains more positive examples for each SDG. LSTM networks trained on this balanced data achieve higher accuracy and sensitivity than those trained on the original imbalanced dataset
- Core assumption: Increased positive examples for underrepresented SDGs directly improve LSTM model performance
- Evidence anchors:
  - [abstract] "Using k-means clustering, label propagation, and LSTM neural networks, the approach increased positive examples for SDGs from fewer than 100 to around 500 per goal, improving classification accuracy and sensitivity metrics by up to 17%"
  - [section] "The classification tests were carried out using LSTM networks trained on both the original dataset and the augmented dataset... Table 5 presents the average accuracy and sensitivity metrics for both the original and augmented datasets"
- Break condition: If synthetic labels are incorrect, the augmented data may mislead the LSTM, reducing overall model performance

### Mechanism 3
- Claim: Doc2vec embeddings capture contextual meaning in legal texts better than frequency-based methods
- Mechanism: Doc2vec creates document-level vectors that preserve semantic relationships between texts, allowing clustering to group truly similar legal cases rather than just texts with similar word frequencies
- Core assumption: Doc2vec vectors represent meaningful semantic similarity for legal documents, enabling effective clustering
- Evidence anchors:
  - [section] "Representing texts as vectors of numbers offers a means to compare texts using algorithms, models, or computational methods... The word2vec family, with particular emphasis on the doc2vec method, addresses these problems"
  - [section] "The doc2vec method extends word representations from word2vec to texts without constraints on size... In this work, the texts will be vectorized using the doc2vec method"
- Break condition: If doc2vec fails to capture legal domain semantics, clustering will group dissimilar texts, making label propagation ineffective

## Foundational Learning

- Concept: Vector embeddings for text representation
  - Why needed here: The clustering and classification algorithms require numerical representations of text documents to compute similarities and make predictions
  - Quick check question: How would you convert a legal document into a vector that captures its semantic meaning?

- Concept: Label propagation in semi-supervised learning
  - Why needed here: The method needs to assign labels to unlabeled texts based on their similarity to labeled examples within clusters
  - Quick check question: What happens to classification performance if synthetic labels are assigned to texts that actually belong to different classes?

- Concept: LSTM networks for sequence learning
  - Why needed here: The final classification step uses LSTM networks, which are effective for capturing dependencies in text data
  - Quick check question: Why might LSTM networks be preferred over simple feedforward networks for text classification tasks?

## Architecture Onboarding

- Component map: Text preprocessing → Doc2vec embedding → K-means clustering → Label propagation → LSTM classification
- Critical path: Embedding → Clustering → Label propagation → Classification (each step depends on the previous one's output)
- Design tradeoffs: Higher cluster count → more precise groups but fewer original labels per cluster; Larger radius → more synthetic labels but potentially less accurate propagation
- Failure signatures: Decreased accuracy after augmentation indicates poor synthetic label quality; High sensitivity but low accuracy suggests overfitting to synthetic data
- First 3 experiments:
  1. Test clustering with different k values (5, 10, 25) and measure label propagation accuracy on validation data
  2. Compare doc2vec vs TF-IDF embeddings for clustering quality using silhouette score
  3. Evaluate LSTM performance with varying proportions of synthetic labels (10%, 30%, 50%) to find optimal augmentation level

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would more sophisticated embedding methods like BERTopic or transformer-based approaches compare to doc2vec in clustering performance for legal text augmentation?
- Basis in paper: [explicit] The paper suggests using BERT models and GPT family in future work for enhanced text abstraction capability in the embedding stage
- Why unresolved: The study used doc2vec as a baseline and explicitly notes that more sophisticated models could be explored in future research
- What evidence would resolve it: Direct comparison of clustering and classification performance using doc2vec versus BERTopic/transformer embeddings on the same legal text datasets

### Open Question 2
- Question: What is the optimal balance between synthetic label precision and quantity in the proposed clustering-based data augmentation approach?
- Basis in paper: [inferred] The paper discusses avoiding cluster edges to maintain higher similarity among processes but doesn't empirically determine the trade-off between label precision and quantity
- Why unresolved: The study focuses on improving classification metrics but doesn't systematically investigate how varying the label propagation precision affects downstream classification performance
- What evidence would resolve it: Systematic experiments varying the label propagation threshold and radius to measure precision-recall trade-offs and their impact on classification accuracy

### Open Question 3
- Question: How would the proposed clustering-based augmentation method perform on other legal classification tasks beyond SDG categorization?
- Basis in paper: [explicit] The authors note their method could be applied to other legal classification tasks and mention potential applications for COVID-19 case prioritization
- Why unresolved: The study is limited to SDG classification in Brazilian Supreme Court cases, and generalization to other legal domains hasn't been tested
- What evidence would resolve it: Application and evaluation of the method on different legal classification tasks (e.g., case type categorization, procedural classification) in various legal systems

## Limitations
- The exact parameter ranges for clustering (number of clusters, distance radius, threshold proportion) are not fully specified, which could impact reproducibility
- The study focuses on a specific legal domain (Brazilian Supreme Federal Court) and SDGs, limiting generalizability to other legal contexts
- Doc2vec hyperparameters and training details are unclear, potentially affecting embedding quality and downstream clustering performance

## Confidence
- **High**: The clustering-based augmentation mechanism and its impact on increasing positive examples (verified by increased sample counts from <100 to ~500 per SDG)
- **Medium**: The 17% improvement in classification metrics (accuracy and sensitivity) - while results are presented, the exact statistical significance and variance across runs is not fully detailed
- **Low**: The generalizability of the approach to other legal domains and classification tasks beyond the specific SDGs studied

## Next Checks
1. Test the clustering and label propagation pipeline with different parameter configurations (k=5, 10, 25; varying radius thresholds) to identify optimal settings and assess sensitivity to hyperparameter choices
2. Validate the semantic quality of doc2vec embeddings by comparing clustering results using doc2vec versus TF-IDF embeddings on the same legal text corpus
3. Evaluate the method on a different legal domain or classification task to assess generalizability beyond SDGs in Brazilian court cases