---
ver: rpa2
title: Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly
  Detection
arxiv_id: '2405.15370'
source_url: https://arxiv.org/abs/2405.15370
tags:
- anomaly
- data
- time
- series
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes LLMAD, a novel LLM-based framework for accurate
  and interpretable time series anomaly detection. LLMAD uses In-Context Learning
  (ICL) to retrieve similar normal and abnormal time series segments for context,
  and employs Anomaly Detection Chain-of-Thought (AnoCoT) to inject domain knowledge
  into LLMs.
---

# Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection

## Quick Facts
- **arXiv ID:** 2405.15370
- **Source URL:** https://arxiv.org/abs/2405.15370
- **Reference count:** 40
- **Primary result:** LLMAD achieves comparable detection performance to state-of-the-art deep learning methods while providing interpretable explanations for time series anomalies

## Executive Summary
This paper introduces LLMAD, a novel framework that leverages Large Language Models (LLMs) for time series anomaly detection (TSAD). The approach innovatively combines In-Context Learning (ICL) with retrieved similar normal and abnormal examples, along with an Anomaly Detection Chain-of-Thought (AnoCoT) prompting strategy that incorporates domain knowledge. LLMAD achieves detection performance comparable to state-of-the-art deep learning methods while offering remarkable interpretability through detailed explanations including anomaly types, alarm levels, and reasoning. The framework demonstrates that LLMs can be effectively adapted for TSAD without requiring fine-tuning on specific datasets.

## Method Summary
LLMAD employs a three-stage process: First, time series data is preprocessed through rescaling and indexing. Second, similar normal and abnormal time series segments are retrieved from a constructed database using FastDTW for similarity computation, which are then incorporated into the LLM prompt through ICL. Third, the LLM performs inference using the AnoCoT approach, which guides the model through global trend assessment, local anomaly assessment, and reassessment steps while injecting domain-specific knowledge such as judgment rules, anomaly type definitions, and alarm level criteria. This combination enables the LLM to reason like a human expert and provide comprehensive explanations for its detections.

## Key Results
- LLMAD achieves detection performance comparable to state-of-the-art deep learning methods (LSTM-AD, USAD, BeatGAN) on KPI, Yahoo, and WSD datasets
- The framework provides interpretable explanations including anomaly types, alarm levels, and detailed reasoning for detections
- GPT-4 outperforms GPT-3.5 and Llama-3-70B significantly in both detection accuracy and interpretability quality
- Using 2 positive and 1 negative sample for ICL provides an optimal trade-off between performance and prompt efficiency

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** In-context learning (ICL) with retrieved similar normal and abnormal time series significantly improves LLM performance for time series anomaly detection.
- **Mechanism:** By providing both positive (anomalous) and negative (normal) examples that are similar to the input time series, the LLM establishes a clearer boundary between normal and abnormal patterns, enabling accurate few-shot anomaly detection without fine-tuning.
- **Core assumption:** LLMs can effectively learn to distinguish between normal and abnormal patterns when provided with contextually relevant examples.
- **Evidence anchors:**
  - [abstract]: "LLMAD innovatively applies LLMs for in-context anomaly detection by retrieving both positive and negative similar time series segments, significantly enhancing LLMs' effectiveness."
  - [section]: "With the time series database constructed, LLMAD retrieves the most similar K1 normal time series and the K2 anomalous time series from S̃ and Ŝ to a target time series data T by leveraging the FastDTW algorithm for similarity computation... Incorporating the retrieved similar normal and abnormal data from historical records into the prompt of the LLMs enhances the ICL capability."
- **Break condition:** If the retrieved examples are not sufficiently similar or representative of the input time series, the ICL approach may fail to establish clear boundaries between normal and abnormal patterns.

### Mechanism 2
- **Claim:** Anomaly Detection Chain of Thoughts (AnoCoT) prompting, which incorporates domain knowledge and expert step-wise reasoning, improves both the accuracy and interpretability of TSAD results.
- **Mechanism:** AnoCoT guides the LLM through a three-step inference process: global trend assessment, local anomaly assessment, and reassessment. It also injects domain-specific knowledge such as judgment rules, anomaly type definitions, and alarm level criteria into the prompt, enabling the LLM to reason like a human expert and provide comprehensive explanations.
- **Core assumption:** LLMs can effectively follow complex reasoning steps and apply domain-specific knowledge when provided in a structured format.
- **Evidence anchors:**
  - [abstract]: "LLMAD employs the Anomaly Detection Chain-of-Thought (AnoCoT) approach to mimic expert logic for its decision-making process. This method further enhances its performance and enables LLMAD to provide explanations for their detections through versatile perspectives."
  - [section]: "The step-wise inference design emulates the logical reasoning of expert engineers, which substantially enhances the accuracy of TSAD and the quality of interpretability."
- **Break condition:** If the domain knowledge is not accurately defined or the reasoning steps are not clearly structured, the AnoCoT approach may lead to incorrect or incomplete interpretations.

### Mechanism 3
- **Claim:** The combination of ICL and AnoCoT enables LLMs to provide accurate and interpretable TSAD results at a low cost compared to traditional deep learning methods.
- **Mechanism:** By leveraging the pre-trained knowledge of LLMs and providing them with relevant examples and structured reasoning steps, LLMAD can accurately detect anomalies and provide comprehensive explanations without the need for extensive training data or manual analysis. This approach significantly reduces the time and effort required for TSAD compared to traditional methods.
- **Core assumption:** The pre-trained knowledge of LLMs is sufficient to understand and reason about time series data when provided with appropriate context and guidance.
- **Evidence anchors:**
  - [abstract]: "Experiments on three datasets indicate that our LLMAD achieves detection performance comparable to state-of-the-art deep learning methods while offering remarkable interpretability for detections."
  - [section]: "By incorporating the retrieved similar normal and abnormal data from historical records into the prompt of the LLMs enhances the ICL capability... This provides a comprehensive representation of the data background, anomaly patterns, and distinctions tailored to a specific time series dataset."
- **Break condition:** If the LLM's pre-trained knowledge is not sufficient to understand the specific domain or if the ICL and AnoCoT approaches are not properly implemented, the accuracy and interpretability of the results may be compromised.

## Foundational Learning

- **Concept: Time Series Anomaly Detection (TSAD)**
  - **Why needed here:** Understanding the task of identifying atypical patterns in time series data is crucial for implementing and evaluating LLMAD.
  - **Quick check question:** What is the main objective of time series anomaly detection, and why is interpretability important in this context?

- **Concept: In-Context Learning (ICL)**
  - **Why needed here:** ICL is a key technique used in LLMAD to enable the LLM to learn from a few examples without fine-tuning, which is essential for the few-shot anomaly detection approach.
  - **Quick check question:** How does ICL differ from traditional fine-tuning, and what are the benefits of using ICL for time series anomaly detection?

- **Concept: Chain of Thoughts (CoT) Prompting**
  - **Why needed here:** CoT prompting is a technique used in LLMAD to guide the LLM through a step-by-step reasoning process, which is crucial for providing interpretable explanations.
  - **Quick check question:** What is the purpose of CoT prompting, and how does it differ from standard prompting approaches?

## Architecture Onboarding

- **Component map:** Data preprocessing -> Time series ICL -> AnoCoT -> LLM inference
- **Critical path:**
  1. Preprocess input time series data
  2. Retrieve similar normal and abnormal examples from database
  3. Construct prompt with AnoCoT and domain knowledge
  4. Feed prompt to LLM and generate anomaly detection results and explanations

- **Design tradeoffs:**
  - Token usage vs. explanation quality: Using more tokens for detailed explanations may improve interpretability but increase latency and cost
  - Number of retrieved examples vs. performance: Using more examples may improve accuracy but increase complexity and latency

- **Failure signatures:**
  - Incorrect anomaly detection: May be caused by insufficient or irrelevant retrieved examples, inaccurate domain knowledge, or improper reasoning steps
  - Incomplete or unclear explanations: May be caused by inadequate prompt construction, insufficient domain knowledge, or LLM limitations

- **First 3 experiments:**
  1. Evaluate the impact of using different numbers of retrieved examples on anomaly detection accuracy and interpretability
  2. Assess the effect of injecting different types of domain knowledge on the quality of explanations
  3. Compare the performance of LLMAD using different LLM models (e.g., GPT-3.5, GPT-4, Llama-3) to identify the most suitable model for the task

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the performance of LLMAD vary across different LLM models (e.g., GPT-4 vs. Llama-3-70B) in terms of TSAD accuracy and interpretability?
- **Basis in paper:** [explicit] The paper compares the performance of LLMAD using GPT-4, GPT-3.5, and Llama-3-70B, showing that GPT-4 outperforms the other two models significantly.
- **Why unresolved:** While the paper provides a comparison, it does not delve into the specific reasons why GPT-4 performs better, such as its ability to handle complex reasoning or its larger parameter size.
- **What evidence would resolve it:** A detailed analysis of the strengths and weaknesses of each LLM model in the context of TSAD, including a comparison of their reasoning capabilities and parameter sizes.

### Open Question 2
- **Question:** What is the impact of the number of positive and negative samples used for ICL on the performance of LLMAD?
- **Basis in paper:** [explicit] The paper explores the effect of different ICL settings, including the number of positive and negative samples, on the performance of LLMAD.
- **Why unresolved:** The paper shows that using 2 positive/1 negative samples is a good trade-off, but it does not investigate the optimal number of samples for different datasets or anomaly types.
- **What evidence would resolve it:** A systematic study of the impact of varying the number of positive and negative samples on the performance of LLMAD across different datasets and anomaly types.

### Open Question 3
- **Question:** How does the inclusion of domain knowledge in the prompt affect the interpretability of the generated explanations?
- **Basis in paper:** [explicit] The paper introduces AnoCoT, which incorporates domain knowledge tailored to TSAD, and shows that it improves the quality of interpretability compared to standard CoT.
- **Why unresolved:** While the paper demonstrates the effectiveness of AnoCoT, it does not provide a detailed analysis of how specific domain knowledge components (e.g., judgment rules, anomaly type definitions) contribute to the interpretability of the explanations.
- **What evidence would resolve it:** A comprehensive evaluation of the impact of different domain knowledge components on the interpretability of the generated explanations, including a comparison of the explanations generated with and without specific components.

## Limitations

- The framework's performance heavily depends on the quality and diversity of retrieved similar examples; poor retrieval quality could significantly degrade detection accuracy
- Domain knowledge injection is critical but not fully specified in implementation details, raising concerns about reproducibility across different time series domains
- The method's scalability with increasing data volume and complexity has not been thoroughly evaluated

## Confidence

- **High Confidence Claims:**
  - LLMAD demonstrates competitive detection performance compared to state-of-the-art deep learning methods on benchmark datasets
  - The combination of ICL and AnoCoT provides interpretable explanations for anomaly detections
  - The framework successfully adapts LLMs for time series anomaly detection without fine-tuning

- **Medium Confidence Claims:**
  - The interpretability provided by LLMAD is practically useful for domain experts
  - The framework can generalize across different time series domains (KPIs, server metrics, etc.)
  - The computational efficiency compared to traditional deep learning approaches is favorable

- **Low Confidence Claims:**
  - Long-term reliability and stability of LLMAD in production environments
  - Performance on highly complex, multivariate time series data
  - Effectiveness across diverse domain-specific anomaly types not covered in the evaluated datasets

## Next Checks

1. **Retrieval Quality Analysis:** Systematically evaluate the impact of varying retrieval similarity thresholds and the number of retrieved examples on detection accuracy and interpretability quality across all three datasets.

2. **Domain Knowledge Robustness:** Conduct ablation studies by varying the comprehensiveness and specificity of injected domain knowledge to quantify its contribution to detection performance and explanation quality.

3. **Scalability Assessment:** Test LLMAD's performance and latency characteristics with progressively larger time series datasets (10x, 100x the original size) to evaluate computational feasibility for real-world deployment scenarios.