---
ver: rpa2
title: Common Ground Tracking in Multimodal Dialogue
arxiv_id: '2403.17284'
source_url: https://arxiv.org/abs/2403.17284
tags:
- group
- dialogue
- ground
- common
- evidence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of tracking common ground in
  multimodal dialogue, focusing on identifying shared beliefs and questions under
  discussion among participants in task-oriented conversations. The authors propose
  a method that combines formal models of common ground with automated pipelines to
  track its evolution over time.
---

# Common Ground Tracking in Multimodal Dialogue

## Quick Facts
- arXiv ID: 2403.17284
- Source URL: https://arxiv.org/abs/2403.17284
- Reference count: 0
- Key outcome: Proposed method tracks common ground in multimodal dialogue using formal models, achieving average Sørensen-Dice coefficient of 0.903 for fact and evidence banks

## Executive Summary
This paper addresses the challenge of tracking common ground in multimodal dialogue, focusing on identifying shared beliefs and questions under discussion among participants in task-oriented conversations. The authors propose a method that combines formal models of common ground with automated pipelines to track its evolution over time. They augment the Weights Task Dataset with gesture, action, and common ground annotations, enabling the operationalization of their formal model. The proposed system uses a move classifier to predict cognitive states, a propositional extractor to retrieve task-relevant content, and closure rules to update the common ground structure.

## Method Summary
The approach uses a multimodal pipeline to track common ground in task-oriented dialogue. A move classifier predicts cognitive states (STATEMENT, ACCEPT, DOUBT) using LSTM-based models with multimodal features. Propositional extractors (CGA with all modalities, DP with text only) retrieve task-relevant content. Closure rules derived from epistemic logic update the common ground structure (QBank, EBank, FBank) based on predicted moves and extracted propositions. The system is evaluated using Sørensen-Dice coefficient to measure overlap between extracted propositions and ground truth across different groups in the Weights Task Dataset.

## Key Results
- Incorporating multiple modalities improves retrieval of correct propositions and their assignment to appropriate common ground levels
- The model achieves average Sørensen-Dice coefficient of 0.903 for the union of fact and evidence banks
- Ablation studies show modality-specific contributions vary by group, with some performing better unimodally

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Combining multiple modalities (language, gesture, action, prosody, CPS) improves the model's ability to assign correct evidence levels to task-relevant propositions.
- Mechanism: Each modality captures different aspects of the shared belief space. Gesture and action annotations directly capture non-linguistic references to task objects, prosody captures speaker confidence and turn-taking cues, and CPS indicators reflect collaborative intent. When these are fused, the model has richer contextual information to distinguish between mere statements of evidence and group acceptance (facts).
- Core assumption: Different modalities provide complementary, not redundant, information about the common ground.
- Evidence anchors:
  - [abstract] "empirical results show that incorporating multiple modalities improves the retrieval of correct propositions and their assignment to the appropriate level of common ground"
  - [section 6.4] "closure rules derived from the epistemic logic... update the status of QBank, EBank, and FBank"
  - [corpus] weak evidence: only 0/8 corpus neighbors mention multimodal common ground tracking specifically
- Break condition: If modalities provide overlapping or conflicting information without clear fusion strategy, model performance degrades.

### Mechanism 2
- Claim: The formal evidence-based belief model (EB-DEL) allows graded updates to shared beliefs, avoiding binary true/false errors.
- Mechanism: Propositions start in QBank as questions. Evidence for a proposition is tracked separately from belief. A statement adds evidence; acceptance removes uncertainty and promotes to fact. This models real-world dialogue where people express tentative beliefs before group consensus.
- Core assumption: Participants' cognitive states can be accurately classified as STATEMENT, ACCEPT, or DOUBT using multimodal cues.
- Evidence anchors:
  - [abstract] "formal closure rules derived from situated evidence and belief axioms and update operations"
  - [section 4.3] "Update with Evidence: [!φ][E]ψ... Update with Belief: [E]φ → [!φ][B]ψ"
  - [corpus] weak evidence: corpus neighbors focus on general multimodal dialogue but not epistemic logic-based belief tracking
- Break condition: If the move classifier misclassifies cognitive states, evidence levels become corrupted, leading to incorrect bank assignments.

### Mechanism 3
- Claim: Propositional extraction using both CGA (multimodal annotation) and DP (language-only) methods allows evaluation of modality contribution and provides robustness.
- Mechanism: CGA uses all modalities directly annotated, while DP uses only text with dense paraphrasing. Comparing these isolates the value added by non-linguistic information. CGA can capture gestures/actions that DP cannot.
- Core assumption: Dense paraphrasing preserves propositional content even without multimodal context.
- Evidence anchors:
  - [abstract] "augmenting the Weights Task Dataset with gesture, action, and common ground annotations"
  - [section 6.3] "CGA method... multi-modally-informed method of propositional extraction... DP method... unimodal"
  - [corpus] weak evidence: no corpus neighbor explicitly discusses dual extraction methods
- Break condition: If dense paraphrasing introduces ambiguity or loses critical references, DP performance will diverge significantly from CGA.

## Foundational Learning

- Concept: Epistemic logic and evidence-based belief models
  - Why needed here: The system must track not just what propositions are mentioned, but the degree of evidence and belief behind them across participants.
  - Quick check question: In the closure rules, what distinguishes adding a proposition to EBank versus FBank?

- Concept: Multimodal feature engineering and fusion
  - Why needed here: Each modality (gesture, action, prosody, CPS) contributes unique signals about collaborative intent and reference.
  - Quick check question: Which individual modality alone achieved perfect F ∪ E DSC in Group 1?

- Concept: Dialogue state tracking vs. common ground tracking
  - Why needed here: DST tracks individual user needs; CGT tracks shared group beliefs. This distinction drives the architecture.
  - Quick check question: What are the three components of the Common Ground Structure (CGS)?

## Architecture Onboarding

- Component map: Utterance → Move Classifier → Propositional Extractor → Closure Rules → CGS Update → DSC Evaluation
- Critical path: Utterance → Move Classifier → Propositional Extractor → Closure Rules → CGS Update → DSC Evaluation
- Design tradeoffs:
  - Multimodal fusion vs. individual modality baselines (some groups perform better unimodally)
  - Data augmentation (SMOTE) to handle class imbalance vs. potential overfitting
  - Dense paraphrasing vs. direct annotation accuracy
- Failure signatures:
  - Low DSC in F ∪ E but high in QBank: propositions found but evidence levels wrong (likely move classifier errors)
  - Consistently low DSC across all banks: propositional extraction failing (likely feature engineering issues)
  - Group-specific modality dependencies: some groups communicate differently; need adaptive modality weighting
- First 3 experiments:
  1. Ablation study: run with each individual modality removed to identify most critical features
  2. Move classifier only evaluation: measure classification accuracy without closure rules to isolate source of errors
  3. Propositional extraction comparison: compute DSC using only CGA vs. only DP to quantify modality contribution

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do power dynamics influence the construction of common ground in multimodal dialogue?
- Basis in paper: [inferred] The paper mentions the potential for power dynamics to bias the construction of common ground towards certain people or assertions, but does not explore this aspect in detail.
- Why unresolved: The paper focuses on the technical aspects of tracking common ground and does not delve into the social dynamics that may influence the process.
- What evidence would resolve it: Analyzing the data for patterns of dominance or influence in the construction of common ground, and correlating these with factors such as gender, age, or social status.

### Open Question 2
- Question: Can the common ground model be extended to accommodate individual speaker banks, and how would this affect the model's performance?
- Basis in paper: [explicit] The paper suggests that the model could benefit from separate banks for each speaker to facilitate knowledge sharing and collaboration.
- Why unresolved: The paper does not implement or evaluate this extension, leaving its potential impact on the model's performance unknown.
- What evidence would resolve it: Implementing the extended model and comparing its performance to the current model on the Weights Task Dataset or similar tasks.

### Open Question 3
- Question: How does the complexity of the task and the number of task items affect the scalability of the common ground tracking model?
- Basis in paper: [explicit] The paper acknowledges that the complexity of proposition construction scales with the complexity of the task and number of task items.
- Why unresolved: The paper only evaluates the model on the Weights Task Dataset, which has a limited number of task items and relations. The model's performance on more complex tasks is unknown.
- What evidence would resolve it: Evaluating the model on tasks with varying levels of complexity and number of task items, and analyzing the impact on the model's performance and scalability.

## Limitations
- The approach was tested on only 9 task-oriented dialogue groups, raising questions about performance on different domains or conversation types
- The closure rules rely on accurate cognitive state classification, and errors in the move classifier can cascade through the entire system
- Evaluation metrics focus on proposition-level overlap rather than semantic correctness of the common ground structure itself

## Confidence
- High confidence: The core mechanism of using multimodal features to improve proposition-level common ground tracking is well-supported by empirical results showing DSC improvements of 0.03-0.09 over baselines
- Medium confidence: The formal evidence-based belief model (EB-DEL) provides a sound theoretical foundation, but its practical implementation details and potential edge cases are not fully explored
- Medium confidence: The ablation study results showing modality-specific contributions are compelling, though the small sample size limits generalizability

## Next Checks
1. **Ablation testing on individual groups**: Replicate the modality ablation study for each of the 9 groups individually to identify whether the observed modality dependencies are consistent across all groups or specific to certain conversational styles
2. **Move classifier error analysis**: Manually examine cases where the move classifier misclassifies cognitive states and trace how these errors propagate through the closure rules to quantify their impact on final DSC scores
3. **Cross-domain evaluation**: Apply the trained model to a different multimodal dialogue dataset (such as TRACE or GuessWhich) to assess generalizability beyond the Weights Task Dataset and identify domain-specific limitations