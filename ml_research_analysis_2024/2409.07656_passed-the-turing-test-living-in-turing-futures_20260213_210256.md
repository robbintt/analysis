---
ver: rpa2
title: 'Passed the Turing Test: Living in Turing Futures'
arxiv_id: '2409.07656'
source_url: https://arxiv.org/abs/2409.07656
tags:
- turing
- machine
- test
- would
- machines
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper argues that large language models based on transformer
  architectures have effectively passed the Turing test by demonstrating the ability
  to engage in human-like conversation and perform intellectual tasks once thought
  exclusive to humans. The author contends that Turing's original test was more of
  a thought experiment to argue for machine intelligence rather than a practical experiment,
  and that modern transformers meet Turing's criteria for an "adequate proof" of machine
  intelligence through their ability to learn and scale without preprogramming.
---

# Passed the Turing Test: Living in Turing Futures

## Quick Facts
- arXiv ID: 2409.07656
- Source URL: https://arxiv.org/abs/2409.07656
- Reference count: 21
- Primary result: Large language models based on transformer architectures have effectively passed the Turing test by demonstrating human-like conversation and intellectual capabilities

## Executive Summary
This paper argues that modern transformer-based language models have achieved Turing's vision of machine intelligence through their ability to learn from experience without preprogramming. The author contends that Turing's original test was more of a thought experiment to argue for machine intelligence rather than a practical experiment, and that transformers meet Turing's criteria for "adequate proof" through autonomous learning capability and emergent abilities at critical model scales. The paper highlights that transformers can perform well on diverse tasks ranging from composing sonnets to arithmetic, with intelligence that grows predictably with model and data scaling.

However, the paper also raises concerns about the extreme resource intensity of current AI systems and calls for more sustainable approaches inspired by Turing's vision of "child machines" that learn like human children. The author proposes modern "Turing-like tests" for AI evaluation that would involve adversarial testing and statistical protocols to assess AI systems in realistic settings. While the theoretical framework connecting Turing's vision to modern transformers is compelling, the paper lacks direct experimental evidence and relies heavily on interpretation of Turing's writings rather than concrete validation.

## Method Summary
The paper employs a theoretical analysis approach, examining Turing's original writings and comparing them with modern transformer architectures to assess whether current AI systems meet Turing's criteria for machine intelligence. The methodology involves interpreting Turing's vision of learning machines, analyzing the scaling properties of transformers, and evaluating emergent capabilities without preprogramming. The approach is primarily conceptual rather than experimental, focusing on philosophical and theoretical alignment between Turing's vision and modern AI capabilities.

## Key Results
- Transformers demonstrate human-like conversation abilities and intellectual tasks once thought exclusive to humans
- Intelligence in transformers emerges at critical model scales and grows predictably with scaling
- Current AI systems are extremely resource-intensive, calling for more sustainable approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformers pass Turing's test by learning from experience without preprogramming
- Mechanism: The transformer architecture uses attention mechanisms to learn patterns from data, allowing it to scale intelligence through training rather than hardcoded rules
- Core assumption: Intelligence can emerge from pattern recognition and scaling without explicit programming of reasoning rules
- Evidence anchors:
  - [abstract] "Without resorting to preprogramming or special tricks, their intelligence grows as they learn from experience"
  - [section] "The machines he envisioned in 1946 would be able to change their structure autonomously by learning from experience, like brains"
  - [corpus] Weak - no direct corpus evidence found
- Break condition: If emergent abilities require pre-specified training objectives or architectures that encode human reasoning patterns

### Mechanism 2
- Claim: Transformers meet Turing's "adequate proof" criteria through autonomous learning capability
- Mechanism: The ability to acquire skills like arithmetic through scaling demonstrates that intelligence emerges from the learning process itself
- Core assumption: The emergence of complex abilities from simple architectures through scaling constitutes proof of intelligence
- Evidence anchors:
  - [section] "Instead of specifying a controlled experiment, Turing continuously varied the conditions of his test... used it as a thought experiment to argue for machine intelligence"
  - [section] "Turing immediately shifted the focus to research on learning machines: 'What steps should be taken now if the experiment is to be successful?'"
  - [corpus] Weak - no direct corpus evidence found
- Break condition: If emergent abilities are actually the result of hidden human-designed patterns in training data

### Mechanism 3
- Claim: Transformer intelligence grows with model and data scaling in a way that matches Turing's prediction
- Mechanism: The scaling laws show that transformer capabilities increase predictably with size, and certain abilities emerge at critical scales
- Core assumption: Scaling behavior demonstrates genuine intelligence growth rather than just memorization
- Evidence anchors:
  - [section] "The intelligence of generative transformers grows with the scaling of the model and its pretraining data"
  - [section] "There are tasks where their ability can be seen to increase gradually, and tasks where their ability emerges at a critical scale"
  - [corpus] Weak - no direct corpus evidence found
- Break condition: If scaling simply amplifies memorized patterns without genuine understanding

## Foundational Learning

- Concept: Turing test as empirical definition of machine intelligence
  - Why needed here: The paper argues the Turing test serves as a criterion for machine intelligence rather than a practical experiment
  - Quick check question: Why did Turing shift focus from the imitation game to research on learning machines?

- Concept: Learning vs. preprogramming in AI systems
  - Why needed here: The distinction between learning machines and preprogrammed ones is central to the argument about why transformers meet Turing's criteria
  - Quick check question: What was Turing's objection to preprogrammed machines in the context of his test?

- Concept: Emergent abilities at critical model scales
  - Why needed here: Understanding how certain capabilities emerge only at specific scales is key to grasping why transformers can perform tasks Turing considered benchmarks
  - Quick check question: What does it mean when an ability "emerges at a critical scale" in transformer models?

## Architecture Onboarding

- Component map: Transformer architecture -> Attention mechanism -> Pretraining on large datasets -> Emergent capabilities -> Human-like performance
- Critical path: Data quality and diversity -> Model scale -> Training duration -> Capability emergence -> Evaluation against human benchmarks
- Design tradeoffs: Model size vs. efficiency, pretraining data vs. fine-tuning, capability emergence vs. interpretability
- Failure signatures: Memorization without generalization, inability to handle novel scenarios, brittleness on edge cases, resource inefficiency
- First 3 experiments:
  1. Test arithmetic capabilities at different model scales to observe emergence patterns
  2. Evaluate conversation quality against human judges to assess Turing test performance
  3. Compare resource consumption against task performance to identify efficiency bottlenecks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we design Turing-like tests that effectively evaluate AI systems in realistic, high-stakes scenarios while preventing data contamination and poisoning attacks?
- Basis in paper: explicit
- Why unresolved: The paper identifies the need for adversarial testing and statistical protocols but does not provide specific methodologies for implementation.
- What evidence would resolve it: Empirical results demonstrating successful evaluation of AI systems using proposed Turing-like tests that can detect and mitigate data contamination and poisoning attacks.

### Open Question 2
- Question: What are the minimum computational and energy requirements for developing AI systems that match Turing's vision of "child machines" while remaining sustainable and environmentally friendly?
- Basis in paper: explicit
- Why unresolved: The paper highlights the unsustainable energy consumption of current AI systems but does not propose specific technical solutions for reducing this consumption.
- What evidence would resolve it: Comparative studies showing energy efficiency improvements in AI systems designed according to Turing's naturalistic principles versus current transformer architectures.

### Open Question 3
- Question: At what scale do transformer architectures achieve human-like performance across all cognitive tasks, and what are the limitations of scaling alone in achieving general artificial intelligence?
- Basis in paper: inferred
- Why unresolved: The paper discusses emergent abilities at critical scales but does not specify the ultimate limits of scaling or whether it can achieve human-level general intelligence.
- What evidence would resolve it: Systematic scaling studies that map the relationship between model size, training data, and performance across diverse cognitive tasks, identifying potential ceilings or fundamental limitations.

## Limitations
- The analysis relies heavily on theoretical interpretation rather than concrete experimental results
- Claims about transformers "passing" the Turing test lack direct empirical validation and specific evaluation protocols
- The paper does not provide quantitative data on success rates or detailed conversation protocols

## Confidence

**High Confidence**: The interpretation of Turing's original vision regarding learning machines and the importance of autonomous learning over preprogramming is well-supported by historical context and Turing's own writings.

**Medium Confidence**: The claim that transformers meet Turing's criteria for an "adequate proof" of machine intelligence through their ability to learn and scale is reasonable but lacks direct experimental validation.

**Low Confidence**: The assertion that transformers have definitively "passed the Turing test" is the most uncertain claim without specific experimental protocols, evaluation criteria, and quantitative results.

## Next Checks

1. **Empirical Turing Test Evaluation**: Conduct a controlled experiment using blinded human evaluators who interact with both transformer models and humans across multiple conversation topics and tasks, documenting success rates and specific failure modes.

2. **Capability Emergence Analysis**: Systematically test transformer models at different scales (e.g., 10B, 100B, 1T parameters) on tasks like arithmetic and logical reasoning to verify claimed emergence patterns and document scaling relationships.

3. **Resource Efficiency Assessment**: Measure the computational resources required for transformer models to achieve human-level performance on various tasks, then compare this to human cognitive efficiency to validate sustainability concerns and test whether more efficient approaches are feasible.