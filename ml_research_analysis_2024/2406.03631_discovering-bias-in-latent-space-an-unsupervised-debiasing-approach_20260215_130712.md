---
ver: rpa2
title: 'Discovering Bias in Latent Space: An Unsupervised Debiasing Approach'
arxiv_id: '2406.03631'
source_url: https://arxiv.org/abs/2406.03631
tags: []
core_contribution: This paper addresses the issue of bias in foundation models, particularly
  their sensitivity to superficial changes in input prompts, which can lead to inconsistent
  performance. The authors propose STEER FAIR, an unsupervised inference-time debiasing
  method that identifies and steers away from bias directions in the model's internal
  representation space.
---

# Discovering Bias in Latent Space: An Unsupervised Debiasing Approach

## Quick Facts
- **arXiv ID**: 2406.03631
- **Source URL**: https://arxiv.org/abs/2406.03631
- **Reference count**: 25
- **Primary result**: Unsupervised STEER FAIR outperforms supervised baseline with 100 labels by 10.86% accuracy points and 12.95 score points

## Executive Summary
This paper addresses bias in foundation models that causes inconsistent performance across superficial prompt variations. The authors propose STEER FAIR, an unsupervised inference-time debiasing method that identifies bias directions in the model's latent space using PCA on activation patterns from constructed demonstrations. The method then steers activation values away from these identified directions during inference. Experiments on three benchmark tasks show significant reductions in performance variance, with STEER FAIR outperforming supervised baselines while requiring no labeled data for training.

## Method Summary
STEER FAIR is an unsupervised inference-time debiasing method that constructs demonstrations from unlabeled samples to identify bias directions in the latent space. The method enumerates bias association rules, creates demonstration sets by mimicking these biases, and collects attention head activation values from these demonstrations. PCA is applied to identify principal bias directions, which are combined using QR decomposition to create an orthonormal basis. During inference, activation values are shifted away from these bias directions using a controlled strength parameter. The approach targets the residual stream in transformer models, specifically modifying attention head activations in the last token to reduce bias while preserving base model performance.

## Key Results
- STEER FAIR significantly reduces performance variance across prompt modifications on ScienceQA, MME Benchmark, and Visual Genome Relation
- Outperforms supervised baseline (ITI) with 100 labels by average of 10.86% accuracy points and 12.95 score points
- Matches performance of supervised baseline with 500 labels while requiring no labeled training data
- Maintains relatively stable average performance with fluctuations within ±2% across different numbers of unlabeled samples

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bias manifests as simple association rules in latent space that can be identified through PCA on activation patterns
- Mechanism: Constructs demonstrations mimicking bias behaviors, collects attention head activations, and applies PCA to identify principal directions
- Core assumption: Bias directions are linearly separable and captured by first principal component
- Evidence anchors: [abstract] exploits simple association rules; [section 3.3] uses PCA1 as bias direction; [corpus] weak evidence from related works
- Break condition: If bias directions are not linearly separable or require multiple components

### Mechanism 2
- Claim: Steering activations away from identified bias directions reduces performance variance
- Mechanism: Shifts attention head activation values away from bias directions during inference using strength parameter α
- Core assumption: Identified bias directions generalize and removing them doesn't harm base performance
- Evidence anchors: [abstract] shifts activation values away; [section 3.5] steers last token activations; [section 5.4] shows stable Avg% within ±2%
- Break condition: If directions don't generalize or steering removes necessary information

### Mechanism 3
- Claim: QR decomposition creates orthonormal basis that effectively captures bias without correlation
- Mechanism: Uses QR decomposition to orthogonalize bias direction vectors, then averages orthonormal basis
- Core assumption: Bias directions are not perfectly correlated and orthogonalization preserves essential information
- Evidence anchors: [section 3.4] uses QR decomposition for orthonormal basis; [section 5.3] shows minimal overlap between directions; [corpus] missing evidence
- Break condition: If directions are highly correlated or number of directions is large

## Foundational Learning

- **PCA (Principal Component Analysis)**
  - Why needed here: Identifies primary direction in activation space that captures bias behavior
  - Quick check question: What does PCA identify in a dataset of activation vectors from bias demonstrations?

- **Residual Stream Architecture**
  - Why needed here: Understanding residual connections is crucial for knowing where to intervene in internal representations
  - Quick check question: How do residual connections in transformers allow for layer-wise processing of information?

- **Attention Mechanism**
  - Why needed here: Method specifically targets attention head activations to identify and modify bias directions
  - Quick check question: What information is captured in the attention head activation values that the method uses?

## Architecture Onboarding

- **Component map**: Input preprocessing -> Construct demonstrations -> Latent space analysis -> Direction combination -> Inference-time intervention -> Output processing
- **Critical path**: 1) Construct demonstrations from unlabeled data, 2) Collect activation values, 3) Identify bias directions via PCA, 4) Combine directions using QR decomposition, 5) Implement inference-time steering, 6) Hyperparameter tuning
- **Design tradeoffs**: Simple averaging vs QR decomposition (simpler but may introduce correlation), N samples (more may introduce noise vs fewer may miss patterns), α strength (too high may disrupt performance, too low may not reduce bias sufficiently), K heads (more may capture more bias but increase computational cost)
- **Failure signatures**: Performance degrades significantly after intervention, no improvement in standard deviation, hyperparameter tuning fails, identified directions don't generalize
- **First 3 experiments**: 1) Test with α=1, K=all heads on small yes/no dataset, 2) Vary N (10, 50, 100, 500) to find optimal range, 3) Compare against ITI baseline with 100 labels on ScienceQA

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How many unlabeled samples are needed to effectively identify bias directions, and how does this vary with dataset size and complexity?
- Basis in paper: [explicit] Even N < 100 can preserve accuracy; lowest std achieved at N = 300-1000
- Why unresolved: Paper suggests larger N may introduce noise but doesn't provide definitive optimal number
- What evidence would resolve it: Experiments varying N with analysis of relationship to standard deviation and explained variance ratio

### Open Question 2
- Question: How does STEER FAIR perform on non-enumerable bias like harmful text generation or misinformation?
- Basis in paper: [inferred] Paper mentions extending to non-enumerable bias as potential improvement area
- Why unresolved: No experimental results or analysis provided for non-enumerable bias
- What evidence would resolve it: Experiments on datasets involving harmful text generation or misinformation

### Open Question 3
- Question: How does performance compare to other debiasing methods like embedding-based models or post-hoc intervention?
- Basis in paper: [explicit] Only compared to ITI method, showing STEER FAIR outperforms ITI with 100 labels
- Why unresolved: Limited comparison to one other method without comprehensive analysis
- What evidence would resolve it: Experiments comparing STEER FAIR to range of other debiasing methods

## Limitations
- Generalizability of bias direction identification across different datasets and model architectures remains unclear
- Specific hyperparameter sensitivity (particularly α and K) was not fully explored across parameter space
- QR decomposition approach lacks extensive validation compared to simpler alternatives

## Confidence
- **High confidence**: Empirical demonstration that STEER FAIR reduces performance variance across prompt modifications on three benchmark tasks
- **Medium confidence**: Claim that unsupervised STEER FAIR outperforms supervised baseline with 100 labels by 10.86% accuracy points, given limited ablation studies on training set size
- **Medium confidence**: Assertion that identified bias directions are linearly separable and captured by first principal components, based primarily on explained variance analysis

## Next Checks
1. **Cross-architecture validation**: Test STEER FAIR's effectiveness on models from different architectural families (e.g., BERT, OPT) to assess generalizability beyond decoder-only transformers

2. **Bias direction stability analysis**: Systematically vary N (from 10 to 1000) and measure stability of identified bias directions using cosine similarity between direction vectors across different random seeds

3. **Ablation on combination method**: Compare QR decomposition against simple averaging and weighted averaging for combining bias directions, measuring both performance variance reduction and absolute accuracy to quantify orthogonalization benefit