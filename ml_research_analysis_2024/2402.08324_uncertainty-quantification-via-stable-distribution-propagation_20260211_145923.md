---
ver: rpa2
title: Uncertainty Quantification via Stable Distribution Propagation
arxiv_id: '2402.08324'
source_url: https://arxiv.org/abs/2402.08324
tags:
- distribution
- gaussian
- network
- marginal
- distributions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Stable Distribution Propagation (SDP), a
  method for propagating Gaussian and Cauchy input uncertainties through neural networks
  to quantify output uncertainties. The core idea is to use local linearization for
  non-linear layers, which is shown to be optimal in terms of total variation distance
  for the ReLU non-linearity.
---

# Uncertainty Quantification via Stable Distribution Propagation

## Quick Facts
- arXiv ID: 2402.08324
- Source URL: https://arxiv.org/abs/2402.08324
- Reference count: 40
- Introduces Stable Distribution Propagation (SDP) for propagating Gaussian and Cauchy input uncertainties through neural networks

## Executive Summary
This paper presents Stable Distribution Propagation (SDP), a method for propagating uncertainty through neural networks by leveraging local linearization for non-linear layers. The approach demonstrates theoretical optimality in terms of total variation distance for ReLU non-linearities and enables efficient propagation of covariances and correlated scales. SDP is evaluated on UCI regression tasks and selective prediction for out-of-distribution detection, showing competitive performance against baseline methods.

## Method Summary
SDP operates by approximating non-linear transformations in neural networks through local linearization, which is theoretically justified for ReLU activations in terms of total variation distance. This linearization allows for efficient propagation of uncertainty distributions (Gaussian and Cauchy) through network layers while maintaining computational tractability. The method can handle correlated uncertainties and scales effectively to high-dimensional problems. For selective prediction tasks, SDP is combined with the MS-RIO algorithm to enable confidence-calibrated abstention from uncertain predictions.

## Key Results
- On UCI regression tasks, SDP achieves competitive or superior performance compared to baselines in terms of prediction interval coverage probability and mean prediction interval width
- For selective prediction on MNIST with EMNIST letters as out-of-distribution data, SDP achieves an AUC of 18.3%, outperforming baseline approaches
- The method demonstrates broad applicability across different uncertainty quantification scenarios, from calibrated confidence intervals to out-of-distribution detection

## Why This Works (Mechanism)
The effectiveness of SDP stems from its theoretically grounded approach to approximating non-linear transformations through local linearization. For ReLU activations specifically, this linearization is optimal in terms of total variation distance, providing a principled way to propagate uncertainty through otherwise intractable non-linearities. By maintaining distributional information (mean and covariance for Gaussians, scale parameters for Cauchy) rather than just point estimates, SDP captures the full uncertainty structure through the network.

## Foundational Learning
- **Total Variation Distance**: A measure of the difference between probability distributions, used here to quantify the optimality of linearization approximations - needed to theoretically justify the approximation approach, check by comparing TV distances between exact and linearized transformations
- **Gaussian and Cauchy Distribution Propagation**: The mathematical framework for propagating these specific distributions through linear transformations - essential for the core methodology, verify by confirming the propagation equations for means and covariances/scales
- **Local Linearization**: The technique of approximating non-linear functions with their first-order Taylor expansions around operating points - fundamental to making uncertainty propagation computationally tractable, test by examining approximation error as a function of non-linearity curvature
- **Selective Prediction**: The paradigm of abstaining from making predictions when uncertainty exceeds a threshold - critical for practical deployment in safety-critical applications, validate by measuring coverage-probability trade-offs
- **Covariance Propagation**: The method for tracking how uncertainty correlations evolve through network layers - necessary for capturing realistic uncertainty structures, check by verifying positive semi-definiteness preservation
- **Activation Function Analysis**: The study of how different non-linearities (ReLU, tanh) affect uncertainty propagation - important for understanding method limitations, examine by comparing propagation behavior across activation types

## Architecture Onboarding

**Component Map**: Input Distribution -> Linear Layers (exact propagation) -> Non-linear Layers (linearized) -> Output Distribution

**Critical Path**: The core computational path involves propagating mean and covariance (for Gaussians) or scale parameters (for Cauchy) through each layer, with linearization applied at non-linearities to maintain tractability

**Design Tradeoffs**: The method trades exactness for computational efficiency by linearizing non-linearities, enabling uncertainty propagation through deep networks at reasonable computational cost. This introduces approximation errors but maintains tractability for high-dimensional problems.

**Failure Signatures**: Performance degradation occurs when: 1) input distributions deviate significantly from Gaussian/Cauchy assumptions, 2) network contains highly non-linear regions where linearization breaks down, 3) depth is excessive leading to accumulated linearization errors, or 4) activation functions differ substantially from those analyzed (ReLU, tanh).

**3 First Experiments**:
1. Verify mean and variance propagation through a single linear layer with Gaussian input
2. Test linearization accuracy for ReLU activation across different input regimes
3. Evaluate uncertainty propagation through a simple two-layer network with synthetic data

## Open Questions the Paper Calls Out
None specified in the provided materials.

## Limitations
- Theoretical optimality proof for ReLU linearization is limited to specific conditions and may not generalize to all network architectures or data distributions
- Performance with non-Gaussian input distributions beyond Cauchy, and with activation functions other than ReLU and tanh, remains unexplored
- Experimental validation uses relatively small-scale datasets compared to modern deep learning benchmarks, limiting generalizability

## Confidence
- Theoretical optimality proof for ReLU: **High**
- Competitive performance on UCI datasets: **Medium** (limited dataset diversity)
- Out-of-distribution detection capabilities: **Medium** (single OOD scenario tested)

## Next Checks
1. Test SDP on larger-scale datasets (ImageNet, CIFAR-100) to assess scalability and performance in modern deep learning contexts
2. Evaluate robustness to non-Gaussian input distributions (Laplace, multimodal) and alternative activation functions (Leaky ReLU, ELU)
3. Conduct ablation studies on network depth to quantify the impact of accumulated linearization errors on uncertainty estimates