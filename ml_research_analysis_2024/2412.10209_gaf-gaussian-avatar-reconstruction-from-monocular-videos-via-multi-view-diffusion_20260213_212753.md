---
ver: rpa2
title: 'GAF: Gaussian Avatar Reconstruction from Monocular Videos via Multi-view Diffusion'
arxiv_id: '2412.10209'
source_url: https://arxiv.org/abs/2412.10209
tags:
- head
- diffusion
- novel
- multi-view
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of reconstructing photorealistic
  and animatable 3D head avatars from monocular videos captured by commodity devices.
  The limited observations in such videos leave unobserved regions under-constrained,
  leading to artifacts in novel view synthesis.
---

# GAF: Gaussian Avatar Reconstruction from Monocular Videos via Multi-view Diffusion

## Quick Facts
- arXiv ID: 2412.10209
- Source URL: https://arxiv.org/abs/2412.10209
- Authors: Jiapeng Tang; Davide Davoli; Tobias Kirschstein; Liam Schoneveld; Matthias Niessner
- Reference count: 40
- Primary result: Introduces GAF method for photorealistic 3D head avatar reconstruction from monocular videos, outperforming state-of-the-art methods in novel view synthesis and expression synthesis.

## Executive Summary
This paper tackles the challenge of reconstructing photorealistic and animatable 3D head avatars from monocular videos captured by commodity devices. The limited observations in such videos leave unobserved regions under-constrained, leading to artifacts in novel view synthesis. To address this, the authors introduce a multi-view head diffusion model that leverages priors to fill in missing regions and ensure view consistency. They use normal maps rendered from FLAME-based head reconstruction for precise viewpoint control and condition the diffusion model on VAE features to preserve facial identity and appearance details. For Gaussian avatar reconstruction, they distill multi-view diffusion priors by using iteratively denoised images as pseudo-ground truths, mitigating over-saturation issues. Evaluations on the NeRSemble dataset show that GAF outperforms previous state-of-the-art methods in novel view synthesis and expression synthesis.

## Method Summary
The method reconstructs 3D head avatars from monocular videos using Gaussian splatting with multi-view diffusion priors. First, it tracks FLAME head parameters from input videos and renders normal maps for viewpoint control. A multi-view diffusion model is trained to generate consistent multi-view images conditioned on normal maps and VAE features. For Gaussian avatar reconstruction, the method uses iteratively denoised images from the diffusion model as pseudo-ground truths for optimization. A latent upsampler refines the denoised latents before decoding to images. The optimized Gaussian splats are then rigged to the FLAME mesh for animation. The approach addresses the under-constrained nature of monocular video input by leveraging learned priors to fill unobserved regions and ensure view consistency.

## Key Results
- GAF outperforms previous state-of-the-art methods (INSTA, FlashAvatar, GA) in novel view synthesis on NeRSemble dataset
- Achieves superior performance in expression synthesis, demonstrating high-fidelity avatar reconstructions
- Effectively mitigates over-saturation issues through iterative denoising approach
- Preserves facial identity and appearance details through VAE feature conditioning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-view diffusion priors fill unobserved regions and ensure view consistency in Gaussian splatting renderings.
- Mechanism: By training a multi-view head diffusion model on multi-view video data, the model learns to jointly generate consistent images across multiple views conditioned on a single input image and normal maps. This learned prior is then used to regularize the optimization of Gaussian avatars, filling in missing regions that are unobserved in the monocular video input.
- Core assumption: The multi-view head diffusion model has learned sufficient priors about head geometry and appearance to plausibly complete unobserved regions.
- Evidence anchors:
  - [abstract]: "To address this problem, we introduce a multi-view head diffusion model, leveraging its priors to fill in missing regions and ensure view consistency in Gaussian splatting renderings."
  - [section 4.2]: "We now seek to utilize the multi-view diffusion priors for head Gaussian reconstruction... effectively mitigating over-saturation issues."
  - [corpus]: Weak evidence. No direct mention of multi-view diffusion in related papers, but several papers mention diffusion-guided Gaussian splatting for unconstrained 3D reconstruction.

### Mechanism 2
- Claim: Normal maps from FLAME reconstruction provide precise viewpoint control for the diffusion model.
- Mechanism: Instead of using camera pose embeddings, the diffusion model is conditioned on normal maps rendered from the FLAME mesh reconstruction. These normal maps provide pixel-aligned inductive biases that facilitate alignment between the generated images and the conditioning normal maps, enabling more precise and reliable novel view generation for heads.
- Core assumption: Normal maps contain sufficient information to accurately represent the head geometry from different viewpoints.
- Evidence anchors:
  - [abstract]: "To enable precise viewpoint control, we use normal maps rendered from FLAME-based head reconstruction, which provides pixel-aligned inductive biases."
  - [section 4.1]: "To control viewpoint, we leverage normal maps rendered from the FLAME mesh reconstruction at target views as diffusion guidance."
  - [corpus]: Weak evidence. No direct mention of normal maps in related papers, but several papers mention camera pose conditioning for diffusion models.

### Mechanism 3
- Claim: Iteratively denoised images as pseudo-ground truths mitigate over-saturation issues in Gaussian avatar reconstruction.
- Mechanism: Instead of using a single-step score distillation sampling loss, the method uses iteratively denoised images as pseudo-ground truths for novel view supervision. This iterative denoising process reduces the stochasticity and noisy gradients that can cause over-saturated appearance issues in synthesized 3D assets.
- Core assumption: Iteratively denoised images provide a more stable and accurate supervision signal than single-step denoising.
- Evidence anchors:
  - [abstract]: "For Gaussian avatar reconstruction, we distill multi-view diffusion priors by using iteratively denoised images as pseudo-ground truths, effectively mitigating over-saturation issues."
  - [section 4.2]: "At each iteration, we randomly select the i-th input frame Ii and its FLAME mesh Mi... Then z0 is decoded back to 4 images {Ë†Ij i } that are served as pseudo supervision."
  - [corpus]: Weak evidence. No direct mention of iteratively denoised images in related papers, but the paper "Reconfusion: 3D reconstruction with diffusion priors" is cited, which may be related to this approach.

## Foundational Learning

- Concept: 3D Gaussian Splatting
  - Why needed here: Gaussian splatting is used to represent the 3D head avatar, providing real-time rendering and efficient geometry representation.
  - Quick check question: What are the key parameters of a 3D Gaussian splat, and how do they affect the rendered appearance?

- Concept: Diffusion Models
  - Why needed here: Diffusion models are used to learn multi-view priors for head appearance and geometry, enabling the completion of unobserved regions and ensuring view consistency.
  - Quick check question: How does a diffusion model generate novel views from a single input image, and what role do the conditioning factors play?

- Concept: FLAME Head Model
  - Why needed here: The FLAME head model is used to provide a parametric head mesh for normal map generation and to rig the Gaussian splats for animation.
  - Quick check question: What are the key parameters of the FLAME head model, and how do they control head pose and expression?

## Architecture Onboarding

- Component map:
  - Monocular video -> FLAME head tracking -> Normal map generation -> Multi-view head diffusion model -> Iteratively denoised images -> Gaussian avatar reconstruction -> Animatable head avatar

- Critical path: Monocular video -> FLAME head tracking -> Multi-view head diffusion -> Gaussian avatar reconstruction -> Animatable head avatar

- Design tradeoffs:
  - Using normal maps vs. camera pose embeddings for viewpoint control: Normal maps provide more precise control but require accurate FLAME reconstruction.
  - Iteratively denoised images vs. single-step denoising for pseudo-ground truths: Iterative denoising reduces over-saturation but increases computational cost.

- Failure signatures:
  - Artifacts in unobserved regions: Indicates insufficient priors learned by the multi-view diffusion model.
  - Inconsistencies across views: Suggests misalignment between the normal maps and the generated images.
  - Over-saturated appearance: May be caused by noisy gradients from single-step denoising.

- First 3 experiments:
  1. Ablation study: Replace normal maps with camera pose embeddings to assess the impact on viewpoint control and view consistency.
  2. Ablation study: Use single-step denoising instead of iterative denoising to evaluate the effect on over-saturation and reconstruction quality.
  3. Qualitative evaluation: Visualize the generated multi-view images from the diffusion model to assess identity preservation and view consistency.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but based on the limitations section, some potential open questions include:

1. How does the performance of GAF scale with increasing head pose variations in the input video?
2. Can the multi-view head diffusion model be effectively trained on datasets with significantly different head appearances (e.g., diverse ethnicities, ages)?
3. What is the impact of different VAE architectures on the quality of the multi-view head diffusion model?

## Limitations
- Performance may degrade with extreme head poses or complex backgrounds not well-represented in training data
- Computational cost of iterative denoising and Gaussian avatar optimization may limit real-time applications
- Generalizability to diverse head shapes and appearances beyond the NeRSemble dataset remains unclear

## Confidence
- Confidence Level: Medium
- Main claims about effectiveness of multi-view diffusion priors, normal map conditioning, and iterative denoising are supported by quantitative results on NeRSemble dataset
- Performance on more challenging real-world scenarios with complex backgrounds, occlusions, and extreme poses remains to be validated

## Next Checks
1. Evaluate the method on a larger and more diverse dataset of monocular videos, including challenging scenarios with occlusions, extreme poses, and varying lighting conditions.
2. Conduct an ablation study to assess the individual contributions of the multi-view diffusion priors, normal map conditioning, and iterative denoising approach to the overall performance.
3. Compare the proposed method with state-of-the-art monocular 3D head reconstruction techniques in terms of runtime efficiency, memory usage, and robustness to tracking failures or occlusions.