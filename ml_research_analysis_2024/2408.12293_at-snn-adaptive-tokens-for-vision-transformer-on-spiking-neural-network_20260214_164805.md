---
ver: rpa2
title: 'AT-SNN: Adaptive Tokens for Vision Transformer on Spiking Neural Network'
arxiv_id: '2408.12293'
source_url: https://arxiv.org/abs/2408.12293
tags:
- tokens
- halting
- accuracy
- timesteps
- block
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes AT-SNN, a method to dynamically adjust the
  number of tokens processed during inference in SNN-based vision transformers. It
  applies adaptive computation time (ACT) to SNNs for the first time, enabling selective
  discarding of less informative spatial tokens.
---

# AT-SNN: Adaptive Tokens for Vision Transformer on Spiking Neural Network

## Quick Facts
- arXiv ID: 2408.12293
- Source URL: https://arxiv.org/abs/2408.12293
- Reference count: 7
- Primary result: Applies adaptive computation time (ACT) to SNNs for the first time, achieving up to 42.4% token reduction on CIFAR-100 with higher accuracy than state-of-the-art methods

## Executive Summary
AT-SNN introduces a novel adaptive token mechanism for vision transformers implemented on spiking neural networks (SNNs). The method dynamically adjusts the number of spatial tokens processed during inference by selectively discarding less informative tokens based on a two-dimensional halting policy across timesteps and network blocks. This approach achieves higher accuracy with significantly fewer tokens compared to existing methods, while also reducing computational energy consumption.

## Method Summary
AT-SNN integrates adaptive computation time (ACT) into SNN-based vision transformers by implementing a two-dimensional halting policy that determines when to stop processing tokens both across timesteps and network blocks. The method introduces a token-merge mechanism based on token similarity to combine less informative tokens, reducing the total token count while preserving essential information. Implemented on the Spikformer architecture, this adaptive approach selectively processes only the most relevant tokens for each input image, achieving computational efficiency without sacrificing accuracy.

## Key Results
- Achieves higher accuracy than state-of-the-art methods while using significantly fewer tokens
- Reduces token count by up to 42.4% on CIFAR-100 benchmark
- Demonstrates effective energy consumption reduction through selective token processing
- Successfully applies ACT to SNNs for the first time in vision transformer applications

## Why This Works (Mechanism)
The adaptive token mechanism works by leveraging the inherent sparsity of spiking neural networks combined with dynamic computation halting. By evaluating token importance across both temporal and spatial dimensions, the system can identify and discard redundant or uninformative tokens early in the processing pipeline. The token-merge strategy preserves spatial relationships while reducing computational load, and the two-dimensional halting policy ensures that computation stops as soon as sufficient information has been extracted. This selective processing aligns with the energy-efficient nature of SNNs while maintaining or improving classification accuracy.

## Foundational Learning
- **Spiking Neural Networks (SNNs)**: Bio-inspired neural networks that communicate via discrete spikes rather than continuous values. Needed for understanding the computational substrate and energy efficiency characteristics.
- **Vision Transformers**: Deep learning models that process images using self-attention mechanisms across spatial tokens. Required to understand how spatial information is represented and processed.
- **Adaptive Computation Time (ACT)**: A method for dynamically adjusting the number of computational steps based on input difficulty. Essential for grasping how computation can be allocated efficiently.
- **Token-based Processing**: The concept of representing images as sequences of spatial tokens that can be individually processed. Critical for understanding the granularity of the adaptive mechanism.
- **Halting Policy**: A mechanism that determines when to stop computation for each token. Key to understanding how the system decides which tokens to keep or discard.
- **Token Similarity Measures**: Methods for evaluating the redundancy or importance of spatial tokens. Important for understanding the token-merge strategy.

## Architecture Onboarding

**Component Map:**
Input Image → Spatial Tokenization → Adaptive Token Selection → Token Processing Blocks → Classification Head

**Critical Path:**
The critical computational path involves the adaptive token selection mechanism, which must evaluate token importance across timesteps and blocks before routing tokens to subsequent processing stages. This creates a dependency where the number of active tokens can vary dynamically during inference.

**Design Tradeoffs:**
The method trades implementation complexity for computational efficiency, requiring additional logic for token evaluation and merging. The two-dimensional halting policy adds overhead but enables more precise control over computation. The token-merge strategy must balance between reducing token count and preserving spatial information integrity.

**Failure Signatures:**
Potential failures include premature halting of important tokens, excessive token merging leading to loss of spatial resolution, and inconsistent performance across different input difficulty levels. The method may also struggle with tasks requiring fine-grained spatial detail.

**First Experiments:**
1. Test adaptive token behavior on simple MNIST images to verify basic functionality
2. Compare token reduction rates across CIFAR-10 and CIFAR-100 to establish dataset sensitivity
3. Evaluate accuracy retention when varying the halting policy thresholds to understand hyperparameter sensitivity

## Open Questions the Paper Calls Out
None

## Limitations
- Generalization across diverse vision tasks beyond standard image classification benchmarks remains unproven
- The token-merge strategy may not optimally handle cases where semantically important tokens have high spatial correlation
- Computational overhead of the halting policy and token-merge operations is not thoroughly quantified
- Energy consumption reduction claims rely on assumptions about spike-based hardware implementations

## Confidence

**High Confidence:**
- Implementation of ACT within the SNN framework is well-described and reproducible
- Experimental results demonstrating token reduction and accuracy maintenance on standard benchmarks are clearly presented

**Medium Confidence:**
- Energy consumption reduction claims rely on assumptions about spike-based hardware implementations
- The novelty claim of applying ACT to SNNs for the first time requires careful verification against related work

## Next Checks
1. Evaluate AT-SNN on a diverse set of vision tasks including object detection and semantic segmentation to assess cross-task generalization
2. Conduct ablation studies to quantify the computational overhead of the halting policy and token-merge operations
3. Test the method's robustness to different token similarity thresholds and analyze sensitivity to hyperparameters across datasets