---
ver: rpa2
title: Medical Dialogue Generation via Intuitive-then-Analytical Differential Diagnosis
arxiv_id: '2401.06541'
source_url: https://arxiv.org/abs/2401.06541
tags:
- dialogue
- diagnosis
- medical
- generation
- diseases
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating accurate and interpretable
  medical dialogue responses by explicitly modeling the differential diagnosis process.
  The proposed framework, IADDx, employs intuitive-then-analytic reasoning to generate
  a differential diagnosis.
---

# Medical Dialogue Generation via Intuitive-then-Analytical Differential Diagnosis

## Quick Facts
- arXiv ID: 2401.06541
- Source URL: https://arxiv.org/abs/2401.06541
- Authors: Kaishuai Xu; Wenjun Hou; Yi Cheng; Jian Wang; Wenjie Li
- Reference count: 15
- Primary result: Outperforms state-of-the-art methods in both response quality and differential diagnosis accuracy

## Executive Summary
This paper introduces IADDx, a framework that improves medical dialogue generation by explicitly modeling the differential diagnosis process. The system uses intuitive-then-analytic reasoning: first retrieving similar cases and disease documents to form a preliminary diagnosis list, then refining it using a graph-enhanced multi-disease classifier. The framework achieves significant improvements in both response quality (BLEU/ROUGE scores) and diagnostic accuracy while providing interpretable diagnostic paths through a diagnosis-oriented entity graph.

## Method Summary
IADDx operates in two stages to generate medical dialogue responses. The intuitive stage retrieves similar patient cases and disease documents to form an initial differential diagnosis list. The analytic stage refines this list using a graph-enhanced multi-disease classifier that leverages a diagnosis-oriented entity graph connecting body systems, organs, diseases, and symptoms. The resulting differential diagnosis guides knowledge retrieval and response generation through a FiD-based generation model, with dialogue acts predicted to determine the most relevant knowledge for each response.

## Key Results
- Significantly outperforms state-of-the-art methods on both MedDG and KaMed datasets
- Improves BLEU and ROUGE scores for response quality
- Achieves better entity precision/recall/F1 and disease F1 scores for differential diagnosis accuracy
- Provides interpretable diagnostic paths through the diagnosis-oriented entity graph

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The two-stage differential diagnosis improves both accuracy and interpretability
- Mechanism: Intuitive stage narrows potential diseases through case/document retrieval, analytic stage refines using diagnosis-oriented graph
- Core assumption: Explicit modeling of differential diagnosis leads to more reliable responses
- Evidence anchors: Abstract and methodology sections describe the two-stage process
- Break condition: Failure of intuitive association retrieval collapses the entire foundation

### Mechanism 2
- Claim: Diagnosis-oriented entity graph provides interpretable diagnostic paths
- Mechanism: Connects systems → organs → diseases → symptoms to explain reasoning
- Core assumption: Clinicians and patients value interpretable reasoning over black-box predictions
- Evidence anchors: Abstract mentions graph enhances and interprets diagnostic process
- Break condition: Overly complex graph may hinder rather than help interpretability

### Mechanism 3
- Claim: Graph-enhanced multi-disease classifier improves diagnostic accuracy
- Mechanism: Uses cross-attention between SOAP segments and entity embeddings for multi-disease prediction
- Core assumption: Domain knowledge through DOG provides better context than statistical approaches
- Evidence anchors: Abstract describes classifier leveraging domain knowledge
- Break condition: Graph attention overfitting to training data relationships

## Foundational Learning

- Concept: Differential diagnosis process
  - Why needed here: Framework is built around explicitly modeling this clinical reasoning
  - Quick check question: What are the two main types of reasoning clinicians use when forming a differential diagnosis?

- Concept: Knowledge retrieval for medical applications
  - Why needed here: Framework relies on retrieving relevant patient cases and disease documents
  - Quick check question: How does the system determine which patient cases are "similar" to the current patient's presentation?

- Concept: Graph neural networks and attention mechanisms
  - Why needed here: DOG uses GAT to update entity embeddings and cross-attention for classification
  - Quick check question: How does the GAT layer update entity embeddings based on neighboring information?

## Architecture Onboarding

- Component map: Intuitive Association (retriever + BERT encoder) → Analytic Refinement (DOG + GAT + multi-disease classifier) → Diagnosis-guided Response Generation (act predictor + knowledge retriever + generator)
- Critical path: SOAP extraction → intuitive association retrieval → analytic refinement with DOG → knowledge retrieval guided by diagnosis → response generation
- Design tradeoffs: DOG provides interpretability but adds complexity; two-stage approach is more accurate but slower; knowledge retrieval adds specificity but requires comprehensive corpus
- Failure signatures: Poor retrieval quality leads to wrong preliminary diagnosis; DOG construction errors propagate; incorrect dialogue act prediction leads to irrelevant knowledge retrieval
- First 3 experiments:
  1. Test intuitive association retrieval with known similar cases to verify relevance scoring
  2. Validate DOG construction by checking entity connections against medical knowledge sources
  3. Evaluate multi-disease classifier predictions against ground truth diagnoses on validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the framework be adapted to handle multiple languages or non-English medical dialogue datasets?
- Basis in paper: Uses MedBERT pre-trained on Chinese medical documents
- Why unresolved: Paper focuses on Chinese datasets without discussing multilingual adaptations
- What evidence would resolve it: Experiments applying framework to non-Chinese datasets or integrating multilingual capabilities

### Open Question 2
- Question: What are the limitations of current diagnosis-oriented graph construction and how can it capture more complex medical relationships?
- Basis in paper: Mentions using diagnosis-oriented graph but doesn't analyze limitations
- Why unresolved: Paper doesn't provide comprehensive analysis of graph limitations
- What evidence would resolve it: Analysis of graph performance on various medical scenarios and suggestions for incorporating more complex relationships

### Open Question 3
- Question: How does framework performance compare to human clinicians in real-world diagnosis and dialogue generation?
- Basis in paper: Mentions assisting clinicians and patients but doesn't compare to human performance
- Why unresolved: Paper evaluates against baseline models, not human clinicians
- What evidence would resolve it: Study comparing framework diagnostic accuracy and dialogue quality with human clinicians in real-world settings

## Limitations
- Performance may not generalize beyond tested medical specialties and Chinese datasets
- Two-stage approach adds significant computational overhead compared to simpler methods
- Framework heavily depends on quality and comprehensiveness of medical knowledge corpus

## Confidence

**High Confidence Claims**:
- Two-stage differential diagnosis framework architecture is sound
- Framework outperforms baseline methods on tested datasets
- DOG provides interpretable diagnostic paths as claimed

**Medium Confidence Claims**:
- Framework performance generalizes to other medical domains
- Interpretability benefits outweigh added complexity in clinical settings
- Knowledge retrieval consistently provides relevant information across diverse presentations

## Next Checks

1. Test framework on medical dialogue datasets from different specialties and languages to assess generalizability
2. Conduct blinded study with practicing clinicians to evaluate interpretability and clinical utility of DOG-generated diagnostic paths
3. Measure inference time and resource requirements of two-stage approach versus single-stage alternatives, focusing on DOG construction and knowledge retrieval impact