---
ver: rpa2
title: Interpreting Affine Recurrence Learning in GPT-style Transformers
arxiv_id: '2410.17438'
source_url: https://arxiv.org/abs/2410.17438
tags:
- layer
- vector
- vectors
- attention
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how GPT-style transformers perform in-context
  learning (ICL) on affine recurrence tasks by training a custom three-layer transformer
  and analyzing its internal mechanisms. The authors trained the model on normalized
  affine recurrence sequences and examined attention patterns, OV circuits, and direct
  logit attributions across layers.
---

# Interpreting Affine Recurrence Learning in GPT-style Transformers

## Quick Facts
- arXiv ID: 2410.17438
- Source URL: https://arxiv.org/abs/2410.17438
- Reference count: 16
- The paper analyzes how three-layer transformers learn to predict affine recurrence sequences through copying and negative similarity mechanisms.

## Executive Summary
This paper investigates how GPT-style transformers perform in-context learning on affine recurrence tasks by training a custom three-layer transformer and analyzing its internal mechanisms. The authors examine attention patterns, OV circuits, and direct logit attributions across layers to understand how the model solves the task of predicting the next vector in an affine recurrence sequence. The study reveals a clear mechanistic picture: the zeroth layer forms a crude estimate by copying and scaling the previous vector, the second layer refines this estimate using negative similarity heads that subtract similar vectors, and the first layer contributes minimally as a bias term. This work advances mechanistic interpretability of transformer behaviors in numerical analysis tasks and provides insights for future research on higher-dimensional recurrences and polynomial sequences.

## Method Summary
The authors trained a custom three-layer transformer (dmodel=128, dhead=64, dmlp=3072) on normalized affine recurrence sequences with 40-dimensional vectors and sequence lengths 3-14. The model was trained for 100,000 steps using AdamW optimizer with weight decay 0.01 and learning rate 0.0001, achieving 0.0001 MSE on test data. They applied interpretability techniques including direct logit attribution, attention pattern visualization, and OV/QK circuit analysis to examine how the model solves the affine recurrence task. The analysis focused on identifying layer-specific mechanisms, particularly the copying behavior in the zeroth layer and negative similarity heads in the second layer.

## Key Results
- The zeroth layer forms an initial crude estimate by copying and scaling the previous vector with R² = 0.83 linear relationship
- The second layer refines the initial estimate using negative similarity heads with checkerboard attention patterns for alternating sequences
- The first layer contributes minimally, acting more like a bias term with near-zero direct logit attribution scores

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The zeroth layer forms an initial crude estimate by copying and scaling the previous vector
- Mechanism: The zeroth layer attention patterns show strong focus on the previous vector (previous token head behavior). The OV circuits demonstrate a linear relationship between input and output vectors with slopes between 2.1-2.5, suggesting the operation ⃗vn → ⃗vn + α⃗vn−1 where α > 2
- Core assumption: The OV circuit analysis accurately captures the transformation being applied to residual stream vectors
- Evidence anchors:
  - [abstract] "the zeroth layer forms an initial crude estimate by copying and scaling the previous vector"
  - [section 4.4] "OV Values of Residual Stream Vectors in Layer 0" shows R² = 0.83 linear relationship
  - [corpus] Weak evidence - corpus neighbors discuss attention patterns but not specific affine recurrence mechanisms

### Mechanism 2
- Claim: The second layer refines the initial estimate using negative similarity heads that subtract similar vectors
- Mechanism: The second layer exhibits checkerboard attention patterns for alternating sequences and QK circuits resembling positive identity matrices while OV circuits resemble negative identity matrices. This creates a "negative similarity" effect where similar vectors are subtracted from the destination vector
- Core assumption: The QK and OV circuit analysis correctly identifies the mathematical operations being performed
- Evidence anchors:
  - [abstract] "subsequently refined through negative similarity heads in the second layer"
  - [section 4.6] "Second Layer QK/OV Circuits" explicitly describes QK as positive identity and OV as negative identity
  - [corpus] Moderate evidence - corpus neighbors discuss attention heads but not specifically negative similarity mechanisms

### Mechanism 3
- Claim: The first layer acts as a bias term with minimal contribution to the actual computation
- Mechanism: Direct logit attributions for first layer heads are near zero, and ablation experiments show minimal performance degradation when first layer heads are removed. The OV circuits exhibit low effective rank and sparse structure
- Core assumption: Mean ablation is a valid method for determining head utility in this context
- Evidence anchors:
  - [abstract] "the first layer contributes minimally, acting more like a bias term"
  - [section 4.5] "First Layer" discusses ablation results and OV circuit sparsity
  - [corpus] Weak evidence - corpus neighbors don't discuss layer-specific contributions in affine recurrence tasks

## Foundational Learning

- Concept: Affine recurrence equations and their properties
  - Why needed here: The entire task revolves around predicting sequences defined by ⃗an = c⃗an−1 + ⃗d, requiring understanding of how linear transformations and constant offsets generate sequences
  - Quick check question: Given ⃗a0 = [1, 2], c = 2, ⃗d = [0, 1], what is ⃗a2?

- Concept: Transformer attention mechanisms and residual streams
  - Why needed here: The analysis relies on understanding how attention patterns direct information flow and how residual streams accumulate information across layers
  - Quick check question: In an autoregressive transformer, can position i attend to positions j where j > i?

- Concept: Mechanistic interpretability techniques (direct logit attribution, OV/QK circuit analysis)
  - Why needed here: The paper uses these specific techniques to analyze how the model solves the affine recurrence task, requiring understanding of what each technique measures
  - Quick check question: What does a positive eigenvalue score for an OV circuit indicate about a head's behavior?

## Architecture Onboarding

- Component map: Input → Embedding → Layer 0 (crude estimate via copying) → Layer 1 (minimal contribution) → Layer 2 (refinement via negative similarity) → Output
- Critical path: The model processes affine recurrence sequences through three layers, with each layer contributing specific transformations: zeroth layer creates initial estimate, first layer adds bias, second layer refines through negative similarity
- Design tradeoffs: Three layers chosen to balance computational efficiency with sufficient capacity for both crude estimation and refinement; normalization bounds prevent gradient explosion but may limit the range of learnable affine recurrences
- Failure signatures: Checkerboard pattern absence in layer 2 attention indicates non-alternating sequences; uniform attention patterns suggest the model cannot distinguish sequence positions; large MSE indicates failure to learn the recurrence pattern
- First 3 experiments:
  1. Verify zeroth layer copying behavior by inputting known affine recurrence sequences and checking if output ≈ input + α·previous
  2. Test second layer negative similarity by examining attention patterns on alternating vs non-alternating sequences
  3. Confirm first layer bias behavior by ablating heads and measuring performance impact on MSE

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do transformers handle higher-dimensional affine recurrences beyond the 40-dimensional case studied?
- Basis in paper: [explicit] The authors suggest extending analysis to higher-dimensional linear recurrences as future work, noting their code supports this functionality.
- Why unresolved: The current study only examined 40-dimensional vectors, leaving uncertainty about whether the observed mechanisms (zeroth layer copying, second layer negative similarity heads) scale effectively to higher dimensions.
- What evidence would resolve it: Training and analyzing transformers on 100+ dimensional affine recurrences while examining whether the same layer-specific mechanisms emerge and remain effective.

### Open Question 2
- Question: Can the same mechanistic interpretability techniques be applied to polynomial recurrences?
- Basis in paper: [explicit] The authors propose exploring polynomial sequences as future work, suggesting their interpretability framework might generalize.
- Why unresolved: Polynomial recurrences introduce non-linear terms that may require fundamentally different mechanisms than the linear affine case studied here.
- What evidence would resolve it: Training transformers on polynomial recurrence tasks and determining whether similar QK/OV circuit patterns emerge or if entirely different mechanisms are needed.

### Open Question 3
- Question: What is the precise role of the first layer heads that contribute minimally to the task?
- Basis in paper: [explicit] The authors found first layer heads have near-zero direct logit attribution scores and their ablation barely affects performance, yet they still have structured OV circuits.
- Why unresolved: While the paper suggests these heads act as bias terms, the exact functional purpose of maintaining structured but minimally-contributing heads remains unclear.
- What evidence would resolve it: Systematic ablation studies varying different types of inputs to first layer heads, or examining whether these heads become more important under different recurrence parameters or initialization conditions.

## Limitations

- The study focuses on a narrow problem class (affine recurrences) with fixed dimensionality (40D vectors) and sequence lengths (3-14), limiting generalizability
- Interpretability analyses rely heavily on linear relationship assumptions that may miss non-linear mechanisms
- The three-layer architecture was chosen for computational efficiency rather than being proven optimal for this task

## Confidence

**High confidence** in the zeroth layer copying mechanism: The evidence from OV circuit analysis (R² = 0.83) and attention pattern observations provides strong support for this claim. The linear relationship between input and output vectors is clearly demonstrated.

**Medium confidence** in the second layer negative similarity mechanism: While QK/OV circuit analysis shows the expected identity matrix relationships, the causal intervention experiments on QK circuits are described but not extensively validated. The checkerboard pattern interpretation is compelling but could have alternative explanations.

**Low confidence** in the first layer acting as bias: The ablation results and direct logit attribution scores suggest minimal contribution, but the analysis is less rigorous compared to other layers. The sparse OV circuit structure is observed but not conclusively linked to bias-like behavior.

## Next Checks

1. **Causal intervention validation**: Perform systematic ablation studies where first layer heads are removed individually and in combinations to quantify their exact contribution to task performance. Measure MSE degradation and analyze how residual stream vectors change.

2. **Cross-sequence generalization test**: Evaluate the model on affine recurrence sequences with different coefficients (c values outside the training distribution) and different vector dimensionalities to test the robustness of the learned mechanisms.

3. **Alternative interpretability verification**: Apply different interpretability techniques (such as path patching or activation maximization) to verify the QK/OV circuit analysis conclusions, particularly for the negative similarity mechanism in layer 2.