---
ver: rpa2
title: Real, fake and synthetic faces -- does the coin have three sides?
arxiv_id: '2404.01878'
source_url: https://arxiv.org/abs/2404.01878
tags:
- image
- images
- synthetic
- deepfake
- real
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper investigates the trends and patterns observed in real,
  deepfake, and synthetic facial images to determine if these three types of images
  can be considered as distinct classes. The analysis is conducted in two parts: first,
  the performance of eight deep learning models in distinguishing between the three
  classes is evaluated.'
---

# Real, fake and synthetic faces -- does the coin have three sides?

## Quick Facts
- arXiv ID: 2404.01878
- Source URL: https://arxiv.org/abs/2404.01878
- Authors: Shahzeb Naeem; Ramzi Al-Sharawi; Muhammad Riyyan Khan; Usman Tariq; Abhinav Dhall; Hasan Al-Nashash
- Reference count: 40
- Key outcome: Three types of facial images (real, deepfake, synthetic) form distinct classes based on deep learning classification and image property analysis

## Executive Summary
This paper investigates whether real, deepfake, and synthetic facial images represent three distinct classes by analyzing both classification performance and image properties. Using eight deep learning models, the authors demonstrate that these image types can be reliably distinguished, with ViT Patch-16 achieving 98.25% accuracy. The study also reveals systematic differences in image properties across the three classes, with synthetic images showing consistently lower values for brightness, luminosity, and detail compared to real and deepfake images.

## Method Summary
The study analyzes 30,000 facial images (10,000 each of real, deepfake, and synthetic) using a two-pronged approach. First, eight pre-trained deep learning models are trained to classify the three image types, with data augmentation applied during training. Second, images are divided into nine regions and six properties (brightness, sharpness, luminosity, RGB mean, contrast, detail) are computed for each region. Statistical analysis including ANOVA tests is performed to identify differences between classes.

## Key Results
- ViT Patch-16 achieved 97.37% sensitivity, 98.69% specificity, 97.48% precision, and 98.25% accuracy in three-way classification
- Synthetic images consistently show lower values for brightness, luminosity, green-mean, blue-mean, and detail compared to real and deepfake images
- ANOVA tests confirm statistically significant differences between classes across all analyzed image properties
- More complex deep learning models (ViT, EfficientNet, MobileNet) outperform simpler architectures for this classification task

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Synthetic facial images can be distinguished from real and deepfake images using image property analysis because they exhibit systematically different statistical distributions in visual features.
- Mechanism: The paper systematically measures six image properties (brightness, sharpness, luminosity, RGB mean, contrast, detail) across nine facial regions and entire images. Synthetic images consistently show lower average values for five of these properties (brightness, luminosity, green-mean, blue-mean, detail) while showing higher sharpness. These consistent patterns create separable distributions that deep learning models can exploit.
- Core assumption: The generative processes for synthetic faces produce systematically different image properties compared to real and deepfake images, and these differences are preserved across different facial regions.
- Evidence anchors:
  - [abstract] "The analysis of image properties reveals noticeable differences across the three categories of images, supporting the idea that synthetic, deepfake and real face images are indeed three different classes."
  - [section] "We saw noticeable differences across the three category of images" and "the synthetic class is typically below the curves of the other two classes, thus indicating lower average values across all image regions for each of the image properties"
  - [corpus] Weak - the related papers focus on detection methods but don't analyze the fundamental property differences between synthetic and deepfake images
- Break condition: If generative models improve to the point where synthetic images match real image property distributions, this mechanism would fail. Also fails if the property measurement methods don't capture the actual perceptual differences.

### Mechanism 2
- Claim: Deep learning models can effectively classify the three image types because the task involves learning distinct feature distributions rather than subtle variations within a single class.
- Mechanism: The paper tests eight different deep learning architectures, finding that more complex models (ViT Patch-16, EfficientNet-b0, MobileNetV2) perform significantly better than simpler ones (DenseNet-121, ShuffleNet-v2, VGG-16). This suggests the classification task requires learning complex feature hierarchies that simpler models cannot capture.
- Core assumption: The three image classes have sufficiently distinct feature distributions that deep learning models can learn to separate them with high accuracy.
- Evidence anchors:
  - [abstract] "ViT Patch-16 model performing best on this task with a class-averaged sensitivity, specificity, precision, and accuracy of 97.37%, 98.69%, 97.48%, and 98.25%, respectively"
  - [section] "The models that achieved good classification performance tended to be more complex compared to those that achieved bad classification performance, indicating the need for complex deep learning models to correctly classify between real images, deepfake images, and synthetic images"
  - [corpus] Weak - related papers focus on binary deepfake detection rather than three-way classification
- Break condition: If the feature distributions between classes become too similar (e.g., if synthetic and deepfake generation methods converge), classification accuracy would drop significantly.

### Mechanism 3
- Claim: The nine-region facial decomposition approach enables more robust classification by capturing local variations that may differ between image types.
- Mechanism: By dividing each facial image into nine non-overlapping regions and analyzing properties in each region separately, the method captures localized artifacts or quality differences that might be averaged out in whole-image analysis. The ANOVA test confirms that differences between classes are statistically significant across regions.
- Core assumption: Different image generation methods produce region-specific artifacts or quality variations that can be detected through localized analysis.
- Evidence anchors:
  - [abstract] "we look to further delve into the similarities and differences between these three sets of images by investigating their image properties both in the context of the entire image as well as in the context of specific regions within the image"
  - [section] "Analysis is performed on these non-overlapping portions of the image and on the entire image" and "ANOVA test was also performed and provided further clarity amongst the patterns associated between the images of the three classes"
  - [corpus] Weak - related papers don't mention region-based analysis approaches
- Break condition: If region-based analysis doesn't provide additional discriminative power over whole-image analysis, or if the regions don't align well with where artifacts occur.

## Foundational Learning

- Concept: Image property measurement and statistical analysis
  - Why needed here: The paper relies on computing and comparing multiple image properties (brightness, sharpness, etc.) across different regions and classes. Understanding how these measurements work and how to interpret their statistical significance is crucial for evaluating the results.
  - Quick check question: What does a low p-value in the ANOVA test indicate about the differences between image classes for a particular property?

- Concept: Deep learning model architecture and performance metrics
  - Why needed here: The paper uses eight different deep learning models and reports multiple performance metrics (sensitivity, specificity, precision, accuracy). Understanding these architectures and metrics is essential for interpreting which models work best and why.
  - Quick check question: Why might a more complex model like ViT Patch-16 outperform simpler models like DenseNet-121 on this three-class classification task?

- Concept: Image preprocessing and face detection techniques
  - Why needed here: The paper describes specific preprocessing steps including face detection with YOLOv8 Nano, pose filtering, and region extraction. Understanding these techniques is important for reproducing the results and understanding potential biases.
  - Quick check question: How does constraining images to frontal or near-frontal poses help reduce variability in the classification task?

## Architecture Onboarding

- Component map: Dataset loading (real, deepfake, synthetic) → Preprocessing (face detection, pose filtering, region extraction) → Augmentation (flipping, rotation, grayscale, etc.) → Model training (8 architectures) → Evaluation (confusion matrices, performance metrics) → Image property computation (6 properties × 9 regions + whole image) → Statistical analysis (ANOVA) → Visualization (line plots, p-value plots)

- Critical path: The most critical path is the data preprocessing → model training/evaluation sequence, as errors in preprocessing (especially face detection and region extraction) would propagate through all subsequent analysis.

- Design tradeoffs: The paper trades computational efficiency for thoroughness by using nine regions per image plus whole-image analysis, and by testing eight different deep learning architectures. This provides comprehensive insights but requires significant computational resources.

- Failure signatures: Poor face detection accuracy would manifest as mis-aligned regions and invalid property measurements. If models show high accuracy on synthetic but poor accuracy on real/deepfake, this suggests the property differences are driving the results rather than learning robust features.

- First 3 experiments:
  1. Verify face detection and region extraction work correctly by visualizing preprocessed images and regions
  2. Test image property computation on a small subset of images to ensure calculations match expectations
  3. Train a simple baseline model (e.g., logistic regression on image properties) to establish whether property-based classification is feasible before using complex deep learning models

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the patterns and trends observed in real, deepfake, and synthetic facial images differ across various cultural and demographic groups?
- Basis in paper: [inferred] The paper analyzes image properties such as brightness, sharpness, luminosity, RGB mean, contrast, and detail across different facial regions, but does not explore potential variations across cultural or demographic groups.
- Why unresolved: The study focuses on a general analysis of image properties without considering potential differences in these properties across various demographic groups, which could provide valuable insights into the universality or specificity of the observed patterns.
- What evidence would resolve it: Conducting a similar analysis of image properties across diverse cultural and demographic groups, and comparing the results to identify any significant differences or similarities in the patterns observed.

### Open Question 2
- Question: How do the detection capabilities of deep learning models for real, deepfake, and synthetic facial images change as the quality and realism of generated images improve over time?
- Basis in paper: [explicit] The paper discusses the high level of verisimilitude attained by current deepfakes and the ever-rising quality of generative artificial intelligence, but does not explore how this impacts the detection capabilities of deep learning models.
- Why unresolved: As generative AI continues to advance, the gap between real and generated images may narrow, potentially reducing the effectiveness of current detection models and necessitating the development of more robust algorithms.
- What evidence would resolve it: Conducting longitudinal studies to evaluate the performance of deep learning models on datasets of real, deepfake, and synthetic images generated at different time points, and analyzing how their detection capabilities change as the quality and realism of generated images improve.

### Open Question 3
- Question: How do the image properties of real, deepfake, and synthetic facial images differ when analyzed using other color spaces or feature extraction techniques?
- Basis in paper: [inferred] The paper analyzes image properties in the context of the RGB color space and specific facial regions, but does not explore how these properties might differ when using other color spaces or feature extraction methods.
- Why unresolved: Different color spaces and feature extraction techniques may reveal additional patterns or trends in the image properties of real, deepfake, and synthetic facial images, which could provide further insights into their distinctions and aid in the development of more effective detection algorithms.
- What evidence would resolve it: Repeating the image property analysis using various color spaces (e.g., HSV, YCbCr) and feature extraction techniques (e.g., wavelet transforms, histogram of oriented gradients) to compare the observed patterns and trends with those obtained using the RGB color space and the original method.

## Limitations

- The study uses controlled dataset conditions with specific image resolutions (256x256) and strict frontal pose requirements that may not reflect real-world conditions
- Pre-trained ImageNet models may introduce domain adaptation biases when applied to facial imagery
- The analysis focuses on six specific image properties without exploring other potentially discriminative features or temporal artifacts in video-based deepfakes

## Confidence

- Classification accuracy results: High - Clear performance metrics and systematic evaluation across multiple models provide robust evidence
- Image property differences: Medium - Statistical significance is demonstrated, but the practical relevance of observed differences to human perception remains unclear
- Three-class distinction claim: Medium - Supported by both classification and property analysis, but could be influenced by dataset composition and preprocessing choices

## Next Checks

1. Test classification performance on higher-resolution images and more varied poses to assess robustness to real-world conditions
2. Conduct ablation studies removing specific image properties to determine which features drive the most discriminative power
3. Compare results with alternative property measurement methods and additional statistical tests to verify the robustness of observed differences