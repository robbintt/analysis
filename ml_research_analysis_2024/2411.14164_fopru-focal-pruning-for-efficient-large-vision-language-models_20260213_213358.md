---
ver: rpa2
title: 'FoPru: Focal Pruning for Efficient Large Vision-Language Models'
arxiv_id: '2411.14164'
source_url: https://arxiv.org/abs/2411.14164
tags:
- tokens
- visual
- token
- pruning
- fopru
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Focal Pruning (FoPru), a training-free method
  for accelerating inference in large vision-language models (LVLMs) by pruning redundant
  visual tokens. FoPru uses attention-based token significance scores from the vision
  encoder to identify and prune unimportant visual tokens.
---

# FoPru: Focal Pruning for Efficient Large Vision-Language Models

## Quick Facts
- arXiv ID: 2411.14164
- Source URL: https://arxiv.org/abs/2411.14164
- Reference count: 40
- Primary result: Achieves up to 2.61x speedup in Time To First Token and 1.24x in Time Per Output Token while maintaining high accuracy through attention-based visual token pruning.

## Executive Summary
This paper introduces Focal Pruning (FoPru), a training-free method for accelerating inference in large vision-language models (LVLMs) by pruning redundant visual tokens. The method uses attention-based token significance scores from the vision encoder to identify and prune unimportant visual tokens, achieving up to 99.8% reduction in visual tokens while maintaining high accuracy. Two pruning strategies are proposed: rank pruning for global significance and row pruning for preserving spatial continuity. Extensive experiments across three LVLMs and seven datasets demonstrate substantial efficiency improvements with minimal accuracy loss.

## Method Summary
FoPru is a training-free pruning method that extracts attention maps from the penultimate layer of the vision encoder to calculate token significance scores using variance-based feature selection. Two pruning strategies are applied: rank pruning selects globally significant tokens, while row pruning preserves continuous key information row by row. The pruned tokens are reordered to maintain their original spatial positions before being projected into the LLM for inference. The method achieves efficiency gains by reducing computational load early in the processing pipeline while preserving critical visual information for accurate language understanding.

## Key Results
- Achieves up to 2.61x speedup in Time To First Token and 1.24x in Time Per Output Token
- Reduces visual tokens by up to 99.8% while maintaining high accuracy across multiple datasets
- Outperforms existing training-free pruning approaches in both accuracy and efficiency
- Demonstrates effectiveness across three LVLMs (LLaVA-NeXT-8B, LLaVA-1.6-7B, LLaVA-1.6-13B) and seven diverse datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Attention-based pruning using the vision encoder's internal attention maps captures token importance more effectively than LLM-layer pruning.
- Mechanism: The method extracts attention maps from the penultimate layer of the vision encoder, computes a variance-based significance score per token, and uses this score to prune tokens before they enter the LLM. This early pruning reduces computational load for the LLM's auto-regressive decoding.
- Core assumption: The attention distribution in deep vision encoder layers reflects the true semantic importance of visual tokens.
- Evidence anchors: [abstract] "FoPru uses attention-based token significance scores from the vision encoder to identify and prune unimportant visual tokens"; [section] "the deep layers present a phenomenon known as mode collapse, where over 80% of the attention is concentrated on less than 25% of the tokens."

### Mechanism 2
- Claim: Row pruning preserves spatial continuity in images better than global rank pruning for tasks requiring structural context.
- Mechanism: The method reshapes the one-dimensional token significance scores into a two-dimensional grid matching the image layout, sums significance scores row-wise, selects the most significant rows, and then flattens the result. This ensures that entire horizontal bands of tokens are retained together.
- Core assumption: Horizontal continuity of visual information is critical for many vision-language tasks.
- Evidence anchors: [abstract] "the row strategy, which focuses on preserving continuous key information in images from a local perspective"; [section] "Considering that textual information is predominantly organized horizontally, we compute an aggregate significance score for each of the n rows."

### Mechanism 3
- Claim: Reordering pruned tokens to their original spatial positions restores positional context necessary for accurate LLM inference.
- Mechanism: After pruning, the selected token indices are sorted in ascending order before projection into the LLM, ensuring that the relative positional relationships among retained tokens match their original arrangement in the image.
- Core assumption: The LLM's cross-attention layers rely on the positional order of visual tokens to maintain spatial context.
- Evidence anchors: [abstract] "the selected tokens are reordered to maintain their original positional relationships"; [section] "Sorting Iidx in ascending order yields Isorted, which maintains the tokens' original spatial positions."

## Foundational Learning

- Concept: Variance-based feature selection in high-dimensional spaces
  - Why needed here: The method uses variance of attention vectors to determine which dimension (row vs column) better discriminates token importance
  - Quick check question: If the variance of column-wise attention is higher than row-wise, which vector should be chosen as the significance score?

- Concept: Token pruning strategies and their impact on downstream model performance
  - Why needed here: The paper compares rank-based and row-based pruning to show how different selection criteria affect accuracy
  - Quick check question: What is the primary difference between rank pruning and row pruning in terms of information preservation?

- Concept: Attention map interpretation in transformer-based vision encoders
  - Why needed here: Understanding how attention weights reflect token importance is critical to justify the pruning approach
  - Quick check question: In a deep vision encoder layer, what does a mode collapse in attention weights indicate about token redundancy?

## Architecture Onboarding

- Component map: Vision encoder (e.g., CLIP ViT) -> Attention map extraction -> Token significance calculation -> Token pruning (rank/row) -> Token reordering -> Projection to text space -> LLM inference

- Critical path: Extract attention maps from penultimate encoder layer -> Compute significance scores -> Apply pruning strategy -> Reorder tokens -> Project and feed to LLM

- Design tradeoffs:
  - Early pruning (encoder) vs late pruning (LLM): Early pruning reduces LLM compute but may lose fine-grained details; late pruning retains more context but is computationally expensive
  - Rank vs row pruning: Rank captures global importance but may break spatial coherence; row preserves spatial structure but may miss globally important isolated tokens

- Failure signatures:
  - Accuracy drop with low retention ratios: Indicates pruning is too aggressive or significance scoring is misaligned with task needs
  - GPU usage unchanged: Suggests pruning is not effective or tokens are not being removed before LLM processing
  - Mode collapse not present: Significance scores may not reflect true importance if attention is evenly distributed

- First 3 experiments:
  1. Run FoPru with rank pruning at 50% retention on LLaVA-1.6-7B using the POPE dataset; measure accuracy and TTFT
  2. Run FoPru with row pruning at 50% retention on the same model and dataset; compare accuracy and TTFT to rank pruning
  3. Vary retention ratio from 25% to 75% with rank pruning; plot accuracy vs retention to identify the optimal tradeoff point

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal pruning ratio for different types of visual tasks, and how can it be determined automatically for a given model and dataset?
- Basis in paper: [explicit] The paper notes that "the optimal pruning ratios for visual tokens vary across different tasks and models, and they remain unclear" and that performance is dataset-specific
- Why unresolved: The paper demonstrates that optimal pruning ratios differ across datasets but doesn't provide a method to automatically determine the optimal ratio for new tasks
- What evidence would resolve it: A study showing how task characteristics correlate with optimal pruning ratios, along with a predictive model that can recommend the best pruning ratio for new tasks based on their features

### Open Question 2
- Question: How does the interaction between token pruning strategies and the specific architecture of different visual encoders affect pruning effectiveness?
- Basis in paper: [inferred] The paper uses CLIP as the visual encoder and shows that attention maps from the penultimate layer are used for token significance, but doesn't explore how different encoders would impact results
- Why unresolved: The methodology relies on CLIP's attention distribution, but there's no exploration of whether other encoders would provide better attention maps for pruning
- What evidence would resolve it: Comparative experiments using multiple visual encoders and attention layers to identify which combinations yield the best pruning performance across different task types

### Open Question 3
- Question: Can the token pruning approach be extended to also consider textual token redundancy, creating a unified multimodal pruning framework?
- Basis in paper: [explicit] The paper focuses exclusively on visual token pruning, noting that "visual tokens dominate the input tokens to the LLM" but not exploring whether textual tokens could also be pruned
- Why unresolved: The current approach only addresses visual token redundancy, leaving potential efficiency gains from textual token pruning unexplored
- What evidence would resolve it: Experiments demonstrating the effectiveness of jointly pruning both visual and textual tokens, with analysis of how the relative importance of each modality varies across different task types

## Limitations

- The method's effectiveness may be architecture-specific, potentially degrading with different vision encoders or LLM backbones
- The superiority of variance-based significance scoring is not benchmarked against alternative importance metrics
- Limited analysis of how pruning affects model robustness or generalization to out-of-distribution data

## Confidence

- **High Confidence**: The core methodology of attention-based token pruning is technically sound and the implementation details are clearly specified. The claimed speedups (2.61x TTFT, 1.24x TPOT) are supported by experimental results across multiple models and datasets.
- **Medium Confidence**: The claim that encoder-layer pruning outperforms LLM-layer pruning is supported by the observation of mode collapse in deep layers, but lacks direct ablation studies comparing different pruning locations. The superiority of row pruning for spatial tasks is theoretically justified but requires more empirical validation.
- **Low Confidence**: The assertion that variance-based significance scoring is optimal for token importance determination is not compared against other scoring methods. The impact of pruning on model robustness and out-of-distribution performance remains unexamined.

## Next Checks

1. **Ablation on Pruning Location**: Run FoPru with the same pruning strategy but extract attention maps from different encoder layers (early, middle, and late) and compare the accuracy-speed tradeoff to determine the optimal pruning depth.

2. **Significance Scoring Comparison**: Implement and test alternative token importance metrics (e.g., max attention weight, mean attention weight, entropy of attention distribution) alongside the variance-based method to empirically validate the choice of scoring mechanism.

3. **Spatial Reasoning Benchmark**: Evaluate FoPru with both rank and row pruning strategies on spatial reasoning datasets like VSR (Visual Spatial Reasoning) or specific spatial question-answering tasks to quantify the claimed advantage of row pruning for spatially-structured tasks.