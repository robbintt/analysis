---
ver: rpa2
title: Towards the Reusability and Compositionality of Causal Representations
arxiv_id: '2403.09830'
source_url: https://arxiv.org/abs/2403.09830
tags:
- causal
- variables
- representations
- target
- decaf
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DECAF, a framework for adapting and composing
  causal representations across environments in the Temporal Intervened Sequences
  (TRIS) setting. The approach detects which causal factors can be reused and which
  need adaptation by analyzing discrepancies in intervention target prediction accuracy
  between source and target environments.
---

# Towards the Reusability and Compositionality of Causal Representations

## Quick Facts
- arXiv ID: 2403.09830
- Source URL: https://arxiv.org/abs/2403.09830
- Reference count: 40
- Key outcome: DECAF significantly outperforms direct fine-tuning and zero-shot baselines, achieving higher correlation between inferred and ground-truth causal factors with only a few target samples.

## Executive Summary
This paper introduces DECAF, a framework for adapting and composing causal representations across environments in the Temporal Intervened Sequences (TRIS) setting. DECAF detects which causal factors can be reused and which need adaptation by analyzing discrepancies in intervention target prediction accuracy between source and target environments. For changing factors, DECAF employs a normalizing flow to adapt the representation while keeping invariant factors unchanged. Experiments on three benchmarks show that combining DECAF with four state-of-the-art CRL methods significantly outperforms direct fine-tuning and zero-shot baselines.

## Method Summary
DECAF detects changing causal factors by comparing False Positive Rates of a target classifier that predicts intervention targets between source and target environments. Variables with significant FPR changes are flagged as needing adaptation. A normalizing flow then transforms the representations of changed factors while preserving invariant factors. For composition, DECAF concatenates latent representations of shared causal variables identified across multiple source environments. The framework is integrated with four CRL methods (CITRISVAE, LEAP, DMSVAE, iVAE) and evaluated on three benchmarks (Voronoi, Interventional Pong, and Temporal Causal3DIdent).

## Key Results
- DECAF achieves higher correlation (R2 and Spearman) between inferred and ground-truth causal factors compared to direct fine-tuning and zero-shot baselines
- The framework maintains strong performance with only 1K-5K target samples, demonstrating sample efficiency
- Composition experiments show DECAF can successfully combine causal representations from multiple sources when shared factors are identified correctly

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DECAF detects changed factors by measuring discrepancies in intervention target prediction accuracy between source and target environments.
- Mechanism: A target classifier predicts next-step intervention targets from current and next latent states. When applied in a new environment, the False Positive Rate for each causal variable increases if that variable's representation has changed.
- Core assumption: The classifier's accuracy depends on how well the latent representation captures intervention dynamics, which change only for variables whose causal factors transform between environments.
- Evidence anchors: [abstract], [section 4], corpus (weak evidence)
- Break condition: If the classifier over-predicts interventions in unseen environments, it might incorrectly flag invariant factors as changing.

### Mechanism 2
- Claim: Only changed causal factors are adapted using a normalizing flow, while invariant factors are reused directly.
- Mechanism: DECAF trains a normalizing flow to map original latent representations of changed factors to new representations that better capture target environment intervention dynamics, conditioned on intervention targets.
- Core assumption: The normalizing flow can learn an invertible mapping that transforms changed factors while preserving information needed to predict interventions.
- Evidence anchors: [abstract], [section 4], corpus (weak evidence)
- Break condition: If changes between environments are too complex for the normalizing flow or too few target samples are available.

### Mechanism 3
- Claim: DECAF can compose causal representations from multiple source environments by identifying shared and changed factors.
- Mechanism: DECAF detects shared causal variables between each source representation and target, then concatenates the latent representations of all identified shared variables.
- Core assumption: Shared causal variables between sources and target have the same representations and can be meaningfully concatenated.
- Evidence anchors: [abstract], [section 4], corpus (weak evidence)
- Break condition: If shared variables have different representations across sources or overlap isn't handled correctly.

## Foundational Learning

- Concept: Temporal Intervened Sequences (TRIS) setting
  - Why needed here: DECAF builds on this setting, which assumes temporal sequences with known intervention targets at each time step.
  - Quick check question: What information do we have available at each time step that's crucial for DECAF's approach?

- Concept: Normalizing flows for representation adaptation
  - Why needed here: DECAF uses normalizing flows to adapt representations of changed causal factors while maintaining invertibility.
  - Quick check question: What property of normalizing flows makes them suitable for adapting representations between environments in DECAF?

- Concept: False Positive Rate (FPR) analysis for change detection
  - Why needed here: DECAF detects changed factors by comparing FPR of intervention prediction between source and target environments.
  - Quick check question: Why does DECAF use False Positive Rate (rather than other metrics) to detect changed factors when applying the target classifier in a new environment?

## Architecture Onboarding

- Component map:
  Source model -> Target classifier -> Change detector -> Normalizing flow -> Projection function

- Critical path:
  1. Train source CRL model on source environment
  2. Train target classifier on source data
  3. Apply target classifier to target environment
  4. Detect changed factors via FPR comparison
  5. Train normalizing flow on changed factors using target data
  6. Construct final representation (adapted changed factors + invariant factors)

- Design tradeoffs:
  - Detection threshold τ: Lower thresholds detect more changes but risk false positives; higher thresholds are conservative but may miss needed adaptations
  - Flow depth: Deeper flows can capture more complex changes but require more target samples and computation
  - Sample efficiency vs. accuracy: DECAF trades some accuracy for extreme sample efficiency compared to fine-tuning

- Failure signatures:
  - High variance in results across seeds: May indicate instability in change detection or flow training
  - Poor performance on changed factors but good on invariant factors: Suggests change detection is working but flow adaptation is failing
  - Good performance on all factors without adaptation: May indicate environments are too similar or change detection threshold is too high

- First 3 experiments:
  1. Run 0-shot evaluation (freeze source model, test on target) to establish baseline
  2. Apply DECAF with default parameters on a simple adaptation task (e.g., VORONOI REG→CH)
  3. Test DECAF composition by combining two source environments with complementary representations and evaluating on a target that requires both

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does DECAF's performance scale with the number of target samples in the adaptation setting?
- Basis in paper: [inferred] The paper shows strong results with 1K-5K samples but doesn't explore performance at much larger sample sizes.
- Why unresolved: Experiments only evaluate up to 10K samples, leaving questions about scaling behavior and potential crossover points with other methods.
- What evidence would resolve it: Systematic experiments varying target sample size across multiple orders of magnitude (e.g., 1K, 10K, 100K, 1M) showing correlation metrics and computational efficiency comparisons.

### Open Question 2
- Question: Can DECAF's detection mechanism reliably distinguish between coordinate transformations versus complex structural changes?
- Basis in paper: [explicit] The paper demonstrates detection works for coordinate system changes but only uses synthetic benchmarks with invertible changes.
- Why unresolved: Real-world environments might involve non-invertible or discontinuous changes that could fool the FPR/FNR-based detection method.
- What evidence would resolve it: Experiments on benchmarks with diverse change types including non-invertible transformations, variable removal/addition, and structural graph changes.

### Open Question 3
- Question: What is the theoretical relationship between the modularity assumption and identifiability guarantees of different CRL methods when composing representations?
- Basis in paper: [inferred] The paper assumes causal factors can be composed when identified as invariant, but doesn't provide theoretical analysis of when this works.
- Why unresolved: While experiments show empirical success, there's no formal proof that the composed representation maintains the same causal semantics.
- What evidence would resolve it: Formal theorems characterizing conditions under which DECAF's composition preserves causal identifiability.

## Limitations

- The effectiveness of change detection depends heavily on the quality and quantity of target samples, with unclear performance in extreme low-data regimes.
- The normalizing flow adaptation component may struggle with more complex or nonlinear changes between environments beyond the benchmark tasks.
- The paper doesn't adequately address potential failure modes when source and target environments have fundamentally different causal structures.

## Confidence

- **High Confidence**: The core mechanism of detecting changed factors through intervention prediction accuracy discrepancies is well-founded and theoretically sound.
- **Medium Confidence**: The normalizing flow adaptation works well for benchmark tasks but may struggle with complex changes; composition mechanism assumes consistent shared variables across sources.
- **Low Confidence**: The paper doesn't adequately address failure modes with fundamentally different causal structures or noisy/incomplete intervention targets.

## Next Checks

1. Test DECAF with extreme low-data regimes (<100 target samples) to establish minimum sample requirements for reliable adaptation.
2. Evaluate DECAF's performance when source and target environments have partially overlapping but not identical causal structures to test robustness to imperfect change detection.
3. Benchmark DECAF against a fine-tuning baseline that adapts all factors (not just changed ones) to quantify the trade-off between sample efficiency and adaptation accuracy.