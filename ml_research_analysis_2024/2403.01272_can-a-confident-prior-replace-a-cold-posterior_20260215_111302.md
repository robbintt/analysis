---
ver: rpa2
title: Can a Confident Prior Replace a Cold Posterior?
arxiv_id: '2403.01272'
source_url: https://arxiv.org/abs/2403.01272
tags:
- prior
- posterior
- cold
- likelihood
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates whether posterior tempering in Bayesian
  neural networks can be replaced by confidence-inducing priors. The authors propose
  two such priors: DirClip, a clipped Dirichlet prior that is practical to sample
  and nearly matches cold posterior performance, and a theoretical "confidence prior"
  that directly enforces low aleatoric uncertainty but cannot be easily sampled.'
---

# Can a Confident Prior Replace a Cold Posterior?

## Quick Facts
- arXiv ID: 2403.01272
- Source URL: https://arxiv.org/abs/2403.01272
- Reference count: 40
- Primary result: A clipped Dirichlet prior (DirClip) achieves 93-94% test accuracy on CIFAR-10, comparable to cold posteriors, without requiring tempering

## Executive Summary
This paper investigates whether posterior tempering in Bayesian neural networks can be replaced by confidence-inducing priors. The authors propose two such priors: DirClip, a clipped Dirichlet prior that is practical to sample and nearly matches cold posterior performance, and a theoretical "confidence prior" that directly enforces low aleatoric uncertainty but cannot be easily sampled. Experiments on ResNet20/CIFAR-10 show DirClip achieves 93-94% test accuracy, comparable to cold posteriors, without requiring tempering. The authors also analyze why Dirichlet priors diverge when applied directly over model parameters and show that gradient-based sampling can be unstable for low-concentration Dirichlet distributions, but this can be mitigated through careful initialization.

## Method Summary
The paper proposes two approaches to replace cold posterior tempering with confidence-inducing priors. First, the DirClip prior clips the density of a Dirichlet prior to avoid divergence while controlling aleatoric uncertainty. Second, a theoretical confidence prior is introduced that directly approximates a cold likelihood as temperature approaches zero. Both are combined with categorical likelihood and trained using Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) on ResNet20/CIFAR-10. The DirClip prior requires careful clipping value selection to balance stability and performance, while the confidence prior faces sampling challenges due to multiple local maxima.

## Key Results
- DirClip prior achieves 93-94% test accuracy on CIFAR-10, matching cold posterior performance without tempering
- Dirichlet priors diverge when applied directly over parameters due to unbounded density in the limit of low aleatoric uncertainty
- Gradient-based sampling of low-concentration Dirichlet priors (α < 0.8) becomes unstable, but can be mitigated through fine-tuning from high-accuracy checkpoints

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A confidence-inducing prior can replace cold posterior tempering by directly enforcing low aleatoric uncertainty.
- Mechanism: The DirClip prior clips the density of the Dirichlet prior to avoid divergence, allowing it to control aleatoric uncertainty without tempering.
- Core assumption: The clipping value is high enough to avoid numerical instability but low enough to enforce confidence.
- Evidence anchors:
  - [abstract] "DirClip, a clipped Dirichlet prior that is practical to sample and nearly matches cold posterior performance"
  - [section] "By clipping the density of the Dirichlet prior, we fixed its divergence, leading to a valid prior distribution that controls the level of aleatoric uncertainty."
  - [corpus] Weak evidence; no direct mention of confidence-inducing priors replacing cold posteriors.
- Break condition: If the clipping value is too low, the prior density becomes unbounded and diverges.

### Mechanism 2
- Claim: The confidence prior directly enforces high prediction confidence, approximating a cold posterior as temperature approaches zero.
- Mechanism: The confidence prior's density is proportional to the maximum predicted probability, converging to a cold likelihood as temperature decreases.
- Core assumption: The confidence prior can be practically sampled despite having many local maxima.
- Evidence anchors:
  - [abstract] "Second, we introduce a confidence prior that directly approximates a cold likelihood in the limit of decreasing temperature"
  - [section] "When this prior is combined with a categorical likelihood, as T → 0, their product converges to a cold likelihood."
  - [corpus] Weak evidence; no direct mention of confidence priors approximating cold posteriors.
- Break condition: If the temperature is too high, the confidence prior does not approximate a cold posterior effectively.

### Mechanism 3
- Claim: Fine-tuning from a high-accuracy checkpoint stabilizes training with low-concentration DirClip priors.
- Mechanism: Initializing from a model with high training accuracy ensures predictions are in the converging phase of the Dirichlet posterior gradient.
- Core assumption: The fine-tuned model maintains high accuracy during further training with the DirClip prior.
- Evidence anchors:
  - [abstract] "how fine-tuning can mitigate numerical instability"
  - [section] "In contrast, the DirClip posterior shows a surprising behavior, assigning the highest probability density to a model that only has a 10% training accuracy."
  - [corpus] Weak evidence; no direct mention of fine-tuning stabilizing training.
- Break condition: If the fine-tuned model's accuracy drops significantly, the DirClip prior may still cause instability.

## Foundational Learning

- Concept: Bayesian Neural Networks
  - Why needed here: Understanding BNNs is crucial for grasping how the DirClip and confidence priors modify the posterior distribution.
  - Quick check question: What is the difference between a Bayesian Neural Network and a standard neural network?

- Concept: Dirichlet Distribution
  - Why needed here: The Dirichlet prior is central to controlling aleatoric uncertainty in the classification setting.
  - Quick check question: How does the concentration parameter of the Dirichlet distribution affect the predicted probabilities?

- Concept: Posterior Tempering
  - Why needed here: Understanding why posterior tempering is used and its limitations is key to appreciating the proposed solutions.
  - Quick check question: What is the cold posterior effect, and why is it problematic from a Bayesian perspective?

## Architecture Onboarding

- Component map:
  Prior distribution -> Categorical likelihood -> SGHMC sampling -> ResNet20 model -> CIFAR-10 dataset

- Critical path:
  1. Define the prior distribution (DirClip or confidence prior).
  2. Combine the prior with the categorical likelihood.
  3. Sample the posterior using SGHMC.
  4. Evaluate the posterior predictive distribution.

- Design tradeoffs:
  - DirClip prior: Easier to sample but requires careful choice of clipping value.
  - Confidence prior: Theoretically sound but difficult to sample due to local maxima.
  - SGHMC: Biased but computationally efficient compared to HMC.

- Failure signatures:
  - Divergence: Model parameters or predictions become unbounded.
  - Low test accuracy: The prior does not effectively control aleatoric uncertainty.
  - Numerical instability: Gradients become too large or too small during training.

- First 3 experiments:
  1. Train a ResNet20 on CIFAR-10 with a standard Normal prior and categorical likelihood to establish a baseline.
  2. Train a ResNet20 on CIFAR-10 with the DirClip prior and categorical likelihood, varying the clipping value.
  3. Train a ResNet20 on CIFAR-10 with the confidence prior and categorical likelihood, varying the temperature parameter.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the instability of Dirichlet priors for small concentration parameters (α < 0.8) be eliminated without requiring fine-tuning from high-accuracy checkpoints?
- Basis in paper: [explicit] The paper shows that gradient-based sampling of Dirichlet priors becomes unstable when α < 0.8, leading to particles converging to wrong classes, but notes this is an optimization problem rather than a statistical property.
- Why unresolved: The paper only offers two solutions: use α > 0.8 or fine-tune from a 100% accuracy checkpoint. Neither fully addresses the fundamental instability issue.
- What evidence would resolve it: A method that enables stable sampling of Dirichlet priors with α < 0.8 without requiring initialization from high-accuracy models, or a theoretical proof that such stability is impossible.

### Open Question 2
- Question: Is there a principled way to compute the "change of variables" correction term when transforming from model parameters to model predictions for functional priors?
- Basis in paper: [explicit] The paper notes that setting p(θ) = p(ˆy) without the Jacobian correction term does not result in the correct prior predictive distribution, and that approximating this transformation is beyond the scope of the paper.
- Why unresolved: The paper acknowledges this is a difficult problem with no simple solution and defers it to future research, while still using priors over predictions without the correction term.
- What evidence would resolve it: A method to accurately compute or approximate the volume ratio |∆ˆy|/|∆θ| for neural network parameter-to-function transformations, or a proof that such computation is intractable for general neural networks.

### Open Question 3
- Question: Does the confidence prior converge to a cold posterior distribution when used with categorical likelihood, or do they differ in ways that affect inference quality?
- Basis in paper: [explicit] The paper shows that in the limit of T → 0, the confidence prior combined with categorical likelihood converges to a cold likelihood, and that if the posterior mode reaches 100% accuracy, the two distributions have identical Laplace approximations.
- Why unresolved: The paper notes that the confidence prior has many local maxima making it nearly impossible to sample directly, so this convergence cannot be empirically verified through sampling.
- What evidence would resolve it: A method to effectively sample from the confidence prior (possibly through advanced optimization techniques), or a theoretical proof that despite the convergence of densities, the distributions differ in their sampling properties in ways that affect inference.

## Limitations
- DirClip prior requires careful tuning of clipping parameter to avoid numerical instability
- Confidence prior suffers from practical sampling difficulties due to multiple local maxima
- Analysis is limited to ResNet20 architecture on CIFAR-10 dataset

## Confidence
- DirClip prior performance claims: Medium - supported by CIFAR-10 experiments but limited to specific architectures
- Theoretical convergence of confidence prior: Medium - rigorous for synthetic data but untested on real datasets
- Gradient instability analysis: High - well-supported by both theoretical and empirical evidence

## Next Checks
1. Test DirClip prior performance across multiple architectures (e.g., WideResNet, DenseNet) and datasets beyond CIFAR-10
2. Evaluate whether fine-tuning from high-accuracy checkpoints consistently mitigates numerical instability across different hyperparameter settings
3. Implement and test practical sampling strategies for the confidence prior, such as stochastic approximation methods or variational inference alternatives