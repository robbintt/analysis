---
ver: rpa2
title: 'Chain-of-Restoration: Multi-Task Image Restoration Models are Zero-Shot Step-by-Step
  Universal Image Restorers'
arxiv_id: '2410.08688'
source_url: https://arxiv.org/abs/2410.08688
tags:
- degradation
- image
- degradations
- restoration
- order
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of composite image degradation,
  where multiple degradation types (e.g., noise, haze, rain) simultaneously affect
  an image. Traditional methods require training on exponentially many combinations
  of degradations, which is computationally prohibitive.
---

# Chain-of-Restoration: Multi-Task Image Restoration Models are Zero-Shot Step-by-Step Universal Image Restorers

## Quick Facts
- arXiv ID: 2410.08688
- Source URL: https://arxiv.org/abs/2410.08688
- Authors: Jin Cao; Deyu Meng; Xiangyong Cao
- Reference count: 40
- Key outcome: Multi-task models trained on individual degradations can remove any composite degradation combination in zero-shot manner using Chain-of-Restoration

## Executive Summary
This paper addresses the challenge of composite image degradation where multiple degradation types simultaneously affect an image. Traditional methods require training on exponentially many combinations of degradations, which is computationally prohibitive. The authors propose Chain-of-Restoration (CoR), inspired by Chain-of-Thought reasoning in language models, which guides multi-task image restoration models to remove one degradation basis at a time until the image is fully restored. By integrating a simple Degradation Discriminator into pre-trained multi-task models, CoR achieves effective universal image restoration with limited training data.

## Method Summary
Chain-of-Restoration (CoR) is a method for universal image restoration that leverages pre-trained multi-task models to remove composite degradations in a step-by-step manner. The approach trains models only on individual degradation bases (e.g., Gaussian noise, rain, haze) rather than all possible combinations. During inference, a Degradation Discriminator identifies the current degradation type in the input image, and the multi-task model removes that specific degradation. This process iterates until the image is fully restored. The method achieves zero-shot performance on composite degradations without requiring training on all degradation combinations, significantly reducing computational burden while maintaining or improving restoration quality.

## Key Results
- CoR significantly improves multi-task model performance on composite degradation removal, often matching or surpassing state-of-the-art methods trained on all degradations
- 2-order HAIR with CoR surpasses 3-order HAIR in both PSNR and SSIM on CDD-11 dataset
- CoR achieves effective universal image restoration with limited training data by training only on individual degradation bases
- The approach demonstrates that multi-task models inherently process one degradation at a time when faced with composite degradations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Chain-of-Restoration leverages the observed behavior that multi-task models trained on individual degradations predominantly address only one degradation at a time when faced with composite degradations.
- Mechanism: The method iteratively applies the multi-task model to the input image, with each step targeting and removing one specific degradation basis as identified by the Degradation Discriminator. This process continues until the image is fully restored.
- Core assumption: Multi-task image restoration models inherently process one degradation type at a time, even when multiple degradations are present in the input image.
- Evidence anchors:
  - [abstract]: "Inspired by the Chain-of-Thought that prompts large language models (LLMs) to address problems step-by-step, we propose Chain-of-Restoration (CoR), which instructs models to remove unknown composite degradations step-by-step."
  - [section]: "As previously introduced, we observed that multi-task models trained on multiple degradations typically address only one degradation when faced with an image containing composite degradations."
  - [corpus]: Weak - The corpus neighbors discuss related topics like universal image restoration and agent-based approaches, but do not specifically address the single-degradation-per-step behavior of multi-task models.
- Break condition: The process stops when the Degradation Discriminator identifies the image as clean (i.e., no degradations remain).

### Mechanism 2
- Claim: The Degradation Discriminator enables the model to identify the current degradation type in the input image, allowing for targeted removal of one degradation basis per step.
- Mechanism: The Degradation Discriminator classifies the input image as either clean or containing one of the known degradation bases. It uses soft margins (ϵo and ϵbi) to prioritize higher-order degradations and control the restoration sequence.
- Core assumption: A simple classifier can accurately identify the current degradation type in an image, even when multiple degradations are present.
- Evidence anchors:
  - [abstract]: "By integrating a simple Degradation Discriminator into pre-trained multi-task models, CoR facilitates the process where models remove one degradation basis per step, continuing this process until the image is fully restored from the unknown composite degradation."
  - [section]: "To ascertain the degradation state of an input image, a Degradation Discriminator (DD) is essential."
  - [corpus]: Weak - The corpus neighbors do not provide specific evidence for the effectiveness of degradation discriminators in multi-degradation scenarios.
- Break condition: The iterative process stops when the Degradation Discriminator outputs "clean," indicating no degradations remain.

### Mechanism 3
- Claim: By training on individual degradation bases rather than all possible combinations, the UIR task setting significantly reduces the computational burden while maintaining or improving restoration performance.
- Mechanism: The model is trained only on a set of degradation bases (individual degradation types). During inference, it can handle any combination of these bases in a zero-shot manner by sequentially removing each degradation.
- Core assumption: Training on individual degradation types is sufficient for a model to generalize and effectively remove any combination of these degradations.
- Evidence anchors:
  - [abstract]: "Specifically, UIR doesn't require training on all the degradation combinations but only on a set of degradation bases and then removing any degradation that these bases can potentially compose in a zero-shot manner."
  - [section]: "In numerous practical scenarios, complexity is often a result of interacting simpler elements... we suspect that managing complex image degradations could be broken down into handling their individual components."
  - [corpus]: Weak - The corpus neighbors discuss related topics like universal blind image restoration and all-in-one methods, but do not specifically address the training on individual bases and zero-shot combination removal.
- Break condition: The model successfully removes all degradations in the input image, achieving results comparable to or surpassing state-of-the-art methods trained on all degradation combinations.

## Foundational Learning

- Concept: Chain-of-Thought (CoT) reasoning in language models
  - Why needed here: The Chain-of-Restoration (CoR) method is directly inspired by CoT, which enables LLMs to break down complex problems into smaller, manageable steps. Understanding CoT provides the conceptual foundation for how CoR guides multi-task models to remove composite degradations step-by-step.
  - Quick check question: How does Chain-of-Thought prompting improve the performance of large language models on complex reasoning tasks?

- Concept: Zero-shot learning
  - Why needed here: The UIR task setting and CoR method both rely on zero-shot learning, where models are trained on individual degradation bases but can handle any combination of these bases during inference without further training. Understanding zero-shot learning is crucial for grasping how the model generalizes to unseen composite degradations.
  - Quick check question: What is the key difference between zero-shot learning and traditional supervised learning?

- Concept: Multi-task learning and model capacity
  - Why needed here: The effectiveness of CoR depends on the ability of multi-task models to handle multiple degradation types. Understanding the principles of multi-task learning, including model capacity and the trade-offs between training on individual tasks versus combined tasks, is essential for appreciating how CoR leverages existing multi-task models.
  - Quick check question: How does training a model on multiple tasks simultaneously affect its performance on individual tasks compared to training separate models for each task?

## Architecture Onboarding

- Component map:
  - Multi-task image restoration model: Pre-trained on individual degradation bases (e.g., noise, haze, rain)
  - Degradation Discriminator: Classifies the input image as clean or containing one of the known degradation bases. Uses soft margins to prioritize higher-order degradations
  - CoR Controller: Orchestrates the iterative process, calling the Degradation Discriminator and multi-task model in sequence until the image is fully restored

- Critical path:
  1. Input degraded image
  2. Degradation Discriminator identifies current degradation type
  3. Multi-task model removes the identified degradation
  4. Repeat steps 2-3 until Degradation Discriminator outputs "clean"
  5. Output restored image

- Design tradeoffs:
  - Blind vs. non-blind models: Non-blind models (with known degradation types) can achieve better performance with CoR due to reduced Degradation Coupling, but blind models offer more flexibility
  - Order of the model: Higher-order models (trained on more degradation combinations) require more training time but less inference time with CoR. Lower-order models are computationally cheaper but may need more steps to restore the image
  - Soft margins (ϵo and ϵbi): Tuning these parameters allows control over the restoration sequence and prioritization of higher-order degradations, but requires careful experimentation to optimize

- Failure signatures:
  - Degradation Coupling: When the model's removal of one degradation inadvertently affects other unintended degradations, leading to suboptimal results
  - Incorrect degradation identification: If the Degradation Discriminator misclassifies the current degradation type, the model may apply the wrong restoration step
  - Insufficient model capacity: If the multi-task model lacks the capacity to effectively remove individual degradations, CoR may fail to fully restore the image

- First 3 experiments:
  1. Implement a simple Degradation Discriminator (binary classifier) and integrate it with a pre-trained multi-task model to test the basic CoR workflow on a single composite degradation type
  2. Experiment with different soft margin values (ϵo and ϵbi) to optimize the restoration sequence and prioritize higher-order degradations
  3. Compare the performance of CoR with blind and non-blind multi-task models on a dataset with multiple composite degradation types to assess the impact of Degradation Coupling

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several unresolved issues emerge from the work:

### Open Question 1
- Question: What is the maximum number of degradation bases that can be effectively handled by Chain-of-Restoration before model capacity and training data limitations become prohibitive?
- Basis in paper: [explicit] The paper discusses training complexity scaling exponentially with the number of degradation bases (2^n - 1 possible combinations) and mentions that "a higher order doesn't mean better performance since the capacity of the models is always limited"
- Why unresolved: The paper provides theoretical analysis showing exponential growth in training data requirements but doesn't empirically test the upper limit of degradation bases that can be effectively handled
- What evidence would resolve it: Systematic experiments varying the number of degradation bases (e.g., 3, 5, 10, 15) while measuring PSNR/SSIM performance and training/inference time ratios would establish the practical limits

### Open Question 2
- Question: Can Chain-of-Restoration be extended to handle spatially-varying composite degradations where different regions of an image have different degradation combinations?
- Basis in paper: [inferred] The paper treats composite degradations as uniform across the entire image, but real-world images often have spatially-varying degradations (e.g., haze near horizon, noise in dark regions)
- Why unresolved: The current Degradation Discriminator and CoR framework assumes a single degradation type per image, without addressing spatial heterogeneity
- What evidence would resolve it: Modifying CoR to process image patches or use attention mechanisms to handle spatial variations, then demonstrating improved performance on datasets with spatially-varying degradations

### Open Question 3
- Question: How does the ordering strategy in Degradation Discriminator affect the final restoration quality, and can it be optimized automatically?
- Basis in paper: [explicit] The paper introduces soft margins (ϵo, ϵbi) to influence degradation ordering but states "the restoration sequence of the bases is not predetermined or controllable"
- Why unresolved: While the paper demonstrates that ordering matters (showing examples where different sequences yield different results), it doesn't explore whether optimal ordering can be learned rather than manually set
- What evidence would resolve it: Experiments comparing fixed ordering strategies versus learned ordering policies, potentially using reinforcement learning to optimize the sequence based on intermediate restoration quality metrics

## Limitations
- The fundamental claim that multi-task models inherently process one degradation at a time lacks rigorous theoretical justification or ablation studies
- The Degradation Discriminator's performance on complex composite degradations is not thoroughly evaluated
- The soft margin hyperparameters appear to be tuned for specific datasets, raising concerns about generalization to different degradation sets

## Confidence
- **High confidence**: The CoR algorithm is well-specified and the experimental methodology is sound for the tested scenarios
- **Medium confidence**: The performance improvements over baselines are demonstrated, but the results may be dataset-dependent given the specific degradation sets used
- **Low confidence**: The fundamental claim that multi-task models inherently process one degradation at a time lacks rigorous theoretical justification or ablation studies

## Next Checks
1. Conduct ablation studies to quantify how often multi-task models actually address only one degradation versus multiple degradations simultaneously in composite scenarios
2. Test CoR with degradation sets beyond the five bases used in the paper to assess generalizability to different types of image degradations
3. Evaluate the Degradation Discriminator's accuracy on composite images with multiple degradation types present, not just single degradation classification