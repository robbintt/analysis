---
ver: rpa2
title: 'Qua$^2$SeDiMo: Quantifiable Quantization Sensitivity of Diffusion Models'
arxiv_id: '2412.14628'
source_url: https://arxiv.org/abs/2412.14628
tags:
- quantization
- weight
- layers
- pixart
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Qua2SeDiMo is a Post-Training Quantization (PTQ) framework that
  quantifies the sensitivity of different weight layers, operations, and architectures
  in diffusion models to quantization-induced performance degradation. It leverages
  graph neural networks to attribute end-to-end task performance directly to individual
  layers and block structures, bypassing costly calibration datasets.
---

# Qua$^2$SeDiMo: Quantifiable Quantization Sensitivity of Diffusion Models
## Quick Facts
- arXiv ID: 2412.14628
- Source URL: https://arxiv.org/abs/2412.14628
- Reference count: 40
- Primary result: Achieves 3.4-3.9 bit quantization for diffusion models with minimal quality loss

## Executive Summary
Qua$^2$SeDiMo is a Post-Training Quantization (PTQ) framework that quantifies sensitivity of diffusion model components to quantization-induced performance degradation. It uses graph neural networks to attribute end-to-end task performance directly to individual layers and block structures without requiring calibration datasets. The framework identifies the most sensitive components and builds efficient mixed-precision configurations, enabling sub-4-bit weight quantization while maintaining high image quality across multiple diffusion architectures.

## Method Summary
The framework employs graph neural networks to analyze diffusion model architectures and quantify sensitivity of different weight layers, operations, and structures to quantization. By attributing end-to-end task performance directly to individual components, it bypasses the need for costly calibration datasets. The sensitivity analysis identifies which components are most vulnerable to quantization degradation, allowing the construction of mixed-precision configurations that preserve critical operations while aggressively quantizing less sensitive ones.

## Key Results
- Achieves 3.4-3.9 bit weight quantization without significant quality degradation
- Outperforms existing PTQ methods in FID and CLIP scores on PixArt-α, PixArt-Σ, Hunyuan-DiT, and SDXL
- Maintains high-fidelity image generation even with low-bit activation quantization
- Demonstrates superior performance compared to baseline quantization approaches

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to precisely identify which components of diffusion models are most sensitive to quantization error. By using graph neural networks to analyze the structural relationships between different layers and operations, it can attribute performance degradation to specific components. This targeted approach allows for selective preservation of high-precision weights where needed while aggressively quantizing less critical components, resulting in optimal mixed-precision configurations that maintain model performance at very low bit widths.

## Foundational Learning
- Diffusion models: Generative models that denoise images through iterative steps; needed to understand quantization targets and their sensitivity patterns
- Post-Training Quantization (PTQ): Quantization without retraining; critical for understanding the framework's approach and limitations
- Graph Neural Networks (GNNs): Used for sensitivity attribution; fundamental to the framework's ability to analyze architectural relationships
- Mixed-precision quantization: Technique of using different bit-widths for different components; essential for understanding the optimization strategy
- FID and CLIP scores: Evaluation metrics for image quality and text-image alignment; used to validate quantization effectiveness

## Architecture Onboarding
Component map: Input diffusion model -> GNN sensitivity analysis -> Sensitivity-attributed graph -> Mixed-precision configuration -> Quantized model
Critical path: The sensitivity analysis phase using GNNs is the bottleneck, as it requires comprehensive graph processing of the entire model architecture.
Design tradeoffs: Precision vs. performance balance, computational overhead of sensitivity analysis vs. quantization benefits, model-specific vs. generalizable configurations
Failure signatures: Poor sensitivity attribution leading to inappropriate quantization, overfitting to specific architectures, excessive computational overhead during analysis
First experiments: 1) Run sensitivity analysis on a small diffusion model variant, 2) Compare mixed-precision configurations against uniform quantization, 3) Validate FID score improvements on a held-out validation set

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Evaluation limited to specific diffusion architectures (PixArt-α, PixArt-Σ, Hunyuan-DiT, SDXL), raising questions about generalizability
- Lack of extensive perceptual studies beyond FID and CLIP scores to validate "no significant loss" claims
- No runtime benchmarks provided to quantify actual memory savings versus computational overhead
- Does not address quantization-aware training scenarios where fine-tuning is permissible

## Confidence
- Technical methodology: Medium
- Generalizability claims: Low
- Performance metrics: Medium
- User study validation: Low

## Next Checks
1. Test Qua$^2$SeDiMo on additional diffusion architectures (e.g., Imagen, Muse, or latent diffusion variants) to assess generalizability
2. Conduct runtime profiling to measure actual memory savings versus inference overhead
3. Perform extensive perceptual user studies comparing 3.4-3.9 bit quantized outputs against full-precision baselines across diverse image categories