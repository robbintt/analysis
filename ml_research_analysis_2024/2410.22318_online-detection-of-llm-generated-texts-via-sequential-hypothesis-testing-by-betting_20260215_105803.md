---
ver: rpa2
title: Online Detection of LLM-Generated Texts via Sequential Hypothesis Testing by
  Betting
arxiv_id: '2410.22318'
source_url: https://arxiv.org/abs/2410.22318
tags: []
core_contribution: The paper proposes a method for online detection of LLM-generated
  texts using sequential hypothesis testing by betting. The core idea is to frame
  the problem as a sequential hypothesis testing task, where at each round, a text
  is observed and a decision is made whether it is generated by an LLM or a human.
---

# Online Detection of LLM-Generated Texts via Sequential Hypothesis Testing by Betting

## Quick Facts
- arXiv ID: 2410.22318
- Source URL: https://arxiv.org/abs/2410.22318
- Authors: Can Chen; Jun-Kun Wang
- Reference count: 40
- Primary result: Proposes an online method for detecting LLM-generated texts using sequential hypothesis testing with betting, achieving controlled false positive rates and fast detection times.

## Executive Summary
This paper introduces a novel approach for online detection of LLM-generated texts using sequential hypothesis testing by betting. The method frames the detection problem as a sequential hypothesis testing task, where at each round a text is observed and a decision is made whether it is generated by an LLM or a human. The algorithm leverages existing score functions for detecting LLM-generated texts and updates a parameter using Online Newton Steps to accumulate wealth rapidly when an LLM-generated text is detected. The wealth serves as evidence to declare the source as an LLM, with statistical guarantees on false positive rate and expected time to correctly identify an LLM.

## Method Summary
The method frames online LLM detection as a sequential hypothesis testing problem where texts arrive sequentially and decisions are made in real-time. At each round, the algorithm observes a text yt and samples a human-written text xt from a prepared dataset. It computes a score difference gt = ϕ(xt) - ϕ(yt) using an existing score function ϕ, then updates wealth Wt = Wt-1 · (1 - gtθt) where θt is updated using Online Newton Steps. The algorithm declares the source as an LLM when Wt exceeds a threshold (1/α for simple hypothesis or 2/α for composite hypothesis), providing statistical guarantees on false positive rate through Ville's inequality.

## Key Results
- The algorithm can quickly detect LLM-generated texts while maintaining controlled false positive rates across various score functions and scoring models.
- Detection time is influenced by the relative magnitude of (∆ - ϵ) and (dt - ϵ), with larger score discrepancies between human and LLM texts leading to faster detection.
- The method performs well in composite hypothesis testing scenarios where small differences in means between different human writers are allowed.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The algorithm provides statistical guarantees by framing LLM detection as sequential hypothesis testing via betting.
- Mechanism: At each round, the algorithm observes text yt and samples human text xt. It computes score difference gt = ϕ(xt) - ϕ(yt) and updates wealth Wt = Wt-1 · (1 - gtθt). The parameter θt is updated using Online Newton Steps to accumulate wealth rapidly when yt is LLM-generated. The algorithm rejects H0 when Wt ≥ 1/α, which is guaranteed to be a level-α test under Ville's inequality.
- Core assumption: The wealth process remains a nonnegative supermartingale when H0 is true, requiring that scores from human and LLM texts have different means under H1.
- Evidence anchors:
  - [abstract] "The method leverages existing score functions for detecting LLM-generated texts and updates a parameter using Online Newton Steps to increase wealth rapidly when an LLM-generated text is detected."
  - [section 2] "We frame the problem of online detecting LLMs as a sequential hypothesis testing problem... We also aim to control the type-I error (false positive rate) while maximizing the power to reduce type-II error"

### Mechanism 2
- Claim: The algorithm can handle composite hypothesis testing where there may be small differences in means between different human writers.
- Mechanism: The algorithm decouples the composite hypothesis into two separate tests (H0^A and H0^B) with wealth processes W^A_t and W^B_t. It uses parameter ϵ to allow for small differences in means between human texts. The algorithm rejects H0 when either W^A_t ≥ 2/α or W^B_t ≥ 2/α.
- Core assumption: The score difference gt can be bounded within [-dt, dt] for each round t, allowing the algorithm to maintain nonnegative wealth processes.
- Evidence anchors:
  - [section 3] "We consider the scenario where an upper bound on|gt+1|, which is denoted by dt+1, is available before updating θt+1 at each round t."

### Mechanism 3
- Claim: The algorithm's performance depends on the relative magnitude of (∆ - ϵ) and (dt - ϵ), where ∆ is the actual mean difference between human and LLM texts.
- Mechanism: The expected detection time is bounded by E[τ] ≲ d*³/(∆ - ϵ)² · log((d* + ϵ)(3+1/γ)/(∆ - ϵ)²α), where larger (∆ - ϵ) leads to shorter detection times. The algorithm can quickly detect LLMs when score discrepancy between human and LLM texts is large relative to variation among human texts.
- Core assumption: The score function ϕ can produce scores with sufficiently different means for human-written and LLM-generated texts, and the variance of these scores is bounded.
- Evidence anchors:
  - [section 4.2] "We observe that the rejection time is influenced by the relative magnitude of∆ − ϵ and dt − ϵ, as predicted by our propositions"

## Foundational Learning

- Concept: Sequential hypothesis testing with level-α and asymptotic power one
  - Why needed here: Provides the statistical framework for making online decisions about LLM authorship with guaranteed error rates
  - Quick check question: What is the difference between level-α and asymptotic power one in hypothesis testing?

- Concept: Online convex optimization and regret bounds
  - Why needed here: Enables the algorithm to adaptively update parameters θt to maximize wealth accumulation when detecting LLMs
  - Quick check question: How does the regret bound of Online Newton Steps relate to the wealth accumulation in the betting framework?

- Concept: Ville's inequality and randomized Ville's inequality
  - Why needed here: Provides the mathematical foundation for controlling type-I error rates in sequential testing
  - Quick check question: Under what conditions can Ville's inequality be applied to a wealth process?

## Architecture Onboarding

- Component map: Score function ϕ -> Score difference gt -> Wealth update Wt -> Parameter update θt -> Decision rule

- Critical path:
  1. Observe text yt from unknown source
  2. Sample human text xt from prepared dataset
  3. Compute scores ϕ(xt) and ϕ(yt)
  4. Calculate gt = ϕ(xt) - ϕ(yt)
  5. Update wealth Wt = Wt-1 · (1 - gtθt)
  6. Check if Wt ≥ threshold, if yes declare LLM source
  7. Update θt+1 using Online Newton Steps
  8. Repeat until decision made or time budget exhausted

- Design tradeoffs:
  - Score function selection: More discriminative functions lead to faster detection but may require more computation
  - Parameter estimation: Using first few samples to estimate dt and ϵ trades off between early detection and statistical guarantees
  - Significance level α: Lower α provides stronger guarantees but may require more observations for detection

- Failure signatures:
  - High false positive rates: Indicates score function cannot distinguish human from LLM texts, or estimated parameters are incorrect
  - Slow detection times: Suggests score function has small ∆ or high variance among human texts
  - Algorithm never declares LLM: Could indicate insufficient time budget or score function is ineffective

- First 3 experiments:
  1. Test with synthetic data where ground truth is known to verify statistical guarantees
  2. Compare detection times and FPRs across different score functions with the same scoring model
  3. Test algorithm performance when xt and yt come from different text domains to assess domain robustness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different choices of scoring models and score functions impact the expected time to detect LLM-generated text under various hypothesis testing scenarios?
- Basis in paper: [explicit] The paper demonstrates that configurations using Fast-DetectGPT or Likelihood score functions with appropriate scoring models (e.g., Neo-2.7) yield faster detection times, while some supervised classifiers (RoBERTa-based) may fail to strictly control FPRs.
- Why unresolved: While the paper compares several score functions and scoring models, it does not provide a systematic analysis of how different combinations affect detection time across various text domains and source models.
- What evidence would resolve it: Controlled experiments comparing detection times for various combinations of score functions and scoring models across multiple text domains and LLM sources, with statistical analysis of the results.

### Open Question 2
- Question: Can the performance of the proposed algorithm be improved by designing score functions specifically tailored for sequential hypothesis testing?
- Basis in paper: [inferred] The paper acknowledges that using estimated parameters based on the first few time steps may lead to suboptimal performance, suggesting that designing score functions tailored for sequential settings could enhance efficacy.
- Why unresolved: The paper uses existing score functions designed for offline detection, which may not be optimal for the online sequential setting. No attempt is made to design new score functions specifically for this purpose.
- What evidence would resolve it: Development and evaluation of new score functions designed specifically for sequential hypothesis testing, comparing their performance against existing score functions in terms of detection time and FPR control.

### Open Question 3
- Question: How does the choice of the parameter ϵ affect the trade-off between false positive rate and expected detection time in the composite hypothesis testing scenario?
- Basis in paper: [explicit] The paper discusses the composite hypothesis testing scenario, where ϵ allows for a small difference in means between human-written texts. It shows that smaller ϵ and larger ∆ lead to shorter detection times.
- Why unresolved: While the paper provides bounds on the expected detection time as a function of ϵ, it does not explore the practical implications of different ϵ choices on the trade-off between FPR and detection time.
- What evidence would resolve it: Empirical studies varying the value of ϵ across different text domains and source models, analyzing the resulting FPRs and detection times to identify optimal choices for different scenarios.

## Limitations
- The algorithm requires a dataset of human-written text examples for sampling at each round, which may not always be available or representative of the target domain.
- Detection time can be long if the score discrepancy between human and LLM texts is small or if there is high variance among human texts.
- The algorithm is designed for binary classification (LLM vs. human) and may not generalize well to more complex scenarios involving multiple LLM models or mixed authorship.

## Confidence
- Performance depends on availability of discriminative score functions: Medium
- Parameter estimation accuracy affects algorithm guarantees: Medium
- Real-world performance may vary from experimental results: Medium

## Next Checks
1. Conduct experiments with synthetic data where ground truth is known to verify the statistical guarantees of controlled false positive rate and expected detection time under various conditions.
2. Perform ablation studies to assess the impact of different score functions, parameter estimation methods, and significance levels on detection performance.
3. Test the algorithm's robustness to domain shifts by evaluating its performance when human and LLM texts come from different domains or when the human text dataset is not representative of the observed texts.