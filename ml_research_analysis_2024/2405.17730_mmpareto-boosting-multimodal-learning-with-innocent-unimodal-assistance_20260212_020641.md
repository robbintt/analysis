---
ver: rpa2
title: 'MMPareto: Boosting Multimodal Learning with Innocent Unimodal Assistance'
arxiv_id: '2405.17730'
source_url: https://arxiv.org/abs/2405.17730
tags:
- multimodal
- learning
- unimodal
- gradient
- pareto
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies gradient conflicts between multimodal and
  unimodal objectives in multitask-like multimodal frameworks, which can mislead unimodal
  encoder optimization. The authors observe that multimodal gradients have smaller
  magnitude and covariance than unimodal gradients, causing conventional Pareto integration
  to harm generalization.
---

# MMPareto: Boosting Multimodal Learning with Innocent Unimodal Assistance

## Quick Facts
- **arXiv ID**: 2405.17730
- **Source URL**: https://arxiv.org/abs/2405.17730
- **Reference count**: 27
- **Primary result**: MMPareto achieves 75.13% accuracy on CREMA-D vs 71.10% for uniform baseline, outperforming individually trained unimodal models.

## Executive Summary
This paper addresses gradient conflicts between multimodal and unimodal objectives in multitask-like multimodal frameworks. The authors observe that multimodal gradients have smaller magnitude and covariance than unimodal gradients, causing conventional Pareto integration to harm generalization. MMPareto provides direction common to all objectives while enhancing magnitude for better generalization. Experiments across multiple datasets show MMPareto achieves superior multimodal performance and extends to multi-task scenarios.

## Method Summary
MMPareto integrates gradients from multimodal and unimodal losses by first computing individual gradients for multimodal (Lm) and unimodal (Lk_u) losses, then solving Pareto optimization to find optimal weights αm, αu. For non-conflict cases, it equally weights multimodal and unimodal gradients. For conflict cases, it finds a non-conflict direction and scales the gradient magnitude by factor γ>1 to boost noise strength. The method uses ResNet-18 or MBT backbone, SGD with momentum, learning rate 1e-3, γ=1.5, and 2 NVIDIA RTX 3090 GPUs.

## Key Results
- MMPareto achieves 75.13% accuracy on CREMA-D vs 71.10% for uniform baseline
- Outperforms individually trained unimodal models on multimodal tasks
- Extends to multi-task scenarios, demonstrating scalability beyond bimodal cases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multimodal gradients have smaller magnitude and covariance than unimodal gradients, causing gradient conflicts.
- Core assumption: Multimodal loss is easier to learn due to richer information from all modalities, resulting in smaller gradient magnitudes and covariances.
- Evidence: Abstract states "gradient magnitude and covariance of the easier-to-learn multimodal loss are smaller than the unimodal one."

### Mechanism 2
- Claim: Conventional Pareto integration fails in multimodal scenarios because it assigns larger weights to smaller multimodal gradients, harming generalization.
- Core assumption: Larger noise strength in SGD leads to flatter minima and better generalization.
- Evidence: Abstract states "conventional Pareto could affect SGD noise strength and then bring the model to a sharper minima, weakening model generalization ability."

### Mechanism 3
- Claim: MMPareto ensures innocent unimodal assistance by providing a final gradient with a direction common to all objectives and enhanced magnitude for improved generalization.
- Core assumption: Enhancing gradient magnitude during integration increases SGD noise strength, leading to flatter minima and improved generalization.
- Evidence: Abstract states "MMPareto algorithm, which could ensure a final gradient with direction that is common to all learning objectives and enhanced magnitude to improve generalization."

## Foundational Learning

- Concept: Pareto integration in multi-task learning
  - Why needed here: MMPareto builds upon Pareto integration to address gradient conflicts in multimodal learning.
  - Quick check question: What is the goal of Pareto integration in multi-task learning, and how does it find a common descent direction for all objectives?

- Concept: Stochastic Gradient Descent (SGD) and its noise properties
  - Why needed here: MMPareto leverages SGD noise strength to improve generalization by ensuring flatter minima.
  - Quick check question: How does the noise strength in SGD affect the generalization of the model, and what factors influence the noise strength?

- Concept: Multimodal learning and the imbalanced multimodal learning problem
  - Why needed here: MMPareto is designed to address the imbalanced multimodal learning problem by mitigating gradient conflicts between multimodal and unimodal objectives.
  - Quick check question: What is the imbalanced multimodal learning problem, and why does it arise in multimodal learning scenarios?

## Architecture Onboarding

- Component map: Input data -> Unimodal encoders -> Multimodal encoder -> Predictions -> Multimodal and unimodal losses -> MMPareto gradient integration -> Parameter update

- Critical path: 1) Forward pass through unimodal and multimodal encoders, 2) Compute multimodal and unimodal losses, 3) Backward pass to compute gradients, 4) MMPareto integrates gradients to produce final gradient, 5) Update parameters using final gradient

- Design tradeoffs: MMPareto vs uniform baseline (direction alignment vs simple summation), MMPareto vs conventional Pareto (handles multimodal-specific conflicts), complexity vs performance (additional computation for superior results)

- Failure signatures: Poor multimodal performance from improper gradient integration, unimodal encoder overfitting from inadequate regularization or high learning rates

- First 3 experiments: 1) Compare MMPareto with baselines on Colored-and-gray-MNIST, 2) Analyze gradient magnitudes/covariances during training, 3) Visualize loss landscape and generalization gap across methods

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal range of gradient magnitude enhancement (γ) for MMPareto across different datasets and architectures?
- Basis: Paper uses γ=1.5 but doesn't explore optimal values across scenarios
- Why unresolved: Only one γ value tested without systematic exploration
- Resolution evidence: Systematic experiments varying γ across datasets and architectures

### Open Question 2
- Question: How does MMPareto perform in multimodal pre-training scenarios compared to discriminative tasks?
- Basis: Paper mentions applicability to pre-training frameworks like BLIP-2
- Why unresolved: Only discriminative tasks tested, not pre-training scenarios
- Resolution evidence: Experiments applying MMPareto to multimodal pre-training frameworks

### Open Question 3
- Question: Can MMPareto be extended to handle more than three modalities effectively?
- Basis: Paper tests three modalities (CMU-MOSI) but claims scalability
- Why unresolved: Only three modalities tested without exploration of scalability
- Resolution evidence: Experiments with four or more modalities measuring performance degradation

### Open Question 4
- Question: What is the theoretical relationship between gradient covariance estimation accuracy and MMPareto's performance?
- Basis: Paper mentions covariance as future direction but doesn't explore estimation errors
- Why unresolved: Covariance estimation accuracy not analyzed for performance impact
- Resolution evidence: Theoretical analysis of estimation errors followed by empirical validation

## Limitations

- Limited exploration of optimal gradient magnitude enhancement factor γ across different scenarios
- Only tested on bimodal and three-modality cases without verification of scalability to many modalities
- Weak corpus signals suggest limited direct prior validation of multimodal-specific Pareto integration claims

## Confidence

- **High Confidence**: Multimodal and unimodal objectives can conflict during shared encoder optimization; gradient magnitude differences exist between objectives
- **Medium Confidence**: Smaller multimodal gradients lead to ineffective Pareto integration; enhanced gradient magnitude improves generalization through noise strength
- **Low Confidence**: Specific mathematical relationship between gradient magnitudes/covariances and Pareto weights; generalizability beyond bimodal scenarios

## Next Checks

1. **Gradient Analysis Validation**: Track gradient magnitudes and covariances during training to empirically verify multimodal gradients are consistently smaller than unimodal gradients across datasets and architectures.

2. **Generalization Gap Measurement**: Compare test accuracy versus training accuracy for models trained with MMPareto, uniform baseline, and conventional Pareto to quantify whether MMPareto produces flatter minima and better generalization.

3. **Multi-Modal Extension Test**: Implement MMPareto for a three-modality scenario (audio-text-vision) to verify scalability beyond bimodal cases and effectiveness of conflict detection/resolution mechanisms.