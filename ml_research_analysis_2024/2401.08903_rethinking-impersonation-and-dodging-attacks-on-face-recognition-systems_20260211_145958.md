---
ver: rpa2
title: Rethinking Impersonation and Dodging Attacks on Face Recognition Systems
arxiv_id: '2401.08903'
source_url: https://arxiv.org/abs/2401.08903
tags:
- adversarial
- attacks
- attack
- face
- dodging
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper identifies a fundamental gap in adversarial attacks
  on face recognition (FR) systems: previous impersonation attacks do not necessarily
  succeed in dodging attacks, especially in black-box settings. The authors propose
  Adversarial Pruning (Adv-Pruning), a three-stage method (Priming, Pruning, and Restoration)
  that enhances dodging attack capabilities while maintaining impersonation performance.'
---

# Rethinking Impersonation and Dodging Attacks on Face Recognition Systems

## Quick Facts
- arXiv ID: 2401.08903
- Source URL: https://arxiv.org/abs/2401.08903
- Reference count: 40
- Primary result: Adv-Pruning significantly improves dodging attack success while maintaining impersonation capabilities

## Executive Summary
This paper identifies a fundamental limitation in adversarial attacks on face recognition systems: previous impersonation attacks do not necessarily succeed in dodging attacks, particularly in black-box settings. The authors propose Adversarial Pruning (Adv-Pruning), a three-stage method that enhances dodging attack capabilities while maintaining impersonation performance. The method quantifies adversarial perturbation priorities, prunes less impactful perturbations, and introduces Biased Gradient Adaptation to add dodging-favorable perturbations in vacated regions. Experiments demonstrate significant improvements in dodging attack success rates across multiple datasets and face recognition models.

## Method Summary
The paper proposes Adversarial Pruning (Adv-Pruning), a three-stage method consisting of Priming, Pruning, and Restoration phases. The method addresses the fundamental gap where impersonation attacks fail to guarantee successful dodging attacks in black-box settings. Adv-Pruning quantifies the importance of each adversarial perturbation, prunes less impactful ones, and uses Biased Gradient Adaptation to introduce dodging-favorable perturbations in the vacated regions. This approach maintains strong impersonation performance while significantly improving dodging attack success rates.

## Key Results
- Adv-Pruning significantly improves dodging ASR while maintaining impersonation ASR compared to state-of-the-art methods
- The method proves effective under JPEG compression (quality levels 60-80) and against adversarial robust models
- Experimental validation conducted on multiple datasets (LFW, CelebA-HQ, FFHQ, BUPT-Balancedface) and FR models (IR152, FaceNet, MF, ArcFace, etc.)

## Why This Works (Mechanism)
Adv-Pruning works by strategically reallocating adversarial perturbation budget from less impactful regions to those more favorable for dodging attacks. The method first quantifies perturbation importance through the Priming stage, then removes less critical perturbations during Pruning, and finally uses Biased Gradient Adaptation during Restoration to add new perturbations specifically targeted at evading recognition. This approach recognizes that different regions of the adversarial perturbation contribute differently to impersonation versus dodging objectives, allowing for optimized allocation of the perturbation budget.

## Foundational Learning
- **Adversarial perturbation quantification**: Understanding how to measure perturbation importance is crucial for effective pruning. Quick check: Can you explain why some perturbations contribute more to impersonation than dodging?
- **Black-box attack transferability**: The method specifically addresses challenges in black-box settings where the attacker lacks full model access. Quick check: What makes black-box attacks fundamentally different from white-box attacks in face recognition?
- **Perturbation budget allocation**: The core innovation involves reallocating limited perturbation resources. Quick check: How does the method determine which perturbations to keep versus prune?

## Architecture Onboarding

Component map: Input image -> Priming (importance scoring) -> Pruning (removal of low-priority perturbations) -> Restoration (Biased Gradient Adaptation) -> Adversarial example

Critical path: The Priming stage identifies perturbation priorities, which directly determines which perturbations survive the Pruning stage. The Restoration stage then builds upon these pruned regions to add dodging-specific modifications.

Design tradeoffs: The method trades some computational overhead in the multi-stage process for improved attack effectiveness, particularly in black-box scenarios where single-stage attacks typically fail.

Failure signatures: If the Priming stage incorrectly identifies perturbation importance, the Pruning stage may remove critical perturbations, leading to reduced attack effectiveness for both impersonation and dodging objectives.

First experiments:
1. Test Adv-Pruning on a simple face recognition model with known architecture to verify the three-stage process works as intended
2. Compare perturbation distributions before and after each stage to validate the pruning and restoration mechanisms
3. Evaluate attack success rates on a held-out test set to establish baseline performance before scaling to larger experiments

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions beyond the fundamental gap it addresses between impersonation and dodging attacks.

## Limitations
- Effectiveness on alternative FR architectures (e.g., attention-based or transformer models) remains unverified
- The perturbation prioritization criteria may not generalize to models with different loss landscapes
- JPEG compression robustness only tested at moderate quality levels (60-80), leaving uncertainty about extreme compression scenarios

## Confidence
- High confidence: The fundamental gap identification and quantitative improvements in dodging ASR are well-supported
- Medium confidence: The three-stage framework is novel but superiority over alternative pruning strategies needs more exploration
- Medium confidence: Effectiveness against adversarial robust models demonstrated but may not hold against specialized defenses

## Next Checks
1. Test Adv-Pruning transferability to face recognition models outside the current evaluation scope, particularly those using different backbone architectures
2. Evaluate the method's performance on additional demographic datasets to verify no introduction of demographic biases
3. Conduct experiments with varying JPEG compression quality levels (including extreme cases like quality 20-40) and other common image distortions