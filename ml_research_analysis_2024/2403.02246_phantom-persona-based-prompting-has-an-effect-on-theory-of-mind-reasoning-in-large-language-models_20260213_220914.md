---
ver: rpa2
title: 'PHAnToM: Persona-based Prompting Has An Effect on Theory-of-Mind Reasoning
  in Large Language Models'
arxiv_id: '2403.02246'
source_url: https://arxiv.org/abs/2403.02246
tags:
- personality
- traits
- task
- performance
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study explores how persona-based prompting affects large
  language models'' (LLMs) Theory-of-Mind (ToM) reasoning abilities across three tasks:
  Information Access, Answerability, and Belief Understanding. Using eight personality
  traits (Big Five OCEAN and Dark Triad), we systematically evaluate performance changes
  in Mistral 7B, Llama 2, Falcon 7B, Zephyr 7B Beta, and GPT-3.5.'
---

# PHAnToM: Persona-based Prompting Has An Effect on Theory-of-Mind Reasoning in Large Language Models

## Quick Facts
- **arXiv ID**: 2403.02246
- **Source URL**: https://arxiv.org/abs/2403.02246
- **Reference count**: 40
- **Primary result**: Persona-based prompting significantly affects large language models' Theory-of-Mind reasoning performance, with Dark Triad traits showing the largest impact and generally adverse effects

## Executive Summary
This study systematically evaluates how persona-based prompting affects large language models' Theory-of-Mind (ToM) reasoning abilities across three tasks: Information Access, Answerability, and Belief Understanding. Using eight personality traits from the Big Five OCEAN and Dark Triad frameworks, the researchers tested five models (Mistral 7B, Llama 2, Falcon 7B, Zephyr 7B Beta, and GPT-3.5). Results demonstrate that Dark Triad traits have the largest impact on ToM performance, with models like Llama 2 showing up to 33% performance decline when prompted with Machiavellianism. The findings suggest that carefully considering assigned personas is crucial as these can significantly shape LLMs' social-cognitive reasoning abilities.

## Method Summary
The study evaluates five large language models using persona-based prompting with eight personality traits (Big Five OCEAN and Dark Triad) across three ToM tasks. The researchers prepended personality descriptions to task prompts, then measured performance using weighted F1 scores for Information Access and Answerability tasks, and accuracy for Belief Understanding. They compared performance against baseline (no prompt) conditions to quantify the impact of different persona assignments. The experimental design included multiple model architectures with different training methodologies (RLHF vs dialogue fine-tuning) to examine sensitivity variations.

## Key Results
- Dark Triad traits have the largest impact on ToM performance across all models
- Llama 2 shows up to 33% performance decline with Machiavellianism prompting
- GPT-3.5 demonstrates the most resilience with moderate variations across traits
- Agreeableness and Conscientiousness traits generally improve performance while Dark Triad traits impair it
- Training methodology affects sensitivity, with RLHF models showing higher responsiveness to persona descriptions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Persona-based prompting alters internal model activations related to social reasoning
- Mechanism: The model's internal representations of social dynamics are shifted based on the personality trait description, affecting how it processes Theory-of-Mind tasks
- Core assumption: The personality description is semantically meaningful enough to shift internal representations
- Evidence anchors:
  - [abstract] "Results show that Dark Triad traits have the largest impact on ToM performance"
  - [section] "The differences in the influences of persona-based prompting on various tasks could be attributed to the specific ToM constructs assessed by each task"
  - [corpus] Weak - no direct corpus evidence about internal representations
- Break condition: If personality descriptions are ignored by the model or treated as irrelevant context

### Mechanism 2
- Claim: Persona-based prompting creates implicit reasoning biases in social-cognitive tasks
- Mechanism: The model adopts a persona that carries implicit social reasoning biases, which then influences its performance on Theory-of-Mind tasks
- Core assumption: The persona description is internalized as part of the model's reasoning context
- Evidence anchors:
  - [abstract] "highlighting the importance of carefully considering the personas assigned to LLMs, as these can significantly shape their reasoning abilities"
  - [section] "Our findings suggest that persona-based prompting, particularly when aligned with specific personality traits, can influence ToM task performance in predictable ways"
  - [corpus] Weak - no direct corpus evidence about implicit bias mechanisms
- Break condition: If the model maintains a consistent baseline regardless of persona description

### Mechanism 3
- Claim: Different training methodologies create varying sensitivity to persona-based prompting
- Mechanism: Models fine-tuned with RLHF are more sensitive to personality descriptions than those fine-tuned on LLM-generated dialogues
- Core assumption: Training methodology affects how models process and respond to persona-based prompts
- Evidence anchors:
  - [section] "Llama 2 and GPT-3.5 were fine-tuned using Reinforcement Learning with Human Feedback (RLHF)...Zephyr and Falcon were predominantly fine-tuned on LLM-generated dialogues"
  - [section] "Llama 2 demonstrates the highest sensitivity to persona-based prompts, with a notable 33% decrease in F1 score"
  - [corpus] Weak - no direct corpus evidence about training methodology effects
- Break condition: If all models show similar sensitivity regardless of training methodology

## Foundational Learning

- **Concept**: Theory of Mind (ToM)
  - Why needed here: This study evaluates how persona-based prompting affects ToM reasoning in LLMs
  - Quick check question: What is the "Sally and Ann" task and why is it significant for Theory of Mind evaluation?

- **Concept**: Personality trait frameworks (Big Five OCEAN, Dark Triad)
  - Why needed here: The study uses these specific personality traits to create persona-based prompts
  - Quick check question: What are the five subscales of the Big Five personality model and how do they differ from the Dark Triad traits?

- **Concept**: Prompt engineering techniques
  - Why needed here: The study specifically examines how different prompt engineering approaches (persona-based vs traditional role-play) affect model performance
  - Quick check question: How does persona-based prompting differ from traditional task-specific role-play prompting in LLM applications?

## Architecture Onboarding

- **Component map**: Persona description generation → Prompt template creation → Model execution with different LLMs → Performance measurement across three ToM tasks → Statistical analysis of results
- **Critical path**: Persona description → Prompt template → Model execution → Performance measurement → Analysis
- **Design tradeoffs**: Using multiple LLMs provides broader generalizability but increases computational cost; focusing on three specific ToM tasks provides depth but may miss other relevant cognitive dimensions
- **Failure signatures**: Performance not changing with different personas (prompt ignored), extreme variance across tasks (task-specific issues), one model consistently outperforming others (model-specific bias)
- **First 3 experiments**:
  1. Run baseline performance on all three ToM tasks without any persona prompting
  2. Apply Agreeableness persona prompting and measure performance changes across all models and tasks
  3. Apply Machiavellianism persona prompting and compare performance degradation patterns with Agreeableness results

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different fine-tuning methodologies (e.g., RLHF vs. instruction tuning vs. human-generated dialogue) influence LLMs' sensitivity to persona-based prompting across various tasks?
- Basis in paper: [explicit] The paper observes that Llama 2 and GPT-3.5 (fine-tuned with RLHF) show higher sensitivity to personality descriptions compared to Falcon and Zephyr (fine-tuned on LLM-generated dialogues).
- Why unresolved: While the paper identifies a correlation between fine-tuning methodology and sensitivity, it does not establish causal mechanisms or explore intermediate factors that might mediate this relationship.
- What evidence would resolve it: Controlled experiments comparing models with identical architectures but different fine-tuning approaches, coupled with analysis of internal representations during persona-based prompting.

### Open Question 2
- Question: What are the long-term effects of consistent persona-based prompting on LLMs' performance across diverse tasks beyond ToM reasoning?
- Basis in paper: [inferred] The paper examines immediate effects of persona-based prompts but does not explore how repeated exposure to specific personas might affect model behavior over time or across different task domains.
- Why unresolved: The study focuses on single-instance performance changes without considering cumulative effects of persona adoption or potential adaptation mechanisms in LLMs.
- What evidence would resolve it: Longitudinal studies tracking model performance across multiple sessions and task types when consistently exposed to specific personas.

### Open Question 3
- Question: How do different prompt engineering techniques (e.g., role-play prompts, task-specific prompts) compare in their effectiveness at enhancing ToM reasoning across various LLM architectures?
- Basis in paper: [explicit] The paper compares persona-based prompting with traditional task-specific role-play prompts, finding mixed results that suggest traditional approaches are not always effective.
- Why unresolved: While the paper demonstrates differential effectiveness of different prompting approaches, it does not systematically explore the interaction between prompt type, task complexity, and model architecture.
- What evidence would resolve it: Comprehensive comparative studies varying prompt engineering techniques across multiple tasks and model architectures, with analysis of which combinations yield optimal performance.

## Limitations
- The exact phrasing and wording of personality trait descriptions remain unspecified
- Only three specific ToM tasks are evaluated, potentially missing other dimensions of social-cognitive reasoning
- The study does not empirically validate the proposed mechanisms of how persona-based prompting affects model performance

## Confidence

**High Confidence**: The empirical observation that different personality traits produce varying effects on model performance is well-supported by the experimental data across multiple models and tasks. The finding that Dark Triad traits generally have adverse effects on performance while traits like Agreeableness and Conscientiousness improve performance is consistently demonstrated.

**Medium Confidence**: The claim that training methodology (RLHF vs dialogue fine-tuning) affects sensitivity to persona-based prompting is supported by the observed differences between Llama 2/GPT-3.5 and Zephyr/Falcon, but the underlying mechanism remains speculative without direct evidence linking training approaches to persona processing.

**Low Confidence**: The proposed mechanisms about how persona-based prompting alters internal model activations or creates implicit reasoning biases lack direct empirical support from this study. These remain theoretical explanations for the observed patterns.

## Next Checks

1. **Mechanism Validation**: Conduct activation analysis to empirically verify whether persona-based prompting actually shifts internal representations related to social reasoning, using techniques like probing classifiers or representation similarity analysis.

2. **Prompt Sensitivity Analysis**: Systematically vary the wording and specificity of personality trait descriptions to determine the minimum prompt complexity required to produce measurable effects, testing whether the observed performance changes are robust to prompt variations.

3. **Generalization Testing**: Evaluate the effects of persona-based prompting on additional ToM tasks beyond the three studied (such as false-belief tasks or emotional inference tasks) to determine whether the observed patterns generalize across different dimensions of Theory-of-Mind reasoning.