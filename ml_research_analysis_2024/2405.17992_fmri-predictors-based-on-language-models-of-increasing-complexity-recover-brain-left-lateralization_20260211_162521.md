---
ver: rpa2
title: fMRI predictors based on language models of increasing complexity recover brain
  left lateralization
arxiv_id: '2405.17992'
source_url: https://arxiv.org/abs/2405.17992
tags:
- brain
- language
- correlation
- gyrus
- parameters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated the left-right asymmetry in language processing
  using fMRI and increasingly complex language models. The authors analyzed fMRI data
  from participants listening to naturalistic text, using 28 pretrained models ranging
  from 124M to 14.2B parameters.
---

# fMRI predictors based on language models of increasing complexity recover brain left lateralization

## Quick Facts
- arXiv ID: 2405.17992
- Source URL: https://arxiv.org/abs/2405.17992
- Authors: Laurent Bonnasse-Gahot; Christophe Pallier
- Reference count: 40
- One-line primary result: Brain correlation increases linearly with model size logarithm, with stronger effect in left hemisphere

## Executive Summary
This study investigates left-right asymmetry in language processing by analyzing fMRI data from participants listening to naturalistic text, using 28 pretrained language models ranging from 124M to 14.2B parameters. The authors find that brain correlation follows a scaling law with model size, and this effect is stronger in the left hemisphere. The left-right difference in brain correlation also follows a scaling law with model size, providing a computational reconciliation of classical observations of left hemisphere dominance for language. The results suggest that larger models better capture language representations in the left hemisphere, particularly in regions associated with high-level language comprehension and semantic processing.

## Method Summary
The study uses fMRI data from 49 English speakers listening to "Le Petit Prince" audiobook, analyzing 28 pretrained language models across 8 families (124M to 14.2B parameters). Language model activations are extracted and convolved with hemodynamic response function, then mapped to fMRI time series using ridge regression with cross-validation. Brain correlations are computed and analyzed for scaling relationships with model size, with left-right hemispheric differences examined using Harvard-Oxford atlas regions. The analysis is replicated across English, Chinese, and French datasets to verify generalizability.

## Key Results
- Brain correlation increases linearly with the logarithm of model parameters (scaling law)
- Left hemisphere shows stronger brain correlation than right hemisphere, with the asymmetry following a scaling law
- The cortical areas most affected by model size are angular gyrus, precuneus, and medial prefrontal cortex, involved in high-level language comprehension
- Similar scaling laws and left-right asymmetry observed across English, Chinese, and French datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Larger language models capture increasingly sophisticated language representations that better align with brain activity in the left hemisphere, particularly in semantic and high-level language comprehension regions.
- Mechanism: As model size increases, the complexity and quality of linguistic representations improve. These representations progressively align better with neural activity patterns, especially in regions specialized for language processing like the left angular gyrus, precuneus, and medial prefrontal cortex. The left-right asymmetry emerges because these regions are more specialized for language and thus show stronger alignment with larger models' representations.
- Core assumption: Language processing regions in the left hemisphere are more specialized for high-level semantic processing, making them more sensitive to improvements in model representations.
- Evidence anchors:
  - [abstract]: "we observe that the performance of models in predicting brain responses follows a scaling law, where the fit with brain activity increases linearly with the logarithm of the number of parameters of the model" and "the left-right difference in brain correlation follows a scaling law with the number of parameters"
  - [section]: "The cortical areas where model size has the strongest impact are the Angular gyrus, the Precuneus and the medial prefrontal cortex... These regions are not specific to language, e.g. they are part of the default mode network, but are involved in the highest levels of language comprehension"
  - [corpus]: Weak evidence - corpus shows related work on model-brain alignment but doesn't directly address left-right asymmetry mechanisms
- Break condition: If language processing were distributed equally across hemispheres, or if model representations improved equally in both hemispheres, the asymmetry would not emerge.

### Mechanism 2
- Claim: The emergence of left-right asymmetry is driven by training-dependent improvements in language models, not just model architecture size.
- Mechanism: During training, language models develop increasingly sophisticated representations of language. As training progresses, these representations better match neural activity patterns in left hemisphere language regions. The asymmetry emerges because training improves left hemisphere alignment more than right hemisphere alignment, particularly in regions associated with high-level semantic processing.
- Core assumption: Training process shapes representations in ways that differentially affect left and right hemisphere language regions.
- Evidence anchors:
  - [abstract]: "we report analyses of an fMRI dataset where we manipulate the complexity of large language models, testing 28 pretrained models from 8 different families, ranging from 124M to 14.2B parameters"
  - [section]: "we compared r-scores for randomly initialized, untrained models, and for trained models... with training, brain correlations get better on the left hemisphere compared to the right one"
  - [corpus]: Weak evidence - corpus contains related work on model-brain alignment but lacks specific evidence about training-dependent asymmetry emergence
- Break condition: If untrained models showed similar asymmetry, or if training affected both hemispheres equally, this mechanism would not hold.

### Mechanism 3
- Claim: The scaling law relationship between model size and brain correlation reflects improvements in model performance on language tasks that translate to better neural alignment.
- Mechanism: As models grow larger, their performance on language tasks (measured by perplexity and other benchmarks) improves. This enhanced task performance corresponds to better capture of linguistic features that are represented in brain activity patterns. The left hemisphere shows stronger alignment because it processes more complex language features that larger models better capture.
- Core assumption: Improvements in language model performance on standard benchmarks translate to better alignment with brain activity patterns.
- Evidence anchors:
  - [abstract]: "the performance of models in predicting brain responses follows a scaling law, where the fit with brain activity increases linearly with the logarithm of the number of parameters of the model (and its performance on natural language processing tasks)"
  - [section]: "we also look at measures of models' performance beyond their raw number of parameters... Both measures exhibit strong correlation with brain fit"
  - [corpus]: Moderate evidence - corpus includes related work showing model size affects brain alignment, though not specifically addressing task performance relationships
- Break condition: If model size improvements didn't translate to better task performance, or if task performance didn't correlate with brain alignment, this mechanism would fail.

## Foundational Learning

- Concept: fMRI signal processing and hemodynamic response function
  - Why needed here: The study relies on fMRI data from participants listening to text, requiring understanding of how neural activity translates to BOLD signals and how these signals are processed
  - Quick check question: How does the hemodynamic response function affect the alignment between model predictions and fMRI time series?

- Concept: Language model architectures and parameter scaling
  - Why needed here: The study examines 28 models ranging from 124M to 14.2B parameters across 8 families, requiring understanding of how model architecture affects representational capacity
  - Quick check question: What architectural differences between Transformer and Mamba models might affect their brain alignment performance?

- Concept: Brain lateralization and language network organization
  - Why needed here: The study investigates left-right asymmetry in language processing, requiring understanding of how language networks are organized across hemispheres
  - Quick check question: What evidence supports the classical view of left hemisphere dominance for language, and how might this relate to model-brain alignment?

## Architecture Onboarding

- Component map: fMRI preprocessing pipeline -> Language model activation extraction -> Ridge regression encoding model fitting -> Scaling law and lateralization analysis
- Critical path: Data preprocessing → Model activation extraction → Encoding model fitting → Statistical analysis of scaling and lateralization
- Design tradeoffs: The study uses group-averaged data for computational efficiency but acknowledges individual variability; the choice of regions of interest versus whole-brain analysis affects sensitivity to lateralization effects
- Failure signatures: Lack of scaling relationship would indicate models aren't capturing increasingly sophisticated language representations; absence of lateralization would suggest models aren't aligning with hemisphere-specific language processing
- First 3 experiments:
  1. Replicate the scaling law analysis using a smaller subset of models to verify the basic relationship
  2. Test whether the asymmetry holds when normalizing brain correlations by inter-subject reliability
  3. Compare trained versus untrained versions of the same model family to verify training-dependent effects on lateralization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific linguistic or semantic representations in larger language models drive the observed left hemisphere lateralization?
- Basis in paper: [explicit] The paper states that the main effect of increasing model size is to improve the model capabilities at the semantic and pragmatic levels, but questions remain about which specific representations are responsible for the left-right asymmetry.
- Why unresolved: The study observes the asymmetry but does not directly analyze what representations in the models are responsible for it. It calls for detailed comparisons of features discovered by large vs small language models.
- What evidence would resolve it: Comparative analysis of linguistic features (lexical, syntactic, semantic, pragmatic) in different sized models and their corresponding fMRI prediction accuracy in left vs right hemispheres would help identify the responsible representations.

### Open Question 2
- Question: Does the emergence of left hemisphere lateralization during model training mirror the developmental trajectory of language lateralization in human infants?
- Basis in paper: [explicit] The paper notes that language processing in the brain starts bilaterally and becomes progressively lateralized over time in humans, and presents preliminary exploration showing the left-right asymmetry emerges during the training process of language models.
- Why unresolved: While the paper observes that asymmetry emerges during training, it does not directly compare this process to human language development or establish any parallels.
- What evidence would resolve it: Longitudinal tracking of lateralization patterns during both human language acquisition and model training, examining whether similar developmental trajectories exist.

### Open Question 3
- Question: Is the observed left hemisphere dominance for language processing universal across all languages and cultures?
- Basis in paper: [explicit] The paper extends its analysis to Chinese and French data and observes similar scaling laws and left-right asymmetry, noting that left dominance is universal in humans.
- Why unresolved: While the study shows the effect holds in three languages, it doesn't test a broader range of languages with different linguistic structures or investigate potential cultural influences on hemispheric specialization.
- What evidence would resolve it: Testing the model across a wider variety of languages (including non-Indo-European languages) and diverse cultural contexts to confirm universal applicability of the findings.

## Limitations

- The study relies on group-averaged fMRI data, limiting conclusions about individual differences in lateralization patterns
- Results may be specific to the particular language models and fMRI dataset used, requiring validation across different models and tasks
- The mechanisms linking model size to left hemisphere alignment remain partially speculative, with causal relationships not fully established

## Confidence

- High confidence: Core findings about scaling law relationship and emergence of left-right asymmetry with increasing model size
- Medium confidence: Specific mechanisms proposed for how model architecture and training affect hemispheric specialization
- Low confidence: Generalizability to individual subjects and different language models beyond those tested

## Next Checks

1. Test whether the asymmetry persists when controlling for task difficulty or linguistic complexity within the stimuli
2. Compare brain alignment across different model architectures (e.g., Transformers vs Mamba) to assess whether the scaling law is architecture-independent
3. Conduct the same analysis on individual subject data to verify that group-level patterns reflect consistent individual differences rather than averaging artifacts