---
ver: rpa2
title: 'Generative flow induced neural architecture search: Towards discovering optimal
  architecture in wavelet neural operator'
arxiv_id: '2405.06910'
source_url: https://arxiv.org/abs/2405.06910
tags:
- neural
- wavelet
- operator
- flow
- state
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a generative flow-based neural architecture
  search algorithm for neural operators, specifically applied to the wavelet neural
  operator (WNO). The method learns stochastic policies to generate sequences of architecture
  hyperparameters (wavelet basis and activation operators) that are proportional to
  the reward from the terminal state, which is defined as the exponent of the negative
  of the WNO loss on the validation dataset.
---

# Generative flow induced neural architecture search: Towards discovering optimal architecture in wavelet neural operator

## Quick Facts
- arXiv ID: 2405.06910
- Source URL: https://arxiv.org/abs/2405.06910
- Reference count: 36
- Primary result: Flow-based neural architecture search for wavelet neural operators achieves 0.17-1% error reduction across fluid mechanics problems

## Executive Summary
This paper introduces a generative flow-based neural architecture search algorithm specifically designed for wavelet neural operators (WNO). The method learns stochastic policies to sequentially generate architecture hyperparameters (wavelet basis and activation operators) based on validation loss rewards, without requiring complete episodic training like reinforcement learning approaches. The approach is demonstrated on four fluid mechanics problems including Burgers equation, Darcy flow, and Navier-Stokes equations, showing consistent improvements over vanilla WNO with error reductions ranging from 0.17% to over 1% in relative L2 error.

## Method Summary
The proposed method uses generative flows to learn a stochastic policy that generates sequences of architecture hyperparameters (wavelet basis and activation operators) for WNO. The policy is trained by minimizing flow violation between states and maximizing terminal reward, where the reward is defined as the exponent of the negative validation loss. This allows sequential hyperparameter generation without complete episodic training. The approach demonstrates zero-shot super-resolution capabilities and is evaluated on 1D Burgers equation, 2D Darcy flow (square and triangular domains), and 2D incompressible Navier-Stokes equations.

## Key Results
- FWNO reduces error on Burgers equation from 1.75% to 1.44% (0.31% improvement)
- FWNO reduces error on Darcy flow in square domain from 1.8% to 1.58% (0.22% improvement)
- FWNO reduces error on Navier-Stokes equations from 3.43% to 2.35% (1.08% improvement)
- Zero-shot super-resolution capabilities maintained accuracy at higher resolutions than training

## Why This Works (Mechanism)
The generative flow-based approach works by learning a stochastic policy that generates architecture hyperparameters sequentially based on validation loss rewards. The flow-based policy learning enables efficient exploration of the architecture space without requiring complete episodic training, making it more computationally efficient than reinforcement learning approaches. The method leverages the smoothness properties of flows to ensure stable policy updates and avoid mode collapse issues during training.

## Foundational Learning
- Neural operators: Learn mappings between infinite-dimensional function spaces, essential for solving PDEs efficiently without mesh dependence
  - Why needed: Traditional neural networks operate on finite-dimensional spaces, making them unsuitable for learning continuous operators
  - Quick check: Verify that the WNO architecture can approximate the target operator within desired accuracy bounds
- Generative flows: Invertible neural networks that transform between simple base distributions and complex target distributions
  - Why needed: Enable efficient sampling and density estimation for sequential hyperparameter generation
  - Quick check: Confirm that flow transformations are invertible and Jacobian determinants are computable
- Reinforcement learning vs flow-based methods: Flow-based approaches avoid the need for complete episodic training by learning policies that generate sequences directly
  - Why needed: Reduces computational overhead and enables more efficient architecture search
  - Quick check: Compare computational complexity and sample efficiency with RL-based approaches

## Architecture Onboarding

**Component map:**
Input space -> Wavelet basis selection -> Activation operator selection -> WNO architecture -> Validation loss -> Reward computation -> Flow policy update

**Critical path:**
Wavelet basis selection -> Activation operator selection -> WNO training -> Validation loss computation -> Reward propagation -> Policy update

**Design tradeoffs:**
- Flow-based vs RL-based policy learning: Flow methods offer computational efficiency but may have limited exploration capabilities
- Sequential vs parallel hyperparameter generation: Sequential generation enables conditional dependencies but may be slower
- Reward function design: Exponentiated negative validation loss provides smooth gradients but may not capture all performance aspects

**Failure signatures:**
- Policy collapse leading to repetitive architecture generation
- Insufficient exploration resulting in suboptimal architectures
- Flow instability causing training divergence or numerical issues

**First experiments:**
1. Verify flow invertibility and Jacobian determinant computation on simple test distributions
2. Test sequential hyperparameter generation on synthetic validation loss landscapes
3. Compare flow-based policy learning convergence with random search baseline

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions, but several areas require further investigation including the method's generalizability to other neural operator architectures, computational complexity characterization, and potential policy collapse issues during training.

## Limitations
- Assumes validation loss is sufficient objective function for architecture optimization across all problem domains
- Computational complexity of flow-based approach not fully characterized for varying problem scales
- Generalizability to neural operator architectures beyond WNO remains uncertain
- Lacks comprehensive ablation studies to quantify individual component contributions

## Confidence
**High confidence:** Basic methodology of using generative flows for sequential hyperparameter generation is sound and technically feasible
**Medium confidence:** Empirical improvements over vanilla WNO are valid but may not generalize to all problem types or architectures
**Low confidence:** Claims about zero-shot super-resolution capabilities and applicability to arbitrary neural operator architectures require additional validation

## Next Checks
1. Conduct extensive ablation studies to isolate the contribution of flow-based policy learning versus random search in achieving reported performance improvements
2. Test the approach on additional neural operator architectures (e.g., Fourier Neural Operators) to assess generalizability beyond WNO
3. Perform computational complexity analysis comparing the proposed method with alternative architecture search approaches (Bayesian optimization, reinforcement learning) across varying problem scales and dimensionalities