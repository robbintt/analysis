---
ver: rpa2
title: Multi-Level Additive Modeling for Structured Non-IID Federated Learning
arxiv_id: '2405.16472'
source_url: https://arxiv.org/abs/2405.16472
tags:
- level
- femam
- non-iid
- each
- multi-level
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of modeling non-IID (non-identically
  independently distributed) data across clients in federated learning. The authors
  propose a novel method called Multi-level Additive Modeling (MAM) that captures
  the fine-grained structure of non-IID distributions.
---

# Multi-Level Additive Modeling for Structured Non-IID Federated Learning

## Quick Facts
- arXiv ID: 2405.16472
- Source URL: https://arxiv.org/abs/2405.16472
- Reference count: 40
- Key outcome: Proposes FeMAM, a federated learning algorithm using multi-level additive modeling that outperforms existing methods on non-IID data

## Executive Summary
This paper addresses the challenge of modeling non-IID data distributions across clients in federated learning. The authors propose Multi-level Additive Modeling (MAM) that organizes models in a hierarchical structure where each client's prediction is a sum of outputs from models assigned across different levels. The method uses a global model at the top level, clustered models in middle levels, and client-specific models at the bottom level. An efficient federated learning algorithm FeMAM is developed to jointly learn this multi-level structure and shared models. Extensive experiments demonstrate significant improvements over existing clustered and personalized FL methods across various non-IID settings.

## Method Summary
FeMAM implements multi-level additive modeling by training a hierarchical structure of models in a federated setting. Each client's prediction combines outputs from multiple shared models across different levels. The algorithm starts with a global model and progressively adds new levels when convergence is achieved. At each level, clients are assigned to one model (global, clustered, or client-specific). After each level converges, a pruning step removes models that don't significantly improve validation loss. The training proceeds in a staircase pattern where levels are added incrementally and the model structure is optimized through adaptive convergence criteria and loss-based pruning.

## Key Results
- FeMAM outperforms FedAvg and other personalized FL methods on non-IID data
- Significant improvements in both accuracy and macro-F1 score across multiple datasets
- The multi-level structure effectively captures fine-grained non-IID distributions
- Adaptive convergence and pruning mechanisms optimize the knowledge-sharing structure

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Additive modeling enables knowledge sharing at multiple granularities without interference.
- Mechanism: Each client's prediction is a sum of outputs from models assigned to it across all levels, allowing fine-grained knowledge sharing.
- Core assumption: The additive structure can approximate arbitrary non-IID distributions across clients.
- Evidence anchors: [abstract] "In federated MAM (FeMAM), each client is assigned to at most one model per level and its personalized prediction sums up the outputs of models assigned to it across all levels." [section] "MAM embodies the model personalization f_i(x) for each client by adding outputs from multiple shared models from different levels."
- Break condition: If the additive structure cannot capture the true underlying data distribution, performance will degrade.

### Mechanism 2
- Claim: Progressive level adding enables adaptive convergence across different types of non-IID.
- Mechanism: FeMAM starts with a global model and incrementally adds new levels only when the current training stabilizes, allowing each client to stop joining the current level if the latest model achieves sufficiently small validation loss.
- Core assumption: The complexity of the underlying data distribution determines the number of levels needed for convergence.
- Evidence anchors: [abstract] "To approximate the arbitrary structure of non-IID across clients, FeMAM introduces more flexibility and adaptivity to FL by incrementally adding new models to the prediction of each client and reassigning another if necessary, automatically optimizing the knowledge-sharing structure." [section] "Levels are added progressively when the previous level converges, so the convergence curves are staircase-style."
- Break condition: If the convergence criterion is too strict or too loose, the algorithm may add unnecessary levels or miss important ones.

### Mechanism 3
- Claim: Model pruning with loss reduction orientation optimizes knowledge-sharing structure.
- Mechanism: After each level converges, FeMAM checks the validation loss on each client before and after adding the latest model, removing models that only marginally reduce the validation loss.
- Core assumption: Not all models at each level contribute equally to each client's performance.
- Evidence anchors: [section] "Models that only marginal reduce the validation loss by less than ϵ are removed" [section] "This straightforward strategy allows each client to select only beneficial models and results in distinct number models for each client."
- Break condition: If the threshold ϵ is set incorrectly, important models may be pruned or unnecessary models retained.

## Foundational Learning

- Concept: Federated Learning
  - Why needed here: The entire framework operates in a federated setting where clients have local data and a central server coordinates model training.
  - Quick check question: What is the main challenge that federated learning addresses compared to traditional centralized learning?

- Concept: Non-IID data distributions
  - Why needed here: The paper specifically addresses the challenge of modeling non-IID distributions across clients, which is a fundamental problem in federated learning.
  - Quick check question: How does non-IID data distribution differ from IID, and why does it matter for federated learning?

- Concept: Additive modeling
  - Why needed here: The core innovation uses additive modeling to combine multiple shared models into a single prediction for each client.
  - Quick check question: What is the advantage of using additive modeling over other ensemble methods in this federated learning context?

## Architecture Onboarding

- Component map: Server maintains multi-level model structure -> Clients keep previous levels' models and receive one model from latest level -> Local training with level-wise optimization -> Validation-based model pruning -> Progressive level adding based on convergence

- Critical path: 1. Initialize with global model (FedAvg) 2. Train until convergence 3. Add next level with clustered models 4. Train until convergence 5. Repeat until maximum level reached 6. Apply model pruning based on validation loss

- Design tradeoffs: More levels provide finer-grained knowledge sharing but increase communication and computation costs; Stricter pruning criteria reduce model complexity but may remove useful models; Slower progressive adding ensures stability but increases training time

- Failure signatures: Plateau in accuracy despite adding new levels; Increasing validation loss during training; Models becoming too similar across different levels; Communication overhead becoming prohibitive

- First 3 experiments: 1. Compare FeMAM with FedAvg on IID data to verify baseline performance 2. Test FeMAM on cluster-wise non-IID to verify clustered knowledge sharing 3. Evaluate FeMAM on client-wise non-IID to verify personalization capability

- Additional notes: The architecture is designed to be adaptive, with the number of levels and models per client varying based on the underlying data distribution structure.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical guarantee for the convergence of FeMAM under non-IID data settings with unknown structures?
- Basis in paper: [explicit] The paper provides convergence analysis for FeMAM, but focuses on the convergence of the clustering objective F and the FL objective R separately. It assumes specific conditions like unbiased gradient estimators and bounded gradients, which may not hold in real-world non-IID scenarios.
- Why unresolved: The convergence analysis relies on assumptions that might not be satisfied in practice, especially for complex non-IID structures. The paper does not provide a comprehensive convergence proof for FeMAM under all possible non-IID scenarios.
- What evidence would resolve it: A rigorous theoretical analysis that establishes the convergence of FeMAM under a wider range of non-IID data distributions and relaxes the assumptions made in the current analysis.

### Open Question 2
- Question: How does the performance of FeMAM scale with the number of clients and the complexity of the non-IID structure?
- Basis in paper: [inferred] The paper demonstrates the effectiveness of FeMAM on various non-IID settings, but the experiments are limited to a specific number of clients and non-IID structures. The scalability of FeMAM to larger client populations and more complex non-IID scenarios is not explored.
- Why unresolved: The paper does not provide a systematic study on how the performance of FeMAM is affected by the number of clients and the complexity of the non-IID structure. This information is crucial for understanding the practical applicability of FeMAM in real-world federated learning systems.
- What evidence would resolve it: Extensive experiments that evaluate the performance of FeMAM on federated learning systems with varying numbers of clients and diverse non-IID structures, along with a theoretical analysis of the scalability of the algorithm.

### Open Question 3
- Question: How does FeMAM handle dynamic changes in the non-IID structure over time?
- Basis in paper: [inferred] The paper assumes a static non-IID structure and does not address the scenario where the non-IID structure evolves over time. In real-world federated learning systems, the data distribution across clients can change due to various factors, such as user behavior changes or concept drift.
- Why unresolved: The current FeMAM algorithm is designed for a fixed non-IID structure and does not have mechanisms to adapt to dynamic changes. This limitation can lead to performance degradation when the non-IID structure evolves.
- What evidence would resolve it: An extension of FeMAM that incorporates mechanisms to detect and adapt to changes in the non-IID structure over time, along with experimental results demonstrating the effectiveness of the adapted algorithm in dynamic federated learning scenarios.

## Limitations

- Empirical validation scope is limited to computer vision datasets (Tiny ImageNet, CIFAR-100)
- Communication overhead may be significant due to progressive level-adding mechanism
- Hyperparameter sensitivity, particularly pruning threshold ϵ and level-adding criteria, may require careful tuning

## Confidence

Our confidence in the core claims is **Medium**.

## Next Checks

1. **Ablation study on level structure**: Remove the mid-level clustered models and evaluate whether FeMAM still outperforms FedAvg, isolating the contribution of each level.

2. **Cross-dataset generalization**: Apply FeMAM to non-vision datasets (e.g., text classification on Shakespeare or Stack Overflow) to assess its generalizability across different data types.

3. **Communication cost analysis**: Measure the actual communication rounds and model parameters transmitted during training compared to baseline methods to quantify the practical overhead of the multi-level approach.