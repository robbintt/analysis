---
ver: rpa2
title: 'KNOWCOMP POKEMON Team at DialAM-2024: A Two-Stage Pipeline for Detecting Relations
  in Dialogical Argument Mining'
arxiv_id: '2407.19740'
source_url: https://arxiv.org/abs/2407.19740
tags:
- data
- argument
- mining
- relations
- stage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses dialogical argument mining (DialAM) by proposing
  a two-stage pipeline to detect argumentative and illocutionary relations in dialogues.
  The method employs a two-step S-node prediction model for argumentative relations
  and a YA-node prediction model for illocutionary relations, both enhanced with data
  augmentation.
---

# KNOWCOMP POKEMON Team at DialAM-2024: A Two-Stage Pipeline for Detecting Relations in Dialogical Argument Mining

## Quick Facts
- arXiv ID: 2407.19740
- Source URL: https://arxiv.org/abs/2407.19740
- Reference count: 17
- Key outcome: Achieved 1st place in ARI Focused score and 4th place in Global Focused score in DialAM-2024

## Executive Summary
This paper presents a two-stage pipeline for detecting argumentative and illocutionary relations in dialogical argument mining (DialAM). The pipeline employs a two-step S-node prediction model for argumentative relations and a YA-node prediction model for illocutionary relations, both enhanced with data augmentation techniques. The method achieved first place in the ARI Focused score and fourth place in the Global Focused score at the DialAM-2024 shared task, demonstrating effective performance in relation detection tasks.

## Method Summary
The proposed two-stage pipeline addresses the challenge of detecting relations in dialogical argument mining. Stage 1 employs a two-step S-node prediction model that first determines whether a relation exists between nodes using binary classification, then classifies the relation type (RA, CA, or MA) using ternary classification. Stage 2 utilizes a YA-node prediction model that incorporates contextual information to predict illocutionary relations. Both stages leverage data augmentation strategies to improve model performance and handle data imbalances. The pipeline uses DeBERTa-base and DeBERTa-large models for different classification tasks, with learning rate 1e-5, weight decay 0.01, and fp16 training enabled.

## Key Results
- Achieved 1st place in ARI Focused score with 0.5653 F1-score
- Achieved 4th place in Global Focused score with 0.3732 F1-score
- Demonstrated effective performance in detecting both argumentative and illocutionary relations

## Why This Works (Mechanism)
The two-stage pipeline works by first establishing the existence of relations through binary classification, then determining the specific relation type. This approach reduces the complexity of the classification task by breaking it into more manageable subtasks. The incorporation of contextual information in Stage 2 allows the model to consider the broader dialogue context when predicting illocutionary relations, which are more nuanced and dependent on surrounding discourse. Data augmentation techniques help address class imbalance issues and improve the model's ability to generalize to unseen data.

## Foundational Learning
- **DeBERTa model architecture**: DeBERTa (Decoding-enhanced BERT with disentangled attention) provides enhanced representation capabilities compared to BERT, particularly useful for relation classification tasks where understanding context is crucial.
- **Binary vs. ternary classification**: The two-step approach uses binary classification to determine relation existence first, then ternary classification to identify the specific relation type, simplifying the learning task.
- **Context incorporation**: Including contextual information from surrounding dialogue nodes helps the model better understand the nuanced meanings of illocutionary relations.
- **Data augmentation techniques**: Adding negative samples and manipulating existing data helps address class imbalance and improves model robustness.
- **Argumentative relation types (RA, CA, MA)**: Understanding the distinction between Request-Argument, Challenge-Argument, and Maintain-Argument relations is essential for accurate classification.
- **Illocutionary relation categories**: The 11 types of illocutionary relations require different modeling approaches due to their complexity and dependence on context.

## Architecture Onboarding

**Component Map**: QT30 Corpus -> Data Preprocessing -> Stage 1 (Two-Step S-node Prediction) -> Stage 2 (YA-node Prediction) -> Relation Detection

**Critical Path**: Data preprocessing -> Two-Step S-node Prediction (binary classification -> ternary classification) -> YA-node Prediction with context -> Final relation detection

**Design Tradeoffs**: The two-step approach trades computational complexity for improved accuracy by breaking down the classification task, while context incorporation adds model complexity but improves nuanced relation detection.

**Failure Signatures**: Poor performance on ILO task indicates inadequate context modeling; low precision on rare relation types suggests insufficient data augmentation or class imbalance issues.

**First Experiments**:
1. Implement binary classification component of Stage 1 and evaluate relation existence detection
2. Test ternary classification component of Stage 1 with RA, CA, and MA relation types
3. Implement YA-node prediction model with basic context incorporation and evaluate ILO detection

## Open Questions the Paper Calls Out
### Open Question 1
How does the performance of the two-step S-node prediction model compare to a single multi-classification model in terms of both general and focused metrics?
- **Basis in paper**: The paper mentions that a two-step model was compared to a four-label direct classification model, with the two-step model showing better general scores at the expense of focused scores.
- **Why unresolved**: The paper does not provide a detailed comparison of the two-step model's performance against a single multi-classification model across all metrics.
- **What evidence would resolve it**: A comprehensive comparison of the two-step model's performance against a single multi-classification model, including all relevant metrics such as precision, recall, and F1-score for both general and focused tasks.

### Open Question 2
What is the impact of incorporating additional contextual information in the YA-node prediction model on its performance?
- **Basis in paper**: The paper mentions that context is introduced in the YA-node prediction model to consider two L-nodes connected by TA-nodes and two or more I-nodes connected by S-nodes.
- **Why unresolved**: The paper does not provide specific results or analysis on how the inclusion of additional contextual information affects the model's performance.
- **What evidence would resolve it**: Detailed performance metrics of the YA-node prediction model with and without the incorporation of additional contextual information, highlighting any improvements or trade-offs.

### Open Question 3
How does the data augmentation technique used in the pipeline affect the model's ability to generalize to unseen data?
- **Basis in paper**: The paper describes the use of data augmentation techniques, such as adding data that does not fit any relation in the relation set, to improve the performance of fine-tuned models.
- **Why unresolved**: The paper does not provide specific analysis or results on how the data augmentation technique impacts the model's generalization to unseen data.
- **What evidence would resolve it**: Results from experiments comparing the model's performance on unseen data with and without the data augmentation technique, demonstrating any improvements in generalization.

## Limitations
- Lack of detailed implementation specifications for context incorporation mechanism in Stage 2
- Unspecified data augmentation strategy for YA-node prediction model
- Limited generalizability due to reliance on specific QT30 corpus and model architectures

## Confidence
- **Claim**: Pipeline achieved first place in ARI Focused score - **Label**: High
- **Claim**: Two-step approach improves general scores compared to single classification - **Label**: Medium
- **Claim**: Context incorporation improves ILO detection - **Label**: Low (due to unspecified implementation details)

## Next Checks
1. Implement and test the context incorporation mechanism as described in the paper to verify its effectiveness in improving relation detection
2. Conduct a sensitivity analysis on the data augmentation strategy to determine its impact on model performance and potential biases
3. Perform cross-dataset validation by applying the trained models to different argumentative dialogue datasets to assess generalizability