---
ver: rpa2
title: Do We Really Need to Drop Items with Missing Modalities in Multimodal Recommendation?
arxiv_id: '2408.11767'
source_url: https://arxiv.org/abs/2408.11767
tags:
- multimodal
- missing
- recommendation
- items
- modalities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of missing multimodal data in
  recommendation systems, where items often lack visual or textual information. The
  authors challenge the common practice of dropping items with missing modalities,
  showing it is not only unnecessary but also harmful to recommendation performance.
---

# Do We Really Need to Drop Items with Missing Modalities in Multimodal Recommendation?

## Quick Facts
- arXiv ID: 2408.11767
- Source URL: https://arxiv.org/abs/2408.11767
- Reference count: 40
- One-line primary result: Graph-aware imputation of missing multimodal features consistently improves recommendation performance compared to dropping items with missing modalities.

## Executive Summary
This paper challenges the common practice of dropping items with missing visual or textual data in multimodal recommendation systems. The authors demonstrate that imputing missing modalities using traditional machine learning and novel graph-aware methods not only preserves valuable user-item interactions but also significantly improves the performance gap between multimodal and pure collaborative filtering models. Their proposed methods leverage the item-item co-purchase graph and multimodal similarities of co-interacted items, showing consistent improvements across three Amazon Review datasets.

## Method Summary
The authors propose a pre-processing pipeline for imputing missing multimodal features in recommendation systems. They compare traditional imputation methods (Zeros, Random, GlobalMean, NeighMean) with graph-aware approaches (MultiHop, PersPageRand) that propagate features over the item-item co-purchase graph. The graph-aware methods use multiple hops and personalized PageRank normalization to impute missing features from co-interacted items. The imputed data is then used to train both collaborative filtering and multimodal recommendation models, with performance evaluated using Recall@20 and nDCG@20 metrics.

## Key Results
- Imputing missing modalities instead of dropping items consistently improves multimodal recommendation performance across all tested datasets.
- Graph-aware imputation methods (MultiHop and PersPageRand) outperform traditional imputation methods.
- High top-k sparsification and multiple propagation hops yield the best performance in graph-aware methods.
- The improvement is particularly notable for items with both visual and textual features missing.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph-aware imputation improves multimodal recommendation by leveraging the structure of the user-item interaction graph to propagate multimodal features from co-interacted items.
- Mechanism: The method builds an item-item co-purchase graph where edges represent shared interactions. Missing multimodal features are imputed by propagating features from neighboring items over multiple hops, using either simple mean aggregation or more advanced diffusion-based methods like personalized PageRank.
- Core assumption: Items co-interacted by users share semantically similar multimodal features, making them reliable sources for imputation.
- Evidence anchors:
  - [abstract] "we propose three more effective imputation solutions that leverage the item-item co-purchase graph and the multimodal similarities of co-interacted items"
  - [section 2.2] "we propose to frame the imputation of missing modalities in multimodal recommendation as a process involving the propagation of nodes multimodal features over the item-item graph"
  - [corpus] Weak - corpus papers focus on missing modality imputation in general but do not directly support the specific graph-aware approach proposed here.
- Break condition: If co-interacted items do not share similar multimodal features (e.g., in sparse graphs or niche domains), the imputation quality degrades.

### Mechanism 2
- Claim: Imputing missing modalities instead of dropping items preserves more user-item interactions and improves the performance gap between multimodal and pure collaborative filtering models.
- Mechanism: By imputing rather than dropping, the system retains all user-item interactions, including those involving items with missing modalities. This richer interaction graph allows multimodal models to outperform their CF counterparts more consistently.
- Core assumption: Retaining interactions with items having imputed features is more beneficial than losing those interactions entirely.
- Evidence anchors:
  - [abstract] "showing that any data pre-filtering is not only unnecessary but also harmful to the performance"
  - [section 3.2] "the imputed setting consistently shows an improvement from CF to multimodal RSs"
  - [corpus] Weak - related works address missing modalities but do not explicitly validate the harm of dropping items as shown here.
- Break condition: If imputed features are of very low quality, they may introduce noise that outweighs the benefit of retaining interactions.

### Mechanism 3
- Claim: Multi-hop feature propagation and personalized PageRank normalization in the item-item graph lead to better imputation quality than single-hop or non-diffusion methods.
- Mechanism: The MultiHop method iteratively propagates features across multiple hops in the item-item graph, while PersPageRank incorporates personalized PageRank normalization to account for varying node degrees and improve smoothing.
- Core assumption: Multiple hops and diffusion-based normalization capture broader and more reliable semantic relationships than local neighborhoods alone.
- Evidence anchors:
  - [section 2.2] "we propose a third graph-aware imputation that modifies the MultiHop strategy by incorporating personalized PageRank"
  - [section 3.2] "MultiHop and PersPageRand steadily settle as the superior solutions"
  - [corpus] Weak - while graph diffusion is known in GNN literature, its specific application to multimodal imputation is not directly evidenced in the corpus.
- Break condition: If the graph is too sparse or noisy, multi-hop propagation may amplify errors rather than recover meaningful features.

## Foundational Learning

- Concept: Graph neural networks and message passing
  - Why needed here: The imputation methods rely on propagating multimodal features over the user-item interaction graph using techniques inspired by GNNs.
  - Quick check question: How does feature propagation in GNNs differ from simple averaging over neighbors?

- Concept: Collaborative filtering and implicit feedback
  - Why needed here: The system builds on CF principles, using user-item interactions as the base signal enhanced by multimodal features.
  - Quick check question: What is the difference between explicit and implicit feedback in recommendation?

- Concept: Missing data imputation in machine learning
  - Why needed here: The work adapts classical imputation strategies (mean, random, zeros) and extends them with graph-aware methods.
  - Quick check question: What are the trade-offs between simple imputation methods and model-based imputation?

## Architecture Onboarding

- Component map:
  Data preprocessing -> Multimodal feature extraction -> Missing modality detection -> Imputation -> Model training -> Evaluation

- Critical path:
  User-item interaction data → Multimodal feature extraction → Missing modality detection → Imputation → Model training → Evaluation

- Design tradeoffs:
  - Dropping vs. imputing: Dropping preserves data quality but loses interactions; imputing retains interactions but risks noise.
  - Imputation method choice: Simple methods are fast but less effective; graph-aware methods are more effective but computationally heavier.
  - Graph construction: Top-k sparsification reduces noise but may lose rare but meaningful connections.

- Failure signatures:
  - Imputation quality drops when the item-item graph is too sparse or disconnected.
  - Model performance degrades if imputed features are dominated by noise.
  - High variance in results across datasets suggests sensitivity to domain characteristics.

- First 3 experiments:
  1. Run BPRMF and VBPR on dropped vs. imputed datasets to confirm the performance gap improvement.
  2. Compare Zeros, Random, GlobalMean vs. NeighMean, MultiHop, PersPageRank on a small dataset.
  3. Sweep top-k sparsification and propagation hops for PersPageRank on Beauty dataset to find optimal hyperparameters.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of graph-aware imputation methods vary across different types of missing modality patterns (e.g., single modality missing vs. both modalities missing)?
- Basis in paper: [explicit] The paper discusses the problem of missing modalities in multimodal recommendation and proposes graph-aware imputation methods, but does not explicitly analyze performance variations across different missing modality patterns.
- Why unresolved: The paper focuses on the overall effectiveness of imputation methods but does not provide a detailed analysis of how different missing modality patterns affect performance.
- What evidence would resolve it: Experimental results comparing the performance of graph-aware imputation methods across datasets with different missing modality patterns (e.g., some items missing only visual features, others missing only textual features, and some missing both).

### Open Question 2
- Question: What is the impact of incorporating end-to-end learning with the proposed imputation methods on recommendation performance?
- Basis in paper: [inferred] The paper proposes an untrained pre-processing pipeline for imputing missing modalities, suggesting that future work could integrate these methods end-to-end into the recommendation pipeline.
- Why unresolved: The current approach treats imputation as a separate pre-processing step, and the potential benefits of integrating it end-to-end with the recommendation model are not explored.
- What evidence would resolve it: Comparative experiments evaluating the performance of recommendation models that incorporate imputation methods end-to-end versus those using pre-processing imputation.

### Open Question 3
- Question: How do the proposed graph-aware imputation methods perform on datasets with different graph structures or densities?
- Basis in paper: [explicit] The paper leverages the item-item co-purchase graph for imputation but does not explore how different graph structures or densities affect performance.
- Why unresolved: The experiments are conducted on specific datasets, and the generalizability of the graph-aware methods to different graph structures is not assessed.
- What evidence would resolve it: Experiments on diverse datasets with varying graph structures and densities to evaluate the robustness and adaptability of the graph-aware imputation methods.

## Limitations

- The effectiveness of graph-aware imputation is sensitive to graph density and quality, which are not fully characterized.
- The paper assumes multimodal features can be meaningfully propagated, but this may not hold in domains with sparse or noisy co-interactions.
- The core empirical findings rely on Amazon review datasets where co-purchase patterns may not generalize to other domains.

## Confidence

- Multimodal imputation outperforms dropping items (High): Directly supported by experiments across three datasets.
- Graph-aware methods improve over simple imputation (Medium): Results show consistent gains but with some variability across datasets.
- Multi-hop and personalized PageRank normalization are optimal (Medium): Performance is best on average, but not universally across all settings.

## Next Checks

1. Evaluate the imputation methods on a dataset with a different interaction structure (e.g., explicit ratings or sequential interactions) to test generalizability.
2. Perform ablation studies to isolate the contribution of graph structure vs. feature quality in the imputation process.
3. Test the robustness of the imputation methods under varying levels of missingness (e.g., 50%, 75%, 90% missing modalities) to assess scalability.