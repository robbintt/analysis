---
ver: rpa2
title: Dual adversarial and contrastive network for single-source domain generalization
  in fault diagnosis
arxiv_id: '2407.13978'
source_url: https://arxiv.org/abs/2407.13978
tags:
- fault
- features
- process
- diagnosis
- mode
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses single-source domain generalization for multi-mode
  fault diagnosis in process industrial systems. The key challenge is extracting domain-invariant
  fault features from single-mode data to accurately diagnose faults in unseen modes,
  given the complexity of spatiotemporal information in multi-mode samples.
---

# Dual adversarial and contrastive network for single-source domain generalization in fault diagnosis

## Quick Facts
- arXiv ID: 2407.13978
- Source URL: https://arxiv.org/abs/2407.13978
- Reference count: 40
- Primary result: DACN achieves high classification accuracy on unseen modes for multi-mode fault diagnosis using only single-mode data

## Executive Summary
This paper addresses the challenge of fault diagnosis in process industrial systems across multiple operating modes using only data from a single mode. The key innovation is a Dual Adversarial and Contrastive Network (DACN) that generates diverse pseudo-fault features through an adversarial approach and extracts domain-invariant feature representations using combined contrastive and adversarial learning. Experiments on the Tennessee Eastman process and continuous stirred-tank reactor demonstrate that DACN achieves high classification accuracy on unseen modes while maintaining a small model size, effectively solving the single-source domain generalization problem in multi-mode fault diagnosis.

## Method Summary
DACN employs a two-stage training process: pre-training and adversarial training. During pre-training, the model learns fault features from single-mode data using cross-entropy loss. In the adversarial training stage, an AdaIN feature transformer generates pseudo-fault features by adjusting the magnitude and noise characteristics of single-mode fault features. These pseudo-features are then processed through a domain-invariant feature extractor that combines supervised contrastive learning (to group samples of the same fault class) and adversarial learning (to remove domain-specific variations). The model is trained with a combined loss function that balances classification accuracy, domain invariance, and feature diversity, optimized through Bayesian methods.

## Key Results
- DACN achieves high classification accuracy on unseen modes while maintaining small model size
- The method effectively handles the complexity of spatiotemporal information in multi-mode samples
- Experimental validation on both Tennessee Eastman process and continuous stirred-tank reactor demonstrates robust performance across different industrial systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The model generates pseudo-fault features that are both diverse and semantically consistent, avoiding the pitfalls of directly generating unseen mode samples.
- Mechanism: The AdaIN feature transformer simulates unseen mode fault features by adjusting the magnitude and noise characteristics of single-mode fault features. The dual adversarial training strategy—where the AdaIN feature transformer minimizes the discriminative loss while the domain-invariant feature extractor maximizes it—ensures that the generated features differ significantly in domain-specific aspects but remain consistent in fault semantics.
- Core assumption: Mode features can be represented by the mean and variance of the fault-free data, and fault features can be decomposed into domain-invariant and domain-specific components.
- Evidence anchors:
  - [abstract]: "An adversarial pseudo-sample feature generation strategy is developed to create fake unseen mode sample features with sufficient semantic information and diversity..."
  - [section]: "AdaIN feature transformer H generates pseudo-fault features f'i based on the single seen mode fault features fi. f'i = H ( fi, n1, n2) = h1 (n1) (fi − µi)/σi + h2 (n2), where n1 is randomly sampled from a uniform distribution between 0.05 and 1.95, n2 is randomly sampled from standard Gaussian distribution..."
  - [corpus]: No direct evidence in corpus; this is a novel method not discussed in neighbor papers.
- Break condition: If the decomposition into domain-invariant and domain-specific features is not valid for the target industrial process, or if the mode features cannot be adequately removed by standardization, the pseudo-fault features may not capture the necessary diversity.

### Mechanism 2
- Claim: Domain-invariant fault features are extracted by combining supervised contrastive learning and adversarial learning, allowing the model to generalize across modes.
- Mechanism: Supervised contrastive learning pulls samples of the same fault class closer in the embedding space, while adversarial learning between the domain-invariant feature extractor and the discriminator removes domain-specific variations. This combination ensures that the model focuses on features that are consistent across modes.
- Core assumption: The fault classes are the same across all modes, and the differences between modes are primarily in domain-specific features rather than fault semantics.
- Evidence anchors:
  - [abstract]: "An enhanced domain-invariant feature extraction strategy is designed to capture common feature representations across multi-modes, utilizing contrastive learning and adversarial learning..."
  - [section]: "Supervised contrastive loss is defined as... Domain-invariant fault features may not be effectively extracted using only supervised contrastive learning, especially between samples with significant domain differences. Therefore, adversarial learning is introduced..."
  - [corpus]: No direct evidence in corpus; this combination of methods is specific to this paper.
- Break condition: If the supervised contrastive learning is unable to effectively group samples of the same class due to high intra-class variability, or if the adversarial training fails to remove domain-specific features, the extracted features may not be truly domain-invariant.

### Mechanism 3
- Claim: Pre-training on single-mode data provides a foundation for generating valid pseudo-fault features, improving the overall model performance.
- Mechanism: The pre-training process allows the model to learn the fault features of the single seen mode before attempting to generate pseudo-fault features. This ensures that the generated features are grounded in the actual fault knowledge of the system.
- Core assumption: The single seen mode data contains sufficient information about the fault features to be generalized to other modes.
- Evidence anchors:
  - [abstract]: "The main idea of DACN is to generate diverse sample features and extract domain-invariant feature representations."
  - [section]: "The pre-training process enables the DGRN model to learn single seen mode fault features in advance, facilitating the generation of more effective pseudo-fault features during later training process."
  - [corpus]: No direct evidence in corpus; pre-training is a common practice but its specific application here is novel.
- Break condition: If the single seen mode data is not representative of the fault features present in other modes, the pre-training may lead to biased or insufficient pseudo-fault features.

## Foundational Learning

- Concept: Domain Generalization
  - Why needed here: The paper aims to diagnose faults in unseen operating modes using only data from a single mode. Domain generalization techniques are essential to learn features that are invariant across different modes.
  - Quick check question: Can you explain the difference between domain adaptation and domain generalization in the context of fault diagnosis?

- Concept: Adversarial Learning
  - Why needed here: Adversarial learning is used to remove domain-specific features from the extracted fault features, ensuring that the model focuses on domain-invariant characteristics.
  - Quick check question: How does the gradient reversal layer (GRL) facilitate adversarial learning in this model?

- Concept: Contrastive Learning
  - Why needed here: Contrastive learning is employed to bring samples of the same fault class closer in the embedding space, improving the model's ability to distinguish between different fault classes across modes.
  - Quick check question: What is the role of the temperature parameter τ in the supervised contrastive loss function?

## Architecture Onboarding

- Component map:
  - Data Processing -> Feature Extractor (F) -> AdaIN Feature Transformer (H) -> Domain-Invariant Feature Extractor (G) -> Classifier (C) -> Discriminator (D)

- Critical path:
  1. Data processing (standardization and time series expansion)
  2. Feature extraction (F)
  3. Pseudo-fault feature generation (H)
  4. Domain-invariant feature extraction (G)
  5. Classification (C)

- Design tradeoffs:
  - Generating pseudo-fault features instead of unseen mode samples avoids the complexity of direct sample generation but relies on the assumption that fault features can be decomposed into domain-invariant and domain-specific components.
  - Combining supervised contrastive learning and adversarial learning enhances domain-invariant feature extraction but increases model complexity.
  - Pre-training on single-mode data provides a foundation for pseudo-fault feature generation but may introduce bias if the single mode is not representative.

- Failure signatures:
  - High accuracy on the single seen mode but poor performance on unseen modes indicates a failure to extract domain-invariant features.
  - Low diversity in pseudo-fault features suggests that the AdaIN feature transformer is not effectively simulating unseen mode variations.
  - High intra-class variability in the embedding space indicates that the supervised contrastive learning is not effectively grouping samples of the same class.

- First 3 experiments:
  1. Train the model on the single seen mode and evaluate its performance on the same mode to ensure basic functionality.
  2. Generate pseudo-fault features and evaluate their diversity and semantic consistency using visualization techniques (e.g., t-SNE).
  3. Evaluate the model's performance on unseen modes and compare it to baseline methods to assess the effectiveness of the domain-invariant feature extraction strategy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would DGRN perform on multi-source domain generalization scenarios where fault data is available from multiple modes rather than a single mode?
- Basis in paper: [inferred] The paper focuses on single-source domain generalization and compares DGRN to other methods that also assume single-source scenarios. However, the methodology could theoretically be extended to multiple sources.
- Why unresolved: The paper does not experiment with or discuss multi-source domain generalization, leaving open the question of whether the approach would maintain its effectiveness when multiple source modes are available.
- What evidence would resolve it: Experimental results comparing DGRN's performance on multi-source domain generalization tasks against both single-source approaches and traditional multi-source methods would provide clarity.

### Open Question 2
- Question: How sensitive is DGRN's performance to the choice of hyperparameters (λ1, λ2, λ3) in the loss function, and is there an optimal way to set these values?
- Basis in paper: [explicit] The paper mentions that hyperparameters are obtained through Bayesian optimization but does not discuss the sensitivity of performance to these values or provide guidance on optimal selection.
- Why unresolved: While the paper demonstrates good performance with optimized hyperparameters, it does not explore how robust this performance is to hyperparameter variations or provide a systematic approach for setting these values in different scenarios.
- What evidence would resolve it: A sensitivity analysis showing DGRN's performance across different hyperparameter settings, along with recommendations for hyperparameter selection based on problem characteristics, would address this question.

### Open Question 3
- Question: How does DGRN handle the presence of unknown faults in unseen modes, and what is its performance in such scenarios?
- Basis in paper: [inferred] The paper focuses on known fault classes and does not discuss or test DGRN's ability to handle unknown or novel fault types that may appear in unseen modes.
- Why unresolved: Real-world industrial systems may encounter previously unseen fault types, but the paper does not address this scenario or evaluate DGRN's robustness to such situations.
- What evidence would resolve it: Experimental results testing DGRN's performance on datasets containing unknown fault classes in unseen modes, along with analysis of its ability to detect and handle such cases, would provide answers.

## Limitations

- The effectiveness of the AdaIN feature transformer depends heavily on the validity of decomposing fault features into domain-invariant and domain-specific components, which may not hold for all industrial processes
- The model assumes fault classes remain consistent across modes, potentially limiting applicability in scenarios where operating conditions significantly alter fault manifestations
- The pre-training approach may introduce bias if the single seen mode is not representative of other modes, affecting pseudo-fault feature quality

## Confidence

- Mechanism 1 (Pseudo-fault generation): Medium - The approach is novel and theoretically sound, but effectiveness depends on assumptions about feature decomposition that may not universally apply
- Mechanism 2 (Domain-invariant extraction): High - The combination of contrastive and adversarial learning is well-established, though specific implementation details are novel
- Mechanism 3 (Pre-training): Medium - Standard practice in deep learning, but its specific application here introduces mode representation assumptions

## Next Checks

1. Conduct ablation studies to determine the individual contribution of supervised contrastive learning versus adversarial learning to domain generalization performance
2. Test the model's robustness by evaluating performance across different numbers of training modes to understand scalability limits
3. Analyze the diversity of generated pseudo-fault features using quantitative metrics beyond accuracy to ensure semantic preservation