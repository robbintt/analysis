---
ver: rpa2
title: Tackling Selfish Clients in Federated Learning
arxiv_id: '2407.15402'
source_url: https://arxiv.org/abs/2407.15402
tags:
- clients
- selfish
- client
- update
- global
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the novel problem of selfish clients in federated
  learning, where clients deliberately manipulate their model updates to prioritize
  their local data distribution over the global model's performance. The authors propose
  RFL-Self, a robust aggregation strategy that identifies and recovers true updates
  from selfish clients by leveraging robust statistics and convex combinations.
---

# Tackling Selfish Clients in Federated Learning

## Quick Facts
- arXiv ID: 2407.15402
- Source URL: https://arxiv.org/abs/2407.15402
- Authors: Andrea Augello; Ashish Gupta; Giuseppe Lo Re; Sajal K. Das
- Reference count: 40
- Key outcome: RFL-Self effectively mitigates selfish clients in FL by detecting and recovering their updates, maintaining high accuracy for normal clients while preventing selfish clients from gaining unfair advantages.

## Executive Summary
This paper introduces the novel problem of selfish clients in federated learning, where clients deliberately manipulate their model updates to prioritize their local data distribution over the global model's performance. The authors propose RFL-Self, a robust aggregation strategy that identifies and recovers true updates from selfish clients by leveraging robust statistics and convex combinations. Experimental results on MNIST and CIFAR-10 datasets demonstrate that RFL-Self effectively mitigates the negative impact of selfish clients, maintaining high accuracy for normal clients while preventing selfish clients from gaining unfair advantages. The method outperforms standard strategies like median and downscaling, especially in non-IID settings with up to 20% selfish clients.

## Method Summary
The paper addresses the problem of selfish clients in federated learning by proposing RFL-Self, a robust aggregation strategy. The method operates in two main phases: detection and recovery. First, the server computes the L2 norm of each client's update and compares it to the median norm. Updates with norms significantly larger than the median are suspected to be selfish. For each suspected update, the server recovers an estimate of the true update by computing a convex combination of the received update and the median update, ensuring the recovered update has the same norm as the median. This recovered update is then used in the aggregation process. The method is evaluated on MNIST and CIFAR-10 datasets with non-IID data partitioning, comparing RFL-Self against baseline strategies like median and downscaling aggregation.

## Key Results
- RFL-Self maintains high accuracy for normal clients even with up to 20% selfish clients
- Selfish clients gain minimal advantage from their manipulation under RFL-Self
- RFL-Self outperforms median and downscaling baselines, especially in non-IID settings
- Recovery error is bounded and independent of the number of selfish clients as long as they are insufficient to induce substantial bias into the median

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Selfish clients craft updates that are larger in magnitude than true updates, enabling detection via median-based norm comparison.
- Mechanism: A selfish client modifies its update according to Eq. (4) to increase its influence on the global model. The norm of this modified update is guaranteed to exceed the median norm of all updates.
- Core assumption: The true update δs is similar in magnitude to the average update of normal clients δ[k]\{s}.
- Evidence anchors:
  - [abstract] RFL-Self incorporates an innovative method to recover (or estimate) the true updates of selfish clients from the received ones, leveraging robust statistics (median of norms) of the updates at every round.
  - [section 3.2.1] RFL-Self first computes the L2 norm of each update and finds a median norm Nmed. Since a selfish client aims to increase its influence on the global model to deviate the training toward its local model, it is obvious that selfish updates are larger in magnitude than those from other clients.
- Break condition: If the assumption that δs is similar in magnitude to δ[k]\{s} fails, then the norm-based detection may fail, leading to false negatives or positives.

### Mechanism 2
- Claim: RFL-Self recovers true updates of selfish clients by convexly combining the received update with the median update.
- Mechanism: For each suspected selfish client, the server computes a convex combination δ′s = βˆδs + (1 − β)δmed such that ||δ′s|| = Nmed. This scales down and rotates the selfish update toward the median update.
- Core assumption: The median update δmed is a good estimator of the mean update of all but the selfish clients.
- Evidence anchors:
  - [section 3.2.2] RFL-Self uses the received selfish updates ˆδs to compute an estimate δ′s of the true update δs and uses the estimate in the aggregation process.
  - [section 3.2.4] If the first two conditions hold, then ¯δ[k]\{s} ≃ δmed and from Eqs. (4) and (5) we get δ′s ≃ βαkδs + (1 − βαk)¯δ[k]\{s}.
- Break condition: If the median update is not representative of the normal clients' updates (e.g., due to high variance or skew), the recovery will be inaccurate.

### Mechanism 3
- Claim: The recovery error in RFL-Self is bounded and independent of the number of selfish clients as long as they are insufficient to induce substantial bias into the median.
- Mechanism: Theorem 2 provides an upper bound on the expected error in the recovered aggregated update: E||δ[k] − δ′[k]||2 ≤ 4+k/4k Tr(var(δ)).
- Core assumption: The number of selfish clients is less than half of the total clients, so the median remains representative.
- Evidence anchors:
  - [section 3.2.4] Theorem 2. The maximum error in the recovered aggregated update is bounded by 4+k/4k Tr(var(δ)).
  - [section 3.2.4] According to Theorem 2, the error does not depend on the number of selfish clients as long as they are insufficient to induce substantial bias into the median.
- Break condition: If more than half of the clients are selfish, the median will be biased toward selfish updates, invalidating the bound and recovery.

## Foundational Learning

- Concept: Federated Learning (FL) basics and non-IID data settings
  - Why needed here: The paper's entire context is built on FL, and the problem of selfish clients is most pronounced in non-IID settings where local optima differ.
  - Quick check question: In FL, how does the server aggregate updates from clients, and why is non-IID data a challenge?

- Concept: Robust statistics (median, trimmed mean) and their use in adversarial ML
  - Why needed here: RFL-Self leverages robust statistics to detect and mitigate selfish clients, similar to how they are used against Byzantine attacks.
  - Quick check question: Why is the median more robust to outliers than the mean in aggregation?

- Concept: Convex combinations and their geometric interpretation
  - Why needed here: The recovery mechanism uses a convex combination to project the selfish update toward the median, ensuring the recovered update has the median norm.
  - Quick check question: What geometric transformation does a convex combination of two vectors represent?

## Architecture Onboarding

- Component map:
  - Client side: Local training, selfish update computation (Eq. 4), sending updates to server
  - Server side: Aggregation loop, norm computation, median finding, selfish client detection, update recovery (Eq. 5), robust aggregation (Eq. 7)
  - Key data structures: List of client updates, list of update norms, set of suspected selfish clients

- Critical path:
  1. Server receives updates from all clients
  2. Compute norms and find median norm Nmed
  3. Compute marginal median update δmed
  4. For each client, if ||δi|| > Nmed, mark as suspected selfish
  5. For each suspected client, solve Eq. (6) for β and compute δ′i via Eq. (5)
  6. Aggregate as in Eq. (7) and update global model

- Design tradeoffs:
  - Detection simplicity vs. false positives: Simple norm-based detection is lightweight but may misclassify normal clients with large updates
  - Recovery method: Convex combination preserves some contribution of selfish clients vs. dropping them entirely, which could harm generalization
  - Computational overhead: O(kd + k log k) for median computation, negligible compared to O(dk log k) for median of updates

- Failure signatures:
  - High variance in test accuracy across normal clients indicates selfish influence
  - No convergence (oscillating weights) suggests multiple selfish clients canceling each other out
  - If RFL-Self performance drops to median/downscaling levels, the recovery mechanism may be failing (e.g., too many selfish clients)

- First 3 experiments:
  1. Run FL with 1 selfish client (α=0.3) and measure accuracy drop without mitigation
  2. Apply RFL-Self and compare normal vs. selfish client accuracy to baseline
  3. Vary percentage of selfish clients (0%, 10%, 20%) and measure impact on median-based detection accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method perform when selfish clients collude to coordinate their updates?
- Basis in paper: [inferred] The paper assumes selfish clients are independent and do not collude, but does not explore scenarios where they might coordinate their actions.
- Why unresolved: The theoretical analysis and experiments focus on independent selfish clients, leaving the collusion scenario unexplored.
- What evidence would resolve it: Experiments comparing RFL-Self performance with and without collusion among selfish clients, potentially showing whether the method remains effective or requires modification.

### Open Question 2
- Question: Can the estimation of the number of clients (k) in Algorithm 2 be made more robust to handle scenarios where k changes dynamically during training?
- Basis in paper: [explicit] The paper assumes k is fixed at the beginning of the FL process, but acknowledges that this may not always hold in real-world scenarios.
- Why unresolved: The current estimation method relies on the assumption of a fixed k, and its performance in dynamic settings is unknown.
- What evidence would resolve it: Experiments testing Algorithm 2's performance when k changes during training, potentially leading to improvements in the estimation method for dynamic scenarios.

### Open Question 3
- Question: How does the performance of RFL-Self scale with increasing dataset size and model complexity?
- Basis in paper: [inferred] The experiments are conducted on relatively small datasets (MNIST and CIFAR-10) and shallow models, leaving the method's scalability unexplored.
- Why unresolved: The paper does not provide insights into how RFL-Self performs with larger, more complex datasets and deeper models.
- What evidence would resolve it: Experiments testing RFL-Self on larger datasets (e.g., CIFAR-100, ImageNet) and deeper models (e.g., ResNet, Vision Transformers), potentially revealing performance trends and limitations.

## Limitations

- The assumption that true updates have similar magnitude to normal client updates may fail in highly heterogeneous FL settings, potentially causing detection failures
- The effectiveness of recovery degrades when more than 10-20% of clients are selfish, though the exact threshold is not empirically validated
- Performance guarantees rely on the median remaining representative, which may not hold in extreme non-IID scenarios

## Confidence

- Mechanism 1 (norm-based detection): Medium - theoretically sound but sensitive to the similarity assumption
- Mechanism 2 (convex recovery): Medium-High - geometric interpretation is clear, but effectiveness depends on median quality
- Overall effectiveness claim: Medium - strong experimental results but limited to specific dataset/architecture combinations

## Next Checks

1. Test RFL-Self with >20% selfish clients and verify if detection/recovery breaks down as theory predicts
2. Evaluate performance under extreme non-IID settings (clients with single classes) to stress-test median assumptions
3. Implement ablation study removing the recovery step to quantify the value of convex combination vs simple detection+dropping