---
ver: rpa2
title: The Unreliability of Acoustic Systems in Alzheimer's Speech Datasets with Heterogeneous
  Recording Conditions
arxiv_id: '2409.12170'
source_url: https://arxiv.org/abs/2409.12170
tags:
- speech
- acoustic
- features
- dataset
- alzheimer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We evaluated the validity of acoustic systems for AD detection
  in speech datasets with heterogeneous recording conditions. Using MFCCs and Wav2vec
  2.0 embeddings, we show that AD vs.
---

# The Unreliability of Acoustic Systems in Alzheimer's Speech Datasets with Heterogeneous Recording Conditions

## Quick Facts
- arXiv ID: 2409.12170
- Source URL: https://arxiv.org/abs/2409.12170
- Reference count: 0
- Primary result: AD vs. control classification performance above chance when using only non-speech regions indicates recording conditions (bit rate, codec, sampling rate) are correlated with class label.

## Executive Summary
This study reveals that acoustic systems for Alzheimer's disease (AD) detection in speech datasets can achieve above-chance performance even when analyzing only non-speech regions, indicating that recording conditions rather than speech content drive classification. Using MFCCs and Wav2vec2 embeddings on the ADreSSo and SpanishAD datasets, the authors demonstrate that heterogeneous recording conditions systematically differ between AD and control groups. The spurious correlations persist despite noise reduction and loudness normalization, suggesting that most existing AD speech datasets are unreliable for acoustic feature-based detection. The findings recommend using transcript-based approaches or datasets with controlled acoustic conditions instead.

## Method Summary
The authors analyzed two datasets: ADreSSo (derived from Pitt corpus, 77 controls/81 AD) and SpanishAD (39 subjects, 18 controls/21 AD). They extracted MFCCs and Wav2vec2 embeddings from both speech and non-speech regions identified by Silero VAD. A simple DNN classifier with time-distributed dense layer, 1D convolution, and sigmoid output was trained using 8-fold cross-validation with 50 random seeds. The analysis was conducted on original audio and enhanced versions (noise reduction via FullSubNet, loudness normalization, downsampled to 16 kHz). Performance was evaluated using AUC (Area Under Curve) to measure AD vs. control classification.

## Key Results
- Classification performance above chance using only non-speech regions indicates recording conditions correlate with AD/control labels
- The effect persists even after applying noise reduction and loudness normalization
- Results were replicated on a Spanish dataset (SpanishAD), suggesting the problem is not language-specific
- MFCCs and Wav2vec2 embeddings both show spurious correlations, indicating the issue affects multiple feature types

## Why This Works (Mechanism)

### Mechanism 1
Acoustic features in AD speech datasets can be predicted from non-speech regions, indicating that recording conditions are correlated with the class label. Recording conditions (bit rate, codec, sampling rate) vary systematically between AD and control groups, and these acoustic artifacts are encoded in MFCC and Wav2vec2 embeddings even when no speech is present. The core assumption is that the VAD system reliably separates speech from non-speech, and the classifier does not learn spurious correlations from residual speech artifacts in non-speech segments.

### Mechanism 2
Enhancement methods like noise reduction and loudness normalization can reduce but not eliminate the effect of acoustic heterogeneity on classification performance. Enhancement methods improve overall audio quality but do not fully remove systematic differences in recording conditions between groups, which persist in the feature space. The core assumption is that enhancement methods are applied uniformly across all samples and do not introduce new biases.

### Mechanism 3
Acoustic heterogeneity in datasets collected for other purposes (e.g., transcript-based studies) can lead to unreliable acoustic feature-based AD detection when repurposed. Datasets not originally collected with controlled acoustic conditions contain systematic differences in recording setups between groups, leading to spurious correlations when acoustic features are used for classification. The core assumption is that the original data collection did not control for recording conditions, and these uncontrolled factors are correlated with the class label.

## Foundational Learning

- **Voice Activity Detection (VAD)**: Why needed - To separate speech from non-speech regions for spurious correlation analysis. Quick check - What is the threshold used for the Silero VAD model in this study?
- **Mel-Frequency Cepstral Coefficients (MFCCs)**: Why needed - Standard acoustic feature affected by recording conditions. Quick check - How many MFCC coefficients are extracted in this study?
- **Wav2vec2 Embeddings**: Why needed - Self-supervised speech representations affected by recording conditions. Quick check - What is the dimensionality of the Wav2vec2 embeddings used for the ADreSSo dataset?

## Architecture Onboarding

- **Component map**: Raw audio → VAD → Feature extraction (MFCC/Wav2vec2) → Classification (DNN) → Evaluation (AUC)
- **Critical path**: Raw audio → VAD → Feature extraction → Classification → AUC calculation
- **Design tradeoffs**: Using non-speech regions for analysis may underestimate true performance but provides conservative estimate of spurious correlations
- **Failure signatures**: High AUC on non-speech regions indicates spurious correlations; low AUC on speech regions suggests acoustic features not capturing relevant information
- **First 3 experiments**:
  1. Run system on ADreSSo dataset with MFCC features using non-speech regions identified by VAD
  2. Apply noise reduction enhancement to ADreSSo dataset and re-run with Wav2vec2 embeddings
  3. Compare performance on SpanishAD dataset with and without loudness normalization using manual annotations for non-speech regions

## Open Questions the Paper Calls Out

### Open Question 1
Do findings about spurious correlations between recording conditions and AD detection apply to datasets collected with controlled acoustic conditions? The study only examined heterogeneous datasets and did not test controlled conditions. A comparative study using both heterogeneous and controlled datasets would resolve this.

### Open Question 2
How do pitch-based features and speech rate estimates perform in detecting AD when applied to non-speech regions? The authors note these features are only defined over speech regions but suggest they would likely be affected by acoustic conditions. An analysis applying these features to both speech and non-speech regions would resolve this.

### Open Question 3
Can noise reduction and loudness normalization consistently mitigate effects of recording condition biases across different datasets? The study tested specific enhancement methods on two datasets but did not explore a wider range. A comprehensive evaluation across multiple datasets would resolve this.

## Limitations

- Cannot definitively prove spurious correlations stem solely from recording conditions rather than subtle phonetic differences
- Enhancement methods may not fully address all forms of acoustic heterogeneity in real-world datasets
- SpanishAD dataset is small (n=39) and may not generalize to all linguistic contexts

## Confidence

**High confidence**: Classification above chance using only non-speech regions is robust across two independent datasets and multiple feature types.

**Medium confidence**: Recording conditions are the primary source of spurious correlations, though other uncontrolled acoustic variables may contribute.

**Low confidence**: Transcript-based or manually annotated approaches are necessarily more reliable than acoustic features, as manual annotations may have their own biases.

## Next Checks

1. Conduct controlled experiment varying recording conditions (bit rate, codec, sampling rate) within subjects while keeping diagnostic status constant to isolate acoustic properties from diagnostic signal.

2. Perform ablation studies on enhancement pipeline to determine which specific processing steps most effectively reduce spurious correlations.

3. Validate findings on a dataset with explicitly controlled acoustic conditions to establish performance baseline for "clean" acoustic AD detection.