---
ver: rpa2
title: Chatbots and Zero Sales Resistance
arxiv_id: '2408.10291'
source_url: https://arxiv.org/abs/2408.10291
tags:
- science
- weights
- insight
- number
- more
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper argues that the pursuit of ever-increasing numbers of
  weights in large-scale machine learning applications, while promising to tackle
  complexity, is energetically unsustainable and can lead to manipulative strategies
  where science is used as a strawman for economic and financial power. The author
  proposes a paradigm shift from focusing on more weights and little insight to more
  insight and fewer weights.
---

# Chatbots and Zero Sales Resistance

## Quick Facts
- arXiv ID: 2408.10291
- Source URL: https://arxiv.org/abs/2408.10291
- Reference count: 24
- Primary result: The paper argues that pursuing ever-increasing numbers of weights in large-scale ML is energetically unsustainable and risks using science as a strawman for economic power, calling for a paradigm shift toward more insight and fewer weights.

## Executive Summary
This paper critiques the current trajectory of large-scale machine learning, particularly deep neural networks with massive parameter counts. The author argues that while these systems achieve impressive performance through brute-force exploration of vast state spaces, they are energetically unsustainable and fail to provide genuine scientific understanding. Instead of prioritizing model size and predictive accuracy, the paper advocates for a fundamental shift toward models that prioritize insight and explainability over raw control and parameter count.

## Method Summary
The paper presents a qualitative critique of current large-scale ML approaches rather than empirical research. It discusses the mechanisms by which deep neural networks achieve performance through exponential scaling of parameters, the correlation-causation problem in ML, and the energy sustainability crisis. The arguments are based on theoretical reasoning and existing literature rather than new experiments or data analysis.

## Key Results
- Large ML models with trillions of parameters may require Gigawatts of power during training, far exceeding human brain efficiency
- ML systems optimize for correlations rather than causal understanding, limiting their scientific utility
- The current paradigm of "more weights and little insight" needs to shift toward "more insight and fewer weights"

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ML systems achieve high accuracy by exponentially scaling parameters, creating NP = N^L possible paths between inputs and outputs
- Core assumption: Loss landscape is smooth enough for gradient descent to navigate effectively
- Evidence: Abstract mentions pursuit of increasing weights is energetically unsustainable; section explains DNN path space
- Break condition: Models become too large for practical training or loss landscape becomes too rugged

### Mechanism 2
- Claim: ML's correlation-based approach works for prediction but fails for scientific understanding
- Core assumption: Training data adequately represents the distribution of interest
- Evidence: Abstract calls for paradigm shift from weights to insight; section explains ML catches correlations not causation
- Break condition: When causal relationships change over time or out-of-distribution data is encountered

### Mechanism 3
- Claim: Energy cost of training large models creates sustainability crisis
- Core assumption: Current hardware cannot support scaling demands of state-of-the-art ML
- Evidence: Abstract states chatbots with trillions of weights may reach Gigawatts of power demand
- Break condition: Energy costs exceed economic benefits or face regulatory constraints

## Foundational Learning

- Concept: Curse of Dimensionality
  - Why needed here: ML's advantage is handling high-dimensional problems traditional methods cannot solve
  - Quick check question: Why does the number of possible states grow exponentially with dimensions?

- Concept: Gradient Descent and Loss Landscapes
  - Why needed here: ML training iteratively updates weights to minimize loss function
  - Quick check question: What happens to gradient descent when loss landscape has many local minima?

- Concept: Explainability vs. Performance Trade-off
  - Why needed here: Complex models become less interpretable and less useful for scientific understanding
  - Quick check question: Why might highly accurate but uninterpretable models be problematic for scientific discovery?

## Architecture Onboarding

- Component map: Input layer (x) -> Hidden layers (z1...zL) with weights (W1...WL) and biases (b1...bL) -> Output layer (y)
- Critical path: Data preprocessing → Model architecture definition → Forward pass → Loss calculation → Backward pass → Weight update → Repeat until convergence
- Design tradeoffs: Model size vs. training time vs. energy consumption; accuracy vs. explainability; correlation vs. causation; control vs. insight
- Failure signatures: Model fails to converge; poor generalization; high energy costs with diminishing returns; inability to explain predictions
- First 3 experiments:
  1. Train small neural network on simple dataset and visualize loss landscape
  2. Compare training times and energy consumption for models of increasing size
  3. Evaluate pre-trained model on out-of-distribution data to test generalization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise relationship between number of weights in a DNN and energy consumption during training?
- Basis: Paper states chatbots with trillions of weights may reach Gigawatts of power demand vs. 20 Watts for human brain
- Why unresolved: Provides qualitative comparison but no quantitative relationship model
- Evidence needed: Detailed energy model or empirical data linking weight count to energy consumption

### Open Question 2
- Question: How can we develop ML models that prioritize insight over control while maintaining or improving performance?
- Basis: Author calls for paradigm shift from more weights and little insight to more insight and less weights
- Why unresolved: Does not provide specific methods for developing insight-focused ML models
- Evidence needed: Novel architectures or training methods demonstrating improved insight without sacrificing performance

### Open Question 3
- Question: What are most effective ways to quantify and incorporate uncertainty in ML models, especially in high-dimensional weight spaces?
- Basis: Paper lists uncertainty quantification as main criticism, stating it's extremely hard to estimate robustness in high-dimensional weight spaces
- Why unresolved: Does not propose specific solutions for uncertainty quantification
- Evidence needed: New uncertainty quantification techniques handling high-dimensional weight spaces

## Limitations

- Arguments are primarily qualitative rather than empirical, making direct validation challenging
- Lacks specific datasets, quantitative metrics, or experimental results to substantiate claims
- Comparison between human brain efficiency and AI systems lacks rigorous analysis of underlying assumptions

## Confidence

- **High Confidence**: Large ML models consume significant energy during training is well-established in literature
- **Medium Confidence**: Increasing model complexity leads to decreased explainability has strong empirical support
- **Low Confidence**: Current ML approaches fundamentally cannot achieve scientific understanding overstates the case given modern causal ML methods

## Next Checks

1. Conduct systematic literature review to quantify relationship between model size, training energy consumption, and predictive performance across domains
2. Implement controlled experiment comparing large high-performance ML model with smaller interpretable alternative on scientific discovery task
3. Survey AI researchers and practitioners to assess whether large-scale ML approaches are being used as "strawmen for economic and financial power"