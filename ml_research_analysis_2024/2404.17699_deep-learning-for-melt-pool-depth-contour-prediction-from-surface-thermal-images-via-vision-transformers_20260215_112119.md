---
ver: rpa2
title: Deep Learning for Melt Pool Depth Contour Prediction From Surface Thermal Images
  via Vision Transformers
arxiv_id: '2404.17699'
source_url: https://arxiv.org/abs/2404.17699
tags:
- melt
- pool
- image
- transformer
- thermal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a hybrid CNN-Transformer architecture to predict
  subsurface melt pool contours in laser powder bed fusion from high-speed thermal
  video sequences. The model embeds spatial information using a ResNet encoder and
  temporal relationships using a transformer, enabling accurate prediction of melt
  pool depth profiles from surface thermal signatures.
---

# Deep Learning for Melt Pool Depth Contour Prediction From Surface Thermal Images via Vision Transformers

## Quick Facts
- arXiv ID: 2404.17699
- Source URL: https://arxiv.org/abs/2404.17699
- Reference count: 40
- Primary result: Hybrid CNN-Transformer architecture predicts subsurface melt pool depth contours from surface thermal images with superior shape preservation metrics compared to conventional baselines

## Executive Summary
This work introduces a hybrid CNN-Transformer architecture to predict subsurface melt pool contours in laser powder bed fusion from high-speed thermal video sequences. The model embeds spatial information using a ResNet encoder and temporal relationships using a transformer, enabling accurate prediction of melt pool depth profiles from surface thermal signatures. Experimental results show the model outperforms conventional computer vision baselines (U-Net, ViT) in shape preservation metrics, achieving high intersection-over-union scores and strong correlation with ground truth melt pool dimensions. Pre-training on simulation data further improves performance and reduces experimental data requirements. The framework enables real-time defect detection and control in additive manufacturing.

## Method Summary
The proposed method combines a ResNet-based CNN encoder for spatial feature extraction from thermal images with a Transformer module for temporal modeling across video sequences. The architecture processes high-speed thermal video data to predict subsurface melt pool depth contours. The approach leverages both experimental thermal imaging data and simulation-generated datasets, with pretraining on simulation data improving performance on experimental data. The model is evaluated against conventional computer vision baselines including U-Net and ViT architectures, demonstrating superior performance in predicting melt pool depth profiles and shapes.

## Key Results
- Hybrid CNN-Transformer model achieves higher intersection-over-union scores than U-Net and ViT baselines for melt pool contour prediction
- Pretraining on simulation data significantly improves performance on experimental datasets, reducing data requirements
- Strong correlation between predicted and ground truth melt pool dimensions, with superior shape preservation metrics

## Why This Works (Mechanism)
The CNN-Transformer hybrid architecture effectively captures both spatial and temporal patterns in thermal video sequences. The ResNet encoder extracts rich spatial features from individual thermal images, while the Transformer module models temporal dynamics across the video sequence. This dual approach allows the model to learn complex relationships between surface thermal signatures and subsurface melt pool characteristics. The pretraining on simulation data provides a strong initialization that transfers well to experimental conditions, reducing the amount of labeled experimental data needed for good performance.

## Foundational Learning
- **Laser Powder Bed Fusion (LPBF)**: Why needed - Understanding the additive manufacturing process being monitored; Quick check - Verify knowledge of how laser scanning creates melt pools and affects material properties
- **Thermal Imaging in Manufacturing**: Why needed - Foundation for interpreting thermal video data as input; Quick check - Confirm understanding of thermal camera resolution, frame rates, and limitations in industrial settings
- **Transformer Architectures**: Why needed - Core component for temporal modeling in the hybrid approach; Quick check - Validate knowledge of self-attention mechanisms and sequence modeling capabilities
- **ResNet Encoders**: Why needed - Spatial feature extraction backbone for the CNN component; Quick check - Ensure understanding of residual connections and their role in deep network training
- **Melt Pool Dynamics**: Why needed - Essential for interpreting predictions and model behavior; Quick check - Review basic physics of melt pool formation, cooling, and solidification

## Architecture Onboarding

**Component Map**: Thermal Video Sequence -> ResNet Encoder -> Feature Maps -> Transformer -> Melt Pool Depth Contours

**Critical Path**: The sequence from thermal input through ResNet feature extraction to Transformer temporal modeling represents the critical path for accurate predictions. Any degradation in spatial feature quality or temporal modeling capability directly impacts prediction accuracy.

**Design Tradeoffs**: The hybrid approach balances computational efficiency with modeling capability. Pure CNN approaches lack temporal modeling strength, while pure Transformer approaches may be computationally expensive for high-resolution thermal images. The ResNet-Transformer combination optimizes for both spatial detail preservation and temporal relationship capture.

**Failure Signatures**: Poor predictions occur when: (1) Thermal image quality degrades due to reflections or noise; (2) Melt pool dynamics change significantly from training distribution; (3) Material properties or laser parameters fall outside the model's training range; (4) Pretraining simulation data poorly represents experimental conditions.

**First Experiments**: (1) Test model performance on held-out experimental data with known ground truth to establish baseline accuracy; (2) Conduct ablation study removing Transformer component to quantify temporal modeling contribution; (3) Evaluate pretraining benefits by comparing models trained from scratch vs pretraining on simulation data.

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset size and diversity remain unclear, with benefits of simulation pretraining suggesting potential data scarcity in real experimental conditions
- Generalization capability to different materials, laser parameters, and geometries needs validation beyond the specific experimental setup
- Real-time performance characterization is limited - actual inference latency measurements and computational requirements are not provided

## Confidence
- Core technical contribution (hybrid architecture design): High
- Performance improvements over baselines: High
- Pretraining benefits: Medium (limited ablation and validation)
- Real-time implementation feasibility: Low (insufficient computational characterization)
- Generalization to new conditions: Low (limited cross-validation)

## Next Checks
1. Test model performance across multiple material systems and laser parameter ranges to assess generalization
2. Conduct ablation studies isolating the contribution of temporal vs spatial modeling components
3. Measure and report actual inference latency and resource requirements for true real-time implementation in industrial additive manufacturing systems