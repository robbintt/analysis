---
ver: rpa2
title: Synthetic Electroretinogram Signal Generation Using Conditional Generative
  Adversarial Network for Enhancing Classification of Autism Spectrum Disorder
arxiv_id: '2407.08166'
source_url: https://arxiv.org/abs/2407.08166
tags:
- signals
- synthetic
- classification
- were
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of applying AI to classify neurodevelopmental
  disorders like autism spectrum disorder (ASD) when only limited real-world electroretinogram
  (ERG) data is available. To overcome this, the authors propose generating synthetic
  ERG signals using a conditional generative adversarial network (CGAN) trained on
  real ERG recordings.
---

# Synthetic Electroretinogram Signal Generation Using Conditional Generative Adversarial Network for Enhancing Classification of Autism Spectrum Disorder

## Quick Facts
- arXiv ID: 2407.08166
- Source URL: https://arxiv.org/abs/2407.08166
- Reference count: 40
- Primary result: CGAN-generated synthetic ERG signals improved ASD classification accuracy from 0.891 to 0.883

## Executive Summary
This paper addresses the challenge of applying AI to classify neurodevelopmental disorders like autism spectrum disorder (ASD) when only limited real-world electroretinogram (ERG) data is available. To overcome this, the authors propose generating synthetic ERG signals using a conditional generative adversarial network (CGAN) trained on real ERG recordings. These synthetic signals are then used to augment the training dataset for two classification models: a Time Series Transformer (TST) and a Visual Transformer (ViT) that operates on continuous wavelet transform (CWT) representations of the signals. The results show that incorporating synthetic data significantly improved classification performance, with the TST model achieving a balanced accuracy of 0.891 and the ViT model reaching 0.883 on the augmented dataset, compared to lower accuracies on the original limited dataset. This approach demonstrates that synthetic ERG generation can enhance AI-based classification of ASD and related disorders using ERG data.

## Method Summary
The authors developed a conditional GAN with a bidirectional LSTM generator to create synthetic ERG signals conditioned on class labels (ASD vs. control). Real ERG waveforms from 50 subjects (30 ASD, 20 control) were used to train the CGAN, which then generated hundreds of synthetic signals per class. For classification, two transformer-based models were employed: a Time Series Transformer operating directly on time-domain data, and a Visual Transformer processing 3-channel wavelet scalograms (Ricker, Gaussian, and Morlet wavelets) derived from the ERG signals. Both models were trained with 5-fold cross-validation, and performance was evaluated using balanced accuracy, precision, recall, F1-score, and AUC metrics.

## Key Results
- TST model achieved balanced accuracy of 0.891 on augmented dataset
- ViT model reached balanced accuracy of 0.883 on augmented dataset
- Synthetic data augmentation significantly improved classification performance compared to original limited dataset
- CGAN successfully generated ERG signals maintaining morphological features of natural signals

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The conditional GAN (CGAN) effectively generates synthetic ERG signals that retain morphological features of natural signals.
- Mechanism: The CGAN architecture uses a Bidirectional LSTM layer in the generator to capture temporal dependencies in ERG waveforms, producing realistic synthetic signals conditioned on class labels (ASD vs. control). The discriminator learns to distinguish real from synthetic signals, improving generator quality through adversarial training.
- Core assumption: ERG signals contain sufficient temporal patterns that can be learned and reproduced by a BLSTM-based generator.
- Evidence anchors: [abstract] "Synthetic ERG signals generated from real ERG recordings carry similar information as natural ERGs"; [section] "Using the proposed model, hundreds of signals were synthesized for each class of ASD or control"

### Mechanism 2
- Claim: Wavelet transformation captures discriminative frequency features that improve classification performance.
- Mechanism: Continuous Wavelet Transform (CWT) converts time-domain ERG signals into time-frequency representations (scalograms) that highlight transient features and oscillatory potentials. The three-channel approach using Ricker, Gaussian, and Morlet wavelets provides complementary views of the signal structure.
- Core assumption: The time-frequency representation contains more discriminative information than raw time-domain signals for ASD vs. control classification.
- Evidence anchors: [section] "Using the method [21], we determined the three most optimal mother functions for our dataset: Ricker, Gaussian, and Morlet"; [section] "The input for the ViT model was the wavelet scalograms obtained using CWT"

### Mechanism 3
- Claim: Transformer architectures effectively learn patterns from synthetic ERG data augmentation.
- Mechanism: Both Time Series Transformer (TST) and Visual Transformer (ViT) architectures learn hierarchical representations from ERG data. The TST operates directly on time-series data while ViT processes wavelet-transformed images. Synthetic data augmentation addresses the limited sample size problem inherent in neurodevelopmental disorder research.
- Core assumption: Transformer models can effectively learn from the ERG signal patterns, both in time and time-frequency domains, and benefit from synthetic data augmentation.
- Evidence anchors: [abstract] "incorporating synthetic data significantly improved classification performance"; [section] "Introducing synthetic signals into the training dataset significantly enhanced the performance of all models"

## Foundational Learning

- Concept: GAN architecture and training dynamics
  - Why needed here: Understanding how CGANs generate realistic synthetic data is fundamental to evaluating the proposed approach
  - Quick check question: What is the key difference between standard GAN and conditional GAN in terms of training objective?

- Concept: Time series signal processing
  - Why needed here: ERG signals are temporal data requiring understanding of signal characteristics like oscillatory potentials and wave morphology
  - Quick check question: Why might wavelet transform be preferred over Fourier transform for analyzing ERG signals?

- Concept: Transformer architectures for sequence modeling
  - Why needed here: Both TST and ViT are transformer-based models that require understanding of self-attention mechanisms and positional encodings
  - Quick check question: How does the Time Series Transformer differ from the standard Transformer architecture in handling temporal data?

## Architecture Onboarding

- Component map: Real ERG signals → Train/test split → CGAN training → Synthetic generation → Augmentation → CWT transformation → 3-channel image → ViT; Real ERG signals → TST; Both → Classification evaluation
- Critical path: CGAN generation → Data augmentation → Transformer training → Classification evaluation
- Design tradeoffs:
  - BLSTM vs CNN in generator: BLSTM better captures temporal dependencies but may be slower
  - Three-wavelet channels vs single wavelet: More comprehensive feature capture but higher computational cost
  - Hybrid ViT vs pure TST: ViT leverages spatial patterns in wavelet images while TST captures temporal dynamics directly
- Failure signatures:
  - Poor synthetic data quality: Generated signals don't match real ERG morphology
  - Overfitting: High training accuracy but low test accuracy, especially with synthetic data
  - Class imbalance issues: Models favor majority class despite augmentation
- First 3 experiments:
  1. Baseline: Train TST and ViT on original data only (no augmentation) to establish performance floor
  2. Ablation: Test CGAN with different generator architectures (BLSTM vs CNN) to validate design choice
  3. Cross-validation: Perform 5-fold CV on synthetic + real data to assess generalization and variance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do variations in electrode types (fiber, gold foil, contact lens, skin) affect the performance of synthetic ERG signal generation and subsequent classification accuracy?
- Basis in paper: [explicit] The paper mentions that different electrode types affect ERG waveform amplitude and that synthetic ERG generation could help with reference waveform availability regardless of electrode type.
- Why unresolved: The study used a specific electrode type (skin electrodes) and did not test how different electrode types would impact the quality of synthetic ERG generation or classification performance.
- What evidence would resolve it: Comparative studies generating synthetic ERGs using data from multiple electrode types and evaluating classification performance across these variations.

### Open Question 2
- Question: What is the optimal balance between synthetic and real ERG signals for maximizing classification performance across different neurodevelopmental disorders?
- Basis in paper: [inferred] The paper shows significant performance improvements with synthetic data augmentation but does not explore optimal ratios or investigate whether different disorders might require different synthetic-to-real ratios.
- Why unresolved: The study used a fixed ratio of synthetic to real data (approximately 2:1) and only focused on ASD classification, leaving questions about optimal ratios for other conditions.
- What evidence would resolve it: Systematic experiments varying synthetic-to-real ratios and testing across multiple neurodevelopmental disorders to determine optimal augmentation strategies.

### Open Question 3
- Question: How do patient-specific factors such as age, sex, and iris color affect the quality and clinical utility of synthetic ERG signals for classification tasks?
- Basis in paper: [explicit] The paper notes that ERG amplitude is affected by age, sex, and iris color, and mentions that synthetic signals could help address these variations.
- Why unresolved: The study did not investigate how well synthetic ERG generation preserves or accounts for these individual patient characteristics in the generated signals.
- What evidence would resolve it: Detailed analysis of synthetic ERG signals across different patient demographics and correlation studies between synthetic and real signal characteristics across these factors.

## Limitations
- Evaluation conducted on single dataset without external validation
- Synthetic data quality relies on visual similarity claims without quantitative metrics
- Small dataset size (50 subjects) for deep learning applications
- Incomplete ablation studies - no comparison with simpler augmentation methods

## Confidence

**High Confidence:**
- The CGAN architecture can generate synthetic ERG signals that maintain temporal structure
- Transformer models can classify ERG signals with reasonable accuracy
- Data augmentation generally improves classification performance on limited datasets

**Medium Confidence:**
- The specific BLSTM-based CGAN architecture is optimal for ERG signal generation
- CWT transformation with three specific wavelets provides optimal feature representation
- The magnitude of performance improvement (BA 0.891 to 0.883) is directly attributable to synthetic data

**Low Confidence:**
- These results generalize to other neurodevelopmental disorders beyond ASD
- The generated synthetic signals would pass rigorous statistical tests for real vs. synthetic discrimination
- The exact hyperparameter choices (learning rates, network depths) are optimal

## Next Checks

1. **Statistical validation of synthetic data quality**: Apply two-sample tests (KS test, Wasserstein distance) to quantify how closely synthetic ERG distributions match real data distributions across multiple signal characteristics.

2. **External validation on independent dataset**: Test the trained classification models on ERG data from different cohorts or recording conditions to assess generalization beyond the original dataset.

3. **Ablation of synthetic data contribution**: Conduct controlled experiments comparing performance with: (a) original data only, (b) augmented with random noise, (c) augmented with simple signal transformations, and (d) augmented with CGAN-generated data to isolate the specific benefit of CGAN augmentation.