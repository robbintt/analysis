---
ver: rpa2
title: Bayesian Multi-Task Transfer Learning for Soft Prompt Tuning
arxiv_id: '2402.08594'
source_url: https://arxiv.org/abs/2402.08594
tags:
- source
- task
- target
- prompt
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a Bayesian approach to multi-task prompt tuning,
  where prompts are trained from multiple source tasks to be applied to a target task.
  The method uses Stein Variational Gradient Descent (SVGD) to approximate the posterior
  distribution of prompts across source tasks, and then uses the source prompts' posterior
  distribution as the prior for the target task.
---

# Bayesian Multi-Task Transfer Learning for Soft Prompt Tuning

## Quick Facts
- arXiv ID: 2402.08594
- Source URL: https://arxiv.org/abs/2402.08594
- Authors: Haeju Lee; Minchan Jeong; Se-Young Yun; Kee-Eung Kim
- Reference count: 29
- Primary result: Bayesian multi-task prompt tuning outperforms state-of-the-art parameter-efficient fine-tuning methods while using fewer parameters across 21 NLP datasets

## Executive Summary
This paper introduces a Bayesian approach to multi-task prompt tuning that leverages knowledge from multiple source tasks to improve performance on target tasks. The method uses Stein Variational Gradient Descent (SVGD) to approximate the posterior distribution of prompts learned across source tasks, which then serves as the prior for prompt learning on target tasks. The approach addresses the challenge of limited target task data by effectively transferring knowledge from related tasks while maintaining uncertainty quantification through Bayesian inference.

The proposed method demonstrates significant improvements over existing parameter-efficient fine-tuning approaches across diverse NLP tasks including classification, while using fewer trainable parameters than full fine-tuning. The Bayesian framework provides not only improved performance but also uncertainty estimates that can be valuable for downstream applications requiring confidence measures.

## Method Summary
The method employs a two-stage approach to multi-task transfer learning for soft prompt tuning. In the first stage, prompts are trained simultaneously across multiple source tasks using SVGD to approximate the posterior distribution of prompts. SVGD maintains a set of particle prompts that collectively approximate the true posterior through iterative updates that minimize the KL divergence between the particle distribution and the true posterior. In the second stage, the learned posterior distribution from source tasks is used as the prior for prompt tuning on the target task, allowing the model to leverage knowledge from source tasks while adapting to the specific characteristics of the target task.

The soft prompts are trained in a parameter-efficient manner, requiring modification of only a small fraction of the PLM parameters compared to full fine-tuning. The Bayesian framework naturally handles uncertainty in the prompt parameters, which is particularly valuable when target task data is limited. The method is evaluated across 21 datasets spanning diverse NLP tasks, demonstrating both improved performance and parameter efficiency compared to state-of-the-art baselines.

## Key Results
- Outperforms state-of-the-art parameter-efficient fine-tuning methods across 21 diverse NLP datasets
- Achieves better performance while using fewer trainable parameters than full fine-tuning
- Demonstrates effective knowledge transfer from multiple source tasks to target tasks with limited data
- Provides uncertainty quantification through Bayesian posterior approximation

## Why This Works (Mechanism)
The method works by leveraging the Bayesian framework to effectively transfer knowledge across multiple source tasks while maintaining uncertainty quantification. SVGD provides a principled way to approximate the posterior distribution of prompts learned across source tasks, capturing the uncertainty and variability in the learned representations. This posterior then serves as an informative prior for the target task, allowing the model to start from a knowledge-rich initialization rather than learning from scratch. The particle-based approximation maintains diversity in the prompt representations, which helps capture different aspects of the source task knowledge and improves generalization to the target task.

## Foundational Learning

**Stein Variational Gradient Descent (SVGD)**: A non-parametric variational inference method that uses a set of particles to approximate a target distribution. Needed to maintain diversity in the prompt representations across source tasks while approximating the posterior distribution. Quick check: Verify that the SVGD updates preserve the diversity of particle prompts and converge to a good approximation of the true posterior.

**Soft Prompt Tuning**: A parameter-efficient fine-tuning method that prepends learnable prompt vectors to the input embeddings of a PLM. Needed to enable efficient adaptation of PLMs to downstream tasks while modifying only a small fraction of parameters. Quick check: Confirm that the soft prompts can effectively modulate the PLM's behavior for different tasks with minimal parameter changes.

**Bayesian Inference for Transfer Learning**: Using posterior distributions from source tasks as priors for target tasks. Needed to leverage knowledge from multiple related tasks while maintaining principled uncertainty quantification. Quick check: Ensure that the prior from source tasks meaningfully improves target task performance compared to random initialization.

## Architecture Onboarding

**Component Map**: Source Tasks -> SVGD Posterior Approximation -> Target Task Prior -> Soft Prompt Tuning -> PLM Output

**Critical Path**: The critical path involves the SVGD optimization over source tasks to learn the posterior distribution, followed by using this posterior as a prior for target task prompt tuning. The quality of the posterior approximation directly impacts the effectiveness of the transferred knowledge.

**Design Tradeoffs**: The method trades computational overhead of maintaining multiple particle prompts during SVGD optimization against the benefit of better posterior approximation and knowledge transfer. Alternative approaches like using a single posterior mean would be computationally cheaper but might lose important uncertainty information.

**Failure Signatures**: Poor performance may arise from: (1) insufficient diversity in source tasks leading to poor generalization, (2) inadequate SVGD approximation failing to capture the true posterior, (3) mismatch between source and target task distributions, or (4) overfitting to source tasks when target task data is abundant.

**3 First Experiments**:
1. **Ablation on Number of Particles**: Test the impact of varying the number of SVGD particles on both performance and computational cost to find the optimal tradeoff.
2. **Source Task Relevance**: Systematically vary the similarity between source and target tasks to quantify how task relatedness affects transfer effectiveness.
3. **Comparison to MAP Estimation**: Compare the full Bayesian approach against a maximum a posteriori (MAP) estimation baseline that uses only the posterior mean, isolating the benefit of uncertainty quantification.

## Open Questions the Paper Calls Out
None

## Limitations

**Scalability Concerns**: The method's reliance on SVGD for posterior approximation may face scalability challenges with larger numbers of source tasks or prompts, though this is not explicitly explored in the paper.

**Task Type Generalization**: The evaluation focuses primarily on classification tasks, leaving unclear whether the approach generalizes effectively to generation tasks or structured prediction tasks that may require different prompt strategies.

**Computational Overhead**: The computational overhead of maintaining multiple samples during SVGD optimization is not thoroughly analyzed, particularly in comparison to simpler multi-task learning baselines that might achieve similar performance with less complexity.

## Confidence

**Methodological Claims**: High confidence - The Bayesian multi-task prompt tuning approach and SVGD-based posterior approximation are clearly formulated with reasonable implementation details.

**Empirical Results**: Medium confidence - The performance improvements over baselines are well-documented but may not fully account for hyperparameter tuning differences across methods.

**Parameter Efficiency Claims**: High confidence - The number of parameters used is explicitly reported and verifiable, with clear comparisons to full fine-tuning baselines.

**Generalization Claims**: Medium confidence - While the evaluation covers multiple task types, the results may not represent the full spectrum of NLP applications, particularly generation and structured prediction tasks.

## Next Checks

1. **Scalability Testing**: Evaluate the method's performance and computational efficiency as the number of source tasks increases from 3-5 to 10-20 tasks to assess practical scalability limits and identify potential bottlenecks.

2. **Task Diversity Analysis**: Systematically vary the semantic and functional similarity between source and target tasks to quantify the impact of source task selection on transfer effectiveness, identifying optimal strategies for source task curation.

3. **Generation Task Extension**: Apply the method to text generation tasks (summarization, translation, dialogue) to verify whether the Bayesian prompt tuning approach generalizes beyond classification tasks and identify any task-specific modifications needed.