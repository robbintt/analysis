---
ver: rpa2
title: 'OTTER: Effortless Label Distribution Adaptation of Zero-shot Models'
arxiv_id: '2404.08461'
source_url: https://arxiv.org/abs/2404.08461
tags:
- label
- distribution
- otter
- zero-shot
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces OTTER, a method for adapting zero-shot models
  to handle mismatched label distributions in downstream tasks. The core idea is to
  use optimal transport to rebalance model predictions based on an estimated target
  label distribution, without requiring labeled data or access to the pretraining
  distribution.
---

# OTTER: Effortless Label Distribution Adaptation of Zero-shot Models

## Quick Facts
- arXiv ID: 2404.08461
- Source URL: https://arxiv.org/abs/2404.08461
- Reference count: 40
- Primary result: OTTER adapts zero-shot models to mismatched label distributions via optimal transport, improving accuracy by 4.8% in image classification and 15.9% in text classification across 21 datasets

## Executive Summary
OTTER addresses the challenge of adapting zero-shot models to downstream tasks with mismatched label distributions. The method uses optimal transport to rebalance model predictions based on an estimated target label distribution, without requiring labeled data or access to the pretraining distribution. It theoretically recovers the Bayes-optimal classifier under label shift and demonstrates significant empirical improvements across both image and text classification tasks.

## Method Summary
OTTER works by first estimating the target label distribution from unlabeled data, then using optimal transport to compute a transformation matrix that rebalances the model's predictions to match this distribution. The transformation is applied to the model's output logits, effectively adapting the zero-shot predictions to the new distribution without fine-tuning. This approach leverages the structure of optimal transport to ensure the transformation preserves the semantic relationships between classes while correcting for distribution shift.

## Key Results
- Improves average accuracy by 4.8% in image classification and 15.9% in text classification across 21 datasets
- Outperforms prior matching baselines in most evaluated scenarios
- Extends to few-shot learning and mitigates LLM selection bias
- Theoretically recovers Bayes-optimal classifier under label shift conditions

## Why This Works (Mechanism)
OTTER exploits the structure of optimal transport to find the minimal adjustment needed to transform the model's predictions from the source to target distribution. By preserving semantic relationships between classes while correcting for distribution shift, it maintains the model's learned representations while adapting to new label frequencies. The method's effectiveness stems from its ability to leverage unlabeled data to estimate the target distribution and apply a principled transformation without requiring any labeled examples.

## Foundational Learning
1. **Optimal Transport** - A mathematical framework for finding minimal-cost transformations between probability distributions
   - Why needed: Provides the mathematical foundation for computing label distribution adjustments
   - Quick check: Verify that transport costs preserve semantic similarity between classes

2. **Label Shift** - A scenario where the label distribution changes between pretraining and target domains while the conditional distribution remains constant
   - Why needed: Defines the specific type of distribution shift OTTER addresses
- Quick check: Confirm that feature-label relationships remain stable across domains

3. **Zero-shot Learning** - Models that make predictions on new classes without task-specific training
   - Why needed: The target application domain where labeled data is unavailable
   - Quick check: Validate that original model performance is preserved before distribution adjustment

4. **Bayes-optimal Classifier** - The theoretically optimal decision rule that minimizes classification error
   - Why needed: Provides the theoretical benchmark OTTER aims to recover under label shift
   - Quick check: Verify that error rates approach theoretical lower bounds when conditions are met

## Architecture Onboarding

Component map: Pretrained Model -> Optimal Transport Solver -> Distribution Transformer -> Adapted Predictions

Critical path: The key computational sequence flows from the pretrained model through the optimal transport solver to produce transformed predictions. The bottleneck is typically the computation of the transport matrix, which scales with the number of classes.

Design tradeoffs: OTTER trades computational overhead (for computing transport matrices) against the benefit of adaptation without labeled data. The method assumes access to unlabeled data from the target domain and accurate distribution estimation, but avoids the cost of fine-tuning or labeled examples.

Failure signatures: Performance degrades when target label distributions are poorly estimated, when the optimal transport computation becomes intractable for large label spaces, or when the underlying conditional distributions shift beyond what label shift assumptions can handle.

First experiments:
1. Verify distribution transformation by applying OTTER to a simple synthetic dataset with known label shift
2. Test sensitivity to distribution estimation error by adding noise to the target label distribution
3. Compare performance against a baseline that simply normalizes predictions by class frequency

## Open Questions the Paper Calls Out
The paper primarily focuses on classification tasks and theoretical guarantees under idealized conditions. It does not extensively address scenarios with significant feature distribution shift, applications to structured prediction tasks, or the computational scaling for very large label spaces.

## Limitations
- Theoretical guarantees assume perfect knowledge of target label distribution, which may not hold in practice
- Performance depends on quality of unlabeled data for distribution estimation
- Computational complexity of optimal transport may limit scalability to very large label spaces
- Limited evaluation on non-classification tasks and structured prediction scenarios

## Confidence
- **High** confidence in empirical improvements across 21 datasets
- **Medium** confidence in theoretical recovery of Bayes-optimal classifiers under idealized conditions
- **Medium** confidence in extensions to few-shot learning and LLM selection bias due to limited ablation studies

## Next Checks
1. Test OTTER's performance when target label distributions are estimated with varying degrees of error to quantify sensitivity to distribution estimation quality
2. Evaluate OTTER on non-classification tasks such as object detection or semantic segmentation to assess broader applicability
3. Conduct controlled experiments varying the mismatch between pretraining and target label distributions to better understand when OTTER provides the most benefit