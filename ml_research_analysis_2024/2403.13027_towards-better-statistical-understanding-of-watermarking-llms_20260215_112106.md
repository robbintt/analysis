---
ver: rpa2
title: Towards Better Statistical Understanding of Watermarking LLMs
arxiv_id: '2403.13027'
source_url: https://arxiv.org/abs/2403.13027
tags: []
core_contribution: This paper studies the trade-off between model distortion and detection
  ability in watermarking large language models (LLMs). The authors formulate the
  problem as a constrained optimization based on the green-red list algorithm, showing
  that the optimal solution has an analytical property that guides algorithm design.
---

# Towards Better Statistical Understanding of Watermarking LLMs

## Quick Facts
- arXiv ID: 2403.13027
- Source URL: https://arxiv.org/abs/2403.13027
- Reference count: 40
- Key outcome: Theoretical framework and algorithm for LLM watermarking with optimal trade-off between model distortion and detection ability

## Executive Summary
This paper addresses the fundamental trade-off in LLM watermarking between model distortion and detection ability through a rigorous statistical framework. The authors formulate watermarking as a constrained optimization problem based on the green-red list algorithm, proving that the optimal solution has analytical properties that guide practical algorithm design. They develop an online dual gradient ascent algorithm and establish its asymptotic Pareto optimality between distortion and detection performance. The work provides both theoretical guarantees and empirical validation across extensive datasets, demonstrating superior performance compared to existing watermarking approaches.

## Method Summary
The authors formulate LLM watermarking as a constrained optimization problem where they minimize model distortion while ensuring detection capability. They employ the green-red list algorithm as the foundation, where watermarked outputs are drawn from a "green list" with higher probability than normal outputs. The distortion is measured using KL divergence, and detection ability is ensured by constraining the probability of green list selection. An online dual gradient ascent algorithm is developed to solve this optimization problem iteratively, with theoretical guarantees of asymptotic Pareto optimality. The algorithm maintains individual detection ability for every prompt while achieving the optimal trade-off between distortion and detectability.

## Key Results
- Proved asymptotic Pareto optimality of the dual gradient ascent algorithm between model distortion and detection ability
- Demonstrated explicit guarantee of increased green list probability for detection across all prompts
- Validated superior performance over benchmark algorithms on extensive datasets
- Showed that the optimal solution has analytical properties that guide algorithm design

## Why This Works (Mechanism)
The approach works by formulating watermarking as a constrained optimization problem that explicitly balances two competing objectives: minimizing distortion while ensuring detectability. The green-red list framework provides a natural way to encode watermarks by altering output probabilities. The dual gradient ascent algorithm efficiently navigates the trade-off space, with theoretical guarantees ensuring convergence to the Pareto frontier. The use of KL divergence as a distortion metric provides a principled way to measure distributional changes while maintaining mathematical tractability.

## Foundational Learning
- **Green-Red List Algorithm**: A watermarking technique that separates outputs into watermarked (green) and normal (red) lists with different selection probabilities
  - Why needed: Provides the fundamental mechanism for encoding watermarks in LLM outputs
  - Quick check: Verify that green list selection probability exceeds red list probability by the required margin

- **KL Divergence**: A measure of the difference between two probability distributions
  - Why needed: Quantifies model distortion when watermarked outputs are generated
  - Quick check: Ensure KL divergence remains bounded and interpretable for distortion measurement

- **Dual Gradient Ascent**: An optimization algorithm for solving constrained optimization problems by optimizing the Lagrangian
  - Why needed: Enables efficient navigation of the distortion-detectability trade-off space
  - Quick check: Verify convergence of primal and dual variables to stationary points

- **Pareto Optimality**: A state where no objective can be improved without worsening another
  - Why needed: Characterizes the fundamental trade-off between distortion and detection
  - Quick check: Plot objective values to verify no points dominate others on the frontier

## Architecture Onboarding

**Component Map**: Optimization problem formulation -> Dual gradient ascent algorithm -> KL divergence calculation -> Green-red list selection -> Output generation

**Critical Path**: The algorithm iteratively updates watermarked probabilities while maintaining the detection constraint, with each iteration involving gradient calculations, dual variable updates, and probability normalization.

**Design Tradeoffs**: KL divergence provides mathematical tractability but may not perfectly capture perceptual quality; online optimization enables adaptation but requires careful step size selection; the green-red list approach is simple but may have limited watermark capacity.

**Failure Signatures**: Algorithm divergence if step sizes are too large; detection failure if KL divergence constraint is violated; excessive distortion if the trade-off parameter is poorly chosen.

**First Experiments**:
1. Verify convergence of the dual gradient ascent algorithm on a simple two-class problem
2. Test the algorithm's ability to maintain detection guarantees under varying distortion levels
3. Compare performance against baseline watermarking algorithms on a small dataset

## Open Questions the Paper Calls Out
None

## Limitations
- KL divergence may not fully capture practical perceptual quality degradation
- Asymptotic optimality claims may not translate directly to finite-sample performance
- Lack of real-world deployment scenarios and adversarial robustness testing

## Confidence
- High confidence in the optimization formulation and convergence guarantees
- Medium confidence in the practical implications of theoretical results
- Low confidence in model behavior under adversarial attacks and multi-user scenarios

## Next Checks
1. Conduct adversarial robustness testing with various attack strategies to evaluate watermark detectability under intentional removal attempts
2. Perform user studies to measure perceived quality degradation and correlate with KL divergence metrics
3. Test the algorithm's performance in multi-user scenarios with key collisions to validate claims about individual detection ability