---
ver: rpa2
title: A General Black-box Adversarial Attack on Graph-based Fake News Detectors
arxiv_id: '2404.15744'
source_url: https://arxiv.org/abs/2404.15744
tags:
- uni00000013
- news
- uni00000011
- graph
- detectors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes GAFSI, the first general black-box adversarial
  attack framework for graph-based fake news detectors. The method simulates fake
  social interactions (sharing behaviors) to fool detectors based on different graph
  structures.
---

# A General Black-box Adversarial Attack on Graph-based Fake News Detectors

## Quick Facts
- arXiv ID: 2404.15744
- Source URL: https://arxiv.org/abs/2404.15744
- Reference count: 12
- Introduces GAFSI, the first general black-box adversarial attack framework for graph-based fake news detectors

## Executive Summary
This paper presents GAFSI, the first general black-box adversarial attack framework for graph-based fake news detectors. The framework simulates fake social interactions (sharing behaviors) to fool detectors based on different graph structures. GAFSI uses a fraudster selection module to identify influential users leveraging both local and global information, then employs a post injection module to guide these users to create shared relations by sending posts. The framework adds these sharing records to the social context, enabling attacks against various detectors. Experiments on Politifact and Gossipcop datasets show GAFSI achieves success rates of 0.70-0.98 against different GNN-based detectors, outperforming state-of-the-art baselines in most cases while maintaining computational efficiency similar to SGA baseline.

## Method Summary
GAFSI introduces a general black-box adversarial attack framework for graph-based fake news detectors. The method operates through two main components: a fraudster selection module that identifies influential users using both local and global information, and a post injection module that guides these users to create fake sharing behaviors. The framework simulates these fake social interactions by adding sharing records to the social context graph, effectively poisoning the input to fool various GNN-based fake news detectors. The approach is designed to work against different graph structures and detector architectures without requiring white-box access to the target model.

## Key Results
- Achieves success rates of 0.70-0.98 against different GNN-based fake news detectors
- Outperforms state-of-the-art baselines in most cases
- Maintains computational efficiency comparable to SGA baseline
- Validated on Politifact and Gossipcop datasets

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to simulate realistic fake social interactions that exploit the graph structure dependencies in fake news detection systems. By strategically selecting influential users and creating fake sharing behaviors, GAFSI introduces perturbations that propagate through the social network graph, misleading the GNN-based detectors that rely on these connectivity patterns for accurate classification.

## Foundational Learning
1. **Graph Neural Networks (GNNs)**: Deep learning models that operate on graph-structured data, aggregating information from neighboring nodes to make predictions. Needed to understand the target architecture being attacked. Quick check: Verify GNNs use message passing to update node representations based on neighbors.

2. **Graph Poisoning Attacks**: Adversarial techniques that manipulate the graph structure or node features to degrade model performance. Required to contextualize GAFSI within existing attack literature. Quick check: Confirm attacks can target either graph structure, node features, or both.

3. **Social Influence Maximization**: The process of identifying key individuals whose actions can influence the largest number of people in a network. Essential for the fraudster selection mechanism. Quick check: Verify influence propagation follows network topology and user connectivity patterns.

4. **Black-box Adversarial Attacks**: Attack strategies that don't require knowledge of the target model's internal parameters or architecture. Fundamental to understanding GAFSI's general applicability. Quick check: Confirm attacks rely only on input-output observations of the target system.

5. **Fake News Detection on Social Graphs**: Detection approaches that leverage social context and user interactions to identify misinformation. Provides the attack target context. Quick check: Verify detectors use both content features and social graph structures for classification.

## Architecture Onboarding

**Component Map**: User Selection Module -> Post Injection Module -> Social Graph Poisoning -> Detector Output

**Critical Path**: Fraudster Selection → Fake Sharing Creation → Graph Augmentation → Detector Confusion

**Design Tradeoffs**: The framework balances attack effectiveness against computational efficiency by limiting the number of fake interactions while maximizing their impact through strategic user selection. This contrasts with brute-force approaches that create many fake interactions but are computationally expensive.

**Failure Signatures**: Attacks may fail when influential users are already flagged as suspicious, when the social graph has strong community structures that resist manipulation, or when detectors employ temporal analysis to identify abnormal sharing spikes.

**First Experiments**: 1) Baseline comparison against random user selection for fraudster identification, 2) Ablation study removing global information from fraudster selection, 3) Transferability test across different detector architectures

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Limited to Politifact and Gossipcop datasets, which may not represent the full diversity of real-world social media environments
- Assumes controlled injection of fake sharing behaviors without accounting for platform-specific defenses and rate limiting
- Does not address whether injected behaviors create convincing fake news narratives or merely statistical artifacts

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Technical implementation of fraudster selection and post injection modules | High |
| Experimental results showing strong performance metrics | Medium |
| Claims about real-world attack effectiveness and practical deployment | Low |
| Framework's novelty as first general black-box approach | High |
| Computational efficiency comparison with SGA baseline | Medium |

## Next Checks
1. Cross-dataset validation: Test GAFSI against additional fake news datasets from different platforms and languages to assess generalizability beyond Politifact and Gossipcop.

2. Defense robustness testing: Implement and evaluate detector defenses such as anomaly detection in sharing patterns, temporal analysis of interaction spikes, and user behavior profiling to measure GAFSI's effectiveness against realistic countermeasures.

3. Scalability assessment: Evaluate the framework's performance on larger, more complex social graphs with millions of users and interactions to verify computational efficiency claims and identify potential bottlenecks in fraudster selection and post injection at scale.