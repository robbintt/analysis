---
ver: rpa2
title: 'Exploring Human-AI Perception Alignment in Sensory Experiences: Do LLMs Understand
  Textile Hand?'
arxiv_id: '2406.06587'
source_url: https://arxiv.org/abs/2406.06587
tags:
- textile
- alignment
- participants
- textiles
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the perceptual alignment between large
  language models (LLMs) and human touch experiences using a "Guess What Textile"
  interaction task. Participants handled textile samples and described the differences
  between them to the LLM, which attempted to identify the target textile based on
  similarity in embedding space.
---

# Exploring Human-AI Perception Alignment in Sensory Experiences: Do LLMs Understand Textile Hand?

## Quick Facts
- arXiv ID: 2406.06587
- Source URL: https://arxiv.org/abs/2406.06587
- Authors: Shu Zhong; Elia Gatti; Youngjun Cho; Marianna Obrist
- Reference count: 40
- One-line primary result: LLMs show partial alignment with human touch experiences for textiles, with success rate of 22.5% and varying alignment across different textile types

## Executive Summary
This paper investigates whether large language models can understand human tactile experiences through a "Guess What Textile" interaction task. Forty participants described the differences between pairs of textile samples to an LLM, which attempted to identify the target textile using semantic similarity in embedding space. The study reveals that while some perceptual alignment exists between humans and LLMs for touch experiences, it varies significantly across different textile samples, with silk satin showing better alignment than cotton denim. The research highlights the need for improved human-AI perceptual alignment in sensory experiences and suggests that training data variations may contribute to the observed differences in alignment across textiles.

## Method Summary
The study used 20 textile samples (cotton denim, silk satin, etc.) with textual descriptions and 40 participants who completed 80 interaction tasks. Participants handled textile pairs and described their touch differences verbally, with automatic speech recognition (ASR) converting speech to text. The LLM predictions were based on cosine similarity between participant descriptions and pre-computed textile embeddings using OpenAI's text-embedding-3-small model. Participants also provided subjective validity and similarity ratings for each prediction, with the system allowing up to three attempts per task using iterative vector adjustments.

## Key Results
- The overall success rate was 22.5%, with significant variation across different textile samples
- Silk satin showed better perceptual alignment than cotton denim, suggesting material properties affect LLM understanding
- Average validity score was 5.25 and similarity score was 4.77 for incorrect predictions, indicating partial understanding even when predictions were wrong

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can capture semantic relationships between textile descriptions through embedding similarity.
- Mechanism: Textile descriptions are converted into fixed-dimensional vectors using OpenAI's text-embedding-3-small model. These vectors encode semantic meaning, allowing similar textiles (e.g., "soft") to cluster together in the embedding space. When a participant describes a textile, their description is embedded and compared via cosine similarity to pre-computed textile embeddings, enabling the LLM to predict which textile is being described.
- Core assumption: The embedding space preserves perceptual similarity for tactile properties.
- Evidence anchors:
  - [abstract]: "Using these descriptions, the LLM attempted to identify the target textile by assessing similarity within its high-dimensional embedding space."
  - [section 3.3]: "Model embeddings... offer a way to gauge semantic similarity in the vector space."
  - [corpus]: No direct evidence; weak corpus alignment for tactile keywords.
- Break condition: If textile descriptions contain ambiguous or culturally variable terms, embeddings may not preserve perceptual similarity.

### Mechanism 2
- Claim: Comparative touch descriptions improve LLM alignment by anchoring descriptions to known reference textiles.
- Mechanism: Participants handle a reference and target textile, then describe the differences. The LLM uses the reference textile's embedding as a starting point and adjusts it based on the participant's description. This iterative adjustment helps the LLM refine its prediction through successive trials.
- Core assumption: Differences between textiles are sufficiently distinctive to guide predictions.
- Evidence anchors:
  - [abstract]: "Participants handled textile samples and described the differences between them to the LLM."
  - [section 3.1]: "Participants provide verbal descriptors of their sensory experience while handling two textiles at a time."
  - [corpus]: No strong corpus evidence for comparative tactile descriptions.
- Break condition: If reference and target textiles are too similar, differences may be too subtle for the LLM to disambiguate.

### Mechanism 3
- Claim: Human subjective ratings (validity and similarity) provide nuanced alignment feedback beyond binary accuracy.
- Mechanism: Participants rate how well the LLM's guess matches their intended description (validity) and how similar the guessed textile is to the target (similarity). These ratings capture degrees of misalignment, allowing the system to quantify perceptual gaps.
- Core assumption: Human judgments reliably reflect perceptual alignment.
- Evidence anchors:
  - [abstract]: "participants didn't perceive their textile experiences closely matched by the LLM predictions."
  - [section 4.1]: "The two additional subjective measures (validity and similarity scores) captured the participants' subjective judgement of the AI's performance."
  - [corpus]: No corpus evidence for subjective tactile alignment ratings.
- Break condition: If participants are inconsistent in their ratings, the alignment measures lose reliability.

## Foundational Learning

- Concept: Embedding similarity and cosine distance
  - Why needed here: Understanding how the LLM compares descriptions to textiles.
  - Quick check question: If two textile descriptions have cosine similarity of 0.9, are they more or less similar than those with 0.3?

- Concept: Iterative vector adjustment
  - Why needed here: Explaining how the LLM refines predictions across attempts.
  - Quick check question: Why does the system add the query embedding to the start embedding rather than replacing it?

- Concept: Subjective vs. objective metrics
  - Why needed here: Distinguishing between success rate and human ratings.
  - Quick check question: If the LLM guesses correctly but participants rate validity low, what does that imply?

## Architecture Onboarding

- Component map: ASR -> Embedding Model -> Vector Search -> Prediction -> UI -> Human Rating
- Critical path: Participant description -> ASR -> embedding -> cosine similarity -> prediction -> participant rating
- Design tradeoffs: Using pre-computed embeddings saves computation but limits adaptability to new textiles; adding multimodal input could improve alignment but increases complexity.
- Failure signatures: Low success rate with high validity/similarity scores suggests the LLM understands descriptions but lacks granularity; high success rate with low ratings suggests correct guesses but misaligned interpretations.
- First 3 experiments:
  1. Run the task with a single participant and one textile pair to verify the end-to-end pipeline.
  2. Test embedding similarity for known similar and dissimilar textiles to validate the embedding space.
  3. Measure prediction accuracy when the reference and target textiles are maximally different versus minimally different.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do multimodal LLMs (MLLMs) perform in perceptual alignment tasks compared to text-only LLMs for touch experiences?
- Basis in paper: [explicit] The paper discusses MLLMs as a future research direction and their potential to process multimodal inputs for enhanced human-AI perceptual alignment.
- Why unresolved: Current research focuses on foundational language models; MLLMs are emerging technology with limited empirical studies on perceptual alignment for touch.
- What evidence would resolve it: Comparative studies measuring success rates, validity, and similarity scores between MLLMs and text-only LLMs in textile hand tasks.

### Open Question 2
- Question: What specific characteristics of textile samples contribute most to perceptual alignment bias in LLMs?
- Basis in paper: [inferred] The paper observes significant variance in success rates across different textiles, suggesting that certain textile properties make them more distinguishable to LLMs.
- Why unresolved: The study identifies bias exists but does not analyze which textile properties (e.g., texture, material composition) most influence alignment.
- What evidence would resolve it: Systematic analysis correlating textile properties with alignment metrics across a broader range of samples.

### Open Question 3
- Question: How does the subjective nature of touch experiences affect the consistency of human-AI perceptual alignment across different individuals?
- Basis in paper: [explicit] The paper acknowledges that subjective sensory judgment varies widely among individuals, which affects alignment measures.
- Why unresolved: The study uses a relatively homogeneous participant group and does not explore individual differences in touch perception.
- What evidence would resolve it: Longitudinal studies with diverse participant groups measuring alignment consistency across multiple sessions and individuals.

## Limitations
- The study's sample size (40 participants, 80 tasks) limits generalizability of perceptual alignment findings across broader populations and textile types
- Reliance on text-based descriptions for tactile experiences may not fully capture the richness of human touch perception
- The embedding model (OpenAI text-embedding-3-small) was not specifically trained for textile descriptions, potentially limiting its ability to capture nuanced tactile differences

## Confidence

**High Confidence:** The observed 22.5% success rate and average validity/similarity scores are reliable findings from the user study, as these are direct measurements from the experimental data.

**Medium Confidence:** The conclusion that perceptual alignment varies significantly between different textiles (silk satin vs. cotton denim) is supported by the data, though the underlying reasons for these differences require further investigation.

**Low Confidence:** The paper's suggestion that training data variations contribute to alignment differences lacks direct evidence and requires additional experiments to validate.

## Next Checks
1. Test the embedding model's ability to distinguish between textile descriptions with known similar/dissimilar properties to validate the embedding space quality
2. Conduct the same study with a larger and more diverse participant pool to assess generalizability of perceptual alignment findings
3. Experiment with fine-tuning the embedding model specifically on textile descriptions to determine if this improves alignment performance