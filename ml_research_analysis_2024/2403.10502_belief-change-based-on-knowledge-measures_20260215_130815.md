---
ver: rpa2
title: Belief Change based on Knowledge Measures
arxiv_id: '2403.10502'
source_url: https://arxiv.org/abs/2403.10502
tags: []
core_contribution: This paper proposes a novel quantitative Belief Change (BC) framework
  based on Knowledge Measures (KMs). The authors introduce a principle of minimal
  surprise to define KM-based BC operators that aim to minimize the information-theoretic
  surprise of the modified belief.
---

# Belief Change based on Knowledge Measures

## Quick Facts
- arXiv ID: 2403.10502
- Source URL: https://arxiv.org/abs/2403.10502
- Authors: Umberto Straccia; Giovanni Casini
- Reference count: 40
- Key outcome: Introduces KM-based belief change operators satisfying AGM postulates and provides quantitative measures for information loss/gain during belief operations

## Executive Summary
This paper proposes a novel quantitative Belief Change framework based on Knowledge Measures (KMs). The authors introduce a principle of minimal surprise to define KM-based BC operators that minimize information-theoretic surprise when modifying beliefs. They show these operators satisfy the AGM postulates and can represent any AGM-compliant BC operator. The framework provides quantitative measures for information loss, gain, and change during belief operations, and briefly explores iterated revision.

## Method Summary
The paper develops a belief change framework using Knowledge Measures (KMs) based on probability distributions over possible worlds. The core method defines contraction operators that select remainders with minimal KM values, representing the least surprising modifications to beliefs. Revision is derived via the Levi identity, and quantitative measures compute information changes using differences in KM values. The framework establishes that KM-based operators satisfy AGM postulates and can characterize any AGM-compliant operator through appropriate probability distribution translations.

## Key Results
- KM-contraction operators satisfy all AGM contraction postulates (Proposition 10)
- Any AGM contraction operator can be represented as a KM-contraction operator (Proposition 13)
- The framework provides explicit formulas for quantitative measures of information loss/gain/change (Corollaries 1 and 3)
- KM-based severe withdrawal operators can be defined and satisfy relevant postulates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: KM-based belief change operators satisfy the AGM postulates.
- Mechanism: The framework maps AGM postulates to probabilistic counterparts via P-entailment, then uses a probability distribution to guide contraction through the principle of minimal surprise (selecting the least surprising/most probable worlds).
- Core assumption: P-entailment correctly generalizes classical entailment while preserving logical structure needed for AGM postulates.
- Evidence anchors:
  - [abstract]: "KM-based BC operators that satisfy the so-called AGM postulates"
  - [section 4.1]: Proposition 10 proves KM-contraction satisfies AGM postulates
  - [corpus]: Weak - corpus neighbors discuss AGM-like operators but don't directly verify satisfaction of all AGM postulates
- Break condition: If P-entailment fails to preserve necessary logical relationships between AGM postulates, the KM framework would not satisfy AGM requirements.

### Mechanism 2
- Claim: Any AGM contraction operator can be represented as a KM-contraction operator.
- Mechanism: AGM contraction operators can be characterized by faithful assignments (total preorders), which can be translated into probability distributions. These distributions then define KM-contraction operators that behave identically to the original AGM operators.
- Core assumption: Faithful assignments can be faithfully translated into probability distributions that preserve the contraction behavior.
- Evidence anchors:
  - [abstract]: "a characterisation of any BC operator that satisfies the AGM postulates as a KM-based BC operator"
  - [section 4.1]: Proposition 13 proves this correspondence
  - [corpus]: Weak - corpus neighbors discuss realization of operators but not the specific KM-AGM correspondence
- Break condition: If the translation from faithful assignments to probability distributions loses information about the original operator's behavior, the representation would fail.

### Mechanism 3
- Claim: The framework provides quantitative measures for information loss/gain/change during belief operations.
- Mechanism: The Shannon KM (κS) provides a quantitative measure of knowledge content. By comparing κS values before and after belief operations, the framework quantifies information loss (contraction), gain (expansion), and change (revision).
- Core assumption: The Shannon KM correctly measures information content in a way that reflects intuitive notions of information loss/gain.
- Evidence anchors:
  - [abstract]: "introduce quantitative measures that account for the information loss of contraction, information gain of expansion and information change of revision"
  - [section 4.1]: Corollaries 1 and 3 provide explicit formulas for these measures
  - [corpus]: Weak - corpus neighbors discuss information measures but not specifically in the context of belief change operations
- Break condition: If the Shannon KM does not accurately capture the information content relevant to belief change, the quantitative measures would be misleading.

## Foundational Learning

- Concept: Probability distributions over possible worlds
  - Why needed here: The framework uses probability distributions to model uncertainty about which world is actual, which is fundamental to the KM approach
  - Quick check question: How does the framework handle the case where multiple worlds have non-zero probability?

- Concept: P-entailment and its relationship to classical entailment
  - Why needed here: P-entailment is the probabilistic generalization of classical entailment used throughout the framework to define AGM postulates
  - Quick check question: Can you give an example where P-entailment differs from classical entailment?

- Concept: Information theory and Shannon entropy
  - Why needed here: The Shannon KM uses information-theoretic concepts to measure knowledge content and guide belief change operations
  - Quick check question: Why does the framework use negative log probability as the measure of knowledge content?

## Architecture Onboarding

- Component map:
  - Probability distribution component: Defines P over possible worlds
  - KM component: Computes κS(ϕ) = -log₂P(ϕ) for any formula ϕ
  - Contraction component: Implements KM-based contraction using remainders and minimal surprise
  - Revision component: Implements KM-based revision via Levi identity
  - Quantitative measures: Computes information loss/gain/change using κS differences

- Critical path:
  1. Define probability distribution P over worlds
  2. Compute KM values κS(ϕ) for relevant formulas
  3. For contraction: find remainders, select minimal KM elements, construct result
  4. For revision: use Levi identity with contraction and expansion
  5. Compute quantitative measures as needed

- Design tradeoffs:
  - The framework trades computational complexity (finding remainders, computing KMs) for principled handling of uncertainty
  - Using probability distributions allows flexible modeling but requires careful specification of P
  - The framework prioritizes minimal surprise over other possible principles like conservatism

- Failure signatures:
  - Inconsistent results when different probability distributions are used
  - AGM postulates not satisfied due to incorrect P-entailment implementation
  - Information measures not matching intuitive expectations due to KM formulation issues

- First 3 experiments:
  1. Verify KM-contraction satisfies AGM postulates on a simple example with 2-3 propositional variables
  2. Test the correspondence between an AGM contraction and its KM representation
  3. Compute information loss/gain measures for basic contraction and expansion operations and verify they match expectations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the KM-based contraction operator relate to Levi's value-based Levi contraction, and can the two be unified or compared more formally?
- Basis in paper: [explicit] The paper mentions that Levi's value-based contraction uses a value maximization selection process among saturatable contractions, while the KM-based approach uses KM minimization over remainders. The relationship is stated as unclear and left for future work.
- Why unresolved: The paper acknowledges the similarity in axioms (E) of KMs and strong monotonicity of IV, but notes the overall definitions and selection processes differ significantly.
- What evidence would resolve it: A formal proof or counterexample showing the equivalence or non-equivalence of KM-based and value-based Levi contractions under specific conditions.

### Open Question 2
- Question: How can the KM-based framework be extended to handle first-order languages or paraconsistent logics, and what challenges would arise in defining appropriate knowledge measures?
- Basis in paper: [explicit] The paper suggests investigating the application of KMs to FOL, paraconsistent logics, non-monotonic logics, conditional logics, and various many-valued and fuzzy logics as future work.
- Why unresolved: The current framework is based on classical propositional logic, and extending it to more complex logics would require new definitions of entailment, consistency, and knowledge measures that are not straightforward.
- What evidence would resolve it: A formal extension of the KM axioms and contraction/revision operators to a specific non-classical logic, along with examples demonstrating its application.

### Open Question 3
- Question: What is the relationship between the KM-based severe withdrawal operator and other non-recovery-postulate-compliant contraction operators, such as ring withdrawal or recuperative withdrawal?
- Basis in paper: [explicit] The paper mentions that one may define a KM-based ring withdrawal operator using a KM-based severe withdrawal operator or even using a KM-based AGM contraction operator, but leaves the detailed investigation for future work.
- Why unresolved: While the paper provides a sphere-based view of severe withdrawal, it does not explore the connections to other non-recovery contraction operators in depth.
- What evidence would resolve it: A comparative analysis of the KM-based severe withdrawal operator and other non-recovery operators, including formal proofs of their relationships or counterexamples showing their differences.

## Limitations
- The framework assumes well-defined probability distributions over worlds, which may be challenging to specify in practice
- The treatment of iterated revision is incomplete, failing to satisfy all Darwiche-Pearl postulates
- The framework's practical applicability in complex belief networks remains unvalidated beyond simple examples

## Confidence
- High confidence: AGM postulates satisfaction for KM-contraction (supported by Proposition 10)
- Medium confidence: Characterization of AGM operators as KM operators (Proposition 13 requires careful probability distribution translation)
- Low confidence: Practical applicability in complex belief networks (limited validation beyond simple examples)

## Next Checks
1. Verify the probability distribution translation preserves contraction behavior for a comprehensive set of AGM contraction operators, not just a few examples
2. Test the framework's performance on belief networks with cyclic dependencies and non-trivial logical relationships
3. Extend the iterated revision analysis to determine if alternative KM formulations can satisfy all Darwiche-Pearl postulates while maintaining the framework's core properties