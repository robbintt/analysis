---
ver: rpa2
title: Focused Active Learning for Histopathological Image Classification
arxiv_id: '2404.04663'
source_url: https://arxiv.org/abs/2404.04663
tags: []
core_contribution: This study addresses the challenge of efficient data acquisition
  for machine learning in digital pathology, where existing active learning methods
  struggle with artifacts, ambiguities, and class imbalances. The proposed Focused
  Active Learning (FocAL) method combines a Bayesian Neural Network with Out-of-Distribution
  detection to estimate different uncertainties for the acquisition function.
---

# Focused Active Learning for Histopathological Image Classification

## Quick Facts
- arXiv ID: 2404.04663
- Source URL: https://arxiv.org/abs/2404.04663
- Reference count: 40
- Key outcome: FocAL achieves Cohen's kappa of 0.764 using only 0.69% of labeled Panda dataset (4,400 patches) for prostate cancer classification

## Executive Summary
This study introduces Focused Active Learning (FocAL), a method designed to improve data acquisition efficiency in digital pathology by addressing common challenges like artifacts, ambiguities, and class imbalances. Traditional active learning methods often struggle with these issues, leading to suboptimal model performance. FocAL combines a Bayesian Neural Network with Out-of-Distribution (OoD) detection to estimate different types of uncertainties—epistemic, aleatoric, and OoD—which are then weighted and used in the acquisition function. The method is tested on MNIST and the Panda dataset for prostate cancer classification, demonstrating superior performance over existing approaches while requiring significantly less labeled data.

## Method Summary
FocAL addresses the challenge of efficient data acquisition in digital pathology by combining a Bayesian Neural Network with Out-of-Distribution detection. The method estimates three types of uncertainties: epistemic uncertainty (weighted to address class imbalance), aleatoric uncertainty (to handle ambiguous images), and an OoD score (to identify artifacts). These uncertainties are integrated into the acquisition function to prioritize the most informative and least problematic samples. The approach is validated on MNIST and the Panda dataset, showing improved performance over existing active learning methods with minimal labeled data requirements.

## Key Results
- FocAL achieves a Cohen's kappa of 0.764 on the Panda dataset using only 0.69% of labeled data (4,400 patches).
- The method outperforms existing active learning approaches in both MNIST and prostate cancer classification tasks.
- FocAL effectively focuses on informative images while avoiding ambiguities and artifacts during acquisition.

## Why This Works (Mechanism)
FocAL works by integrating multiple uncertainty measures to guide the selection of informative and reliable samples for labeling. Epistemic uncertainty helps address class imbalance by prioritizing underrepresented classes, while aleatoric uncertainty identifies ambiguous images that may confuse the model. Out-of-Distribution detection filters out artifacts and irrelevant samples, ensuring the model focuses on high-quality data. This multi-faceted approach reduces the need for extensive labeled data while maintaining high classification accuracy.

## Foundational Learning

### Bayesian Neural Networks
**Why needed:** To quantify uncertainty in predictions, enabling the model to distinguish between informative and ambiguous samples.
**Quick check:** Verify that the BNN outputs both mean predictions and uncertainty estimates for each sample.

### Out-of-Distribution Detection
**Why needed:** To identify artifacts and out-of-distribution samples that could degrade model performance.
**Quick check:** Ensure the OoD score is calibrated to detect known artifacts in the dataset.

### Uncertainty Quantification
**Why needed:** To differentiate between epistemic (model) and aleatoric (data) uncertainties, allowing targeted handling of class imbalance and ambiguities.
**Quick check:** Confirm that epistemic and aleatoric uncertainties are computed separately and weighted appropriately in the acquisition function.

## Architecture Onboarding

### Component Map
Bayesian Neural Network -> Uncertainty Estimation -> Out-of-Distribution Detection -> Acquisition Function -> Data Selection

### Critical Path
1. Bayesian Neural Network processes input images.
2. Uncertainty estimates (epistemic, aleatoric) and OoD scores are computed.
3. Acquisition function combines these metrics to prioritize samples.
4. Selected samples are labeled and added to the training set.

### Design Tradeoffs
- **Epistemic vs. Aleatoric Uncertainty:** Epistemic uncertainty is weighted to address class imbalance, while aleatoric uncertainty handles ambiguities. This tradeoff ensures the model focuses on underrepresented classes without being misled by noisy data.
- **OoD Detection vs. Uncertainty:** OoD detection identifies artifacts, while uncertainty metrics handle ambiguities. Balancing these ensures the model avoids problematic samples while learning from informative ones.

### Failure Signatures
- **Overfitting to Artifacts:** If OoD detection is not robust, the model may overfit to artifacts instead of focusing on informative samples.
- **Class Imbalance Ignored:** If epistemic uncertainty weighting is not properly calibrated, the model may ignore underrepresented classes.
- **Ambiguity Misclassification:** If aleatoric uncertainty is not handled correctly, the model may misclassify ambiguous images.

### First Experiments
1. Test FocAL on a small subset of the Panda dataset to validate uncertainty weighting.
2. Compare FocAL's performance with and without OoD detection on a dataset with known artifacts.
3. Evaluate the impact of epistemic uncertainty weighting on class imbalance by testing on a balanced vs. imbalanced dataset.

## Open Questions the Paper Calls Out
None

## Limitations
- The method's generalizability across diverse histopathological domains and imaging protocols is unverified.
- The computational complexity of combining Bayesian Neural Networks with OoD detection may limit real-time or resource-constrained clinical applications.
- Reliance on manual annotation of artifacts and ambiguities introduces potential subjectivity, affecting reproducibility.

## Confidence
- **High:** Core methodology effectively identifies and prioritizes informative samples while avoiding problematic ones.
- **Medium:** Scalability claims require further validation across diverse datasets and larger sample sizes.
- **Low:** Clinical implementation claims lack real-world deployment testing or comparison against domain expert workflows.

## Next Checks
1. Cross-dataset validation testing FocAL's performance on histopathological images from different cancer types and imaging systems.
2. Ablation studies quantifying the individual contributions of epistemic uncertainty weighting, aleatoric uncertainty handling, and OoD detection to overall performance.
3. Time and resource complexity analysis comparing FocAL against existing active learning methods in terms of computational requirements and annotation time savings in practical pathology workflows.