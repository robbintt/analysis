---
ver: rpa2
title: 'CausalScore: An Automatic Reference-Free Metric for Assessing Response Relevance
  in Open-Domain Dialogue Systems'
arxiv_id: '2406.17300'
source_url: https://arxiv.org/abs/2406.17300
tags: []
core_contribution: This paper introduces CausalScore, a novel reference-free metric
  for evaluating response relevance in open-domain dialogue systems. The metric leverages
  causal strength between dialogue histories and responses, estimated using unconditional
  and conditional independence classifiers.
---

# CausalScore: An Automatic Reference-Free Metric for Assessing Response Relevance in Open-Domain Dialogue Systems

## Quick Facts
- **arXiv ID**: 2406.17300
- **Source URL**: https://arxiv.org/abs/2406.17300
- **Reference count**: 22
- **Key outcome**: CausalScore outperforms state-of-the-art metrics in aligning with human judgments on response relevance in open-domain dialogue systems.

## Executive Summary
This paper introduces CausalScore, a novel reference-free metric for evaluating response relevance in open-domain dialogue systems. The metric leverages causal strength between dialogue histories and responses, estimated using unconditional and conditional independence classifiers. Experimental results demonstrate that CausalScore significantly outperforms state-of-the-art metrics in aligning with human judgments across multiple datasets and evaluation dimensions. Additionally, the authors release CGDIALOG+, a new dataset with human-annotated causal relations and pairwise human preferences to support future metric development. CausalScore achieves higher correlations with human judgments on relevance and overall quality compared to baselines like BLEU, BERTScore, and ChatGPT-based metrics.

## Method Summary
CausalScore evaluates response relevance by estimating causal strength between dialogue histories and responses using classifier-based conditional independence (CI) tests. The method first trains an unconditional independence classifier (Cuncond) to identify candidate utterances with statistical dependence on the response. Then, a conditional independence classifier (Ccond) is trained using incremental self-training with constraints to refine these candidates by conditioning on other utterances. The final CausalScore is computed as the average of unconditional and conditional dependence probabilities. The approach is trained and evaluated on CGDIALOG+, a new dataset with human-annotated causal relations and pairwise preference judgments across five dimensions.

## Key Results
- CausalScore achieves significantly higher correlations with human judgments on relevance and overall quality compared to BLEU, BERTScore, and ChatGPT-based metrics
- The metric demonstrates consistent performance across three dialogue datasets (ESConv, MSC, DREAM)
- CGDIALOG+ dataset with human-annotated causal relations and pairwise preferences supports future metric development

## Why This Works (Mechanism)

### Mechanism 1
CausalScore improves evaluation alignment by using classifier-based conditional independence tests to detect true causal relations rather than relying on surface similarity or fluency. Unconditional independence classifiers identify candidate utterances with statistical dependence on the response; conditional independence classifiers refine these by conditioning on other utterances, isolating genuine causal links. The final score averages these probabilities to reflect overall causal strength.

### Mechanism 2
Self-training with constraints enhances CI classifier performance by expanding training data while controlling noise. After initial supervised training, the classifier predicts on unlabeled data; only predictions with high confidence (>0.9) and satisfying domain-specific constraints (e.g., utterances within recent turns) are added as pseudo-labels, iteratively refining the classifier.

### Mechanism 3
Pairwise human preference judgments reduce bias and improve evaluation quality compared to Likert-scale scoring. Annotators compare two responses per dialogue history and select preferences across five dimensions (relevance, empathy, etc.), with aggregation via voting schema to produce ordinal human scores.

## Foundational Learning

- **Conditional independence testing**: Needed to isolate genuine causal relations between dialogue history utterances and responses while controlling for confounding utterances. Quick check: If utterance A is independent of response R given utterance B, what does that imply about the causal relationship between A and R?

- **Mutual information as a proxy for causal strength**: Needed because CI test outputs can be interpreted as probabilities of dependence, which map to mutual information, a measure of statistical dependence that approximates causal influence. Quick check: If CMI(I(A;R|B)) > CMI(I(A;R)), what does that tell you about the role of B in the A→R relationship?

- **Self-training with constraints**: Needed to leverage unlabeled dialogue data for improving classifier generalization without introducing too much noise. Quick check: What risk arises if the confidence threshold for pseudo-label inclusion is set too low?

## Architecture Onboarding

- **Component map**: RoBERTa backbone → unconditional classifier → candidate selection → conditional classifier → score aggregation → output
- **Critical path**: Unconditional classifier outputs → candidate utterances → conditional classifier inputs → conditional probabilities → CausalScore aggregation
- **Design tradeoffs**: Using CI tests trades model interpretability for better causal alignment; self-training trades computation for performance; pairwise judgments trade annotation speed for reduced bias
- **Failure signatures**: Low correlations with human judgments despite high classifier accuracy; score distributions too narrow; high variance in ablation studies
- **First 3 experiments**:
  1. Ablation: Remove unconditional classifier step and evaluate correlation drop
  2. Ablation: Replace self-training with fixed supervised training and compare performance
  3. Cross-dataset evaluation: Train on one dataset, test on another to assess domain generalization

## Open Questions the Paper Calls Out

### Open Question 1
How does CausalScore perform on domains significantly different from the training data, such as technical support or medical conversations? The paper mentions that CausalScore's performance may drop when applied to unseen domains, and provides some out-of-domain evaluation results, but the evaluation is limited to three dialogue datasets (ESConv, MSC, DREAM).

### Open Question 2
How sensitive is CausalScore to the quality and size of the annotated causal relation dataset (CGDIALOG+)? The paper acknowledges that the CGDIALOG+ dataset is relatively small and mentions the potential impact on industrial applications, but does not provide experiments varying the size or quality of the training data.

### Open Question 3
How does CausalScore compare to human evaluation in terms of cost and time efficiency? The paper states that CausalScore aims to provide a cost-effective alternative to human evaluation, which is expensive and time-consuming, but does not provide a direct comparison of the cost and time required for human evaluation versus CausalScore.

## Limitations

- Primary uncertainty in whether classifier-based conditional independence tests truly capture causal strength versus detecting spurious statistical dependencies
- Self-training procedure introduces additional uncertainty as pseudo-label quality depends heavily on initial classifier and constraint design
- Evaluation relies on correlations with human judgments, which themselves can be noisy and subjective for open-domain dialogue relevance assessment

## Confidence

- **High confidence**: CausalScore's superior correlation with human judgments compared to baselines, supported by multiple correlation metrics across three datasets
- **Medium confidence**: The effectiveness of self-training with constraints, as the specific implementation details and stopping criteria are not fully specified
- **Medium confidence**: The claim that pairwise preferences reduce annotation bias, as this relies on prior literature and moderate inter-annotator agreement (Krippendorff's alpha of 0.6708)

## Next Checks

1. Conduct ablation studies to quantify the contribution of the unconditional classifier step versus using only conditional dependence probabilities
2. Test domain generalization by training CausalScore on one dataset and evaluating on a held-out dataset from a different source
3. Compare CausalScore's performance against a causal inference baseline using Granger causality or other established causal discovery methods for dialogue systems