---
ver: rpa2
title: 'Retrospective Comparative Analysis of Prostate Cancer In-Basket Messages:
  Responses from Closed-Domain LLM vs. Clinical Teams'
arxiv_id: '2409.18290'
source_url: https://arxiv.org/abs/2409.18290
tags:
- responses
- radonc-gpt
- care
- patient
- team
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RadOnc-GPT, a GPT-4-powered large language model specialized for
  prostate cancer radiotherapy, was integrated with hospital and radiation oncology
  databases to assist in drafting responses to in-basket messages. In a retrospective
  study of 158 patient-clinician message pairs, RadOnc-GPT responses were evaluated
  using natural language processing and clinician/nurse grading.
---

# Retrospective Comparative Analysis of Prostate Cancer In-Basket Messages: Responses from Closed-Domain LLM vs. Clinical Teams

## Quick Facts
- arXiv ID: 2409.18290
- Source URL: https://arxiv.org/abs/2409.18290
- Reference count: 40
- RadOnc-GPT achieves comparable or slightly better response quality than human care teams while saving clinicians 2.4 minutes per message

## Executive Summary
This study evaluates RadOnc-GPT, a GPT-4o-powered LLM specialized for prostate cancer radiotherapy, against human care teams for in-basket message responses. In a retrospective analysis of 158 patient-clinician message pairs, RadOnc-GPT responses were assessed using NLP metrics and blinded clinical grading. The system achieved comparable or slightly better scores than human teams in clarity and empathy, with high semantic similarity to human responses. Nurses estimated 5.2 minutes saved per message, and clinicians 2.4 minutes, demonstrating workflow efficiency improvements. While results are promising, human oversight remains necessary for deployment.

## Method Summary
The study employed a retrospective comparative design using 158 previously recorded in-basket message interactions from prostate cancer patients. RadOnc-GPT, integrated with hospital EHR (Epic) and radiation oncology database (Aria), generated responses to patient inquiries. The 316 responses (158 human + 158 AI) were randomized and blinded for evaluation. Clinical teams and nurses graded responses on Completeness, Correctness, Clarity, and Empathy using a structured rubric. NLP quantitative analysis (sentiment, semantic similarity, readability) complemented the clinical grading. Time savings were estimated through workflow modeling from inquiry reading to response delivery.

## Key Results
- RadOnc-GPT achieved comparable or slightly better scores than human care teams in clarity and empathy
- High semantic similarity between AI and human responses across multiple NLP metrics
- Estimated time savings of 5.2 minutes per message for nurses and 2.4 minutes for clinicians
- Overall response quality maintained with potential for significant workflow efficiency improvements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RadOnc-GPT achieves comparable or slightly better response quality by leveraging specialized EHR integration and domain-focused prompt engineering
- Mechanism: The system retrieves patient-specific clinical context (treatment details, diagnosis, clinical notes) and uses tailored prompts that simulate attending physician behavior, resulting in more comprehensive and empathetic responses than generic LLM approaches
- Core assumption: Specialized prompts and EHR context retrieval can compensate for the lack of real-time clinical judgment
- Evidence anchors:
  - [abstract] "RadOnc-GPT, a specialized Large Language Model (LLM) powered by GPT-4 that has been designed with a focus on radiotherapeutic treatment of prostate cancer with advanced prompt engineering"
  - [section] "We developed RadOnc-GPT, an OpenAI GPT-4o-powered LLM, which is integrated with EHR... RadOnc-GPT can generate more personalized responses with greater details in a zero-shot without training"
- Break condition: If the retrieved EHR data is incomplete or contains errors, the generated responses may propagate incorrect information

### Mechanism 2
- Claim: The evaluation methodology provides robust comparison between AI and human responses through multiple validation layers
- Mechanism: Combining NLP quantitative analysis (sentiment, semantic similarity, readability) with blinded clinical grading creates a comprehensive assessment framework that captures both technical and clinical quality dimensions
- Core assumption: Multiple evaluation methods reduce individual bias and provide a more complete picture of response quality
- Evidence anchors:
  - [section] "Our study's evaluation was divided into two main components: natural language processing (NLP) quantitative assessments and clinical professional grading"
  - [section] "For the grading study, we focused on six dimensions of evaluation: completeness, correctness, clarity, empathy, estimated time to respond, and extensive editing required"
- Break condition: If graders have inconsistent standards or the NLP metrics don't align with clinical effectiveness, the evaluation may not accurately reflect real-world utility

### Mechanism 3
- Claim: Time savings estimates are based on realistic workflow modeling that accounts for both direct response generation and review processes
- Mechanism: The study models the complete workflow from reading patient inquiry to sending response, including time for nurses to research and determine referral needs, providing realistic efficiency estimates
- Core assumption: The estimated time savings translate directly to clinical productivity gains and cost reductions
- Evidence anchors:
  - [abstract] "RadOnc-GPT is estimated to save 5.2 minutes per message for nurses and 2.4 minutes for clinicians, from reading the inquiry to sending the response"
  - [section] "Based on our estimation, using RadOnc-GPT to assist in in-basket messages generation... RadOnc-GPT could save approximately 5.2 minutes per message for nurses and 2.41 minutes for clinicians"
- Break condition: If clinicians spend additional time verifying AI-generated content or if the quality requires significant editing, the time savings may be overstated

## Foundational Learning

- Concept: Natural Language Processing evaluation metrics (sentiment analysis, semantic similarity, readability scores)
  - Why needed here: The study uses multiple NLP metrics to quantitatively compare AI and human responses across different quality dimensions
  - Quick check question: What does a semantic similarity score of 0.85 between AI and human responses indicate about their content alignment?

- Concept: Clinical grading rubric design and inter-rater reliability
  - Why needed here: The study employs a structured grading system with multiple clinicians and nurses to evaluate response quality across dimensions like completeness, correctness, clarity, and empathy
  - Quick check question: Why is it important that the study reports ICC (interclass correlation coefficient) values for the grading results?

- Concept: Electronic Health Record (EHR) data integration and retrieval patterns
  - Why needed here: RadOnc-GPT's effectiveness depends on its ability to access and integrate relevant patient information from multiple sources (Epic, Aria)
  - Quick check question: What types of patient data does RadOnc-GPT retrieve from the EHR systems to generate informed responses?

## Architecture Onboarding

- Component map: Patient message -> EHR data retrieval -> GPT-4o LLM with specialized prompts -> Response draft -> Clinician review -> Response delivery
- Critical path: Patient message → EHR data retrieval → LLM response generation → Clinician review/editing → Response delivery
- Design tradeoffs:
  - Specialization vs. generalization: Focused on prostate cancer radiotherapy vs. broader medical applications
  - Automation vs. oversight: AI-generated drafts require human review to ensure accuracy and appropriateness
  - Complexity vs. usability: Comprehensive data retrieval vs. system performance and response time
- Failure signatures:
  - Incomplete or incorrect EHR data retrieval leading to inaccurate responses
  - LLM generating overly generic or contextually inappropriate responses
  - Clinical graders showing high variability in evaluation standards
  - System performance issues when handling high message volumes

- First 3 experiments:
  1. Test the EHR data retrieval system with different patient IDs to verify complete and accurate information extraction
  2. Evaluate response quality with different prompt variations to optimize for clinical accuracy and empathy
  3. Conduct a pilot study with actual clinical staff to assess workflow integration and identify practical limitations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal balance between LLM-generated and human oversight in in-basket message responses?
- Basis in paper: [inferred] The paper shows RadOnc-GPT performs comparably to human care teams but emphasizes caution before deployment without human oversight.
- Why unresolved: The study is retrospective and doesn't explore real-world implementation with varying levels of human oversight.
- What evidence would resolve it: A prospective randomized controlled trial comparing different levels of human oversight (full human review, partial review, no review) on response quality metrics and clinical outcomes.

### Open Question 2
- Question: How generalizable are the results to other cancer types and medical specialties?
- Basis in paper: [explicit] The study focused specifically on prostate cancer radiotherapy and acknowledges results may not generalize to other LLMs or medical domains.
- Why unresolved: The evaluation was limited to one disease site and one LLM model (GPT-4o).
- What evidence would resolve it: Replication of the study across multiple cancer types, medical specialties, and different LLM models to establish generalizability.

### Open Question 3
- Question: What is the impact of LLM-assisted responses on long-term patient outcomes and healthcare costs?
- Basis in paper: [inferred] The paper estimates significant time savings and potential cost reduction but doesn't examine long-term patient outcomes or actual healthcare utilization changes.
- Why unresolved: The study is cross-sectional and doesn't track patient outcomes or healthcare system metrics over time.
- What evidence would resolve it: Longitudinal studies tracking patient satisfaction, health outcomes, follow-up visits, and healthcare costs before and after implementing LLM-assisted responses.

## Limitations
- Retrospective study design at single institution limits external validity
- Sample size of 158 message pairs may not capture full diversity of clinical scenarios
- Does not address long-term impacts on patient outcomes or healthcare costs

## Confidence

**High Confidence**: The NLP quantitative metrics and clinical grading methodology are well-documented and appropriately applied. The time savings estimates are based on explicit workflow modeling.

**Medium Confidence**: The comparative performance results are credible but may be influenced by selection bias in the retrospective sample. The clinical grading, while blinded, involves a limited number of evaluators.

**Medium Confidence**: The integration mechanism with EHR systems is described but implementation details remain partially unspecified, affecting reproducibility.

## Next Checks

1. Conduct a prospective, multi-center trial with diverse clinical settings to validate external generalizability of the time savings and quality metrics.
2. Implement a longitudinal study tracking patient satisfaction and clinical outcomes following AI-assisted responses versus traditional care team responses.
3. Perform a detailed workflow analysis with actual clinical staff to measure real-world integration challenges and identify potential bottlenecks in the review process.