---
ver: rpa2
title: 'Enhancing Taobao Display Advertising with Multimodal Representations: Challenges,
  Approaches and Insights'
arxiv_id: '2407.19467'
source_url: https://arxiv.org/abs/2407.19467
tags:
- multimodal
- representations
- pre-training
- item
- recommendation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Taobao's advertising system traditionally relied on sparse ID\
  \ features, limiting its ability to capture semantic information from multimodal\
  \ data such as images and text. To overcome this, the authors introduced a two-phase\
  \ framework: (1) pre-training multimodal representations using semantic-aware contrastive\
  \ learning (SCL), which leverages user search queries and purchase actions to construct\
  \ semantically similar sample pairs, and (2) integrating these representations into\
  \ existing ID-based models using two approaches\u2014SimTier, which simplifies multimodal\
  \ data into similarity tiers, and Multimodal Knowledge Extractor (MAKE), which enables\
  \ multi-epoch training to address training epoch discrepancies."
---

# Enhancing Taobao Display Advertising with Multimodal Representations: Challenges, Approaches and Insights

## Quick Facts
- **arXiv ID:** 2407.19467
- **Source URL:** https://arxiv.org/abs/2407.19467
- **Reference count:** 40
- **Primary result:** Achieved 3.5% CTR, 1.5% RPM, and 2.9% ROI improvements system-wide through multimodal representations

## Executive Summary
Taobao's advertising system traditionally relied on sparse ID features, limiting its ability to capture semantic information from multimodal data such as images and text. To overcome this, the authors introduced a two-phase framework: (1) pre-training multimodal representations using semantic-aware contrastive learning (SCL), which leverages user search queries and purchase actions to construct semantically similar sample pairs, and (2) integrating these representations into existing ID-based models using two approachesâ€”SimTier, which simplifies multimodal data into similarity tiers, and Multimodal Knowledge Extractor (MAKE), which enables multi-epoch training to address training epoch discrepancies. The system was deployed in mid-2023, achieving significant performance improvements, including a 3.5% increase in CTR, 1.5% in RPM, and 2.9% in ROI system-wide, with even greater gains for new advertisements (6.9% CTR, 3.7% RPM, 7.7% ROI). The approach also effectively mitigated cold-start issues and improved performance on infrequent items.

## Method Summary
The authors developed a two-phase framework for enhancing Taobao's advertising system with multimodal representations. First, they pre-trained multimodal representations using semantic-aware contrastive learning (SCL), which constructs semantically similar sample pairs based on user search queries and purchase actions. Second, they integrated these representations into existing ID-based models using two approaches: SimTier, which simplifies multimodal data into similarity tiers, and Multimodal Knowledge Extractor (MAKE), which enables multi-epoch training to address training epoch discrepancies. This approach effectively captured semantic information from multimodal data, overcoming the limitations of sparse ID features and improving performance across various advertising scenarios, particularly for new advertisements and infrequent items.

## Key Results
- Achieved 3.5% increase in CTR, 1.5% in RPM, and 2.9% in ROI system-wide
- New advertisements showed even greater improvements: 6.9% CTR, 3.7% RPM, and 7.7% ROI
- Effectively mitigated cold-start issues and improved performance on infrequent items

## Why This Works (Mechanism)
The system works by first capturing rich semantic information from multimodal data (images and text) through semantic-aware contrastive learning, which uses user search queries and purchase actions to create semantically similar sample pairs. This pre-trained representation is then integrated into existing ID-based models through two complementary approaches: SimTier simplifies multimodal data into similarity tiers for efficient processing, while MAKE enables multi-epoch training to handle the training epoch discrepancies between multimodal and ID-based features. This dual integration strategy allows the system to leverage both the semantic richness of multimodal data and the efficiency of ID-based features, resulting in significant performance improvements across various advertising scenarios.

## Foundational Learning
- **Semantic-aware contrastive learning (SCL)**: Creates semantically similar sample pairs using user search queries and purchase actions to capture rich semantic information from multimodal data
- **Why needed**: Traditional ID-based features lack the ability to capture semantic relationships between items, limiting advertising effectiveness
- **Quick check**: Verify that SCL-generated pairs truly represent semantically similar items through manual inspection or user studies

- **SimTier integration**: Simplifies multimodal data into similarity tiers for efficient processing within existing ID-based models
- **Why needed**: Direct integration of complex multimodal features can be computationally expensive and may not align well with existing model architectures
- **Quick check**: Measure computational overhead and ensure tier assignments correlate with actual semantic similarity

- **MAKE (Multi-epoch training)**: Enables multi-epoch training to address training epoch discrepancies between multimodal and ID-based features
- **Why needed**: Multimodal and ID-based features often require different numbers of training epochs for optimal performance
- **Quick check**: Validate that multi-epoch training converges to better performance than single-epoch training

## Architecture Onboarding

### Component Map
User Behavior Data -> SCL Pre-training -> Multimodal Representations -> SimTier/MAKE Integration -> Enhanced ID-based Model -> Performance Metrics

### Critical Path
The critical path involves SCL pre-training to generate multimodal representations, followed by integration through either SimTier or MAKE, and finally feeding these enhanced features into the existing ID-based model for inference and performance measurement.

### Design Tradeoffs
The authors balanced computational efficiency (through SimTier's tier-based simplification) against representation richness (through MAKE's multi-epoch training). SimTier offers faster processing but may lose some fine-grained semantic information, while MAKE preserves more detail but requires more computational resources. The dual approach allows flexibility based on deployment constraints.

### Failure Signatures
Performance degradation would likely manifest as reduced CTR, RPM, and ROI improvements, particularly for new advertisements and infrequent items. Integration failures might show as inconsistent tier assignments in SimTier or training instability in MAKE. The semantic-aware contrastive learning could fail if user behavior data is insufficient or noisy.

### Exactly 3 First Experiments
1. Validate SCL pre-training by measuring semantic similarity between generated representations and human-annotated item relationships
2. Compare SimTier tier assignments against ground truth semantic similarity to ensure tier-based simplification preserves meaningful distinctions
3. Test MAKE's multi-epoch training by comparing convergence curves with single-epoch training on a small sample of multimodal and ID-based features

## Open Questions the Paper Calls Out
None

## Limitations
- Primary focus on internal Taobao metrics without external validation or comparison to established multimodal advertising benchmarks
- Lack of detailed ablation studies showing the relative contribution of different multimodal signals (images vs. text) to performance gains
- No clear delineation of when to prefer SimTier over MAKE in practical deployment scenarios

## Confidence

**High confidence:** Technical implementation of multimodal representation framework and observed system-wide improvements in CTR, RPM, and ROI metrics

**Medium confidence:** Claimed superiority over traditional ID-based approaches due to lack of direct comparative experiments with other multimodal advertising systems

**Low confidence:** Generalizability of semantic-aware contrastive learning methodology to other e-commerce platforms with different user behavior patterns

## Next Checks
1. Conduct A/B testing comparing the multimodal approach against other state-of-the-art multimodal advertising systems (e.g., MOON Embedding) using standardized benchmark datasets to validate performance claims beyond internal metrics

2. Perform ablation studies isolating the contribution of each multimodal signal (images, text, user queries) to quantify their relative importance in driving the observed performance improvements

3. Test the framework's robustness by deploying it in different market segments or product categories within Taobao to assess its effectiveness across diverse advertising contexts and user demographics