---
ver: rpa2
title: Classification Under Strategic Self-Selection
arxiv_id: '2402.15274'
source_url: https://arxiv.org/abs/2402.15274
tags: []
core_contribution: This paper studies the problem of classification under strategic
  self-selection, where agents choose whether to participate in a screening process
  based on the learned classifier. The key idea is to model application decisions
  as a function of the classifier's conditional precision, and then optimize the classifier
  to maximize accuracy on the induced applicant population.
---

# Classification Under Strategic Self-Selection

## Quick Facts
- arXiv ID: 2402.15274
- Source URL: https://arxiv.org/abs/2402.15274
- Authors: Guy Horowitz; Yonatan Sommer; Moran Koren; Nir Rosenfeld
- Reference count: 40
- Primary result: A differentiable framework that models strategic self-selection enables learning classifiers that outperform naïve approaches by optimizing for accuracy on the induced applicant population

## Executive Summary
This paper addresses classification under strategic self-selection, where agents decide whether to participate in screening based on beliefs about the classifier's precision. The authors propose a differentiable optimization framework that replaces discrete application decisions with continuous surrogate variables, enabling effective gradient-based learning. Their approach accounts for the fact that application choices shape the test-time distribution, making standard i.i.d. assumptions invalid. Experiments demonstrate that the proposed method can effectively learn classifiers that account for self-selective behavior, with strategic variants showing improved accuracy over naïve approaches.

## Method Summary
The authors propose a differentiable framework for learning under strategic self-selection by replacing discrete application decisions with continuous surrogate variables. The method jointly optimizes classifier parameters and application decisions using a precision proxy that approximates conditional precision metrics. They employ a sigmoid-based smoothing function to approximate discrete application decisions, making the optimization differentiable. The framework supports statistical parity constraints and includes regularization terms to ensure numerical stability. Training involves optimizing a strategic learning objective that accounts for the induced applicant population distribution.

## Key Results
- Strategic learning variants consistently outperform naïve approaches across datasets, with accuracy improvements ranging from 1-4% on test sets
- The proposed differentiable framework effectively models self-selection behavior, enabling gradient-based optimization of strategic objectives
- Statistical parity constraints limit the firm's ability to control applications by inducing an ordering based on base rates

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Strategic self-selection enables a firm to shape the applicant population by controlling the classifier's precision.
- **Mechanism**: The classifier determines conditional precision metrics which candidates use to decide whether to apply. By optimizing for precision in specific groups, the firm can selectively enable or disable applications from those groups.
- **Core assumption**: Candidates are rational decision-makers who apply only when expected utility from passing screening exceeds associated costs.
- **Evidence anchors**:
  - [abstract] "application choices derive from beliefs regarding classification outcomes"
  - [section] "Since these choices in aggregate determine the test-time distribution, learning becomes susceptible to self-selection"
  - [corpus] Weak - no direct corpus evidence found
- **Break condition**: If candidates have private information not captured by published precision metrics, or if application decisions are driven by non-rational factors.

### Mechanism 2
- **Claim**: Learning under self-selection requires differentiable optimization because application decisions depend on the classifier being optimized.
- **Mechanism**: The authors replace discrete application decisions with continuous surrogate variables that are differentiable in the classifier parameters. This allows gradient descent optimization while accounting for strategic self-selection.
- **Core assumption**: A smooth sigmoid function can effectively approximate the discrete application decision threshold.
- **Evidence anchors**:
  - [section] "Our solution, which jointly addresses both problems, is to replace ai ∈ {0, 1} with a continuous surrogate âi ∈ [0, 1]"
  - [section] "The challenge is therefore to account for the dependence of application decisions a* on the classifier f being optimized"
  - [corpus] Weak - no direct corpus evidence found
- **Break condition**: If the sigmoid approximation introduces significant bias in the precision proxy, making the optimization ineffective.

### Mechanism 3
- **Claim**: Statistical parity constraints limit the firm's power to control applications by forcing compliance with a natural ordering based on base rates.
- **Mechanism**: When enforcing independence between predictions and group membership, applications must follow an ordering based on decreasing base rates (μz). This prevents the firm from arbitrarily blocking groups from applying.
- **Core assumption**: The firm can enforce statistical parity constraints during training.
- **Evidence anchors**:
  - [section] "To restrict this power, one idea is to simply remove z from the set of features"
  - [section] "Our next result shows that statistical parity limits the power of strategic learning in a particular way—by inducing an ordering over group applications"
  - [corpus] Weak - no direct corpus evidence found
- **Break condition**: If the statistical parity constraint cannot be effectively enforced in practice, or if the firm finds ways to circumvent it.

## Foundational Learning

- **Concept**: Strategic classification with feature modification
  - **Why needed here**: Provides context for why strategic classification literature is relevant, even though this paper studies a different type of strategic action (self-selection vs. feature modification)
  - **Quick check question**: What distinguishes self-selection from feature modification in strategic classification?

- **Concept**: Decision-dependent distribution shift
  - **Why needed here**: The target distribution changes based on the classifier itself, making standard i.i.d. assumptions invalid
  - **Quick check question**: How does the distribution pf differ from the original distribution p in this setting?

- **Concept**: Calibration in machine learning
  - **Why needed here**: The paper discusses calibrated score functions, which are weaker than standard calibration but still important for understanding how thresholds affect applications
  - **Quick check question**: What is the relationship between score function calibration and the monotonicity of precision?

## Architecture Onboarding

- **Component map**:
  Data preprocessing pipeline -> Classifier training module -> Strategic optimization module -> Evaluation framework

- **Critical path**:
  1. Preprocess data and create one-hot encodings for categorical features
  2. Train initial naive classifier using standard logistic regression
  3. Implement differentiable precision proxy with corrective term
  4. Implement sigmoid-based application surrogate
  5. Optimize strategic learning objective with regularization
  6. Evaluate on test set and measure induced accuracy

- **Design tradeoffs**:
  - Using linear classifiers for simplicity vs. more complex models that might better capture relationships
  - Adding regularization for statistical parity vs. potentially reduced predictive performance
  - Using continuous approximations for discrete decisions vs. potential bias introduction

- **Failure signatures**:
  - Optimization getting stuck in local minima due to non-convexity
  - Precision proxy becoming numerically unstable
  - No applications occurring in some groups despite apparent opportunity

- **First 3 experiments**:
  1. Compare naive vs. strategic learning on adult dataset with c=0.7
  2. Test effect of removing group features (stratx\z) on bank dataset
  3. Validate statistical parity enforcement by checking application ordering matches base rate ordering

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How robust is the proposed differentiable framework to different assumptions about user behavior and beliefs?
- **Basis in paper**: [explicit] The paper mentions that the approach assumes rationality and certain beliefs, but does not explore robustness to violations of these assumptions.
- **Why unresolved**: The experiments focus on the case where beliefs are based on precision metrics, but do not explore how the framework performs when users have different or more complex beliefs.
- **What evidence would resolve it**: Experiments comparing the framework's performance under different user behavior models and belief structures.

### Open Question 2
- **Question**: What are the long-term effects of strategic learning on the composition and quality of the applicant population?
- **Basis in paper**: [inferred] The paper discusses how learning can shape the applicant population, but does not explore long-term dynamics or potential feedback loops.
- **Why unresolved**: The experiments focus on a single round of learning and application, without considering how the population might evolve over time.
- **What evidence would resolve it**: Simulations or experiments tracking the evolution of the applicant population over multiple rounds of learning and application.

### Open Question 3
- **Question**: How does the proposed framework scale to large datasets and complex model architectures?
- **Basis in paper**: [explicit] The experiments use relatively small datasets and linear classifiers, but do not explore scalability to larger and more complex settings.
- **Why unresolved**: The framework relies on differentiable approximations and regularizations, which may become computationally challenging for large-scale problems.
- **What evidence would resolve it**: Experiments evaluating the framework's performance and computational efficiency on larger datasets and more complex model architectures.

## Limitations

- Empirical evaluation relies on only two real-world datasets (adult and bank), limiting generalizability
- Results show modest accuracy improvements (1-4%) that vary across datasets
- Analysis of statistical parity constraints is primarily theoretical with limited empirical validation of real-world deployment scenarios

## Confidence

**High**: The theoretical framework for modeling strategic self-selection is sound and mathematically rigorous
**Medium**: The differentiable optimization approach works in practice, though hyperparameter sensitivity wasn't extensively explored
**Low**: Claims about statistical parity constraints meaningfully limiting strategic control need more empirical validation

## Next Checks

1. Test the framework on additional diverse datasets to assess robustness and generalizability
2. Conduct ablation studies varying the sigmoid temperature parameter and regularization strength
3. Measure actual fairness impacts beyond statistical parity (e.g., demographic parity, equalized odds)