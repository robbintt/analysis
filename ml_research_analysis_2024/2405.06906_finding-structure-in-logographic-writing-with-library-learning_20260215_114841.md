---
ver: rpa2
title: Finding structure in logographic writing with library learning
arxiv_id: '2405.06906'
source_url: https://arxiv.org/abs/2405.06906
tags:
- library
- chinese
- writing
- system
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a library learning framework to discover and
  analyze structural patterns in logographic writing systems, particularly Chinese.
  The method uses iterative program synthesis to identify reusable graphical components
  and build hierarchical abstractions that compress the writing system's description
  length.
---

# Finding structure in logographic writing with library learning

## Quick Facts
- arXiv ID: 2405.06906
- Source URL: https://arxiv.org/abs/2405.06906
- Reference count: 14
- This paper proposes a library learning framework to discover and analyze structural patterns in logographic writing systems, particularly Chinese.

## Executive Summary
This paper introduces a computational framework that applies library learning to analyze structural patterns in logographic writing systems, with a focus on Chinese characters. The approach uses iterative program synthesis to identify reusable graphical components and build hierarchical abstractions that compress the writing system's description length. By treating characters as stroke sequences and discovering reusable patterns, the model rediscovers known linguistic structures like radicals and provides insights into how human inductive biases toward representational efficiency shape the evolution of combinatorial structures in writing systems.

## Method Summary
The method uses Stitch, a library learning algorithm, to iteratively discover reusable graphical components from Chinese character stroke sequences. Characters are represented as LISP-style programs using 33 stroke primitives plus a list symbol. The algorithm performs top-down searches to identify maximally reusable parts, adds them as library functions, and rewrites characters using these abstractions. The framework optimizes description length by balancing character compression against library size overhead using a λ-calculus-based cost function. The optimal library L* is found by minimizing the total description length DLL(W) = DL(W|L) + DL(L).

## Key Results
- The model rediscovers known linguistic structures like radicals with 93% accuracy
- Traditional Chinese shows higher compression ratios than simplified Chinese, indicating greater systematicity
- Chinese writing systems have become simpler over time in terms of program complexity
- 77.3% of learned library functions were hierarchically defined in simplified Chinese analysis

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Library learning compresses writing systems by discovering reusable graphical components (like radicals) and their hierarchical relations
- Mechanism: Stitch algorithm iteratively identifies maximally reusable parts from character stroke sequences, adds them as library functions, and rewrites characters using these abstractions, reducing overall description length
- Core assumption: The base DSL can uniquely encode every character as a stroke sequence with canonical orderings
- Evidence anchors:
  - [abstract] "Built on top of state-of-the-art library learning and program synthesis techniques, our computational framework discovers known linguistic structures in the Chinese writing system"
  - [section] "Stitch algorithm (Bowers et al., 2023) for efficiently discovering library functions... making it tractable for us to examine the entire writing system"

### Mechanism 2
- Claim: MDL-based compression captures human inductive biases toward representational efficiency in language evolution
- Mechanism: The optimal library minimizes description length by balancing character compression against library size overhead, reflecting efficiency pressures that shape combinatorial structures
- Core assumption: Human cognitive systems favor representations that minimize description length
- Evidence anchors:
  - [abstract] "explore the idea that combinatoriality in language reflects a human inductive bias toward representational efficiency"
  - [section] "We define the description length DLL (W) of a writing system W under a specific library L... C(W) = minL DLL (W)"

### Mechanism 3
- Claim: Compression ratio serves as a proxy for systematicity in writing systems
- Mechanism: More systematic writing systems (with more reusable patterns) achieve higher compression ratios; comparing traditional vs simplified Chinese shows systematicity differences
- Core assumption: Systematic patterns enable greater compression through reuse
- Evidence anchors:
  - [section] "From the MDL perspective, systematic-patterned data should be more compressive. Therefore, the compression ratio can be viewed as a proxy for the systematicity"
  - [section] "traditional Chinese yielded a higher compression rate than the simplified Chinese, suggesting the simplification process... did break part of the systematicity"

## Foundational Learning

- Concept: Domain-Specific Language (DSL) for stroke primitives
  - Why needed here: Provides formal representation of Chinese characters as stroke sequences that library learning can process
  - Quick check question: How many stroke primitives are used in the base DSL and what do they represent?

- Concept: Minimum Description Length (MDL) principle
  - Why needed here: Formalizes the tradeoff between character compression and library overhead to identify optimal representations
  - Quick check question: What two components make up the total description length in the MDL framework?

- Concept: Hierarchical decomposition of graphical elements
  - Why needed here: Captures how radicals and components are recursively composed from smaller parts
  - Quick check question: What percentage of learned library functions were hierarchically defined in the simplified Chinese analysis?

## Architecture Onboarding

- Component map: Character programs (stroke sequences) -> Stitch algorithm -> Library function discovery -> Character rewriting -> Compression evaluation
- Critical path: Stroke sequence → Stitch iteration → Library function discovery → Character rewriting → Compression evaluation
- Design tradeoffs:
  - Base DSL size vs expressiveness: 33 primitives chosen for modern Chinese characters
  - Speed vs completeness: Stitch is 3 orders of magnitude faster than DreamCoder but may miss some patterns
  - Hierarchical vs flat decomposition: Hierarchical functions capture more structure but increase complexity
- Failure signatures:
  - Low compression ratios despite many iterations
  - Library functions that don't align with known radicals
  - High description length in base DSL indicates poor stroke encoding
- First 3 experiments:
  1. Run library learning on a small toy writing system (3-5 characters) and verify it discovers expected components
  2. Test compression on oracle bone vs simplified Chinese and check if results match expected simplification trend
  3. Compare compression ratios of traditional vs simplified Chinese on aligned character pairs to verify systematicity difference

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the library learning framework be extended to analyze other writing systems beyond Chinese, such as alphabetic scripts or syllabaries?
- Basis in paper: [explicit] The authors discuss applying their model to Chinese but suggest future work could analyze broader form-meaning mappings and other writing systems.
- Why unresolved: The paper focuses solely on Chinese characters and does not demonstrate the framework's applicability to other writing systems or provide evidence of its effectiveness in those contexts.
- What evidence would resolve it: Testing the library learning framework on diverse writing systems like Arabic, Japanese kana, or Egyptian hieroglyphs, and comparing the discovered structures to known linguistic analyses.

### Open Question 2
- Question: How do individual character recognition and learning behaviors differ between traditional and simplified Chinese scripts?
- Basis in paper: [explicit] The authors mention that the simplification process may have disrupted systematicity and could contribute to recognition and learning behavior differences.
- Why unresolved: While the paper provides evidence of systematicity differences between traditional and simplified Chinese, it does not directly investigate how these differences impact character recognition or learning outcomes.
- What evidence would resolve it: Conducting psycholinguistic experiments comparing character recognition accuracy, reading speed, and learning efficiency between traditional and simplified Chinese readers.

### Open Question 3
- Question: Can the library learning framework be used to predict future evolution trends in writing systems?
- Basis in paper: [explicit] The authors analyze historical changes in Chinese scripts and suggest that their framework could provide insights into the evolution of efficient communication systems.
- Why unresolved: The paper focuses on analyzing past changes in Chinese writing systems but does not explore the framework's potential for predicting future evolutionary trends in writing systems.
- What evidence would resolve it: Applying the library learning framework to contemporary writing systems and using the discovered structures to make predictions about future changes, then validating these predictions against actual developments over time.

## Limitations
- The Stitch algorithm's implementation details remain underspecified, particularly regarding stopping criteria for iterative library growth
- The description length measure DL(·) depends on λ-calculus-based cost functions that aren't fully detailed
- The corpus analysis comparing different Chinese scripts relies on aligned character subsets (754 per script) that may not be representative

## Confidence

- **High Confidence**: The model's ability to rediscover known radicals (93% F1) and the general finding that traditional Chinese shows higher compression ratios than simplified Chinese
- **Medium Confidence**: The claim that compression ratio serves as a valid proxy for systematicity, as this requires additional validation beyond the paper's evidence
- **Low Confidence**: The broader claim about efficiency pressures shaping the evolution of all combinatorial structures in writing systems, as this extrapolates from Chinese to general linguistic theory

## Next Checks

1. **Replication Test**: Implement Stitch from the paper's description and verify it discovers at least 80% of known radicals on the MoE dataset, documenting any implementation decisions that required specification.

2. **Cross-Script Validation**: Apply the compression analysis to an additional logographic system (e.g., Egyptian hieroglyphs from the LogogramNLP corpus) to test whether systematicity-proxy claims hold across different writing traditions.

3. **Component Distribution Analysis**: Verify that the proportion of hierarchical vs flat library functions (reported as 77.3% hierarchical for simplified Chinese) remains consistent when the model is trained on progressively larger character subsets to test for convergence properties.