---
ver: rpa2
title: A Novel Pseudo Nearest Neighbor Classification Method Using Local Harmonic
  Mean Distance
arxiv_id: '2405.06238'
source_url: https://arxiv.org/abs/2405.06238
tags: []
core_contribution: The paper introduces the LMPHNN (Novel Pseudo Nearest Neighbor
  Classification Method Using Local Harmonic Mean Distance) classifier to address
  the sensitivity of the K value in KNN algorithms, especially for small sample sizes
  and outliers. LMPHNN combines the local mean vector approach of LMPNN with the harmonic
  mean distance (HMD) metric from LMKHNN.
---

# A Novel Pseudo Nearest Neighbor Classification Method Using Local Harmonic Mean Distance

## Quick Facts
- arXiv ID: 2405.06238
- Source URL: https://arxiv.org/abs/2405.06238
- Authors: Junzhuo Chen; Zhixin Lu; Shitong Kang
- Reference count: 28
- LMPHNN achieves average precision of 97%, recall of 80%, and F1 score of 0.7832

## Executive Summary
This paper introduces the LMPHNN classifier to address the sensitivity of the K value in KNN algorithms, especially for small sample sizes and outliers. LMPHNN combines the local mean vector approach of LMPNN with the harmonic mean distance (HMD) metric from LMKHNN. The method generates pseudo nearest neighbors (PNNs) by comparing the HMD of the query sample with local mean vectors across different classes. Extensive experiments on 9 UCI and Kaggle datasets demonstrate that LMPHNN significantly outperforms seven other KNN-based classifiers while being less sensitive to the K parameter.

## Method Summary
LMPHNN uses harmonic mean distance (HMD) as a distance metric combined with local mean vectors approach. For each class, it finds k nearest neighbors, computes local mean vectors (LMVs) for the first j nearest neighbors (j â‰¤ k), and calculates HMD between query sample and multiple LMVs. The classifier then assigns weights to LMVs and combines them via harmonic mean to generate pseudo nearest neighbors (PNNs). Classification is performed by selecting the class with minimum combined harmonic distance. The method was tested on 9 datasets with 1:1 train-test split and K values ranging from 2 to 10.

## Key Results
- LMPHNN achieves average precision of 97%, recall of 80%, and F1 score of 0.7832
- Significantly outperforms seven other KNN-based classifiers across all performance metrics
- Demonstrates improved robustness and lower sensitivity to the K value parameter
- Shows consistent performance across datasets ranging from 178 to 10,000 samples

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LMPHNN improves KNN robustness by replacing Euclidean distance with harmonic mean distance (HMD) for pseudo nearest neighbor generation
- Mechanism: HMD reduces sensitivity to k by weighting neighbors according to their relative proximity and diminishing the influence of distant points, thereby mitigating noise and outlier effects
- Core assumption: Harmonic mean better captures local similarity than arithmetic mean or Euclidean distance when k is variable
- Evidence anchors: Weak; no direct citations of HMD in neighbor papers

### Mechanism 2
- Claim: LMPHNN constructs pseudo nearest neighbors (PNNs) using weighted local mean vectors rather than raw neighbor points
- Mechanism: By averaging over k neighbors per class to form local mean vectors, the method smooths class boundaries and reduces variance introduced by outliers
- Core assumption: Local means are more representative of class prototypes than individual neighbors
- Evidence anchors: Weak; neighbor papers focus on clustering, not PNN generation

### Mechanism 3
- Claim: LMPHNN allows class-specific k values implicitly via harmonic mean weighting rather than a single global k
- Mechanism: By weighting each local mean according to its harmonic distance, the method adapts influence per class without changing k explicitly
- Core assumption: Different classes may have different optimal neighborhood sizes; implicit weighting approximates this
- Evidence anchors: Missing; no direct evidence in neighbor papers

## Foundational Learning

- Concept: Harmonic Mean Distance (HMD)
  - Why needed here: HMD provides a distance metric that is less sensitive to outliers and varying k values than Euclidean distance
  - Quick check question: How does harmonic mean differ from arithmetic mean when one distance is much larger than others?

- Concept: Local Mean Vector (LMV)
  - Why needed here: LMVs summarize local neighborhoods to form more stable class prototypes, reducing noise influence
  - Quick check question: Why might averaging over k neighbors reduce variance compared to using single nearest neighbor?

- Concept: Pseudo Nearest Neighbor (PNN)
  - Why needed here: PNNs replace raw neighbors with class-representative prototypes, improving classification robustness
  - Quick check question: What advantage does a PNN have over a true nearest neighbor when classes overlap?

## Architecture Onboarding

- Component map: Data ingestion -> Neighborhood search (kNN) -> Local mean vector computation -> Harmonic mean distance calculation -> Weighted PNN assignment -> Classification output
- Critical path: 1) For each class, find k nearest neighbors to query; 2) Compute local mean vectors for each subset of neighbors; 3) Calculate harmonic mean distances between query and each LMV set; 4) Assign weights to LMVs and combine via harmonic mean; 5) Select class with minimum combined harmonic distance
- Design tradeoffs: Fixed k vs. adaptive k (fixed is simpler but less flexible; adaptive requires additional computation); Euclidean vs. HMD (Euclidean is faster but more sensitive to outliers; HMD is more robust but heavier)
- Failure signatures: High variance in accuracy across k values (k selection issue); poor precision despite high recall (class imbalance or overlapping classes); sudden drop in performance on small datasets (insufficient neighbors for LMV smoothing)
- First 3 experiments: 1) Run LMPHNN vs. LMKNN on a small UCI dataset with known outliers; compare sensitivity to k; 2) Vary k from 2 to 10 on a balanced dataset; plot accuracy and F1 stability; 3) Replace HMD with Euclidean in LMPHNN; measure performance degradation on noisy data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the LMPHNN classifier perform on datasets with high dimensionality compared to other KNN-based classifiers?
- Basis in paper: The paper mentions that the classifier was tested on 9 UCI and Kaggle datasets with varying attributes, but does not specifically address high-dimensional datasets
- Why unresolved: The experiments conducted in the paper do not explicitly test the classifier's performance on high-dimensional datasets, leaving this aspect unexplored
- What evidence would resolve it: Conducting experiments on datasets with high dimensionality and comparing the performance of LMPHNN with other KNN-based classifiers would provide evidence to answer this question

### Open Question 2
- Question: What is the impact of the parameter k on the performance of the LMPHNN classifier in different scenarios?
- Basis in paper: The paper mentions that the classifier's sensitivity to the parameter k is reduced, but does not provide a detailed analysis of its impact in different scenarios
- Why unresolved: The paper does not provide a comprehensive analysis of how the parameter k affects the performance of the LMPHNN classifier in different scenarios, leaving this aspect unexplored
- What evidence would resolve it: Conducting experiments with varying values of k in different scenarios and analyzing the impact on the classifier's performance would provide evidence to answer this question

### Open Question 3
- Question: How does the LMPHNN classifier handle imbalanced datasets compared to other KNN-based classifiers?
- Basis in paper: The paper does not specifically address the handling of imbalanced datasets by the LMPHNN classifier
- Why unresolved: The paper does not provide any information on how the LMPHNN classifier performs on imbalanced datasets, leaving this aspect unexplored
- What evidence would resolve it: Conducting experiments on imbalanced datasets and comparing the performance of LMPHNN with other KNN-based classifiers would provide evidence to answer this question

## Limitations

- Limited methodological transparency regarding parameter selection and preprocessing details
- Lack of statistical significance testing across datasets to validate performance claims
- No controlled outlier injection experiments to demonstrate robustness claims
- Absence of confidence intervals for reported performance metrics

## Confidence

| Claim | Confidence |
|-------|------------|
| LMPHNN achieves 97% precision, 80% recall, 0.7832 F1 | Medium |
| LMPHNN outperforms seven KNN baselines | Medium |
| LMPHNN is less sensitive to k parameter | Medium |
| LMPHNN handles outliers better than baselines | Low |

## Next Checks

1. Replicate the LMPHNN algorithm on at least 3 UCI datasets with known outlier distributions to test sensitivity to k values (2-10)
2. Conduct paired t-tests between LMPHNN and baseline classifiers (KNN, LMKNN, PNN) on all 9 datasets to assess statistical significance of performance differences
3. Implement an ablation study replacing HMD with Euclidean distance in LMPHNN to quantify the contribution of the harmonic mean metric to performance gains