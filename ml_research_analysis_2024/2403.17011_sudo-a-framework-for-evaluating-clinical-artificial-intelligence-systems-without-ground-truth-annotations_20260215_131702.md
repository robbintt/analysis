---
ver: rpa2
title: 'SUDO: a framework for evaluating clinical artificial intelligence systems
  without ground-truth annotations'
arxiv_id: '2403.17011'
source_url: https://arxiv.org/abs/2403.17011
tags: []
core_contribution: SUDO is a framework to evaluate AI system predictions without ground-truth
  labels, addressing the challenge of distribution shift and missing labels in clinical
  data. It assigns temporary labels to data points, trains classifiers, and uses the
  discrepancy between classifier performances to estimate class contamination and
  prediction reliability.
---

# SUDO: a framework for evaluating clinical artificial intelligence systems without ground-truth annotations

## Quick Facts
- arXiv ID: 2403.17011
- Source URL: https://arxiv.org/abs/2403.17011
- Reference count: 37
- SUDO reliably proxies model performance, identifies unreliable predictions, informs model selection, and enables algorithmic bias assessment without ground-truth annotations in clinical AI systems.

## Executive Summary
SUDO is a framework that addresses the challenge of evaluating clinical artificial intelligence systems when ground-truth labels are unavailable or incomplete. It works by assigning temporary labels to data points in the wild, training classifiers to distinguish these pseudo-labeled points from ground-truth labeled points, and using the discrepancy between classifier performances to estimate class contamination and prediction reliability. Through experiments across dermatology images, histopathology patches, and clinical reports, SUDO demonstrates strong correlations with true performance metrics and provides valuable insights for model selection and bias assessment.

## Method Summary
SUDO operates by first deploying an AI system on data in the wild and discretizing its probability outputs into intervals. For each interval, pseudo-labels are assigned to data points, and classifiers are trained to distinguish these pseudo-labeled points from ground-truth labeled points in the training set. The classifiers are then evaluated on a held-out set with ground-truth labels, and the discrepancy between their performances under different pseudo-labels indicates the likelihood of class contamination. This process allows SUDO to estimate the reliability of AI predictions and identify unreliable ones without requiring ground-truth annotations for the data in the wild.

## Key Results
- SUDO achieves strong correlations (|ρ| > 0.8) with true performance metrics across multiple clinical datasets
- The framework successfully identifies unreliable AI predictions and informs model selection without ground-truth annotations
- SUDO enables algorithmic bias assessment by stratifying predictions across different patient groups, even without ground-truth labels

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** SUDO can act as a reliable proxy for model performance on data in the wild without ground-truth labels by leveraging pseudo-labels to quantify class contamination.
- **Mechanism:** SUDO assigns temporary labels to data points in the wild, trains classifiers to distinguish these pseudo-labeled points from ground-truth labeled points in the training set, and evaluates the classifiers on a held-out set with ground-truth labels. The discrepancy between classifier performances under different pseudo-labels indicates the likelihood of class contamination.
- **Core assumption:** The classifiers trained on pseudo-labeled data can effectively discriminate between classes, and the held-out set with ground-truth labels is representative of the data in the wild.
- **Evidence anchors:**
  - [abstract] "SUDO assigns temporary labels to data points in the wild and directly uses them to train distinct models, with the highest performing model indicative of the most likely label."
  - [section] "We found that SUDO correlates (ρ = −0.84 and −0.76 for DeepDerm and HAM10000, respectively) with the proportion of positive instances in each of the chosen probability intervals (Fig. 2c and d)."
- **Break condition:** If the data in the wild exhibits a drastically different class distribution or a third unseen class that the classifiers cannot handle, SUDO's reliability as a proxy may break down.

### Mechanism 2
- **Claim:** SUDO can identify unreliable AI predictions and inform model selection by quantifying the degree of class contamination in predictions.
- **Mechanism:** SUDO assigns pseudo-labels to data points in the wild, trains classifiers, and evaluates their performance. The degree of class contamination, indicated by the pseudo-label discrepancy, helps identify unreliable predictions. Models with lower class contamination are considered more reliable.
- **Core assumption:** The pseudo-labels assigned to data points in the wild are indicative of the true labels, and the classifiers can effectively learn to distinguish between pseudo-labeled and ground-truth labeled data.
- **Evidence anchors:**
  - [abstract] "Through experiments with AI systems developed for dermatology images, histopathology patches, and clinical reports, we show that SUDO can be a reliable proxy for model performance and thus identify unreliable AI predictions."
  - [section] "We found that SUDO can help inform model selection on data in the wild without annotations. Specifically, HAM10000 and DeepDerm achieve an area under the reliability-completeness curve (AURCC = 0.864 and 0.621, respectively) and, with ground-truth annotations, these models achieve ( AUC = 0.67 and 0.56)."
- **Break condition:** If the pseudo-labels are systematically incorrect or if the classifiers fail to learn the distinction between pseudo-labeled and ground-truth labeled data, SUDO's ability to identify unreliable predictions may be compromised.

### Mechanism 3
- **Claim:** SUDO can assess algorithmic bias on data without ground-truth annotations by stratifying predictions and analyzing pseudo-label discrepancies across different groups.
- **Mechanism:** SUDO is applied to stratified groups of data (e.g., based on skin tone or other protected attributes). The pseudo-label discrepancies across these groups indicate differences in model performance, which can be used to assess algorithmic bias.
- **Core assumption:** The pseudo-label discrepancies across groups are reflective of the true performance differences, and the data in each group is sufficiently representative for meaningful analysis.
- **Evidence anchors:**
  - [abstract] "By stratifying the value of SUDO across various groups of patients, we demonstrate that it also allows for the previously out-of-reach assessment of algorithmic bias for data without ground-truth annotations."
  - [section] "With NPV = 0.83 and 0.78, respectively, we found that both SUDO and the traditional approach (with ground-truth labels) identified a bias in favour of patients with a Fitzpatrick scale of I-II."
- **Break condition:** If the groups are not sufficiently distinct or if the pseudo-label discrepancies are influenced by factors other than model performance, SUDO's assessment of algorithmic bias may be inaccurate.

## Foundational Learning

- **Concept:** Distribution shift
  - **Why needed here:** Understanding distribution shift is crucial because SUDO is designed to evaluate AI systems on data that differ from the training data, which is a common scenario in clinical settings.
  - **Quick check question:** What is distribution shift, and why is it a challenge for evaluating AI systems in clinical settings?

- **Concept:** Pseudo-labeling
  - **Why needed here:** Pseudo-labeling is the core mechanism of SUDO, where temporary labels are assigned to data points in the wild to train classifiers and estimate class contamination.
  - **Quick check question:** How does pseudo-labeling help in quantifying class contamination without ground-truth labels?

- **Concept:** Class contamination
  - **Why needed here:** Class contamination refers to the mixture of data points from different classes in a given probability interval, which SUDO aims to quantify to assess prediction reliability.
  - **Quick check question:** Why is quantifying class contamination important for identifying unreliable AI predictions?

## Architecture Onboarding

- **Component map:** Data in the wild -> AI system deployment -> Probability discretization -> Pseudo-label assignment -> Classifier training -> Evaluation
- **Critical path:** The critical path involves deploying the AI system on data in the wild, discretizing the probability outputs, assigning pseudo-labels, training classifiers, and evaluating their performance to derive the pseudo-label discrepancy.
- **Design tradeoffs:** The tradeoff between the granularity of probability intervals and the number of data points sampled affects the accuracy and computational cost of SUDO.
- **Failure signatures:** If the pseudo-label discrepancies are consistently low across all probability intervals, it may indicate that the classifiers are not effectively distinguishing between classes.
- **First 3 experiments:**
  1. Deploy the AI system on a small subset of data in the wild and observe the distribution of probability outputs.
  2. Assign pseudo-labels to the data points and train a classifier to distinguish between pseudo-labeled and ground-truth labeled data.
  3. Evaluate the classifier's performance on a held-out set and calculate the pseudo-label discrepancy.

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability across clinical domains may vary due to different data characteristics or class distributions
- The framework's reliance on held-out sets with ground-truth labels may limit applicability in resource-constrained settings
- Computational complexity of training multiple classifiers may pose challenges for real-time applications

## Confidence
- **High Confidence:** The framework's ability to reliably proxy model performance (correlation |ρ| > 0.8) and identify unreliable predictions is supported by strong experimental evidence across multiple datasets and clinical applications.
- **Medium Confidence:** The assessment of algorithmic bias using SUDO is promising but requires further validation across diverse clinical populations and protected attributes to ensure robustness and fairness.
- **Medium Confidence:** The utility of SUDO for model selection and performance monitoring in clinical deployment scenarios is demonstrated, but long-term validation in real-world clinical settings is needed to confirm its practical value.

## Next Checks
1. Apply SUDO to clinical AI systems in domains beyond dermatology, histopathology, and clinical reports (e.g., radiology, genomics) to assess its generalizability and identify domain-specific limitations.
2. Evaluate the computational requirements of SUDO on large-scale clinical datasets and explore optimization strategies to improve its scalability for real-time or resource-constrained applications.
3. Conduct a longitudinal study to assess SUDO's performance in real-world clinical settings, including its ability to detect performance degradation, identify unreliable predictions, and support model updates over time.