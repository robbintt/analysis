---
ver: rpa2
title: "Detecting Domain Shift in Multiple Instance Learning for Digital Pathology\
  \ Using Fr\xE9chet Domain Distance"
arxiv_id: '2405.09934'
source_url: https://arxiv.org/abs/2405.09934
tags:
- domain
- shift
- data
- performance
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of detecting domain shifts\
  \ in attention-based multiple-instance learning (MIL) for digital pathology. The\
  \ authors propose a novel unsupervised metric called Fr\xE9chet Domain Distance\
  \ (FDD) to quantify the effects of domain shift on MIL performance."
---

# Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance

## Quick Facts
- arXiv ID: 2405.09934
- Source URL: https://arxiv.org/abs/2405.09934
- Reference count: 37
- This paper addresses the challenge of detecting domain shifts in attention-based multiple-instance learning (MIL) for digital pathology.

## Executive Summary
This paper addresses the challenge of detecting domain shifts in attention-based multiple-instance learning (MIL) for digital pathology. The authors propose a novel unsupervised metric called Fréchet Domain Distance (FDD) to quantify the effects of domain shift on MIL performance. They train a CLAM model on lymph node WSI data and evaluate it on data from a different hospital, splitting it into subsets representing varying levels of domain shift. The proposed FDD metric, which uses aggregated positive evidence features from the MIL model, achieves a mean Pearson correlation of 0.70 with changes in classification performance (MCC metric) across 10-fold cross-validation models. This outperforms baseline methods including Deep ensemble (0.45), Difference of Confidence (-0.29), and Representation shift (0.56). The results demonstrate that FDD is an effective tool for detecting domain shifts in attention-based MIL, potentially aiding in safe deployment of such systems in clinical practice.

## Method Summary
The proposed method trains a CLAM (Clustering-constrained Attention Multiple Instance Learning) model on source domain data (Camelyon dataset of lymph node WSIs) and evaluates it on target domain data (BRLN dataset from AIDA) to detect domain shift. The FDD metric extracts features from the MIL model's penultimate layer, aggregates the top K patches with highest attention scores (positive evidence), models these as multivariate Gaussian distributions, and computes the Fréchet distance between source and target domain distributions. The method uses 10-fold cross-validation and evaluates correlation between FDD scores and performance drops measured by Matthews correlation coefficient (MCC).

## Key Results
- FDD metric achieves mean Pearson correlation of 0.70 with MCC performance drop across 10-fold cross-validation
- Outperforms baseline methods: Deep ensemble (0.45), Difference of Confidence (-0.29), and Representation shift (0.56)
- Using 64 positive evidence features provides optimal domain shift detection
- Successfully identifies performance drops on axillary node dissection subset (0.11 MCC drop) and lobular carcinoma subset (0.07 MCC drop)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The FDD metric leverages attention scores to select informative patches, which helps distinguish between different levels of domain shift.
- Mechanism: By aggregating the K highest attention scores, the FDD metric focuses on patches that the MIL model considers most relevant for classification, capturing domain shift in the most informative regions.
- Core assumption: Attention scores in MIL models correlate with patch importance for classification and are stable across domains.
- Evidence anchors:
  - [abstract] "The proposed FDD metric, which uses aggregated positive evidence features from the MIL model"
  - [section] "We are interested in using the FD for measuring the domain shift between different WSI datasets Xd. To this end, we extract features from the MIL model applied to all the WSIs in Xd"
- Break condition: If attention scores become unreliable due to domain shift or if patch importance differs significantly between domains.

### Mechanism 2
- Claim: The Fréchet distance (FD) provides a meaningful measure of distribution similarity between datasets in the feature space.
- Mechanism: By modeling the aggregated patch features as multivariate Gaussian distributions and computing the FD, FDD quantifies how much the feature distributions differ between datasets, indicating domain shift severity.
- Core assumption: The aggregated patch features follow a multivariate Gaussian distribution, and the FD is a suitable metric for measuring distribution similarity.
- Evidence anchors:
  - [section] "Inspired by FID, we propose a metric named Fréchet Domain Distance (FDD) for evaluating if a model is experiencing a drop in performance on some new dataset"
  - [section] "We can compute means µK d and covariance matrices CK d from MK d extracted from two datasets d = 1 and d = 2. By measuring the FD, we arrive at our proposed FDD"
- Break condition: If the feature distributions are not well-approximated by multivariate Gaussians or if the FD is not sensitive to the specific type of domain shift.

### Mechanism 3
- Claim: Using a subset of highly informative patches (positive evidence) is more effective for domain shift detection than using all patches or random subsets.
- Mechanism: Selecting only the K patches with the highest attention scores reduces noise and focuses on the most relevant features, improving the sensitivity of FDD to domain shift.
- Core assumption: The K patches with the highest attention scores are more informative for detecting domain shift than the average of all patches or random patches.
- Evidence anchors:
  - [section] "Positive evidence or Negative evidence are defined as the K patch features that have the K highest or lowest attention scores, respectively"
  - [section] "From Fig. 1 we can see that if we further investigated all model-dataset combinations that resulted in F DD64 above 0.5, we would detect many cases with a drop in performance larger than 0.05"
- Break condition: If the attention scores do not reliably identify the most informative patches for domain shift detection.

## Foundational Learning

- Concept: Multiple Instance Learning (MIL)
  - Why needed here: Understanding the MIL framework is crucial for interpreting how the attention mechanism works and how features are aggregated.
  - Quick check question: How does MIL differ from traditional supervised learning in terms of instance-level labeling?

- Concept: Attention Mechanisms in Deep Learning
  - Why needed here: The attention mechanism is central to the proposed method, as it is used to select the most informative patches for domain shift detection.
  - Quick check question: What is the role of attention scores in a typical attention-based MIL model?

- Concept: Fréchet Distance (FD) and Fréchet Inception Distance (FID)
  - Why needed here: Understanding the FD and its application in FID provides the foundation for the proposed FDD metric.
  - Quick check question: How is the Fréchet distance between two multivariate Gaussian distributions computed?

## Architecture Onboarding

- Component map:
  CLAM model -> Feature extraction (penultimate layer, mean patch features, positive/negative/combined evidence features) -> FDD computation module (FD calculation using aggregated features) -> Evaluation pipeline (Pearson correlation with performance drop, cross-validation)

- Critical path:
  1. Train CLAM model on source domain data
  2. Extract features from CLAM model for both source and target domain data
  3. Aggregate features based on attention scores (positive evidence)
  4. Compute FDD using the aggregated features
  5. Evaluate FDD correlation with performance drop

- Design tradeoffs:
  - Number of patches (K) to include in aggregated features: Higher K may capture more information but also more noise
  - Feature selection strategy: Positive evidence vs. negative evidence vs. combined evidence vs. mean features
  - Type of features: Penultimate layer features vs. patch features

- Failure signatures:
  - Low correlation between FDD and performance drop: May indicate that the feature selection strategy or FD computation is not capturing the relevant aspects of domain shift
  - High standard deviation in correlation across cross-validation folds: May indicate instability in the method or insufficient data

- First 3 experiments:
  1. Compare FDD with different numbers of aggregated patches (K) to find the optimal value
  2. Evaluate the impact of different feature selection strategies (positive, negative, combined evidence) on FDD performance
  3. Test FDD on a synthetic domain shift scenario with known ground truth to validate its sensitivity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we differentiate between domain shifts that have positive versus negative effects on MIL performance?
- Basis in paper: [explicit] The paper notes that the ductal carcinoma subset performed better than in-domain Camelyon data, highlighting that domain shift quantification cannot currently separate beneficial from detrimental shifts.
- Why unresolved: The proposed FDD metric and baseline methods only measure the magnitude of domain shift, not its direction of effect on performance.
- What evidence would resolve it: Development and evaluation of metrics that can distinguish whether a domain shift improves or worsens MIL performance, potentially by incorporating performance improvement thresholds or directional sensitivity analysis.

### Open Question 2
- Question: How can we improve the calibration of uncertainty estimates in MIL to enhance domain shift detection?
- Basis in paper: [explicit] The paper observes that baseline methods using uncertainty and confidence aggregation (Deep ensemble and Difference of Confidence) showed poor ability to estimate performance drops, potentially due to overconfident predictions in supervised DL.
- Why unresolved: The calibration issues of uncertainty estimates in the context of MIL with attention mechanisms remain unexplored.
- What evidence would resolve it: Empirical studies comparing calibrated versus uncalibrated uncertainty estimates for domain shift detection in MIL, using techniques like temperature scaling or Bayesian methods.

### Open Question 3
- Question: What is the optimal number and type of attention-based features for domain shift quantification in MIL?
- Basis in paper: [explicit] The paper explores different feature sets (positive evidence, negative evidence, combined evidence, random features) and varying numbers of features (K from 1 to 128), finding that 64 positive evidence features with FDD performed best.
- Why unresolved: While 64 positive evidence features were optimal in this specific setup, the generalizability to other MIL architectures or datasets is unclear.
- What evidence would resolve it: Systematic evaluation of feature selection strategies and quantities across diverse MIL models, datasets, and domain shift scenarios to establish generalizable guidelines.

## Limitations
- The study only evaluates the proposed method on a single source-target domain pair (Camelyon to BRLN), limiting the generalizability of the findings.
- The optimal number of aggregated patches (K) is not thoroughly explored, and the choice of 64 patches may not be optimal for all scenarios.
- The CLAM architecture details and implementation code are not fully specified, which may hinder faithful reproduction of the results.

## Confidence
- High confidence in the mechanism of using aggregated positive evidence features and Fréchet distance for domain shift detection.
- Medium confidence in the superiority of FDD over baseline methods, as the study only compares it to a limited set of baselines.
- Low confidence in the generalizability of the results to other MIL architectures, datasets, and domain shift scenarios.

## Next Checks
1. Reproduce the study using a different MIL architecture (e.g., Attention-based MIL or WSISA) and evaluate the performance of FDD on the same dataset.
2. Conduct experiments on additional source-target domain pairs, including synthetic domain shift scenarios with known ground truth, to validate the robustness and sensitivity of FDD.
3. Investigate the impact of varying the number of aggregated patches (K) on the performance of FDD and identify the optimal value for different MIL architectures and datasets.