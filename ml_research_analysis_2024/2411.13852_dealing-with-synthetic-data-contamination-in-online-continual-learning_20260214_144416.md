---
ver: rpa2
title: Dealing with Synthetic Data Contamination in Online Continual Learning
arxiv_id: '2411.13852'
source_url: https://arxiv.org/abs/2411.13852
tags:
- data
- synthetic
- dataset
- esrm
- contamination
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the impact of synthetic data contamination
  on online continual learning (CL). The authors experimentally demonstrate that synthetic
  data significantly degrades performance in online CL, especially at high contamination
  ratios.
---

# Dealing with Synthetic Data Contamination in Online Continual Learning

## Quick Facts
- arXiv ID: 2411.13852
- Source URL: https://arxiv.org/abs/2411.13852
- Reference count: 40
- Primary result: ESRM significantly outperforms 6 baselines in mitigating synthetic data contamination effects on online continual learning

## Executive Summary
This paper investigates the impact of synthetic data contamination on online continual learning performance. Through extensive experiments across four benchmark datasets, the authors demonstrate that synthetic data significantly degrades model performance, particularly at high contamination ratios. They propose ESRM, a method combining entropy-based sample selection and contrastive learning to mitigate contamination effects. ESRM achieves substantially better performance than six baseline methods across all tested datasets, maintaining model plasticity while reducing catastrophic forgetting. The code is publicly available at https://github.com/WangMaorong/ESRM.

## Method Summary
The authors propose ESRM, a method that combines entropy-based sample selection (ES) with contrastive learning (RM) to mitigate synthetic data contamination in online continual learning. The approach uses an entropy criterion to preferentially store real samples in the memory buffer while employing contrastive learning to align feature representations between synthetic and real data groups. The method builds on replay-based continual learning frameworks and incorporates self-distillation loss for confidence regularization. Experiments are conducted on CIFAR-10/100, TinyImageNet, and ImageNet-100 with synthetic data generated by Stable Diffusion XL, v1.4, v2.1, VQDM, and GLIDE at contamination ratios ranging from 0% to 95%.

## Key Results
- ESRM significantly outperforms six baseline methods (ER, DER++, ERACE, OCM, GSA, OnPro) across all benchmark datasets
- Performance degradation is substantial at high contamination ratios (80-95%) for baseline methods
- ESRM maintains both learning accuracy (plasticity) and relative forgetting (stability) metrics better than alternatives
- The method shows consistent effectiveness across CIFAR-100, TinyImageNet, and ImageNet-100 datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Synthetic data contamination causes performance degradation in online continual learning because synthetic samples have lower entropy distributions than real data
- Mechanism: Lower entropy synthetic samples cluster more tightly in embedding space, creating feature misalignment with real data that degrades classification accuracy
- Core assumption: Entropy distribution differences between synthetic and real data persist throughout training and are detectable by the learning model
- Evidence anchors:
  - [abstract] "we experimentally demonstrate that synthetic data significantly degrades performance in online continual learning"
  - [section 4.3] "One noteworthy characteristic of synthetic data is its lower entropy distribution compared to real data"
  - [corpus] Weak - no direct evidence about entropy clustering effects
- Break condition: If synthetic generation models evolve to produce more diverse, higher-entropy outputs that better match real data distributions

### Mechanism 2
- Claim: Entropy-based sample selection can mitigate contamination effects by preferentially storing real samples in the memory buffer
- Mechanism: ES strategy uses entropy as a proxy for "realness" - higher entropy samples are more likely real and thus more valuable for replay
- Core assumption: Entropy is a reliable indicator that can distinguish synthetic from real samples during online learning
- Evidence anchors:
  - [section 4.2] "we propose ES, a memory management strategy. Guided by Obs. 3 (synthetic data has lower entropy distributions)"
  - [section 5.3] "ES uses entropy criteria to split it into two groups X new + and X new - of the same size"
  - [corpus] Weak - no direct evidence about entropy as reliable discriminator
- Break condition: If synthetic data generation advances to produce samples with entropy distributions indistinguishable from real data

### Mechanism 3
- Claim: Contrastive learning between synthetic and real sample groups can align their feature representations and reduce performance degradation
- Mechanism: RM loss maximizes cosine similarity between projected embeddings of high-entropy (likely real) and low-entropy (likely synthetic) samples
- Core assumption: Feature alignment between synthetic and real data groups will improve generalization to real test data
- Evidence anchors:
  - [section 5.2] "we propose RM. The main idea of RM is to maximize the cosine similarity between the features of real and synthetic data"
  - [section 4.3] "the embeddings of real data are inferior and fail to align with the superior embeddings of synthetic samples"
  - [corpus] Weak - no direct evidence about contrastive learning alignment benefits
- Break condition: If feature alignment creates overfitting to synthetic data characteristics rather than bridging the real-synthetic gap

## Foundational Learning

- Concept: Continual Learning without Forgetting
  - Why needed here: Online CL requires learning new tasks while maintaining performance on previous tasks
  - Quick check question: What is the main challenge in continual learning that makes synthetic contamination particularly problematic?

- Concept: Replay-based Methods and Memory Buffers
  - Why needed here: ESRM is built on replay-based methods that store historical data to prevent forgetting
  - Quick check question: How does the quality of data in the memory buffer affect overall model performance?

- Concept: Contrastive Learning and Embedding Alignment
  - Why needed here: RM component uses contrastive learning to align feature representations between synthetic and real data
  - Quick check question: What is the goal of maximizing similarity between different data groups in contrastive learning?

## Architecture Onboarding

- Component map: Feature extractor (f) -> Projection head (g) -> Classifier (Ï•) -> Entropy Selection (ES) -> Real-synthetic similarity Maximization (RM) -> Self-distillation loss (LSDC)

- Critical path: Incoming batch -> entropy calculation -> ES buffer update -> combined batch -> LCE + LSDC + LRM -> backward pass

- Design tradeoffs:
  - ES vs random sampling: Better real sample selection vs computational overhead
  - RM vs standard classification: Feature alignment vs potential overfitting to synthetic patterns
  - Buffer size vs contamination ratio: Larger buffers can store more real samples but increase memory cost

- Failure signatures:
  - Performance degradation increases with contamination ratio despite ES
  - High entropy samples still being synthetic (false positives)
  - Feature misalignment persists despite RM loss

- First 3 experiments:
  1. Test ES alone with fixed RM (only LCE + LSDC) on C100/SDXL to verify entropy selection effectiveness
  2. Test RM alone with fixed ES (only LCE + LSDC) on C100/SDXL to verify contrastive alignment effectiveness
  3. Test full ESRM on clean dataset to ensure no performance degradation from added components

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- The entropy-based distinction between synthetic and real data assumes persistent distributional differences that may not hold as synthetic generation technology advances
- The effectiveness of contrastive learning for alignment between synthetic and real data groups remains unproven - could potentially introduce overfitting to synthetic patterns
- No ablation study provided to isolate the individual contributions of ES and RM components to overall performance
- Experimental validation focuses on classification tasks; applicability to other task types remains unknown

## Confidence
- Performance degradation from synthetic contamination: **High** (directly demonstrated experimentally across multiple datasets)
- Entropy as reliable discriminator: **Medium** (mechanism proposed but not rigorously validated)
- Contrastive learning for feature alignment: **Medium** (mechanism described but effectiveness unproven)
- ESRM superiority over baselines: **High** (statistically significant improvements shown across benchmarks)

## Next Checks
1. Conduct ablation studies comparing ES-only and RM-only variants against full ESRM to quantify individual component contributions
2. Test ESRM on non-classification tasks (e.g., regression or segmentation) to assess generalizability beyond image classification
3. Evaluate performance with advanced synthetic data generators (e.g., newer diffusion models) to test robustness against evolving synthetic data quality