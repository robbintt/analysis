---
ver: rpa2
title: Creating emoji lexica from unsupervised sentiment analysis of their descriptions
arxiv_id: '2404.01439'
source_url: https://arxiv.org/abs/2404.01439
tags:
- sentiment
- emoji
- emojis
- lexicon
- tweets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel approach to automatically construct
  emoji sentiment lexica using an unsupervised sentiment analysis system based on
  emoji descriptions from Emojipedia. The method analyzes sentiment by considering
  linguistic dependencies and incorporates emoji definitions to predict sentiment
  without manual annotation.
---

# Creating emoji lexica from unsupervised sentiment analysis of their descriptions

## Quick Facts
- arXiv ID: 2404.01439
- Source URL: https://arxiv.org/abs/2404.01439
- Reference count: 20
- Proposed method achieves accuracy improvements of 2%-8% over methods using only cldr names

## Executive Summary
This paper presents a novel approach to automatically construct emoji sentiment lexica using an unsupervised sentiment analysis system based on emoji descriptions from Emojipedia. The method analyzes sentiment by considering linguistic dependencies and incorporates emoji definitions to predict sentiment without manual annotation. The resulting lexica are evaluated against manually labeled datasets and compared with existing approaches, showing improvements of 2%-8% in accuracy over methods using only cldr names and outperforming methods relying on external labeled data by 1%-3%.

## Method Summary
The unsupervised system uses emoji descriptions from Emojipedia as a source of sentiment information, parsing each definition, normalizing text, tagging parts of speech, building dependency parses, and propagating sentiment scores from merged lexica across syntactic dependencies. The approach handles linguistic structures like negation, intensification, and adversative clauses, and combines multiple sentiment lexica (so-cal and afinn) to increase coverage. The method is evaluated on English and Spanish datasets, comparing performance against existing approaches that use only cldr names or external labeled data.

## Key Results
- Accuracy improvements of 2%-8% over methods using only cldr names
- Outperforms methods relying on external labeled data by 1%-3%
- Confirms emoji definitions add valuable discriminating information for sentiment analysis

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using emoji descriptions from Emojipedia as a source of sentiment information works because the creators' intended meanings are less noisy than mined contextual usages.
- Mechanism: The system parses each emoji's definition, normalizes text, tags parts of speech, builds dependency parses, and propagates sentiment scores from a merged lexicon across syntactic dependencies, accounting for linguistic structures like negation, intensification, and adversative clauses.
- Core assumption: The sentiment expressed in an emoji's creator-defined description is a reliable prior for its overall sentiment, independent of how users actually employ it.
- Evidence anchors:
  - [abstract] "The initial sentiment of each emoji is derived from a sentiment score obtained after applying the meaning assigned by its creator."
  - [section 3.2.4] Explains the propagation of sentiment scores through dependency parses and handling of negation, intensifiers, and adversatives.
  - [corpus] Weak/no direct match; no corpus entries directly reference Emojipedia definitions as training data.
- Break condition: If the creator's intended sentiment diverges systematically from user interpretation (e.g., sarcasm or reappropriation), the prior will be misleading.

### Mechanism 2
- Claim: Propagating sentiment scores across syntactic dependencies rather than treating words in isolation yields more accurate sentiment classification.
- Mechanism: After dependency parsing, each token's polarity is propagated through edges, with special handling for negation (reversing polarity), intensifiers (scaling), and adversative/concessive clauses (adjusting contribution weight).
- Core assumption: Linguistic dependencies carry sentiment-relevant information that isolated word-level lexicons miss; correctly handling these dependencies improves classification accuracy.
- Evidence anchors:
  - [section 3.2.4] Details propagation rules for intensifiers, negations, and adversatives.
  - [abstract] Mentions "an unsupervised sentiment analysis system based on the definitions given by emoji creators in Emojipedia."
  - [corpus] Weak; no corpus entries directly reference dependency-based sentiment propagation.
- Break condition: If dependency parsing is unreliable on informal text (high noise), propagation will propagate errors.

### Mechanism 3
- Claim: Combining multiple sentiment lexica (so-cal, afinn) and merging uncommon words yields better coverage and avoids zero-score gaps.
- Mechanism: Merge lexica into a single list with polarity values from -5 to 5, averaging overlapping entries; use this unified list for propagation.
- Core assumption: No single lexicon captures all sentiment-bearing words; merging increases coverage without introducing conflicting polarity signals.
- Evidence anchors:
  - [section 3.2.3] Describes merging so-cal and afinn, handling uncommon words.
  - [abstract] References "an unsupervised sentiment analysis system based on the definitions given by emoji creators in Emojipedia."
  - [corpus] Weak; no corpus entries mention lexicon merging.
- Break condition: If lexica are highly inconsistent, averaging may dilute strong signals.

## Foundational Learning

- Concept: Dependency parsing and sentiment propagation across syntactic structures.
  - Why needed here: Enables capturing context-dependent sentiment cues (negation, intensifiers) that isolated word scores miss.
  - Quick check question: What happens to a positive word's polarity when it appears under negation in the dependency tree?
- Concept: Lexicon merging and handling of unseen words.
  - Why needed here: Ensures robust coverage of sentiment-bearing terms without introducing polarity gaps.
  - Quick check question: How are overlapping entries handled when merging two lexica with different polarity values?
- Concept: Evaluation metrics beyond accuracy (macro-averaged precision and F1).
  - Why needed here: Class imbalance in sentiment datasets can make accuracy misleading; macro-averages give a fairer picture.
  - Quick check question: If a dataset has 80% neutral tweets, which metric (accuracy vs macro-F1) is more informative?

## Architecture Onboarding

- Component map: Data ingestion (tweets + Emojipedia definitions) -> Preprocessing (normalization, NER) -> NLP pipeline (lemmatization, POS tagging, dependency parsing) -> Sentiment lexicon merge -> Unsupervised sentiment propagation -> Lexicon construction -> Evaluation
- Critical path: Ingestion -> Preprocessing -> Dependency parsing -> Sentiment propagation -> Lexicon output. Each step must succeed before the next.
- Design tradeoffs: (a) Richer linguistic analysis (dependencies) increases accuracy but adds computational cost; (b) Merging lexica improves coverage but may introduce noise; (c) Using creator definitions avoids manual annotation but may not reflect user usage.
- Failure signatures: Low macro-F1 scores despite high accuracy indicate class imbalance; high false positives on negated contexts indicate propagation rules need tuning.
- First 3 experiments:
  1. Compare sentiment scores with and without dependency propagation on a small labeled emoji set.
  2. Test lexicon merging by evaluating coverage before/after merge on a held-out word list.
  3. Run the pipeline on a small emoji definition corpus and manually inspect propagated sentiment values for correctness.

## Open Questions the Paper Calls Out
None

## Limitations
- The exact implementation details of the usspad sentiment propagation algorithm are not fully specified
- The method assumes emoji definitions capture creator-intended sentiment, which may not align with actual user interpretations
- Merging sentiment lexica could introduce noise if the lexica have conflicting polarity assignments for overlapping terms

## Confidence

High confidence in the core methodology of using emoji descriptions for sentiment lexicon construction
Medium confidence in the effectiveness of dependency-based sentiment propagation, given potential parsing errors in informal text
Medium confidence in the 2%-8% accuracy improvement claim, as this depends on the quality of evaluation datasets
Low confidence in generalizability across languages beyond English and Spanish, as the approach may not account for cultural differences in emoji interpretation

## Next Checks

1. Test propagation sensitivity: Run the system with and without dependency propagation on a small labeled emoji set to quantify the impact of linguistic dependencies on sentiment classification accuracy.

2. Evaluate definition quality: Manually sample emoji definitions from Emojipedia and assess whether the creator-intended sentiment aligns with common user interpretations, particularly for emojis with evolving meanings.

3. Cross-lingual validation: Apply the method to a third language (e.g., Japanese) with a manually labeled emoji sentiment dataset to test the approach's generalizability beyond English and Spanish.