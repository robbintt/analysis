---
ver: rpa2
title: Counterfactual-based Root Cause Analysis for Dynamical Systems
arxiv_id: '2406.08106'
source_url: https://arxiv.org/abs/2406.08106
tags:
- root
- cause
- system
- counterfactual
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a method for identifying root causes in dynamic
  systems using counterfactual reasoning. The authors model dynamic causal systems
  using Residual Neural Networks and derive counterfactual distributions over trajectories.
---

# Counterfactual-based Root Cause Analysis for Dynamical Systems

## Quick Facts
- arXiv ID: 2406.08106
- Source URL: https://arxiv.org/abs/2406.08106
- Reference count: 18
- Method identifies root causes in dynamic systems using counterfactual reasoning with Residual Neural Networks and Shapley value approximation

## Executive Summary
This paper presents a method for identifying root causes in dynamic systems using counterfactual reasoning. The authors model dynamic causal systems using Residual Neural Networks and derive counterfactual distributions over trajectories. Their approach addresses limitations of existing methods by handling non-linear systems, structural influences, and large variable sets. The method involves fitting a normal system model, estimating counterfactual distributions through interventions on noise and structure, and using an efficient Shapley value approximation to rank potential root causes.

## Method Summary
The method learns a residual neural network model from normal data to represent the transition dynamics of a dynamic causal system. For counterfactual inference, it performs interventions on both the structural equations and noise components, then evaluates which interventions most effectively prevent anomalies. The approach uses an efficient approximation to Shapley values to rank interventions by their contribution to failure, enabling scalability to systems with large numbers of variables.

## Key Results
- Interventions on both structural equations and noise jointly outperform interventions on noise alone
- The Shapley value approximation enables scalability to systems with large numbers of variables
- Learning separate models for normal and factum data captures true causal structure while remaining flexible to anomalies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Counterfactual interventions on both structural equations and noise jointly outperform interventions on noise alone
- Mechanism: By modeling the dynamic causal system with a Residual Neural Network and deriving counterfactual distributions over trajectories, the method can simulate alternative outcomes by intervening on both the structural equation and external influence. This captures both direct and indirect effects of interventions.
- Core assumption: The structural causal model is correctly specified and the residual network accurately represents the transition dynamics
- Evidence anchors:
  - [abstract] "We show quantitatively that more root causes are identified when an intervention is performed on the structural equation and the external influence, compared to an intervention on the external influence only."
  - [section 4] "For an intervention in F M we intervene on the noise as before and we additionally intervene on the structure by do(Sj t ) = ˜Sj t (see Eq. 2)"
- Break condition: If the residual network poorly approximates the true transition dynamics, or if the causal graph is misspecified, the counterfactual distributions will be inaccurate

### Mechanism 2
- Claim: The Shapley value approximation enables scalability to systems with large numbers of variables
- Mechanism: Exact Shapley value computation scales exponentially with the number of variables. By approximating Shapley values using only singleton intervention sets (ignoring interactions between interventions), the computational complexity becomes linear in the number of variables, making it feasible for dynamic systems with many nodes.
- Core assumption: Interactions between multiple interventions are negligible or rarely occur
- Evidence anchors:
  - [abstract] "By employing an efficient approximation to a corresponding Shapley value, we also obtain a ranking between the different subsystems at different points in time being responsible for an observed failure, which is applicable in settings with large number of variables."
  - [section 3.2] "Consequently we arrive the following simple expression of contribution score of individual interventions ξ for each point in time and node: Sh(ξ) := log EY∼PMF ξ {ϕ (Y)} (7)"
- Break condition: If multiple simultaneous interventions are common root causes, this approximation will miss important interactions and reduce accuracy

### Mechanism 3
- Claim: Learning separate models for normal and factum data captures the true causal structure while remaining flexible to anomalies
- Mechanism: The method learns two transition functions - one from normal data only (fN) and one from both normal and factum data (fNF). The factum model uses the normal transition function during counterfactual intervention, ensuring the counterfactual trajectory reverts to normal behavior patterns while preserving the structural relationships learned from both datasets.
- Core assumption: The transition function remains stable between normal and anomalous states for non-root-cause variables
- Evidence anchors:
  - [section 4] "If for both, normal as well as abnormal data, a node and hence its transition function is not anomalous, the transition function would be identical for both settings. Therefore, in 3.2 we additionally fit a transition function f j NF with normal and factum data as input on the same parents and children as in 3.1"
- Break condition: If the transition function changes significantly for non-root-cause variables during anomalies, the method will incorrectly attribute changes to root causes

## Foundational Learning

- Concept: Structural Causal Models (SCMs) and their dynamic extension
  - Why needed here: The entire method is built on the framework of SCMs, using them to define interventions, counterfactuals, and root causes
  - Quick check question: What is the difference between a hard intervention (do(Sj t ) = ˜Sj t) and a soft intervention (do(PN j t) = ˜PN j t) in an SCM?

- Concept: Counterfactual inference and abduction
- Why needed here: The method uses counterfactual reasoning to determine what would have happened if a subsystem behaved normally, which requires understanding abduction (inferring noise from observations) and prediction
- Quick check question: In the abduction step, how is the noise posterior distribution PN j t(N j t|YF) computed from the observed factum trajectory?

- Concept: Shapley values and their computational complexity
- Why needed here: Shapley values provide the theoretical foundation for ranking interventions by their contribution to failure, but their exponential complexity necessitates approximation
- Quick check question: What is the computational complexity of exact Shapley value calculation in terms of the number of interventions n?

## Architecture Onboarding

- Component map:
  - Data preprocessing: Time-series normalization and splitting into normal/factum sets
  - Model learning: Two residual networks - fN (normal data only) and fNF (normal + factum data)
  - SCM construction: Abduction step to compute noise posteriors from factum observations
  - Counterfactual generation: Sampling trajectories under different intervention sets
  - Evaluation: Classification of counterfactual trajectories using anomaly detector
  - Ranking: Shapley value approximation to score interventions

- Critical path: Factum observation → SCM abduction → counterfactual sampling → anomaly classification → Shapley value ranking → root cause identification

- Design tradeoffs:
  - Computational efficiency vs. accuracy: Exact Shapley values are intractable for large systems; approximation sacrifices some accuracy for scalability
  - Model complexity vs. interpretability: Residual networks capture non-linear dynamics but are less interpretable than linear models
  - Assumption strength vs. applicability: Requires known causal graph and absence of latent confounders, limiting real-world applicability

- Failure signatures:
  - Poor performance on non-linear systems: Indicates the residual network is insufficient to capture complex dynamics
  - Inaccurate root cause identification when multiple simultaneous interventions occur: Suggests the singleton approximation fails
  - Degradation when causal graph is misspecified: Shows the method's sensitivity to structural assumptions

- First 3 experiments:
  1. Linear synthetic system with known ground truth: Inject root causes at different nodes/times and verify identification accuracy
  2. FitzHugh-Nagumo nonlinear oscillator: Test the method's ability to handle cyclic systems with non-linear dynamics
  3. River flow rate dataset: Apply the method to real-world data with an unobserved confounder to assess robustness to model violations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the method change when multiple root causes are present simultaneously in dynamic systems?
- Basis in paper: [inferred] The paper mentions that the current method is limited to identifying single interventions as root causes and suggests extending it to identify multiple root causes in future work.
- Why unresolved: The paper does not provide experimental results or analysis for scenarios with multiple simultaneous root causes, focusing instead on single intervention cases.
- What evidence would resolve it: Experimental results showing the method's performance on synthetic and real-world datasets with known multiple root causes, comparing accuracy and computational efficiency against baseline methods.

### Open Question 2
- Question: How robust is the method to uncertainties in the causal graphical structure and the presence of latent confounders?
- Basis in paper: [explicit] The authors explicitly state that their method is limited by the assumptions of known causal graph structure and absence of latent confounders, and mention plans to extend the method to handle these uncertainties.
- Why unresolved: The paper does not provide experimental results or theoretical analysis on the method's performance under graph structure uncertainties or latent confounders.
- What evidence would resolve it: Experiments varying the assumed causal graph structure (e.g., adding/removing edges) and introducing latent confounders, measuring the impact on root cause identification accuracy and comparing with methods that explicitly model uncertainty.

### Open Question 3
- Question: How does the proposed Shapley value approximation compare to exact Shapley values in terms of accuracy and computational efficiency for root cause identification in dynamic systems?
- Basis in paper: [explicit] The authors introduce a simple approximation to Shapley values to handle scalability issues, but do not provide a comparison with exact Shapley values.
- Why unresolved: The paper does not present a quantitative comparison between the proposed approximation and exact Shapley values in terms of ranking quality and computational cost.
- What evidence would resolve it: A detailed analysis comparing the proposed approximation against exact Shapley values on small-scale problems where exact computation is feasible, measuring both the quality of root cause rankings and computational time.

## Limitations
- Requires known causal graph structure as input, limiting applicability in scenarios where causal relationships are unknown
- Assumes absence of latent confounders, a strong assumption rarely satisfied in real-world systems
- Performance may degrade when multiple simultaneous interventions are common root causes due to Shapley value approximation

## Confidence
- High confidence: The theoretical framework based on SCMs and counterfactual reasoning is sound and well-established in the causal inference literature
- Medium confidence: The empirical results on synthetic systems are promising, but the small number of experiments and limited dataset diversity warrant caution
- Low confidence: The performance on real-world data (river dataset) lacks rigorous evaluation metrics and comparison to baseline methods

## Next Checks
1. Ablation study on approximation accuracy: Compare root cause identification performance using exact Shapley values (for small systems) versus the proposed approximation to quantify the trade-off between accuracy and scalability
2. Sensitivity analysis to causal graph misspecification: Systematically vary the input causal graph structure and measure the impact on root cause identification accuracy to assess robustness to model violations
3. Evaluation on diverse real-world datasets: Apply the method to multiple real-world dynamic systems (e.g., industrial processes, financial markets, biological networks) with ground truth root causes to validate generalization beyond synthetic and single real-world examples