---
ver: rpa2
title: 'MALTO at SemEval-2024 Task 6: Leveraging Synthetic Data for LLM Hallucination
  Detection'
arxiv_id: '2403.00964'
source_url: https://arxiv.org/abs/2403.00964
tags:
- data
- language
- ensemble
- hallucination
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of detecting semantic hallucinations
  in natural language generation (NLG) models, where fluent but inaccurate outputs
  are produced. The authors propose an automatic pipeline that leverages data augmentation
  and ensemble modeling to improve hallucination detection.
---

# MALTO at SemEval-2024 Task 6: Leveraging Synthetic Data for LLM Hallucination Detection

## Quick Facts
- arXiv ID: 2403.00964
- Source URL: https://arxiv.org/abs/2403.00964
- Reference count: 1
- Key outcome: Proposed ensemble approach achieves 80.07% accuracy on SHROOM task

## Executive Summary
This paper addresses the critical challenge of detecting semantic hallucinations in natural language generation models, where models produce fluent but inaccurate outputs. The authors propose an automatic pipeline that leverages data augmentation and ensemble modeling to improve hallucination detection performance. The key innovation lies in using LLM-aided pseudo-labelling and sentence rephrasing to expand the training dataset, combined with an ensemble of three distinct models: a BERT-based classifier, a model using Conditioned Reinforcement Learning Fine Tuning (C-RLFT), and a sequential model based on iterative fine-tuning. The approach achieves an accuracy of 80.07% on the SHROOM task, with particular emphasis on recall as a critical metric for identifying potentially inaccurate generated text.

## Method Summary
The proposed method combines data augmentation techniques with an ensemble modeling approach to detect semantic hallucinations in generated text. The pipeline begins with augmenting the original dataset through LLM-aided pseudo-labelling and sentence rephrasing, which significantly increases training data diversity and quantity. Three models are then trained using different strategies: a baseline BERT-based classifier, a C-RLFT model that uses reinforcement learning with specific reward functions, and a sequential model that progressively fine-tunes on increasingly higher-quality data. These models are combined through an ensemble layer that learns to weight their predictions optimally. The approach leverages pre-training on Natural Language Inference (NLI) tasks to provide a strong foundation for the hallucination detection task.

## Key Results
- The ensemble approach achieves 80.07% accuracy on the SHROOM task
- Sequential training strategy outperforms individual techniques
- The ensemble model shows particular strength in recall, critical for detecting hallucinations
- C-RLFT and sequential training models demonstrate substantial performance improvements over baseline

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Data augmentation using pseudo-labelling and sentence rephrasing increases training data diversity and quantity, improving hallucination detection
- Mechanism: Pseudo-labelling generates synthetic labels for unlabelled data using LLMs, while sentence rephrasing creates diverse versions of existing samples. Both techniques expand the training dataset, allowing the model to learn from a wider range of examples.
- Core assumption: Pseudo-labels and rephrased sentences maintain semantic consistency with original data
- Evidence anchors: Abstract mentions enriching data with augmentation techniques including LLM-aided pseudo-labelling and sentence rephrasing; section 2.1 discusses both techniques being based on LLMs

### Mechanism 2
- Claim: Ensemble approach combining three different models outperforms individual techniques by leveraging complementary strengths
- Mechanism: Each model captures different aspects of hallucination detection through distinct training strategies, and the ensemble layer combines their predictions to integrate strengths and mitigate weaknesses
- Core assumption: Three models are sufficiently diverse and capture complementary information about hallucinations
- Evidence anchors: Abstract describes ensemble from three models pre-trained on NLI tasks and fine-tuned on diverse datasets; section 2.3 notes ensemble effectiveness in other NLP tasks

### Mechanism 3
- Claim: Sequential training strategy enhances model understanding by progressively fine-tuning on higher-quality data
- Mechanism: Model first trains on large pseudo-labelled data, then refines on rephrased data with correct labels, and finally fine-tunes on gold dataset, allowing gradual adaptation to task
- Core assumption: Model benefits from learning on large diverse dataset before exposure to smaller higher-quality datasets
- Evidence anchors: Section 2.2.3 describes strategy of starting with substantial data including synthetic labels and progressively updating with consistent data; section 3.4 shows substantial improvements from C-RLFT and sequential training

## Foundational Learning

- Concept: Natural Language Inference (NLI)
  - Why needed here: NLI relates to hallucination detection as both involve comparing generated text with reference text to determine semantic consistency
  - Quick check question: What is the main goal of NLI, and how does it relate to the task of hallucination detection?

- Concept: Data augmentation techniques
  - Why needed here: Data augmentation increases size and diversity of training dataset, crucial for improving model's ability to detect hallucinations
  - Quick check question: What are the two main data augmentation techniques used in this work, and how do they contribute to the task?

- Concept: Ensemble learning
  - Why needed here: Ensemble learning combines multiple models to leverage complementary strengths and improve overall performance
  - Quick check question: How does the ensemble layer in this work combine the predictions of the three individual models?

## Architecture Onboarding

- Component map: Data augmentation pipeline (pseudo-labelling and sentence rephrasing) -> Three individual models (baseline, C-RLFT, and sequential) -> Ensemble layer (weighted combination of model predictions)
- Critical path: Data augmentation → Individual model training → Ensemble layer training → Final hallucination detection
- Design tradeoffs: Using pseudo-labelled data increases dataset size but may introduce noise; sequential training balances benefits of large diverse data with quality of gold labels; ensemble approach combines complementary models but adds complexity
- Failure signatures: Poor performance on individual models may indicate issues with data augmentation or model training strategies; inconsistent predictions across three models may suggest need for further model diversity or ensemble tuning
- First 3 experiments:
  1. Train and evaluate each individual model (baseline, C-RLFT, and sequential) on augmented dataset to assess performance and complementarity
  2. Train and evaluate ensemble layer using predictions of three individual models on validation set to determine optimal weighting scheme
  3. Conduct ablation study to assess impact of each data augmentation technique (pseudo-labelling and sentence rephrasing) on final performance

## Open Questions the Paper Calls Out

The paper identifies several open questions regarding the proposed approach. One key question is how the sequential fine-tuning strategy would perform if the order of datasets were altered, such as starting with gold data instead of pseudo-labelled data. Another important question concerns the extent to which data augmentation techniques introduce noise or biases that could degrade model performance. The authors also question how the ensemble model's performance varies when using different weighting schemes for individual models in the ensemble.

## Limitations

- The paper lacks detailed analysis of augmentation quality and doesn't characterize the noise introduced by pseudo-labelling
- Specific contributions of each component model to the ensemble's success aren't thoroughly analyzed
- The sequential training strategy's benefits are shown but the impact of varying data quality and quantity at each stage isn't explored
- The paper doesn't explore alternative weighting schemes for the ensemble model

## Confidence

- **High Confidence:** The overall effectiveness of the ensemble approach in improving hallucination detection performance
- **Medium Confidence:** The specific mechanisms by which data augmentation contributes to improved performance
- **Medium Confidence:** The sequential training strategy's ability to enhance model understanding of the hallucination detection task

## Next Checks

1. **Augmentation Quality Analysis:** Conduct in-depth analysis of quality of pseudo-labels generated by LLM and semantic consistency of rephrased sentences; measure accuracy of pseudo-labels against manually annotated data and assess impact of low-quality augmentations on model performance

2. **Ensemble Component Analysis:** Perform ablation study to quantify individual contributions of each model (baseline, C-RLFT, and sequential) to ensemble's performance; analyze diversity of predictions across models and identify specific strengths each model brings to ensemble

3. **Sequential Training Optimization:** Experiment with varying quality and quantity of data at each stage of sequential training strategy; investigate impact of different fine-tuning sequences, optimal number of epochs at each stage, and effect of skipping or reordering stages on final performance