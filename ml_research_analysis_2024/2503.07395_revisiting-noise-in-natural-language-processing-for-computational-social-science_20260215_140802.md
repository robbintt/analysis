---
ver: rpa2
title: Revisiting Noise in Natural Language Processing for Computational Social Science
arxiv_id: '2503.07395'
source_url: https://arxiv.org/abs/2503.07395
tags:
- chapter
- language
- historical
- https
- values
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Challenges the traditional view that noise in computational social
  science (CSS) is inherently detrimental. Through five interconnected case studies
  examining OCR errors in historical newspapers, archaic language, subjective annotations,
  and LLM-generated bias, demonstrates that noise manifests uniquely across contexts
  and requires distinct mitigation strategies.
---

# Revisiting Noise in Natural Language Processing for Computational Social Science

## Quick Facts
- arXiv ID: 2503.07395
- Source URL: https://arxiv.org/abs/2503.07395
- Reference count: 0
- Challenges traditional view that noise in CSS is inherently detrimental, showing it can encode valuable cultural information

## Executive Summary
This paper reexamines the role of noise in computational social science (CSS) by presenting five interconnected case studies that demonstrate noise manifests uniquely across contexts and requires distinct mitigation strategies. Through analysis of OCR errors in historical newspapers, archaic language, subjective annotations, and LLM-generated bias, the author shows that some noise encodes valuable cultural information while other noise is truly harmful. The research concludes that CSS researchers must thoughtfully evaluate noise type before selecting handling approach, as no single solution fits all noise types.

## Method Summary
The paper presents five case studies examining different types of noise in CSS contexts. For OCR errors in historical newspapers, the author analyzes 5 million articles from 2,000 newspapers spanning 1820-2000. The study evaluates various embedding models including fastText, GloVe, BERT, and SBERT on clean and OCR-corrupted text. For historical language analysis, the author examines newspapers from 1905-1925, comparing modern NLP model performance on low-noise versus high-noise scenarios. The subjective annotation study analyzes 5,000 politically-charged tweets annotated by two groups with differing perspectives. The LLM bias analysis tests multiple prompt variations on Llama 3.2 3B model, analyzing textual justifications rather than single values.

## Key Results
- Modern NLP models perform surprisingly well on low-noise historical text without special adaptations
- Community-level prediction aggregation effectively filters individual post noise in subjective annotation tasks
- Multiple prompt variations and analyzing textual justifications yield more reliable LLM bias detection than single-value approaches
- Tailored embedding models are needed for high-noise OCR scenarios, while clean text benefits from standard approaches

## Why This Works (Mechanism)
The effectiveness of context-specific noise handling stems from understanding that different noise types have distinct characteristics and impacts. OCR errors create systematic character-level corruption that requires specialized embedding models, while cultural and linguistic variation represents information-rich noise that should be preserved. Subjective annotations benefit from aggregation because individual biases cancel out at community level, revealing underlying consensus. LLM bias analysis succeeds through prompt variation because it captures the range of possible interpretations rather than a single biased output.

## Foundational Learning
- Noise characterization: Understanding whether noise is harmful or information-rich determines appropriate handling strategy
- Why needed: Different noise types require fundamentally different approaches - preservation vs. mitigation
- Quick check: Classify noise as either systematic corruption or cultural/linguistic variation

- Model adaptation: Selecting embedding models based on noise level rather than default choices
- Why needed: High-noise scenarios require robust representations while clean text benefits from standard models
- Quick check: Compare model performance across noise levels to identify optimal approach

- Community aggregation: Using collective predictions to filter individual bias in subjective tasks
- Why needed: Individual annotator bias can be reduced through aggregation, revealing true consensus
- Quick check: Measure variance reduction in aggregated vs. individual predictions

## Architecture Onboarding
Component map: OCR text -> Embedding model -> Classification task; Historical text -> Modern NLP model -> Analysis; Subjective annotations -> Community aggregation -> Consensus prediction; LLM bias -> Prompt variation -> Textual justification analysis

Critical path: Data preprocessing -> Noise characterization -> Model selection -> Validation -> Application
The critical path emphasizes that noise characterization must precede model selection, as the appropriate approach depends entirely on understanding the noise type and its impact on downstream tasks.

Design tradeoffs: The study balances between preserving potentially valuable cultural information and removing harmful corruption. For OCR errors, aggressive cleaning might remove valuable context, while for subjective annotations, over-aggregation might smooth out important nuance. The tradeoff involves choosing between precision and recall based on whether noise represents signal or corruption.

Failure signatures: Model performance degradation indicates inappropriate noise handling strategy. For OCR errors, using standard embeddings on corrupted text leads to poor classification. For subjective tasks, ignoring community-level aggregation results in individual bias dominating predictions. For LLM bias, single prompt analysis misses the range of possible outputs.

First experiments:
1. Character error rate analysis on OCR-corrupted text to quantify noise level
2. Cross-validation comparing different embedding models on clean vs. corrupted historical text
3. Variance analysis of individual vs. aggregated predictions in subjective annotation tasks

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Dataset size limitations restrict generalizability to other historical collections
- Single newspaper corpus from 1905-1925 limits testing on other historical domains
- Political discourse context of Twitter dataset may not generalize to other domains
- Conservative-liberal binary framework may oversimplify complex political landscapes
- Focus on English-language sources limits applicability to multilingual CSS research

## Confidence
High confidence in OCR case study methodology and results due to systematic validation across multiple time periods and model types.

Medium confidence in historical text performance claims, subjective annotation findings, and LLM bias analysis due to context-specific limitations and potential generalizability issues.

## Next Checks
1. Test the low-noise historical text methodology on non-English historical corpora to assess cross-linguistic generalizability
2. Apply the community-level prediction aggregation framework to subjective annotation tasks in non-political domains (e.g., sentiment analysis, product reviews)
3. Evaluate the prompt variation strategy for LLM bias detection using alternative political frameworks beyond the two-party system to capture more nuanced ideological positions