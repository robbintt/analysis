---
ver: rpa2
title: Distribution Guided Active Feature Acquisition
arxiv_id: '2410.03915'
source_url: https://arxiv.org/abs/2410.03915
tags:
- features
- acquisition
- feature
- information
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a framework for active feature acquisition
  (AFA) in machine learning, where an agent interacts with the environment to acquire
  informative features on-the-fly for improved predictions. The key idea is to model
  arbitrary conditional distributions among features using generative models, which
  underpin the AFA problem.
---

# Distribution Guided Active Feature Acquisition

## Quick Facts
- arXiv ID: 2410.03915
- Source URL: https://arxiv.org/abs/2410.03915
- Reference count: 24
- Primary result: State-of-the-art performance on active feature acquisition across UCI datasets, MNIST, and unsupervised tasks with improved accuracy and efficiency

## Executive Summary
This paper introduces a framework for active feature acquisition (AFA) that models arbitrary conditional distributions among features using generative models to guide feature selection. The approach learns a single generative model capable of computing conditional likelihoods for any subset of observed and unobserved features, enabling effective greedy acquisition policies and reinforcement learning approaches. The framework also incorporates interpretability through explicit sub-goals and robustness via out-of-distribution detection during acquisition.

## Method Summary
The framework centers on ACFlow (Arbitrary Conditional Flow), a generative model that learns a single model to compute conditional likelihoods p(xu|xo) for any subset of features. This model enables greedy feature selection based on expected information gain and serves as a surrogate model providing intermediate rewards and auxiliary information for reinforcement learning agents. The GSMRL approach uses hierarchical action space grouping based on marginal informativeness to manage large action spaces. The method addresses interpretability through goal-based explainability and robustness via partially observed out-of-distribution (PO-MSMA) detection.

## Key Results
- State-of-the-art performance on UCI repository and MNIST datasets for both supervised and unsupervised AFA tasks
- Significant improvements in accuracy and efficiency compared to baselines, especially for high-dimensional data and large action spaces
- Effective OOD detection during acquisition with AUROC scores demonstrating robustness
- Goal-based acquisition policies providing interpretable explanations for feature selection decisions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modeling arbitrary conditional distributions among features enables more effective active feature acquisition by capturing dependencies that inform which features are most informative to acquire next.
- Mechanism: The ACFlow model learns a single generative model that can compute conditional likelihoods p(xu|xo) for any subset of observed and unobserved features. This allows the acquisition policy to estimate the mutual information between each candidate feature and the target given current observations, enabling greedy selection of the most informative feature at each step.
- Core assumption: The conditional dependencies among features can be effectively modeled by a single generative model that yields tractable conditional likelihoods for arbitrary subsets.
- Evidence anchors:
  - [abstract]: "We build our AFA framework on a backbone of understanding the information and conditional dependencies that are present in the data."
  - [section 3]: "In this work, we propose to explicitly model these conditional dependencies among features to aid AFA approaches."
  - [corpus]: Weak evidence - no direct corpus citations about conditional modeling in AFA, though related works on arbitrary conditionals exist.

### Mechanism 2
- Claim: Using intermediate rewards based on information gain and auxiliary information from the generative surrogate model helps RL agents learn better acquisition policies by addressing credit assignment problems and high-dimensional action spaces.
- Mechanism: The GSMRL approach provides intermediate rewards at each acquisition step based on the reduction in uncertainty about the target variable (information gain), and provides auxiliary information including imputed values, uncertainties, and expected information gain for unobserved features. This guides the agent toward acquiring features that are both informative and cost-effective.
- Core assumption: The generative surrogate model can accurately estimate the information gain and uncertainties needed for intermediate rewards and auxiliary information.
- Evidence anchors:
  - [section 5.2]: "The surrogate model assesses the intermediate reward for a newly acquired feature i with rm(s, i) := H(y | xo) − γH(y | xo, xi)"
  - [section 5.2]: "We propose using the surrogate model to also provide auxiliary information to augment the current state and assist the agent."
  - [corpus]: Weak evidence - while model-based RL is established, the specific use of generative surrogate models for AFA is novel and lacks direct corpus support.

### Mechanism 3
- Claim: Hierarchical action space grouping based on marginal informativeness to the target variable helps RL agents navigate large action spaces more effectively by reducing exploration complexity.
- Mechanism: Features are clustered into groups based on their mutual information with the target variable I(xi; y), and a hierarchical policy first selects a group then selects a feature within that group. This reduces the d-dimensional action space to K + N decisions where K is the number of groups and N is the average group size.
- Core assumption: Marginal informativeness to the target variable provides a reasonable basis for grouping features that will be jointly informative for prediction.
- Evidence anchors:
  - [section 5.3]: "Given the estimated mutual information, we can simply sort and divide the candidate features into different groups."
  - [section 5.3]: "The grouping shall also help guide the agent in later acquisitions, where it may seek less marginally informative features (that may be jointly informative with the current observations) to obtain more nuanced discrimination."
  - [corpus]: Weak evidence - while action space clustering is used in RL, the specific approach of grouping by marginal informativeness for AFA is novel.

## Foundational Learning

- Concept: Mutual Information
  - Why needed here: Mutual information quantifies the amount of information one random variable contains about another, which is essential for measuring the informativeness of candidate features for predicting the target variable.
  - Quick check question: What is the formula for mutual information between two random variables X and Y, and how does it relate to conditional entropy?

- Concept: Generative Flow Models
  - Why needed here: Flow models like ACFlow can learn complex probability distributions and provide exact likelihoods through the change of variables formula, which is necessary for computing arbitrary conditional distributions p(xu|xo).
  - Quick check question: How does the change of variables formula enable flow models to compute exact likelihoods, and what is the key property that makes this possible?

- Concept: Markov Decision Processes (MDPs)
  - Why needed here: The active feature acquisition problem is formulated as an MDP where states represent acquired features, actions represent feature acquisition decisions, and rewards represent the trade-off between prediction accuracy and acquisition cost.
  - Quick check question: What are the components of an MDP (S, A, T, γ, R) and how do they map to the active feature acquisition problem?

## Architecture Onboarding

- Component map: ACFlow model -> Greedy/GSMRL agent -> Feature acquisition -> Prediction -> Reward calculation
- Critical path: ACFlow → Greedy/GSMRL agent → Feature acquisition → Prediction → Reward calculation
- Design tradeoffs: Model complexity vs. tractability (ACFlow must balance expressiveness with computational efficiency), exploration vs. exploitation (agent must balance trying new features vs. selecting known informative ones)
- Failure signatures: Poor prediction accuracy despite feature acquisition (likely ACFlow model issues), agent getting stuck in local optima (likely exploration problems), OOD detector false positives/negatives (likely threshold issues)
- First 3 experiments:
  1. Train ACFlow on simple dataset with known conditional dependencies and verify it can compute correct conditional likelihoods for various subsets
  2. Implement greedy acquisition policy and test on synthetic dataset where optimal acquisition order is known
  3. Train GSMRL agent on small-scale problem and verify it learns to acquire features that improve prediction accuracy more than random acquisition

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the hierarchical acquisition policy compare to alternative feature grouping strategies, such as random clustering or graph-based methods?
- Basis in paper: [explicit] The paper mentions comparing the information-based grouping scheme to random clustering, row clustering, and graph clustering in Section 10.2.2, but does not provide detailed results for all these comparisons.
- Why unresolved: The paper only briefly mentions the comparison and does not provide detailed results or analysis for all the alternative grouping schemes.
- What evidence would resolve it: A comprehensive comparison of the hierarchical acquisition policy with different feature grouping strategies, including detailed results and analysis, would help determine the effectiveness of the information-based grouping scheme.

### Open Question 2
- Question: Can the partially observed out-of-distribution detection method be extended to handle more complex data types, such as images with varying resolutions or spatial constraints?
- Basis in paper: [inferred] The paper mentions that the OOD detection method is designed for partially observed instances, but does not explicitly discuss its applicability to more complex data types or spatial constraints.
- Why unresolved: The paper focuses on the development of the OOD detection method for partially observed instances, but does not explore its potential for handling more complex data types or spatial constraints.
- What evidence would resolve it: An extension of the OOD detection method to handle more complex data types, such as images with varying resolutions or spatial constraints, and a thorough evaluation of its performance would help determine its applicability to a broader range of scenarios.

### Open Question 3
- Question: How does the goal-based acquisition policy perform in real-world applications, such as medical diagnosis or autonomous driving, where interpretability and explainability are crucial?
- Basis in paper: [explicit] The paper mentions that the goal-based acquisition policy is designed to provide explanations for the acquisitions, but does not explicitly discuss its performance in real-world applications.
- Why unresolved: The paper focuses on the development of the goal-based acquisition policy and its performance on benchmark datasets, but does not explore its potential for real-world applications where interpretability and explainability are crucial.
- What evidence would resolve it: A thorough evaluation of the goal-based acquisition policy in real-world applications, such as medical diagnosis or autonomous driving, and an analysis of its interpretability and explainability would help determine its practical value.

## Limitations

- The framework relies heavily on ACFlow's ability to accurately capture arbitrary conditional distributions, which may struggle with very complex or non-stationary data distributions
- RL policy generalization is primarily validated on relatively clean UCI datasets and MNIST, with uncertain robustness to noisier real-world scenarios
- OOD detection component is introduced but evaluated only on a subset of experiments, with uncharacterized false positive and false negative rates

## Confidence

**High Confidence** (Strong empirical support, well-established theory):
- The basic premise that modeling conditional feature dependencies can inform feature acquisition decisions
- The effectiveness of mutual information as a measure of feature informativeness
- The general formulation of AFA as an MDP

**Medium Confidence** (Reasonable assumptions but limited validation):
- The specific ACFlow architecture's ability to capture all relevant conditional dependencies
- The GSMRL approach with intermediate rewards providing significant advantages over simpler methods
- The hierarchical action space grouping improving RL performance

**Low Confidence** (Novel components with minimal validation):
- The OOD detection component's real-world effectiveness
- The goal-based explainability method providing meaningful interpretations
- Performance on very high-dimensional data (beyond MNIST)

## Next Checks

1. **Conditional Likelihood Validation**: Systematically evaluate ACFlow's accuracy in estimating p(xu|xo) for various subset sizes and data distributions using synthetic datasets where ground truth conditionals are known.

2. **OOD Detection Benchmarking**: Conduct comprehensive evaluation of the OOD detector across multiple datasets with varying degrees of distributional shift, measuring both detection rates and computational overhead during acquisition.

3. **Transfer Learning Assessment**: Test the GSMRL agent's ability to transfer learned policies across different datasets with similar feature spaces but different underlying distributions, measuring policy degradation and adaptation requirements.