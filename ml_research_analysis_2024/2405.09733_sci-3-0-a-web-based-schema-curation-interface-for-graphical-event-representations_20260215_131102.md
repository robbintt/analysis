---
ver: rpa2
title: 'SCI 3.0: A Web-based Schema Curation Interface for Graphical Event Representations'
arxiv_id: '2405.09733'
source_url: https://arxiv.org/abs/2405.09733
tags:
- event
- events
- schema
- graph
- curation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The Schema Curation Interface 3.0 (SCI 3.0) is a web-based tool
  that enables manual refinement of automatically induced event schemas. The tool
  allows users to visualize, edit, and curate complex event representations through
  a graphical interface, supporting features like hierarchical event structures, logic
  gates, and temporal sequences.
---

# SCI 3.0: A Web-based Schema Curation Interface for Graphical Event Representations

## Quick Facts
- arXiv ID: 2405.09733
- Source URL: https://arxiv.org/abs/2405.09733
- Reference count: 0
- After two rounds of curation, event coverage doubled from 376 to 753 events and participants from 957 to 1,561

## Executive Summary
The Schema Curation Interface 3.0 (SCI 3.0) is a web-based tool designed to enable manual refinement of automatically induced event schemas. The tool provides a graphical interface for visualizing, editing, and curating complex event representations, supporting hierarchical event structures, logic gates, and temporal sequences. By enabling human feedback on entity grounding, event relationships, and argument identification, SCI 3.0 significantly improves the quality of induced schemas. The tool also supports integration with human-in-the-loop schema induction systems and is open-source, designed to streamline the curation process for complex event schemas.

## Method Summary
The method involves using SCI 3.0 for manual curation of automatically generated schema graphs. First, automatically generated schemas are obtained using a system that employs GPT-3 for hierarchical schema induction, paired with relevant news articles and chapter structures. The SCI 3.0 web application is then set up locally, and the generated schema graphs are uploaded for manual curation. Users perform real-time editing of event schema properties, including adding, removing, or editing sub-events, entities, and relations. After initial manual curation, a second iteration is conducted with the processed event list for reference, informed by schema-guided event prediction from the RESIN-pipeline.

## Key Results
- Event coverage doubled from 376 to 753 events after two rounds of curation
- Participant coverage doubled from 957 to 1,561 after two rounds of curation
- Manual curation informed by schema-guided event prediction significantly improved schema quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Real-time visual editing of hierarchical event schemas improves manual curation accuracy by enabling direct manipulation of event-event and entity-entity relations.
- Mechanism: The interface renders schemas as interactive graphs where users can add/remove events, participants, and relations via right-click context menus, bypassing the need to edit raw JSON.
- Core assumption: Users can more accurately model event hierarchies when they see and manipulate them directly rather than editing serialized data.
- Evidence anchors: [abstract] "The tool allows users to visualize, edit, and curate complex event representations through a graphical interface, supporting features like hierarchical event structures, logic gates, and temporal sequences." [section 4] "React.js, Flask, and Cytoscape.js were used to design the web application... The graph is then constructed with nodes and edges in Cytoscape for rendering on the browser."

### Mechanism 2
- Claim: Integration of schema-guided event prediction with manual curation increases schema coverage by identifying and incorporating frequently occurring but missing events.
- Mechanism: After initial manual curation, the schema is passed to an event prediction system (RESIN-pipeline) which generates matched and unmatched events. The unmatched events are filtered for significance and frequency, then used to guide a second curation round where users add these events to the schema.
- Core assumption: High-frequency unmatched events represent meaningful gaps in the schema that, when filled, significantly improve coverage.
- Evidence anchors: [section 5] "Following this, a second iteration of manual curation is conducted with SCI 3.0 and the processed event list for reference... we managed to double our event coverage across all curated schemas." [section 5] "Based on a new set of news articles, the RESIN-pipeline... provided us with a list of matched and unmatched events covered by our event schemas."

### Mechanism 3
- Claim: The use of Wikidata QNodes for grounding events and entities ensures semantic consistency and interoperability across schemas.
- Mechanism: During schema induction, events are represented as sentences which are then grounded to Wikidata QNodes using a natural language inference model. This grounding provides a standardized semantic reference for events and entities, enabling consistent interpretation and integration across different schemas.
- Core assumption: Wikidata provides a sufficiently comprehensive and accurate knowledge base for grounding event and entity semantics in diverse domains.
- Evidence anchors: [section 3] "To ground these events within the ontology, allowing us to extract event arguments, we employ a natural language inference (NLI) model to compare the generated sentences with the definitions of the QNodes." [section 4.1] "wd_node, wd_label, and wd_description are the event grounding in Wikidata, this information can be found in the DWD."

## Foundational Learning

- Concept: Hierarchical event structures
  - Why needed here: The tool models complex real-world events as hierarchies of sub-events, requiring users to understand parent-child relationships and their implications for event flow.
  - Quick check question: What is the difference between a chapter event and a primitive event in the schema?

- Concept: Semantic grounding and Wikidata
  - Why needed here: Events and entities are grounded to Wikidata QNodes to ensure semantic consistency and enable interoperability, requiring understanding of knowledge graphs and semantic web concepts.
  - Quick check question: What information is stored in the wd_node, wd_label, and wd_description fields?

- Concept: Schema-guided event prediction
  - Why needed here: The system uses induced schemas to predict events in new text, requiring understanding of how schemas represent event patterns and how they can be applied for information extraction.
  - Quick check question: How does the RESIN-pipeline use schemas to predict events in new articles?

## Architecture Onboarding

- Component map:
  Frontend (React.js) -> Backend (Flask) -> Visualization (Cytoscape.js) -> Schema Format (JSON SDF) -> External Systems (OpenAI GPT-3, RESIN-pipeline, Wikidata)

- Critical path: User uploads schema → Flask processes and stores schema → Cytoscape renders graph → User edits via React interface → Changes propagated back to Flask → Schema file updated

- Design tradeoffs:
  - Visual editing vs. direct JSON manipulation: Visual editing improves usability but may abstract away important schema details
  - Real-time updates vs. performance: Frequent graph updates provide immediate feedback but may impact performance with large schemas
  - Wikidata grounding vs. flexibility: Grounding ensures consistency but may limit the tool's applicability to domains not well-covered by Wikidata

- Failure signatures:
  - Graph rendering issues: Incorrect or missing schema elements in the visualization
  - Context menu failures: Right-click actions not triggering expected behaviors
  - JSON synchronization problems: Visual edits not properly reflected in the underlying schema file
  - Grounding errors: Events or entities failing to link to appropriate Wikidata QNodes

- First 3 experiments:
  1. Upload a simple schema and verify that all events, entities, and relations are correctly rendered in the graph
  2. Add a new primitive event with participants and relations via the context menu, then check that the schema file is updated correctly
  3. Use the view entities option to list all entities in a schema and verify that the information is accurate and complete

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can entity grounding be automated to reduce the manual curation burden?
- Basis in paper: [explicit] The paper mentions that entity grounding is the most time-consuming process in schema curation due to the extensive effort required to search through Wikidata.
- Why unresolved: The paper suggests integrating a human-in-the-loop schema system for prompting a dialog component with keywords to search candidate entities and relation Qnodes, but does not provide details on the effectiveness or implementation of this solution.
- What evidence would resolve it: Empirical results comparing the time and accuracy of manual entity grounding versus the proposed automated system would provide evidence of its effectiveness.

### Open Question 2
- Question: What are the specific criteria for determining when to add new events versus reusing existing sub-events across schemas?
- Basis in paper: [inferred] The paper mentions the potential for creating a library of sub-events to save curators time in recreating the same events used elsewhere, but does not specify the criteria for this decision.
- Why unresolved: The paper does not provide guidelines or examples of when to create new events versus reusing existing ones, which could impact the consistency and efficiency of the curation process.
- What evidence would resolve it: A set of criteria or a decision tree for determining when to create new events versus reusing existing ones, along with examples of its application, would provide clarity on this issue.

### Open Question 3
- Question: How does the quality and coverage of automatically induced schemas compare to manually curated schemas in downstream NLP tasks?
- Basis in paper: [explicit] The paper states that automatically induced schemas are often noisy, have limited coverage, and are unsuitable for downstream tasks, which is why manual curation is necessary.
- Why unresolved: While the paper demonstrates improvements in event coverage and participants through manual curation, it does not provide a direct comparison of the quality and performance of automatically induced versus manually curated schemas in specific NLP tasks.
- What evidence would resolve it: Empirical results comparing the performance of automatically induced and manually curated schemas on various NLP tasks, such as information extraction, event prediction, or knowledge base construction, would provide evidence of their relative quality and utility.

## Limitations

- The claimed doubling of event coverage lacks detailed methodological transparency, with underspecified filtering criteria for "significant" unmatched events.
- No quantitative evaluation of user experience or curation efficiency is provided, lacking data on time savings, error reduction, or user satisfaction.
- The integration with Wikidata for semantic grounding is untested for domain-specific coverage limitations, not addressing scenarios where Wikidata lacks relevant concepts.

## Confidence

- High Confidence: The technical implementation of SCI 3.0 using React.js, Flask, and Cytoscape.js for interactive graph editing is well-documented and reproducible
- Medium Confidence: The workflow of combining manual curation with schema-guided event prediction is logically sound, but the impact claims need more rigorous validation
- Low Confidence: The semantic grounding mechanism's effectiveness and coverage across diverse domains is asserted but not empirically verified

## Next Checks

1. Conduct a controlled user study comparing schema curation time and accuracy using SCI 3.0 versus traditional JSON editing methods
2. Test the Wikidata grounding system on domain-specific schemas (e.g., medical or technical domains) to identify coverage gaps and measure grounding accuracy
3. Implement A/B testing of the two-round curation process with varying thresholds for "significant" unmatched events to optimize the balance between coverage gains and curation effort