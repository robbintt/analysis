---
ver: rpa2
title: Unleashing the Potential of Model Bias for Generalized Category Discovery
arxiv_id: '2412.12501'
source_url: https://arxiv.org/abs/2412.12501
tags:
- categories
- novel
- known
- category
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles Generalized Category Discovery (GCD), where
  models must recognize both known and novel categories from unlabeled data. The main
  challenge is model bias towards known categories and lack of supervision for novel
  ones.
---

# Unleashing the Potential of Model Bias for Generalized Category Discovery

## Quick Facts
- arXiv ID: 2412.12501
- Source URL: https://arxiv.org/abs/2412.12501
- Reference count: 13
- Key outcome: SDC achieves 2.64% improvement in novel category accuracy and 2.00% improvement in harmonic mean score over state-of-the-art methods

## Executive Summary
This paper addresses the challenge of Generalized Category Discovery (GCD), where models must recognize both known and novel categories from unlabeled data. The key innovation is Self-Debiasing Calibration (SDC), which leverages the biased model's output to mitigate category bias and confusion. By using two logit adjustment techniques - subtracting biased logits for known categories and adding transfer logits for novel categories - along with an entropy-based weighting mechanism, SDC significantly improves performance on identifying novel categories while maintaining known category accuracy.

## Method Summary
SDC consists of pre-training on labeled data using cross-entropy and masked language modeling, followed by training on unlabeled data with self-debiasing calibration. The method initializes trainable components from a pre-trained biased model, computes biased logits for unlabeled data, and applies logit adjustment through Category Bias Mitigation (CBM) and Category Confusion Mitigation (CCM). An entropy-based weighting mechanism modulates the adjustment intensity per sample. Pseudo-labels are generated via Sinkhorn-Knopp algorithm and combined with cross-entropy and contrastive loss for final training.

## Key Results
- SDC outperforms state-of-the-art methods on three text datasets (BANKING, HWU64, CLINC)
- Achieves 2.64% improvement in novel category accuracy
- Improves harmonic mean score by 2.00% compared to previous best methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Model bias towards known categories can be explicitly measured and subtracted from logits to reduce overconfident predictions for known classes.
- Mechanism: The biased pre-trained model's output logits serve as a precise proxy for category bias. By subtracting these logits (scaled by factor α) from the current model's logits for known categories, the method reduces overconfidence and mitigates misclassification of novel samples into known classes.
- Core assumption: The biased model's predictions accurately reflect the degree of bias towards known categories, and this bias is consistent enough to be corrected by simple subtraction.
- Evidence anchors:
  - [abstract] "it provides an accurate modeling of category bias, which can be utilized to measure the degree of bias and debias the output of the current training model"
  - [section] "First, it provides an accurate modeling of category bias, which can be utilized to measure the degree of bias and debias the output of the current training model"
  - [corpus] Weak evidence: No direct neighbor citations support this mechanism specifically.
- Break condition: If the biased model's predictions are not representative of the true bias (e.g., due to distribution shift), subtraction could over-correct and harm known category performance.

### Mechanism 2
- Claim: Knowledge transfer from known to novel categories via prototype similarity reduces category confusion among novel classes.
- Mechanism: A transfer matrix T is constructed using cosine similarities between known category prototypes and novel category prototypes. This matrix reweights the biased model's logits to generate "transfer logits" that guide the current model to distinguish novel categories based on their similarity to known ones.
- Core assumption: Novel categories are meaningfully similar to known categories, and this similarity can be captured by prototype alignment.
- Evidence anchors:
  - [abstract] "it offers valuable insights for distinguishing different novel categories by transferring knowledge between similar categories"
  - [section] "the output of the biased model offers insightful hints for distinguishing between different novel categories by transferring knowledge between similar categories"
  - [corpus] Weak evidence: No direct neighbor citations support this mechanism specifically.
- Break condition: If novel categories are not semantically related to known ones, transfer could introduce noise and worsen confusion.

### Mechanism 3
- Claim: Entropy of biased model's predictions effectively distinguishes known from novel samples, enabling sample-specific weighting.
- Mechanism: Entropy is computed from the biased model's softmax output for each sample. Low entropy indicates confidence in known categories, high entropy suggests novel categories. This entropy is transformed via sigmoid to produce a weighting factor αi that modulates logit adjustment intensity per sample.
- Core assumption: Known category samples produce low-entropy predictions, while novel samples produce high-entropy predictions under the biased model.
- Evidence anchors:
  - [section] "samples from known categories exhibit low entropy because the biased model is confident in these categories. Conversely, samples from novel categories exhibit high entropy"
  - [section] "we use the entropy of the biased logits as an indicator to differentiate samples from known or novel categories"
  - [corpus] Weak evidence: No direct neighbor citations support this mechanism specifically.
- Break condition: If entropy distributions overlap significantly between known and novel samples, the weighting becomes unreliable.

## Foundational Learning

- Concept: Cross-entropy loss
  - Why needed here: Used for supervised training on labeled data and for training with pseudo-labels on unlabeled data.
  - Quick check question: What is the difference between using cross-entropy with true labels versus pseudo-labels?

- Concept: Sinkhorn-Knopp algorithm
  - Why needed here: Solves the optimal transport problem to generate balanced pseudo-labels across all categories.
  - Quick check question: Why is balancing pseudo-labels across categories important in GCD?

- Concept: Contrastive learning
  - Why needed here: Encourages consistent representations within categories by pulling together positive pairs and pushing apart negative pairs.
  - Quick check question: How does instance-level contrastive learning complement pseudo-label training in this framework?

## Architecture Onboarding

- Component map:
  - Pre-trained backbone (frozen biased model) -> Trainable backbone (initialized from biased model) -> Biased classifier (frozen) -> Trainable classifier (initialized with prototypes) -> Logit adjustment module (CBM + CCM + Entropy weighting) -> Sinkhorn-Knopp pseudo-label generator -> Contrastive loss module

- Critical path:
  1. Pre-train on labeled data (CE + MLM loss)
  2. Initialize trainable components from pre-trained model
  3. Compute biased logits for unlabeled data
  4. Apply logit adjustment (CBM, CCM, weighting)
  5. Generate pseudo-labels via Sinkhorn-Knopp
  6. Train on labeled + pseudo-labeled data (CE + contrastive)

- Design tradeoffs:
  - Freezing vs. fine-tuning the biased model: freezing ensures consistent bias measurement but limits adaptation
  - Prototype-based transfer vs. learned similarity: prototypes are simpler but may miss complex relationships
  - Entropy-based weighting vs. fixed weighting: adaptive but sensitive to entropy distribution shifts

- Failure signatures:
  - Known category accuracy drops significantly: likely over-penalization from logit adjustment
  - Novel category accuracy plateaus: possible insufficient transfer or poor pseudo-label quality
  - Both accuracies drop: likely poor initialization or optimization instability

- First 3 experiments:
  1. Ablation: Remove CBM and measure known category accuracy degradation
  2. Ablation: Remove CCM and measure novel category accuracy degradation
  3. Ablation: Replace entropy weighting with fixed α and measure overall performance change

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Self-Debiasing Calibration (SDC) framework perform when applied to datasets with highly imbalanced known and novel category ratios?
- Basis in paper: [inferred] The paper discusses the effect of known category ratio but does not provide extensive experimental results or analysis for highly imbalanced scenarios.
- Why unresolved: The paper only tests a limited range of known category ratios and does not explore extreme imbalances, which could reveal limitations or strengths of the model.
- What evidence would resolve it: Conducting experiments with datasets where the known category ratio is significantly skewed (e.g., 90% known, 10% novel) would provide insights into the model's robustness and adaptability in such scenarios.

### Open Question 2
- Question: What is the impact of using different backbone architectures (e.g., RoBERTa, DistilBERT) on the performance of the SDC framework?
- Basis in paper: [explicit] The paper mentions using a pre-trained Bert-base-uncased model as the backbone but does not explore the effects of using other architectures.
- Why unresolved: The choice of backbone architecture could influence the model's ability to generalize and adapt to novel categories, and its impact on SDC's performance remains unexplored.
- What evidence would resolve it: Comparative experiments using different backbone architectures with the same SDC framework would reveal how the choice of backbone affects performance, particularly in identifying novel categories.

### Open Question 3
- Question: How does the SDC framework handle cases where the number of novel categories is not known a priori, and what is the accuracy of its category estimation method?
- Basis in paper: [explicit] The paper mentions using a dropout algorithm to estimate the number of categories and provides results showing close estimations, but does not discuss handling cases where the number of novel categories is unknown.
- Why unresolved: The accuracy and reliability of the category estimation method in real-world applications where the number of categories is unknown are not thoroughly examined.
- What evidence would resolve it: Detailed analysis of the estimation method's accuracy across diverse datasets and scenarios, along with its impact on the overall performance of the SDC framework, would provide insights into its practical applicability.

## Limitations
- The entropy-based weighting mechanism's effectiveness depends heavily on the separation between known and novel category entropy distributions, which may not hold in datasets with subtle category distinctions or domain shifts.
- The prototype-based transfer matrix assumes linear relationships between known and novel categories, potentially limiting performance when novel categories have complex semantic relationships with known ones.
- The paper provides limited ablation studies on the individual contributions of CBM and CCM components, making it difficult to assess their relative importance.

## Confidence
- **High confidence**: The overall SDC framework design and its superior performance compared to baselines is well-supported by experimental results.
- **Medium confidence**: The theoretical justification for using biased model outputs as proxy for category bias, though the practical effectiveness depends on dataset characteristics.
- **Medium confidence**: The claim that SDC specifically excels at novel category discovery, as the improvements are demonstrated but could be influenced by dataset-specific factors.

## Next Checks
1. Conduct ablation studies varying the entropy threshold for weighting to determine optimal separation between known and novel categories.
2. Test SDC on datasets with varying degrees of semantic similarity between known and novel categories to validate the prototype transfer assumption.
3. Implement an alternative to the prototype-based transfer matrix (e.g., learned similarity metric) to assess whether the improvement is specific to the transfer mechanism or the overall debiasing approach.