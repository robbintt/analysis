---
ver: rpa2
title: Salutary Labeling with Zero Human Annotation
arxiv_id: '2405.17627'
source_url: https://arxiv.org/abs/2405.17627
tags:
- learning
- active
- influence
- salutary
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces salutary labeling, an active learning framework
  that automatically selects and labels the most informative samples without human
  annotation. The core innovation lies in using influence functions to identify the
  most beneficial samples and assigning them the labels that maximize positive influence
  on model performance.
---

# Salutary Labeling with Zero Human Annotation

## Quick Facts
- arXiv ID: 2405.17627
- Source URL: https://arxiv.org/abs/2405.17627
- Authors: Wenxiao Xiao; Hongfu Liu
- Reference count: 40
- Primary result: Salutary labeling achieves superior performance to traditional active learning strategies while eliminating human annotation needs

## Executive Summary
This paper introduces salutary labeling, an active learning framework that automatically selects and labels the most informative samples without human annotation. The core innovation lies in using influence functions to identify the most beneficial samples and assigning them labels that maximize positive influence on model performance. Unlike traditional active learning methods that rely on human-annotated labels, salutary labeling autonomously assigns labels by choosing the category that yields the greatest positive impact. The approach was evaluated across nine benchmark datasets, demonstrating superior performance compared to traditional active learning strategies while eliminating the need for human annotation.

## Method Summary
Salutary labeling uses influence functions to automatically select the most informative samples and assign them labels that maximize model performance, eliminating human annotation requirements. The method computes influence for each unlabeled sample across all possible labels and assigns the label yielding the greatest positive influence. For non-convex models like deep neural networks, the approach uses surrogate logistic regression models trained on embeddings extracted by the non-convex model. The framework was evaluated on nine benchmark datasets using a query budget of 10 samples per round over 10 rounds, comparing against traditional active learning baselines.

## Key Results
- Salutary labeling outperforms traditional active learning methods across nine benchmark datasets
- The approach eliminates the need for human annotation while maintaining or improving model performance
- Promising results demonstrated when extended to large language model fine-tuning using surrogate models
- Influence function estimations show high correlation with actual loss changes despite not perfectly matching

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Salutary labeling automatically selects the most beneficial labels without human annotation by maximizing influence on model performance.
- **Mechanism:** The method computes influence for each unlabeled sample across all possible labels and assigns the label that yields the greatest positive influence. This circumvents the need for ground truth labels while still leveraging influence function's ability to identify informative samples.
- **Core assumption:** The label that maximizes influence function value is the most beneficial label for model performance, even if it differs from the ground truth.
- **Evidence anchors:**
  - [abstract] "automatically assigns the most beneficial labels to the most informative samples without human annotation"
  - [section] "assigning the label that yields the greatest positive influence"
  - [corpus] Weak - no direct mention of label assignment strategies in corpus papers
- **Break condition:** If influence function calculation is inaccurate for non-convex models, or if the assumption that maximum influence equals maximum benefit fails, this mechanism breaks.

### Mechanism 2
- **Claim:** Influence function accurately estimates the impact of adding a new sample on validation loss.
- **Mechanism:** The method adapts influence function, originally designed for leave-one-out analysis, to estimate the effect of adding a sample. It uses this estimation to select samples with the highest potential impact on model performance.
- **Core assumption:** Influence function provides accurate relative rankings of sample importance for add-one-in scenarios, even if absolute values differ from actual loss changes.
- **Evidence anchors:**
  - [section] "The influence estimation for new samples does not perfectly match the actual loss change, likely because they were unseen during initial training. However, the influence estimations are highly correlated with actual loss differences"
  - [section] "Influence function offers a more direct and precise assessment of a data point's importance to the model"
  - [corpus] Weak - corpus doesn't directly address influence function accuracy for add-one-in scenarios
- **Break condition:** If the correlation between influence estimates and actual impact is too low, or if the Hessian computation becomes unreliable for complex models, this mechanism fails.

### Mechanism 3
- **Claim:** Surrogate models enable extension of salutary labeling to non-convex deep learning scenarios.
- **Mechanism:** When dealing with non-convex models like LLMs, the method uses a surrogate logistic regression model on the embeddings extracted by the non-convex model. This surrogate model then applies influence function to select and label samples.
- **Core assumption:** The surrogate convex model on embeddings provides a reasonable approximation for influence estimation in non-convex scenarios.
- **Evidence anchors:**
  - [section] "we adopt the same strategy as in the work of Li and Liu [52], which uses a surrogate convex model on the embeddings extracted by the non-convex model"
  - [section] "achieve promising results as illustrated in Section 5.3"
  - [corpus] Weak - corpus doesn't discuss surrogate model approaches for influence function
- **Break condition:** If the surrogate model fails to capture the relevant dynamics of the non-convex model, or if the embedding space doesn't preserve influence relationships, this mechanism breaks.

## Foundational Learning

- **Concept:** Influence function and its mathematical foundations
  - **Why needed here:** Understanding how influence function works is crucial for implementing salutary labeling and knowing its limitations
  - **Quick check question:** What are the requirements for influence function to work properly (convex loss, positive definite Hessian, etc.)?

- **Concept:** Active learning principles and traditional selection strategies
  - **Why needed here:** To understand how salutary labeling differs from and improves upon existing active learning approaches
  - **Quick check question:** How do uncertainty-based and representativeness-based active learning methods differ from influence-based methods?

- **Concept:** Label noise and its impact on model training
  - **Why needed here:** The paper's key insight is that ground truth labels aren't always optimal; understanding label noise helps explain why salutary labels might outperform ground truth
  - **Quick check question:** In what scenarios might a non-ground-truth label actually improve model performance more than the correct label?

## Architecture Onboarding

- **Component map:** Sample → Compute influence for all labels → Select label with max influence → Rank samples → Select top k → Assign labels → Retrain model

- **Critical path:** Sample → Compute influence for all labels → Select label with max influence → Rank samples → Select top k → Assign labels → Retrain model

- **Design tradeoffs:**
  - Computational cost vs. accuracy: Computing influence for all labels is expensive but necessary for correct label assignment
  - Convex vs. non-convex models: Requires different approaches (direct vs. surrogate)
  - Query budget size: Small budgets maintain distinction between methods; large budgets may saturate performance

- **Failure signatures:**
  - Poor correlation between influence estimates and actual impact
  - Hessian matrix becomes non-invertible or unstable
  - Surrogate model fails to capture relevant model dynamics
  - Computational resources exhausted during influence calculations

- **First 3 experiments:**
  1. Implement influence function calculation on a simple convex model (logistic regression) and verify it produces reasonable rankings
  2. Add label selection component and test on a binary classification dataset to verify salutary labels are being assigned
  3. Extend to a non-convex model using surrogate approach and verify performance on a simple NLP task

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions but implicitly raises several important research directions regarding the accuracy of influence function estimations, optimal query budget sizes, and extension to non-convex models.

## Limitations

- Computational complexity of computing influence for all possible labels across the unlabeled pool represents a significant practical limitation
- The extension to non-convex models via surrogate approaches introduces an additional layer of approximation whose reliability is not thoroughly validated
- The paper lacks runtime comparisons and does not discuss computational budgets or wall-clock time requirements

## Confidence

**High confidence**: The paper successfully demonstrates that salutary labeling can achieve competitive performance with traditional active learning methods while eliminating human annotation requirements across nine benchmark datasets.

**Medium confidence**: The claim that salutary labels often outperform ground truth labels is supported by experimental results but lacks theoretical justification and doesn't explain when or why this phenomenon occurs.

**Low confidence**: The computational feasibility claims are weak. The paper states the method is "computationally efficient" without providing runtime comparisons or discussing scalability to larger datasets.

## Next Checks

1. **Correlation quantification**: Measure the absolute error between influence function predictions and actual loss changes when adding samples, not just the correlation coefficient. This would reveal whether influence functions provide actionable rankings or merely relative orderings.

2. **Computational complexity analysis**: Benchmark the wall-clock time for salutary labeling versus traditional active learning methods across different dataset sizes. Include GPU/CPU requirements and scaling behavior as the unlabeled pool grows.

3. **Robustness to noise testing**: Systematically vary the proportion of mislabeled samples in the training data and measure how salutary labeling performance degrades compared to ground truth labeling. This would quantify the practical limits of the "ground truth isn't always optimal" claim.