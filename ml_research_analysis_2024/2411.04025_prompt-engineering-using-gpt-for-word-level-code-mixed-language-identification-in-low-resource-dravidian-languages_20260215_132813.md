---
ver: rpa2
title: Prompt Engineering Using GPT for Word-Level Code-Mixed Language Identification
  in Low-Resource Dravidian Languages
arxiv_id: '2411.04025'
source_url: https://arxiv.org/abs/2411.04025
tags: []
core_contribution: This study investigates language identification for word-level
  code-mixed text in Dravidian languages (Tamil and Kannada) using GPT-3.5 Turbo via
  prompt engineering. The task addresses the challenge of accurately classifying individual
  words in multilingual social media text that blends Dravidian languages with English.
---

# Prompt Engineering Using GPT for Word-Level Code-Mixed Language Identification in Low-Resource Dravidian Languages

## Quick Facts
- arXiv ID: 2411.04025
- Source URL: https://arxiv.org/abs/2411.04025
- Reference count: 40
- Primary result: GPT-3.5 Turbo with prompt engineering achieves macro F1 of 0.4493 for Kannada and 0.3312 for Tamil in word-level code-mixed language identification

## Executive Summary
This study investigates language identification for word-level code-mixed text in Dravidian languages (Tamil and Kannada) using GPT-3.5 Turbo via prompt engineering. The task addresses the challenge of accurately classifying individual words in multilingual social media text that blends Dravidian languages with English. A prompt-based approach was employed, leveraging zero-shot prompting with GPT-3.5 Turbo at different temperature settings. The results show that the Kannada model outperformed the Tamil model across most metrics, with macro F1 scores of 0.4493 versus 0.3312 respectively.

## Method Summary
The researchers employed a prompt engineering approach using GPT-3.5 Turbo for word-level code-mixed language identification in Tamil and Kannada. They utilized zero-shot prompting with temperature variations to optimize model performance. The methodology focused on classifying individual words in code-mixed social media text that combines Dravidian languages with English. No traditional machine learning baselines were used for comparison, and the study did not include detailed error analysis or ablation studies to understand model behavior systematically.

## Key Results
- Kannada achieved macro F1 of 0.4493, macro precision of 0.5474, and macro recall of 0.4241 with accuracy of 0.6994
- Tamil achieved macro F1 of 0.3312, macro precision of 0.3259, and macro recall of 0.3657 with accuracy of 0.6689
- Kannada significantly outperformed Tamil across all evaluation metrics, demonstrating language-specific performance variations

## Why This Works (Mechanism)
Unknown: The paper does not provide explicit explanation of the underlying mechanism. Based on the methodology, it appears that GPT-3.5 Turbo's strong language understanding capabilities enable it to distinguish between Dravidian languages and English through contextual patterns in the prompt, though this remains speculative without further analysis.

## Foundational Learning
- Code-mixing: The blending of two or more languages within a single utterance or text - essential for understanding the problem domain and evaluation context
- Prompt engineering: The process of designing effective input prompts for language models - critical for achieving optimal zero-shot performance
- Zero-shot learning: Model's ability to perform tasks without specific training examples - relevant for understanding the approach's limitations and applicability
- Dravidian languages: A language family including Tamil and Kannada - important for understanding the linguistic challenges and potential generalization to other languages in the family

## Architecture Onboarding
Component map: Input text -> GPT-3.5 Turbo (zero-shot prompting with temperature variation) -> Language classification output
Critical path: Word extraction from code-mixed text -> Prompt generation -> LLM inference -> Classification decision
Design tradeoffs: Zero-shot prompting avoids need for labeled training data but may limit performance compared to fine-tuned models; temperature variation allows exploration of output diversity but optimal settings not thoroughly analyzed
Failure signatures: Systematic misclassifications likely occur with ambiguous words shared between languages or English loanwords; performance gap between Tamil and Kannada suggests language-specific challenges
First experiments:
1. Test prompt variations (few-shot vs zero-shot) to assess impact on classification accuracy
2. Vary temperature settings systematically to identify optimal values for each language
3. Implement confidence thresholding to filter uncertain predictions and evaluate precision-recall tradeoffs

## Open Questions the Paper Calls Out
Unknown: The paper does not explicitly call out specific open questions for future research.

## Limitations
- Narrow focus on only two Dravidian languages limits generalizability to other language pairs
- No comparison to traditional machine learning approaches (SVM, LSTM) to establish baseline performance
- Lack of detailed error analysis prevents understanding of systematic failure patterns

## Confidence
High confidence in methodology and result presentation; Medium confidence in practical applicability due to low absolute performance metrics and unexplored language-specific factors.

## Next Checks
1. Conduct ablation studies comparing GPT-3.5 Turbo performance against traditional machine learning approaches (e.g., SVM, LSTM) using the same datasets to establish baseline comparisons
2. Perform detailed error analysis to identify specific patterns in misclassifications, particularly examining whether certain language pairs or word types consistently cause errors
3. Test the model on additional Dravidian languages (e.g., Telugu, Malayalam) to determine if the observed Tamil-Kannada performance gap generalizes to other language pairs in the family