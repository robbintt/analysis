---
ver: rpa2
title: 'EvoGPT-f: An Evolutionary GPT Framework for Benchmarking Formal Math Languages'
arxiv_id: '2402.16878'
source_url: https://arxiv.org/abs/2402.16878
tags:
- light
- lean
- loss
- formal
- validation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EvoGPT-f, an evolutionary framework for the
  first systematic quantitative analysis of the differential machine learnability
  of five formal math corpora (Lean 3, Lean 4, Coq, HOL 4, HOL Light) using four tokenization
  methods (character, word-level, Byte Pair Encoding, and StarCoder tokenizer). The
  framework evolves populations of Transformers to optimize training hyperparameters
  and architectures for learning the statistical structure of each formal language.
---

# EvoGPT-f: An Evolutionary GPT Framework for Benchmarking Formal Math Languages

## Quick Facts
- arXiv ID: 2402.16878
- Source URL: https://arxiv.org/abs/2402.16878
- Authors: Johnathan Mercer
- Reference count: 40
- Primary result: Introduces evolutionary framework for quantitative analysis of differential machine learnability across five formal math languages

## Executive Summary
This paper presents EvoGPT-f, an evolutionary framework for the first systematic quantitative analysis of machine learnability across formal mathematical languages. The framework evolves populations of Transformers to optimize training hyperparameters and architectures for learning the statistical structure of formal languages. Using this approach, the study benchmarks five formal math corpora (Lean 3, Lean 4, Coq, HOL 4, HOL Light) with four tokenization methods, revealing significant differences in learnability between languages and versions.

## Method Summary
EvoGPT-f uses genetic algorithms to evolve populations of Transformers, optimizing their training hyperparameters and architectures to minimize validation loss on formal math corpora. The framework processes five formal mathematical languages using four tokenization methods, tracking fitness improvements across generations. Validation loss is normalized using baseline entropy and overfitting penalties to enable cross-corpus comparisons. The evolutionary process runs for 15 generations with population size 10, using genetic operators including mutation and crossover to explore the hyperparameter space.

## Key Results
- Lean 4 and Coq exhibit significantly greater machine learnability than other formal languages
- Lean 4 shows 20-50% improvement in machine learnability compared to Lean 3
- BPE tokenization generally outperforms character and word-level methods across corpora

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The evolutionary algorithm improves model fitness by selecting architectures and hyperparameters that minimize validation loss on formal math corpora.
- Mechanism: Natural selection pressures favor GPT configurations with lower validation loss, leading to population improvement over generations.
- Core assumption: Validation loss is a reliable proxy for machine learnability of formal languages.
- Evidence anchors:
  - [abstract] "Results show that Lean 4 and Coq exhibit significantly greater facility for machine learning, with Lean 4 showing a 20-50% improvement in machine learnability compared to Lean 3."
  - [section 4.1] "We observe in Figure 2 the strict dominance (in game-theoretic terms) of the validation loss curves of latter generations over earlier generations; this behavior is consistent across corpora and tokenization methods."

### Mechanism 2
- Claim: Normalization by baseline entropy adjusts for inherent prediction difficulty across different tokenization methods and corpora.
- Mechanism: By dividing validation loss by corpus entropy, we account for the varying information content in different formal languages.
- Core assumption: Shannon entropy captures the fundamental difficulty of predicting token sequences in formal languages.
- Evidence anchors:
  - [section 4.2] "Let Hc,k be the Shannon entropy of the tokens for a given (c, k). The normalized validation loss Ln1 c,k is defined by: Ln1 c,k = Lv c,k ∗ (1/exp(−(Lv c,k /Lt c,k − 1)2)) ∗ (min c,k Hc,k/Hc,k)"
  - [section 4.2] "The first component adjusts for the relative entropy level (i.e. inherent prediction difficulty) of the corpora and tokenization method using the entropies in Table 2."

### Mechanism 3
- Claim: The overfitting penalty component of normalization accounts for differences in train/validation loss ratios across corpora.
- Mechanism: Gaussian penalty based on (validation loss / training loss - 1) amplifies losses when models overfit, adjusting for varying generalization capabilities.
- Core assumption: Higher validation/training loss ratios indicate overfitting that should be penalized in cross-corpus comparisons.
- Evidence anchors:
  - [section 4.2] "The first Gaussian component is an overfitting penalty which amplifies the loss based on the discrepancy between the model's training and validation loss."
  - [section 4.1] "Turning to the validation of the evolutionary process, we observe in Figure 2 the strict dominance (in game-theoretic terms) of the validation loss curves of latter generations over earlier generations; this behavior is consistent across corpora and tokenization methods."

## Foundational Learning

- Concept: Genetic algorithms and evolutionary optimization
  - Why needed here: The framework uses evolutionary methods to search the hyperparameter space for optimal GPT configurations.
  - Quick check question: What are the three main genetic operators used in EvoGPT-f to evolve populations of Transformers?

- Concept: Transformer architecture and tokenization
  - Why needed here: Understanding how different tokenization methods affect model performance is crucial for interpreting the benchmarking results.
  - Quick check question: How does the choice between character-level and word-level tokenization affect the vocabulary size and potential model performance?

- Concept: Statistical normalization and entropy
  - Why needed here: The benchmarking methodology relies on normalizing validation loss by baseline entropy to account for varying prediction difficulties.
  - Quick check question: What does Shannon entropy measure in the context of formal math languages, and why is it important for comparing machine learnability?

## Architecture Onboarding

- Component map: Data preprocessing pipeline -> Evolutionary algorithm engine -> GPT training module -> Analysis dashboard (EvoEDA)
- Critical path: load corpus -> tokenize -> initialize population -> evolve through generations (train -> evaluate -> select -> mutate/crossover) -> analyze results
- Design tradeoffs: Trades computational efficiency for comprehensive benchmarking by training multiple models per generation across multiple tokenization methods
- Failure signatures: Watch for exploding gradients, overfitting on small corpora, and memory overflow during training
- First 3 experiments:
  1. Run EvoGPT-f on a single corpus with character tokenization to validate the evolutionary algorithm works as expected.
  2. Test different population sizes (5, 10, 20) on the same corpus to understand the impact on convergence speed and quality.
  3. Compare BPE tokenization with varying vocabulary sizes on a single corpus to validate the preliminary vocabulary selection methodology.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the observed performance gap between Lean 3 and Lean 4 reflect fundamental differences in language design or merely implementation improvements in the proof assistant?
- Basis in paper: [explicit] The paper notes "a significant improvement of ∼ 20 − 50% in machine learnability between these versions" and attributes this to Lean's redesign from version 3 to 4
- Why unresolved: The framework measures learnability of formal mathematical content rather than language design features themselves; implementation optimizations in the proof assistant could affect corpus quality without changing the underlying language
- What evidence would resolve it: Controlled experiments comparing identical mathematical content formalized in both versions, or analysis of specific language features that changed between versions

### Open Question 2
- Question: How do tokenization choices interact with language-specific syntactic structures, and could optimal tokenization differ by corpus?
- Basis in paper: [explicit] The paper uses a preliminary BPE vocabulary size selection study that is described as "rudimentary" and notes that "the optimal vocabulary size is entangled with the architecture optimization"
- Why unresolved: The study used fixed vocabulary sizes per corpus rather than optimizing tokenization jointly with model architecture, and the paper acknowledges this limitation
- What evidence would resolve it: Joint optimization of tokenization and model architecture, or systematic comparison of different tokenization strategies (including byte-level) for each corpus

### Open Question 3
- Question: How does corpus size affect the validity of the learnability comparisons, particularly for HOL Light which shows significant overfitting?
- Basis in paper: [inferred] The paper observes "significant evolutionary departure of validation from training (20-40%) for HOL Light systematically across tokenization methods" and notes this was "to be expected, based on the relatively smaller size of the HOL Light corpus"
- Why unresolved: The paper acknowledges the corpus size issue but doesn't fully explore how to normalize for corpus size effects or whether smaller corpora are inherently harder to learn
- What evidence would resolve it: Experiments with downsampled versions of larger corpora to match HOL Light's size, or statistical methods to account for corpus size in the learnability metric

## Limitations

- The normalization methodology assumes Shannon entropy reliably captures prediction difficulty across diverse formal languages
- The framework optimizes for validation loss rather than directly measuring proof generation capability
- Relatively small corpus sizes (5.5M-70.5M characters) may limit generalizability of evolutionary optimization results

## Confidence

**High Confidence**: The evolutionary mechanism for improving model fitness through validation loss optimization is well-established and empirically validated
**Medium Confidence**: The specific 20-50% improvement claims for Lean 4 depend on normalization assumptions about entropy as a difficulty proxy
**Low Confidence**: The connection between benchmarked learnability and actual proof generation capability remains speculative without direct validation

## Next Checks

1. **Cross-validation of evolutionary results**: Run the evolutionary framework with multiple random seeds (minimum 5) on the same corpus-tokenization combinations to establish statistical significance of the observed fitness improvements and ensure results are not artifacts of particular initialization.

2. **Ground-truth proof generation validation**: Select the top-performing models from each language-tokenization combination and test their actual proof generation capabilities on a standardized set of formal math problems, comparing against their validation loss rankings to validate the correlation between benchmarked learnability and practical performance.

3. **Entropy difficulty validation**: Conduct ablation studies where models are trained on corpora with systematically modified entropy (through controlled vocabulary reduction or structural simplification) to verify that the normalization methodology accurately captures the relationship between entropy and prediction difficulty across different formal languages.