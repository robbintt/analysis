---
ver: rpa2
title: When is Tree Search Useful for LLM Planning? It Depends on the Discriminator
arxiv_id: '2402.10890'
source_url: https://arxiv.org/abs/2402.10890
tags:
- planning
- methods
- tree
- search
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the role of discriminators in language
  agents using large language models (LLMs) for multi-step problem solving. It examines
  how discrimination accuracy affects the performance of agents using advanced planning
  methods like iterative correction and tree search compared to simpler re-ranking.
---

# When is Tree Search Useful for LLM Planning? It Depends on the Discriminator

## Quick Facts
- arXiv ID: 2402.10890
- Source URL: https://arxiv.org/abs/2402.10890
- Reference count: 24
- This paper investigates how discrimination accuracy affects the performance of advanced planning methods compared to simpler re-ranking approaches in LLM-based planning.

## Executive Summary
This paper examines the critical role of discriminators in language agent planning, revealing that advanced planning methods like iterative correction and tree search only outperform simpler re-ranking when discriminators achieve at least 90% accuracy. Through experiments on text-to-SQL parsing and mathematical reasoning tasks, the authors demonstrate that current LLM-based discriminators fall short of this threshold, limiting the practical utility of sophisticated planning methods. The study also shows that incorporating environmental observations (executability checks and execution results) can significantly improve discrimination accuracy, though tree search remains substantially slower than alternative approaches with negligible performance gains.

## Method Summary
The paper implements a generator-discriminator framework where a generator produces candidate solutions, a discriminator evaluates them, and a planning method guides the search process. Three planning methods are compared: re-ranking (selecting the highest-scoring candidate), iterative correction (generating corrected versions of the best candidate), and tree search (using Monte Carlo simulations to explore the solution space). The framework is evaluated on two real-world tasks - text-to-SQL parsing using Spider and Bird datasets, and mathematical reasoning using GSM8K - with various LLM discriminators including open-source models (CodeLlama variants), closed-source models (GPT-3.5/4), and fine-tuned versions. Simulation experiments with oracle discriminators establish the relationship between discrimination accuracy and planning performance.

## Key Results
- Advanced planning methods (iterative correction and tree search) only significantly outperform re-ranking when discriminator accuracy exceeds 90%
- Environmental observations (executability checks and execution results) improve LLM-based discriminator accuracy by up to 30.2 absolute points on text-to-SQL tasks
- Tree search is 10-20 times slower than other methods but provides negligible performance gains when using LLM-based discriminators
- Current open-source LLMs demonstrate mediocre discrimination abilities, struggling particularly with identifying non-executable programs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Discrimination accuracy directly determines the effectiveness of advanced planning methods over re-ranking
- Mechanism: The discriminator guides the planning method toward correct solutions by evaluating partial plans. Low accuracy causes incorrect acceptance of wrong plans or rejection of correct ones
- Core assumption: Binary classification accuracy correlates with planning guidance ability
- Evidence anchors:
  - [abstract] "advanced planning methods demand discriminators with at least 90% accuracy to achieve significant improvements over re-ranking"
  - [section 5.2] "discrimination accuracy closely correlates with the performance of agents on all three datasets"
- Break condition: When discrimination accuracy falls below 90%, performance gains become negligible

### Mechanism 2
- Claim: Environmental observations significantly improve LLM-based discriminator accuracy
- Mechanism: Adding execution feedback allows discriminators to filter non-executable programs and make more informed decisions
- Core assumption: LLM discriminators struggle with non-executable program identification and benefit from execution feedback
- Evidence anchors:
  - [section 6.2] "we improve the discrimination accuracy of LLMs by up to 30.2 and 8.4 absolute points on text-to-SQL parsing and mathematical reasoning, respectively"
  - [section 6.1] "LLM-based discriminators can correctly assess a decent number of language agents' actions with their environmental observations"
- Break condition: When environmental feedback is unavailable or unreliable

### Mechanism 3
- Claim: Advanced planning methods may not balance accuracy and efficiency with LLM-based discriminators
- Mechanism: Tree search's computational overhead (10-20x slower) outweighs benefits when using imperfect LLM discriminators
- Core assumption: The computational cost of tree search exceeds its marginal performance benefits with imperfect discriminators
- Evidence anchors:
  - [abstract] "tree search is at least 10–20 times slower but leads to negligible performance gains"
  - [section 5.2] "the inference time for iterative correction increases as the accuracy threshold is raised"
- Break condition: When using oracle-level discriminators (≥90% accuracy), the tradeoff may become acceptable

## Foundational Learning

- Concept: Discriminator-guided planning framework
  - Why needed here: Understanding generator-discriminator-planning method interaction is fundamental to grasping discrimination accuracy importance
  - Quick check question: What role does the discriminator play in guiding the planning process?

- Concept: Binary question answering for discrimination
  - Why needed here: Discrimination is formulated as binary question answering, key to understanding accuracy measurement
  - Quick check question: How is the discrimination score computed in the binary question answering formulation?

- Concept: Monte Carlo Tree Search (MCTS) mechanics
  - Why needed here: Tree search implementation uses MCTS principles, crucial for understanding its computational overhead
  - Quick check question: What are the five steps of the MCTS algorithm implemented in this paper?

## Architecture Onboarding

- Component map: Generator (CodeLlama-13B-Instruct) → Discriminator (various LLMs) → Planning Method (re-ranking, iterative correction, tree search) → Environment (execution results)
- Critical path: Generation → Discrimination → Planning decision → Action execution → Feedback to discriminator
- Design tradeoffs: Accuracy vs. efficiency tradeoff in tree search; discrimination accuracy threshold requirement for advanced planning methods
- Failure signatures: Discrimination errors (assigning higher scores to wrong programs); exploration errors (failing to find correct programs before termination)
- First 3 experiments:
  1. Run simulation experiments with oracle discriminators at different accuracy thresholds (τ = 0.6, 0.8, 0.9, 1.0) to observe performance correlation
  2. Implement executability check enhancement and measure discrimination accuracy improvement
  3. Add execution result feedback to discriminator and evaluate end-to-end performance with enhanced discriminators

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of generator perplexity on planning methods, and how can it be incorporated into the evaluation framework?
- Basis in paper: [explicit] The paper mentions that the generator's perplexity can be transformed into a probability and multiplied by the discriminator's score, but excludes such use due to mixed results in preliminary experiments
- Why unresolved: The paper does not explore this further or provide evidence on how the generator's perplexity affects planning methods
- What evidence would resolve it: Conducting a comprehensive study on the impact of generator perplexity on planning methods, including experiments with different ways of incorporating it into the evaluation framework

### Open Question 2
- Question: How do natural language plans affect the overall performance of agents for mathematical reasoning, considering the intermediate semantic parsing step?
- Basis in paper: [inferred] The paper focuses on formal language plans (programs) and acknowledges that natural language plans require an additional semantic parsing step
- Why unresolved: The paper does not explore the use of natural language plans or investigate how the intermediate semantic parsing step affects overall performance
- What evidence would resolve it: Conducting experiments with natural language plans and comparing their performance with formal language plans, while analyzing the impact of the intermediate semantic parsing step

### Open Question 3
- Question: How does instruction-tuning impact models' discrimination accuracy, and what are the potential benefits of extending the study to other LLMs of code?
- Basis in paper: [explicit] The paper mentions that it focuses on instruction-tuned LLMs that have seen code data during pre-training and acknowledges that future research may extend the study to other LLMs of code
- Why unresolved: The paper does not provide evidence on the impact of instruction-tuning on models' discrimination accuracy or explore the potential benefits of using other LLMs of code
- What evidence would resolve it: Conducting an ablation study on the impact of instruction-tuning on models' discrimination accuracy and comparing the performance of different LLMs of code

## Limitations

- The 90% discrimination accuracy threshold may be task-specific rather than universal across different domains
- The study focuses exclusively on programming tasks (text-to-SQL and math reasoning), limiting generalizability to other domains
- Tree search's inefficiency (10-20x slower) is clearly demonstrated but potential hybrid approaches are not explored
- Environmental observation enhancements show promise but computational overhead and scalability are not fully analyzed

## Confidence

**High Confidence**: The correlation between discrimination accuracy and planning method performance is strongly supported by consistent simulation experiment results across all three datasets.

**Medium Confidence**: The specific 90% accuracy threshold requirement for advanced planning methods is supported but may vary with task complexity and noise levels.

**Medium Confidence**: Environmental observations effectively improve discrimination accuracy, though the paper doesn't provide theoretical justification for why these specific observations are most effective.

## Next Checks

1. **Threshold Robustness Test**: Validate whether the 90% accuracy threshold generalizes across different task domains and problem complexities by testing on non-programming tasks

2. **Environmental Observation Dependency Analysis**: Systematically measure the marginal benefit of each type of environmental observation and quantify performance degradation when each is removed

3. **Efficiency Optimization Experiment**: Implement and evaluate tree search with adaptive depth limits or early termination conditions based on discrimination confidence scores to determine if the accuracy-efficiency tradeoff can be improved