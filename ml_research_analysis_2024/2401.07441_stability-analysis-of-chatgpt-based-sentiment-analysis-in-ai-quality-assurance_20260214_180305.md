---
ver: rpa2
title: Stability Analysis of ChatGPT-based Sentiment Analysis in AI Quality Assurance
arxiv_id: '2401.07441'
source_url: https://arxiv.org/abs/2401.07441
tags:
- chatgpt
- sentiment
- arxiv
- perturbation
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates stability in a ChatGPT-based sentiment
  analysis system, focusing on operational uncertainty and model robustness. It evaluates
  how prompt design, timing, and text perturbations affect ChatGPT's performance.
---

# Stability Analysis of ChatGPT-based Sentiment Analysis in AI Quality Assurance

## Quick Facts
- **arXiv ID:** 2401.07441
- **Source URL:** https://arxiv.org/abs/2401.07441
- **Reference count:** 40
- **Key outcome:** Investigates ChatGPT stability in sentiment analysis, showing robustness to typos/homoglyphs/homophones but vulnerability to synonyms, with prompt engineering and temporal factors affecting consistency.

## Executive Summary
This study examines the stability and robustness of ChatGPT-based sentiment analysis systems, focusing on operational uncertainties including prompt design, timing effects, and text perturbations. The research evaluates how different types of adversarial attacks (typo, homoglyph, homophone, and synonym) impact ChatGPT's sentiment classification performance across benchmark datasets. Results demonstrate that while ChatGPT shows strong resilience against most common text perturbations, it remains notably vulnerable to synonym-based attacks, which pose a realistic threat to sentiment analysis reliability.

The investigation also reveals significant effects of prompt engineering and model version updates on output consistency, with shorter texts showing higher susceptibility to attacks. Temporal analysis uncovers non-deterministic behavior in ChatGPT's outputs, raising important considerations for practical deployment in AI quality assurance contexts. These findings highlight the need for careful system design and ongoing monitoring when implementing ChatGPT-based sentiment analysis solutions.

## Method Summary
The researchers conducted comprehensive experiments on benchmark sentiment analysis datasets, systematically testing ChatGPT's performance under various conditions. They evaluated four types of text perturbations: typo attacks, homoglyph attacks, homophone attacks, and synonym attacks. The study examined the effects of different prompt engineering approaches and analyzed temporal stability by comparing outputs across different model versions and time periods. Performance metrics were collected and analyzed to assess robustness, consistency, and vulnerability patterns across different text characteristics and attack types.

## Key Results
- ChatGPT demonstrates strong robustness against typo, homoglyph, and homophone attacks but shows notable vulnerability to synonym perturbations
- Prompt engineering significantly influences output distributions, though full exploration of prompt variations remains incomplete
- Temporal analysis reveals non-deterministic behavior in ChatGPT outputs, with shorter texts being more vulnerable to adversarial attacks

## Why This Works (Mechanism)
ChatGPT's transformer-based architecture enables it to maintain semantic understanding despite character-level perturbations like typos and homoglyphs, as these don't typically alter word meaning or context. The model's pretraining on diverse text corpora provides resilience against common orthographic variations. However, synonym attacks directly target semantic content, replacing words with meaning-equivalent alternatives that can shift sentiment interpretation, explaining the observed vulnerability. The non-deterministic behavior likely stems from ChatGPT's sampling-based decoding strategy and potential stochastic elements in its inference pipeline.

## Foundational Learning
- **Text Perturbation Attacks:** Understanding different attack types is crucial for assessing model robustness; quick check: review attack methodologies and their success rates
- **Prompt Engineering:** Different prompts can significantly affect model outputs; quick check: experiment with multiple prompt formulations on sample data
- **Temporal Stability:** Model behavior can change across versions and time; quick check: compare outputs from different model versions on identical inputs
- **Adversarial Resilience:** Models may show unexpected vulnerabilities to certain attack types; quick check: test model response to various adversarial strategies
- **Text Length Effects:** Input characteristics influence model vulnerability; quick check: analyze performance across different text length ranges

## Architecture Onboarding

**Component Map:** User Input -> Prompt Engineering -> ChatGPT Model -> Sentiment Classification -> Output Analysis

**Critical Path:** Text Input → Prompt Processing → Model Inference → Sentiment Classification → Output Evaluation

**Design Tradeoffs:** The study balances comprehensive attack testing with practical deployment considerations, prioritizing real-world applicable perturbations over theoretical extremes. The focus on benchmark datasets provides controlled conditions but may limit generalizability to production scenarios.

**Failure Signatures:** Vulnerability to synonym attacks indicates semantic-level weaknesses; non-deterministic outputs suggest stochastic processing elements; shorter text vulnerability points to context-dependency issues in the model's reasoning process.

**First Experiments:**
1. Test model response to simple typo perturbations in controlled test sentences
2. Evaluate impact of different prompt formulations on identical input text
3. Compare outputs from different ChatGPT model versions on the same sentiment analysis task

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions for future research.

## Limitations
- Evaluation focuses on four specific perturbation types, potentially missing other realistic attack vectors
- Only two model versions compared, limiting understanding of stability across broader update spectrum
- Limited sampling of prompt variations and text characteristics leaves uncertainty about full operational range

## Confidence

| Claim | Confidence |
|-------|------------|
| Robustness against typo/homoglyph/homophone attacks | High |
| Vulnerability to synonym attacks | Medium |
| Impact of prompt engineering on output consistency | Medium |
| Temporal stability and non-deterministic behavior | Low |
| Text length effects on vulnerability | Medium |

## Next Checks
1. Test system stability across broader range of text lengths and domains beyond current datasets
2. Evaluate additional adversarial attack types and more sophisticated perturbation strategies
3. Conduct long-term monitoring across multiple model versions to better characterize temporal stability patterns