---
ver: rpa2
title: 'Navigating Conflicting Views: Harnessing Trust for Learning'
arxiv_id: '2406.00958'
source_url: https://arxiv.org/abs/2406.00958
tags:
- views
- trust
- learning
- uncertainty
- opinion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a trust-based method for resolving conflicts
  in multi-view classification. The core idea is to model computational trust through
  a probability-sensitive trust discounting mechanism that evaluates the reliability
  of view-specific predictions generated by evidence-based frameworks.
---

# Navigating Conflicting Views: Harnessing Trust for Learning

## Quick Facts
- arXiv ID: 2406.00958
- Source URL: https://arxiv.org/abs/2406.00958
- Authors: Jueqing Lu; Wray Buntine; Yuanyuan Qi; Joanna Dipnall; Belinda Gabbe; Lan Du
- Reference count: 40
- Primary result: Trust-based method resolves conflicts in multi-view classification, improving accuracy and uncertainty estimation.

## Executive Summary
This paper introduces a trust-based method for resolving conflicts in multi-view classification by modeling computational trust through a probability-sensitive trust discounting mechanism. The approach evaluates the reliability of view-specific predictions and adjusts final predictions according to trust degrees, enhancing conflict resolution capabilities. Evaluated on six real-world datasets, the method demonstrates significant improvements in accuracy, agreement metrics, and uncertainty-aware prediction identification.

## Method Summary
The method uses an evidence-based framework enhanced by trust discounting, employing stage-wise training: warming up the referral network, updating the functional network, adjusting the referral network, and finally adjusting the functional network. The trust discounting mechanism applies a probability-sensitive rule based on binomial opinion theory to adjust functional opinions according to trust values computed from referral evidence. This approach resolves conflicts by amplifying contributions from reliable views while reducing influence from less reliable ones.

## Key Results
- Significant improvements in Top-1 Accuracy across six real-world datasets
- Enhanced Fleiss' Kappa and a new metric Multi-View Agreement with Ground Truth (MV AGT)
- Robust performance in identifying incorrect predictions using uncertainty scores, measured by AUC-ROC

## Why This Works (Mechanism)

### Mechanism 1
Trust discounting resolves conflicts by adjusting the belief mass of conflicting views according to their trustworthiness. Each view's evidence is converted into a trust degree using a probability-sensitive rule, which is then used to discount the view's opinion before fusion, reducing the influence of less reliable views.

### Mechanism 2
The trust discounting mechanism corrects under-estimation of uncertainty in conflicting views. By applying trust discounting, the uncertainty of the fused opinion increases when views conflict, even if individual view uncertainties are low, aligning the uncertainty with actual disagreement among views.

### Mechanism 3
Stage-wise training stabilizes the optimization of the trust discounting mechanism. The training process is divided into stages, first warming up the referral network, then updating the functional network, and finally adjusting the referral network, preventing numerical instability and ensuring proper learning of trust values.

## Foundational Learning

- **Concept: Subjective Logic (SL)** - Why needed: SL provides the mathematical framework for representing and combining uncertain beliefs from different views, essential for the trust discounting mechanism. Quick check: What are the three components of a multinomial opinion in SL, and how do they relate to belief, uncertainty, and base rate?

- **Concept: Evidence Theory** - Why needed: Evidence Theory allows the model to collect and evaluate evidence from each view, which is then used to compute trust values for the trust discounting mechanism. Quick check: How is evidence collected from each view, and how is it transformed into belief masses and uncertainty in the Evidential Deep Learning framework?

- **Concept: Dirichlet Distribution** - Why needed: The Dirichlet Distribution is used to model the distribution of class probabilities for each view, essential for computing belief masses and uncertainty in the Evidential Deep Learning framework. Quick check: How are the parameters of the Dirichlet Distribution related to the evidence collected from each view, and how are belief masses and uncertainty derived from these parameters?

## Architecture Onboarding

- **Component map**: Input multi-view data -> Functional network generates evidence -> Referral network generates referral evidence -> Trust discounting mechanism computes trust values -> Fusion module combines trust-discounted opinions -> Output final prediction and uncertainty

- **Critical path**: Input multi-view data flows through functional networks to generate evidence, then referral networks generate referral evidence for trust computation. Trust values adjust functional opinions before fusion, producing final predictions and uncertainty estimates.

- **Design tradeoffs**: Using a separate referral network adds complexity but allows instance-wise trust evaluation. The probability-sensitive trust discounting rule is more interpretable but may be less flexible than other discounting rules. Stage-wise training ensures stability but may require careful tuning of warm-up epochs.

- **Failure signatures**: If trust discounting fails to resolve conflicts, model performance may degrade especially on datasets with high view disagreement. If staged training is not properly implemented, the model may fail to converge or learn incorrect trust values. If the trust network overfits, generalization performance may suffer.

- **First 3 experiments**: 1) Evaluate model performance on synthetic dataset with known view conflicts to verify trust discounting correctly resolves these conflicts. 2) Compare model's uncertainty estimates with actual prediction correctness on held-out test set to assess uncertainty correction effectiveness. 3) Ablate stage-wise training by training without it to assess impact on model stability and performance.

## Open Questions the Paper Calls Out

### Open Question 1
How does the proposed trust discounting mechanism generalize to multi-class classification problems with more than three classes, particularly when conflicts arise between multiple views across different classes? The current experimental setup focuses on datasets with a relatively small number of classes, and the paper does not provide insights into how the method would perform or need to be adapted for scenarios with a significantly larger class space.

### Open Question 2
What is the impact of the trust discounting mechanism on the interpretability of the model's predictions, particularly in high-stakes domains like medical diagnosis? While the paper demonstrates effectiveness in improving prediction accuracy, it does not explore how this approach influences the model's transparency and explainability, which are crucial factors in high-stakes domains.

### Open Question 3
How does the proposed method handle scenarios where the ground truth label is ambiguous or uncertain, such as in cases where multiple diagnoses are plausible? The paper focuses on resolving conflicts between views but does not explicitly address situations where the ground truth label itself is uncertain or subject to interpretation.

## Limitations

- The effectiveness of trust discounting heavily relies on the referral network's ability to accurately assess view reliability, but limited analysis is provided of referral network performance or failure modes
- The staged training approach prevents early numerical instability, yet the optimal number of warm-up epochs is not justified
- The new MV AGT metric, while intuitive, lacks comparison with established agreement measures to validate its superiority

## Confidence

- **High confidence**: Mathematical formulation of trust discounting and its theoretical grounding in subjective logic
- **Medium confidence**: Practical effectiveness of stage-wise training, primarily justified by stability concerns rather than performance gains
- **Low confidence**: Generalization of results across diverse datasets, given limited ablation studies on architectural choices and training hyperparameters

## Next Checks

1. Conduct ablation studies varying the number of warm-up epochs to determine optimal stage-wise training duration and its impact on convergence
2. Compare MV AGT with established inter-rater agreement metrics (e.g., Krippendorff's alpha) across multiple datasets to validate its discriminative power
3. Analyze referral network predictions on a held-out validation set to assess whether trust scores correlate with actual view reliability and identify potential overfitting