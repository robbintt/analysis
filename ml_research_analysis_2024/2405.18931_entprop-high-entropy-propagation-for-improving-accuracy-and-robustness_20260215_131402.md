---
ver: rpa2
title: 'EntProp: High Entropy Propagation for Improving Accuracy and Robustness'
arxiv_id: '2405.18931'
source_url: https://arxiv.org/abs/2405.18931
tags: []
core_contribution: This paper addresses the challenge of improving both standard accuracy
  and robustness against out-of-distribution domains in deep neural networks. The
  proposed method, High Entropy Propagation (EntProp), introduces a novel disentangled
  learning approach using auxiliary batch normalization layers (ABNs) that distinguishes
  sample domains based on entropy.
---

# EntProp: High Entropy Propagation for Improving Accuracy and Robustness

## Quick Facts
- arXiv ID: 2405.18931
- Source URL: https://arxiv.org/abs/2405.18931
- Authors: Shohei Enomoto
- Reference count: 23
- One-line primary result: Introduces EntProp method that improves both standard accuracy and robustness by using entropy-based sample selection with auxiliary batch normalization layers

## Executive Summary
EntProp addresses the challenge of improving both standard accuracy and robustness against out-of-distribution domains in deep neural networks. The method introduces a novel disentangled learning approach using auxiliary batch normalization layers (ABNs) that distinguishes sample domains based on entropy. EntProp selects high-entropy samples from clean data and feeds them to the ABN-applied network, further increasing their entropy through data augmentation and free adversarial training.

## Method Summary
EntProp is a disentangled learning approach that uses auxiliary batch normalization (ABN) layers to improve both standard accuracy and robustness. The method selects high-entropy samples from clean data and trains them using ABNs, while clean samples use main batch normalization (MBN) layers. Entropy-increasing transformations like MixUp and free adversarial training are applied to high-entropy samples to bring them further away from the in-distribution domain. This separation prevents mixing of BN layer statistics and allows more efficient disentangled learning with mixture distributions.

## Key Results
- Achieves higher Hscore (harmonic mean of standard and robust accuracy) compared to baseline methods across various architectures and datasets
- Shows significant improvements on small datasets by mitigating overfitting issues through effective entropy-based undersampling
- Maintains lower training costs compared to traditional adversarial training methods
- Demonstrates effectiveness on multiple datasets including CIFAR-100, CUB-200-2011, OxfordPets, StanfordCars, and ImageNet

## Why This Works (Mechanism)

### Mechanism 1
High-entropy samples fed to auxiliary batch normalization (ABN) layers improve both standard accuracy and robustness by effectively disentangling in-distribution and out-of-distribution domains. The method selects high-entropy samples from clean data and trains them using ABNs, while clean samples use main batch normalization (MBN) layers. This separation prevents mixing of BN layer statistics and affine parameters, allowing the MBN-applied network to learn better features from both domains.

### Mechanism 2
Data augmentation and free adversarial training increase sample entropy without additional training costs, enhancing model accuracy. MixUp linearly combines two samples, increasing entropy by assigning two labels to the combined sample. Free adversarial training reuses gradients from the previous iteration to generate adversarial examples without extra computational cost.

### Mechanism 3
Entropy-based undersampling mitigates overfitting on small datasets by selectively training ABN-applied networks with high-entropy samples. By selecting only high-entropy samples for ABN training, the method reduces the risk of overfitting that occurs when using all samples for adversarial training, especially on small datasets.

## Foundational Learning

- **Entropy as uncertainty measure**: Why needed - Entropy distinguishes between in-distribution and out-of-distribution samples by measuring the uncertainty of model predictions. Quick check - How does the entropy of a model's prediction relate to the certainty of its classification?
- **Disentangled learning via mixture distribution**: Why needed - Allows the model to learn features from both clean (in-distribution) and transformed (out-of-distribution) samples without mixing BN statistics. Quick check - Why is it beneficial to use different BN layers for clean and transformed samples?
- **Adversarial training trade-offs**: Why needed - Understands the balance between standard accuracy and robustness, which EntProp aims to improve simultaneously. Quick check - What is the trade-off between standard accuracy and robustness in adversarial training?

## Architecture Onboarding

- **Component map**: Input -> Entropy Calculation -> Sample Selection -> Data Augmentation (MixUp) -> Free Adversarial Training -> Loss Computation -> Parameter Update (MBN and ABN networks)
- **Critical path**: 1. Compute entropy for clean samples using MBN-applied network 2. Select top k% high-entropy samples 3. Apply data augmentation (MixUp) to selected samples 4. Generate adversarial examples using free adversarial training 5. Compute losses and update network parameters
- **Design tradeoffs**: Balancing k (percentage of high-entropy samples) vs. computational cost and performance; Number of iterations n for adversarial attacks vs. training time and robustness; Using entropy vs. other uncertainty metrics for sample selection
- **Failure signatures**: If entropy does not correlate with domain distinction, leading to ineffective sample selection; If adversarial training introduces instability or degrades standard accuracy; If the method leads to overfitting on small datasets despite undersampling
- **First 3 experiments**: 1. Implement entropy calculation and high-entropy sample selection; verify that selected samples have higher entropy than others. 2. Add data augmentation (MixUp) to selected samples; confirm entropy increase without additional training cost. 3. Integrate free adversarial training; ensure adversarial examples are generated without extra computational overhead.

## Open Questions the Paper Calls Out

### Open Question 1
Does the entropy-based domain distinction in EntProp generalize to other uncertainty metrics beyond those tested? The paper states "All metrics show no significant differences" but notes "The results show that different architectures have different effective metrics." This question remains unresolved as the study only tested a limited set of uncertainty metrics and did not explore a broader range across different architectures.

### Open Question 2
How does EntProp's performance scale with dataset size, particularly for extremely large or small datasets? While the paper mentions EntProp is "highly effective at training on small datasets" and shows improvement over AdvProp which overfits on small data, it does not explore extreme dataset sizes. Experiments on datasets with orders of magnitude more or fewer samples would reveal EntProp's performance boundaries.

### Open Question 3
Can EntProp be effectively combined with other disentangled learning approaches that use different transformation types? The paper discusses EntProp's compatibility with vision transformers and potential combination with loss functions like GPaCo, but does not explore combinations with other disentangled learning methods using different transformations. Experiments combining EntProp with other disentangled learning frameworks using diverse transformation types would determine its versatility.

## Limitations

- The core assumption that high-entropy clean samples are similar to out-of-distribution samples lacks direct empirical validation within the paper
- Exact implementation details of entropy calculation and the threshold for sample selection are not fully specified
- The entropy-based undersampling approach for mitigating overfitting on small datasets is proposed but not thoroughly validated

## Confidence

- **High Confidence**: Experimental results demonstrating improved Hscore across multiple datasets and architectures
- **Medium Confidence**: Mechanism of disentangled learning through ABNs is logically sound but specific role of entropy needs more validation
- **Medium Confidence**: Claims about mitigating overfitting through entropy-based undersampling are plausible but theoretical justification is limited

## Next Checks

1. **Validation of Entropy-Sample Correlation**: Conduct experiments to verify that high-entropy samples selected by EntProp are indeed more similar to out-of-distribution samples than randomly selected samples, using established out-of-distribution detection metrics.

2. **Ablation Study on Entropy Threshold**: Perform an ablation study varying the entropy threshold for sample selection to determine the optimal balance between selecting truly out-of-distribution-like samples and maintaining sufficient training data diversity.

3. **Theoretical Analysis of Disentangled Learning**: Develop a theoretical framework or conduct controlled experiments to analyze how separating clean and high-entropy samples into different BN layers improves the learning of domain-distinct features, potentially using visualization techniques or feature space analysis.