---
ver: rpa2
title: Relative Counterfactual Contrastive Learning for Mitigating Pretrained Stance
  Bias in Stance Detection
arxiv_id: '2405.10991'
source_url: https://arxiv.org/abs/2405.10991
tags:
- stance
- samples
- bias
- detection
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of pretrained stance bias in stance
  detection, where language models embed biased knowledge into stance relation semantics.
  The authors propose Relative Counterfactual Contrastive Learning (RCCL) to mitigate
  this bias by measuring and adjusting relative stance bias instead of absolute bias.
---

# Relative Counterfactual Contrastive Learning for Mitigating Pretrained Stance Bias in Stance Detection

## Quick Facts
- arXiv ID: 2405.10991
- Source URL: https://arxiv.org/abs/2405.10991
- Authors: Jiarui Zhang; Shaojuan Wu; Xiaowang Zhang; Zhiyong Feng
- Reference count: 14
- Primary result: Proposed RCCL method achieves SOTA performance with macro-F1 scores of 0.651 on UKP and 0.728 on VAST in few-shot scenarios

## Executive Summary
This paper addresses pretrained stance bias in stance detection, where language models embed biased knowledge into stance relation semantics. The authors propose Relative Counterfactual Contrastive Learning (RCCL) to mitigate this bias by measuring and adjusting relative stance bias instead of absolute bias. The core method involves using a structural causal model to locate pretrained stance bias, generating relative stance samples through masked language model prediction, and applying contrastive learning based on counterfactual theory to preserve context stance relations. Experiments on datasets like SemEval-2016, UKP, and VAST demonstrate that RCCL outperforms existing stance detection and debiasing baselines.

## Method Summary
The Relative Counterfactual Contrastive Learning (RCCL) method mitigates pretrained stance bias in stance detection by generating relative stance samples through target-aware masked language model prediction and applying contrastive learning based on counterfactual theory. The approach uses a structural causal model to identify the causal path where pretrained models influence stance predictions through mediator knowledge. By masking target-unrelated words and generating counterfactual samples, the method decouples context representation from pretrained bias, then applies margin-based ranking loss to learn discriminative features that preserve context stance relations while reducing bias.

## Key Results
- RCCL achieves state-of-the-art performance with macro-F1 scores of 0.651 on UKP and 0.728 on VAST datasets
- Outperforms existing stance detection and debiasing baselines including BERTSEP, BERTMEAN, CL, C2L, and SSR
- Demonstrates effectiveness in both few-shot and zero-shot learning scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pretrained stance bias arises from the causal path X → M ← T, where T (pretrained model) influences M (mediator knowledge) and Y (stance prediction) indirectly through X (context representation).
- Mechanism: By masking target-unrelated words and generating counterfactual samples, the method decouples X from T, breaking the backdoor path and allowing the model to learn stance relations based on context rather than pretrained bias.
- Core assumption: The stance label can be reliably inferred from the masked context, and the masked samples still preserve enough semantic information to represent the stance.
- Evidence anchors:
  - [abstract]: "We use contrastive learning based on counterfactual theory to mitigate pretrained stance bias and preserve context stance relation."
  - [section 3.2]: "The increased probability of Y given X will be affected by the spurious correlation via the two paths: T → X and T → M → Y."
  - [corpus]: Weak. The corpus does not directly discuss causal graphs or backdoor paths; it only mentions "biases" in general terms.
- Break condition: If masking removes too much semantic information, the counterfactual samples may not be representative, or if the stance is heavily dependent on the masked tokens.

### Mechanism 2
- Claim: Relative measurement of stance bias (using relative anchors instead of absolute) circumvents the difficulty of quantifying absolute bias.
- Mechanism: By generating samples with the same or different stance labels relative to the original, the model learns to distinguish stance based on context rather than pretrained bias, using contrastive learning to pull similar samples together and push dissimilar ones apart.
- Core assumption: The relative stance samples generated are valid counterfactuals that maintain the context's stance relation while altering the stance label.
- Evidence anchors:
  - [abstract]: "Instead of absolute measurement, we turn to relative measurement via itself as an anchor for overtaking its weak quantifiability."
  - [section 3.3]: "We use the classifier f to classify the stance label ŷi of generated samples... The final stance relation consists of context stance and pretrained stance."
  - [corpus]: Weak. The corpus does not provide specific examples or metrics related to relative stance measurement.
- Break condition: If the relative samples do not adequately represent the counterfactual scenario or if the model cannot learn the distinction between context and pretrained stance.

### Mechanism 3
- Claim: Contrastive learning with margin-based ranking loss improves robustness against data scarcity by learning discriminative features.
- Mechanism: The loss function encourages the model to make the representations of positive (same stance) samples closer and negative (different stance) samples farther apart, enhancing the model's ability to distinguish subtle stance differences.
- Core assumption: The contrastive pairs (positive and negative samples) are informative and contribute to learning meaningful features.
- Evidence anchors:
  - [section 3.4]: "We adopt the following margin-based ranking loss for model training: LCONTRA = -1/N ∑ max(0, Δm + 1/P ∑ sθ(hi, h+i,p) - 1/Q ∑ sθ(hi, h-i,q)),"
  - [section 4.4]: "Negative samples enhance the diversity of the original dataset due to different labels. Contrastive learning is more sensitive to negative samples than data augmentation."
  - [corpus]: Weak. The corpus does not discuss specific loss functions or the impact of contrastive learning on data scarcity.
- Break condition: If the number of contrastive pairs is insufficient or the margin value is not properly tuned, the contrastive learning may not effectively improve the model's robustness.

## Foundational Learning

- Concept: Causal inference and structural causal models (SCM)
  - Why needed here: To understand and mitigate the spurious causal correlation introduced by pretrained models, which is crucial for accurate stance detection.
  - Quick check question: Can you explain how the backdoor path X → M ← T contributes to pretrained stance bias?

- Concept: Counterfactual reasoning
  - Why needed here: To generate relative stance samples that represent alternative scenarios, helping the model learn stance relations based on context rather than pretrained bias.
  - Quick check question: How does generating counterfactual samples help in mitigating pretrained stance bias?

- Concept: Contrastive learning
  - Why needed here: To learn discriminative features by comparing positive and negative samples, improving the model's ability to distinguish subtle stance differences and enhancing robustness against data scarcity.
  - Quick check question: What is the role of the margin-based ranking loss in contrastive learning for stance detection?

## Architecture Onboarding

- Component map:
  Pretrained language model (T) -> Context representation (X) -> Classifier (f) -> Stance label (Y)
  Counterfactual sample generator -> Relative stance samples -> Contrastive learning module

- Critical path:
  1. Encode context representation using pretrained language model.
  2. Generate counterfactual samples by masking target-unrelated words and filling with T5.
  3. Classify stance labels for generated samples using classifier.
  4. Apply contrastive learning with margin-based ranking loss to update model parameters.

- Design tradeoffs:
  - Masking ratio: Higher ratios may remove too much semantic information, while lower ratios may not effectively decouple context from pretrained bias.
  - Number of contrastive pairs: More pairs can improve learning but increase computational cost.
  - Margin value in contrastive loss: Needs to be tuned to balance the pull and push forces effectively.

- Failure signatures:
  - Model performance degrades significantly on datasets with longer comments or more complex stance relations.
  - Contrastive learning does not improve performance, indicating insufficient or uninformative contrastive pairs.
  - Generated counterfactual samples do not accurately represent the counterfactual scenario, leading to incorrect stance labels.

- First 3 experiments:
  1. Test the impact of different masking ratios on model performance to find the optimal balance between preserving semantic information and decoupling context from pretrained bias.
  2. Evaluate the effectiveness of different numbers of contrastive pairs to determine the optimal number for learning discriminative features.
  3. Compare the performance of the proposed method with and without contrastive learning to assess the contribution of contrastive learning to mitigating pretrained stance bias.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed Relative Counterfactual Contrastive Learning (RCCL) method perform on stance detection tasks in languages other than English?
- Basis in paper: [inferred] The paper primarily focuses on English datasets (SemEval-2016, UKP, and VAST) and does not explore the method's performance on multilingual datasets.
- Why unresolved: The paper does not provide evidence of the method's effectiveness on non-English datasets, which is crucial for assessing its generalizability and applicability in diverse linguistic contexts.
- What evidence would resolve it: Conducting experiments on multilingual datasets and comparing the results with those from English datasets would provide insights into the method's cross-lingual performance and robustness.

### Open Question 2
- Question: What is the impact of varying the masked ratio on the performance of the RCCL method for stance detection tasks?
- Basis in paper: [explicit] The paper mentions that the masked ratio affects the model's performance and provides some experimental results, but it does not extensively explore the impact of different masked ratios on the final outcomes.
- Why unresolved: The paper does not thoroughly investigate how different masked ratios influence the model's performance, leaving uncertainty about the optimal ratio for various datasets and tasks.
- What evidence would resolve it: Conducting a comprehensive study with a wide range of masked ratios and analyzing their effects on the model's performance across different datasets would help identify the optimal masked ratio for stance detection tasks.

### Open Question 3
- Question: How does the RCCL method handle stance detection tasks with extremely scarce data, such as in the zero-shot learning scenario?
- Basis in paper: [explicit] The paper mentions that the method is tested on few-shot and zero-shot scenarios using the VAST dataset, but it does not provide detailed analysis of the method's performance in the most extreme data scarcity conditions.
- Why unresolved: The paper does not explore the method's effectiveness in scenarios where the available data is extremely limited, which is crucial for understanding its applicability in real-world situations with minimal training data.
- What evidence would resolve it: Conducting experiments on datasets with varying levels of data scarcity, including the most extreme cases, and comparing the results with those from other state-of-the-art methods would provide insights into the method's robustness and effectiveness in zero-shot learning scenarios.

## Limitations

- Causal mechanism assumptions: The paper relies heavily on the causal graph framework (X → M ← T) to explain pretrained stance bias, but this causal structure is not empirically validated through ablation studies.
- Counterfactual sample quality: The generation of relative stance samples depends on target-aware masked language model prediction, but the paper lacks detailed analysis of sample quality and semantic coherence.
- Generalizability concerns: The method shows strong performance on stance detection datasets, but its effectiveness for other NLP tasks with different types of bias (gender, racial, political) is unknown.

## Confidence

- High Confidence (75-90%): The experimental results demonstrating improved performance over baselines on the three benchmark datasets. The methodology for generating relative stance samples and applying contrastive learning is clearly specified and reproducible.
- Medium Confidence (50-75%): The causal explanation of pretrained stance bias through the structural causal model. While theoretically sound, the actual contribution of each causal path to the final bias is not quantified or experimentally validated.
- Low Confidence (25-50%): The claim that relative measurement fundamentally solves the quantifiability problem of absolute bias. This represents a theoretical leap that requires more empirical justification, particularly regarding how relative anchors provide more meaningful bias measurement than absolute metrics.

## Next Checks

1. **Ablation study on causal components**: Systematically remove or modify components of the causal graph (e.g., test with different masking strategies, or without the M mediator) to empirically validate which parts of the causal explanation are necessary for performance improvements.

2. **Counterfactual sample quality analysis**: Conduct human evaluation or automated semantic coherence checks on the generated relative stance samples to verify they maintain context while appropriately altering stance labels, ensuring the contrastive learning pairs are meaningful.

3. **Cross-task bias mitigation evaluation**: Apply the RCCL framework to a different NLP task with known bias issues (such as sentiment analysis with demographic bias) to test whether the relative counterfactual contrastive learning approach generalizes beyond stance detection.