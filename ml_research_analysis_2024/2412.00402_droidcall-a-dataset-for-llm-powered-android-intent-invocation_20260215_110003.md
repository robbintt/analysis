---
ver: rpa2
title: 'DroidCall: A Dataset for LLM-powered Android Intent Invocation'
arxiv_id: '2412.00402'
source_url: https://arxiv.org/abs/2412.00402
tags:
- data
- arxiv
- function
- android
- droidcall
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DroidCall, the first open-sourced dataset
  for Android intent invocation using large language models (LLMs). The authors created
  a flexible data generation pipeline that automatically produces 10k training and
  200 test samples by predefining 24 Android-related functions and leveraging self-instruct
  paradigms with GPT-4-turbo.
---

# DroidCall: A Dataset for LLM-powered Android Intent Invocation

## Quick Facts
- arXiv ID: 2412.00402
- Source URL: https://arxiv.org/abs/2412.00402
- Reference count: 40
- Key outcome: First open-sourced dataset for Android intent invocation, enabling small models to match or exceed GPT-4o performance

## Executive Summary
This paper introduces DroidCall, a specialized dataset for Android intent invocation using large language models. The authors developed an automated data generation pipeline that creates 10,000 training samples using self-instruct paradigms with GPT-4-turbo, based on 24 predefined Android functions. Experimental results demonstrate that small language models fine-tuned on DroidCall achieve 85-93% soft accuracy, approaching or surpassing GPT-4o performance while using simpler prompts (645 vs 1367 average tokens). The dataset covers common mobile operations and includes an end-to-end Android demo showcasing on-device intent invocation capabilities.

## Method Summary
The authors created DroidCall using a self-instruct paradigm where GPT-4-turbo generates function calling examples based on predefined Android functions. The pipeline involves iterative sampling and filtering to produce diverse, high-quality synthetic data without manual seed creation. Small language models (Qwen2.5-3B, Gemma2-2B) are fine-tuned using LoRA adapters with specific hyperparameters (rank 8, alpha 16, learning rate 1.41e-5, 24 epochs). The dataset includes 10k training and 200 test samples, and evaluation uses code_short prompt format comparing against general function calling datasets and GPT-4o.

## Key Results
- Small models fine-tuned on DroidCall achieve 85-93% soft accuracy, matching or exceeding GPT-4o performance
- DroidCall-trained models use simpler prompts (645 tokens) compared to GPT-4o (1367 tokens) while maintaining accuracy
- Specialized Android intent dataset outperforms general function calling datasets for Android-specific tasks
- End-to-end demo demonstrates successful on-device intent invocation using fine-tuned models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Specialized Android intent invocation dataset improves function calling accuracy more than general datasets
- Mechanism: Domain-specific data teaches models Android-specific language patterns and context, enabling better intent recognition
- Core assumption: Models can generalize from Android-specific function calling examples to handle novel but similar intent scenarios
- Evidence anchors:
  - [abstract]: "small language models such as Qwen2.5-3B and Gemma2.5-3B fine-tuned with DroidCall can approach or even surpass the capabilities of GPT-4o for accurate Android intent invocation"
  - [section]: "we demonstrated that using the DroidCall dataset is more effective than using a general function calling dataset in scenarios aimed at Android intent invocation"
- Break condition: If Android intent patterns are too diverse or evolve rapidly, the dataset may become outdated quickly

### Mechanism 2
- Claim: Fine-tuning small models on DroidCall enables them to match or exceed GPT-4o performance with simpler prompts
- Mechanism: Specialized fine-tuning allows models to learn task-specific patterns, reducing reliance on extensive prompt engineering
- Core assumption: Small models can achieve comparable performance to larger models when trained on high-quality, task-specific data
- Evidence anchors:
  - [abstract]: "Models like Gemma2-2B and Qwen2.5-3B achieve 85-93% soft accuracy, approaching or surpassing GPT-4o performance while using simpler prompts (645 vs 1367 average tokens)"
  - [section]: "it is evident that when a model is required to perform a specific task, a dataset constructed for that task, such as DroidCall, can yield better results compared to a general-purpose dataset"
- Break condition: If the task complexity exceeds the model's capacity despite specialized training

### Mechanism 3
- Claim: Automated pipeline with self-instruct paradigm generates high-quality synthetic data without manual seed creation
- Mechanism: Iterative sampling and filtering processes produce diverse, relevant examples while maintaining quality standards
- Core assumption: GPT-4-turbo can generate diverse and accurate function calling examples when guided by proper sampling strategies and filters
- Evidence anchors:
  - [section]: "we detail our method for generating the DroidCall dataset, the first open-sourced dataset for Android intent invocation. Our method requires minimal human supervision and can be easily extended"
  - [section]: "The data generated from this process will serve as seed data for subsequent data generation stages"
- Break condition: If GPT-4-turbo's outputs become repetitive or drift from intended function calling patterns

## Foundational Learning

- Concept: Function calling in LLMs
  - Why needed here: Core task for Android intent invocation - models must correctly identify and parameterize functions
  - Quick check question: What format should function call outputs follow for Android intent execution?

- Concept: Android intents and implicit intents
  - Why needed here: Understanding the underlying Android mechanism that DroidCall targets for automation
  - Quick check question: What's the difference between explicit and implicit intents in Android?

- Concept: LoRA fine-tuning for small models
  - Why needed here: Efficient parameter-efficient adaptation of small models for specialized tasks
  - Quick check question: How does LoRA differ from full fine-tuning in terms of parameter updates?

## Architecture Onboarding

- Component map: Sampler -> LLM (GPT-4-turbo) -> Filter -> Collector -> Fine-tuning Framework (LoRA) -> Evaluation System (Accuracy/Soft Accuracy) -> End-to-end Demo (Retriever + Fine-tuned model + Intent executor)
- Critical path: Data generation → Fine-tuning → Evaluation → Demo deployment
- Design tradeoffs:
  - Dataset size vs quality (10k samples chosen for balance)
  - Model size vs performance (small models selected for on-device deployment)
  - Prompt simplicity vs completeness (short prompts reduce token usage)
- Failure signatures:
  - Low accuracy despite fine-tuning: Check data quality or model capacity
  - High similarity scores in filtering: Adjust LCS ROUGE threshold
  - Demo not working: Verify function implementation matches model outputs
- First 3 experiments:
  1. Test zero-shot function calling accuracy on a small sample
  2. Compare fine-tuning with general vs. DroidCall dataset
  3. Evaluate prompt length vs accuracy trade-off with different formats

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the long-term impact of using DroidCall on model performance when faced with evolving Android intents and API changes?
- Basis in paper: [inferred] The paper mentions that the function predefinition approach abstracts away intent details, but doesn't address how models handle evolving Android versions
- Why unresolved: The dataset was constructed for current Android intents and doesn't address backward/forward compatibility issues
- What evidence would resolve it: Longitudinal studies testing model performance across multiple Android version updates and API changes

### Open Question 2
- Question: How does the performance of DroidCall-trained models compare to traditional UI automation approaches in real-world usage scenarios?
- Basis in paper: [explicit] The paper mentions existing agents rely on UI interactions but doesn't provide direct comparisons with UI automation methods
- Why unresolved: The paper only compares against cloud-based LLMs and doesn't benchmark against established UI automation frameworks
- What evidence would resolve it: Controlled experiments comparing intent invocation models against UI automation tools on identical tasks

### Open Question 3
- Question: What is the optimal balance between dataset size and model performance for different Android intent categories?
- Basis in paper: [inferred] The paper uses a fixed 10k training samples but doesn't explore how performance scales with dataset size or varies by intent type
- Why unresolved: The dataset size was chosen arbitrarily and the paper doesn't analyze the marginal benefit of additional training data
- What evidence would resolve it: Systematic studies varying dataset size and measuring performance across different intent categories

## Limitations

- Dataset generalization may be limited to 24 predefined Android functions, potentially missing novel or edge-case intent scenarios
- Evaluation scope is restricted to internal test sets and simplified prompt comparisons without extensive real-world deployment testing
- Data quality verification relies on automated filtering with limited manual inspection of synthetic data quality and diversity

## Confidence

**High Confidence**:
- Dataset creation methodology using self-instruct paradigms is technically sound and well-documented
- Experimental design comparing DroidCall against general function calling datasets is methodologically valid
- Reported accuracy improvements (85-93% soft accuracy) are internally consistent with the experimental setup

**Medium Confidence**:
- Claims about matching or surpassing GPT-4o performance with simpler prompts are supported but would benefit from additional verification
- Assertion that DroidCall is "the first open-sourced dataset for Android intent invocation" appears accurate based on literature review

**Low Confidence**:
- Long-term effectiveness of the dataset as Android ecosystems evolve
- Generalizability of results to real-world deployment scenarios beyond controlled demo environment
- Robustness of data generation pipeline to produce consistently high-quality synthetic examples

## Next Checks

1. **Cross-Dataset Evaluation**: Test fine-tuned models on both DroidCall and general function calling datasets to quantify the actual performance gap and assess whether improvement is consistent across different evaluation scenarios

2. **Real-World Deployment Test**: Deploy the fine-tuned models in a real Android application with diverse user inputs to evaluate performance in practical settings, measuring not just accuracy but also latency, robustness to user input variations, and error recovery

3. **Data Quality Audit**: Conduct a systematic audit of the DroidCall dataset by sampling and manually reviewing 100+ examples to verify that automated generation pipeline consistently produces semantically accurate and diverse function calling examples that cover intended Android intent patterns