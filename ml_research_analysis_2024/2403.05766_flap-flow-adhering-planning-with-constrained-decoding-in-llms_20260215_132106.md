---
ver: rpa2
title: 'FLAP: Flow-Adhering Planning with Constrained Decoding in LLMs'
arxiv_id: '2403.05766'
source_url: https://arxiv.org/abs/2403.05766
tags: []
core_contribution: This paper addresses the challenge of generating faithful plans
  for task-oriented dialogs that adhere to predefined workflows and API dependencies.
  The authors propose FLAP, a Flow-Adhering Planning algorithm based on constrained
  decoding with lookahead heuristic for large language models (LLMs).
---

# FLAP: Flow-Adhering Planning with Constrained Decoding in LLMs

## Quick Facts
- arXiv ID: 2403.05766
- Source URL: https://arxiv.org/abs/2403.05766
- Reference count: 19
- Primary result: FLAP improves faithfulness of plans in task-oriented dialogs by enforcing workflow adherence and API dependency preservation through constrained decoding

## Executive Summary
This paper introduces FLAP (Flow-Adhering Planning), a constrained decoding algorithm for large language models (LLMs) that generates faithful plans for task-oriented dialogs. The method addresses the challenge of ensuring that LLM-generated plans adhere to predefined workflows and maintain correct API dependencies. By combining flow alignment with dependency graph constraints and a lookahead heuristic for token scoring, FLAP significantly improves plan faithfulness compared to baseline prompting approaches.

## Method Summary
FLAP operates by prompting LLMs to generate thoughts and corresponding APIs, then enforcing constraints through structural and coherency checks. The algorithm maintains dynamic dependency graphs and uses a lookahead heuristic to score candidate tokens during plan generation. This constrained decoding approach ensures that generated plans align with predefined natural language flows while preserving API dependencies. The method is evaluated across 4 domains, 13 intents, 64 APIs, and 260 user queries, demonstrating improved faithfulness compared to baseline methods.

## Key Results
- FLAP significantly improves plan faithfulness compared to prompting-based baselines and other decoding methods
- On smaller LLMs (7B parameters), FLAP achieves comparable performance to larger models (30B-40B)
- The approach successfully maintains API dependencies while adhering to predefined workflow flows

## Why This Works (Mechanism)
FLAP works by constraining the LLM's decoding process through structural checks that enforce flow adherence and dependency preservation. The lookahead heuristic evaluates potential next tokens not just on immediate coherence but also on their ability to maintain valid paths through the dependency graph. This prevents the model from generating sequences that violate workflow constraints or create impossible API dependency chains.

## Foundational Learning
1. **Constrained Decoding** - Limiting token generation to valid sequences based on predefined rules; needed to enforce workflow adherence
2. **Dependency Graphs** - Directed graphs representing API relationships; needed to track and preserve execution order
3. **Lookahead Heuristic** - Scoring mechanism that evaluates future token possibilities; needed for maintaining constraint satisfaction
4. **Flow Alignment** - Matching generated content to predefined workflow patterns; needed for plan faithfulness
5. **API Dependency Management** - Tracking prerequisite relationships between API calls; needed for valid plan execution
6. **Dynamic Graph Updates** - Modifying dependency structures during generation; needed for handling evolving plan states

Quick check: Each concept ensures the generated plan remains both syntactically valid and semantically coherent with the intended workflow.

## Architecture Onboarding

**Component Map**: LLM Generator -> Thought/Plan Output -> Flow Constraint Checker -> Dependency Graph Manager -> Lookahead Scorer -> Final Output

**Critical Path**: The core execution path flows from the LLM's token generation through the constraint checkers, with the lookahead scorer influencing token selection before final output. The dependency graph manager maintains state throughout generation.

**Design Tradeoffs**: The approach trades computational overhead (lookahead scoring, graph maintenance) for improved plan faithfulness. This creates tension between generation speed and constraint satisfaction.

**Failure Signatures**: Common failure modes include getting stuck in local minima where valid continuations are exhausted, lookahead scoring becoming computationally prohibitive for complex graphs, and brittleness when workflows are underspecified or ambiguous.

**First Experiments**: 1) Test constrained decoding with a simple linear workflow to verify basic functionality, 2) Introduce API dependencies to validate dependency graph enforcement, 3) Apply lookahead heuristic to a small non-linear workflow to assess improvement in plan faithfulness.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to specific task-oriented dialog domains with predefined workflows
- Computational efficiency of lookahead heuristic for larger graphs or longer sequences not discussed
- Potential brittleness when dealing with ambiguous or underspecified workflows

## Confidence
- **High confidence**: Core algorithm design and improvement over prompting baselines
- **Medium confidence**: Claims about smaller LLMs achieving comparable performance to larger models
- **Low confidence**: Real-world deployment scenarios and robustness to noisy/degenerate input

## Next Checks
1. Test FLAP on more diverse and complex domains beyond task-oriented dialogs to assess generalizability
2. Evaluate computational overhead of the lookahead heuristic on larger dependency graphs and longer plan sequences
3. Conduct ablation studies to quantify the contribution of each constraint (flow adherence vs. API dependency preservation) to overall performance