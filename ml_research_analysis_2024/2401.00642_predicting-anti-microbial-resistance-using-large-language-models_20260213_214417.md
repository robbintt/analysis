---
ver: rpa2
title: Predicting Anti-microbial Resistance using Large Language Models
arxiv_id: '2401.00642'
source_url: https://arxiv.org/abs/2401.00642
tags:
- resistance
- antibiotic
- data
- language
- genes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using a nucleotide sequence-based language
  model and a text-based language model to classify antibiotic resistance genes. The
  nucleotide sequence-based model is fine-tuned using a multi-species nucleotide sequence
  language model, while the text-based model is fine-tuned using a biomedical text
  corpus.
---

# Predicting Anti-microbial Resistance using Large Language Models

## Quick Facts
- arXiv ID: 2401.00642
- Source URL: https://arxiv.org/abs/2401.00642
- Reference count: 12
- Key outcome: Ensemble fusion of nucleotide and text-based language models outperforms nucleotide-only models in antibiotic resistance drug class prediction

## Executive Summary
This paper proposes a novel method for predicting antibiotic resistance drug classes using a combination of nucleotide sequence-based and text-based language models. The approach integrates two complementary feature spaces - genomic sequence patterns and biological/clinical context - through a weighted soft-voting ensemble. The method also incorporates ontology-based class integration across different AMR databases and uses LLM-based data augmentation to address class imbalance. Experimental results demonstrate improved performance over nucleotide-only approaches across multiple evaluation metrics.

## Method Summary
The proposed method fine-tunes two pre-trained models - a nucleotide sequence-based transformer (NT) and a biomedical text transformer (BioBERT) - on AMR datasets. The NT model uses a 6-mer tokenizer for DNA sequences, while BioBERT processes gene family and resistance mechanism metadata. The two models are combined using weighted soft-voting ensemble after integrating CARD and MEGARes databases through EBI ARO ontology mapping. Data augmentation is performed for rare classes using BioGPT to generate synthetic text descriptions. The approach addresses limitations of previous methods that relied solely on nucleotide sequences or text information.

## Key Results
- Ensemble method achieves better performance than nucleotide sequence language model alone in drug resistance class prediction
- Text information-based language model shows 9.53 accuracy and 30.34 macro F1 score improvement in CARD dataset
- Ontology integration and LLM-based augmentation improve performance, particularly for classes with few samples

## Why This Works (Mechanism)

### Mechanism 1
Ensemble fusion of nucleotide and text representations improves predictive accuracy over nucleotide-only models. The weighted soft-voting ensemble combines probability distributions from two complementary feature spaces (nucleotide sequence patterns from NT and biological/clinical context from BioBERT), allowing the model to leverage both sequence-level structural features and semantic metadata about resistance mechanisms and gene families. Core assumption: the two models capture non-overlapping or complementary information that, when combined, yields better predictions than either alone.

### Mechanism 2
Ontology-based class integration improves sample efficiency and allows unified evaluation across databases. EBI ARO ontology mapping maps heterogeneous classification schemes from CARD and MEGARes into a common hierarchical structure, increasing effective sample size and enabling multi-source training. Core assumption: hierarchical mapping preserves meaningful biological relationships and does not introduce noisy or incorrect groupings.

### Mechanism 3
LLM-based data augmentation compensates for class imbalance and improves rare class recall. BioGPT is prompted to generate synthetic text descriptions of rare gene classes, which are then paired with corresponding nucleotide sequences to create additional training samples. Core assumption: generated text is biologically plausible and captures class-specific patterns that help the model generalize to rare classes.

## Foundational Learning

- **Fine-tuning vs. Pre-training**: Fine-tuning adapts pre-trained models to specific tasks using domain data, while pre-training learns general representations from large corpora. Quick check: What is the difference between fine-tuning and pre-training in the context of transformer models?

- **Tokenization strategies for nucleotide sequences**: The NT model uses a 6-mer tokenizer to convert DNA sequences into discrete tokens for the transformer architecture. Quick check: Why might a 6-mer tokenizer be chosen over shorter k-mers for genomic sequences?

- **Soft-voting ensemble methods**: The two fine-tuned models are combined using weighted soft voting to aggregate their probability predictions. Quick check: How does soft voting differ from hard voting in ensemble learning, and why might it be preferred here?

## Architecture Onboarding

- **Component map**: Input (nucleotide sequences, metadata) -> NT Encoder (6-mer tokenized transformer) -> BioBERT Encoder (PubMed/PMC pre-trained) -> Fine-tuning layers (LoRA for NT, classification head for BioBERT) -> Ensemble module (weighted soft-voting combiner) -> Augmentation module (BioGPT prompt-based synthetic data generator) -> Output (predicted drug class probabilities)

- **Critical path**: 1) Load and tokenize nucleotide sequences and metadata 2) Fine-tune NT on sequence-only data 3) Fine-tune BioBERT on text-only data 4) Map and merge CARD/MEGARes classes using EBI ARO ontology 5) Generate synthetic samples for rare classes with BioGPT 6) Train ensemble with validation-based weight optimization 7) Evaluate on held-out test set

- **Design tradeoffs**: Using LoRA reduces fine-tuning cost but may limit adaptation depth; weighted soft-voting assumes independence of model errors; BioGPT augmentation introduces potential label noise; limiting sequences to 1000 tokens may truncate informative context

- **Failure signatures**: Ensemble weights collapse toward one model; macro F1 lags behind accuracy; performance degrades when integrating external databases; rare class recall drops despite augmentation

- **First 3 experiments**: 1) Train NT alone on CARD dataset; measure baseline accuracy and macro F1 2) Train BioBERT alone on text metadata; compare against NT baseline 3) Perform ontology mapping and integration; retrain ensemble and measure improvement

## Open Questions the Paper Calls Out

- **How does the performance of the nucleotide sequence-based language model compare to other state-of-the-art models for predicting antibiotic resistance genes?**: The paper mentions that the proposed method outperforms the nucleotide sequence-based language model but does not provide a direct comparison to other state-of-the-art models.

- **How does the proposed method handle the integration of different antibiotic resistance gene databases with varying classification systems?**: While the paper proposes using EBI ARO ontology for integration, it does not provide details on the specific challenges and solutions for integrating databases with different classification systems.

- **How does the proposed data augmentation technique using a large language model improve the performance of the model for rare classes?**: The paper proposes LLM-based augmentation but does not provide a detailed analysis of its impact on rare class performance or compare results with and without augmentation.

## Limitations

- Lack of ablation studies to isolate contribution of each component (ontology integration, LLM augmentation, ensemble method)
- No validation of biological accuracy or relevance of LLM-generated synthetic data
- Unclear generalizability across different AMR databases and hierarchical structures
- Key implementation details missing (fine-tuning hyperparameters, ensemble weight optimization, exact ontology mapping rules)

## Confidence

- **High confidence**: Overall experimental design using pre-trained models, ensemble methods, and data augmentation is sound and aligns with established best practices
- **Medium confidence**: Reported performance improvements are plausible given complementary data modalities and ensemble methods, but lack of detailed ablations reduces certainty
- **Low confidence**: Impact and quality of LLM-based data augmentation is uncertain due to absence of validation of generated data quality

## Next Checks

1. **Ablation study**: Conduct controlled experiments to assess the marginal contribution of each proposed component by systematically removing or replacing them

2. **Quality control of synthetic data**: Evaluate biological plausibility and label consistency of LLM-generated text samples using expert review or downstream task performance with and without augmentation

3. **Cross-database generalization**: Test the method on a third AMR database (e.g., ResFinder or ARG-ANNOT) to assess robustness of ontology mapping and overall model performance across different data sources