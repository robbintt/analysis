---
ver: rpa2
title: A Framework for Portrait Stylization with Skin-Tone Awareness and Nudity Identification
arxiv_id: '2403.14264'
source_url: https://arxiv.org/abs/2403.14264
tags:
- stylization
- portrait
- skin
- nudity
- content
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The authors present a portrait stylization framework that addresses
  two key challenges in real-world deployment: skin-tone preservation and nudity filtering.
  They introduce a Skin-Tone-Aware Portrait Stylization Module (STAPSM) that uses
  skin-tone spectrum augmentation during training and progressive two-stage inference
  to maintain diverse skin tones while stylizing portraits.'
---

# A Framework for Portrait Stylization with Skin-Tone Awareness and Nudity Identification

## Quick Facts
- arXiv ID: 2403.14264
- Source URL: https://arxiv.org/abs/2403.14264
- Authors: Seungkwon Kim; Sangyeon Kim; Seung-Hun Nam
- Reference count: 0
- Primary result: Framework achieves 0.987 accuracy and 0.993 recall on nudity classification while preserving diverse skin tones

## Executive Summary
This paper presents a portrait stylization framework designed for commercial deployment with Webtoon IPs, addressing two critical challenges: skin-tone preservation and nudity filtering. The authors introduce a Skin-Tone-Aware Portrait Stylization Module (STAPSM) that uses progressive two-stage inference with edge and depth ControlNet conditions to maintain input skin tones during stylization. They also develop a Nudity Content Identification Module (NCIM) that combines CLIP-based classification with keyword matching to reliably filter explicit content. The system has been deployed in production, generating over 2 million images across 15 Webtoon IPs without reported misuse incidents.

## Method Summary
The framework combines a LoRA-based portrait stylization model with a hybrid nudity detection system. For stylization, the approach uses progressive two-stage inference: first applying edge-based ControlNet conditions with denoising strength 0.4 to preserve shapes and skin tone, then applying depth-based ControlNet with denoising strength 0.5 to enhance stylization while maintaining the preserved skin tone. The model is trained with skin-tone spectrum augmentation to expand the skin tone distribution in the dataset. For nudity filtering, the system combines NSFW-D (a CLIP-based classifier) with BLIP caption-based keyword matching (BLIP-KM) to create a hybrid approach that improves reliability and cultural adaptability.

## Key Results
- Achieved 0.987 accuracy and 0.993 recall on nudity classification
- Outperformed existing methods in user studies on skin-tone preservation
- Successfully deployed in production with over 2 million generated images
- No reported misuse incidents across 15 Webtoon IP applications

## Why This Works (Mechanism)

### Mechanism 1
Progressive two-stage inference with edge-based and depth-based ControlNet conditions preserves skin tone while achieving stylization quality. Edge-based representation better preserves skin tone information than depth-based representation, and the progressive approach allows controlled stylization.

### Mechanism 2
Skin-tone spectrum augmentation during training expands the skin tone distribution in the dataset to match real-world diversity. The augmented samples create a balanced skin tone distribution that doesn't bias toward the Webtoon character's original skin tone.

### Mechanism 3
Hybrid nudity filtering combining CLIP-based embedding classification with keyword matching improves detection reliability and cultural adaptability. CLIP-based methods alone have inherent biases that can be mitigated by rule-based keyword matching.

## Foundational Learning

- Concept: Stable Diffusion fine-tuning with LoRA
  - Why needed: Understanding how LoRA adapters work with Stable Diffusion is essential for implementing STAPSM's skin-tone-aware stylization
  - Quick check: What is the difference between full fine-tuning and LoRA fine-tuning in terms of parameter efficiency and storage requirements?

- Concept: ControlNet conditioning mechanisms
  - Why needed: The progressive inference relies on edge-based and depth-based ControlNet conditions, requiring understanding of how these conditions control the generation process
  - Quick check: How does the edge-based ControlNet differ from depth-based ControlNet in terms of the structural information they provide to the generation process?

- Concept: CLIP embedding similarity calculations
  - Why needed: NCIM uses CLIP embeddings for nudity detection, requiring understanding of how cosine similarity is used for concept matching
  - Quick check: What is the relationship between CLIP embedding similarity scores and the likelihood of an image containing explicit content?

## Architecture Onboarding

- Component map:
  - Input portrait image -> STAPSM (LoRA model with progressive inference) -> NCIM (CLIP + keyword matching) -> Stylized image output

- Critical path:
  1. Input portrait image
  2. Skin-tone spectrum augmentation (training only)
  3. Progressive inference through STAPSM
  4. NCIM filtering of input and output
  5. Final stylized image delivery

- Design tradeoffs:
  - Progressive inference vs. single-pass: Better skin tone preservation but increased inference time
  - Hybrid filtering vs. pure CLIP: Improved reliability but requires maintaining keyword lists
  - Data augmentation vs. limited training data: Better generalization but increased storage/compute

- Failure signatures:
  - Skin tone drift: If generated images consistently match character skin tone rather than input
  - False negatives in NCIM: Explicit content passing through detection
  - Style degradation: If progressive inference causes loss of Webtoon character features

- First 3 experiments:
  1. Test skin tone preservation across diverse input images with varying skin tones
  2. Evaluate NCIM detection accuracy on refined nudity dataset with edge cases
  3. Compare stylization quality and skin tone preservation between progressive and single-pass inference

## Open Questions the Paper Calls Out

### Open Question 1
How can the proposed skin-tone-aware framework be extended to handle full-body portrait stylization while maintaining skin-tone consistency across different body parts? The current framework is designed specifically for portrait images and does not address the additional complexities of full-body images.

### Open Question 2
What are the long-term effects of deploying such AI systems on societal perceptions of beauty standards, particularly regarding skin tone diversity? The paper focuses on technical solutions to skin-tone bias but does not investigate how widespread use of such stylization tools might reinforce or challenge existing beauty standards.

### Open Question 3
How can the nudity detection module be further improved to handle cultural variations in what constitutes explicit content? While the paper introduces a hybrid approach combining CLIP-based filtering with keyword matching, it does not provide a systematic method for adapting to diverse cultural standards.

## Limitations

- The skin-tone preservation mechanism relies heavily on data augmentation quality, and exact prompts are not fully specified
- The hybrid nudity filtering system requires ongoing maintenance of culturally appropriate keyword dictionaries
- The evaluation lacks quantitative comparison of inference speed between progressive and single-pass approaches

## Confidence

**High Confidence:** The framework's deployment success with over 2 million generated images and zero reported misuse incidents provides strong empirical support for the practical effectiveness of the combined STAPSM and NCIM approach.

**Medium Confidence:** The mechanism explanations for skin-tone preservation through progressive inference are logically sound but lack detailed ablation studies showing the individual contribution of each component.

**Low Confidence:** The cultural adaptability claims for the NCIM system are primarily based on the hybrid approach design rather than extensive testing across diverse cultural contexts.

## Next Checks

1. Conduct controlled experiments comparing skin-tone preservation across the full spectrum of skin tones using quantitative color distance metrics (Î”E) between input and output images.

2. Test the hybrid filtering system on culturally diverse datasets from multiple regions, measuring false positive/negative rates and evaluating the effectiveness of keyword matching rules across different cultural contexts.

3. Measure and compare inference time, GPU memory usage, and quality metrics between the two-stage progressive approach and single-pass alternatives to determine practical trade-offs for real-time deployment scenarios.