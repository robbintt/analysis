---
ver: rpa2
title: An $\mathbf{L^*}$ Algorithm for Deterministic Weighted Regular Languages
arxiv_id: '2411.06228'
source_url: https://arxiv.org/abs/2411.06228
tags: []
core_contribution: This paper presents a weighted variant of Angluin's L algorithm
  for learning deterministic weighted finite-state automata (WDFSA) from an oracle.
  The method generalizes the original L algorithm to work with semifield-weighted
  FSAs, where weights support division but not necessarily subtraction.
---

# An $\mathbf{L^*}$ Algorithm for Deterministic Weighted Regular Languages

## Quick Facts
- arXiv ID: 2411.06228
- Source URL: https://arxiv.org/abs/2411.06228
- Reference count: 6
- Presents L* algorithm variant for learning deterministic weighted FSAs from oracle queries

## Executive Summary
This paper introduces a weighted variant of Angluin's L* algorithm for learning deterministic weighted finite-state automata (WDFSA) from an oracle. The method extends the original L* algorithm to work with semifield-weighted FSAs, maintaining an empirical Hankel matrix and iteratively making it consistent and closed through membership and equivalence queries. The algorithm guarantees exact learning of the minimal WDFSA generating the target language in finite time when the language is deterministic, with time complexity O(N^5 M^2 |Σ|^2).

## Method Summary
The algorithm maintains an empirical Hankel matrix representing the learned automaton and uses membership queries to gather data about the target language. Through equivalence queries, it checks whether the current hypothesis is correct and, if not, receives counterexamples to refine the model. The method iteratively makes the Hankel matrix consistent and closed, which corresponds to refining the automaton's structure. The learning process continues until the hypothesis exactly matches the target language, at which point the minimal WDFSA is obtained.

## Key Results
- Exact learning of minimal deterministic weighted FSAs in finite time
- Time complexity of O(N^5 M^2 |Σ|^2) where N is number of states, M is longest counterexample, and |Σ| is alphabet size
- More faithful generalization of Angluin's original algorithm compared to previous weighted variants

## Why This Works (Mechanism)
The algorithm leverages the connection between L* learning and weighted FSA minimization through Hankel matrix completion. By maintaining consistency and closure properties of the empirical Hankel matrix, the algorithm systematically refines its hypothesis until it matches the target language. The use of membership and equivalence queries allows for targeted refinement based on concrete counterexamples.

## Foundational Learning
- Weighted finite-state automata: Essential for understanding the learning target; quick check: can you define semiring operations on WFSA weights?
- Hankel matrices in automata theory: Critical for the learning mechanism; quick check: can you explain the relationship between Hankel matrices and automata minimality?
- Angluin's L* algorithm: The base algorithm being generalized; quick check: can you describe how membership and equivalence queries work in the original L*?
- Semifields: Required for the weight structure; quick check: can you give examples of semifields and explain why subtraction is not required?
- Determinism in weighted automata: Core assumption for correctness; quick check: can you explain how determinism affects the learning process?

## Architecture Onboarding
- Component map: Oracle -> Membership/Equivalence Queries -> Empirical Hankel Matrix -> Hypothesis Automaton -> Consistency/Closure Checks -> Updated Hypothesis
- Critical path: Oracle queries drive Hankel matrix updates, which trigger automaton refinement until equivalence is proven
- Design tradeoffs: Requires determinism assumption for correctness vs. flexibility of weighted representations
- Failure signatures: Non-deterministic target languages will cause infinite learning loops; insufficient counterexamples may lead to incorrect models
- First experiments: 1) Learn a simple deterministic weighted language with known structure 2) Test convergence on a non-deterministic language to observe failure mode 3) Measure learning time against theoretical complexity bound

## Open Questions the Paper Calls Out
None

## Limitations
- Requires weights to form a semifield (division supported, subtraction not required)
- Assumes target language is deterministic, which may not hold in practice
- High polynomial complexity (O(N^5 M^2 |Σ|^2)) may limit practical scalability

## Confidence
- High confidence in theoretical correctness of L* generalization and Hankel matrix connection
- Medium confidence in practical efficiency claims given high polynomial complexity
- Medium confidence in uniqueness of approach as most faithful to original L* algorithm

## Next Checks
1. Implement the algorithm on benchmark weighted regular languages to empirically verify finite convergence and measure runtime against theoretical bounds
2. Test algorithm behavior on nearly-deterministic languages to quantify robustness to determinism assumption violations
3. Compare learning performance with previous weighted FSA approaches on same benchmarks to validate improved fidelity claims