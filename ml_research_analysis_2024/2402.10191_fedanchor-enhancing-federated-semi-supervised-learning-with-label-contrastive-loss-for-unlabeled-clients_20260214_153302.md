---
ver: rpa2
title: 'FedAnchor: Enhancing Federated Semi-Supervised Learning with Label Contrastive
  Loss for Unlabeled Clients'
arxiv_id: '2402.10191'
source_url: https://arxiv.org/abs/2402.10191
tags:
- data
- fedanchor
- anchor
- learning
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes FedAnchor, a federated semi-supervised learning
  (FSSL) method that addresses the challenges of data labeling in federated learning
  environments. The core idea is to leverage a small set of labeled anchor data on
  the server to generate pseudo-labels for unlabeled client data through a novel label
  contrastive loss based on cosine similarity.
---

# FedAnchor: Enhancing Federated Semi-Supervised Learning with Label Contrastive Loss for Unlabeled Clients

## Quick Facts
- arXiv ID: 2402.10191
- Source URL: https://arxiv.org/abs/2402.10191
- Authors: Xinchi Qiu; Yan Gao; Lorenzo Sani; Heng Pan; Wanru Zhao; Pedro P. B. Gusmao; Mina Alibeigi; Alex Iacob; Nicholas D. Lane
- Reference count: 40
- Primary result: FedAnchor outperforms state-of-the-art methods in federated semi-supervised learning with improved convergence and accuracy

## Executive Summary
FedAnchor addresses the challenge of data labeling in federated learning environments by leveraging a small set of labeled anchor data on the server to generate pseudo-labels for unlabeled client data. The method introduces a novel label contrastive loss based on cosine similarity to mitigate confirmation bias and overfitting issues associated with traditional pseudo-labeling techniques. By implementing a double-head structure where one head is trained on labeled anchor data, FedAnchor demonstrates significant improvements in both convergence rate and model accuracy compared to existing state-of-the-art methods.

## Method Summary
FedAnchor is a federated semi-supervised learning framework that utilizes a small set of labeled anchor data on the server to improve model training on unlabeled client data. The core innovation is the label contrastive loss, which uses cosine similarity to compare predicted labels against anchor data labels, reducing confirmation bias in pseudo-label generation. The framework employs a double-head structure where one head is specifically trained on the labeled anchor data, while the other handles unlabeled client data. This approach allows for more reliable pseudo-label generation and faster convergence while maintaining model accuracy across various federated learning scenarios.

## Key Results
- FedAnchor achieves 80.36% accuracy on CIFAR10 with 250 anchor data points, compared to 77.82% for SemiFL
- Demonstrates improved convergence rates compared to state-of-the-art methods
- Reduces communication overhead by efficiently utilizing limited labeled data on the server

## Why This Works (Mechanism)
FedAnchor works by addressing the fundamental challenge of label scarcity in federated learning through strategic use of anchor data. The label contrastive loss mechanism ensures that pseudo-labels generated for client data are more reliable by comparing them against known anchor labels using cosine similarity. This approach reduces the confirmation bias that typically occurs when models generate their own labels. The double-head structure allows one part of the model to maintain strong performance on labeled data while the other adapts to unlabeled data, creating a more robust learning process. The anchor data serves as a quality control mechanism, preventing the model from drifting too far from ground truth labels during the pseudo-labeling process.

## Foundational Learning

**Federated Semi-Supervised Learning (FSSL)**: Semi-supervised learning in distributed environments where clients have unlabeled data. Why needed: Most real-world federated learning scenarios involve unlabeled client data, making traditional supervised approaches infeasible.

**Pseudo-labeling**: Technique where a model generates labels for unlabeled data based on its predictions. Why needed: Enables training on unlabeled data in semi-supervised settings. Quick check: Verify that pseudo-labels have high confidence scores before using them in training.

**Confirmation Bias in Pseudo-labeling**: Problem where models reinforce their own incorrect predictions when generating pseudo-labels. Why needed: Understanding this limitation is crucial for developing more robust FSSL methods. Quick check: Monitor prediction entropy to detect potential confirmation bias.

**Label Contrastive Loss**: Loss function that compares predicted labels against anchor labels using similarity metrics. Why needed: Provides a mechanism to validate pseudo-labels against known ground truth. Quick check: Ensure anchor data is representative of the overall data distribution.

**Double-head Architecture**: Model structure with separate heads for labeled and unlabeled data processing. Why needed: Allows specialized treatment of different data types within the same model. Quick check: Verify that both heads maintain balanced performance throughout training.

## Architecture Onboarding

**Component Map**: Server(anchor data + model) -> Clients(unlabeled data) -> Model aggregation -> Server update

**Critical Path**: Anchor data processing → Label contrastive loss computation → Pseudo-label generation → Client model training → Model aggregation

**Design Tradeoffs**: 
- Small anchor set reduces privacy concerns but may limit model generalization
- Label contrastive loss adds computational overhead but improves pseudo-label quality
- Double-head structure increases model complexity but provides better performance

**Failure Signatures**: 
- Poor performance when anchor data distribution significantly differs from client data
- Confirmation bias indicated by decreasing prediction entropy over time
- Communication bottlenecks if anchor data is too large or frequent updates are required

**Three First Experiments**:
1. Baseline comparison using standard pseudo-labeling without anchor data
2. Varying anchor data size to determine optimal trade-off between performance and resource usage
3. Testing on datasets with different distribution shifts between server and client data

## Open Questions the Paper Calls Out
None

## Limitations
- Performance on complex tasks beyond standard image classification remains untested
- Effectiveness when anchor data distribution significantly differs from client data is uncertain
- Privacy implications of sharing anchor data between server and clients are not extensively discussed

## Confidence

**High Confidence**:
- Improved convergence rates and accuracy compared to state-of-the-art methods
- Effectiveness of label contrastive loss in reducing confirmation bias

**Medium Confidence**:
- Scalability to larger, more diverse datasets
- Performance in real-world federated learning environments

**Low Confidence**:
- Communication overhead reduction claims without empirical measurements
- Performance on complex tasks beyond standard image classification

## Next Checks

1. Evaluate FedAnchor on more complex tasks and larger-scale datasets to assess scalability and generalizability beyond standard image classification benchmarks.

2. Conduct experiments to quantify the impact of anchor data distribution mismatch between server and clients on overall model performance.

3. Implement and test privacy-preserving techniques for anchor data sharing to ensure compliance with federated learning privacy requirements while maintaining FedAnchor's effectiveness.