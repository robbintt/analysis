---
ver: rpa2
title: 'Artificial intelligence for science: The easy and hard problems'
arxiv_id: '2408.14508'
source_url: https://arxiv.org/abs/2408.14508
tags:
- problem
- science
- scientific
- hard
- problems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper distinguishes between two types of AI-driven scientific\
  \ discovery: \"easy\" problems, where the problem is well-specified and optimization\
  \ techniques can be applied, and \"hard\" problems, where the challenge lies in\
  \ formulating the problem itself. While AI has excelled at the easy problem, the\
  \ hard problem\u2014conceptual innovation in problem specification\u2014remains\
  \ beyond current AI capabilities."
---

# Artificial intelligence for science: The easy and hard problems

## Quick Facts
- arXiv ID: 2408.14508
- Source URL: https://arxiv.org/abs/2408.14508
- Reference count: 40
- Primary result: AI excels at well-specified scientific problems but struggles with conceptual innovation in problem formulation

## Executive Summary
The paper distinguishes between two types of AI-driven scientific discovery: "easy" problems, where the problem is well-specified and optimization techniques can be applied, and "hard" problems, where the challenge lies in formulating the problem itself. While AI has excelled at the easy problem, the hard problem—conceptual innovation in problem specification—remains beyond current AI capabilities. The authors analyze historical scientific breakthroughs (oxygen discovery, electromagnetic theory, protein folding) to illustrate the limitations of existing AI models. They argue that solving the hard problem requires continual conceptual revision based on poorly defined constraints, which is a key aspect of human scientific creativity. The authors propose studying the cognitive science of scientists to develop new computational agents that can automatically infer and update scientific paradigms, bridging the gap between easy and hard problems.

## Method Summary
The authors employ a conceptual analysis approach, examining historical scientific breakthroughs to identify patterns in how scientists formulate and reformulate problems. They analyze three key examples: the discovery of oxygen, the development of electromagnetic theory, and protein folding. Through these case studies, they identify common features of "hard" problems that require conceptual innovation. The paper also reviews current AI capabilities and limitations in scientific discovery, drawing on existing literature in machine learning, cognitive science, and the philosophy of science. Based on this analysis, the authors propose a research program centered on studying scientists' cognitive processes to develop new computational agents capable of automatic paradigm inference and revision.

## Key Results
- AI systems excel at optimization within well-defined problem spaces but cannot formulate new problems
- Scientific breakthroughs often require reconceptualizing the problem itself, not just solving existing formulations
- Current AI lacks the ability to revise conceptual frameworks based on poorly defined constraints
- The cognitive science of scientists' problem-formulation processes offers a path toward more capable scientific AI

## Why This Works (Mechanism)
The mechanism relies on recognizing that scientific discovery operates at two levels: solving problems within existing paradigms (easy) and creating new paradigms by reconceptualizing problems (hard). AI excels at the former because it involves optimization within well-defined spaces, but struggles with the latter because it requires creativity in problem formulation under uncertainty. The proposed solution involves reverse-engineering human scientists' cognitive processes for conceptual innovation, then translating these into computational models that can automatically infer and update scientific paradigms.

## Foundational Learning
- **Problem specification vs. problem solving**: Understanding that AI's current limitations stem from inability to reformulate problems, not solve them
  - Why needed: Distinguishes between what AI can currently do and what's required for breakthrough science
  - Quick check: Can you identify whether a scientific problem is "easy" or "hard" based on whether it requires paradigm shift?

- **Paradigm shifts in science**: Historical patterns of how scientific concepts evolve and problems are reconceptualized
  - Why needed: Provides the theoretical foundation for what "hard" problems look like
  - Quick check: Can you trace how the problem of "combustion" evolved into "oxidation" through oxygen discovery?

- **Cognitive science of scientific creativity**: How scientists actually formulate and reformulate problems during discovery
  - Why needed: Provides the empirical basis for developing new AI architectures
  - Quick check: Can you map the cognitive steps a scientist takes when moving from observation to hypothesis?

- **Computational models of concept learning**: How machines can represent and update conceptual frameworks
- **Scientific methodology under uncertainty**: How scientists operate when constraints are poorly defined
- **Automated theory revision**: Computational approaches to updating knowledge structures

## Architecture Onboarding

**Component map**: Cognitive Process Analysis -> Computational Agent Design -> Scientific Problem Formulation Engine -> Problem Revision Module

**Critical path**: Problem Specification → Conceptual Framework → Constraint Identification → Revision Criteria → New Problem Formulation

**Design tradeoffs**: Interpretability vs. performance in cognitive models, computational efficiency vs. conceptual richness, domain-specific vs. general-purpose agents

**Failure signatures**: Agents get stuck in local optima of problem formulations, inability to recognize when current framework is insufficient, failure to generate novel conceptual connections

**First 3 experiments**:
1. Test whether AI can recognize when a scientific problem requires paradigm shift rather than solution optimization
2. Evaluate AI's ability to generate multiple alternative problem formulations from the same set of observations
3. Measure the effectiveness of cognitive-inspired architectures at discovering novel problem formulations in controlled domains

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- The distinction between "easy" and "hard" problems, while intuitive, lacks formal criteria for classification
- The proposal to study scientists' cognitive processes is methodologically sound but faces significant translation challenges
- The paper does not address how to measure or quantify conceptual innovation in problem formulation

## Confidence
- **High**: AI's current success on well-specified problems (e.g., protein structure prediction)
- **Medium**: The characterization of "hard" problems requiring conceptual innovation
- **Low**: The proposed pathway from cognitive science to computational agents

## Next Checks
1. Conduct a systematic survey of scientists across disciplines to identify common patterns in problem formulation and paradigm shifts
2. Develop benchmark tasks that explicitly test AI systems' ability to reformulate scientific problems under changing constraints
3. Create a framework for quantifying the "hardness" of scientific problems based on the degree of conceptual innovation required for their solution