---
ver: rpa2
title: Evaluation of QCNN-LSTM for Disability Forecasting in Multiple Sclerosis Using
  Sequential Multisequence MRI
arxiv_id: '2401.12132'
source_url: https://arxiv.org/abs/2401.12132
tags:
- quantum
- each
- qubit
- learning
- classical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated three quantum convolutional neural network
  (QCNN)-LSTM models for predicting disability progression in Multiple Sclerosis using
  sequential MRI data, comparing them against classical architectures (VGG16-LSTM
  and ViViT). QCNN models used Matrix Product State (MPS), reverse MERA, and Tree-Tensor
  Network (TTN) circuits with amplitude encoding, achieving holdout testing ROC-AUC
  scores of 0.70, 0.77, and 0.81 respectively.
---

# Evaluation of QCNN-LSTM for Disability Forecasting in Multiple Sclerosis Using Sequential Multisequence MRI

## Quick Facts
- arXiv ID: 2401.12132
- Source URL: https://arxiv.org/abs/2401.12132
- Reference count: 3
- Three quantum-classical hybrid models achieved ROC-AUC scores of 0.70-0.81 for MS disability prediction

## Executive Summary
This study presents three quantum convolutional neural network (QCNN)-LSTM models for predicting disability progression in Multiple Sclerosis using sequential multisequence MRI data. The QCNN models utilize Matrix Product State (MPS), reverse MERA, and Tree-Tensor Network (TTN) quantum circuits with amplitude encoding, achieving holdout testing ROC-AUC scores of 0.70, 0.77, and 0.81 respectively. These models were compared against classical architectures (VGG16-LSTM and ViViT) with scores of 0.73 and 0.77. Notably, QCNN-LSTMs trained significantly faster (39.4 seconds per fold) than classical models (217-224 seconds per fold), with no statistically significant performance differences between approaches.

## Method Summary
The study employed 5-fold cross-validation on a dataset of 703 MS patients with near-annual contrast-enhanced multisequence cervical spine MRIs collected between 2006-2023. The dataset was partitioned into 60:20:20 train/validation/test splits. Three QCNN architectures (MPS, reverse MERA, TTN) with 16-qubit amplitude encoding were implemented, each followed by a classical LSTM layer (1024 units, 0.5 dropout). Quantum circuits used U3-IsingXX-YY-ZZ-U3 gates with CNOT pooling. Models were trained using binary cross-entropy loss and compared against classical VGG16-LSTM and ViViT baselines using ROC-AUC scores and training times, with statistical significance assessed via Levene's test and Student's t-test.

## Key Results
- QCNN-LSTM models achieved ROC-AUC scores of 0.70 (MPS), 0.77 (MERA), and 0.81 (TTN) on holdout testing
- Classical models scored 0.73 (VGG16-LSTM) and 0.77 (ViViT)
- No statistically significant performance differences between models (p=0.713)
- QCNN-LSTMs trained 5.5x faster than classical models (39.4 sec/fold vs 217-224 sec/fold, p<0.001)

## Why This Works (Mechanism)
The quantum convolutional layers extract hierarchical spatial features from MRI sequences through tensor network architectures, while the LSTM layer captures temporal dependencies across sequential scans. The amplitude encoding efficiently represents high-dimensional image data in quantum states, and the quantum-classical hybrid approach leverages quantum parallelism for feature extraction while maintaining classical processing for temporal modeling.

## Foundational Learning
- **Amplitude encoding**: Maps classical data to quantum states for quantum processing - needed for efficient representation of high-dimensional MRI data
- **Matrix Product States**: Quantum circuit architecture for entanglement management - needed to control quantum correlations in feature extraction
- **Tensor network quantum circuits**: Structured quantum circuits for efficient computation - needed to implement scalable quantum feature extraction
- **Quantum-classical hybrid models**: Integration of quantum and classical components - needed to combine quantum feature extraction with classical temporal modeling
- **Cross-validation with stratified splits**: Ensures model robustness across diverse patient populations - needed for reliable performance estimation
- **ROC-AUC metric**: Measures classification performance across all thresholds - needed to evaluate disability progression prediction

## Architecture Onboarding
- **Component map**: MRI images → Amplitude encoding → QCNN (MPS/MERA/TTN) → Classical LSTM → Binary classification
- **Critical path**: Image preprocessing → Quantum feature extraction → LSTM temporal modeling → Classification output
- **Design tradeoffs**: Quantum circuit complexity vs. computational feasibility, qubit size vs. image resolution, training speed vs. prediction accuracy
- **Failure signatures**: Vanishing gradients between quantum and classical layers, memory constraints with larger qubit sizes, poor convergence with inadequate hyperparameters
- **First experiments**: 1) Verify quantum circuit implementation with test inputs, 2) Validate amplitude encoding preserves image features, 3) Test classical LSTM baseline for temporal modeling capability

## Open Questions the Paper Calls Out
- **Hardware vs. Simulator Performance**: How QCNN-LSTM models perform on real quantum hardware versus simulators, given current NISQ device noise characteristics
- **Optimal Qubit Size**: The ideal qubit size for processing high-resolution medical images while maintaining computational feasibility, constrained by current memory limitations
- **Quantum Error Correction Impact**: How different quantum error correction methods affect classification performance and noise resilience in deployed models

## Limitations
- Performance tested only on simulators, not real quantum hardware
- Limited to 16-qubit systems due to memory constraints
- No statistically significant performance advantage over classical models

## Confidence
- **High Confidence**: ROC-AUC scores and training time measurements are clearly reported and internally consistent
- **Medium Confidence**: Statistical testing methodology described, but sample size adequacy for detecting meaningful differences uncertain
- **Low Confidence**: Clinical relevance and practical implementation details of quantum-classical hybrid approach not fully elaborated

## Next Checks
1. Request and implement exact quantum circuit hyperparameter configurations to verify reported performance
2. Reproduce the image preprocessing pipeline to confirm 16-qubit amplitude encoding methodology
3. Conduct power analysis to determine if study had sufficient statistical power to detect clinically meaningful differences between classical and quantum models