---
ver: rpa2
title: 'Mind''s Eye of LLMs: Visualization-of-Thought Elicits Spatial Reasoning in
  Large Language Models'
arxiv_id: '2404.03622'
source_url: https://arxiv.org/abs/2404.03622
tags:
- reasoning
- spatial
- visual
- navigation
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Visualization-of-Thought (VoT) prompting
  to elicit spatial reasoning in large language models (LLMs) by visualizing their
  reasoning traces. VoT prompts models to generate interleaved reasoning and visualization
  steps, grounding subsequent steps in visualized internal states.
---

# Mind's Eye of LLMs: Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models

## Quick Facts
- arXiv ID: 2404.03622
- Source URL: https://arxiv.org/abs/2404.03622
- Authors: Wenshan Wu; Shaoguang Mao; Yadong Zhang; Yan Xia; Li Dong; Lei Cui; Furu Wei
- Reference count: 40
- Primary result: Visualization-of-Thought (VoT) prompting significantly improves spatial reasoning in LLMs by generating interleaved reasoning and visualization steps.

## Executive Summary
This paper introduces Visualization-of-Thought (VoT) prompting, a novel approach that elicits spatial reasoning capabilities in large language models by visualizing their reasoning traces. VoT prompts models to generate interleaved reasoning and visualization steps, grounding subsequent reasoning in visualized internal states. The method is evaluated on three spatial reasoning tasks—natural language navigation, visual navigation, and visual tiling—where it significantly outperforms standard chain-of-thought prompting and even multimodal models. The approach reveals that LLMs can perform mental image manipulation for spatial tasks, suggesting their potential to mimic human-like spatial reasoning processes.

## Method Summary
The Visualization-of-Thought (VoT) prompting method guides LLMs to generate reasoning traces that include both logical steps and corresponding visualizations. Unlike standard chain-of-thought prompting, VoT explicitly asks models to visualize their internal states at each reasoning step, creating a "mind's eye" that grounds subsequent steps in visual context. The visualization format is flexible, allowing models to generate diagrams, maps, or symbolic representations that capture spatial relationships. This approach leverages the model's ability to maintain coherence between textual reasoning and visual elements, creating a feedback loop where each visualization informs the next reasoning step. The method is evaluated across three spatial reasoning tasks that require different types of spatial understanding, from abstract navigation to concrete object manipulation.

## Key Results
- VoT improves natural language navigation accuracy by 23.5% compared to no-visualization baseline
- VoT outperforms standard chain-of-thought prompting across all three evaluated spatial reasoning tasks
- VoT surpasses multimodal models in visual navigation and visual tiling tasks despite being text-only
- Performance gains are most pronounced for models with sufficient reasoning capacity, with diminishing returns for smaller models

## Why This Works (Mechanism)
VoT works by creating a feedback loop between reasoning and visualization that mimics human spatial problem-solving. When models generate visualizations alongside their reasoning steps, they create persistent spatial representations that can be referenced and manipulated in subsequent steps. This visual grounding prevents the loss of spatial information that typically occurs in pure text-based reasoning chains. The interleaved format forces the model to externalize its internal spatial representations, making them available for refinement and correction. By treating visualizations as first-class citizens in the reasoning process rather than mere illustrations, VoT enables models to perform iterative mental image manipulation—a core component of human spatial reasoning. The approach leverages the model's existing multimodal capabilities in a text-only context, suggesting that spatial reasoning may be more about representation and process than modality.

## Foundational Learning
- **Chain-of-Thought Prompting**: A prompting technique where models generate intermediate reasoning steps to solve complex problems. Why needed: Provides baseline comparison and shows that standard reasoning chains lack spatial grounding. Quick check: Test if adding visualization steps to CoT improves performance beyond CoT alone.
- **Spatial Reasoning**: The cognitive ability to manipulate and reason about spatial relationships and objects. Why needed: Core capability being evaluated and the target skill VoT aims to elicit. Quick check: Measure improvement on tasks requiring different types of spatial manipulation (navigation vs. object arrangement).
- **Mental Image Manipulation**: The ability to create, modify, and use visual representations in problem-solving. Why needed: The hypothesized mechanism by which VoT enables spatial reasoning. Quick check: Analyze whether generated visualizations show progressive refinement across reasoning steps.
- **Prompt Engineering**: The practice of designing input prompts to elicit desired behaviors from language models. Why needed: VoT is fundamentally a prompting technique that relies on careful prompt design. Quick check: Test sensitivity to different visualization formats and prompt phrasings.

## Architecture Onboarding

**Component Map**: Input prompt -> LLM reasoning engine -> Visualization generator -> Visual-spatial reasoning -> Output generation -> Visual grounding feedback loop

**Critical Path**: The critical path flows from prompt reception through reasoning generation to visualization creation, then loops back as visualizations inform subsequent reasoning steps. The visualization generator component is essential—without it, the spatial grounding feedback loop breaks and performance degrades to baseline levels.

**Design Tradeoffs**: VoT trades prompt complexity for reasoning capability, requiring more elaborate prompts but potentially unlocking spatial reasoning in otherwise limited models. The approach is model-agnostic but shows diminishing returns for smaller models, creating a capacity threshold below which VoT provides minimal benefit. Visualization format flexibility allows adaptation to different task types but may introduce variability in what constitutes an effective visualization.

**Failure Signatures**: Performance collapses to near-baseline levels when visualization steps are removed from prompts, indicating the visualizations are not merely decorative but functionally necessary. Models below certain capacity thresholds show minimal improvement, suggesting VoT requires sufficient underlying reasoning ability. Inconsistent or irrelevant visualizations correlate with incorrect final answers, indicating the importance of visualization quality for the grounding mechanism.

**3 First Experiments**:
1. Remove visualization steps from VoT prompts while keeping reasoning steps to test if performance drops to baseline
2. Replace VoT visualizations with random or irrelevant images to test if any visualization helps or only task-relevant ones
3. Apply VoT to non-spatial reasoning tasks to test if the approach is specific to spatial reasoning or generalizes to other domains

## Open Questions the Paper Calls Out
None

## Limitations
- Performance improvements may be partially attributed to prompt engineering rather than genuine spatial reasoning capabilities
- The approach shows diminishing returns for less capable models, suggesting effectiveness is model-dependent
- Evaluation primarily uses relatively simple spatial tasks, leaving unclear whether VoT scales to more complex, real-world spatial reasoning scenarios

## Confidence

High confidence: The core observation that VoT outperforms standard chain-of-thought prompting on the tested benchmarks, and that models can generate and reference visual elements in their reasoning traces.

Medium confidence: The claim that VoT reveals LLMs' ability to perform mental image manipulation for spatial tasks, as this interpretation relies on the assumption that the generated visualizations represent genuine internal representations rather than just compliant outputs to the prompt.

Low confidence: The assertion that VoT mimics human-like spatial reasoning processes, as the relationship between VoT-generated visualizations and human cognitive processes remains speculative.

## Next Checks
1. Test VoT on more complex spatial reasoning tasks that require multi-step planning and error correction to assess scalability beyond the current benchmarks.
2. Conduct a systematic ablation study varying the visualization format, content, and frequency to isolate which aspects of VoT contribute most to performance gains.
3. Compare VoT performance across a wider range of model sizes and architectures to better understand the approach's model dependency and potential limitations.