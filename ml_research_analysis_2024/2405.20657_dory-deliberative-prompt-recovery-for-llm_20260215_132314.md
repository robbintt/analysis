---
ver: rpa2
title: 'DORY: Deliberative Prompt Recovery for LLM'
arxiv_id: '2405.20657'
source_url: https://arxiv.org/abs/2405.20657
tags:
- prompt
- arxiv
- output
- recovery
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DORY is a novel approach for prompt recovery from large language
  model outputs using output uncertainty. It identifies a strong negative correlation
  between output probability-based uncertainty and recovery success, then leverages
  this insight to guide recovery through draft reconstruction, hint refinement, and
  noise reduction.
---

# DORY: Deliberative Prompt Recovery for LLM

## Quick Facts
- arXiv ID: 2405.20657
- Source URL: https://arxiv.org/abs/2405.20657
- Reference count: 40
- DORY achieves 10.82% average improvement in BLEU-1 score over existing methods

## Executive Summary
DORY introduces a novel approach for prompt recovery from LLM outputs by leveraging output uncertainty as a guiding signal. The framework identifies that tokens with lower predictive uncertainty are more likely to be part of the original prompt, enabling iterative refinement through draft reconstruction, hint extraction, and noise filtering. Evaluated across multiple LLMs and benchmarks, DORY demonstrates state-of-the-art performance while operating with a single LLM and no external resources.

## Method Summary
DORY operates through a three-stage iterative framework: draft reconstruction uses few-shot learning to create initial prompt guesses from outputs; hint refinement extracts low-uncertainty tokens from output text as recovery clues; noise reduction filters out non-shared tokens by comparing draft outputs with actual outputs. The approach leverages length-normalized predictive entropy as the primary uncertainty metric and requires only a single LLM without training or external resources.

## Key Results
- Achieves 10.82% average improvement in BLEU-1 score over existing methods
- Demonstrates strong negative correlation (r ≥ 0.742) between output uncertainty and recovery success
- Sets new state-of-the-art record across multiple LLMs and benchmarks

## Why This Works (Mechanism)

## Mechanism 1
- **Claim**: Output probability-based uncertainty (specifically LN-PE) has a strong negative correlation with prompt recovery success.
- **Mechanism**: Lower uncertainty in output tokens indicates higher likelihood those tokens are shared with the prompt, providing actionable hints for reconstruction.
- **Core assumption**: Uncertainty measured via length-normalized predictive entropy correlates more strongly with prompt recovery than raw predictive entropy.
- **Evidence anchors**:
  - [abstract] "identify a strong(negative) correlation between output probability-based uncertainty and the success of prompt recovery"
  - [section] "the sentence-wise output uncertainty and recovery performance exhibit strong (negative) correlation (r ≥ 0.742)"
  - [corpus] Weak - no direct corpus evidence for uncertainty correlation; cited only as motivation
- **Break condition**: If output token probabilities are uniformly distributed or LLM is overconfident across all tokens, uncertainty metric loses discriminative power.

## Mechanism 2
- **Claim**: DORY can recover prompts using only a single LLM without external resources or training.
- **Mechanism**: Leverages self-guided iterative refinement: draft reconstruction → hint extraction from low-uncertainty tokens → noise reduction via comparison with draft outputs.
- **Core assumption**: The same LLM can generate both outputs and refine prompts using internally derived clues.
- **Evidence anchors**:
  - [abstract] "operates using a single LLM without any external resources or model"
  - [section] "DORY...draft reconstruction, hint refinement, and noise reduction" - explicitly states no external training
  - [corpus] Weak - neighboring papers don't confirm single-LLM-only approaches
- **Break condition**: If LLM cannot self-reference or generate meaningful low-uncertainty tokens, refinement loop fails.

## Mechanism 3
- **Claim**: Separating shared tokens (hints) from non-shared tokens (noise) improves recovery accuracy.
- **Mechanism**: Draft outputs are generated from recovered drafts; tokens present in both draft outputs and actual outputs with low uncertainty are kept as hints, others marked as noise.
- **Core assumption**: Draft outputs from recovered drafts will have overlapping low-uncertainty tokens with actual outputs if they correspond to prompt content.
- **Evidence anchors**:
  - [section] "comparing draft hint and hint to separate the noise (i.e., non-shared tokens)"
  - [abstract] "DORY involves reconstructing drafts from outputs, refining these with hints, and filtering out noise based on uncertainty"
  - [corpus] Weak - no corpus evidence for this dual-output comparison strategy
- **Break condition**: If draft generation diverges significantly from actual output distribution, noise filtering becomes unreliable.

## Foundational Learning

- **Concept**: Predictive Entropy (PE) and Length-normalized PE (LN-PE)
  - Why needed here: Core uncertainty metric that correlates with prompt recovery success
  - Quick check question: Why normalize PE by sentence length instead of using raw PE?

- **Concept**: Token-level vs sentence-level uncertainty analysis
  - Why needed here: Different granularities yield different recovery signals
  - Quick check question: How does uncertainty differ between shared and non-shared tokens?

- **Concept**: Few-shot learning with template-based prompts
  - Why needed here: Enables DORY to operate without training while guiding LLM reasoning
  - Quick check question: What examples are needed in few-shot prompts for effective draft reconstruction?

## Architecture Onboarding

- **Component map**: Draft Reconstruction → Hint Refinement → Noise Reduction → Final Prompt Recovery
- **Critical path**: Hint extraction from low-uncertainty tokens is the bottleneck; if hints are weak, recovery fails
- **Design tradeoffs**: Single LLM simplicity vs potential gains from trained inversion models; dynamic vs fixed uncertainty thresholds
- **Failure signatures**: High BLEU-1 scores but poor semantic similarity indicates noise remains; low uncertainty across all tokens indicates metric saturation
- **First 3 experiments**:
  1. Compare LN-PE vs fixed α thresholds on a small benchmark
  2. Test hint-only vs hint+noise ablation to quantify noise impact
  3. Vary few-shot example count to find optimal draft reconstruction quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does DORY's performance scale with increasingly longer prompts, particularly those exceeding 20 tokens?
- Basis in paper: The paper reports recovery performance across different prompt length distributions in Tables 12-15, showing that DORY outperforms baselines for both short (≤20 tokens) and longer (>20) prompts.
- Why unresolved: The paper doesn't provide systematic analysis of performance degradation as prompt length increases, nor does it explore the upper limit of prompt length where DORY's effectiveness might break down.
- What evidence would resolve it: A comprehensive evaluation measuring DORY's performance across a wider range of prompt lengths (e.g., 20-100 tokens in increments), identifying the point where performance plateaus or degrades significantly.

### Open Question 2
- Question: What specific architectural or training modifications could further improve DORY's performance on prompts containing complex mathematical or technical content?
- Basis in paper: The paper shows that DORY achieves strong results on the Arxiv Math benchmark, but doesn't investigate targeted improvements for mathematical domains where performance might be lower than general domains.
- Why unresolved: The current DORY framework doesn't incorporate domain-specific adaptations or specialized mathematical reasoning capabilities, which could be limiting factors for complex technical prompts.
- What evidence would resolve it: Comparative experiments testing DORY with mathematical domain-specific fine-tuning, integration of symbolic computation tools, or architectural modifications that enhance mathematical reasoning capabilities.

### Open Question 3
- Question: How would DORY's performance change when applied to prompts containing code snippets or highly structured data formats?
- Basis in paper: The paper demonstrates DORY's effectiveness on general text prompts but doesn't evaluate its capability with code-based or structured data prompts, which represent a distinct prompt category.
- Why unresolved: Code and structured data prompts may require different uncertainty quantification approaches and hint extraction methods compared to natural language prompts, potentially exposing limitations in the current framework.
- What evidence would resolve it: Systematic evaluation of DORY on benchmarks specifically containing code prompts (e.g., programming tasks, API specifications) and structured data prompts (e.g., JSON, XML-based instructions), measuring performance degradation or identifying necessary architectural adaptations.

## Limitations
- Correlation between uncertainty and recovery success may be dataset-dependent and not generalize to all domains
- Computational overhead of multiple LLM passes may limit practical deployment compared to trained inversion models
- Noise reduction mechanism assumes sufficient token overlap between draft and actual outputs, which may fail for highly creative prompts

## Confidence
**High Confidence Claims**:
- The negative correlation between output uncertainty and recovery success is empirically demonstrated across multiple benchmarks
- DORY achieves measurable improvements in BLEU-1 scores compared to baseline methods
- The three-stage framework (draft reconstruction → hint refinement → noise reduction) is internally consistent and implementable

**Medium Confidence Claims**:
- The specific choice of length-normalized predictive entropy (LN-PE) as the optimal uncertainty metric
- The generalizability of DORY's performance to prompts outside the evaluated benchmarks
- The computational efficiency compared to alternative prompt recovery approaches

**Low Confidence Claims**:
- Claims about DORY being superior to all existing methods without comparison to the most recent prompt inversion techniques
- The assertion that no external resources are needed, given the computational overhead of multiple LLM passes
- Performance guarantees for prompts longer than 20 tokens, which are mentioned as challenging but not thoroughly evaluated

## Next Checks
1. **Cross-domain Robustness Test**: Evaluate DORY on diverse domains (legal, medical, creative writing) beyond the academic-focused benchmarks to assess correlation stability and recovery performance across different uncertainty patterns.

2. **Computational Efficiency Benchmark**: Measure the actual compute cost of DORY's iterative refinement approach versus single-pass trained inversion models, including wall-clock time and API token usage for practical deployment scenarios.

3. **Noise Threshold Sensitivity Analysis**: Systematically vary the uncertainty threshold for noise identification and measure its impact on recovery accuracy to determine whether the current threshold selection is optimal or dataset-specific.