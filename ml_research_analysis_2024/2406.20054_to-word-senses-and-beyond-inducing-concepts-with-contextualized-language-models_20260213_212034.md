---
ver: rpa2
title: 'To Word Senses and Beyond: Inducing Concepts with Contextualized Language
  Models'
arxiv_id: '2406.20054'
source_url: https://arxiv.org/abs/2406.20054
tags:
- word
- concept
- concepts
- occurrences
- clusters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces Concept Induction, a novel unsupervised
  task that learns soft word clusters (concepts) directly from raw text, unifying
  polysemy and synonymy modeling. The authors propose a bi-level methodology: a local
  lemma-centric clustering to group occurrences into senses, followed by a global
  cross-lexicon clustering to merge local clusters into concepts.'
---

# To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models

## Quick Facts
- arXiv ID: 2406.20054
- Source URL: https://arxiv.org/abs/2406.20054
- Reference count: 12
- Key outcome: Bi-level clustering approach (F1 0.64 on full data, 0.62 on synonym-rich subset) outperforms baselines in concept induction and improves Word Sense Induction using contextualized embeddings

## Executive Summary
This paper introduces Concept Induction, an unsupervised task that learns soft word clusters (concepts) directly from raw text, unifying polysemy and synonymy modeling. The authors propose a bi-level methodology: local lemma-centric clustering to group occurrences into senses, followed by global cross-lexicon clustering to merge local clusters into concepts. Evaluated on SemCor with BCubed metrics, the bi-level approach outperforms local-only and global-only baselines. It also improves Word Sense Induction and generates competitive concept-aware embeddings for the Word-in-Context task. Manual annotation confirms clusters mostly reflect true synonyms and concepts, validating the approach's effectiveness in modeling lexical meaning beyond traditional sense induction.

## Method Summary
The authors propose a bi-level clustering approach to Concept Induction that leverages contextualized language model embeddings. First, they extract BERT Large embeddings for word occurrences and perform local clustering per lemma to identify senses. Then, they average local cluster embeddings and perform global clustering across all words to identify concepts. This approach generalizes Word Sense Induction by capturing both polysemy (one word, multiple senses) and synonymy (multiple words, shared concepts). The method is evaluated on SemCor using BCubed metrics and compared to local-only and global-only baselines, showing consistent improvements. The induced concepts are also used to create concept-aware static embeddings that perform competitively on the Word-in-Context task.

## Key Results
- Bi-level approach achieves BCubed F1 of 0.64 on full SemCor dataset, outperforming local-only (0.56) and global-only (0.53) baselines
- On synonym-rich subset, bi-level approach achieves F1 of 0.62, maintaining advantage over baselines
- Concept-aware embeddings derived from induced concepts achieve competitive performance on Word-in-Context task using only 52,997 SemCor occurrences versus millions from Wikipedia baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The bi-level clustering approach improves both concept induction and word sense induction by leveraging complementary local and global views of the data.
- Mechanism: The local lemma-centric clustering first groups occurrences of individual words into senses, reducing noise and variance. The global cross-lexicon clustering then merges these local clusters based on their averaged embeddings, allowing correction of local clustering errors and capturing synonymy across the lexicon.
- Core assumption: The contextual embeddings from BERT Large contain sufficient semantic information to distinguish senses locally and concepts globally, and the two levels of clustering are mutually beneficial.
- Evidence anchors:
  - [abstract] "We find that the local and the global levels are mutually beneficial to induce concepts and also senses in our setting."
  - [section] "This demonstrates the benefits of our bi-level approach, and its ability to leverage both local and global views when inducing concepts."
  - [corpus] "We find that best results were obtained using layers 14 to 17, that are the reported results." (Limited evidence that specific layers are best; other depths not fully explored)
- Break condition: If the contextual embeddings do not reliably distinguish senses locally, the local clustering step would fail to reduce noise, negating the benefits of the bi-level approach.

### Mechanism 2
- Claim: The proposed methodology can learn WordNet-based concepts from raw text using contextualized language model embeddings, generalizing beyond traditional word sense induction.
- Mechanism: By representing word occurrences as contextualized embeddings and clustering them first locally (per word) and then globally (across words), the system learns a soft clustering of words into concepts. Polysemous words appear in multiple clusters (one per sense), and synonymous words appear in shared clusters.
- Core assumption: The semantic annotations in SemCor (WordNet synsets) provide a valid reference for evaluating concept induction, and the induced clusters align with these annotations.
- Evidence anchors:
  - [abstract] "We evaluate the obtained clustering on SemCor's annotated data and obtain good performance (BCubed F1 above 0.60)."
  - [section] "This task generalizes Word Sense Induction. We propose a bi-level approach to Concept Induction that leverages both a local lemma-centric view and a global cross-lexicon view to induce concepts."
  - [corpus] "In this study we call sense of a word its usage to refer to a concept." (Definition is provided but not empirically validated against external data)
- Break condition: If the reference annotations in SemCor are not representative of true lexical concepts, the evaluation would not accurately reflect the quality of the induced concepts.

### Mechanism 3
- Claim: Concept-aware static embeddings derived from the induced concepts are competitive with state-of-the-art approaches on the Word-in-Context task while using less training data.
- Mechanism: By averaging the contextualized embeddings of all occurrences in each concept cluster, the system creates static embeddings that represent the semantic content of the concept. These embeddings can then be used to determine if two occurrences refer to the same concept by comparing their closest concept embeddings.
- Core assumption: The averaged embeddings of concept clusters capture the essential semantic features of the concept and are sufficient for the Word-in-Context task.
- Evidence anchors:
  - [abstract] "Finally, we create static embeddings representing our induced concepts and use them on the Word-in-Context task, obtaining competitive performance with the State-of-the-Art."
  - [section] "Our concept-aware embeddings obtain very similar results to those of their sense-aware embeddings, with ours derived from our bi-level approach even outperforming their CBOW method."
  - [corpus] "We used 52 997 occurrences from the SemCor dataset while they used a dump of Wikipedia, gathering millions of occurrences." (Explicit comparison of training data size)
- Break condition: If the averaging process loses critical semantic distinctions within a concept, or if the Word-in-Context task requires more fine-grained distinctions than the concept embeddings provide, the performance would degrade.

## Foundational Learning

- Concept: Polysemy and synonymy as complementary facets of lexical ambiguity.
  - Why needed here: The paper's central argument is that existing NLP tasks treat these phenomena independently, but Concept Induction unifies them. Understanding this relationship is crucial to grasp the motivation and contribution.
  - Quick check question: Can you explain the difference between polysemy and synonymy, and why the paper argues they should be considered together?

- Concept: Contextualized Language Models and their use for semantic representation.
  - Why needed here: The methodology relies on extracting contextualized embeddings from BERT Large to represent word occurrences. Understanding how these models work and why their embeddings are useful for semantic tasks is fundamental.
  - Quick check question: How do contextualized language models like BERT differ from static word embeddings, and why are their hidden layers useful for representing word senses?

- Concept: Clustering algorithms and evaluation metrics for semantic tasks.
  - Why needed here: The paper uses Kmeans and Agglomerative clustering at two levels, and evaluates the results using BCubed metrics. Understanding these techniques and how they are applied to semantic data is necessary to follow the methodology and results.
  - Quick check question: What is the difference between Kmeans and Agglomerative clustering, and why might one be preferred over the other for this task?

## Architecture Onboarding

- Component map: Data preprocessing -> BERT embedding extraction -> Local clustering -> Global clustering -> Concept embedding creation -> Evaluation
- Critical path: Data preprocessing → Embedding extraction → Local clustering → Global clustering → Concept embedding creation → Evaluation. Each step depends on the successful completion of the previous one.
- Design tradeoffs:
  - Local vs. Global clustering: The bi-level approach adds complexity but aims to improve both concept and sense induction. A simpler global-only approach would be faster but potentially less accurate.
  - Choice of clustering algorithm: Kmeans assumes spherical clusters and requires specifying the number of clusters, while Agglomerative is more flexible but can be computationally expensive.
  - Choice of BERT layers: Different layers may capture different aspects of semantics; the paper uses layers 14-17 based on empirical results, but this could be dataset-dependent.
- Failure signatures:
  - Low BCubed F1 scores: Indicates the induced clusters do not align well with the reference annotations, suggesting issues with the embeddings, clustering algorithms, or the bi-level approach itself.
  - Poor performance on WiC task: Suggests the concept embeddings do not capture the necessary semantic distinctions for this task.
  - High variance in local clustering results: Indicates the local embeddings are not reliable for distinguishing senses, which would propagate to the global level.
- First 3 experiments:
  1. Run the local-only clustering baseline (Kmeans and Agglomerative) on a small subset of SemCor to verify it can distinguish senses for individual words.
  2. Run the global-only clustering (Kmeans and Agglomerative) on the same subset to see if it can capture synonymy without local preprocessing.
  3. Run the full bi-level approach on the subset and compare its performance to the local-only and global-only baselines using BCubed F1 to confirm the benefits of the bi-level approach.

## Open Questions the Paper Calls Out

- Question: How would Concept Induction performance change when applied to verbs, adjectives, and adverbs instead of only nouns?
  - Basis in paper: [explicit] The paper explicitly limits its study to nouns and suggests future work should explore other parts-of-speech.
  - Why unresolved: The methodology and hyperparameter tuning were optimized specifically for nouns, and the semantic properties of other parts-of-speech may require different approaches or representations.
  - What evidence would resolve it: Running the full Concept Induction pipeline on annotated datasets containing verbs, adjectives, and adverbs with evaluation using the same BCubed metrics would show performance differences across parts-of-speech.

- Question: Would an iterative or joint optimization approach to local and global clustering outperform the current sequential bi-level method?
  - Basis in paper: [inferred] The paper mentions that its sequential bi-level method cannot split local clusters using global information, and suggests this as a limitation that future research could address.
  - Why unresolved: The current method alternates between local and global clustering but doesn't allow for mutual refinement where global information could correct local splits or vice versa.
  - What evidence would resolve it: Implementing an iterative approach that alternates local and global clustering until convergence, or a joint optimization framework, and comparing its Concept Induction F1 scores against the current sequential method on the same datasets.

- Question: How does Concept Induction performance scale with dataset size, particularly for words with many occurrences per lemma?
  - Basis in paper: [explicit] The paper notes that the current evaluation used SemCor with only ~30 occurrences per lemma on average, and questions whether the observed advantages over traditional WSI methods would hold on larger datasets.
  - Why unresolved: The current experiments were conducted on relatively small, sparse datasets, making it unclear if the bi-level approach's benefits would persist when words have hundreds of occurrences.
  - What evidence would resolve it: Evaluating Concept Induction on much larger corpora (like Wikipedia or web-scale data) with high-occurrence words, comparing the relative performance of bi-level CI versus traditional WSI methods as occurrence counts increase.

## Limitations
- Evaluation is limited to SemCor corpus with WordNet annotations, potentially introducing bias if these annotations don't fully capture semantic nuances
- The bi-level approach's benefits may not scale to larger datasets with many occurrences per lemma, as current evaluation used relatively sparse data
- Hyperparameter sensitivity (number of clusters, distance thresholds, BERT layers) is not thoroughly explored, leaving questions about robustness

## Confidence
- Confidence in core claims is Medium. The methodology is well-motivated and results show clear improvements over baselines, but evaluation scope is narrow.
- The claim that contextualized embeddings from specific BERT layers are optimal is supported by empirical results but lacks theoretical justification (Medium).
- The assertion that the bi-level approach is mutually beneficial for both concept and sense induction is demonstrated but could benefit from ablation studies (Medium).

## Next Checks
1. Evaluate the bi-level approach on a different corpus with alternative sense inventories (e.g., OntoNotes) to test generalizability beyond SemCor and WordNet.
2. Conduct an ablation study comparing local-only, global-only, and bi-level approaches across multiple datasets to quantify the specific contributions of each level.
3. Perform a sensitivity analysis on clustering hyperparameters (k values, distance thresholds) and BERT layer selection to determine the robustness of the approach to these choices.