---
ver: rpa2
title: The Sample Complexity of Gradient Descent in Stochastic Convex Optimization
arxiv_id: '2404.04931'
source_url: https://arxiv.org/abs/2404.04931
tags:
- sample
- then
- function
- such
- bound
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper establishes tight lower bounds on the sample complexity\
  \ of gradient descent (GD) in stochastic convex optimization. The main result shows\
  \ that for standard hyperparameter choices, GD requires \u03A9(d/m + 1/\u221Am)\
  \ samples, matching the worst-case sample complexity of empirical risk minimizers."
---

# The Sample Complexity of Gradient Descent in Stochastic Convex Optimization

## Quick Facts
- **arXiv ID:** 2404.04931
- **Source URL:** https://arxiv.org/abs/2404.04931
- **Authors:** Roi Livni
- **Reference count:** 40
- **Primary result:** Shows gradient descent with standard hyperparameters has no advantage over empirical risk minimizers, requiring Œ©(d/m + 1/‚àöm) samples when dimension exceeds sample size.

## Executive Summary
This paper establishes tight lower bounds on the sample complexity of gradient descent (GD) in stochastic convex optimization. The main result demonstrates that for standard hyperparameter choices, GD requires Œ©(d/m + 1/‚àöm) samples, matching the worst-case sample complexity of empirical risk minimizers. This proves that GD has no inherent advantage over naive ERMs despite its iterative nature. The analysis involves constructing adversarial functions where GD overfits despite standard assumptions, and resolves an open question about the necessary number of iterations to avoid overfitting when dimension exceeds sample size.

## Method Summary
The paper analyzes gradient descent in stochastic convex optimization by constructing adversarial function families that exploit the interaction between learning rate, iteration count, and dimension. The construction combines Nemirovski's function for trajectory control with Feldman's function to enable polynomial dependence on dimension. The analysis shows that when T ‚â§ cubic in dimension, the generalization gap is dominated by the linear dependence on dimension (d/m). For larger T, the stability term (Œ∑‚àöT) becomes dominant but still matches ERM bounds. The proof technique uses a reduction from sample-dependent oracles to standard first-order oracles through careful interpolation, preserving the overfitting behavior.

## Key Results
- Gradient descent with optimal hyperparameters has generalization error of Œò(d/m + 1/‚àöm), matching worst-case ERMs
- When dimension exceeds sample size (d > m), T = Œ©(1/Œµ‚Å¥) iterations are necessary to avoid overfitting
- The linear improvement over previous bounds is tight for d < m, while becoming vacuous for d ‚â• m

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Gradient descent with standard hyperparameters has no advantage over empirical risk minimizers in stochastic convex optimization when dimension exceeds sample size.
- **Mechanism:** The proof constructs a family of adversarial functions where GD's trajectory converges to a point that overfits the training data, matching the worst-case generalization error of ERMs.
- **Core assumption:** There exists a distribution and function family where GD's trajectory can be precisely controlled through a carefully designed subgradient oracle.
- **Evidence anchors:**
  - [abstract]: "We show that the generalization error of GD, with (minmax) optimal choice of hyper-parameters, can be ÀúŒò(d/m + 1/‚àöm)"
  - [section]: "Our bound also shows that, for general hyper-parameters, when the dimension is strictly larger than number of samples, T=Œ©(1/Œµ4) iterations are necessary to avoid overfitting"
  - [corpus]: Weak evidence - neighboring papers focus on different aspects of gradient methods and generalization.

### Mechanism 2
- **Claim:** The adversarial function family exploits the interaction between learning rate, iteration count, and dimension to create overfitting scenarios.
- **Mechanism:** When T ‚â§ cubic in dimension, the generalization gap is dominated by the linear dependence on dimension (d/m). For larger T, the stability term (Œ∑‚àöT) becomes dominant, but still matches ERM bounds.
- **Core assumption:** The Nemirovski function and its variants can be modified to create the required overfitting dynamics while maintaining convexity and Lipschitzness.
- **Evidence anchors:**
  - [section]: "Equation (7) does not hold for d < m, and the linear improvement over [2, 20] is tight"
  - [section]: "Equation (7) becomes vacuous for such choice of parameters, but Carmon et al. [11] showed that the sample complexity of any ERM is bounded by ÀúO((d + ‚àöm)/m)"
  - [corpus]: Weak evidence - neighboring papers don't directly address the d/m term dominance.

### Mechanism 3
- **Claim:** The reduction from sample-dependent oracles to standard first-order oracles preserves the overfitting behavior through interpolation techniques.
- **Mechanism:** By encoding the sample into an auxiliary coordinate and using a strongly convex perturbation, the construction ensures that the trajectory visits points where the interpolated function is differentiable and maintains the desired dynamics.
- **Core assumption:** The interpolation lemma (Lemma 7) guarantees existence of a convex, Lipschitz function that matches the trajectory points and gradients.
- **Evidence anchors:**
  - [section]: "We therefore provide an elementary, self-contained, proof to the following easy to prove Lemma, (proof is provided in Appendix A)"
  - [section]: "With Lemma 7 at hand, consider the function ‚Ñé(ùë§, ùëß) = 1/2 (ùë§ (ùëë + 1))¬≤ + Œ±(ùëß) ¬∑ ùë§ (ùëë + 1)"
  - [corpus]: No direct evidence - this is a novel technical contribution not present in neighboring work.

## Foundational Learning

- **Concept:** Stochastic Convex Optimization (SCO) setup with Lipschitz convex functions and first-order oracles
  - Why needed here: The entire analysis assumes this standard SCO framework where algorithms access functions only through subgradients
  - Quick check question: What is the relationship between the population loss F(w) and empirical risk F_S(w) in SCO?

- **Concept:** Stability-based generalization bounds for iterative algorithms
  - Why needed here: The paper uses stability arguments to bound generalization error, building on Bassily et al.'s work
  - Quick check question: How does the Œ∑‚àöT term arise in the stability bound for gradient descent?

- **Concept:** Convex interpolation and extension theorems
  - Why needed here: The proof requires constructing a function that passes through specific trajectory points with specific gradients
  - Quick check question: What conditions must be satisfied for a set of value-gradient-point triples to be interpolable by a convex function?

## Architecture Onboarding

- **Component map:** Adversarial function construction (Nemirovski variant + Feldman function) -> Sample-dependent oracle definition and analysis -> Reduction to standard oracle through interpolation -> Trajectory analysis and projection arguments
- **Critical path:** Construct adversarial function ‚Üí Define sample-dependent oracle ‚Üí Analyze trajectory ‚Üí Reduce to standard oracle ‚Üí Prove generalization bound
- **Design tradeoffs:** 
  - Using Nemirovski function allows trajectory control but limits iterations to O(d)
  - Feldman function enables polynomial dependence on dimension but complicates oracle design
  - Interpolation approach is general but requires careful verification of differentiability
- **Failure signatures:** 
  - If the trajectory deviates from the designed path, the overfitting claim fails
  - If the interpolation violates convexity or Lipschitzness, the reduction breaks
  - If the dimension-sample ratio assumptions are violated, the bounds become vacuous
- **First 3 experiments:**
  1. Verify the trajectory properties for the Nemirovski-based construction with d = T = 4
  2. Check the interpolation conditions for a small set of trajectory points
  3. Test the generalization gap computation for the reduced function with known oracle

## Open Questions the Paper Calls Out

- **Open Question 1:** Is there a generalization bound for GD such that the expected population loss minus the optimal loss is bounded by O(dŒ∑‚àöT/m + 1/‚àöm)?
  - Basis in paper: Explicitly stated as an open problem in the discussion section
  - Why unresolved: The paper shows that GD's sample complexity matches worst-case ERMs, but it's unknown if GD can achieve better generalization bounds in certain regimes
  - What evidence would resolve it: A mathematical proof demonstrating such a generalization bound for GD, or a counterexample showing it's impossible

- **Open Question 2:** Are there choices of learning rate Œ∑ and number of iterations T (depending on m) such that Œ∑T/m = Œ©(1), but GD still has dimension-independent sample complexity?
  - Basis in paper: Explicitly stated as an open problem in the discussion section
  - Why unresolved: While the paper shows GD requires T = Œ©(1/Œµ‚Å¥) iterations to avoid overfitting when d > m, it's unknown if there exist hyperparameter choices that allow GD to generalize despite instability
  - What evidence would resolve it: A proof demonstrating such hyperparameter choices exist, or a proof showing they cannot exist

- **Open Question 3:** What is the sample complexity of GD when the function f(w,z) is Œò(1)-smooth, Œ∑ and T are chosen such that Œ∑ + 1/(Œ∑T) = o(1), but Œ∑T/m = Œ©(1)?
  - Basis in paper: Explicitly stated as an open problem in the discussion section
  - Why unresolved: The paper shows that for smooth functions, GD's stability is governed by O(Œ∑T/m), but it's unknown how this affects sample complexity in the regime where stability and optimization error are both significant
  - What evidence would resolve it: A mathematical proof establishing the sample complexity in this regime, or a construction demonstrating that GD can or cannot achieve dimension-independent sample complexity

## Limitations
- The construction relies on a carefully designed adversarial function family where GD's trajectory can be precisely controlled, which may be fragile
- The reduction from sample-dependent oracles to standard first-order oracles depends on interpolation conditions that, while proven, may not hold for all possible trajectories
- The bounds are worst-case and may not reflect typical practical scenarios

## Confidence
- **High Confidence:** The main claim that GD has Œò(d/m + 1/‚àöm) generalization error with optimal hyperparameters is well-supported by the construction and analysis.
- **Medium Confidence:** The necessity of Œ©(1/Œµ‚Å¥) iterations to avoid overfitting when d > m is established but relies on specific parameter choices in the construction.
- **Low Confidence:** The exact constants and threshold values in the adversarial function construction are not fully specified, which could affect the tightness of the bounds.

## Next Checks
1. **Trajectory Verification:** Implement the Nemirovski-based construction with small dimensions (d=4, T=4) and verify that GD's trajectory matches the theoretically predicted path.
2. **Interpolation Validation:** Test the interpolation lemma by constructing a small set of trajectory points with specified gradients and verifying that a convex, Lipschitz function exists that passes through them.
3. **Generalization Gap Testing:** Implement the reduced function with the standard first-order oracle and run GD with various hyperparameter choices to empirically verify the predicted generalization error bounds.