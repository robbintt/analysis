---
ver: rpa2
title: Teaching LLMs to Abstain across Languages via Multilingual Feedback
arxiv_id: '2406.15948'
source_url: https://arxiv.org/abs/2406.15948
tags:
- language
- languages
- feedback
- multilingual
- abstain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces the first study on multilingual LLM abstention,\
  \ proposing to teach LLMs to abstain by generating and learning from multilingual\
  \ feedback in related languages. Existing abstention approaches degrade by up to\
  \ 20.5% in low-resource languages due to LLMs\u2019 diminishing calibration and\
  \ reasoning capabilities."
---

# Teaching LLMs to Abstain across Languages via Multilingual Feedback

## Quick Facts
- arXiv ID: 2406.15948
- Source URL: https://arxiv.org/abs/2406.15948
- Reference count: 40
- Existing abstention approaches degrade by up to 20.5% in low-resource languages

## Executive Summary
This paper addresses the critical challenge of multilingual LLM abstention, where existing approaches fail significantly in low-resource languages due to LLMs' diminishing calibration and reasoning capabilities. The authors propose a novel approach that teaches LLMs to abstain by generating and learning from multilingual feedback in related languages. Through experiments across three models and datasets, the proposed method improves low-resource language abstention accuracy by up to 9.2%, outperforming strong baselines. The study reveals that multilingual feedback is more equitable across languages, cultural factors strongly impact abstention behavior, and that abstaining is a language-specific problem requiring targeted strategies.

## Method Summary
The approach involves teaching LLMs to abstain from answering when knowledge is insufficient by generating feedback on proposed answers in related languages. The method uses four multilingual feedback strategies: MONO-NATIVE (same language), MONO-ENGLISH (English), MULTI-RANDOM (random languages), and MULTI-RELATED (linguistically related languages). The LLM generates feedback on its proposed answer and uses this feedback for self-reflection to make abstain decisions. The approach is evaluated on multilingual QA datasets (M-MMLU, M-Hellaswag, Belebele) across 26 languages using metrics including Abstain Accuracy, Reliable Accuracy, and Effective Reliability.

## Key Results
- Existing abstention approaches degrade by up to 20.5% in low-resource languages
- Proposed multilingual feedback approach improves low-resource language abstention accuracy by up to 9.2%
- Culturally-informed language selection yields the best utility and equity results
- Abstaining is identified as a language-specific problem requiring targeted strategies

## Why This Works (Mechanism)

### Mechanism 1
Multilingual feedback from related languages helps identify knowledge gaps across diverse cultures, perspectives, and contexts. When an LLM generates feedback on its proposed answer in related languages, it leverages linguistic and cultural similarities to surface information that may be missing or underrepresented in the target language. This self-reflective process allows the model to detect inconsistencies or blind spots not apparent when evaluating the answer in isolation.

### Mechanism 2
Conflicting feedback across related languages improves LLM self-reflection and abstention decisions. When feedback from related languages disagrees in content or conclusion, it creates a knowledge conflict that forces the LLM to critically evaluate its proposed answer. This conflict signals potential uncertainty or incomplete knowledge, prompting the model to abstain rather than provide a potentially incorrect answer.

### Mechanism 3
Cultural relatedness in language selection yields the most equitable and effective abstention strategy. By selecting feedback languages based on cultural similarity rather than just linguistic distance, the approach addresses underlying cultural biases and knowledge disparities in LLMs. This ensures feedback comes from culturally aligned sources, making it more relevant and actionable for the target language context.

## Foundational Learning

- **Language relatedness metrics (linguistic, geographic, phonological, genetic, inventory, featural)**: Understanding how languages are related helps in selecting appropriate feedback languages that can provide meaningful insights into knowledge gaps in the target language. *Quick check*: What are the six linguistic attributes used in Lang2vec to measure language relatedness, and how do they differ in their approach to defining similarity?

- **Cross-lingual transfer learning principles**: The approach relies on the ability of multilingual LLMs to transfer knowledge from related languages to improve performance in under-resourced languages. *Quick check*: How does cross-lingual transfer learning differ from traditional transfer learning, and what are the key factors that influence its effectiveness?

- **Calibration and uncertainty estimation in language models**: The abstention mechanism depends on the LLM's ability to assess its own confidence and uncertainty when faced with potentially conflicting information. *Quick check*: What are the main challenges in calibrating language models for uncertainty estimation, and how do these challenges differ across languages with varying resource levels?

## Architecture Onboarding

- **Component map**: Input question in target language -> QA generation -> Feedback generation in 3 related languages -> Abstention decision -> Final decision with confidence score

- **Critical path**: 1. Receive question in target language 2. Generate proposed answer using QA LLM 3. Generate feedback in 3 related languages 4. Evaluate feedback for relevance, informativeness, and conflicts 5. Make abstention decision based on feedback analysis 6. Return final decision with confidence score

- **Design tradeoffs**: Language selection (linguistic vs. cultural relatedness), number of feedback languages (more perspectives vs. computational cost), feedback quality vs. quantity

- **Failure signatures**: Consistently low abstention accuracy across all languages, high accuracy in high-resource but low in low-resource languages, high rate of false positives in low-resource languages

- **First 3 experiments**: 1. Ablation study comparing different language relatedness metrics on abstention accuracy across resource levels 2. Sensitivity analysis of number of feedback languages (k=1,2,3,4,5) on performance and computational efficiency 3. Cross-model evaluation comparing general-purpose LLM (GPT-4) with explicitly multilingual model (AYA-13B) for feedback generation quality and impact on abstention decisions

## Open Questions the Paper Calls Out

### Open Question 1
How do cultural factors specifically influence the effectiveness of multilingual feedback for LLM abstention across different language families and regions? While the paper demonstrates that culture impacts language selection and LLM abstention behavior, it doesn't provide detailed mechanisms or frameworks for how specific cultural dimensions affect feedback generation and self-reflection processes.

### Open Question 2
What are the optimal strategies for combining multilingual feedback with retrieval-augmented generation to improve LLM abstention reliability in low-resource languages? The paper shows effectiveness but doesn't explore optimal integration strategies such as timing of feedback generation relative to retrieval or how to weight feedback from different languages when they conflict.

### Open Question 3
How can we develop language-specific abstention strategies that account for the unique challenges faced by individual low-resource languages rather than treating them as a homogeneous group? The authors observe that Tamil and Malayalam are consistently the most challenging languages across models, datasets, and approaches, but don't propose concrete methodologies for creating tailored abstention strategies for individual languages.

## Limitations

- The selection of "related languages" remains somewhat arbitrary, relying on linguistic attributes that may not optimally capture semantic and cultural similarities
- The approach assumes LLMs can effectively process and weigh conflicting feedback, but lacks detailed analysis of the LLM's internal reasoning process
- Temperature-based sampling for feedback generation introduces randomness that may affect consistency and reliability of abstention decisions

## Confidence

- **High Confidence**: Degradation of existing abstention approaches in low-resource languages (up to 20.5% accuracy loss) and improvement from multilingual feedback (up to 9.2%)
- **Medium Confidence**: Culturally-informed language selection yielding best utility and equity results, mechanism of conflicting feedback improving self-reflection
- **Low Confidence**: Inherent equity of multilingual feedback across language communities, generalizability to languages beyond the 26 tested

## Next Checks

1. **Ablation Study on Language Selection Criteria**: Compare linguistic-based language selection versus cultural-based selection using explicit cultural similarity metrics to measure whether cultural similarity predicts better abstention performance than purely linguistic relatedness across different domain types.

2. **Conflict Processing Analysis**: Implement systematic analysis of how the LLM processes conflicting feedback by varying the degree and nature of conflicts in generated feedback to test whether the model can distinguish between informative conflicts and uninformative conflicts.

3. **Cross-Domain Generalization Test**: Evaluate the multilingual feedback approach on a new set of languages and domains not included in the original study, particularly focusing on languages from different language families and cultures to measure whether performance improvements generalize beyond Indo-European and East Asian languages.