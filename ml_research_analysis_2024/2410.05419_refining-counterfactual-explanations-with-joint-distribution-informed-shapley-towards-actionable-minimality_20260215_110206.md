---
ver: rpa2
title: Refining Counterfactual Explanations With Joint-Distribution-Informed Shapley
  Towards Actionable Minimality
arxiv_id: '2410.05419'
source_url: https://arxiv.org/abs/2410.05419
tags:
- counterfactual
- equation
- data
- shapley
- cola
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of actionable minimality in counterfactual
  explanations (CE), where existing methods often include unnecessary feature changes.
  The authors propose COLA (Counterfactuals with Limited Actions), a versatile algorithmic
  framework that minimizes required feature changes while maintaining CE validity.
---

# Refining Counterfactual Explanations With Joint-Distribution-Informed Shapley Towards Actionable Minimality

## Quick Facts
- **arXiv ID**: 2410.05419
- **Source URL**: https://arxiv.org/abs/2410.05419
- **Reference count**: 40
- **Primary result**: COLA achieves 13-25% of feature changes compared to original CE while reaching 80% counterfactual effect, demonstrating the importance of proper alignment between factual and counterfactual data.

## Executive Summary
This paper addresses the actionable minimality problem in counterfactual explanations (CE), where existing methods often include unnecessary feature changes that make explanations impractical for real-world application. The authors propose COLA, a versatile algorithmic framework that minimizes required feature changes while maintaining CE validity. The key innovation is computing a joint distribution between observed and counterfactual data using optimal transport (OT), then leveraging it to inform Shapley values for feature attributions (FA). Experiments across four datasets, five CE algorithms, and 12 models show that COLA significantly outperforms existing methods in achieving actionable minimality.

## Method Summary
COLA (Counterfactuals with Limited Actions) is a framework that refines counterfactual explanations by minimizing feature changes while maintaining counterfactual validity. The method computes a joint distribution between factual and counterfactual data using optimal transport, then uses this distribution to inform Shapley values for feature attribution. The framework consists of four main components: ACE (Counterfactual Explanation Generator), AProb (Joint Distribution Calculator), AShap (Shapley Calculator), and AValue (Value Calculator). The joint distribution captures the minimal modification cost between factual and counterfactual data, which is then used to compute feature attributions that reflect the most cost-effective paths to counterfactuals. The method is versatile and can be integrated with various existing CE algorithms.

## Key Results
- COLA reduces feature changes to 13-25% of original CE while maintaining 80% counterfactual effect
- CF-pOT (COLA with OT-based joint distribution) outperforms baseline methods across all datasets and models
- Counterintuitive finding: OT-based alignment sometimes outperforms exact CE algorithm pairings for feature attribution
- COLA demonstrates superior performance compared to existing Shapley methods that don't incorporate counterfactual knowledge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The joint distribution between factual and counterfactual data computed via optimal transport (OT) enables better feature attribution than using counterfactuals alone
- Mechanism: OT minimizes the total feature modification cost between factual and counterfactual data, creating an alignment that reflects minimal changes needed to achieve counterfactual outcomes. This alignment is then used to inform Shapley values, ensuring that feature attributions correspond to the most cost-effective paths to counterfactuals
- Core assumption: The alignment that minimizes feature modification cost is the most appropriate alignment for feature attribution purposes
- Evidence anchors: [abstract]: "We demonstrate that optimal transport (OT) effectively derives this distribution, especially when the alignment between observed and counterfactual data is unclear"; [section 4]: "OT minimizes the total feature modification cost... This directly corresponds to our objective in equation 1a of finding feature modifications that achieve the counterfactual outcomes at minimal cost"

### Mechanism 2
- Claim: The p-SHAP method generalizes existing Shapley methods and can outperform them by incorporating counterfactual knowledge
- Mechanism: p-SHAP extends baseline Shapley methods by integrating joint probability distributions between factual and counterfactual data. This allows it to capture the counterfactual structure that traditional methods miss, leading to more actionable feature attributions
- Core assumption: Counterfactual knowledge improves feature attribution for actionable minimality
- Evidence anchors: [section 4]: "Interestingly, we emphasize that AProb, in order to lead to a good FA performance, does not necessarily require knowledge of the CE algorithm being used"; [section 6]: "The result showing that CF-pOT outperforms RB-pOT demonstrates that the use of OT enhances the performance of p-SHAP specifically by providing effective factual-counterfactual alignment"

### Mechanism 3
- Claim: The counterintuitive finding that exact alignment between factual and counterfactual instances may underperform p-SHAP solution
- Mechanism: Even when CE algorithms provide exact pairings between factual and counterfactual instances, the OT-based joint distribution can identify better alignments for feature attribution by considering the global structure of both datasets rather than individual pairings
- Core assumption: Global joint distribution optimization can outperform exact pairwise alignments for feature attribution
- Evidence anchors: [abstract]: "Additionally, a counterintuitive finding is uncovered: it may be misleading to rely on an exact alignment defined by the CE generation mechanism in conducting FA"; [section 6]: "It is interesting to note that CF-pOT sometimes performs better than CF-pEct, suggesting that the mechanism used to generate counterexamples may not always provide the best alignment for achieving actionable minimality"

## Foundational Learning

- **Optimal Transport (OT)**: Why needed here: OT is the core mechanism for computing joint distributions between factual and counterfactual data, which enables better feature attributions. Quick check question: How does OT differ from simply computing pairwise distances between factual and counterfactual instances?

- **Shapley Values**: Why needed here: Shapley values provide the theoretical foundation for feature attribution, and the paper extends them to incorporate counterfactual knowledge. Quick check question: What is the difference between baseline Shapley, random baseline Shapley, and counterfactual Shapley?

- **Counterfactual Explanations**: Why needed here: The entire framework is built around refining counterfactual explanations to be more actionable and minimal. Quick check question: What distinguishes instance-based CE from group-based CE or distributional CE?

## Architecture Onboarding

- **Component map**: ACE (Counterfactual Explanation Generator) → AProb (Joint Distribution Calculator) → AShap (Shapley Calculator) → AValue (Value Calculator) → COLA final output
- **Critical path**: ACE → AProb → AShap → AValue → COLA final output
- **Design tradeoffs**: Using OT vs. exact alignment: OT provides better global optimization but loses exact pairing information; Amax Value vs. Aavg Value: Amax Value is simpler but Aavg Value provides smoother transitions; Entropic regularization in OT: Helps with numerical stability but may reduce optimality
- **Failure signatures**: Poor performance: Check if AProb is producing meaningful joint distributions; High computational cost: OT computation scales poorly with dataset size; Unstable results: Check if Shapley calculations are converging properly
- **First 3 experiments**: 1) Run COLA with a simple dataset and CE algorithm to verify basic functionality; 2) Compare RB-pUni vs CF-pOT to observe the impact of incorporating counterfactual knowledge; 3) Test with known alignment (CF-pEct) vs OT alignment to verify the counterintuitive finding

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal alignment method between factual and counterfactual instances for maximizing actionable minimality?
- Basis in paper: [explicit] The paper notes that even when CE algorithms explicitly match factual instances to counterfactuals, it is challenging to justify that the known alignment optimizes performance, and finding the best alignment remains an open question.
- Why unresolved: The paper shows that CF-pOT (using optimal transport) sometimes outperforms CF-pEct (using known exact alignment), suggesting that the generation mechanism may not always provide the best alignment.
- What evidence would resolve it: Empirical comparison of different alignment methods (OT-based, exact matching, random matching, learned matching) across diverse datasets and CE algorithms, measuring both counterfactual effect and action minimality.

### Open Question 2
- Question: How does the computational complexity of COLA scale with large datasets and high-dimensional feature spaces?
- Basis in paper: [explicit] The paper analyzes COLA's complexity and notes that solving MILP formulations (used for optimality benchmarks) is computationally expensive and only applies to small-scale datasets.
- Why unresolved: While the paper provides theoretical complexity analysis, it doesn't empirically demonstrate performance on large-scale problems or compare runtime with existing methods.
- What evidence would resolve it: Systematic benchmarking of COLA's runtime and scalability across datasets of varying sizes and dimensions, compared to alternative approaches.

### Open Question 3
- Question: Can the joint distribution computation in p-SHAP be improved beyond optimal transport for better actionable minimality?
- Basis in paper: [explicit] The paper demonstrates that OT-based joint distributions outperform random and uniform distributions, but notes that "devising a better AProb algorithm is hence an interesting topic worth exploration."
- Why unresolved: While OT shows superior performance, the paper acknowledges that "pOT does not need to be the true joint distribution" and that "any known best p still has non-negligible gap to the global optimality."
- What evidence would resolve it: Development and empirical validation of alternative joint distribution methods (e.g., learned distributions, hybrid approaches) that outperform OT in achieving counterfactual effects with minimal actions.

## Limitations
- The counterintuitive finding that exact alignments may be misleading is demonstrated empirically but lacks theoretical guarantees and may be dataset-specific.
- The paper doesn't provide error bounds or robustness analysis for the OT-based joint distribution estimation.
- Computational complexity of OT scales poorly with dataset size, limiting applicability to large-scale problems.

## Confidence

- **High confidence**: The experimental results showing COLA reduces feature changes to 13-25% while maintaining 80% counterfactual effect are well-supported with quantitative metrics.
- **Medium confidence**: The claim that p-SHAP generalizes existing methods and benefits from counterfactual knowledge is supported by ablation studies but relies on specific implementation choices.
- **Low confidence**: The assertion that OT alignment is universally superior to exact CE algorithm alignments is based on limited experimental evidence across 4 datasets and may not generalize.

## Next Checks

1. **Theoretical analysis**: Prove or disprove whether OT-based joint distribution estimation is guaranteed to improve feature attribution quality compared to exact alignments, or identify conditions under which it fails.

2. **Generalization testing**: Evaluate COLA on datasets with different characteristics (high-dimensional, sparse, non-tabular) and with CE algorithms not included in the original study to test robustness.

3. **Robustness analysis**: Measure COLA's performance under noisy counterfactuals and adversarial CE algorithms to determine if the method is sensitive to the quality of initial counterfactuals.