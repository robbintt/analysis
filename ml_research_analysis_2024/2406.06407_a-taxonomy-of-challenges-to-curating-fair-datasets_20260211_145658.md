---
ver: rpa2
title: A Taxonomy of Challenges to Curating Fair Datasets
arxiv_id: '2406.06407'
source_url: https://arxiv.org/abs/2406.06407
tags:
- data
- dataset
- fairness
- datasets
- fair
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a taxonomy of challenges dataset curators face
  when creating fair machine learning datasets, identified through interviews with
  30 practitioners. The authors categorize challenges across five phases of the dataset
  lifecycle (requirements, design, implementation, evaluation, maintenance) and five
  levels of the broader fairness landscape (individual, discipline, organization,
  regulatory, socio-political).
---

# A Taxonomy of Challenges to Curating Fair Datasets

## Quick Facts
- arXiv ID: 2406.06407
- Source URL: https://arxiv.org/abs/2406.06407
- Reference count: 40
- Primary result: Taxonomy of challenges in fair dataset curation across dataset lifecycle phases and broader landscape levels

## Executive Summary
This paper presents a comprehensive taxonomy of challenges faced by dataset curators when creating fair machine learning datasets. Through interviews with 30 practitioners, the authors identify and categorize challenges across five phases of the dataset lifecycle (requirements, design, implementation, evaluation, maintenance) and five levels of the broader fairness landscape (individual, discipline, organization, regulatory, socio-political). The study reveals systemic issues in how fairness is conceptualized, operationalized, and incentivized within the ML ecosystem, highlighting the need for structural changes to support equitable dataset development.

## Method Summary
The authors conducted semi-structured interviews with 30 dataset curation practitioners across academia, industry, and government sectors. Participants included data scientists, ML engineers, researchers, and policy experts working on various ML applications. Interviews explored practitioners' experiences with dataset development, their understanding of fairness, and the obstacles they encountered when attempting to create fair datasets. The qualitative data was analyzed using thematic coding to develop the taxonomy structure and identify specific challenges within each category.

## Key Results
- Dataset curators struggle to balance technical dataset requirements with fairness goals, particularly regarding scope and diversity
- Creating taxonomies and labels that accurately reflect fairness definitions proves challenging across all lifecycle phases
- Limited availability of diverse data and systemic issues around recognition and incentives hinder fair dataset work
- Challenges exist at multiple levels: individual practitioners, organizational structures, regulatory frameworks, and broader socio-political contexts

## Why This Works (Mechanism)
The taxonomy framework works by systematically mapping challenges across both the dataset development lifecycle and the broader socio-technical ecosystem. This dual-axis approach reveals how technical obstacles (like data availability) intersect with organizational and regulatory barriers, providing a holistic view of what impedes fair dataset curation. The mechanism reveals that challenges are not isolated technical problems but emerge from complex interactions between technical requirements, organizational priorities, and systemic inequities in the ML field.

## Foundational Learning
- Dataset lifecycle phases (requirements, design, implementation, evaluation, maintenance) - why needed: Understanding where challenges emerge in the development process; quick check: Can identify which phase-specific challenges affect current projects
- Fairness landscape levels (individual, discipline, organization, regulatory, socio-political) - why needed: Recognizing that fairness challenges extend beyond technical considerations; quick check: Can map challenges to appropriate intervention levels
- Taxonomy development methodology - why needed: Understanding how to systematically categorize and analyze complex challenges; quick check: Can apply similar coding approaches to other ML challenges

## Architecture Onboarding

**Component Map**
Individual practitioners -> Organizational structures -> Regulatory frameworks -> Broader socio-political context

**Critical Path**
Dataset requirements definition -> Data collection and labeling -> Model training and evaluation -> Deployment and maintenance

**Design Tradeoffs**
Technical completeness vs. fairness goals, Data diversity vs. collection feasibility, Standardization vs. contextual adaptation

**Failure Signatures**
Incomplete challenge identification, Oversimplification of complex interactions, Focus on technical solutions without systemic change

**First Experiments**
1. Apply taxonomy to map challenges in a current dataset curation project
2. Conduct stakeholder analysis to identify which landscape levels most affect your work
3. Design intervention strategy targeting one specific challenge across multiple lifecycle phases

## Open Questions the Paper Calls Out
None

## Limitations
- Sample of 30 practitioners may not capture full diversity of experiences across domains and regions
- Taxonomy structure may oversimplify complex interdependencies between challenges
- Study focuses primarily on technical and organizational challenges, with less attention to individual-level factors

## Confidence

**High confidence in:**
- Validity of specific practitioner-reported challenges within their domains

**Medium confidence in:**
- Completeness of taxonomy structure across all five phases and levels
- Generalizability of findings beyond studied practitioner group

## Next Checks

1. Conduct follow-up surveys with interviewed practitioners to validate taxonomy completeness and accuracy, particularly regarding challenges at intersections of different phases and levels

2. Perform cross-domain case studies to test whether identified challenges manifest similarly in different ML application areas (healthcare, finance, autonomous systems)

3. Implement a subset of recommended systemic changes in partner organizations and measure impact on fair dataset curation practices over time