---
ver: rpa2
title: 'CantonMT: Cantonese to English NMT Platform with Fine-Tuned Models Using Synthetic
  Back-Translation Data'
arxiv_id: '2403.11346'
source_url: https://arxiv.org/abs/2403.11346
tags:
- data
- synthetic
- translation
- machine
- mbart
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work explores synthetic data augmentation via back-translation
  for Cantonese-to-English neural machine translation, a low-resource language pair.
  Three models (OpusMT, NLLB, mBART) were fine-tuned using limited real bilingual
  data and synthetic data generated by translating monolingual Cantonese sentences.
---

# CantonMT: Cantonese to English NMT Platform with Fine-Tuned Models Using Synthetic Back-Translation Data

## Quick Facts
- arXiv ID: 2403.11346
- Source URL: https://arxiv.org/abs/2403.11346
- Authors: Kung Yin Hong; Lifeng Han; Riza Batista-Navarro; Goran Nenadic
- Reference count: 5
- Key outcome: Fine-tuned NMT models with synthetic back-translation data outperform baseline models and commercial translators for Cantonese-English translation

## Executive Summary
This work addresses the challenge of Cantonese-to-English neural machine translation by leveraging synthetic data augmentation through back-translation. Using limited real bilingual data (9,100 sentence pairs) and generating synthetic parallel data from monolingual Cantonese sources, the researchers fine-tuned three pre-trained models (OpusMT, NLLB, mBART). The fine-tuned models demonstrated substantial improvements over baseline deployments, achieving 50% score increases in automatic evaluations. The best system, NLLB fine-tuned with mBART-generated synthetic data, performed comparably or better than commercial translation services like Baidu and Bing. The study also developed the CantonMT platform to facilitate further research in this low-resource language pair.

## Method Summary
The researchers employed a back-translation approach to augment limited Cantonese-English bilingual data. They first translated monolingual Cantonese sentences into English using pre-trained models, creating synthetic parallel data. Three pre-trained models (OpusMT, NLLB, mBART) were then fine-tuned using both the real bilingual data and synthetic data. The synthetic data generation involved translating monolingual Cantonese sentences (from sources like Cantonese subset of UN Parallel Corpus and Global Voices) into English. Model fine-tuning was performed for 30 epochs with a learning rate of 5e-5 and batch size of 16. The CantonMT platform was developed to allow users to switch between different translation models and compare outputs.

## Key Results
- Fine-tuned models achieved 50% score increases over baseline deployments across automatic evaluation metrics
- NLLB model fine-tuned with mBART-generated synthetic data performed best, matching or exceeding commercial translators (Baidu, Bing)
- Model switching and adding more real bilingual data further improved translation quality
- Synthetic back-translation effectively augmented limited real bilingual training data

## Why This Works (Mechanism)
The approach works by leveraging the abundance of monolingual Cantonese text to create synthetic parallel data, addressing the fundamental challenge of limited bilingual resources for this language pair. By fine-tuning pre-trained models on this augmented dataset, the system learns to handle Cantonese-specific linguistic features while maintaining English translation quality. The back-translation process creates additional training examples that capture patterns in the target language, effectively bridging the resource gap between low-resource and high-resource language pairs.

## Foundational Learning

**Neural Machine Translation (NMT)**
- *Why needed:* Core technology for automated translation between languages
- *Quick check:* Verify understanding of encoder-decoder architecture and attention mechanisms

**Back-Translation**
- *Why needed:* Synthetic data generation technique for low-resource language pairs
- *Quick check:* Confirm understanding of forward/backward translation cycles and data filtering

**Pre-trained Models**
- *Why needed:* Foundation for fine-tuning with limited resources
- *Quick check:* Verify knowledge of transfer learning and model adaptation

**Automatic Evaluation Metrics**
- *Why needed:* Quantitative assessment of translation quality
- *Quick check:* Confirm understanding of BLEU, BERTScore, COMET, and hLEPOR metrics

**Low-Resource Language Pairs**
- *Why needed:* Contextualizes the challenge and solution approach
- *Quick check:* Verify understanding of data scarcity and its impact on NMT performance

## Architecture Onboarding

**Component Map**
Monolingual Cantonese Data -> Back-translation Model -> Synthetic Parallel Data -> Fine-tuning Pipeline -> CantonMT Platform

**Critical Path**
Monolingual Cantonese sentences → Back-translation (Cantonese→English) → Synthetic parallel corpus creation → Fine-tuning of pre-trained models → Deployment in CantonMT platform

**Design Tradeoffs**
- Synthetic vs. real data quality: Tradeoff between quantity and accuracy
- Model selection: Balance between model size, training efficiency, and performance
- Evaluation approach: Automatic metrics vs. human evaluation limitations

**Failure Signatures**
- Synthetic data introducing translation errors that propagate to fine-tuned models
- Overfitting to synthetic data characteristics
- Performance degradation on domain-specific or colloquial Cantonese

**First 3 Experiments**
1. Generate synthetic data using different back-translation models and compare fine-tuning outcomes
2. Vary the ratio of real to synthetic data during fine-tuning to find optimal balance
3. Test model performance on out-of-domain Cantonese test sets to assess generalization

## Open Questions the Paper Calls Out
None

## Limitations
- Small real bilingual training data (9,100 sentence pairs) constrains potential performance
- Synthetic data quality depends on initial translation model, introducing potential error propagation
- Limited to Cantonese-English pair, limiting generalizability to other low-resource languages
- Lack of human evaluation means automatic metrics may not fully capture translation quality

## Confidence

**High confidence:** Experimental methodology is clearly described and follows established NMT practices; performance improvements are statistically significant and consistent across metrics.

**Medium confidence:** Claims about matching commercial translators are supported by automatic metrics but require human validation; model-switching contribution needs more systematic study.

**Low confidence:** Long-term generalization and robustness to real-world scenarios remain unknown due to limited testing conditions.

## Next Checks
1. Conduct human evaluation studies comparing fine-tuned models against baseline models and commercial translators, focusing on adequacy, fluency, and Cantonese-specific features.

2. Perform domain adaptation experiments using out-of-domain test sets to assess model robustness and identify performance degradation patterns across different text sources.

3. Implement systematic ablation studies to quantify individual contributions of back-translation data quality, model architecture choice, and fine-tuning duration to performance improvements.