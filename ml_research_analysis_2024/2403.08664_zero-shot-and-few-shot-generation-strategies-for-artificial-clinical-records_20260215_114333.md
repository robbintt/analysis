---
ver: rpa2
title: Zero-shot and Few-shot Generation Strategies for Artificial Clinical Records
arxiv_id: '2403.08664'
source_url: https://arxiv.org/abs/2403.08664
tags:
- prompt
- data
- clinical
- records
- few-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates zero-shot and few-shot prompting for generating
  synthetic electronic health records (EHRs) to address privacy concerns in clinical
  research. The authors propose a chain-of-thought prompting strategy for the Llama
  2 model to generate History of Present Illness narratives from Chief Complaint inputs.
---

# Zero-shot and Few-shot Generation Strategies for Artificial Clinical Records

## Quick Facts
- arXiv ID: 2403.08664
- Source URL: https://arxiv.org/abs/2403.08664
- Authors: Erlend Frayling; Jake Lever; Graham McDonald
- Reference count: 35
- One-line primary result: Zero-shot CoT prompting with Llama 2 achieves ROUGE-1 scores of 0.236, comparable to fine-tuned GPT-2 models at 0.23

## Executive Summary
This paper investigates zero-shot and few-shot prompting strategies for generating synthetic electronic health records (EHRs) to address privacy concerns in clinical research. The authors propose a chain-of-thought prompting strategy for the Llama 2 model to generate History of Present Illness (HPI) narratives from Chief Complaint (CC) inputs. They evaluate their approach using ROUGE metrics on MIMIC-IV data, finding that zero-shot CoT prompting achieves performance comparable to fine-tuned GPT-2 models while avoiding the need for sensitive patient data in fine-tuning.

## Method Summary
The authors use MIMIC-IV dataset containing 7000 discharge summaries with CC and HPI pairs (6000 training, 1000 test samples). They implement two prompting strategies for Llama 2: direct prompting and chain-of-thought (CoT) prompting that first generates gender and ethnicity before the HPI. Few-shot learning is explored using both random examples and ColBERT-PRF retrieved similar examples. The approach is compared against fine-tuned baseline models including GPT-2, BioGPT, and Llama 2. ROUGE-1, ROUGE-2, ROUGE-L, and ROUGE-L-Sum scores are used to evaluate generated HPIs against ground truth.

## Key Results
- Zero-shot CoT prompting with Llama 2 achieves ROUGE-1 score of 0.236, comparable to fine-tuned GPT-2 at 0.23
- Few-shot learning with random examples improved direct prompt performance but reduced CoT effectiveness
- The approach demonstrates that carefully designed prompting can enable effective synthetic EHR generation without requiring access to sensitive patient data for fine-tuning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Chain-of-thought prompting improves zero-shot HPI generation by explicitly guiding the model through EHR structure
- Mechanism: The CoT prompt first asks the model to generate gender and ethnicity before generating the HPI. This sequential reasoning step forces the model to consider patient context, which improves the relevance and coherence of the generated HPI narrative
- Core assumption: The model's parametric knowledge includes understanding of EHR structure and that generating auxiliary patient attributes helps contextualize the HPI
- Evidence anchors:
  - [abstract] "In this work introduce a novel prompting technique that leverages a chain-of-thought approach, enhancing the model's ability to generate more accurate and contextually relevant medical narratives without prior fine-tuning."
  - [section] "We propose to instruct the model to generate other parts of the EHR records, for a given CC, before instructing the model to generate the HPI."
  - [corpus] Weak evidence - no direct comparison of CoT vs non-CoT approaches in the corpus neighbors
- Break condition: If the model lacks sufficient knowledge about EHR structure or if the auxiliary attributes (gender/ethnicity) are not meaningfully connected to the HPI content

### Mechanism 2
- Claim: Few-shot learning with similar examples improves direct prompt performance by providing relevant context
- Mechanism: By retrieving and including similar CC-HPI pairs from the training set, the model receives in-context examples that demonstrate the expected output format and style for similar medical complaints
- Core assumption: The model can effectively use retrieved examples to adapt its generation to match the style and content of similar cases
- Evidence anchors:
  - [abstract] "Few-shot learning with random examples improved the baseline direct prompt but reduced CoT performance."
  - [section] "we use the ColBERT-PRF retriever to find similar examples [29]. We create a dense index of the CCs in the training dataset, and for each CC in the test dataset we retrieve the top two most relevant training dataset CCs with their associated HPIs to use as the similar examples."
  - [corpus] No direct evidence in corpus neighbors about retrieval-based few-shot learning
- Break condition: If the retrieved examples are not sufficiently similar or if the model cannot effectively integrate the examples into its generation process

### Mechanism 3
- Claim: Zero-shot CoT performance matches fine-tuned GPT-2 by leveraging Llama 2's strong pre-training on diverse text
- Mechanism: Llama 2's extensive pre-training on web-scale data provides it with broad medical and general knowledge, allowing it to generate reasonable HPIs without fine-tuning when guided by effective prompting
- Core assumption: The pre-training data includes sufficient medical domain knowledge and that prompting can effectively activate this knowledge
- Evidence anchors:
  - [abstract] "Our findings suggest that this chain-of-thought prompted approach allows the zero-shot model to achieve results on par with those of fine-tuned models, based on Rouge metrics evaluation."
  - [section] "we focus on developing prompting strategies to use LLMs without fine-tuning in a zero-shot and few-shot setting, to remove the need to access sensitive patient data for fine-tuning, relying instead on the parametric knowledge of the pre-trained model to generate synthetic HPIs."
  - [corpus] No direct evidence in corpus neighbors about zero-shot performance comparison with fine-tuned models
- Break condition: If the pre-training data lacks sufficient medical domain coverage or if the prompting strategy fails to activate relevant knowledge

## Foundational Learning

- Concept: Chain-of-thought reasoning
  - Why needed here: Enables complex medical narrative generation by breaking down the task into structured steps (gender → ethnicity → HPI)
  - Quick check question: Why might generating gender and ethnicity before the HPI improve the quality of the generated narrative?

- Concept: In-context learning
  - Why needed here: Few-shot learning strategies rely on the model learning from examples provided in the prompt
  - Quick check question: What is the difference between few-shot learning with random examples versus similar examples?

- Concept: Zero-shot learning
  - Why needed here: The core contribution is demonstrating effective zero-shot performance without requiring sensitive patient data for fine-tuning
  - Quick check question: What makes zero-shot learning particularly valuable for clinical applications?

## Architecture Onboarding

- Component map: Llama 2 13B model (4-bit quantized) → System Prompt (EHR structure instructions) → Input Prompt (specific CC) → Generated HPI
- Critical path: CC input → System prompt processing → Chain-of-thought reasoning → HPI generation → ROUGE evaluation
- Design tradeoffs: Zero-shot vs few-shot (data efficiency vs performance), CoT vs direct prompting (complexity vs effectiveness), quantization (memory vs speed)
- Failure signatures: Poor ROUGE scores, incoherent narratives, failure to follow EHR structure, over-reliance on random examples
- First 3 experiments:
  1. Test zero-shot CoT prompting with simple CC inputs to verify basic functionality
  2. Compare zero-shot vs few-shot performance on a small validation set
  3. Test different ordering of CoT steps (ethnicity before gender vs gender before ethnicity)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the CoT prompting strategy improve performance on other EHR generation tasks beyond HPI generation?
- Basis in paper: [explicit] The authors suggest their CoT approach "enhances the model's ability to generate more accurate and contextually relevant medical narratives" and show improved zero-shot performance, but only test on HPI generation specifically
- Why unresolved: The paper only evaluates the CoT method on one specific task (HPI generation from CC inputs). The effectiveness for other EHR sections or different clinical text generation tasks remains untested
- What evidence would resolve it: Empirical results comparing CoT performance to baseline methods on generating other EHR sections (e.g., discharge summaries, lab reports) or different clinical text tasks

### Open Question 2
- Question: How does the CoT prompting approach scale with model size beyond the 13B Llama 2 model tested?
- Basis in paper: [explicit] The authors note their Llama 2 13B model "loaded with 4-bit quantization" and show it achieves competitive performance with fine-tuned GPT-2, but don't explore larger or smaller model sizes
- Why unresolved: The paper only tests one model size. The relative benefits of CoT prompting versus model scale remain unknown
- What evidence would resolve it: Comparative results showing performance curves for different model sizes (e.g., 7B, 34B, 70B) with and without CoT prompting

### Open Question 3
- Question: Can the few-shot learning performance be improved by optimizing the number, selection strategy, or ordering of examples?
- Basis in paper: [inferred] The paper notes that few-shot learning with random examples improved the direct prompt but reduced CoT performance, suggesting the current approach may not be optimal
- Why unresolved: The authors only test two simple few-shot strategies (random and similar examples) without exploring parameter tuning for these methods
- What evidence would resolve it: Systematic ablation studies varying the number of examples, selection algorithms, and example ordering to identify optimal few-shot configurations

### Open Question 4
- Question: How does the synthetic EHR data quality compare to real data when evaluated on downstream clinical NLP tasks?
- Basis in paper: [explicit] The authors mention that previous work has used synthetic clinical text for downstream tasks but focus their evaluation on ROUGE metrics against real EHRs rather than task performance
- Why unresolved: The paper evaluates generation quality through ROUGE scores but doesn't test whether the synthetic data actually improves downstream task performance
- What evidence would resolve it: Results from fine-tuning NLP models on synthetic versus real EHR data and comparing their performance on clinical entity recognition, relation extraction, or other downstream tasks

## Limitations

- The evaluation relies entirely on ROUGE metrics, which measure n-gram overlap rather than clinical accuracy or coherence of generated narratives
- The few-shot learning results show that random examples improved direct prompting but harmed CoT performance, suggesting potential interference between the chain-of-thought reasoning and example-based adaptation
- The clinical validity and safety of generated synthetic records is completely unknown from the current evaluation framework

## Confidence

**High Confidence**: The zero-shot CoT prompting strategy achieves comparable ROUGE-1 performance to fine-tuned models on MIMIC-IV data. The methodology for prompt engineering and evaluation is clearly described and reproducible.

**Medium Confidence**: The claim that zero-shot CoT performance matches fine-tuned models is supported by ROUGE-1 scores but lacks complete baseline comparisons across all ROUGE metrics. The mechanism by which CoT prompting improves generation quality is plausible but not empirically validated.

**Low Confidence**: The effectiveness of few-shot learning strategies is questionable given the contradictory results between random and similar examples, and the negative impact on CoT performance. The clinical validity and safety of generated synthetic records is completely unknown from the current evaluation framework.

## Next Checks

1. **Clinical Expert Review**: Have medical professionals evaluate a sample of generated HPIs for clinical coherence, relevance, and safety, rather than relying solely on ROUGE metrics. This would validate whether statistical similarity translates to clinical utility.

2. **Comprehensive Baseline Comparison**: Obtain and report ROUGE scores for all baseline models (GPT-2, BioGPT, Llama 2 fine-tuned) across all three ROUGE metrics to verify the claim that zero-shot CoT performance is truly comparable to fine-tuned approaches.

3. **Cross-Dataset Validation**: Test the zero-shot CoT approach on a different clinical dataset (such as MIMIC-III or a different hospital system) to assess whether the prompting strategy generalizes beyond the specific characteristics of MIMIC-IV, and evaluate whether performance degrades when the model encounters different writing styles or clinical terminology patterns.