---
ver: rpa2
title: 'COLUMBUS: Evaluating COgnitive Lateral Understanding through Multiple-choice
  reBUSes'
arxiv_id: '2409.04053'
source_url: https://arxiv.org/abs/2409.04053
tags:
- puzzle
- puzzles
- rebus
- rules
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces COLUMBUS, a synthetic benchmark for evaluating
  visual lateral thinking in vision-language models (VLMs). The authors define visual
  lateral thinking as a multiple-choice question-answering task using rebus puzzles
  and propose a three-step taxonomy-driven methodology for generating such puzzles.
---

# COLUMBUS: Evaluating COgnitive Lateral Understanding through Multiple-choice reBUSes

## Quick Facts
- **arXiv ID**: 2409.04053
- **Source URL**: https://arxiv.org/abs/2409.04053
- **Reference count**: 40
- **Primary result**: VLMs show significant performance gaps compared to humans on visual lateral thinking tasks

## Executive Summary
This paper introduces COLUMBUS, a synthetic benchmark designed to evaluate visual lateral thinking capabilities in vision-language models (VLMs) using rebus puzzles. The benchmark employs a taxonomy-driven methodology to generate over 1,000 puzzles based on compounds and common phrases, creating a multiple-choice question-answering task. The authors demonstrate that while state-of-the-art VLMs achieve decent accuracy, they lag substantially behind human performance, suggesting current models struggle with the creative and out-of-the-box thinking required for visual lateral reasoning.

## Method Summary
The COLUMBUS benchmark generates visual lateral thinking puzzles through a three-step taxonomy-driven methodology. The process begins with curated collections of compounds and common phrases, which are then transformed into rebus puzzles following specific generation rules. Each puzzle presents a visual representation that requires creative interpretation to arrive at the correct answer among four candidates. The methodology aims to capture the essence of visual lateral thinking by requiring models to make unconventional associations between visual elements and linguistic concepts, testing their ability to think beyond literal interpretations.

## Key Results
- VLMs achieve significantly lower accuracy than humans on COLUMBUS benchmark puzzles
- Human-curated descriptions improve VLM performance but don't close the performance gap
- VLMs struggle with abstraction and self-generating appropriate representations for lateral thinking tasks

## Why This Works (Mechanism)
COLUMBUS works by testing VLMs' ability to perform visual lateral thinking through rebus puzzles that require creative interpretation of visual elements. The benchmark's effectiveness stems from its focus on tasks that demand unconventional associations and out-of-the-box thinking, which are areas where current VLMs show limitations. The methodology captures the gap between literal visual understanding and creative reasoning by requiring models to bridge visual representations with abstract linguistic concepts.

## Foundational Learning
- **Visual Lateral Thinking**: The ability to solve problems through creative, indirect approaches using visual information; needed to understand what COLUMBUS actually tests; quick check: can the model solve a rebus puzzle that requires thinking beyond literal interpretation
- **Rebus Puzzles**: Visual word puzzles that use pictures to represent words or parts of words; fundamental to the benchmark's design; quick check: can you decode a simple rebus puzzle like "man" over "board" = "man overboard"
- **Taxonomy-driven Generation**: A systematic approach to creating puzzles using predefined categories and rules; needed to understand the methodology; quick check: does the generation process follow a clear hierarchical structure

## Architecture Onboarding

**Component Map**: VLM -> Visual Encoder -> Language Model -> Answer Selector

**Critical Path**: Visual input → Feature extraction → Abstraction layer → Reasoning component → Multiple-choice selection

**Design Tradeoffs**: The benchmark prioritizes task specificity over generalizability, focusing on visual lateral thinking rather than broader VLM capabilities. This creates a targeted evaluation but may limit applicability to other reasoning tasks.

**Failure Signatures**: VLMs struggle with puzzles requiring novel associations, show performance improvements with human-provided context, and fail to self-generate appropriate abstraction levels for puzzle interpretation.

**First Experiments**:
1. Test VLM performance on COLUMBUS with varying levels of visual complexity
2. Evaluate the impact of pre-training data on lateral thinking performance
3. Compare COLUMBUS results across VLMs with different architectural approaches

## Open Questions the Paper Calls Out
None

## Limitations
- Synthetic benchmark may not fully capture the complexity of real-world lateral thinking
- Reliance on pre-existing compound collections constrains puzzle diversity
- Human-curated descriptions may provide unfair cognitive scaffolding

## Confidence

**High Confidence**: VLMs show performance gaps compared to humans on visual lateral thinking tasks

**Medium Confidence**: The gap reflects challenges in abstraction and representation generation rather than fundamental lateral thinking capacity

**Medium Confidence**: Taxonomy-driven methodology captures essential aspects of visual lateral thinking but may be overly restrictive

## Next Checks
1. Test COLUMBUS benchmark performance across a broader range of VLMs, including both pure vision-language models and those fine-tuned specifically on creative/visual reasoning tasks

2. Conduct ablation studies removing human-curated descriptions to establish baseline performance and determine whether improvements are primarily due to better representation generation

3. Evaluate human performance on COLUMBUS puzzles with and without time constraints and reference materials to establish more realistic human baselines