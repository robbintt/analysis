---
ver: rpa2
title: How Good are LLMs at Relation Extraction under Low-Resource Scenario? Comprehensive
  Evaluation
arxiv_id: '2406.11162'
source_url: https://arxiv.org/abs/2406.11162
tags:
- language
- datasets
- dataset
- relation
- extraction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work constructs low-resource relation extraction datasets
  in 10 low-resource languages (LRLs) from Central Asia, Southeast Asia, and the Middle
  East by translating English RE datasets (NYT10, FewRel, CrossRE) using multilingual
  machine translation and filtering low-quality data via language perplexity. It evaluates
  several open-source LLMs (LLaMA, Falcon, BLOOMZ, Qwen, OLMo) on these datasets,
  finding that LLaMA and Falcon achieve the highest F1 scores (up to 78.6).
---

# How Good are LLMs at Relation Extraction under Low-Resource Scenario? Comprehensive Evaluation

## Quick Facts
- arXiv ID: 2406.11162
- Source URL: https://arxiv.org/abs/2406.11162
- Reference count: 16
- LLMs achieve up to 78.6 F1 score on low-resource relation extraction tasks

## Executive Summary
This work constructs low-resource relation extraction datasets in 10 low-resource languages (LRLs) from Central Asia, Southeast Asia, and the Middle East by translating English RE datasets (NYT10, FewRel, CrossRE) using multilingual machine translation and filtering low-quality data via language perplexity. It evaluates several open-source LLMs (LLaMA, Falcon, BLOOMZ, Qwen, OLMo) on these datasets, finding that LLaMA and Falcon achieve the highest F1 scores (up to 78.6). The study demonstrates that including an intermediate Chinese translation (Path2) yields higher quality data than direct translation (Path1), and filtering reduces perplexity by up to 19.64 points. Overall, LLMs show promising performance on LRL relation extraction when aided by quality dataset construction and filtering.

## Method Summary
The authors construct low-resource RE datasets by translating English RE datasets (NYT10, FewRel, CrossRE) into 10 low-resource languages using NLLB multilingual translation model. They employ two translation pathways: Path1 (direct translation) and Path2 (via Chinese intermediary). Language perplexity filtering removes low-quality samples using a threshold of 20. Five open-source LLMs (LLaMA, Falcon, BLOOMZ, Qwen, OLMo) are fine-tuned on the filtered datasets using a negative log-likelihood loss function. The models are evaluated using F1 score on test sets for each language and model combination.

## Key Results
- LLaMA and Falcon achieve the highest F1 scores (up to 78.6) among evaluated LLMs
- Path2 (via Chinese intermediary) yields lower perplexity values than Path1, indicating higher translation quality
- Perplexity filtering reduces perplexity by up to 19.64 points, improving dataset quality
- Direct translation quality varies significantly across language families, with Turkic languages showing particular challenges

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Translating English RE datasets to low-resource languages using multilingual MT improves RE performance in low-resource settings
- Mechanism: Leverages existing high-quality English RE datasets by translating them into target languages, creating labeled data where none previously existed
- Core assumption: Machine translation preserves entity relations and context well enough for RE tasks
- Evidence anchors:
  - [abstract] "This work constructs low-resource relation extraction datasets in 10 low-resource languages (LRLs) from Central Asia, Southeast Asia, and the Middle East by translating English RE datasets"
  - [section] "We first employ a machine translation model to translate the original English RE dataset... into low-resource language (LRLs)"
  - [corpus] Weak - only 8 corpus neighbors found, average FMR=0.526 suggests moderate relatedness
- Break condition: Translation quality degrades significantly, losing relation context or misaligning entities

### Mechanism 2
- Claim: Filtering translated data using language perplexity removes low-quality samples and improves dataset quality
- Mechanism: Calculates perplexity scores for translated text and removes samples exceeding a threshold, reducing noise in the dataset
- Core assumption: Perplexity is a reliable indicator of translation quality for RE purposes
- Evidence anchors:
  - [abstract] "Then, we use the language perplexity (PPL) to filter out the low-quality data from the translated datasets"
  - [section] "If the perplexity PPL(T (n) LRL) is higher than a threshold τ, we remove the sample from the dataset"
  - [corpus] Weak - corpus doesn't directly support this mechanism
- Break condition: Perplexity threshold is set too high (keeps bad data) or too low (removes good data)

### Mechanism 3
- Claim: Including an intermediate Chinese translation (Path2) yields higher quality data than direct translation (Path1)
- Mechanism: Chain translation through an intermediate language to improve translation quality for some language pairs
- Core assumption: Translating through Chinese improves quality for certain target languages
- Evidence anchors:
  - [section] "Path2 incorporated an additional step of translating into an intermediary language (Chinese) before translating into LRLs"
  - [section] "Experimental results show that the dataset constructed using Path2 exhibits a lower PPL value than that of Path1"
  - [corpus] Weak - no corpus evidence for this specific claim
- Break condition: Intermediate language adds noise rather than improving quality

## Foundational Learning

- Concept: Relation Extraction as a specialized instance of Information Extraction
  - Why needed here: Understanding RE's role in transforming unstructured text to structured information helps contextualize the research
  - Quick check question: What is the primary focus of relation extraction compared to general information extraction?

- Concept: Low-resource language challenges in NLP
  - Why needed here: Explains why conventional methods and LLMs perform poorly on LRLs
  - Quick check question: Why do both conventional RE methods and LLM-based methods perform poorly on low-resource languages?

- Concept: Perplexity as a quality metric for language data
  - Why needed here: Critical for understanding the filtering mechanism used to improve dataset quality
  - Quick check question: How does language perplexity help identify low-quality translated samples?

## Architecture Onboarding

- Component map: English RE datasets (NYT10, FewRel, CrossRE) -> NLLB multilingual translation -> Perplexity filtering (multilingual BERT) -> LLM fine-tuning (LLaMA, Falcon, BLOOMZ, Qwen, OLMo) -> F1 score evaluation

- Critical path: English dataset → MT translation → Perplexity filtering → LLM training → F1 score evaluation

- Design tradeoffs:
  - Translation quality vs. computational cost
  - Filtering threshold vs. dataset size
  - Direct vs. chained translation paths
  - Model parameter count vs. performance

- Failure signatures:
  - High perplexity values indicate poor translation quality
  - Low F1 scores suggest entity misalignment or relation loss during translation
  - Dataset size reduction after filtering indicates quality issues

- First 3 experiments:
  1. Test translation quality by comparing entity alignment rates between English and LRL versions
  2. Vary perplexity threshold to find optimal balance between dataset size and quality
  3. Compare F1 scores between Path1 and Path2 translations for languages where both are available

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of LLMs on LRL RE tasks compare when using different filtering thresholds for language perplexity?
- Basis in paper: [explicit] The paper discusses using a threshold of 20 for filtering low-quality data based on language perplexity.
- Why unresolved: The paper does not explore how varying the threshold might impact the quality and quantity of the filtered dataset, or the subsequent performance of LLMs on RE tasks.
- What evidence would resolve it: Conducting experiments with different perplexity thresholds and analyzing the resulting dataset quality and LLM performance would provide insights into the optimal filtering strategy.

### Open Question 2
- Question: What are the long-term implications of using machine translation for constructing LRL RE datasets in terms of data bias and representation?
- Basis in paper: [inferred] The paper relies on machine translation to create datasets for LRLs, which may introduce biases or inaccuracies.
- Why unresolved: The paper does not address potential biases introduced during the translation process or how these might affect the representation of LRLs in the datasets.
- What evidence would resolve it: A comprehensive analysis of the translated datasets for biases and inaccuracies, along with an assessment of their impact on LLM training and performance, would clarify these implications.

### Open Question 3
- Question: How does the inclusion of an intermediate translation step (Path2) affect the semantic integrity of the extracted relations compared to direct translation (Path1)?
- Basis in paper: [explicit] The paper introduces Path2, which involves an additional translation step through Chinese before translating to LRLs, and compares it with direct translation (Path1).
- Why unresolved: While the paper notes that Path2 results in lower perplexity, it does not thoroughly investigate whether this leads to better preservation of semantic relationships in the extracted data.
- What evidence would resolve it: A detailed comparison of the semantic accuracy and consistency of relations extracted using Path1 versus Path2 would provide insights into the effectiveness of the intermediate translation step.

## Limitations
- Translation quality through multilingual MT remains a critical bottleneck, with no direct evaluation of entity alignment preservation
- Perplexity threshold of 20 appears somewhat arbitrary with limited justification for the specific value
- Evaluation focuses on a narrow set of 10 languages from specific geographic regions, limiting generalizability

## Confidence
**High Confidence**: The finding that perplexity filtering improves dataset quality (up to 19.64 points reduction) is well-supported by the methodology and results. The relative performance ranking of LLMs (LLaMA and Falcon outperforming others) is also robust given the consistent F1 score patterns across languages.

**Medium Confidence**: The claim that Path2 (via Chinese intermediary) consistently yields higher quality data than Path1 is supported by perplexity metrics but may vary by language family and translation direction. The overall F1 scores (up to 78.6) are impressive but should be interpreted cautiously given the synthetic nature of the test data.

**Low Confidence**: The assumption that perplexity is a reliable proxy for translation quality specific to RE tasks lacks strong validation. The scalability of this approach to languages with significantly different scripts or linguistic structures from the tested set remains unproven.

## Next Checks
1. Conduct human evaluation of translated entity alignments to verify that relation extraction labels remain accurate after translation, particularly for languages with non-Latin scripts.

2. Test alternative perplexity thresholds and compare against downstream F1 scores to establish optimal filtering parameters for different language families.

3. Evaluate the approach on languages from different linguistic families (e.g., African or South Asian languages) to assess generalizability beyond the current Central Asian, Southeast Asian, and Middle Eastern focus.