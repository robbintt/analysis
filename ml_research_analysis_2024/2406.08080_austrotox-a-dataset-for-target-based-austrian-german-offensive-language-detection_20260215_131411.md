---
ver: rpa2
title: 'AustroTox: A Dataset for Target-Based Austrian German Offensive Language Detection'
arxiv_id: '2406.08080'
source_url: https://arxiv.org/abs/2406.08080
tags: []
core_contribution: This paper introduces AustroTox, a dataset for target-based Austrian
  German offensive language detection, addressing the lack of such resources in languages
  other than English. The dataset comprises 4,562 user comments annotated for binary
  offensiveness classification and token-level spans identifying vulgarities and targets
  of offensive statements.
---

# AustroTox: A Dataset for Target-Based Austrian German Offensive Language Detection

## Quick Facts
- **arXiv ID:** 2406.08080
- **Source URL:** https://arxiv.org/abs/2406.08080
- **Reference count:** 40
- **Primary result:** Introduces AustroTox dataset for Austrian German offensive language detection with 4,562 annotated comments

## Executive Summary
This paper presents AustroTox, a novel dataset for target-based offensive language detection in Austrian German, addressing the scarcity of such resources for non-English languages. The dataset contains 4,562 user comments annotated for binary offensiveness classification and token-level spans identifying vulgarities and targets. The authors evaluate both fine-tuned language models and large language models (LLMs) across zero- and few-shot learning scenarios. Results demonstrate that fine-tuned models excel at detecting vulgar dialect while LLMs show superior performance in general offensiveness detection, highlighting the complementary strengths of different approaches.

## Method Summary
The AustroTox dataset was constructed through manual annotation of 4,562 Austrian German user comments collected from social media platforms. Annotators were trained to identify offensive content and mark specific tokens representing vulgar language and targets of offensive statements. The dataset supports both binary classification tasks and token-level span identification. For evaluation, the authors fine-tuned several transformer-based language models including German-specific variants, and tested zero-shot and few-shot capabilities of large language models on the same task. Performance metrics included precision, recall, and F1-score for both classification and span detection tasks.

## Key Results
- Fine-tuned models outperform LLMs in detecting vulgar dialect expressions
- Large language models demonstrate superior performance in general offensiveness detection
- The dataset enables both binary classification and token-level span annotation tasks
- Performance varies significantly between zero-shot and few-shot learning scenarios

## Why This Works (Mechanism)
The dataset's effectiveness stems from its focus on Austrian German dialect-specific vulgarities and cultural context that general offensive language datasets miss. Fine-tuned models benefit from domain-specific training on the dialect's linguistic patterns, while LLMs leverage broader world knowledge for contextual offensiveness detection. The token-level span annotations provide granular information about offensive elements that enables more sophisticated model training and evaluation.

## Foundational Learning
- **Dialect-specific language modeling:** Why needed: Austrian German contains unique vulgar expressions and linguistic patterns. Quick check: Compare model performance on Austrian vs standard German offensive language.
- **Token-level span annotation:** Why needed: Identifying specific offensive tokens improves model precision. Quick check: Evaluate annotation consistency across multiple annotators.
- **Zero-shot vs few-shot learning:** Why needed: Different approaches suit different resource availability scenarios. Quick check: Measure performance degradation as shot count decreases.
- **Target identification:** Why needed: Understanding who is targeted by offensive language is crucial for content moderation. Quick check: Test model ability to distinguish between self-directed and other-directed offense.

## Architecture Onboarding
**Component Map:** Data Collection -> Annotation -> Model Training -> Evaluation
**Critical Path:** Annotated data → Model fine-tuning → Performance evaluation → Comparison with LLMs
**Design Tradeoffs:** Fine-tuned models offer better dialect detection but require more training data, while LLMs provide better generalization but may miss dialect-specific nuances
**Failure Signatures:** Models may confuse dialect-specific expressions with general vulgarity, or miss culturally-specific offensive contexts
**First 3 Experiments:**
1. Evaluate inter-annotator agreement on token-level span annotations
2. Test model performance on a held-out test set from different time periods
3. Compare Austrian German model performance against standard German baselines

## Open Questions the Paper Calls Out
None

## Limitations
- Manual annotation process may contain inter-annotator variability not extensively documented
- Dataset may have regional bias based on the specific social media sources used
- Limited evaluation of model performance across different Austrian German dialects and sociolects

## Confidence
- **High confidence:** Binary offensiveness classification performance, differential performance between fine-tuned models and LLMs
- **Medium confidence:** Token-level span annotation reliability, generalization across different Austrian German dialects

## Next Checks
1. Conduct inter-annotator agreement analysis to quantify reliability of token-level span annotations
2. Perform cross-validation with a holdout test set not used during any fine-tuning or few-shot learning
3. Test dataset robustness by evaluating model performance across different Austrian German dialects and sociolects not well-represented in the original 4,562 comments