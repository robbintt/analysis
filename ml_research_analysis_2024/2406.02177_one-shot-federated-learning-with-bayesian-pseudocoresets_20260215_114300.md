---
ver: rpa2
title: One-Shot Federated Learning with Bayesian Pseudocoresets
arxiv_id: '2406.02177'
source_url: https://arxiv.org/abs/2406.02177
tags:
- learning
- bayesian
- client
- federated
- communication
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the communication bottleneck in federated
  learning (FL) by introducing a one-shot Bayesian approach using Bayesian pseudocoresets
  (BPCs) in function space. The key insight is that function-space representation
  avoids the mode collapse issue that plagues parameter-space FL methods, especially
  with neural networks.
---

# One-Shot Federated Learning with Bayesian Pseudocoresets

## Quick Facts
- arXiv ID: 2406.02177
- Source URL: https://arxiv.org/abs/2406.02177
- Authors: Tim d'Hondt; Mykola Pechenizkiy; Robert Peharz
- Reference count: 40
- One-line primary result: Achieves competitive accuracy to state-of-the-art FL methods while reducing communication cost by up to two orders of magnitude

## Executive Summary
This paper introduces a one-shot Bayesian federated learning approach using Bayesian pseudocoresets in function space. The method addresses the communication bottleneck in federated learning by having each client learn a small set of synthetic data points (pseudocoresets) that serve as approximate sufficient statistics of their local data. These pseudocoresets are then aggregated at the server to perform global inference. Experiments on synthetic and real-world datasets show that BPC-FL achieves competitive accuracy while significantly reducing communication cost compared to traditional FL methods.

## Method Summary
The method uses Bayesian pseudocoresets (BPCs) to represent client data in function space rather than parameter space. Each client learns a small pseudodataset that approximates the sufficient statistics of their local data using a forward KL divergence optimization. The server aggregates these pseudodatasets by simple concatenation and performs inference using standard Bayesian methods. The function-space representation avoids the posterior collapse issue that plagues parameter-space FL methods, especially with neural networks.

## Key Results
- Achieves competitive accuracy to state-of-the-art FL methods on EMNIST-62
- Reduces communication cost by up to two orders of magnitude compared to multi-round FL
- Provides well-calibrated uncertainty estimates as measured by expected calibration error

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Function-space representation avoids posterior collapse caused by mode mismatch across clients
- Mechanism: By working in function space rather than parameter space, the method treats the neural network as a stochastic process, collapsing all symmetric parameter modes into a single mode in function space
- Core assumption: The mapping from parameter space to function space is well-defined and preserves the essential structure of the posterior distribution
- Evidence anchors:
  - [abstract] "we explore approximate inference in the function-space representation of client posteriors, hence suffering less or not at all from multi-modality"
  - [section] "In function space, the posterior will concentrate on a single function in the infinite data limit"
  - [corpus] Weak - corpus doesn't directly address function-space vs parameter-space collapse

### Mechanism 2
- Claim: Bayesian pseudocoresets serve as approximate sufficient statistics for client data
- Mechanism: Each client learns a small set of synthetic data points (pseudocoresets) that approximate the sufficient statistics of their local data
- Core assumption: The pseudocoreset posterior adequately approximates the true posterior for a sufficiently small C
- Evidence anchors:
  - [abstract] "Each client learns a small set of synthetic data points (pseudocoresets) at each client, which serve as approximate sufficient statistics of the local data"
  - [section] "a BPC is a collection of synthetic data points whose weight posterior approximates the weight of the entire dataset"
  - [corpus] Weak - corpus mentions related one-shot methods but doesn't discuss pseudocoreset sufficiency directly

### Mechanism 3
- Claim: Forward KL divergence prevents posterior collapse in client-server aggregation
- Mechanism: Using forward KL divergence (p||q) instead of reverse KL forces the approximate posterior to have broad support over all functions probable under the true posterior
- Core assumption: Forward KL divergence provides better coverage of the true posterior than reverse KL in this distributed setting
- Evidence anchors:
  - [section] "Our motivation for using the forward KL divergence is that this divergence forces q(fZm) to have a broad support over all functions that are probable under p(fZm|Dm)"
  - [section] "contrary to the reverse KL divergence, choosing the forward KL divergence prevents us from having to backpropagate through a Monte Carlo sampling process"
  - [corpus] Weak - corpus doesn't discuss KL divergence choices in detail

## Foundational Learning

- Concept: Bayesian inference and posterior distributions
  - Why needed here: The entire method is built on Bayesian principles of inference from local client posteriors
  - Quick check question: What is the difference between the prior, likelihood, and posterior in Bayesian inference?

- Concept: Variational inference and KL divergence
  - Why needed here: The method uses variational inference with KL divergence to approximate posteriors and train pseudocoresets
  - Quick check question: What is the difference between forward KL (p||q) and reverse KL (q||p) divergence?

- Concept: Federated learning and distributed optimization
  - Why needed here: Understanding the communication constraints and distributed nature of the problem is crucial for the method's design
  - Quick check question: What is the communication bottleneck in traditional federated learning approaches?

## Architecture Onboarding

- Component map: Client-side BPC learning -> Client sends BPC to server -> Server aggregates BPCs -> Server performs inference
- Critical path: Client learns BPC → Client sends BPC to server → Server aggregates BPCs → Server performs inference
- Design tradeoffs: Communication efficiency vs. approximation quality; computation cost vs. convergence speed
- Failure signatures: Poor performance despite low communication (bad pseudocoreset approximation); high communication requirements (inefficient BPC learning)
- First 3 experiments:
  1. Run on a simple synthetic regression dataset with 2-3 clients to verify basic functionality
  2. Compare BPC-FL performance with FedAvg on EMNIST-62 with varying communication rounds
  3. Test uncertainty calibration by measuring ECE on a held-out test set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the computational and memory cost of BPC-fKL scale with dataset size and model complexity?
- Basis in paper: [explicit] The paper mentions that BPC-fKL requires a very large amount of disk space to store pretrained optimization trajectories and has a 10-100 fold longer runtime over FedAvg.
- Why unresolved: The paper only provides qualitative statements about the computational cost but doesn't give specific scaling analysis or empirical measurements across different dataset sizes and model architectures.
- What evidence would resolve it: Detailed experiments showing runtime and memory usage as functions of dataset size, number of clients, model size, and pseudodataset size.

### Open Question 2
- Question: What are the privacy guarantees of BPC-FL under realistic FL settings with heterogeneous data distributions?
- Basis in paper: [explicit] The paper discusses the lack of privacy guarantees and mentions that differential privacy guarantees have been shown to be easily implemented in BPC learning through DP-SGD.
- Why unresolved: The paper only briefly mentions the challenge of adding privacy guarantees and doesn't provide any empirical evaluation of privacy-utility trade-offs under realistic FL settings.
- What evidence would resolve it: Experiments showing the impact of different privacy budgets on model performance across various FL scenarios with heterogeneous data distributions.

### Open Question 3
- Question: How does BPC-FL perform in cross-silo FL settings with limited client availability?
- Basis in paper: [inferred] The paper focuses on cross-device FL with a large number of clients (100 in experiments) but doesn't discuss scenarios with limited client availability.
- Why unresolved: The paper doesn't explore how BPC-FL performs when only a small subset of clients is available in each round or when clients have very limited data.
- What evidence would resolve it: Experiments comparing BPC-FL performance with different numbers of available clients and varying client data sizes in each round.

## Limitations

- Limited empirical validation on complex vision datasets and diverse neural network architectures
- No comprehensive analysis of the computational and memory scaling costs
- Lack of privacy-utility trade-off evaluation under realistic FL settings

## Confidence

- Function-space collapse avoidance: Medium
- Pseudocoreset sufficiency: Medium  
- Communication-cost claims: Low

## Next Checks

1. Evaluate BPC-FL on more diverse datasets (e.g., CIFAR-10, NLP tasks) and with different neural network architectures to verify the function-space collapse avoidance mechanism generalizes.

2. Test the method with increasing numbers of clients and varying data heterogeneity levels to understand when the pseudocoreset approximation breaks down.

3. Conduct ablation studies measuring the actual bandwidth saved (pseudocoreset size vs. full model parameters) and compare wall-clock time to traditional FL with optimal communication schedules.