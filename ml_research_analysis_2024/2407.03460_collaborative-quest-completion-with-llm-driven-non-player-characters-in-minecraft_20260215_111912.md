---
ver: rpa2
title: Collaborative Quest Completion with LLM-driven Non-Player Characters in Minecraft
arxiv_id: '2407.03460'
source_url: https://arxiv.org/abs/2407.03460
tags: []
core_contribution: This paper explores how human players collaborate with LLM-driven
  NPCs in Minecraft. The authors create a quest where players work with two GPT-4
  NPCs to rescue a character on a floating island.
---

# Collaborative Quest Completion with LLM-driven Non-Player Characters in Minecraft

## Quick Facts
- arXiv ID: 2407.03460
- Source URL: https://arxiv.org/abs/2407.03460
- Reference count: 3
- Primary result: LLM-driven NPCs in Minecraft can provide contextual assistance and sub-goal guidance, but completion rates remain limited without visual grounding

## Executive Summary
This paper explores collaborative gameplay between human players and GPT-4-driven NPCs in Minecraft. The authors design a quest where players work with two NPCs to rescue a character on a floating island, analyzing 28 participants' interactions through gameplay logs and recordings. The study finds that NPCs can provide contextual game assistance and maintain collaborative focus through sub-goal generation, but face significant limitations due to their language-only nature. Only 25% of players completed the full quest, highlighting the challenges of language models without visual grounding in 3D game environments.

## Method Summary
The study implements two GPT-4 NPCs (Elena and Alaric) in Minecraft with distinct personas, backstories, and goals. NPCs use carefully crafted prompts that include API function definitions for game actions. The system incorporates sub-goal generation after every 6 conversational turns and communicates function call success/failure back to the model for contextual responses. Players interact via voice using speech-to-text and text-to-speech integration. The quest requires collaborative problem-solving across multiple steps, with the study analyzing gameplay logs and recordings from 28 participants.

## Key Results
- NPCs successfully provide contextual game assistance including answering questions and helping with tasks like mining and combat
- Sub-goal generation helps maintain collaborative focus, with NPCs using generated sub-goals to guide players back to main objectives
- Only 25% of players completed the full quest, demonstrating limitations of language-only models without visual grounding
- Most players found the experience fun and immersive despite technical limitations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4 NPCs provide contextual game assistance by combining learned game knowledge with real-time dialogue generation.
- Mechanism: NPCs use personas and backstories to guide behavior, generating responses based on learned Minecraft knowledge and making API function calls when needed.
- Core assumption: GPT-4 has sufficient general knowledge about Minecraft mechanics to provide helpful responses without extensive fine-tuning.
- Evidence anchors: NPCs helped with tasks like making daytime, mining, finding locations, and fighting monsters; but corpus papers focus on NPC design without direct evidence about knowledge grounding effectiveness.

### Mechanism 2
- Claim: Sub-goal generation helps NPCs maintain collaborative focus and guide players toward quest completion.
- Mechanism: After every 6 conversational turns, GPT-4 generates a sub-goal aligned with the NPC's main objective, which is incorporated into responses to steer the conversation back toward the quest.
- Core assumption: GPT-4 can generate contextually appropriate sub-goals that are both relevant to the current conversation and aligned with the overall quest objective.
- Evidence anchors: Generated sub-goals helped NPCs guide players back to main tasks when they deviated; but corpus papers discuss LLM NPC dialogue without specifically addressing sub-goal generation for collaboration.

### Mechanism 3
- Claim: Including function call status (success/failure) in prompts enables NPCs to communicate errors contextually in natural language.
- Mechanism: Function call success/failure status is captured and included in the next prompt to GPT-4, allowing the model to generate appropriate responses acknowledging outcomes.
- Core assumption: GPT-4 can effectively interpret function call status and generate contextually appropriate responses that acknowledge both success and failure states.
- Evidence anchors: Including function return value in prompts enabled NPCs to communicate errors more contextually; but corpus papers discuss LLM NPC errors without specifically addressing function call status communication.

## Foundational Learning

- Concept: Prompt engineering for role-based behavior
  - Why needed here: NPCs need to maintain consistent personas and goals throughout the interaction to create believable and helpful collaborative partners.
  - Quick check question: What are the three key elements included in each NPC's prompt to establish their role and behavior?

- Concept: API function call integration
  - Why needed here: NPCs need to perform in-game actions to be useful collaborators, requiring a mechanism to translate natural language requests into executable game commands.
  - Quick check question: How does the system communicate the success or failure of an NPC's attempted action back to the language model?

- Concept: Sub-goal generation for conversation management
  - Why needed here: Without explicit sub-goals, NPCs tend to drift from the main quest objective when players introduce new topics or requests.
  - Quick check question: How frequently are sub-goals generated during the player-NPC interaction?

## Architecture Onboarding

- Component map: Minecraft game world -> GPT-4 NPCs (Elena, Alaric) -> Prompt generation system -> Function call interface -> Game state monitor -> Sub-goal generation module -> Speech-to-text/text-to-speech -> Logging system

- Critical path: Player speaks → Speech-to-text → Prompt construction → GPT-4 response → Function call execution (if needed) → Game state update → Response delivery (text/voice) → Logging

- Design tradeoffs:
  - Language-only model vs. multimodal model: Current system uses GPT-4 without visual capabilities, requiring players to verbally describe visual information
  - Predefined vs. dynamic quest structure: Quest steps are predefined but NPC responses are dynamically generated
  - Function call breadth vs. safety: Limited set of safe function calls vs. broader but potentially risky capabilities

- Failure signatures:
  - NPCs giving incorrect information about their location or game state
  - NPCs failing to guide players back to main quest objectives
  - NPCs making function calls that don't exist or have incorrect syntax
  - NPCs not acknowledging when their attempted actions fail

- First 3 experiments:
  1. Test basic conversation flow: Have players ask simple questions and verify NPCs respond appropriately with correct information and function calls when needed.
  2. Test sub-goal generation: Introduce intentional conversation deviations and verify NPCs use generated sub-goals to guide players back to quest objectives.
  3. Test error communication: Have NPCs attempt actions that will fail and verify they communicate the failures contextually to players.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would integrating visual grounding and real-time game-state information into LLM-driven NPCs significantly improve collaborative task completion rates in 3D games?
- Basis in paper: The paper identifies that NPCs lack visual grounding and real-time game-state awareness, leading to limitations in spatial awareness, error communication, and contextual understanding. It suggests that future improvements could involve using models with visual capabilities and real-time game state information.
- Why unresolved: The paper only speculates about the potential benefits of visual grounding and real-time game-state information without empirically testing these enhancements. The current study uses language-only models, leaving the impact of these features unexplored.
- What evidence would resolve it: Conducting a user study comparing the performance of NPCs with and without visual grounding and real-time game-state information in a similar collaborative quest would provide empirical evidence of the impact of these features on task completion rates and user experience.

### Open Question 2
- Question: How does the collaborative behavior of LLM-driven NPCs vary across different player skill levels in Minecraft?
- Basis in paper: The paper notes that the study participants were relatively skilled Minecraft players, which may have influenced their interaction patterns with NPCs. It suggests that less-skilled players might exhibit different interaction and collaboration types, potentially focusing more on information-seeking rather than collaborative behaviors.
- Why unresolved: The study did not include players with varying skill levels, so the differences in collaborative behavior across skill levels remain unexplored. The paper only hypothesizes about potential differences without empirical data.
- What evidence would resolve it: Conducting a user study with participants of varying skill levels and analyzing their interactions with LLM-driven NPCs would reveal how player skill influences collaborative behavior and the types of assistance requested from NPCs.

### Open Question 3
- Question: To what extent can LLM-driven NPCs maintain narrative consistency and avoid generating harmful or inappropriate content in open-ended dialogues?
- Basis in paper: The paper mentions that the study employed a large language model with the risk of exposing players to unanticipated and unsolicited harmful outputs. It notes that participants were advised about this risk in the consent form, and the constraints of the game were assumed to function as baseline harm mitigation.
- Why unresolved: The paper does not provide detailed analysis of the frequency or nature of harmful content generated by the NPCs. It only mentions that participants were not exposed to harmful language, but does not explore the effectiveness of the constraints or the potential for harmful content generation.
- What evidence would resolve it: Analyzing the game logs and recordings for instances of harmful or inappropriate content generated by the NPCs, and assessing the effectiveness of the constraints in preventing such content, would provide insights into the risks and mitigation strategies for maintaining narrative consistency and safety in LLM-driven NPCs.

## Limitations
- Language-only model without visual perception creates asymmetrical collaboration requiring players to verbally describe visual information
- NPCs lack real-time game state awareness, leading to incorrect responses about their own location or game state
- Quest completion rate remains low at 25%, indicating significant limitations in task completion without visual grounding

## Confidence

Medium confidence in contextual assistance mechanism due to reliance on general knowledge
Medium confidence in sub-goal generation effectiveness due to variable quality of generated sub-goals
Medium-High confidence in error communication mechanism due to concrete function call status feedback

## Next Checks

1. **Visual grounding test**: Integrate a visual perception system (e.g., image captioning or object detection) to provide NPCs with visual context, then compare collaboration quality with the language-only baseline.

2. **Sub-goal quality analysis**: Systematically evaluate the generated sub-goals for relevance, specificity, and alignment with quest objectives across different conversation types and player behaviors.

3. **Function call reliability test**: Create a comprehensive test suite of valid and invalid function calls to measure how consistently NPCs can execute intended actions and communicate failures.