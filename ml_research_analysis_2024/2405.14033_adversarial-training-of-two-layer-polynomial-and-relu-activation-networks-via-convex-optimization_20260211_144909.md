---
ver: rpa2
title: Adversarial Training of Two-Layer Polynomial and ReLU Activation Networks via
  Convex Optimization
arxiv_id: '2405.14033'
source_url: https://arxiv.org/abs/2405.14033
tags:
- convex
- training
- adversarial
- networks
- polynomial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper develops a convex semidefinite program (SDP) for adversarial\
  \ training of two-layer polynomial activation neural networks. The key contribution\
  \ is proving that this convex formulation achieves the same globally optimal solution\
  \ as its nonconvex counterpart while improving robust test accuracy against \u2113\
  \u221E attacks."
---

# Adversarial Training of Two-Layer Polynomial and ReLU Activation Networks via Convex Optimization

## Quick Facts
- arXiv ID: 2405.14033
- Source URL: https://arxiv.org/abs/2405.14033
- Reference count: 40
- Authors: Daniel Kuelbs; Sanjay Lall; Mert Pilanci

## Executive Summary
This paper introduces a convex semidefinite programming (SDP) approach for adversarial training of two-layer polynomial activation neural networks. The key innovation is proving that this convex formulation achieves the same globally optimal solution as its nonconvex counterpart while improving robust test accuracy against ℓ∞ attacks. The authors provide exact solvers for small-scale problems and scalable PyTorch implementations for both polynomial and ReLU networks. Empirical results show that retraining the final two layers of a Pre-Activation ResNet-18 model with their convex adversarial training achieves significantly higher robust test accuracies than sharpness-aware minimization.

## Method Summary
The paper develops a convex SDP formulation for adversarial training by leveraging convex relaxations of polynomial activation functions. For two-layer polynomial networks, the authors reformulate the nonconvex training problem into a semidefinite program by exploiting sum-of-squares (SOS) representations of polynomial constraints. For ReLU networks, they use a similar convex relaxation approach that approximates the piecewise linear ReLU function. The key insight is that these convex formulations can be solved to global optimality using standard SDP solvers, avoiding the local minima issues common in gradient-based training of nonconvex neural networks.

## Key Results
- Convex SDP formulation achieves the same globally optimal solution as its nonconvex counterpart for two-layer polynomial activation networks
- Retraining the final two layers of Pre-Activation ResNet-18 with convex adversarial training achieves higher robust test accuracy than sharpness-aware minimization
- Scalable PyTorch implementations enable practical deployment with reduced computational overhead compared to iterative descent methods

## Why This Works (Mechanism)
The convex relaxation approach works by transforming the adversarial training problem into a convex optimization problem through sum-of-squares polynomial relaxations. This allows the use of powerful convex optimization techniques that guarantee global optimality, eliminating the local minima issues that plague traditional gradient-based training of nonconvex neural networks. The method exploits the structure of polynomial activation functions to create convex constraints that bound the adversarial examples within the ℓ∞ norm ball.

## Foundational Learning

**Semidefinite Programming (SDP)**: A class of convex optimization problems where the objective is to optimize a linear function over the intersection of the cone of positive semidefinite matrices with an affine space. Needed because SDP provides the mathematical framework for solving the convex relaxation of the adversarial training problem to global optimality. Quick check: Can verify convexity by checking that the Hessian of the objective function is positive semidefinite.

**Sum-of-Squares (SOS) Polynomials**: A polynomial that can be expressed as a sum of squared polynomials. Required because SOS representations provide the convex relaxation that enables the transformation of the nonconvex adversarial training problem into a tractable SDP. Quick check: Can verify SOS property using the Gram matrix representation and checking positive semidefiniteness.

**Robust Optimization**: Optimization under uncertainty where the objective accounts for worst-case scenarios. Essential because adversarial training is fundamentally a robust optimization problem where the goal is to minimize the worst-case loss over an ℓ∞ norm ball around each training example. Quick check: Can verify robust formulation by checking that the optimization includes constraints for all perturbations within the specified norm ball.

## Architecture Onboarding

**Component Map**: Data samples -> Polynomial/ReLU activation layer -> Convex relaxation (SOS) -> SDP formulation -> Global optimal solution -> Adversarial training

**Critical Path**: The core training pipeline involves: (1) Computing convex relaxations of polynomial constraints using SOS, (2) Formulating the adversarial training problem as an SDP, (3) Solving the SDP to global optimality, (4) Extracting the optimal network parameters for robust training.

**Design Tradeoffs**: The approach trades off some representational power (limited to two-layer networks and specific activation functions) for the benefit of guaranteed global optimality and reduced computational overhead. The convex formulation is more computationally intensive than standard gradient descent for the same network size, but provides theoretical guarantees that eliminate the need for multiple random restarts.

**Failure Signatures**: The method may fail when the polynomial degree is too low to capture the complexity of the data distribution, or when the ℓ∞ norm bound is too large for the convex relaxation to provide tight bounds. Additionally, the approach may not generalize well to very deep networks or activation functions that cannot be expressed as polynomials.

**First Experiments**:
1. Verify the equivalence between the convex SDP solution and the nonconvex solution on small synthetic datasets with known optimal solutions
2. Compare robust test accuracy against ℓ∞ attacks for different polynomial degrees and regularization parameters
3. Benchmark computational efficiency against standard PGD-based adversarial training methods for varying network sizes

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical guarantees may not fully extend to practical scenarios with finite data and computational constraints
- Empirical evaluation focuses primarily on ℓ∞ attacks and two-layer architectures, leaving open questions about performance under different attack types and deeper network structures
- Scalability analysis based on specific benchmark datasets may not generalize to more complex real-world applications with larger input dimensions or different data distributions

## Confidence
**High confidence in**: The theoretical equivalence between the convex SDP formulation and its nonconvex counterpart for two-layer polynomial activation networks, and the practical implementation details for PyTorch-based training.

**Medium confidence in**: The empirical improvements in robust test accuracy against ℓ∞ attacks compared to sharpness-aware minimization, given that results are demonstrated on specific datasets and architectures.

**Low confidence in**: The generalization of the convex approach to arbitrary activation functions beyond polynomial and ReLU, and the scalability claims for very deep networks or high-dimensional data without further empirical validation.

## Next Checks
1. Evaluate the convex adversarial training approach under multiple attack types (ℓ2, ℓ0) and compare performance against state-of-the-art adversarial training methods across diverse datasets and network architectures.

2. Conduct ablation studies to quantify the impact of different hyperparameters (regularization coefficients, activation function degrees) on both robust accuracy and computational efficiency.

3. Perform stress tests on the scalability of the SDP formulation for networks with more than two layers or with higher-dimensional inputs to validate the practical limits of the approach.