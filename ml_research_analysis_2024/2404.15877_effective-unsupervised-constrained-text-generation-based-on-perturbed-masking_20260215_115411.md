---
ver: rpa2
title: Effective Unsupervised Constrained Text Generation based on Perturbed Masking
arxiv_id: '2404.15877'
source_url: https://arxiv.org/abs/2404.15877
tags:
- edit
- generation
- methods
- search
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes PMCTG, an unsupervised constrained text generation
  framework that improves effectiveness by searching for the best edit position and
  action in each step. The method extends perturbed masking technique to effectively
  search for the most incongruent token to edit and introduces four multi-aspect scoring
  functions to select edit actions.
---

# Effective Unsupervised Constrained Text Generation based on Perturbed Masking

## Quick Facts
- arXiv ID: 2404.15877
- Source URL: https://arxiv.org/abs/2404.15877
- Reference count: 35
- Key outcome: PMCTG achieves 7.47 average NLL on keywords-to-sentence generation and iBLEU scores of 15.22 on Quora and 26.13 on Wikianswers for paraphrasing, outperforming previous methods

## Executive Summary
This paper proposes PMCTG, an unsupervised constrained text generation framework that improves effectiveness by searching for the best edit position and action in each step. The method extends perturbed masking technique to effectively search for the most incongruent token to edit and introduces four multi-aspect scoring functions to select edit actions. Experiments on keywords-to-sentence generation and paraphrasing tasks demonstrate PMCTG achieves new state-of-the-art results without requiring supervised data, making it applicable to different generation tasks.

## Method Summary
PMCTG uses perturbed masking to estimate token incongruency by calculating how much masking a token affects predictions of its neighbors. Tokens with low impact scores are considered incongruent and targeted for editing. After selecting an edit position, the method evaluates candidate actions (insert/replace/delete) using weighted combinations of fluency (language model likelihood), editorial rationality (local edit coherence via perturbed masking), semantic similarity (keyword and sentence-level similarity), and diversity (BLEU-based diversity score). The method alternates between position selection and action selection until maximum steps reached, choosing the best-scoring sentence as output.

## Key Results
- PMCTG achieves 7.47 average NLL on keywords-to-sentence generation, outperforming previous methods like G2LC (7.56) and CGMH (7.70)
- For paraphrasing, PMCTG achieves iBLEU scores of 15.22 on Quora and 26.13 on Wikianswers
- The method demonstrates effectiveness on both keywords-to-sentence generation and paraphrasing tasks without requiring supervised data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PMCTG uses perturbed masking to estimate token incongruency, enabling more targeted edits than stochastic sampling
- Mechanism: Perturbed masking calculates how much masking a token affects predictions of its neighbors. Tokens with low impact scores are considered incongruent and targeted for editing
- Core assumption: The token with weakest correlation to its neighbors is most likely to need editing to improve sentence coherence
- Evidence anchors: [abstract]: "PMCTG extends perturbed masking technique to effectively search for the most incongruent token to edit"

### Mechanism 2
- Claim: Multi-aspect scoring functions guide action selection based on fluency, rationality, semantic similarity, and diversity
- Mechanism: After selecting an edit position, the method evaluates candidate actions using weighted combinations of fluency, editorial rationality, semantic similarity, and diversity
- Core assumption: Combining multiple evaluation criteria provides better action selection than single-criterion methods
- Evidence anchors: [abstract]: "Then it introduces four multi-aspect scoring functions to select edit action to further reduce search difficulty"

### Mechanism 3
- Claim: The search process iteratively refines sentences by finding best edit positions and actions without requiring supervised data
- Mechanism: The method alternates between position selection (using perturbed masking) and action selection (using scoring functions) until maximum steps reached
- Core assumption: Local edits guided by position and action scoring will converge to high-quality constrained text without global supervision
- Evidence anchors: [abstract]: "Since PMCTG does not require supervised data, it could be applied to different generation tasks"

## Foundational Learning

- Concept: Masked Language Modeling (MLM)
  - Why needed here: PMCTG relies on BERT's MLM capability to evaluate how masking tokens affects predictions, which is fundamental to the perturbed masking technique
  - Quick check question: How does BERT's masked language modeling objective enable the calculation of token impact scores in perturbed masking?

- Concept: Metropolis-Hastings sampling
  - Why needed here: Understanding this stochastic sampling method helps contrast why PMCTG's deterministic scoring approach may be more efficient than CGMH's random sampling
  - Quick check question: What is the key difference between Metropolis-Hastings sampling and PMCTG's scoring-based approach in terms of search efficiency?

- Concept: Beam search vs local edit strategies
  - Why needed here: PMCTG uses local edits rather than beam search; understanding both approaches clarifies why local edits work better for large search spaces like paraphrasing
  - Quick check question: Why might local edit-based methods like PMCTG outperform beam search-based methods for paraphrasing tasks?

## Architecture Onboarding

- Component map: Input sentence -> Pre-trained BERT model -> Pre-trained language model -> Scoring functions -> Iterative search loop -> Output sentence
- Critical path: 1. Token incongruency calculation via perturbed masking 2. Edit position sampling based on incongruency scores 3. Candidate action generation and scoring 4. Action selection based on weighted scoring functions 5. Sentence update and repeat until convergence
- Design tradeoffs: Using BERT for perturbed masking adds computational overhead but provides better position selection than random sampling; multiple scoring functions increase complexity but improve action quality; local edits reduce search space but may miss global optimal solutions
- Failure signatures: Poor fluency despite high scores (scoring function weights need tuning); getting stuck in repetitive edits (incongruency calculation may not capture context well); slow convergence (scoring functions may not effectively guide search)
- First 3 experiments: 1. Test perturbed masking position selection on a simple sentence with obvious incongruencies to verify it identifies correct tokens 2. Compare action scoring performance with and without each scoring component to validate their contributions 3. Run PMCTG on a small keywords-to-sentence task and analyze step-by-step edits to understand search behavior

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does PMCTG's performance scale with increasing constraint complexity or length?
- Basis in paper: [explicit] The paper mentions that PMCTG outperforms previous methods but does not explore performance variations with different constraint lengths or complexities
- Why unresolved: The experiments focus on fixed constraint numbers (1-4 keywords) and do not investigate how the method performs with more complex or longer constraints
- What evidence would resolve it: Conducting experiments with varying numbers of constraints and analyzing PMCTG's performance metrics across different constraint complexities

### Open Question 2
- Question: Can PMCTG's perturbed masking technique be extended to other NLP tasks beyond constrained text generation?
- Basis in paper: [explicit] The paper extends perturbed masking from dependency parsing to constrained text generation, suggesting potential applicability to other tasks
- Why unresolved: The paper only demonstrates PMCTG's effectiveness in keywords-to-sentence generation and paraphrasing, leaving open the question of its broader applicability
- What evidence would resolve it: Applying PMCTG's perturbed masking approach to other NLP tasks (e.g., text summarization, dialogue generation) and evaluating its performance

### Open Question 3
- Question: How does the choice of language model (LSTM vs. GPT2) affect PMCTG's performance in different domains or tasks?
- Basis in paper: [explicit] The paper shows PMCTG-LSTM outperforming PMCTG-GPT2 in keywords-to-sentence generation, but GPT2 works better in paraphrasing, indicating domain/task-specific effectiveness
- Why unresolved: The paper does not provide a comprehensive analysis of how different language models impact PMCTG's performance across various domains or tasks
- What evidence would resolve it: Conducting experiments using different language models with PMCTG across multiple domains and tasks to compare performance metrics

## Limitations

- The paper does not specify critical hyperparameters for the scoring functions, particularly the weight parameters (λ values), making faithful reproduction challenging
- Computational cost concerns arise from multiple BERT evaluations required for perturbed masking calculations at each editing step
- The method's generalizability to other constrained text generation tasks beyond the evaluated domains remains untested

## Confidence

**High Confidence Claims:**
- PMCTG extends perturbed masking technique to effectively search for the most incongruent token to edit
- The method introduces four multi-aspect scoring functions (fluency, editorial rationality, semantic similarity, diversity) for action selection
- PMCTG achieves state-of-the-art performance on keywords-to-sentence generation and paraphrasing tasks

**Medium Confidence Claims:**
- Perturbed masking provides more targeted edits than stochastic sampling approaches
- The multi-aspect scoring approach is superior to single-criterion methods for action selection
- Local edit strategies work better than beam search for large search spaces like paraphrasing

**Low Confidence Claims:**
- The specific weight values for scoring function components are optimal across different tasks
- The method will generalize equally well to other constrained text generation tasks
- Computational efficiency is maintained for longer sequences or more complex constraints

## Next Checks

**Validation Check 1: Hyperparameter Sensitivity Analysis**
Conduct systematic experiments varying the weight parameters (λ values) in the scoring functions across a reasonable range to validate whether the reported performance is robust or highly sensitive to specific parameter choices.

**Validation Check 2: Ablation Study on Scoring Components**
Implement ablations that remove each scoring component individually (fluency, editorial rationality, semantic similarity, diversity) to quantify their individual contributions and confirm whether the multi-aspect approach is genuinely superior.

**Validation Check 3: Cross-Domain Generalization Test**
Apply PMCTG to a different constrained text generation task not evaluated in the paper (such as text simplification or controlled language generation) to assess whether the method generalizes beyond the evaluated domains.