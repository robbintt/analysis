---
ver: rpa2
title: 'FightLadder: A Benchmark for Competitive Multi-Agent Reinforcement Learning'
arxiv_id: '2406.02081'
source_url: https://arxiv.org/abs/2406.02081
tags:
- left
- right
- games
- learning
- algorithms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FightLadder, a competitive multi-agent reinforcement
  learning benchmark featuring real-time fighting games with visual inputs. The platform
  supports various fighting games like Street Fighter II, Street Fighter III, and
  Mortal Kombat, providing implementations of state-of-the-art competitive MARL algorithms
  including independent learning, two-timescale learning, fictitious self-play, policy-space
  response oracle, and league training.
---

# FightLadder: A Benchmark for Competitive Multi-Agent Reinforcement Learning

## Quick Facts
- arXiv ID: 2406.02081
- Source URL: https://arxiv.org/abs/2406.02081
- Reference count: 40
- Primary result: Introduces a competitive MARL benchmark using fighting games with visual inputs

## Executive Summary
FightLadder presents a novel benchmark platform for competitive multi-agent reinforcement learning using real-time fighting games with visual inputs. The platform supports classic fighting games like Street Fighter II, Street Fighter III, and Mortal Kombat, implementing state-of-the-art competitive MARL algorithms including independent learning, two-timescale learning, fictitious self-play, policy-space response oracle, and league training. The evaluation framework employs Elo ratings and exploitability tests to assess algorithm performance.

The benchmark reveals that while baseline algorithms can effectively defeat built-in game AIs in single-player mode, they struggle to learn non-exploitable strategies in two-player competitive settings without human knowledge and demonstrations. This finding exposes fundamental challenges in competitive MARL and provides a structured environment for advancing research in this field.

## Method Summary
The FightLadder platform implements a competitive multi-agent reinforcement learning benchmark using fighting games with visual inputs. The system integrates several state-of-the-art competitive MARL algorithms including independent learning, two-timescale learning, fictitious self-play, policy-space response oracle, and league training. The platform uses Elo ratings and exploitability tests as evaluation metrics. Experiments demonstrate that baseline algorithms can learn policies to defeat built-in game AIs in single-player mode but face difficulties in learning non-exploitable strategies in two-player mode without human knowledge and demonstrations.

## Key Results
- Baseline algorithms successfully defeat built-in game AIs in single-player mode
- Algorithms struggle to learn non-exploitable strategies in two-player mode without human knowledge
- The platform exposes fundamental challenges in competitive MARL research

## Why This Works (Mechanism)
The FightLadder platform works by providing a structured competitive environment where MARL algorithms must learn to handle strategic interactions and exploitability in real-time fighting games. The use of visual inputs adds complexity that requires algorithms to process and respond to dynamic visual information. The Elo rating system provides a standardized way to measure relative performance, while exploitability tests identify vulnerabilities in learned strategies. The platform's design forces algorithms to balance between exploiting opponents and maintaining robust, non-exploitable strategies.

## Foundational Learning

**Reinforcement Learning**: Understanding of basic RL concepts including state-action spaces, rewards, and policy optimization. Needed for implementing and evaluating MARL algorithms. Quick check: Can explain the difference between value-based and policy-based methods.

**Multi-Agent Systems**: Knowledge of how multiple agents interact in shared environments, including concepts of cooperation and competition. Needed for understanding competitive MARL dynamics. Quick check: Can describe the challenges of non-stationarity in multi-agent environments.

**Game Theory**: Understanding of strategic decision-making, Nash equilibria, and exploitability concepts. Needed for evaluating competitive strategies. Quick check: Can explain what makes a strategy exploitable in competitive settings.

**Computer Vision**: Basic understanding of processing visual inputs for decision-making. Needed for handling the visual input aspect of fighting games. Quick check: Can describe how convolutional neural networks process visual information.

**Elo Rating System**: Understanding of how Elo ratings work and their application in competitive settings. Needed for evaluating algorithm performance. Quick check: Can calculate Elo rating changes after a match.

## Architecture Onboarding

**Component Map**: Environment (fighting games) -> Visual Input Processing -> MARL Algorithm -> Strategy Output -> Elo Rating System -> Exploitability Test

**Critical Path**: Visual input → State representation → Policy selection → Action execution → Outcome evaluation → Rating update

**Design Tradeoffs**: The platform balances between using established fighting games for consistency while implementing modern MARL algorithms. The choice of visual inputs adds complexity but provides a more realistic challenge compared to abstract state representations.

**Failure Signatures**: Algorithms may overfit to specific opponent strategies, fail to generalize across different fighting games, or develop exploitable patterns that are easily countered by simple strategies.

**First Experiments**:
1. Test independent learning algorithm against built-in game AI in single-player mode
2. Evaluate fictitious self-play algorithm's performance in two-player mode
3. Compare Elo ratings of different algorithms across multiple fighting games

## Open Questions the Paper Calls Out

The paper highlights several open questions regarding the scalability of the platform to more complex or modern games, the generalizability of results across different fighting game environments, and the specific aspects of competitive MARL that make learning non-exploitable strategies particularly challenging. The paper also questions whether the observed limitations are inherent to the platform or specific to the tested algorithms.

## Limitations

- Limited evidence on scalability to more complex or modern games
- Sample size and diversity of experiments not clearly specified
- Potential biases in Elo rating system and exploitability tests not thoroughly addressed

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Baseline algorithms struggle to learn non-exploitable strategies | Medium |
| FightLadder can catalyze advancement in competitive MARL research | Medium |
| Platform exposes critical challenges in competitive MARL | Medium |

## Next Checks

1. Conduct a more extensive ablation study to isolate which specific aspects of the FightLadder environment contribute most to the observed difficulties in learning non-exploitable strategies

2. Test the platform with a wider variety of fighting games, including more modern titles, to assess scalability and generalizability

3. Implement and evaluate additional competitive MARL algorithms not mentioned in the paper to determine if the observed limitations are inherent to the platform or specific to the tested algorithms