---
ver: rpa2
title: 'C4Q: A Chatbot for Quantum'
arxiv_id: '2402.01738'
source_url: https://arxiv.org/abs/2402.01738
tags:
- quantum
- user
- gate
- chatbot
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'C4Q is a chatbot that helps non-experts understand quantum computing
  by answering questions about qubits and quantum gates. Unlike ChatGPT, which provides
  unreliable answers, C4Q uses a specialized architecture: a fine-tuned classification
  LLM categorizes user queries, a QA LLM extracts relevant parameters, and a logical
  engine generates accurate responses using Qiskit.'
---

# C4Q: A Chatbot for Quantum

## Quick Facts
- arXiv ID: 2402.01738
- Source URL: https://arxiv.org/abs/2402.01738
- Reference count: 34
- Primary result: C4Q achieves 100% classification accuracy and 98% QA accuracy for quantum computing queries, outperforming general LLMs like ChatGPT

## Executive Summary
C4Q is a specialized chatbot designed to help non-experts understand quantum computing by answering questions about qubits and quantum gates. Unlike general-purpose LLMs that provide unreliable answers, C4Q uses a hybrid architecture combining fine-tuned classification and QA LLMs with a deterministic logical engine powered by Qiskit. This approach ensures C4Q always provides correct answers for basic quantum gate queries. The system currently handles basic quantum gates and states, with plans to expand to advanced topics and improve conversational responsiveness.

## Method Summary
C4Q employs a multi-stage architecture where user queries are first classified into one of three types (define, draw, apply) using a fine-tuned BERT model, then relevant parameters are extracted by a QA LLM. The logical engine uses these structured inputs to call Qiskit, producing deterministic and accurate quantum computations. The classification LLM achieved 100% accuracy after 2 epochs of fine-tuning on a curated dataset, while the QA LLM reached 98% accuracy across 2000 tests. The system is built with React frontend, Django API, PostgreSQL database, and integrates Qiskit for quantum computations.

## Key Results
- Classification LLM achieved 100% accuracy after 2 epochs of fine-tuning
- QA LLM reached 98% accuracy across 2000 tests
- C4Q provides deterministic, correct answers for basic quantum gate queries unlike probabilistic LLMs
- System handles three query types: defining gates, drawing gate representations, and applying gates to states

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The hybrid architecture ensures 100% accuracy by combining classification and extraction layers with a deterministic logical engine
- Mechanism: User input is first classified into one of three query types by a fine-tuned BERT model, then a QA LLM extracts relevant parameters. The logical engine uses these structured inputs to call Qiskit, producing deterministic outputs
- Core assumption: The classification and QA LLMs are accurate enough that downstream logic never receives malformed or misclassified queries
- Evidence anchors:
  - [abstract] "C4Q uses a pre-trained large language model only to discover and classify user requests. It then generates an accurate answer using an own engine."
  - [section] "The Classification LLM classifies user questions in three categories: defining a quantum gate, drawing a quantum gate and applying a quantum gate."

### Mechanism 2
- Claim: Fine-tuning BERT on a curated dataset improves classification accuracy to 100% after 2 epochs
- Mechanism: The team created a labeled dataset of 80-20 train-validation splits with natural language questions about quantum gates. Fine-tuning used AdamW with learning rate 2x10^-5 and epsilon 1x10^-8, converging quickly
- Core assumption: The dataset is representative of real user queries and balanced across categories
- Evidence anchors:
  - [section] "The classification LLM achieved 100% accuracy after 2 epochs"
  - [section] "Following the recommendations, the fine-tuning process adhered to the following specific parameters: ... learning rate, lr, of 2·10^-5 and an epsilon, eps, of 1·10^-8"

### Mechanism 3
- Claim: Qiskit integration ensures all quantum computations are physically valid and reproducible
- Mechanism: The logical engine maps query parameters to Qiskit operations (e.g., circuit construction, gate application). Since Qiskit enforces quantum rules, outputs are always mathematically correct
- Core assumption: The logical engine correctly translates classification and QA outputs into valid Qiskit calls
- Evidence anchors:
  - [section] "Using the classification and the information extracted by the LLMs, this module generates an accurate answer using an own engine."
  - [section] "The logical engine ensures the precise execution of quantum computations."

## Foundational Learning

- Concept: Quantum gate basics (Pauli X, Y, Z, Hadamard, CNOT, etc.)
  - Why needed here: C4Q answers queries about these gates; understanding their definitions and effects is essential for interpreting responses
  - Quick check question: What is the matrix representation of the Pauli Z gate and what does it do to the |0⟩ and |1⟩ states?

- Concept: Qiskit circuit construction
  - Why needed here: The logical engine relies on Qiskit to generate circuits and simulate gate applications; new contributors must know how to build and run circuits
  - Quick check question: How do you create a 2-qubit circuit in Qiskit and apply a CNOT gate?

- Concept: BERT fine-tuning for classification
  - Why needed here: The classification LLM is key to routing queries; understanding how to prepare data, train, and evaluate ensures future updates are reliable
  - Quick check question: What is the purpose of the learning rate and epsilon parameters in AdamW optimizer during BERT fine-tuning?

## Architecture Onboarding

- Component map: Frontend (React) -> API (Django) -> Database (PostgreSQL) -> Classification LLM -> QA LLM -> Logical Engine -> Qiskit
- Critical path: User query → API → Classification LLM → QA LLM → Logical Engine → Qiskit → Response
- Design tradeoffs:
  - Accuracy vs. responsiveness: Using multiple LLM calls plus Qiskit slows response but ensures correctness
  - Dataset curation: High-quality training data yields 100% accuracy but requires manual effort
  - Extensibility: Hard-coded gate definitions are simple but limit adding new gates without code changes
- Failure signatures:
  - Misclassification → Wrong answer type but still runs
  - Parameter extraction failure → Missing gate parameters → Default values used or error
  - Qiskit error → Backend crash or exception
- First 3 experiments:
  1. Test classification accuracy with 50 unseen user-like queries
  2. Verify QA LLM correctly extracts phase shift for phase gates across 20 variations
  3. Validate logical engine produces correct circuit output for a known gate-state combination

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does C4Q's accuracy compare to Copilot in Azure Quantum and Quantum AI Chatbot when handling the same set of quantum computing questions?
- Basis in paper: [explicit] The paper mentions becoming aware of these two initiatives and plans to evaluate them in depth in future works
- Why unresolved: The paper states that at the moment we have not studied the quality of either system, but we plan to evaluate them in depth in future works
- What evidence would resolve it: A systematic evaluation comparing C4Q's accuracy with these two systems on the same quantum computing question set

### Open Question 2
- Question: Can C4Q maintain its 100% classification accuracy when expanding to more advanced quantum computing topics beyond basic gates and states?
- Basis in paper: [inferred] The paper mentions current focus on fundamentals with plans to broaden functionality, and achieved 100% accuracy after 2 epochs on basic topics
- Why unresolved: The paper only reports results for basic quantum gates and states, not for more complex topics
- What evidence would resolve it: Testing C4Q's classification accuracy on a dataset containing advanced quantum computing topics

### Open Question 3
- Question: What specific improvements in conversational responsiveness could be achieved by incorporating message history awareness into C4Q?
- Basis in paper: [explicit] The paper states that the symbiotic relationship between information extraction, logical computation, and quantum handling enables the sophistication and effectiveness of C4Q, ensuring a consistent level of accuracy. The high accuracy distinguishes C4Q from other chatbots relying primarily on LLMs and extensive datasets, and thus answering according to probabilities. It is important to acknowledge that attention to accuracy has an impact on responsiveness. In comparison to other chatbots like ChatGPT, the conversational experience with C4Q still lacks a certain human-like quality. This is a feature that we plan to improve
- Why unresolved: The paper acknowledges the lack of human-like quality in C4Q's conversational experience and plans to improve it, but doesn't specify what improvements would be most effective
- What evidence would resolve it: User studies comparing C4Q's current conversational experience with versions incorporating message history awareness

## Limitations

- Dataset representativeness: The 100% classification accuracy depends heavily on the curated training set's coverage of real user queries, with no validation against out-of-distribution queries
- Scalability concerns: The hard-coded logical engine integration with Qiskit may not scale well for more complex quantum operations
- Conversational limitations: The system processes single-turn queries effectively but struggles with multi-turn conversations, limiting real-world usability

## Confidence

- High confidence: The core claim that combining classification, extraction, and deterministic quantum computation produces more accurate results than general LLMs
- Medium confidence: The claim that C4Q "always provides correct answers" for basic quantum gate queries, assuming perfect classification and parameter extraction
- Low confidence: The assertion that this approach can be easily extended to "advanced quantum computing topics" without significant architectural modifications

## Next Checks

1. **Out-of-distribution query testing** - Test the classification and QA models with 100 queries that deliberately fall outside the training distribution to assess robustness

2. **Multi-turn conversation simulation** - Implement a test suite that simulates realistic conversation patterns where users ask follow-up questions about previously discussed gates or circuits, measuring accuracy degradation across turns

3. **Performance benchmarking** - Compare response times and accuracy against both ChatGPT and a baseline Qiskit-only approach across 50 diverse quantum computing queries to quantify the practical benefit of the hybrid architecture