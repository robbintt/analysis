---
ver: rpa2
title: 'When predict can also explain: few-shot prediction to select better neural
  latents'
arxiv_id: '2405.14425'
source_url: https://arxiv.org/abs/2405.14425
tags:
- co-smoothing
- neural
- should
- data
- latent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses a limitation in co-smoothing, a standard prediction
  framework for evaluating latent variable models in neural data analysis. The authors
  show that high co-smoothing scores do not guarantee accurate latent dynamics, as
  models with extraneous dynamics can achieve similar performance.
---

# When predict can also explain: few-shot prediction to select better neural latents

## Quick Facts
- arXiv ID: 2405.14425
- Source URL: https://arxiv.org/abs/2405.14425
- Authors: Kabir Dabholkar; Omri Barak
- Reference count: 40
- High co-smoothing scores don't guarantee accurate latent dynamics; few-shot co-smoothing better penalizes extraneous dynamics

## Executive Summary
This paper addresses a critical limitation in the standard co-smoothing prediction framework used to evaluate latent variable models (LVMs) in neural data analysis. The authors demonstrate that high co-smoothing scores can be achieved by models with complex, extraneous latent dynamics that don't improve predictive accuracy. To address this, they propose "few-shot co-smoothing," which estimates decoders from limited trials, thereby penalizing models with unnecessary latent structure. Using synthetic HMM data and state-of-the-art methods (LFADS and STNDT), they show that few-shot co-smoothing correlates with model simplicity and better aligns with ground truth dynamics.

## Method Summary
The paper introduces few-shot co-smoothing as an improved evaluation metric for latent variable models. Standard co-smoothing predicts held-out trials using decoders trained on all available data, which can mask extraneous dynamics in the latent space. Few-shot co-smoothing instead trains decoders on limited trials (k-shot), making the prediction task harder and penalizing complex latent structures that don't contribute to generalization. The method involves training LVMs on neural data, computing both standard and few-shot co-smoothing scores, and using cross-decoding analysis as a proxy for ground truth alignment. Experiments use synthetic HMMs with varying complexity and real neural data from the mc_maze_20 dataset, comparing performance across different LVM architectures.

## Key Results
- Synthetic HMM experiments show co-smoothing scores fail to distinguish between simple and complex models with similar predictive performance
- Few-shot co-smoothing scores correlate strongly with model simplicity, as measured by cross-decoding R² scores
- LFADS and STNDT models show higher few-shot co-smoothing scores when their latent dynamics are closer to ground truth
- Cross-decoding analysis confirms few-shot co-smoothing effectively identifies extraneous dynamics in real neural data

## Why This Works (Mechanism)
Standard co-smoothing allows models to learn complex latent dynamics that don't improve prediction because decoders can overfit to the full training set. By limiting decoder training to few trials, few-shot co-smoothing creates a more challenging prediction task that penalizes unnecessary complexity. This forces models to develop simpler, more generalizable latent representations that capture essential dynamics rather than noise or irrelevant structure.

## Foundational Learning
**Latent Variable Models**: Statistical models that infer unobserved variables driving observed neural activity
- Why needed: Core framework for understanding neural population dynamics
- Quick check: Can explain how LVMs differ from direct regression approaches

**Co-smoothing**: Prediction framework where decoders are trained on one trial and tested on held-out trials
- Why needed: Standard evaluation metric for LVMs in neuroscience
- Quick check: Understand the Q metric calculation and normalization

**Cross-decoding**: Training decoders across different experimental conditions to test representational similarity
- Why needed: Proxy for ground truth alignment when true dynamics are unknown
- Quick check: Can interpret R² scores as measures of cross-condition generalization

## Architecture Onboarding

**Component Map**: Neural data -> LVM (HMM/LFADS/STNDT) -> Latents -> Decoders -> Predictions -> Q scores

**Critical Path**: Data preprocessing → Model training → Standard co-smoothing evaluation → Few-shot co-smoothing evaluation → Cross-decoding analysis

**Design Tradeoffs**: Simpler latents vs prediction accuracy; k-shot trial count vs score stability; decoder complexity vs few-shot performance

**Failure Signatures**: 
- High standard co-smoothing but low few-shot co-smoothing → extraneous dynamics
- Low scores for both metrics → poor model fit or insufficient data
- High variance in few-shot scores → inadequate k-shot trials or unstable regression

**First Experiments**:
1. Run HMM experiments on synthetic data with varying noise levels
2. Compare standard vs few-shot co-smoothing on simple vs complex ground truth
3. Test sensitivity to k-shot trial count on real neural data

## Open Questions the Paper Calls Out
The paper doesn't explicitly call out open questions but raises several implicit ones through its findings and limitations.

## Limitations
- Few-shot co-smoothing requires sufficient trial diversity for reliable decoder estimation
- Method assumes ground truth simplicity exists and should be preferred
- Performance depends on careful selection of k-shot parameters
- Validation relies on cross-decoding rather than direct ground truth comparisons for real data

## Confidence
High confidence in synthetic HMM results demonstrating the core limitation of standard co-smoothing
Medium confidence in real neural data results due to indirect validation through cross-decoding
Medium confidence in generalizability across different LVM architectures

## Next Checks
1. Reproduce synthetic HMM experiments to verify co-smoothing vs few-shot co-smoothing performance gap across different noise levels and latent dimensionalities
2. Implement cross-decoding analysis on synthetic data with known ground truth to validate few-shot co-smoothing correlation with true model simplicity
3. Test sensitivity of few-shot co-smoothing to different k values and trial sampling strategies on real neural datasets with varying trial counts