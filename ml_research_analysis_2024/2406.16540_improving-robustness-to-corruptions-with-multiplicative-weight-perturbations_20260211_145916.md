---
ver: rpa2
title: Improving robustness to corruptions with multiplicative weight perturbations
arxiv_id: '2406.16540'
source_url: https://arxiv.org/abs/2406.16540
tags:
- damp
- training
- data
- corruption
- corruptions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of improving deep neural network
  robustness to input corruptions without harming clean-image accuracy. The core method,
  DAMP, introduces multiplicative weight perturbations during training to simulate
  input corruptions in the weight space, thereby enhancing generalization to various
  distortions.
---

# Improving robustness to corruptions with multiplicative weight perturbations

## Quick Facts
- arXiv ID: 2406.16540
- Source URL: https://arxiv.org/abs/2406.16540
- Reference count: 40
- Primary result: Introduces DAMP method that improves corruption robustness without harming clean accuracy

## Executive Summary
This paper addresses the problem of improving deep neural network robustness to input corruptions without harming clean-image accuracy. The core method, DAMP, introduces multiplicative weight perturbations during training to simulate input corruptions in the weight space, thereby enhancing generalization to various distortions. The paper also establishes a connection between adversarial multiplicative perturbations and Adaptive Sharpness-Aware Minimization (ASAM). Empirical results show DAMP consistently outperforms standard methods like Dropout and SAM across CIFAR-10/100, TinyImageNet, and ImageNet datasets, improving corruption robustness without sacrificing clean accuracy. Notably, DAMP enables training a ViT-S/16 on ImageNet from scratch with performance comparable to ResNet50, achieving top-1 error of 23.7% without extensive data augmentations.

## Method Summary
DAMP (Dynamic Adversarial Multiplicative Perturbation) introduces a novel training mechanism that applies multiplicative perturbations to network weights during training. These perturbations simulate input corruptions in the weight space, forcing the model to learn more robust representations. The method connects to ASAM by showing that adversarial multiplicative perturbations can be viewed as a form of sharpness-aware optimization. During training, the network weights are dynamically adjusted with perturbations that mimic various input corruptions, creating a form of implicit data augmentation in the parameter space. This approach differs from traditional augmentation techniques by operating directly on the model parameters rather than the input data.

## Key Results
- DAMP consistently outperforms standard methods like Dropout and SAM across CIFAR-10/100, TinyImageNet, and ImageNet datasets
- Improves corruption robustness without sacrificing clean accuracy
- Enables training a ViT-S/16 on ImageNet from scratch with top-1 error of 23.7%, comparable to ResNet50 without extensive augmentations

## Why This Works (Mechanism)
The paper proposes that multiplicative weight perturbations create a regularization effect that forces the network to learn more stable representations. By simulating input corruptions in the weight space, the model develops internal mechanisms to handle various distortions. The connection to ASAM suggests that these perturbations help the model find flatter minima in the loss landscape, which are known to generalize better. The weight-space perturbations act as a form of implicit data augmentation, exposing the model to a wider variety of effective inputs during training without requiring additional computational overhead for data augmentation.

## Foundational Learning
- Sharpness-Aware Minimization (SAM): An optimization technique that encourages finding flatter minima in the loss landscape; needed to understand the connection between weight perturbations and generalization; quick check: compare loss surface flatness between SAM and DAMP-trained models
- Adversarial training: Training with adversarial examples to improve robustness; provides context for why weight perturbations might help; quick check: compare robustness against white-box adversarial attacks
- Multiplicative noise injection: Adding noise that scales with the magnitude of parameters; relevant for understanding how perturbations affect different layers; quick check: analyze perturbation magnitude across network layers
- Vision Transformer architecture: Understanding ViT components and training dynamics; crucial for interpreting the ViT training results; quick check: compare attention patterns between DAMP and standard ViT training
- Corruption robustness benchmarks: Standard datasets and metrics for evaluating model robustness; provides context for performance evaluation; quick check: verify results on additional corruption types beyond standard benchmarks

## Architecture Onboarding
Component map: Input data -> Neural network layers -> Multiplicative weight perturbations -> Loss computation -> Parameter updates

Critical path: The training loop where weight perturbations are applied at each iteration before computing gradients. This perturbation step is critical because it directly influences the gradients and subsequent weight updates.

Design tradeoffs: The perturbation magnitude must be carefully balanced - too small provides insufficient regularization, while too large can destabilize training. The method trades computational simplicity for robustness gains.

Failure signatures: If perturbations are too aggressive, training may become unstable with exploding gradients. If too conservative, robustness improvements will be minimal. The method may also be less effective on architectures with normalization layers that could dampen perturbation effects.

First experiments:
1. Compare training curves between DAMP and standard training on CIFAR-10
2. Measure corruption robustness on a single corruption type before and after DAMP training
3. Analyze the distribution of weight perturbations across different network layers

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions in the provided context.

## Limitations
- The connection between adversarial multiplicative perturbations and ASAM is primarily theoretical and requires more rigorous empirical validation across diverse architectures
- The computational overhead of multiplicative weight perturbations versus their robustness gains is not thoroughly analyzed
- The claim that DAMP enables training ViT from scratch without extensive augmentations needs independent verification, particularly on other vision transformers and larger-scale datasets

## Confidence
- Robustness improvements: Medium - results show consistent improvements across datasets but may not generalize to all corruption types or real-world scenarios
- ASAM connection: Low - primarily theoretical with limited empirical validation
- ViT training claim: Medium - pending replication on larger models and datasets

## Next Checks
1. Evaluate DAMP's effectiveness on additional corruption types not covered in standard benchmarks, including adversarial attacks
2. Conduct ablation studies to isolate the impact of multiplicative perturbations versus other training components
3. Test DAMP on larger ViT variants (e.g., ViT-Large) and compare training dynamics with and without standard augmentations