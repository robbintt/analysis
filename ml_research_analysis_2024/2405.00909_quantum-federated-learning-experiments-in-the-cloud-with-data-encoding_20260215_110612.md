---
ver: rpa2
title: Quantum Federated Learning Experiments in the Cloud with Data Encoding
arxiv_id: '2405.00909'
source_url: https://arxiv.org/abs/2405.00909
tags: []
core_contribution: This paper presents a proof-of-concept implementation of Quantum
  Federated Learning (QFL) on cloud platforms using IBM Qiskit, addressing the challenge
  of training quantum models across decentralized datasets while preserving privacy.
  The core method employs amplitude encoding to transform genomic data into quantum
  states, which are then processed through variational quantum circuits using the
  Quantum Circuit Neural Network (QCNN) approach.
---

# Quantum Federated Learning Experiments in the Cloud with Data Encoding

## Quick Facts
- arXiv ID: 2405.00909
- Source URL: https://arxiv.org/abs/2405.00909
- Reference count: 13
- Primary result: Weighted averaging aggregation achieves best QFL performance, with global model accuracy matching or exceeding highest-performing clients

## Executive Summary
This paper presents a proof-of-concept implementation of Quantum Federated Learning (QFL) on cloud platforms using IBM Qiskit, addressing the challenge of training quantum models across decentralized datasets while preserving privacy. The core method employs amplitude encoding to transform genomic data into quantum states, which are then processed through variational quantum circuits using the Quantum Circuit Neural Network (QCNN) approach. Three aggregation schemes—Simple Averaging, Weighted Averaging, and Best Pick—are evaluated for combining client model updates at a central server. Experiments using genomic datasets show that the Weighted Averaging method achieves the best performance, with the global model accuracy consistently matching or exceeding that of the highest-performing clients, while training loss decreases steadily across epochs.

## Method Summary
The implementation uses amplitude encoding to map genomic features into quantum states, reducing qubit requirements from linear (basis encoding) to logarithmic scale. Each client trains a local quantum model using a Variational Quantum Circuit (VQC) with RealAmplitudes ansatz and COBYLA optimizer on their data partition. The quantum circuits process the encoded data through a RawFeatureVector feature map, and parameters are updated iteratively to minimize mean squared error loss. After local training, clients send their model parameters to a central server, which aggregates them using one of three methods: Simple Averaging, Weighted Averaging (weighted by client performance), or Best Pick (selecting the highest-performing client's parameters). The global model is then distributed back to clients for the next training epoch.

## Key Results
- Weighted averaging aggregation consistently achieves global model accuracy that matches or exceeds the highest-performing client
- Training loss decreases steadily across epochs for all aggregation methods, with Weighted Averaging showing the most stable convergence
- The 200-feature genomic dataset is effectively encoded using just 8 qubits via amplitude encoding, demonstrating qubit efficiency
- QFL implementation is feasible on cloud quantum simulators, though real hardware evaluation is needed for practical deployment

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Amplitude encoding enables compact representation of high-dimensional genomic data in quantum states.
- Mechanism: Classical genomic features are mapped into amplitudes of a quantum state vector, reducing qubit requirements from linear (basis encoding) to logarithmic scale.
- Core assumption: The input data distribution is normalized and suitable for amplitude representation without significant loss of information.
- Evidence anchors:
  - [abstract] "amplitude encoding to transform genomic data into quantum states"
  - [section] "By employing amplitude encoding, we simplify model training with our 200-feature dataset, leveraging only a fraction of the qubits typically required."
  - [corpus] Weak evidence; no corpus papers discuss amplitude encoding specifics.
- Break condition: Data features exceed dynamic range limits for amplitude encoding, causing information loss or numerical instability.

### Mechanism 2
- Claim: Weighted averaging aggregation improves global model performance by prioritizing updates from high-performing clients.
- Mechanism: Client updates are scaled by performance-based weights before averaging, so contributions from better models have greater influence on the global model.
- Core assumption: Performance metrics (e.g., accuracy) reliably reflect the quality and generalizability of local models across the federated network.
- Evidence anchors:
  - [section] "Weighted A veragingimproves the aggregation process by considering the relative importance of each client's update."
  - [section] "This method ensures that the global model takes advantage of the strengths of the higher performing clients while mitigating the impact of the lower performing ones."
  - [corpus] No corpus evidence directly supports this aggregation claim.
- Break condition: Weighting function misestimates client contributions, leading to bias or overfitting to a subset of clients.

### Mechanism 3
- Claim: Variational Quantum Circuits (VQC) with parameterized ansatze enable iterative optimization of quantum models within federated learning.
- Mechanism: Clients use parameterized quantum circuits to encode data and learn weights via classical optimizers (e.g., COBYLA) to minimize loss functions, then share parameters for global aggregation.
- Core assumption: The chosen ansatz structure is expressive enough to capture the problem's complexity within the available qubit budget and circuit depth.
- Evidence anchors:
  - [section] "The VQC uses RawFeatureVector() as a feature map to encode classical data into quantum states."
  - [section] "The optimization is performed by employing the COBYLA() algorithm, a gradient-free optimizer suitable for the noisy conditions of current quantum technology."
  - [corpus] No corpus evidence discusses VQC optimization specifics.
- Break condition: Ansatz underfitting or overfitting relative to the data complexity, or optimizer failing to converge within budget.

## Foundational Learning

- Concept: Quantum amplitude encoding
  - Why needed here: Enables efficient representation of high-dimensional genomic data using fewer qubits, critical for scaling QFL experiments.
  - Quick check question: If a dataset has 200 features, how many qubits are needed for amplitude encoding versus basis encoding?

- Concept: Federated averaging schemes
  - Why needed here: Different aggregation methods (simple, weighted, best pick) affect global model convergence and performance balance across clients.
  - Quick check question: What is the mathematical difference between simple averaging and weighted averaging in federated learning?

- Concept: Variational quantum circuits and optimization
  - Why needed here: QFL relies on iterative parameter updates of quantum circuits; understanding VQC structure and classical optimization is key to implementation.
  - Quick check question: Why might a gradient-free optimizer like COBYLA be chosen over gradient-based methods in current quantum computing contexts?

## Architecture Onboarding

- Component map:
  Data Encoding Layer -> Quantum Circuit Layer -> Classical Optimization -> Federated Coordination -> Cloud Backend

- Critical path:
  1. Encode client data into quantum states.
  2. Run VQC on simulator to compute predictions.
  3. Calculate loss and update parameters via COBYLA.
  4. Send updated parameters to server.
  5. Server aggregates parameters using weighted averaging.
  6. Return global parameters to clients for next epoch.

- Design tradeoffs:
  - Using simulators avoids hardware queuing delays but limits realism and qubit count (max 25 qubits here).
  - Amplitude encoding is qubit-efficient but requires normalized data.
  - Weighted averaging improves performance but adds complexity and potential bias if performance metrics are noisy.

- Failure signatures:
  - Convergence stalls: Likely optimizer or ansatz expressiveness issues.
  - Degraded accuracy on certain clients: Possible imbalance in weighted averaging or data distribution mismatch.
  - High simulator queue times: Consider switching to smaller ansatz or reducing circuit depth.

- First 3 experiments:
  1. Run QFL with amplitude encoding on a small synthetic dataset; verify correct qubit usage and data transformation.
  2. Implement simple averaging aggregation and confirm global model accuracy falls within client performance range.
  3. Switch to weighted averaging; tune weighting function to prioritize higher-performing clients and observe performance gains.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of QFL compare between different quantum hardware backends (e.g., superconducting vs. trapped-ion) when moving from simulators to real quantum devices?
- Basis in paper: [inferred] The paper mentions using IBM's quantum cloud platform and Qiskit simulators, but does not evaluate performance on actual quantum hardware or compare different hardware types.
- Why unresolved: The paper only uses simulators and does not test on real quantum hardware, leaving the question of hardware-dependent performance unanswered.
- What evidence would resolve it: Experimental results comparing QFL performance across different quantum hardware backends (IBM, IonQ, Rigetti) when running on actual quantum devices.

### Open Question 2
- Question: What is the optimal number of qubits needed for effective amplitude encoding of genomic datasets in QFL, considering the trade-off between information capacity and quantum circuit depth?
- Basis in paper: [explicit] The paper states "amplitude encoding emerges as a more efficient alternative" and "our 200-feature genomic dataset can be effectively encoded using just 8 qubits" but doesn't explore the optimal qubit count or provide a systematic analysis.
- Why unresolved: While the paper demonstrates amplitude encoding with 8 qubits for their specific dataset, it doesn't provide a framework for determining the optimal qubit count for different dataset sizes or explore the theoretical limits.
- What evidence would resolve it: A comprehensive study varying qubit counts for different dataset sizes, measuring performance metrics (accuracy, training time) to identify the optimal encoding strategy.

### Open Question 3
- Question: How does the choice of optimizer (e.g., COBYLA vs. gradient-based methods) impact the convergence speed and final accuracy of QFL models in practice?
- Basis in paper: [explicit] The paper states "The optimization is performed by employing the COBYLA() algorithm, a gradient-free optimizer suitable for the noisy conditions of current quantum technology" but does not compare it with other optimization strategies.
- Why unresolved: The paper selects COBYLA but doesn't benchmark it against alternative optimizers or provide theoretical justification for this choice in the QFL context.
- What evidence would resolve it: Experimental results comparing COBYLA with gradient-based optimizers (Adam, SGD) and other gradient-free methods (Nelder-Mead, Powell) across multiple QFL scenarios.

## Limitations
- Limited to simulator evaluation without real quantum hardware testing, restricting assessment of noise and decoherence effects
- No statistical significance testing or error bars reported for accuracy metrics
- Unvalidated generalization to larger qubit counts and different data distributions

## Confidence
- QFL feasibility and weighted averaging performance: Medium confidence (limited validation, no independent replication)
- Amplitude encoding mechanism: Low confidence (no comparative analysis with alternatives)
- VQC optimization approach: Low confidence (no ablation studies on ansatz expressiveness)

## Next Checks
1. Reproduce experiments on real IBM quantum hardware (e.g., ibmq_qasm_simulator) to assess noise sensitivity and verify simulator results.
2. Conduct ablation studies varying ansatz depth and width to determine minimum requirements for maintaining accuracy.
3. Test aggregation methods under non-i.i.d. data splits to evaluate robustness in realistic federated scenarios.