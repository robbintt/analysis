---
ver: rpa2
title: Bag of Tricks to Boost Adversarial Transferability
arxiv_id: '2401.08734'
source_url: https://arxiv.org/abs/2401.08734
tags:
- adversarial
- attack
- transferability
- attacks
- step
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work studies adversarial transferability in deep neural networks.
  The authors identify that standard hyperparameters like iteration count, step size,
  and momentum decay can significantly impact attack performance, motivating a systematic
  exploration.
---

# Bag of Tricks to Boost Adversarial Transferability
## Quick Facts
- arXiv ID: 2401.08734
- Source URL: https://arxiv.org/abs/2401.08734
- Reference count: 40
- Primary result: Proposed tricks improve adversarial transferability by up to 19.9% against strong defenses on ImageNet

## Executive Summary
This paper investigates how standard hyperparameters in adversarial attacks affect transferability across deep neural networks. The authors systematically explore iteration count, step size, and momentum decay, finding they significantly impact attack success. They propose multiple practical tricks including random global momentum initialization, scheduled step sizes, dual examples with ensemble strategies, spectral-based input transformations targeting high-frequency components, and model shuffling. These tricks are evaluated across CNNs and transformers on ImageNet, showing consistent improvements in attack success rates. The approach also generalizes to audio-visual models, demonstrating broad applicability.

## Method Summary
The authors conduct a systematic exploration of how standard hyperparameters affect adversarial transferability in deep neural networks. They identify that iteration count, step size, and momentum decay can significantly impact attack performance. Building on this foundation, they propose several practical tricks: random global momentum initialization to better explore the perturbation space, scheduled step sizes to balance convergence and transferability, dual examples with ensemble strategies for richer gradient estimation, spectral-based input transformations targeting high-frequency components, and ensemble strategies like gradient alignment and model shuffling. These techniques are evaluated on ImageNet with multiple CNN and transformer models, demonstrating consistent improvements in attack success rates, particularly when combined.

## Key Results
- Random global momentum initialization improves transferability by better exploring the perturbation space
- Scheduled step sizes balance convergence and transferability across attack iterations
- Combined tricks achieve up to 19.9% improvement against strong defenses
- Approach validated across both CNN and transformer architectures, plus audio-visual models

## Why This Works (Mechanism)
The effectiveness stems from addressing fundamental limitations in standard adversarial attack approaches. Random momentum initialization helps escape local minima and explore diverse perturbation directions that transfer better across models. Scheduled step sizes prevent premature convergence while maintaining attack momentum throughout iterations. Spectral transformations target high-frequency components that are often poorly aligned across different architectures, exploiting universal vulnerabilities. Dual examples and ensemble strategies provide richer gradient information that captures more diverse decision boundaries. The combination of these tricks creates perturbations that exploit both common architectural weaknesses and domain-specific vulnerabilities across model families.

## Foundational Learning
**Adversarial Transferability**: Why needed - Understanding how adversarial examples crafted for one model can fool others is crucial for black-box attacks. Quick check - Verify attacks transfer between different architectures on held-out model pairs.
**Momentum Iterative Method**: Why needed - Momentum helps escape poor local maxima during attack optimization. Quick check - Compare attack success with and without momentum across multiple iterations.
**Spectral Domain Analysis**: Why needed - High-frequency components often reveal universal vulnerabilities across architectures. Quick check - Measure attack success when targeting different frequency bands separately.

## Architecture Onboarding
**Component Map**: Input images -> Preprocessing (spectral transform) -> Attack optimization (momentum + scheduled step) -> Ensemble evaluation (multiple models) -> Output adversarial examples
**Critical Path**: Input -> Spectral preprocessing -> Momentum iterative attack -> Ensemble model evaluation -> Transferability assessment
**Design Tradeoffs**: Higher iteration counts improve convergence but may reduce transferability; larger step sizes increase attack strength but risk instability; ensemble size improves robustness but increases computational cost
**Failure Signatures**: Poor transferability when perturbations align too closely with source model's decision boundary; failure to generalize when spectral transformations mismatch target model's frequency response
**First Experiments**: 1) Ablation study of individual tricks on ResNet-vgg pairs, 2) Transferability across CNN-transformer pairs with varying ensemble sizes, 3) Computational overhead analysis when combining all tricks

## Open Questions the Paper Calls Out
None

## Limitations
- Empirical improvements require extensive hyperparameter tuning, raising questions about generalizability
- Effectiveness may diminish against sophisticated defenses or evolving architectures
- Primarily validated on ImageNet, uncertain performance in other domains like medical imaging
- Computational overhead of multiple tricks not extensively characterized

## Confidence
**High**: Core observation that hyperparameters significantly impact transferability, supported by systematic ablation studies
**Medium**: Individual effectiveness of proposed tricks, as improvements vary across model pairs and defenses
**Medium**: Synergistic effects of combining tricks, as some combinations show complex interactions

## Next Checks
1. Conduct ablation studies on computational overhead when applying multiple tricks simultaneously, measuring attack runtime and resource requirements
2. Test transferability of enhanced attacks across diverse domains beyond ImageNet, including medical imaging and low-resolution tasks
3. Evaluate robustness of combined trick effectiveness against emerging adversarial training methods and certified defenses targeting frequency-domain perturbations