---
ver: rpa2
title: 'State Soup: In-Context Skill Learning, Retrieval and Mixing'
arxiv_id: '2406.08423'
source_url: https://arxiv.org/abs/2406.08423
tags:
- state
- learning
- mixing
- task
- states
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper explores the concept of "state soups" for improving in-context
  learning in gated-linear recurrent neural networks, specifically Mamba-2.8b. The
  authors investigate whether internal states can be treated as task vectors that
  can be stored, retrieved, and linearly combined to enhance performance.
---

# State Soup: In-Context Skill Learning, Retrieval and Mixing

## Quick Facts
- arXiv ID: 2406.08423
- Source URL: https://arxiv.org/abs/2406.08423
- Reference count: 32
- Key outcome: State soups improve few-shot learning performance in Mamba-2.8b through task state clustering, retrieval, and mixing

## Executive Summary
This paper introduces "state soups" - a technique for improving in-context learning in gated-linear recurrent neural networks by treating internal states as task vectors that can be stored, retrieved, and linearly combined. The authors demonstrate that states from the same task cluster together in low-dimensional projections, enabling effective task retrieval even from small k-shot demonstrations. By mixing states from multiple demonstrations, the approach outperforms standard in-context learning, particularly when using A-decay mixing that accounts for sequential dependencies in the data.

## Method Summary
The method involves processing demonstration examples through Mamba-2.8b to extract internal states, creating a library of task-specific states. For task retrieval, query states from k-shot examples are compared to the library using cosine similarity to find the most similar task state. For state mixing, states from multiple demonstrations are averaged (either by simple mean or A-decay mixing that accounts for the sequential nature of SSMs). The mixed state is then used as the initial state for processing test sequences. Experiments are conducted on 6 main ICL tasks plus 4 additional tasks for clustering analysis.

## Key Results
- States from the same task cluster together in 2D t-SNE projections, enabling effective task retrieval
- Query states from k-shot demonstrations can retrieve the correct task state with high accuracy, even for small k
- Mixing states from multiple demonstrations improves few-shot learning performance, with A-decay mixing outperforming mean mixing for sequential data
- State mixing achieves performance on par with or better than processing full 32-shot demonstrations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Internal states of Mamba-2.8b can be treated as task vectors for retrieval and mixing
- Mechanism: The gated-linear recurrence in Mamba creates a linear relationship between input tokens and internal states, allowing states to be interpolated and combined linearly without disrupting the model's internal representations
- Core assumption: The linearity of recurrence means that a weighted average of states corresponds to processing a weighted average of the inputs that generated those states
- Evidence anchors:
  - [abstract] "Building on parallels between fine-tuning and in-context learning, we investigate whether we can treat internal states as task vectors that can be stored, retrieved, and then linearly combined, exploiting the linearity of recurrence"
  - [section] "Observe that due to the linearity of SSM, for each k ∈ {1, . . . t− 1} we can write this equation as: f (x1, . . . , xt) = f (xk+1, . . . , xt) + (Qt−k k′=1 Ak′) f (x1, . . . , xk)"
- Break condition: The linearity assumption breaks down when multiple layers are stacked, as intermediate layer outputs depend on previous layer states, making A-decay mixing only an approximation

### Mechanism 2
- Claim: Task-specific states cluster together in a low-dimensional projection, enabling retrieval
- Mechanism: The internal state representations encode task-specific information in a way that preserves semantic similarity, allowing states from the same task to be grouped together using dimensionality reduction techniques
- Core assumption: The state vector at a given layer contains sufficient information to distinguish between different tasks
- Evidence anchors:
  - [section] "we take an intermediate layer from every state in our skill library, and we project it to two dimensions using T-SNE. As a result, we obtain a proper clustering, where states corresponding to the same task are grouped together"
  - [section] "we check if a query vector qk τ obtained by processing a k-shot example from a taskτ from the skill library can be correctly identified as coming from τ"
- Break condition: If the task representation is distributed across multiple layers or requires non-linear transformations to be decoded, simple 2D projection may not capture the task distinctions

### Mechanism 3
- Claim: Mixing states from multiple demonstrations improves few-shot learning performance
- Mechanism: By averaging states from multiple k-shot demonstrations, the model can aggregate the information from different examples, effectively creating a more robust representation of the task
- Core assumption: Each state captures task-relevant information that can be combined linearly to improve performance
- Evidence anchors:
  - [section] "our simple mixing strategy (blue line) mixes 32/k states, each obtained by independently processing k examples. As such, mixing always uses 32 examples in total. We observe that although mixing 32 1-shot states does not lead to great results, mixtures of 4-shot states are already on par or even slightly better than processing the whole 32-shot at once"
  - [section] "We use qk τ to retrieve the most similar state from the library, which is then mixed with the query state. The mixed state is finally used as the initial state for processing the test sample"
- Break condition: If the states contain conflicting information or if the mixing weights are not appropriate for the specific task combination, performance may degrade

## Foundational Learning

- Concept: Gated-linear recurrent neural networks
  - Why needed here: Understanding how Mamba processes sequences and maintains internal states is crucial for grasping why state interpolation works
  - Quick check question: What is the key difference between gated-linear recurrences and traditional RNNs in terms of computational complexity?

- Concept: Linear state-space models and their properties
  - Why needed here: The paper relies on the linearity property to justify state interpolation and mixing
  - Quick check question: How does the linearity of SSMs enable efficient computation of the Qk Ak′ matrix used in A-decay mixing?

- Concept: Dimensionality reduction techniques (t-SNE, PCA)
  - Why needed here: The paper uses these techniques to visualize and analyze the clustering of task states
  - Quick check question: What is the key difference between t-SNE and PCA in terms of how they preserve information during dimensionality reduction?

## Architecture Onboarding

- Component map: Mamba-2.8b architecture consists of multiple SSM layers, each with its own state vector. The paper focuses on the 32nd layer for state retrieval and mixing experiments. The model uses a GPT-NeoX-20B tokenizer and processes sequences of varying lengths for different tasks.

- Critical path: For state mixing experiments, the critical path is: process k examples → obtain state → mix with other states → use mixed state as initial state for test sequence processing. For task retrieval, the critical path is: process k-shot example → obtain query state → find nearest neighbor in library → use retrieved state for test sequence.

- Design tradeoffs: The paper chooses to use a single intermediate layer (32nd out of 64) for state retrieval, which may not capture the full task representation but simplifies the implementation. The mixing strategies (mean mixing vs A-decay mixing) represent different tradeoffs between simplicity and accounting for sequential dependencies.

- Failure signatures: Poor performance in state mixing experiments could indicate that the states are not sufficiently task-specific or that the mixing weights are not optimal. Failure in task retrieval could indicate that the task information is not well-encoded in the chosen layer or that the dimensionality reduction is not capturing the relevant distinctions.

- First 3 experiments:
  1. Verify state clustering: Process a small set of states from different tasks and visualize their clustering using t-SNE to confirm that states from the same task group together
  2. Test task retrieval: Create a small library of states and test if query states from k-shot examples can correctly retrieve the corresponding task states
  3. Validate A-decay mixing: Implement the A-decay mixing approach on a simple sequential task and compare its performance against mean mixing and sequential processing

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of state soup techniques scale with the number of states in the library and the diversity of tasks represented?
- Basis in paper: [inferred] The paper mentions using 10 states per task in their retrieval experiments but doesn't explore how performance changes with larger or more diverse libraries.
- Why unresolved: The experiments were limited to a small, fixed number of tasks and states per task, making it unclear how the approach would perform with more complex or numerous tasks.
- What evidence would resolve it: Experiments varying the size and diversity of the state library while measuring retrieval accuracy and mixing performance across a broader range of tasks.

### Open Question 2
- Question: What is the theoretical limit of task retrieval accuracy using query states from different layers of the model?
- Basis in paper: [explicit] The paper notes that intermediate layers encode task information most reliably but doesn't systematically investigate which layers provide optimal retrieval performance.
- Why unresolved: The paper only uses the 32nd layer for retrieval experiments without exploring how retrieval accuracy varies across different layers or combining information from multiple layers.
- What evidence would resolve it: A systematic study measuring retrieval accuracy across all layers and testing layer combinations to determine optimal retrieval strategies.

### Open Question 3
- Question: How does the A-decay mixing approach compare to other state mixing methods when applied to tasks with varying degrees of temporal dependency?
- Basis in paper: [explicit] The paper introduces A-decay mixing and compares it to mean mixing and sequential processing, but only tests on relatively simple sequential tasks.
- Why unresolved: The experiments focus on short sequences without exploring how mixing strategies perform on tasks with different temporal characteristics or longer sequences.
- What evidence would resolve it: Experiments applying different mixing strategies to tasks with varying temporal dependencies and sequence lengths to determine when A-decay mixing is most effective.

## Limitations

- The approach's effectiveness is limited to gated-linear recurrent neural networks where the linearity assumption holds
- Scalability concerns arise with maintaining and searching large state libraries for practical applications
- The temporal stability of mixed states over long sequences has not been thoroughly investigated

## Confidence

**High Confidence**: The claim that states from the same task cluster together in low-dimensional projections is well-supported by direct visualization evidence and systematic retrieval experiments.

**Medium Confidence**: The assertion that mixing states improves few-shot learning performance is supported by experimental results, but the specific conditions under which mixing helps versus hurts performance are not fully characterized.

**Low Confidence**: The broader claim that simple linear state interpolation methods can generally improve next-token perplexity and downstream ICL task performance is limited by the narrow task set and model architecture tested.

## Next Checks

1. **Cross-task state compatibility**: Systematically test whether mixing states from semantically similar but technically distinct tasks provides benefits, or whether states are too task-specific to be meaningfully combined across related domains.

2. **State library scaling analysis**: Measure the computational cost and retrieval accuracy degradation as state library size increases from dozens to thousands of tasks, and test whether approximate nearest neighbor methods maintain retrieval quality while improving efficiency.

3. **Temporal stability validation**: Track the performance of mixed states over progressively longer sequences to determine whether the benefits persist or whether state mixing introduces instability in long-range dependencies.