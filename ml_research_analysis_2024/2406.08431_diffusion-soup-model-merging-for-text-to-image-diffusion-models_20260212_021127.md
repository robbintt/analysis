---
ver: rpa2
title: 'Diffusion Soup: Model Merging for Text-to-Image Diffusion Models'
arxiv_id: '2406.08431'
source_url: https://arxiv.org/abs/2406.08431
tags:
- diffusion
- soup
- data
- souping
- trained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Diffusion Soup, a method for aggregating
  text-to-image diffusion models trained on sharded data. The key idea is to average
  the weights of individual models to obtain a single model, enabling training-free
  continual learning and unlearning.
---

# Diffusion Soup: Model Merging for Text-to-Image Diffusion Models

## Quick Facts
- arXiv ID: 2406.08431
- Source URL: https://arxiv.org/abs/2406.08431
- Reference count: 40
- One-line primary result: Averaging weights of diffusion models trained on sharded data produces a single model that outperforms training on the union of all data, enabling continual learning, unlearning, and zero-shot style mixing.

## Executive Summary
This paper introduces Diffusion Soup, a method for aggregating multiple text-to-image diffusion models trained on sharded data by averaging their weights. The key insight is that this weight averaging produces a model that samples from a point approximating the geometric mean of the constituent data distributions, rather than the arithmetic mean. This approach achieves strong empirical performance, outperforming a paragon model trained on the union of all data shards by 30% on domain-sharded data and 59% on aesthetic data, while also enabling anti-memorization guarantees and zero-shot style mixing.

## Method Summary
The method involves fine-tuning a shared pretrained diffusion model (Stable Diffusion 2.1) on individual data shards, then averaging the resulting model weights to create a "soup" model. The averaging is performed in the weight space, leveraging the additive nature of gradient descent updates. Optionally, mixing weights can be optimized greedily to further improve performance. The resulting model inherits properties from all constituent models, enabling continual learning through re-averaging and unlearning by removing specific specialists.

## Key Results
- Diffusion Soup achieves a 30% improvement in Image Reward (.34 → .44) on domain-sharded data compared to a paragon model trained on the union of all shards
- On aesthetic data, Diffusion Soup shows a 59% improvement in IR (.37 → .59) compared to the combined model
- The method enables zero-shot style mixing, generating hybrid styles by blending models finetuned on different style datasets
- Soup models demonstrate anti-memorization properties, with ≤1% performance degradation when removing any specialist

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Averaging weights of diffusion models trained on sharded data produces a model that approximates the geometric mean of constituent data distributions
- **Mechanism:** Diffusion model training involves additive weight updates via gradient descent, allowing a Taylor expansion to show that weighted averages of fine-tuned weights produce a model whose output approximates the geometric mean
- **Core assumption:** Fine-tuned weights are small perturbations around a common pretrained checkpoint
- **Evidence anchors:** Abstract states this approximation; Proposition 1 and proof in section 4.1 support it; weak support from related work on model averaging
- **Break condition:** Large weight shifts during fine-tuning or poor choice of pretrained checkpoint invalidate the geometric mean approximation

### Mechanism 2
- **Claim:** Sampling from the geometric mean of distributions provides anti-memorization guarantees
- **Mechanism:** The geometric mean smooths over individual dataset details, making exact training sample reproduction difficult; aligns with Near Access Freeness framework showing ε-NAF satisfaction
- **Core assumption:** Geometric mean of disjoint datasets' distributions yields sampling distribution statistically far from individual training samples
- **Evidence anchors:** Proposition 3 and surrounding text in section 5.1 link to ε-NAF; abstract mentions anti-memorization guarantees; weak corpus evidence from neighbor papers
- **Break condition:** Significant dataset overlap or poor geometric mean approximation weakens anti-memorization guarantees

### Mechanism 3
- **Claim:** Diffusion Soup enables zero-shot style mixing by blending styles of models finetuned on different shards
- **Mechanism:** Averaging weights from models trained on different style datasets produces a hybrid model sampling from a mixture distribution, implicitly blending styles without hybrid training data
- **Core assumption:** Styles are represented in weight space such that averaging meaningfully combines them
- **Evidence anchors:** Abstract mentions zero-shot style mixing; section 6.2 demonstrates blending Pokemon and FS-COCO styles; no direct corpus evidence
- **Break condition:** If style information isn't linearly separable in weight space or averaging washes out distinctive features, hybrid style generation fails

## Foundational Learning

- **Concept:** Stochastic differential equations (SDEs) and score-based diffusion models
  - **Why needed here:** Theoretical results rely on understanding score function evolution under diffusion and how averaging weights affects sampling distribution
  - **Quick check question:** What is the role of the score function in the backward diffusion process, and how does it relate to the data distribution?

- **Concept:** Geometric vs. arithmetic mean of probability distributions
  - **Why needed here:** Paper hinges on distinction that averaging weights samples from geometric mean, not arithmetic mean, key to performance and anti-memorization properties
  - **Quick check question:** How does sampling from the geometric mean of two distributions differ from sampling from their arithmetic mean in terms of likelihood of reproducing training data?

- **Concept:** Near Access Freeness (NAF) and differential privacy concepts
  - **Why needed here:** Anti-memorization claim grounded in NAF framework, requiring understanding to evaluate validity
  - **Quick check question:** What is the ε-NAF condition, and how does it prevent a model from reproducing training samples?

## Architecture Onboarding

- **Component map:** Text prompt → CLIP text encoder → timestep conditioning → denoising U-Net (averaged weights) → image generation
- **Critical path:** Prompt → CLIP text encoder → timestep conditioning → denoising U-Net (averaged weights) → image generation
- **Design tradeoffs:**
  - Pro: No additional inference cost vs. ensembling; enables continual learning/unlearning via re-averaging
  - Con: Requires storing and averaging multiple finetuned model checkpoints; greedy souping adds optimization overhead
- **Failure signatures:**
  - Performance drops if weight perturbations are too large (Taylor approximation fails)
  - Style mixing fails if finetuned styles aren't well-represented in weight space
  - Anti-memorization weakens if datasets overlap or geometric mean is poorly approximated
- **First 3 experiments:**
  1. **Ablation on step count and learning rate:** Train specialists with varying steps and learning rates; verify souping still outperforms all baselines (as in Fig. 7 left)
  2. **Greedy vs. uniform souping on specialists:** Compare TIFA/IR/CLIP scores of uniform soup, greedy soup, and reverse greedy soup on domain-sharded data
  3. **Unlearning robustness test:** Remove each specialist from the soup one at a time; measure drop in performance to confirm ≤1% degradation

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the choice of hyperparameters (e.g., learning rate, number of steps) affect the performance of Diffusion Soup compared to the Combined Model Paragon?
- **Basis in paper:** [explicit] The paper discusses hyperparameter choices and their impact on model performance, mentioning specific learning rates and step sizes used for finetuning
- **Why unresolved:** While the paper shows that Diffusion Soup outperforms the Combined Model Paragon under certain hyperparameter settings, it does not explore the full range of possible hyperparameters or provide a comprehensive analysis of their effects
- **What evidence would resolve it:** Conducting extensive hyperparameter searches for both Diffusion Soup and the Combined Model Paragon, and comparing their performance across various settings, would provide a clearer understanding of the optimal hyperparameter choices for each approach

### Open Question 2
- **Question:** Can Diffusion Soup be extended to other generative models beyond diffusion models, such as GANs or VAEs?
- **Basis in paper:** [inferred] The paper focuses on applying Diffusion Soup to text-to-image diffusion models, but the underlying concept of averaging model weights could potentially be applicable to other generative model architectures
- **Why unresolved:** The paper does not investigate the feasibility or performance of Diffusion Soup when applied to other generative models. Further research is needed to determine if the benefits observed in diffusion models can be replicated in different model architectures
- **What evidence would resolve it:** Experimenting with Diffusion Soup on various generative models, such as GANs or VAEs, and comparing their performance to traditional training methods, would provide insights into the generalizability of the approach

### Open Question 3
- **Question:** How does the choice of data shards and their composition affect the performance of Diffusion Soup?
- **Basis in paper:** [explicit] The paper discusses using different data shards (e.g., domain-specific, aesthetic) and their impact on model performance, but does not explore the optimal composition or selection of shards
- **Why unresolved:** While the paper demonstrates the benefits of using data shards, it does not provide guidelines for selecting or composing shards to maximize performance. Further investigation is needed to understand the relationship between shard composition and model quality
- **What evidence would resolve it:** Conducting experiments with various shard compositions, sizes, and selection strategies, and analyzing their impact on Diffusion Soup's performance, would provide insights into the optimal data shard configurations

## Limitations
- Theoretical guarantees depend on fine-tuning producing small weight perturbations, but perturbation magnitude is not empirically verified
- Anti-memorization claims lack direct empirical validation beyond citing NAF framework
- Zero-shot style mixing is demonstrated qualitatively but not quantitatively measured
- Paper focuses on image generation tasks without addressing potential limitations in other domains or model architectures

## Confidence

- **High confidence:** The core observation that averaging fine-tuned weights produces a model outperforming individual specialists is well-supported by experimental results across multiple datasets and metrics
- **Medium confidence:** Theoretical mechanism linking weight averaging to geometric mean sampling is mathematically sound but relies on unverified assumptions about small weight perturbations
- **Low confidence:** Anti-memorization guarantees are theoretically grounded but lack direct empirical validation beyond theoretical framework citation

## Next Checks

1. **Empirical perturbation analysis:** Measure the magnitude of weight changes during fine-tuning across different datasets and learning rates to verify that perturbations remain small enough for the geometric mean approximation to hold

2. **Direct memorization testing:** Evaluate the soup model on memorization metrics (e.g., FID on training vs. test sets) to empirically verify the anti-memorization claims beyond theoretical guarantees

3. **Style mixing quantification:** Develop quantitative metrics for style mixing quality (e.g., CLIP similarity to target style combinations) to move beyond qualitative demonstrations of zero-shot style blending