---
ver: rpa2
title: 'Incorporating uncertainty quantification into travel mode choice modeling:
  a Bayesian neural network (BNN) approach and an uncertainty-guided active survey
  framework'
arxiv_id: '2406.10948'
source_url: https://arxiv.org/abs/2406.10948
tags: []
core_contribution: This study addresses the lack of uncertainty quantification in
  deep learning-based travel mode choice models, which can lead to misguidance when
  predictions are made for out-of-distribution scenarios. The authors propose a Bayesian
  neural network-based travel mode prediction (BTMP) model that quantifies prediction
  uncertainty using Monte Carlo dropout.
---

# Incorporating uncertainty quantification into travel mode choice modeling: a Bayesian neural network (BNN) approach and an uncertainty-guided active survey framework

## Quick Facts
- arXiv ID: 2406.10948
- Source URL: https://arxiv.org/abs/2406.10948
- Reference count: 0
- Key outcome: Proposed Bayesian neural network with Monte Carlo dropout quantifies prediction uncertainty; uncertainty-guided active survey framework reduces required survey responses by 20%-50% compared to random sampling while achieving the same predictive accuracy.

## Executive Summary
This study addresses the critical gap in uncertainty quantification for deep learning-based travel mode choice models. Traditional deep learning approaches lack the ability to measure confidence in their predictions, which can lead to misguidance when applied to out-of-distribution scenarios. The authors propose a Bayesian neural network-based travel mode prediction (BTMP) model that uses Monte Carlo dropout to quantify prediction uncertainty, enabling the model to identify scenarios where its predictions are unreliable. Additionally, they develop an uncertainty-guided active survey framework that dynamically formulates survey questions targeting high-uncertainty scenarios, iteratively improving the model with fewer data samples.

## Method Summary
The study develops a Bayesian neural network (BTMP) with Monte Carlo dropout for uncertainty quantification in travel mode choice modeling. The BTMP model uses two hidden layers of 128 neurons each with dropout rates of 0.25 and 0.5, respectively. During inference, MC dropout samples different model weight configurations to produce a distribution of predictions, with entropy serving as the uncertainty measure. The uncertainty-guided active survey framework uses these uncertainty estimates to prioritize survey questions, collecting responses to the most informative scenarios first. The model is iteratively retrained with newly collected data, improving accuracy faster than random sampling. Experiments are conducted on synthetic datasets (10,000 OD pairs each) and real-world survey data from a Beijing university (7,367 records).

## Key Results
- BTMP effectively quantifies prediction uncertainty, enabling identification of out-of-distribution scenarios
- Uncertainty-guided active survey framework reduces required survey responses by 20%-50% compared to random sampling
- The framework achieves the same predictive accuracy with significantly fewer data samples, making travel mode surveys more cost-effective
- BTMP outperforms traditional models in handling scenarios with limited training data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: BTMP quantifies prediction uncertainty using MC Dropout, enabling the model to "know" when it lacks confidence in its predictions.
- Mechanism: By applying dropout at both training and inference time, MC Dropout samples different model weight configurations, producing a distribution of predictions. The entropy of this distribution serves as a measure of uncertainty, with higher entropy indicating less confidence.
- Core assumption: Dropout layers in the neural network act as approximate Bayesian inference, capturing epistemic uncertainty due to limited data.
- Evidence anchors: [abstract] "quantifies the uncertainty of travel mode predictions, enabling the model itself to 'know' and 'tell' what it doesn't know"; [section] "Monte Carlo dropout (MC Dropout) is a widely adopted and mainstream method"; [corpus] Weak; no direct citations, but MC Dropout is a well-known technique in Bayesian deep learning literature.
- Break condition: If the dropout rate is too low, the uncertainty estimate may not capture the full epistemic uncertainty; if too high, the model may underperform in accuracy.

### Mechanism 2
- Claim: The uncertainty-guided active survey framework dynamically identifies the most informative data points, reducing the number of required survey responses by 20%-50%.
- Mechanism: The framework uses BTMP's uncertainty estimates to prioritize survey questions that target high-uncertainty scenarios. By iteratively collecting responses to these questions, the model is trained on the most informative data, improving accuracy faster than random sampling.
- Core assumption: Data points with high prediction uncertainty are the most informative for reducing overall model uncertainty and improving generalization.
- Evidence anchors: [abstract] "uncertainty-guided active survey framework... iteratively improving the model with fewer data samples... reduces required survey responses by 20%â€“50%"; [section] "uncertainty-guided active survey framework... dynamically formulates survey questions representing travel mode choice scenarios with high prediction uncertainty"; [corpus] Weak; no direct citations, but the concept of active learning is well-established in machine learning literature.
- Break condition: If the uncertainty estimates are inaccurate or if the model's uncertainty does not correlate with informativeness, the active sampling may not yield efficiency gains.

### Mechanism 3
- Claim: BTMP's architecture, with two hidden layers of 128 neurons each and dropout, balances model complexity and generalization, enabling effective uncertainty quantification.
- Mechanism: The moderate network size prevents overfitting while maintaining enough capacity to capture complex mode choice patterns. Dropout regularizes the model and facilitates uncertainty estimation via MC Dropout.
- Core assumption: The chosen network architecture is sufficient to model the underlying relationships in travel mode choice data without being overly complex.
- Evidence anchors: [section] "The BTMP model takes the attributes of mode choice alternatives as input... The input data is then fed into two hidden layers, each with 128 neurons"; [section] "Dropout is applied to the two hidden layers with probabilities of 0.25 and 0.5 on the first and second hidden layers respectively"; [corpus] Weak; no direct citations, but the architecture choices are standard in deep learning practice.
- Break condition: If the data is too complex for the chosen architecture, the model may underfit; if too simple, it may overfit despite dropout regularization.

## Foundational Learning

- Concept: Bayesian Neural Networks (BNNs)
  - Why needed here: BNNs provide a framework for quantifying uncertainty in deep learning models, which is critical for high-stakes decision-making in transportation planning.
  - Quick check question: How does replacing point estimates with distributions over weights in a neural network enable uncertainty quantification?

- Concept: Monte Carlo Dropout
  - Why needed here: MC Dropout is a practical method for implementing BNNs, allowing uncertainty estimation without significant changes to standard neural network training.
  - Quick check question: Why does applying dropout at inference time (in addition to training) enable uncertainty estimation?

- Concept: Active Learning
  - Why needed here: Active learning strategies focus data collection on the most informative samples, reducing the cost and effort of surveys while improving model performance.
  - Quick check question: How does querying the model for its uncertainty help identify the most informative data points for labeling?

## Architecture Onboarding

- Component map: Input layer (mode attributes) -> Two hidden layers (128 neurons each with dropout) -> Output layer (softmax over modes) -> Uncertainty estimation (MC Dropout) -> Active survey module (uncertainty-guided sampling)
- Critical path: 1. Train BTMP on initial labeled data 2. Use MC Dropout to quantify uncertainty on unlabeled data 3. Select high-uncertainty samples for active survey 4. Collect responses and retrain BTMP 5. Repeat until accuracy threshold or budget limit
- Design tradeoffs: Network depth vs. uncertainty estimation accuracy (deeper networks may capture more complex patterns but could be harder to regularize for reliable uncertainty estimates); Dropout rate vs. model performance (higher dropout rates increase uncertainty estimation but may reduce accuracy if too aggressive); Active sampling vs. random sampling (active sampling is more efficient but relies on accurate uncertainty estimates)
- Failure signatures: Uncertainty estimates are consistently low across all samples (model may be overconfident due to insufficient regularization or architecture limitations); Active sampling does not improve accuracy faster than random sampling (uncertainty estimates may not correlate with informativeness, or model may be too simple to benefit from targeted data collection); Model accuracy plateaus early (initial training data may be insufficient, or architecture may be too limited to capture underlying patterns)
- First 3 experiments: 1. Train BTMP on synthetic data with varying diversity levels and observe uncertainty estimates; verify that higher diversity leads to higher uncertainty 2. Compare BTMP's performance using active sampling vs. random sampling on a synthetic dataset; measure the reduction in required samples for a target accuracy 3. Apply BTMP and active sampling to a real-world travel mode choice dataset; evaluate the efficiency gains in terms of survey cost and model accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the proposed active survey framework compare to other active learning strategies, such as uncertainty sampling or query-by-committee, in terms of data efficiency and model accuracy?
- Basis in paper: [inferred] The paper only compares the proposed uncertainty-guided active survey framework with simple random sampling and random sampling from most frequently visited destinations. It does not compare with other active learning strategies.
- Why unresolved: The paper does not provide a comprehensive comparison of different active learning strategies.
- What evidence would resolve it: A study that compares the performance of the proposed framework with other active learning strategies using the same datasets and evaluation metrics.

### Open Question 2
- Question: How does the proposed framework handle the cold-start problem, where the model has limited initial training data and may struggle to accurately quantify uncertainty?
- Basis in paper: [inferred] The paper does not explicitly discuss how the framework handles the cold-start problem. It only mentions that the initial training data is randomly selected from the data pool.
- Why unresolved: The paper does not provide a detailed explanation of how the framework addresses the cold-start problem.
- What evidence would resolve it: A study that investigates the performance of the framework with different initial training data sizes and explores strategies to mitigate the cold-start problem.

### Open Question 3
- Question: How does the proposed framework perform in real-world applications with more complex travel mode choice scenarios, such as those involving multiple modes, transfer options, and dynamic travel conditions?
- Basis in paper: [explicit] The paper only tests the framework using synthetic datasets and a real-world dataset from a single university. It does not explore more complex travel mode choice scenarios.
- Why unresolved: The paper does not provide evidence of the framework's performance in real-world applications with more complex travel mode choice scenarios.
- What evidence would resolve it: A study that applies the framework to real-world travel mode choice data from different cities or regions with more complex travel mode choice scenarios and evaluates its performance.

## Limitations
- The exact implementation details of the synthetic data generation process are not fully specified, which may affect reproducibility of the results
- The specific training hyperparameters (learning rate, optimizer, epochs) are not provided, potentially impacting model performance
- The active survey framework's effectiveness may be sensitive to the specific uncertainty estimation method used (MC Dropout), which has its own limitations in capturing certain types of uncertainty

## Confidence

- **High confidence**: The core mechanism of using MC Dropout for uncertainty quantification in BTMP is well-established in the Bayesian deep learning literature
- **Medium confidence**: The effectiveness of the uncertainty-guided active survey framework in reducing required samples by 20%-50% is supported by experiments but may vary with different datasets and uncertainty estimation methods
- **Medium confidence**: The architectural choices (two hidden layers of 128 neurons each, dropout rates of 0.25 and 0.5) are reasonable but not extensively validated across different travel mode choice scenarios

## Next Checks

1. **Synthetic Data Validation**: Generate multiple synthetic datasets with varying diversity levels and distributions to test BTMP's uncertainty quantification across different scenarios
2. **Hyperparameter Sensitivity Analysis**: Conduct experiments varying dropout rates, network sizes, and training hyperparameters to understand their impact on uncertainty estimation and active sampling efficiency
3. **Real-World Dataset Extension**: Apply the BTMP model and active survey framework to additional real-world travel mode choice datasets from different geographic regions to assess generalizability and identify potential limitations