---
ver: rpa2
title: 'Chitchat as Interference: Adding User Backstories to Task-Oriented Dialogues'
arxiv_id: '2402.15248'
source_url: https://arxiv.org/abs/2402.15248
tags: []
core_contribution: This paper addresses the challenge of user chitchat interference
  in task-oriented dialogues (TODs), where users introduce personal stories or non-task-related
  information that can disrupt the conversation flow. The authors propose an automated
  method to augment the MultiWOZ dataset with user backstories and corresponding system
  reactions, creating a testbed for TOD systems to handle such interferences.
---

# Chitchat as Interference: Adding User Backstories to Task-Oriented Dialogues

## Quick Facts
- arXiv ID: 2402.15248
- Source URL: https://arxiv.org/abs/2402.15248
- Authors: Armand Stricker; Patrick Paroubek
- Reference count: 0
- Key outcome: Automated dataset augmentation with user backstories improves TOD systems' handling of chitchat while maintaining task completion

## Executive Summary
This paper addresses the challenge of user chitchat interference in task-oriented dialogues, where personal stories or non-task-related information disrupt conversation flow. The authors propose an automated method to augment the MultiWOZ dataset with user backstories and corresponding system reactions, creating a testbed for TOD systems to handle such interferences. Using few-shot prompting with Llama-2-70B, they generate these augmentations from the FusedChat dataset, which contains human-generated chitchat exchanges. The augmented dataset includes user turns with backstories and system responses that acknowledge the backstory while continuing the task.

## Method Summary
The authors use few-shot prompting with Llama-2-70B to automatically augment the MultiWOZ dataset by generating user backstories and corresponding system reactions. They source chitchat exchanges from the FusedChat dataset, which contains human-generated conversations. The augmentation process creates user turns that include personal stories or non-task-related information, paired with system responses that acknowledge these backstories while maintaining focus on the task. The augmented dataset is then used to train TOD models, with the goal of improving their ability to handle chitchat interference while maintaining task completion performance.

## Key Results
- The standard TOD model trained on MultiWOZ alone handles chitchat but doesn't adequately address user backstories
- Models trained on FusedChat dialogues tend to focus on chitchat at the expense of task completion
- The model trained on the augmented dataset performs comparably to standard TOD models on task completion while providing better acknowledgment of user backstories

## Why This Works (Mechanism)
The mechanism works by exposing TOD models to realistic instances of chitchat interference during training, allowing them to learn how to acknowledge personal stories while maintaining task focus. The augmentation creates a balanced training signal where both task completion and social acknowledgment are important. The few-shot prompting approach with Llama-2-70B generates contextually appropriate backstories that are grounded in real human chitchat patterns from FusedChat, making the augmented data more realistic than purely synthetic generation.

## Foundational Learning
- **Task-oriented dialogue systems**: Why needed - Core domain being improved; Quick check - Can the system successfully complete restaurant and hotel bookings
- **Dataset augmentation**: Why needed - Creates training data for scenarios not present in original MultiWOZ; Quick check - Does the augmented dataset contain realistic backstory patterns
- **Few-shot prompting**: Why needed - Enables generation of contextually appropriate backstories without extensive fine-tuning; Quick check - Are the generated backstories coherent and relevant to the conversation context
- **Human evaluation methodology**: Why needed - Assesses quality of model responses beyond automated metrics; Quick check - Do human judges prefer responses that acknowledge backstories

## Architecture Onboarding

**Component Map:**
MultiWOZ -> Llama-2-70B (few-shot prompting) -> Augmented dataset -> TOD model training -> Evaluation

**Critical Path:**
FusedChat → Backstory generation → System response generation → Model training → Human evaluation

**Design Tradeoffs:**
- Automated augmentation vs manual annotation: Speed and scalability vs quality control
- Few-shot prompting vs fine-tuning: Lower computational cost vs potentially more precise control
- Task completion vs backstory acknowledgment: Balancing functional requirements with conversational quality

**Failure Signatures:**
- Generated backstories that are irrelevant to the conversation context
- System responses that ignore the task in favor of addressing the backstory
- Models that acknowledge backstories but fail to complete the booking task

**First Experiments:**
1. Evaluate baseline MultiWOZ-trained model on augmented test set to measure chitchat interference impact
2. Train model on augmented dataset and compare task completion metrics to baseline
3. Conduct human evaluation comparing responses from baseline vs augmented model on backstory handling

## Open Questions the Paper Calls Out
None

## Limitations
- The automated augmentation approach may introduce inconsistencies or biases in generated backstories and responses
- Human evaluation methodology lacks detail on annotator numbers, agreement scores, and evaluation criteria
- The study only evaluates two baseline models, limiting contextualization of improvements

## Confidence
- **High confidence**: The core methodology of dataset augmentation using LLM prompting is sound and well-described
- **Medium confidence**: The general trend that models trained on augmented data better handle backstories while maintaining task performance
- **Low confidence**: Specific quantitative improvements and the absolute quality of generated responses

## Next Checks
1. Conduct ablation studies with varying amounts of augmented data to determine optimal augmentation ratios and assess the relationship between augmentation volume and performance gains
2. Implement blind human evaluations with detailed annotation guidelines and calculate inter-annotator agreement scores to validate the preference judgments
3. Test the augmented models on an entirely separate test set of real user dialogues containing natural chitchat to verify generalization beyond the synthetic augmentations