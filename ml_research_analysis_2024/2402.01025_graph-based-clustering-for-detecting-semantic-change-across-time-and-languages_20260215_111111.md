---
ver: rpa2
title: Graph-based Clustering for Detecting Semantic Change Across Time and Languages
arxiv_id: '2402.01025'
source_url: https://arxiv.org/abs/2402.01025
tags:
- word
- time
- semantic
- change
- sense
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of detecting semantic change
  in word meanings over time and across languages. Previous approaches using contextualized
  embeddings and clustering methods struggle to capture low-frequency word senses
  and produce time-independent clusters, hindering the analysis of semantic change.
---

# Graph-based Clustering for Detecting Semantic Change Across Time and Languages

## Quick Facts
- arXiv ID: 2402.01025
- Source URL: https://arxiv.org/abs/2402.01025
- Reference count: 40
- This work proposes a graph-based clustering approach that substantially outperforms previous methods in detecting semantic change across four languages.

## Executive Summary
This work addresses the challenge of detecting semantic change in word meanings over time and across languages. Previous approaches using contextualized embeddings and clustering methods struggle to capture low-frequency word senses and produce time-independent clusters, hindering the analysis of semantic change. The authors propose a graph-based clustering approach that leverages temporal and spatial dynamic graphs to represent changes in word meanings. Their method introduces a novel clustering strategy that generates time-dependent sense clusters and employs a neighbor-based distance metric to capture the semantics of each sense cluster. The approach is evaluated on the SemEval2020 binary classification task, where it substantially outperforms previous methods in detecting semantic change across four languages (English, German, Latin, and Swedish). Additionally, the authors demonstrate the approach's ability to visualize semantic changes in both intra-language and inter-language setups, enabling the study of how word meanings evolve and diverge across languages over time.

## Method Summary
The proposed approach uses graph-based clustering to create time-dependent sense clusters from contextualized embeddings, iteratively merging clusters based on centroid distance thresholds to preserve low-frequency senses. A neighbor-based distance metric computes semantic similarity between clusters by considering their k-nearest neighbors rather than just centroids. Temporal dynamic graphs track semantic change by computing pairwise similarities across time periods using bipartite matching, distinguishing between acquisition and loss of meanings based on threshold criteria. The method is evaluated on SemEval2020 Task 1 for binary classification and ranking of semantic change across English, German, Latin, and Swedish.

## Key Results
- Substantially outperforms previous methods on SemEval2020 binary classification task for detecting semantic change
- Successfully detects semantic change across four languages (English, German, Latin, and Swedish)
- Demonstrates ability to visualize semantic changes in both intra-language and inter-language setups
- Introduces a graph-based clustering approach that generates time-dependent sense clusters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph-based clustering outperforms traditional k-means by creating time-dependent sense clusters.
- Mechanism: The method initializes each embedding as a separate cluster and iteratively merges clusters whose centroids are below a threshold, preserving low-frequency senses that k-means would subsume.
- Core assumption: Time-independent clusters misinterpret senses across corpora due to context variation between 19th and 20th century texts.
- Evidence anchors:
  - [abstract]: "introduce a graph-based clustering approach to capture nuanced changes in both high- and low-frequency word senses across time and languages"
  - [section]: "we found that this method often produces poor sense clusters that fail to capture word senses, particularly problematic when dealing with low-frequency word senses"
  - [corpus]: Weak - no explicit corpus-level evidence provided for this specific mechanism
- Break condition: If the iterative merging threshold is set too high, clusters will merge incorrectly, losing sense distinctions.

### Mechanism 2
- Claim: Neighbor-based distance metric captures semantic similarity better than Euclidean distance by incorporating k-nearest neighbors.
- Mechanism: Similarity between sense clusters is computed by matching k-nearest semantic neighbors rather than just comparing cluster centroids, reducing sensitivity to embedding quality variations.
- Core assumption: The semantics of a cluster are better represented by its nearest neighbors than by its centroid alone.
- Evidence anchors:
  - [abstract]: "employs a neighbor-based distance metric to capture the semantics of each sense cluster"
  - [section]: "our neighbor-based metric does this by computing the similarity between the k semantically nearest neighbors to each cluster centroid"
  - [corpus]: Weak - no corpus-level evidence provided for this specific mechanism
- Break condition: If k is too small, the metric loses robustness; if too large, it becomes computationally expensive without accuracy gains.

### Mechanism 3
- Claim: Temporal dynamic graphs with bipartite matching enable accurate tracking of both acquisition and loss of word senses over time.
- Mechanism: By computing pairwise similarities between sense clusters across time periods using bipartite matching, the approach can distinguish between gaining new meanings and losing existing ones based on threshold criteria.
- Core assumption: Semantic similarity between clusters across time periods accurately reflects whether meanings are preserved, gained, or lost.
- Evidence anchors:
  - [abstract]: "leverages temporal and spatial dynamic graphs to represent changes in word meanings"
  - [section]: "Our goal is to identify meaning changes over time, especially to distinguish between the acquisition and loss of meanings"
  - [corpus]: Weak - no explicit corpus-level evidence provided for this specific mechanism
- Break condition: If the semantic similarity threshold is poorly calibrated, the approach will misclassify meaning changes.

## Foundational Learning

- Concept: Contextualized embeddings and their limitations in semantic change detection
  - Why needed here: The paper addresses why contextualized embeddings coupled with clustering methods underperform static embeddings in detecting semantic change
  - Quick check question: Why do contextualized embeddings struggle with low-frequency word senses when used with traditional clustering methods?

- Concept: Graph-based clustering and iterative merging
  - Why needed here: The approach uses graph-based clustering that iteratively merges clusters based on centroid distance thresholds to preserve sense distinctions
  - Quick check question: How does initializing each embedding as a separate cluster help capture low-frequency word senses?

- Concept: Bipartite matching for cross-time/sense comparison
  - Why needed here: The approach uses bipartite matching to compute similarity between sense clusters across different time periods and languages
  - Quick check question: What problem does bipartite matching solve when comparing sense clusters from different time periods?

## Architecture Onboarding

- Component map:
  Input: Contextualized embeddings from BERT/m-BERT
  Core: Graph-based clustering (iterative merging), bipartite matching, neighbor-based distance metric
  Output: Temporal and spatial dynamic graphs for visualization and semantic change detection

- Critical path:
  1. Generate contextualized embeddings for target words across time periods and languages
  2. Apply graph-based clustering to create time-dependent sense clusters
  3. Compute sense cluster similarities using neighbor-based distance metric and bipartite matching
  4. Detect semantic change using threshold-based criteria on similarity matrices
  5. Visualize changes in temporal/spatial dynamic graphs

- Design tradeoffs:
  - Time-dependent vs time-independent clusters: Time-dependent clusters capture context variation but increase complexity
  - k-nearest neighbors size: Larger k improves robustness but increases computational cost
  - Threshold values: Must be tuned per language; poor calibration leads to misclassification

- Failure signatures:
  - Poor detection accuracy when threshold values are not properly tuned
  - Inability to distinguish between acquisition and loss of meanings when similarity matrices are ambiguous
  - Loss of low-frequency senses if merging threshold is too high

- First 3 experiments:
  1. Test clustering quality on a small synthetic dataset with known low-frequency senses to verify iterative merging preserves them
  2. Compare neighbor-based distance metric vs Euclidean distance on a dataset with ambiguous sense clusters to measure improvement
  3. Run binary classification on SemEval2020 dev set with varying k values to find optimal neighbor count for accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the embedding quality of m-BERT across different languages impact the performance of the proposed approach in the ranking task, and what specific improvements could be made to enhance the detection of fine-grained semantic changes in non-English languages?
- Basis in paper: [inferred] The paper discusses the varying embedding quality of m-BERT across languages, particularly noting its superiority in English. It suggests that lower-quality embeddings in non-English languages might hinder the approach's performance in the ranking task, which requires quantifying the degree of semantic change.
- Why unresolved: The paper acknowledges the challenge but does not provide specific strategies or evidence to improve embedding quality for non-English languages or to mitigate the impact on the ranking task's performance.
- What evidence would resolve it: Comparative experiments showing the performance of the approach on non-English languages with improved embedding techniques or enhanced multilingual BERT models, alongside a detailed analysis of the correlation between embedding quality and ranking task accuracy.

### Open Question 2
- Question: What are the specific challenges and potential solutions for aligning embedding spaces at the meaning level rather than the word level in the cross-lingual setup, and how would this impact the detection of semantic change across languages?
- Basis in paper: [explicit] The paper discusses the current approach's focus on word-level alignment and acknowledges the lack of clarity on how embedding spaces handle words with polysemy profiles when adjusted via word-level alignments.
- Why unresolved: The paper identifies the limitation but does not explore methods for meaning-level alignment or provide evidence of its potential benefits or challenges.
- What evidence would resolve it: Development and evaluation of a cross-lingual semantic change detection model that employs meaning-level alignment techniques, with comparative analysis against the current word-level approach, highlighting improvements in detecting nuanced semantic changes.

### Open Question 3
- Question: How do the biases present in historical corpora and the BERT model affect the results of semantic change detection, and what strategies could be implemented to mitigate these biases?
- Basis in paper: [explicit] The paper acknowledges the potential biases arising from historical corpora, which may be skewed towards male authors, and the BERT model, known to encode social biases related to gender and race.
- Why unresolved: The paper mentions these biases but does not delve into their specific impact on semantic change detection results or propose methods to address them.
- What evidence would resolve it: An analysis of semantic change detection results before and after implementing bias mitigation strategies, such as data augmentation, bias-aware training, or post-processing techniques, to assess their effectiveness in reducing bias-induced inaccuracies.

## Limitations
- Performance constrained by embedding quality alignment across languages and time periods
- Iterative merging process requires careful threshold calibration to avoid losing low-frequency senses
- Neighbor-based distance metric introduces computational overhead that scales with k

## Confidence
- Graph-based clustering mechanism (High): Supported by clear theoretical justification and demonstrated improvements over k-means
- Neighbor-based distance metric effectiveness (Medium): Mechanistically sound but lacks direct empirical comparison on low-frequency sense detection
- Temporal dynamic graph tracking (Medium): The bipartite matching approach is theoretically valid, but empirical evidence for distinguishing acquisition vs loss of meanings is limited

## Next Checks
1. Conduct ablation studies on the neighbor-based distance metric by comparing it directly with Euclidean distance on datasets containing known ambiguous sense clusters
2. Test the approach on a controlled synthetic dataset with artificially introduced low-frequency senses to verify the iterative merging preserves them effectively
3. Evaluate the sensitivity of detection accuracy to different threshold configurations (tsc, tlow) across all four languages to determine optimal tuning procedures