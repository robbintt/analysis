---
ver: rpa2
title: Knowledge Distillation of Black-Box Large Language Models
arxiv_id: '2401.07013'
source_url: https://arxiv.org/abs/2401.07013
tags:
- proxy
- teacher
- knowledge
- black-box
- distillation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of distilling knowledge from
  proprietary large language models (LLMs) like GPT-4 to smaller, open-source models
  when internal states are inaccessible. The proposed Proxy-KD method introduces a
  proxy model between the black-box teacher and the student, aligning the proxy with
  the teacher using supervised fine-tuning and preference optimization.
---

# Knowledge Distillation of Black-Box Large Language Models

## Quick Facts
- arXiv ID: 2401.07013
- Source URL: https://arxiv.org/abs/2401.07013
- Reference count: 31
- Key outcome: Llama-2-7B student achieves 56.78% average accuracy using Proxy-KD vs 53.66% for vanilla black-box KD

## Executive Summary
This paper addresses the challenge of distilling knowledge from proprietary large language models (LLMs) like GPT-4 to smaller, open-source models when internal states are inaccessible. The proposed Proxy-KD method introduces a proxy model between the black-box teacher and the student, aligning the proxy with the teacher using supervised fine-tuning and preference optimization. The student then learns from both the teacher's outputs and the proxy's aligned output distributions, with sample-level weighting to focus on well-aligned samples. Experiments show Proxy-KD outperforms both traditional black-box and white-box knowledge distillation methods across multiple benchmarks.

## Method Summary
Proxy-KD introduces a three-stage approach to black-box knowledge distillation. First, a proxy model is aligned with the black-box teacher through supervised fine-tuning and preference optimization using only the teacher's outputs. Second, the student model learns from both the teacher's responses and the proxy's aligned output distributions, with a sample-level weighting mechanism that emphasizes samples where the proxy-teacher alignment is strong. This approach addresses the limitation of traditional black-box distillation methods that can only access the teacher's final outputs without internal states or gradients.

## Key Results
- Llama-2-7B student achieves 56.78% average accuracy using Proxy-KD
- Outperforms vanilla black-box KD (53.66%) and white-box KD (54.21%) baselines
- Demonstrates consistent improvements across reasoning, code, and instruction following tasks
- Sample-level weighting mechanism contributes to 1-2% performance gains

## Why This Works (Mechanism)
Proxy-KD works by creating an intermediary model that bridges the gap between the inaccessible black-box teacher and the student model. The proxy model learns to mimic the teacher's behavior through supervised fine-tuning and preference optimization, creating a more accessible target for the student to learn from. By training the student on both the teacher's outputs and the proxy's distributions, the method captures richer information about the teacher's knowledge. The sample-level weighting ensures that the student focuses on samples where the proxy-teacher alignment is strong, avoiding propagation of errors from poorly aligned samples.

## Foundational Learning

**Knowledge Distillation**: The process of transferring knowledge from a large model (teacher) to a smaller one (student). Why needed: Enables deployment of efficient models while preserving teacher capabilities. Quick check: Verify student performance improves when trained with teacher outputs.

**Supervised Fine-Tuning**: Training a model on labeled data to adapt it to specific tasks. Why needed: Aligns proxy model with teacher's output patterns. Quick check: Compare proxy and teacher outputs on validation set.

**Preference Optimization**: Training method that uses preference data to align model outputs with desired behaviors. Why needed: Improves proxy alignment with teacher's implicit preferences. Quick check: Measure correlation between proxy and teacher rankings.

**Black-Box Access**: Scenario where only model outputs are accessible, not internal states. Why needed: Reflects real-world constraints with proprietary models. Quick check: Verify only final outputs are used, no gradients or activations.

## Architecture Onboarding

**Component Map**: Black-Box Teacher -> Proxy Model (SFT + Preference Opt) -> Student Model (with Sample Weighting)

**Critical Path**: The alignment of proxy with teacher is the bottleneck. Poor proxy-teacher alignment directly degrades student performance, making the quality of SFT and preference optimization crucial.

**Design Tradeoffs**: Using a proxy adds computational overhead and complexity versus direct distillation, but enables richer learning signals. The sample weighting mechanism adds implementation complexity but improves robustness to proxy misalignment.

**Failure Signatures**: If the proxy fails to align with the teacher, student performance will degrade to or below vanilla black-box KD levels. Over-reliance on poorly aligned samples (due to incorrect weighting) can actively harm student learning.

**3 First Experiments**:
1. Measure proxy-teacher alignment quality on held-out samples
2. Test student performance with different proxy initialization strategies
3. Evaluate impact of removing sample-level weighting on final student accuracy

## Open Questions the Paper Calls Out
None

## Limitations
- Proxy model selection and initialization strategy not thoroughly explored
- Performance on domain-specific tasks not evaluated
- Computational overhead of proxy model not analyzed

## Confidence

**High confidence**: Experimental methodology is sound and improvements are statistically significant within tested domains.

**Medium confidence**: Theoretical justification for proxy approach is plausible but long-term effectiveness across diverse scenarios needs validation.

**Low confidence**: Scalability claims to larger models or more complex teachers lack empirical support.

## Next Checks

1. Conduct ablation study on different proxy model architectures and initialization strategies
2. Evaluate Proxy-KD performance on specialized domain-specific datasets
3. Measure and compare computational costs (training time, memory) against vanilla black-box distillation