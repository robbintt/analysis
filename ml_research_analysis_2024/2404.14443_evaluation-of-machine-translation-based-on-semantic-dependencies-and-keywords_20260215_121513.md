---
ver: rpa2
title: Evaluation of Machine Translation Based on Semantic Dependencies and Keywords
arxiv_id: '2404.14443'
source_url: https://arxiv.org/abs/2404.14443
tags:
- semantic
- translation
- machine
- dependency
- sentence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a machine translation evaluation method that
  integrates semantic dependency and keyword information to better capture deep semantic
  meaning, addressing the limitation of existing metrics that focus mainly on lexical
  and syntactic similarity. Using the Harbin Institute of Technology's Language Technology
  Platform, the method analyzes semantic dependency graphs and keyword weight sets
  for both reference and machine-translated sentences.
---

# Evaluation of Machine Translation Based on Semantic Dependencies and Keywords

## Quick Facts
- arXiv ID: 2404.14443
- Source URL: https://arxiv.org/abs/2404.14443
- Reference count: 0
- Primary result: Proposed method achieves 0.795 accuracy on 93 English-Chinese sentence pairs, outperforming BLEU (0.581), METEOR (0.602), and pure semantic dependency analysis (0.655).

## Executive Summary
This paper proposes a machine translation evaluation method that integrates semantic dependency and keyword information to better capture deep semantic meaning, addressing the limitation of existing metrics that focus mainly on lexical and syntactic similarity. Using the Harbin Institute of Technology's Language Technology Platform, the method analyzes semantic dependency graphs and keyword weight sets for both reference and machine-translated sentences. It computes semantic similarity by matching word pairs within corresponding dependency relations and combining them with keyword similarity scores. Experiments on 93 English-Chinese sentence pairs show the proposed approach achieves an accuracy of 0.795, outperforming baselines like BLEU and METEOR.

## Method Summary
The method uses the Harbin Institute of Technology's Language Technology Platform for semantic dependency analysis and keyword extraction. It constructs semantic association pairs from dependency graphs, calculates word similarity using HowNet/CiLin fusion method, and combines semantic dependency similarity with keyword similarity scores to evaluate translation quality. The approach processes both reference and machine-translated sentences to generate semantic dependency graphs and weighted keyword sets, then computes word-pair similarities within dependency relations and keyword matches, finally aggregating these into a combined semantic correctness score.

## Key Results
- sdp+key method achieves 0.795 accuracy on 93 English-Chinese sentence pairs
- Outperforms BLEU (0.581), METEOR (0.602), and pure semantic dependency analysis (0.655)
- Case studies demonstrate improved detection of missing translations, word-choice errors, and incorrect semantic dependencies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Semantic dependency analysis captures deep grammatical relationships beyond surface word matching.
- Mechanism: The LTP platform extracts semantic dependency graphs, then word-pair similarity is computed within each dependency relation type and aggregated.
- Core assumption: Dependency relations preserve semantic equivalence even if word order or syntax varies.
- Evidence anchors: [abstract] "Use the language technology platform... to conduct semantic dependency analysis... obtain semantic dependency graphs, keywords, and weight information." [section 3.1] "Semantic dependency analysis represents the meaning of a sentence through a set of dependent word pairs and their corresponding relationships." [corpus] No direct corpus evidence; method relies on LTP output quality.
- Break condition: If dependency parser fails to resolve core arguments (e.g., mislabels subject/object), similarity scores will drop and false negatives increase.

### Mechanism 2
- Claim: Keyword weighting supplements dependency-based similarity by emphasizing content-bearing terms.
- Mechanism: Extract keywords with weights from both sentences; match by word similarity; aggregate weighted scores.
- Core assumption: Missing or mistranslated keywords indicate substantive semantic loss more reliably than small lexical differences.
- Evidence anchors: [abstract] "add a calculation method for the keyword similarity... taking into account... sentence keywords." [section 3.2] "Keyword extraction is to structure the information contained in the text and integrate the extracted information in a unified form." [corpus] No direct corpus evidence; depends on keyword extraction accuracy.
- Break condition: If keyword extractor over-emphasizes function words or misses domain terms, scores will be noisy and correlation with human judgment degrades.

### Mechanism 3
- Claim: Combining dependency and keyword scores improves overall accuracy versus either alone.
- Mechanism: Final score = weighted sum of dependency similarity and keyword similarity.
- Core assumption: The two signals are complementary and errors in one are offset by the other.
- Evidence anchors: [abstract] "The experimental results show that the accuracy of the evaluation algorithm has been improved compared with similar methods." [section 4.2] "sdp+key 0.795" outperforms "sdp 0.655" and BLEU/METEOR baselines. [corpus] Experimental result in table supports claim; no external replication cited.
- Break condition: If both signals are systematically biased in the same direction, combination will amplify rather than correct errors.

## Foundational Learning

- Concept: Semantic dependency parsing
  - Why needed here: Provides structured deep semantic relations needed for word-pair matching.
  - Quick check question: What is the difference between syntactic dependency and semantic dependency?

- Concept: Keyword extraction with weighting
  - Why needed here: Highlights content-bearing terms that drive meaning preservation.
  - Quick check question: How does the keyword weight influence the final similarity score?

- Concept: Word similarity measures (Hownet + Cilin)
  - Why needed here: Enables matching across synonyms and morphological variants in dependency pairs and keywords.
  - Quick check question: Why combine multiple thesauri instead of using one?

## Architecture Onboarding

- Component map: LTP dependency parser -> dependency graph extraction -> word-pair similarity calculation -> dependency score; LTP keyword extractor -> weighted keyword list -> keyword similarity calculation -> keyword score; Combiner -> final semantic correctness score
- Critical path: Parse -> Extract -> Match -> Aggregate -> Combine
- Design tradeoffs: Dependency parsing adds depth but introduces parsing errors; keyword extraction is simpler but less context-aware. No explicit weight tuning between dependency and keyword components; fixed equal weighting may not suit all domains.
- Failure signatures: Low dependency scores with high keyword scores suggest syntactic structure is broken but content words are present. High dependency scores with low keyword scores indicate correct grammar but missing key content.
- First 3 experiments: 1) Run both parsers on a small golden set; check dependency label accuracy vs human annotations. 2) Vary keyword weight ratio (e.g., 0.7/0.3 vs 0.5/0.5) and observe accuracy changes. 3) Replace LTP parser with another dependency parser; compare score distributions and correlation with human judgments.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the integration of keyword information specifically improve the detection of semantic errors in machine translation compared to using semantic dependencies alone?
- Basis in paper: [explicit] The paper states that adding keyword information can highlight key semantics that cannot be captured by semantic dependencies alone, leading to more accurate detection of missing translations, word-choice errors, and incorrect semantic dependencies.
- Why unresolved: The paper provides case studies showing improvements but does not quantify the specific contribution of keyword information versus semantic dependencies in error detection.
- What evidence would resolve it: A controlled experiment comparing error detection rates using only semantic dependencies, only keyword information, and their combination would clarify their individual and joint contributions.

### Open Question 2
- Question: What is the impact of semantic dependency distance and direction on the accuracy of machine translation evaluation?
- Basis in paper: [inferred] The paper mentions dependency distance (DD) and direction in related works but does not incorporate these features into its evaluation method, despite their potential to capture syntactic patterns.
- Why unresolved: The paper focuses on semantic association pairs and keyword similarity but does not explore how dependency distance or direction might enhance evaluation accuracy.
- What evidence would resolve it: Experiments incorporating dependency distance and direction metrics into the evaluation framework and comparing results with the current method would determine their impact.

### Open Question 3
- Question: How does the proposed method perform on languages other than English-Chinese, particularly those with different syntactic structures?
- Basis in paper: [inferred] The method is evaluated only on English-Chinese sentence pairs, and the paper does not discuss its applicability to other language pairs or structurally different languages.
- Why unresolved: The effectiveness of semantic dependency and keyword-based evaluation may vary depending on the linguistic characteristics of the language pair.
- What evidence would resolve it: Testing the method on multiple language pairs (e.g., English-French, English-Japanese) and analyzing performance differences would reveal its generalizability.

## Limitations
- Evaluation based on only 93 sentence pairs, limiting statistical significance and generalizability
- Relies entirely on Harbin Institute of Technology's Language Technology Platform with no comparison to alternatives
- No implementation details for HowNet/Cilin-based word similarity calculation, making exact replication difficult
- Fixed equal weighting between dependency and keyword components may not be optimal across domains

## Confidence

- Overall accuracy improvement claim: Medium (supported by experimental results but limited sample size)
- Mechanism 1 (dependency parsing): Medium (theoretical soundness but parser quality unknown)
- Mechanism 2 (keyword weighting): Medium (conceptually sound but extraction accuracy unverified)
- Mechanism 3 (combination benefits): Low-Medium (empirical support but no ablation study of weighting)

## Next Checks

1. Validate the accuracy of LTP's dependency parser and keyword extractor against human annotations on a small sample set
2. Conduct an ablation study varying the relative weights between dependency and keyword similarity scores
3. Replicate the evaluation using an alternative dependency parser to test robustness to parsing quality