---
ver: rpa2
title: 'Dense Passage Retrieval: Is it Retrieving?'
arxiv_id: '2402.11035'
source_url: https://arxiv.org/abs/2402.11035
tags:
- knowledge
- bert
- retrieval
- training
- pre-trained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether dense passage retrieval (DPR) models
  are truly retrieving new knowledge or merely improving access to existing knowledge
  stored in large language models (LLMs). The authors use a combination of probing,
  layer activation analysis, and model editing to analyze DPR-trained models.
---

# Dense Passage Retrieval: Is it Retrieving?
## Quick Facts
- arXiv ID: 2402.11035
- Source URL: https://arxiv.org/abs/2402.11035
- Reference count: 26
- Primary result: DPR training decentralizes knowledge storage but does not add new knowledge to models

## Executive Summary
This paper investigates whether dense passage retrieval (DPR) models truly retrieve new knowledge or merely improve access to existing knowledge stored in large language models. Through a combination of probing, layer activation analysis, and model editing experiments, the authors find that DPR training decentralizes knowledge storage across model layers, creating multiple access pathways. However, the model's ability to retrieve is bounded by its internal knowledge, suggesting DPR models are constrained to retrieving information based on pre-existing knowledge rather than learning new facts during fine-tuning.

## Method Summary
The authors employ a multi-pronged approach to analyze DPR-trained models. They conduct probing experiments to examine knowledge storage patterns, analyze layer activation distributions to understand how information is accessed, and perform model editing to test knowledge dependencies. The methodology focuses on understanding how DPR training affects knowledge representation and retrieval capabilities, specifically examining whether the fine-tuning process adds new knowledge or merely optimizes access to existing knowledge.

## Key Results
- DPR training decentralizes knowledge storage, creating multiple access pathways across model layers
- Model editing experiments show retrieval performance degrades when specific knowledge is removed
- DPR models' retrieval capabilities are bounded by their internal knowledge, not extending beyond what was present in the pre-trained model

## Why This Works (Mechanism)
DPR works by optimizing the model's ability to access and retrieve information that is already encoded in its parameters. The training process does not add new knowledge but rather reorganizes how existing knowledge is stored and accessed. This mechanism involves creating multiple pathways to the same information across different layers, making retrieval more robust but fundamentally limited to the model's pre-existing knowledge base.

## Foundational Learning
1. Dense Passage Retrieval (DPR): A neural retrieval method that encodes passages and queries into dense vectors for efficient similarity search
   - Why needed: Enables efficient information retrieval from large text collections
   - Quick check: Verify vector similarity search produces relevant passages for given queries

2. Model Probing: Techniques to examine what knowledge is stored in neural network layers
   - Why needed: Allows analysis of knowledge distribution and accessibility
- Quick check: Confirm probing accuracy correlates with retrieval performance

3. Layer Activation Analysis: Studying how different model layers contribute to information access
   - Why needed: Reveals how knowledge is distributed and accessed across the network
   - Quick check: Verify layer contributions align with knowledge retrieval patterns

## Architecture Onboarding
**Component Map:** Query Encoder -> Passage Encoder -> Similarity Computation -> Ranking
**Critical Path:** Query encoding → similarity scoring → passage ranking → top-k retrieval
**Design Tradeoffs:** DPR balances between compact representation size and retrieval accuracy, with smaller vectors enabling faster search but potentially reducing semantic matching quality
**Failure Signatures:** Retrieval performance degrades when key knowledge is removed from the base model, indicating reliance on existing knowledge rather than learned new information
**First Experiments:**
1. Measure retrieval accuracy on questions where answer knowledge is present vs. absent in base model
2. Compare layer activation patterns before and after DPR training
3. Perform controlled model editing to remove specific knowledge and measure retrieval impact

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis focuses on indirect evidence through probing and activation patterns rather than direct measurement of knowledge acquisition
- Study limited to specific DPR architecture and training regime, may not generalize to all dense retrieval models
- Conclusions about knowledge addition rely on model editing experiments that could have alternative interpretations

## Confidence
**High Confidence:** DPR training creates multiple access pathways to existing knowledge and decentralizes knowledge storage across layers
**Medium Confidence:** DPR does not add new knowledge to the model, though this conclusion is based on indirect evidence
**Low Confidence:** DPR models are fundamentally constrained to retrieving information based on pre-existing knowledge, as this may overstate the limitations of DPR training

## Next Checks
1. Conduct controlled experiments comparing DPR models trained on different datasets with varying levels of knowledge overlap with the pre-trained language model to determine if DPR can learn to retrieve information not present in the original model

2. Perform ablation studies that systematically remove specific knowledge from the base model before DPR fine-tuning to measure whether DPR training can compensate for missing information or if retrieval performance is strictly bounded by pre-existing knowledge

3. Design experiments that test DPR retrieval on time-sensitive or rapidly evolving knowledge domains where the pre-trained model would have limited or outdated information, to assess whether DPR training enables effective retrieval of information not present during pre-training