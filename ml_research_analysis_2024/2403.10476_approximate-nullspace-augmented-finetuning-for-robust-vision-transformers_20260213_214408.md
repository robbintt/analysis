---
ver: rpa2
title: Approximate Nullspace Augmented Finetuning for Robust Vision Transformers
arxiv_id: '2403.10476'
source_url: https://arxiv.org/abs/2403.10476
tags:
- nullspace
- noise
- robustness
- vision
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to enhance the robustness of vision
  transformers (ViTs) by exploiting the concept of nullspace from linear algebra.
  The key idea is to identify and synthesize approximate nullspace noise for ViT encoder
  blocks and then fine-tune the model using this noise as data augmentation.
---

# Approximate Nullspace Augmented Finetuning for Robust Vision Transformers

## Quick Facts
- arXiv ID: 2403.10476
- Source URL: https://arxiv.org/abs/2403.10476
- Authors: Haoyang Liu; Aditya Singh; Yijiang Li; Haohan Wang
- Reference count: 40
- Primary result: Nullspace noise fine-tuning improves ViT robustness to both adversarial attacks and distribution shifts

## Executive Summary
This paper introduces a novel approach to enhance vision transformer (ViT) robustness by leveraging the mathematical concept of nullspace from linear algebra. The key insight is that the patch embedding layer in many ViTs creates a non-trivial nullspace due to dimension reduction, which provides inherent robustness to certain perturbations. The authors extend this concept to the nonlinear encoder blocks through optimization, synthesizing approximate nullspace noise vectors. By fine-tuning models with this noise as data augmentation, they demonstrate significant improvements in both adversarial and out-of-distribution robustness without requiring architectural modifications.

## Method Summary
The method operates in two main steps: first, it learns noise vectors that minimally influence the model's output by optimizing for approximate nullspace elements in the nonlinear encoder blocks; second, it fine-tunes the pre-trained model using these noise vectors as additive input perturbations during training. The approach exploits the nullspace property of the patch embedding layer and extends it to the entire model through a fine-tuning process that enlarges the approximate nullspace. The authors validate their approach across multiple benchmark datasets, showing consistent improvements in robustness to various types of distribution shifts and adversarial attacks.

## Key Results
- Nullspace fine-tuning improves adversarial robustness against FGSM, CW, PatchFool, and DamageNet attacks
- Out-of-distribution robustness improves on ImageNet-C, ImageNet-A, ImageNet-V2, ImageNet-R, ImageNet-Sketch, and Stylized-ImageNet
- Method consistently improves model robustness without architectural modifications
- Results demonstrate state-of-the-art performance on multiple robustness benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The patch embedding layer in ViTs creates a non-trivial nullspace due to dimension reduction, providing inherent robustness to certain perturbations.
- Mechanism: The patch embedding layer projects high-dimensional image patches (c×r×r) to lower-dimensional embeddings (d), creating a nullspace where perturbations do not affect the output. This nullspace property extends to the entire model since the first layer determines invariance.
- Core assumption: The dimension of patch embeddings (d) is smaller than the input patch dimension (c×r×r), creating a non-trivial nullspace.
- Evidence anchors:
  - [abstract]: "We start from the observation that many existing ViTs satisfy this property because their patch embedding layer has a non-trivial nullspace."
  - [section 3.1]: "Since the first layer of the ViT is a linear mapping, according to the rank-nullity theorem, it always has a non-trivial nullspace if cr² > d."
  - [corpus]: No direct corpus evidence supporting this specific claim about nullspace in patch embeddings.

### Mechanism 2
- Claim: The method synthesizes approximate nullspace elements for nonlinear encoder blocks through optimization, creating noise vectors that minimally influence model output.
- Mechanism: An optimization process minimizes the difference between model outputs with and without noise, while regularizing the noise magnitude. This finds perturbations that satisfy a relaxed invariance property for nonlinear layers.
- Core assumption: The optimization can find noise vectors that approximately satisfy the nullspace invariance property for nonlinear transformer encoders.
- Evidence anchors:
  - [section 3.3]: "Equation (4) minimizes the ℓ2 norm between the predicted logits with and without the noise."
  - [section 3.2]: "We extend the notion of nullspace to the nonlinear setting and define the Generalized Nullspace."
  - [corpus]: No direct corpus evidence supporting the effectiveness of this optimization approach.

### Mechanism 3
- Claim: Fine-tuning with synthesized nullspace noise enlarges the approximate nullspace, improving robustness to both adversarial and natural perturbations.
- Mechanism: The fine-tuning process makes the model more tolerant to noise vectors in the approximate nullspace by repeatedly exposing it to these perturbations during training, effectively expanding the set of benign perturbations.
- Core assumption: Making the model invariant to more nullspace-like perturbations will generalize to improved robustness against various types of distribution shifts.
- Evidence anchors:
  - [section 4]: "We propose a fine-tuning strategy for ViTs wherein we augment the training data with synthesized approximate nullspace noise."
  - [section 5.2]: "Our nullspace finetuning method consistently improves the robustness of models under distribution shifts and adversarial attacks."
  - [corpus]: No direct corpus evidence supporting the generalization claim from nullspace invariance to overall robustness.

## Foundational Learning

- Concept: Nullspace in linear algebra
  - Why needed here: The entire method is built on the concept of nullspace from linear algebra, extended to neural networks
  - Quick check question: What is the nullspace of a linear transformation, and why does it imply invariance to certain perturbations?

- Concept: Vision Transformer architecture
  - Why needed here: Understanding the patch embedding layer, self-attention mechanism, and classification head is crucial for grasping how nullspace applies to ViTs
  - Quick check question: How does the patch embedding layer in ViTs reduce dimensionality, and what mathematical property does this create?

- Concept: Data augmentation and robustness
  - Why needed here: The method uses nullspace noise as a form of data augmentation to improve model robustness
  - Quick check question: How does data augmentation typically improve model robustness, and how does nullspace noise differ from standard augmentation techniques?

## Architecture Onboarding

- Component map:
  - Patch embedding layer (linear, creates nullspace) -> Self-attention encoder blocks (nonlinear, approximate nullspace synthesis) -> Classification head (evaluates robustness improvements) -> Noise synthesis module (optimizes for approximate nullspace vectors) -> Fine-tuning pipeline (applies nullspace augmentation during training)

- Critical path: Patch embedding → Self-attention → Classification. The nullspace property from the patch embedding propagates through the network, and the fine-tuning improves tolerance at each stage.

- Design tradeoffs:
  - Computational cost vs. robustness gain (nullspace synthesis requires additional optimization)
  - Regularization strength (λ parameter) vs. noise magnitude and effectiveness
  - Number of fine-tuning iterations vs. risk of overfitting to nullspace patterns

- Failure signatures:
  - Noise vectors that significantly affect model output despite optimization
  - Degradation in clean accuracy after nullspace fine-tuning
  - Limited improvement on robustness benchmarks despite successful nullspace enlargement

- First 3 experiments:
  1. Verify nullspace existence in patch embedding layer for a simple ViT variant by computing basis vectors and testing invariance
  2. Synthesize approximate nullspace noise for encoder blocks and measure output difference with varying regularization strengths
  3. Fine-tune a pre-trained ViT with nullspace noise on a small dataset and evaluate robustness improvements on a single benchmark (e.g., FGSM attack)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise relationship between the nullspace property at the patch embedding layer and the encoder-level approximate nullspace?
- Basis in paper: [explicit] The paper establishes that the patch embedding layer has a non-trivial nullspace and empirically identifies an approximate nullspace at the encoder level.
- Why unresolved: While the paper shows both exist, it does not formally prove that the encoder-level approximate nullspace is a direct consequence of the patch embedding nullspace, or if they are independent properties.
- What evidence would resolve it: A formal mathematical proof showing that the encoder-level approximate nullspace must exist given the patch embedding nullspace, or empirical evidence showing different behavior when the patch embedding nullspace is modified.

### Open Question 2
- Question: How does the size of the approximate nullspace (as measured by the norm of nullspace noise) relate to the overall robustness of the model?
- Basis in paper: [inferred] The paper shows that nullspace noise fine-tuning enlarges the approximate nullspace and improves robustness, but does not quantify this relationship.
- Why unresolved: The paper demonstrates correlation but does not establish a quantitative relationship between nullspace size and robustness metrics across different models and datasets.
- What evidence would resolve it: Systematic experiments measuring the relationship between nullspace norm bounds and specific robustness metrics (adversarial accuracy, mCE on ImageNet-C, etc.) across multiple model architectures and datasets.

### Open Question 3
- Question: Can the nullspace-based approach be extended to other architectures beyond Vision Transformers?
- Basis in paper: [inferred] The paper focuses exclusively on Vision Transformers, though it mentions that the concept could apply to other architectures.
- Why unresolved: The paper does not explore whether CNNs or other architectures have similar nullspace properties or if the approach would work for them.
- What evidence would resolve it: Experiments applying the same methodology to CNNs and other architectures to determine if they have similar nullspace properties and if nullspace-based fine-tuning improves their robustness.

## Limitations

- The method relies on the assumption that patch embedding layers in ViTs have non-trivial nullspaces, which may not hold for all ViT architectures
- The synthesis of approximate nullspace elements for nonlinear layers depends on optimization that may not find globally optimal solutions
- The generalization from nullspace invariance to broader robustness improvements remains empirically demonstrated but theoretically unproven

## Confidence

- High confidence in the mathematical foundation regarding linear nullspaces in patch embeddings
- Medium confidence in the effectiveness of the approximate nullspace synthesis for nonlinear layers
- Medium confidence in the claimed robustness improvements across all evaluated benchmarks
- Low confidence in the scalability of the method to extremely large-scale models or diverse architecture variants

## Next Checks

1. Verify the nullspace property exists across multiple ViT variants (DeiT, Swin, etc.) by empirically testing patch embedding invariance
2. Compare the nullspace noise approach against standard data augmentation methods on clean accuracy to quantify any potential degradation
3. Test the method's effectiveness on smaller datasets to determine if robustness gains persist with limited training data