---
ver: rpa2
title: Compression Repair for Feedforward Neural Networks Based on Model Equivalence
  Evaluation
arxiv_id: '2402.11737'
source_url: https://arxiv.org/abs/2402.11737
tags:
- neural
- repair
- compressed
- network
- networks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to repair compressed feedforward neural
  networks by evaluating the equivalence between original and compressed networks.
  The core idea is to construct a merged network from the original and compressed
  networks, then use reachability analysis to compute the output discrepancy.
---

# Compression Repair for Feedforward Neural Networks Based on Model Equivalence Evaluation

## Quick Facts
- arXiv ID: 2402.11737
- Source URL: https://arxiv.org/abs/2402.11737
- Reference count: 27
- Primary result: Compressed network accuracy improved from 91% to 98% on MNIST while maintaining reduced size

## Executive Summary
This paper introduces a novel approach to repairing compressed feedforward neural networks by evaluating equivalence between original and compressed models. The method constructs a merged network from both versions and uses reachability analysis to compute output discrepancies. Based on these discrepancies, a repair framework generates new training data and retrains the compressed network to reduce the output difference. The approach successfully restored a compressed MNIST network from 91% to 98% accuracy, matching the original network's performance while maintaining compression benefits.

## Method Summary
The core methodology involves creating a merged network architecture that combines the original and compressed networks, then applying reachability analysis to quantify the output differences between them. This discrepancy computation serves as the foundation for the repair framework, which generates targeted training samples designed to minimize the identified gaps. The compressed network is then retrained using this specialized dataset, effectively narrowing the performance gap while preserving the compression benefits. The approach specifically targets feedforward networks and demonstrates particular effectiveness on image classification tasks.

## Key Results
- Successfully repaired compressed network accuracy from 91% to 98% on MNIST dataset
- Achieved original network performance while maintaining reduced model size
- Demonstrated effectiveness of equivalence-based repair framework for feedforward networks

## Why This Works (Mechanism)
The method works by systematically identifying and addressing the specific areas where compressed networks deviate from their original counterparts. By using reachability analysis on a merged network architecture, it can precisely locate where and how the compressed network's outputs differ from the original. This targeted approach allows for focused retraining that addresses only the problematic areas rather than requiring complete retraining from scratch. The equivalence evaluation provides a quantitative metric for repair progress, ensuring that improvements are measurable and directed.

## Foundational Learning
- **Reachability Analysis**: Needed to compute output discrepancies between networks; quick check: verify bounds on output differences are correctly calculated
- **Model Equivalence Evaluation**: Essential for quantifying performance gaps; quick check: ensure equivalence metrics are properly defined and computed
- **Merged Network Construction**: Required to compare original and compressed networks; quick check: validate merged architecture maintains both networks' characteristics
- **Targeted Retraining**: Core repair mechanism; quick check: confirm new training samples effectively address identified discrepancies

## Architecture Onboarding

**Component Map**: Original Network -> Merged Network -> Reachability Analysis -> Discrepancy Computation -> Repair Framework -> Retrained Compressed Network

**Critical Path**: The most critical components are the reachability analysis for discrepancy computation and the targeted retraining process. These determine both the effectiveness of the repair and the computational feasibility of the approach.

**Design Tradeoffs**: The method trades computational complexity in the reachability analysis phase for improved accuracy in the final compressed network. While this adds overhead during repair, it enables maintaining compression benefits while recovering lost accuracy.

**Failure Signatures**: Common failure modes include computational intractability of reachability analysis for larger networks, insufficient new training data generation, and incomplete discrepancy resolution during retraining. The method may also struggle with non-feedforward architectures.

**3 First Experiments**:
1. Apply the repair framework to different compression ratios (10%, 50%, 90%) on MNIST to assess scalability
2. Test on a deeper feedforward architecture (multiple hidden layers) to evaluate performance on more complex networks
3. Compare repair effectiveness across different initial compression methods (pruning vs. quantization)

## Open Questions the Paper Calls Out
None

## Limitations
- Reachability analysis may become computationally intractable for larger networks
- Effectiveness primarily demonstrated on simple MNIST dataset, generalizability uncertain
- Requires access to both original and compressed networks, limiting practical deployment scenarios

## Confidence
- **High Confidence**: Core methodology of equivalence evaluation is theoretically sound
- **Medium Confidence**: MNIST results are promising but require validation on more complex datasets
- **Low Confidence**: Claims about maintaining reduced size while achieving original accuracy need broader empirical validation

## Next Checks
1. Test the repair framework on deeper architectures (ResNet, VGG) and more complex datasets (CIFAR-10, ImageNet)
2. Evaluate computational overhead of reachability analysis and explore approximation techniques for efficiency
3. Investigate effectiveness when only compressed network is available, without access to original network