---
ver: rpa2
title: Preventing Collapse in Contrastive Learning with Orthonormal Prototypes (CLOP)
arxiv_id: '2403.18699'
source_url: https://arxiv.org/abs/2403.18699
tags:
- learning
- contrastive
- collapse
- class
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses neural collapse in contrastive learning, where
  embeddings converge into lower-dimensional spaces, reducing their spatial utility
  and making classes indistinguishable. The authors theoretically analyze the effect
  of large learning rates on contrastive losses relying solely on cosine similarity,
  deriving an upper bound of sqrt(2) + O(1/k) to avoid collapse for k classes.
---

# Preventing Collapse in Contrastive Learning with Orthonormal Prototypes (CLOP)

## Quick Facts
- arXiv ID: 2403.18699
- Source URL: https://arxiv.org/abs/2403.18699
- Authors: Huanran Li; Manh Nguyen; Daniel Pimentel-AlarcÃ³n
- Reference count: 34
- Key outcome: CLOP prevents neural collapse in contrastive learning by promoting orthogonal linear subspaces among class embeddings, leading to more stable training across different learning rates and batch sizes

## Executive Summary
This paper addresses neural collapse in contrastive learning, where embeddings converge into lower-dimensional spaces, reducing their spatial utility and making classes indistinguishable. The authors theoretically analyze the effect of large learning rates on contrastive losses relying solely on cosine similarity, deriving an upper bound of sqrt(2) + O(1/k) to avoid collapse for k classes. They propose CLOP (Contrastive Learning with Orthonormal Prototypes), a novel semi-supervised loss function that prevents neural collapse by promoting orthogonal linear subspaces among class embeddings. Unlike prior approaches that enforce simplex ETF structure, CLOP focuses on subspace separation, leading to more distinguishable embeddings.

## Method Summary
CLOP introduces a semi-supervised loss function that operates by promoting orthonormal prototypes for each class during contrastive learning. The method encourages embeddings to occupy orthogonal linear subspaces, preventing the collapse phenomenon where embeddings converge to a lower-dimensional space. The approach combines unsupervised contrastive loss with a supervised prototype alignment term, where prototypes are learned to be orthonormal while class representations are pulled toward their corresponding prototypes. This dual objective ensures that class embeddings remain distinguishable while maintaining the benefits of contrastive learning.

## Key Results
- Theoretical analysis derives sqrt(2) + O(1/k) upper bound to avoid collapse for k classes under idealized cosine similarity losses
- Extensive experiments on CIFAR-100 and Tiny-ImageNet demonstrate CLOP's effectiveness in preventing collapse
- CLOP shows significantly greater stability across different learning rates and batch sizes compared to standard contrastive learning
- Performance comparable to large batch sizes (2048) even with small batch sizes (32)

## Why This Works (Mechanism)
CLOP works by enforcing orthogonality between class prototypes, which directly prevents the convergence of embeddings into lower-dimensional subspaces. By promoting orthonormal prototypes, the method ensures that each class occupies a distinct linear subspace in the embedding space. This structural separation maintains the discriminative power of the learned representations even when learning rates are high or batch sizes are small. The semi-supervised nature allows the model to leverage both labeled and unlabeled data effectively, with the prototype alignment term providing additional supervision that stabilizes training.

## Foundational Learning
- **Neural Collapse**: Phenomenon where deep network representations converge to specific geometric patterns during training. Why needed: Understanding this behavior is crucial as it directly motivates the development of CLOP to prevent collapse.
- **Contrastive Learning**: Self-supervised learning method that learns representations by contrasting similar and dissimilar pairs. Why needed: CLOP builds upon contrastive learning framework, modifying it to prevent collapse.
- **Orthonormal Prototypes**: Set of vectors that are mutually orthogonal and unit-norm. Why needed: These prototypes form the core mechanism by which CLOP enforces subspace separation.
- **Cosine Similarity**: Measure of similarity between two non-zero vectors based on the cosine of the angle between them. Why needed: The theoretical analysis relies on understanding how cosine similarity-based losses behave under different conditions.
- **Semi-supervised Learning**: Learning approach that uses both labeled and unlabeled data. Why needed: CLOP's loss function combines unsupervised contrastive objectives with supervised prototype alignment.
- **Linear Subspaces**: Vector spaces that are closed under addition and scalar multiplication. Why needed: CLOP promotes embeddings to occupy orthogonal linear subspaces to maintain class separability.

## Architecture Onboarding
- **Component Map**: Input data -> Backbone network -> Embedding space -> CLOP loss (contrastive + prototype alignment) -> Gradients -> Backbone update
- **Critical Path**: The core mechanism is the prototype alignment term in the loss function that enforces orthogonality between class prototypes while pulling class representations toward their respective prototypes
- **Design Tradeoffs**: CLOP trades off some computational overhead from maintaining and updating prototypes against the benefit of preventing collapse and improving stability
- **Failure Signatures**: If prototypes become non-orthonormal or if the alignment term dominates too strongly, the method may fail to maintain good representation quality or prevent collapse effectively
- **3 First Experiments**:
  1. Test CLOP on a simple synthetic dataset with known class structure to verify prototype orthogonality
  2. Compare embedding visualizations with and without CLOP on CIFAR-100 to observe collapse prevention
  3. Evaluate stability across different learning rates by training with CLOP at learning rates ranging from 0.001 to 1.0

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical analysis assumes idealized cosine similarity-based losses and may not fully translate to complex practical scenarios
- Semi-supervised nature introduces dependencies on labeled data availability that are not thoroughly explored across different labeling scenarios
- Experimental validation remains limited to standard benchmark datasets without testing on more diverse or challenging datasets with class imbalance or domain shift

## Confidence
- High confidence in the theoretical analysis of collapse bounds and the mathematical framework
- Medium confidence in the experimental results on CIFAR-100 and Tiny-ImageNet
- Low confidence in the generalization of results to real-world, complex datasets and the scalability analysis

## Next Checks
1. Evaluate CLOP's performance on datasets with severe class imbalance and domain shift to test robustness
2. Conduct ablation studies to quantify the contribution of each component in the CLOP loss function
3. Compare CLOP against a broader range of collapse prevention methods on multiple benchmarks