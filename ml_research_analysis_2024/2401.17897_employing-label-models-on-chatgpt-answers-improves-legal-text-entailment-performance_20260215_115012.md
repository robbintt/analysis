---
ver: rpa2
title: Employing Label Models on ChatGPT Answers Improves Legal Text Entailment Performance
arxiv_id: '2401.17897'
source_url: https://arxiv.org/abs/2401.17897
tags:
- chatgpt
- legal
- label
- answers
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores the use of label models to integrate and refine
  provisional answers generated by ChatGPT for legal text entailment. While ChatGPT
  shows promising results, its non-deterministic responses at higher temperature settings
  lead to inconsistencies.
---

# Employing Label Models on ChatGPT Answers Improves Legal Text Entailment Performance

## Quick Facts
- **arXiv ID**: 2401.17897
- **Source URL**: https://arxiv.org/abs/2401.17897
- **Reference count**: 28
- **Key result**: Label models improve ChatGPT accuracy on legal entailment from 67.89% to 76.15% using 10 responses at temperature 0.5

## Executive Summary
This paper presents a novel approach to improving legal text entailment by treating ChatGPT's stochastic outputs as noisy predictions and consolidating them using label models. The researchers found that while ChatGPT performs well on legal entailment tasks, its non-deterministic responses at higher temperature settings lead to inconsistent results. By generating multiple provisional answers and applying label models, particularly the Generative model, they achieved significant accuracy improvements on the COLIEE 2022 dataset. The study also provides an error analysis of ChatGPT's incorrect responses, categorizing them into four distinct types.

## Method Summary
The approach involves generating multiple provisional answers from ChatGPT at temperature 0.5 using a Reason-then-Answer prompt structure, then applying label models (particularly the Generative model) to consolidate these noisy predictions into more accurate final answers. The method treats ChatGPT outputs as weak supervision sources that need aggregation and denoising, leveraging the diversity introduced by temperature-controlled stochasticity to capture different valid interpretations of legal texts.

## Key Results
- Accuracy improved from 67.89% to 76.15% using the Generative model with 10 ChatGPT responses at temperature 0.5
- Reason-then-Answer prompt structure achieved 2.75% performance boost over direct answering
- Error analysis revealed four distinct categories of ChatGPT's incorrect responses in legal entailment tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Label models effectively consolidate noisy predictions from multiple ChatGPT outputs with non-zero temperature.
- Mechanism: The label model aggregates diverse predictions from multiple LLM runs, each potentially capturing different valid interpretations of the legal text, thereby reducing the variance inherent in stochastic outputs.
- Core assumption: The aggregation process can distinguish between noise and signal, and that consensus among diverse predictions indicates higher accuracy.
- Evidence anchors:
  - [abstract] "By that way, we treat ChatGPT answers as noisy predictions which can be consolidated by label models."
  - [section] "In these experiments, we set the temperature variable to be non-zero to enable possibilities of ChatGPT producing different answers... we propose to treat ChatGPT answers as provisional answers, and to leverage the label models to integrate the provisional answers to consolidated answers."
  - [corpus] Weak, as no corpus directly confirms this specific mechanism in legal entailment.
- Break condition: If the underlying model's errors are systematic rather than random, aggregation may amplify rather than reduce errors.

### Mechanism 2
- Claim: Temperature-controlled stochasticity introduces beneficial diversity in legal reasoning paths.
- Mechanism: Varying temperature creates different reasoning trajectories, each potentially capturing distinct valid interpretations or aspects of complex legal scenarios, improving coverage.
- Core assumption: Legal entailment benefits from multiple reasoning approaches rather than a single deterministic path.
- Evidence anchors:
  - [abstract] "On the other hand, if the temperature is larger than zero, ChatGPT answers are not deterministic, leading to inconsistent answers and fluctuating results."
  - [section] "Table 2 shows some information on the results of prompting ChatGPT 10 times with different temperature values. It can be seen that within a single run, the best accuracy could be 76.15% when the temperature equals 0.4, 0.6, 0.8, 0.9 or 1.0."
  - [corpus] Moderate, related work shows LLMs struggle with consistency but benefits of diversity are not explicitly proven.
- Break condition: If temperature variation introduces contradictory reasoning rather than complementary perspectives.

### Mechanism 3
- Claim: Specific prompt structures guide ChatGPT toward more reliable legal reasoning.
- Mechanism: The "Reason-then-Answer" prompt structure mimics systematic human legal reasoning, leading to more thorough analysis before conclusion.
- Core assumption: Legal reasoning benefits from explicit step-by-step analysis rather than direct answer prediction.
- Evidence anchors:
  - [section] "The designed prompts are as follows... Reason-then-Answer prompt achieves a performance boost of 2.75%, reaching an accuracy of 70.64%... This is in contrast to the previous accuracy of 67.89%."
  - [section] "ChatGPT using the Reason-then-Answer prompt demonstrates a performance improvement of 2.75%... The Reason-then-Answer prompt yields the highest accuracy, indicating its appropriateness as a prompt type."
  - [corpus] Strong, Chain-of-Thought prompting literature supports this approach.
- Break condition: If the model relies on surface patterns in the prompt rather than genuine reasoning.

## Foundational Learning

- Concept: Weak supervision and label models
  - Why needed here: The approach treats ChatGPT outputs as weak supervision sources that need aggregation and denoising.
  - Quick check question: What is the fundamental difference between majority voting and probabilistic label models like Dawid-Skene?

- Concept: Temperature parameter in LLMs
  - Why needed here: Understanding how temperature affects output diversity is crucial for designing the multiple-prediction approach.
  - Quick check question: How does temperature affect the probability distribution over tokens in LLM generation?

- Concept: Legal text entailment task structure
  - Why needed here: The method specifically targets COLIEE-style entailment tasks, requiring understanding of query-article relationships.
  - Quick check question: What distinguishes legal entailment from general textual entailment in terms of reasoning requirements?

## Architecture Onboarding

- Component map: ChatGPT prompt generator → Multiple LLM invocations (different temperatures) → Label model aggregator → Final prediction
- Critical path: Prompt generation → LLM invocation → Answer collection → Label model processing → Output prediction
- Design tradeoffs: Number of predictions vs. computational cost; temperature settings vs. answer diversity; simple vs. complex label models
- Failure signatures: Consistent errors across all temperature settings; label models failing to improve accuracy; accuracy degradation with more predictions
- First 3 experiments:
  1. Test accuracy of single ChatGPT run with temperature 0.5 vs. temperature 0
  2. Compare majority voting vs. Generative model label aggregation on 10 predictions
  3. Vary number of predictions (3, 5, 10) to find optimal trade-off between accuracy and computation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of label models change when integrating provisional answers from different ChatGPT configurations (e.g., varying temperature, prompt types, or fine-tuning on legal data)?
- Basis in paper: [explicit] The paper explores the impact of temperature on ChatGPT's performance and shows that label models improve accuracy when integrating provisional answers.
- Why unresolved: The study focuses on a specific temperature setting (0.5) and prompt type (Reason-then-Answer) for integrating provisional answers using label models. The performance of label models when combining provisional answers from different ChatGPT configurations remains unexplored.
- What evidence would resolve it: Conducting experiments that compare the performance of label models when integrating provisional answers from various ChatGPT configurations, such as different temperature settings, prompt types, or fine-tuned models on legal data.

### Open Question 2
- Question: How do different label models (e.g., FlyingSquid, Dawid-Skene, Hyper label model, F ABLE, Generative model) perform when integrating provisional answers from ChatGPT in other domains or tasks?
- Basis in paper: [explicit] The paper evaluates the performance of several label models (FlyingSquid, Dawid-Skene, Hyper label model, F ABLE, Generative model) in integrating provisional answers from ChatGPT for legal text entailment.
- Why unresolved: The study focuses on legal text entailment using the COLIEE 2022 dataset. The effectiveness of different label models in integrating provisional answers from ChatGPT in other domains or tasks is not explored.
- What evidence would resolve it: Conducting experiments that apply different label models to integrate provisional answers from ChatGPT in various domains or tasks, such as sentiment analysis, question answering, or summarization, and comparing their performance.

### Open Question 3
- Question: How does the number of provisional answers generated by ChatGPT affect the performance of label models in integrating them into consolidated answers?
- Basis in paper: [explicit] The paper investigates the performance of the "Generative model" label model when integrating different numbers of provisional answers (3 to 10) from ChatGPT.
- Why unresolved: The study provides insights into the impact of the number of provisional answers on the performance of a specific label model (Generative model) but does not explore the general relationship between the number of provisional answers and the performance of various label models.
- What evidence would resolve it: Conducting experiments that systematically vary the number of provisional answers generated by ChatGPT and evaluate the performance of different label models in integrating them into consolidated answers, identifying the optimal number of provisional answers for each label model.

## Limitations
- Limited to single dataset (COLIEE 2022) without testing generalizability to other legal corpora
- Does not explore systematic parameter space for temperature settings
- Error analysis remains qualitative rather than quantitative

## Confidence
- High confidence: The accuracy improvement claim (76.15% vs 67.89%) and the basic mechanism of using label models to aggregate multiple predictions
- Medium confidence: The effectiveness of the Reason-then-Answer prompt structure and the categorization of error types
- Low confidence: The generalizability of findings to other legal datasets, the optimal temperature settings, and the robustness of the approach to different label model implementations

## Next Checks
1. Replicate the accuracy results on COLIEE 2023 or other legal entailment datasets to test generalizability
2. Conduct systematic ablation studies varying the number of predictions (3, 5, 15) and temperature settings to identify optimal configurations
3. Implement alternative label models (e.g., majority voting, Snorkel) to compare their effectiveness against the Generative model approach