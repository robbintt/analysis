---
ver: rpa2
title: 'IBD-PSC: Input-level Backdoor Detection via Parameter-oriented Scaling Consistency'
arxiv_id: '2405.09786'
source_url: https://arxiv.org/abs/2405.09786
tags:
- attacks
- benign
- samples
- backdoor
- poisoned
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a simple yet effective input-level backdoor
  detection (IBD-PSC) method to filter out malicious testing images. The method is
  motivated by the observation that the prediction confidences of poisoned samples
  are significantly more consistent than those of benign ones when amplifying model
  parameters, a phenomenon termed parameter-oriented scaling consistency (PSC).
---

# IBD-PSC: Input-level Backdoor Detection via Parameter-oriented Scaling Consistency

## Quick Facts
- arXiv ID: 2405.09786
- Source URL: https://arxiv.org/abs/2405.09786
- Authors: Linshan Hou; Ruili Feng; Zhongyun Hua; Wei Luo; Leo Yu Zhang; Yiming Li
- Reference count: 40
- Primary result: Achieves high AUROC/F1 scores in detecting poisoned samples by amplifying BN parameters

## Executive Summary
IBD-PSC is an input-level backdoor detection method that identifies poisoned samples by exploiting parameter-oriented scaling consistency (PSC). The core insight is that scaling batch normalization parameters causes benign samples to lose confidence in their predicted class while poisoned samples maintain high confidence in the target class. The method amplifies BN parameters starting from the last layer, uses an adaptive algorithm to select optimal layers, and computes PSC values to distinguish poisoned from benign samples. Experiments show superior performance against various backdoor attacks with good resistance to adaptive attacks.

## Method Summary
IBD-PSC detects poisoned samples by scaling batch normalization (BN) parameters in the model and monitoring prediction confidence changes. The method starts with a suspicious image and the original model, then runs an adaptive algorithm to select the starting BN layer for amplification based on local benign sample error rates. It generates multiple scaled models by progressively amplifying BN parameters from the selected layer, computes the PSC value as the average confidence across these models, and compares it to a threshold to make a binary decision. The approach leverages the observation that poisoned samples exhibit more consistent confidences than benign ones when BN parameters are scaled, a phenomenon termed parameter-oriented scaling consistency.

## Key Results
- Achieves high AUROC and F1 scores across CIFAR-10, GTSRB, and SubImageNet-200 datasets
- Outperforms baseline defenses (STRIP, TeCo, SCALE-UP) against diverse attack methods
- Demonstrates resistance to adaptive attacks with only 0.2% performance degradation
- Shows computational efficiency with acceptable memory and inference time overhead

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Poisoned samples exhibit more consistent prediction confidences than benign samples when BN parameters are scaled.
- **Mechanism:** Scaling BN parameters amplifies feature norms differently for benign vs. poisoned samples. For benign samples, increased feature norms cause a shift in predicted class, decreasing confidence in the original label. Poisoned samples, due to their backdoor trigger, maintain high confidence in the target class even with amplified norms.
- **Core assumption:** Backdoored models have larger variance in feature distributions for the target class compared to other classes.
- **Evidence anchors:** [abstract] "the prediction confidences of poisoned samples are significantly more consistent than those of benign ones when amplifying model parameters."
- **Break condition:** If the backdoor trigger does not create a distinct variance pattern in feature space, or if the scaling factor is too small to induce meaningful norm changes.

### Mechanism 2
- **Claim:** Adaptive layer selection improves detection by focusing amplification on layers where trigger features are most prominent.
- **Mechanism:** Algorithm 1 incrementally scales BN layers from the end, monitoring error rate η on local benign samples. When η exceeds threshold ξ, amplification stops. This targets layers where trigger-induced feature changes are most pronounced.
- **Core assumption:** Trigger patterns manifest as complex features learned by deeper convolutional layers.
- **Evidence anchors:** [section 4.3] "motivated by the previous findings that trigger patterns often manifest as complicated features learned by the deeper (convolutional) layers."
- **Break condition:** If trigger features are evenly distributed across layers, or if deeper layers do not capture trigger patterns (e.g., in patch-based attacks with localized triggers).

### Mechanism 3
- **Claim:** Scaling multiple BN layers with a small factor is more stable than scaling a single layer with a large factor.
- **Mechanism:** Amplifying multiple consecutive BN layers with factor ω=1.5 increases feature norm significantly without requiring an unreasonably large single-layer factor, avoiding instability across attacks.
- **Core assumption:** Accumulated amplification across layers produces consistent norm increases.
- **Evidence anchors:** [section 3] "amplifying multiple BN layers with a small factor (e.g., 1.5) can also significantly increase the feature norm in the last pre-FC layer."
- **Break condition:** If BN layers are not sequentially connected in a way that allows cumulative norm increases, or if small factors are insufficient to induce detectable changes.

## Foundational Learning

- **Concept:** Batch Normalization (BN) mechanics
  - Why needed here: IBD-PSC scales BN parameters (γ, β) to induce feature norm changes. Understanding BN's role in feature transformation is critical.
  - Quick check question: What happens to a feature map when BN's γ parameter is scaled up by 1.5?

- **Concept:** Feature norm and prediction confidence relationship
  - Why needed here: Theorem 3.1 links large feature norms to decreased confidence in original predicted class for benign samples. This underpins PSC.
  - Quick check question: If a feature norm doubles, how does it affect the softmax probability of the original class?

- **Concept:** Backdoor attack mechanics (poison-only vs training-controlled)
  - Why needed here: IBD-PSC must work across attack types. Understanding how triggers are embedded (patch, transformation, etc.) informs detection strategy.
  - Quick check question: How does a WaNet attack differ from a BadNets attack in terms of trigger injection?

## Architecture Onboarding

- **Component map:** Suspicious image -> Model Amplification -> Input Detection -> Binary decision
- **Critical path:**
  1. Load suspicious image and original model
  2. Run Algorithm 1 to select k (starting BN layer for amplification)
  3. Generate n scaled models by amplifying k to k+n-1 BN layers
  4. Compute PSC value using Equation (4)
  5. Compare PSC to threshold T and output decision

- **Design tradeoffs:**
  - Memory vs. speed: Storing n amplified models increases memory usage but allows parallel inference; sequential inference saves memory but is slower.
  - Detection accuracy vs. false positives: Higher T reduces false positives but may miss poisoned samples; lower T increases sensitivity but raises false positive rate.
  - Amplification scope: Amplifying only later BN layers (as in IBD-PSC) vs. all layers - later layers may capture trigger features better but could miss shallow-trigger attacks.

- **Failure signatures:**
  - High false positive rate: Likely due to overfitting on benign samples (common in GTSRB per Table A9) or insufficient amplification.
  - Low detection rate: May indicate trigger features are not captured by amplified layers, or scaling factor is too small.
  - Unstable performance across attacks: Could result from attack-specific trigger patterns not aligning with amplification strategy.

- **First 3 experiments:**
  1. **Baseline ablation:** Run IBD-PSC with n=1 (single amplified model) on BadNets attack to confirm need for multiple models.
  2. **Layer selection sensitivity:** Vary ξ in Algorithm 1 (e.g., 0.3, 0.6, 0.9) and observe impact on detection performance across attacks.
  3. **Scaling factor sweep:** Test ω=1.2, 1.5, 1.8 on WaNet attack to find optimal balance between norm increase and stability.

## Open Questions the Paper Calls Out
- How does the IBD-PSC method perform when applied to non-image modalities like text or audio?
- Can the IBD-PSC method be extended to "data-free" scenarios where no local benign samples are available?
- How can the memory and inference time costs of IBD-PSC be reduced?

## Limitations
- Requires a small number of local benign samples for adaptive layer selection, limiting applicability in data-scarce scenarios
- Computational overhead from loading multiple amplified models increases memory and inference time compared to standard inference
- Performance may degrade for attacks with triggers that don't create distinct variance patterns in feature space

## Confidence

**High Confidence:** Experimental results showing superior AUROC and F1 scores compared to baseline defenses across multiple datasets and attack methods. The methodology of amplifying BN parameters is clearly specified and reproducible.

**Medium Confidence:** The theoretical foundation explaining why PSC occurs. While the mathematical derivations are sound, the practical applicability across all backdoor attack scenarios needs more validation.

**Low Confidence:** The claim of being "resistant to adaptive attacks" is based on only one adaptive attack variant (Adaptive WaNet). More comprehensive adaptive attack testing is needed to substantiate this claim.

## Next Checks

1. **Adaptive Attack Robustness Test:** Implement and evaluate IBD-PSC against a broader range of adaptive attacks where adversaries specifically design triggers to maintain confidence stability under parameter scaling.

2. **Cross-Architecture Generalization:** Test IBD-PSC on diverse architectures beyond ResNet and MobileNet (e.g., Vision Transformers, EfficientNet) to validate generalizability.

3. **Trigger Pattern Sensitivity Analysis:** Systematically vary trigger size, location, and complexity to identify which trigger characteristics most impact PSC effectiveness.