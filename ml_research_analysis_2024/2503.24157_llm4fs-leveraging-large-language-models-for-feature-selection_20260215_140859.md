---
ver: rpa2
title: 'LLM4FS: Leveraging Large Language Models for Feature Selection'
arxiv_id: '2503.24157'
source_url: https://arxiv.org/abs/2503.24157
tags:
- feature
- selection
- llms
- methods
- traditional
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses automated feature selection by comprehensively
  evaluating LLM-based methods and proposing LLM4FS, a hybrid strategy where LLMs
  directly apply traditional data-driven techniques (e.g., random forest) on provided
  data samples to compute feature importance scores. Experiments on four datasets
  using AUROC show that LLM4FS outperforms both pure LLM-based and traditional methods
  alone.
---

# LLM4FS: Leveraging Large Language Models for Feature Selection

## Quick Facts
- **arXiv ID:** 2503.24157
- **Source URL:** https://arxiv.org/abs/2503.24157
- **Reference count:** 24
- **Primary result:** LLM4FS, a hybrid LLM + traditional method strategy, outperforms both pure LLM and traditional methods alone on four datasets, with DeepSeek-R1 achieving GPT-4.5-level performance at 1.5% of the cost.

## Executive Summary
This paper introduces LLM4FS, a hybrid approach for automated feature selection that combines the contextual understanding of large language models with the statistical reliability of traditional data-driven methods. The LLM is prompted to directly apply traditional algorithms (like random forest) to a small sample of the data and output feature importance scores. Experiments on four datasets using AUROC show that LLM4FS outperforms both pure LLM-based and traditional methods alone. DeepSeek-R1 achieves performance comparable to GPT-4.5 at only 1.5% of its cost, and LLM4FS with DeepSeek-R1+RF offers improved stability and computational efficiency, maintaining speed while enhancing accuracy.

## Method Summary
LLM4FS leverages LLMs as orchestrators that apply traditional feature selection methods to small data samples. The process involves sampling approximately 200 data points, prompting the LLM to execute a specified traditional algorithm (e.g., random forest) on these samples, and outputting feature importance scores in JSON format. The LLM's role is reduced to procedural execution of a reliable statistical method rather than reasoning about features from knowledge. The resulting scores are used to rank features, with the top 30% evaluated by downstream logistic regression AUROC. The approach aims to combine LLM interpretability with the robustness of traditional methods while maintaining cost efficiency.

## Key Results
- LLM4FS outperforms both pure LLM-based and traditional methods alone on four datasets using AUROC
- DeepSeek-R1 achieves GPT-4.5-level performance at only 1.5% of the cost
- LLM4FS with DeepSeek-R1+RF offers improved stability and computational efficiency
- Hybrid strategy achieves good trade-off between speed and accuracy while maintaining stability

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLM4FS improves performance by combining the LLM's contextual/data-interpretation capabilities with the statistical robustness of traditional feature selection methods.
- **Mechanism:** The LLM is prompted with raw data samples and instructed to directly call a specific traditional algorithm (e.g., random forest). The LLM acts as an orchestrator that can parse the data format, select the appropriate computational method, execute it (by generating runnable code or simulating the computation), and output the resulting importance scores. This leverages the LLM's ability to understand task instructions and data structure to apply a reliable, data-driven scoring method.
- **Core assumption:** The LLM can correctly interpret a CSV of raw samples and accurately simulate or generate code for the specified traditional algorithm's feature importance calculation.
- **Evidence anchors:**
  - [abstract]: "hybrid strategy leverages the contextual understanding of LLMs and the high statistical reliability of traditional data-driven methods"
  - [section II.B]: Detailed prompt instructs LLM to "apply random forest... to analyze the dataset samples" and output scores in JSON.
  - [corpus]: Indirect support; neighbor papers explore LLM-based feature selection but not this specific hybrid orchestration pattern.
- **Break condition:** LLM fails to correctly implement the traditional method's logic (e.g., generating incorrect code, misinterpreting the data structure, or producing non-deterministic/score-violating outputs). Evidence: Paper notes "LLMs indeed utilize traditional data-driven feature selection methods, as we execute the code returned by LLMs and obtain the same results (importance scores)."

### Mechanism 2
- **Claim:** The hybrid architecture provides stability and reduces variance compared to pure LLM-based scoring, as the final score is grounded in a deterministic algorithmic computation.
- **Mechanism:** Traditional methods like random forest compute feature importance based on concrete statistical properties (e.g., Gini impurity decrease). When the LLM is constrained to output scores derived from such a method, the output distribution becomes less sensitive to minor prompt variations or LLM generative randomness, leading to more consistent feature rankings across runs.
- **Core assumption:** The underlying traditional method's importance scores are inherently more stable and reproduceable than an LLM's purely generative, knowledge-based scoring.
- **Evidence anchors:**
  - [section IV.B Finding 5]: "DeepSeek-R1 demonstrates stability in the search path... DeepSeek-R1+RF exhibit commendable performance while maintaining stability."
  - [section IV.B Finding 4]: Hybrid strategy achieves a good trade-off between speed and accuracy, implying controlled variance.
  - [corpus]: Weak direct evidence; neighbor papers discuss stability of LLM outputs but not via this hybrid anchoring.
- **Break condition:** The LLM consistently fails to apply the traditional method correctly, introducing new variance. Or, the chosen traditional method itself is unstable on small sample subsets provided to the LLM.

### Mechanism 3
- **Claim:** The approach achieves strong cost-performance efficiency by using a small, cheap data sample (~200 points) to elicit the LLM's orchestration of a powerful method, avoiding the cost of full-data LLM processing or expensive API calls for complex reasoning.
- **Mechanism:** Instead of requiring the LLM to reason over the entire dataset or generate feature importance from latent knowledge (which may be costly and unreliable), the system provides a small, representative sample. The LLM's task is reduced to procedural execution ("call random forest on this"), which cheaper/faster models (like DeepSeek-R1) can perform reliably. The computational heavy lifting is done by the efficient traditional method on the small sample.
- **Core assumption:** A small, random sample (~200 points) is sufficient for the traditional method (e.g., random forest) to generate a robust feature importance ranking that generalizes to the full dataset.
- **Evidence anchors:**
  - [section II.B]: "send approximately 200 data samples (typically accounting for 20% or less of the total data)"
  - [section IV.B Finding 3 & Fig. 6]: DeepSeek-R1 achieves performance comparable to GPT-4.5 at 1.5% of the cost, and hybrid strategies maintain speed while improving accuracy.
  - [corpus]: No direct cost-efficiency evidence in neighbors.
- **Break condition:** The small sample is not representative, causing the traditional method's scores on it to poorly correlate with scores from the full dataset, degrading downstream performance.

## Foundational Learning

- **Concept: Prompt Engineering for Tool/Code Execution**
  - *Why needed here:* The core of LLM4FS is a prompt that directs an LLM to *use* a traditional method, not just reason about features. This requires crafting instructions that unambiguously specify the algorithm, input data format, and output format (JSON with scores in [0,1]).
  - *Quick check question:* If the prompt says "apply random forest and provide an importance score for every feature," what minimal elements must you explicitly define to ensure the LLM generates executable, correctly-formatted results?

- **Concept: Traditional Feature Selection Algorithms**
  - *Why needed here:* To design the LLM's task and evaluate the results, one must understand what methods like Random Forest, Forward Selection, or MRMR actually compute and their statistical assumptions (e.g., RF importance is based on impurity decrease, not necessarily predictive power on unseen data).
  - *Quick check question:* Why might the feature importance scores from a Random Forest trained on a 200-sample subset differ from scores computed on the full training set? What does this imply for the hybrid strategy's design?

- **Concept: API-Based LLM Interaction & Output Parsing**
  - *Why needed here:* The system calls LLMs via API (see section III.A.1). Implementation requires handling API parameters (temperature T=0.1), parsing structured responses (JSON), and managing potential invalid outputs or errors from the LLM.
  - *Quick check question:* The paper sets `T=0.1` for more stable outputs. What is the causal trade-off here between output stability and diversity/creativity for this specific task?

## Architecture Onboarding

- **Component map:** Data Sampler -> Prompt Constructor -> LLM Client -> Response Parser & Validator -> Feature Ranker -> Downstream Evaluator
- **Critical path:** Data Sampler → Prompt Constructor → LLM Client → Response Parser → Feature Ranker. The parser is a key failure point.
- **Design tradeoffs:**
  - *Sample Size:* Smaller samples are cheaper/faster for LLM context but may yield unreliable traditional method scores. Paper uses ~200 (≤20%).
  - *Traditional Method Choice:* RF is highlighted as stable; other methods (forward/backward) may lead to instability (section IV.C). Trade stability for potential marginal gains.
  - *LLM Model:* Cost (Fig.5) vs. reliability (GPT-o3-mini may yield "lower or invalid values"). DeepSeek-R1 offers best reported balance.
- **Failure signatures:**
  1. **Invalid JSON:** Parser fails. Response likely missing or malformed. Mitigation: stricter prompt, retry logic.
  2. **Score Range Violation:** Scores outside [0,1] or non-unique. Indicates LLM did not follow instruction. Mitigation: output validation and re-prompt.
  3. **Method Misapplication:** LLM returns scores based on its own knowledge, not the requested algorithm. Detectable by: a) executing returned code yields different results, b) scores differ significantly from running the method directly on the sample. Mitigation: more explicit prompting, using few-shot examples of correct code output.
- **First 3 experiments:**
  1. **Baseline LLM-Only:** Implement prompt from Section II.A (semantic assessment). Run on one dataset (e.g., Pima) with DS-R1. Compare top-30% feature AUROC to traditional RF baseline. Expect: performance gap.
  2. **Hybrid Proof-of-Concept (RF):** Implement LLM4FS with `random forest` as the sole method. Use 200-sample prompt. Parse JSON scores. Compare AUROC to pure LLM and pure RF on same sample. Expect: hybrid matches or surpasses both.
  3. **Cost & Stability Check:** For one dataset, run LLM-only vs. LLM4FS+RF with both DS-R1 and GPT-o3-mini. Log: API cost (per 1k tokens), wall-clock time, AUROC at 30% features, and variance across 3 random seeds (sample subset + LLM T=0.1). Expect: DS-R1+RF best cost-accuracy-stability trade-off.

## Open Questions the Paper Calls Out

- **Question:** How can LLM4FS be stabilized to ensure consistent high performance when integrated with traditional feature selection methods beyond random forest?
  - **Basis in paper:** [explicit] "its performance still shows noticeable instability when paired with other traditional data-driven approaches. This highlights a crucial limitation and suggests that improving the stability and robustness of the hybrid framework across a wider range of models remains a key direction for future research."
  - **Why unresolved:** The evaluation focuses on random forest; instability with other methods (e.g., forward selection, MRMR) is noted but not analyzed or mitigated.
  - **What evidence would resolve it:** Extensive experiments with multiple traditional methods (e.g., forward, backward, RFE, MRMR) across diverse datasets, diagnosing causes (e.g., hyperparameter sensitivity, dataset characteristics), and proposing stabilization strategies (e.g., adaptive method selection, ensembles) that yield robust AUROC improvements.

- **Question:** What privacy-preserving techniques can be integrated into LLM4FS to prevent sensitive data leakage from private datasets (e.g., healthcare)?
  - **Basis in paper:** [explicit] "A key concern is whether LLMs can inadvertently record or retain sensitive information from these datasets, potentially leading to unintentional data leakage when responding to queries. Federated learning presents a promising solution."
  - **Why unresolved:** The privacy risk is raised but not empirically investigated or addressed in the LLM4FS implementation.
  - **What evidence would resolve it:** Conduct membership inference or reconstruction attacks on LLM4FS to quantify leakage; then implement and evaluate federated learning or differential privacy within the pipeline, measuring trade-offs between privacy guarantees and feature selection performance (AUROC).

- **Question:** Can a specialized foundational model for feature engineering be created to automate feature selection more effectively than general-purpose LLMs?
  - **Basis in paper:** [explicit] "Developing such a foundational model—which provides a unified, robust, and user-friendly interface for complex data processing tasks—will greatly benefit the intelligent decision-making community."
  - **Why unresolved:** The paper adapts general LLMs with traditional methods; no dedicated model for feature engineering exists or is evaluated.
  - **What evidence would resolve it:** Pre-train a large model on diverse tabular datasets with feature selection objectives, benchmark it against LLM4FS and traditional methods on a heterogeneous suite of datasets, and demonstrate gains in automation, robustness, and accuracy.

## Limitations

- The stability and performance gains depend heavily on the chosen traditional method (RF vs. MRMR), with RF being the most reliable
- The 200-sample size is justified as sufficient for robust ranking, but the paper does not explore the sensitivity of this choice
- The claim of cost efficiency relies on DeepSeek-R1's performance; results may differ with other models or pricing
- The paper does not deeply explore why certain traditional methods (e.g., MRMR) are unstable when orchestrated by LLMs

## Confidence

- **High:** The hybrid strategy's mechanism (LLM orchestrating traditional methods) is clearly explained and empirically supported. The AUROC improvement and cost efficiency with DeepSeek-R1 are directly observed in experiments.
- **Medium:** The stability and reduced variance of the hybrid approach are inferred from observed results (Finding 5) and the grounding in deterministic algorithmic computation. The claim that a small sample suffices for robust ranking is supported but not extensively validated.
- **Low:** The paper does not deeply explore why certain traditional methods (e.g., MRMR) are unstable when orchestrated by LLMs, nor does it test the limits of the 200-sample size or the sensitivity to prompt variations.

## Next Checks

1. **Prompt Fidelity Test:** For one dataset, run LLM4FS with the exact prompt from the paper (if available) and compare the returned scores to those obtained by running the specified traditional method (e.g., Random Forest) directly on the 200-sample subset. This validates whether the LLM is truly orchestrating the method or hallucinating.

2. **Sample Size Sensitivity:** Repeat the experiment with different sample sizes (e.g., 100, 200, 500) for the hybrid strategy on one dataset. Measure AUROC and stability (variance across 3 seeds) to confirm that 200 is a robust choice and identify the point of diminishing returns.

3. **Method Stability Comparison:** Run the hybrid strategy with multiple traditional methods (RF, MRMR, Forward Selection) on one dataset. Compare not only AUROC but also the consistency of feature rankings across multiple random seeds for the 200-sample selection. This isolates the source of instability (LLM vs. method).