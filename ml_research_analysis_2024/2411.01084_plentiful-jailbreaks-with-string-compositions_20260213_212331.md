---
ver: rpa2
title: Plentiful Jailbreaks with String Compositions
arxiv_id: '2411.01084'
source_url: https://arxiv.org/abs/2411.01084
tags:
- string
- attack
- transformations
- arxiv
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores how invertible string transformations like
  leetspeak, Base64, and Morse code can be composed into complex encoding schemes
  to jailbreak large language models. The authors introduce an automated framework
  that samples from thousands of possible string compositions to generate adversarial
  prompts.
---

# Plentiful Jailbreaks with String Compositions

## Quick Facts
- arXiv ID: 2411.01084
- Source URL: https://arxiv.org/abs/2411.01084
- Reference count: 6
- Best-of-n attack achieves jailbreak success rates of up to 91% across multiple frontier models

## Executive Summary
This paper introduces an automated framework for jailbreaking large language models using compositional string transformations. By sampling from thousands of possible string compositions involving transformations like leetspeak, Base64, and Morse code, the authors demonstrate that encoding-based attacks remain highly effective against frontier models. The best-of-n attack strategy, which randomly samples multiple compositions per harmful intent, achieves significantly higher success rates than standalone transformations.

## Method Summary
The paper proposes an automated best-of-n attack framework that samples from a combinatorially large number of string compositions to jailbreak LLMs. The method uses 20 invertible string transformations (reversal, leetspeak, Base64, Morse code, etc.) composed in sequence to encode harmful prompts. For each harmful intent, the framework randomly samples n compositions and considers the intent jailbroken if at least one composition produces an unsafe response. The approach is evaluated on HarmBench using a judge classifier to determine if responses are harmful.

## Key Results
- Ensemble attack with all 20 standalone transformations achieves significantly higher ASR than individual transformations
- Adaptive best-of-n attack achieves comparable ASRs to ensemble attack with similar attack budget
- Up to 91% jailbreak success rate across multiple frontier models (Claude 3.5 Sonnet, Claude 3 Haiku, Claude 3 Opus, GPT-4o, GPT-4o-mini)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adversarial inputs with string transformations exploit a common vulnerability across different LLMs, where encoding schemes bypass safety alignment while preserving semantic meaning.
- Mechanism: Invertible transformations encode harmful intent in ways that models fail to recognize as dangerous, while still being able to generate harmful content when decoded.
- Core assumption: LLMs treat encoded text as semantically different from the original, missing safety signals during pre-decoding processing.
- Evidence anchors:
  - [abstract] "encoding-based attacks remain a persistent vulnerability even in advanced LLMs"
  - [section] "Many standalone transformations yield unimpressive ASRs, but for every single model, the ensemble attack obtains a significantly higher ASR"
  - [corpus] Weak - neighbor papers focus on compositional attacks and defenses, but don't directly validate the shared vulnerability hypothesis
- Break condition: Models develop pre-decoding safety classifiers that recognize encoded harmful intent patterns across transformation types.

### Mechanism 2
- Claim: Random sampling of string compositions creates novel attack vectors that evade model defenses trained on fixed transformation patterns.
- Mechanism: The combinatorial space of string compositions means most sampled attacks are unique, avoiding memorization-based defenses.
- Core assumption: Model defenses are primarily trained on known transformation patterns, not the vast space of possible compositions.
- Evidence anchors:
  - [abstract] "With 20 individual transformations in our library, we can generate a combinatorially large number of string compositions"
  - [section] "Because it is infeasible to ensemble all compositions, we incorporate random sampling into an adaptive attack scheme"
  - [corpus] Weak - neighbor papers mention compositional attacks but don't analyze the novelty space exploitation
- Break condition: Models implement dynamic safety checking that analyzes semantic content regardless of encoding complexity.

### Mechanism 3
- Claim: The adaptive best-of-n sampling strategy increases attack success by exploiting the "one-shot" nature of most model defenses.
- Mechanism: By sampling multiple compositions per intent, the attack finds at least one that bypasses the model's single-pass safety filters.
- Core assumption: Models apply safety filters once per input rather than recursively or iteratively across transformation layers.
- Evidence anchors:
  - [section] "Given an attack budget n, for some harmful intent, we randomly sample n compositions... and consider the intent jailbroken if at least one composition resulted in a harmful response"
  - [section] "The adaptive attack obtains comparable ASRs to our previous ensemble attack with a comparable attack budget"
  - [corpus] Weak - neighbor papers don't discuss the effectiveness of multiple sampling strategies
- Break condition: Models implement multi-pass safety checking or aggregate safety scores across transformation layers.

## Foundational Learning

- Concept: Invertible string transformations
  - Why needed here: The entire attack framework depends on being able to encode and decode text programmatically without information loss
  - Quick check question: If transformation f is invertible, what must be true about f⁻¹(f(s)) for any input string s?
  
- Concept: Combinatorial explosion in transformation compositions
  - Why needed here: Understanding why random sampling is necessary and why defenses struggle with this attack vector
  - Quick check question: With 20 transformations and compositions of length 3, approximately how many unique compositions are possible (assuming order matters and repetitions allowed)?

- Concept: Adversarial attack success rate (ASR) measurement
  - Why needed here: The paper's primary evaluation metric requires understanding how to measure and interpret attack effectiveness
  - Quick check question: If an attack succeeds on 16 out of 20 harmful intents, what is the ASR percentage?

## Architecture Onboarding

- Component map: Attack generator → String composition sampler → Prompt template engine → Model interface → Judge classifier → Success aggregator
- Critical path: Random composition sampling → Prompt generation → Model inference → Judge classification → Success determination
- Design tradeoffs: Breadth (many transformations) vs depth (complex compositions) - more transformations increases coverage but may reduce effectiveness per composition
- Failure signatures: Low ASR across all models suggests transformation library issues; high variance suggests sampling problems; model-specific failures suggest alignment differences
- First 3 experiments:
  1. Run ensemble attack with all 20 standalone transformations on a single model to establish baseline vulnerability
  2. Test adaptive attack with n=5 on same model to verify sampling improves success rate
  3. Compare ASR between intent-targeted vs response-targeted compositions to identify optimal attack direction

## Open Questions the Paper Calls Out

The paper doesn't explicitly call out open questions, but several remain:

### Open Question 1
- Question: How does the performance of string composition-based jailbreaks scale with increasing composition length and complexity?
- Basis in paper: [inferred] The paper mentions using 2-3 transformations in compositions and sampling from thousands of possible compositions, but doesn't explore the effects of longer or more complex compositions
- Why unresolved: The paper focuses on compositions of 2-3 transformations and doesn't systematically study how attack success rates change as compositions become longer or more complex
- What evidence would resolve it: Systematic experiments varying composition length (e.g., 1, 2, 3, 4, 5 transformations) and measuring attack success rates across different model families would show the relationship between composition complexity and jailbreak effectiveness

### Open Question 2
- Question: Are there specific combinations of string transformations that are more effective than others, or does effectiveness scale randomly with composition length?
- Basis in paper: [inferred] The paper uses random sampling of compositions but doesn't analyze whether certain transformation sequences are systematically more effective
- Why unresolved: The adaptive attack randomly samples compositions without analyzing patterns in which transformations work best together
- What evidence would resolve it: Analysis of attack success rates for specific transformation combinations, including whether certain transformations (like binary/Base64) are more effective when placed in specific positions within compositions

### Open Question 3
- Question: How do string composition attacks perform against models specifically trained to resist encoding-based jailbreaks?
- Basis in paper: [explicit] The paper concludes by encouraging safety researchers to devote attention to these attacks, implying they may not be well-defended against
- Why unresolved: The paper only tests against standard frontier models without exploring how models trained with specific defenses against encoding attacks would perform
- What evidence would resolve it: Testing the same attack methods against models trained with defenses specifically targeting string transformations (e.g., automatic decoding of inputs, detection of encoded content) would reveal the effectiveness of such defenses

## Limitations
- Effectiveness relies on models' ability to reliably apply and reverse complex formatting operations, which may vary across architectures
- The adaptive best-of-n sampling strategy creates scalability challenges due to the combinatorially large attack space
- The HarmBench dataset may not fully represent the complete space of harmful content that could be encoded through string compositions

## Confidence
**High Confidence**: The fundamental observation that invertible string transformations can be composed to create jailbreaking attacks is well-supported by experimental results showing high ASR (up to 91%) across multiple models.

**Medium Confidence**: The claim that encoding-based attacks represent a "persistent vulnerability" is supported by the results but lacks longitudinal evidence showing whether this vulnerability persists as models are updated or fine-tuned specifically to defend against such attacks.

**Low Confidence**: The assertion that compositional attacks are fundamentally more effective than single transformations is primarily demonstrated through ensemble comparisons rather than systematic ablation studies of composition complexity versus effectiveness.

## Next Checks
1. **Transformation Reliability Audit**: Systematically test the invertibility and reliability of each transformation across different model families to quantify the failure rates of complex transformations (JSON, LaTeX, Python markdown) versus simpler ones.

2. **Composition Complexity Analysis**: Conduct controlled experiments varying composition length and transformation types to determine whether longer compositions consistently yield higher ASR or whether there's a complexity threshold beyond which effectiveness plateaus or decreases.

3. **Dynamic Safety Filter Evaluation**: Test whether models with iterative or multi-pass safety checking show reduced vulnerability to compositional attacks compared to single-pass models, directly validating the paper's mechanism assumption about one-shot safety filters.