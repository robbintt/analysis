---
ver: rpa2
title: Learning Spatio-Temporal Patterns of Polar Ice Layers With Physics-Informed
  Graph Neural Network
arxiv_id: '2406.15299'
source_url: https://arxiv.org/abs/2406.15299
tags:
- graph
- layers
- layer
- learning
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a physics-informed graph neural network, PSAGE-LSTM,
  to predict the thickness of deep polar ice layers using information from shallow
  layers and physical properties from the MAR weather model. The method combines the
  GraphSAGE framework for learning spatial graph features with LSTM for temporal changes,
  and incorporates physical node features like snow mass balance and surface temperature.
---

# Learning Spatio-Temporal Patterns of Polar Ice Layers With Physics-Informed Graph Neural Network

## Quick Facts
- arXiv ID: 2406.15299
- Source URL: https://arxiv.org/abs/2406.15299
- Authors: Zesheng Liu; Maryam Rahnemoonfar
- Reference count: 27
- Primary result: PSAGE-LSTM achieves 2.8526 ± 0.0748 RMSE on Greenland ice sheet thickness prediction

## Executive Summary
This paper proposes a physics-informed graph neural network, PSAGE-LSTM, to predict the thickness of deep polar ice layers using information from shallow layers and physical properties from the MAR weather model. The method combines the GraphSAGE framework for learning spatial graph features with LSTM for temporal changes, and incorporates physical node features like snow mass balance and surface temperature. Experiments on Greenland ice sheet data show that PSAGE-LSTM consistently outperforms non-inductive and non-physical models like GCN-LSTM and GraphSAGE-LSTM, achieving a lower root mean squared error of 2.8526 ± 0.0748 compared to 3.1872 ± 0.0511 for GraphSAGE-LSTM. The results demonstrate the effectiveness of integrating physics-informed learning into graph neural networks for improved prediction of polar ice layer thickness.

## Method Summary
The method predicts deep ice layer thickness by learning spatio-temporal features from shallow layers and physical properties from the MAR weather model. It uses a GraphSAGE-LSTM architecture where GraphSAGE learns spatial relationships through local neighbor sampling, and LSTM captures temporal evolution across years. Physical node features including snow mass balance, surface temperature, and other MAR model outputs are integrated as node attributes. The model is trained on 5 years of shallow layer data (2007-2011) to predict 15 years of deep layer thickness (1992-2006), using MSE loss and Adam optimizer with learning rate scheduling.

## Key Results
- PSAGE-LSTM achieves RMSE of 2.8526 ± 0.0748 on deep ice layer thickness prediction
- GraphSAGE-LSTM baseline achieves 3.1872 ± 0.0511 RMSE
- PSAGE-LSTM outperforms GCN-LSTM, AGCN-LSTM, and Adaptive GraphSAGE-LSTM baselines
- Physical node features from MAR weather model contribute to improved prediction accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GraphSAGE's local neighbor sampling reduces sensitivity to noise in radar echogram images compared to full graph convolution.
- Mechanism: By sampling a fixed number of neighbors at each aggregation step rather than aggregating over all connected nodes, GraphSAGE limits the influence of noisy or outlier measurements in the ice layer thickness data.
- Core assumption: Noise in radar echogram images manifests as spurious connections between nodes that are not physically related, and these spurious connections can be mitigated by limiting neighbor aggregation to a local neighborhood.
- Evidence anchors:
  - [abstract] "Unlike most previous ice layer tracking methods that apply convolutional neural networks to raw echogram images, our proposed method uses a graph neural network to determine the thickness of deep ice layers, where the graph neural network is shown to be less sensitive to noise and has a more stable performance."
  - [section] "Through sampling from the neighbor nodes with different depths, GraphSAGE only learns from limited sampled neighbors instead of the complete input graph, which reduces the adverse effects of possible outliers and enhances the model's generalization ability."

### Mechanism 2
- Claim: Physical node features from the MAR weather model provide auxiliary information that constrains predictions to physically plausible values.
- Mechanism: The integration of snow mass balance, surface temperature, and other physical measurements as node features creates a physically-informed latent space where predictions must align with known physical processes governing ice formation and melting.
- Core assumption: The physical properties measured by the MAR model have direct causal relationships with ice layer formation processes, and these relationships can be learned by the neural network to improve prediction accuracy.
- Evidence anchors:
  - [abstract] "introduce measurements of physical ice properties from Model Atmospheric Regional (MAR) weather model as physical node features"
  - [section] "We focus on five physical properties: snow mass balance, surface temperature, meltwater refreezing, height change due to melting, and snowpack heights."

### Mechanism 3
- Claim: The combination of GraphSAGE for spatial feature learning and LSTM for temporal dynamics enables effective prediction of deep ice layer thickness from shallow layer patterns.
- Mechanism: GraphSAGE captures the spatial relationships between different measurement points across the ice sheet, while LSTM models the temporal evolution of ice layer formation, allowing the network to learn patterns that persist across years and depths.
- Core assumption: The formation patterns of deep ice layers are predictable from the characteristics of shallower layers, and these patterns have both spatial structure (varying across the ice sheet) and temporal consistency (evolving predictably over years).
- Evidence anchors:
  - [abstract] "combines the GraphSAGE framework for graph feature learning with the long short-term memory (LSTM) structure for learning temporal changes"
  - [section] "we will use the shallow five ice layers (2007-2011) to learn the spatio-temporal features of internal ice layers and provide precise predictions for the thickness of fifteen deep ice layers (1992-2006)"

## Foundational Learning

- Concept: Graph neural networks and their variants (GraphSAGE vs GCN)
  - Why needed here: The ice sheet data is naturally represented as a graph where nodes are measurement points and edges represent spatial relationships, making GNNs the appropriate architecture choice.
  - Quick check question: What is the key difference between GraphSAGE and GCN in terms of how they aggregate information from neighboring nodes?

- Concept: Physics-informed machine learning and the integration of physical models with neural networks
  - Why needed here: Ice sheet dynamics are governed by well-understood physical processes, and incorporating these constraints can improve prediction accuracy and physical interpretability.
  - Quick check question: How do physical node features from the MAR model differ from typical learned node features in a standard graph neural network?

- Concept: Spatio-temporal modeling and the challenges of predicting future states from past observations
- Why needed here: The task requires predicting the thickness of deep ice layers (future states) based on the characteristics of shallow layers (past states), which involves modeling both spatial patterns and temporal evolution.
  - Quick check question: Why is an LSTM structure particularly suitable for modeling the temporal aspect of ice layer formation compared to a simple feed-forward network?

## Architecture Onboarding

- Component map: Input sequence of 5 temporal graphs (each with 256 nodes) → PSAGE-LSTM layer (256 channels) → Two hidden linear layers (128 and 64 channels) → Output linear layer (15 channels for 15 years of predictions) → HardSwish activation and Dropout (p=0.2) between layers
- Critical path: The PSAGE-LSTM layer is the core innovation that combines GraphSAGE spatial aggregation with LSTM temporal modeling, incorporating physical node features; all other components serve to process and refine the learned representations
- Design tradeoffs: GraphSAGE's local sampling improves noise robustness but may miss long-range spatial dependencies; physical features add domain knowledge but introduce potential bias if MAR model is inaccurate; LSTM captures temporal patterns but increases model complexity and training time
- Failure signatures: Poor generalization to unseen spatial regions (indicating insufficient spatial modeling); predictions that violate known physical constraints (indicating issues with physics-informed features); high variance across different random seeds (indicating overfitting or instability)
- First 3 experiments:
  1. Train a baseline GraphSAGE-LSTM without physical features to quantify the impact of physics-informed learning
  2. Test different combinations of physical features from the MAR model to identify the most beneficial subset
  3. Compare GraphSAGE-LSTM with GCN-LSTM to verify the noise robustness claim and understand when GraphSAGE's local sampling is advantageous

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different combinations of physical node features from the MAR weather model affect the performance of PSAGE-LSTM?
- Basis in paper: [explicit] The paper states that "Experiments are conducted with different combinations of physical properties as physical node features, where some combinations may enhance the final results while some combinations of physical features will undermine them. This paper will only report the results of the best physical node feature combination."
- Why unresolved: The paper only reports the results of the best physical node feature combination without detailing the performance of other combinations.
- What evidence would resolve it: Comprehensive experimental results comparing the performance of PSAGE-LSTM using various combinations of physical node features from the MAR weather model.

### Open Question 2
- Question: How does the inclusion of the EvolveGCN layer as an adaptive layer impact the stability and performance of graph neural networks like GCN-LSTM and AGCN-LSTM on larger datasets?
- Basis in paper: [explicit] The paper mentions that "we also find that using EvolveGCN as an adaptive layer may not be stable for larger datasets or different models."
- Why unresolved: The paper indicates potential instability with the EvolveGCN layer but does not provide detailed analysis or evidence of its impact on larger datasets.
- What evidence would resolve it: Detailed experimental analysis and results demonstrating the stability and performance of GCN-LSTM and AGCN-LSTM with and without the EvolveGCN layer on larger datasets.

### Open Question 3
- Question: What are the specific challenges and limitations of using airborne snow radar sensor data for predicting deep ice layer thickness, and how can they be mitigated?
- Basis in paper: [explicit] The paper highlights that "noise in the raw echogram images has been proven to be a significant issue" and discusses the limitations of traditional methods and the advantages of graph neural networks.
- Why unresolved: While the paper identifies noise as a significant issue, it does not delve into the specific challenges and potential mitigation strategies for using airborne snow radar sensor data.
- What evidence would resolve it: A comprehensive analysis of the challenges and limitations of airborne snow radar sensor data, along with proposed strategies and their effectiveness in mitigating these issues.

## Limitations
- The model's performance depends on the accuracy of the MAR weather model's physical measurements
- Limited comparison with only four baseline models reduces generalizability of superiority claims
- The relationship between shallow and deep ice layers may not remain consistent under changing climate conditions

## Confidence
- High confidence: The general architecture combining GraphSAGE and LSTM for spatio-temporal ice layer prediction
- Medium confidence: The specific RMSE improvement (2.8526 ± 0.0748 vs 3.1872 ± 0.0511) given the single dataset source
- Medium confidence: The noise robustness claim, which is theoretically sound but not empirically validated through controlled noise injection experiments

## Next Checks
1. Cross-validation with independent ice sheet data: Test the PSAGE-LSTM model on ice sheet data from Antarctica or different time periods to verify generalization beyond the Greenland dataset.

2. Controlled noise sensitivity experiments: Systematically add synthetic noise to the input graphs and compare the performance degradation of GraphSAGE-LSTM versus GCN-LSTM to empirically validate the noise robustness claim.

3. Ablation study of physical features: Remove individual physical features from the MAR model (e.g., surface temperature, snow mass balance) to quantify their individual contributions to the overall performance improvement.