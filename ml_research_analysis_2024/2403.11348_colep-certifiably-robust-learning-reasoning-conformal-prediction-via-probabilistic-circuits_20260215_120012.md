---
ver: rpa2
title: 'COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic
  Circuits'
arxiv_id: '2403.11348'
source_url: https://arxiv.org/abs/2403.11348
tags:
- colep
- prediction
- knowledge
- coverage
- probability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: COLEP proposes a certifiably robust learning-reasoning conformal
  prediction framework using probabilistic circuits to bridge worst-case robustness
  certification and uncertainty quantification. The framework trains multiple data-driven
  models in a learning component and encodes their logical relationships in a reasoning
  component using probabilistic circuits.
---

# COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic Circuits

## Quick Facts
- arXiv ID: 2403.11348
- Source URL: https://arxiv.org/abs/2403.11348
- Authors: Mintong Kang; Nezihe Merve Gürel; Linyi Li; Bo Li
- Reference count: 40
- Key outcome: COLEP achieves up to 12% improvement in certified coverage on GTSRB, 9% on CIFAR-10, and 14% on AwA2 compared to state-of-the-art baselines

## Executive Summary
COLEP introduces a certifiably robust learning-reasoning conformal prediction framework that bridges worst-case robustness certification with uncertainty quantification. The framework trains multiple data-driven models in a learning component and encodes their logical relationships in a reasoning component using probabilistic circuits (PCs). This allows COLEP to provide end-to-end certification of prediction coverage under bounded adversarial perturbations. The theoretical analysis proves that COLEP achieves higher certified coverage and accuracy than single models when knowledge model utilities are non-trivial.

## Method Summary
COLEP integrates a learning component (main model + L knowledge models) with a reasoning component (R probabilistic circuits) to achieve certifiably robust conformal prediction. The learning component consists of a main model and multiple knowledge models trained to detect specific concepts, while the reasoning component uses PCs to encode logical rules between concepts. The framework first certifies the robustness of the learning component using randomized smoothing, then derives bounds on corrected probabilities after reasoning, and finally constructs prediction sets using worst-case non-conformity scores. This end-to-end approach ensures certified coverage under ℓ2 bounded adversarial perturbations.

## Key Results
- COLEP achieves up to 12% improvement in certified coverage on GTSRB, 9% on CIFAR-10, and 14% on AwA2 compared to state-of-the-art baselines
- Theoretical analysis proves COLEP achieves higher prediction coverage and accuracy than single models when knowledge model utilities are non-trivial
- COLEP maintains high coverage under adversarial attacks while providing interpretable uncertainty quantification through probabilistic circuits

## Why This Works (Mechanism)

### Mechanism 1
- Claim: COLEP improves certified coverage by encoding domain knowledge into probabilistic circuits that correct prediction probabilities based on logical implications.
- Mechanism: The reasoning component uses probabilistic circuits (PCs) to encode implication rules (e.g., "IsStopSign =⇒ IsOctagon"). When a perturbed input causes the main model to misclassify (e.g., a speed limit sign as a stop sign), the PC down-weights the incorrect probability based on the logical contradiction with the shape knowledge model. This correction is computed exactly and efficiently using the PC structure, which guarantees that the corrected probability reflects the encoded domain knowledge.
- Core assumption: The knowledge models accurately detect their respective concepts and the encoded logical rules are valid for the dataset.
- Evidence anchors:
  - [abstract]: "COLEP proposes a certifiably robust learning-reasoning conformal prediction framework using probabilistic circuits to bridge worst-case robustness certification and uncertainty quantification."
  - [section 3.2]: "To achieve exact and efficient reasoning, we employ probabilistic circuits (PCs) within the reasoning component."
  - [section 3.2]: "The reasoning component can correct the output probability with encoded knowledge rules and improve the robustness of the prediction."
- Break condition: If the knowledge models are inaccurate or the logical rules are invalid, the PC corrections will be incorrect, potentially degrading performance below that of a single model.

### Mechanism 2
- Claim: COLEP achieves higher certified coverage than a single model when knowledge model utilities are non-trivial.
- Mechanism: The theoretical analysis shows that COLEP's prediction coverage improves when the knowledge models have high utility (measured by T(r) and Z(r) values) and the logical rules have high uniqueness (measured by U(r)). The reasoning component corrects the main model's probabilities in a way that increases confidence in the true class while decreasing confidence in incorrect classes, leading to better coverage in adversarial settings.
- Core assumption: The utility of knowledge models and the uniqueness of logical rules are sufficiently high to make the correction beneficial.
- Evidence anchors:
  - [abstract]: "Theoretically, we provide end-to-end certification of prediction coverage for COLEP under ℓ2 bounded adversarial perturbations. We also provide certified coverage considering the finite size of the calibration set. Furthermore, we prove that COLEP achieves higher prediction coverage and accuracy over a single model as long as the utilities of knowledge models are non-trivial."
  - [section 5.3]: "Theorem 4 (Comparison of Marginal Coverage ofCOLEP and Main Model). Consider the adversary setting... Then we have: P[Yn+1 ∈ ˆC COLEP n,α ( ˜Xn+1)] > P[Yn+1 ∈ ˆCn,α( ˜Xn+1)], w.p. 1− max j∈[Nc] {exp [−2nDa(0.5 − A(ˆπj, Da))2ϵ2 j,1,Da] +nDbexp [− 2nDb (A(ˆπj, Db) − 0.5)X c∈{0,1}pjcϵj,c,Db 2]}"
  - [section 5.3]: "Theorem 5 (Comparison of Prediction Accuracy of COLEP and Main Model). Suppose that we evaluate the expected prediction accuracy of ˆπCOLEP j (·) and ˆπj(·) on n samples drawn from Dm and denote the prediction accuracy as A(ˆπCOLEP j (·), Dm) and A(ˆπj(·), Dm). Then we have: A(ˆπCOLEP j (·), Dm) ≥ A(ˆπj(·), Dm), w.p. 1− X D∈{Da,Db}pD X c∈{0,1}PD [Y = j] exp [−2n(ϵj,c,D)2]."
- Break condition: If the knowledge models have low accuracy or the logical rules are too general (low uniqueness), the corrections may not improve coverage and could even harm it.

### Mechanism 3
- Claim: COLEP provides end-to-end certified coverage by combining robustness certification of the learning component with exact reasoning through PCs.
- Mechanism: The framework first certifies the robustness of the learning component (main and knowledge models) using methods like randomized smoothing to get bounds on their output probabilities under input perturbations. Then, using Theorem 1, it derives bounds on the corrected probabilities after the reasoning component. Finally, it constructs prediction sets using worst-case non-conformity scores that account for these bounds, ensuring certified coverage under bounded perturbations.
- Core assumption: The learning component can be certified using existing robustness methods, and the PC reasoning is exact and efficient.
- Evidence anchors:
  - [abstract]: "Theoretically, we provide end-to-end certification of prediction coverage for COLEP in the presence of bounded adversarial perturbations."
  - [section 4.1]: "We use randomized smoothing (Cohen et al., 2019) (details in Appendix C.3), and get the bound of ˆπ under the perturbation. Next, we certify reasoning robustness by deriving the reasoning-corrected bounds using the bounds of the learning component (Thm. 1)."
  - [section 4.2]: "Theorem 2 (Certifiably Robust Conformal Prediction of COLEP). Consider a new test sample Xn+1 drawn from PXY . For any bounded perturbation ∥ϵ∥2 ≤ δ in the input space and the adversarial sample ˜Xn+1 := Xn+1 + ϵ, we have the following guaranteed marginal coverage: P[Yn+1 ∈ ˆC COLEPδ n,α ( ˜Xn+1)] ≥ 1 − α"
- Break condition: If the learning component certification is too loose or the PC reasoning is approximate rather than exact, the end-to-end certification guarantees may not hold.

## Foundational Learning

- Concept: Probabilistic Circuits (PCs) for exact and efficient inference
  - Why needed here: PCs allow exact computation of marginal probabilities and logical reasoning with weighted rules, which is essential for the reasoning component to correct predictions efficiently and provably.
  - Quick check question: Can you explain why PCs are preferred over Markov Logic Networks (MLNs) for this application?

- Concept: Randomized smoothing for learning component certification
  - Why needed here: Randomized smoothing provides probabilistic guarantees on model predictions under input perturbations, which is necessary to bound the outputs of the main and knowledge models before they enter the reasoning component.
  - Quick check question: What is the relationship between the smoothing parameter σ and the perturbation bound δ in randomized smoothing?

- Concept: Conformal prediction with non-conformity scores
  - Why needed here: Conformal prediction provides statistically rigorous prediction sets with guaranteed coverage, which is the foundation that COLEP builds upon by making it robust to adversarial perturbations.
  - Quick check question: How does the choice of non-conformity score function affect the size and coverage of prediction sets?

## Architecture Onboarding

- Component map:
  - Learning component: Main model + L knowledge models (DNNs trained to detect specific concepts)
  - Reasoning component: R probabilistic circuits encoding logical rules between concepts
  - Output: Corrected conditional probabilities used for conformal prediction

- Critical path:
  1. Input passes through main model and knowledge models
  2. Their outputs are fed into the reasoning component (PCs)
  3. PCs compute corrected probabilities using encoded logical rules
  4. Corrected probabilities are used to construct prediction sets via conformal prediction

- Design tradeoffs:
  - More knowledge models improve coverage but increase computational cost and require more training data
  - More complex logical rules in PCs improve expressiveness but may reduce efficiency
  - Choice of rule weights affects correction strength; too high can over-correct, too low provides no benefit

- Failure signatures:
  - Low coverage: Knowledge models are inaccurate or logical rules are invalid
  - High computational cost: Too many knowledge models or overly complex PCs
  - Degraded performance vs single model: Rule weights are poorly chosen or knowledge is not relevant

- First 3 experiments:
  1. Implement a simple COLEP with one main model, one knowledge model, and one PC with a single rule on a toy dataset
  2. Evaluate certified coverage under ℓ2 perturbations on GTSRB with shape knowledge only
  3. Compare coverage and set size with RSCP baseline under PGD attack on CIFAR-10

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of COLEP scale with an increasing number of knowledge rules and PCs?
- Basis in paper: [explicit] The paper mentions that COLEP has 3 PCs and 28 knowledge rules in GTSRB, 3 PCs and 30 knowledge rules in CIFAR-10, and 4 PCs and 187 knowledge rules in AwA2. It also states that the utility of knowledge models and rules positively correlates with the effectiveness of COLEP.
- Why unresolved: The paper does not provide a systematic analysis of how COLEP's performance changes as the number of knowledge rules and PCs increases. It only provides results for the specific configurations used in the experiments.
- What evidence would resolve it: Experiments evaluating COLEP's performance with varying numbers of knowledge rules and PCs, showing the relationship between the number of rules and PCs and the certified coverage and accuracy.

### Open Question 2
- Question: How does COLEP handle cases where the knowledge rules contain errors or are incomplete?
- Basis in paper: [explicit] The paper discusses the potential limitations of COLEP, including the access to knowledge rules and the possibility of knowledge rules being contaminated by adversarial attacks or containing noises and misinformation.
- Why unresolved: The paper does not provide a detailed analysis of how COLEP performs when the knowledge rules are imperfect. It only mentions that the process of knowledge-checking is independent and parallel to COLEP.
- What evidence would resolve it: Experiments evaluating COLEP's performance with knowledge rules that contain errors or are incomplete, showing the impact of imperfect knowledge rules on the certified coverage and accuracy.

### Open Question 3
- Question: How does the selection of weights for knowledge rules affect the performance of COLEP?
- Basis in paper: [explicit] The paper mentions that the weight w of logical rules is specified based on the utility of the corresponding knowledge rule and that the effectiveness of COLEP correlates with the utility of knowledge rules. It also states that the authors assume all knowledge rules have the same weight w and select a proper weight via grid searching.
- Why unresolved: The paper does not provide a detailed analysis of how different weight selection strategies affect COLEP's performance. It only mentions that the authors use a fixed weight of 1.5 for all knowledge rules.
- What evidence would resolve it: Experiments evaluating COLEP's performance with different weight selection strategies, showing the impact of weight selection on the certified coverage and accuracy.

## Limitations

- Performance depends critically on the accuracy of knowledge models and validity of encoded logical rules - incorrect knowledge can degrade performance below single-model baselines
- Computational overhead from maintaining multiple knowledge models and performing exact PC reasoning may limit scalability to complex domains
- The framework requires access to domain-specific knowledge rules, which may not be available or may be imperfect in real-world applications

## Confidence

- **High Confidence**: The end-to-end certification framework combining randomized smoothing with PC reasoning for constructing certified prediction sets (Mechanism 3)
- **Medium Confidence**: The theoretical improvement guarantees when knowledge model utilities are non-trivial (Mechanism 2) - depends on empirical validation of T(r), Z(r), and U(r) values
- **Medium Confidence**: The exact reasoning capability of PCs for correcting prediction probabilities (Mechanism 1) - assumes correct encoding of domain knowledge

## Next Checks

1. **Rule Validity Assessment**: Systematically evaluate the impact of invalid or noisy knowledge rules on COLEP performance across all three datasets to identify break conditions for Mechanism 1
2. **Utility Threshold Analysis**: Determine the minimum utility thresholds (T(r), Z(r), U(r)) required for COLEP to outperform single models on each dataset to validate Mechanism 2 assumptions
3. **Computational Overhead Benchmarking**: Measure the per-inference computational cost of COLEP versus baselines, including PC reasoning time, to assess scalability limitations for real-world deployment