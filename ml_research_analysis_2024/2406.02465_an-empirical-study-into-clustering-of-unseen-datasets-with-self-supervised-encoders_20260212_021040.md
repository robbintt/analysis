---
ver: rpa2
title: An Empirical Study into Clustering of Unseen Datasets with Self-Supervised
  Encoders
arxiv_id: '2406.02465'
source_url: https://arxiv.org/abs/2406.02465
tags:
- clustering
- encoders
- dino
- moco-v3
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether self-supervised learning (SSL)
  encoders can cluster unseen datasets without retraining. The authors cluster embeddings
  from SSL models (MoCo-v3, DINO, VICReg, MAE) and supervised models on 26 datasets,
  measuring agreement with ground-truth labels using AMI.
---

# An Empirical Study into Clustering of Unseen Datasets with Self-Supervised Encoders

## Quick Facts
- arXiv ID: 2406.02465
- Source URL: https://arxiv.org/abs/2406.02465
- Reference count: 40
- Self-supervised encoders outperform supervised models on far-out-of-domain clustering tasks

## Executive Summary
This empirical study investigates whether self-supervised learning (SSL) encoders can effectively cluster unseen datasets without retraining. The authors evaluate 26 diverse image datasets using SSL models (MoCo-v3, DINO, VICReg, MAE) and supervised models, measuring clustering performance via Adjusted Mutual Information (AMI). Results show SSL encoders perform worse than supervised models on in-domain data but outperform them on far-out-of-domain datasets. Fine-tuned SSL encoders perform best near training domains but degrade on far-OOD data. The study reveals that clustering quality correlates with silhouette scores in UMAP-reduced space, enabling proxy evaluation without labels. The research demonstrates that SSL encoders prioritize different features than supervised models, particularly in background-foreground relationships.

## Method Summary
The study evaluates clustering performance by extracting embeddings from pre-trained SSL and supervised encoders across 26 diverse image datasets. For each dataset, the authors apply clustering algorithms to the embeddings and measure agreement with ground-truth labels using Adjusted Mutual Information (AMI). The evaluation includes baseline SSL models (MoCo-v3, DINO, VICReg, MAE) and supervised models, as well as fine-tuned versions of SSL encoders. Clustering quality is also assessed in UMAP-reduced embedding space using silhouette scores to establish a proxy metric for evaluation without ground-truth labels. The datasets span various domains and image types to test domain generalization capabilities.

## Key Results
- SSL encoders perform worse than supervised models on in-domain clustering tasks
- SSL encoders outperform supervised models on far-out-of-domain datasets
- Fine-tuned SSL encoders perform best near training domains but degrade on far-OOD data
- Clustering quality correlates with silhouette scores in UMAP-reduced space, enabling proxy evaluation without labels

## Why This Works (Mechanism)
The effectiveness of SSL encoders on far-OOD clustering stems from their ability to learn feature representations that are invariant to domain-specific characteristics while preserving task-relevant information. Unlike supervised models that optimize for class-specific features aligned with their training data, SSL models learn representations based on self-supervised objectives (e.g., contrastive learning, masked autoencoding) that capture more generalizable visual patterns. This makes SSL embeddings more adaptable to novel domains where supervised models' class-specific features may not transfer well.

## Foundational Learning
1. **Self-Supervised Learning Objectives**: Why needed - To understand how different SSL approaches (contrastive, masked autoencoding) create generalizable representations. Quick check - Review MoCo, DINO, VICReg, and MAE papers to understand their specific objectives.
2. **Clustering Metrics**: Why needed - AMI is the primary evaluation metric requiring understanding of information theory concepts. Quick check - Verify AMI calculation and compare with NMI and ARI for consistency.
3. **Domain Generalization**: Why needed - The study's core contribution involves OOD generalization, requiring understanding of domain shift concepts. Quick check - Review literature on domain adaptation and generalization bounds.

## Architecture Onboarding
Component Map: Pre-trained Encoder -> Feature Extraction -> Clustering Algorithm -> Evaluation (AMI/Silhouette)
Critical Path: The essential flow is encoder extraction → clustering → metric evaluation, where each stage depends on the previous one functioning correctly.
Design Tradeoffs: SSL vs supervised encoders represent the fundamental tradeoff between generalization and task-specific performance.
Failure Signatures: Poor clustering on in-domain data for SSL models indicates domain mismatch; poor far-OOD performance for fine-tuned models suggests overfitting to training distribution.
First Experiments: 1) Test SSL vs supervised clustering on a simple in-domain dataset, 2) Evaluate silhouette correlation with AMI on a held-out validation set, 3) Compare clustering performance across different SSL objectives on a diverse dataset.

## Open Questions the Paper Calls Out
None

## Limitations
- Focus exclusively on image datasets limits generalizability to other data types like text or audio
- Evaluation relies on a single clustering metric (AMI), potentially missing nuances captured by additional metrics
- Qualitative analysis of background-foreground relationships in SSL embeddings lacks quantitative validation

## Confidence
- High: SSL encoders underperform supervised models on in-domain clustering tasks
- Medium: SSL encoders excel on far-OOD datasets
- Low: Clustering quality correlates with silhouette scores in UMAP space

## Next Checks
1. Replicate the study on non-image datasets such as text or audio to assess cross-modal generalizability
2. Conduct ablation studies to isolate the impact of specific SSL objectives (e.g., MoCo vs. DINO) on clustering performance
3. Test additional clustering metrics (e.g., NMI, ARI) to confirm the robustness of the AMI-based conclusions