---
ver: rpa2
title: 'ProIn: Learning to Predict Trajectory Based on Progressive Interactions for
  Autonomous Driving'
arxiv_id: '2403.16374'
source_url: https://arxiv.org/abs/2403.16374
tags:
- agent
- interaction
- prediction
- agents
- trajectory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a progressive interaction network for autonomous
  driving trajectory prediction. The core idea is to incrementally incorporate map
  information into agent features at multiple stages: after historical trajectory
  encoding, after social interaction, and after multi-modal differentiation.'
---

# ProIn: Learning to Predict Trajectory Based on Progressive Interactions for Autonomous Driving

## Quick Facts
- arXiv ID: 2403.16374
- Source URL: https://arxiv.org/abs/2403.16374
- Reference count: 39
- Key outcome: State-of-the-art trajectory prediction with minFDE of 1.1554 on Argoverse 1 and 1.35 on Argoverse 2

## Executive Summary
This paper introduces a progressive interaction network for autonomous driving trajectory prediction that incrementally incorporates map information at three distinct stages: after historical trajectory encoding, after social interaction, and after multi-modal differentiation. The method achieves state-of-the-art performance on Argoverse benchmarks by using graph convolutions to progressively refine agent features with relevant map constraints at each stage. Additionally, the authors propose a weight allocation mechanism for multi-modal training that allows each mode to learn from single-mode ground truth with different weights based on prediction accuracy, improving overall prediction quality.

## Method Summary
The proposed method processes autonomous driving scenes through a multi-stage pipeline. First, agent historical trajectories are encoded using an LSTM-based encoder, while map information is encoded using a graph convolutional network. The core innovation is a progressive interaction network that incorporates map information at three stages: after the initial encoding, after modeling social interactions between agents, and after multi-modal differentiation. This staged approach allows agents to progressively focus on relevant map constraints at each stage. For multi-modal prediction, the method uses k independent MLPs with a weight allocation mechanism that assigns different learning weights to each mode based on their prediction accuracy, rather than using winner-take-all training.

## Key Results
- Achieves state-of-the-art minFDE of 1.1554 on Argoverse 1 test set
- Achieves state-of-the-art minFDE of 1.35 on Argoverse 2 test set
- Outperforms existing methods like LaneGCN, PAGA, and GANet on both datasets
- Demonstrates improved performance over single-stage interaction approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Progressive interaction enables more accurate feature representation by focusing on relevant map regions at each stage.
- Mechanism: The network incorporates map information at three distinct stages—after historical trajectory encoding, after social interaction, and after multi-modal differentiation—using graph convolutions. This staged approach allows the agent feature to progressively refine its understanding of relevant map constraints.
- Core assumption: The relevant map information for each stage is different and can be effectively captured through progressive interaction.
- Evidence anchors:
  - [abstract] "The network progressively encode the complex influence of map constraints into the agent's feature through graph convolutions at the following three stages: after historical trajectory encoder, after social interaction, and after multi-modal differentiation."
  - [section] "The mechanism includes four modules... Firstly, after historical trajectory encoder, we use a Map-Agent interaction module... Secondly, as the map is only one of many factors... An Agent-Agent interaction module is used... Thirdly, to model the fact that agents may change their initial routing... another Map-Agent interaction module is added... Finally, we use k independent MLPs with residuals to achieve multi-modal differentiation."
- Break condition: If the map information required at each stage is not distinct or if the graph convolution cannot effectively capture the relevant information, the progressive interaction may not provide benefits.

### Mechanism 2
- Claim: The dynamic range selection strategy for Map-Agent interaction improves computational efficiency and relevance of map information.
- Mechanism: Instead of using a fixed range for selecting neighboring map nodes, the method uses a dynamic range centered around the agent's current position plus a vector representing its speed over 25 time steps. This allows the agent to focus on map areas along its moving direction.
- Core assumption: Agents need to pay more attention to map areas along their moving direction, and this attention should adapt to their speed.
- Evidence anchors:
  - [section] "Instead of statically delimiting a fixed range... we adopt a dynamic range selection strategy... given an agent, we take its position p(T ) +D as the center of neighbor, and the range is set by a circle with |D| + δ as the radius."
  - [section] "This dynamic strategy is not only more effective but also contributes to faster inference speed, since there are many low-speed agents whose neighborhoods can be smaller with less nodes in Map-Agent to compute."
- Break condition: If the dynamic range selection does not accurately capture the relevant map information or if the computational savings are negligible, this strategy may not be beneficial.

### Mechanism 3
- Claim: The weight allocation mechanism for multi-modal training improves the learning of each mode by assigning different weights based on prediction accuracy.
- Mechanism: Instead of using the winner-take-all strategy, the method assigns a weight to each mode based on their final displacement errors. The smaller the endpoint error of a mode, the greater the learning weight it receives.
- Core assumption: Each mode has different prediction capabilities, and assigning weights based on accuracy allows for more effective learning of all modes.
- Evidence anchors:
  - [abstract] "a weight allocation mechanism is proposed for multi-modal training, so that each mode can obtain learning opportunities from a single-mode ground truth."
  - [section] "In the second stage, we use an allocation loss to update all prediction branches... a weight wk is assigned to each mode based on their final displacement errors... The smaller endpoint error of the mode is, the greater learning weight will it be."
- Break condition: If the weight allocation mechanism does not accurately reflect the prediction accuracy or if it leads to overfitting on certain modes, it may not improve the overall performance.

## Foundational Learning

- Concept: Graph Convolutional Networks (GCNs)
  - Why needed here: GCNs are used to model the irregular topology of roads and relationships between agents and map elements, which is crucial for capturing the complex interactions in the driving scene.
  - Quick check question: How do GCNs differ from traditional convolutional neural networks in handling irregular data structures like graphs?

- Concept: Multi-modal prediction
  - Why needed here: Trajectory prediction is inherently multi-modal due to the uncertainty in agents' intentions, and the method needs to predict multiple possible trajectories for each agent.
  - Quick check question: What are the challenges of multi-modal prediction, and how does the weight allocation mechanism address these challenges?

- Concept: Dynamic range selection
  - Why needed here: The dynamic range selection strategy for Map-Agent interaction allows the agent to focus on relevant map areas along its moving direction, improving both computational efficiency and prediction accuracy.
  - Quick check question: How does the dynamic range selection strategy adapt to different agent speeds, and why is this adaptation important?

## Architecture Onboarding

- Component map:
  - Agent Encoder -> Map Encoder -> Progressive Interaction Network (Map-Agent after encoder -> Agent-Agent -> Map-Agent after multi-modal) -> Multi-modal Differentiation (K independent MLPs) -> Scoring Head

- Critical path:
  1. Encode agent history and map features using LSTM and GCN encoders
  2. Progressive interaction network for incorporating map information at three stages
  3. Multi-modal differentiation for predicting multiple trajectories using independent MLPs
  4. Scoring head for outputting confidence scores for each trajectory
  5. Training with allocation loss and endpoint loss for improving multi-modal prediction

- Design tradeoffs:
  - Progressive interaction vs. one-stage interaction: Progressive interaction allows for more accurate feature representation but may increase computational complexity
  - Dynamic range selection vs. fixed range: Dynamic range selection improves computational efficiency and relevance but may require more careful tuning
  - Weight allocation vs. winner-take-all: Weight allocation allows for more effective learning of all modes but may be more complex to implement

- Failure signatures:
  - Poor prediction accuracy: May indicate issues with progressive interaction, dynamic range selection, or weight allocation
  - High computational cost: May indicate inefficiencies in the progressive interaction network or dynamic range selection
  - Mode collapse: May indicate issues with the weight allocation mechanism or training strategy

- First 3 experiments:
  1. Ablation study to evaluate the impact of each component in the progressive interaction network
  2. Comparison of dynamic range selection vs. fixed range for Map-Agent interaction
  3. Evaluation of weight allocation mechanism vs. winner-take-all strategy for multi-modal training

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the progressive interaction network's performance change when incorporating additional map features beyond lane segments, such as traffic signals or crosswalks?
- Basis in paper: [inferred] The paper mentions that map information is incorporated through interactions with lane segments, but does not explore the impact of additional map features.
- Why unresolved: The paper focuses on lane segments as the primary map feature, leaving the effect of other map elements unexplored.
- What evidence would resolve it: Experimental results comparing the model's performance with and without additional map features.

### Open Question 2
- Question: Can the weight allocation mechanism be extended to handle multi-mode ground truth data, where multiple valid future trajectories are provided?
- Basis in paper: [explicit] The paper discusses a weight allocation mechanism for single-mode ground truth data, suggesting potential extension to multi-mode scenarios.
- Why unresolved: The current implementation and experiments are limited to single-mode ground truth, not addressing the scenario of multiple valid trajectories.
- What evidence would resolve it: Implementation and evaluation of the weight allocation mechanism with multi-mode ground truth data.

### Open Question 3
- Question: What is the impact of varying the number of prediction branches (K) on the model's performance and computational efficiency?
- Basis in paper: [inferred] The paper uses K=6 branches for multi-modal prediction but does not explore the effects of different values of K.
- Why unresolved: The choice of K=6 is not justified or compared against other values, leaving the optimal number of branches unclear.
- What evidence would resolve it: Experiments comparing model performance and computational costs across different values of K.

## Limitations
- The paper lacks architectural details critical for reproduction, particularly the exact configuration of graph convolution layers and MLP architectures
- The ablation studies are incomplete, only showing end-to-end performance rather than isolating the contribution of each progressive interaction stage
- The computational efficiency claims regarding dynamic range selection are not empirically validated against a fixed-range baseline

## Confidence
- High confidence: The core mechanism of progressive interaction is well-explained and the results are reproducible on benchmark datasets
- Medium confidence: The weight allocation mechanism is plausible but its specific implementation details are unclear
- Low confidence: The exact architectural configurations and training hyperparameters needed for faithful reproduction

## Next Checks
1. Reimplement the method with fixed vs. dynamic range selection to empirically validate the claimed computational efficiency benefits
2. Conduct a proper ablation study isolating the contribution of each progressive interaction stage rather than just showing end-to-end performance
3. Test the weight allocation mechanism against simpler alternatives (uniform weights, winner-take-all) to verify it provides meaningful improvement beyond just being a different training strategy