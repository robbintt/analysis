---
ver: rpa2
title: 'Dr3: Ask Large Language Models Not to Give Off-Topic Answers in Open Domain
  Multi-Hop Question Answering'
arxiv_id: '2403.12393'
source_url: https://arxiv.org/abs/2403.12393
tags:
- off-topic
- answer
- answers
- question
- react
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Dr3 reduces off-topic answers in ODMHQA by nearly 13%, improving\
  \ Exact Match by nearly 3% compared to the baseline ReAct+. It proposes a Discriminate\u2192\
  Re-Compose\u2192Re-Solve\u2192Re-Decompose mechanism that leverages LLM capabilities\
  \ to detect and correct off-topic answers through step-wise revisions along the\
  \ reversed reasoning chain."
---

# Dr3: Ask Large Language Models Not to Give Off-Topic Answers in Open Domain Multi-Hop Question Answering

## Quick Facts
- arXiv ID: 2403.12393
- Source URL: https://arxiv.org/abs/2403.12393
- Reference count: 0
- Dr3 reduces off-topic answers in ODMHQA by nearly 13%, improving Exact Match by nearly 3% compared to baseline ReAct+

## Executive Summary
Dr3 addresses the critical issue of off-topic answers in open domain multi-hop question answering (ODMHQA) by introducing a Discriminate→Re-Compose→Re-Solve→Re-Decompose mechanism. The system leverages LLM capabilities to detect and correct off-topic answers through step-wise revisions along the reversed reasoning chain. Experiments on HotpotQA and 2WikiMultiHopQA datasets demonstrate that Dr3 reduces off-topic answers to 7.42% while achieving 33.80% Exact Match, compared to ReAct+'s 23.69% off-topic ratio and 31.00% EM.

## Method Summary
Dr3 introduces a three-stage correction mechanism that operates when a Discriminator identifies an off-topic answer. The Corrector first attempts Re-Compose to generate a new answer by reconsidering the question and evidence, then uses Re-Solve to address potential passage errors by replacing passages and re-solving sub-questions, and finally employs Re-Decompose to re-examine the reasoning chain structure. The system uses davinci-002 LLM with ColBERTv2 for retrieval, iterating through correction stages until producing an on-topic answer or reaching a threshold.

## Key Results
- Off-topic answers reduced from 23.69% (ReAct+) to 7.42% (Dr3) - nearly 13% improvement
- Exact Match improved from 31.00% (ReAct+) to 33.80% (Dr3) - nearly 3% gain
- Re-Compose module shows strongest individual contribution (+1.0% EM) compared to Re-Solve (+0.8%) and Re-Decompose (+0.4%)

## Why This Works (Mechanism)

### Mechanism 1: Discriminator-based off-topic detection
The Discriminator leverages LLM intrinsic capabilities to judge whether generated answers fall within the semantic range of available options. It prompts the LLM to conceptualize candidate answers before assessing if the generated answer matches the question's intent.

### Mechanism 2: Re-Compose for self-correction
Inspired by Zheng et al. (2023), Re-Compose provides the hint "The answer is not [Ansold]" to encourage the LLM to reconsider the question and evidence, generating potentially on-topic answers through explicit correction feedback.

### Mechanism 3: Re-Solve for passage error correction
Re-Solve addresses passage errors by replacing passages in observations based on retrieval probabilities, then re-solving sub-questions with ReAct+. This iterates until an on-topic answer is found or a threshold is reached, targeting the 41% of cases stemming from retrieval issues.

## Foundational Learning

- Concept: Multi-hop question answering
  - Why needed here: Dr3 operates on the reasoning chain structure of multi-hop QA, understanding how questions decompose into sub-questions is critical
  - Quick check question: How many sub-questions are typically needed for HotpotQA questions and why?

- Concept: Chain-of-Thought reasoning
  - Why needed here: Dr3 leverages LLM reasoning capabilities, understanding CoT patterns helps design effective prompts for Discriminator and Corrector
  - Quick check question: What distinguishes effective CoT prompts from ineffective ones in the context of answer validation?

- Concept: Retrieval-augmented generation
  - Why needed here: Re-Solve module depends on retrieving relevant passages, understanding IR system behavior is crucial
  - Quick check question: What factors affect passage retrieval quality in open-domain QA systems?

## Architecture Onboarding

- Component map: Question → Decomposition → Sub-questions → Answer → Discriminator → (if off-topic) Corrector chain → Final answer
- Critical path: Question → Decomposition → Sub-questions → Answer → Discriminator → (on-topic?) → Output
  - The path loops back through Corrector modules when Discriminator flags off-topic answers
- Design tradeoffs:
  - Accuracy vs latency: Multiple correction iterations improve accuracy but increase inference time
  - Prompt complexity vs effectiveness: More detailed prompts improve judgment quality but increase token costs
  - IR system dependency: Re-Solve's effectiveness depends on retrieval quality
- Failure signatures:
  - Discriminator consistently approves off-topic answers → Prompt needs refinement
  - Corrector gets stuck in loops → Thresholds (TD) need adjustment or new stopping criteria
  - System fails on specific question types → Question type analysis needed for specialized handling
- First 3 experiments:
  1. Test Discriminator accuracy on a diverse set of off-topic/appropriate answer pairs to establish baseline performance
  2. Measure impact of each Corrector module independently to understand individual contribution
  3. Analyze correlation between number of sub-questions and off-topic ratio to validate design assumptions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Dr3 change when using different LLMs beyond text-davinci-002?
- Basis in paper: The paper only reports results using text-davinci-002 as the LLM, leaving the performance with other LLMs unexplored.
- Why unresolved: The paper does not provide any experimental results or analysis on the performance of Dr3 with different LLMs.
- What evidence would resolve it: Experiments comparing the performance of Dr3 using various LLMs (e.g., GPT-4, Claude, etc.) on the same datasets and evaluation metrics.

### Open Question 2
- Question: What is the impact of varying the maximum number of replaced passages (TD) in the Re-Solve stage on the performance of Dr3?
- Basis in paper: The paper sets TD to 3 for each Sub-Question but does not explore the effects of different values.
- Why unresolved: The paper does not provide any ablation studies or analysis on how changing the TD value affects the performance of Dr3.
- What evidence would resolve it: Experiments evaluating the performance of Dr3 with different TD values (e.g., 1, 2, 3, 5) on the same datasets and evaluation metrics.

### Open Question 3
- Question: How does the performance of Dr3 compare to other post-hoc correction methods for ODMHQA?
- Basis in paper: The paper focuses on the Dr3 mechanism and does not compare it to other post-hoc correction methods for ODMHQA.
- Why unresolved: The paper does not provide any comparison or analysis of Dr3 against other post-hoc correction methods for ODMHQA.
- What evidence would resolve it: Experiments comparing the performance of Dr3 to other post-hoc correction methods (e.g., Verify-and-Edit, LLM-AUGMENTER) on the same datasets and evaluation metrics.

## Limitations

- Discriminator reliability uncertainty: No empirical validation of LLM's ability to consistently conceptualize appropriate answer ranges for diverse question types
- IR system coverage ceiling: Performance limited by external retrieval system's ability to find correct passages, with unknown ceiling on achievable improvements
- Limited generalizability: Only tested on two datasets (HotpotQA and 2WikiMultiHopQA) with one LLM model (davinci-002)

## Confidence

- High Confidence: EM improvement metric (+2.80%) and off-topic reduction (-12.92%) are directly measurable from reported results
- Medium Confidence: Three-stage Corrector mechanism is conceptually sound with positive ablation study contributions
- Low Confidence: Fundamental assumption that LLMs can reliably judge answer appropriateness based on semantic intent

## Next Checks

1. **Discriminator Validation**: Create controlled test set with 100 hand-labeled question-answer pairs spanning diverse types, measuring Discriminator's precision, recall, and F1 score for detecting off-topic answers.

2. **IR System Coverage Analysis**: For the 41% of off-topic answers attributed to passage errors, measure what fraction can actually be resolved through Re-Solve by analyzing whether correct passages exist in the database.

3. **Cross-Dataset Generalization**: Test Dr3 on a third multi-hop QA dataset with different characteristics (e.g., QASC or ComplexWebQuestions) to validate whether the 13% off-topic reduction holds across different question distributions.