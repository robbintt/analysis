---
ver: rpa2
title: 'Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs'
arxiv_id: '2403.12596'
source_url: https://arxiv.org/abs/2403.12596
tags:
- answer
- table
- rationale
- reasoning
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Chart-based Reasoning: Transferring Capabilities from LLMs to
  VLMs proposes a method to improve reasoning capabilities of vision-language models
  (VLMs) by transferring knowledge from large language models (LLMs). The core approach
  involves continuing pre-training of the vision backbone using chart-to-table translation
  tasks and fine-tuning with a synthetic dataset 20x larger than the original, containing
  additional QA pairs and rationales generated by LLMs.'
---

# Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs

## Quick Facts
- arXiv ID: 2403.12596
- Source URL: https://arxiv.org/abs/2403.12596
- Reference count: 7
- Key outcome: Chart-based Reasoning transfers reasoning capabilities from LLMs to VLMs, achieving 77.3% relaxed accuracy on ChartQA and outperforming 10x larger models without OCR

## Executive Summary
Chart-based Reasoning proposes a method to improve vision-language models' reasoning capabilities by transferring knowledge from large language models. The approach involves continuing pre-training of the vision backbone on chart-to-table translation tasks and fine-tuning on a synthetic dataset 20x larger than the original, containing QA pairs and rationales generated by LLMs. Applied to PaLI-3, the resulting ChartPaLI-5B achieves state-of-the-art performance on ChartQA (77.3% relaxed accuracy) and shows strong generalization to FigureQA and PlotQA. The method leverages multitask learning with separate task prefixes for answers and rationales, and can be further refined with program-of-thought prompting using PaLM 2-S.

## Method Summary
The method improves VLM reasoning capabilities through a two-stage process. First, the vision backbone (ViT encoder) is pre-trained on chart-to-table translation tasks using a mixture of synthetic and real chart datasets, improving chart feature extraction. Second, both vision and language backbones are fine-tuned on a 20x larger synthetic dataset containing QA pairs and rationales generated by LLMs. The fine-tuning uses a multitask loss treating answer and rationale prediction as separate tasks with different prefixes. The synthetic data is generated by first extracting tables from charts (using gold tables when available), then using LLMs to generate QA pairs and corresponding rationales. The model can be further refined using program-of-thought prompting with external LLMs.

## Key Results
- ChartPaLI-5B achieves 77.3% relaxed accuracy on ChartQA, outperforming PaLI-X-55B (10x larger) without OCR
- State-of-the-art performance on FigureQA (99.1%) and PlotQA (40.3%) benchmarks
- Program-of-thought prompting with PaLM 2-S further improves performance to 81.3%, surpassing GPT-4V and Gemini Ultra
- The multitask setup outperforms singletask on the more difficult human-set portion of ChartQA

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Continuing pre-training on chart-to-table translation tasks improves the vision backbone's internal representation of charts, enabling better extraction of chart values.
- Mechanism: By exposing the ViT encoder to more chart images paired with their table representations during pre-training, it learns richer visual features specific to chart structures (axes, legends, data point positioning) rather than general image features.
- Core assumption: Chart images have distinctive visual patterns that can be learned through continued pre-training, and this learned representation transfers to downstream reasoning tasks.
- Evidence anchors:
  - [abstract]: "We first improve the chart representation by continuing the pre-training stage using an improved version of the chart-to-table translation task"
  - [section]: "We empirically show that this indeed improves performance through experiments on ChartQA... As expected, the increase is predominantly in the augmented set, given that the pre-training mixture is constructed synthetically as well."

### Mechanism 2
- Claim: Fine-tuning on a 20x larger synthetic dataset with rationales generated by LLMs transfers reasoning capabilities from LLMs to VLMs.
- Mechanism: The synthetic dataset provides diverse examples covering complex reasoning scenarios (multiple value extraction, arithmetic operations) with explicit rationales showing the reasoning steps, which teaches the VLM to generate similar reasoning traces internally.
- Core assumption: VLMs can learn to generate reasoning traces by seeing examples of them, and these traces improve downstream answer accuracy.
- Evidence anchors:
  - [abstract]: "To improve general reasoning capabilities and improve numerical operations, we synthesize reasoning traces using the table representation of charts."
  - [section]: "We use the synthetic data to fine-tune the model for the downstream task. We investigate two ways of incorporating the rationales... We hypothesize that the improvement comes from better use of the rationales, guiding the model to internally produce a form of reasoning before producing the final answer."

### Mechanism 3
- Claim: The multi-task loss setup (treating answer and rationale prediction as separate tasks) improves performance compared to single-task joint prediction.
- Mechanism: By treating answer and rationale as independent tasks with separate prefixes, the model doesn't need to predict longer sequences and can focus on each task separately, reducing interference between answer and rationale tokens.
- Core assumption: Separating the tasks allows the model to specialize better for each, and the rationales still guide the reasoning process without the computational overhead of predicting them fully.
- Evidence anchors:
  - [abstract]: "Lastly, our model is fine-tuned using the multitask loss introduced by Hsieh et al. (2023)"
  - [section]: "However, when used in the multitask setup, we note a quality improvement, particularly noticeable in the more difficult human-set... We hypothesize that the improvement comes from better use of the rationales, guiding the model to internally produce a form of reasoning before producing the final answer."

## Foundational Learning

- Concept: Chain-of-thought prompting
  - Why needed here: Understanding how LLMs generate reasoning traces is essential for creating synthetic data that can transfer these capabilities to VLMs
  - Quick check question: How does chain-of-thought prompting differ from standard prompting in terms of output structure and reasoning quality?

- Concept: Vision-language model architecture
  - Why needed here: The paper builds on PaLI-3's encoder-decoder architecture with ViT and UL2 backbones, so understanding how vision and language components interact is crucial
  - Quick check question: What are the key differences between encoder-decoder and decoder-only architectures for VLMs in terms of training and inference?

- Concept: Multitask learning with task prefixes
  - Why needed here: The multi-task setup uses different prefixes ("Rationale:" and "Question:") to separate tasks, which is critical for understanding the training methodology
  - Quick check question: How do task prefixes in models like T5 enable multitask learning without architectural changes?

## Architecture Onboarding

- Component map: PaLI-3 architecture consists of ViT-3B vision encoder, UL2-3B language encoder-decoder, and a multimodal pre-training stage. The ChartPaLI-5B variant continues pre-training the ViT encoder on chart-to-table tasks and fine-tunes both components on the synthetic dataset.
- Critical path: Pre-training ViT on chart representations → Fine-tuning both backbones on synthetic data with multitask loss → Optional refinement with PaLM 2-S using program-of-thoughts
- Design tradeoffs: Larger synthetic dataset improves reasoning but increases training time; multitask setup reduces inference time but may slightly underperform singletask in some cases; continuing pre-training improves chart understanding but requires more compute
- Failure signatures: Poor chart value extraction (vision backbone not learning chart features), incorrect arithmetic in rationales (language backbone not learning computation), or failure to generate rationales (multi-task setup not working)
- First 3 experiments:
  1. Test chart-to-table pre-training impact: Compare ChartQA performance with and without continued pre-training on the chart-to-table mixture
  2. Test multitask vs singletask: Compare performance using the same synthetic data but different loss setups
  3. Test synthetic data impact: Compare performance using original ChartQA vs the full 20x larger synthetic dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the quality of inferred tables from OCR systems compare to gold tables when used for synthetic data generation in chart reasoning tasks?
- Basis in paper: [inferred] The paper mentions that gold tables are available for most chart sources except Pew, where tables are inferred using ChartOCR. It notes that the method is "fairly resilient" to mistakes in inferred tables but doesn't quantify the impact.
- Why unresolved: The paper doesn't provide systematic comparison between using gold tables versus OCR-inferred tables for synthetic data generation quality.
- What evidence would resolve it: Controlled experiments comparing model performance when using gold tables versus OCR-inferred tables for synthetic data generation on the same chart dataset.

### Open Question 2
- Question: What is the optimal balance between synthetic data diversity and quality when transferring reasoning capabilities from LLMs to VLMs?
- Basis in paper: [explicit] The paper discusses using 20x larger synthetic dataset and mentions "diversity matters more than model size" but doesn't investigate optimal diversity-quality trade-offs.
- Why unresolved: The paper uses greedy decoding with temperature τ = 0 for synthetic data generation and doesn't explore the impact of different sampling strategies or diversity controls.
- What evidence would resolve it: Systematic ablation studies varying synthetic data diversity (through sampling temperature, model size, prompt variations) while measuring downstream task performance.

### Open Question 3
- Question: How does the performance of the proposed method scale with increasing chart complexity and reasoning difficulty?
- Basis in paper: [inferred] The paper shows strong performance on ChartQA, FigureQA, and PlotQA but doesn't analyze failure modes or performance degradation on increasingly complex reasoning tasks.
- Why unresolved: The error analysis section identifies specific failure modes (color reasoning, complex numerical conditions) but doesn't quantify how performance changes with increasing complexity levels.
- What evidence would resolve it: Detailed performance analysis on benchmark subsets stratified by reasoning complexity, number of operations required, and chart visual complexity.

## Limitations
- Reliance on gold tables: The synthetic data generation pipeline requires gold table annotations, limiting scalability to new chart datasets without extensive manual annotation
- Color reasoning challenges: The model struggles with questions requiring color-based reasoning, suggesting the vision backbone's feature representations may not fully capture color semantics
- Complex numerical conditions: Questions involving multiple arithmetic operations with conditional logic remain challenging

## Confidence
- High confidence: The core methodology (continued pre-training + synthetic data fine-tuning + multitask loss) is well-supported by ablation studies and achieves state-of-the-art results on ChartQA
- Medium confidence: The proposed mechanisms for why the method works (improved chart representations, reasoning transfer via rationales, multitask benefits) are plausible but not definitively proven
- Medium confidence: The generalization claims to FigureQA and PlotQA are supported but less extensively validated than the ChartQA results

## Next Checks
1. Conduct an ablation study removing the multitask loss to quantify its specific contribution versus using a single-task setup with rationales
2. Test the model on chart datasets without gold table annotations to evaluate real-world applicability and identify failure modes
3. Compare performance between the singletask and multitask setups on the human-set portion of ChartQA to validate the claimed quality improvements