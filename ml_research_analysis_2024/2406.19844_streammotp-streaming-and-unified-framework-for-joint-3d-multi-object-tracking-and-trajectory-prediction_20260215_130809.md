---
ver: rpa2
title: 'StreamMOTP: Streaming and Unified Framework for Joint 3D Multi-Object Tracking
  and Trajectory Prediction'
arxiv_id: '2406.19844'
source_url: https://arxiv.org/abs/2406.19844
tags: []
core_contribution: StreamMOTP addresses the problem of 3D multi-object tracking (MOT)
  and trajectory prediction in autonomous driving by proposing a streaming and unified
  framework. The core method idea involves a streaming framework with a memory bank
  to maintain long-term latent features for tracked objects, a relative spatio-temporal
  positional encoding strategy to bridge coordinate representation gaps between tracking
  and prediction tasks, and a dual-stream predictor to simultaneously predict trajectories
  for both tracked and newly perceived objects.
---

# StreamMOTP: Streaming and Unified Framework for Joint 3D Multi-Object Tracking and Trajectory Prediction

## Quick Facts
- arXiv ID: 2406.19844
- Source URL: https://arxiv.org/abs/2406.19844
- Authors: Jiaheng Zhuang; Guoan Wang; Siyu Zhang; Xiyang Wang; Hangning Zhou; Ziyao Xu; Chi Zhang; Zhiheng Li
- Reference count: 39
- Primary result: AMOTA improved by 3.84% and minADE/minFDE reduced by 0.220/0.141 compared to previous methods

## Executive Summary
StreamMOTP addresses the challenge of 3D multi-object tracking (MOT) and trajectory prediction in autonomous driving by proposing a streaming and unified framework. The method introduces a memory bank to maintain long-term latent features for tracked objects, a relative spatio-temporal positional encoding strategy to bridge coordinate representation gaps between tracking and prediction tasks, and a dual-stream predictor to simultaneously predict trajectories for both tracked and newly perceived objects. Extensive experiments on the nuScenes dataset demonstrate significant improvements over state-of-the-art methods, with AMOTA improved by 3.84% and minADE/minFDE reduced by 0.220/0.141.

## Method Summary
StreamMOTP is a streaming framework that processes data in a frame-by-frame manner while maintaining long-term information through a memory bank. The model consists of four main components: feature extraction using MLPs for proposals and tracklets, a spatio-temporal encoder with relative positional encoding, a MOT head using optimal transport for object association, and a dual-stream predictor for trajectory prediction. The framework jointly optimizes MOT and trajectory prediction tasks using a combined loss function, with scheduled sampling for memory bank initialization. Training is extended from single-frame to multi-frame sequences to better align with actual deployment scenarios.

## Key Results
- AMOTA improved by 3.84% compared to previous state-of-the-art methods
- minADE reduced by 0.220 and minFDE reduced by 0.141 on trajectory prediction
- Demonstrates consistent performance improvements across various memory bank lengths

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The streaming framework with memory bank preserves and leverages long-term latent features for tracked objects, improving long-term sequence modeling.
- Mechanism: The model maintains a memory bank of FÃ—N latent features, where F is the memory length and N is the number of objects per frame. At each time step, the latent features of tracked objects associated with newly perceived objects are saved into the memory bank. These features are then utilized in subsequent frames to enhance features for tracked objects through a dynamic ego transformation and temporal aggregation.
- Core assumption: Long-term historical information is crucial for improving both tracking and prediction performance in autonomous driving scenarios.
- Evidence anchors:
  - [abstract] "we construct the model in a streaming manner and exploit a memory bank to preserve and leverage the long-term latent features for tracked objects more effectively"
  - [section III-A] "we introduce a Memory Bank for tracked objects to maintain long-term latent features for utilizing the long-term information more effectively"
  - [corpus] Weak evidence - the corpus neighbors do not directly discuss memory banks for 3D MOT and trajectory prediction
- Break condition: If the memory bank becomes too large or if the ego transformation parameters cannot effectively align features across frames, the long-term modeling capability may degrade.

### Mechanism 2
- Claim: The relative spatio-temporal positional encoding strategy bridges the coordinate representation gap between tracking and prediction tasks while maintaining pose-invariance.
- Mechanism: A relative spatio-temporal positional encoding is introduced to encode the relative position and heading angle differences between objects in different frames. This encoding is incorporated into the attention mechanism to differentiate between coordinate-independent and dependent features, allowing for both tracking and prediction to use appropriate coordinate systems.
- Core assumption: The tasks of tracking and prediction require different coordinate representations, and a unified encoding strategy can effectively bridge this gap.
- Evidence anchors:
  - [abstract] "a relative spatio-temporal positional encoding strategy is introduced to bridge the gap of coordinate representations between the two tasks and maintain the pose-invariance for trajectory prediction"
  - [section III-B] "we propose a relative Spatio-Temporal Positional Encoding (STPE) strategy... This approach differentiates between coordinate-independent and dependent features"
  - [corpus] No direct evidence - the corpus neighbors do not discuss spatio-temporal positional encoding strategies
- Break condition: If the relative encoding fails to capture the necessary spatial relationships or if the attention mechanism cannot effectively utilize the encoded information, the coordinate representation gap may not be adequately bridged.

### Mechanism 3
- Claim: The dual-stream predictor improves the quality and temporal consistency of predicted trajectories by simultaneously predicting trajectories for both tracked and newly perceived objects.
- Mechanism: The dual-stream predictor consists of a primary branch for predicting trajectories of detected objects in the current frame and an auxiliary branch for generating trajectories for previously tracked objects. The predictions from the previous frame serve as a prior reference for the current frame, enhancing both accuracy and temporal coherence.
- Core assumption: There is significant overlap between predicted trajectories of objects in consecutive frames, and leveraging this overlap can improve prediction quality.
- Evidence anchors:
  - [abstract] "we further improve the quality and consistency of predicted trajectories with a dual-stream predictor"
  - [section III-D] "The predictor comprises two branches... The primary branch follows Single Frame Prediction to predict from the context features of proposals, while the auxiliary branch leverages the context features of tracklets"
  - [corpus] No direct evidence - the corpus neighbors do not discuss dual-stream predictors for 3D MOT and trajectory prediction
- Break condition: If the association between objects in consecutive frames is incorrect or if the temporal consistency constraint is too rigid, the dual-stream predictor may introduce errors or reduce flexibility in trajectory prediction.

## Foundational Learning

- Concept: Attention mechanisms and multi-head attention
  - Why needed here: The StreamMOTP framework heavily relies on attention mechanisms for feature interaction and aggregation across objects and frames.
  - Quick check question: How does multi-head attention differ from single-head attention, and why is it beneficial in this context?

- Concept: Positional encoding in transformer models
  - Why needed here: The relative spatio-temporal positional encoding is a key component for bridging the coordinate representation gap between tracking and prediction tasks.
  - Quick check question: What is the purpose of positional encoding in transformer models, and how does the relative encoding differ from absolute encoding?

- Concept: Optimal transport and Sinkhorn algorithm
  - Why needed here: The association between tracked objects and newly perceived objects is performed using optimal transport with the Sinkhorn algorithm.
  - Quick check question: How does the Sinkhorn algorithm solve the optimal transport problem, and why is it suitable for object association in this framework?

## Architecture Onboarding

- Component map: Feature Extraction -> Spatio-Temporal Encoder -> MOT Head -> Dual-Stream Predictor
- Critical path:
  1. Extract features from proposals and tracklets using MLPs
  2. Fuse historical trajectories with tracklet features using cross-attention
  3. Apply ego transformation and temporal aggregation with memory bank features
  4. Perform spatio-temporal interaction using relative positional encoding
  5. Compute affinity matrix and perform association using optimal transport
  6. Predict trajectories using dual-stream predictor

- Design tradeoffs:
  - Memory bank length vs. computational efficiency: Longer memory banks provide better long-term modeling but increase computational cost
  - Number of attention heads vs. model capacity: More attention heads can capture more complex relationships but may lead to overfitting
  - Trade-off between tracking and prediction performance: Joint optimization may favor one task over the other depending on the loss weighting

- Failure signatures:
  - Poor tracking performance: Incorrect associations, high AMOTA/MOTA errors
  - Inaccurate trajectory predictions: High minADE/minFDE, lack of temporal consistency
  - Computational inefficiency: Slow inference times, memory constraints
  - Overfitting: Performance degradation on validation/test sets compared to training

- First 3 experiments:
  1. Ablation study on memory bank length: Evaluate the impact of different memory bank lengths on tracking and prediction performance
  2. Coordinate representation analysis: Compare the performance of absolute vs. relative positional encoding strategies
  3. Single-stream vs. dual-stream predictor: Assess the benefits of the dual-stream predictor in terms of prediction quality and temporal consistency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of StreamMOTP scale with increasing memory bank length, and what is the optimal memory length for balancing computational efficiency and tracking/prediction accuracy?
- Basis in paper: [explicit] The paper states "Furthermore, Table IV shows that as the length of the memory bank expands, the model's performance grows, which further demonstrates the impact of the memory bank."
- Why unresolved: The paper only shows that increasing memory length improves performance but does not specify an optimal length or discuss the computational trade-offs.
- What evidence would resolve it: Systematic experiments varying memory bank length and measuring both performance metrics (AMOTA, minADE, minFDE) and computational metrics (inference time, memory usage) to identify the optimal trade-off point.

### Open Question 2
- Question: How does StreamMOTP perform in extremely dense traffic scenarios with hundreds of agents, and what are its limitations in such conditions?
- Basis in paper: [inferred] The paper demonstrates strong performance on the nuScenes dataset but does not specifically address extremely dense traffic scenarios or scalability to hundreds of agents.
- Why unresolved: The nuScenes dataset, while comprehensive, may not fully capture the most challenging dense traffic scenarios that autonomous vehicles encounter in real-world deployments.
- What evidence would resolve it: Testing StreamMOTP on datasets with extremely high agent density (e.g., simulation environments with controllable agent counts) and measuring performance degradation as agent count increases.

### Open Question 3
- Question: What is the impact of StreamMOTP's streaming framework on training convergence speed and stability compared to traditional snapshot-based methods?
- Basis in paper: [explicit] The paper states "we extend the pattern of training from single-frame to multi-frame so as to narrow the gap between training and actual deployment" and mentions the streaming framework's benefits.
- Why unresolved: While the paper mentions the streaming framework's advantages, it does not provide quantitative comparisons of training convergence speed or stability against snapshot-based methods.
- What evidence would resolve it: Comparative experiments measuring training convergence curves (loss vs. epochs) and stability metrics (variance in validation performance across training runs) between StreamMOTP and equivalent snapshot-based methods.

## Limitations

- The exact architecture details of key components (MLPs, MHCA, decoder transformer) are not fully specified, making precise reproduction challenging.
- The effectiveness of the relative spatio-temporal positional encoding strategy lacks direct corpus evidence for independent verification.
- The specific benefits of the dual-stream predictor over single-stream alternatives are not thoroughly validated through detailed ablation studies.

## Confidence

- **High**: The streaming framework concept and basic architecture design (Memory Bank, MOT Head, Dual-Stream Predictor)
- **Medium**: The relative spatio-temporal positional encoding strategy and its effectiveness in bridging coordinate gaps
- **Medium**: The dual-stream predictor's contribution to trajectory quality and temporal consistency

## Next Checks

1. **Memory Bank Ablation**: Systematically vary memory bank length (F parameter) to quantify its impact on long-term tracking performance and computational efficiency.
2. **Coordinate Encoding Comparison**: Implement and compare absolute vs. relative positional encoding strategies to validate the claimed benefits of the relative approach.
3. **Association Robustness Test**: Evaluate the optimal transport-based association under varying object density and occlusion scenarios to assess its reliability across different driving conditions.