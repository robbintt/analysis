---
ver: rpa2
title: 'SFC: Achieve Accurate Fast Convolution under Low-precision Arithmetic'
arxiv_id: '2407.02913'
source_url: https://arxiv.org/abs/2407.02913
tags:
- convolution
- fast
- quantization
- algorithm
- winograd
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes SFC (Symbolic Fourier Convolution), a new fast
  convolution algorithm designed to maintain accuracy under low-precision arithmetic,
  which is critical for efficient model quantization. SFC extends the Discrete Fourier
  Transform (DFT) using symbolic computing to avoid irrational numbers, requiring
  only additions for transformation at specific transform points.
---

# SFC: Achieve Accurate Fast Convolution under Low-precision Arithmetic

## Quick Facts
- arXiv ID: 2407.02913
- Source URL: https://arxiv.org/abs/2407.02913
- Authors: Liulu He; Yufei Zhao; Rui Gao; Yuan Du; Li Du
- Reference count: 33
- Key outcome: SFC achieves 3.68× multiplication reduction for 3×3 convolutions while maintaining accuracy under low-precision arithmetic

## Executive Summary
This paper introduces SFC (Symbolic Fourier Convolution), a novel fast convolution algorithm that maintains accuracy under low-precision arithmetic critical for efficient model quantization. SFC extends the Discrete Fourier Transform using symbolic computing to avoid irrational numbers, requiring only additions for transformation at specific transform points. The algorithm introduces correction terms to convert invalid circular convolution outputs into valid ones, enhancing computational efficiency. The authors provide the first numerical error analysis of this type of algorithm and demonstrate significant improvements in computation efficiency for quantized models while maintaining accuracy.

## Method Summary
SFC extends the Discrete Fourier Transform (DFT) using symbolic computing to represent irrational coefficients as first-order integer polynomials, eliminating rounding errors from high-precision arithmetic. The algorithm introduces correction terms to convert invalid circular convolution outputs from the Fourier method into valid linear convolution results. The authors provide numerical error analysis comparing SFC to Winograd and FFT, proving SFC achieves a 3.68× multiplication reduction for 3×3 convolution while maintaining equivalent numerical accuracy. Experiments on ImageNet with pre-trained ResNet models demonstrate that SFC significantly improves computation efficiency of quantized models while maintaining accuracy, surpassing both quantization-alone and existing fast convolution quantization methods.

## Key Results
- SFC achieves 3.68× multiplication reduction for 3×3 convolutions compared to baseline methods
- SFC maintains higher accuracy than Winograd (2.25× reduction) at equivalent numerical precision
- FPGA implementation shows significant BOPs reduction while maintaining model accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SFC uses symbolic computation to represent irrational coefficients as first-order integer polynomials, eliminating rounding errors from high-precision arithmetic.
- Mechanism: By expressing DFT coefficients symbolically (e.g., s = e^(iπ/3) for DFT-6), all arithmetic is reduced to integer operations and additions, bypassing the need for floating-point irrational calculations.
- Core assumption: The symbolic representation maintains exact algebraic equivalence to the original irrational values when combined through polynomial arithmetic.
- Evidence anchors:
  - [abstract] "we proposes SFC, a new algebra transform for fast convolution by extending the Discrete Fourier Transform (DFT) with symbolic computing, in which only additions are required to perform the transformation at specific transform points, avoiding the calculation of irrational number and reducing the requirement for precision."
  - [section] "We employ symbolic computing rather than numerical computing to implement the discrete Fourier transform (DFT). By selecting an appropriate number of DFT points, we can avoid or minimize the irrational values involved in computing."
- Break condition: If the symbolic polynomial multiplication introduces higher-order terms that cannot be reduced back to first-order form using the defined relations (e.g., s² = s - 1 for DFT-6).

### Mechanism 2
- Claim: SFC introduces correction terms to convert invalid circular convolution outputs into valid linear convolution results, improving computational efficiency.
- Mechanism: Instead of discarding invalid outputs from circular convolution, SFC adds correction terms derived from the difference between circular and linear convolution terms, effectively recovering valid outputs with minimal additional computation.
- Core assumption: The circular convolution outputs contain partial sums that can be algebraically adjusted to form correct linear convolution results.
- Evidence anchors:
  - [abstract] "we enhance convolution efficiency by introducing correction terms to convert invalid circular convolution outputs of the Fourier method into effective ones."
  - [section] "We introduce correction terms to fully exploit the cyclic convolution output generated by the Fourier method to enhance computing utilization."
- Break condition: If the correction terms require more arithmetic operations than simply computing the linear convolution directly, or if the algebraic relationships between circular and linear terms become too complex to express with simple corrections.

### Mechanism 3
- Claim: SFC achieves better numerical stability than Winograd by using well-conditioned transformation matrices with lower condition numbers.
- Mechanism: The transformation matrix A in SFC has a lower condition number (κ(A) = 2.7-3.5) compared to Winograd (κ(A) = 2.4-31.0), reducing error amplification during quantization.
- Core assumption: The condition number of the transformation matrix directly correlates with numerical error amplification in quantized arithmetic.
- Evidence anchors:
  - [abstract] "numerical error analysis is presented for the first time in this type of work and proves that our algorithms can provide a 3.68× multiplication reduction for 3×3 convolution, while the Winograd algorithm only achieves 2.25× at equivalent numerical accuracy."
  - [section] "Set s + δs = (G · f) ⊙Q (BT · x), by substituting y = AT · s into the Equation 13, we can obtain: δy = (AT )−1 · δs" and "Here we can perform an analysis of Eq.16. The first term ||(AT )−1|| · ||(AT )|| is the condition number of matrix AT, denoted as κ(AT)."
- Break condition: If the condition number advantage is offset by increased quantization error from the symbolic representation or if the error analysis model doesn't capture real-world quantization behavior.

## Foundational Learning

- Concept: Discrete Fourier Transform (DFT) and its relationship to convolution
  - Why needed here: SFC is fundamentally an extension of DFT using symbolic computation, so understanding how DFT enables fast convolution is essential.
  - Quick check question: How does the convolution theorem relate circular convolution in the time domain to multiplication in the frequency domain?

- Concept: Condition number and numerical stability in matrix operations
  - Why needed here: The paper's error analysis relies on understanding how the condition number of transformation matrices affects error propagation in quantized arithmetic.
  - Quick check question: Given a matrix with singular values σ_max and σ_min, what is its condition number and how does it affect error amplification?

- Concept: Polynomial arithmetic and symbolic computation
  - Why needed here: SFC's core innovation is representing irrational numbers as polynomials with integer coefficients, requiring understanding of polynomial multiplication and reduction rules.
  - Quick check question: If s² = s - 1 in a symbolic system, what is the result of multiplying (a₀ + a₁s) by (b₀ + b₁s) and reducing to first-order form?

## Architecture Onboarding

- Component map: Symbolic transformation matrices (BT, G, A) implement the forward transform → Element-wise polynomial multiplication in transformed domain → Inverse transformation using symbolic iDFT → Correction terms for circular to linear conversion
- Critical path: The critical path is the symbolic forward transform (BT · x), element-wise multiplication (polynomial form), and inverse transform (A · result). The correction terms add minimal overhead as they're simple additions based on boundary elements.
- Design tradeoffs: SFC trades increased transformation complexity (symbolic polynomial arithmetic) for reduced numerical error and better quantization compatibility. The choice of 4 or 6 DFT points balances the availability of reducible polynomial forms against the arithmetic complexity of larger transforms.
- Failure signatures: Numerical instability will manifest as accuracy degradation during quantization, particularly in layers with large feature maps. Performance bottlenecks may occur if the symbolic multiplication isn't optimized, as polynomial multiplication requires more operations than simple integer multiplication.
- First 3 experiments:
  1. Verify symbolic DFT correctness by comparing SFC-4 output against standard DFT for random inputs, ensuring polynomial arithmetic produces equivalent results.
  2. Test correction term effectiveness by comparing circular convolution outputs with and without correction terms against direct linear convolution.
  3. Quantize SFC-transformed tensors at different bitwidths (8-bit, 6-bit, 4-bit) and measure accuracy degradation versus baseline direct convolution quantization.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical limit of numerical accuracy achievable by SFC algorithms as the kernel size increases, and how does this compare to FFT and Winograd methods?
- Basis in paper: [explicit] The paper discusses numerical error analysis comparing SFC to Winograd and FFT, noting SFC's condition numbers (κ(AT)) are lower than Winograd's but higher than FFT's.
- Why unresolved: The paper provides specific numerical error comparisons for certain kernel sizes (3x3, 5x5, 7x7) but doesn't establish a general theoretical limit or scaling behavior for arbitrarily large kernels.
- What evidence would resolve it: A comprehensive mathematical proof or extensive simulation results showing numerical error trends across a wide range of kernel sizes, ideally with asymptotic analysis.

### Open Question 2
- Question: How does the frequency-wise quantization strategy perform across different network architectures and datasets beyond ResNet on ImageNet?
- Basis in paper: [explicit] The paper mentions frequency-wise quantization and provides ablation studies on ResNet-18, noting it improves accuracy especially at lower bitwidths.
- Why unresolved: The evaluation is limited to specific ResNet models on ImageNet; generalization to other architectures (e.g., Transformers, EfficientNet) and datasets (e.g., CIFAR, medical imaging) is not explored.
- What evidence would resolve it: Experimental results applying SFC with frequency-wise quantization to diverse network architectures and datasets, comparing performance against standard quantization methods.

### Open Question 3
- Question: What are the practical limitations of the iterative convolution approach for very large kernel sizes, and how does its efficiency compare to FFT beyond 3 iterations?
- Basis in paper: [explicit] The paper proposes an iterative approach for large kernels and mentions that beyond 3 iterations, FFT becomes more efficient theoretically.
- Why unresolved: The paper provides a theoretical example for a 29x29 kernel but doesn't explore the practical crossover point, implementation challenges, or real-world performance beyond this case.
- What evidence would resolve it: Empirical studies comparing SFC iterative convolution and FFT across various large kernel sizes, including hardware implementation results, timing analysis, and identification of practical bottlenecks.

## Limitations
- The exact implementation details of polynomial multiplication and correction terms are not fully specified, making reproducibility challenging
- FPGA implementation lacks detailed architectural specifications regarding resource utilization and timing constraints
- The frequency-wise quantization strategy's performance across diverse network architectures and datasets remains unexplored

## Confidence

**High Confidence**: The theoretical framework of using symbolic computation to avoid irrational numbers in Fourier transforms is sound and well-grounded in algebraic principles. The condition number analysis connecting matrix conditioning to numerical stability has established mathematical foundations.

**Medium Confidence**: The claimed 3.68× multiplication reduction for 3×3 convolutions is supported by the error analysis but depends critically on correct implementation of the symbolic arithmetic and correction terms. The Winograd comparison is reasonable but the specific numerical advantage depends on implementation details not fully specified.

**Low Confidence**: The FPGA implementation claims regarding resource utilization and timing are difficult to verify without more detailed architectural specifications. The assertion that correction terms add minimal overhead lacks quantitative support in the paper.

## Next Checks
1. **Symbolic Arithmetic Verification**: Implement the SFC-4 algorithm with explicit polynomial multiplication and reduction rules, then verify against standard DFT outputs for random input matrices to ensure algebraic equivalence.

2. **Correction Term Validation**: Create a test case comparing circular convolution outputs with and without correction terms against direct linear convolution, measuring the computational overhead and accuracy impact of the correction mechanism.

3. **Quantization Stability Analysis**: Perform systematic quantization experiments across multiple bitwidths (8-bit, 6-bit, 4-bit) for SFC-transformed tensors, measuring accuracy degradation versus baseline direct convolution quantization to validate the claimed numerical stability benefits.