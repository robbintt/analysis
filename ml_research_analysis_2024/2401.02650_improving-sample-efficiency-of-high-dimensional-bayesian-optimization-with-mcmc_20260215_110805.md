---
ver: rpa2
title: Improving sample efficiency of high dimensional Bayesian optimization with
  MCMC
arxiv_id: '2401.02650'
source_url: https://arxiv.org/abs/2401.02650
tags:
- optimization
- points
- distribution
- mcmc-bo
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MCMC-BO, a Bayesian optimization method for
  high-dimensional spaces that combines Markov Chain Monte Carlo sampling with Gaussian
  process Thompson sampling. The key innovation is using MCMC to efficiently sample
  from an intractable posterior distribution induced by Thompson sampling, allowing
  the algorithm to adaptively focus candidate points on promising regions rather than
  requiring dense discretization of the entire space.
---

# Improving sample efficiency of high dimensional Bayesian optimization with MCMC

## Quick Facts
- arXiv ID: 2401.02650
- Source URL: https://arxiv.org/abs/2401.02650
- Authors: Zeji Yi; Yunyue Wei; Chu Xin Cheng; Kaibo He; Yanan Sui
- Reference count: 7
- Primary result: MCMC-BO improves sample efficiency in high-dimensional Bayesian optimization by combining MCMC sampling with Gaussian process Thompson sampling

## Executive Summary
This paper introduces MCMC-BO, a novel Bayesian optimization method designed to handle high-dimensional search spaces efficiently. The key innovation is using Markov Chain Monte Carlo sampling to draw from the intractable posterior distribution induced by Thompson sampling, allowing the algorithm to adaptively focus candidate points on promising regions without requiring dense discretization of the entire space. The method provides theoretical convergence guarantees while demonstrating strong empirical performance on both synthetic functions and reinforcement learning tasks.

The algorithm addresses a fundamental challenge in Bayesian optimization: how to maintain sample efficiency when dealing with high-dimensional spaces where traditional discretization approaches become computationally prohibitive. By combining MCMC sampling with Thompson sampling from Gaussian processes, MCMC-BO can explore high-dimensional spaces more effectively while requiring fewer function evaluations than existing state-of-the-art methods.

## Method Summary
MCMC-BO combines Markov Chain Monte Carlo sampling with Gaussian process Thompson sampling to perform Bayesian optimization in high-dimensional spaces. The method uses MCMC to sample from the posterior distribution over functions induced by Thompson sampling, rather than requiring dense discretization of the entire search space. This allows the algorithm to adaptively focus on promising regions while maintaining theoretical convergence guarantees. The approach leverages Gaussian process regression to model the objective function and uses Thompson sampling to guide the search, with MCMC providing the mechanism to efficiently explore the posterior distribution without the computational burden of traditional discretization methods.

## Key Results
- MCMC-BO outperforms state-of-the-art baselines including TuRBO and LA-MCTS on high-dimensional synthetic functions (d=200-800)
- The method achieves faster convergence on Mujoco reinforcement learning tasks compared to competing approaches
- MCMC-BO maintains computational efficiency by tracking only a batch of points rather than requiring dense discretization

## Why This Works (Mechanism)
MCMC-BO works by leveraging the power of Thompson sampling combined with MCMC sampling to efficiently explore high-dimensional posterior distributions. Traditional Thompson sampling in high dimensions requires computing posterior samples at every point in a discretized space, which becomes computationally intractable. By using MCMC to directly sample from the posterior distribution, MCMC-BO can focus computational resources on promising regions while still maintaining the exploration-exploitation balance that makes Thompson sampling effective.

The Gaussian process regression provides a probabilistic model of the objective function, while Thompson sampling guides the search by considering uncertainty in this model. The MCMC component then enables efficient exploration of the posterior distribution without requiring exhaustive computation across the entire high-dimensional space. This combination allows MCMC-BO to maintain the theoretical guarantees of Thompson sampling while achieving practical efficiency in high-dimensional settings.

## Foundational Learning

**Gaussian Process Regression**: A non-parametric Bayesian approach for modeling unknown functions that provides uncertainty estimates along with predictions. Why needed: Provides the probabilistic framework for modeling the objective function in Bayesian optimization. Quick check: Can represent any smooth function with appropriate kernel choice.

**Thompson Sampling**: A Bayesian approach to decision-making under uncertainty that samples from the posterior distribution to balance exploration and exploitation. Why needed: Provides the theoretical foundation for optimal exploration-exploitation trade-off. Quick check: Achieves optimal regret bounds in bandit problems.

**Markov Chain Monte Carlo**: A class of algorithms for sampling from complex probability distributions by constructing a Markov chain with the desired distribution as its equilibrium. Why needed: Enables efficient sampling from intractable posterior distributions without discretization. Quick check: Converges to target distribution given sufficient iterations.

## Architecture Onboarding

**Component Map**: Gaussian Process -> Thompson Sampling -> MCMC Sampling -> Candidate Selection

**Critical Path**: The algorithm follows the sequence: (1) Update GP posterior with observed data, (2) Generate Thompson samples via MCMC, (3) Select candidate points from Thompson samples, (4) Evaluate function at candidates, (5) Update GP with new observations.

**Design Tradeoffs**: The method trades computational complexity of discretization for MCMC sampling overhead. While discretization requires evaluating the posterior at every point in a grid, MCMC sampling requires only a batch of points but introduces sampling variance. The choice of MCMC parameters and GP kernel significantly impacts performance.

**Failure Signatures**: Poor performance may occur when: (1) The acquisition function fails to provide good candidate points, (2) MCMC sampling parameters are poorly tuned, leading to slow mixing or poor coverage, (3) The GP kernel is mismatched to the function characteristics, or (4) The function has very sharp local optima that are difficult to discover with batch sampling.

**First Experiments**:
1. Test MCMC-BO on low-dimensional synthetic functions (d=2-10) to verify basic functionality and compare against standard BO methods
2. Evaluate sensitivity to MCMC sampling parameters (number of samples, step size) on benchmark functions
3. Compare wall-clock time versus sample efficiency against discretization-based Thompson sampling approaches

## Open Questions the Paper Calls Out
None

## Limitations

- The method's performance depends heavily on the acquisition function's ability to provide good candidate points, as theoretical guarantees require idealized acquisition functions
- Computational overhead from MCMC sampling is not fully characterized, and the method's efficiency gains may vary with problem characteristics
- Limited validation on real-world engineering problems with expensive black-box functions beyond the presented Mujoco tasks

## Confidence

- Theoretical convergence guarantees: **High** - The paper provides rigorous mathematical proofs for the MCMC-BO algorithm's convergence properties
- Empirical performance claims: **Medium** - Strong results on benchmark functions and Mujoco tasks, but limited testing on diverse real-world applications
- Computational efficiency claims: **Medium** - The method reduces computational burden compared to discretization approaches, but MCMC sampling overhead is not fully characterized

## Next Checks

1. Test MCMC-BO on a broader range of real-world optimization problems with expensive black-box functions, such as hyperparameter tuning for deep learning models or engineering design optimization
2. Conduct a systematic ablation study on MCMC sampling parameters and covariance kernel choices to understand their impact on performance and identify optimal configurations
3. Compare MCMC-BO's sample efficiency and wall-clock time against other high-dimensional BO methods on problems with varying function characteristics (e.g., separability, conditioning, multi-modality)