---
ver: rpa2
title: 'Retaining Key Information under High Compression Ratios: Query-Guided Compressor
  for LLMs'
arxiv_id: '2406.02376'
source_url: https://arxiv.org/abs/2406.02376
tags:
- compression
- context
- document
- information
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: QGC introduces a query-guided compression approach for long context
  in LLMs, addressing the loss of key information at high compression ratios. It uses
  query-aware document encoding, weighted n-gram pooling, query-document reviewing,
  and semantic alignment to retain query-relevant content.
---

# Retaining Key Information under High Compression Ratios: Query-Guided Compressor for LLMs

## Quick Facts
- arXiv ID: 2406.02376
- Source URL: https://arxiv.org/abs/2406.02376
- Reference count: 4
- Achieves up to 2.75x higher compression ratios and 2.42x higher throughput than LongLLMLingua while maintaining accuracy within 10% loss

## Executive Summary
QGC introduces a query-guided compression approach for long context in LLMs that addresses the loss of key information at high compression ratios. The method uses query-aware document encoding, weighted n-gram pooling, query-document reviewing, and semantic alignment to retain query-relevant content. Experimental results on NaturalQuestions, TriviaQA, and HotpotQA demonstrate significant improvements in compression efficiency while maintaining acceptable accuracy levels.

## Method Summary
QGC employs a multi-stage compression pipeline that begins with query-aware document encoding to identify relevant content. The system then applies weighted n-gram pooling to prioritize important information based on query relevance. A query-document reviewing stage ensures semantic alignment between compressed content and original information. The approach is specifically designed to handle high compression ratios while preserving critical information needed for downstream tasks like question answering.

## Key Results
- Achieves up to 2.75x higher compression ratios compared to LongLLMLingua
- Improves throughput by 2.42x over baseline methods
- Maintains accuracy within 10% loss threshold under high compression conditions
- Demonstrates effectiveness across NaturalQuestions, TriviaQA, and HotpotQA datasets

## Why This Works (Mechanism)
The query-guided approach works by aligning the compression process with the specific information needs dictated by user queries. By incorporating query relevance into document encoding and n-gram selection, the system can prioritize information that directly supports answering the given query. The semantic alignment component ensures that compressed representations maintain the relationships and context necessary for accurate response generation, even at high compression ratios where traditional methods typically fail.

## Foundational Learning
- Query-aware encoding: Why needed - To identify and prioritize document content relevant to specific user queries; Quick check - Verify that encoded representations capture query-relevant features through downstream task performance
- Weighted n-gram pooling: Why needed - To selectively retain information based on importance scores rather than uniform compression; Quick check - Analyze n-gram frequency distributions before and after pooling
- Semantic alignment: Why needed - To maintain contextual relationships and meaning in compressed representations; Quick check - Compare semantic similarity metrics between original and compressed documents

## Architecture Onboarding
Component map: Document input -> Query-aware encoder -> Weighted n-gram pooler -> Query-document reviewer -> Semantic aligner -> Compressed output

Critical path: The most important components are the query-aware encoder and semantic aligner, as they determine both what information is selected and how well it maintains meaning. The weighted n-gram pooling serves as the primary compression mechanism but depends on accurate relevance scoring from the encoder.

Design tradeoffs: The system prioritizes query-relevance over comprehensive document coverage, which may miss information needed for queries not anticipated during compression. The query-guided approach adds computational overhead compared to static compression methods but enables higher compression ratios.

Failure signatures: Performance degradation occurs when queries require information outside the compressed document's scope, when query relevance scoring fails to identify important content, or when semantic alignment cannot preserve necessary context at extreme compression ratios.

First experiments:
1. Test compression on documents with varying query types to assess adaptability
2. Compare performance across different compression ratio thresholds
3. Evaluate query-response accuracy with and without the query-document reviewing stage

## Open Questions the Paper Calls Out
The paper acknowledges several limitations including the need for broader evaluation beyond QA tasks, the somewhat arbitrary nature of the 10% accuracy threshold, and the potential for query-guided methods to introduce biases toward certain document structures or query types.

## Limitations
- Evaluation focuses primarily on three QA datasets, limiting generalizability to other domains
- The 10% accuracy threshold for acceptable performance lacks clear justification for real-world applications
- Claims of compression ratio improvements require careful validation under identical conditions
- Query-guided approach may introduce biases toward specific query types or document structures

## Confidence
- Claims about compression ratios and throughput improvements: Medium
- Claims about maintaining accuracy within 10% loss: Medium
- Claims about inference efficiency and latency reduction: Medium
- Claims about query-relevance preservation: Medium

## Next Checks
1. Test QGC on non-QA tasks (e.g., summarization, document classification) to assess generalizability beyond the evaluated domains
2. Conduct ablation studies to quantify the individual contributions of each component (query-aware encoding, weighted n-gram pooling, etc.) to overall performance
3. Evaluate performance degradation at compression ratios beyond those tested, to determine the practical limits of the approach