---
ver: rpa2
title: 'Younger: The First Dataset for Artificial Intelligence-Generated Neural Network
  Architecture'
arxiv_id: '2406.15132'
source_url: https://arxiv.org/abs/2406.15132
tags:
- dataset
- younger
- operator
- neural
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Younger introduces the first dataset for Artificial Intelligence-Generated
  Neural Network Architecture (AIGNNA), containing 7,629 unique neural network architectures
  derived from over 174K real-world models across 30+ tasks. The dataset represents
  each architecture as a directed acyclic graph (DAG) with detailed operator-level
  information, enabling two primary design paradigms: local (architecture component
  refinement) and global (complete architecture generation from scratch).'
---

# Younger: The First Dataset for Artificial Intelligence-Generated Neural Network Architecture

## Quick Facts
- arXiv ID: 2406.15132
- Source URL: https://arxiv.org/abs/2406.15132
- Reference count: 40
- First dataset for AI-generated neural network architecture with 7,629 unique DAG-represented architectures from 174K real-world models

## Executive Summary
Younger introduces the first dataset specifically designed for Artificial Intelligence-Generated Neural Network Architecture (AIGNNA), containing 7,629 unique neural network architectures derived from over 174K real-world models across 30+ tasks. Each architecture is represented as a directed acyclic graph (DAG) with detailed operator-level information, enabling both local architecture component refinement and global complete architecture generation. The dataset achieves AUC scores of 0.99 for data flow design and 0.84 for operator design, while serving as a promising benchmark for graph neural networks due to its diverse graph structural characteristics.

## Method Summary
Younger is constructed by converting neural network models from public hubs into ONNX format, then extracting directed acyclic graphs (DAGs) that represent architectures with detailed operator-level information. The dataset facilitates two primary design paradigms: local (focusing on fine-tuning and optimizing architecture components) and global (generating entire neural network architectures from scratch). For the local paradigm, community detection algorithms extract subgraphs as building blocks, while graph neural networks like GCN, GAT, and GraphSAGE are employed for various tasks including edge prediction and operator classification.

## Key Results
- Achieved AUC scores of 0.99 for data flow design and 0.84 for operator design in local architecture refinement
- Successfully demonstrated global architecture generation with a negative log-likelihood of at least 345.4988 using DiGress
- Validated as a promising benchmark for graph neural networks due to diverse DAG structural characteristics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Younger enables automated neural network architecture generation by providing a large-scale dataset of real-world architectures represented as DAGs.
- Mechanism: The dataset captures diverse architectural patterns and relationships between operators, enabling AI models to learn how to construct valid architectures from scratch or refine existing ones.
- Core assumption: Real-world architectures contain sufficient diversity and patterns to train generative models for novel architecture creation.
- Evidence anchors:
  - [abstract] "Younger introduces the first dataset for Artificial Intelligence-Generated Neural Network Architecture (AIGNNA), containing 7,629 unique neural network architectures derived from over 174K real-world models"
  - [section] "Derived from over 174K real-world models across more than 30 tasks from various public model hubs, Younger includes 7,629 unique architectures, and each is represented as a directed acyclic graph with detailed operator-level information"
  - [corpus] Weak - corpus contains only 8 related papers with very low citation counts (0.0 average), suggesting this is a novel contribution with limited external validation yet
- Break condition: If real-world architectures are too homogeneous or lack sufficient diversity, the dataset won't capture enough variation to train generative models effectively.

### Mechanism 2
- Claim: The DAG representation with operator-level details enables both local and global architecture design paradigms.
- Mechanism: Local design allows refinement of specific components (operator selection, data flow), while global design enables complete architecture generation from scratch, both supported by the structured representation.
- Core assumption: DAG representation preserves sufficient architectural information while being computationally tractable for learning algorithms.
- Evidence anchors:
  - [abstract] "The dataset facilitates two primary design paradigms: global, for creating complete architectures from scratch, and local, for detailed architecture component refinement"
  - [section] "We introduce two paradigms for AIGNNA, characterized by escalating complexity: 1) Local: This paradigm focuses on fine-tuning and optimizing components... 2) Global: This more demanding paradigm entails generating entire neural network architectures from scratch"
  - [corpus] Missing - corpus doesn't contain similar multi-paradigm architecture generation approaches
- Break condition: If the DAG representation loses critical architectural information during conversion from ONNX, neither paradigm will work effectively.

### Mechanism 3
- Claim: Younger serves as a benchmark for graph neural networks due to its unique structural properties.
- Mechanism: The dataset's diverse graph sizes (from dozens to hundreds of thousands of nodes) and operator types create challenging testbeds for GNN scalability, robustness, and generalization.
- Core assumption: Graph neural networks can effectively learn from DAG-structured data with heterogeneous node types.
- Evidence anchors:
  - [abstract] "experiments revealed that due to the representation of architecture as DAG, Younger's unique graph structural characteristics make it a promising benchmark dataset in advancing research in Graph Neural Networks (GNN)"
  - [section] "Younger introduces a new dimension to GNN benchmarking by providing a dataset of diverse, complex directed acyclic graphs (DAGs) ranging dramatically in scale and complexity"
  - [corpus] Weak - corpus contains related graph neural network papers but none specifically addressing architecture DAGs as benchmarks
- Break condition: If GNNs cannot effectively handle the heterogeneous node types and varying graph scales present in Younger, the benchmark utility will be limited.

## Foundational Learning

- Concept: Directed Acyclic Graphs (DAGs) and their properties
  - Why needed here: The entire dataset and all learning paradigms rely on understanding DAG structures where nodes represent operators and edges represent data flows
  - Quick check question: Can you explain why neural network architectures must be represented as DAGs rather than general graphs?

- Concept: ONNX operator specification and representation
  - Why needed here: Understanding the 193 ONNX operators and how they're represented in the dataset is crucial for working with the node features and designing experiments
  - Quick check question: What's the difference between representing operators with and without attributes in the context of this dataset?

- Concept: Graph Neural Networks (GNNs) fundamentals
  - Why needed here: The experiments and potential applications rely on GNNs for learning patterns in the architectural DAGs
  - Quick check question: How would you modify a standard GNN to handle heterogeneous node types (different operators) in the Younger dataset?

## Architecture Onboarding

- Component map: ONNX model conversion pipeline -> DAG extraction tool -> Three dataset series (Complete, Filter, Split) -> Community detection for subgraph extraction -> GCN, GAT, SAGE, GAE, VGAE baseline models -> Official website with dataset querying, downloading, and contribution capabilities

- Critical path: 1) Retrieve models from public hubs → Convert to ONNX → Extract DAGs → Filter unique architectures; 2) For local paradigm: Split dataset → Apply community detection → Extract subgraphs → Train GNN models; 3) For global paradigm: Train graph generation model (e.g., DiGress) on full DAGs

- Design tradeoffs:
  - Operator representation: Including attributes increases granularity but dramatically increases node feature space complexity
  - Dataset size vs. quality: Filtering to 7,629 unique architectures from 174K models balances diversity with computational tractability
  - Homogeneous vs. heterogeneous treatment: Treating all nodes as homogeneous operators simplifies learning but loses type-specific information

- Failure signatures:
  - Out-of-memory errors during GAT training (occurs with high node feature cardinality)
  - Poor multi-classification performance due to operator type imbalance
  - Failed ONNX conversion for large models (>300 nodes excluded from global experiments)

- First 3 experiments:
  1. Data flow design experiment: Train GCN on binary edge prediction task with 'Operator w/o Attributes' configuration
  2. Operator design experiment: Apply community detection to extract subgraphs, then train SAGE for operator classification
  3. Node embedding visualization: Extract embeddings from trained GCN and visualize with t-SNE to observe operator clustering patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the heterogeneity of operator types affect the performance of graph neural networks on the Younger dataset?
- Basis in paper: [explicit] The paper discusses the complexity introduced by different operator types and their attributes, and mentions the challenge of treating graphs as homogeneous vs. heterogeneous.
- Why unresolved: The paper only treats the architectures as homogeneous graphs to avoid introducing more variables. It does not explore the impact of heterogeneity on GNN performance.
- What evidence would resolve it: Experiments comparing GNN performance on heterogeneous vs. homogeneous graph representations of the Younger dataset.

### Open Question 2
- Question: What is the optimal way to extract building blocks for neural network architecture from the Younger dataset?
- Basis in paper: [inferred] The paper uses community detection to extract subgraphs, but acknowledges this may not be the most effective method and suggests it as preliminary validation.
- Why unresolved: The paper does not explore alternative methods for extracting building blocks or validate the effectiveness of the community detection approach.
- What evidence would resolve it: Comparison of various building block extraction methods (e.g., manual annotation, different community detection algorithms) and their impact on AIGNNA performance.

### Open Question 3
- Question: How does the distribution of operator types in the Younger dataset impact the performance of operator design in the local paradigm?
- Basis in paper: [explicit] The paper notes that some operator types appear more frequently than others, causing models to be biased towards predicting the majority of operators.
- Why unresolved: The paper does not explore techniques to mitigate this bias or investigate the impact of different operator type distributions on performance.
- What evidence would resolve it: Experiments varying the operator type distribution in the training data and measuring the impact on operator design performance.

## Limitations

- Global architecture generation evaluation remains preliminary with only single experiment using DiGress
- Operator design experiments show high variance with standard deviations ranging from 0.016 to 0.100
- Dataset limited to models available on public hubs, potentially introducing selection bias

## Confidence

- **High Confidence**: The dataset construction methodology and local architecture refinement results (AUC scores of 0.99 for data flow design and 0.84 for operator design) are well-documented and reproducible. The DAG representation and two-paradigm framework are clearly specified.
- **Medium Confidence**: The claim that Younger serves as a benchmark for graph neural networks is supported by experimental results but lacks extensive external validation. The dataset's utility for GNN research is demonstrated but not comprehensively explored.
- **Low Confidence**: The global architecture generation capabilities and the overall effectiveness of AI-generated neural network architectures (AIGNNA) are not thoroughly validated. The single experiment with DiGress provides limited evidence for the dataset's utility in this challenging paradigm.

## Next Checks

1. **Benchmark Validation**: Conduct a comprehensive benchmark study using multiple GNN architectures (not just the baseline models) on the Younger dataset to evaluate its utility as a GNN benchmark. Compare performance across different graph scales and operator distributions.

2. **Global Architecture Generation**: Implement and evaluate additional global architecture generation methods (e.g., VAE-based approaches, reinforcement learning) on the Younger dataset. Compare their performance against the reported DiGress results using multiple metrics beyond negative log-likelihood.

3. **Real-world Deployment Test**: Select a set of target tasks not represented in the original 30+ tasks, use the Younger dataset to train an AIGNNA model, and evaluate the generated architectures' performance on these unseen tasks. This would provide evidence for the dataset's generalization capabilities.