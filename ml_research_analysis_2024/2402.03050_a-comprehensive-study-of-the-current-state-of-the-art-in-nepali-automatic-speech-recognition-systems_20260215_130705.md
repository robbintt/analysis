---
ver: rpa2
title: A Comprehensive Study of the Current State-of-the-Art in Nepali Automatic Speech
  Recognition Systems
arxiv_id: '2402.03050'
source_url: https://arxiv.org/abs/2402.03050
tags:
- speech
- nepali
- language
- recognition
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey comprehensively reviews Nepali Automatic Speech Recognition
  (ASR) research, identifying limited publicly available datasets and language models
  as key challenges. The review examines 16 Nepali ASR publications using datasets
  like OSLR54 and OSLR43, finding that models combining CNN, ResNet, and BiLSTM architectures
  achieve the best performance (CER 10.30% on multi-speaker data).
---

# A Comprehensive Study of the Current State-of-the-Art in Nepali Automatic Speech Recognition Systems

## Quick Facts
- arXiv ID: 2402.03050
- Source URL: https://arxiv.org/abs/2402.03050
- Reference count: 39
- Primary result: CNN-ResNet-BiLSTM architectures achieve 10.30% CER on multi-speaker Nepali speech data

## Executive Summary
This survey comprehensively reviews Nepali Automatic Speech Recognition (ASR) research, identifying limited publicly available datasets and language models as key challenges. The review examines 16 Nepali ASR publications using datasets like OSLR54 and OSLR43, finding that models combining CNN, ResNet, and BiLSTM architectures achieve the best performance (CER 10.30% on multi-speaker data). Major obstacles include noise in recordings, lack of diverse speech samples, and insufficient language model development. The authors recommend expanding datasets to include activity-based recordings, developing multilingual models, and applying transfer learning techniques. They suggest that industrial-level Nepali ASR applications could significantly improve digital accessibility for non-literate users and preserve endangered Nepali dialects.

## Method Summary
The authors conducted a systematic literature review of 16 Nepali ASR publications, analyzing architectures, datasets, evaluation metrics, and performance outcomes. They categorized research based on neural network approaches (CNN, LSTM, BiLSTM, RNN, Transformer), examined dataset characteristics (OSLR54, OSLR43), and evaluated results using CER and WER metrics. The survey synthesized findings across multiple studies to identify trends, challenges, and opportunities in Nepali ASR development.

## Key Results
- CNN-ResNet-BiLSTM architectures achieve best performance with 10.30% CER on multi-speaker data
- Limited dataset availability (OSLR54, OSLR43) constrains research progress
- Transfer learning from multilingual models is recommended but currently unavailable for Nepali ASR

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Combined CNN-ResNet-BiLSTM architecture improves Nepali ASR performance by capturing hierarchical and temporal speech patterns.
- Mechanism: CNNs extract local speech features, ResNet mitigates vanishing gradients and speeds training, BiLSTM captures long-range temporal dependencies in Nepali phonemes.
- Core assumption: Nepali speech has both local and long-range dependencies that can be captured by hierarchical neural features.
- Evidence anchors:
  - [abstract]: "models combining CNN, ResNet, and BiLSTM architectures achieve the best performance (CER 10.30% on multi-speaker data)"
  - [section]: "Dhakal et al. [24] introduced a model that uses a combination of Residual Network (ResNet) within BiLSTM and 1D-CNN framework... The ResNet architecture is employed to enhance the efficiency of network training and mitigate premature saturation of the CTC-loss function"
- Break condition: If Nepali speech data lacks sufficient diversity, hierarchical features may not generalize; also if dataset is too small, deeper models overfit.

### Mechanism 2
- Claim: CTC loss alignment allows direct speech-to-text mapping without separate language model.
- Mechanism: CTC enables end-to-end training by aligning variable-length speech frames to text sequences without pre-segmentation.
- Core assumption: Nepali speech can be directly aligned to characters/words without intermediate segmentation.
- Evidence anchors:
  - [abstract]: "CTC-based loss function allows for training DNN-based E2E ASR models"
  - [section]: "Dhakal et al. [24] trained using CTC loss function... Joshi et al. [15] trained using CTC loss function"
- Break condition: If Nepali has strong tonal dependencies or code-switching, CTC may struggle without language model support.

### Mechanism 3
- Claim: Transfer learning from multilingual models improves low-resource Nepali ASR.
- Mechanism: Pretraining on larger multilingual corpora and fine-tuning on Nepali data transfers learned speech patterns.
- Core assumption: Shared phonetic and acoustic features across languages can be leveraged for Nepali.
- Evidence anchors:
  - [section]: "The Nepali Automatic Speech Recognition (ASR) system currently faces a limitation in the availability of pre-trained models for transfer learning... The model developed by scholars should be published to facilitate interested researchers in applying transfer learning and achieving improved outcomes"
  - [corpus]: No explicit corpus evidence for multilingual pretraining; this is an assumption.
- Break condition: If Nepali has unique phonological features not present in pretraining languages, transfer gains may be limited.

## Foundational Learning

- Concept: Acoustic modeling basics (MFCC, spectrograms)
  - Why needed here: ASR systems convert raw audio into feature vectors for neural networks.
  - Quick check question: What audio features are commonly used as input to Nepali ASR models?

- Concept: Sequence modeling (RNNs, Transformers)
  - Why needed here: Speech is a sequential signal; models must capture temporal dependencies.
  - Quick check question: Which architectures in the survey explicitly handle long-term dependencies?

- Concept: Evaluation metrics (CER, WER)
  - Why needed here: ASR performance is quantified using character/word error rates.
  - Quick check question: How do CER and WER differ, and which does the best Nepali model achieve?

## Architecture Onboarding

- Component map: Preprocessed audio features → CNN layers → ResNet blocks → BiLSTM layers → CTC decoder → Text output
- Critical path: Data → Feature extraction → CNN → ResNet → BiLSTM → CTC loss → Text output
- Design tradeoffs:
  - Model depth vs. overfitting on small datasets
  - CTC-only vs. CTC+attention for better alignment
  - Monolingual vs. multilingual pretraining for data efficiency
- Failure signatures:
  - High CER on multi-speaker data → need speaker adaptation or more diverse training data
  - Overfitting on single speaker → add regularization, dropout, data augmentation
  - Poor generalization to new accents → expand dataset coverage
- First 3 experiments:
  1. Baseline: 1D-CNN + BiLSTM + CTC on OSLR54 dataset
  2. Add ResNet: 1D-CNN + ResNet + BiLSTM + CTC, compare CER
  3. Transfer learning: Pretrain on multilingual ASR model, fine-tune on Nepali data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal dataset size and composition needed to achieve industrial-level performance in Nepali ASR systems?
- Basis in paper: [explicit] The paper identifies limited publicly available speech datasets and lack of diverse speech samples as major challenges
- Why unresolved: The authors note that current datasets suffer from noise, lack of accents/dialects, and insufficient size, but don't specify the exact dataset requirements for industrial-grade performance
- What evidence would resolve it: Systematic experiments testing different dataset sizes, compositions (activity-based vs read speech), and diversity levels to establish performance benchmarks

### Open Question 2
- Question: How do transformer-based architectures (e.g., Conformer) compare to current CNN/LSTM combinations for Nepali ASR?
- Basis in paper: [inferred] The authors suggest conducting experimental investigation on contemporary models employing attention-based architectures
- Why unresolved: The survey focuses on CNN/LSTM-based models, but transformer architectures are identified as cutting-edge yet untested for Nepali ASR
- What evidence would resolve it: Direct performance comparison between transformer-based models and current state-of-the-art CNN/LSTM models using the same datasets and evaluation metrics

### Open Question 3
- Question: What is the impact of transfer learning from high-resource languages on Nepali ASR performance?
- Basis in paper: [explicit] The authors note that "The Nepali Automatic Speech Recognition (ASR) system currently faces a limitation in the availability of pre-trained models for transfer learning"
- Why unresolved: Despite the potential benefits of transfer learning, the paper indicates no pre-trained models are available for Nepali ASR, and their effectiveness remains untested
- What evidence would resolve it: Experiments applying pre-trained models from related languages (e.g., Hindi, other Indo-Aryan languages) and measuring performance gains on Nepali ASR tasks

## Limitations
- Limited dataset availability constrains research progress and generalizability of results
- No independent verification of reported performance metrics across studies
- Transfer learning recommendations lack empirical validation for Nepali specifically

## Confidence
- High Confidence: The identification of data scarcity and limited language model development as fundamental challenges
- Medium Confidence: The architectural recommendations (CNN-ResNet-BiLSTM with CTC) showing best performance
- Low Confidence: Transfer learning recommendations and industrial application claims

## Next Checks
1. **Independent Benchmark Validation:** Replicate the top-performing Nepali ASR architectures on the OSLR54 and OSLR43 datasets using standardized preprocessing and evaluation protocols to verify the reported 10.30% CER figure and compare different architectural approaches under controlled conditions.

2. **Transfer Learning Pilot Study:** Conduct a controlled experiment pretraining on a multilingual ASR model (e.g., Whisper or similar) and fine-tuning on Nepali data, comparing performance against monolingual baselines to quantify actual transfer learning benefits for Nepali speech recognition.

3. **Dataset Diversity Assessment:** Systematically evaluate model performance across different speaker demographics, recording conditions, and potentially underrepresented Nepali dialects within the available datasets to identify performance gaps and inform future data collection priorities.