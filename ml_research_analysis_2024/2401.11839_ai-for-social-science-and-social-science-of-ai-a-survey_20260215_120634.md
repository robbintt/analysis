---
ver: rpa2
title: 'AI for social science and social science of AI: A Survey'
arxiv_id: '2401.11839'
source_url: https://arxiv.org/abs/2401.11839
tags:
- language
- large
- social
- research
- science
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper surveys the intersection of large language models (LLMs)
  and social science, categorizing it into two directions: AI for social science and
  social science of AI. The survey highlights how LLMs serve as tools to enhance social
  science research and explores their social behaviors and characteristics as intelligent
  agents.'
---

# AI for social science and social science of AI: A Survey

## Quick Facts
- arXiv ID: 2401.11839
- Source URL: https://arxiv.org/abs/2401.11839
- Reference count: 19
- Key outcome: Survey categorizes LLM-social science intersection into "AI for social science" (LLMs as tools) and "social science of AI" (studying LLMs as social entities), identifying future research directions

## Executive Summary
This survey systematically categorizes the intersection of large language models (LLMs) and social science into two complementary directions: AI for social science (using LLMs as tools to enhance research efficiency) and social science of AI (studying LLM agents as social entities). The paper reviews applications across psychology, sociology, economics, politics, and linguistics, and summarizes state-of-the-art simulation platforms for AI-driven social experiments. It emphasizes the need for systematic theories to understand AI agents' social roles and highlights future research directions including multimodal capabilities and standardized evaluation methods.

## Method Summary
This survey paper reviews existing literature at the intersection of LLMs and social science through a systematic categorization approach. The authors identified and organized relevant papers into two main directions: AI for social science (LLMs as research tools) and social science of AI (studying LLMs as social entities). The methodology involves literature review and synthesis across 19 references, organizing findings by social science sub-disciplines and research stages. The survey identifies applications, tools, and future research directions without presenting novel experimental methods.

## Key Results
- Establishes a clear taxonomy separating LLM applications as tools versus studying LLM agents as social entities
- Reviews LLM applications across five social science disciplines (psychology, sociology, economics, politics, linguistics)
- Summarizes simulation platforms enabling AI-driven social experiments and multi-agent environments
- Identifies future research directions including systematic theories for AI agents and multimodal capabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The survey establishes a useful taxonomy by splitting the intersection of AI and social science into "AI for social science" and "social science of AI."
- Mechanism: This separation allows researchers to clearly distinguish between using AI as a tool versus studying AI agents as social entities. It grounds each work's research significance and application scope.
- Core assumption: The two directions, though sharing technical methodologies, have distinct research objectives and scopes of application.
- Evidence anchors:
  - [abstract] The paper "systematically categorize previous explorations in the combination of AI and social science into two directions that share common technical approaches but differ in their research objectives."
  - [section] "These directions share common technological approaches, they have distinct research objectives, significance, and scopes of application."
- Break condition: If AI agents become indistinguishable from humans in behavior, the distinction between "AI for social science" and "social science of AI" may become less meaningful.

### Mechanism 2
- Claim: Large language models can serve as effective tools at every stage of social science research, enhancing efficiency.
- Mechanism: LLMs automate or assist with tasks such as literature review, hypothesis generation, experiment simulation, survey design, and data analysis, thereby improving speed, reducing costs, and lowering barriers to entry.
- Core assumption: The language understanding and generation capabilities of LLMs are sufficient to meaningfully assist in these research tasks.
- Evidence anchors:
  - [abstract] "The first direction is focused on AI for social science, where AI is utilized as a powerful tool to enhance various stages of social science research."
  - [section] "Large language models can be applied at every stage of social science research, improving efficiency across the board."
- Break condition: If LLMs generate fabricated or incorrect information that cannot be reliably validated, their utility as research tools diminishes.

### Mechanism 3
- Claim: The development of simulation platforms based on large language models enables new forms of social science research.
- Mechanism: These platforms allow researchers to create multi-agent environments, simulate human-like interactions, and explore emergent social behaviors in ways that are faster, cheaper, and more ethical than traditional methods.
- Core assumption: Large language models can simulate human behavior believably enough to yield insights into social phenomena.
- Evidence anchors:
  - [abstract] "We also summarized state-of-art experiment simulation platforms to facilitate research in these two directions."
  - [section] "These platforms utilize large language models as agents and allow for the setting and implementation of intervention conditions to simulate diverse social situations, interactions, and behaviors."
- Break condition: If large language models fail to accurately simulate human behavior or if the simulation platforms lack sufficient flexibility and realism, their research value is limited.

## Foundational Learning

- Concept: Understanding the distinction between "AI for social science" and "social science of AI."
  - Why needed here: This foundational concept is the organizing principle of the entire survey. Without it, the reader cannot understand the framework or the categorization of the research.
  - Quick check question: Can you explain the difference between using AI as a tool in social science research versus studying AI agents as social entities?

- Concept: Familiarity with large language models (LLMs) and their capabilities.
  - Why needed here: The survey focuses on the intersection of LLMs and social science. A basic understanding of what LLMs are and what they can do is essential to grasp the applications and implications discussed.
  - Quick check question: What are some key capabilities of large language models that make them useful for social science research?

- Concept: Knowledge of core social science research methodologies (e.g., experiments, surveys, content analysis).
  - Why needed here: The survey reviews how LLMs can be applied at different stages of social science research. Understanding these methodologies is crucial to appreciate the potential impact of LLMs.
  - Quick check question: What are the main stages of the social science research process, and how might large language models assist at each stage?

## Architecture Onboarding

- Component map:
  - Literature Review Section -> Overview of the field and the two main directions
  - AI for Social Science Section -> Applications of LLMs as tools in social science research (hypothesis generation, hypothesis verification)
  - Social Science of AI Section -> Research on the social behaviors and characteristics of AI agents (psychology, sociology, economics, politics, linguistics)
  - Public Tools and Resources Section -> Overview of simulation platforms and tools based on LLMs
  - Conclusion -> Summary of key findings and future directions

- Critical path:
  1. Read the introduction and literature review to understand the context and the two main directions
  2. Explore the "AI for social science" section to learn about LLM applications as tools
  3. Investigate the "social science of AI" section to understand research on AI agents as social entities
  4. Review the public tools and resources section to discover available simulation platforms
  5. Read the conclusion to grasp the key findings and future research directions

- Design tradeoffs:
  - Breadth vs. Depth: The survey covers a wide range of topics but may not delve deeply into each one. This tradeoff allows for a comprehensive overview but may require additional reading for in-depth understanding.
  - Technical Detail vs. Accessibility: The survey aims to be accessible to a broad audience, which may mean sacrificing some technical detail. This tradeoff makes the survey more widely applicable but may not satisfy those seeking highly technical information.

- Failure signatures:
  - Lack of clarity in the distinction between the two main directions
  - Incomplete or inaccurate coverage of LLM applications or social science research
  - Failure to identify key challenges or limitations of using LLMs in social science
  - Insufficient discussion of future research directions or potential impacts

- First 3 experiments:
  1. Use an LLM to assist with a literature review on a specific social science topic. Compare the results to a traditional literature review in terms of speed, comprehensiveness, and quality.
  2. Design a simple experiment using a simulation platform based on LLMs to explore a social phenomenon (e.g., cooperation, conflict, social influence). Analyze the results and compare them to real-world data or theoretical predictions.
  3. Use an LLM to generate hypotheses for a social science research project. Evaluate the quality and novelty of the hypotheses compared to those generated by human researchers.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can large language models (LLMs) effectively simulate human behavior in social science experiments without significant bias or limitations?
- Basis in paper: [explicit] The paper discusses the use of LLMs as believable proxies for human behavior in social science research, highlighting both their potential and limitations, including concerns about their believability, transparency, and reproducibility.
- Why unresolved: While LLMs have shown promise in mimicking human behavior, the paper emphasizes that there is currently no "gold standard" study demonstrating their ability to accurately simulate humans. Additionally, the inherent biases in LLMs and their black-box nature pose challenges to their use in social science research.
- What evidence would resolve it: A comprehensive, systematic study comparing the behavior of LLM agents to that of human subjects across a wide range of social science experiments, using standardized metrics and controlling for potential biases.

### Open Question 2
- Question: How can the social science of AI be developed into a systematic theory to understand the social behaviors of AI agents?
- Basis in paper: [inferred] The paper highlights the need for a systematic theory for the social science of AI, similar to the social science of humans, to connect and organize the currently fragmented research efforts and allow for a comprehensive examination of AI agents' social characteristics.
- Why unresolved: While there is growing interest in studying the social behaviors of AI agents, the field lacks a cohesive theoretical framework to guide research and understanding. This hinders the ability to draw meaningful conclusions about the social dynamics of AI communities and their potential impact on society.
- What evidence would resolve it: The development of a comprehensive theoretical framework that integrates insights from various social science disciplines and provides a structured approach to studying the social behaviors of AI agents, including their interactions, norms, and emergent properties.

### Open Question 3
- Question: What are the key factors influencing the behavior of AI agents generated by language models in social dilemmas?
- Basis in paper: [explicit] The paper mentions the need to investigate the factors influencing intelligent agent behavior generated by language models across a wider range of social dilemmas, including model architecture, training parameters, and various partner strategies.
- Why unresolved: While some studies have explored the behavior of AI agents in specific social dilemmas, the factors influencing their behavior are not yet fully understood. This limits the ability to predict and control the behavior of AI agents in complex social situations.
- What evidence would resolve it: A series of controlled experiments manipulating different factors (e.g., model architecture, training data, partner strategies) and observing their effects on the behavior of AI agents in various social dilemmas, using a combination of quantitative and qualitative analysis methods.

## Limitations

- The survey's comprehensiveness is difficult to evaluate without knowing the specific search strategy and inclusion/exclusion criteria used to identify the 19 references.
- The paper doesn't specify how it assessed the methodological rigor or significance of individual studies, making it unclear how much weight to give to the synthesized conclusions.
- The rapidly evolving nature of LLM technology means some findings or platform capabilities may become outdated quickly.

## Confidence

- High confidence: The conceptual framework distinguishing "AI for social science" from "social science of AI" is well-articulated and represents a meaningful organizational principle that has face validity in the field.
- Medium confidence: The claim that LLMs can enhance social science research efficiency is supported by multiple examples, but the extent of improvement and reliability varies significantly by application domain and research stage.
- Medium confidence: The utility of simulation platforms for social science research is plausible based on described capabilities, but real-world validation studies demonstrating their scientific value remain limited.

## Next Checks

1. Conduct an independent literature search using systematic review protocols to compare coverage against the survey's reference list and identify any significant gaps or biases in the current survey.
2. Perform a case study where the same social science research task (e.g., literature review, hypothesis generation, or survey design) is completed both with and without LLM assistance, measuring time, quality, and researcher effort across multiple teams.
3. Design and execute a controlled experiment using one of the mentioned simulation platforms to test a specific social science hypothesis, comparing results against traditional experimental data or theoretical predictions to assess validity and reliability.