---
ver: rpa2
title: Attention-aware non-rigid image registration for accelerated MR imaging
arxiv_id: '2404.17621'
source_url: https://arxiv.org/abs/2404.17621
tags: []
core_contribution: The paper introduces a self-supervised deep learning framework
  for non-rigid image registration in accelerated MRI. It combines local visual representations
  and global contextual information using a transformer-based module to handle motion
  estimation in the presence of undersampling artifacts.
---

# Attention-aware non-rigid image registration for accelerated MR imaging

## Quick Facts
- arXiv ID: 2404.17621
- Source URL: https://arxiv.org/abs/2404.17621
- Reference count: 40
- The paper introduces a self-supervised deep learning framework for non-rigid image registration in accelerated MRI, achieving superior performance across different sampling trajectories and acceleration factors.

## Executive Summary
This paper presents a self-supervised deep learning framework for non-rigid image registration in accelerated MRI that combines local visual representations with global contextual information through a transformer-based attention mechanism. The method addresses the challenge of motion estimation in the presence of undersampling artifacts by leveraging a Global Motion Aggregation (GMA) module that uses self-attention to compute similarity between pixels and project contextual features onto motion feature maps. The approach achieves accurate motion estimation across different sampling trajectories (Cartesian and radial) and acceleration factors up to 16x for cardiac motion and 30x for respiratory motion, outperforming conventional and deep learning-based methods in motion-compensated reconstruction.

## Method Summary
The method employs a multi-scale cost volume approach combined with attention-aware global context integration for non-rigid registration. It features a feature encoder for local representation, a denoiser branch to mitigate undersampling artifacts, a context encoder for smoothed images, and a transformer-based Global Motion Aggregation module. The framework uses GRU-based iterative refinement of motion estimates through cost volume construction at multiple scales (kernels of sizes 1, 2, 4, 8). The entire system is trained self-supervised using photometric loss, smoothness constraints, and denoising objectives to achieve robust motion estimation under high acceleration factors.

## Key Results
- Achieves accurate motion estimation across different sampling trajectories (Cartesian and radial) and acceleration factors up to 16x for cardiac motion and 30x for respiratory motion
- Outperforms conventional and deep learning-based methods in motion-compensated reconstruction, preserving high image fidelity
- Demonstrates superior image quality both qualitatively and quantitatively with metrics including SSIM, PSNR, NRMSE, and HFEN

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Attention-aware self-attention module mitigates undersampling artifact ambiguities in motion estimation
- Mechanism: The Global Motion Aggregation (GMA) module uses self-attention to compute similarity between pixels in the fixed image and project contextual features onto motion feature maps. This enables the network to identify anatomically coherent regions despite missing k-space data.
- Core assumption: Pixels belonging to the same anatomical structure have similar appearance and motion patterns, and these patterns are preserved enough under undersampling to be detected by attention.
- Evidence anchors:
  - [abstract] "additionally leverage long-range contextual information using a transformer-based module to alleviate ambiguities in the presence of artifacts caused by undersampling"
  - [section II-A] "We aim to enhance the motion features by incorporating global context through instilling self-similarities between pixels of the fixed image in the hidden representation of the multi-scale motion information"
- Break condition: If undersampling artifacts obscure anatomical boundaries enough that pixel similarity no longer reflects anatomical coherence, the attention mechanism will propagate incorrect motion cues.

### Mechanism 2
- Claim: Denoiser module improves registration robustness under high acceleration factors
- Mechanism: A ResNet-based denoiser smooths undersampled images before feature extraction, reducing aliasing artifacts that would otherwise corrupt the registration process.
- Core assumption: Smoothing undersampled images preserves anatomical structure sufficiently while reducing aliasing artifacts that confuse the registration network.
- Evidence anchors:
  - [abstract] "We additionally leverage the image features of a denoised image to alleviate the impact of aliasing artifacts"
  - [section II-A] "We use a modified ResNet-15 to denoise the undersampled artifact-reduced images" and "We inject the smoothed image representation into the self-attention operator"
- Break condition: If denoising removes too much high-frequency detail essential for accurate registration, or if residual aliasing remains significant, registration accuracy will degrade.

### Mechanism 3
- Claim: Multi-scale cost volume approach captures both large and small displacements
- Mechanism: Cost volumes are built at multiple resolutions (kernels of sizes 1, 2, 4, 8) through average pooling, allowing the network to capture large displacements at coarse scales and refine them at fine scales.
- Core assumption: Motion patterns in MRI have both global (large displacement) and local (fine detail) components that can be efficiently captured through hierarchical cost volume processing.
- Evidence anchors:
  - [section II-A] "We apply volume cascading by using average pooling with different kernels of sizes 1, 2, 4, and 8 to build multi-scale cost volumes and allow for capturing large and small displacements"
- Break condition: If the motion is too complex or non-rigid for the hierarchical approach to resolve, or if the computational cost of multi-scale processing outweighs benefits, performance may plateau or degrade.

## Foundational Learning

- Concept: Transformer self-attention mechanism
  - Why needed here: Transformers capture long-range dependencies that convolutional networks struggle with, essential for identifying anatomical coherence across large displacements in MRI motion estimation
  - Quick check question: How does the self-attention mechanism in transformers differ from convolutional receptive fields in terms of capturing spatial relationships?

- Concept: Cost volume construction for optical flow
  - Why needed here: Cost volumes encode similarity between all pixel pairs, providing the foundation for estimating dense motion fields between image pairs
  - Quick check question: What is the computational complexity of a full cost volume and how does multi-scale pooling address this?

- Concept: Recurrent neural network update operators (GRU/LSTM)
  - Why needed here: Recurrent decoding iteratively refines motion estimates by learning residual updates, improving convergence to accurate motion fields
  - Quick check question: How does the gated recurrent unit (GRU) update motion estimates differently from a simple residual network?

## Architecture Onboarding

- Component map: Fixed image → Feature Encoder → Cost Volume → GRU Decoder → Motion Estimate; Moving image follows same path for comparison
- Critical path: Fixed image → Feature Encoder → Cost Volume → GRU Decoder → Motion Estimate; Moving image follows same path for comparison
- Design tradeoffs:
  - Attention vs. pure convolution: Better global context understanding vs. higher computational cost
  - Multi-scale vs. single-scale cost volumes: Better displacement range vs. increased memory usage
  - Denoiser inclusion: Improved robustness under acceleration vs. additional network complexity
- Failure signatures:
  - Motion fields with excessive smoothing (over-regularization)
  - Discontinuities in motion fields (insufficient smoothness constraints)
  - Inaccurate boundary motion (denoiser removing critical detail)
  - Slow convergence (inadequate update operator capacity)
- First 3 experiments:
  1. Test registration performance on fully sampled data without denoiser to establish baseline
  2. Evaluate impact of different update operators (GRU vs LSTM) on motion estimation accuracy
  3. Compare registration results with and without GMA module to quantify attention contribution

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method perform on 3D cardiac cine data compared to 2D registration?
- Basis in paper: [inferred] The paper focuses on 2D pairwise registration and mentions plans to extend to 3D in the future. It also notes that a 3D extension will result in a considerable increase in computational overhead.
- Why unresolved: The current framework operates on 2D data slices, while the authors acknowledge the need for 3D registration to account for through-plane motion and anatomical variations. They propose investigating alternative cost volume modeling techniques to manage computational overhead in 3D.
- What evidence would resolve it: Testing the proposed framework on 3D cardiac cine data and comparing its performance to the 2D approach and other state-of-the-art 3D registration methods.

### Open Question 2
- Question: Can the proposed method be integrated into an end-to-end trained motion-compensated reconstruction framework?
- Basis in paper: [explicit] The authors mention their aim to investigate the integration of the registration network within an end-to-end trained motion-compensated reconstruction framework in the future.
- Why unresolved: The current approach uses a two-step process where motion estimation and motion-compensated reconstruction are performed separately. An end-to-end framework could potentially improve the overall reconstruction quality by allowing the registration and reconstruction modules to be jointly optimized.
- What evidence would resolve it: Developing and evaluating an end-to-end framework that combines the proposed registration network with a motion-compensated reconstruction module, and comparing its performance to the current two-step approach and other state-of-the-art methods.

### Open Question 3
- Question: How does the proposed method handle different pathologies and cardiac functions beyond those included in the training dataset?
- Basis in paper: [inferred] The authors acknowledge that their training database had a limited size and covered a restricted number of pathologies and cardiac functions. They also note that other collected data may have features not accounted for, which may result in suboptimal performance.
- Why unresolved: The paper demonstrates the effectiveness of the proposed method on a specific set of pathologies and cardiac functions. However, it is unclear how well the method generalizes to other pathologies and cardiac functions not included in the training dataset.
- What evidence would resolve it: Evaluating the proposed method on a diverse set of pathologies and cardiac functions, including those not present in the training dataset, and comparing its performance to other state-of-the-art methods.

## Limitations
- The paper lacks detailed architectural specifications for the Global Motion Aggregation (GMA) module, making exact replication challenging
- Performance claims are based on retrospective undersampling rather than prospectively accelerated data, which may not reflect real-world conditions
- The contribution of individual components (denoiser, attention module, multi-scale cost volumes) is not explicitly quantified through ablation studies

## Confidence
- High confidence: The overall framework design and its application to accelerated MRI motion estimation is well-founded
- Medium confidence: The specific architectural choices and their implementation details, particularly the GMA module
- Medium confidence: Quantitative results on retrospective undersampling datasets, with lower confidence for prospective acceleration scenarios

## Next Checks
1. Implement ablation studies to isolate the contribution of the attention-aware GMA module versus baseline cost-volume registration without global context aggregation
2. Test the method on prospectively undersampled data with realistic acquisition artifacts to validate real-world performance claims
3. Evaluate the sensitivity of registration accuracy to different acceleration factors and sampling trajectories not covered in the original study