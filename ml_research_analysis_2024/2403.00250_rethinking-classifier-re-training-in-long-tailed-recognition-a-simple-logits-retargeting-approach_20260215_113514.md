---
ver: rpa2
title: 'Rethinking Classifier Re-Training in Long-Tailed Recognition: A Simple Logits
  Retargeting Approach'
arxiv_id: '2403.00250'
source_url: https://arxiv.org/abs/2403.00250
tags:
- class
- logits
- learning
- methods
- classifier
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper revisits classifier re-training in long-tailed recognition
  and proposes a novel approach called Logits Retargeting (LORT). The key contributions
  are: (1) introducing two new metrics - Logits Magnitude and Regularized Standard
  Deviation - to better measure and compare model performance; (2) proposing LORT,
  a simple method that divides the original one-hot label into small true label probabilities
  and large negative label probabilities to effectively reduce Logits Magnitude and
  improve model performance.'
---

# Rethinking Classifier Re-Training in Long-Tailed Recognition: A Simple Logits Retargeting Approach

## Quick Facts
- arXiv ID: 2403.00250
- Source URL: https://arxiv.org/abs/2403.00250
- Reference count: 40
- Achieves state-of-the-art performance on CIFAR100-LT, ImageNet-LT, and iNaturalist2018 datasets

## Executive Summary
This paper introduces Logits Retargeting (LORT), a novel approach to classifier re-training in long-tailed recognition that addresses the limitations of existing methods focused on weight magnitude reduction. The authors propose two new metrics - Logits Magnitude and Regularized Standard Deviation - to better measure model performance and demonstrate that reducing Logits Magnitude during training leads to improved accuracy. LORT achieves state-of-the-art results by dividing original one-hot labels into small true label probabilities and large negative label probabilities, effectively reducing Logits Magnitude while maintaining discriminative power.

## Method Summary
The method employs a two-stage decoupled training approach. First, a feature extractor is trained using standard cross-entropy loss with proper regularization. Then, the classifier is retrained using LORT, which modifies the label distribution by assigning small probabilities to the true class (e.g., 0.02) and distributing the remaining probability mass across all classes (e.g., 0.98/K for each of K classes). This creates large negative label probabilities that effectively reduce Logits Magnitude during training. The approach is simple to implement and can serve as a plug-and-play retraining method that enhances other long-tailed recognition techniques.

## Key Results
- Achieves 1-1.5% improvement over state-of-the-art on CIFAR100-LT dataset
- Shows 0.5-0.6% improvement on ImageNet-LT and iNaturalist2018 datasets
- Demonstrates robustness to hyperparameter variations across different settings
- Reduces Logits Magnitude more effectively than traditional weight normalization methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Logits Magnitude is a superior metric because it directly measures the difference between positive and negative sample logits for each class, making it more invariant to weight scaling than Weight Norm.
- Mechanism: Logits Magnitude captures the relative confidence of positive vs. negative samples for each class, while Weight Norm only measures absolute vector magnitude. When the model converges, the Logits Magnitude remains stable even if weights are scaled.
- Core assumption: The optimal classification decision boundary depends on the relative logits of positive vs. negative samples, not the absolute weight magnitudes.
- Evidence anchors:
  - [abstract]: "We propose a new metric called Logits Magnitude as a superior measure of model performance, replacing the commonly used Weight Norm."
  - [section]: "The Logits Magnitude demonstrates not only reduced susceptibility to bias ε during convergence but also a strong correlation with the final classification accuracy, unlike direct computation of magnitudes using vector length."
  - [corpus]: Weak evidence - no related papers directly discuss Logits Magnitude metric specifically.
- Break condition: If the feature extractor produces features with very different distributions across classes, Logits Magnitude might not capture the true discriminative power.

### Mechanism 2
- Claim: Reducing Logits Magnitude when it's nearly balanced decreases errors and disturbances during training.
- Mechanism: When Logits Magnitude is large, random perturbations (from sampling bias, overfitting, etc.) have a bigger impact on the classification decision. By reducing the magnitude, these perturbations become proportionally smaller.
- Core assumption: Training perturbations scale proportionally with the Logits Magnitude, so reducing the magnitude reduces their relative impact.
- Evidence anchors:
  - [abstract]: "we prove that reducing the absolute value of Logits Magnitude when it is nearly balanced can effectively decrease errors and disturbances during training, leading to better model performance."
  - [section]: "These perturbations ∆ are commonly introduced during the training process, particularly due to factors such as overfitting in the initial stage of training and bias in the sampling of the training set."
  - [corpus]: Weak evidence - no related papers explicitly discuss perturbation reduction through Logits Magnitude control.
- Break condition: If the perturbations are not proportional to Logits Magnitude (e.g., if they come from a different source like adversarial examples), this mechanism breaks down.

### Mechanism 3
- Claim: Large negative label probabilities in LORT effectively reduce Logits Magnitude while maintaining discriminative power.
- Mechanism: By assigning small probabilities to the true class and large probabilities to all other classes, LORT forces the model to make confident predictions for the true class while being uncertain about others. This reduces the gap between positive and negative logits.
- Core assumption: The model can learn to make confident predictions for the true class even with small positive probabilities if the negative probabilities are even smaller.
- Evidence anchors:
  - [abstract]: "LORT divides the original one-hot label into small true label probabilities and large negative label probabilities distributed across each class."
  - [section]: "we demonstrate, both theoretically and experimentally, that a larger negative label probability can lead to better results."
  - [corpus]: Weak evidence - no related papers discuss this specific logits retargeting approach.
- Break condition: If the negative probabilities become too large, the model may fail to converge or lose discriminative power.

## Foundational Learning

- Concept: Long-tailed distribution
  - Why needed here: The paper addresses long-tailed recognition, where class distributions are highly imbalanced with few samples for many classes.
  - Quick check question: What is the imbalanced ratio (IR) and how is it calculated?

- Concept: Decoupled training
  - Why needed here: The paper uses a two-stage training process: first learning general feature representations, then retraining the classifier.
  - Quick check question: Why might decoupled training be more effective than joint training for long-tailed recognition?

- Concept: Label smoothing
  - Why needed here: LORT is fundamentally similar to label smoothing but uses much larger negative probabilities.
  - Quick check question: How does label smoothing typically work, and what's the key difference in LORT's approach?

## Architecture Onboarding

- Component map: Feature extractor -> Classifier head (weights W, biases b) -> Loss function (LORT-modified) -> SGD optimizer

- Critical path:
  1. Train feature extractor with standard cross-entropy loss
  2. Freeze feature extractor weights
  3. Retrain classifier using LORT-modified labels
  4. Evaluate on balanced test set

- Design tradeoffs:
  - LORT vs. traditional methods: LORT directly targets Logits Magnitude reduction, while traditional methods focus on weight regularization or re-sampling
  - Label smoothing value: Larger values reduce Logits Magnitude more but may hurt convergence if too large
  - Feature extractor quality: LORT works best with strong, balanced feature representations

- Failure signatures:
  - Overfitting to majority classes: Check if minority class accuracy is significantly lower
  - Poor convergence: Monitor training loss; if it plateaus early, the label smoothing value might be too large
  - Sensitivity to hyperparameters: Test different learning rates and weight decays to ensure stability

- First 3 experiments:
  1. Baseline comparison: Run CIFAR100-LT with IR=100 using standard cross-entropy vs. LORT with δ=0.98
  2. Ablation study: Test different label smoothing values (0.2, 0.5, 0.8, 0.98, 0.99) to find optimal performance
  3. Sensitivity analysis: Test different learning rates and weight decays to verify LORT's robustness to hyperparameter changes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed Logits Retargeting (LORT) method perform on datasets with different types of class imbalance distributions, such as those with multiple modes or heavy-tailed distributions?
- Basis in paper: [inferred] The paper primarily evaluates LORT on long-tailed datasets with exponential decay, but does not explore other imbalance distributions.
- Why unresolved: The effectiveness of LORT on various imbalance distributions remains unexplored, limiting its generalizability.
- What evidence would resolve it: Conducting experiments on datasets with different imbalance distributions, such as those with multiple modes or heavy-tailed distributions, would provide insights into LORT's performance and robustness across diverse scenarios.

### Open Question 2
- Question: Can the Logits Retargeting (LORT) method be extended to other domains beyond image classification, such as natural language processing or speech recognition?
- Basis in paper: [explicit] The paper focuses on long-tailed image classification and does not explore the applicability of LORT to other domains.
- Why unresolved: The effectiveness of LORT in other domains remains unknown, limiting its potential impact.
- What evidence would resolve it: Applying LORT to other domains, such as natural language processing or speech recognition, and evaluating its performance would demonstrate its versatility and potential for broader applications.

### Open Question 3
- Question: How does the Logits Retargeting (LORT) method compare to other state-of-the-art methods for long-tailed recognition when applied to datasets with different feature representations, such as those learned using self-supervised learning or transfer learning?
- Basis in paper: [inferred] The paper evaluates LORT on feature representations learned using standard supervised learning, but does not explore its performance with other feature learning methods.
- Why unresolved: The effectiveness of LORT with different feature representations remains unexplored, limiting its potential improvements.
- What evidence would resolve it: Conducting experiments on datasets with feature representations learned using self-supervised learning or transfer learning, and comparing LORT's performance to other state-of-the-art methods, would provide insights into its strengths and weaknesses in different feature learning scenarios.

## Limitations
- The theoretical analysis relies on simplifying assumptions that may not hold in practice
- The perturbation reduction mechanism lacks rigorous formal proof
- Limited evaluation on datasets with different imbalance distributions
- No exploration of LORT's applicability to other domains beyond image classification

## Confidence
- Theoretical grounding: Low - relies on intuitive explanations with weak formal proofs
- Experimental results: Medium - compelling improvements across multiple datasets but limited diversity
- Method generalizability: Medium - simple implementation suggests broad applicability but untested on other domains
- Hyperparameter robustness: Medium - claims of robustness need more extensive validation

## Next Checks
1. Conduct a controlled experiment varying Logits Magnitude independently (e.g., through weight scaling) while keeping other factors constant to isolate its effect
2. Test LORT on additional long-tailed benchmarks beyond the three datasets used to verify generalizability
3. Perform an ablation study comparing LORT with different label smoothing values while controlling for the total probability mass assigned to non-target classes