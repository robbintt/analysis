---
ver: rpa2
title: Carbon Intensity-Aware Adaptive Inference of DNNs
arxiv_id: '2403.15824'
source_url: https://arxiv.org/abs/2403.15824
tags:
- carbon
- inference
- energy
- footprint
- intensity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the high carbon footprint of DNN inference
  by proposing a heuristic approach that dynamically selects models based on real-time
  carbon intensity. By choosing larger, more accurate models during low-carbon-intensity
  periods and smaller, less accurate ones during high-carbon-intensity periods, the
  method aims to balance accuracy and carbon efficiency.
---

# Carbon Intensity-Aware Adaptive Inference of DNNs

## Quick Facts
- arXiv ID: 2403.15824
- Source URL: https://arxiv.org/abs/2403.15824
- Reference count: 10
- Primary result: Heuristic approach achieves 80% improvement in carbon emission efficiency compared to fixed-model strategies

## Executive Summary
This paper addresses the high carbon footprint of DNN inference by proposing a heuristic approach that dynamically selects models based on real-time carbon intensity. The method chooses larger, more accurate models during low-carbon-intensity periods and smaller, less accurate ones during high-carbon-intensity periods, aiming to balance accuracy and carbon efficiency. The study evaluates the approach using vision recognition models and Twitter request traces, showing significant improvements in carbon emission efficiency while maintaining high accuracy.

## Method Summary
The proposed method uses a heuristic algorithm that maps current carbon intensity to an optimal energy consumption level, then selects the model whose per-inference energy consumption most closely matches this target. The approach relies on historical carbon intensity data showing diurnal patterns and uses a linear interpolation formula to determine the appropriate model for each time period. The evaluation uses vision recognition models (ResNet variants, VGG, AlexNet) and measures energy consumption per inference on Google Cloud NVIDIA V100 GPU VM with Triton Inference server.

## Key Results
- Carbon emission efficiency improved by 80% compared to fixed-model strategies
- Achieved 6.57% error rate with 1532g CO₂ emissions, outperforming ResNet101 in both accuracy and carbon efficiency
- The heuristic method successfully balances accuracy and carbon footprint by adapting model selection to carbon intensity patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic model selection based on carbon intensity reduces overall carbon footprint while maintaining accuracy
- Mechanism: The heuristic algorithm maps current carbon intensity to an optimal energy consumption level, then selects the model whose per-inference energy consumption most closely matches this target. During low carbon intensity periods, larger more accurate models are chosen; during high intensity periods, smaller less accurate models are used.
- Core assumption: The relationship between carbon intensity and model energy consumption is linear and can be interpolated using the provided equation
- Evidence anchors:
  - [abstract] "Our heuristic algorithm uses larger, high-accuracy models during low-intensity periods and smaller, lower-accuracy ones during high-intensity periods"
  - [section 3] "Through this formula, E_Selected, the energy consumption per inference of the model suitable for the carbon intensity of the corresponding time period, can be obtained"
  - [corpus] Weak evidence - related papers focus on different optimization strategies but don't validate this specific interpolation approach
- Break condition: The linear interpolation assumption breaks if carbon intensity doesn't scale proportionally with model energy consumption, or if the relationship varies significantly by model architecture

### Mechanism 2
- Claim: The carbon emission efficiency metric provides meaningful comparison between different inference strategies
- Mechanism: By dividing the accuracy improvement by the additional carbon emissions, the metric quantifies the environmental cost of accuracy gains, enabling fair comparison between fixed-model and adaptive approaches
- Core assumption: The metric meaningfully captures the tradeoff between accuracy and carbon footprint in a single dimension
- Evidence anchors:
  - [section 4] "It is defined as the difference in application quality between two configurations, divided by the change in carbon production"
  - [abstract] "We also introduce a metric, carbon-emission efficiency, which quantitatively measures the efficacy of adaptive model selection in terms of carbon footprint"
  - [corpus] Weak evidence - no related papers discuss this specific metric or validate its usefulness for comparing inference strategies
- Break condition: The metric becomes less meaningful if accuracy improvements don't scale linearly with carbon emissions, or if other factors (latency, cost) become dominant considerations

### Mechanism 3
- Claim: Historical carbon intensity patterns can be used to predict optimal model selection timing
- Mechanism: By analyzing historical carbon intensity data (showing diurnal patterns), the system can anticipate when to use different models to maximize carbon efficiency
- Core assumption: Historical carbon intensity patterns are sufficiently predictable to inform model selection decisions
- Evidence anchors:
  - [section 2] "Carbon intensity... exhibits a discernible diurnal pattern... This cycle arises from fluctuations in renewable energy production"
  - [section 4] "we used the historical records of 30-min. interval carbon intensity changes, which was collected during 2023 June in South West England"
  - [corpus] Weak evidence - while carbon intensity patterns are mentioned, no papers validate using these patterns for predictive model selection
- Break condition: The mechanism fails if carbon intensity patterns become unpredictable due to changes in energy grid composition or if short-term fluctuations dominate the diurnal pattern

## Foundational Learning

- Concept: Carbon intensity variation and its relationship to energy grid composition
  - Why needed here: Understanding how carbon intensity varies throughout the day is fundamental to the adaptive approach
  - Quick check question: What causes carbon intensity to vary diurnally, and how does this affect the choice of DNN model for inference?

- Concept: Energy consumption measurement and modeling for DNN inference
  - Why needed here: Accurate energy consumption data for different models is essential for the interpolation formula
  - Quick check question: How was energy consumption per inference measured for the different vision recognition models, and what factors might affect these measurements?

- Concept: Tradeoffs between model accuracy and computational efficiency
  - Why needed here: The core insight is that different models offer different accuracy-energy tradeoffs that can be exploited based on carbon intensity
  - Quick check question: How do the accuracy and energy consumption measurements in Table 1 illustrate the fundamental tradeoff between accuracy and computational cost?

## Architecture Onboarding

- Component map: Carbon intensity data source → Heuristic algorithm → Model selection → Inference execution → Carbon emission measurement
- Critical path: Carbon intensity data → Heuristic algorithm → Model selection → Inference execution → Carbon emission measurement
- Design tradeoffs:
  - Model pool size vs. complexity of selection algorithm
  - Real-time vs. predictive carbon intensity adaptation
  - Accuracy requirements vs. carbon efficiency goals
  - CPU-only vs. GPU-accelerated inference servers
- Failure signatures:
  - High variance in accuracy when using adaptive approach vs. fixed model
  - Failure to find appropriate model for certain carbon intensity levels
  - Increased latency due to model switching overhead
  - Inaccurate energy consumption measurements affecting selection
- First 3 experiments:
  1. Implement the interpolation formula with a small model pool (2-3 models) and validate that model selection changes appropriately with different carbon intensity inputs
  2. Measure actual carbon emissions when running the adaptive approach vs. fixed-model approaches under simulated carbon intensity patterns
  3. Test the robustness of the approach with synthetic carbon intensity data that includes unexpected fluctuations to identify break conditions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed heuristic approach perform in domains other than vision recognition, such as natural language processing or recommendation systems?
- Basis in paper: [explicit] The paper mentions plans to apply the approach to inference services across different domains in future work.
- Why unresolved: The current evaluation only demonstrates effectiveness for vision recognition models.
- What evidence would resolve it: Applying the heuristic approach to various DNN inference services in different domains and comparing carbon emission efficiency and accuracy against fixed-model strategies.

### Open Question 2
- Question: What is the optimal model selection strategy that maximizes carbon emission efficiency using non-linear optimization techniques like reinforcement learning?
- Basis in paper: [explicit] The paper plans to apply non-linear optimization techniques such as reinforcement learning to maximize carbon emission efficiency.
- Why unresolved: The current heuristic approach is a simplified method and may not achieve optimal results.
- What evidence would resolve it: Implementing and evaluating reinforcement learning-based model selection strategies, comparing their performance against the heuristic approach in terms of carbon emission efficiency and accuracy.

### Open Question 3
- Question: How does the carbon emission efficiency metric correlate with other sustainability metrics, such as carbon footprint per dollar spent or carbon footprint per unit of accuracy improvement?
- Basis in paper: [inferred] The paper introduces carbon emission efficiency as a metric but does not explore its relationship with other sustainability metrics.
- Why unresolved: The paper focuses on carbon emission efficiency but does not compare it to other potential sustainability metrics.
- What evidence would resolve it: Conducting a comparative analysis of carbon emission efficiency against other sustainability metrics, evaluating their correlations and trade-offs in various DNN inference scenarios.

## Limitations
- The approach relies on predictable carbon intensity patterns that may not hold during grid instability or extreme weather events
- The linear interpolation formula may not accurately capture the relationship between carbon intensity and model energy consumption across diverse architectures
- Evaluation is limited to vision recognition models, raising questions about generalizability to other domains

## Confidence

**High Confidence**: The core claim that dynamic model selection based on carbon intensity can reduce overall carbon footprint is well-supported by the experimental results showing 80% improvement in carbon emission efficiency compared to fixed-model strategies.

**Medium Confidence**: The carbon emission efficiency metric provides a meaningful way to quantify tradeoffs between accuracy and carbon footprint, though its general applicability across different application domains remains unproven.

**Low Confidence**: The assumption that historical carbon intensity patterns can reliably predict optimal model selection timing lacks validation against real-world variability and extreme scenarios.

## Next Checks

1. Test the approach under synthetic carbon intensity data with significant random fluctuations to evaluate robustness against prediction failures and identify break conditions in the linear interpolation formula.

2. Extend the evaluation to different model architectures (beyond vision recognition) and application domains to assess generalizability of the carbon emission efficiency metric and selection heuristic.

3. Conduct a sensitivity analysis on the carbon intensity prediction horizon - evaluate how prediction windows of 15 minutes, 30 minutes, and 60 minutes affect model selection accuracy and overall carbon efficiency.