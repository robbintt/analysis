---
ver: rpa2
title: Automated Deep Learning for Load Forecasting
arxiv_id: '2405.08842'
source_url: https://arxiv.org/abs/2405.08842
tags:
- load
- forecasting
- ssea
- used
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EnergyDragon is an AutoDL framework that automatically selects
  features, optimizes DNN architectures, and tunes hyperparameters for load forecasting.
  It extends the DRAGON package with innovations including an embedded feature selection
  method and a faster search algorithm.
---

# Automated Deep Learning for Load Forecasting

## Quick Facts
- arXiv ID: 2405.08842
- Source URL: https://arxiv.org/abs/2405.08842
- Authors: Julie Keisler; Sandra Claudel; Gilles Cabriel; Margaux BrÃ©gÃ¨re
- Reference count: 40
- EnergyDragon framework achieves 19% MAPE improvement over GAM and AutoPyTorch baselines on French load data

## Executive Summary
EnergyDragon is an AutoDL framework that automatically selects features, optimizes DNN architectures, and tunes hyperparameters for load forecasting. It extends the DRAGON package with innovations including an embedded feature selection method and a faster search algorithm. Applied to the French load signal, EnergyDragon found DNNs that outperformed state-of-the-art methods (including GAMs and AutoPyTorch) by 19% in MAPE. The framework also demonstrated strong performance on Norwegian load data, improving GAM forecasts by 17%. Key innovations include using L1 regularization for feature selection and incorporating self-attention layers, which proved effective for load forecasting tasks.

## Method Summary
EnergyDragon uses a directed acyclic graph (DAG) representation for DNN architectures, combining 1D/2D convolutions, attention layers, and MLPs. The framework employs an asynchronous evolutionary algorithm to search for optimal architectures while jointly optimizing feature selection through L1 regularization. Feature selection is implemented by relaxing binary indicators to real-valued weights optimized during training. The search algorithm maintains a population of DNNs, using tournament selection, crossover, and mutation operators, with asynchronous replacement to save computation time. Models are trained with cyclic learning rates and evaluated using MAPE and RMSE metrics.

## Key Results
- EnergyDragon outperformed GAM baseline by 19% MAPE on French load data
- Achieved 17% improvement over GAM on Norwegian load data
- Outperformed AutoPyTorch and DARTS on both datasets
- Self-attention layers proved particularly effective for load forecasting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EnergyDragon outperforms traditional load forecasting models by automatically selecting optimal input features using embedded L1 regularization during training.
- Mechanism: The framework introduces a continuous feature selection process where binary feature indicators are relaxed to real-valued weights, optimized jointly with DNN parameters using an L1 penalty to encourage sparsity.
- Core assumption: The relaxed feature weights can be effectively optimized using gradient descent while maintaining model performance.
- Evidence anchors:
  - [abstract]: "EnergyDragon automatically selects the features embedded in the DNN training in an innovative way"
  - [section 3.2]: "We introduce âˆ€ð‘— âˆˆ âŸ¦1, ð¹âŸ§ : ð‘ ð‘— âˆˆ { 0, 1} such that xð‘— âˆˆ Ë†ð‘‹ â‡” ð‘ ð‘— = 1 . To use gradient descent to find the optimal features, our indicators ð‘ = (ð‘1, . . . , ð‘ð¹ ) are relaxed: ð‘¤ = {sigmoid(ð‘¤ ð‘— )} ð¹ ð‘—=1 âˆˆ [ 0, 1]ð¹ with ð‘¤ ð‘— âˆˆ R and ð‘ ð‘— = 1ð‘¤ ð‘— >0"
  - [corpus]: Weak evidence - corpus focuses on automated forecasting but does not detail embedded feature selection mechanisms.
- Break condition: If the relaxed weights fail to converge to meaningful feature importance scores, or if the L1 penalty overprunes useful features.

### Mechanism 2
- Claim: The DAG-based search space enables flexible DNN architectures tailored to load forecasting tasks.
- Mechanism: EnergyDragon uses a directed acyclic graph representation where nodes are layers and edges are connections, allowing arbitrary combinations of 1D/2D convolutions, attention layers, and other operations.
- Core assumption: The DAG structure can represent architectures that capture both temporal and spatial relationships in load data.
- Evidence anchors:
  - [abstract]: "optimizes the architecture and the hyperparameters of the networks"
  - [section 3.1]: "Each architecture ð›¼ âˆˆ A is represented by a DAG Î“, where the nodes are the DNN layers and the edges are the connections between them"
  - [corpus]: Moderate evidence - related work mentions spatio-temporal modeling but doesn't detail DAG-based architecture search.
- Break condition: If the search space is too large to explore effectively, or if certain critical layer combinations are missing from the candidate set.

### Mechanism 3
- Claim: Steady-state evolutionary algorithm with crossover operators efficiently navigates the search space for high-performing DNNs.
- Mechanism: The framework maintains a population of DNNs, using tournament selection, crossover, and mutation to generate offspring, replacing worse individuals asynchronously to save computation time.
- Core assumption: The evolutionary operators can effectively explore and exploit the search space without getting stuck in local optima.
- Evidence anchors:
  - [abstract]: "incorporates an original feature selection efficient for load forecasting and a faster search algorithm"
  - [section 3.4]: "we have implemented an asynchronous (or steady-state) evolutionary algorithm (SSEA) as our search algorithm"
  - [section 4.3]: "Among the ED results, the random search got the worst results, which demonstrates the performance of our search algorithm"
  - [corpus]: Weak evidence - corpus doesn't discuss evolutionary algorithms for load forecasting.
- Break condition: If the population converges prematurely or if the crossover operator disrupts good building blocks.

## Foundational Learning

- Concept: Directed Acyclic Graphs (DAGs) for neural architecture representation
  - Why needed here: Enables flexible combination of different layer types and connections, critical for modeling complex load forecasting patterns
  - Quick check question: How would you represent a skip connection in a DAG architecture?

- Concept: Feature selection through regularization (L1/LASSO)
  - Why needed here: Reduces model complexity and improves generalization by identifying truly relevant input variables
  - Quick check question: What happens to feature weights when L1 regularization is applied during training?

- Concept: Evolutionary algorithms for hyperparameter optimization
  - Why needed here: Efficiently explores large search spaces without requiring gradient information for discrete choices
  - Quick check question: How does tournament selection help maintain diversity in the population?

## Architecture Onboarding

- Component map: Input processing DAG (Î“1) -> Flatten layer -> Output processing DAG (Î“2) -> Feature selection module -> Evolutionary search controller

- Critical path:
  1. Initialize population with simple architectures
  2. Train each DNN with joint feature/weight optimization for E_w epochs
  3. Apply hard feature selection and continue weight optimization
  4. Evaluate on validation set and select best performers
  5. Generate offspring through crossover/mutation
  6. Replace worst individuals if offspring performs better

- Design tradeoffs:
  - Search space flexibility vs. computational cost
  - Feature selection granularity vs. optimization stability
  - Population size vs. convergence speed
  - Number of training epochs vs. overfitting risk

- Failure signatures:
  - All models converge to similar architectures (lack of diversity)
  - Feature selection fails to identify meaningful variables (weights remain uniformly distributed)
  - Population size too small â†’ premature convergence
  - Training instability â†’ NaN losses or exploding gradients

- First 3 experiments:
  1. Verify DAG encoding/decoding works by reconstructing a known architecture
  2. Test feature selection module on synthetic data with known important features
  3. Run SSEA with tiny population on simplified search space to validate evolutionary operators

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the EnergyDragon framework perform on datasets with different characteristics, such as different countries or time periods?
- Basis in paper: [inferred] The paper presents results for the French and Norwegian load datasets, but does not explore other datasets or time periods.
- Why unresolved: The paper focuses on demonstrating the effectiveness of EnergyDragon on two specific datasets, but does not investigate its performance on other datasets or time periods.
- What evidence would resolve it: Conducting experiments on additional datasets from different countries or time periods would provide evidence of EnergyDragon's generalizability.

### Open Question 2
- Question: How does the EnergyDragon framework compare to other AutoDL approaches in terms of computational efficiency?
- Basis in paper: [explicit] The paper mentions that training a DNN is expensive in terms of time and computational resources, but does not provide a direct comparison of EnergyDragon's efficiency with other AutoDL approaches.
- Why unresolved: The paper focuses on demonstrating the effectiveness of EnergyDragon, but does not provide a comprehensive comparison of its computational efficiency with other AutoDL approaches.
- What evidence would resolve it: Conducting experiments to compare the computational efficiency of EnergyDragon with other AutoDL approaches would provide evidence of its relative efficiency.

### Open Question 3
- Question: How does the EnergyDragon framework handle missing or incomplete data in the input features?
- Basis in paper: [inferred] The paper does not explicitly address the issue of missing or incomplete data in the input features, but it is a common challenge in real-world applications.
- Why unresolved: The paper focuses on demonstrating the effectiveness of EnergyDragon under ideal conditions, but does not explore its robustness to missing or incomplete data.
- What evidence would resolve it: Conducting experiments to evaluate EnergyDragon's performance on datasets with missing or incomplete data would provide evidence of its robustness to such scenarios.

## Limitations
- Cannot reproduce exact GAM baseline due to confidentiality restrictions
- Baseline hyperparameters and search spaces for AutoPyTorch and DARTS are unspecified
- Generalizability to datasets beyond French and Norwegian load data is not demonstrated
- No analysis of performance under different forecasting horizons or missing data conditions

## Confidence

**High confidence**: The core mechanism of using L1 regularization for embedded feature selection is well-established in machine learning literature and the implementation details are clearly specified. The general approach of combining DAG-based architecture representation with evolutionary search follows proven AutoDL methodologies.

**Medium confidence**: The specific improvements claimed over industry baselines (GAM, AutoPyTorch) are less certain due to the confidentiality constraints around the GAM implementation and unspecified baseline hyperparameters. The 19% MAPE improvement is impressive but difficult to independently verify.

**Low confidence**: The generalizability of EnergyDragon beyond the French and Norwegian load datasets is not demonstrated. The study does not address potential overfitting to the specific temporal patterns in these datasets or performance degradation under different forecasting horizons.

## Next Checks

1. **Reimplement the feature selection mechanism**: Test the L1-regularized feature selection on synthetic load forecasting datasets with known feature importance to verify that the relaxed binary indicators effectively identify relevant variables during training.

2. **Compare against fully specified baselines**: Implement a transparent GAM-like model and standard AutoML baselines (AutoPyTorch, DARTS) with documented hyperparameters to independently verify the claimed performance improvements.

3. **Test on out-of-distribution data**: Evaluate EnergyDragon on load forecasting datasets from different geographical regions, time periods, or with different input feature sets to assess robustness and generalizability beyond the French and Norwegian datasets used in the study.