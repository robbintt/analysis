---
ver: rpa2
title: Revisiting Agnostic PAC Learning
arxiv_id: '2407.19777'
source_url: https://arxiv.org/abs/2407.19777
tags:
- erdi
- have
- hypothesis
- algorithm
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper revisits agnostic PAC learning, showing that the standard
  Empirical Risk Minimization (ERM) algorithm is suboptimal by a $\sqrt{\ln(1/\tau)}$
  factor when $\tau = \text{er}D(hD^)$ is treated as a parameter. The authors prove
  that any proper learning algorithm must incur this factor, then present a new improper
  algorithm, DisagreeingExperts, that achieves an optimal error bound for nearly the
  full range of $\tau$.
---

# Revisiting Agnostic PAC Learning

## Quick Facts
- arXiv ID: 2407.19777
- Source URL: https://arxiv.org/abs/2407.19777
- Authors: Steve Hanneke; Kasper Green Larsen; Nikita Zhivotovskiy
- Reference count: 40
- Standard ERM is suboptimal by a √ln(1/τ) factor in agnostic PAC learning

## Executive Summary
This paper demonstrates that standard Empirical Risk Minimization (ERM) algorithms are suboptimal in agnostic PAC learning by a factor of √ln(1/τ) when the best hypothesis error τ is treated as a parameter. The authors prove that any proper learning algorithm must incur this penalty, then introduce a new improper algorithm called DisagreeingExperts that achieves optimal error bounds for nearly the full range of τ values. The key innovation is recursively training pairs of nearly optimal classifiers that disagree on many predictions, then combining their outputs based on conditional distributions.

## Method Summary
The DisagreeingExperts algorithm works by recursively partitioning the hypothesis space into "agreeing" and "disagreeing" regions, reducing the effective error in the agreeing region through repeated conditional learning. The algorithm maintains a set of expert pairs and iteratively refines them by finding new pairs that disagree on many predictions. When experts agree, the algorithm leverages this similarity to obtain tighter concentration bounds. The method requires knowledge of the failure probability δ and uses a validation set to ensure proper error control throughout the recursive process.

## Key Results
- ERM and any proper learning algorithm are suboptimal by √ln(1/τ) factor
- DisagreeingExperts achieves optimal error bound for nearly full range of τ
- Sample complexity improves from τ + O(√τ ln(1/τ)/n) to τ + O(√τ(d+ln(1/δ))/n) for most τ values

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The DisagreeingExperts algorithm achieves optimal agnostic PAC learning by recursively training pairs of nearly optimal classifiers that disagree on many predictions, thus overcoming the √ln(1/τ) penalty.
- Mechanism: The algorithm recursively partitions the hypothesis space into "agreeing" and "disagreeing" regions, reducing the effective error in the agreeing region through repeated conditional learning. By carefully managing the balance between the two regions, it maintains optimal error rates.
- Core assumption: The hypothesis set H has finite VC-dimension d, and the best hypothesis h*_D has error τ that is neither too small nor too large.
- Evidence anchors:
  - [abstract]: "Our algorithm introduces several new ideas that we hope may find further applications in learning theory."
  - [section]: "Our improved algorithm relies on several new insights regarding Empirical Risk Minimization."
  - [corpus]: Weak evidence - related works focus on different aspects of PAC learning but don't directly address the √ln(1/τ) penalty.
- Break condition: If τ is extremely small (less than d/n), the algorithm reverts to standard ERM behavior, losing the √ln(1/τ) improvement.

### Mechanism 2
- Claim: Proper learning algorithms cannot achieve the optimal error bound due to a fundamental limitation in how they must select hypotheses from the original hypothesis set.
- Mechanism: Any proper algorithm must choose hypotheses from H, which constrains its ability to exploit conditional distributions where the optimal error is smaller than τ.
- Core assumption: The hypothesis set H contains only a restricted set of classifiers, and the proper algorithm must return a hypothesis from this set.
- Evidence anchors:
  - [abstract]: "Concretely we show that ERM, and any other proper learning algorithm, is sub-optimal by a √ln(1/τ) factor."
  - [section]: "Our lower bound proof is quite simple... there is a hypothesis h∈H with erD(h) = τ."
  - [corpus]: Weak evidence - related works don't specifically address proper learning limitations in the agnostic setting.
- Break condition: If the hypothesis set H is sufficiently rich (approaching the set of all possible classifiers), proper learning might approach optimal error.

### Mechanism 3
- Claim: The algorithm's performance improves when near-optimal hypotheses are sufficiently similar, allowing stronger concentration bounds than standard ERM.
- Mechanism: When all near-optimal hypotheses agree on most predictions, the algorithm can leverage this similarity to obtain tighter error bounds, effectively reducing the √ln(1/τ) factor.
- Core assumption: There exists a subset of hypotheses that are all close to optimal and have high agreement probability.
- Evidence anchors:
  - [section]: "If the hypotheses in H are sufficiently similar, then this union bound improves for H."
  - [section]: "Since |erD(h′)− erD(h)| = O(PrD[h(x)≠ h′(x)]) = O(τ/ln(1/τ)), we get stronger concentration."
  - [corpus]: Weak evidence - related works don't explicitly address hypothesis similarity in the context of error bounds.
- Break condition: If near-optimal hypotheses are highly diverse (disagree on many predictions), this mechanism provides little benefit.

## Foundational Learning

- Concept: VC-dimension
  - Why needed here: The VC-dimension d of the hypothesis set H determines the sample complexity and error bounds throughout the analysis.
  - Quick check question: What is the VC-dimension of a hypothesis set containing all linear classifiers in d-dimensional space?

- Concept: Empirical Risk Minimization (ERM)
  - Why needed here: ERM serves as both the baseline algorithm being improved upon and as a subroutine within the new algorithm.
  - Quick check question: How does the error of ERM on a finite sample relate to the true error of the hypothesis it selects?

- Concept: Agnostic PAC learning
  - Why needed here: The paper addresses the agnostic setting where the best hypothesis may have non-zero error, distinguishing it from realizable learning.
  - Quick check question: What is the key difference between the realizable and agnostic PAC learning settings?

## Architecture Onboarding

- Component map:
  - Main algorithm: DisagreeingExperts
  - Subroutine: CoreDisagreeingExperts
  - Validation: ERM on separate validation set
  - Partitioning: Splits data into multiple sets for different purposes
  - Recursion: Iterative refinement through conditional learning

- Critical path:
  1. Partition training data into sets B and C
  2. Recursively find disagreeing expert pairs using B
  3. Partition C based on expert disagreements
  4. Run ERM on each partition of C
  5. Combine results using a conditional classifier

- Design tradeoffs:
  - Proper vs. improper learning: The algorithm sacrifices efficiency for optimality
  - Recursion depth vs. sample allocation: Deeper recursion requires more samples per iteration
  - Hypothesis similarity vs. diversity: Balancing agreement for concentration vs. disagreement for progress

- Failure signatures:
  - Algorithm reverts to ERM behavior for very small τ
  - Performance degrades when near-optimal hypotheses are highly diverse
  - Sample complexity increases significantly for extreme values of τ

- First 3 experiments:
  1. Implement the algorithm on a simple hypothesis set (e.g., intervals on the line) with known optimal error
  2. Compare performance against standard ERM across a range of τ values
  3. Test the algorithm's sensitivity to the partitioning of data between sets B and C

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can we design an optimal agnostic PAC learner that automatically adapts to the failure probability δ without requiring explicit knowledge of it?
- Basis in paper: [explicit] The paper mentions this as an open question in the conclusion, noting that their algorithm requires knowledge of the failure probability δ while ERM automatically works for all values of δ simultaneously.
- Why unresolved: The current algorithm requires δ as an input parameter, while ERM has the desirable property of being universally applicable across all failure probabilities.
- What evidence would resolve it: A new algorithm that achieves optimal sample complexity without requiring δ as an input parameter, or a lower bound proving that such adaptation is impossible.

### Open Question 2
- Question: Is there a higher lower bound for proper learning algorithms when τ ≈ d/n?
- Basis in paper: [explicit] The paper mentions this as an open question in the conclusion, suggesting it "could be the case that there is a higher lower bound for all learning algorithms when τ≈ d/n."
- Why unresolved: The current lower bound for proper learners may not be tight for the regime where τ is close to d/n.
- What evidence would resolve it: Either a matching upper bound algorithm for this regime, or a strengthened lower bound proof showing that the current bound is indeed loose when τ ≈ d/n.

### Open Question 3
- Question: Can we design an efficient algorithm (in terms of running time) with sample complexity similar to the proposed DisagreeingExperts algorithm?
- Basis in paper: [explicit] The paper mentions this as an open question, noting that even if ERM over H is efficient, it's unclear how to determine if there are two hypotheses that are both near-optimal and yet disagree on many samples.
- Why unresolved: The current algorithm's core operation of finding disagreeing experts appears computationally challenging, as it requires checking all pairs of hypotheses for disagreement.
- What evidence would resolve it: An efficient implementation of the core operations (finding disagreeing experts) with provable guarantees, or a computational complexity lower bound showing that the problem is inherently hard.

## Limitations

- Algorithm's optimal performance critically depends on having sufficient data relative to d
- Theoretical analysis assumes access to an independent validation set, which may not be practical
- Algorithm's complexity increases with number of recursive steps, potentially limiting applicability to large hypothesis spaces

## Confidence

- High Confidence: The fundamental limitation of proper learning algorithms (Mechanism 2) is well-established through the simple lower bound proof
- Medium Confidence: The core mechanism of recursively finding disagreeing expert pairs (Mechanism 1) is theoretically sound but may face practical challenges in implementation
- Low Confidence: The performance improvement claims for highly similar hypotheses (Mechanism 3) rely on specific conditions that may not hold in practice

## Next Checks

1. Implement the algorithm on a simple hypothesis set (e.g., intervals on the line) with known optimal error to verify the claimed √ln(1/τ) improvement over ERM

2. Test the algorithm's sensitivity to the partitioning ratio between sets B and C, measuring how performance varies with different allocations

3. Evaluate the algorithm on synthetic distributions where the optimal error τ is varied systematically, comparing the achieved error bounds against the theoretical predictions