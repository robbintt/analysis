---
ver: rpa2
title: Large language models can be zero-shot anomaly detectors for time series?
arxiv_id: '2405.14755'
source_url: https://arxiv.org/abs/2405.14755
tags:
- time
- series
- anomaly
- anomalies
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a framework called S IGLLM for using large
  language models (LLMs) to detect anomalies in univariate time series data. The authors
  convert time series data into text format and propose two methods: P ROMPTER, which
  directly prompts LLMs to identify anomalies, and D ETECTOR, which uses LLMs'' forecasting
  capabilities to detect anomalies by comparing predicted and actual values.'
---

# Large language models can be zero-shot anomaly detectors for time series?

## Quick Facts
- **arXiv ID**: 2405.14755
- **Source URL**: https://arxiv.org/abs/2405.14755
- **Reference count**: 11
- **Primary result**: SIGLLM framework converts time series to text for LLM-based anomaly detection

## Executive Summary
This paper introduces SIGLLM, a framework that repurposes large language models for zero-shot time series anomaly detection by converting numerical time series data into textual format. The authors propose two distinct approaches: PROMPTER, which directly prompts LLMs to identify anomalies, and DETECTOR, which leverages LLMs' forecasting capabilities by comparing predicted values against actual observations. The framework is evaluated across 11 diverse time series datasets against 10 existing anomaly detection methods, demonstrating that while LLM-based approaches can detect anomalies without training, they still lag behind specialized deep learning models by approximately 30% in F1 score.

## Method Summary
The SIGLLM framework addresses the challenge of applying LLMs to time series anomaly detection by converting numerical time series data into text format, making it compatible with LLMs' natural language processing capabilities. The framework implements two distinct approaches: PROMPTER directly prompts the LLM to identify anomalous points in the text-formatted time series, while DETECTOR uses the LLM's forecasting ability to predict future values and flags points where actual values deviate significantly from predictions. Both methods operate in a zero-shot manner without requiring model training on anomaly detection tasks. The time series data is converted to text using standardized numerical representations, and anomaly scores are generated either through direct LLM assessment (PROMPTER) or prediction error analysis (DETECTOR).

## Key Results
- DETECTOR method achieved average F1 score of 0.525 across all 11 datasets
- PROMPTER method underperformed DETECTOR significantly in anomaly detection accuracy
- State-of-the-art deep learning models outperformed LLM-based approaches by approximately 30%
- Both SIGLLM methods demonstrated viable zero-shot anomaly detection capabilities despite performance gap

## Why This Works (Mechanism)
None

## Foundational Learning
- **Time series to text conversion**: Necessary to make numerical time series data compatible with LLMs' text processing capabilities; quick check: verify conversion preserves temporal ordering and numerical precision
- **Zero-shot learning**: Allows LLMs to perform anomaly detection without task-specific training; quick check: test with various prompt formulations to assess consistency
- **Anomaly scoring mechanisms**: Two approaches - direct LLM assessment vs. prediction error analysis; quick check: compare score distributions across different anomaly types
- **Univariate vs multivariate analysis**: Framework currently focuses on univariate time series; quick check: evaluate performance degradation when applied to multivariate data
- **Context window limitations**: LLMs' fixed context windows constrain the amount of historical data available for forecasting; quick check: measure performance impact of different window sizes
- **Prompt engineering impact**: Quality of prompts significantly affects PROMPTER's performance; quick check: A/B test different prompt templates

## Architecture Onboarding

**Component Map**: Time Series → Text Converter → LLM (PROMPTER or DETECTOR) → Anomaly Scores

**Critical Path**: Text conversion and prompt formulation are bottlenecks for PROMPTER, while context window size limits DETECTOR's forecasting horizon and accuracy.

**Design Tradeoffs**: PROMPTER offers direct interpretation but suffers from high false positives, while DETECTOR leverages LLMs' strengths in pattern recognition but requires careful threshold tuning.

**Failure Signatures**: PROMPTER produces excessive false positives on noisy data, while DETECTOR struggles with non-stationary signals and limited context windows, leading to missed anomalies in trend shifts.

**First Experiments**:
1. Test SIGLLM on a dataset with clear periodic patterns to evaluate DETECTOR's forecasting accuracy
2. Apply PROMPTER to a dataset with isolated anomalies to assess false positive rates
3. Vary context window sizes to quantify impact on DETECTOR's performance with different time series lengths

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can LLMs achieve competitive performance with deep learning models in time series anomaly detection through architectural modifications or larger context windows?
- Basis in paper: [explicit] The paper shows LLMs perform 30% worse than state-of-the-art deep learning models and identifies limited context window size as a major weakness
- Why unresolved: The paper only tests existing LLMs without exploring architectural modifications or the impact of larger context windows on performance
- What evidence would resolve it: Comparative experiments testing LLMs with increased context windows or modified architectures against deep learning models on the same benchmarks

### Open Question 2
- Question: What specific post-processing strategies could effectively reduce false positives in the PROMPTER approach without significantly impacting recall?
- Basis in paper: [explicit] The paper identifies high false positive rates in PROMPTER as a key limitation and suggests exploring log probabilities as a confidence measure
- Why unresolved: The paper only proposes future exploration of log probabilities without testing specific post-processing methods or their impact on precision-recall trade-offs
- What evidence would resolve it: Empirical evaluation of various post-processing techniques (thresholding, smoothing, statistical filtering) on their ability to improve precision while maintaining recall

### Open Question 3
- Question: Would incorporating temporal dependencies and trend information into LLM forecasting improve anomaly detection accuracy in non-stationary time series?
- Basis in paper: [inferred] The paper notes that DETECTOR struggles with non-stationary signals and that larger window sizes are needed to capture trend properties
- Why unresolved: The paper only identifies this limitation without testing methods to incorporate temporal dependencies or trend modeling into the LLM framework
- What evidence would resolve it: Comparative experiments testing DETECTOR with trend-aware features, temporal attention mechanisms, or hybrid approaches against the baseline on non-stationary datasets

## Limitations
- Performance gap of approximately 30% compared to state-of-the-art deep learning models
- Conversion from time series to text may introduce information loss
- Evaluation limited to univariate time series datasets

## Confidence
- **Medium Confidence**: LLMs can perform zero-shot anomaly detection
- **Low Confidence**: Practical viability for real-world applications
- **Medium Confidence**: Relative performance comparison between PROMPTER and DETECTOR

## Next Checks
1. Evaluate SIGLLM framework on multivariate time series datasets to assess performance in realistic scenarios
2. Test framework with different LLM architectures and model sizes to determine performance scaling
3. Conduct ablation studies on text encoding scheme to quantify information loss and explore alternative representations