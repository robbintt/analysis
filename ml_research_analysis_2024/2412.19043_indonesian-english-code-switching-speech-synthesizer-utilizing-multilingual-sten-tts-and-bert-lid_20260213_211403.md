---
ver: rpa2
title: Indonesian-English Code-Switching Speech Synthesizer Utilizing Multilingual
  STEN-TTS and Bert LID
arxiv_id: '2412.19043'
source_url: https://arxiv.org/abs/2412.19043
tags:
- code-switching
- language
- speech
- indonesian
- sten-tts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first Indonesian-English code-switching
  TTS system based on STEN-TTS, incorporating a BERT-based language identification
  component to handle mixed-language text. The approach removes language embedding
  from STEN-TTS and uses fine-tuned mBERT for per-word language identification to
  correctly guide phonemization.
---

# Indonesian-English Code-Switching Speech Synthesizer Utilizing Multilingual STEN-TTS and Bert LID

## Quick Facts
- arXiv ID: 2412.19043
- Source URL: https://arxiv.org/abs/2412.19043
- Reference count: 0
- This paper presents the first Indonesian-English code-switching TTS system based on STEN-TTS, incorporating a BERT-based language identification component to handle mixed-language text

## Executive Summary
This paper introduces the first Indonesian-English code-switching text-to-speech (TTS) system that addresses the challenge of synthesizing speech from mixed-language text. The system builds upon the STEN-TTS architecture by removing language-specific embedding components and integrating a fine-tuned multilingual BERT model for per-word language identification. This approach enables accurate phonemization of code-switched text by correctly identifying each word's language before applying appropriate pronunciation rules. The system demonstrates significant improvements in both naturalness and intelligibility compared to monolingual baselines, successfully handling both balanced and unbalanced code-switching scenarios.

## Method Summary
The system modifies STEN-TTS by removing the language embedding component, allowing the encoder's output to be passed directly to the variance adaptor without language-specific constraints. A fine-tuned mBERT model performs per-word language identification, classifying each token as either Indonesian or English before phonemization. The phonemizer then applies the appropriate grapheme-to-phoneme conversion rules based on the identified language. The modified STEN-TTS model is trained and evaluated using a combination of Indonesian and English datasets, including Common Voice v4 and CoVoST 2, with human evaluation conducted across seven code-switching cases using 35 respondents.

## Key Results
- CS-TTS model achieves MOS scores of 3.38, significantly improving from baseline scores of ~2.16 (Indonesian) and ~1.84 (English)
- Word Error Rate reduced from 36.44% (Indonesian baseline) and 42.18% (English baseline) to 17.43% with CS-TTS
- The system demonstrates strong performance across both balanced and unbalanced code-switching scenarios
- Minor phoneme pronunciation issues persist despite overall improvements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Removing the language embedding from STEN-TTS allows the model to process mixed-language input without being constrained to a single target language
- Mechanism: The language embedding previously provided language-specific context to the encoder's output, which biased the model toward generating speech in only one language per sentence. By removing it, the encoder's output is passed directly to the variance adaptor, enabling the model to handle code-switched text without retraining
- Core assumption: The variance adaptor and decoder can handle language-agnostic input and still produce coherent speech when combined with correct phonemization
- Evidence anchors:
  - [abstract] "Key modifications include... removing language embedding from the base model"
  - [section] "Removing the language embedding component directs the encoder's output directly to the variance adaptor. This approach circumvents the need for retraining the STEN-TTS model..."

### Mechanism 2
- Claim: Fine-tuning mBERT for per-word language identification enables accurate phonemization of code-switched text
- Mechanism: mBERT is fine-tuned on a balanced dataset of Indonesian and English tokens, then used to classify each word's language before passing it to Phonemizer. This ensures each word is converted to phonemes according to its actual language, preventing mispronunciation due to incorrect language rules
- Core assumption: mBERT's multilingual representations are sufficiently discriminative to classify words in code-switched contexts without confusion from shared vocabulary or cognates
- Evidence anchors:
  - [abstract] "adding a language identification component to the text-to-phoneme conversion using fine-tuned BERT for per-word language identification"
  - [section] "A two-dimensional fully connected layer was added to mBERT to classify the language of each token in the input text"

### Mechanism 3
- Claim: Combining STEN-TTS without language embedding and mBERT-based LID yields improved naturalness and intelligibility in code-switched speech synthesis
- Mechanism: The modified STEN-TTS handles the cross-language prosody and speaker consistency, while mBERT ensures correct phonemization. Together, they produce speech that is both more natural (higher MOS) and more intelligible (lower WER) than monolingual baselines
- Core assumption: The interaction between encoder output, variance adaptor, and phonemizer is sufficient to model the complex timing and rhythm of code-switched speech
- Evidence anchors:
  - [abstract] "Experimental results demonstrate that the code-switching model achieves superior naturalness and improved speech intelligibility compared to the Indonesian and English baseline STEN-TTS models"
  - [section] "Overall, CS-TTS and CS-TTS Topline models demonstrate more consistent and superior performance across various language scenarios compared to baseline models"

## Foundational Learning

- Concept: Code-switching and its linguistic challenges
  - Why needed here: Understanding code-switching is essential to grasp why standard monolingual TTS fails and why per-word language identification is required
  - Quick check question: What is the difference between intra-sentential and inter-sentential code-switching, and which does this system address?

- Concept: Multilingual BERT and token-level classification
  - Why needed here: mBERT's multilingual representations and fine-tuning process are central to the LID component's design and effectiveness
  - Quick check question: How does mBERT's token representation differ from word-level embeddings, and why is this important for per-word LID?

- Concept: Phonemization and grapheme-to-phoneme conversion
  - Why needed here: Correct phonemization is crucial for intelligibility, and the system's approach to routing words to the right phoneme rules is a core innovation
  - Quick check question: What happens if a word is phonemized using the wrong language's rules, and how does this affect speech intelligibility?

## Architecture Onboarding

- Component map: Input text → mBERT LID (per-word language) → Phonemizer (grapheme-to-phoneme) → STEN-TTS encoder (without language embedding) → variance adaptor → decoder → Mel spectrogram → vocoder → waveform
- Critical path: Text → LID → Phonemizer → TTS model → Output speech
- Design tradeoffs: Removing language embedding avoids retraining but may lose language-specific prosody cues; fine-tuning mBERT adds complexity but improves phonemization accuracy
- Failure signatures: Mispronunciation of code-switched words, unnatural prosody, or increased word error rate in intelligibility tests
- First 3 experiments:
  1. Test mBERT LID accuracy on a held-out code-switched dataset
  2. Compare Phonemizer output for code-switched vs monolingual text
  3. Evaluate MOS and WER for CS-TTS vs baselines on a small set of code-switched sentences

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the STEN-TTS model perform when handling code-switching scenarios beyond Indonesian-English, such as Indonesian-Javanese-English or other language combinations?
- Basis in paper: [inferred] The paper focuses on Indonesian-English code-switching but mentions STEN-TTS has demonstrated effective cross-language adaptation across five languages (English, Mandarin, Japanese, Indonesian, and Vietnamese)
- Why unresolved: The study only evaluates Indonesian-English code-switching, leaving the model's performance with other language pairs untested
- What evidence would resolve it: Testing the modified STEN-TTS model with different language pairs beyond Indonesian-English and comparing the results with the Indonesian-English case

### Open Question 2
- Question: What is the impact of the language identification errors on the overall speech quality and intelligibility in real-world applications?
- Basis in paper: [explicit] The paper mentions that the LID component may misclassify language labels, leading to errors in phoneme pronunciation
- Why unresolved: The study only evaluates the impact of LID errors on a limited set of SUS sentences and does not explore the broader implications in real-world scenarios
- What evidence would resolve it: Conducting user studies with a diverse set of code-switching sentences and evaluating the impact of LID errors on speech quality and intelligibility in real-world applications

### Open Question 3
- Question: How does the removal of the language embedding component affect the model's ability to handle longer and more complex code-switching sentences?
- Basis in paper: [inferred] The paper mentions that removing the language embedding component led to variations in phoneme pronunciation and longer durations in audio
- Why unresolved: The study only evaluates the impact of removing the language embedding component on a limited set of code-switching sentences and does not explore the broader implications for longer and more complex sentences
- What evidence would resolve it: Testing the modified STEN-TTS model with longer and more complex code-switching sentences and evaluating the impact of removing the language embedding component on speech quality and intelligibility

## Limitations
- The system's performance with language pairs beyond Indonesian-English remains untested
- Per-word language identification may struggle with ambiguous words or low-resource language pairs where cross-lingual representations are less distinct
- The approach doesn't model longer-range code-switching patterns or intra-word mixing phenomena

## Confidence

- **High Confidence**: The core architecture modifications (removing language embedding, integrating mBERT LID) and their basic effectiveness are well-supported by the evaluation results, showing consistent improvements over baselines in both MOS and WER metrics
- **Medium Confidence**: The claim that this is the "first Indonesian-English code-switching TTS system" is based on the literature review provided, but the rapidly evolving nature of code-switching research means this could be challenged by concurrent work not yet published
- **Medium Confidence**: While the system shows improved performance on the test cases, the generalization to more diverse code-switching patterns (beyond the seven balanced cases tested) remains to be fully validated

## Next Checks

1. **Cross-validation with external code-switching datasets**: Test the system on Indonesian-English code-switching data from different domains or recording conditions to assess robustness and generalization beyond the current test set

2. **Ablation study of mBERT LID accuracy**: Quantify the impact of mBERT LID errors on overall system performance by measuring how misclassifications correlate with pronunciation errors and intelligibility degradation

3. **Speaker consistency evaluation**: Conduct human evaluations specifically focused on whether the synthesized speech maintains consistent speaker identity and prosody when switching between Indonesian and English within the same utterance