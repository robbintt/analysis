---
ver: rpa2
title: 'MAGDi: Structured Distillation of Multi-Agent Interaction Graphs Improves
  Reasoning in Smaller Language Models'
arxiv_id: '2402.01620'
source_url: https://arxiv.org/abs/2402.01620
tags:
- round
- magd
- reasoning
- distillation
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of expensive and inefficient multi-agent
  language model interactions for reasoning tasks by introducing MAGDi, a structured
  distillation method that transfers knowledge from multi-agent interaction graphs
  (MAGs) into smaller language models. The core method represents multi-agent interactions
  as directed acyclic graphs (MAGs) where nodes are model generations and edges indicate
  interaction structure.
---

# MAGDi: Structured Distillation of Multi-Agent Interaction Graphs Improves Reasoning in Smaller Language Models

## Quick Facts
- arXiv ID: 2402.01620
- Source URL: https://arxiv.org/abs/2402.01620
- Reference count: 34
- Primary result: MAGDi improves reasoning accuracy by up to 4.61% across seven benchmarks while reducing inference tokens by up to 9x

## Executive Summary
MAGDi introduces a structured distillation approach that transfers knowledge from multi-agent interaction graphs (MAGs) into smaller language models to improve reasoning capabilities. The method represents multi-agent interactions as directed acyclic graphs where nodes are model generations and edges indicate interaction structure. By augmenting a base student model with a Graph Neural Network and fine-tuning using three objectives (next-token prediction, contrastive loss between correct/incorrect reasoning, and graph-based node classification), MAGDi captures richer reasoning knowledge than traditional single-teacher distillation. Experiments show MAGDi outperforms single-teacher baselines by up to 4.61% average accuracy across seven reasoning benchmarks while dramatically reducing inference tokens.

## Method Summary
MAGDi constructs multi-agent interaction graphs from teacher model discussions on reasoning tasks, where nodes represent model generations and edges capture interaction structure. The base student model (e.g., Mistral-7B) is augmented with a Graph Neural Network to process the graph structure. Three fine-tuning objectives are used: next-token prediction on correct reasoning chains, a contrastive loss between correct and incorrect reasoning, and graph-based node classification to capture interaction patterns. During inference, the Graph Neural Network is removed, making deployment efficient. The method demonstrates positive scaling with base model size and improved performance on out-of-domain tasks compared to single-teacher approaches.

## Key Results
- MAGDi outperforms single-teacher distillation baselines by up to 4.61% average accuracy across seven reasoning benchmarks
- Inference tokens reduced by up to 9x compared to the original multi-agent framework
- Positive scaling demonstrated with base model size and improved performance on out-of-domain tasks
- Multi-teacher distillation provides additional gains over single strongest teacher by 1.50% average

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structured distillation from multi-agent interaction graphs captures richer reasoning knowledge than single-teacher distillation
- Mechanism: MAGs encode not just correct reasoning chains but also incorrect reasoning paths and the iterative refinement process between agents
- Core assumption: Graph structure contains meaningful information about reasoning quality and improvement
- Evidence anchors: [abstract], [section], [corpus]

### Mechanism 2
- Claim: Multi-teacher distillation provides performance gains over single-teacher approaches
- Mechanism: Different teacher models bring diverse reasoning approaches and perspectives
- Core assumption: Teacher models have complementary reasoning strengths and weaknesses
- Evidence anchors: [abstract], [section], [corpus]

### Mechanism 3
- Claim: The contrastive loss between correct and incorrect reasoning provides valuable learning signals
- Mechanism: Explicitly contrasting correct and incorrect reasoning chains helps distinguish valid from invalid patterns
- Core assumption: Incorrect reasoning from strong teachers is high-quality negative examples
- Evidence anchors: [abstract], [section], [corpus]

## Foundational Learning

- Concept: Graph Neural Networks for structure-aware representation learning
  - Why needed here: Interaction structure contains information about reasoning refinement beyond text content
  - Quick check question: Can you explain how a Graph Convolutional Network aggregates information from neighboring nodes?

- Concept: Contrastive learning for distinguishing positive and negative examples
  - Why needed here: Model needs to learn what incorrect reasoning patterns to avoid
  - Quick check question: What is the purpose of the margin parameter in margin-based contrastive loss?

- Concept: Multi-task learning and joint model training
  - Why needed here: MAGDi-MT demonstrates training one model across multiple reasoning tasks
  - Quick check question: How does multi-task training differ from training separate models for each task?

## Architecture Onboarding

- Component map: Base student model + Graph Neural Network module + Three training objectives
- Critical path: Construct MAGs → Augment base model with GNN → Train with three objectives → Deploy without GNN
- Design tradeoffs: GNN adds complexity but enables structure learning; removed at inference for efficiency
- Failure signatures: Poor OOD performance suggests overfitting; no improvement over baselines suggests GNN isn't learning useful representations
- First 3 experiments:
  1. Verify MAG construction works correctly by checking node labels and edge connections
  2. Test base model + GNN without training objectives to ensure architecture can forward pass
  3. Train with only next-token prediction objective to establish baseline multi-teacher performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does MAGDi's performance scale with the number of interaction rounds in training data?
- Basis in paper: [explicit] Paper mentions varying interaction rounds but doesn't analyze their impact on MAGDi's performance
- Why unresolved: No detailed analysis of how number of rounds affects performance or if there's optimal number
- What evidence would resolve it: Experiments with MAGDi using training data with varying numbers of interaction rounds and comparing benchmark performance

### Open Question 2
- Question: How does choice of base student model architecture affect MAGDi's performance and efficiency gains?
- Basis in paper: [inferred] Paper tests different base models but doesn't deeply analyze architectural impact
- Why unresolved: Demonstrates positive scaling with size but doesn't explore architectural differences
- What evidence would resolve it: Experimenting with MAGDi using base models with different architectures and comparing performance

### Open Question 3
- Question: Can MAGDi be effectively applied to domains beyond reasoning tasks?
- Basis in paper: [inferred] Focuses on reasoning tasks without exploring other NLP or structured prediction applications
- Why unresolved: Doesn't investigate generalizability to other domains
- What evidence would resolve it: Applying MAGDi to other NLP tasks or structured prediction problems and evaluating performance

## Limitations
- Requires multiple strong teacher models to generate diverse MAGs, creating computational overhead
- Assumes incorrect reasoning from high-quality teachers provides useful negative examples without rigorous validation
- Sensitive to hyperparameter tuning, particularly balance between three fine-tuning objectives

## Confidence

**High Confidence** (Supported by direct experimental evidence):
- Measurable accuracy improvements over single-teacher baselines across all seven benchmarks
- 9x reduction in inference tokens empirically validated
- Consistent performance gains when scaling base model size

**Medium Confidence** (Strong results but with some caveats):
- Positive scaling behavior appears robust but tested across limited range of model sizes
- Out-of-domain performance suggests generalization but specific tasks may not be representative
- Graph-based node classification contributes meaningfully but exact mechanism isn't fully characterized

**Low Confidence** (Limited evidence or significant assumptions):
- Assumption that graph structure captures meaningful reasoning patterns beyond text-based distillation is largely theoretical
- Contrastive learning mechanism's effectiveness relies on implicit assumptions about quality of incorrect reasoning
- Performance with limited teacher diversity or weaker teachers is unexplored

## Next Checks
1. **Ablation study of MAG structure**: Remove graph-based components and train using only text-based distillation from same MAGs to quantify graph structure's contribution versus multi-teacher knowledge alone.

2. **Teacher quality sensitivity analysis**: Systematically vary strength and diversity of teacher models, measuring performance degradation with weaker or more homogeneous teachers to understand method's robustness.

3. **Cross-domain generalization testing**: Evaluate MAGDi on broader set of out-of-domain tasks including non-reasoning domains to better understand limits of claimed generalization capabilities.