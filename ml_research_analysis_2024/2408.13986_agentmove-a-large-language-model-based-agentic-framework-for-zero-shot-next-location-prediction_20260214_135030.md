---
ver: rpa2
title: 'AgentMove: A Large Language Model based Agentic Framework for Zero-shot Next
  Location Prediction'
arxiv_id: '2408.13986'
source_url: https://arxiv.org/abs/2408.13986
tags:
- mobility
- prediction
- data
- user
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'AgentMove is an LLM-based agentic framework for zero-shot next
  location prediction. It systematically decomposes the task into three components:
  individual mobility pattern mining via spatial-temporal memory, urban structure
  modeling through a world knowledge generator, and collective pattern extraction
  using a graph-based approach.'
---

# AgentMove: A Large Language Model based Agentic Framework for Zero-shot Next Location Prediction

## Quick Facts
- arXiv ID: 2408.13986
- Source URL: https://arxiv.org/abs/2408.13986
- Authors: Jie Feng; Yuwei Du; Jie Zhao; Yong Li
- Reference count: 40
- AgentMove outperforms leading baselines by 3.33% to 8.57% across 8 of 12 metrics in zero-shot next location prediction

## Executive Summary
AgentMove is an LLM-based agentic framework designed for zero-shot next location prediction that systematically decomposes the task into three components: individual mobility pattern mining, urban structure modeling, and collective pattern extraction. Unlike direct LLM generation approaches, AgentMove employs a multi-module architecture that leverages spatial-temporal memory, world knowledge generation, and graph-based collective knowledge extraction to capture complex mobility patterns. Experiments on 12 cities using Foursquare and ISP data demonstrate that AgentMove achieves superior performance across multiple metrics compared to leading baselines.

## Method Summary
AgentMove processes user trajectory data through a three-module framework that integrates individual, collective, and urban structure patterns. The framework first decomposes the prediction task, then uses a spatial-temporal memory module to capture individual mobility patterns through short-term, long-term, and user profile memories. A world knowledge generator extracts geospatial knowledge from LLMs to model urban structures and exploration behavior, while a collective knowledge extractor discovers shared mobility patterns through graph-based analysis. The integrated reasoning module synthesizes these components to generate predictions using zero-shot LLM prompting without training on target data.

## Key Results
- Outperforms leading baselines by 3.33% to 8.57% across 8 of 12 metrics
- Demonstrates robust predictions across different LLM providers (OpenAI, DeepInfra, SiliconFlow)
- Shows reduced geographical bias compared to direct LLM approaches
- Successfully handles both returning and exploring behaviors in human mobility

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AgentMove's systematic decomposition of mobility prediction into individual, collective, and urban structure components enables better capture of complex mobility patterns than direct LLM generation.
- Mechanism: By decomposing the task, AgentMove isolates different aspects of mobility behavior - individual patterns via spatial-temporal memory, shared patterns via graph-based extraction, and exploration behavior via world knowledge generation. Each module addresses a specific gap in direct LLM approaches.
- Core assumption: Complex human mobility can be effectively modeled by separating individual behavior patterns, population-level patterns, and environmental influences rather than treating them as a single sequence prediction problem.
- Evidence anchors: [abstract] "However, they directly generate the final output using LLMs without systematic design, which limits the potential of LLMs to uncover complex mobility patterns"; [section 3.1] "By integrating domain knowledge of human mobility, we implement the core components in the general agentic framework"
- Break condition: If the decomposition creates information silos that prevent cross-module reasoning, or if the integration step fails to synthesize insights effectively.

### Mechanism 2
- Claim: The spatial-temporal memory module enables AgentMove to retain and leverage historical mobility patterns, providing advantages over pure LLM methods.
- Mechanism: The module stores user profiles, long-term memory, and short-term memory separately, allowing efficient retrieval of mobility history and adaptation to evolving user preferences. This addresses LLMs' limited ability to maintain context across long sequences.
- Core assumption: LLMs have limited capacity to retain and reason over long-term user mobility history without explicit memory structures.
- Evidence anchors: [section 3.2.1] "This module contains three submodules–short-term memory, long-term memory and user profiles–to capture the multi-level mobility patterns of individuals"; [section 3.2.3] "These memory-based prompts are consolidated into a cohesive spatial-temporal summary of the original trajectory"
- Break condition: If the memory retrieval becomes too slow for real-time applications, or if the memory content becomes stale and irrelevant.

### Mechanism 3
- Claim: The world knowledge generator enables modeling of exploration behavior by extracting geospatial knowledge from LLMs and constructing multi-scale urban structures.
- Mechanism: By converting coordinates to text addresses and prompting LLMs to generate potential exploration locations at district, block, street, and POI levels, AgentMove models both returning and exploring behaviors in human mobility.
- Core assumption: LLMs contain sufficient geospatial knowledge about urban structures that can be extracted and structured for mobility prediction.
- Evidence anchors: [section 3.3.2] "Based on the real structured address information, we design prompts to motivate LLMs to generate potential candidate places for exploration"; [section 3.3.1] "We propose to utilize the text address which human is familiar to describe the coarse location of trajectory"
- Break condition: If LLMs hallucinate non-existent locations, or if the multi-scale generation mechanism produces too many irrelevant candidates.

## Foundational Learning

- Concept: Task decomposition in complex prediction problems
  - Why needed here: Direct LLM generation fails to capture the multi-faceted nature of human mobility; decomposition allows specialized handling of individual patterns, collective patterns, and environmental factors
  - Quick check question: What are the three main components AgentMove decomposes the mobility prediction task into, and why is each important?

- Concept: Memory-augmented language models
  - Why needed here: Standard LLMs have limited context windows and struggle with long-term dependencies; explicit memory structures allow retention and retrieval of user mobility history
  - Quick check question: What are the three submodules of AgentMove's spatial-temporal memory, and what aspect of mobility does each capture?

- Concept: Geospatial knowledge extraction from language models
  - Why needed here: LLMs trained on web text contain implicit geographic knowledge that can be structured and used for predicting exploration behavior in mobility
  - Quick check question: How does AgentMove convert raw trajectory coordinates into a format that LLMs can reason about for urban structure modeling?

## Architecture Onboarding

- Component map: Task decomposition module (planner) → Spatial-temporal memory module (individual patterns) → World knowledge generator (urban structure) → Collective knowledge extractor (shared patterns) → Reasoning & prediction module (integration)
- Critical path: User trajectory → Task decomposition → Individual pattern mining → Urban structure modeling → Collective pattern discovery → Integrated reasoning → Prediction output
- Design tradeoffs: Memory storage vs. real-time performance; granularity of urban structure vs. computational cost; exploration vs. exploitation in predictions
- Failure signatures: Degraded performance on cold-start users (memory issues); geographic bias in predictions (world knowledge issues); inability to capture emerging mobility trends (collective knowledge issues)
- First 3 experiments:
  1. Implement and test spatial-temporal memory module alone on a small city dataset, measuring improvement over baseline LLM approach
  2. Add world knowledge generator and test its impact on exploration prediction rates
  3. Integrate collective knowledge extractor and evaluate performance across multiple cities with varying data volumes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does AgentMove's performance compare to deep learning models when trained on increasingly larger mobility datasets?
- Basis in paper: [inferred] The paper states that deep learning models rely on large amounts of private mobility data and improve with more data, while AgentMove is evaluated in a zero-shot setting.
- Why unresolved: The paper only compares AgentMove against deep learning baselines trained on standard dataset splits, not varying amounts of training data.
- What evidence would resolve it: Experiments showing accuracy trends of AgentMove versus deep learning models as training dataset sizes increase from small to large.

### Open Question 2
- Question: What is the impact of geographical bias on AgentMove's predictions in cities not represented in the training data of the base LLMs?
- Basis in paper: [explicit] The paper discusses geographical bias across 12 cities and notes that LLMs may have biases based on their training data distribution.
- Why unresolved: The paper only tests on 12 cities and does not explore performance in cities from underrepresented regions or with distinct mobility patterns.
- What evidence would resolve it: Evaluation of AgentMove's accuracy and bias metrics on mobility data from cities in underrepresented regions or with significantly different urban structures.

### Open Question 3
- Question: How does AgentMove handle out-of-distribution location categories or novel urban environments not seen during LLM training?
- Basis in paper: [inferred] The paper mentions that AgentMove uses text-based addresses to align with LLM geospatial knowledge, but doesn't address handling of novel location types.
- Why unresolved: The experiments use existing POI categories from Foursquare and ISP data, without testing AgentMove's generalization to completely new location types.
- What evidence would resolve it: Experiments where AgentMove is tested on trajectories containing location categories or urban environments that were not present in the LLM's pre-training corpus.

## Limitations

- The relative contribution of each module to overall performance is not quantified through ablation studies
- Performance depends on the quality and coverage of historical mobility data, which may vary significantly across cities
- Reliance on LLM-extracted geospatial knowledge introduces potential hallucination risks and geographical bias
- The graph-based collective knowledge extraction may be computationally expensive for real-time applications

## Confidence

**High Confidence**: Claims about overall performance improvements (3.33% to 8.57% gains across 8 of 12 metrics) are well-supported by the experimental results presented in the paper. The comparison against 9 baselines across 12 cities provides robust empirical evidence.

**Medium Confidence**: Claims about the specific mechanisms of each module (memory retention, knowledge extraction, collective pattern discovery) are reasonably supported but lack detailed ablation studies showing individual contributions. The paper demonstrates these components work together but doesn't isolate their separate impacts.

**Low Confidence**: Claims about the framework's generalizability to new cities and its ability to reduce geographical bias require more extensive validation beyond the 12 cities tested. The zero-shot nature is demonstrated but real-world deployment scenarios may present additional challenges.

## Next Checks

1. **Ablation study validation**: Conduct experiments removing each module (memory, world knowledge, collective extraction) individually to quantify their separate contributions to the overall performance improvement, confirming the decomposition assumption.

2. **Geographical bias stress test**: Test AgentMove on cities from different regions (particularly non-Western cities) and measure performance degradation, comparing against the baseline methods to verify the claimed reduced geographical bias.

3. **Real-time performance benchmark**: Measure the end-to-end latency of AgentMove's multi-module pipeline on a representative city dataset, comparing against simpler direct LLM approaches to validate the computational efficiency tradeoff.