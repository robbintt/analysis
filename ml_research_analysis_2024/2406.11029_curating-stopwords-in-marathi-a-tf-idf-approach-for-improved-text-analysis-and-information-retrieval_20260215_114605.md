---
ver: rpa2
title: 'Curating Stopwords in Marathi: A TF-IDF Approach for Improved Text Analysis
  and Information Retrieval'
arxiv_id: '2406.11029'
source_url: https://arxiv.org/abs/2406.11029
tags:
- stopwords
- language
- marathi
- list
- words
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the scarcity of comprehensive stopword lists
  for the Marathi language, a low-resource Indian language, by proposing a TF-IDF-based
  approach combined with human evaluation to curate a list of 400 stopwords. The method
  involves segmenting a large Marathi corpus into chunks, calculating TF-IDF scores
  for each word, extracting the top 5,000 words with the lowest scores from each chunk,
  and then performing an intersection to identify common terms.
---

# Curating Stopwords in Marathi: A TF-IDF Approach for Improved Text Analysis and Information Retrieval

## Quick Facts
- **arXiv ID:** 2406.11029
- **Source URL:** https://arxiv.org/abs/2406.11029
- **Reference count:** 17
- **Primary result:** Curated a list of 400 Marathi stopwords using TF-IDF scoring and human evaluation, integrated into mahaNLP library

## Executive Summary
This paper addresses the scarcity of comprehensive stopword lists for Marathi, a low-resource Indian language, by proposing a TF-IDF-based approach combined with human evaluation to curate a list of 400 stopwords. The method involves segmenting a large Marathi corpus into chunks, calculating TF-IDF scores for each word, extracting the top 5,000 words with the lowest scores from each chunk, and then performing an intersection to identify common terms. Human evaluation further refines the list. The curated stopwords were integrated into the mahaNLP library. The impact of stopword removal was tested on text classification tasks, showing minimal impact on model accuracy (e.g., MahaBERT maintained 94.06% accuracy with stopwords). This work provides the largest stopword list for Marathi, contributing to advancements in Marathi NLP applications.

## Method Summary
The methodology employs a multi-stage approach for stopword curation in Marathi. First, a large Marathi corpus is segmented into manageable chunks for processing efficiency. TF-IDF (Term Frequency-Inverse Document Frequency) scores are computed for each word across the corpus, identifying terms with low TF-IDF scores as potential stopwords since these words appear frequently but carry minimal semantic value. From each corpus chunk, the top 5,000 words with the lowest TF-IDF scores are extracted. An intersection operation across all chunks identifies the most consistently low-scoring terms. This preliminary list undergoes human evaluation for refinement, though specific details about evaluator expertise and criteria are not provided. The final curated list of 400 stopwords is integrated into the mahaNLP library for practical NLP applications. The effectiveness of stopword removal is evaluated on text classification tasks using models like MahaBERT, demonstrating that removing stopwords has minimal impact on classification accuracy while potentially improving computational efficiency.

## Key Results
- Curated a comprehensive list of 400 Marathi stopwords using TF-IDF scoring and human evaluation
- Integration of curated stopwords into the mahaNLP library for practical NLP applications
- Minimal impact on text classification accuracy (MahaBERT maintained 94.06% accuracy) when using the curated stopwords

## Why This Works (Mechanism)
The TF-IDF approach effectively identifies stopwords by leveraging the statistical property that stopwords typically appear frequently across documents but carry little discriminative information. Low TF-IDF scores indicate words that are common throughout the corpus but don't help distinguish between different documents or topics. The intersection across corpus chunks ensures that only consistently frequent, low-information words are selected, reducing the likelihood of including domain-specific terms. Human evaluation provides the necessary linguistic judgment to refine the list, capturing cultural and contextual nuances that purely statistical methods might miss in a morphologically rich language like Marathi.

## Foundational Learning

**TF-IDF scoring** - why needed: Identifies words with low discriminative power that appear frequently across documents
 - quick check: Verify that selected stopwords have consistently low TF-IDF scores across corpus segments

**Corpus segmentation** - why needed: Enables processing of large datasets in manageable chunks while maintaining statistical validity
 - quick check: Ensure each segment is large enough to capture word frequency distributions reliably

**Intersection methodology** - why needed: Filters out chunk-specific words to identify universally common low-value terms
 - quick check: Confirm that intersected words appear across multiple segments with consistent low scores

**Human evaluation** - why needed: Adds linguistic expertise to refine statistically-derived lists and capture language-specific nuances
 - quick check: Establish clear annotation guidelines and inter-annotator agreement metrics

**Morphological analysis** - why needed: Marathi's rich morphology requires consideration of word forms and inflections in stopword identification
 - quick check: Verify that different morphological forms of the same word are consistently treated as stopwords

## Architecture Onboarding

**Component map:** Marathi corpus -> Segmentation -> TF-IDF scoring -> Low-score extraction (top 5,000 per chunk) -> Intersection -> Human evaluation -> Curated stopword list -> mahaNLP integration -> NLP task evaluation

**Critical path:** Corpus segmentation → TF-IDF computation → Intersection operation → Human refinement → Integration and validation

**Design tradeoffs:** The TF-IDF approach balances automation with linguistic accuracy, but may miss context-dependent stopwords. Larger intersection sets would provide more comprehensive coverage but risk including less universal terms. Human evaluation improves quality but reduces scalability and introduces subjectivity.

**Failure signatures:** Corpus bias leading to domain-specific stopwords, morphological variants not properly handled, human evaluators with insufficient Marathi expertise, or intersection sets too small/large compromising list quality.

**First experiments:**
1. Test curated stopwords on diverse Marathi NLP tasks (sentiment analysis, named entity recognition, information retrieval) beyond classification
2. Compare classification accuracy with and without stopword removal across multiple runs and datasets with statistical significance testing
3. Conduct systematic survey of existing Marathi stopword lists for direct size and content comparison to validate "largest list" claim

## Open Questions the Paper Calls Out
None

## Limitations
- Corpus size and composition unspecified, making it difficult to assess representativeness and generalizability of the stopword list
- Human evaluation process lacks detail regarding evaluator expertise, number of evaluators, and specific annotation criteria
- Claims about being "the largest stopword list for Marathi" lack comparative analysis with existing resources and their relative sizes
- TF-IDF methodology may not fully capture domain-specific or context-dependent stopwords important for specialized applications

## Confidence

**High confidence:** The methodological framework (TF-IDF scoring + intersection + human refinement) is clearly described and technically sound

**Medium confidence:** The integration with mahaNLP library and its practical implementation details

**Low confidence:** Claims about being "the largest" list without comparative analysis, and the generalizability of results across different Marathi text domains

## Next Checks

1. Conduct a systematic survey of existing Marathi stopword lists and perform direct size and content comparison to validate the "largest list" claim

2. Implement the curated stopword list in diverse Marathi NLP tasks beyond text classification (such as information retrieval, sentiment analysis, and named entity recognition) to assess cross-task effectiveness

3. Perform statistical significance testing comparing classification performance with and without stopword removal across multiple runs and datasets to verify the claimed minimal impact is not due to random variation