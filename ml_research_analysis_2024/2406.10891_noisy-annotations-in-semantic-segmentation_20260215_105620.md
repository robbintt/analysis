---
ver: rpa2
title: Noisy Annotations in Semantic Segmentation
arxiv_id: '2406.10891'
source_url: https://arxiv.org/abs/2406.10891
tags:
- noise
- label
- segmentation
- noisy
- mask
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of label noise in instance segmentation,
  proposing a novel stochastic benchmark that combines class and spatial noise to
  simulate real-world annotation errors. The authors introduce two datasets, COCO-N
  and Cityscapes-N, each with three levels of noise (easy, medium, hard), and a weakly
  supervised annotation noise benchmark, COCO-WAN.
---

# Noisy Annotations in Semantic Segmentation

## Quick Facts
- arXiv ID: 2406.10891
- Source URL: https://arxiv.org/abs/2406.10891
- Reference count: 40
- Authors propose a novel stochastic benchmark combining class and spatial noise to simulate real-world annotation errors in instance segmentation

## Executive Summary
This paper addresses the critical challenge of label noise in instance segmentation by introducing a comprehensive benchmark that simulates real-world annotation errors. The authors propose combining class noise with spatial noise (scale, localization, and approximation errors) to create more realistic evaluation conditions. They introduce two datasets, COCO-N and Cityscapes-N, each with three noise levels, and demonstrate that transformer-based models like Mask2Former show greater robustness to label noise compared to CNN-based architectures.

## Method Summary
The paper introduces a stochastic noise generation script that combines class noise with three types of spatial noise: scale errors (size discrepancies), localization errors (position inaccuracies), and approximation errors (boundary inaccuracies). The benchmark includes COCO-N and Cityscapes-N datasets with easy, medium, and hard noise levels, plus COCO-WAN for weakly supervised annotation noise. Models are trained using standard procedures from MMDetection, with performance evaluated using mAP and boundary mAP metrics.

## Key Results
- Models trained on noisy labels show 79-91% retention of original mAP depending on noise level and dataset
- Transformer-based models (Mask2Former) demonstrate significantly greater robustness to label noise than CNN-based architectures
- Spatial noise remains challenging to distinguish from clean labels, limiting effectiveness of existing noise-robust learning methods
- Class noise can be partially separated during training, but spatial noise impacts model boundaries where confidence is lowest

## Why This Works (Mechanism)

### Mechanism 1
The proposed stochastic noise benchmark effectively simulates real-world annotation errors by combining class and spatial noise. By blending random label flipping with scale, localization, and approximation errors, the benchmark creates a comprehensive evaluation environment reflecting real-world data complexities. The core assumption is that real-world annotation errors are independent and randomly distributed across these dimensions. Break condition: If spatial noise correlates with specific object classes or contexts.

### Mechanism 2
Transformer-based models demonstrate greater robustness to label noise compared to CNN-based architectures due to their self-attention mechanism and global context understanding. This allows transformers to better filter out spurious correlations introduced by noise and focus on relevant features. The core assumption is that self-attention can effectively distinguish relevant features even when labels are corrupted. Break condition: If noise overwhelms the model's ability to focus on relevant features.

### Mechanism 3
The weakly supervised annotation noise benchmark (COCO-WAN) effectively simulates noise from semi-automated annotation tools by using foundation models with weak annotations. This captures specific biases like color/texture preferences and object conflation that arise from automated annotation processes. The core assumption is that foundation model biases are representative of real-world semi-automated tools. Break condition: If foundation model biases don't generalize to actual annotation tools.

## Foundational Learning

- Concept: Instance segmentation
  - Why needed here: Understanding the task is crucial for grasping label noise challenges and benchmark significance
  - Quick check question: What is the difference between instance segmentation and semantic segmentation?

- Concept: Label noise
  - Why needed here: The paper focuses on label noise impact on instance segmentation models
  - Quick check question: What are the main types of label noise, and how do they affect model performance?

- Concept: Self-attention mechanism
  - Why needed here: Transformers' robustness to noise is attributed to self-attention
  - Quick check question: How does self-attention in transformers differ from traditional convolutional operations?

## Architecture Onboarding

- Component map: Noise generation script -> COCO-N/Cityscapes-N datasets -> Instance segmentation models (Mask R-CNN, Mask2Former, YOLACT) -> Evaluation pipeline (mAP, AP b)
- Critical path: Generate noisy labels → Train instance segmentation models → Evaluate performance using standard metrics
- Design tradeoffs: Realism of simulated noise vs. computational cost; noise type selection affects result generalizability
- Failure signatures: Unrealistic noise patterns; evaluation metrics that don't capture true noise impact
- First 3 experiments:
  1. Generate noisy labels on COCO subset and visualize clean vs. noisy annotations
  2. Train Mask R-CNN on noisy labels and evaluate on clean validation data
  3. Compare Mask2Former vs. Mask R-CNN performance on same noisy labels

## Open Questions the Paper Calls Out

### Open Question 1
How can we effectively distinguish between clean and noisy labels at the pixel level in instance segmentation, particularly for spatial noise? The paper highlights the difficulty in separating spatial noise from clean labels, noting that most spatial noise occurs at boundaries where models exhibit least confidence. This remains unresolved because existing methods rely on loss separability, which is challenging for spatial noise. Resolution would require methods that accurately identify and separate clean and noisy pixels through advanced loss functions or noise estimation techniques.

### Open Question 2
How does label noise affect instance segmentation models on long-tailed class distributions like LVIS? The paper mentions long-tail distributions and exacerbated noise effects but lacks detailed analysis. This remains unexplored because the study doesn't investigate specific impacts on long-tailed datasets. Resolution would require experiments comparing model performance on long-tailed datasets with varying noise levels, including class imbalance analysis.

### Open Question 3
Can transformer architectures be further optimized to enhance their robustness to label noise in instance segmentation? While the paper establishes transformer robustness, it doesn't explore optimization strategies. This remains unresolved because specific architectural or training modifications aren't investigated. Resolution would require research into architectural enhancements, data augmentation, or loss function modifications tailored for transformers handling label noise.

## Limitations

- Noise simulation assumes independence between class and spatial errors, which may not hold in real-world scenarios
- Benchmark focuses on instance segmentation and may not generalize to semantic segmentation or object detection
- Limited analysis of noise impact on long-tailed class distributions common in real-world datasets

## Confidence

- **High**: Transformer models show greater robustness to label noise compared to CNN-based architectures
- **Medium**: Noise generation methodology accurately simulates real-world annotation errors
- **Medium**: Class noise can be separated from clean labels during training, while spatial noise cannot

## Next Checks

1. Validate the independence assumption between class and spatial noise by analyzing correlation patterns in real-world annotation datasets
2. Test benchmark generalizability by applying it to semantic segmentation tasks and comparing results
3. Investigate whether transformer robustness extends to other vision tasks beyond instance segmentation