---
ver: rpa2
title: A Survey on Graph Condensation
arxiv_id: '2402.02000'
source_url: https://arxiv.org/abs/2402.02000
tags: []
core_contribution: 'This survey comprehensively reviews Graph Condensation (GC), a
  technique for reducing large-scale graphs into smaller, informative ones while preserving
  essential information for downstream tasks. The paper proposes a formal definition
  of GC and establishes a taxonomy categorizing existing methods into three types:
  graph-guided, model-guided, and hybrid.'
---

# A Survey on Graph Condensation

## Quick Facts
- arXiv ID: 2402.02000
- Source URL: https://arxiv.org/abs/2402.02000
- Authors: Hongjia Xu; Liangliang Zhang; Yao Ma; Sheng Zhou; Zhuonan Zheng; Bu Jiajun
- Reference count: 10
- Primary result: A structured taxonomy of Graph Condensation methods categorizing objectives and formulations

## Executive Summary
This survey comprehensively reviews Graph Condensation (GC), a technique for reducing large-scale graphs into smaller, informative ones while preserving essential information for downstream tasks. The paper proposes a formal definition of GC and establishes a taxonomy categorizing existing methods into three types: graph-guided, model-guided, and hybrid. It also classifies the formulations for generating condensed graphs into two categories: modifying the original graphs or creating synthetic ones. The survey analyzes datasets, evaluation metrics, and applications, and discusses limitations and future directions.

## Method Summary
Graph Condensation reduces large graphs to smaller ones while preserving essential information for downstream tasks. The survey proposes a formal definition of GC and categorizes existing methods into three objectives: graph-guided (preserving spectral/spatial properties), model-guided (retaining model capabilities), and hybrid (combining both). Formulations include modification (aggregating nodes via projection matrices) and synthetic (directly optimizing condensed graph components). The survey evaluates effectiveness through graph property preservation, model performance metrics, and condensed graph properties, while efficiency is measured through condensation time, memory usage, and downstream task training time.

## Key Results
- Comprehensive taxonomy categorizing GC methods into graph-guided, model-guided, and hybrid objectives
- Formal definition of Graph Condensation with two formulation strategies: modification and synthetic
- Analysis of datasets, evaluation metrics, and applications across different GC approaches
- Identification of limitations and future research directions for the field

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph Condensation reduces computational burden by creating a smaller, task-specific graph that preserves essential information.
- Mechanism: The process formulates a condensed graph through optimization that minimizes information loss while reducing scale, allowing downstream GNNs to train faster on the smaller graph.
- Core assumption: The condensed graph retains sufficient information to maintain comparable GNN performance to training on the full graph.
- Evidence anchors:
  - [abstract] "reduce the scale of large graphs to smaller ones while preserving essential information for downstream tasks"
  - [section 2.2] "Gc as the Condensed graph only if V′ ⊈ V"
  - [corpus] Weak evidence; the corpus neighbors focus on related surveys but don't provide direct experimental validation of this mechanism.
- Break condition: If the condensed graph loses critical structural or feature information, GNN performance will degrade significantly, negating the computational benefits.

### Mechanism 2
- Claim: Different condensation objectives (graph-guided, model-guided, hybrid) target specific information preservation needs.
- Mechanism: Graph-guided objectives preserve spectral or spatial properties, model-guided objectives maintain GNN performance, and hybrid objectives balance both, allowing customization based on application requirements.
- Core assumption: The choice of objective directly impacts which graph properties are preserved in the condensed graph.
- Evidence anchors:
  - [section 3] "categorize the condensing objectives into three types: preserving certain properties of the graph (graph guided), retaining the GNNs' capabilities for downstream tasks (model guided), or simultaneously accomplishing both (hybrid)"
  - [section 3.1] "Spectral Property Guided Methods... ϕ(G) = ϕ(LG)"
  - [corpus] No direct evidence in corpus; this is derived from the survey's own taxonomy.
- Break condition: If the objective doesn't align with the actual information needs of the downstream task, the condensed graph will be ineffective despite being smaller.

### Mechanism 3
- Claim: The formulation strategy (modification vs. synthetic) determines the computational efficiency and interpretability of the condensed graph.
- Mechanism: Modification strategies aggregate nodes from the original graph, offering strong efficiency and interpretability, while synthetic strategies generate new graphs through optimization, offering flexibility but potentially higher computational cost.
- Core assumption: The formulation strategy impacts both the quality of the condensed graph and the resources required to generate it.
- Evidence anchors:
  - [section 4.1] "Modification approaches encompass actions such as node aggregation and deletion... A′ = P⊤AP, X′ = P+X"
  - [section 4.2] "Synthetic approaches... take the condensed graphs as parameters and directly optimize them"
  - [section 4.3] "the Modification formulations exhibit the strongest computational efficiency and interpretability"
- Break condition: If the synthetic formulation's parameter space is too large, optimization may fail to converge, or if modification aggregation is too aggressive, critical information may be lost.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs)
  - Why needed here: GNNs are the primary models trained on both original and condensed graphs; understanding their operation is crucial for grasping condensation objectives.
  - Quick check question: What is the fundamental operation that allows GNNs to process graph-structured data?

- Concept: Graph Spectral Theory
  - Why needed here: Spectral properties (eigenvalues, eigenvectors of the Laplacian) are key targets for preservation in some condensation methods.
  - Quick check question: How does the graph Laplacian matrix relate to the connectivity structure of a graph?

- Concept: Dataset Distillation
  - Why needed here: Graph Condensation is conceptually related to dataset distillation from computer vision, but adapted for graph data's unique properties.
  - Quick check question: What is the primary goal of dataset distillation in machine learning?

## Architecture Onboarding

- Component map: Graph preprocessing module -> Condensation module (objective selection and formulation) -> Optimization engine (parameter tuning) -> Evaluation pipeline (effectiveness and efficiency metrics)
- Critical path: Define condensation objective -> Select formulation strategy -> Optimize condensed graph parameters -> Evaluate effectiveness and efficiency -> Iterate if necessary
- Design tradeoffs: Graph-guided objectives preserve structure but may not optimize for task performance; model-guided objectives optimize for performance but may lose interpretability; hybrid objectives balance both but are more complex to implement
- Failure signatures: Significant performance gap between original and condensed graphs; high condensation time relative to training time savings; inability to converge on synthetic formulations with large parameter spaces
- First 3 experiments:
  1. Implement a simple modification-based condensation method (e.g., node aggregation) on a small graph dataset and compare GNN training time and accuracy.
  2. Apply a model-guided objective (e.g., gradient matching) to a node classification task and evaluate performance preservation.
  3. Conduct an ablation study comparing graph-guided, model-guided, and hybrid objectives on the same dataset to understand their relative strengths.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we develop a unified framework that balances effectiveness and efficiency in Graph Condensation, allowing for the determination of optimal condensation ratios based on predefined application requirements?
- Basis in paper: [explicit] The paper discusses the tradeoff between effectiveness and efficiency in Graph Condensation and suggests that a tradeoff framework is needed to specify the utility of GC and expand its application scope.
- Why unresolved: The paper acknowledges the need for a tradeoff framework but does not provide a concrete solution or methodology for determining optimal condensation ratios based on application requirements.
- What evidence would resolve it: Developing a comprehensive tradeoff framework that considers both effectiveness and efficiency metrics, and provides guidelines for determining optimal condensation ratios based on specific application needs, would resolve this question.

### Open Question 2
- Question: How can we enhance the interpretability of condensed graphs, particularly for newly generated nodes and edges, to better understand their semantic meanings in real-world applications?
- Basis in paper: [explicit] The paper highlights the challenge of interpreting newly generated elements in condensed graphs and suggests that enhancing their interpretability is crucial for expanding the application scenarios of Graph Condensation.
- Why unresolved: The paper does not provide a specific methodology or approach for enhancing the interpretability of condensed graphs, particularly for newly generated nodes and edges.
- What evidence would resolve it: Developing techniques or methodologies that can effectively interpret the semantic meanings of newly generated nodes and edges in condensed graphs, and demonstrate their practical applicability in real-world scenarios, would resolve this question.

### Open Question 3
- Question: How can we extend Graph Condensation methods to handle more complex graph types, such as dynamic and heterogeneous graphs, while preserving richer information from the original graph?
- Basis in paper: [explicit] The paper acknowledges that existing Graph Condensation methods primarily focus on undirected, homogeneous, static graphs, and suggests that extending them to handle more complex graph types is an important future direction.
- Why unresolved: The paper does not provide specific approaches or techniques for extending Graph Condensation to handle dynamic and heterogeneous graphs, or for preserving richer information from the original graph.
- What evidence would resolve it: Developing and demonstrating the effectiveness of Graph Condensation methods that can handle dynamic and heterogeneous graphs, while preserving richer information from the original graph, would resolve this question.

## Limitations

- The survey is primarily theoretical and lacks empirical validation of the claimed mechanisms and effectiveness of different condensation approaches
- Specific implementation details for objective functions and formulations are not provided for each method
- Exact preprocessing steps and hyperparameter settings for benchmark datasets are not specified

## Confidence

- **High Confidence**: The taxonomy classification (graph-guided, model-guided, hybrid) is well-grounded in the surveyed literature and provides a logical framework for understanding condensation objectives
- **Medium Confidence**: The mechanism descriptions are theoretically sound but lack empirical validation; claims about computational efficiency and information preservation are supported by analysis but not by independent experimental results
- **Low Confidence**: The comparative analysis of formulation strategies (modification vs. synthetic) relies heavily on the survey's own assertions rather than empirical evidence from the literature

## Next Checks

1. **Empirical Benchmark Study**: Conduct a systematic comparison of condensation methods across multiple graph datasets and downstream tasks to validate the effectiveness claims and identify which formulations work best under which conditions
2. **Convergence Analysis**: Test the synthetic formulation approach on graphs of varying sizes to determine the parameter space limits where optimization remains tractable and effective
3. **Generalization Study**: Evaluate condensed graphs across different GNN architectures to assess whether model-guided condensation truly preserves task-specific information or overfits to specific model types