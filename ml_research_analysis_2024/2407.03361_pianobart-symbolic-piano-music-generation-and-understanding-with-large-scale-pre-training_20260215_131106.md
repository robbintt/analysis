---
ver: rpa2
title: 'PianoBART: Symbolic Piano Music Generation and Understanding with Large-Scale
  Pre-Training'
arxiv_id: '2407.03361'
source_url: https://arxiv.org/abs/2407.03361
tags: []
core_contribution: This paper introduces PianoBART, a pre-trained model based on BART
  that performs symbolic piano music generation and understanding. It addresses the
  challenge of generating and understanding music by learning musical structures and
  patterns.
---

# PianoBART: Symbolic Piano Music Generation and Understanding with Large-Scale Pre-Training

## Quick Facts
- arXiv ID: 2407.03361
- Source URL: https://arxiv.org/abs/2407.03361
- Reference count: 31
- Primary result: Pre-trained BART model achieves state-of-the-art performance on symbolic piano music generation and understanding tasks including music continuation, velocity prediction, melody extraction, emotion classification, and composer classification

## Executive Summary
PianoBART introduces a pre-trained model based on BART that performs both symbolic piano music generation and understanding. The model addresses the challenge of generating and understanding music by learning musical structures and patterns through a novel multi-level object selection strategy during pre-training. PianoBART uses Octuple encoding to represent MIDI data compactly and is pre-trained on a large dataset of piano MIDI files, then fine-tuned for various music generation and understanding tasks. Experimental results demonstrate that PianoBART achieves outstanding performance across multiple tasks, outperforming baseline models in generating high-quality, coherent music pieces and comprehending music.

## Method Summary
PianoBART is a BART-based encoder-decoder architecture that uses Octuple encoding to convert MIDI files into sequences of 8 musical elements per token (TS, BPM, bar, position, instrument, pitch, duration, velocity). The model is pre-trained using BART's denoising objective with five transformations (token masking, deletion, infilling, sentence permutation, document rotation) combined with a multi-level object selection strategy that prevents information leakage or loss. This strategy dynamically chooses different time spans (Octuple, Bar, n-Bar levels) and object granularities (Element vs Token) during pre-training. The pre-trained model is then fine-tuned on downstream tasks including music continuation, velocity prediction, melody extraction, emotion classification, and composer classification.

## Key Results
- Achieves state-of-the-art performance on music continuation tasks with superior pitch and rhythmic structure preservation
- Demonstrates high accuracy on velocity prediction (94.3%), melody extraction (92.1%), emotion classification (81.5%), and composer classification (89.2%) tasks
- Outperforms baseline models including MGG, MGEN, and MusicBERT on all tested tasks
- Shows strong generalization ability across different musical styles and composers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The multi-level object selection strategy prevents information leakage and loss during pre-training.
- Mechanism: By dynamically choosing different time spans (Octuple, Bar, n-Bar levels) and object granularities (Element vs Token), the strategy avoids over-corrupting or under-corrupting musical patterns, which helps the model learn deeper structural relationships.
- Core assumption: Musical patterns in piano music have varying repetition scales that can be captured by flexible time spans.
- Evidence anchors:
  - [abstract]: "We devise a multi-level object selection strategy for different pre-training tasks of PianoBART, which can prevent information leakage or loss and enhance learning ability."
  - [section]: "The n-Bar Level method... can effectively prevent information loss and avoid information leakage. Furthermore, the dynamic selection range helps the model to learn more structural relations in music like intra-bar and inter-bar connections."
- Break condition: If the duration-based span selection in n-Bar Level does not reflect actual musical phrase boundaries, it could still mask too much or too little.

### Mechanism 2
- Claim: Pre-training with BART's denoising objective improves both generation and understanding by learning bidirectional context.
- Mechanism: BART's encoder-decoder structure reconstructs corrupted sequences, forcing the model to capture full musical context in both directions, unlike unidirectional or purely masked language models.
- Core assumption: Symbolic music generation benefits from bidirectional context understanding combined with autoregressive decoding.
- Evidence anchors:
  - [abstract]: "PianoBART, a pre-trained model that uses BART for both symbolic piano music generation and understanding."
  - [section]: "Unlike BERT-based pre-trained models, PianoBART uses an encoder-decoder structure that allows it to be applied for sequence-to-sequence task, thus handling both generation and comprehension."
- Break condition: If the corruption transformations are too destructive, reconstruction may fail and harm downstream fine-tuning.

### Mechanism 3
- Claim: Octuple encoding reduces sequence length while preserving musical semantics, enabling efficient long-term learning.
- Mechanism: Encoding each note into 8 musical elements (pitch, duration, velocity, etc.) compresses the sequence and allows parallel processing of elements, supporting full-song understanding and long continuation tasks.
- Core assumption: All musical information needed for generation/understanding can be represented within the 8-element octuple without loss of expressive detail.
- Evidence anchors:
  - [abstract]: "We adopt the compact Octuple encoding... It can efficiently and comprehensively represent music and greatly reduce the sequence length."
  - [section]: "Each octuple token corresponds to a note and contains 8 musical elements... The embeddings of the 8 elements in each token are concatenated together and then linear projected to the embedding token."
- Break condition: If certain musical nuances (e.g., expressive timing) are not captured in the 8 elements, the model may miss important context.

## Foundational Learning

- Concept: Transformer self-attention mechanism
  - Why needed here: Enables modeling of long-range dependencies in symbolic music sequences, essential for capturing repeated patterns and musical structure.
  - Quick check question: How does multi-head attention allow the model to attend to different musical aspects (e.g., rhythm vs harmony) simultaneously?

- Concept: Tokenization and sequence representation
  - Why needed here: Converting MIDI into octuple tokens determines what the model "sees" as input; poor tokenization would break learning.
  - Quick check question: What musical information is lost if velocity or duration is omitted from the octuple encoding?

- Concept: Pre-training vs fine-tuning distinction
  - Why needed here: PianoBART is first pre-trained on large unlabeled data, then fine-tuned on task-specific labeled data; understanding this pipeline is key to reproducing results.
  - Quick check question: Why does pre-training on unlabeled data help when downstream tasks have limited labels?

## Architecture Onboarding

- Component map:
  MIDI -> Octuple tokens (8 elements per token) -> BART encoder (bidirectional) -> BART decoder (autoregressive) -> Linear projections per element or pooled decoder state -> Output tokens

- Critical path:
  1. Tokenize MIDI into octuple sequence
  2. Apply one of five BART transformations with multi-level object selection
  3. Encoder processes corrupted input bidirectionally
  4. Decoder reconstructs original sequence autoregressively
  5. Compute cross-entropy loss against original sequence

- Design tradeoffs:
  - Octuple encoding reduces sequence length but may compress expressive details
  - Multi-level object selection adds complexity but prevents leakage/loss
  - BART's larger parameter count (225M) vs BERT-based models increases compute cost but improves generation capability

- Failure signatures:
  - Low pre-training reconstruction accuracy (<90%) indicates destructive corruption or poor encoding
  - Poor fine-tuning performance despite high pre-training accuracy suggests task-data mismatch
  - GPU OOM errors likely due to max sequence length 1024 octuple tokens (check batch size)

- First 3 experiments:
  1. Verify octuple tokenization produces correct sequence length and element counts on a small MIDI file
  2. Run pre-training for 1 epoch and check reconstruction accuracy on held-out batch
  3. Fine-tune on velocity prediction task and verify classification accuracy >50% on validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed multi-level object selection strategy compare to other strategies in terms of preventing information leakage and loss during pre-training?
- Basis in paper: [explicit] The paper mentions that the proposed strategy is designed to prevent information leakage and loss, but it does not provide a detailed comparison with other strategies.
- Why unresolved: The paper does not provide a comprehensive comparison of the proposed strategy with other existing strategies in the literature.
- What evidence would resolve it: A detailed comparison of the proposed strategy with other strategies in terms of preventing information leakage and loss during pre-training, along with experimental results, would resolve this question.

### Open Question 2
- Question: How does the performance of PianoBART vary with different pre-training tasks and transformations?
- Basis in paper: [explicit] The paper mentions that PianoBART uses various pre-training tasks and transformations, but it does not provide a detailed analysis of how the performance varies with different combinations.
- Why unresolved: The paper does not provide a comprehensive analysis of the impact of different pre-training tasks and transformations on the performance of PianoBART.
- What evidence would resolve it: A detailed analysis of the performance of PianoBART with different pre-training tasks and transformations, along with experimental results, would resolve this question.

### Open Question 3
- Question: How does the proposed multi-level object selection strategy affect the model's ability to capture underlying musical patterns?
- Basis in paper: [explicit] The paper mentions that the proposed strategy is designed to enhance the model's learning ability and prevent information leakage or loss, but it does not provide a detailed analysis of its impact on capturing musical patterns.
- Why unresolved: The paper does not provide a comprehensive analysis of the impact of the proposed strategy on the model's ability to capture underlying musical patterns.
- What evidence would resolve it: A detailed analysis of the impact of the proposed strategy on the model's ability to capture underlying musical patterns, along with experimental results, would resolve this question.

## Limitations

- The paper lacks precise specification of how the n-Bar Level object selection (Equation 1) samples the random duration threshold m, making it difficult to reproduce the exact masking strategy
- While PianoBART achieves high performance, the pre-training uses a fixed dataset of 4166 MIDI pieces which may not fully represent the diversity of piano music
- The 225M parameter model with 1024 token sequence length requires significant GPU memory, and computational efficiency considerations are not discussed

## Confidence

- **High confidence** in the core architectural approach: The use of BART's encoder-decoder structure for symbolic music is well-established, and the Octuple encoding scheme is clearly specified with 8 musical elements per token.
- **Medium confidence** in the multi-level object selection strategy: While the paper provides theoretical justification and experimental results, the lack of detailed implementation specifications makes it difficult to verify whether the claimed benefits are fully reproducible.
- **Low confidence** in generalization claims: The paper demonstrates strong performance on the tested datasets but does not provide evidence for cross-dataset generalization or performance on out-of-distribution music styles.

## Next Checks

1. **Reconstruction accuracy validation**: Pre-train PianoBART for 1 epoch on a small subset of the data and verify that reconstruction accuracy exceeds 90% on held-out validation sequences, confirming the denoising objective is learnable.

2. **Generation quality assessment**: Fine-tune on music continuation task and generate 10 continuation sequences, then compute human evaluation scores for coherence and musicality to complement the automated PFS, PCHE, and GS metrics.

3. **Cross-dataset robustness**: Test the pre-trained model on a held-out dataset (e.g., a subset of EMOPIA not used in pre-training) for velocity prediction and melody extraction tasks to assess generalization beyond the training distribution.