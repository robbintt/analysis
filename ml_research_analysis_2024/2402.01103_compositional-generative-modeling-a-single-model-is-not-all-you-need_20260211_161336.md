---
ver: rpa2
title: 'Compositional Generative Modeling: A Single Model is Not All You Need'
arxiv_id: '2402.01103'
source_url: https://arxiv.org/abs/2402.01103
tags:
- generative
- distribution
- compositional
- arxiv
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper argues for constructing complex generative systems by
  composing simpler models, rather than relying on increasingly large monolithic models.
  The authors demonstrate that compositional approaches enable more data-efficient
  learning, generalization to unseen data distributions, and the ability to construct
  new generative models for unseen tasks through probability composition.
---

# Compositional Generative Modeling: A Single Model is Not All You Need

## Quick Facts
- **arXiv ID**: 2402.01103
- **Source URL**: https://arxiv.org/abs/2402.01103
- **Reference count**: 29
- **Primary result**: Compositional generative modeling achieves better data efficiency and generalization by composing simpler models rather than using monolithic approaches

## Executive Summary
This paper presents a framework for constructing complex generative models by composing simpler components rather than relying on increasingly large monolithic models. The authors demonstrate that compositional approaches enable more data-efficient learning, generalization to unseen data distributions, and the ability to construct new generative models for unseen tasks through probability composition. They show that compositional components can be discovered from data in an unsupervised manner. Experiments across trajectory modeling, visual synthesis, and planning tasks show that compositional methods achieve better performance with limited data compared to monolithic models. The paper also discusses challenges in sampling from compositional distributions and presents practical implementations using energy-based models and diffusion models.

## Method Summary
The authors propose factorizing complex generative models into products or mixtures of simpler distributions, which can be learned more efficiently and composed to create new generative capabilities. They implement this using energy-based models (EBMs) and diffusion models, showing how these can be composed through energy addition or other operations. The framework includes methods for discovering compositional structure from data, training individual components, and sampling from composed distributions using techniques like annealed importance sampling and Langevin dynamics. The approach is validated across multiple domains including trajectory modeling, visual synthesis, and planning tasks.

## Key Results
- Compositional generative modeling enables data-efficient learning by factorizing complex distributions into simpler components
- The approach generalizes to unseen data distributions by ensuring each component remains in-distribution
- Discovered compositional components can be recombined to create new generative models for tasks completely unseen at training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Compositional generative modeling enables more data-efficient learning by factorizing complex distributions into simpler components
- Mechanism: When learning a joint distribution over multiple variables, data requirements grow exponentially with the number of variables. By factorizing the distribution into independent components (e.g., p(A)p(B)p(C,D)), each component requires only polynomial data, and the full distribution can be reconstructed through composition
- Core assumption: The underlying data distribution exhibits independence structure that can be exploited through factorization
- Evidence anchors:
  - [abstract] "we show how such a compositional generative approach enables us to learn distributions in a more data-efficient manner"
  - [section 2] "the data required to learn distributions over a joint set of variables generally increases exponentially... Constructing large multimodal generative models... falls into the same difficulty"
  - [corpus] Weak evidence - no direct supporting papers found in corpus

### Mechanism 2
- Claim: Compositional models can generalize to unseen data distributions by ensuring each component remains in-distribution
- Mechanism: When a distribution is factorized, the compositional model can handle combinations of factors that were not seen during training, as long as each individual factor was observed. This enables generalization to new combinations of concepts or scenarios
- Core assumption: Local factors in the factorization remain in-distribution even when their combinations are novel
- Evidence anchors:
  - [abstract] "enabling generalization to parts of the data distribution unseen at training time"
  - [section 2] "Even in settings where distributions are not accurately modeled as a product of independent factors, such a factorization can still lead to better models given limited data"
  - [corpus] Weak evidence - no direct supporting papers found in corpus

### Mechanism 3
- Claim: Discovered compositional components can be recombined to create new generative models for unseen tasks
- Mechanism: Components discovered from data (e.g., object representations) can be treated as building blocks that can be combined in novel ways to construct generative models for tasks not seen during training, enabling zero-shot generalization
- Core assumption: Discovered components capture meaningful, reusable structure from the data that generalizes across tasks
- Evidence anchors:
  - [abstract] "we can discover separate compositional components from data... construct new generative models for tasks completely unseen at training"
  - [section 4] "discovered components... can be multiplied together to form new scenes with a hybrid composition of objects"
  - [corpus] Weak evidence - no direct supporting papers found in corpus

## Foundational Learning

- Concept: Probability factorization and independence
  - Why needed here: The core thesis relies on understanding how joint probability distributions can be decomposed into products of simpler distributions, and when such factorization is valid
  - Quick check question: Given p(X,Y) = p(X)p(Y|X), when can we simplify this to p(X,Y) = p(X)p(Y)? What assumption must hold?

- Concept: Energy-based models and MCMC sampling
  - Why needed here: The paper proposes using energy-based models to represent composed distributions, requiring understanding of how to sample from unnormalized distributions using MCMC methods
  - Quick check question: How does the energy function E(x) relate to the probability density p(x)? What is the computational challenge in normalizing this?

- Concept: Diffusion models as sequential EBMs
  - Why needed here: The paper leverages the connection between diffusion models and EBMs to implement compositional sampling, requiring understanding of how denoising functions at different noise levels can be interpreted as energy functions
  - Quick check question: In a diffusion model, what does the denoising function ϵ(x,t) represent at a fixed noise level t? How does this relate to the gradient of an energy function?

## Architecture Onboarding

- Component map: Data → Individual model training → Composition operation → Sampling procedure → Generated output
- Critical path: Data → Individual model training → Composition operation → Sampling procedure → Generated output
- Design tradeoffs:
  - Using EBMs enables direct composition through energy addition but requires MCMC sampling which can be slow
  - Using diffusion models enables more efficient sampling but requires careful implementation of composition through the EBM interpretation
  - Discovered components enable zero-shot generalization but may capture spurious correlations
- Failure signatures:
  - Poor generation quality indicates incorrect composition operation or inadequate sampling
  - Mode collapse suggests components are too correlated or composition weights are incorrect
  - Slow sampling indicates inefficient MCMC or need for better initialization strategies
- First 3 experiments:
  1. Implement product composition of two simple 2D Gaussian EBMs - verify that samples follow the product distribution
  2. Train two separate generative models on different factors of a synthetic dataset, then compose them and compare sample quality to a monolithic model trained on the full distribution
  3. Implement compositional sampling using diffusion models by adding score functions at different noise levels, then verify samples follow the composed distribution using likelihood estimates

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical characterization of compositional generalization in generative modeling, and how does it compare to existing theoretical work on additive models?
- Basis in paper: [explicit] The authors state "it would be interesting to theoretically characterize compositional generalization in such systems as well as alternative approaches to improve such generalization. Past theoretical work has characterized compositional generalization in additive models (Wiedemer et al., 2024; Lachapelle et al., 2024), and it would be interesting to extend such analysis to compositional generative modeling."
- Why unresolved: The paper identifies this as an open direction but does not provide theoretical analysis or characterization of compositional generalization in generative modeling.
- What evidence would resolve it: Formal theoretical proofs showing conditions under which compositional generative models generalize better than monolithic models, and comparison with additive model theory.

### Open Question 2
- Question: How can we automatically discover the correct compositional structure between models and the appropriate per-model weighting for new tasks?
- Basis in paper: [explicit] The authors state "the current work on compositional modeling assumes a fixed prespecified structure through which models are composed, limiting generalization to new distributions. To flexibly apply compositional models across new tasks, it would be important to construct systems that can instead automatically discover the correct compositional structure between models as well as the appropriate per-model weighting."
- Why unresolved: Current approaches require manual specification of compositional structure, which limits their flexibility and practical application to novel tasks.
- What evidence would resolve it: Algorithms that can automatically infer compositional structure from data without prior knowledge, validated on multiple datasets and task types.

### Open Question 3
- Question: How can compositional generative modeling be made more robust to spurious correlations in real-world data that violate independence assumptions?
- Basis in paper: [inferred] The authors note "current work on discovering compositional structure assumes that data is naturally factorized into an independent product of components. In many real-world settings, gathered data will often exhibit spurious correlations that violate such independence assumptions, causing existing algorithms to fail to discover the correct structure."
- Why unresolved: Real-world data often contains complex dependencies and spurious correlations that existing compositional methods cannot handle, limiting their practical applicability.
- What evidence would resolve it: Methods that can identify and handle spurious correlations, validated on datasets with known spurious correlations and demonstrated robustness to real-world data.

## Limitations

- The paper's empirical claims lack extensive validation on real-world, large-scale datasets
- The sampling efficiency claims need more rigorous benchmarking, particularly regarding trade-offs between composition quality and computational cost
- The unsupervised discovery of compositional components remains a theoretical proposition without comprehensive empirical validation

## Confidence

- **High confidence**: The theoretical framework for compositional generative modeling is sound, and the mathematical derivations are correct
- **Medium confidence**: The experimental results on synthetic datasets demonstrate the proposed approach's effectiveness
- **Low confidence**: Claims about zero-shot generalization and unsupervised component discovery require more extensive validation on diverse real-world datasets

## Next Checks

1. **Scaling test**: Evaluate compositional performance on larger-scale datasets (e.g., full ImageNet) and compare against state-of-the-art monolithic generative models in terms of both quality and computational efficiency

2. **Factorization analysis**: Systematically investigate when and why compositional factorization succeeds or fails by testing on datasets with varying degrees of conditional independence and measuring the impact on generation quality

3. **Zero-shot generalization benchmark**: Design a comprehensive benchmark to test the claimed zero-shot generalization capabilities by training compositional models on subsets of compositional factors and evaluating their ability to generate novel combinations not seen during training