---
ver: rpa2
title: Searching, fast and slow, through product catalogs
arxiv_id: '2401.00737'
source_url: https://arxiv.org/abs/2401.00737
tags:
- search
- section
- product
- tf-idf
- more
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a unified architecture for SKU search in CRM
  systems that combines real-time dynamic suggestions with a lower-latency search
  system. The core idea is to use a Trie data structure for instant suggestions as
  users type, while employing character-level TF-IDF combined with language model
  embeddings for more accurate results when users initiate a search explicitly.
---

# Searching, fast and slow, through product catalogs

## Quick Facts
- arXiv ID: 2401.00737
- Source URL: https://arxiv.org/abs/2401.00737
- Reference count: 19
- Primary result: Multi-component SKU search system achieves 84.63% accuracy with 269.88ms latency, outperforming Dynamics CRM default search

## Executive Summary
This paper presents a unified architecture for SKU search in CRM systems that combines real-time dynamic suggestions with a lower-latency search system. The core idea is to use a Trie data structure for instant suggestions as users type, while employing character-level TF-IDF combined with language model embeddings for more accurate results when users initiate a search explicitly. The authors demonstrate that this multi-component approach significantly outperforms the default search engine in Dynamics CRM, addressing issues of "zero search results" and "too many results".

## Method Summary
The system uses a Trie-based dynamic suggestion component (70.82% accuracy, 22.7ms latency) for real-time prefix matching, and a user-initiated search pipeline combining character-level TF-IDF, LLM embeddings, and LCS reranking (84.63% accuracy, 269.88ms latency). SKU descriptions are enhanced using GPT-3.5-turbo for better user context. The approach specifically addresses the challenges of searching abbreviated SKU names in CRM systems, where traditional word-level methods fail due to high abbreviation density.

## Key Results
- 84.63% accuracy with 269.88ms latency for user-initiated searches
- 70.82% accuracy with 22.7ms latency for real-time suggestions
- Outperforms Dynamics CRM default search, reducing "zero search results" and "too many results" issues
- Successfully processes 228,000 SKU variants while maintaining sub-300ms response times

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Character-level TF-IDF outperforms word-level TF-IDF for SKU search because SKUs contain abbreviations and short, non-standard strings.
- Mechanism: TF-IDF computes term importance by weighting frequency inversely by document frequency. At character level, it captures patterns in abbreviations that word-level methods miss.
- Core assumption: SKU strings are too fragmented for meaningful word tokenization; abbreviations are more reliably detected at character granularity.
- Evidence anchors:
  - [section] "As already discussed in Section 6.2 and Table 1, the performance of the word-level TF-IDF is very poor with an accuracy of only about ≈ 54%."
  - [abstract] "making use of character level TF-IDF in combination with language model vector embeddings"

### Mechanism 2
- Claim: Trie-based dynamic suggestions provide low-latency prefix matching, while user-initiated search with TF-IDF+LLM offers higher accuracy for full queries.
- Mechanism: Trie stores all SKU names; each keystroke narrows candidate set linearly. For full queries, TF-IDF captures character patterns, LLM captures semantic similarity, and LCS reranking ensures best match to original query.
- Core assumption: Users need both real-time feedback (Trie) and precise results (TF-IDF+LLM) at different stages of typing.
- Evidence anchors:
  - [section] "Dynamic search offers rapid feedback allowing users to refine their queries on the fly."
  - [abstract] "that provides both a real-time suggestion system (based on a Trie data structure) as well as a lower latency search system"

### Mechanism 3
- Claim: GPT-3.5-turbo-generated descriptions improve seller comprehension and decision speed without affecting search accuracy.
- Mechanism: Zero-shot prompt engineering transforms cryptic SKU names into human-readable English summaries. Parallel API calls mitigate high per-request latency.
- Core assumption: Sellers benefit from natural language context when evaluating search results, even if search itself uses abbreviations.
- Evidence anchors:
  - [section] "Using low-temperature-settings to further improve responses, we make another API request to summarize the description in a maximum of 250 characters."
  - [abstract] "we show how SKU descriptions may be enhanced via generative text models (using gpt-3.5-turbo)"

## Foundational Learning

- Concept: Trie data structure
  - Why needed here: Enables O(length of query) lookup for prefix matching, critical for sub-300ms dynamic suggestions on ~228k SKU variants.
  - Quick check question: What is the worst-case time complexity of retrieving all strings with a given prefix in a Trie?

- Concept: TF-IDF weighting
  - Why needed here: Character-level TF-IDF distinguishes rare abbreviation patterns from common ones, improving relevance ranking over raw cosine similarity.
  - Quick check question: How does IDF term weighting affect similarity scores when the query contains rare SKU substrings?

- Concept: LLM embedding similarity
  - Why needed here: Captures semantic similarity for longer, more structured queries that TF-IDF alone cannot resolve (e.g., paraphrased product names).
  - Quick check question: Why might multi-qa-MiniLM-L6-cos-v1 outperform msmarco-distilbert-base-v4 for short SKU queries?

## Architecture Onboarding

- Component map:
  Pattern matcher -> Trie -> spell check -> TF-IDF -> LLM -> LCS rerank -> results

- Critical path: Query → pattern matcher → Trie → spell check → TF-IDF → LLM → LCS rerank → results
- Design tradeoffs:
  - Trie size vs. latency: larger Trie = slower but more matches
  - Embedding dimension vs. latency: higher dims improve accuracy but slow scoring
  - GPT batch size vs. total processing time: more parallelism = faster catalog generation but higher API quota usage

- Failure signatures:
  - Zero results → Trie not populated or pattern matcher missed edge cases
  - Too many results → TF-IDF/LLM thresholds too low, LCS rerank ineffective
  - High latency → embedding dimension too large, LLM embedding model too heavy, GPT API throttling

- First 3 experiments:
  1. Measure Trie lookup time for random prefixes of lengths 1-5; verify sub-30ms target.
  2. Compare character-level TF-IDF accuracy with and without spell check on a held-out query set.
  3. Test LLM vs. TF-IDF-only accuracy on long vs. short queries to quantify complementary performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would fine-tuning language models on CRM-specific data impact search accuracy compared to using pre-trained models?
- Basis in paper: [explicit] The paper mentions "In future work, we intend to investigate possible lift in performance by fine-tuning the language models instead of relying on their pre-trained versions."
- Why unresolved: The paper only mentions this as a future direction without providing experimental results comparing fine-tuned versus pre-trained models.
- What evidence would resolve it: A controlled experiment comparing search accuracy with pre-trained versus fine-tuned language models on the same CRM dataset would provide definitive evidence.

### Open Question 2
- Question: Can a semantic abbreviation embedding model be developed that captures semantic similarity at the abbreviation level rather than word/sentence level?
- Basis in paper: [explicit] The authors state "we intend to develop our own semantic abbreviation embeddings specifically trained on abbreviations so we can capture some semantic similarity, not at the word / sentence level but rather at the abbreviation level."
- Why unresolved: This is explicitly stated as future work without implementation or results presented.
- What evidence would resolve it: Development and evaluation of such an abbreviation-specific embedding model on CRM SKU data, with quantitative comparison to existing embedding approaches.

### Open Question 3
- Question: What is the impact of expanding abbreviations on search accuracy across different types of CRM queries?
- Basis in paper: [explicit] The paper discusses their abbreviation expansion strategy but notes "We reserve a more systematic treatment of abbreviation expansion and discovery to a future extension of the model."
- Why unresolved: The paper presents their expansion approach but doesn't provide comprehensive evaluation of how this impacts different query types or overall search performance.
- What evidence would resolve it: A detailed ablation study showing search accuracy with and without abbreviation expansion across various query categories (e.g., partial abbreviations, complete abbreviations, non-abbreviated queries).

## Limitations

- Performance depends heavily on specific SKU dataset characteristics with high abbreviation density
- 84.63% accuracy measured only on 513 manually labeled queries that previously returned zero results
- Memory requirements (50MB for Trie) and latency constraints may not scale to catalogs orders of magnitude larger
- GPT-3.5-turbo processing time (120 minutes for entire catalog) may be impractical for frequent updates

## Confidence

- **High Confidence**: The Trie-based dynamic suggestion mechanism and character-level TF-IDF approach are well-established techniques with clear performance benefits demonstrated in the results.
- **Medium Confidence**: The integration of LLM embeddings with TF-IDF shows complementary performance gains, though the specific choice of multi-qa-MiniLM-L6-cos-v1 and its optimal threshold (0.4) may not generalize across domains.
- **Medium Confidence**: GPT-3.5-turbo description enhancement improves user experience, but the 120-minute processing time for the entire catalog and reliance on parallel API calls may not be practical for all deployment scenarios.

## Next Checks

1. **Dataset Generalization Test**: Evaluate the complete system on a different SKU dataset (e.g., automotive parts or electronics components) with varying abbreviation patterns and catalog sizes to assess cross-domain performance degradation.

2. **Latency Scaling Analysis**: Measure end-to-end latency and memory usage when scaling from 228k to 2M+ SKUs, identifying the exact thresholds where the Trie or embedding similarity scoring becomes bottlenecks.

3. **User Experience Validation**: Conduct A/B testing with actual CRM users comparing the multi-component system against baseline search, measuring not just accuracy but task completion time and user satisfaction across different query types (abbreviated vs. natural language).