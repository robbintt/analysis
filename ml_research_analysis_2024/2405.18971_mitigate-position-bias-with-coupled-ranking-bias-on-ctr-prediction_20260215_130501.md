---
ver: rpa2
title: Mitigate Position Bias with Coupled Ranking Bias on CTR Prediction
arxiv_id: '2405.18971'
source_url: https://arxiv.org/abs/2405.18971
tags:
- position
- bias
- ranking
- gradient
- estimation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the overestimation of position gradient in
  CTR prediction caused by coupled ranking bias and position bias. The authors propose
  a novel gradient interpolation method that fuses a conventional position-aware model
  with a position-unaware model using an adaptive weight to suppress the overestimation.
---

# Mitigate Position Bias with Coupled Ranking Bias on CTR Prediction

## Quick Facts
- arXiv ID: 2405.18971
- Source URL: https://arxiv.org/abs/2405.18971
- Authors: Yao Zhao; Zhining Liu; Tianchi Cai; Haipeng Zhang; Chenyi Zhuang; Jinjie Gu
- Reference count: 37
- Primary result: Novel gradient interpolation method mitigates position bias overestimation in CTR prediction, achieving 3.43% and 2.69% CTR improvements in online A/B tests.

## Executive Summary
This paper addresses the critical challenge of position bias overestimation in CTR prediction caused by the coupled effects of position bias and ranking bias. The authors propose a novel gradient interpolation method that fuses position-aware and position-unaware models using an adaptive weight to suppress overestimation. The optimal weight is determined by minimizing the gap between fused CTR and ground-truth CTR using a small set of random ranking samples. Experiments on both synthetic and industrial datasets demonstrate consistent improvements in AUC and significant CTR gains in online A/B tests.

## Method Summary
The proposed method uses gradient interpolation to fuse a position-aware model (with position features) and a position-unaware model (without position features) using an adaptive weight. The optimal fusing weight is determined by minimizing the difference between the fused model's predictions and ground-truth position bias estimated from a small set of random ranking samples. To improve computational efficiency, the authors introduce a randomization trick that randomly assigns random position features to a proportion of samples during training, equivalent to model fusion but with lower computational cost. The method is implemented using a transformer backbone with MLP layers, trained with L2 regularization and Adam optimizer.

## Key Results
- The gradient interpolation method achieves consistent AUC improvements over baseline methods on both synthetic and industrial datasets
- Online A/B tests show significant CTR increases of 3.43% and 2.69% in two industrial recommendation tasks
- The proposed method reduces position bias estimation error compared to existing approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gradient interpolation suppresses overestimation by fusing a position-aware model with a position-unaware model using an adaptive weight.
- Mechanism: The position-aware model overestimates the position gradient due to coupled ranking bias, while the position-unaware model underestimates it. Interpolation balances these effects.
- Core assumption: The overestimation and underestimation effects are linear and can be balanced through weighted interpolation.
- Evidence anchors: Abstract states the method "fuses two estimation methods using a fusing weight" to overcome overestimation.

### Mechanism 2
- Claim: Optimal fusing weight determined using a small set of random ranking samples without laborious grid search.
- Mechanism: Random ranking eliminates ranking bias, allowing ground-truth position bias estimation. The optimal weight minimizes the gap between fused and ground-truth predictions.
- Core assumption: A small unbiased validation set is available and representative enough for accurate ground-truth position bias estimation.
- Evidence anchors: Abstract mentions "adaptive method to automatically determine the optimal fusing weight" using random ranking samples.

### Mechanism 3
- Claim: Randomization trick accelerates computation by using sample fusion instead of model fusion.
- Mechanism: Instead of maintaining two separate models, random position features are assigned to a proportion of samples equal to the fusing weight during training.
- Core assumption: Sample fusion strategy is mathematically equivalent to weighted model fusion.
- Evidence anchors: Section describes using "an equivalent sample fusion strategy" to improve computation efficiency.

## Foundational Learning

- Concept: Position Bias
  - Why needed here: Position bias affects user interaction with recommended items based on their position, which is the core problem this paper addresses.
  - Quick check question: What is position bias and how does it affect user interaction with recommended items?

- Concept: Ranking Bias
  - Why needed here: Ranking bias causes higher-ranked items to have higher CTRs, complicating accurate position bias estimation when both biases are coupled.
  - Quick check question: How does ranking bias differ from position bias, and why is their coexistence problematic for CTR prediction?

- Concept: Gradient Interpolation
  - Why needed here: Gradient interpolation is the proposed method to mitigate overestimation of position gradient caused by coupled biases.
  - Quick check question: Explain how gradient interpolation works to suppress overestimation of position gradient.

## Architecture Onboarding

- Component map: Data -> Transformer Backbone -> MLP -> CTR Prediction (position-aware and position-unaware variants)
- Critical path: Data collection → Model training (position-aware and position-unaware) → Random ranking sample collection → Optimal weight calculation → Model serving with randomization trick
- Design tradeoffs: Accuracy vs. computational efficiency - maintaining two models vs. using randomization trick
- Failure signatures: Overestimation of position gradient (high AUC but poor unbiased test performance), underestimation of position gradient (low AUC), unstable weight calculation (fluctuating performance)
- First 3 experiments:
  1. Verify position-aware model overestimates position gradient on unbiased test set compared to ground-truth position bias
  2. Implement randomization trick and confirm similar performance to explicit model fusion with calculated optimal weight
  3. Test sensitivity to random ranking sample set size used for weight calculation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the optimal weight for gradient interpolation be determined without relying on random ranking samples?
- Basis in paper: Authors mention planning future work to determine the hyperparameter weight without random ranking samples.
- Why unresolved: Current method requires random ranking samples, which may be impractical in real-world scenarios due to user experience concerns.
- What evidence would resolve it: A novel method that accurately estimates optimal weight without requiring random ranking samples.

### Open Question 2
- Question: How does the proposed method perform in scenarios with multiple types of biases beyond position and ranking biases?
- Basis in paper: Authors mention synthetic datasets are ideal for modeling position bias and ranking bias, but don't explore other bias types.
- Why unresolved: Experiments focus on position and ranking biases, leaving performance in more complex scenarios unexplored.
- What evidence would resolve it: Experiments demonstrating effectiveness in scenarios with multiple bias types.

### Open Question 3
- Question: How does the randomization trick impact the accuracy of gradient interpolation results?
- Basis in paper: Authors propose randomization trick to improve computation efficiency but don't explore its impact on accuracy.
- Why unresolved: Impact on accuracy is unexplored, and it's unclear whether this approach introduces additional biases or errors.
- What evidence would resolve it: Experiments comparing accuracy with and without randomization trick, plus analysis of potential biases or errors introduced.

## Limitations

- The method assumes a small set of random ranking samples can provide accurate ground-truth position bias estimates, which may be expensive or impractical to collect in real-world scenarios
- The effectiveness relies on the linear relationship between position-aware and position-unaware model outputs, which may not hold in all scenarios with complex feature interactions
- The claim that the method works "regardless of the existence of the ranking bias" is not thoroughly validated across different bias scenarios

## Confidence

- **High Confidence**: Experimental results showing consistent AUC improvements and online CTR increases are well-supported by data presented
- **Medium Confidence**: Computational efficiency claims through randomization trick are plausible but lack direct comparison metrics against explicit model fusion
- **Low Confidence**: Assertion that the method works "regardless of the existence of the ranking bias" is not thoroughly validated across different bias scenarios

## Next Checks

1. Test the method's sensitivity to random ranking sample set size - evaluate performance degradation as unbiased validation set shrinks from 5% to 0.1% of training data
2. Validate randomization trick's computational claims by implementing both sample fusion and explicit model fusion approaches, measuring training and inference time differences
3. Conduct experiments with synthetic datasets where the relationship between position-aware and position-unaware model outputs is explicitly non-linear to test method's robustness to assumption violations