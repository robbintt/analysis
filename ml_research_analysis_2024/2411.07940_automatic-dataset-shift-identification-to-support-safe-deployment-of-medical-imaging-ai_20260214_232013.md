---
ver: rpa2
title: Automatic dataset shift identification to support safe deployment of medical
  imaging AI
arxiv_id: '2411.07940'
source_url: https://arxiv.org/abs/2411.07940
tags:
- shift
- test
- shifts
- prevalence
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of identifying the root causes
  of dataset shifts in medical imaging AI models. While detecting the presence of
  shifts is important, knowing the specific type of shift (prevalence, covariate,
  or mixed) is critical for choosing the right mitigation strategy.
---

# Automatic dataset shift identification to support safe deployment of medical imaging AI

## Quick Facts
- arXiv ID: 2411.07940
- Source URL: https://arxiv.org/abs/2411.07940
- Authors: MÃ©lanie Roschewitz; Raghav Mehta; Charles Jones; Ben Glocker
- Reference count: 40
- Key outcome: First unsupervised framework for dataset shift identification in medical imaging, achieving 85-100% accuracy in distinguishing prevalence, covariate, and mixed shifts across three imaging modalities.

## Executive Summary
This paper addresses the critical problem of identifying the root causes of dataset shifts in medical imaging AI models, which is essential for safe deployment. While detecting the presence of shifts is important, knowing the specific type of shift (prevalence, covariate, or mixed) is critical for choosing the right mitigation strategy. The authors propose a novel two-stage unsupervised framework that combines model outputs and self-supervised encoder features to accurately detect and identify shift types. The framework is evaluated across three imaging modalities and five types of real-world shifts using large public datasets, demonstrating robust performance and highlighting the importance of using self-supervised encoders for detecting subtle covariate shifts.

## Method Summary
The proposed method is a two-stage unsupervised framework for dataset shift identification. The first stage involves shift detection using both model outputs (BBSD) and self-supervised encoder features (MMD test) combined in a dual approach. If a shift is detected, the second stage estimates the prevalence shift, adjusts the reference set accordingly, and compares feature distributions to determine if the shift is prevalence, covariate, or mixed. The framework leverages self-supervised encoders trained on ImageNet to extract rich feature representations that are sensitive to distribution changes orthogonal to the downstream task.

## Key Results
- The Duo detector (combining output-based and feature-based detection) performs best overall across shifts and datasets
- Self-supervised encoders yield substantially higher shift detection power than supervised counterparts for subtle shifts
- Output-based detection is optimal for prevalence shifts, while feature-based detection is essential for covariate shifts
- The framework accurately distinguishes between prevalence shifts, covariate shifts, and mixed shifts with high accuracy (85-100% depending on shift type and test set size)

## Why This Works (Mechanism)

### Mechanism 1
Self-supervised encoders are more effective than supervised encoders for detecting subtle covariate shifts because they learn richer, task-agnostic feature representations. These features capture general image characteristics and fine-grained details, making them sensitive to distribution changes orthogonal to the downstream task (like scanner or gender shifts), which supervised encoders may miss. Core assumption: Feature distributions extracted by self-supervised encoders change detectably under covariate shifts but remain stable under prevalence shifts.

### Mechanism 2
Output-based detectors are optimal for prevalence shifts because changes in label distribution directly affect model prediction scores. Prevalence shift changes the proportion of positive/negative cases in the test set, which alters the distribution of predicted probabilities output by the model. Statistical tests comparing these output distributions (e.g., Kolmogorov-Smirnov) can detect such shifts without needing ground truth labels. Core assumption: The model's predicted probabilities are well-calibrated and reflective of the true label distribution under prevalence shift.

### Mechanism 3
Combining output-based and feature-based detection yields robust identification of shift type because they capture complementary aspects of the data distribution. The framework first detects a shift using both output and feature-based signals. If a shift is detected, it estimates prevalence in the test set, adjusts the reference set accordingly, and compares feature distributions. If feature differences disappear after adjustment, the shift is prevalence-only; if they persist, covariate shift is present. Model output differences before and after adjustment distinguish mixed shifts. Core assumption: Prevalence and covariate shifts affect output and feature distributions in distinguishable patterns, and prevalence can be estimated accurately without labels.

## Foundational Learning

- **Concept: Distribution shift in machine learning**
  - Why needed here: The entire framework is built around detecting and identifying different types of distribution shifts (prevalence, covariate, mixed) that can degrade model performance in clinical settings.
  - Quick check question: What is the difference between prevalence shift and covariate shift, and how do they each affect model outputs and features?

- **Concept: Self-supervised learning and feature extraction**
  - Why needed here: Self-supervised encoders are used to extract feature representations for shift detection, and understanding how they learn without labels is crucial to appreciate their advantage over supervised encoders.
  - Quick check question: Why might features from a self-supervised encoder trained on ImageNet be more effective for detecting medical image shifts than features from a supervised encoder?

- **Concept: Statistical hypothesis testing for distribution comparison**
  - Why needed here: The shift detection methods rely on statistical tests (e.g., Kolmogorov-Smirnov, Maximum Mean Discrepancy) to compare distributions between reference and test sets without requiring labels.
  - Quick check question: How does the Maximum Mean Discrepancy (MMD) test work to detect differences between two distributions?

## Architecture Onboarding

- **Component map:** Input images -> Task model (ResNet-50) -> Output-based detector (BBSD) + Self-supervised encoder (SimCLR) -> Feature-based detector (MMD) -> Duo detector -> Prevalence estimator (CPMCN) -> Shift identification logic

- **Critical path:** 1) Run Duo detector (output-based + feature-based) on test vs reference 2) If no shift detected, stop 3) If shift detected, estimate prevalence in test set using CPMCN 4) Resample reference set to match estimated test prevalence 5) Compare feature distributions (test vs adjusted reference) 6) If differences disappear, classify as prevalence shift 7) If differences persist, compare output distributions to distinguish covariate vs mixed shift

- **Design tradeoffs:** Using SSL features vs task model features (SSL more sensitive to covariate shifts but may be less discriminative); test set size (larger improves detection but increases computational cost); choice of statistical test (MMD is non-parametric but may have higher variance with small samples)

- **Failure signatures:** High false positive rate (inappropriate encoder or test parameters); misclassification of mixed shifts as prevalence-only (inaccurate prevalence estimation or insufficient feature distribution change); failure to detect subtle covariate shifts (need more powerful SSL encoder or larger test set)

- **First 3 experiments:** 1) Verify Duo detector correctly identifies no shift on test sets resampled without shift 2) Test prevalence shift detection accuracy on test sets with known prevalence shifts 3) Test covariate shift detection accuracy on test sets with known acquisition or subpopulation shifts

## Open Questions the Paper Calls Out
- **Open Question 1:** How effective would the proposed shift identification framework be in detecting and identifying shifts in data distributions that involve multiple modalities or complex combinations of shifts?
- **Open Question 2:** How does the choice of self-supervised encoder architecture (e.g., SimCLR vs. RetFound) impact the accuracy of shift detection and identification in different imaging modalities?
- **Open Question 3:** What are the computational costs associated with implementing the proposed shift identification framework in real-time clinical settings, and how can these costs be optimized?

## Limitations
- Conclusions rely on carefully curated public datasets and simulated shifts that may not fully capture real-world deployment complexity
- Effectiveness for extremely rare conditions or subtle shifts with limited data remains uncertain
- Computational cost of the two-stage detection process and choice of hyperparameters are not thoroughly explored

## Confidence
- **High confidence:** Superiority of combining output-based and feature-based detection methods is well-supported by empirical results across multiple datasets and shift types
- **Medium confidence:** Specific advantage of self-supervised encoders over supervised encoders for detecting subtle covariate shifts is demonstrated but may depend on choice of SSL method and nature of shift
- **Low confidence:** Generalizability to extremely rare conditions or highly imbalanced datasets is not fully validated

## Next Checks
1. Evaluate framework performance on a dataset with highly imbalanced class distribution (1% prevalence) and subtle covariate shift (scanner change)
2. Deploy framework on real clinical dataset from different institution/country without ground truth labels to assess real-world detection and identification ability
3. Measure runtime and memory usage of two-stage detection process on large-scale datasets and investigate impact of varying test set sizes and statistical test parameters on accuracy and efficiency