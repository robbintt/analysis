---
ver: rpa2
title: Improving OCR Quality in 19th Century Historical Documents Using a Combined
  Machine Learning Based Approach
arxiv_id: '2401.07787'
source_url: https://arxiv.org/abs/2401.07787
tags: []
core_contribution: The paper focuses on improving the OCR quality of 19th-century
  historical documents, specifically the complex and intricate structure of the Habsburg
  civil service records known as the Schematismus. The authors address the challenge
  of extracting information from these documents by developing a machine learning
  approach that combines structure recognition and OCR.
---

# Improving OCR Quality in 19th Century Historical Documents Using a Combined Machine Learning Based Approach

## Quick Facts
- arXiv ID: 2401.07787
- Source URL: https://arxiv.org/abs/2401.07787
- Reference count: 40
- 71.98% reduction in CER and 52.49% reduction in WER for 19th century Habsburg civil service records

## Executive Summary
This paper addresses the challenge of improving OCR quality for complex 19th-century historical documents, specifically the Habsburg civil service records known as the Schematismus. The authors develop a machine learning approach that combines structure recognition and OCR by first segmenting documents into layout elements using a Faster R-CNN model trained on synthetic data, then applying fine-tuned Tesseract OCR to each segment. The combined approach achieves significant improvements in character and word error rates compared to standard Tesseract OCR.

## Method Summary
The authors generate 3,766 synthetic Schematismus-style documents using LaTeX scripts to train a Faster R-CNN model with ResNet-50 backbone for layout detection. This model is fine-tuned on 39 manually annotated historical documents. A custom font mimicking the original document style is created using FontForge and used to fine-tune Tesseract OCR. The combined pipeline first detects text blocks and then applies optimized OCR to each segment, achieving substantial improvements in character and word error rates on 15 evaluation pages from 1910 documents.

## Key Results
- 71.98% reduction in Character Error Rate (CER) compared to standard Tesseract OCR
- 52.49% reduction in Word Error Rate (WER) compared to standard Tesseract OCR
- 91.8% precision on synthetic data for layout detection
- 76.4% precision on manually annotated real documents for layout detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Layout segmentation before OCR improves accuracy by reducing multi-block context confusion.
- Mechanism: Faster R-CNN detects and isolates individual text blocks (paragraphs, headings, etc.) so each OCR pass processes only one coherent structure, avoiding cross-block character substitutions.
- Core assumption: Tesseract's line-wise processing is sensitive to surrounding blocks; isolated snippets yield fewer errors.
- Evidence anchors:
  - [abstract]: "split the individual document pages into their layout elements, in order to preserve the context of the different blocks of text"
  - [section]: "By interpreting the preservation of the complex original information as context, we further assumed that the provision of this context could contribute crucially to improved OCR accuracy."
- Break condition: If layout detection misses boundaries, snippets will contain mixed blocks and errors will not improve.

### Mechanism 2
- Claim: Fine-tuning Tesseract on a custom font modeled after the original document reduces character substitution errors.
- Mechanism: Synthetic documents rendered in a font matching the historical typeface train Tesseract's character classifiers to recognize period-specific glyphs and spacing.
- Core assumption: The visual similarity between custom font and original enables the model to generalize to unseen but similar documents.
- Evidence anchors:
  - [abstract]: "We then used Tesseract-OCR, which was further optimised for the style of our documents"
  - [section]: "Using the open source program 'FontForge' [...], we further customised the font in accordance with the original."
- Break condition: If synthetic data distribution diverges from real documents, fine-tuning gains vanish.

### Mechanism 3
- Claim: Synthetic data generation enables training a layout detector without costly manual annotations.
- Mechanism: LaTeX scripts create thousands of annotated documents mimicking the target layout, providing abundant training data for Faster R-CNN.
- Core assumption: Generated documents are visually realistic enough for the model to transfer to real historical pages.
- Evidence anchors:
  - [section]: "we synthesised Hof- und Staatsschematismus-style data, which we used to train our model"
  - [section]: "3,766 synthetic Schematismus documents have been generated using this approach"
- Break condition: If synthetic style deviates from real documents, detector accuracy degrades on real data.

## Foundational Learning

- Concept: Intersection over Union (IoU) for bounding box evaluation.
  - Why needed here: Quantifies layout detector precision and guides post-processing merging of overlapping boxes.
  - Quick check question: Given two boxes with areas 100 and 25 and overlap 10, what is IoU?

- Concept: Character vs Word Error Rate (CER/WER) definitions.
  - Why needed here: Metrics to measure OCR improvement from layout segmentation and fine-tuning.
  - Quick check question: If a word has one wrong character, does CER increase by 1/N or 1?

- Concept: Transfer learning and fine-tuning in CNNs.
  - Why needed here: Enables adaptation of a pre-trained Faster R-CNN to a new domain with limited real data.
  - Quick check question: What changes when switching from random init to pretrained=True in PyTorch Faster R-CNN?

## Architecture Onboarding

- Component map: PDF → synthetic data generator → Faster R-CNN layout detector → Tesseract OCR (fine-tuned) → CER/WER evaluation
- Critical path: Layout detection → image snippet extraction → OCR → metrics; each step depends on the previous
- Design tradeoffs: Synthetic data richness vs. manual annotation accuracy; layout detector resolution vs. inference speed
- Failure signatures: Low IoU scores → bad bounding boxes; high CER after segmentation → segmentation errors; no WER improvement → OCR fine-tuning ineffective
- First 3 experiments:
  1. Run Faster R-CNN on a sample page, measure IoU against ground truth to validate layout detection
  2. Apply fine-tuned Tesseract to full-page images, compute baseline CER/WER
  3. Apply layout detection + snippet OCR, compare metrics to baseline to confirm improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the layout detection model be further improved by including a wider variety of historical document layouts in the training data?
- Basis in paper: [inferred] The authors suggest that the model could be improved by including documents with layouts similar to older Schematismus-style documents from the first half of the 19th century.
- Why unresolved: The paper does not provide experimental results or quantitative data to support this claim.
- What evidence would resolve it: Conducting experiments with training data that includes a wider variety of historical document layouts and comparing the performance of the layout detection model to the current version.

### Open Question 2
- Question: Can the Tesseract OCR model be further optimized for even better performance on historical documents?
- Basis in paper: [inferred] The authors mention that the custom-designed font used for fine-tuning Tesseract could be improved to make text extraction even better.
- Why unresolved: The paper does not provide details on how the font could be improved or experimental results demonstrating the impact of such improvements.
- What evidence would resolve it: Developing and testing an improved custom font for Tesseract OCR and comparing the performance of the optimized model to the current version on historical documents.

### Open Question 3
- Question: Can the methods used in this paper be applied to other types of historical documents?
- Basis in paper: [inferred] The authors express interest in exploring whether the methods used in this paper can be applied to other types of historical documents.
- Why unresolved: The paper does not provide any experimental results or case studies demonstrating the applicability of the methods to other types of historical documents.
- What evidence would resolve it: Conducting experiments with other types of historical documents and evaluating the performance of the layout detection and OCR models on these documents.

## Limitations
- The visual fidelity between synthetic and historical documents remains unvalidated through direct comparison metrics
- The small fine-tuning set of only 39 pages may limit the model's generalization to real documents
- The custom font creation process lacks validation that it captures all relevant character variations present in the original documents

## Confidence
- High Confidence: The general approach of combining layout segmentation with OCR is well-established and theoretically sound. The reported CER/WER improvements (71.98% and 52.49% respectively) are internally consistent with the methodology described.
- Medium Confidence: The specific performance gains attributed to the combined approach are plausible but would benefit from ablation studies showing individual contributions of layout segmentation versus font fine-tuning.
- Low Confidence: The direct comparison between synthetic and real document layouts is not demonstrated. The claim that the custom font sufficiently represents the historical typeface lacks empirical validation through character-level accuracy analysis.

## Next Checks
1. Conduct a visual similarity analysis comparing synthetic document samples with real Schematismus pages using image-based similarity metrics to quantify the synthetic-real gap.

2. Perform an ablation study isolating the contributions of layout segmentation and font fine-tuning by measuring OCR performance with each component independently and in combination.

3. Validate the Faster R-CNN's real-world performance by testing it on a separate held-out set of manually annotated historical documents not used in fine-tuning, measuring both detection accuracy (IoU) and downstream OCR impact.