---
ver: rpa2
title: A Truly Joint Neural Architecture for Segmentation and Parsing
arxiv_id: '2402.02564'
source_url: https://arxiv.org/abs/2402.02564
tags:
- parsing
- architecture
- segmentation
- morphological
- joint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a joint neural architecture for morphological
  segmentation and dependency parsing of morphologically rich languages (MRLs). The
  key challenge addressed is the high morphological ambiguity in MRLs, where raw tokens
  may consist of multiple linguistic units that serve as nodes in the syntactic tree.
---

# A Truly Joint Neural Architecture for Segmentation and Parsing

## Quick Facts
- arXiv ID: 2402.02564
- Source URL: https://arxiv.org/abs/2402.02564
- Authors: Danit Yshaayahu Levi; Reut Tsarfaty
- Reference count: 13
- Primary result: State-of-the-art joint segmentation and parsing for Hebrew using a lattice-based neural architecture with multi-task learning

## Executive Summary
This paper introduces a truly joint neural architecture for morphological segmentation and dependency parsing in morphologically rich languages (MRLs). The key insight is that traditional pipeline approaches, where segmentation precedes parsing, suffer from error propagation when morphological ambiguity leads to incorrect segmentations. The proposed solution uses a lattice representation that preserves all possible morphological analyses of each token, which is then provided to an arc-factored neural model that jointly determines both the correct segmentation and syntactic structure. Experiments on Hebrew demonstrate state-of-the-art results for parsing, POS tagging, and segmentation using a single model, showing that the joint approach significantly outperforms pipeline baselines.

## Method Summary
The architecture begins with a morphological analyzer that generates all possible segmentations for each token, creating a lattice of morphological analyses. This lattice is linearized into a sequence suitable for neural processing, where each segment is represented by contextualized embeddings generated from AlephBERT. The linearized lattice is processed by a BiLSTM encoder, and a biaffine attention mechanism scores potential head arcs and dependency labels for each segment. The model is trained end-to-end using multi-task learning to also predict POS tags, gender, number, and person features. During inference, a maximum spanning tree algorithm selects the optimal dependency structure while excluding auxiliary tokens that represent incorrect segmentations.

## Key Results
- Achieves state-of-the-art dependency parsing LAS scores on Hebrew UD treebank
- Outperforms traditional pipeline approaches by 2-3% in parsing accuracy
- Demonstrates strong performance in POS tagging and morphological segmentation as auxiliary tasks
- Shows that contextualized embeddings from AlephBERT significantly improve over static embeddings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Joint morphological segmentation and parsing outperforms pipeline approaches in MRLs because segmentation errors in early stages cascade and harm downstream syntactic predictions.
- Mechanism: The lattice-based linearization preserves all possible morphological analyses, allowing the arc-factored model to jointly select both correct segments and syntactic arcs during a single forward pass. Incorrect segments are mapped to an auxiliary node during training and excluded at inference, ensuring that syntactic context informs segmentation decisions.
- Core assumption: Morphological ambiguity is a primary source of parsing degradation in MRLs, and resolving it jointly with syntax improves both tasks.
- Evidence anchors:
  - [abstract]: "When segmentation is performed prior to (and independently of) the parsing phase, segmentation errors may propagate to undermine the syntactic predictions."
  - [section]: "Crucially, these parsers and others ... all subscribe to a pipeline approach, where the input tokens are pre-segmented, and these segments uniquely determine the nodes in the tree. This pipeline approach has been applied across many language types, including morphologically rich languages (MRL). However, MRLs pose a significant challenge to such architectures."
  - [corpus]: Weak evidence—corpus lacks citations supporting segmentation as the sole bottleneck in MRL parsing.
- Break condition: If morphological ambiguity is low (e.g., in languages with fixed segmentation or analytic morphology), the joint approach offers no advantage over a pipeline.

### Mechanism 2
- Claim: Contextual embeddings generated from valid sentence contexts for each morphological analysis improve lattice encoding quality versus embeddings from the raw linearized lattice.
- Mechanism: For each possible analysis of a token, the model constructs a sentence where that analysis replaces the original token, generates contextualized embeddings for its morphemes, and concatenates them. This preserves local context and avoids the non-linear, out-of-order structure of the linearized lattice.
- Core assumption: LLMs can generate meaningful contextualized embeddings for morpheme sequences when provided with grammatically valid contexts.
- Evidence anchors:
  - [section]: "The way we generate embedding for the input lattice complements the architectural design and significantly impacts the parser performance."
  - [section]: "Table 4 highlights the significance of the embedding method... a notable enhancement is also observed when altering the context of the linearized lattice as we propose."
  - [corpus]: Weak—no comparative ablations against static embeddings in the corpus.
- Break condition: If the LLM encoder cannot generate meaningful embeddings for morpheme sequences (e.g., OOV morphemes), the context substitution fails to improve performance.

### Mechanism 3
- Claim: Multi-task learning (MTL) of POS, gender, number, and person features improves joint segmentation and parsing accuracy.
- Mechanism: Separate linear layers are applied on top of the BiLSTM output to predict linguistic features, with cross-entropy losses combined with the parsing loss. The auxiliary supervision encourages the shared encoder to learn richer morpheme representations.
- Core assumption: Morphological features are predictive of syntactic structure and segmentation boundaries.
- Evidence anchors:
  - [section]: "We aimed to leverage additional linguistic tasks such as gender, person, number, and POS. Consequently, we expanded upon the original architecture introduced by Dozat and Manning to accommodate these MTL objectives."
  - [section]: "Table 3 shows the results of our proposed approach with ablation of the MTL contribution... These results demonstrate that our joint architecture surpasses the original Biaffine architecture in Hebrew parsing."
  - [corpus]: No direct citations; improvement inferred from ablation results only.
- Break condition: If feature labels are noisy or missing, MTL can degrade rather than improve parsing accuracy.

## Foundational Learning

- Concept: Morphologically Rich Languages (MRLs) and morphological ambiguity
  - Why needed here: The paper's entire motivation rests on the parsing difficulty introduced by tokens that can be segmented in multiple valid ways, each yielding different syntactic trees.
  - Quick check question: In a sentence like "bclm hneim," how many distinct morphological analyses are possible, and why does each lead to a different parse?

- Concept: Lattice representation and linearization
  - Why needed here: The architecture converts a non-linear ambiguity structure into a linear sequence suitable for LSTM encoders while preserving all possible analyses.
  - Quick check question: How does the linearization preserve the partial order of tokens, and what constraint is enforced when selecting arcs to form a valid tree?

- Concept: Arc-factored dependency parsing and Biaffine scoring
  - Why needed here: The core model selects head arcs and labels for each segment; understanding the Biaffine mechanism is key to grasping how segmentation decisions emerge from arc selection.
  - Quick check question: In the joint model, how does the auxiliary token allow the model to exclude irrelevant segments from the final dependency tree?

## Architecture Onboarding

- Component map: Morphological Analyzer -> Linearization module -> AlephBERT encoder -> BiLSTM -> Biaffine head/label scorer + MTL heads -> MST decoder
- Critical path: MA -> linearization -> contextualized embeddings -> BiLSTM -> Biaffine scoring -> MST -> final parse
- Design tradeoffs:
  - Joint modeling vs. pipeline: Joint modeling trades training complexity for end-to-end accuracy; pipeline allows modular upgrades but suffers from error propagation.
  - Lattice linearization vs. graph encoding: Linearization is simple to implement with existing encoders but loses explicit graph structure; graph encoding would require custom architectures.
  - MTL inclusion: Adds supervision and may improve generalization but increases training time and hyperparameter tuning burden.
- Failure signatures:
  - Low segmentation F1 but high parsing F1: Likely due to lenient evaluation or gold MA coverage in experiments.
  - High segmentation F1 but low parsing F1: Segmentation decisions may be correct but syntactically incoherent; check arc scoring or MST decoding.
  - Training divergence: Embedding generation for large lattices may cause memory overflow; try gradient checkpointing or smaller batch sizes.
- First 3 experiments:
  1. Run the baseline Biaffine model with gold segmentation on the Hebrew UD dev set to establish a performance ceiling.
  2. Replace the gold segmentation with predicted segmentation from Seker and Tsarfaty (2020) and measure parsing drop to quantify segmentation impact.
  3. Swap AlephBERT with mBERT in the joint model to measure the effect of encoder choice on segmentation and parsing accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the joint neural architecture for segmentation and parsing compare in performance to traditional pipeline approaches when evaluated on morphologically rich languages beyond Hebrew?
- Basis in paper: [explicit] The paper discusses the performance of the joint neural architecture on Hebrew and mentions the potential for evaluating it on other morphologically rich languages.
- Why unresolved: The paper primarily focuses on Hebrew as a case study and does not provide comparative results for other morphologically rich languages.
- What evidence would resolve it: Conducting experiments with the joint neural architecture on a diverse set of morphologically rich languages and comparing the results with traditional pipeline approaches would provide the necessary evidence.

### Open Question 2
- Question: What are the limitations and challenges of using morphological analyzers (MAs) in the proposed joint neural architecture, and how can they be addressed to improve parsing performance?
- Basis in paper: [explicit] The paper discusses the use of MAs for generating lattices and mentions the potential impact of MA coverage on parsing performance.
- Why unresolved: The paper acknowledges the importance of MAs but does not delve into specific limitations or propose solutions to address them.
- What evidence would resolve it: Investigating the limitations of MAs in detail and proposing methods to enhance their coverage and accuracy would provide insights into improving parsing performance.

### Open Question 3
- Question: How does the proposed joint neural architecture handle out-of-vocabulary (OOV) tokens, and what strategies can be implemented to improve its handling of such cases?
- Basis in paper: [explicit] The paper mentions the potential presence of OOV tokens and the need to evaluate the model's performance in scenarios where some analyses may be missing.
- Why unresolved: The paper does not provide specific strategies or results related to handling OOV tokens in the joint neural architecture.
- What evidence would resolve it: Implementing and evaluating different strategies for handling OOV tokens, such as leveraging context or incorporating external resources, would provide insights into improving the model's robustness.

## Limitations

- Experimental scope limited to Hebrew only, making generalization to other MRLs uncertain
- Relies heavily on morphological analyzer coverage, with no discussion of handling missing analyses
- Computational complexity of lattice processing may not scale to languages with extreme morphological ambiguity

## Confidence

- Joint modeling superiority: High
- Contextualized embeddings benefit: Medium
- MTL contribution: Medium
- Morphological ambiguity as primary bottleneck: Low

## Next Checks

1. Apply the model to a morphologically distinct MRL (e.g., Turkish or Arabic) and compare performance to the Hebrew results to assess cross-linguistic applicability.
2. Implement a gold-segmentation pipeline baseline on the Hebrew dataset to quantify the exact performance gap between joint and pipeline approaches under controlled conditions.
3. Remove the contextualized embedding generation step and replace with static embeddings to isolate the contribution of contextualization versus the lattice representation itself.