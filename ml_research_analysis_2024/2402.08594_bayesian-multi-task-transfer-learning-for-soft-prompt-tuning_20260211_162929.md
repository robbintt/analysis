---
ver: rpa2
title: Bayesian Multi-Task Transfer Learning for Soft Prompt Tuning
arxiv_id: '2402.08594'
source_url: https://arxiv.org/abs/2402.08594
tags:
- source
- task
- target
- prompt
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a Bayesian approach to multi-task prompt tuning,
  where prompts are trained from multiple source tasks to be applied to a target task.
  The method uses Stein Variational Gradient Descent (SVGD) to approximate the posterior
  distribution of prompts across source tasks, and then uses the source prompts' posterior
  distribution as the prior for the target task.
---

# Bayesian Multi-Task Transfer Learning for Soft Prompt Tuning

## Quick Facts
- arXiv ID: 2402.08594
- Source URL: https://arxiv.org/abs/2402.08594
- Authors: Haeju Lee; Minchan Jeong; Se-Young Yun; Kee-Eung Kim
- Reference count: 29
- Key outcome: BMTPT outperforms state-of-the-art parameter-efficient fine-tuning methods while using fewer parameters

## Executive Summary
This paper presents BMTPT (Bayesian Multi-Task Prompt Tuning), a novel approach for transfer learning in prompt tuning that leverages Bayesian inference to capture correlations among multiple source tasks. The method uses Stein Variational Gradient Descent (SVGD) to approximate the posterior distribution of prompts across source tasks, which is then used as a prior for the target task prompt. Experiments on 21 diverse NLP datasets demonstrate that BMTPT achieves superior performance compared to existing parameter-efficient fine-tuning methods while maintaining high parameter efficiency.

## Method Summary
BMTPT operates in two stages: source posterior learning and target task adaptation. In the source stage, SVGD is used to approximate the posterior distribution of prompts across multiple source tasks by iteratively updating M particles (soft prompts) based on the cross-entropy loss. This posterior distribution is then used as a prior for the target task. During target adaptation, the prompt is initialized as the average of the source prompts and trained using a combined loss function that includes maximum likelihood estimation for the target task and regularization based on the prior. The target prompt consists of a full-rank matrix (initialized from the particle average) and a low-rank matrix, resulting in significant parameter efficiency compared to full fine-tuning or methods using auxiliary networks.

## Key Results
- BMTPT outperforms SOTA parameter-efficient fine-tuning methods (ATTEMPT, MPT) across 21 target tasks
- Achieves parameter efficiency of only 0.035% compared to full fine-tuning
- The 5-particle BMTPT performs comparably to the 10-particle variant while using fewer parameters
- Demonstrates robustness across diverse task types from GLUE, SuperGLUE, and MRQA benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: BMTPT outperforms other prompt tuning transfer methods by capturing the full posterior distribution of source prompts rather than relying on individually trained and aggregated prompts.
- Mechanism: Instead of training a separate prompt for each source task and then combining them, BMTPT uses Stein Variational Gradient Descent (SVGD) to approximate the posterior distribution of prompts across all source tasks. This posterior is then used as the prior for the target task prompt, allowing the target prompt to be initialized from a more representative distribution that captures task correlations.
- Core assumption: The posterior distribution of prompts across source tasks contains more useful information for transfer learning than the individual prompts alone, and SVGD can effectively approximate this distribution.
- Evidence anchors:
  - [abstract] "Our approach requires no auxiliary models other than the prompt itself, achieving a high degree of parameter efficiency."
  - [section] "We use the source prompts' posterior distribution as the prior for the target task."
- Break condition: If the source tasks are too diverse or unrelated, the posterior distribution may become too diffuse to provide useful guidance for the target task.

### Mechanism 2
- Claim: The Bayesian framework in BMTPT provides better regularization during target adaptation compared to methods that only use initialization from source tasks.
- Mechanism: During target adaptation, BMTPT uses the approximated posterior as a prior in a MAP inference framework, which regularizes the target prompt training by pulling it toward the region of weight space that is informative for multiple source tasks. This is implemented through a regularization term in the loss function that encourages the target prompt to stay close to the mean of the source prompt distribution.
- Core assumption: The region of weight space that is good for multiple source tasks is also likely to be good for the target task, making this regularization beneficial.
- Evidence anchors:
  - [section] "We model p(θT |θS) as the multivariate Gaussian with mean θS" and the use of this as a prior during target adaptation.
  - [section] "This objective suggests that, during target adaptation, we can initialize θT with the average value of the optimized particles θS."
- Break condition: If the source tasks are too dissimilar from the target task, this regularization could hinder performance by pulling the target prompt away from an optimal solution for the specific target task.

### Mechanism 3
- Claim: BMTPT's efficiency comes from using a small number of particles in SVGD combined with the posterior-as-prior framework, requiring fewer parameters than methods that use auxiliary networks.
- Mechanism: BMTPT uses only M particles (typically M ≤ 10) to approximate the posterior distribution, which requires only M · l · d additional parameters. The target prompt is then composed of a full-rank matrix (initialized from the particle average) and a low-rank matrix, resulting in (l · d)/N + (l + d) parameters per target task when adapting to N tasks. This is significantly fewer than methods like ATTEMPT (232K parameters) or MPT (77.6K parameters).
- Core assumption: A small number of well-chosen particles can adequately represent the posterior distribution, and the full-rank/low-rank decomposition is sufficient for target task adaptation.
- Evidence anchors:
  - [section] "Since we employ a small number of particles, the memory consumption by SVGD particles is almost negligible."
  - [section] "This makes BMTPT train only 0.035 % parameters compared to full fine-tuning."
- Break condition: If the number of particles is too small relative to the complexity of the posterior distribution, the approximation may be poor and hurt performance.

## Foundational Learning

- Concept: Variational Inference (VI)
  - Why needed here: BMTPT uses VI methods (specifically SVGD) to approximate the posterior distribution of prompts across source tasks, which is intractable to compute exactly.
  - Quick check question: What is the key difference between traditional VI methods and particle-based VI methods like SVGD?

- Concept: Bayesian Inference and MAP Estimation
  - Why needed here: BMTPT frames the target task prompt optimization as a MAP inference problem where the posterior from source tasks serves as the prior, requiring understanding of Bayesian principles.
  - Quick check question: In the context of BMTPT, what does the posterior distribution from source tasks represent when used as a prior for the target task?

- Concept: Kernel Methods and Reproducing Kernel Hilbert Spaces (RKHS)
  - Why needed here: SVGD relies on kernel functions (specifically RBF kernels) to measure similarity between particles and to compute the Stein discrepancy, which is central to the algorithm's operation.
  - Quick check question: How does the choice of kernel function affect the behavior of particles in SVGD?

## Architecture Onboarding

- Component map:
  Source tasks (K datasets) -> Prompt particles (M) -> SVGD optimization -> Approximated posterior -> Target task prompt (full-rank + low-rank matrices)

- Critical path:
  1. Initialize M particles with random tokens
  2. For each SVGD iteration: sample one example from each source task, prepend to each particle, compute cross-entropy loss, update particles using SVGD rule
  3. After source posterior learning: average particles to form full-rank matrix initialization for target prompt
  4. Initialize low-rank matrix with ones
  5. Train target prompt using combined MLE loss + prior regularization

- Design tradeoffs:
  - Number of particles M vs. approximation quality vs. computational cost
  - Choice of kernel bandwidth vs. particle diversity vs. mode collapse
  - Full-rank vs. low-rank decomposition vs. parameter efficiency vs. expressivity
  - SVGD damping parameter vs. variance collapse vs. convergence stability

- Failure signatures:
  - Performance plateaus early: likely too few particles or kernel bandwidth too large
  - Training becomes unstable: check SVGD damping parameter or learning rates
  - No improvement over vanilla PT: source tasks may be too dissimilar from target or posterior approximation poor
  - Memory issues: reduce batch size or number of particles

- First 3 experiments:
  1. Ablation study: Compare BMTPT with and without the prior regularization term during target adaptation to verify its contribution
  2. Sensitivity analysis: Test BMTPT with different numbers of particles (e.g., 3, 5, 10) to find optimal trade-off between performance and efficiency
  3. Cross-dataset generalization: Test BMTPT on a target task that is very different from all source tasks to evaluate robustness of the Bayesian transfer approach

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of BMTPT change when using different numbers of particles in SVGD, and is there an optimal number that balances computational efficiency with transfer learning effectiveness?
- Basis in paper: [explicit] The paper investigates the effect of the number of particles on target adaptation performance, comparing 5-particle and 10-particle BMTPT, and finds that the 10-particle case does not yield better results than the 5-particle case.
- Why unresolved: The paper does not explore a wide range of particle numbers, leaving the question of whether an optimal number exists between 5 and 10 or beyond.
- What evidence would resolve it: Systematic experimentation with a broader range of particle numbers (e.g., 3, 5, 7, 10, 15) and analysis of the trade-off between computational cost and performance could identify an optimal number of particles.

### Open Question 2
- Question: Can BMTPT be extended to handle more complex and diverse distributions in the source tasks, such as those with multiple modes or heavy tails, without suffering from variance collapse in SVGD?
- Basis in paper: [inferred] The paper mentions that SVGD may suffer from variance collapse if the number of particles is not sufficiently large compared to the particle dimension, and that the samples of θS can be predominantly positioned near the peak of the global posterior distribution during the source posterior learning process.
- Why unresolved: The paper does not provide a detailed analysis of how BMTPT performs with more complex source task distributions or strategies to mitigate variance collapse in such cases.
- What evidence would resolve it: Experiments with source tasks exhibiting diverse and complex distributions, coupled with techniques to address variance collapse (e.g., adjusting kernel parameters, using more particles), could demonstrate the robustness of BMTPT in handling such scenarios.

### Open Question 3
- Question: How does the choice of kernel function in SVGD affect the performance of BMTPT, and are there alternative kernel functions that could improve the approximation of the source posterior distribution?
- Basis in paper: [explicit] The paper uses the Radial Basis Function (RBF) kernel in SVGD and mentions that the bandwidth parameter is adjusted according to the distances between particles.
- Why unresolved: The paper does not explore the impact of different kernel functions on the performance of BMTPT or investigate alternative kernels that might better capture the structure of the source posterior distribution.
- What evidence would resolve it: Comparative experiments using different kernel functions (e.g., polynomial, Laplacian) and analysis of their effects on the approximation quality and downstream task performance could identify more suitable kernels for BMTPT.

### Open Question 4
- Question: Can BMTPT be adapted to leverage task-specific information during the source posterior learning phase, potentially improving the quality of the transferred knowledge?
- Basis in paper: [inferred] The paper focuses on learning a general posterior distribution over prompts across source tasks without explicitly incorporating task-specific information.
- Why unresolved: The paper does not investigate whether incorporating task-specific information during source posterior learning could enhance the effectiveness of the transferred knowledge for target tasks.
- What evidence would resolve it: Experiments comparing BMTPT with and without task-specific information during source posterior learning, and analysis of the impact on target task performance, could reveal the potential benefits of leveraging task-specific information.

## Limitations

- The evaluation lacks comparisons against simple ensemble methods or single-task prompt tuning baselines, making it difficult to isolate the benefits of the Bayesian approach
- The parameter efficiency claims rely on comparisons with methods using auxiliary networks, but ablation studies are missing to determine whether the full-rank/low-rank decomposition is necessary for performance gains
- The paper doesn't explore the robustness of BMTPT when source tasks are very dissimilar from the target task, leaving uncertainty about its effectiveness in low-similarity transfer scenarios

## Confidence

- **High confidence** in the mechanism that SVGD can approximate posterior distributions of prompts across source tasks, as this is well-established in the variational inference literature
- **Medium confidence** in the claim that using the posterior distribution as a prior improves target task performance, as the evaluation methodology has limitations
- **Low confidence** in the parameter efficiency claims relative to all possible approaches, given the limited comparison set

## Next Checks

1. **Baseline completeness validation**: Compare BMTPT against a simple ensemble of individually trained prompts (one per source task) to determine if the Bayesian aggregation provides meaningful benefits beyond basic multi-source knowledge aggregation.

2. **Parameter efficiency validation**: Conduct an ablation study removing the full-rank/low-rank decomposition and using a simpler parameter-efficient approach (e.g., Adapter-Bot) to determine whether the Bayesian framework or the architectural choices drive the parameter efficiency.

3. **Source task diversity validation**: Test BMTPT on target tasks that are deliberately dissimilar from all source tasks to evaluate whether the Bayesian transfer approach degrades gracefully or catastrophically when source-target task similarity is low.