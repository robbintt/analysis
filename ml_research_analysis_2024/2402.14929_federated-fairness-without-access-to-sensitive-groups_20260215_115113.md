---
ver: rpa2
title: Federated Fairness without Access to Sensitive Groups
arxiv_id: '2402.14929'
source_url: https://arxiv.org/abs/2402.14929
tags:
- group
- learning
- fairness
- clients
- groups
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new federated learning approach that ensures
  group fairness without requiring knowledge of sensitive groups during training.
  The proposed Relaxed Conditional Value-at-Risk (RCVaR) objective maximizes the performance
  of the worst-performing group, subject to a configurable group size constraint,
  while allowing trade-offs between fairness and utility through a hyperparameter.
---

# Federated Fairness without Access to Sensitive Groups

## Quick Facts
- arXiv ID: 2402.14929
- Source URL: https://arxiv.org/abs/2402.14929
- Reference count: 40
- Primary result: Achieves group fairness in federated learning without requiring knowledge of sensitive groups

## Executive Summary
This paper introduces a novel federated learning approach that ensures group fairness without needing access to sensitive group labels during training. The method uses a Relaxed Conditional Value-at-Risk (RCVaR) objective to maximize the performance of the worst-performing group, subject to a configurable group size constraint. Through a single hyperparameter, the approach enables flexible trade-offs between fairness and utility while maintaining convergence guarantees in heterogeneous federated settings.

## Method Summary
The method proposes FedSRCVaR, a federated algorithm that optimizes the RCVaR objective using a smooth approximation of the non-differentiable plus function. The algorithm alternates between local gradient updates at clients and server-side averaging of model parameters and threshold values. The smooth approximation enables efficient gradient-based optimization while preserving theoretical convergence guarantees. The approach operates without sensitive group labels by identifying high-risk samples through a threshold parameter that is learned jointly with the model parameters.

## Key Results
- Achieves effective worst-group performance improvement without unnecessarily harming average performance
- Produces solutions comparable to centralized baselines while maintaining federated advantages
- Enables a wide range of fairness-utility trade-offs through a single hyperparameter
- Demonstrates robustness when sensitive groups are incorrectly anticipated at test time

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RCVaR achieves worst-case group fairness without needing labeled sensitive groups by optimizing over all possible subsets of size ρ
- Mechanism: The RCVaR objective uses conditional value-at-risk (CVaR) to focus on the worst-performing ρ fraction of samples across all clients, treating this as the "sensitive group" without requiring prior knowledge of who belongs to it
- Core assumption: The worst-performing samples can be meaningfully aggregated across heterogeneous client distributions to form a coherent high-risk group
- Evidence anchors:
  - [abstract]: "Our objective allows the federation to learn a Pareto efficient global model ensuring worst-case group fairness and it enables, via a single hyper-parameter, trade-offs between fairness and utility, subject only to a group size constraintρ"
  - [section 3.2]: "RCVaR ensures minimax properly Pareto fairness, where the worst possible group is formed by the high-risk samples subject to a predefined group size constraintρ"

### Mechanism 2
- Claim: The trade-off parameter ϵ allows flexible balancing between average performance and worst-case fairness
- Mechanism: By adjusting ϵ from 0 (pure worst-case focus) to 1 (pure average focus), RCVaR can produce a continuum of Pareto-optimal solutions that trade off between utility and fairness
- Core assumption: The federated learning problem admits solutions that can simultaneously improve worst-group performance while maintaining reasonable average performance
- Evidence anchors:
  - [section 3.2]: "The threshold c is uniformly applied across all clients in the federation to identify the samples that belong to the global high-risk and the low-risk groups"
  - [section 6.2]: "Figure 3 shows that ϵ effectively acts as a tuning parameter between worst group fairness and average performance"

### Mechanism 3
- Claim: FedSRCVaR's smooth approximation enables efficient federated optimization while preserving convergence guarantees
- Mechanism: The algorithm uses a smooth plus function approximation to replace the non-differentiable plus function, allowing gradient-based optimization with convergence guarantees even in the presence of heterogeneous client data
- Core assumption: The smooth approximation is sufficiently accurate for practical purposes while enabling tractable optimization
- Evidence anchors:
  - [section 4.1]: "We consider the family of smoothed plus functions that satisfy Definition 4.1... The designed algorithm and its analysis support any function that is consistent with Definition 4.1"
  - [section 5.1]: "The third term depends on how accurately the smooth plus function approximates the plus function. When γ is sufficiently small, we recover the upper bound for synchronous SGD"

## Foundational Learning

- Concept: Conditional Value-at-Risk (CVaR) and superquantiles
  - Why needed here: CVaR provides the mathematical foundation for identifying and optimizing the worst-performing subset of samples
  - Quick check question: What is the relationship between CVaR and the (1-ρ)-quantile in the context of loss distributions?

- Concept: Pareto optimality and its variants (weak vs. proper)
  - Why needed here: The paper distinguishes between weak Pareto optimality (which may harm well-performing groups) and proper Pareto optimality (which ensures no group is unnecessarily harmed)
  - Quick check question: How does proper Pareto optimality differ from weak Pareto optimality in the context of group fairness?

- Concept: Federated learning optimization with heterogeneous data
  - Why needed here: The algorithm must handle data that is distributed across clients with potentially different distributions
  - Quick check question: What is the key challenge in federated learning that makes direct application of centralized fairness methods insufficient?

## Architecture Onboarding

- Component map:
  - Smooth plus function approximation module -> Federated averaging with local updates (FedAvg-style) -> Threshold parameter c that identifies high-risk samples -> Trade-off parameter ϵ controlling fairness-utility balance -> Group size constraint ρ limiting the worst-case group

- Critical path:
  1. Initialize global model θ and threshold c
  2. Broadcast (θ, c) to all clients
  3. Each client performs τ local gradient steps on both parameters
  4. Clients return updated (θ, c) to server
  5. Server averages updates using batch size weights
  6. Repeat for T communication rounds

- Design tradeoffs:
  - More local epochs τ improves communication efficiency but may degrade worst-group performance for small ρ
  - Smaller smoothing parameter γ improves approximation accuracy but may cause numerical instability
  - Smaller group size ρ focuses on stricter fairness but may make optimization more difficult

- Failure signatures:
  - Degraded worst-group performance despite optimization indicates poor aggregation of high-risk samples across clients
  - Excessive variance in group performance suggests the group size constraint ρ is too small relative to data heterogeneity
  - Slow convergence or instability suggests the smoothing parameter γ needs adjustment

- First 3 experiments:
  1. Verify that FedSRCVaR with ϵ=0 reproduces DRO results on a centralized dataset
  2. Test convergence behavior with τ=1 versus τ>1 on a simple non-IID split
  3. Validate that the smooth approximation preserves the ordering of worst-group samples by comparing to exact CVaR on a small dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FedSRCVaR's performance scale with varying degrees of data heterogeneity across clients?
- Basis in paper: [explicit] The paper discusses convergence guarantees and the impact of heterogeneity on local rounds in Lemma 5.6 and related text.
- Why unresolved: The paper provides theoretical bounds and discusses heterogeneity, but does not present extensive empirical results showing FedSRCVaR's performance across different heterogeneity levels.
- What evidence would resolve it: Experiments showing FedSRCVaR's performance on datasets with controlled levels of heterogeneity, demonstrating its robustness and scalability.

### Open Question 2
- Question: Can FedSRCVaR be extended to non-convex loss functions, and what would be the impact on convergence and excess risk guarantees?
- Basis in paper: [inferred] The current analysis assumes convexity of the loss function and hypothesis class, as stated in Assumptions 5.1 and 5.2.
- Why unresolved: The paper focuses on convex settings, leaving the extension to non-convex cases as an open problem.
- What evidence would resolve it: Analysis and experiments extending FedSRCVaR to non-convex loss functions, showing the impact on convergence rates and excess risk bounds.

### Open Question 3
- Question: How sensitive is FedSRCVaR to the choice of the smoothing parameter γ, and what is the optimal way to select it?
- Basis in paper: [explicit] The paper discusses the role of γ in the smoothed approximation of the plus function and its impact on the optimization error.
- Why unresolved: While the paper mentions the importance of γ, it does not provide a detailed analysis of its sensitivity or guidance on how to optimally select it.
- What evidence would resolve it: Sensitivity analysis and guidelines for selecting the smoothing parameter γ, based on experiments and theoretical insights.

### Open Question 4
- Question: How does FedSRCVaR compare to other fairness-aware federated learning methods in terms of communication efficiency and privacy preservation?
- Basis in paper: [explicit] The paper highlights the lightweight nature of FedSRCVaR in terms of communication overhead compared to methods like BPF.
- Why unresolved: The paper does not provide a comprehensive comparison of FedSRCVaR with other fairness-aware federated learning methods in terms of communication efficiency and privacy preservation.
- What evidence would resolve it: Comparative experiments and analysis of FedSRCVaR against other fairness-aware federated learning methods, focusing on communication efficiency and privacy preservation metrics.

## Limitations
- Empirical evaluation relies on datasets with limited sensitive attribute diversity
- Robustness claims tested only through synthetic group splits, not natural distributions
- Assumes clients can be trusted to correctly implement protocol without addressing Byzantine behavior

## Confidence
- **High Confidence**: The theoretical framework for RCVaR and its fairness properties (Mechanisms 1-2)
- **Medium Confidence**: The practical effectiveness of the smooth approximation and federated optimization (Mechanism 3)
- **Medium Confidence**: The robustness to incorrectly anticipated groups, based on synthetic experiments but lacking validation on naturally occurring distributions

## Next Checks
1. Test FedSRCVaR on a real-world dataset with naturally occurring sensitive groups and unknown true group membership to validate robustness claims
2. Evaluate the algorithm's performance under Byzantine attacks or malicious clients who manipulate their local updates
3. Conduct ablation studies to determine the impact of the smooth approximation parameter γ and local epochs τ on worst-group performance in highly heterogeneous federated settings