---
ver: rpa2
title: 'Enhancing Object Detection Performance for Small Objects through Synthetic
  Data Generation and Proportional Class-Balancing Technique: A Comparative Study
  in Industrial Scenarios'
arxiv_id: '2401.12729'
source_url: https://arxiv.org/abs/2401.12729
tags:
- data
- dataset
- synthetic
- objects
- object
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of detecting small objects in
  industrial scenarios, where collecting and annotating data is time-consuming and
  prone to errors. The authors propose a novel approach that combines synthetic data
  generation with a proportional class-balancing technique to improve the performance
  of object detection models on small objects.
---

# Enhancing Object Detection Performance for Small Objects through Synthetic Data Generation and Proportional Class-Balancing Technique: A Comparative Study in Industrial Scenarios

## Quick Facts
- arXiv ID: 2401.12729
- Source URL: https://arxiv.org/abs/2401.12729
- Reference count: 40
- Primary result: YOLOv5 achieves 0.986 mAP with 11.4% increase in small object precision using 2:1 real:synthetic data ratio

## Executive Summary
This study addresses the challenge of detecting small objects in industrial assembly scenarios where data collection and annotation are costly and error-prone. The authors propose a novel approach combining synthetic data generation with proportional class-balancing to improve object detection performance. By generating additional samples for underrepresented small object classes, they create a balanced dataset that enables better anchor matching and model convergence. Experiments compare three state-of-the-art object detection models (YOLOv5, YOLOv7, SSD) across different real-to-synthetic data ratios, demonstrating that the YOLOv5 model achieves the highest mean average precision (mAP) of 0.986 when trained on a 2:1 ratio of real to synthetic data.

## Method Summary
The method involves generating synthetic images from CAD models of industrial components using 3D rendering with varied backgrounds, lighting, and viewpoints. Five dataset combinations are created with varying real-to-synthetic ratios (DS-1 to DS-5), where DS-1 contains only real data and DS-5 contains only synthetic data. The target classes are proportionally balanced by generating more synthetic samples for underrepresented small objects (LED, resistor, button under 32x32px; buzzer, arduino 32-64px). Three object detection models (YOLOv5, YOLOv7, SSD) are trained for 100 epochs with Adam optimizer, batch size 8, and input resolution 1080x1080px. Performance is evaluated using COCO metrics including mAP, APs (small object precision), and ARs (small object recall).

## Key Results
- YOLOv5 achieves highest mAP of 0.986 on combined real and synthetic dataset (DS-3)
- 11.4% improvement in small object precision (APs) compared to real-only baseline
- Optimal real:synthetic ratio is 2:1 (DS-3), where synthetic data points equal half of real data instances
- Excessive synthetic data (DS-4 and DS-5) degrades performance due to domain shift issues

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Proportional class-balancing reduces bias toward dominant object classes, allowing the model to learn more discriminative features for small objects.
- Mechanism: By synthetically generating additional samples for underrepresented classes, the dataset distribution becomes more uniform. This enables better anchor matching during training, as YOLO-style detectors use predefined anchor boxes that are optimized based on class size distribution.
- Core assumption: The initial real dataset has a skewed distribution where small objects are significantly underrepresented compared to medium and large objects.
- Evidence anchors: [abstract] "create a balanced dataset that enables better anchor matching and model convergence"; [section] "the target classes have been proportionally balanced, giving more significance for the less occurring classes"
- Break condition: If synthetic data is generated with unrealistic characteristics (non-photo-realistic), the model may fail to generalize to real-world images, as seen in DS-4 and DS-5 experiments where excessive synthetic data degraded performance.

### Mechanism 2
- Claim: Synthetic data generation reduces the cost and time of data collection while providing perfectly annotated samples for training.
- Mechanism: CAD models of industrial components are rendered in a simulation environment to create synthetic images. These images include the target objects with accurate bounding box annotations, eliminating the need for manual labeling.
- Core assumption: CAD models are available for the target objects and can be rendered with sufficient variation in scale, illumination, and viewpoint to create a diverse training set.
- Evidence anchors: [abstract] "By generating additional data points for underrepresented classes, they create a balanced dataset"; [section] "CAD data is available and can be utilized as a blue-print for the generation of synthetic data"
- Break condition: If the simulation environment cannot produce sufficient variation in object appearance (e.g., limited viewpoints, no occlusion), the model may overfit to synthetic characteristics and perform poorly on real data.

### Mechanism 3
- Claim: The optimal ratio of synthetic to real data (2:1) maximizes performance by balancing domain adaptation and feature learning.
- Mechanism: Too little synthetic data fails to address class imbalance, while too much synthetic data causes domain shift issues. The 2:1 ratio provides enough synthetic samples to balance the dataset without overwhelming the model with non-realistic data.
- Core assumption: There exists an optimal ratio where synthetic data sufficiently balances the dataset without introducing significant domain discrepancy.
- Evidence anchors: [section] "The optimal combination ratio of real and synthetic data is found to be 2:1 (DS-3)"; [section] "Upon further increasing the synthetic dataset (DS-4 & DS-5) the models tend to learn more features from the prominent synthetic data and therefore performed poorly"
- Break condition: If the synthetic data quality improves (becomes more photo-realistic), the optimal ratio might shift toward using more synthetic data.

## Foundational Learning

- Concept: Anchor-based object detection
  - Why needed here: YOLO and SSD models use predefined anchor boxes to predict object locations. Understanding how anchor matching works is crucial for interpreting why class balancing improves performance.
  - Quick check question: How do anchor boxes in YOLO relate to object size distribution in the training data?

- Concept: Domain adaptation
  - Why needed here: The synthetic data has different characteristics than real images. Understanding domain adaptation helps explain why too much synthetic data can hurt performance.
  - Quick check question: What happens when a model trained on synthetic data is tested on real images with different background and lighting conditions?

- Concept: Class imbalance in deep learning
  - Why needed here: The initial dataset has underrepresented small objects. Understanding class imbalance helps explain why proportional balancing improves model convergence.
  - Quick check question: How does class imbalance affect the loss function and gradient updates during training?

## Architecture Onboarding

- Component map: Real dataset → Class distribution analysis → Synthetic data generation → Combined dataset → Model training → Performance evaluation
- Critical path: Data generation → Class balancing → Model training → Performance evaluation
- Design tradeoffs:
  - Photo-realism vs. computational cost: More realistic rendering improves generalization but increases generation time
  - Dataset size vs. model performance: Too much synthetic data causes domain shift
  - Model complexity vs. inference speed: YOLOv5 offers good balance for real-time applications
- Failure signatures:
  - Model performs well on synthetic validation but poorly on real test data (domain shift)
  - mAP improves but APs remains low (model still struggles with small objects)
  - Performance degrades when synthetic data exceeds 50% of training set
- First 3 experiments:
  1. Train YOLOv5 on real data only (DS-1) to establish baseline performance
  2. Train YOLOv5 on 2:1 real:synthetic ratio (DS-3) to test optimal balancing
  3. Train YOLOv5 on synthetic-only data (DS-5) to measure domain adaptation limits

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal ratio of real to synthetic data for maximizing object detection performance in industrial scenarios with small objects?
- Basis in paper: [explicit] The paper identifies DS-3 (2:1 ratio of real to synthetic data) as the optimal combination, but suggests further investigation is needed to determine the precise optimal ratio.
- Why unresolved: The paper only tests a limited number of ratios (0%, 33%, 50%, 100% synthetic data). The performance difference between DS-3 and DS-4 suggests there might be a more optimal ratio between 50% and 100% synthetic data.
- What evidence would resolve it: Systematic testing of additional ratios between 50% and 100% synthetic data, potentially using a finer-grained approach (e.g., 60%, 70%, 80%, 90%) to pinpoint the exact optimal ratio.

### Open Question 2
- Question: How does the quality of synthetic data (e.g., photorealism) impact the performance of object detection models for small objects in industrial settings?
- Basis in paper: [explicit] The authors note that their synthetic data is "rather simple" and not photo-realistic, and suggest that improving photorealism could potentially improve performance. They also observe that DS-4 (100% synthetic data) performs worse than DS-3 (50% synthetic data), possibly due to the lack of photorealism.
- Why unresolved: The study uses a relatively simple synthetic data generation approach and does not explore the impact of varying photorealism levels.
- What evidence would resolve it: Generating synthetic datasets with varying levels of photorealism (e.g., using different rendering techniques or incorporating more realistic backgrounds and lighting) and comparing their impact on model performance.

### Open Question 3
- Question: How does the proposed proportional class-balancing technique compare to other data augmentation methods for improving small object detection in industrial scenarios?
- Basis in paper: [inferred] The paper focuses on the proportional class-balancing technique and its effectiveness, but does not compare it to other data augmentation methods (e.g., geometric transformations, color jittering, or GAN-based approaches).
- Why unresolved: The study only investigates the proportional class-balancing technique and does not provide a comparative analysis with other data augmentation methods.
- What evidence would resolve it: Conducting experiments comparing the proportional class-balancing technique to other data augmentation methods in terms of their impact on small object detection performance, using the same evaluation metrics and datasets.

## Limitations
- The optimal 2:1 real-to-synthetic ratio may not generalize to other industrial domains or object types
- Performance depends on availability of CAD models for target objects, which may not be feasible for all applications
- Study only tests three specific object detection models without exploring alternative architectures

## Confidence
- High confidence: The methodology for combining synthetic data with proportional class-balancing is clearly described and the experimental setup is well-defined
- Medium confidence: The 11.4% improvement in small object detection is well-supported within the tested industrial scenario, but the optimal ratio finding may be context-dependent
- Medium confidence: The claim that excessive synthetic data degrades performance is supported by the experiments, but the exact threshold where degradation occurs may vary with data quality

## Next Checks
1. Test the 2:1 real-to-synthetic ratio on a different industrial domain (e.g., automotive parts vs. electronics assembly) to verify the optimal ratio generalizes across applications
2. Evaluate model performance when synthetic data quality is improved (higher photo-realism) to determine if the optimal ratio shifts toward more synthetic samples
3. Conduct ablation studies to isolate the contribution of class-balancing from synthetic data generation by testing scenarios where only class distribution is modified without synthetic data