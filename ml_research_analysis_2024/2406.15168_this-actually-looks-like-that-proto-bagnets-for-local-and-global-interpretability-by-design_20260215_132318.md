---
ver: rpa2
title: 'This actually looks like that: Proto-BagNets for local and global interpretability-by-design'
arxiv_id: '2406.15168'
source_url: https://arxiv.org/abs/2406.15168
tags:
- prototypes
- drusen
- prototype
- proto-bagnet
- explanations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Proto-BagNets is a prototype-based network that combines the fine-grained,
  localized interpretability of BagNets with the global interpretability of prototype
  learning to provide accurate and clinically meaningful explanations for medical
  image classification. The authors integrate recent advances in prototype-based network
  training, including a soft aggregation layer, top-k pooling, and sparsity regularization,
  and introduce a dissimilarity loss to prevent redundant prototypes.
---

# This actually looks like that: Proto-BagNets for local and global interpretability-by-design

## Quick Facts
- arXiv ID: 2406.15168
- Source URL: https://arxiv.org/abs/2406.15168
- Reference count: 23
- Primary result: Combines BagNet's localized interpretability with prototype learning's global explanations for clinically meaningful medical image classification

## Executive Summary
Proto-BagNets introduces a prototype-based neural network architecture that merges the fine-grained, localized interpretability of BagNets with the global interpretability of prototype learning for medical image classification. The model employs small, fixed-size prototypes with high-resolution similarity maps to provide precise local explanations while maintaining diverse, clinically relevant global prototypes through specialized training techniques. Evaluated on drusen detection in retinal OCT images, Proto-BagNet achieves performance comparable to state-of-the-art interpretable and non-interpretable models while providing faithful, meaningful explanations of its decision-making process.

## Method Summary
Proto-BagNet integrates prototype-based learning with BagNet's architecture to create an interpretable-by-design model. The system uses small, fixed-size prototypes (7x7 patches) that maintain high-resolution similarity maps for precise local explanations. Key innovations include a soft aggregation layer for prototype relevance computation, top-k pooling for prototype selection, sparsity regularization to encourage diverse prototypes, and a dissimilarity loss to prevent redundant prototypes. The model is trained using a combination of classification loss, reconstruction loss, and the proposed dissimilarity loss, with prototype updates through feature reconstruction rather than backpropagation.

## Key Results
- Achieves comparable performance to state-of-the-art interpretable and non-interpretable models on drusen detection in retinal OCT images
- Provides precise local explanations through small, fixed-size prototypes and high-resolution similarity maps
- Generates meaningful global explanations through diverse and clinically relevant prototypes that accurately localize drusen lesions

## Why This Works (Mechanism)
The architecture works by combining localized feature extraction with prototype-based reasoning. BagNet's small receptive fields ensure precise localization of features, while the prototype layer aggregates these local features into globally meaningful representations. The soft aggregation layer allows for nuanced relevance scoring of prototypes, and the dissimilarity loss ensures prototype diversity. This combination enables the model to provide both precise local explanations (through high-resolution similarity maps) and meaningful global explanations (through diverse, clinically relevant prototypes).

## Foundational Learning

1. **Prototype-based learning**: Uses learned prototypes to represent data patterns and make predictions through similarity matching. Needed for global interpretability; check by examining prototype diversity and clinical relevance.

2. **BagNet architecture**: Employs small, fixed-size receptive fields for precise feature localization. Needed for accurate local explanations; check by analyzing similarity map resolution and localization accuracy.

3. **Soft aggregation layer**: Computes prototype relevance using a differentiable function rather than hard selection. Needed for end-to-end training; check by comparing with hard aggregation approaches.

4. **Top-k pooling**: Selects the most relevant prototypes for final prediction. Needed to reduce noise and improve robustness; check by varying k values and measuring impact on accuracy.

5. **Sparsity regularization**: Encourages diverse prototype learning by penalizing similar prototypes. Needed to prevent redundancy; check by measuring prototype pairwise distances.

6. **Dissimilarity loss**: Explicitly maximizes distances between prototype embeddings. Needed for guaranteed prototype diversity; check by comparing with models using only sparsity regularization.

## Architecture Onboarding

**Component map**: Input -> BagNet feature extractor -> Prototype layer -> Soft aggregation -> Top-k pooling -> Classification output

**Critical path**: Input images pass through BagNet to extract features, which are compared to prototypes using the soft aggregation layer. The top-k most relevant prototypes are selected and used for final classification through a linear layer.

**Design tradeoffs**: Fixed small prototypes (7x7) provide precise localization but may miss larger contextual patterns. The soft aggregation layer enables end-to-end training but adds complexity compared to hard selection methods. Prototype diversity regularization improves interpretability but may reduce reconstruction accuracy.

**Failure signatures**: Poor localization accuracy indicates prototype size is inappropriate for the task. Redundant or clinically irrelevant prototypes suggest the dissimilarity loss or sparsity regularization is insufficient. Low accuracy despite good interpretability may indicate the prototype set doesn't adequately cover the data distribution.

**First experiments**:
1. Ablation study varying prototype size (5x5, 7x7, 9x9) to quantify impact on localization accuracy and interpretability
2. Comparison of soft versus hard aggregation layers on both accuracy and prototype diversity
3. Analysis of prototype coverage by measuring reconstruction error across different data subsets

## Open Questions the Paper Calls Out
The paper acknowledges that the generalizability of Proto-BagNet beyond the drusen detection task remains uncertain, and that clinical relevance of learned prototypes needs more systematic validation beyond visual inspection.

## Limitations
- Generalizability beyond drusen detection in retinal OCT images is uncertain
- Clinical relevance of prototypes primarily demonstrated through visual inspection rather than systematic validation with domain experts
- Computational efficiency claims lack comprehensive evaluation including training overhead

## Confidence

**Prototype learning effectiveness**: High
**Clinical interpretability of prototypes**: Medium  
**Computational efficiency improvements**: Low
**Generalizability to other medical imaging tasks**: Low

## Next Checks

1. Conduct ablation studies systematically varying prototype size, number, and regularization strength to quantify their individual contributions to both accuracy and interpretability

2. Perform cross-dataset validation on diverse medical imaging tasks (e.g., chest X-rays, histopathology) to assess generalizability of the Proto-BagNet architecture

3. Implement quantitative prototype diversity metrics and conduct radiologist studies to validate clinical relevance of learned prototypes beyond visual inspection