---
ver: rpa2
title: 'FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity'
arxiv_id: '2406.18995'
source_url: https://arxiv.org/abs/2406.18995
tags:
- class
- classes
- learning
- labels
- client
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses federated multi-label medical image classification
  under task heterogeneity, where different institutions can only diagnose partial
  categories due to varying expertise and disease prevalence. The authors propose
  FedMLP, a two-stage method that first generates class prototypes from warm-up training
  using weighted-partial-class loss, then performs pseudo-label tagging with self-adaptive
  thresholds and consistency regularization.
---

# FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity

## Quick Facts
- arXiv ID: 2406.18995
- Source URL: https://arxiv.org/abs/2406.18995
- Reference count: 40
- Primary result: FedMLP significantly outperforms state-of-the-art federated semi-supervised and noisy label learning approaches, achieving 67.29 mAP on average for ICH and 26.50 mAP for ChestXray14 under severe label missing conditions.

## Executive Summary
This paper addresses federated multi-label medical image classification under task heterogeneity, where different institutions can only diagnose partial categories due to varying expertise and disease prevalence. The authors propose FedMLP, a two-stage method that first generates class prototypes from warm-up training using weighted-partial-class loss, then performs pseudo-label tagging with self-adaptive thresholds and consistency regularization. Experiments on ICH and ChestXray14 datasets show FedMLP significantly outperforms state-of-the-art federated semi-supervised and noisy label learning approaches.

## Method Summary
FedMLP is a two-stage federated learning method for multi-label medical image classification under task heterogeneity. Stage 1 involves warm-up training using a weighted-partial-class loss with logit adjustment to mitigate class imbalance and reduce false negatives, establishing high-quality class prototypes. Stage 2 performs pseudo-label tagging using these prototypes with self-adaptive thresholds that automatically adjust to class learning difficulty, combined with consistency regularization using the global model to prevent forgetting missing class knowledge. The method handles the challenge where each client only has labels for a subset of all possible classes.

## Key Results
- FedMLP achieves 67.29 mAP on average for ICH dataset under severe label missing conditions
- FedMLP achieves 26.50 mAP for ChestXray14 dataset under severe label missing conditions
- FedMLP significantly outperforms state-of-the-art federated semi-supervised and noisy label learning approaches across both datasets

## Why This Works (Mechanism)

### Mechanism 1
The two-stage design (warm-up + pseudo-labeling) effectively addresses task heterogeneity by first building robust class prototypes and then progressively transferring missing knowledge to each client. In the warm-up stage, FedMLP uses a weighted-partial-class loss with logit adjustment to mitigate the effects of class imbalance and reduce false negatives. This establishes high-quality class prototypes. In the pseudo-labeling stage, these prototypes are used to select high-confidence samples for missing labels, with self-adaptive thresholds automatically adjusting to class learning difficulty.

### Mechanism 2
The self-adaptive threshold mechanism automatically adjusts sample selection ratios based on class learning difficulty, ensuring efficient knowledge transfer for both hot and cool classes. The learning difficulty for each class is estimated using uncertainty metrics from local data, then aggregated globally. This determines the selection ratios τ0 and τ1 for negative and positive samples respectively. More difficult classes get smaller selection ratios to avoid introducing noise.

### Mechanism 3
Consistency regularization between global and local models prevents catastrophic forgetting of missing class knowledge during training. The global model acts as a teacher, providing soft labels for samples where pseudo-labels are uncertain or unavailable. This is combined with the hard pseudo-labels using a weighted-partial-class loss, ensuring all samples contribute to learning.

## Foundational Learning

- Concept: Federated Learning with task heterogeneity
  - Why needed here: The paper addresses a scenario where different clients have access to different subsets of classes, which is more realistic than assuming all clients have the same classes.
  - Quick check question: What's the key difference between task homogeneous and task heterogeneous federated learning?

- Concept: Multi-label classification with partial labels
  - Why needed here: Each client only has labels for a subset of all possible classes, creating a challenging learning scenario where knowledge must be transferred across clients.
  - Quick check question: How does partial label setting differ from traditional multi-label classification?

- Concept: Prototype-based learning
  - Why needed here: Prototypes are used to represent class characteristics and enable pseudo-labeling of missing classes based on feature similarity.
  - Quick check question: What role do class prototypes play in the FedMLP approach?

## Architecture Onboarding

- Component map: Data Augmentation -> Warm-up training with WPC loss -> Prototype generation and aggregation -> Self-adaptive threshold selection -> Consistency regularization with global model -> FedAvg aggregation

- Critical path: Warm-up → Prototype generation → Pseudo-labeling → Consistency regularization → Aggregation

- Design tradeoffs:
  - Warm-up rounds vs. communication efficiency
  - Selection ratio parameters (T0, T1) vs. noise tolerance
  - Local vs. global uncertainty estimation for threshold adaptation

- Failure signatures:
  - Warm-up stage fails: Poor performance on all classes, especially cool classes
  - Pseudo-labeling fails: Model performs well on labeled classes but poorly on missing classes
  - Consistency regularization fails: Model performance degrades over communication rounds

- First 3 experiments:
  1. Baseline FedAvg comparison on both datasets with full labels to establish performance ceiling
  2. FedMLP with different numbers of warm-up rounds to find optimal trade-off
  3. FedMLP with different selection ratio parameters (T0, T1) to evaluate sensitivity to hyperparameter choices

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the FedMLP approach be extended to handle more than 10 classes while maintaining performance?
- Basis in paper: [inferred] The paper focuses on datasets with up to 5 classes for ICH and 8 classes for ChestXray14. The authors mention that "with increasing class absences, existing FL approaches struggle particularly with less prevalent 'cool classes'" and FedMLP consistently achieves top or near-top results. However, there is no discussion on how the approach would scale to datasets with a larger number of classes.
- Why unresolved: The paper does not provide any insights into the scalability of the FedMLP approach to datasets with a larger number of classes. It is unclear whether the current methodology would still be effective or if modifications would be necessary.
- What evidence would resolve it: Experiments on datasets with a larger number of classes, such as ImageNet or other multi-label medical datasets, would provide evidence on the scalability of the FedMLP approach. Additionally, theoretical analysis on the computational complexity and memory requirements of the approach as the number of classes increases would help understand its limitations.

### Open Question 2
- Question: How does the FedMLP approach handle cases where the distribution of classes across clients is highly imbalanced?
- Basis in paper: [explicit] The paper mentions that "due to diversity in class interest, |Si| is not identical for each class" and that "a larger |Si| implies a more common disease i, which is easier to learn than other classes, denoted as 'hot classes', otherwise as 'cool classes'". However, there is no discussion on how the approach handles cases where the distribution of classes across clients is highly imbalanced, such as when one client has data for only one class while another client has data for multiple classes.
- Why unresolved: The paper does not provide any insights into how the FedMLP approach handles cases of highly imbalanced class distributions across clients. It is unclear whether the current methodology would still be effective or if modifications would be necessary.
- What evidence would resolve it: Experiments on datasets with highly imbalanced class distributions across clients, such as synthetic datasets or real-world datasets with known class imbalances, would provide evidence on the robustness of the FedMLP approach. Additionally, theoretical analysis on the impact of class imbalance on the convergence and performance of the approach would help understand its limitations.

### Open Question 3
- Question: How does the FedMLP approach handle cases where the feature distributions of the same class differ significantly across clients due to variations in imaging protocols or equipment?
- Basis in paper: [explicit] The paper mentions that "attributed to heightened privacy concerns, merging multiple medical image datasets into a unified one is often prohibited, presenting additional challenges in developing deep neural models for automated disease classification". However, there is no discussion on how the FedMLP approach handles cases where the feature distributions of the same class differ significantly across clients due to variations in imaging protocols or equipment.
- Why unresolved: The paper does not provide any insights into how the FedMLP approach handles cases of domain shift or distribution mismatch across clients. It is unclear whether the current methodology would still be effective or if modifications would be necessary.
- What evidence would resolve it: Experiments on datasets with known domain shifts or distribution mismatches across clients, such as multi-site medical imaging datasets or datasets with variations in imaging protocols, would provide evidence on the robustness of the FedMLP approach. Additionally, theoretical analysis on the impact of domain shift on the convergence and performance of the approach would help understand its limitations.

## Limitations

- The method's performance heavily depends on the quality of pseudo-labels, which could degrade with more severe label missing conditions than tested
- The self-adaptive threshold mechanism relies on local uncertainty estimates that may not generalize well across different medical imaging domains
- No ablation study on the consistency regularization component to quantify its individual contribution

## Confidence

**Medium confidence** in core claims:
- Empirical results show FedMLP outperforms state-of-the-art methods on two medical datasets
- The two-stage approach is well-motivated and addresses key challenges in task-heterogeneous federated learning
- Some limitations affect robustness: performance depends on pseudo-label quality, self-adaptive thresholds may not generalize, and no ablation studies were conducted

## Next Checks

1. Test FedMLP with non-uniform label distribution across clients to better simulate real-world task heterogeneity
2. Evaluate performance degradation as missing class severity increases beyond the tested 4-class limit
3. Conduct ablation studies removing the consistency regularization and prototype-based pseudo-labeling components to quantify their individual contributions