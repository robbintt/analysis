---
ver: rpa2
title: Trajectory Imputation in Multi-Agent Sports with Derivative-Accumulating Self-Ensemble
arxiv_id: '2408.10878'
source_url: https://arxiv.org/abs/2408.10878
tags:
- midas
- missing
- data
- trajectories
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents MIDAS, a data-efficient framework for imputing
  missing values in multi-agent sports trajectories. The method addresses the challenges
  of dynamic inter-agent interactions and physical plausibility in sports data.
---

# Trajectory Imputation in Multi-Agent Sports with Derivative-Accumulating Self-Ensemble

## Quick Facts
- arXiv ID: 2408.10878
- Source URL: https://arxiv.org/abs/2408.10878
- Authors: Han-Jun Choi; Hyunsung Kim; Minho Lee; Minchul Jeong; Chang-Jo Kim; Jinsung Yoon; Sang-Ki Ko
- Reference count: 33
- One-line primary result: MIDAS achieves state-of-the-art performance in sports trajectory imputation with improved physical plausibility

## Executive Summary
This paper introduces MIDAS, a data-efficient framework for imputing missing values in multi-agent sports trajectories. The method addresses the challenges of dynamic inter-agent interactions and physical plausibility by predicting positions, velocities, and accelerations using a Set Transformer-based neural network, then generating alternative estimates through derivative-accumulating predictions in both forward and backward directions. These predictions are combined using a learnable weighted ensemble to produce final imputed trajectories that outperform existing baselines in both positional accuracy and physical plausibility, particularly in limited-data settings.

## Method Summary
MIDAS uses a Set Transformer encoder to process player trajectories and produce permutation-equivariant embeddings, combined with a global Set Transformer and player-wise Bi-LSTMs to capture temporal patterns. The framework generates three predictions: an initial prediction (IP) that directly predicts positions, velocities, and accelerations; and forward/backward derivative-accumulating predictions (DAP) that recursively accumulate predicted derivatives from nearest observed positions. A learnable Bi-LSTM computes ensemble weights to combine these predictions, allowing the model to adaptively balance their strengths across different missing patterns and segment lengths.

## Key Results
- Outperforms existing baselines in both positional accuracy and physical plausibility metrics
- Shows significant improvements in limited-data settings where other methods struggle
- Demonstrates practical utility in downstream tasks like distance estimation and pass success probability
- Achieves consistent performance across three different sports datasets (soccer, basketball, American football)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The derivative-accumulating self-ensemble (DAP) improves physical plausibility by enforcing temporal consistency in velocity and acceleration predictions.
- Mechanism: Instead of directly predicting positions, the model first predicts velocities and accelerations using a Set Transformer + Bi-LSTM backbone, then recursively accumulates these derivatives from the nearest observed positions in both forward and backward directions to generate alternative position estimates.
- Core assumption: Physical relationships between positions, velocities, and accelerations hold for sports trajectories and can be exploited for more stable predictions.
- Evidence anchors:
  - [abstract]: "It jointly predicts positions, velocities, and accelerations via a Set Transformer-based neural network and generates alternative estimates by recursively accumulating predicted velocity and acceleration values."
  - [section]: "We make alternative derivative-accumulating predictions (DAP), which enforces the physical relationships in Eq.(1) for improved stability."
- Break condition: If velocity/acceleration predictions are highly inaccurate, error compounding during accumulation would degrade performance, especially for longer missing segments.

### Mechanism 2
- Claim: The weighted ensemble dynamically balances initial predictions (IP) and derivative-accumulating predictions (DAP) to mitigate their respective weaknesses.
- Mechanism: A learnable Bi-LSTM computes ensemble weights λk,i, λk,f, λk,b at each time step based on the three predictions and context embeddings, allowing the model to adaptively favor more reliable predictions.
- Core assumption: IP is robust to endpoint anchoring errors while DAP is more accurate for shorter missing segments; the optimal balance varies across segments and sports.
- Evidence anchors:
  - [abstract]: "These predictions are then combined using a learnable weighted ensemble to produce final imputed trajectories."
  - [section]: "Rather than exclusively relying on one prediction, it performs a soft voting ensemble by computing a weighted sum of three predictions, IP and forward/backward DAPs."
- Break condition: If the ensemble weight learning fails to capture segment-specific reliability patterns, the combination could underperform simple baselines.

### Mechanism 3
- Claim: The Set Transformer architecture ensures permutation-equivariance, correctly handling the unordered nature of multi-agent sports data.
- Mechanism: The Set Transformer encoder processes player trajectories to produce permutation-equivariant embeddings {zk_t}, while a global embedding zt is obtained via a full Set Transformer, both fed into player-wise Bi-LSTMs.
- Core assumption: Player order is arbitrary in sports data and should not affect predictions; permutation-equivariance is necessary for fair treatment of all agents.
- Evidence anchors:
  - [abstract]: "By employing the Set Transformer, it models dynamic inter-agent relationships while ensuring permutation-equivariance with respect to agents."
  - [section]: "Since there is generally no inherent order among players in team sports, modeling their movements requires ensuring permutation-equivariance."
- Break condition: If the Set Transformer fails to capture complex player interactions, permutation-equivariance alone would not guarantee good performance.

## Foundational Learning

- Concept: Set Transformer
  - Why needed here: Multi-agent sports data has no inherent player order, requiring permutation-equivariant processing to avoid bias toward specific players.
  - Quick check question: What property does a Set Transformer guarantee that a standard Transformer does not?

- Concept: Bi-LSTM for sequential modeling
  - Why needed here: Player trajectories are sequential time series where past and future contexts both matter for accurate imputation.
  - Quick check question: How does a Bi-LSTM differ from a standard LSTM in handling temporal dependencies?

- Concept: Physical constraints in trajectory data
  - Why needed here: Player movements must obey biomechanical limits (speed, acceleration, directional change) that naive imputation methods often violate.
  - Quick check question: What are the three key physical quantities that must be consistent in sports trajectory data?

## Architecture Onboarding

- Component map: Input → Set Transformer → Bi-LSTM → IP/DAP → Ensemble → Output
- Critical path: Input → Set Transformer → Bi-LSTM → IP/DAP → Ensemble → Output
- Design tradeoffs:
  - Using derivatives improves physical plausibility but risks error compounding
  - Ensemble adds complexity but provides robustness to varying missing patterns
  - Permutation-equivariance ensures fairness but may limit modeling of ordered relationships
- Failure signatures:
  - High step change error indicates unrealistic velocity/acceleration patterns
  - Performance degradation with longer missing segments suggests accumulation issues
  - Similar performance to simple baselines may indicate Set Transformer ineffectiveness
- First 3 experiments:
  1. Compare PE and SCE on uniform missing scenario with and without DAP component
  2. Test ensemble weight sensitivity by fixing weights at different values
  3. Evaluate performance on varying missing lengths to assess error compounding effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of MIDAS scale with increasing numbers of agents (e.g., in sports with larger teams or in other domains like crowd simulation)?
- Basis in paper: [inferred] The paper mentions future work exploring extension to other domains like autonomous driving and crowd simulation, and the model uses a Set Transformer which is designed to handle variable numbers of agents.
- Why unresolved: The experiments are limited to three sports datasets with relatively small team sizes (6-22 players). The theoretical time complexity analysis shows dependence on the number of players, but empirical scaling behavior is not tested.
- What evidence would resolve it: Systematic experiments on datasets with varying numbers of agents (e.g., larger team sports, crowd datasets) measuring performance and computational efficiency as agent count increases.

### Open Question 2
- Question: What is the optimal balance between using derivative-accumulating predictions versus initial predictions across different types of sports or motion patterns?
- Basis in paper: [explicit] The paper discusses how the advantage of DAP over IP varies by sport (soccer vs basketball) and with missing segment length, but doesn't provide a general framework for determining optimal weighting.
- Why unresolved: While the paper shows that MIDAS adaptively learns ensemble weights, it doesn't characterize when and why certain prediction types should be favored. The observed differences between sports suggest underlying factors that aren't fully explained.
- What evidence would resolve it: Analysis of how motion characteristics (velocity variance, directional change frequency, team coordination patterns) correlate with optimal prediction type usage, potentially leading to sport-specific or pattern-specific weighting strategies.

### Open Question 3
- Question: How sensitive is MIDAS to the choice of physical constraints and thresholds (e.g., speed limits, acceleration bounds) used for outlier detection in downstream applications?
- Basis in paper: [explicit] The applications section mentions removing outliers based on specific thresholds (12 m/s for speed, 8 m/s² for acceleration), but doesn't explore sensitivity to these choices.
- Why unresolved: The paper demonstrates practical utility but uses fixed thresholds without investigating how different choices might affect downstream task performance or whether these thresholds should be learned rather than fixed.
- What evidence would resolve it: Systematic evaluation of downstream task performance (e.g., distance estimation, pass success probability) across different threshold values, and comparison of fixed versus learned thresholds.

## Limitations
- Lacks detailed architectural specifications for Set Transformer encoder (attention heads, dimensions) and training hyperparameters
- Claim that derivative-accumulation prevents error compounding is theoretically sound but not empirically validated
- No ablation studies comparing performance with non-permutation-equivariant architectures

## Confidence
- **High confidence** in the positional accuracy improvements over baselines, supported by quantitative results across three sports datasets
- **Medium confidence** in the physical plausibility claims, as step change error improvements are demonstrated but the underlying mechanism's robustness to poor derivative predictions is not tested
- **Low confidence** in the Set Transformer's necessity, as ablation studies comparing to non-permutation-equivariant architectures are absent

## Next Checks
1. Test error propagation by intentionally degrading velocity/acceleration prediction quality and measuring impact on DAP performance across different missing segment lengths
2. Compare performance with a non-permutation-equivariant architecture (e.g., standard Transformer) to quantify the actual benefit of permutation-equivariance in this domain
3. Validate ensemble weight adaptation by fixing weights at extreme values (0.33 each, all IP, all DAP) and measuring performance degradation across varying missing patterns