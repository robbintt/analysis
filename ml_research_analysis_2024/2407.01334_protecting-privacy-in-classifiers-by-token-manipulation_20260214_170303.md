---
ver: rpa2
title: Protecting Privacy in Classifiers by Token Manipulation
arxiv_id: '2407.01334'
source_url: https://arxiv.org/abs/2407.01334
tags:
- token
- sten
- text
- privacy
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses privacy risks in using large language models
  (LLMs) as remote services, where sensitive information is exposed to untrusted providers
  or eavesdroppers. The authors propose two approaches for protecting privacy at the
  token level without accessing LLM parameters: (1) simple many-to-one token mapping
  functions that partition vocabulary into pairs/triplets and map to representative
  tokens, and (2) STENCIL, which creates context-aware tokens by absorbing information
  from adjacent tokens.'
---

# Protecting Privacy in Classifiers by Token Manipulation

## Quick Facts
- **arXiv ID**: 2407.01334
- **Source URL**: https://arxiv.org/abs/2407.01334
- **Reference count**: 18
- **Key outcome**: STENCIL achieves 83-90% accuracy while reducing attacker success rate from 94% to 18-49% on SST2

## Executive Summary
This paper addresses privacy risks in using large language models as remote services, where sensitive information is exposed to untrusted providers. The authors propose token-level privacy preservation methods that work without accessing LLM parameters. Two approaches are evaluated: simple many-to-one token mapping and STENCIL, a context-aware method that manipulates tokens based on neighboring information. Experiments on SST2, IMDb, and QNLI datasets show that while simple mapping functions are easily reconstructed, STENCIL provides better privacy preservation with modest performance trade-offs.

## Method Summary
The paper proposes two privacy-preserving token manipulation methods. First, simple many-to-one mapping partitions vocabulary into pairs or triplets and maps them to representative tokens, reducing search space complexity. Second, STENCIL creates context-aware tokens by combining embeddings of neighboring tokens weighted by a smoothing function, then selecting the nearest token in embedding space. Both methods operate at the token level without requiring access to LLM parameters, making them suitable for protecting sensitive information when using remote LLM services.

## Key Results
- Simple random mapping reduces attacker success rate but is easily reconstructed using beam search
- STENCIL maintains 83-90% classification accuracy while reducing attacker success from 94% to 18-49% on SST2
- STENCIL p variant (excluding target token) provides stronger privacy at the cost of performance
- Context-aware manipulation outperforms simple frequency-based mapping across all tested datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Many-to-one token mapping reduces vocabulary size while maintaining task performance if high-frequency tokens are chosen as representatives
- Mechanism: Partitioning vocabulary into pairs/triplets and mapping to representative tokens introduces ambiguity that protects privacy by creating a search space of 2^m or 3^m possible permutations
- Core assumption: High-frequency tokens carry more task-relevant information than low-frequency tokens
- Evidence anchors:
  - [abstract] "simple mapping functions are easily reconstructed by attackers despite reducing vocabulary size"
  - [section 2] "High-frequency mapping token pairs are selected based on their frequency of occurrence... With the higher-frequency token being designated as the representative"
  - [corpus] Weak evidence - no corpus neighbors directly address frequency-based mapping effectiveness
- Break condition: Attacker gains access to the mapping specifications and uses beam search with language model scoring to reconstruct original text

### Mechanism 2
- Claim: Context-aware token manipulation (STENCIL) provides better privacy preservation than simple mapping by absorbing information from adjacent tokens
- Mechanism: Generating new tokens by combining embeddings of neighboring tokens weighted by a smoothing function, then selecting the nearest token in embedding space
- Core assumption: Contextual information can be leveraged to maintain task performance while obscuring individual token identities
- Evidence anchors:
  - [abstract] "STENCIL, which creates context-aware tokens by absorbing information from adjacent tokens"
  - [section 3] "a mapped token in a sequence 'absorbs' information from adjacent tokens to form a new context-aware token"
  - [corpus] Weak evidence - corpus neighbors focus on different privacy approaches not directly comparable
- Break condition: Attacker uses nearest-neighbor reconstruction on perturbed embeddings to statistically determine original tokens

### Mechanism 3
- Claim: Excluding the target token from contextual manipulation (STENCIL p) enhances privacy at the cost of some performance
- Mechanism: Similar to STENCIL but sets the weight of the target token to zero, forcing the new token to be completely different from the original
- Core assumption: Complete separation from original token identity provides stronger privacy guarantees
- Evidence anchors:
  - [section 3] "STENCIL p, we exclude the target token from the computation of the quasi-embedding vector... by setting fk to zero"
  - [section 3.1] "This exclusion significantly diminishes the attacker's ability to reconstruct the original token at the expense of performance"
  - [corpus] No direct evidence in corpus - this is a novel variant not mentioned in neighbors
- Break condition: Performance degradation becomes too severe for practical use cases

## Foundational Learning

- Concept: Local Differential Privacy
  - Why needed here: Provides the theoretical framework for understanding how noise introduction protects privacy while maintaining utility
  - Quick check question: How does the ε parameter in differential privacy relate to the noise level introduced in token manipulation?

- Concept: Token Embeddings and Cosine Similarity
  - Why needed here: Understanding how tokens are represented as vectors and how similarity measures are used to find nearest neighbors
  - Quick check question: Why does the paper use cosine similarity rather than Euclidean distance for finding nearest tokens in embedding space?

- Concept: Beam Search and Nucleus Sampling
  - Why needed here: These search strategies are used by attackers to reconstruct original text from mapped tokens
  - Quick check question: How does dynamic candidate pruning in nucleus sampling differ from fixed-width beam search?

## Architecture Onboarding

- Component map: Input text → Tokenizer → Privacy-preserving token manipulation → Classifier (RoBERTa/T5) → Output prediction
- Critical path: Token manipulation (both mapping and STENCIL) → Classifier inference
- Performance bottleneck: nearest-neighbor search in embedding space (0.005 seconds per token)
- Design tradeoffs:
  - Privacy vs. performance: Higher privacy requires more aggressive token manipulation but reduces classification accuracy
  - Computational cost vs. effectiveness: More neighbors in STENCIL increases computation but may improve performance
  - Vocabulary size reduction vs. reconstruction difficulty: Smaller active vocabulary is computationally efficient but may be more vulnerable
- Failure signatures:
  - High reconstruction success rate by attacker indicates insufficient privacy
  - Significant drop in classification accuracy indicates too aggressive manipulation
  - Long processing times may indicate inefficient nearest-neighbor search implementation
- First 3 experiments:
  1. Implement basic 2-random token mapping and measure impact on SST2 accuracy vs. reconstruction success rate
  2. Implement STENCIL with varying window sizes (5, 7, 9, 11) and measure privacy-performance tradeoff on IMDb dataset
  3. Compare STENCIL vs. STENCIL p on QNLI task to quantify privacy gains vs. accuracy loss

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can token manipulation methods be extended to generative tasks (e.g., summarization, translation) while maintaining both privacy and performance?
- Basis in paper: [explicit] The authors state "Our experiments were limited to classification tasks in the English language. In future research, we intend to explore the effectiveness of these methods in generative tasks, across languages, and in multilingual settings."
- Why unresolved: The paper only evaluates token manipulation on classification tasks (SST2, IMDb, QNLI), leaving generative tasks unexplored. Generative tasks present unique challenges as they require maintaining coherent output structure and fluency while preserving privacy.
- What evidence would resolve it: Empirical evaluation of STENCIL and baseline methods on generative tasks like summarization or machine translation, measuring both task performance (ROUGE, BLEU scores) and privacy preservation metrics.

### Open Question 2
- Question: What mathematical framework can formally prove the privacy guarantees of token manipulation methods against various attacker models?
- Basis in paper: [inferred] The authors note "We demonstrated the privacy achieved by our methods empirically under one attacking scenario. Further comprehensive testing or mathematical proofs would enhance our understanding of the extent of privacy achieved."
- Why unresolved: The paper provides empirical evaluations against specific attacker models (brute-force, oracle, nearest-neighbor) but lacks formal privacy guarantees. Current differential privacy frameworks focus on embedding-level perturbations rather than token-level manipulations.
- What evidence would resolve it: A formal privacy analysis using information-theoretic measures or differential privacy bounds that quantify the privacy-utility tradeoff for different token manipulation strategies across various attacker capabilities.

### Open Question 3
- Question: How can token manipulation methods incorporate linguistic properties (syntax, semantics) to maintain grammaticality and readability while preserving privacy?
- Basis in paper: [explicit] The authors state "An inherent problem with existing privacy-preserving techniques is their inability to maintain linguistic properties such as grammar and readability... Therefore, an additional avenue we plan to explore is application of these and similar rules in differential privacy techniques."
- Why unresolved: The current STENCIL method and baseline mappers focus on semantic preservation but do not explicitly consider syntactic constraints. This leads to grammatically awkward or semantically nonsensical outputs as shown in Table 2.
- What evidence would resolve it: Implementation of token manipulation methods that incorporate syntactic constraints (POS tags, dependency relations) or semantic similarity measures, with evaluation showing improved grammaticality metrics while maintaining privacy levels.

## Limitations
- Evaluation focuses on controlled settings with specific datasets (SST2, IMDb, QNLI) and relatively short sequences
- Simple mapping functions are easily reconstructed by attackers using beam search and language model scoring
- Reliance on nearest-neighbor search introduces computational overhead (0.005 seconds per token) that may not scale well
- Privacy guarantees are empirically demonstrated but lack formal mathematical proofs

## Confidence
- **High confidence**: The core mechanism of STENCIL (context-aware token manipulation using weighted neighbor embeddings) is well-defined and experimentally validated
- **Medium confidence**: The privacy claims are supported by experimental evidence but may not generalize to all attack scenarios
- **Low confidence**: Claims about STENCIL p providing "significant" privacy improvements over STENCIL are based on limited experimental evidence

## Next Checks
1. **Adversarial Robustness Test**: Implement a stronger attacker using gradient-based reconstruction methods that leverage knowledge of the STENCIL transformation process, measuring whether the 18-49% attacker success rate degrades under more sophisticated attacks.

2. **Cross-Domain Generalization**: Evaluate STENCIL on medical, legal, and financial text domains where privacy concerns are most critical, measuring whether the observed performance-privacy tradeoffs (83-90% accuracy with 18-49% attacker success) hold for domain-specific vocabulary and semantic structures.

3. **Dynamic Privacy Budget Allocation**: Implement a system that adjusts STENCIL parameters (window size, σ values) based on text sensitivity scoring, testing whether adaptive privacy levels can maintain higher accuracy for low-sensitivity content while providing stronger protection for sensitive information.