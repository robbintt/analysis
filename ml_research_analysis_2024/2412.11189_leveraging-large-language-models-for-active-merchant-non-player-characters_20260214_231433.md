---
ver: rpa2
title: Leveraging Large Language Models for Active Merchant Non-player Characters
arxiv_id: '2412.11189'
source_url: https://arxiv.org/abs/2412.11189
tags:
- merchant
- item
- llms
- items
- prices
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses passivity in merchant NPCs by proposing a
  framework called MART, which uses large language models to enable dynamic pricing
  and negotiation. The framework includes an appraiser module for estimating item
  prices from descriptions and a negotiator module for conducting price negotiations
  with players.
---

# Leveraging Large Language Models for Active Merchant Non-player Characters

## Quick Facts
- arXiv ID: 2412.11189
- Source URL: https://arxiv.org/abs/2412.11189
- Authors: Byungjun Kim; Minju Kim; Dayeon Seo; Bugeun Kim
- Reference count: 40
- Key outcome: Proposed MART framework uses LLMs for dynamic pricing and negotiation in merchant NPCs

## Executive Summary
This study addresses passivity in merchant NPCs by proposing a framework called MART, which uses large language models to enable dynamic pricing and negotiation. The framework includes an appraiser module for estimating item prices from descriptions and a negotiator module for conducting price negotiations with players. Experiments compared different training methods and model sizes, finding that finetuning and knowledge distillation enable smaller LLMs to perform effectively. Supervised finetuning achieved low price estimation errors (MAPE around 2.66%), while knowledge distillation allowed smaller models to reach high persuasiveness scores (up to 3.99/5). However, in-context learning with larger models produced the most accurate appraisals but occasionally generated unexpected outputs. The study also identified three irregular cases: giveaways, improvisations, and arithmetic errors, which developers should handle when deploying such systems.

## Method Summary
The MART framework employs two LLM-based modules: an appraiser that estimates item prices from descriptions using supervised finetuning with adapter heads, and a negotiator that conducts price negotiations using knowledge distillation from larger models. The system was trained on WoW Classic item data (3,270 items) and generated negotiation dialogues (2,943 conversations). Two approaches were compared for each module: in-context learning vs. supervised finetuning for appraisal, and zero-shot prompting vs. knowledge distillation for negotiation. The framework aims to create more engaging merchant NPCs that can dynamically price items and negotiate with players rather than using fixed prices.

## Key Results
- Finetuning smaller LLMs achieved comparable performance to much larger models in both appraisal and negotiation tasks
- Knowledge distillation enabled smaller models to reach high persuasiveness scores (up to 3.99/5) while reducing computational costs
- In-context learning with larger models produced the most accurate appraisals but occasionally generated unexpected outputs
- Three irregular cases were identified: giveaways, improvisations, and arithmetic errors occurring in approximately 2.7% of cases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Finetuning smaller LLMs (SFT) can achieve comparable performance to much larger models in both appraisal and negotiation tasks.
- Mechanism: By freezing base LLM parameters and training an adapter head (for appraisal) or using knowledge distillation (for negotiation), smaller models can learn task-specific behaviors without the computational overhead of full fine-tuning or using massive models.
- Core assumption: The base LLM has sufficient general reasoning capabilities that can be adapted to specific game-related tasks with relatively small amounts of task-specific training data.
- Evidence anchors: [abstract] "finetuning and knowledge distillation enable smaller LLMs to perform effectively"; [section] "the SFT method is efficient for developing an appraiser module. Results show that SFT-8b performed much closer to ICL-405b than to ICL-8b"

### Mechanism 2
- Claim: Large language models can effectively handle complex reasoning tasks like item appraisal and negotiation by leveraging their ability to understand natural language descriptions and apply learned patterns.
- Mechanism: LLMs can parse item descriptions containing details like level requirements, effects, and durability, then use this information to estimate prices (appraisal) or generate persuasive negotiation dialogue (negotiation).
- Core assumption: Item descriptions contain sufficient information about item utility and value, and LLMs can effectively extract and reason about this information.
- Evidence anchors: [abstract] "appraiser module for estimating item prices from descriptions"; [section] "we used item descriptions to estimate the item's value. Specifically, we let LLMs appraise game items by observing other game items"

### Mechanism 3
- Claim: Knowledge distillation can effectively transfer persuasive negotiation capabilities from large models to smaller, more deployable models.
- Mechanism: By training smaller "student" models on negotiation data generated by larger "teacher" models, the students learn to emulate the teacher's persuasive tactics while being more computationally efficient.
- Core assumption: The larger teacher model has learned effective persuasion strategies that can be distilled into smaller models without significant loss of quality.
- Evidence anchors: [abstract] "knowledge distillation allowed smaller models to reach high persuasiveness scores (up to 3.99/5)"; [section] "we used the KD method to improve the performance of smaller LLMs. By transferring the knowledge of a larger model to a smaller model, the distillation reduces computational cost while maintaining performance"

## Foundational Learning

- Concept: Supervised finetuning (SFT) with adapter heads
  - Why needed here: Allows efficient adaptation of large language models to specific tasks (item appraisal) without full fine-tuning, reducing computational costs while maintaining performance.
  - Quick check question: What is the difference between full fine-tuning and adapter-based fine-tuning, and why is adapter-based fine-tuning preferred for this application?

- Concept: Knowledge distillation
  - Why needed here: Enables transfer of capabilities from large, resource-intensive models to smaller, more deployable models, making the system practical for real-time game deployment.
  - Quick check question: How does knowledge distillation work in the context of language models, and what are the key considerations for ensuring effective distillation?

- Concept: Zero-shot prompting with tactical instructions
  - Why needed here: Provides a baseline method for negotiation without requiring additional training data, useful for rapid prototyping and comparison with other approaches.
  - Quick check question: What are the limitations of zero-shot prompting for complex tasks like negotiation, and how do tactical instructions help mitigate these limitations?

## Architecture Onboarding

- Component map: Item description → Appraiser Module → Retail price estimate → Negotiator Module → Dialogue response → Final agreed price and item transaction

- Critical path: Item description → Appraiser → Retail price → Negotiator → Player response → Final price agreement

- Design tradeoffs:
  - Model size vs. performance: Larger models perform better but are more expensive to deploy
  - Training vs. prompting: Finetuning provides better performance but requires training data; prompting is easier but less reliable
  - Complexity vs. reliability: More sophisticated negotiation tactics increase persuasiveness but may lead to more irregular cases

- Failure signatures:
  - Appraisal failures: Large MAPE values, high standard deviation, unexpected output rates
  - Negotiation failures: Low persuasiveness scores, high arithmetic errors, giveaway cases, improvisation cases

- First 3 experiments:
  1. Compare in-context learning (ICL) vs. supervised finetuning (SFT) for the appraiser module using the WoW Classic dataset
  2. Test zero-shot prompting vs. knowledge distillation for the negotiator module using generated negotiation dialogues
  3. Analyze the three irregular cases (giveaways, improvisations, arithmetic errors) to understand their frequency and impact on user experience

## Open Questions the Paper Calls Out

- Can the MART framework be generalized to other open-world games or different types of trading NPCs, such as auctioneers or pawnbrokers? The paper mentions that the findings can be generalized to other open-world games or other trading NPCs, including auctioneers or pawnbrokers, but the framework's adaptability to other game environments or NPC types is not empirically tested.

- How does the use of different LLMs, beyond the Llama family, affect the performance and reliability of the MART framework? The paper acknowledges that the experimental results are based on the Llama LLM family, which may lower the generalizability of the results, but did not explore the impact of using other LLM families or models.

- What strategies can be implemented to handle the irregular cases (giveaways, improvisations, and arithmetic errors) that arise when deploying the MART framework in a game? The paper identifies three irregular cases and suggests possible solutions, such as implementing a retrieval-augmented generation system or using external calculators, but these solutions are not tested.

## Limitations
- The irregular cases (giveaways, improvisations, arithmetic errors) occurred in approximately 2.7% of cases and could significantly impact player experience if not properly handled
- The knowledge distillation approach relies on a massive 405B parameter teacher model that may not be accessible to all developers
- The generalizability of these findings to other game genres beyond WoW Classic remains untested

## Confidence

- High confidence: Finetuning and knowledge distillation enable smaller LLMs to perform effectively for both appraisal and negotiation tasks
- Medium confidence: The framework addresses passivity in merchant NPCs through dynamic pricing and negotiation
- Medium confidence: Item descriptions contain sufficient information for accurate price estimation

## Next Checks
1. Conduct a user study with actual players to measure the impact of irregular cases (giveaways, improvisations, arithmetic errors) on player experience and trust in the NPC system
2. Test the generalizability of the framework across different game genres and item types to determine if the WoW Classic-specific approach transfers effectively
3. Evaluate the computational efficiency and latency of the deployed system in real-time gameplay scenarios to ensure it meets practical game development requirements