---
ver: rpa2
title: 'DEEM: Dynamic Experienced Expert Modeling for Stance Detection'
arxiv_id: '2402.15264'
source_url: https://arxiv.org/abs/2402.15264
tags:
- experts
- stance
- expert
- detection
- deem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses stance detection, a natural language processing
  task that identifies the stance towards a specific target in a given text. The authors
  propose DEEM (Dynamic Experienced Expert Modeling), a method that leverages large
  language models (LLMs) to generate and filter experienced experts for stance detection.
---

# DEEM: Dynamic Experienced Expert Modeling for Stance Detection

## Quick Facts
- arXiv ID: 2402.15264
- Source URL: https://arxiv.org/abs/2402.15264
- Authors: Xiaolong Wang; Yile Wang; Sijie Cheng; Peng Li; Yang Liu
- Reference count: 15
- Primary result: DEEM achieves F1 scores of 81.1, 83.4, and 83.4 on P-Stance, SemEval-2016, and MTSD datasets respectively

## Executive Summary
This paper introduces DEEM (Dynamic Experienced Expert Modeling), a novel approach for stance detection that leverages large language models to generate and filter experienced experts. The method addresses the limitations of purely generative expert approaches by combining generation with retrieval, creating a semi-parametric system that achieves state-of-the-art performance on three benchmark datasets. By modeling stance detection as a multi-expert collaborative reasoning task and using semantic similarity for expert retrieval, DEEM demonstrates consistent improvements over existing methods while reducing LLM bias.

## Method Summary
DEEM generates diverse stance detection experts from labeled training data using LLMs, filters them based on occurrence frequency and prediction accuracy, and retrieves the most relevant experts for new sentences using semantic similarity. The method constructs an expert repository of sentence-expert pairs from the training data, then during inference retrieves top-k experienced experts to incorporate into the reasoning prompt. This approach combines the flexibility of generation with the reliability of retrieval, addressing LLM hallucination issues while maintaining generalization capabilities across different stance detection contexts.

## Key Results
- DEEM achieves F1avg scores of 81.1, 83.4, and 83.4 on P-Stance, SemEval-2016, and MTSD datasets respectively
- Outperforms self-consistency reasoning methods and reduces LLM bias in stance detection
- Demonstrates effectiveness of dynamic expert retrieval compared to fully generative approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic retrieval of experienced experts improves stance detection accuracy compared to fully generative expert approaches.
- Mechanism: The system generates diverse experts from labeled training data, filters them based on occurrence frequency and prediction accuracy, and retrieves the most relevant experts for each new sentence using semantic similarity. This semi-parametric approach combines the flexibility of generation with the reliability of retrieval.
- Core assumption: Experts that frequently appear and accurately predict stance in training data will generalize to similar contexts in new sentences.
- Evidence anchors:
  - [abstract] "Experimental results demonstrate that DEEM consistently achieves the best results on three standard benchmarks, outperforms methods with self-consistency reasoning, and reduces the bias of LLMs."
  - [section 3.2] "The generated expert candidates in E are directly generated by LLMs, which are diverse enough but many do not always match the sentences. To make them more generalizable and reliable to new sentences, we designed two heuristic rules to filter the experienced experts among all candidates."
  - [corpus] Weak - related papers focus on zero-shot detection but don't specifically address the dynamic expert retrieval mechanism.

### Mechanism 2
- Claim: Modeling stance detection as a multi-expert collaborative reasoning task improves performance over single-expert approaches.
- Mechanism: Multiple domain-specific experts (e.g., political, cybersecurity, social media) discuss the sentence and target, providing diverse perspectives that lead to more comprehensive and accurate stance predictions.
- Core assumption: Stance detection in social media contexts requires specialized knowledge that can be captured by different types of experts.
- Evidence anchors:
  - [abstract] "Inspired by the wisdom of crowds in sociological theory (Minsky, 1988; Piaget, 2013), we intuitively propose designing multiple capable experts to collaborate in order to come up with a comprehensive stance prediction."
  - [section 3.1] "We leverage the existing training datasets in a novel way to help generate potentially useful experts for solving stance detection, without using much prior knowledge or detailed role descriptions."
  - [corpus] Weak - while related work discusses multi-agent approaches, the specific focus on stance detection expertise is not well-represented.

### Mechanism 3
- Claim: Using experienced experts filtered by both occurrence frequency and prediction accuracy reduces hallucinations and improves reliability.
- Mechanism: The system filters generated experts not just by how often they appear, but also by their accuracy in predicting stance in training data, ensuring that only reliable experts are used for retrieval.
- Core assumption: Experts that are both frequent and accurate in training data are less likely to hallucinate or provide incorrect information in new contexts.
- Evidence anchors:
  - [section 3.2] "it is well known that LLMs can occasionally generate hallucinations (Guerreiro et al., 2023; Ji et al., 2023), thus they could make the responses unreliable and lead to incorrect final predictions. Therefore, experienced experts need to be accurate in analyzing the stance towards the target..."
  - [section 5.2] "We find that the 50% threshold leads to the best results (around 82%), and the performance does not improve when the threshold continues to increase. The reason can be that an intermediate threshold can maintain both the generalization and diversity of potential useful experts for new sentences..."
  - [corpus] Weak - hallucination mitigation is mentioned in related work but not specifically in the context of expert filtering for stance detection.

## Foundational Learning

- Concept: Stance detection task definition
  - Why needed here: Understanding that stance detection involves identifying the attitude (favor/against/neutral) towards a specific target in text is crucial for designing appropriate experts and evaluation metrics.
  - Quick check question: What are the typical stance labels used in stance detection tasks, and how do they differ from sentiment analysis?

- Concept: Large language model reasoning limitations
  - Why needed here: Recognizing that LLMs can hallucinate and struggle with domain-specific knowledge is key to understanding why the expert filtering and retrieval mechanisms are necessary.
  - Quick check question: What are common failure modes of LLMs in specialized tasks like stance detection, and how do they manifest?

- Concept: Few-shot in-context learning
  - Why needed here: The method relies on LLMs' ability to generate experts from labeled examples without fine-tuning, making understanding in-context learning capabilities essential.
  - Quick check question: How does few-shot in-context learning differ from traditional fine-tuning, and what are its limitations for generating domain-specific content?

## Architecture Onboarding

- Component map: Expert Generation -> Expert Filtering -> Expert Repository -> Expert Retrieval -> Reasoning Pipeline
- Critical path: Generation → Filtering → Repository Construction → Retrieval → Reasoning
- Design tradeoffs:
  - Generation diversity vs. filtering stringency: More diverse generation provides more options but requires stricter filtering to maintain quality.
  - Retrieval accuracy vs. computational cost: Higher-quality retrieval (e.g., using better embeddings) improves performance but increases computation.
  - Expert specialization vs. generalization: More specialized experts may be more accurate but less generalizable to new contexts.
- Failure signatures:
  - Poor retrieval performance: Retrieved experts are not relevant to the new sentence, leading to inaccurate predictions.
  - Over-filtering: Too few experts remain after filtering, reducing the diversity and potential usefulness of the expert pool.
  - Under-filtering: Too many unreliable experts remain, introducing noise and hallucinations into the reasoning process.
- First 3 experiments:
  1. Ablation study on filtering thresholds: Vary accuracy and frequency thresholds to find optimal settings.
  2. Retrieval quality analysis: Manually evaluate the relevance of top-k retrieved experts for a sample of test sentences.
  3. Expert diversity assessment: Analyze the distribution of expert types before and after filtering to ensure coverage of key domains.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How well does DEEM perform on stance detection tasks in domains beyond politics and social media?
- Basis in paper: [inferred] The paper states that DEEM was evaluated on three benchmark datasets focusing on political stance detection, but acknowledges the potential limitation of generalizability to other domains.
- Why unresolved: The paper does not provide any evidence or analysis of DEEM's performance on stance detection tasks in other domains, such as finance, healthcare, or technology.
- What evidence would resolve it: Conducting experiments on stance detection datasets from diverse domains and comparing DEEM's performance to other methods would provide evidence of its generalizability.

### Open Question 2
- Question: What is the impact of the filtering strategies (accuracy and frequency thresholds) on DEEM's performance, and how do these thresholds vary across different datasets?
- Basis in paper: [explicit] The paper discusses the filtering strategies used in DEEM, but does not provide a detailed analysis of how these thresholds impact performance or how they vary across datasets.
- Why unresolved: The paper mentions the filtering strategies but does not explore their impact on DEEM's performance or provide insights into how these thresholds should be tuned for different datasets.
- What evidence would resolve it: Conducting experiments with different accuracy and frequency thresholds on various datasets and analyzing the impact on DEEM's performance would provide insights into the optimal filtering strategies.

### Open Question 3
- Question: How does DEEM's performance compare to fine-tuned models on stance detection tasks, especially when fine-tuned models have access to more domain-specific data?
- Basis in paper: [explicit] The paper compares DEEM to fine-tuned models like BERT and BERTweet, but does not explore the performance gap between DEEM and fine-tuned models when the latter have access to more domain-specific data.
- Why unresolved: The paper does not provide a detailed analysis of how DEEM's performance compares to fine-tuned models when the latter have access to more domain-specific data, which could potentially improve their performance.
- What evidence would resolve it: Conducting experiments where fine-tuned models are trained on larger and more domain-specific datasets and comparing their performance to DEEM would provide insights into the performance gap between the two approaches.

## Limitations

- The method's effectiveness for stance detection tasks in domains beyond politics and social media remains unproven, as all experiments were conducted on Twitter-based datasets.
- Computational overhead of generating and filtering experts for each new task could limit scalability, particularly for datasets with many unique targets.
- The filtering thresholds (accuracy and frequency) are set heuristically and may not generalize optimally to all datasets or domains.

## Confidence

- **High Confidence**: The core mechanism of expert retrieval improving stance detection accuracy is well-supported by experimental results showing consistent F1 score improvements across all three benchmark datasets (81.1, 83.4, 83.4) compared to baseline methods.
- **Medium Confidence**: The effectiveness of the two-stage filtering approach (frequency + accuracy) is demonstrated empirically but relies on heuristic thresholds that may not generalize optimally to all datasets.
- **Medium Confidence**: The claim about reducing LLM bias is supported by performance improvements but would benefit from more direct bias measurement and comparison with established bias metrics.

## Next Checks

1. **Cross-Domain Validation**: Apply DEEM to non-Twitter datasets (e.g., news editorials, forum discussions) to test generalization beyond social media contexts and verify that expert retrieval remains effective with different text structures and topic distributions.

2. **Expert Quality Analysis**: Conduct a qualitative analysis of retrieved experts for 100 randomly selected test instances, manually rating their relevance and accuracy to quantify the actual quality of the retrieval mechanism and identify failure patterns.

3. **Efficiency Benchmarking**: Measure the computational overhead of expert generation and filtering relative to inference time, comparing wall-clock performance against baseline methods to assess practical scalability for real-world deployment.