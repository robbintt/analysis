---
ver: rpa2
title: 'Filtered Randomized Smoothing: A New Defense for Robust Modulation Classification'
arxiv_id: '2410.06339'
source_url: https://arxiv.org/abs/2410.06339
tags:
- attacks
- smoothing
- certified
- filter
- classifier
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the vulnerability of deep neural network (DNN)
  based modulation classifiers to adversarial attacks in wireless communications.
  These classifiers, while achieving high accuracy, are susceptible to imperceptible
  adversarial perturbations that can degrade their performance.
---

# Filtered Randomized Smoothing: A New Defense for Robust Modulation Classification

## Quick Facts
- arXiv ID: 2410.06339
- Source URL: https://arxiv.org/abs/2410.06339
- Authors: Wenhan Zhang; Meiyu Zhong; Ravi Tandon; Marwan Krunz
- Reference count: 16
- One-line primary result: FRS achieves 19.37% and 18.21% higher accuracy than baselines under FGSM and PGD attacks, respectively, while providing certified robustness guarantees

## Executive Summary
This paper addresses the vulnerability of deep neural network (DNN) based modulation classifiers to adversarial attacks in wireless communications. While these classifiers achieve high accuracy, they are susceptible to imperceptible adversarial perturbations that can degrade performance. The proposed Filtered Randomized Smoothing (FRS) method exploits spectral heterogeneity between clean and attacked RF signals, applying low-pass filtering before or after noise injection to enhance robustness while maintaining accuracy.

The FRS approach combines low-pass filtering with randomized smoothing, leveraging the observation that clean RF signals concentrate energy in low frequencies while adversarial attacks spread energy across wider frequency ranges. By removing high-frequency components, FRS reduces the effective attack strength while preserving the theoretical robustness guarantees of randomized smoothing. Experimental results on the RadioML dataset show FRS significantly outperforms existing defenses, achieving 19.37% and 18.21% higher accuracy than baselines under FGSM and PGD attacks, respectively, while providing certified robustness guarantees.

## Method Summary
Filtered Randomized Smoothing (FRS) combines spectral filtering with randomized smoothing to create a robust modulation classifier. The method applies a low-pass Butterworth filter either before (Pre-FRS) or after (Post-FRS) Gaussian noise injection. Clean RF signals concentrate energy in low frequencies while adversarial perturbations spread energy across wider ranges, making filtering effective at removing attack components. FRS preserves randomized smoothing's theoretical guarantees while improving accuracy under attacks. The approach is evaluated on the RadioML 2016.10a dataset with 11 modulation schemes across various SNR levels, comparing against regular training, adversarial training, and standard randomized smoothing baselines.

## Key Results
- FRS achieved 19.37% and 18.21% higher accuracy than baselines under FGSM and PGD attacks, respectively
- Post-FRS variant provided the best trade-off between robustness and accuracy
- Certified test accuracy of FRS surpassed that of AT and RS across various attack budgets and channel conditions
- Theoretical analysis established certified robustness guarantees for both Pre-FRS and Post-FRS variants

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Low-pass filtering exploits spectral heterogeneity between clean and adversarial RF signals
- Mechanism: Clean RF signals concentrate energy in low frequencies while adversarial perturbations spread energy across wider frequency ranges. Applying a low-pass filter removes more adversarial perturbation energy than clean signal energy when the cutoff frequency is appropriately chosen.
- Core assumption: The spectral separation between clean and adversarial signals is consistent across different modulation schemes and attack types
- Evidence anchors:
  - [abstract] "clean signals have energy concentrated in low frequencies, while attacks spread energy across a wider range"
  - [section III.A] "clean (un-attacked) RF signals from the waveform typically tend to concentrate in a low-frequency range. In contrast, the frequencies of natural noise and AML attacks are spread over a wider interval"
  - [corpus] Weak evidence - corpus contains related work on randomized smoothing but lacks specific spectral analysis of RF signals
- Break condition: If adversarial attacks adapt to concentrate energy in low frequencies or if channel conditions significantly alter the spectral characteristics of clean signals

### Mechanism 2
- Claim: Post-smoothing filtering maintains theoretical robustness guarantees of randomized smoothing
- Mechanism: Adding Gaussian noise before applying the filter ensures that the filter operates on noisy inputs, preserving the statistical properties needed for certified robustness calculations while removing high-frequency adversarial components
- Core assumption: The filter's Lipschitz constant can be bounded and used to derive certified radius from randomized smoothing guarantees
- Evidence anchors:
  - [section IV] "the filter post-noise augmentation does not compromise the theoretical assurances of randomized smoothing"
  - [section IV.Theorem 1] Provides certified radius formula for post-smoothing filtering
  - [section IV.Theorem 2] Shows how pre-smoothing filtering certified radius relates to filter Lipschitz constant
- Break condition: If the filter introduces significant time-domain shifts that affect the noise distribution or if the filter's Lipschitz constant is too large to provide meaningful robustness

### Mechanism 3
- Claim: Combining filtering with randomized smoothing improves accuracy under attacks while maintaining certified robustness
- Mechanism: The filter reduces the effective attack strength by removing high-frequency components, allowing randomized smoothing to achieve higher certified accuracy with less noise injection, thus preserving more clean signal accuracy
- Core assumption: There exists an optimal noise level that balances robustness and accuracy, and filtering allows this optimal point to be reached with less noise
- Evidence anchors:
  - [section V.C] "By combining filter design with Gaussian randomization, the defender's accuracy gets further improved"
  - [section V.C] "the proposed filter-based approach outperforms the other two in both regimes of ϵ"
  - [corpus] Weak evidence - corpus contains related work on randomized smoothing but lacks specific combinations with filtering
- Break condition: If the filter removes too much signal energy or if the noise level required for certification is still too high despite filtering

## Foundational Learning

- Concept: Spectral analysis of signals using Fast Fourier Transform (FFT)
  - Why needed here: Understanding the frequency domain representation of clean and adversarial signals is crucial for designing effective filters
  - Quick check question: What is the relationship between time-domain signal energy and frequency-domain power spectrum?

- Concept: Randomized smoothing and certified robustness
  - Why needed here: FRS builds upon randomized smoothing to provide provable guarantees against adversarial attacks
  - Quick check question: How does adding Gaussian noise to inputs create a "smoothed" classifier with certified robustness?

- Concept: Lipschitz continuity and its role in robustness analysis
  - Why needed here: The Lipschitz constant of the filter determines how pre-smoothing filtering affects the certified radius
  - Quick check question: What does it mean for a function to be Lipschitz continuous, and how does this property relate to robustness?

## Architecture Onboarding

- Component map:
  Input signal -> Low-pass filter -> Gaussian noise injection -> Base classifier -> Majority vote -> Output

- Critical path:
  1. Input signal → Low-pass filter → Gaussian noise injection → Base classifier → Majority vote → Output
  2. Input signal → Gaussian noise injection → Low-pass filter → Base classifier → Majority vote → Output

- Design tradeoffs:
  - Filter cutoff frequency vs. signal preservation: Lower cutoff removes more adversarial components but also more signal information
  - Noise variance vs. robustness: Higher variance provides larger certified radius but reduces clean accuracy
  - Pre-filtering vs. post-filtering: Pre-filtering requires Lipschitz constant estimation but may provide better robustness; post-filtering is simpler but may be less effective

- Failure signatures:
  - Accuracy degradation on clean signals indicates filter cutoff is too aggressive
  - Small certified radius indicates noise level is insufficient or filter is ineffective
  - Inconsistent classification decisions suggest filter is introducing artifacts

- First 3 experiments:
  1. Test filter impact: Apply low-pass filter to clean and adversarial signals, measure spectral power ratios and classification accuracy
  2. Noise sensitivity analysis: Vary Gaussian noise variance, measure certified radius and clean accuracy
  3. Filter order comparison: Test different Butterworth filter orders (m=1, 2, 3), measure impact on classification and robustness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of filter order (m) in the Butterworth filter affect the certified robustness and accuracy of FRS beyond the tested case of m=2?
- Basis in paper: [explicit] The paper mentions using m=2 for the Butterworth filter and states "With a larger m, the cut-off is sharper, and the filtered waveform experiences more time-domain shifts" but does not explore the impact of different filter orders on performance.
- Why unresolved: The paper only tests m=2 and does not provide experimental results for other filter orders, leaving the optimal filter order for FRS undetermined.
- What evidence would resolve it: Systematic experimental evaluation of FRS with different filter orders (m values) showing the trade-off between robustness, accuracy, and time-domain shifts for each order.

### Open Question 2
- Question: What is the impact of different attack types beyond FGSM and PGD on the effectiveness of FRS?
- Basis in paper: [inferred] The paper only evaluates FRS against FGSM and PGD attacks, but mentions that "it has been shown [14], [15] that such classifiers are not robust to previously unseen adaptive attacks" suggesting other attack types may behave differently.
- Why unresolved: Limited attack diversity in the experimental evaluation prevents understanding FRS's generalizability across different attack strategies.
- What evidence would resolve it: Experimental results showing FRS performance against a diverse set of attack types (e.g., CW, DeepFool, Carlini-Wagner) with varying characteristics and strategies.

### Open Question 3
- Question: How does FRS perform on modulation classification datasets other than RadioML 2016.10a?
- Basis in paper: [explicit] The paper states "we consider the RML 2016.10a dataset" and does not evaluate FRS on other datasets or mention any dataset-specific limitations.
- Why unresolved: Performance on a single dataset cannot establish whether FRS's effectiveness is dataset-dependent or generalizable across different RF signal datasets.
- What evidence would resolve it: Experimental results demonstrating FRS performance on multiple modulation classification datasets with varying characteristics (different SNR ranges, modulation schemes, sample sizes, etc.).

## Limitations
- Spectral separation assumption may not hold across different signal types, channel conditions, or attack strategies
- Filter design relies on fixed parameters (Butterworth order m=2) without systematic exploration of optimal configurations
- Method requires additional computational overhead for filtering and noise injection, potentially impacting real-time deployment
- Theoretical guarantees assume Gaussian noise and specific attack models, potentially limiting applicability to adaptive attacks

## Confidence
- Spectral analysis claims: Low confidence - primarily validated on RadioML dataset with limited external validation
- Certified robustness guarantees: High confidence for theoretical framework, Medium confidence for practical implementation due to Lipschitz constant estimation approximations
- Overall effectiveness claims: Medium confidence - well-supported within studied domain but generalizability to other scenarios uncertain

## Next Checks
1. Test FRS on alternative RF datasets with different modulation schemes and channel conditions to verify spectral separation assumptions hold across diverse scenarios.
2. Evaluate FRS against adaptive attacks that specifically target the spectral filtering mechanism, such as attacks that concentrate energy in low frequencies.
3. Conduct ablation studies varying filter parameters (order, cut-off frequency) and noise levels across the full SNR range to identify optimal configurations for different operating conditions.