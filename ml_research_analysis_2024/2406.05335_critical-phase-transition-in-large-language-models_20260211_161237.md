---
ver: rpa2
title: Critical Phase Transition in Large Language Models
arxiv_id: '2406.05335'
source_url: https://arxiv.org/abs/2406.05335
tags:
- propn
- noun
- phase
- correlation
- sequences
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides numerical evidence that a critical phase transition
  occurs in large language models (LLMs) when varying the temperature parameter. The
  authors analyze statistical properties of texts generated by GPT-2 at different
  temperatures, focusing on correlations between part-of-speech (POS) tags.
---

# Critical Phase Transition in Large Language Models

## Quick Facts
- arXiv ID: 2406.05335
- Source URL: https://arxiv.org/abs/2406.05335
- Reference count: 40
- Primary result: Numerical evidence for critical phase transition in LLMs at T_c ≈ 1, characterized by long-range correlations and power-law decay

## Executive Summary
This paper presents compelling numerical evidence that large language models undergo a critical phase transition when the temperature parameter is varied. By analyzing statistical properties of text generated by GPT-2 at different temperatures, the authors demonstrate that below a critical temperature T_c ≈ 1, sequences exhibit long-range correlations and repetitive structures, while above T_c the correlation decays to zero. At the transition point, the system shows critical slowing down with power-law decay, mirroring phenomena observed in natural languages. The study provides both theoretical analysis and empirical validation across multiple model sizes and datasets.

## Method Summary
The authors investigate phase transitions in LLMs by generating text sequences using GPT-2 (124M), Japanese GPT-2 medium (361M), and Pythia (70M) at varying temperatures from 0.1 to 2.0. They tokenize the sequences and map tokens to universal POS tags or character-based numerals, then compute correlation functions between POS tags for different time intervals and positions. Statistical quantities including integrated correlations, power spectra, and time evolution of POS distributions are calculated across temperatures and sequence lengths. The analysis focuses on identifying signatures of phase transitions such as divergence of integrated correlation at low temperatures, saturation at high temperatures, and power-law decay at the critical point. Natural language datasets (OpenWebTextCorpus and WikiText) are analyzed for comparison.

## Key Results
- Critical temperature T_c ≈ 1 identified where integrated correlation diverges below T_c and saturates above T_c
- Power-law decay of correlation at T_c with exponent -2, matching critical behavior in natural languages
- Critical slowing down observed with autocorrelation time diverging as T approaches T_c from above
- Natural language datasets exhibit similar critical properties, supporting the universality of the transition

## Why This Works (Mechanism)
The mechanism underlying the observed phase transition relates to the balance between randomness and structure in text generation. At high temperatures, the sampling process introduces sufficient randomness to break correlations, resulting in uncorrelated sequences. At low temperatures, the system becomes trapped in repetitive patterns, creating long-range correlations. The critical point represents an optimal balance where the system exhibits scale-free correlations characteristic of criticality. This behavior emerges from the interplay between the model's learned representations and the sampling temperature, with the transition reflecting a fundamental change in the statistical properties of generated sequences.

## Foundational Learning

**Statistical Physics of Phase Transitions**: Understanding critical phenomena, universality classes, and correlation functions. Needed to interpret the observed transition in terms of established physical concepts. Quick check: Verify that correlation functions and critical exponents match theoretical predictions.

**Information Theory and Text Statistics**: Knowledge of entropy, redundancy, and information content in natural language. Required to connect linguistic properties with physical phase transitions. Quick check: Confirm that POS tag correlations capture meaningful linguistic structure.

**Neural Network Sampling**: Understanding temperature-based sampling in language models and its effects on output diversity. Essential for interpreting how temperature controls the transition. Quick check: Verify that temperature scaling produces expected changes in sequence diversity.

## Architecture Onboarding

**Component Map**: Temperature parameter -> Sampling distribution -> Generated sequence -> Token mapping -> POS tag sequence -> Correlation function computation -> Statistical analysis

**Critical Path**: The temperature parameter directly controls the sampling distribution, which determines the generated sequence. The sequence is mapped to POS tags, and correlations between tags are computed to detect the phase transition. The critical temperature T_c ≈ 1 emerges from analyzing how these correlations scale with temperature and sequence length.

**Design Tradeoffs**: The choice of temperature sampling versus other methods (top-k, top-p) affects the transition behavior. Using POS tags as proxies for linguistic structure balances interpretability with computational tractability. The study focuses on relatively small models due to computational constraints, potentially limiting generalizability to larger models.

**Failure Signatures**: Incorrect temperature scaling, improper sampling, or inadequate sequence length can obscure the phase transition. Misalignment in POS tagging or correlation computation can produce spurious results. Insufficient sample size leads to noisy statistics that mask critical behavior.

**Three First Experiments**:
1. Generate sequences at extreme temperatures (0.1 and 2.0) to verify expected behavior of long-range correlations at low T and uncorrelated sequences at high T.
2. Compute correlation functions for different POS tag pairs to confirm that the transition is robust across linguistic categories.
3. Analyze power spectra of POS sequences to verify the presence of critical slowing down near T_c.

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis based on statistical correlations of POS tags and character sequences, which may not capture all relevant aspects of LLM behavior
- Sample limited to relatively small models (up to 361M parameters), potentially limiting generalizability to larger models
- Focus on single-temperature sampling without exploring other sampling methods that might affect transition behavior
- Phenomenological comparison with natural languages without mechanistic explanation for shared critical properties

## Confidence
- Main claims about critical phase transition: High
- Universality across different model sizes: Medium
- Interpretation as true thermodynamic phase transition: Medium
- Comparison with natural language criticality: Medium

## Next Checks
1. Test whether the critical temperature T_c ≈ 1 holds across a broader range of model sizes, particularly larger models beyond 361M parameters, to verify universality.
2. Examine the effect of different sampling methods (top-k, top-p) on the critical behavior to determine if the phase transition is robust to sampling strategy changes.
3. Develop a theoretical framework connecting the observed statistical signatures to actual thermodynamic phase transitions in the underlying neural network dynamics.