---
ver: rpa2
title: 'CuentosIE: can a chatbot about "tales with a message" help to teach emotional
  intelligence?'
arxiv_id: '2403.07193'
source_url: https://arxiv.org/abs/2403.07193
tags:
- emotions
- cuentosie
- user
- chatbot
- tales
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents CuentosIE, a chatbot designed to teach emotional
  intelligence using "tales with a message". The chatbot overcomes limitations of
  modern chatbots like ChatGPT by restricting conversations to a curated set of tales
  and using NLP modules for information retrieval, question generation, and emotion
  classification.
---

# CuentosIE: can a chatbot about "tales with a message" help to teach emotional intelligence?

## Quick Facts
- arXiv ID: 2403.07193
- Source URL: https://arxiv.org/abs/2403.07193
- Reference count: 13
- Primary result: A chatbot using curated tales improves emotional intelligence with high user satisfaction (7.82/10)

## Executive Summary
CuentosIE is a chatbot designed to teach emotional intelligence through curated "tales with a message." Unlike general chatbots, it restricts conversations to a validated set of tales and uses NLP modules for information retrieval, question generation, and emotion classification. The system was evaluated with 360 users across three age groups, achieving high satisfaction and showing improvements in emotional intelligence. The chatbot's ability to store interactions enables longitudinal monitoring and early detection of sensitive situations.

## Method Summary
CuentosIE uses a curated corpus of Spanish tales labeled with emotions and psychological themes. The chatbot architecture combines information retrieval, reading comprehension question generation, and emotion classification using NLP tools (FreeLing, NLTK, spaCy) and machine learning classifiers (e.g., Transformer model). User interactions are stored as XML files with timestamps for longitudinal monitoring. The system was evaluated through experiments with 360 registered users across three age groups, measuring satisfaction and emotional intelligence improvements.

## Key Results
- Achieved high overall satisfaction (7.82/10) from users
- Demonstrated improvements in emotional intelligence across age groups
- Successfully stored and analyzed user interactions for emotional monitoring

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Restricting conversations to curated tales prevents hallucination and ensures domain relevance.
- Mechanism: Controlled corpus eliminates exposure to unreliable external data.
- Core assumption: Tale corpus comprehensively covers needed emotional themes.
- Evidence: Abstract states "selection, collection, and classification of a set of highly specialized tales."
- Break condition: Unrepresentative corpus leads to poor user experience.

### Mechanism 2
- Claim: 30-emotion taxonomy with lexical resources achieves accurate emotion detection.
- Mechanism: Classifier uses terms, Wikipedia pages, and synonyms for contextual disambiguation.
- Core assumption: Training corpora adequately represent emotional expression variability.
- Evidence: Section reports "84.53% accuracy" on emotion classification.
- Break condition: Users express emotions outside the 30-class taxonomy.

### Mechanism 3
- Claim: XML storage enables longitudinal emotional monitoring and sensitive situation detection.
- Mechanism: Timestamped logs track emotion trends and flag concerning patterns.
- Core assumption: Data is detailed yet privacy-preserving.
- Evidence: Section states XML can detect "depression, suicide, and bullying."
- Break condition: Incomplete or privacy-violating storage renders monitoring unusable.

## Foundational Learning

- Information Retrieval with lexical/syntactic knowledge: Why needed? Improves tale matching precision beyond keyword search. Quick check: How does partial parsing improve retrieval vs. keyword search?
- Transformer-based emotion classification: Why needed? Captures context for subtle emotional differences. Quick check: Why is 30-class classification harder than binary sentiment?
- XML-based conversation logging: Why needed? Enables real-time monitoring and offline analysis. Quick check: What privacy safeguards are needed for XML conversation storage?

## Architecture Onboarding

- Component map: Frontend (HTML/PHP/JS) → Discourse Manager → IR Engine, Question Generator, Emotion Classifier → Tale Corpus/XML Logs
- Critical path: 1. User query → DM classification 2. Tale search: DM → IR Engine → ranked tales 3. Chat: DM → Emotion Classifier → emotion-tagged reply + quote 4. All interactions logged to XML
- Design tradeoffs: Restricting tales avoids hallucination but limits scalability; high emotion granularity improves precision but increases complexity; XML logging preserves context but increases storage/privacy overhead
- Failure signatures: High "no_intention" DM classifications, low tale recall, frequent emotion misclassifications
- First 3 experiments: 1. Unit test IR Engine with sample queries 2. Integration test DM flow with functionality switching 3. End-to-end test with sample users verifying XML logging

## Open Questions the Paper Calls Out

- Does CuentosIE demonstrate measurable improvements in users' emotional intelligence over time? The paper proposes psychometric pre/post assessments but only shows satisfaction data.
- How do different age groups and genders respond to specific emotions/themes? Preliminary data suggests differences but lacks deeper correlation analysis.
- Can XML interactions effectively detect sensitive situations like depression or suicide? Mentioned as possible but not validated with real-world evidence.

## Limitations
- Evaluation relies on self-reported satisfaction without objective behavioral metrics
- Limited generalizability due to restricted domain of curated tales
- Emotion classification accuracy not validated on real user conversations

## Confidence

- High confidence: Technical architecture is clearly specified and reproducible
- Medium confidence: Satisfaction scores are supported by user experiments but lack external validation
- Low confidence: Sensitive situation detection claims are not substantiated with real-world evidence

## Next Checks
1. Conduct controlled experiment with chatbot vs. control group using standardized emotional intelligence assessments
2. Validate emotion classifier accuracy on real user conversations, testing colloquial/ambiguous expressions
3. Perform privacy/security audit of XML logging system and evaluate sensitive situation detection algorithms