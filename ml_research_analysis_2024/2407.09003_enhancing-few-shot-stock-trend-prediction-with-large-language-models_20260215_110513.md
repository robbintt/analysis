---
ver: rpa2
title: Enhancing Few-Shot Stock Trend Prediction with Large Language Models
arxiv_id: '2407.09003'
source_url: https://arxiv.org/abs/2407.09003
tags:
- news
- stock
- prediction
- voting
- down
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses stock trend prediction using Large Language
  Models (LLMs) under few-shot settings to overcome the data annotation bottleneck
  in supervised methods. The key idea is a two-step "denoising-then-voting" approach:
  first classifying individual news as Up, Down, or Irrelevant to filter noise, then
  aggregating relevant predictions via majority voting.'
---

# Enhancing Few-Shot Stock Trend Prediction with Large Language Models

## Quick Facts
- arXiv ID: 2407.09003
- Source URL: https://arxiv.org/abs/2407.09003
- Authors: Yiqi Deng; Xingwei He; Jiahao Hu; Siu-Ming Yiu
- Reference count: 17
- Primary result: Achieves 66.59% accuracy on S&P 500, 62.17% on CSI-100, and 61.17% on HK stocks using few-shot LLM prompting

## Executive Summary
This paper addresses stock trend prediction using Large Language Models (LLMs) under few-shot settings to overcome the data annotation bottleneck in supervised methods. The key idea is a two-step "denoising-then-voting" approach: first classifying individual news as Up, Down, or Irrelevant to filter noise, then aggregating relevant predictions via majority voting. Experiments on S&P 500, CSI-100, and HK stocks show 66.59%, 62.17%, and 61.17% accuracy respectively, outperforming standard few-shot baselines by 4-7% and matching state-of-the-art supervised methods. The approach effectively handles noisy news and input length constraints of LLMs.

## Method Summary
The method employs a two-stage process for few-shot stock trend prediction. First, individual news articles are classified as Up, Down, or Irrelevant using in-context learning with LLMs (ChatGPT API). This denoising step filters out news that doesn't contribute to trend prediction. Second, the remaining relevant predictions are aggregated using majority voting to produce the final stock trend prediction. The approach uses 9-shot prompts for S&P 500 and 6-shot prompts for CSI-100 and HK stocks, leveraging the few-shot learning capabilities of LLMs without requiring parameter updates or fine-tuning.

## Key Results
- Achieves 66.59% accuracy on S&P 500 stock trend prediction
- Outperforms standard few-shot baselines by 4-7% across all markets
- Matches state-of-the-art supervised methods while using only 9 examples (S&P 500) or 6 examples (CSI-100/HK)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Filtering irrelevant news before aggregation reduces noise and improves prediction accuracy.
- Mechanism: Introducing an "Irrelevant" class allows the model to classify and exclude news that does not contribute to stock trend prediction. By predicting trends for individual news articles rather than merged news, the model can avoid incorporating misleading features from irrelevant content.
- Core assumption: Individual news articles can be reliably classified as "Up", "Down", or "Irrelevant" using few-shot prompting.
- Evidence anchors:
  - [abstract] "The proposed method offers two advantages: (1) Classifying noisy news as irrelevant removes its impact on the final prediction."
  - [section] "To filter out irrelevant news (i.e., reducing noise), we introduce an additional category named 'Irrelevant' and predict on each news individually instead of on the merged news."
- Break condition: If the model cannot reliably distinguish relevant from irrelevant news, noise filtering will fail and accuracy gains will be lost.

### Mechanism 2
- Claim: Aggregating individual predictions via majority voting avoids input length constraints while maintaining useful information.
- Mechanism: Instead of merging all news into a single input (which may exceed LLM token limits), the model makes separate predictions for each news article and aggregates them using majority voting. This approach preserves information from all relevant news while staying within input constraints.
- Core assumption: Individual news predictions can be meaningfully aggregated to represent the overall market sentiment.
- Evidence anchors:
  - [abstract] "Then we aggregate these predictions using majority voting."
  - [section] "To utilize the remaining relevant news, one straight approach is to consolidate all these news into a single merged news and use LLMs to predict on the merged news...we opt to reuse the predicted results of individual news in the denoising stage and obtain a final prediction through an effective and efficient majority voting mechanism."
- Break condition: If the number of relevant news articles is very low or highly imbalanced, majority voting may not provide a reliable aggregate signal.

### Mechanism 3
- Claim: Few-shot prompting with LLMs can achieve competitive accuracy without extensive labeled data.
- Mechanism: The approach leverages LLMs' in-context learning capabilities to perform stock trend prediction with minimal training examples (9-shot for S&P 500, 6-shot for CSI-100 and HK), eliminating the need for large annotated datasets.
- Core assumption: LLMs can effectively learn stock trend prediction patterns from a small number of examples.
- Evidence anchors:
  - [abstract] "Inspired by the impressive few-shot capability of Large Language Models (LLMs), we propose using LLMs in a few-shot setting to overcome the scarcity of labeled data"
  - [section] "Recent work (Brown et al., 2020; Wei et al., 2022) has shown that pre-trained LLMs are strong in-context learners in few-shot scenarios across various NLP tasks even without additional fine-tuning or gradient updates."
- Break condition: If the few-shot examples are not representative or the task complexity exceeds the model's few-shot learning capacity, performance will degrade significantly.

## Foundational Learning

- Concept: In-context learning with LLMs
  - Why needed here: The approach relies on LLMs learning to classify news as "Up", "Down", or "Irrelevant" from just a few examples without any parameter updates.
  - Quick check question: What is the key difference between in-context learning and traditional fine-tuning in LLMs?

- Concept: Text classification and sentiment analysis
  - Why needed here: The model must accurately classify news articles based on their sentiment and relevance to stock trends.
  - Quick check question: How would you design a prompt to classify a news article as positive, negative, or neutral for stock impact?

- Concept: Statistical aggregation methods
  - Why needed here: Majority voting requires understanding how to aggregate multiple predictions into a single decision.
  - Quick check question: What statistical method would you use if you needed to weight some news articles more heavily than others in the voting process?

## Architecture Onboarding

- Component map:
  - Data preprocessing -> Prompt construction -> Denoising module -> Voting module -> Evaluation

- Critical path:
  1. Load and preprocess news data
  2. Construct few-shot prompts with exemplars
  3. Classify each news article as "Up", "Down", or "Irrelevant"
  4. Filter out irrelevant news
  5. Aggregate remaining predictions via majority voting
  6. Evaluate against ground truth labels

- Design tradeoffs:
  - Using individual news vs. merged news: Individual news avoids noise and input limits but requires more API calls
  - Number of exemplars: More exemplars may improve accuracy but reduce the few-shot nature
  - Threshold Î» in voting: Higher thresholds increase confidence but may reduce recall

- Failure signatures:
  - Low accuracy with high precision: Model is too conservative, missing relevant signals
  - High accuracy with low precision: Model is overfitting to noise or irrelevant news
  - Degraded performance with more news: Majority voting is being overwhelmed by noise

- First 3 experiments:
  1. Baseline test: Run standard prompt (merged news) on S&P 500 data to establish baseline accuracy
  2. Voting only test: Implement voting without denoising to measure impact of aggregation alone
  3. Ablation test: Compare results with and without "Irrelevant" category to quantify denoising benefit

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the denoising-then-voting approach perform when applied to multi-class stock movement prediction (e.g., Up, Down, No Change) instead of binary classification?
- Basis in paper: [inferred] The paper mentions binary classification of stock trends and introduces an "Irrelevant" category as part of the denoising strategy, suggesting potential for extension to multi-class scenarios.
- Why unresolved: The paper only evaluates the method on binary classification tasks and does not explore multi-class scenarios.
- What evidence would resolve it: Experiments comparing the denoising-then-voting approach with multi-class classification baselines on datasets that include "No Change" labels, measuring accuracy and other relevant metrics.

### Open Question 2
- Question: What is the impact of different news summarization techniques on the performance of the denoising-then-voting method?
- Basis in paper: [explicit] The paper compares using news titles versus different 100-token summaries of articles, finding that the first 100 tokens of articles performs best, but does not explore other summarization methods.
- Why unresolved: The paper only evaluates a limited set of summarization techniques and does not compare against other state-of-the-art summarization methods.
- What evidence would resolve it: Experiments comparing the denoising-then-voting approach using different news summarization techniques (e.g., abstractive summarization, extractive summarization) on the same datasets, measuring prediction accuracy.

### Open Question 3
- Question: How does the denoising-then-voting approach scale to real-time stock prediction with streaming news data?
- Basis in paper: [inferred] The paper evaluates the method on historical datasets but does not address the challenges of applying it to real-time prediction scenarios with continuous news streams.
- Why unresolved: The paper does not discuss the computational requirements, latency, or performance degradation that might occur when applying the method to streaming data.
- What evidence would resolve it: Experiments testing the denoising-then-voting approach on simulated or real-time streaming news data, measuring prediction accuracy, computational efficiency, and latency compared to batch processing.

## Limitations
- The method's reliance on ChatGPT API introduces cost and reproducibility concerns with unspecified token limits and pricing
- The "Irrelevant" category classification may be subjective and could introduce bias in news filtering
- The few-shot nature (9 examples for S&P 500, 6 for CSI-100/HK) may not generalize well to markets with different dynamics

## Confidence
- High Confidence: The denoising mechanism (adding "Irrelevant" category) effectively reduces noise and improves accuracy. The majority voting aggregation method successfully handles input length constraints while maintaining performance.
- Medium Confidence: The few-shot learning capability claims are supported by results but would benefit from more extensive ablation studies across different numbers of exemplars and market conditions.
- Low Confidence: The generalizability of the approach to different market conditions and the robustness of the "Irrelevant" classification across diverse news sources remain uncertain without further testing.

## Next Checks
1. **Ablation Study**: Test the model with varying numbers of exemplars (0-shot, 3-shot, 6-shot, 9-shot) across all three markets to determine the minimum effective training examples and assess the true few-shot capability.
2. **Robustness Testing**: Evaluate the model on out-of-distribution news sources and market conditions to assess generalization beyond the current datasets, including cross-market transfer learning.
3. **Cost-Benefit Analysis**: Calculate actual API costs and inference time for the denoising-then-voting approach versus standard methods, and determine the breakeven point where the accuracy gains justify the additional computational expense.