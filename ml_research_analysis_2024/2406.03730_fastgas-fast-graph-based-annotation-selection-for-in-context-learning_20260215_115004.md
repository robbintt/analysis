---
ver: rpa2
title: 'FastGAS: Fast Graph-based Annotation Selection for In-Context Learning'
arxiv_id: '2406.03730'
source_url: https://arxiv.org/abs/2406.03730
tags:
- graph
- fastgas
- arxiv
- annotation
- instances
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces FastGAS, a fast graph-based annotation selection
  method for in-context learning. FastGAS addresses the inefficiency of existing selective
  annotation methods by using a graph partitioning algorithm to divide unlabeled data
  into diverse subgraphs, then applying a greedy selection algorithm to choose representative
  instances within each subgraph.
---

# FastGAS: Fast Graph-based Annotation Selection for In-Context Learning

## Quick Facts
- arXiv ID: 2406.03730
- Source URL: https://arxiv.org/abs/2406.03730
- Reference count: 29
- Outperforms state-of-the-art selective annotation methods in ICL with faster selection times

## Executive Summary
FastGAS introduces a graph-based method for selective annotation in in-context learning (ICL) that addresses the inefficiency of existing approaches. By constructing a similarity graph of unlabeled data, partitioning it into diverse subgraphs, and applying greedy selection within each subgraph, FastGAS achieves both high diversity and representativeness in selected instances while significantly reducing selection time. The method demonstrates superior performance across seven datasets spanning classification and summarization tasks, with effectiveness maintained across different language model sizes.

## Method Summary
FastGAS constructs a k-nearest neighbor graph from Sentence-BERT embeddings of unlabeled instances, partitions this graph into K disjoint subgraphs using multi-level graph bisection, and then applies greedy node selection within each subgraph based on node degree. The selected instances are annotated and used as prompts for ICL, with prompt retrieval performed via cosine similarity in the embedding space. This approach balances diversity and representativeness while achieving O(n log n) selection time complexity.

## Key Results
- Outperforms state-of-the-art baselines across seven datasets in three task types
- Maintains superior performance with faster selection times compared to existing methods
- Demonstrates effectiveness across various language model sizes from smaller models to GPT-3.5-Turbo
- Achieves better diversity and representativeness in selected instances compared to random selection

## Why This Works (Mechanism)

### Mechanism 1
Graph partitioning into diverse subgraphs ensures balanced representativeness and diversity of selected instances. By using a multi-level graph bisection algorithm, the data similarity graph is recursively split into K disjoint components, each treated as a separate candidate set. The greedy selection within each subgraph picks the most connected nodes, which maximally cover their subgraph while maintaining diversity across components.

### Mechanism 2
Greedy selection within subgraphs maximizes local coverage while being computationally efficient. In each subgraph, nodes are selected iteratively by degree, removing the chosen node and its incident edges, which ensures the selected nodes cover the most edges (and thus the most instances) in that subgraph.

### Mechanism 3
Using a small annotation budget subset still yields high ICL performance if the subset is diverse and representative. By selecting at most M/K instances per subgraph (with K partitions), the method ensures that the annotation budget is spread across diverse semantic regions of the data space, leading to effective prompt retrieval.

## Foundational Learning

- **Graph partitioning (K-way bisection)**: Understanding the computational complexity and implementation of efficient graph partitioning algorithms is essential for FastGAS's performance. *Quick check: Why is a multi-level graph bisection preferred over a single-level method for large graphs?*

- **Greedy set cover algorithms**: The greedy node selection is essentially a set cover problem with known approximation guarantees. *Quick check: What is the worst-case approximation ratio of the greedy algorithm for the maximum coverage problem?*

- **Embedding-based similarity graphs**: The quality of the k-nearest neighbor graph directly impacts downstream performance. *Quick check: How does the choice of k (number of neighbors) affect the connectivity and partitioning quality of the similarity graph?*

## Architecture Onboarding

- **Component map**: Embedding Generator -> Similarity Graph Builder -> Graph Partitioner -> Greedy Selector -> Prompt Retriever
- **Critical path**: 1) Embed all unlabeled instances 2) Build similarity graph 3) Partition graph 4) Greedy selection per subgraph 5) Annotate selected instances 6) Prompt retrieval during inference
- **Design tradeoffs**: Larger K provides better diversity but smaller subgraphs may yield less representative nodes; larger k in graph construction creates denser graphs but increases computation and potential over-smoothing
- **Failure signatures**: Poor ICL performance despite short runtime (inappropriate K or k values), high runtime variance (unbalanced subgraph sizes), low diversity in selected prompts (poor partitioning)
- **First 3 experiments**: 1) Run FastGAS with K=2 and K=10 on a small dataset, compare prompt diversity 2) Vary k in graph construction from 5 to 20, measure runtime and ICL accuracy 3) Compare greedy selection against random selection within each subgraph

## Open Questions the Paper Calls Out

- **Open Question 1**: How can the optimal number of partitions (K) and number of neighbors (k) be automatically determined for FastGAS? The paper notes the inability to automatically select appropriate K and k values, with multiple trials being viable given short execution time but inference phase costs limiting this in practice.

- **Open Question 2**: How do the interrelations between samples across different graph pieces influence the overall instance selection in FastGAS? The paper mentions separate greedy selection per piece without exploring how relationships between samples in different pieces affect final selection.

- **Open Question 3**: How does FastGAS perform with larger language models (LLMs) beyond the 7B size limit explored in the paper? The paper only covered LLMs up to 7B due to hardware limitations, with future work aiming to assess efficacy with larger LLMs.

## Limitations
- Dependency on quality of similarity graph construction with fixed k=10 parameter not tuned per dataset
- Implementation details of multi-level graph partitioning are only briefly described
- Selection process does not account for instance difficulty or noise, potentially including outliers
- No comparison against more recent embedding-based or active learning baselines

## Confidence

- **High confidence** in runtime efficiency claims (O(n log n) complexity is well-established)
- **Medium confidence** in diversity and representativeness claims (theoretical balance but evaluation relies on downstream ICL performance)
- **Medium confidence** in generalization across model sizes (consistent improvements shown but limited to few model families)

## Next Checks

1. **Parameter sensitivity analysis**: Systematically vary k and K across all datasets to identify optimal settings and test robustness to parameter choices. Measure both runtime and ICL performance to establish parameter sensitivity curves.

2. **Direct diversity evaluation**: Implement quantitative diversity metrics (e.g., intra-cluster distance, cluster separation) to evaluate the semantic diversity of selected instances independently of downstream ICL performance. Compare these metrics against baseline selection methods.

3. **Cross-domain generalization test**: Apply FastGAS to out-of-domain datasets or different task types (e.g., multi-label classification, long document summarization) to evaluate whether the graph-based partitioning approach maintains its efficiency and performance advantages when the data distribution shifts significantly from evaluated domains.