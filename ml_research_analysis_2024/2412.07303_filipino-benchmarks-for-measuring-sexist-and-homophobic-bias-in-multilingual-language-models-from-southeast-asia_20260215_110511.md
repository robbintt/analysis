---
ver: rpa2
title: Filipino Benchmarks for Measuring Sexist and Homophobic Bias in Multilingual
  Language Models from Southeast Asia
arxiv_id: '2412.07303'
source_url: https://arxiv.org/abs/2412.07303
tags:
- bias
- filipino
- language
- benchmarks
- these
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the lack of non-English bias evaluation benchmarks
  for multilingual language models, specifically focusing on sexist and homophobic
  biases in Filipino. The authors culturally adapt two English benchmarks (CrowS-Pairs
  and WinoQueer) to create Filipino versions, resulting in 7,074 new challenge pairs.
---

# Filipino Benchmarks for Measuring Sexist and Homophobic Bias in Multilingual Language Models from Southeast Asia

## Quick Facts
- arXiv ID: 2412.07303
- Source URL: https://arxiv.org/abs/2412.07303
- Authors: Lance Calvin Lim Gamboa; Mark Lee
- Reference count: 14
- Primary result: Culturally adapted English bias benchmarks to Filipino, creating 7,074 challenge pairs for evaluating sexist and homophobic bias in multilingual language models

## Executive Summary
This paper addresses the critical gap in non-English bias evaluation for multilingual language models by creating culturally adapted Filipino versions of English bias benchmarks (CrowS-Pairs and WinoQueer). The authors document the complex translation and cultural adaptation process, particularly addressing the challenge of adapting English gendered language to Filipino's gender-neutral structure. The resulting benchmarks are used to evaluate eight multilingual language models, revealing substantial sexist and homophobic biases. The study finds that bias levels correlate with the amount of Filipino pretraining data, suggesting that language-specific exposure influences cultural bias acquisition.

## Method Summary
The authors adapted two English bias benchmarks to Filipino through careful translation and cultural adaptation. For CrowS-Pairs, they translated and culturally adapted 4,158 English sentence pairs covering nine social categories. For WinoQueer, they created 2,916 sentence pairs representing 243 queer identities using 12 label types. The bias evaluation uses an iterative masking approach where models mask one token at a time while keeping others fixed, summing log probabilities to estimate sentence likelihoods. This unified method works for both masked and causal models. The final bias score represents the percentage of pairs where models incorrectly rate biased sentences as more probable than unbiased ones.

## Key Results
- Multilingual models exhibit considerable sexist and homophobic bias when evaluated with Filipino benchmarks
- Bias levels correlate with the amount of Filipino data in pretraining corpora
- SEALION models and RoBERTa-Tagalog show higher bias scores due to greater Filipino language exposure
- Cultural adaptation successfully preserved bias distinctions while maintaining natural Filipino language flow

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The bias evaluation method uses iterative masking to approximate sentence likelihoods for multilingual models.
- Mechanism: For each sentence pair, the model masks one token at a time while keeping other tokens fixed, summing the log probabilities to estimate overall sentence plausibility. This is repeated for both sentences in the pair, and the one with higher summed probability is considered more likely.
- Core assumption: Iterative masking with fixed other tokens provides a stable approximation of sentence likelihood in masked and causal models.
- Evidence anchors:
  - [abstract]: "This metric calculates the percentage of prompt pairs in which a model chooses a biased sentence as linguistically more probable compared to the sentence's less biased counterpart."
  - [section]: "The probabilities of the masked tokens at each iteration are recorded and then totaled. The sum of these probabilities represents an estimate of the likelihood a model would choose a sentence."
  - [corpus]: Weak - no corpus data directly addresses this masking approximation method.
- Break condition: If the masking approximation breaks down for highly agglutinative languages or long-range dependencies, the likelihood estimates become unreliable.

### Mechanism 2
- Claim: Cultural adaptation of bias benchmarks requires addressing linguistic gender differences between source and target languages.
- Mechanism: Since Filipino lacks gendered pronouns and nouns, the adaptation introduces gender markers (lalaki/babae) to distinguish biased and unbiased sentences while maintaining natural language flow.
- Core assumption: Adding gender descriptors preserves the original bias distinction while remaining linguistically natural in Filipino.
- Evidence anchors:
  - [abstract]: "We document the translation process, highlighting challenges like linguistic gender differences and cultural adaptation of stereotypes."
  - [section]: "If the need to differentiate between male and female entities arises, the communicator appends the descriptors lalaki (male) or babae (female) to the pertinent nounâ€”e.g., asawang lalaki (male spouse) for husband and asawang babae (female spouse) for wife."
  - [corpus]: Weak - corpus doesn't provide evidence that this adaptation successfully preserves bias distinctions.
- Break condition: If adding gender markers fundamentally changes the sentence meaning or introduces new biases not present in the original.

### Mechanism 3
- Claim: Model bias levels correlate with the amount of pretraining data in the target language.
- Mechanism: Models with more Filipino data in their pretraining corpus (SEALION models, RoBERTa-Tagalog) exhibit higher bias scores because they learn both language patterns and cultural biases from that data.
- Core assumption: More exposure to language-specific data leads to learning of both linguistic patterns and associated cultural biases.
- Evidence anchors:
  - [abstract]: "We also find that for multilingual models, the extent of bias learned for a particular language is influenced by how much pretraining data in that language a model was exposed to."
  - [section]: "What these models do share is the higher proportion of Filipino data in their pretraining corpus. It therefore seems that for multilingual models, exposure to more sample data in low-resource languages like Filipino enables a model to learn not only more aspects of the language itself but also more features of the language's culture and biases."
  - [corpus]: Weak - corpus data doesn't directly measure pretraining data amounts or their correlation with bias.
- Break condition: If bias is primarily driven by model architecture or global pretraining patterns rather than language-specific data volume.

## Foundational Learning

- Concept: Understanding of linguistic gender systems across languages
  - Why needed here: The paper deals with adapting English benchmarks (which use gendered words) to Filipino (which is inherently gender-neutral), requiring knowledge of how different languages encode gender.
  - Quick check question: How would you adapt an English sentence pair like "The doctor helped his patient" vs "The doctor helped her patient" to a gender-neutral language like Turkish?

- Concept: Multilingual bias evaluation metrics and their limitations
  - Why needed here: The paper uses a specific bias scoring method that requires understanding how to measure bias across different languages and model types.
  - Quick check question: What are the key differences between bias evaluation for masked models versus causal models?

- Concept: Cultural adaptation of evaluation benchmarks
  - Why needed here: The paper demonstrates how to adapt English bias benchmarks to Filipino while preserving their validity, which requires understanding both source and target cultures.
  - Quick check question: What considerations would you need to make when adapting Western-centric stereotypes to Southeast Asian cultural contexts?

## Architecture Onboarding

- Component map: Benchmark adaptation module -> Translation and cultural adaptation layer -> Bias evaluation engine (handles masked and causal models) -> Result aggregation and analysis component
- Critical path: The most time-consuming step is running bias evaluation on large models - SEALION-3B took 3:28:07, making this the bottleneck for iteration speed.
- Design tradeoffs: Using iterative masking for likelihood estimation trades computational efficiency for approximation accuracy; using culturally adapted benchmarks trades standardization for cultural relevance.
- Failure signatures: High bias scores (>80%) across most models indicate systematic bias; inconsistent scores across different queer identity labels suggest translation or cultural adaptation issues; runtime errors during masking iterations indicate model-specific limitations.
- First 3 experiments:
  1. Run the bias evaluation on a small masked model (e.g., bert-base-multilingual) to verify the pipeline works end-to-end and understand the expected output format.
  2. Test the cultural adaptation process by manually translating 10-20 sample sentences and having native speakers verify they preserve the original bias distinction.
  3. Compare bias scores between masked and causal versions of the same model on a small subset to validate the likelihood estimation method works across model types.

## Open Questions the Paper Calls Out
None

## Limitations
- The masking-based likelihood approximation may be unreliable for highly agglutinative languages like Filipino with complex morphological structures
- Cultural adaptation relies on researcher judgment without systematic validation from native speakers or back-translation
- The correlation between pretraining data volume and bias levels lacks direct empirical evidence linking specific data proportions to observed bias scores

## Confidence
- **High**: The general finding that multilingual models exhibit measurable bias in Filipino, supported by consistent results across multiple models and benchmark types.
- **Medium**: The specific bias scores and their relative ordering across models, which depend on the validity of the approximation method and cultural adaptation process.
- **Medium**: The correlation between pretraining data volume and bias levels, which shows plausible patterns but lacks direct empirical validation.

## Next Checks
1. **Masking Approximation Validation**: Compare the masking-based likelihood estimates against actual sentence probabilities from models that support direct probability calculation (like BERT) on a subset of test sentences to quantify approximation error.

2. **Cultural Adaptation Verification**: Conduct a blinded study with native Filipino speakers to verify that adapted sentence pairs preserve the original bias distinctions, using both acceptability judgments and bias identification tasks.

3. **Pretraining Data Analysis**: Obtain pretraining data composition information for evaluated models (or estimate it through language modeling on held-out data) to directly test the correlation between Filipino data proportion and bias scores.