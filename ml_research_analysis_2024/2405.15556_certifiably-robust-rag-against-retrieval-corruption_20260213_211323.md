---
ver: rpa2
title: Certifiably Robust RAG against Retrieval Corruption
arxiv_id: '2405.15556'
source_url: https://arxiv.org/abs/2405.15556
tags:
- passages
- robustrag
- robustness
- answer
- keyword
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes RobustRAG as the first defense framework against
  retrieval corruption attacks in retrieval-augmented generation (RAG) systems. The
  key insight is an isolate-then-aggregate strategy: first obtaining LLM responses
  from each retrieved passage in isolation, then securely aggregating these isolated
  responses.'
---

# Certifiably Robust RAG against Retrieval Corruption

## Quick Facts
- arXiv ID: 2405.15556
- Source URL: https://arxiv.org/abs/2405.15556
- Reference count: 40
- Key outcome: Proposes RobustRAG as the first defense framework against retrieval corruption attacks in RAG systems, achieving 24-71% certifiable accuracy while maintaining high clean performance.

## Executive Summary
This paper introduces RobustRAG, the first defense framework designed to protect retrieval-augmented generation (RAG) systems from retrieval corruption attacks. The framework employs an isolate-then-aggregate strategy where responses are generated from each retrieved passage independently before being securely aggregated. Two aggregation techniques are proposed: keyword-based aggregation and decoding-based aggregation. The key innovation is achieving certifiable robustness - for certain queries, RobustRAG can guarantee correct responses even when malicious passages are injected, provided corrupted passages remain less than half of total retrieved passages. Experimental results across open-domain QA and long-form text generation tasks demonstrate the framework's effectiveness across different models and datasets.

## Method Summary
RobustRAG operates on a fundamental principle: instead of generating a single response from all retrieved passages (which could be poisoned), it first generates isolated responses from each passage individually, then securely aggregates these responses. The framework uses two aggregation methods. Keyword aggregation identifies common keywords across isolated responses and selects responses containing these keywords. Decoding aggregation treats aggregation as a decoding problem, searching for responses that maximize a scoring function based on keyword overlap. Both methods incorporate thresholds (α, β, η) to filter out low-quality responses and ensure robustness. The certification process verifies that for certain queries, the aggregated response will be correct regardless of which passages are corrupted, provided the number of corrupted passages is less than half of total retrieved passages.

## Key Results
- Achieves 24-71% certifiable accuracy across different tasks and models while maintaining high clean performance
- Demonstrates effectiveness against various empirical attacks including incoherent, hallucinated, and adversarial prompts
- Shows parameter sensitivity analysis revealing that higher k (total passages) and lower k' (malicious passages) improve certifiable accuracy
- RobustRAG maintains comparable clean performance to standard RAG while providing security guarantees

## Why This Works (Mechanism)
The framework's effectiveness stems from its isolation principle - by generating responses from each passage independently before aggregation, it prevents malicious passages from directly influencing the final output. The secure aggregation methods then identify and prioritize responses that align with the majority, effectively filtering out outliers that may come from corrupted passages. The certifiable robustness guarantee is achieved through careful analysis of the aggregation process, ensuring that when less than half of passages are corrupted, the majority of clean responses will dominate the aggregation outcome.

## Foundational Learning
**Retrieval corruption attacks**: Understanding how attackers can inject malicious passages to manipulate RAG outputs is essential for designing appropriate defenses. Quick check: Verify attack vectors include both prompt injection and content poisoning.

**Certifiable robustness**: The mathematical framework for proving that certain outputs will remain correct despite bounded corruption. Quick check: Confirm the ≤ k'/2 threshold for guaranteed correctness.

**Keyword-based filtering**: Using common keywords as a proxy for semantic similarity to identify trustworthy responses. Quick check: Test keyword extraction sensitivity to different α thresholds.

**Decoding as optimization**: Treating response selection as a search problem over possible outputs. Quick check: Verify decoding algorithm finds optimal responses within computational budget.

**Isolation principle**: The concept that processing components independently before aggregation enhances robustness. Quick check: Compare performance when skipping isolation step.

## Architecture Onboarding
**Component map**: Query -> Retrieval Engine -> Passage Isolation -> LLM Response Generation -> Secure Aggregation -> Final Response

**Critical path**: The LLM response generation and secure aggregation components are most critical, as they directly implement the core defense mechanisms and determine both performance and certifiable guarantees.

**Design tradeoffs**: Higher k values improve certifiability but increase computational cost and may introduce more noise. Lower α/β thresholds improve recall but reduce precision in filtering malicious responses.

**Failure signatures**: Low certifiable accuracy indicates either too many corrupted passages relative to k, or aggregation thresholds that are too strict. Computational timeouts during certification suggest the response space is too large for current parameters.

**Three first experiments**:
1. Baseline RAG vs RobustRAG on clean queries to establish performance overhead
2. Certification analysis with varying k and k' values to find optimal parameters
3. Attack resistance testing with different malicious prompt types to evaluate empirical robustness

## Open Questions the Paper Calls Out
Open Question 1: How does RobustRAG perform against retrieval corruption attacks when the attacker can modify both the content and ranking of benign passages, not just inject malicious passages?
- Basis in paper: Appendix B discusses this generalization but lacks experimental results
- Why unresolved: Main experiments focus on passage injection attacks
- What evidence would resolve it: Experimental results showing certifiable accuracy under various passage modification attacks

Open Question 2: What is the impact of using more sophisticated keyword extraction methods on RobustRAG's performance?
- Basis in paper: Uses simple keyword extraction but acknowledges potential improvements
- Why unresolved: Paper does not explore alternative keyword extraction methods
- What evidence would resolve it: Comparative experiments using different keyword extraction methods and their impact on performance

Open Question 3: How does RobustRAG performance vary across different types of knowledge bases?
- Basis in paper: Uses Google Search as general-purpose knowledge base
- Why unresolved: Does not experiment with domain-specific or structured knowledge bases
- What evidence would resolve it: Experiments using different knowledge base types and their impact on performance

## Limitations
- Certification computational complexity increases exponentially with response set size
- Implementation details for keyword extraction and prompt templates are underspecified
- Empirical evaluation focuses on specific attack models that may not capture all real-world scenarios
- Performance guarantees only hold when corrupted passages are less than half of total retrieved passages

## Confidence
- High confidence in theoretical framework and certifiable robustness guarantees under stated assumptions
- Medium confidence in empirical evaluation results due to implementation-specific factors
- Medium confidence in practical applicability given computational constraints

## Next Checks
1. Implement and validate the EXTRACT KEYWORDS function independently to verify its impact on certification accuracy
2. Conduct scalability testing with varying numbers of retrieved passages to identify computational bottlenecks
3. Evaluate defense effectiveness against adaptive attacks that specifically target the aggregation mechanisms rather than just the LLM responses