---
ver: rpa2
title: Academically intelligent LLMs are not necessarily socially intelligent
arxiv_id: '2403.06591'
source_url: https://arxiv.org/abs/2403.06591
tags:
- social
- intelligence
- uni00000013
- uni00000048
- uni0000004c
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces SESI (Situational Evaluation of Social Intelligence),
  a benchmark for assessing social intelligence in large language models (LLMs) using
  real-world social scenarios. The benchmark is based on established social intelligence
  frameworks and includes 500 questions covering five social intelligence abilities:
  empathy, social cognition, self-presentation, influence, and concern.'
---

# Academically intelligent LLMs are not necessarily socially intelligent

## Quick Facts
- arXiv ID: 2403.06591
- Source URL: https://arxiv.org/abs/2403.06591
- Reference count: 40
- Primary result: Social intelligence is distinct from academic intelligence in LLMs, with best performance at only 55.2% accuracy

## Executive Summary
This paper introduces SESI (Situational Evaluation of Social Intelligence), a benchmark designed to assess social intelligence in large language models using real-world social scenarios. The benchmark covers five social intelligence abilities - empathy, social cognition, self-presentation, influence, and concern - and evaluates 13 popular LLMs. The study finds that social intelligence is distinct from academic intelligence, with a correlation of only 0.3 between the two. The best-performing model achieves only 55.2% accuracy, indicating significant room for improvement. Analysis reveals that models often make superficial friendly responses without considering specific social contexts, and that social factors like personality, gender, and role significantly influence model performance.

## Method Summary
The SESI benchmark is constructed by collecting social contexts and issues from the Reddit Relationships community, generating correct answers based on widely accepted responses, and creating wrong answers through question-switching and reversed answer generation. The evaluation uses a black-box method with Exact Match (EM) accuracy as the metric, comparing model performance across 500 questions with five social intelligence dimensions. The study evaluates 13 popular LLMs and compares their performance with representative academic intelligence benchmarks.

## Key Results
- Social intelligence shows low correlation (0.3) with academic intelligence in LLMs
- Best-performing model achieves only 55.2% accuracy on SESI benchmark
- Superficial friendliness is identified as the primary error cause in social judgments
- Models are significantly influenced by social factors including personality, gender, and role

## Why This Works (Mechanism)

### Mechanism 1
LLMs lack generalizable understanding of social intelligence because their training does not explicitly encode social reasoning frameworks. SESI introduces structured real-world scenarios with multiple-choice options, forcing the model to choose the most contextually appropriate response rather than generating free-form text that may rely on superficial friendliness. This is evidenced by the abstract's statement that "social intelligence is distinct from academic intelligence" with low correlation, and section 2.2's identification of "superficially friendly" as the primary error cause.

### Mechanism 2
Personality and social factor prompts shift LLM behavior because they alter internal representation priors. By prepending personality descriptions (e.g., "You are an extraverted individual"), the model's latent state is nudged toward behavior patterns associated with that trait, influencing social judgment. This is supported by systematic experiments with Big Five traits in sections 4.5-4.9, and the observation that models with low agreeableness outperform high agreeableness.

### Mechanism 3
Social intelligence evaluation benefits from multiple incorrect answer types (question-switching, reversed) because it reduces pattern-matching. Wrong answers are generated by flipping the question or inverting the stance while keeping logical coherence, forcing the model to differentiate based on nuanced understanding rather than surface similarity. This design choice is described in section 3.3.2 and highlighted in section 3.4 as contributing to SESI's "detailed and specific answers" and balanced assessment.

## Foundational Learning

- **Correlation vs. causation in intelligence measurement**: Why needed - The paper claims social intelligence is distinct from academic intelligence; understanding the statistical basis is essential. Quick check: If two variables have a Pearson correlation of 0.2, does that imply independence? (Answer: No; it indicates weak linear association but not absence of other relationships.)

- **Prompt engineering influence on LLM behavior**: Why needed - Experiments rely on prepending personality/role prompts; understanding how this affects internal states is critical. Quick check: What is the difference between in-context learning and fine-tuning? (Answer: In-context learning changes behavior via prompt context; fine-tuning modifies model weights.)

- **Social intelligence theory foundations**: Why needed - SESI is built on Goleman's framework; knowing the theoretical underpinnings helps interpret results. Quick check: Name the two main categories of social intelligence in Goleman's model. (Answer: Social consciousness and social facility.)

## Architecture Onboarding

- **Component map**: Data collection → QA generation → model evaluation → statistical analysis
- **Critical path**: SESI benchmark generator (Reddit scraping → context/issue summarization → QA tuple creation) → Evaluation pipeline (model inference → answer parsing → EM/F1 scoring) → Analysis module (error categorization → factor influence testing)
- **Design tradeoffs**: Static benchmark (reproducible) vs. dynamic Reddit-based updates (realistic but variable)
- **Failure signatures**: High accuracy due to superficial friendliness; inconsistent performance across social factors; low correlation with academic benchmarks
- **First 3 experiments**:
  1. Run SESI on a baseline model without any social factor prompts; record accuracy.
  2. Repeat with personality prompts (extraverted vs. introverted) and compare results.
  3. Test with reversed answer types only; assess if accuracy drops significantly compared to standard wrong answers.

## Open Questions the Paper Calls Out

### Open Question 1
Does the superficial friendliness observed in LLMs stem from training data biases or from specific architectural features of transformer models? The study identifies superficial friendliness as the primary error cause but doesn't investigate its root causes. Comparative analysis of models trained with different alignment approaches or different transformer architectures would help resolve this.

### Open Question 2
How does the relationship between social intelligence and academic intelligence in LLMs compare to the relationship between these intelligences in humans? While the paper demonstrates the distinction exists in LLMs, it doesn't investigate whether this mirrors human cognitive architecture. Comparative studies measuring correlations in both humans and LLMs would provide insight.

### Open Question 3
What is the minimum amount of social context needed for LLMs to make accurate social judgments, and how does context length affect performance across different social intelligence dimensions? The paper uses lengthy social contexts but doesn't systematically investigate the relationship between context length and performance. Systematic experiments varying context length would help determine this.

## Limitations
- Reliance on GPT-3.5-turbo for both data collection and answer generation may introduce systematic biases
- Correlation between social and academic intelligence based on only 13 models provides limited statistical power
- Does not explore whether models can improve social intelligence through fine-tuning versus prompting alone

## Confidence

- **High confidence**: Social intelligence is distinct from academic intelligence (supported by low correlation and error analysis showing superficial responses)
- **Medium confidence**: Personality and social factor prompts meaningfully influence LLM social judgment (requires stronger evidence of underlying mechanism)
- **Medium confidence**: The SESI benchmark provides a valid measure of social intelligence (novelty established but correlation with human judgment not tested)

## Next Checks
1. Test whether models with higher academic performance show stronger correlation with social intelligence when evaluated on a larger sample (30+ models) to assess statistical significance
2. Conduct human evaluation studies comparing SESI model outputs against human expert judgments to validate benchmark accuracy
3. Investigate whether fine-tuning on social scenarios improves performance more than prompting alone, isolating the mechanism of social intelligence improvement