---
ver: rpa2
title: 'To Burst or Not to Burst: Generating and Quantifying Improbable Text'
arxiv_id: '2401.15476'
source_url: https://arxiv.org/abs/2401.15476
tags:
- text
- burst
- sampling
- rank
- real
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of distinguishing machine-generated
  text from human-authored text. It introduces a new sampling technique called Burst
  Sampling, which randomly includes low-probability tokens to produce text that is
  statistically more similar to human text.
---

# To Burst or Not to Burst: Generating and Quantifying Improbable Text

## Quick Facts
- arXiv ID: 2401.15476
- Source URL: https://arxiv.org/abs/2401.15476
- Reference count: 8
- Primary result: Introduces Burst Sampling technique and recoverability metric for distinguishing machine-generated text from human-authored text

## Executive Summary
This paper addresses the challenge of distinguishing machine-generated text from human-authored text by introducing two key innovations: Burst Sampling, a new sampling technique that intentionally includes improbable tokens to better match human text distributions, and recoverability, a metric that measures how likely a given sampling strategy could have generated a particular piece of text. The authors conduct extensive experiments using LLaMA and Vicuna language models across six datasets, finding that human text regularly includes low-probability tokens that typical sampling strategies avoid, creating an inherent distribution shift that can be exploited for detection. The results show that recoverability effectively separates real and generated text when using LLaMA, while burst sampling produces text distributionally closer to real text when using Vicuna.

## Method Summary
The paper introduces burst sampling as an algorithm that learns a distribution over bins of token ranks from human text, then randomly selects bins and samples from them to create text with probability fluctuations similar to human text. Recoverability is introduced as a metric that measures the fraction of tokens in a text that fall within a sampling cutoff (e.g., top-k), exploiting the observation that human text regularly includes low-probability tokens outside typical sampling cutoffs. The authors generate synthetic text using various sampling strategies (top-k, top-p, temperature, and burst sampling) on two 13B parameter models across six datasets, then compute multiple metrics including self-BLEU, log likelihood, rank, burstiness, perplexity, and diversity to compare distributions between real and generated text.

## Key Results
- Recoverability effectively separates real and generated text when using LLaMA but shows limited effectiveness on Vicuna
- Burst sampling produces text that is distributionally closer to real text when using Vicuna compared to traditional sampling methods
- LLaMA and Vicuna exhibit distinct probability distributions, with Vicuna having more front-weighted distributions due to fine-tuning
- The effectiveness of detection methods varies significantly based on the underlying model's probability distribution characteristics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Recoverability works as a synthetic text detection metric because human-authored text uses more low-probability tokens than model-generated text, creating an inherent distribution shift.
- Mechanism: The recoverability metric measures the fraction of tokens in a text that fall within the sampling cutoff. Human text regularly includes low-probability tokens that fall outside typical sampling cutoffs, while generated text avoids these tokens due to the design of sampling strategies.
- Core assumption: Human text distribution has a heavier tail of low-probability tokens compared to text generated by common sampling strategies.
- Evidence anchors:
  - [abstract] "Human text to periodically use low-probability tokens means that for many sampling strategies it is impossible to generate some examples of human-authored text"
  - [section] "we find the design of popular sampling methods to be contradictory to the goal of producing human-like text"

### Mechanism 2
- Claim: Burst sampling produces text closer to human text by intentionally including improbable tokens based on observed human text distributions.
- Mechanism: Burst sampling first learns a distribution over bins of token ranks from human text, then randomly selects bins and samples from them. This creates text with probability fluctuations similar to human text, where improbable tokens appear in bursts rather than uniformly.
- Core assumption: The distribution of improbable tokens in human text can be approximated by binning token ranks and sampling from these bins.
- Evidence anchors:
  - [abstract] "burst sampling, designed to close this gap" and "burst sampling produces text which is distributionally closer to real text"
  - [section] "we introduce an algorithm, Burst Sampling, which randomly includes tokens with high information (low probability)"

### Mechanism 3
- Claim: The distinction between LLaMA and Vicuna distributions explains why different detection methods work better on each model.
- Mechanism: Vicuna's fine-tuning creates more front-weighted distributions, making it harder to distinguish generated text from real text using methods like recoverability. LLaMA's pre-trained distribution has more probability mass in lower ranks, making recoverability effective.
- Core assumption: Fine-tuning for chat behavior shifts the token probability distribution to be more front-weighted compared to pre-trained models.
- Evidence anchors:
  - [abstract] "Vicuna has a notably lower perplexity than LLaMA, a higher value for k-burstiness and a lower value for p-burstiness"
  - [section] "Vicuna sometimes produces probability distributions that are more front-weighted than LLaMA"

## Foundational Learning

- **Concept**: Probability distributions over token sequences in language models
  - Why needed here: The entire paper is built on understanding how language models assign probabilities to tokens and how different sampling strategies use these distributions
  - Quick check question: What is the difference between a model's probability distribution and the sampling strategy used to generate text from that distribution?

- **Concept**: Statistical measures of text similarity and separation
  - Why needed here: The paper introduces recoverability as a metric and uses various statistical tests to compare distributions of real vs generated text
  - Quick check question: How does the Kolmogorov-Smirnov test help determine if two distributions are significantly different?

- **Concept**: Information theory and entropy in text generation
  - Why needed here: The burst sampling technique is motivated by the observation that human text contains more information (lower probability tokens) than typical model-generated text
  - Quick check question: Why would sampling only from high-probability tokens lead to less informative text compared to human-authored text?

## Architecture Onboarding

- **Component map**: 6 datasets (arXiv, CNN/Daily Mail, PG-19, StackExchange, Twitter, Wikipedia) → preprocessing → truncation to 2000 characters → LLaMA 13B and Vicuna 13B models → sampling strategies (Top-k, Top-p, Temperature, Burst Sampling) → metrics computation (Self-BLEU, Log Likelihood, Rank/Log Rank, GLTR, Burstiness metrics, Perplexity, Diversity, Recoverability) → analysis layer (KS tests, Logistic regression classifiers, Fluency analysis)

- **Critical path**: Load dataset and preprocess samples → Generate synthetic text using specified model and sampling strategy → Compute all metrics on both real and synthetic text → Calculate distribution separations using KS tests → Train classifiers if needed for GLTR or all-metrics analysis → Aggregate and analyze results across all combinations

- **Design tradeoffs**: Dataset size vs computational feasibility (10,000 samples per dataset balances statistical power with runtime) → Model size vs experimental scope (13B parameter models chosen to balance quality with feasibility) → Context length vs sample representativeness (256-token continuations with 10% context captures generation behavior while keeping samples manageable)

- **Failure signatures**: Extremely high perplexity on real text but low perplexity on generated text indicates model has learned dataset-specific patterns → Recoverability working equally well on both LLaMA and Vicuna would suggest the method doesn't capture model-specific distribution differences → Burst sampling producing significantly lower fluency scores would indicate the method introduces too much randomness

- **First 3 experiments**:
  1. Generate text using top-k=40 with LLaMA on CNN Daily Mail dataset and compute all metrics to establish baseline behavior
  2. Apply burst sampling to Vicuna on Wikipedia dataset and compare distribution separations to top-k sampling
  3. Compute recoverability for both models on Twitter dataset using k=50 and analyze separability between real and generated text

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does recoverability scale with different k values across models, and what is the optimal k for distinguishing real from generated text?
- Basis in paper: [explicit] The paper discusses recoverability as a metric and tests it with k=40 and k=50, noting differences between LLaMA and Vicuna models.
- Why unresolved: The paper only tests a limited range of k values, and the impact of different k values on recoverability is not fully explored.
- What evidence would resolve it: Experiments testing recoverability across a broader range of k values for both LLaMA and Vicuna models would clarify the optimal k for distinguishing real from generated text.

### Open Question 2
- Question: How do different fine-tuned models (beyond Vicuna) affect the effectiveness of burst sampling and recoverability metrics?
- Basis in paper: [inferred] The paper focuses on LLaMA and Vicuna models, suggesting that model differences impact the effectiveness of these techniques.
- Why unresolved: The study only uses LLaMA and Vicuna, leaving the generalizability of findings to other fine-tuned models unclear.
- What evidence would resolve it: Testing burst sampling and recoverability metrics across a variety of fine-tuned models would reveal if the findings are model-specific or broadly applicable.

### Open Question 3
- Question: Can burst sampling be calibrated to improve fluency without sacrificing its ability to produce text closer to real text?
- Basis in paper: [explicit] The paper notes that burst sampling using LLaMA results in lower fluency compared to other sampling methods.
- Why unresolved: While burst sampling shows promise in producing text closer to real text, its impact on fluency is a limitation that needs addressing.
- What evidence would resolve it: Experiments adjusting burst sampling parameters to enhance fluency while maintaining text authenticity would provide insights into its potential optimization.

## Limitations

- Recoverability shows strong performance on LLaMA but limited effectiveness on Vicuna, suggesting model-specific limitations
- Burst sampling's binned approximation of human text probability distributions lacks thorough validation of accuracy
- Experiments focus only on 13B parameter models, leaving uncertainty about generalization to other model sizes

## Confidence

- **High Confidence**: The observation that human text contains more low-probability tokens than typical model-generated text is well-supported by the distributional analysis
- **Medium Confidence**: The recoverability metric's effectiveness on LLaMA is demonstrated, but its failure on Vicuna and lack of explanation for this discrepancy reduces confidence
- **Low Confidence**: The claim that these methods will generalize to other LLM architectures or larger models is not well-supported given the narrow experimental scope

## Next Checks

1. **Cross-model validation**: Test recoverability and burst sampling on additional model architectures (GPT-3, BLOOM, etc.) to determine if the LLaMA-specific findings hold more broadly

2. **Adversarial sampling strategies**: Implement sampling strategies specifically designed to evade recoverability detection to test the robustness of recoverability as a detection metric

3. **Human evaluation of burst sampling**: Conduct controlled human studies comparing text generated by burst sampling versus traditional methods to assess whether burst sampling produces text that humans perceive as more natural or realistic