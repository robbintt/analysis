---
ver: rpa2
title: Debiasing Recommendation with Personal Popularity
arxiv_id: '2402.07425'
source_url: https://arxiv.org/abs/2402.07425
tags:
- user
- popularity
- recommendation
- items
- users
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of popularity bias in recommendation
  systems, where globally popular items are over-recommended, harming personalization.
  The authors propose "personal popularity" (PP), which identifies different popular
  items for each user based on the preferences of similar users, contrasting with
  global popularity (GP) that uses a single set of popular items for all users.
---

# Debiasing Recommendation with Personal Popularity

## Quick Facts
- **arXiv ID:** 2402.07425
- **Source URL:** https://arxiv.org/abs/2402.07425
- **Reference count:** 40
- **Primary result:** PPAC framework improves recall and NDCG by up to 46.8% and 61.9% respectively while reducing globally popular item recommendations

## Executive Summary
This paper addresses popularity bias in recommendation systems where globally popular items are over-recommended at the expense of personalization. The authors propose a novel concept called "personal popularity" (PP) that identifies different popular items for each user based on preferences of similar users, rather than using a single set of globally popular items for everyone. They introduce the PPAC (Personal Popularity debiasing with A-C) framework that integrates PP into recommendation through counterfactual inference, effectively controlling both direct and indirect effects of popularity on predictions.

## Method Summary
The paper introduces personal popularity (PP) as an alternative to global popularity (GP) for debiasing recommendations. PP identifies popular items based on similar users' preferences for each individual user, creating personalized popularity sets. The PPAC framework integrates this concept using counterfactual inference to control the direct effects of both PP and GP on recommendations. This approach contrasts with traditional methods that treat popularity uniformly across all users. The framework was tested on three datasets with three different base recommendation models, showing consistent improvements over state-of-the-art debiasing methods.

## Key Results
- PPAC achieved up to 46.8% improvement in recall and 61.9% improvement in NDCG
- Effectively reduced the recommendation frequency of globally popular items
- Consistently outperformed state-of-the-art debiasing methods across all tested datasets and base models

## Why This Works (Mechanism)
The PPAC framework works by distinguishing between global popularity (which creates bias by treating all users the same) and personal popularity (which recognizes that different users may have different popular items based on similar users' preferences). By using counterfactual inference, the framework can separate the direct effects of popularity from other factors, allowing for more personalized recommendations that avoid over-recommending items just because they're globally popular.

## Foundational Learning
- **Counterfactual inference**: A technique for estimating what would happen under different conditions by reasoning about alternative scenarios. Needed to separate the direct effects of popularity from other factors in recommendations. Quick check: Can you explain how counterfactual reasoning differs from traditional causal inference?
- **Exposure estimation**: The process of estimating how often items are shown to users. Needed because real-world impression data is often unavailable. Quick check: What are the key challenges in estimating exposure without actual impression logs?
- **User similarity metrics**: Methods for determining which users have similar preferences. Needed to define personal popularity for each user. Quick check: How would you measure similarity between users with different interaction patterns?

## Architecture Onboarding
- **Component map**: User interactions -> Similarity calculation -> Personal popularity identification -> Counterfactual inference engine -> Debiased recommendations
- **Critical path**: The framework must first identify similar users, calculate personal popularity, then apply counterfactual inference to generate recommendations
- **Design tradeoffs**: Using heuristic-based exposure estimation instead of real impression data for practicality vs. accuracy; computational cost of similarity calculations vs. recommendation quality
- **Failure signatures**: Over-reliance on global popularity patterns; inaccurate user similarity leading to poor personal popularity identification; counterfactual estimation errors affecting recommendation quality
- **First experiments**: 1) Test on small dataset with known popularity patterns; 2) Compare personal vs global popularity recommendations; 3) Evaluate impact of different similarity metrics on personal popularity identification

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on heuristic-based exposure estimation without real-world impression data
- Limited evaluation to three datasets with specific popularity distributions
- Does not address cold-start problem or dynamic user preferences

## Confidence
- **High confidence**: PPAC framework's ability to improve recommendation metrics (recall and NDCG)
- **Medium confidence**: Effectiveness of personal popularity concept given limited dataset diversity
- **Low confidence**: Generalizability to real-world systems without accounting for dynamic preferences

## Next Checks
1. Test PPAC with actual impression data from live recommendation systems to validate exposure estimation
2. Evaluate performance on datasets with diverse popularity distributions and different item types
3. Assess robustness when user similarity metrics change or users have limited interaction history