---
ver: rpa2
title: 'Luban: Building Open-Ended Creative Agents via Autonomous Embodied Verification'
arxiv_id: '2405.15414'
source_url: https://arxiv.org/abs/2405.15414
tags:
- luban
- building
- verification
- tasks
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Luban, an open-ended creative agent designed
  to tackle building tasks in Minecraft with abstract criteria. Unlike existing agents
  that excel at tasks with well-defined goals, Luban addresses the challenge of open-ended
  tasks lacking explicit success criteria by employing autonomous embodied verification.
---

# Luban: Building Open-Ended Creative Agents via Autonomous Embodied Verification

## Quick Facts
- arXiv ID: 2405.15414
- Source URL: https://arxiv.org/abs/2405.15414
- Reference count: 40
- Primary result: 33-100% improvement over baselines on open-ended Minecraft building tasks

## Executive Summary
Luban is an open-ended creative agent designed to tackle building tasks in Minecraft with abstract criteria. Unlike existing agents that excel at tasks with well-defined goals, Luban addresses the challenge of open-ended tasks lacking explicit success criteria by employing autonomous embodied verification. The agent uses a two-stage process: first, visual verification of 3D structural objects synthesized from CAD modeling programs, followed by pragmatic verification through environment-relevant functionality programs. Extensive human studies and Elo ratings demonstrate Luban's superior performance in both visualization and pragmatism compared to other baselines.

## Method Summary
Luban operates through a two-stage autonomous embodied verification process. First, it uses visual verification to assess 3D structural objects synthesized from CAD modeling programs. Then, it performs pragmatic verification by generating environment-relevant functionality programs to test the building's actual utility. The agent iteratively refines its output based on verification results, allowing it to handle abstract criteria without explicit success metrics. The system was evaluated on 5 Minecraft building tasks against baselines including Voyager and Creative agents.

## Key Results
- 33-100% improvements in quality ratings across 5 dimensions (Appearance, Complexity, Aesthetics, Building-level Functional, Environmental-level Functional)
- Superior Elo ratings in one-to-one comparison with baseline agents
- Higher pragmatic verification pass rates compared to baselines
- Demonstrated potential for creative tasks in physical world through robotic arm demonstrations

## Why This Works (Mechanism)
The key innovation is the two-stage autonomous embodied verification system. By first verifying structural correctness through CAD program synthesis and then validating functional performance through environment-relevant programs, Luban can assess quality without explicit success criteria. This allows the agent to handle open-ended tasks where traditional reward functions are insufficient.

## Foundational Learning
1. Embodied verification: Needed to validate agent outputs in context; quick check: verification pass rates
2. CAD program synthesis: Required for generating 3D structural representations; quick check: structural accuracy metrics
3. Visual language models for CAD: Enables reasoning about visual structures; quick check: visual verification accuracy
4. Environment-relevant functionality programs: Tests actual utility in context; quick check: pragmatic verification success
5. Iterative refinement: Allows improvement without explicit success metrics; quick check: convergence rate

## Architecture Onboarding

### Component Map
Luban -> CAD modeling library -> Visual verification -> Pragmatic verification -> Iteration

### Critical Path
Input task -> CAD program synthesis -> Visual verification -> Structure generation -> Pragmatic verification -> Environment testing -> Refinement (if needed)

### Design Tradeoffs
- CAD modeling provides structured representation but may limit creativity
- Visual verification ensures structural correctness but adds computational overhead
- Pragmatic verification validates functionality but requires environment interaction
- Iterative refinement improves quality but increases time per task

### Failure Signatures
- Poor visual verification results indicate CAD program issues
- Low pragmatic verification pass rates suggest functional design flaws
- Inconsistent human ratings may indicate subjectivity in creative assessment

### 3 First Experiments
1. Run visual verification on baseline CAD programs to establish baseline accuracy
2. Test pragmatic verification on simple functional buildings to validate environment interaction
3. Compare iteration convergence rates between Luban and baselines on simple tasks

## Open Questions the Paper Calls Out
None

## Limitations
- Human study methodology introduces subjectivity in quality assessment
- Implementation details of CAD modeling library are insufficiently specified
- Lack of objective, automated metrics for creative quality assessment
- Limited task diversity in current evaluation (only 5 benchmark tasks)

## Confidence

**High Confidence:** Core architecture and two-stage verification process are clearly described with quantitative improvements over baselines.

**Medium Confidence:** Human study methodology is well-defined but subjective nature of creative assessment introduces uncertainty.

**Low Confidence:** Implementation details for CAD modeling library and VLM prompting strategies are insufficiently specified.

## Next Checks

1. Implement automated objective metrics for building quality assessment to complement human evaluations

2. Conduct ablation studies to quantify individual contributions of visual and pragmatic verification components

3. Test agent on broader range of building tasks with varying complexity levels to assess scalability and generalization