---
ver: rpa2
title: 'Flashback: Understanding and Mitigating Forgetting in Federated Learning'
arxiv_id: '2402.05558'
source_url: https://arxiv.org/abs/2402.05558
tags: []
core_contribution: 'This paper investigates the problem of knowledge forgetting in
  federated learning (FL), which occurs when models lose previously learned information
  due to heterogeneous data distributions across clients. The authors identify two
  types of forgetting: local forgetting during client updates and aggregation forgetting
  during server-side model aggregation.'
---

# Flashback: Understanding and Mitigating Forgetting in Federated Learning

## Quick Facts
- arXiv ID: 2402.05558
- Source URL: https://arxiv.org/abs/2402.05558
- Reference count: 21
- Key outcome: Flashback reduces round forgetting in federated learning by 6-16 rounds faster convergence on CIFAR10, CINIC10, and FEMNIST datasets

## Executive Summary
This paper addresses the critical problem of knowledge forgetting in federated learning, where models lose previously learned information due to heterogeneous data distributions across clients. The authors identify two distinct types of forgetting: local forgetting during client updates and aggregation forgetting during server-side model aggregation. They propose Flashback, an algorithm that employs dynamic knowledge distillation to mitigate these forgetting mechanisms. By using label counts as a proxy for model knowledge, Flashback adaptively adjusts distillation during both client and server updates, achieving faster convergence and significantly reducing round forgetting compared to existing methods.

## Method Summary
Flashback introduces a two-pronged approach to combat forgetting in federated learning. During client updates, it employs label-weighted knowledge distillation to preserve learned knowledge while adapting to local data. For server-side aggregation, Flashback uses label count information to determine optimal mixing weights between the global model and local client models. The algorithm maintains a knowledge proxy based on label distributions, which guides the strength of knowledge preservation throughout the training process. This dynamic adaptation allows the model to balance between learning new information and retaining previously acquired knowledge.

## Key Results
- Flashback converges 6-16 rounds faster than baselines on CIFAR10, CINIC10, and FEMNIST datasets
- Significantly reduces round forgetting while maintaining high accuracy
- Addresses slow and unstable convergence issues caused by forgetting in FL
- Outperforms existing methods in both convergence speed and final accuracy

## Why This Works (Mechanism)
Flashback works by recognizing that forgetting in federated learning occurs at two critical stages: during client local updates and during server aggregation. The algorithm uses label counts as a proxy for model knowledge to dynamically adjust knowledge distillation strength. When label distributions change significantly, Flashback increases knowledge preservation to prevent catastrophic forgetting. The approach leverages the observation that label distribution changes correlate with forgetting risk, allowing for adaptive intervention without requiring explicit knowledge retention mechanisms.

## Foundational Learning
- **Federated Learning**: Distributed machine learning where multiple clients train a shared model without sharing raw data. Needed to understand the collaborative learning context where forgetting occurs.
- **Knowledge Distillation**: Technique where a model learns from another model's outputs. Required to understand how Flashback preserves knowledge during training.
- **Catastrophic Forgetting**: Phenomenon where neural networks rapidly forget previously learned information when trained on new tasks. Fundamental concept explaining why forgetting is problematic in FL.
- **Label Distribution**: Frequency of different classes in training data. Used as proxy for model knowledge in Flashback's approach.
- **Round Forgetting**: Measure of knowledge loss between communication rounds in FL. Key metric for evaluating forgetting mitigation strategies.

## Architecture Onboarding

**Component Map**: Client updates -> Knowledge distillation -> Server aggregation -> Label count tracking -> Mixing weight calculation -> Global model update

**Critical Path**: The core training loop follows: client local training with knowledge distillation → server aggregation with adaptive mixing → label count update → next round. Each component must function correctly for effective forgetting mitigation.

**Design Tradeoffs**: Flashback trades increased computational overhead during training for faster convergence and better accuracy. The label count proxy is simple but may not capture all aspects of model knowledge, potentially limiting effectiveness in complex scenarios.

**Failure Signatures**: If label distributions are highly skewed or change dramatically between rounds, the label count proxy may become unreliable. Extreme data heterogeneity across clients could overwhelm the adaptive mechanism, leading to suboptimal convergence.

**First Experiments**: 1) Test on a simple two-client scenario with controlled label distribution changes to verify basic functionality. 2) Compare convergence speed with and without knowledge distillation on a single heterogeneous client. 3) Evaluate the impact of different mixing weight strategies during server aggregation.

## Open Questions the Paper Calls Out
None

## Limitations
- Experimental validation limited to image classification tasks (CIFAR10, CINIC10, FEMNIST) using CNN and ResNet architectures
- Label counts as proxy for model knowledge lacks rigorous theoretical justification and may not hold for complex feature spaces
- Computational overhead of Flashback mechanism not extensively explored
- Behavior under extreme data heterogeneity scenarios not thoroughly analyzed

## Confidence

- Forgetting phenomenon identification: High
- Flashback algorithm effectiveness: Medium (strong empirical results but limited task diversity)
- Theoretical foundations: Low (empirical approach with heuristic justifications)

## Next Checks

1. Test Flashback on non-vision tasks (e.g., language modeling or recommendation systems) to verify cross-domain applicability
2. Conduct ablation studies to quantify the contribution of individual Flashback components to overall performance
3. Evaluate the algorithm's behavior under extreme class imbalance scenarios to test the robustness of the label-count proxy assumption