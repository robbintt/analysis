---
ver: rpa2
title: 'DisGeM: Distractor Generation for Multiple Choice Questions with Span Masking'
arxiv_id: '2409.18263'
source_url: https://arxiv.org/abs/2409.18263
tags:
- distractors
- cdgp
- generation
- disgem
- distractor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors present a training-free distractor generation framework
  (DisGeM) for multiple choice questions that uses pre-trained language models with
  a two-stage candidate generation and selection approach. DisGeM outperforms prior
  methods in human evaluations, producing more effective and engaging distractors
  without requiring fine-tuning.
---

# DisGeM: Distractor Generation for Multiple Choice Questions with Span Masking

## Quick Facts
- arXiv ID: 2409.18263
- Source URL: https://arxiv.org/abs/2409.18263
- Authors: Devrim Cavusoglu; Secil Sen; Ulas Sert
- Reference count: 21
- Primary result: Training-free distractor generation framework using pre-trained language models with masked language modeling and natural language inference

## Executive Summary
This paper introduces DisGeM, a training-free framework for generating distractors in multiple choice questions. The method leverages pre-trained language models through a two-stage approach: candidate generation using masked language modeling followed by selection using natural language inference. DisGeM addresses key limitations of previous approaches by producing distractors of variable lengths without requiring fine-tuning.

The framework demonstrates strong performance in human evaluations, outperforming prior methods in producing effective and engaging distractors. The training-free nature makes it practical and adaptable across different domains, though the paper acknowledges several limitations regarding domain-specific adaptability and evaluation scope.

## Method Summary
DisGeM operates through a two-stage process: first generating candidate distractors using masked language modeling where key spans in the question stem are systematically masked and filled by a pre-trained language model; second, selecting the most appropriate distractors using natural language inference to ensure they are plausible yet incorrect. The framework processes the question stem and correct answer to generate multiple candidate distractors, then applies NLI-based filtering to select the most effective options. This approach eliminates the need for task-specific fine-tuning while maintaining flexibility in distractor length and complexity.

## Key Results
- DisGeM outperforms prior methods in human evaluations for distractor effectiveness and engagement
- Successfully generates distractors of variable lengths without requiring fine-tuning
- Two-stage approach (generation + selection) proves more effective than single-stage methods

## Why This Works (Mechanism)
The framework works by combining the generative power of masked language models with the discriminative capability of natural language inference. Masked language modeling allows for creative and context-aware distractor generation by filling in masked spans with semantically plausible alternatives. The NLI-based selection stage then filters these candidates to ensure they are plausible enough to challenge test-takers while remaining incorrect. This dual approach balances creativity with quality control, producing distractors that are both effective and engaging without the need for task-specific training.

## Foundational Learning

Masked Language Modeling
- Why needed: Enables context-aware generation of candidate distractors by predicting masked tokens
- Quick check: Verify model can predict semantically appropriate words for masked positions

Natural Language Inference
- Why needed: Provides a principled way to select distractors that are plausible but incorrect
- Quick check: Ensure NLI model can distinguish between entailed, neutral, and contradictory statements

Two-stage Candidate Generation and Selection
- Why needed: Separates creative generation from quality control to improve overall distractor quality
- Quick check: Verify each stage independently produces reasonable outputs before integration

## Architecture Onboarding

Component Map: Question Stem -> Masked Span Generation -> LLM Distractor Candidates -> NLI Selection -> Final Distractors

Critical Path: The core workflow flows from question processing through masked span identification, candidate generation via LLM, and final selection through NLI scoring. The critical dependency is the quality of the initial span masking, as poor span selection leads to irrelevant distractors regardless of the quality of subsequent stages.

Design Tradeoffs: The training-free approach sacrifices some domain-specific optimization for broad applicability and ease of deployment. The two-stage process adds computational overhead but improves quality control. Variable length distractors provide flexibility but may complicate answer sheet formatting.

Failure Signatures: Poor distractor quality typically manifests as either obvious incorrectness (failing the NLI plausibility check) or being too similar to the correct answer (failing the discrimination requirement). Computational failures may occur during LLM inference if the input exceeds model context limits.

First Experiments:
1. Test span masking on a small set of questions to verify appropriate span identification
2. Run candidate generation with a single question to check LLM output quality
3. Verify NLI selection can effectively filter a small set of distractor candidates

## Open Questions the Paper Calls Out

The paper acknowledges several open questions including the method's performance across diverse question domains and languages, the potential for bias in distractor generation, and the scalability of the approach to very large question banks. The authors also note the need for more extensive quantitative comparisons with state-of-the-art fine-tuned models.

## Limitations

- Reliance on pre-trained language models without fine-tuning may limit domain-specific adaptability
- Two-stage approach introduces implementation complexity and potential selection biases
- Effectiveness across diverse question domains and languages remains under-evaluated

## Confidence

| Claim | Confidence |
|-------|------------|
| DisGeM produces effective distractors without fine-tuning | Medium |
| Human evaluation shows superiority over prior methods | Medium |
| Two-stage approach is more effective than single-stage | Medium |

## Next Checks

1. Conduct a large-scale human evaluation across diverse question domains and languages to assess the generalizability of DisGeM
2. Compare the performance of DisGeM with fine-tuned state-of-the-art distractor generation models on benchmark datasets
3. Investigate the impact of different pre-trained language models on the quality and diversity of generated distractors in DisGeM