---
ver: rpa2
title: A Dual Attention-aided DenseNet-121 for Classification of Glaucoma from Fundus
  Images
arxiv_id: '2406.15113'
source_url: https://arxiv.org/abs/2406.15113
tags:
- glaucoma
- images
- fundus
- classification
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a dual attention-aided DenseNet-121 architecture
  for glaucoma classification from fundus images. The model combines DenseNet-121
  with Convolutional Block Attention Module (CBAM) and Channel Recalibration Module
  (CRM) to enhance feature extraction by highlighting spatial and channel-wise features,
  as well as incorporating edge and statistical information.
---

# A Dual Attention-aided DenseNet-121 for Classification of Glaucoma from Fundus Images

## Quick Facts
- arXiv ID: 2406.15113
- Source URL: https://arxiv.org/abs/2406.15113
- Reference count: 31
- Key result: Achieved 98.58% accuracy and 98.55% F1-score on ACRIMA dataset

## Executive Summary
This paper introduces a dual attention-aided DenseNet-121 architecture for glaucoma classification from fundus images. The model combines DenseNet-121 with Convolutional Block Attention Module (CBAM) and Channel Recalibration Module (CRM) to enhance feature extraction by highlighting spatial and channel-wise features, as well as incorporating edge and statistical information. Evaluated on ACRIMA and RIM-ONE datasets using 5-fold cross-validation, the model achieved 98.58% accuracy and 98.55% F1-score on ACRIMA, and 93.81% accuracy and 93.49% F1-score on RIM-ONE, outperforming state-of-the-art methods. An ablation study confirmed the effectiveness of each component, with the full dual attention setup providing the best performance.

## Method Summary
The proposed method uses DenseNet-121 as a backbone for feature extraction from fundus images, enhanced by two attention modules: CBAM for spatial and channel attention, and CRM for edge and statistical feature recalibration. The model processes 256x256x3 fundus images through transfer learning with DenseNet-121 pre-trained on ImageNet. Features are successively processed by CBAM and CRM modules before classification using a dense layer with sigmoid activation. Training uses binary cross-entropy loss, Adam optimizer with learning rate 0.001, batch size 16, and 50 epochs.

## Key Results
- Achieved 98.58% accuracy and 98.55% F1-score on ACRIMA dataset
- Achieved 93.81% accuracy and 93.49% F1-score on RIM-ONE dataset
- Ablation study confirmed dual attention setup (CBAM + CRM) outperformed individual components and baseline DenseNet-121

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dual attention (CBAM + CRM) improves glaucoma detection by emphasizing spatial and channel features while incorporating edge and statistical information.
- Mechanism: DenseNet-121 extracts deep features, which are then enhanced by CBAM (spatial + channel attention) and CRM (edge + statistical recalibration), improving feature discriminativeness for glaucoma classification.
- Core assumption: Glaucoma-related features in fundus images are spatially and channel-wise discriminative, and edge/statistical information aids in better feature representation.
- Evidence anchors:
  - [abstract]: "The channel recalibration module further enriches the features by utilizing edge information along with the statistical features of the spatial dimension."
  - [section]: "CBAM attention mechanism [18] enhances feature maps from CNNs by integrating channel-wise and spatial attention... SAM improves feature representation in the spatial dimension by generating a new feature map of the same dimension as the input."
  - [corpus]: Found 25 related papers (using 8). Average neighbor FMR=0.379, average citations=0.0. Top related titles: FA-Net: A Fuzzy Attention-aided Deep Neural Network for Pneumonia Detection in Chest X-Rays, AWGUNET: Attention-Aided Wavelet Guided U-Net for Nuclei Segmentation in Histopathology Images.
- Break condition: If glaucoma features are not spatially or channel-wise discriminative, or edge/statistical information does not correlate with glaucoma pathology, the dual attention mechanism may not improve performance.

### Mechanism 2
- Claim: DenseNet-121 serves as an effective backbone for feature extraction due to its dense connectivity and deep feature representation.
- Mechanism: DenseNet-121's dense connectivity allows for efficient gradient flow and feature reuse, enabling it to extract rich features from fundus images for glaucoma classification.
- Core assumption: DenseNet-121 pre-trained on ImageNet can effectively extract features relevant to glaucoma detection from fundus images.
- Evidence anchors:
  - [abstract]: "DenseNet-121 is used to extract deep features from the input fundus images."
  - [section]: "Features generated by the DenseNet-121, denoted as Fenc, are processed by CBAM and CRM modules successively..."
  - [corpus]: Weak evidence; corpus does not specifically mention DenseNet-121's effectiveness for glaucoma detection.
- Break condition: If DenseNet-121 fails to extract features relevant to glaucoma, or if a different architecture is more suitable, performance may degrade.

### Mechanism 3
- Claim: Ablation study confirms the effectiveness of each component (DenseNet-121, CBAM, CRM) and the combined dual attention setup.
- Mechanism: By comparing different configurations (DenseNet-121 alone, DenseNet-121 + CBAM, DenseNet-121 + CRM, DenseNet-121 + CBAM + CRM), the study demonstrates the contribution of each component and the synergy of the dual attention setup.
- Core assumption: The ablation study is conducted rigorously and fairly, with consistent evaluation metrics and datasets.
- Evidence anchors:
  - [abstract]: "An ablation study has also been conducted to show the effectiveness of each of the components."
  - [section]: "Using DenseNet-121 as the backbone, we have performed more experiments to figure out the best architectural configuration... In Table II, it is seen that the introduction of CBAM and CRM modules enhances the performance of the baseline..."
  - [corpus]: Weak evidence; corpus does not mention the ablation study or its results.
- Break condition: If the ablation study is flawed (e.g., inconsistent evaluation, biased comparisons), the claimed effectiveness of components may be inaccurate.

## Foundational Learning

- Concept: Convolutional Neural Networks (CNNs) and their application in medical image analysis
  - Why needed here: Understanding CNNs is crucial for grasping how DenseNet-121 extracts features from fundus images and how attention mechanisms enhance these features.
  - Quick check question: What are the key components of a CNN, and how do they contribute to feature extraction in medical images?

- Concept: Attention mechanisms in deep learning
  - Why needed here: Attention mechanisms (CBAM and CRM) are central to the proposed architecture, enhancing feature representation for glaucoma classification.
  - Quick check question: How do spatial and channel attention differ, and how do they improve CNN performance in medical image analysis?

- Concept: Transfer learning and pre-trained models
  - Why needed here: DenseNet-121 is pre-trained on ImageNet, and understanding transfer learning is essential for appreciating its application in glaucoma detection.
  - Quick check question: What are the benefits and limitations of using pre-trained models for medical image analysis tasks?

## Architecture Onboarding

- Component map: Input (256x256x3 fundus images) -> DenseNet-121 (feature extraction) -> CBAM (spatial + channel attention) -> CRM (edge + statistical recalibration) -> GAP (flatten) -> Dense layer (classification)

- Critical path:
  1. Load and preprocess fundus images
  2. Extract features using DenseNet-121
  3. Apply CBAM to highlight spatial and channel features
  4. Apply CRM to incorporate edge and statistical information
  5. Flatten features using Global Average Pooling (GAP)
  6. Classify using a dense layer with sigmoid activation

- Design tradeoffs:
  - DenseNet-121 vs. other backbones: DenseNet-121 provides good feature extraction but may be computationally expensive compared to lighter models like MobileNetV2.
  - CBAM vs. other attention mechanisms: CBAM is effective but may add computational overhead; other mechanisms might be more efficient but less effective.
  - CRM design: The current CRM design incorporates edge and statistical information, but alternative designs might be more effective or efficient.

- Failure signatures:
  - Poor feature extraction: If DenseNet-121 fails to extract relevant features, attention modules may not improve performance.
  - Ineffective attention: If CBAM or CRM do not enhance features effectively, classification performance may not improve.
  - Overfitting: If the model is too complex for the dataset size, it may overfit and perform poorly on unseen data.

- First 3 experiments:
  1. Train DenseNet-121 alone on the ACRIMA dataset and evaluate performance (accuracy, F1-score).
  2. Add CBAM to DenseNet-121 and compare performance with the baseline.
  3. Add CRM to DenseNet-121 and compare performance with the baseline and CBAM-enhanced model.

## Open Questions the Paper Calls Out

- How does the proposed model perform when trained and tested on a dataset with more diverse ethnic populations?
  - Basis in paper: [inferred] The paper uses ACRIMA and RIM-ONE datasets which are derived from Spanish populations. The authors suggest future work to explore few-shot learning approaches, implying a need for handling diverse datasets.
  - Why unresolved: The current evaluation does not include datasets with diverse ethnic populations, limiting the generalizability of the model.
  - What evidence would resolve it: Testing the model on datasets from different ethnic groups and comparing performance metrics.

- What is the impact of using lightweight backbone architectures on the model's performance and computational efficiency?
  - Basis in paper: [explicit] The authors mention plans to use a lightweight backbone to make the model applicable in a resource-constrained environment.
  - Why unresolved: The current study uses DenseNet-121, which may not be suitable for resource-constrained environments.
  - What evidence would resolve it: Evaluating the model's accuracy and F1-score with lightweight architectures like MobileNetV2 and comparing computational efficiency metrics.

- How does the model perform in detecting early-stage glaucoma compared to advanced stages?
  - Basis in paper: [inferred] The model focuses on classifying normal and glaucomatous eyes, but the distinction between early and advanced stages is not addressed.
  - Why unresolved: The current model does not differentiate between early and advanced stages of glaucoma, which is crucial for timely intervention.
  - What evidence would resolve it: Analyzing the model's performance on datasets that include images labeled with the severity of glaucoma.

## Limitations
- The Channel Recalibration Module (CRM) architecture is not fully specified, making exact replication difficult
- The ablation study, while mentioned, lacks detailed comparative analysis of individual component contributions
- The model's generalization to other fundus datasets remains untested beyond the two evaluated datasets

## Confidence
- **High**: The overall classification performance claims (98.58% Acc, 98.55% F1 on ACRIMA)
- **Medium**: The dual attention mechanism's effectiveness (CBAM + CRM contribution)
- **Low**: Exact CRM module implementation details and their specific impact

## Next Checks
1. Reconstruct the CRM module from scratch using the described edge and statistical features, then validate its impact through controlled ablation tests
2. Test the complete architecture on additional glaucoma fundus datasets (e.g., REFUGE, ORIGA) to assess generalization
3. Compare computational efficiency and parameter counts against baseline DenseNet-121 to quantify the attention modules' overhead