---
ver: rpa2
title: Strengthened Symbol Binding Makes Large Language Models Reliable Multiple-Choice
  Selectors
arxiv_id: '2406.01026'
source_url: https://arxiv.org/abs/2406.01026
tags:
- wrong
- bias
- selection
- llms
- symbol
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that selection bias persists in the supervised
  fine-tuning (SFT) phase for large language models (LLMs) on multiple-choice questions
  (MCQs). The bias is attributed to inadequate multiple-choice symbol binding (MCSB)
  ability, meaning the model struggles to associate answer options with their corresponding
  symbols.
---

# Strengthened Symbol Binding Makes Large Language Models Reliable Multiple-Choice Selectors

## Quick Facts
- arXiv ID: 2406.01026
- Source URL: https://arxiv.org/abs/2406.01026
- Authors: Mengge Xue; Zhenyu Hu; Liqun Liu; Kuo Liao; Shuang Li; Honglin Han; Meng Zhao; Chengguo Yin
- Reference count: 16
- Primary result: PIF reduces selection bias in MCQs by strengthening symbol binding, improving accuracy from 54.6% to 55.0% on MMLU

## Executive Summary
This paper addresses selection bias in large language models when answering multiple-choice questions during supervised fine-tuning. The bias stems from inadequate multiple-choice symbol binding (MCSB) ability, where models fail to properly associate answer options with their corresponding symbols. The authors propose Point-wise Intelligent Feedback (PIF), a method that constructs negative samples by randomly combining incorrect option contents with candidate symbols and uses point-wise loss to provide targeted feedback. Experimental results demonstrate that PIF significantly reduces selection bias by improving MCSB capability, with notable improvements on the MMLU benchmark.

## Method Summary
The authors identify selection bias in multiple-choice question answering as a symptom of weak multiple-choice symbol binding (MCSB) ability in LLMs. Their solution, Point-wise Intelligent Feedback (PIF), addresses this by generating negative samples through random pairing of incorrect answer contents with candidate symbols, then applying point-wise loss to provide specific feedback. This approach strengthens the model's ability to correctly associate answer options with their symbols, thereby reducing selection bias during supervised fine-tuning.

## Key Results
- PIF reduces selection bias (Âµbias) on MMLU from 7.7 to 2.7
- Accuracy improves from 54.6% to 55.0% on MMLU
- PIF demonstrates significant improvement in MCSB capability

## Why This Works (Mechanism)
The mechanism relies on strengthening the model's ability to bind answer symbols to their corresponding content options. Selection bias occurs when models fail to properly associate symbols (A, B, C, D) with their answer options, leading to systematic errors. By creating negative samples that break these associations and providing point-wise feedback, PIF forces the model to learn stronger symbol-option bindings, thereby reducing bias.

## Foundational Learning
- Multiple-choice symbol binding (MCSB): The ability to correctly associate answer symbols with their corresponding options. Needed because weak MCSB leads to selection bias. Quick check: Can the model correctly match symbols to options even when content is scrambled?
- Selection bias in MCQs: Systematic preference for certain answer choices regardless of content. Needed because it represents a fundamental limitation in MCQ performance. Quick check: Does the model show consistent preference for certain letters independent of question content?
- Negative sampling in training: Creating incorrect examples to improve learning. Needed to provide contrastive learning signals. Quick check: Are the negative samples challenging enough to provide meaningful feedback?
- Point-wise loss functions: Loss calculated at individual sample level rather than batch level. Needed for precise feedback on specific symbol-option associations. Quick check: Does the loss function appropriately weight symbol-option binding errors?

## Architecture Onboarding

Component Map:
SFT Training -> MCSB Weakness Detection -> PIF Negative Sample Generation -> Point-wise Loss Application -> Improved Symbol Binding

Critical Path:
The critical path involves detecting MCSB weakness during SFT, generating appropriate negative samples through PIF, applying point-wise loss to strengthen symbol bindings, and measuring reduction in selection bias and improvement in accuracy.

Design Tradeoffs:
- Random negative sample generation vs. more sophisticated sampling strategies
- Point-wise vs. batch-level feedback mechanisms
- Computational overhead of additional negative samples vs. performance gains
- Generalization across different MCQ formats and domains

Failure Signatures:
- Continued selection bias despite PIF application
- Degraded performance on other tasks due to overfitting to MCQ structure
- Computational inefficiency from excessive negative sample generation
- Failure to generalize PIF improvements to new MCQ datasets

First Experiments:
1. Verify MCSB weakness exists in baseline models on multiple MCQ datasets
2. Test PIF's impact on symbol-option association accuracy in isolation
3. Compare PIF performance against baseline SFT on held-out MCQ data

## Open Questions the Paper Calls Out
None specified in the provided materials.

## Limitations
- Experiments primarily conducted on MMLU, limiting generalizability to other domains
- No analysis of computational overhead introduced by PIF during training
- Unclear whether improvements scale with model size
- Mechanism by which random negative samples specifically target MCSB weakness needs more theoretical grounding

## Confidence

| Claim | Confidence |
|-------|------------|
| PIF reduces selection bias and improves accuracy on MMLU | High |
| MCSB weakness is the primary cause of selection bias | Medium |
| PIF generalizes across different model architectures and domains | Low |

## Next Checks
1. Replicate PIF methodology on additional multiple-choice datasets (e.g., RACE, ARC) to assess generalizability
2. Conduct ablation studies comparing PIF with alternative negative sampling strategies
3. Measure computational overhead and training time impact of PIF compared to standard SFT, particularly for larger model sizes