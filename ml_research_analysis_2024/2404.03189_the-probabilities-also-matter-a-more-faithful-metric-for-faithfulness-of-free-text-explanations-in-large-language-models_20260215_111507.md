---
ver: rpa2
title: 'The Probabilities Also Matter: A More Faithful Metric for Faithfulness of
  Free-Text Explanations in Large Language Models'
arxiv_id: '2404.03189'
source_url: https://arxiv.org/abs/2404.03189
tags:
- option
- explanation
- sentence
- explanations
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Correlational Explanatory Faithfulness (CEF),
  a metric that measures how well free-text explanations generated by large language
  models reflect the true factors influencing their predictions. Unlike prior metrics
  that only consider binary changes in predictions, CEF captures both the degree of
  impact of input features and the difference in explanation mention frequency between
  impactful and non-impactful factors.
---

# The Probabilities Also Matter: A More Faithful Metric for Faithfulness of Free-Text Explanations in Large Language Models

## Quick Facts
- arXiv ID: 2404.03189
- Source URL: https://arxiv.org/abs/2404.03189
- Reference count: 40
- The Correlational Counterfactual Test (CCT) outperforms the Counterfactual Test (CT) by measuring the correlation between prediction impact and explanation mention frequency, revealing that larger models (Llama2 70B) produce more faithful explanations.

## Executive Summary
This paper introduces Correlational Explanatory Faithfulness (CEF), a metric that measures how well free-text explanations generated by large language models reflect the true factors influencing their predictions. Unlike prior metrics that only consider binary changes in predictions, CEF captures both the degree of impact of input features and the difference in explanation mention frequency between impactful and non-impactful factors. The authors instantiate CEF on the Counterfactual Test (CT) to create the Correlational Counterfactual Test (CCT), which uses total variation distance to measure prediction shifts. Experiments on three NLP tasks show that CCT captures faithfulness trends missed by the original CT, revealing that model explanations are more likely to mention impactful interventions than less impactful ones.

## Method Summary
The method generates counterfactual interventions by inserting random adjectives and adverbs at 4 random positions in input examples. It computes the total variation distance (TVD) between model predictions before and after interventions to quantify prediction impact. For each explanation, it checks whether the inserted words are mentioned, creating a binary mention importance score. The CCT score is then calculated as the Pearson correlation between TVD values and mention importance scores across all interventions. The framework is applied to Llama2 models (7B, 13B, 70B) on three datasets (e-SNLI, ECQA, ComVE) using both predict-then-explain and explain-then-predict prompting strategies.

## Key Results
- CCT captures faithfulness trends missed by CT, particularly the correlation between explanation mentions and prediction impact
- The largest model (Llama2 70B) produced the most faithful explanations on e-SNLI and ComVE datasets
- CCT is harder to game than CT since achieving maximum correlation requires explanations to mention impactful interventions while not mentioning non-impactful ones
- Correlation between prediction impact and mention frequency provides a more nuanced measure of faithfulness than binary prediction changes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CEF captures faithfulness better than prior metrics by measuring both prediction impact and explanation mention frequency correlation
- Mechanism: The metric computes Pearson correlation between prediction impact (TVD) and mention importance, ensuring explanations mention impactful features more often than non-impactful ones
- Core assumption: A faithful explanation should assign higher mention importance to features with higher prediction impact
- Evidence anchors:
  - [abstract]: "Our metric accounts for the total shift in the model's predicted label distribution, more accurately reflecting the explanations' faithfulness."
  - [section]: "We quantify this relationship by measuring the Pearson correlation coefficient between prediction impact and mention importance"
  - [corpus]: Weak - corpus contains related papers but no direct evidence supporting this specific mechanism
- Break condition: If the correlation between prediction impact and mention importance is zero or negative, CEF fails to capture faithfulness

### Mechanism 2
- Claim: TVD provides a continuous measure of prediction impact rather than binary classification changes
- Mechanism: TVD measures the total variation distance between prediction distributions before and after intervention, capturing the magnitude of prediction shifts
- Core assumption: Changes in prediction probabilities provide more information about feature importance than binary prediction changes
- Evidence anchors:
  - [abstract]: "Our metric accounts for the total shift in the model's predicted label distribution"
  - [section]: "To quantify the degree of prediction impact in a continuous manner, we measure the total shift in the model's predictions"
  - [corpus]: Weak - corpus mentions related work but doesn't directly support TVD choice
- Break condition: If TVD fails to distinguish between interventions with different prediction impacts, the mechanism breaks

### Mechanism 3
- Claim: CCT addresses the gaming vulnerability of CT by requiring explanations to mention impactful features more than non-impactful ones
- Mechanism: CCT uses correlation to measure whether explanations systematically mention features based on their impact, making it harder to game by simply repeating all input text
- Core assumption: A faithful explanation must differentiate between impactful and non-impactful features in its mentions
- Evidence anchors:
  - [abstract]: "Unlike the CT, it cannot be trivially gamed: achieving maximum correlation requires explanations to mention impactful IAs while not mentioning non-impactful IAs"
  - [section]: "Unlike the CT, it cannot be trivially gamed: achieving maximum correlation requires explanations to mention impactful IAs while not mentioning non-impactful IAs"
  - [corpus]: Weak - corpus doesn't directly support this gaming vulnerability claim
- Break condition: If explanations can achieve high CCT scores without actually being faithful, the mechanism fails

## Foundational Learning

- Concept: Pearson correlation coefficient
  - Why needed here: Used to measure the relationship between prediction impact and explanation mentions
  - Quick check question: What values can Pearson correlation coefficient take and what do they mean?

- Concept: Total variation distance
  - Why needed here: Measures the continuous shift in prediction distributions after interventions
  - Quick check question: How does TVD differ from other distance metrics like KL divergence?

- Concept: Counterfactual interventions
  - Why needed here: Method to generate known impactful features for faithfulness testing
  - Quick check question: What are the limitations of using only adjective and adverb insertions as interventions?

## Architecture Onboarding

- Component map: Input examples → Intervention insertion → Model prediction (before/after) → TVD calculation → Explanation analysis → Correlation calculation
- Critical path: 1. Generate counterfactual interventions 2. Get model predictions before and after interventions 3. Calculate TVD for each intervention 4. Check if explanations mention inserted words 5. Compute CCT score
- Design tradeoffs:
  - Intervention type (random adjectives/adverbs vs. semantically coherent changes)
  - Distance metric choice (TVD vs. alternatives)
  - Correlation type (Pearson vs. rank correlation)
  - Mention detection method (exact match vs. semantic similarity)
- Failure signatures:
  - High CCT scores with obviously unfaithful explanations
  - Low CCT scores despite seemingly faithful explanations
  - Inconsistent CCT scores across similar datasets
  - Model predictions not changing despite interventions
- First 3 experiments:
  1. Compare CCT scores across different model sizes (7B, 13B, 70B)
  2. Test CCT with alternative distance metrics (JS divergence, KL divergence)
  3. Evaluate CCT with different correlation coefficients (Spearman, Kendall)

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the text provided.

## Limitations
- The evaluation focuses on three datasets and one model family (Llama2), limiting generalizability claims
- The choice of random adjective/adverb interventions may not represent the most impactful types of interventions for measuring faithfulness
- The paper doesn't adequately address whether the Pearson correlation measure itself is susceptible to gaming or whether alternative correlation metrics might perform differently

## Confidence
- High Confidence: The core methodology for computing TVD and Pearson correlation is sound and correctly implemented. The experimental results showing higher CCT scores for larger models on certain datasets are robust and reproducible.
- Medium Confidence: The claim that CCT addresses CT's gaming vulnerability is supported by theoretical reasoning but not rigorously tested against potential adversarial explanations. The comparison of CCT versus CT across multiple datasets shows trends but doesn't definitively prove CCT's superiority in all faithfulness measurement scenarios.
- Low Confidence: The assertion that CEF/CCT would generalize to other model families (e.g., GPT, Claude) or to different types of interventions beyond adjective/adverb insertion lacks empirical support in the current work.

## Next Checks
1. **Gaming Vulnerability Test**: Systematically attempt to generate explanations that achieve high CCT scores without being faithful by using techniques like repeating all input words, generating semantically plausible but factually incorrect explanations, or using template-based responses that mention intervention words regardless of impact.

2. **Alternative Intervention Types**: Evaluate CCT using semantically coherent interventions (e.g., negation of key predicates, synonym replacement, entity substitution) rather than random adjective/adverb insertion to determine if the metric's effectiveness depends on intervention type.

3. **Cross-Model Generalization**: Apply the CCT framework to other large language model families (GPT-3.5/4, Claude) and compare faithfulness measurements across different architectures to validate whether the observed trends with Llama2 generalize beyond a single model family.