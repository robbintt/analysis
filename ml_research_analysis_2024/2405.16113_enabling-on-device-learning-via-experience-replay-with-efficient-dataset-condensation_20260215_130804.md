---
ver: rpa2
title: Enabling On-Device Learning via Experience Replay with Efficient Dataset Condensation
arxiv_id: '2405.16113'
source_url: https://arxiv.org/abs/2405.16113
tags: []
core_contribution: This paper addresses the challenge of enabling deep learning models
  deployed on edge devices to continuously learn from streaming data, which is typically
  unlabeled, non-i.i.d., and seen only once. The proposed framework, DECO, addresses
  this by condensing incoming data into a limited-size buffer using an efficient dataset
  condensation technique combined with pseudo-labeling and contrastive learning.
---

# Enabling On-Device Learning via Experience Replay with Efficient Dataset Condensation

## Quick Facts
- arXiv ID: 2405.16113
- Source URL: https://arxiv.org/abs/2405.16113
- Reference count: 40
- Primary result: DECO achieves 58.4% accuracy improvement on CIFAR-10 with 1 sample per class buffer vs best baseline

## Executive Summary
This paper addresses the challenge of enabling deep learning models on edge devices to continuously learn from streaming data without catastrophic forgetting. The proposed DECO framework combines efficient dataset condensation with pseudo-labeling and contrastive learning to maintain a compact buffer of representative data for experience replay. By simplifying the gradient matching process and using majority voting for pseudo-labeling, DECO achieves significant performance improvements while remaining computationally feasible for on-device deployment.

## Method Summary
DECO processes streaming data by first assigning pseudo-labels using majority voting within a sliding window, then condenses this data into a limited-size buffer using a simplified one-step gradient matching approach. To improve class purity and mitigate label noise, contrastive learning is applied within the buffer. The framework is specifically designed for unlabeled, non-i.i.d. streaming data scenarios where traditional experience replay would be infeasible due to storage constraints and computational limitations.

## Key Results
- Achieves 58.4% accuracy improvement on CIFAR-10 with 1 sample per class buffer compared to best baseline
- Maintains significant performance advantage even with minimal labeled data ratios
- Demonstrates lower variance and better stability than existing methods, particularly with small buffer sizes
- Shows robust performance across multiple datasets including SVHN, CIFAR-10, CIFAR-100, and ImageNet-10

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gradient matching without inner loop maintains learning performance while drastically reducing computation.
- Mechanism: Uses only the outer loop of gradient matching, computing gradients once after model initialization rather than iteratively updating both model and synthetic data.
- Core assumption: Outer loop gradient matching is sufficient for aligning synthetic and real data distributions.
- Evidence anchors:
  - [abstract] "optimize the algorithm to significantly speed up the condensation process, making it feasible for on-device settings without compromising accuracy."
  - [section] "we introduce a simplified, one-step gradient matching strategy to speed up the condensation process."
  - [corpus] No direct corpus evidence found for one-step gradient matching approach.
- Break condition: If single-step gradient matching fails to align synthetic and real data distributions sufficiently.

### Mechanism 2
- Claim: Majority voting with sliding window improves pseudo-label accuracy for unlabeled streaming data.
- Mechanism: Filters incoming data by retaining only samples where the predicted class appears frequently within a sliding window of the same size as the current data segment.
- Core assumption: Streaming data exhibits temporal correlation with consecutive samples belonging to the same class.
- Evidence anchors:
  - [abstract] "we propose a pseudo-labeling technique designed for unlabeled on-device learning environments."
  - [section] "we propose a simple yet effective majority voting method to filter the samples with low confidence in pseudo-labels."
  - [corpus] No direct corpus evidence found for majority voting approach to pseudo-labeling.
- Break condition: If streaming data becomes less temporally correlated or window size is inappropriate.

### Mechanism 3
- Claim: Contrastive learning within the buffer improves class purity and mitigates effects of noisy pseudo-labels.
- Mechanism: Applies contrastive loss to synthetic buffer data, pulling same-class samples together and pushing different-class samples apart based on their pseudo-labels.
- Core assumption: Contrastive learning can improve class separation even when some pseudo-labels are incorrect.
- Evidence anchors:
  - [abstract] "To counteract the effects of noisy labels during the condensation process, we further utilize a contrastive learning objective to improve the purity of class data within the buffer."
  - [section] "we use contrastive learning to enhance class purity within the buffer."
  - [corpus] No direct corpus evidence found for contrastive learning within dataset condensation buffers.
- Break condition: If contrastive learning fails to sufficiently separate classes with noisy labels.

## Foundational Learning

- Dataset condensation fundamentals
  - Why needed here: The method relies on creating compact synthetic datasets that retain essential information for model training.
  - Quick check question: How does gradient matching work to align synthetic and real data distributions?

- Experience replay in continual learning
  - Why needed here: The buffer stores condensed data for replay-based learning to prevent catastrophic forgetting.
  - Quick check question: What is catastrophic forgetting and how does experience replay help prevent it?

- Pseudo-labeling strategies
  - Why needed here: The method must assign labels to unlabeled streaming data before condensation.
  - Quick check question: Why might pseudo-labeling be less reliable than human-labeled data?

- Contrastive learning principles
  - Why needed here: Contrastive learning improves class separation within the buffer to mitigate label noise.
  - Quick check question: How does contrastive learning encourage similar representations for same-class samples?

## Architecture Onboarding

- Component map: Input stream → Pseudo-labeling with majority voting → Efficient gradient matching condensation → Contrastive learning enhancement → Buffer storage → Model training
- Critical path: New data arrival → Pseudo-label assignment → Majority voting filtering → Gradient matching condensation → Contrastive learning → Buffer update → Periodic model training
- Design tradeoffs: Single-step gradient matching reduces computation but may sacrifice some accuracy; larger sliding windows improve pseudo-label accuracy but reduce available data.
- Failure signatures: Model accuracy plateaus despite new data arrival; buffer condensation produces low-quality synthetic data; contrastive learning fails to improve class separation.
- First 3 experiments:
  1. Test pseudo-labeling accuracy with varying sliding window sizes on synthetic temporally correlated data.
  2. Compare full gradient matching (with inner loop) vs single-step gradient matching on small dataset.
  3. Evaluate contrastive learning effectiveness by measuring class purity in buffer with varying levels of label noise.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of DECO scale with increasing buffer sizes, particularly when approaching full dataset storage?
- Basis in paper: [inferred] The paper mentions that DECO's advantage decreases as buffer capacity increases (e.g., with IpC=50), suggesting a need to understand scaling behavior.
- Why unresolved: The paper only tests up to IpC=50, leaving the performance at larger buffer sizes unexplored.
- What evidence would resolve it: Experiments testing DECO with progressively larger buffer sizes, including near-full dataset storage, to determine the point at which its advantages plateau or diminish.

### Open Question 2
- Question: What is the optimal trade-off between the filter threshold M and the accuracy of pseudo-labeling in non-stationary data streams?
- Basis in paper: [explicit] The paper discusses the impact of the filter threshold M on pseudo-labeling accuracy and data retention, but does not provide a definitive optimal value.
- Why unresolved: The paper shows a trade-off between data retention and label accuracy but does not determine the optimal balance for different data stream characteristics.
- What evidence would resolve it: Systematic experiments varying the filter threshold M across diverse data stream scenarios to identify the optimal value for maximizing model accuracy.

### Open Question 3
- Question: How does DECO perform in scenarios with highly imbalanced class distributions in the streaming data?
- Basis in paper: [inferred] The paper does not address class imbalance, which is a common issue in real-world data streams, suggesting a gap in understanding DECO's robustness.
- Why unresolved: The experimental setup assumes balanced classes, leaving the performance under imbalanced conditions untested.
- What evidence would resolve it: Experiments with streaming data containing highly imbalanced class distributions to evaluate DECO's ability to maintain performance and avoid bias towards majority classes.

## Limitations
- Assumes temporal correlation in streaming data for pseudo-labeling, which may not hold in all real-world scenarios
- Single-step gradient matching simplification may not fully capture complex relationships between synthetic and real data distributions
- Performance claims primarily validated on image classification tasks, limiting generalizability to other data types

## Confidence
**High confidence**: The overall framework design and experimental methodology are sound, with clear baselines and controlled comparisons. The reported improvements over existing methods are statistically significant and reproducible.

**Medium confidence**: The computational efficiency claims rely heavily on the single-step gradient matching simplification, which hasn't been thoroughly benchmarked against more complex alternatives. The pseudo-labeling effectiveness depends on assumptions about data stream characteristics that may vary in practice.

**Low confidence**: The contrastive learning component's contribution is not isolated clearly in ablation studies, making it difficult to assess its standalone impact on buffer quality and final model performance.

## Next Checks
1. **Temporal correlation dependency test**: Evaluate pseudo-labeling accuracy when streaming data arrives in random order versus temporally correlated order, measuring the impact on final model performance.

2. **Gradient matching fidelity analysis**: Compare single-step vs full iterative gradient matching approaches on smaller datasets with detailed metrics on synthetic data quality, including distribution alignment measures and downstream training performance.

3. **Contrastive learning ablation study**: Systematically evaluate the contribution of contrastive learning by testing configurations with and without it across different levels of pseudo-label noise, measuring both buffer class purity and final model accuracy.