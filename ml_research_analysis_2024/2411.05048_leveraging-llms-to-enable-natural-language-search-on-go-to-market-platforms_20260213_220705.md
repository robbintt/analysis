---
ver: rpa2
title: Leveraging LLMs to Enable Natural Language Search on Go-to-market Platforms
arxiv_id: '2411.05048'
source_url: https://arxiv.org/abs/2411.05048
tags:
- search
- fields
- language
- query
- natural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a natural language search system for Zoominfo's
  enterprise platform, addressing the challenge of complex advanced search interfaces
  that require users to navigate hundreds of options. The core method involves converting
  natural language queries into structured JSON search fields using LLMs, which are
  then mapped to the platform's search service query.
---

# Leveraging LLMs to Enable Natural Language Search on Go-to-market Platforms

## Quick Facts
- arXiv ID: 2411.05048
- Source URL: https://arxiv.org/abs/2411.05048
- Reference count: 33
- Primary result: Natural language search system achieved 97% average query accuracy using Claude 3.5 Sonnet

## Executive Summary
This paper presents a natural language search system for Zoominfo's enterprise platform that converts user queries into structured JSON search fields using LLMs. The system addresses the challenge of complex advanced search interfaces by enabling users to search using natural language rather than navigating hundreds of search options. The approach achieves high accuracy through sophisticated prompt engineering and uses JSON as an intermediary format to eliminate syntax errors and simplify ground truth creation.

## Method Summary
The system converts natural language queries into structured JSON search entities using LLM prompting with system messages, few-shot examples, and chain-of-thought reasoning. These JSON entities are then mapped to the platform's search service query. The approach uses detailed system messages defining all search fields, executes query refinement to handle invalid JSON outputs, and employs supervised fine-tuning on Llama3-8B-Instruct. The method was evaluated on 500+ manually created ground truth queries for Zoominfo's ZI Sales product, measuring accuracy across multiple similarity metrics.

## Key Results
- Achieved 97% average query accuracy using Claude 3.5 Sonnet
- JSON intermediary format eliminated syntax errors and simplified ground truth creation
- Fine-tuned Llama3-8B-Instruct achieved comparable results at lower cost
- Supported various field types including company attributes, locations, revenue bounds, and titles

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The JSON intermediary format eliminates syntax errors in the query generation process
- Mechanism: By having the LLM generate a structured JSON output instead of directly generating the final search service query, the system can validate and correct the output before it's executed. JSON has a well-defined structure that's easier to validate than a custom query language
- Core assumption: LLMs can reliably generate syntactically correct JSON when properly prompted
- Evidence anchors:
  - [abstract] "The intermediary JSON format eliminated syntax errors and enabled simpler ground truth creation"
  - [section] "The intermediary search entities provide several benefits, the most notable being the elimination of syntax errors"
- Break condition: If the LLM consistently fails to generate valid JSON despite proper prompting, or if the JSON structure becomes too complex for reliable generation

### Mechanism 2
- Claim: Detailed system messages with comprehensive field definitions significantly improve LLM accuracy
- Mechanism: By explicitly defining every field, its description, allowed values, and logical relationships in the system message, the LLM has sufficient context to make accurate field selections. The 3095-word system message provides exhaustive documentation of the schema
- Core assumption: LLMs can effectively utilize detailed documentation when making field selection decisions
- Evidence anchors:
  - [section] "We observed that explicitly detailing every aspect, structure, and definition worked in our favor and significantly increased our accuracy"
  - [section] "Consequently, we meticulously defined every field within the system message, resulting in a text of 3095 words"
- Break condition: If the system message becomes too long for the LLM to effectively process, or if certain field relationships are too complex to document clearly

### Mechanism 3
- Claim: Chain-of-thought reasoning helps the LLM understand implicit logic and handle ambiguous natural language queries
- Mechanism: By explicitly stating the reasoning process for each example, the LLM learns to apply the same logical steps to new queries. This is particularly important for understanding concepts like "decision makers" or handling mutually exclusive fields
- Core assumption: LLMs can generalize reasoning patterns from explicit examples to new, unseen queries
- Evidence anchors:
  - [section] "We observed that severe specificity often worked in our favor as it would phase out certain careless errors"
  - [section] "CoT prompting is defined as guiding the LLM step-by-step through the exact reasoning process to determine the desired output"
- Break condition: If the reasoning patterns don't generalize well to queries that differ significantly from the training examples

## Foundational Learning

- Concept: JSON data structure and validation
  - Why needed here: The system relies on JSON as an intermediary format between natural language and the search query. Understanding JSON structure is essential for debugging and extending the system
  - Quick check question: What are the basic JSON data types and how would you validate a JSON object in Python?

- Concept: Prompt engineering techniques (system messages, few-shot learning, chain-of-thought)
  - Why needed here: These techniques are fundamental to how the system achieves high accuracy. Understanding them is crucial for optimizing the system and troubleshooting issues
  - Quick check question: How does few-shot learning differ from chain-of-thought prompting in terms of their effects on LLM output?

- Concept: Similarity metrics (exact match, Jaccard, cosine, semantic similarity)
  - Why needed here: These metrics are used to evaluate the accuracy of the LLM's field selections. Understanding them is essential for interpreting evaluation results and improving the system
  - Quick check question: When would you use Jaccard similarity versus cosine similarity for comparing two lists of terms?

## Architecture Onboarding

- Component map: User query → LLM with system message + few-shot examples + CoT → JSON search entities → conversion function → search service query → results
- Critical path: The LLM conversion step is the critical path, as it determines the quality of the entire system. Everything else is relatively straightforward transformation or validation
- Design tradeoffs: Using JSON as an intermediary adds a conversion step but provides error prevention and easier ground truth creation. The tradeoff is between system complexity and reliability
- Failure signatures: If the LLM generates invalid JSON, syntax errors will appear in the conversion step. If field selection is poor, similarity metrics will show low scores for specific field types
- First 3 experiments:
  1. Test LLM output validation by providing various prompts and checking if the JSON is always valid
  2. Evaluate the impact of removing few-shot examples on field accuracy, particularly for ambiguous terms
  3. Compare the accuracy of different similarity metrics for free-text fields to determine which best captures semantic meaning

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the upper limit of query complexity and field combinations that the natural language search system can handle while maintaining high accuracy?
- Basis in paper: [inferred] The paper mentions that fields were "explicitly selected to strike a delicate balance" and notes fewer than 10 out of 509 queries were not supported by the LLM. However, it doesn't establish a clear threshold for maximum complexity.
- Why unresolved: The paper doesn't systematically test or document the maximum complexity of queries (number of fields, nesting levels, or logical operators) that can be handled before accuracy degrades significantly.
- What evidence would resolve it: Systematic testing with increasingly complex queries varying field count, logical operators, and query length to identify the point where accuracy drops below a defined threshold.

### Open Question 2
- Question: How does the system's performance degrade when encountering domain-specific jargon, acronyms, or ambiguous terminology not covered in the training data?
- Basis in paper: [inferred] The paper mentions "company attributes" had a word bank and discusses the importance of pre-defining word banks for categorical fields, but doesn't test performance on unrecognized terminology.
- Why unresolved: While the paper demonstrates high accuracy with existing word banks, it doesn't evaluate how the system handles novel or ambiguous terms that fall outside predefined categories.
- What evidence would resolve it: Testing with queries containing industry-specific terminology, abbreviations, and ambiguous phrases not present in the training data, measuring accuracy degradation and analyzing LLM reasoning patterns.

### Open Question 3
- Question: What is the optimal balance between model size/complexity and cost/performance for different enterprise search use cases?
- Basis in paper: [explicit] The paper explicitly compares Claude 3.5 Sonnet (97% accuracy, slower, more expensive) with Claude 3 Haiku and fine-tuned Llama3-8B-Instruct (both around 95.6% accuracy), but doesn't establish specific use-case guidelines.
- Why unresolved: The paper demonstrates that smaller models can achieve comparable results but doesn't provide a framework for selecting models based on specific enterprise requirements, budget constraints, or latency needs.
- What evidence would resolve it: A systematic evaluation framework mapping enterprise search requirements (query volume, latency tolerance, accuracy needs) to optimal model configurations and associated costs.

## Limitations

- Limited generalizability to other enterprise platforms beyond Zoominfo's ZI Sales product
- Reliance on extensive 3095-word system messages raises scalability and maintenance concerns
- Evaluation focuses on technical accuracy metrics rather than actual user experience or business outcomes

## Confidence

**High Confidence (4/5):** The core mechanism of using JSON as an intermediary format to eliminate syntax errors is well-supported by the empirical results (97% accuracy) and the logical explanation of how structured output prevents generation errors. The evaluation methodology using multiple similarity metrics is rigorous and appropriate.

**Medium Confidence (3/5):** The effectiveness of prompt engineering techniques (system messages, few-shot learning, chain-of-thought) is demonstrated but relies heavily on specific implementation details that aren't fully disclosed. The success with Claude 3.5 Sonnet may not translate directly to other LLM architectures or smaller models without careful tuning.

**Low Confidence (2/5):** The long-term scalability of the approach, particularly maintaining and updating the extensive system message as the search schema changes, is not addressed. The claim that natural language search significantly improves user experience over traditional interfaces lacks empirical validation beyond accuracy metrics.

## Next Checks

1. **Cross-domain evaluation:** Test the system on a different enterprise platform (e.g., a CRM or marketing automation tool) to assess generalizability of the approach and identify domain-specific challenges in natural language understanding.

2. **User experience validation:** Conduct A/B testing comparing task completion time and accuracy between users employing the natural language interface versus traditional advanced search, measuring actual business impact rather than just technical accuracy.

3. **Maintenance impact assessment:** Evaluate the effort required to update the system when the underlying search schema changes by introducing controlled modifications to the field definitions and measuring the accuracy degradation and prompt engineering effort needed for recovery.