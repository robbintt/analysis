---
ver: rpa2
title: Harmonic Reasoning in Large Language Models
arxiv_id: '2409.05521'
source_url: https://arxiv.org/abs/2409.05521
tags:
- tasks
- llms
- reasoning
- chords
- scales
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the reasoning capabilities of large language
  models (LLMs) in musical tasks, focusing on intervals, chords, and scales. Using
  GPT-3.5 and GPT-4o, the study systematically evaluates model performance across
  progressively complex configurations.
---

# Harmonic Reasoning in Large Language Models

## Quick Facts
- arXiv ID: 2409.05521
- Source URL: https://arxiv.org/abs/2409.05521
- Authors: Anna Kruspe
- Reference count: 2
- Primary result: LLMs perform well on basic interval identification but struggle with chords and scales, especially with inversions and enharmonic equivalents.

## Executive Summary
This paper investigates the reasoning capabilities of large language models (LLMs) in musical tasks, focusing on intervals, chords, and scales. Using GPT-3.5 and GPT-4o, the study systematically evaluates model performance across progressively complex configurations. Results show that while LLMs perform well on basic interval identification, accuracy drops significantly for chords and scales, especially when inversions and enharmonic equivalents are introduced. GPT-4o outperforms GPT-3.5, suggesting that larger models and richer training data improve performance, but reasoning remains limited. The findings highlight the distinction between pattern recognition and true understanding, indicating current LLMs rely more on memorization than logical reasoning. The authors provide a benchmark dataset for future research in musical reasoning.

## Method Summary
The study uses the music21 Python library to generate test questions for intervals, chords, and scales with various configurations (e.g., different directions, octave ranges, accidentals). These questions are evaluated using GPT-3.5 and GPT-4o through the OpenAI API, with three runs per experiment to account for randomness. Accuracy is calculated by comparing LLM outputs to ground truth answers. The benchmark dataset includes 500 interval questions and 108 chord and 156 scale test cases in original and varied forms.

## Key Results
- LLMs achieve high accuracy on basic interval identification but struggle with chords and scales.
- Accuracy decreases significantly when inversions and enharmonic equivalents are introduced.
- GPT-4o outperforms GPT-3.5 on simple tasks, but reasoning limitations persist across both models.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs rely more on pattern memorization than true logical reasoning when solving musical tasks.
- Mechanism: The model matches input configurations to training data patterns; when faced with novel configurations (e.g., inversions, enharmonic equivalents), performance degrades sharply because those exact patterns were rarely present in training.
- Core assumption: GPT-4o's higher accuracy on simple tasks reflects broader pattern coverage, not deeper reasoning.
- Evidence anchors:
  - [abstract]: "Results show that while LLMs perform well on basic interval identification, accuracy drops significantly for chords and scales, especially when inversions and enharmonic equivalents are introduced."
  - [section 4]: "This observation leads to a question: does the improvement signify better reasoning or merely a reflection of exposure to more data?"
- Break condition: When task complexity increases beyond common textbook patterns, accuracy collapses.

### Mechanism 2
- Claim: LLM performance is strongly influenced by input format and explicitness of prior information.
- Mechanism: Providing explicit task context (e.g., "what chord types are possible") improves accuracy because the model can constrain its search space, but it still struggles to integrate that context with novel problem structures.
- Core assumption: LLMs have limited short-term contextual integration; they "forget" provided types quickly.
- Evidence anchors:
  - [section 5]: "Interestingly, it was observed that the provided types were quickly 'forgotten' or disregarded by the model in subsequent tasks."
- Break condition: When task requires sustained integration of explicit context with novel structures.

### Mechanism 3
- Claim: Model size and training data breadth correlate with performance but do not guarantee reasoning ability.
- Mechanism: Larger models like GPT-4o outperform smaller ones on basic tasks because they have seen more training examples, but this does not translate to better performance on tasks requiring novel application of rules.
- Core assumption: Improvement from GPT-3.5 to GPT-4o reflects memorization of more patterns, not improved reasoning.
- Evidence anchors:
  - [section 4]: "The more state-of-the-art model GPT-4o displayed markedly better performance, reinforcing the notion that both model size and the extent of training data significantly affect outcomes."
- Break condition: When novel or rarely seen configurations are introduced.

## Foundational Learning

- Concept: Western music theory basics (intervals, chords, scales, inversions, enharmonic equivalents).
  - Why needed here: The experiments test recognition of these musical constructs; understanding their definitions and relationships is essential to interpret results.
  - Quick check question: What is the interval from C to G? What is a C major chord in first inversion?

- Concept: LLM prompting and evaluation methodology.
  - Why needed here: The study uses specific prompt formats and structured evaluation; knowing how to design and assess prompts is key to reproducing or extending the work.
  - Quick check question: How would you instruct an LLM to return chord names in a table format?

- Concept: Pattern recognition vs logical reasoning in AI.
  - Why needed here: The paper distinguishes between memorization of training data patterns and genuine reasoning; understanding this distinction is critical to interpreting results.
  - Quick check question: If an LLM correctly names a C major chord but fails on a C major chord with an enharmonic note swap, is that reasoning or pattern matching?

## Architecture Onboarding

- Component map: music21 library -> test case generation -> prompt construction -> OpenAI API -> result evaluation -> accuracy aggregation
- Critical path: Generate test cases → Format prompts → Run LLM queries → Compare outputs to ground truth → Aggregate accuracy metrics → Analyze configuration effects
- Design tradeoffs: Simple prompt format vs richer context; exhaustive configuration testing vs computational cost; automatic dataset generation vs manual curation
- Failure signatures: Sharp accuracy drops when introducing inversions or enharmonic equivalents; model "forgetting" explicitly provided context; inconsistent performance across runs
- First 3 experiments:
  1. Generate and test upward intervals within one octave using GPT-3.5.
  2. Generate and test chords in original form with explicit chord type hints using GPT-4o.
  3. Generate and test scales in random permutations without prior information using GPT-4o.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do LLMs improve their reasoning capabilities in musical tasks when trained on more diverse and extensive musical datasets?
- Basis in paper: [inferred] from the observation that GPT-4o outperforms GPT-3.5, suggesting that larger models and richer training data improve performance.
- Why unresolved: The paper does not explicitly state whether the improvement is due to better reasoning or merely exposure to more data.
- What evidence would resolve it: Experiments comparing LLMs trained on different datasets with controlled variables, measuring improvements in reasoning versus memorization.

### Open Question 2
- Question: Can the reasoning abilities of LLMs in musical tasks be enhanced through advanced prompting techniques such as Chain-of-Thought or In-Context Learning?
- Basis in paper: [explicit] from the suggestion that more sophisticated models demonstrate emerging reasoning capabilities, and that advanced prompting techniques could improve results.
- Why unresolved: The paper does not test these prompting techniques, leaving their potential impact on musical reasoning unexplored.
- What evidence would resolve it: Empirical studies applying these techniques to the same musical tasks and measuring the improvement in reasoning accuracy.

### Open Question 3
- Question: How do LLMs handle non-Western music structures, and what does this reveal about their reasoning capabilities across different musical systems?
- Basis in paper: [inferred] from the mention of exploring non-Western music as a potential area for future work.
- Why unresolved: The study focuses on Western music, and the reasoning capabilities of LLMs in other musical traditions remain untested.
- What evidence would resolve it: Comparative analysis of LLM performance on tasks involving both Western and non-Western music, assessing their ability to reason across different musical systems.

## Limitations

- Reliance on pattern matching inference rather than direct probing of internal mechanisms.
- Benchmark dataset configurations may not capture full breadth of musical complexity.
- Study focuses exclusively on Western music theory, excluding non-Western systems.

## Confidence

**High confidence**: GPT-3.5 and GPT-4o performance differences on basic interval tasks; accuracy degradation with inversions and enharmonic equivalents; availability of benchmark dataset.

**Medium confidence**: Interpretation that performance differences reflect pattern coverage rather than reasoning ability; conclusions about LLM reasoning limitations in music.

**Low confidence**: Generalization of findings to other musical domains; claims about specific mechanisms underlying "context forgetting."

## Next Checks

1. **Cross-cultural validation**: Test the same benchmark on non-Western musical scales and intervals to assess if performance patterns hold across different musical systems.

2. **Mechanism probing**: Use activation analysis or targeted prompts to determine whether accuracy drops stem from pattern recognition failure versus reasoning breakdown in specific configurations.

3. **Context retention experiment**: Design controlled experiments that explicitly test how long and under what conditions LLMs retain provided context information during multi-step musical reasoning tasks.