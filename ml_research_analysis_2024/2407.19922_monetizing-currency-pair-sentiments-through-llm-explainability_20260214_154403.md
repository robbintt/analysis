---
ver: rpa2
title: Monetizing Currency Pair Sentiments through LLM Explainability
arxiv_id: '2407.19922'
source_url: https://arxiv.org/abs/2407.19922
tags:
- sentiment
- llms
- sentiments
- lstm
- such
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study developed a novel LLM-based technique for post-hoc explainability
  of sentiment analysis (SA) models, identifying "k-sufficient" keyword sets that
  retain the original sentiment classification. Applied to financial currency-pair
  price prediction, the method enriches SA outputs with these keywords to improve
  predictive accuracy.
---

# Monetizing Currency Pair Sentiments through LLM Explainability

## Quick Facts
- **arXiv ID**: 2407.19922
- **Source URL**: https://arxiv.org/abs/2407.19922
- **Reference count**: 32
- **Primary result**: LLM-based explainability technique improves currency pair price prediction accuracy from 1.56% to 0.84% MAPE

## Executive Summary
This study introduces a novel approach to enhancing sentiment analysis through LLM-generated explanations for financial applications. The researchers developed a post-hoc explainability technique that identifies "k-sufficient" keyword sets capable of preserving original sentiment classifications. When applied to currency pair price prediction, the method demonstrates that incorporating sentiment information reduces MAPE from 1.56% to 1.08%, with further improvement to 0.84% when including LLM-derived keyword explanations. The GPT-4.0 model proved most effective at generating quality explanations. This work shows that LLM explainability serves dual purposes: improving interpretability while providing valuable input enrichment for machine learning models, with potential applications extending beyond financial markets.

## Method Summary
The researchers developed a k-sufficient keyword identification method using large language models (LLMs) to enhance sentiment analysis outputs. The approach involves three main phases: first, sentiment analysis models classify text into positive, negative, or neutral sentiments; second, LLMs generate explanations by identifying minimal keyword sets that preserve the original sentiment classification; third, these keyword-enriched sentiment features are incorporated into machine learning models for price prediction. The method employs a two-step filtering process where the LLM iteratively removes non-essential words while maintaining sentiment accuracy above a threshold. The technique was tested on four currency pairs (EUR/USD, GBP/USD, USD/JPY, AUD/USD) using news headlines as sentiment sources, with predictions evaluated using Mean Absolute Percentage Error (MAPE).

## Key Results
- Sentiment information alone improved price prediction MAPE from 1.56% to 1.08%
- Adding LLM-generated keyword explanations further reduced MAPE to 0.84%
- GPT-4.0 outperformed other models in explanation quality and utility
- The approach demonstrated consistent improvements across all four tested currency pairs

## Why This Works (Mechanism)
The mechanism leverages LLMs' ability to identify and extract the most sentiment-relevant information from text, creating more focused and actionable features for prediction models. By isolating "k-sufficient" keyword sets, the approach reduces noise while preserving predictive power, effectively performing feature selection at the semantic level. The LLM explanations serve as an attention mechanism, highlighting which words carry the most sentiment weight for downstream models. This enrichment process creates a feedback loop where sentiment analysis becomes both more interpretable and more accurate, as the explanations capture nuanced relationships between language and market movements that pure sentiment scores might miss.

## Foundational Learning

**Sentiment Analysis Fundamentals**: Understanding polarity classification and emotion detection in text - needed to grasp how market-moving information is extracted from news sources; quick check: verify basic SA accuracy on benchmark datasets.

**Large Language Model Explainability**: Knowledge of how LLMs can generate human-readable justifications for their outputs - essential for understanding the k-sufficient keyword extraction process; quick check: test LLM explanation quality on simple classification tasks.

**Financial Time Series Analysis**: Familiarity with price prediction metrics like MAPE and the relationship between sentiment and market movements - critical for evaluating the practical impact of sentiment enrichment; quick check: benchmark against technical indicator-based predictions.

**Natural Language Processing Pipelines**: Understanding text preprocessing, feature extraction, and model integration - necessary to follow how sentiment features are incorporated into prediction systems; quick check: validate sentiment accuracy on financial news corpora.

## Architecture Onboarding

**Component Map**: News Headlines -> Sentiment Analysis Model -> LLM Explanation Generator -> k-Sufficient Keyword Extractor -> Feature Enriched Dataset -> Price Prediction Model -> MAPE Evaluation

**Critical Path**: The sequence from sentiment classification through LLM explanation generation represents the core innovation, as this enriched feature set directly feeds into improved price predictions.

**Design Tradeoffs**: The approach trades computational overhead (LLM inference) for improved accuracy, with the benefit of enhanced interpretability. The k-sufficient threshold represents a balance between explanation conciseness and sentiment preservation.

**Failure Signatures**: Poor sentiment classification quality propagates through the pipeline, degrading explanations and predictions. Over-aggressive keyword filtering may lose critical sentiment information. LLM hallucinations or irrelevant explanations can introduce noise rather than signal.

**First Experiments**:
1. Test sentiment analysis accuracy on a held-out financial news dataset before proceeding to LLM integration
2. Validate LLM explanation quality by having humans verify sentiment preservation after keyword removal
3. Compare MAPE improvements across different k-threshold values to find optimal balance

## Open Questions the Paper Calls Out
None

## Limitations
- Experimental scope limited to four currency pairs from a single exchange rate API
- Six-month study period may not capture diverse market conditions or volatility regimes
- Potential data leakage issues between training and test sets regarding sentiment-price alignment
- Results may not generalize to other asset classes or longer time horizons

## Confidence

**High**: Core technical approach of using LLM-generated explanations to improve sentiment analysis outputs
**Medium**: Quantitative performance improvements (MAPE reduction from 1.56% to 0.84%) specific to chosen currency pairs and time period
**Low**: Claims about broader applicability beyond finance without validation in other domains

## Next Checks

1. Test the approach across diverse asset classes (commodities, equities, cryptocurrencies) and longer time horizons to assess temporal robustness
2. Implement cross-validation with temporal splits to ensure no look-ahead bias in sentiment-price alignment
3. Compare performance against established technical indicators and fundamental analysis methods in the same experimental framework to establish relative value