---
ver: rpa2
title: A Large Collection of Model-generated Contradictory Responses for Consistency-aware
  Dialogue Systems
arxiv_id: '2403.12500'
source_url: https://arxiv.org/abs/2403.12500
tags: []
core_contribution: This paper introduces the first large-scale dataset of model-generated
  contradictory responses, containing 10K contradictory and 17K noncontradictory responses
  from eight high-performance dialogue generation models. The dataset was constructed
  by collecting responses to follow-up questions from dialogue contexts and annotating
  them for consistency with preceding utterances.
---

# A Large Collection of Model-generated Contradictory Responses for Consistency-aware Dialogue Systems

## Quick Facts
- **arXiv ID:** 2403.12500
- **Source URL:** https://arxiv.org/abs/2403.12500
- **Reference count:** 29
- **Primary result:** Introduces first large-scale dataset of 10K contradictory and 17K noncontradictory model-generated responses for training dialogue consistency detectors

## Executive Summary
This paper presents the first large-scale dataset of model-generated contradictory responses for dialogue consistency evaluation, containing 10K contradictory and 17K noncontradictory responses from eight high-performance dialogue generation models. The dataset was constructed by collecting responses to follow-up questions from dialogue contexts and annotating them for consistency with preceding utterances. Analysis revealed that RGM contradictions often involve intra-utterance inconsistencies and ambiguous expressions, distinguishing them from human-written contradictions. The dataset demonstrates significant value for training consistency-aware dialogue systems.

## Method Summary
The dataset construction process involved collecting dialogue contexts from public sources, generating responses using eight different high-performance dialogue models, and annotating the responses for consistency with preceding utterances. The annotation process employed human annotators to identify contradictions between responses and their corresponding dialogue contexts. The resulting dataset contains 27K responses total, with 10K labeled as contradictory and 17K as noncontradictory. The models used include various state-of-the-art dialogue generation systems, with responses generated for follow-up questions to create realistic conversational scenarios.

## Key Results
- Contradiction detector trained on model-generated data achieved 0.842 accuracy on in-domain tests
- Same detector achieved 0.720-0.787 accuracy on out-of-domain tests
- Model-generated contradictions differ from human-written contradictions, with RGM contradictions showing more intra-utterance inconsistencies and ambiguous expressions

## Why This Works (Mechanism)
The effectiveness stems from leveraging high-performance dialogue models to generate realistic contradictory responses that capture patterns difficult to obtain from human-written data. By using multiple models with different architectures and training approaches, the dataset captures diverse contradiction patterns that reflect various failure modes in dialogue generation systems. The systematic annotation process ensures high-quality labels that enable robust training of contradiction detection models.

## Foundational Learning
- **Dialogue context modeling** - Understanding how previous utterances influence response generation; quick check: ability to identify relevant context information from dialogue history
- **Contradiction detection** - Recognizing logical inconsistencies between statements; quick check: can identify direct contradictions in text pairs
- **Response generation patterns** - Knowledge of how different models generate responses under various conditions; quick check: understanding model-specific generation behaviors
- **Annotation consistency** - Ensuring reliable human judgment in labeling contradictions; quick check: inter-annotator agreement metrics
- **Dataset construction methodology** - Principles for creating high-quality labeled datasets for NLP tasks; quick check: reproducibility of data collection process

## Architecture Onboarding

**Component Map:**
Data Collection -> Response Generation -> Human Annotation -> Dataset Creation -> Model Training -> Contradiction Detection

**Critical Path:**
Dialogue Context Collection → Multiple Model Response Generation → Consistency Annotation → Dataset Assembly → Contradiction Detector Training → Evaluation

**Design Tradeoffs:**
- Model diversity vs. annotation consistency: Using multiple models captures diverse contradictions but may introduce varying contradiction patterns that complicate annotation
- Scale vs. quality: Large-scale data collection enables robust training but requires careful quality control
- Synthetic vs. natural contradictions: Model-generated contradictions may not perfectly represent real-world scenarios but provide scalable training data

**Failure Signatures:**
- Overfitting to specific contradiction patterns from particular models
- Annotation inconsistencies affecting label quality
- Missing contradiction types not captured by the generation models used
- Generalization issues when applied to dialogue systems with different architectures

**First 3 Experiments:**
1. Train contradiction detector on human-written contradiction data only and compare performance against model-generated data
2. Evaluate detector performance across different contradiction severity levels to understand sensitivity
3. Test detector robustness by introducing controlled perturbations to both contradictory and non-contradictory responses

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Dataset construction relies on high-performance models, potentially missing contradictions from less capable systems
- Human annotation introduces possible subjectivity in consistency evaluation
- Evaluation focuses on binary detection without analyzing contradiction types or severity
- Out-of-domain performance (0.720-0.787) suggests potential overfitting to training data patterns

## Confidence
- **High confidence:** Dataset construction methodology and basic statistical analysis are well-documented and reproducible
- **Medium confidence:** Superiority of model-generated data over human-written data for training, as evaluation may not capture all real-world scenarios
- **Medium confidence:** Characterization of RGM contradictions as primarily intra-utterance inconsistencies, based on limited pattern analysis

## Next Checks
1. Evaluate the trained contradiction detector on real user dialogue logs from deployed systems to assess practical performance
2. Conduct ablation studies removing different contradiction types to understand impact on detector performance and generalization
3. Test detector's robustness against adversarial attacks using carefully crafted contradictory responses