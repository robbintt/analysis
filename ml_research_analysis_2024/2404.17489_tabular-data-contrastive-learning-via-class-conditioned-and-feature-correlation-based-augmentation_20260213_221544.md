---
ver: rpa2
title: Tabular Data Contrastive Learning via Class-Conditioned and Feature-Correlation
  Based Augmentation
arxiv_id: '2404.17489'
source_url: https://arxiv.org/abs/2404.17489
tags:
- data
- feature
- learning
- features
- tabular
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of effective data augmentation
  for contrastive learning in tabular data. The authors propose two improvements to
  the standard feature-value corruption technique: class-conditioned corruption, which
  samples replacement values from rows within the same class as the anchor, and correlation-based
  feature masking, which selects features to corrupt based on feature correlation
  structures.'
---

# Tabular Data Contrastive Learning via Class-Conditioned and Feature-Correlation Based Augmentation

## Quick Facts
- arXiv ID: 2404.17489
- Source URL: https://arxiv.org/abs/2404.17489
- Reference count: 21
- Key outcome: Class-conditioned corruption consistently improves accuracy over random corruption (83% of datasets)

## Executive Summary
This paper addresses the challenge of effective data augmentation for contrastive learning in tabular data. The authors propose two improvements to the standard feature-value corruption technique: class-conditioned corruption, which samples replacement values from rows within the same class as the anchor, and correlation-based feature masking, which selects features to corrupt based on feature correlation structures. Experiments on the OpenML-CC18 dataset demonstrate that class-conditioned corruption consistently improves classification accuracy over conventional random corruption, achieving better results on 83% of datasets. However, correlation-based feature masking did not show consistent improvements, likely due to the preprocessed nature of benchmark datasets with low feature correlation. The work highlights the importance of incorporating class information into tabular data augmentation for contrastive learning.

## Method Summary
The paper proposes two augmentation strategies for contrastive learning on tabular data in semi-supervised settings. First, class-conditioned corruption samples replacement values for corrupted features only from rows sharing the same class label as the anchor, preserving semantic similarity between views. Second, correlation-based feature masking selects which features to corrupt based on feature correlation structures, targeting less correlated features for corruption. For unlabeled data, pseudo-labeling is used to estimate class identities. The method employs a three-part neural network (encoder, pre-train head, classification head) trained in two stages: pre-training with contrastive loss using the augmentation strategies, followed by fine-tuning the classification head on labeled data.

## Key Results
- Class-conditioned corruption improves classification accuracy over random corruption on 83% of OpenML-CC18 datasets
- Correlation-based feature masking did not show consistent improvements, likely due to low feature correlation in benchmark datasets
- Class-conditioned corruption is particularly effective for datasets where random corruption can create physically impossible examples (e.g., Balance Scale dataset)
- Both methods outperform no pre-training baseline, with class-conditioned corruption showing the most consistent gains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Class-conditioned corruption improves contrastive learning by ensuring augmented views remain semantically similar to their anchors
- Mechanism: When corrupting a feature value, sampling replacement values only from rows with the same class label reduces semantic drift between anchor and view
- Core assumption: Features that determine class identity are more stable within-class than across-class
- Evidence anchors:
  - [abstract]: "corrupting tabular data conditioned on class identity" and "corrupting a specific tabular entry from an anchor row, instead of randomly sampling a value in the same feature column from the entire table uniformly, we only sample from rows that are identified to be within the same class as the anchor row"
  - [section 2.3]: "The rationale behind this strategy follows that with each feature being corrupted, there exists correlated features left intact"
  - [corpus]: Weak - no direct evidence found in corpus papers
- Break condition: When feature values that determine class identity are not stable within-class (e.g., tabular data where same-class examples have vastly different feature values)

### Mechanism 2
- Claim: Pseudo-labeling enables class-conditioned corruption in semi-supervised settings by providing class estimates for unlabeled data
- Mechanism: Train classifier on labeled data, use it to predict pseudo-labels for unlabeled data, then use these pseudo-labels for class-conditioned sampling during corruption
- Core assumption: Pseudo-labels provide sufficiently accurate class estimates for effective sampling
- Evidence anchors:
  - [abstract]: "We assume the semi-supervised learning setting, and adopt the pseudo labeling technique for obtaining class identities over all table rows"
  - [section 3.1]: "The main challenge within the class-conditioned corruption process is to obtain class labels over the entire table" and "we adapt the popular pseudo labeling approach"
  - [section 2.1]: "we adopt the pseudo labeling technique to obtain estimations of targets"
- Break condition: When pseudo-label accuracy is too low to provide meaningful class separation for sampling

### Mechanism 3
- Claim: Random corruption-based augmentation has inherent limitations for certain tabular datasets
- Mechanism: Some tabular datasets contain features where random corruption creates physically impossible or contradictory examples
- Core assumption: Some tabular features have strong logical dependencies that random corruption violates
- Evidence anchors:
  - [section 4.4]: "One comprehensible example for our argument is the Balance Scale table in the OpenML-CC18 datasets. In the Balance Scale table, each row consists of weights and distances to a pivot in a two-ended scale. Naturally, when we corrupt by swapping weights or distances, the scale balance can change abruptly, leading to a generated row that contradicts the laws of physics"
  - [section 4.4]: "we do however emphasize that such cases are likely rare in more complex and realistic datasets"
- Break condition: When logical dependencies between features are weak or non-existent

## Foundational Learning

- Concept: Contrastive learning and augmentation
  - Why needed here: The entire paper builds on understanding how contrastive learning works and why augmentation matters for it
  - Quick check question: What is the goal of contrastive learning and how do augmentation techniques help achieve it?

- Concept: Semi-supervised learning and pseudo-labeling
  - Why needed here: The class-conditioned corruption method requires understanding how to handle unlabeled data in semi-supervised settings
  - Quick check question: How does pseudo-labeling work and what are its key assumptions and limitations?

- Concept: Feature correlation and feature importance
  - Why needed here: The correlation-based feature masking approach relies on understanding how to measure and use feature relationships
  - Quick check question: What are different ways to measure feature correlation and what are the tradeoffs between them?

## Architecture Onboarding

- Component map:
  - Encoder network (θe) -> Pre-train head (θp) -> Contrastive loss
  - Encoder network (θe) -> Classification head (θc) -> Classification loss
  - Augmentation module -> Applies class-conditioned corruption and/or correlation-based masking
  - Pseudo-labeling module -> Generates class estimates for unlabeled data

- Critical path:
  1. Initialize encoder, pre-train head, classification head
  2. Iteratively: generate pseudo-labels → create augmented views with class-conditioned corruption → optimize contrastive loss → update classifier on labeled data
  3. After pre-training: freeze encoder, train classification head on labeled data

- Design tradeoffs:
  - Class-conditioned vs random corruption: semantic preservation vs computational complexity
  - Correlation-based vs random feature selection: potential for better views vs dependency on feature correlation structure
  - Pseudo-label frequency: accuracy vs computational cost

- Failure signatures:
  - Class-conditioned corruption degrades performance: pseudo-labels are inaccurate or class-conditioned sampling creates too much bias
  - Correlation-based masking degrades performance: features are not meaningfully correlated or correlation measure is inappropriate
  - No pre-training outperforms pre-training: corruption-based augmentation fundamentally incompatible with dataset structure

- First 3 experiments:
  1. Implement baseline with random corruption only, verify it matches literature performance
  2. Add class-conditioned corruption with ground-truth labels (oracle), verify improvement
  3. Add pseudo-labeling module, verify class-conditioned corruption with pseudo-labels matches oracle performance

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the text provided.

## Limitations
- Evaluation restricted to preprocessed OpenML-CC18 datasets that may not reflect real-world scenarios with higher feature correlation
- Correlation-based feature masking showed no consistent improvement, suggesting potential issues with either the feature correlation measure or the preprocessing pipeline
- Computational overhead of class-conditioned sampling not addressed, which requires maintaining class-specific value pools and may become expensive for large datasets

## Confidence

- **High confidence**: Class-conditioned corruption consistently improves accuracy over random corruption (83% of datasets show improvement)
- **Medium confidence**: The failure of correlation-based masking is attributed to low feature correlation in benchmark datasets, but alternative explanations (inappropriate correlation measure, implementation details) are not ruled out
- **Medium confidence**: The mechanism explaining why random corruption can create physically impossible examples is demonstrated on a single dataset (Balance Scale) and may not generalize

## Next Checks

1. Test class-conditioned corruption on raw, un-preprocessed tabular datasets with known feature correlations to verify if the method performs better when feature dependencies are preserved
2. Experiment with alternative feature correlation measures (e.g., mutual information, partial correlation) to determine if the choice of correlation metric affects the performance of feature masking
3. Implement a controlled experiment varying the proportion of features corrupted to identify optimal corruption rates for different dataset characteristics