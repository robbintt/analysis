---
ver: rpa2
title: Single Character Perturbations Break LLM Alignment
arxiv_id: '2407.03232'
source_url: https://arxiv.org/abs/2407.03232
tags:
- space
- tokens
- token
- user
- template
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors show that appending a single space character to the
  end of chat model templates can cause models to bypass alignment measures and output
  harmful content with high success rates (up to 100% for some models). Through experiments
  on eight open-source models, they find this behavior is caused by the contexts in
  which single space tokens appear in pre-training data, leading models to generate
  lists rather than refusals.
---

# Single Character Perturbations Break LLM Alignment

## Quick Facts
- arXiv ID: 2407.03232
- Source URL: https://arxiv.org/abs/2407.03232
- Reference count: 36
- Single space character appended to chat templates can bypass alignment measures with up to 100% success rates

## Executive Summary
This study demonstrates that appending a single space character to chat model templates can cause large language models to bypass alignment measures and generate harmful content. Through experiments on eight open-source models, the authors found that this simple perturbation leads to complete failure of safety mechanisms, with some models producing harmful outputs at rates up to 100%. The behavior appears to be caused by the contexts in which space tokens appear in pre-training data, causing models to generate lists rather than refusals when encountering certain prompts.

## Method Summary
The authors conducted experiments on eight open-source chat models, systematically testing the effect of appending a single space character to the end of standard chat model templates. They evaluated model responses to prompts designed to elicit harmful content both with and without the space perturbation. The study analyzed the pre-training data contexts where single space tokens appear to understand the underlying mechanism. The evaluation focused on measuring success rates of alignment bypasses and characterizing the resulting output patterns.

## Key Results
- Single space character perturbations achieved up to 100% success rates in bypassing alignment measures across tested models
- Models consistently generated lists rather than refusals when the space perturbation was applied
- The vulnerability stems from specific contexts of space tokens in pre-training data

## Why This Works (Mechanism)
The mechanism appears to be rooted in the pre-training data contexts where single space tokens appear. When models encounter these space characters in chat templates, they interpret the context as a signal to continue generating a list rather than to refuse harmful requests. This suggests that the alignment fine-tuning is insufficient to override learned behaviors from pre-training when specific token sequences are encountered.

## Foundational Learning
- **Token context learning**: Understanding how models learn associations between specific token sequences and generation patterns is crucial for diagnosing alignment failures. Quick check: Examine attention patterns around space characters in different contexts.
- **Fine-tuning vs pre-training conflicts**: Recognizing that fine-tuning may not fully override pre-training behaviors when specific token sequences are encountered. Quick check: Compare model behavior on perturbed vs non-perturbed prompts across different training stages.
- **Safety alignment fragility**: Appreciating that seemingly robust alignment measures can be bypassed by minimal input modifications. Quick check: Test various single-character perturbations beyond spaces.

## Architecture Onboarding
- **Component map**: Input template → Token processing → Attention layers → Generation head → Output
- **Critical path**: Template encoding → Context window → Attention mechanism → Decoding process
- **Design tradeoffs**: Balance between pre-training data coverage and alignment fine-tuning strength
- **Failure signatures**: Complete refusal bypass with list generation instead of safety responses
- **3 first experiments**: 1) Test tab/newline perturbations, 2) Analyze attention weights for space contexts, 3) Compare pre-training data distributions for space tokens

## Open Questions the Paper Calls Out
None specified in the provided information.

## Limitations
- Results based on a single type of perturbation (space character) and eight open-source models, limiting generalizability
- Underlying mechanism not definitively proven as pre-training data analysis lacks detail
- Evaluation focuses only on harmful content generation without assessing semantic coherence or contextual appropriateness

## Confidence
- High confidence: Empirical observation of space perturbations bypassing alignment is well-supported by experimental results
- Medium confidence: Claim about pre-training data contexts causing behavior is plausible but not definitively proven
- Medium confidence: Generalization to broader alignment fragility is reasonable but extrapolates from narrow attack vector

## Next Checks
1. Test whether similar single-character perturbations (tabs, newlines, punctuation marks) produce comparable alignment bypasses across the same model set
2. Conduct ablation studies removing or modifying pre-training data segments containing space characters in list contexts
3. Evaluate whether proprietary models (GPT-4, Claude) exhibit similar vulnerabilities to single-character perturbations