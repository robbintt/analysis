---
ver: rpa2
title: Counterfactual Metarules for Local and Global Recourse
arxiv_id: '2405.18875'
source_url: https://arxiv.org/abs/2405.18875
tags:
- rules
- which
- counterfactual
- rule
- metarules
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: T-CREx is a novel model-agnostic method for generating counterfactual
  explanations (CEs) as human-readable rules. It uses tree-based surrogate models
  to learn counterfactual rules alongside "metarules" denoting their regions of optimality,
  enabling both local (individual) and global (group-level) CEs.
---

# Counterfactual Metarules for Local and Global Recourse

## Quick Facts
- **arXiv ID**: 2405.18875
- **Source URL**: https://arxiv.org/abs/2405.18875
- **Reference count**: 25
- **Primary result**: T-CREx achieves superior aggregate performance on CE desiderata while being orders of magnitude faster than baselines.

## Executive Summary
T-CREx is a novel model-agnostic method for generating counterfactual explanations as human-readable rules. It leverages tree-based surrogate models to learn counterfactual rules alongside "metarules" denoting their regions of optimality, enabling both local and global CEs. Experiments on nine datasets show T-CREx outperforms rule-based baselines on CE desiderata (accuracy, feasibility, sparsity, complexity, consistency) while running significantly faster.

## Method Summary
T-CREx uses tree-based surrogate models to approximate black box model behavior and extract interpretable counterfactual rules. The method grows surrogate trees from training data, extracts maximal-valid rules from tree nodes, partitions the input space into cells based on rule boundaries, and uses a secondary tree to classify cells by their optimal counterfactual rule. Metarules aggregate regions where the same rule is optimal, providing both local explanations for individuals and global summaries of recourse options.

## Key Results
- T-CREx achieves superior aggregate performance over rule-based baselines on all CE desiderata
- Runtime is 4.16-4.52 seconds versus 13-1290 seconds for baselines (orders of magnitude faster)
- The method handles both classification and regression, numerical and categorical features
- Qualitative analysis shows rules and metarules provide interpretable global summaries and local CEs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: T-CREx leverages surrogate tree models to create interpretable counterfactual rules with high feasibility and accuracy.
- **Mechanism**: By growing tree-based surrogate models and extracting hyperrectangular rules from their nodes, T-CREx ensures rules are both interpretable and aligned with the model's decision boundaries. The tree structure allows for efficient partitioning of the input space, while the surrogate model's purity optimization aligns with accuracy goals.
- **Core assumption**: Tree-based surrogate models can accurately approximate the behavior of black box models while maintaining interpretability through axis-aligned splits.
- **Evidence anchors**:
  - [abstract]: "It leverages tree-based surrogate models to learn the counterfactual rules, alongside 'metarules' denoting their regions of optimality..."
  - [section]: "Given a dataset of realistically-distributed inputs and associated model outputs, D = {(x ∼ PX , y = f (x))}N n=1, we first grow a tree-based surrogate model..."
- **Break condition**: If the surrogate model fails to capture the complexity of the black box model, or if the tree growth produces overly specific rules that lack generalizability.

### Mechanism 2
- **Claim**: T-CREx uses metarules to provide both local and global counterfactual explanations efficiently.
- **Mechanism**: Metarules aggregate regions of the input space where the same counterfactual rule is optimal, enabling rapid lookup for individual instances while also providing a global summary of recourse options. This dual use reduces computational overhead by front-loading the most expensive steps.
- **Core assumption**: The optimal counterfactual rule for a region of the input space is constant, allowing aggregation into metarules without loss of accuracy.
- **Evidence anchors**:
  - [abstract]: "...alongside metarules denoting their regions of optimality, providing both a global analysis of model behaviour and diverse recourse options for users."
  - [section]: "We propose to describe this group of commonly-explained inputs using metarules, drawn from the same class of interpretable rules R."
- **Break condition**: If the input space is highly fragmented with many local optima, metarules may become too numerous or lose their interpretability.

### Mechanism 3
- **Claim**: T-CREx's cost function balances sparsity and feasibility, leading to practical and interpretable counterfactual rules.
- **Mechanism**: The cost function prioritizes rules requiring minimal feature changes (sparsity) while also favoring rules with high feasibility under the data distribution. This dual focus ensures rules are both simple to describe and actionable in practice.
- **Core assumption**: Users prefer counterfactual rules that require changing fewer features and are more likely to occur in realistic data distributions.
- **Evidence anchors**:
  - [abstract]: "...rules with higher feasibility under PX , which also follows prior work in hypothesising that counterfactuals in highly-populated regions can be more realistically used for recourse..."
  - [section]: "cost(x0, Ri | PX ) = changes(x0, Ri) − feasibility(Ri), where changes(x0, Ri) =PD d=1 1 [(x0 d ≤ li d)∨(ui d < x 0 d)]."
- **Break condition**: If the data distribution is highly skewed or contains many outliers, the feasibility term may dominate and produce rules that are less sparse than desired.

## Foundational Learning

- **Concept**: Tree-based surrogate models
  - Why needed here: Surrogate models approximate the black box model's behavior while maintaining interpretability through axis-aligned splits, enabling the extraction of counterfactual rules.
  - Quick check question: What is the key advantage of using tree-based surrogate models over other types of surrogate models for counterfactual explanation?

- **Concept**: Hyperrectangular rules and metarules
  - Why needed here: Hyperrectangular rules provide a natural way to express counterfactual explanations as conjunctions of feature constraints, while metarules aggregate regions where the same rule is optimal.
  - Quick check question: How do hyperrectangular rules differ from other types of rule representations in terms of interpretability and computational efficiency?

- **Concept**: Counterfactual explanation desiderata (accuracy, feasibility, sparsity, complexity, consistency)
  - Why needed here: These metrics provide a framework for evaluating the quality of counterfactual explanations, guiding the design of the T-CREx algorithm and enabling comparison with baseline methods.
  - Quick check question: Why is it important to consider both accuracy and feasibility when evaluating counterfactual explanations?

## Architecture Onboarding

- **Component map**: Surrogate tree model -> Rule extraction -> Grid partitioning -> Prototype classification -> Metarule aggregation -> Local explanation lookup
- **Critical path**: Surrogate tree growth → Rule extraction → Grid partitioning → Prototype classification → Metarule aggregation → Local explanation lookup
- **Design tradeoffs**:
  - Single vs. multiple surrogate trees: Single trees use entire dataset, potentially yielding better rules but less diversity
  - Accuracy threshold (τ): Higher τ yields more accurate rules but sacrifices feasibility, sparsity, and complexity
  - Feasibility threshold (ρ): Higher ρ yields larger, more feasible rules but may miss important local optima
- **Failure signatures**:
  - No valid rules found: Increase number of surrogate trees or decrease τ
  - Cell limit reached: Decrease number of surrogate trees or increase ρ
  - Poor accuracy: Decrease τ or use multiple surrogate trees
  - Poor feasibility: Increase ρ or use a single surrogate tree
- **First 3 experiments**:
  1. Run T-CREx with a single surrogate tree and default hyperparameters on a small dataset to verify basic functionality
  2. Vary the accuracy threshold (τ) to observe the trade-off between accuracy and other desiderata
  3. Compare runtime and rule quality with different numbers of surrogate trees to find the optimal balance

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the performance of T-CREx vary with different surrogate model types (e.g., decision trees vs. random forests vs. gradient boosted trees)?
- **Basis in paper**: [explicit] The paper mentions that T-CREx uses tree-based surrogate models but does not explore the impact of different tree-based models.
- **Why unresolved**: The paper only uses a single tree-based surrogate model (XGBoost) in its experiments.
- **What evidence would resolve it**: Experiments comparing T-CREx's performance using different types of tree-based surrogate models on the same datasets.

### Open Question 2
- **Question**: How does the inclusion of actionability constraints impact the quality of counterfactual explanations generated by T-CREx?
- **Basis in paper**: [inferred] The paper mentions that a limitation of the current implementation is the lack of actionability constraints, which could lead to non-actionable counterfactuals.
- **Why unresolved**: The paper does not explore the impact of adding actionability constraints to the method.
- **What evidence would resolve it**: Experiments comparing T-CREx's performance with and without actionability constraints on datasets where such constraints are relevant.

### Open Question 3
- **Question**: How does the choice of the feasibility threshold (ρ) impact the trade-off between the accuracy, feasibility, sparsity, and complexity of the generated counterfactual rules?
- **Basis in paper**: [explicit] The paper briefly mentions the feasibility threshold (ρ) and its impact on the algorithm's performance, but does not provide a comprehensive analysis.
- **Why unresolved**: The paper only explores a limited range of ρ values in its experiments.
- **What evidence would resolve it**: A more extensive analysis of T-CREx's performance across a wider range of ρ values, exploring the impact on the various desiderata.

## Limitations

- Computational efficiency gains are demonstrated but scalability to very high-dimensional datasets (>100 features) remains unverified
- Performance on highly imbalanced datasets or those with complex feature interactions is not explicitly tested
- Quality of metarules as global summaries depends on homogeneity of data distribution, which may not hold for all real-world datasets

## Confidence

- **High confidence**: T-CREx's ability to generate counterfactual rules with superior aggregate performance on CE desiderata compared to rule-based baselines
- **Medium confidence**: The computational efficiency claims, as they are based on runtime comparisons with specific baseline implementations
- **Low confidence**: The generalizability of T-CREx to highly complex models or datasets with severe class imbalance, as these scenarios are not explicitly tested

## Next Checks

1. Test T-CREx on a high-dimensional dataset (>100 features) to assess scalability and identify potential bottlenecks
2. Evaluate T-CREx's performance on a highly imbalanced dataset to understand its robustness to class imbalance
3. Compare the quality of metarules as global summaries against other global explanation methods on datasets with heterogeneous data distributions