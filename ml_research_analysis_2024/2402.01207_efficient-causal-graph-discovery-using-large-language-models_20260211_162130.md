---
ver: rpa2
title: Efficient Causal Graph Discovery Using Large Language Models
arxiv_id: '2402.01207'
source_url: https://arxiv.org/abs/2402.01207
tags:
- causal
- graph
- proposed
- variables
- discovery
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a more efficient LLM-based approach for causal
  graph discovery that avoids the quadratic query complexity of pairwise methods by
  using breadth-first search (BFS) to traverse the graph. The method queries the LLM
  to identify all children of each node during BFS traversal, requiring only linear
  queries.
---

# Efficient Causal Graph Discovery Using Large Language Models

## Quick Facts
- arXiv ID: 2402.01207
- Source URL: https://arxiv.org/abs/2402.01207
- Reference count: 17
- Key outcome: LLM-based BFS approach achieves state-of-the-art performance on causal graph discovery with linear query complexity

## Executive Summary
This paper introduces a more efficient approach for causal graph discovery using large language models (LLMs) that avoids the quadratic query complexity of pairwise methods. The method uses breadth-first search (BFS) to traverse the causal graph, querying the LLM to identify all children of each node in a single prompt. This achieves O(n) query complexity compared to O(n²) for pairwise approaches. The method also incorporates observational statistics when available to improve performance. Experiments on three causal graphs (Asia with 8 nodes, Child with 20 nodes, and Neuropathic Pain with 221 nodes) demonstrate state-of-the-art results, with the proposed method being the only one achieving reasonable performance on the large Neuropathic Pain graph.

## Method Summary
The proposed method uses BFS traversal to discover causal graphs by querying an LLM to identify all children of each node in a single prompt. The algorithm starts with a root node and expands each node's children using LLM queries, maintaining DAG structure through cycle checking. When observational statistics are available, Pearson correlation coefficients are added to the prompts to provide statistical grounding for the LLM's causal reasoning. The method consists of three stages: initialization (setting up root nodes), expansion (querying LLM for children of each node), and insertion (adding edges while maintaining DAG constraints). This approach achieves linear query complexity compared to quadratic complexity of pairwise methods.

## Key Results
- Achieves O(n) query complexity versus O(n²) for pairwise LLM methods
- Outperforms traditional statistical methods (GES, PC) and pairwise LLM approaches on three benchmark graphs
- Only method achieving reasonable performance on large Neuropathic Pain graph with 221 nodes
- Incorporates observational statistics to improve performance when available

## Why This Works (Mechanism)

### Mechanism 1
- Claim: BFS traversal with LLM queries achieves O(n) query complexity instead of O(n²)
- Mechanism: By expanding each node once and asking the LLM to return all its children, the algorithm avoids redundant pairwise queries. The BFS order ensures each node is visited exactly once, and the cycle check maintains DAG property.
- Core assumption: LLM can reliably identify all children of a node given its description and current graph context.
- Evidence anchors:
  - [abstract] "the proposed framework uses a breadth-first search (BFS) approach which allows it to use only a linear number of queries"
  - [section] "Instead of querying the LLM for each pair of nodes, we instruct the LLM to identify all potential effects of a single variable in one completion"
- Break condition: If LLM fails to return all children or returns cyclic edges frequently, the O(n) complexity benefit disappears and DAG constraint violations increase.

### Mechanism 2
- Claim: Incorporating observational statistics into LLM prompts improves causal discovery performance
- Mechanism: Adding Pearson correlation coefficients provides statistical grounding that complements LLM's internal knowledge, helping it distinguish between correlated and causally related variables.
- Core assumption: Correlation information is accessible to the LLM and can be integrated into its causal reasoning.
- Evidence anchors:
  - [section] "we also show that the proposed method can easily incorporate observational data when available, to improve performance"
  - [section] "we hypothesize that adding such statistics to the prompt helps the LLM by giving it statistical relationships"
- Break condition: If correlations are noisy or irrelevant to the specific domain, they may introduce confusion rather than improve performance.

### Mechanism 3
- Claim: LLM-based methods can achieve state-of-the-art results on large causal graphs where traditional methods fail
- Mechanism: LLM's knowledge of variable relationships allows it to bypass data-intensive statistical methods, making it scalable to graphs where pairwise methods become intractable (O(n²) queries).
- Core assumption: LLM has sufficient knowledge about the specific domain variables to make accurate causal inferences.
- Evidence anchors:
  - [abstract] "On the large Neuropathic Pain graph, the proposed method is the only one achieving reasonable performance"
  - [section] "the proposed method achieves state-of-the-art or competitive performance on three graphs of varying sizes"
- Break condition: If LLM lacks domain knowledge or the domain is too specialized, performance degrades significantly.

## Foundational Learning

- Concept: Directed Acyclic Graph (DAG) properties
  - Why needed here: The entire algorithm relies on maintaining DAG structure through cycle checking and BFS traversal order
  - Quick check question: Why can't we simply add any edge suggested by the LLM without checking for cycles?

- Concept: Breadth-First Search (BFS) algorithm
  - Why needed here: BFS provides the linear query complexity by visiting each node exactly once in topological order
  - Quick check question: How does BFS order relate to topological sorting in DAGs?

- Concept: Correlation vs causation
  - Why needed here: The method incorporates correlation statistics to improve performance, requiring understanding of their relationship to causation
  - Quick check question: Why might adding correlation information help an LLM distinguish causal from non-causal relationships?

## Architecture Onboarding

- Component map: LLM prompt generator -> BFS queue manager -> cycle checker -> graph builder
- Critical path: Prompt generation -> LLM query -> Response parsing -> Cycle check -> Graph update -> Queue update
- Design tradeoffs: LLM knowledge vs observational data (pure LLM vs hybrid approach), query efficiency vs accuracy (BFS vs pairwise), graph complexity vs LLM prompt size
- Failure signatures: Excessive cycle violations, poor F-score/NHD ratio, LLM timeouts or errors, memory issues with large graphs
- First 3 experiments:
  1. Run BFS on Asia graph with no observational statistics to verify O(n) query count and baseline performance
  2. Add correlation statistics to Asia graph and measure performance change
  3. Run BFS on Child graph with 1000 samples statistics to verify scalability and performance improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the LLM-based causal graph discovery method scale with increasing graph size beyond 221 nodes?
- Basis in paper: [inferred] The paper only tests the method on graphs up to 221 nodes and shows it is the only method achieving reasonable performance on the large Neuropathic Pain graph with 221 nodes.
- Why unresolved: The paper does not explore graph sizes larger than 221 nodes to determine the scalability limits of the proposed method.
- What evidence would resolve it: Experiments applying the method to graphs with 500+ nodes and comparing its performance and query efficiency against other methods would provide insights into its scalability.

### Open Question 2
- Question: How does the proposed method's performance compare to traditional statistical methods when both are given access to the same observational data?
- Basis in paper: [explicit] The paper shows the proposed method outperforms traditional methods without observational data, but does not compare their performance when both have access to observational data.
- Why unresolved: The paper only shows the proposed method's performance with and without observational data, not how it compares to traditional methods given the same data.
- What evidence would resolve it: Experiments comparing the proposed method and traditional statistical methods (like GES and PC) when both are given access to the same observational data would clarify their relative performance.

### Open Question 3
- Question: How does the proposed method's performance change with different LLM architectures and sizes?
- Basis in paper: [inferred] The paper uses GPT-4 but does not explore how different LLM architectures or sizes impact the method's performance.
- Why unresolved: The paper only tests the method with one specific LLM (GPT-4) and does not investigate the impact of using different LLMs.
- What evidence would resolve it: Experiments applying the method with various LLM architectures and sizes (e.g., different GPT versions, Claude, LLaMA) and comparing their performance would reveal how the LLM choice affects the method.

## Limitations
- Method performance depends heavily on LLM's domain knowledge and prompt quality
- Integration of observational statistics lacks detailed evaluation of different statistical measures
- BFS approach may be inefficient for graphs with many nodes having no causal relationships
- Sensitivity to prompt engineering choices and temperature settings not thoroughly explored

## Confidence

**High Confidence:** The O(n) query complexity improvement over pairwise methods is well-established through the BFS traversal mechanism. The basic claim that incorporating observational statistics can improve performance is supported by the theoretical justification and experimental results.

**Medium Confidence:** The state-of-the-art performance claims on the Neuropathic Pain graph are compelling but based on a single large-scale experiment. The generalizability to other complex domains remains to be fully established.

**Low Confidence:** The robustness of the method across different LLM models and prompt formulations is unclear. The sensitivity to prompt engineering choices and temperature settings is not thoroughly explored.

## Next Checks

1. **Cross-Model Validation:** Test the BFS approach with multiple LLM models (GPT-4, Claude, LLaMA) on the Asia and Child graphs to assess model dependency and prompt robustness.

2. **Prompt Sensitivity Analysis:** Systematically vary prompt formulations, temperature settings, and observation statistics inclusion to quantify performance sensitivity and identify optimal configurations.

3. **Edge Case Evaluation:** Create synthetic graphs with varying densities of causal relationships (from sparse to dense) to test the method's performance across different graph topologies and identify failure modes.