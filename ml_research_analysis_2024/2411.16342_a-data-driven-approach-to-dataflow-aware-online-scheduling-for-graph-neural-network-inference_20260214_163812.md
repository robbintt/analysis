---
ver: rpa2
title: A Data-Driven Approach to Dataflow-Aware Online Scheduling for Graph Neural
  Network Inference
arxiv_id: '2411.16342'
source_url: https://arxiv.org/abs/2411.16342
tags:
- graph
- time
- scheduling
- graphs
- dataflow
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a data-driven framework for predicting the
  latency of GNN inference across different accelerator dataflows. The method uses
  regression models trained on simulated synthetic graphs to estimate execution time
  for various dataflow configurations.
---

# A Data-Driven Approach to Dataflow-Aware Online Scheduling for Graph Neural Network Inference

## Quick Facts
- arXiv ID: 2411.16342
- Source URL: https://arxiv.org/abs/2411.16342
- Reference count: 29
- Primary result: Dataflow-aware online scheduling for GNN inference using regression models trained on synthetic graphs, achieving up to 91.28% accuracy in dataflow selection and 3.17× speedup in mean completion time.

## Executive Summary
This work presents a data-driven framework for optimizing GNN inference on heterogeneous multi-accelerator systems. The approach uses regression models trained on simulated synthetic graphs to predict latency for different dataflow configurations. These predictions are then integrated into an online scheduling algorithm that selects the optimal dataflow and accelerator for each incoming GNN inference job. The framework aims to maximize system throughput while minimizing job completion times in dynamic environments.

## Method Summary
The proposed method involves training regression models on simulated synthetic graphs to estimate GNN inference latency across various accelerator dataflows. These models capture the relationship between graph characteristics, dataflow configurations, and execution times. The trained models are then used in an online scheduling algorithm that, upon receiving a new GNN inference job, predicts latency for each possible dataflow-accelerator combination and selects the one expected to yield the lowest completion time. This approach enables data-aware scheduling decisions without the need for actual execution of all possible configurations.

## Key Results
- 91.28% accuracy in selecting the optimal dataflow configuration
- 3.78% mean absolute percentage error (MAPE) in latency prediction
- 3.17× speedup in mean completion time and 6.26× speedup in mean execution time compared to best feasible baseline
- Performance matching the shortest job first heuristic

## Why This Works (Mechanism)
The framework leverages the correlation between graph properties, dataflow configurations, and execution characteristics to make accurate predictions. By training on a diverse set of synthetic graphs, the regression models capture the underlying patterns that govern GNN inference performance across different accelerators and dataflows. This data-driven approach allows for rapid, online decision-making without the computational overhead of exhaustive profiling or simulation.

## Foundational Learning
1. Graph Neural Networks (GNNs)
   - Why needed: Understanding the target workload for optimization
   - Quick check: Familiarize with GNN architectures and their computational patterns

2. Dataflow optimization in ML accelerators
   - Why needed: Key to improving GNN inference performance
   - Quick check: Study different dataflow patterns and their impact on ML workloads

3. Online scheduling algorithms
   - Why needed: Framework relies on real-time decision making
   - Quick check: Review online scheduling heuristics and their performance metrics

4. Regression modeling for performance prediction
   - Why needed: Core technique for estimating latency without actual execution
   - Quick check: Understand regression model selection and training for performance prediction

## Architecture Onboarding
- Component map: Synthetic Graph Generator -> Regression Model Trainer -> Online Scheduler -> Accelerator
- Critical path: Job arrival -> Feature extraction -> Latency prediction -> Dataflow selection -> Job execution
- Design tradeoffs: Accuracy vs. prediction speed, model complexity vs. generalization
- Failure signatures: Inaccurate predictions leading to suboptimal scheduling decisions, model overfitting to synthetic graphs
- First experiments: 1) Validate regression model accuracy on held-out synthetic graphs, 2) Compare predicted vs. actual latency on real GNN models, 3) Benchmark scheduling performance against traditional heuristics

## Open Questions the Paper Calls Out
None specified in the provided information.

## Limitations
- Reliance on synthetic graph simulations may not fully capture real-world GNN inference workloads
- Performance in highly dynamic environments with rapidly changing job arrivals and varying GNN model complexities is not addressed
- Computational overhead of prediction models and its impact on overall system performance, especially in latency-sensitive applications, is not discussed

## Confidence
- Dataflow selection accuracy: High
- Latency prediction accuracy: Medium
- Speedup claims: Low
- Generalization to real-world workloads: Low

## Next Checks
1. Evaluate the framework on real-world GNN inference workloads and compare performance with the synthetic graph simulations.
2. Conduct experiments in highly dynamic environments with varying job arrival rates and GNN model complexities to assess the online scheduling algorithm's robustness.
3. Measure the computational overhead of the prediction models and analyze its impact on overall system performance in latency-sensitive applications.