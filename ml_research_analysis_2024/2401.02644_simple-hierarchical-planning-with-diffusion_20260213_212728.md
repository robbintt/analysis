---
ver: rpa2
title: Simple Hierarchical Planning with Diffusion
arxiv_id: '2401.02644'
source_url: https://arxiv.org/abs/2401.02644
tags:
- diffuser
- planning
- learning
- hierarchical
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a hierarchical diffusion-based planning framework
  for decision-making problems, addressing the computational challenges and generalization
  issues faced by existing diffusion-based methods. The key idea is to adopt a "jumpy"
  planning strategy at the higher level, allowing for a larger receptive field at
  a lower computational cost, and using the jumpy sub-goals to guide a low-level planner
  for fine-tuning.
---

# Simple Hierarchical Planning with Diffusion

## Quick Facts
- arXiv ID: 2401.02644
- Source URL: https://arxiv.org/abs/2401.02644
- Reference count: 40
- Key outcome: Hierarchical Diffuser achieves 12.0% improvement on Maze2D tasks and 9.2% on MuJoCo locomotion tasks compared to baseline Diffuser

## Executive Summary
This paper proposes a hierarchical diffusion-based planning framework to address computational challenges and generalization issues in existing diffusion-based planning methods. The key innovation is a "jumpy" planning strategy at the higher level, which subsamples every K-th state as subgoals, enabling larger receptive fields at lower computational cost. The method consists of two diffusers: a high-level sparse diffuser for subgoal generation and a low-level diffuser for fine-tuning between subgoals. Experiments on standard offline RL benchmarks demonstrate superior performance and efficiency compared to non-hierarchical approaches and other hierarchical methods, with particular success on compositional out-of-distribution tasks.

## Method Summary
The proposed Hierarchical Diffuser consists of two components: a high-level Sparse Diffuser (SD) that operates on subsampled trajectories (every K-th state) to generate subgoals, and a low-level diffuser that refines the plan between adjacent subgoals. The high-level planner uses either sparse states or dense states+actions as input, while the low-level planner works on full K+1 length segments. Both components use diffusion probabilistic models trained with denoising objectives and guidance functions for return prediction. During inference, the high-level planner generates subgoals which are then used to guide parallel low-level segment generation, with the final plan obtained by concatenating all segments.

## Key Results
- Hierarchical Diffuser achieves 12.0% improvement on Maze2D tasks compared to baseline Diffuser
- 9.2% improvement on MuJoCo locomotion tasks over non-hierarchical approaches
- Superior coverage of dataset distribution compared to flat diffusion-based planning
- Better generalization on compositional out-of-distribution tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The "jumpy" planning strategy increases the receptive field at lower computational cost
- Mechanism: By subsampling every K-th state as subgoals, the high-level planner operates on shorter sequences, reducing denoising dimensionality while covering larger temporal spans
- Core assumption: Intermediate states between subgoals are less critical for high-level planning, with dense low-level refinement recovering local details
- Evidence anchors: Abstract states jumpy planning allows larger receptive field at lower cost; section 3.1 describes subsampling trajectories; corpus lacks direct comparison to non-jumpy methods

### Mechanism 2
- Claim: Hierarchical planning improves distribution coverage compared to flat diffusion-based planning
- Mechanism: High-level planner generates subgoals spanning trajectory space while low-level planner fills gaps, ensuring broader dataset distribution exploration
- Core assumption: Dataset contains diverse paths between distant states that high-level planner can discover via subgoal selection
- Evidence anchors: Abstract notes planned trajectories have inadequate coverage; section 4.3 shows HD generates plans covering all distinct paths; corpus lacks quantitative coverage analysis

### Mechanism 3
- Claim: Including dense actions in high-level subgoal representation improves return prediction accuracy
- Mechanism: Dense actions provide implicit intermediate state information, enabling better guidance function training despite sparse states
- Core assumption: Action sequences between subgoals encode sufficient state information for return prediction
- Evidence anchors: Section 3.3 states dense actions facilitate guidance function learning; section 4.3 shows lower validation loss for HD-DA vs SD-SA; corpus lacks direct ablation on dense action inclusion

## Foundational Learning

- Concept: Diffusion probabilistic models and denoising training
  - Why needed here: The entire planner is a diffusion model; understanding score matching and iterative denoising is essential
  - Quick check question: What is the role of the noise prediction network εθ in the training objective?

- Concept: Hierarchical reinforcement learning and subgoal-based planning
  - Why needed here: The method builds on hierarchical RL principles; understanding how subgoals decompose long-horizon tasks is critical
  - Quick check question: How does the choice of K affect the granularity of the high-level plan?

- Concept: Offline reinforcement learning and distribution shift
  - Why needed here: The planner is trained offline; understanding generalization and coverage is key to interpreting results
  - Quick check question: What is the difference between in-distribution and out-of-distribution generalization in this context?

## Architecture Onboarding

- Component map: High-level Sparse Diffuser (states or states+actions) -> Low-level Diffuser (K+1 length segments) -> Concatenated final plan
- Critical path: Train high-level diffuser on subsampled trajectories → Train low-level diffuser on full segments → At test time: Sample high-level subgoals → Sample each low-level segment in parallel → Concatenate
- Design tradeoffs:
  - K selection: Larger K → fewer subgoals, faster high-level planning, but more information loss
  - Dense vs sparse actions in high-level: Dense actions improve guidance learning but increase input dimensionality
  - Parallel vs sequential low-level planning: Parallel is faster but assumes independence of segments
- Failure signatures:
  - Poor coverage: Generated trajectories miss dataset modes → check subgoal sampling diversity
  - Degraded return prediction: Guidance function poorly trained → verify dense action inclusion and return labeling
  - High computational cost: K too small or low-level segments too long → adjust K or segment length
- First 3 experiments:
  1. Ablation: Compare SD (standalone) vs Diffuser on Maze2D to confirm receptive field benefit
  2. Hyperparameter sweep: Vary K on a simple task to find the sweet spot between coverage and detail
  3. OOD test: Use compositional start-goal pairs not in training to verify generalization advantage

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal value of the jumpy step K that balances receptive field and state-action detail retention for RL tasks?
- Basis in paper: The paper discusses the tradeoff in K values and their impact on generalization and performance in Theorem 1 and Section 4.3
- Why unresolved: The paper shows performance initially increases with K but then declines, indicating a need to find an optimal K for different environments and tasks
- What evidence would resolve it: Systematic experiments across diverse environments with varying K values, coupled with analysis of resulting generalization gaps and performance metrics, would help determine the optimal K

### Open Question 2
- Question: How does the Hierarchical Diffuser framework perform on visual domains, and what modifications are necessary for its application?
- Basis in paper: The paper mentions expanding methodology to the visual domain as a potential future direction in the conclusion
- Why unresolved: Current framework is evaluated on non-visual tasks, and its extension to visual domains is not explored
- What evidence would resolve it: Applying Hierarchical Diffuser to visual tasks like Atari games or robotic manipulation with visual inputs and comparing performance to existing methods would provide insights into effectiveness and required modifications

### Open Question 3
- Question: What are the implications of dataset quality on the Hierarchical Diffuser's performance, and how can the model handle unfamiliar trajectories?
- Basis in paper: The paper acknowledges the model's dependency on dataset quality and its struggle with unfamiliar trajectories in the limitations section
- Why unresolved: The paper does not provide solutions or strategies for improving performance with low-quality datasets or handling unfamiliar trajectories
- What evidence would resolve it: Developing and testing strategies for data augmentation, transfer learning, or online adaptation to improve robustness to dataset quality and unfamiliar trajectories would address this question

## Limitations
- The method's performance on highly stochastic environments or with noisy action data remains unclear
- Coverage improvement claims lack quantitative metrics and rely on qualitative evidence
- Computational efficiency claims lack direct comparison metrics against non-hierarchical approaches
- The assumption that subsampling every K-th state captures sufficient high-level structure is not empirically validated against non-jumpy diffusion baselines

## Confidence
- Hierarchical planning efficiency claims: Medium confidence
- Generalization to OOD tasks: Medium confidence
- Coverage improvement claims: Low confidence

## Next Checks
1. Compare jumpy vs non-jumpy high-level planning on identical low-level architectures to isolate the receptive field benefit
2. Implement quantitative trajectory coverage metrics (e.g., KL divergence to dataset distribution) to validate coverage claims
3. Test performance degradation when action sequences are noisy or uninformative to validate dense action inclusion assumptions