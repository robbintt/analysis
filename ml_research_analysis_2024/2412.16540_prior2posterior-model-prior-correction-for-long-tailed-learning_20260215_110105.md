---
ver: rpa2
title: 'Prior2Posterior: Model Prior Correction for Long-Tailed Learning'
arxiv_id: '2412.16540'
source_url: https://arxiv.org/abs/2412.16540
tags: []
core_contribution: The paper addresses the problem of biased predictions in long-tailed
  recognition due to class imbalance during training. The authors observe that the
  effective prior learned by the model differs from the empirical prior based on class
  frequencies, leading to suboptimal performance.
---

# Prior2Posterior: Model Prior Correction for Long-Tailed Learning

## Quick Facts
- **arXiv ID**: 2412.16540
- **Source URL**: https://arxiv.org/abs/2412.16540
- **Authors**: S Divakar Bhat; Amit More; Mudit Soni; Surbhi Agrawal
- **Reference count**: 40
- **Primary result**: Achieves state-of-the-art performance in long-tailed recognition by correcting biased predictions through post-hoc prior adjustment without retraining

## Executive Summary
This paper addresses the challenge of biased predictions in long-tailed recognition due to class imbalance during training. The authors identify that the effective prior learned by the model differs from the empirical prior based on class frequencies, leading to suboptimal performance. They propose Prior2Posterior (P2P), a novel method to accurately model the effective prior using posterior probabilities and correct the predicted posterior probabilities in a post-hoc manner after training. The approach is theoretically optimal for models trained with cross-entropy loss and logit-adjusted loss, and experimental results demonstrate state-of-the-art performance across multiple benchmark datasets.

## Method Summary
The Prior2Posterior (P2P) method addresses long-tailed recognition by correcting the mismatch between the effective prior learned by the model and the empirical prior from training data. The approach involves two training stages: Stage 1 uses cross-entropy loss with instance-balanced sampling, followed by Stage 2 with logit-adjusted loss using balanced softmax. After training, P2P calculates the effective prior from model predictions on validation data and applies a correction to the predicted posterior probabilities. This post-hoc adjustment is theoretically optimal for models trained with cross-entropy or logit-adjusted loss, and can be applied to existing methods without retraining to remove residual bias.

## Key Results
- P2P achieves state-of-the-art performance in the category of logit adjustment methods on CIFAR10-LT, CIFAR100-LT, ImageNet-LT, and iNaturalist18 datasets
- The method demonstrates consistent improvement across different imbalance factors (200, 100, 10, and 50) without requiring model retraining
- P2P successfully improves existing methods post-hoc, showing effectiveness in removing residual bias even after sophisticated training techniques

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The model's effective prior differs from the empirical class frequency prior due to overfitting on head classes and underfitting on tail classes during training.
- **Mechanism**: During training with imbalanced data, the neural network adjusts its predictions to favor head classes. This learned bias (effective prior) becomes embedded in the posterior probabilities, causing the model to underestimate probabilities for tail classes and overestimate for head classes. The discrepancy between this effective prior and the empirical prior based on sample counts leads to suboptimal logit adjustment.
- **Core assumption**: The neural network's predictions approximate Bayesian a posteriori probabilities, but with limited capacity and imperfect optimization, the approximation is biased toward the training distribution.
- **Evidence anchors**: [abstract]: "the effective prior learned by the model at the end of the training, can differ from the empirical prior obtained using class frequencies"; [section]: "class frequencies can not accurately represent the bias present in the trained model"; [corpus]: "weak" - corpus papers discuss long-tailed learning but do not specifically analyze the divergence between effective and empirical priors
- **Break condition**: If the model perfectly generalizes across classes (no overfitting) or if the empirical prior already matches the effective prior, the mechanism breaks down.

### Mechanism 2
- **Claim**: Correcting the predicted posterior probabilities using the calculated effective prior improves model performance on balanced test sets.
- **Mechanism**: The proposed P2P method adjusts the logits by removing the model's learned bias (effective prior) and replacing it with the true test prior. This correction is performed post-hoc, after training, and is theoretically optimal for models trained with cross-entropy or logit-adjusted loss. The adjustment compensates for the mismatch between training and test distributions.
- **Core assumption**: The model's predictions during inference can be used to estimate the effective prior, and this estimate is accurate enough to improve performance.
- **Evidence anchors**: [abstract]: "correct the imbalanced prior by adjusting the predicted a posteriori probabilities (Prior2Posterior: P2P) using the calculated prior"; [section]: "Theorem 1" and "Theorem 2" provide mathematical proof of optimality; [corpus]: "weak" - corpus papers focus on other long-tailed learning techniques but do not specifically validate post-hoc prior correction
- **Break condition**: If the estimate of the effective prior is highly inaccurate (e.g., due to limited validation data), the correction may degrade performance.

### Mechanism 3
- **Claim**: The P2P approach can be applied to existing methods without retraining to further improve their performance.
- **Mechanism**: Since the P2P method only requires access to the model's predictions and does not modify the training process, it can be applied as a post-processing step to any trained model. This allows for removing residual bias that may remain even after sophisticated training techniques like logit adjustment or decoupled training.
- **Core assumption**: The residual bias in the model can be captured by the effective prior and corrected without affecting other learned features.
- **Evidence anchors**: [abstract]: "The proposed approach can be used to inspect any existing method to capture the effective prior and remove any residual bias to improve its performance, post-hoc, without model retraining"; [section]: "we test this idea on several SOTA methods" showing performance improvement; [corpus]: "weak" - corpus papers do not specifically discuss post-hoc bias correction for existing methods
- **Break condition**: If the existing method already perfectly removes all bias, or if the correction interferes with other aspects of the model's performance, the improvement may be minimal or negative.

## Foundational Learning

- **Concept**: Bayes' theorem and the relationship between prior, likelihood, and posterior distributions
  - Why needed here: The entire P2P method is based on adjusting the posterior distribution to match the test prior using Bayes' theorem.
  - Quick check question: Given P(y|x) and P(y), how would you compute P(x|y) using Bayes' theorem?

- **Concept**: Long-tailed class distributions and their impact on model training
  - Why needed here: Understanding why imbalanced training data leads to biased models is fundamental to grasping the P2P motivation.
  - Quick check question: If a dataset has 100 times more samples for class A than class B, what would you expect the model's accuracy to be for these classes without any special handling?

- **Concept**: Cross-entropy loss and its relationship to maximum likelihood estimation
  - Why needed here: The P2P method is optimal for models trained with cross-entropy loss, so understanding this connection is important.
  - Quick check question: How does minimizing cross-entropy loss relate to maximizing the likelihood of the training data?

## Architecture Onboarding

- **Component map**: Trained model -> Validation dataset -> Prior calculation module -> Logit adjustment module -> Evaluation module
- **Critical path**: 1. Load trained model and validation data; 2. Generate predictions on validation data to estimate effective prior; 3. Calculate adjustment terms using Eq. 27 and Eq. 28; 4. Apply adjustment to logits during inference; 5. Evaluate performance on balanced test set
- **Design tradeoffs**: Using more validation data improves prior estimation accuracy but increases computation; applying adjustment at inference time adds minimal overhead compared to retraining; the method is model-agnostic but requires access to validation data
- **Failure signatures**: Performance degrades after P2P application (likely due to poor prior estimation); no improvement on datasets with balanced training data; overcorrection leading to worse performance on head classes
- **First 3 experiments**: 1. Apply P2P to a simple CIFAR-10 model trained with cross-entropy on an imbalanced version of the dataset; 2. Compare P2P with class frequency-based adjustment on a CIFAR-100 model trained with logit-adjusted loss; 3. Apply P2P post-hoc to an existing SOTA method (e.g., cRT) and measure performance improvement on ImageNet-LT

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions.

## Limitations
- The P2P method requires access to a validation set to estimate the effective prior, which may not be available in all deployment scenarios.
- The method assumes that the model's predictions approximate Bayesian posteriors, which may not hold for all architectures or training regimes.
- Performance gains may be marginal if the model is already well-calibrated or if the training distribution closely matches the test distribution.

## Confidence
- **High Confidence**: The theoretical foundation of P2P correction for models trained with cross-entropy and logit-adjusted loss is sound, supported by mathematical proofs (Theorems 1 and 2) and the general principle that correcting for prior mismatch improves generalization.
- **Medium Confidence**: The empirical validation across multiple datasets (CIFAR-10/-100-LT, ImageNet-LT, iNaturalist18) demonstrates consistent improvements, but the magnitude of gains varies by dataset and method. The claim that P2P can improve existing methods without retraining is supported but needs more systematic testing across diverse architectures.
- **Low Confidence**: The exact mechanism by which the effective prior differs from the empirical prior is not fully characterized, and the method's performance on extremely long-tailed distributions (beyond the tested imbalance factors) is unknown.

## Next Checks
1. **Prior Estimation Sensitivity**: Systematically vary the size of the validation set used to estimate the effective prior and measure the impact on P2P performance.
2. **Architecture Generalization**: Apply P2P to a diverse set of model architectures (e.g., transformers, ViTs) trained on long-tailed data to assess method robustness.
3. **Extreme Imbalance**: Test P2P on datasets with imbalance factors exceeding 1000 to evaluate performance on ultra-long-tailed distributions.