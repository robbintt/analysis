---
ver: rpa2
title: Partial Federated Learning
arxiv_id: '2403.01615'
source_url: https://arxiv.org/abs/2403.01615
tags:
- data
- learning
- edge
- server
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Partial Federated Learning (PartialFL), a
  novel algorithm for training machine learning models on distributed data where some
  modalities can be shared centrally while others remain on edge devices. The approach
  leverages contrastive learning to align embeddings across modalities and devices
  without requiring label sharing, enhancing privacy.
---

# Partial Federated Learning

## Quick Facts
- arXiv ID: 2403.01615
- Source URL: https://arxiv.org/abs/2403.01615
- Reference count: 0
- Primary result: PartialFL improves federated learning performance by 1-4% on multi-modal tasks while preserving privacy

## Executive Summary
Partial Federated Learning (PartialFL) is a novel federated learning algorithm that leverages shareable modalities (like text) to train robust embeddings on a central server while keeping sensitive modalities (like audio) on edge devices. The method uses contrastive learning to align embeddings across modalities and devices without requiring label sharing, enhancing privacy. PartialFL was evaluated on speech emotion recognition and image classification tasks, demonstrating consistent performance improvements over traditional federated learning baselines, with up to 4% higher unweighted average recall on emotion recognition tasks.

## Method Summary
PartialFL operates by training a server-side encoder on shareable text data to generate embeddings that are then used to align edge-side text and non-shareable modality embeddings (like audio) through contrastive loss objectives. The global model on edge devices is trained on non-shareable data using a combination of cross-entropy and cross-modal contrastive losses. Local models on edge devices are also trained with embedding alignment losses to prevent overfitting. The framework uses FedAvg or FedProx for model aggregation and incorporates temperature scaling and weight parameters for the contrastive objectives.

## Key Results
- PartialFL achieved up to 4% higher unweighted average recall compared to FedAvg and FedProx baselines on speech emotion recognition tasks
- For image classification, PartialFL improved top-5 accuracy by up to 2.58%
- The method proved robust under non-IID data distributions and when some edge devices lacked certain modalities
- PartialFL approached the performance of centralized training while preserving privacy by not sharing labels

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PartialFL improves federated learning performance by leveraging shareable modalities to train robust embeddings on the server while keeping sensitive modalities on edge devices.
- Mechanism: The server trains an encoder on shareable text data to generate embeddings, which are then used to align edge-side text and audio embeddings via contrastive loss, improving robustness to data heterogeneity.
- Core assumption: Shareable modality embeddings can effectively align with non-shareable modality embeddings.
- Evidence anchors: Section 2.2 describes the server model training and embedding alignment objectives.

### Mechanism 2
- Claim: PartialFL addresses gradient drift in federated learning by using cross-modal alignment loss to minimize the distance between audio and text embeddings.
- Mechanism: The global model on edge devices is trained with a combined loss of cross-entropy and cross-modal contrastive loss, which pulls audio and text embeddings closer for the same data sample.
- Core assumption: Cross-modal contrastive loss can effectively reduce modality-specific feature gaps.
- Evidence anchors: Section 2.3 details the cross-modal alignment loss formulation.

### Mechanism 3
- Claim: PartialFL prevents overfitting on edge devices by aligning local text embeddings with server-generated text embeddings via contrastive loss.
- Mechanism: The local model on edge devices is trained with a combined loss of cross-entropy and embedding alignment loss, which minimizes the distance between local and server-side text embeddings.
- Core assumption: Aligning local and server-side text embeddings can regularize the local model.
- Evidence anchors: Section 2.4 describes the embedding alignment loss between local and server models.

## Foundational Learning

- Concept: Federated Learning (FL) - A distributed machine learning paradigm where models are trained across multiple edge devices holding local data, without exchanging the data itself.
  - Why needed here: PartialFL builds upon FL by introducing the concept of shareable modalities.
  - Quick check question: What is the main privacy benefit of using FL over traditional centralized training?

- Concept: Contrastive Learning - A self-supervised learning technique that learns representations by contrasting positive pairs (similar samples) against negative pairs (dissimilar samples).
  - Why needed here: PartialFL uses contrastive loss objectives to align embeddings across modalities and devices.
  - Quick check question: How does contrastive learning differ from supervised learning in terms of label requirements?

- Concept: Multi-modal Learning - A machine learning approach that processes and correlates information from multiple modalities (e.g., text, audio, image) to improve model performance.
  - Why needed here: PartialFL is designed for multi-modal settings where some modalities are shareable while others are not.
  - Quick check question: What are the main challenges in training models on multi-modal data compared to single-modal data?

## Architecture Onboarding

- Component map: Server model Fs (text encoder) -> Edge devices (global model Fg, local model Fk) -> Text modality embeddings (zT, z′T) -> Contrastive loss objectives
- Critical path: Server trains Fs on shareable text data → Server sends zT to edge devices → Edge devices train Fg and Fk with cross-modal and embedding alignment losses → Edge devices send trained models and z′T to server → Server aggregates global model and trains Fs with embedding alignment loss → Repeat for each global round
- Design tradeoffs:
  - Pros: Improved model performance over traditional FL, robustness to data heterogeneity, privacy preservation by not sharing labels
  - Cons: Added computation for training local and server models, potential privacy risks from sharing modality representations
- Failure signatures:
  - Poor performance: Shareable modality embeddings fail to align with non-shareable modality embeddings
  - Convergence issues: Cross-modal or embedding alignment losses do not converge or cause overfitting/underfitting
  - Communication overhead: Large size of modality representations shared between server and edge devices
- First 3 experiments:
  1. Train PartialFL on IEMOCAP dataset with audio-only global model and compare performance against FedAvg and FedProx baselines.
  2. Train PartialFL on UPMC Food-101 dataset with image-only global model and evaluate impact of non-IID settings by varying the α parameter.
  3. Train PartialFL on IEMOCAP dataset with multi-modal global model (audio + text) and assess performance when some edge devices lack the shareable modality.

## Open Questions the Paper Calls Out
- Question: How does PartialFL perform under label-only sharing scenarios where labels are shared but other modalities remain on edge devices?
- Question: What is the exact communication overhead difference between PartialFL and Split Learning in real-world deployments?
- Question: How does PartialFL handle modality conflicts when the shared modality on the server is noisy or corrupted compared to the edge device's version?

## Limitations
- The model architecture details remain underspecified, particularly regarding audio and image embedding processing
- Evaluation scope is limited to only two datasets, which may not generalize to broader multi-modal scenarios
- Privacy analysis focuses primarily on avoiding label sharing but doesn't comprehensively address potential information leakage through shared modality representations

## Confidence
- **High confidence**: The core mechanism of using shareable modalities to improve federated learning performance through contrastive alignment is well-supported by experimental results
- **Medium confidence**: The robustness claims under non-IID settings and when devices lack certain modalities are supported but could benefit from more extensive experimentation
- **Medium confidence**: The privacy benefits of avoiding label sharing are plausible but require more rigorous privacy analysis

## Next Checks
1. Implement the PartialFL framework with the specified model architectures and contrastive learning objectives, verifying that the performance improvements can be reproduced across different datasets.
2. Conduct a comprehensive privacy assessment examining potential information leakage through shared text representations, including membership inference and reconstruction attacks.
3. Evaluate PartialFL on additional multi-modal datasets beyond speech and image data to assess its effectiveness across different modality combinations and data types.