---
ver: rpa2
title: Algorithm Selection for Optimal Multi-Agent Path Finding via Graph Embedding
arxiv_id: '2406.10827'
source_url: https://arxiv.org/abs/2406.10827
tags:
- mapf
- graph
- features
- problem
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MAG (MAPF Algorithm selection via Graph embedding),
  a novel algorithm selection method for optimal multi-agent path finding (MAPF) problems.
  MAG addresses the challenge of selecting the best optimal MAPF solver for a given
  instance by encoding MAPF problems as graphs and applying a modern graph embedding
  algorithm (FEATHER) to extract features.
---

# Algorithm Selection for Optimal Multi-Agent Path Finding via Graph Embedding

## Quick Facts
- arXiv ID: 2406.10827
- Source URL: https://arxiv.org/abs/2406.10827
- Reference count: 35
- Key outcome: MAG significantly outperforms existing baselines in MAPF algorithm selection accuracy, coverage, and regret metrics across different grid types

## Executive Summary
This paper introduces MAG (MAPF Algorithm selection via Graph embedding), a novel algorithm selection method for optimal multi-agent path finding (MAPF) problems. MAG addresses the challenge of selecting the best optimal MAPF solver for a given instance by encoding MAPF problems as graphs and applying a modern graph embedding algorithm (FEATHER) to extract features. The method combines these graph-based features with existing hand-crafted MAPF-specific features. Extensive experiments on a standard benchmark show that MAG significantly outperforms existing baselines in accuracy, coverage, and regret metrics across three different algorithm selection tasks, particularly in the more challenging in-grid-type and between-grid-type setups.

## Method Summary
MAG encodes MAPF problems using two graph-based methods (G2V and FullG2V) to capture structural patterns, then applies the FEATHER graph embedding algorithm to generate 500-dimensional feature vectors. These graph embeddings are concatenated with existing hand-crafted MAPF-specific features (KBS features) to create a comprehensive feature representation. An XGBoost classifier is trained on these combined features to predict the best optimal MAPF solver for a given instance. The approach works on-the-fly without requiring prior training on specific graphs, enabling effective algorithm selection even for previously unseen MAPF problems.

## Key Results
- MAG achieves 86.7% accuracy on in-grid setup, significantly outperforming G2V (76.8%), FG2V (82.8%), and KBS (77.3%) baselines
- On between-grid-type setup, MAG reaches 74.2% accuracy versus 63.4% for the best baseline, demonstrating strong generalization
- MAG reduces regret by 35.7% compared to the best baseline in between-grid-type setup, indicating better runtime optimization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MAG leverages graph embeddings to capture structural patterns in MAPF problems that hand-crafted features miss.
- Mechanism: By encoding the entire MAPF graph (including shortest paths and agent start/goal pairs as artificial edges) and applying FEATHER, MAG extracts a rich 500-dimensional feature vector representing graph topology and agent distribution.
- Core assumption: Graph structural features correlate with algorithm performance across different MAPF instances.
- Evidence anchors:
  - [abstract]: "We explore graph-based encodings of the MAPF problem and show how they can be used on-the-fly with a modern graph embedding algorithm called FEATHER."
  - [section]: "We propose FullG2V (FG2V), which uses the entire graph G to encode the given MAPF problem."
- Break condition: If MAPF instances share similar graph structures but require different algorithms, the graph embedding may not capture performance-relevant distinctions.

### Mechanism 2
- Claim: Combining multiple feature representations (hand-crafted, G2V, and FG2V) provides complementary information for algorithm selection.
- Mechanism: MAG concatenates graph embeddings with KBS features, creating a comprehensive feature vector that captures both domain-specific and structural properties of MAPF problems.
- Core assumption: Different feature types capture orthogonal aspects of MAPF problem difficulty.
- Evidence anchors:
  - [abstract]: "Then, we show how this encoding can be effectively joined with existing encodings, resulting in a novel AS method we call MAPF Algorithm selection via Graph embedding (MAG)."
  - [section]: "MAG uses G2V and FG2V to create two graphs GG2V and GFG2V that encoding Π. Then, it creates two graph embeddings vG2V and vFG2V by applying FEATHER on these graphs."
- Break condition: If one feature type dominates the others in predictive power, the concatenated approach may introduce noise without improving accuracy.

### Mechanism 3
- Claim: MAG's graph embedding approach works effectively on previously unseen MAPF problems without requiring retraining.
- Mechanism: FEATHER operates on-the-fly without needing prior training on specific graphs, allowing MAG to handle new MAPF instances from different grid types.
- Core assumption: FEATHER's node embedding and max-pooling approach generalizes well to unseen graph structures.
- Evidence anchors:
  - [abstract]: "unlike other graph embedding techniques, it does not require a-priori training. Consequently, the features extracted using FEATHER can be extracted and used in a meaningful way even for graphs created for MAPF problems that are not in the training set."
  - [section]: "Unlike other graph embedding techniques, it does not require a-priori training."
- Break condition: If FEATHER's random walk-based approach fails to capture meaningful structural differences between unseen MAPF graphs.

## Foundational Learning

- Concept: Graph embedding algorithms
  - Why needed here: MAG relies on FEATHER to convert MAPF graphs into numerical feature vectors for machine learning
  - Quick check question: What is the difference between node embedding and graph embedding in the context of MAPF?

- Concept: Multi-agent pathfinding (MAPF) problem formulation
  - Why needed here: Understanding MAPF's NP-hardness and optimal solver diversity is crucial for appreciating why algorithm selection matters
  - Quick check question: What are the two standard cost functions used in MAPF, and how do they differ?

- Concept: Algorithm selection (AS) problem setup
  - Why needed here: MAG is fundamentally an AS method, so understanding the classification framework is essential
  - Quick check question: In the AS context, what is the difference between in-grid, in-grid-type, and between-grid-type setups?

## Architecture Onboarding

- Component map: MAPF problem → G2V encoding → FEATHER embedding → FG2V encoding → FEATHER embedding → KBS features → Concatenation → XGBoost classifier → Algorithm prediction
- Critical path: The feature extraction pipeline (graph encoding + embedding + concatenation) is the most critical component, as errors here propagate to the final prediction
- Design tradeoffs: Using both G2V and FG2V captures different levels of graph detail, but increases feature dimensionality and computational cost
- Failure signatures: Poor performance on between-grid-type tasks suggests the graph embeddings aren't generalizing well; degraded accuracy on maze-like grids indicates G2V's limitations
- First 3 experiments:
  1. Run MAG on a simple in-grid setup to verify basic functionality
  2. Compare MAG's accuracy against KBS and G2V baselines on a single grid type
  3. Test MAG's performance on a between-grid-type setup with training on empty grids and testing on maze grids

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different graph pooling methods (beyond mean and max) affect MAG's performance for MAPF algorithm selection?
- Basis in paper: [inferred] The paper experimented with mean and max pooling methods and found max pooling performed better, but did not explore other pooling methods.
- Why unresolved: The paper only tested two pooling methods (mean and max) and did not systematically explore the impact of other pooling methods on performance.
- What evidence would resolve it: Experimental results comparing MAG's performance using different pooling methods (e.g., sum, attention-based, or learnable pooling) across various MAPF benchmarks and algorithm selection tasks.

### Open Question 2
- Question: Can MAG's graph embedding features be effectively combined with other non-image, non-graph-based feature representations for MAPF algorithm selection?
- Basis in paper: [explicit] The paper combined graph embedding features with hand-crafted KBS features, but did not explore other feature types like runtime-based or problem-specific structural features.
- Why unresolved: The paper only tested combinations of graph embedding features with KBS features, leaving open the question of how other feature types might contribute.
- What evidence would resolve it: Experimental results comparing MAG's performance when combining graph embedding features with various other feature types (e.g., runtime-based features, structural features) across different MAPF benchmarks.

### Open Question 3
- Question: How does MAG's performance scale with increasing numbers of agents and larger problem instances in MAPF?
- Basis in paper: [inferred] The paper used a benchmark with up to 1000 agents, but did not specifically analyze performance trends as problem size increases.
- Why unresolved: The paper presents aggregate results but does not analyze how MAG's performance changes with problem size, which is crucial for real-world applications.
- What evidence would resolve it: Systematic experiments measuring MAG's accuracy, coverage, and regret metrics across MAPF instances with varying numbers of agents and grid sizes, showing performance trends.

## Limitations

- The evaluation relies on a single benchmark dataset, raising questions about generalization to other MAPF problem distributions
- The paper doesn't provide ablation studies isolating the contribution of graph embeddings versus the concatenated feature set
- The mechanism by which FEATHER's graph embeddings specifically capture MAPF-relevant structural patterns remains poorly explained

## Confidence

- **High confidence**: MAG outperforms individual feature methods (G2V, FG2V, KBS) on accuracy metrics, particularly in the more challenging between-grid-type setup where MAG achieves 74.2% accuracy versus 63.4% for the best baseline.
- **Medium confidence**: The claim that MAG "significantly outperforms" existing baselines is supported by the results, but the paper doesn't establish statistical significance of the differences or provide confidence intervals for the metrics.
- **Low confidence**: The mechanism by which FEATHER's graph embeddings specifically capture MAPF-relevant structural patterns remains poorly explained, with limited qualitative analysis of what the embeddings actually represent.

## Next Checks

1. **Ablation study**: Evaluate MAG variants using only G2V features, only FG2V features, and only KBS features to quantify the marginal contribution of graph embeddings versus feature concatenation.
2. **Cross-benchmark testing**: Apply MAG to MAPF problems from a different benchmark or synthetically generated problems to assess generalization beyond the Kaduri et al. dataset.
3. **Statistical analysis**: Perform statistical tests (e.g., McNemar's test for accuracy, paired t-tests for runtime) to establish whether MAG's improvements over baselines are statistically significant rather than due to random variation.