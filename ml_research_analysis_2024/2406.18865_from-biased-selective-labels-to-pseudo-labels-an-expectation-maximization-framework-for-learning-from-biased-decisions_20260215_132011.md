---
ver: rpa2
title: 'From Biased Selective Labels to Pseudo-Labels: An Expectation-Maximization
  Framework for Learning from Biased Decisions'
arxiv_id: '2406.18865'
source_url: https://arxiv.org/abs/2406.18865
tags:
- dcem
- bias
- group
- learning
- causal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Disparate censorship, where labeling decisions are biased across
  subgroups and unlabeled individuals are imputed as negative, can cause machine learning
  models to amplify inequity. This work introduces Disparate Censorship Expectation-Maximization
  (DCEM), an algorithm that learns from such biased labels by leveraging causal assumptions
  about the selective labeling process.
---

# From Biased Selective Labels to Pseudo-Labels: An Expectation-Maximization Framework for Learning from Biased Decisions

## Quick Facts
- arXiv ID: 2406.18865
- Source URL: https://arxiv.org/abs/2406.18865
- Authors: Trenton Chang; Jenna Wiens
- Reference count: 40
- Primary result: DCEM mitigates bias from selective labeling while maintaining model performance

## Executive Summary
This paper addresses the problem of learning from biased selective labels where certain individuals are never tested and assumed negative. The authors introduce DCEM (Disparate Censorship Expectation-Maximization), an algorithm that learns from such biased decisions by leveraging causal assumptions about the selective labeling process. DCEM alternates between imputing pseudo-labels for untested individuals and updating the model with causal regularization that counterbalances labeling bias. The method theoretically regularizes predictions to be lower in regions where individuals are more likely to be untested, mitigating disparate censorship effects.

## Method Summary
DCEM operates through an iterative expectation-maximization framework that alternates between two key steps. In the E-step, the algorithm estimates the probability that untested individuals are actually positive, generating pseudo-labels based on the current model predictions and causal structure. In the M-step, DCEM updates the model parameters by optimizing a loss function that includes causal regularization terms designed to counter the selection bias. The causal regularization specifically penalizes predictions in regions where individuals are more likely to be untested, effectively pushing the decision boundary away from these censored areas. This approach assumes knowledge of the causal mechanism governing selective labeling, allowing the algorithm to distinguish between true negatives and censored positives.

## Key Results
- DCEM improves bias mitigation (area between ROC curves) compared to baselines
- DCEM maintains or improves discriminative performance (AUC) on both synthetic and real clinical data
- DCEM demonstrates greater robustness to changes in data-generation processes than alternative methods
- Shows effectiveness on sepsis classification task using real clinical data

## Why This Works (Mechanism)
DCEM works by explicitly modeling the selective labeling process through causal assumptions. By alternating between pseudo-label imputation and model updating with causal regularization, the algorithm can recover information about the true underlying distribution despite systematic censoring. The key insight is that knowledge of the selection mechanism allows for targeted regularization that specifically addresses regions where censoring is most severe, preventing the model from simply learning to predict negative for untested individuals.

## Foundational Learning

**Causal inference in machine learning**
- Why needed: Understanding selection bias requires causal reasoning about how labeling decisions depend on features
- Quick check: Can you identify the causal assumptions made about the labeling process?

**Expectation-Maximization algorithms**
- Why needed: The iterative imputation and model update framework follows EM principles
- Quick check: How does the E-step differ from standard EM due to selection bias?

**Semi-supervised learning**
- Why needed: The approach leverages unlabeled data through pseudo-label generation
- Quick check: What distinguishes DCEM's use of pseudo-labels from standard semi-supervised approaches?

## Architecture Onboarding

**Component map:**
Model parameters → E-step (pseudo-label imputation) → M-step (model update with causal regularization) → Updated model parameters

**Critical path:**
Model initialization → E-step (estimate P(Y=1|untested)) → M-step (update θ with causal regularization) → Convergence check

**Design tradeoffs:**
- Assumes known causal structure vs. being agnostic to selection mechanism
- Requires iterative computation vs. single-pass methods
- Provides theoretical guarantees under assumptions vs. empirical heuristics

**Failure signatures:**
- Poor performance when causal assumptions are violated
- Convergence issues if regularization is too strong
- Suboptimal results when selection bias mechanism is complex

**3 first experiments:**
1. Synthetic data with known selection bias mechanism to verify theoretical properties
2. Ablation study removing causal regularization to measure its impact
3. Sensitivity analysis varying the strength of selection bias

## Open Questions the Paper Calls Out
None

## Limitations
- Requires precise knowledge of selection bias mechanism and causal structure
- Performance depends critically on correct specification of causal assumptions
- Limited evaluation to one real-world clinical dataset (sepsis classification)
- No analysis of computational complexity or scalability

## Confidence
- Theoretical soundness: High
- Empirical validation: Medium
- Practical applicability: Low-Medium

## Next Checks
1. Test DCEM performance when causal assumptions are partially violated or misspecified
2. Evaluate robustness across diverse real-world datasets with different labeling biases
3. Compare DCEM against state-of-the-art methods for learning from positive and unlabeled data