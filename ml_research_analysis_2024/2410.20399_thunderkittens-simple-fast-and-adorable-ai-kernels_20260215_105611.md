---
ver: rpa2
title: 'ThunderKittens: Simple, Fast, and Adorable AI Kernels'
arxiv_id: '2410.20399'
source_url: https://arxiv.org/abs/2410.20399
tags:
- args
- kernels
- block
- state
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'ThunderKittens is a framework for simplifying the development
  of high-performance AI kernels on GPUs while maintaining ease of use and maintenance.
  The authors introduce three key abstractions: tile data structures with managed
  layouts, a program template for asynchronous execution across thread blocks, and
  grid scheduling for pipelining thread blocks.'
---

# ThunderKittens: Simple, Fast, and Adorable AI Kernels

## Quick Facts
- arXiv ID: 2410.20399
- Source URL: https://arxiv.org/abs/2410.20399
- Reference count: 40
- Simple, fast, and adorable AI kernels framework

## Executive Summary
ThunderKittens (TK) is a framework that simplifies the development of high-performance AI kernels on GPUs while maintaining ease of use and maintenance. The authors introduce three key abstractions: tile data structures with managed layouts, a program template for asynchronous execution across thread blocks, and grid scheduling for pipelining thread blocks. They demonstrate the effectiveness of these abstractions by implementing kernels that match or outperform state-of-the-art baselines across various AI operations, enabling a small academic team to develop performant kernels for a range of AI operations.

## Method Summary
ThunderKittens introduces three abstractions to simplify GPU kernel development: 1) tile data structures with automatic layout management that minimize bank conflicts while maintaining tensor core compatibility, 2) a Linear Compute-Store-Finish (LCSF) template that coordinates asynchronous execution across warps within thread blocks, and 3) grid scheduling that supports persistent launches and optimizes block order for L2 reuse. These abstractions are designed to work together to enable high-performance implementations of AI operations while reducing development complexity.

## Key Results
- Matches CuBLAS and FlashAttention-3 on GEMM and attention inference
- Outperforms strongest baselines by 10-40% on attention backwards
- Achieves 8x speedup on state space models and 14x on linear attention

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Small, opinionated abstractions can achieve state-of-the-art performance across diverse AI kernels
- Mechanism: By mapping abstractions to GPU hierarchy levels, TK reduces complexity while maintaining hardware utilization
- Core assumption: Fundamental computational patterns in AI kernels can be expressed using limited abstractions without significant performance loss
- Evidence anchors: "a small number of key abstractions can drastically simplify the process", "TK uses a 16 × 16 matrix tile as its basic data structure"
- Break Condition: When AI kernels require fundamentally different memory access patterns or computation types

### Mechanism 2
- Claim: Automatic layout management eliminates bank conflicts while maintaining hardware compatibility
- Mechanism: TK selects from three swizzled layouts (32B, 64B, 128B) based on tile width, automatically choosing the largest layout that fits
- Core assumption: Bank conflicts are a primary performance limiter in shared memory access patterns
- Evidence anchors: "TK automatically picks the optimal memory layouts for the tiles to minimize bank conflicts", detailed analysis of six layout strategies
- Break Condition: When tile sizes don't align with swizzling boundaries or when hardware requires non-standard layouts

### Mechanism 3
- Claim: The LCSF template enables high occupancy without resource contention through structured asynchronous execution
- Mechanism: The template provides multi-stage pipeline buffers, synchronization barriers, and asynchronous I/O operations that allow multiple warps to work on different tiles simultaneously
- Core assumption: Memory latency is the primary bottleneck in AI kernels, and overlapping operations can effectively hide this latency
- Evidence anchors: "TK provides a general kernel template for coordinating asynchronous execution across warps", multi-stage buffer support
- Break Condition: When kernel operations are inherently sequential or when memory access patterns don't benefit from overlapping

## Foundational Learning

- Concept: GPU memory hierarchy and access patterns
  - Why needed here: Understanding why TK's abstractions work requires knowing how GPU memory affects performance and how different access patterns create bank conflicts
  - Quick check question: Why does a row-major layout cause bank conflicts when loading into tensor core layouts?

- Concept: Tensor core operation requirements
  - Why needed here: TK's 16x16 tile size and layout management are specifically designed to maximize tensor core utilization
  - Quick check question: What are the layout requirements for tensor core matrix multiply operations?

- Concept: Asynchronous programming patterns
  - Why needed here: The LCSF template relies on producer-consumer patterns and synchronization primitives
  - Quick check question: How do synchronization barriers prevent race conditions while allowing overlapping execution?

## Architecture Onboarding

- Component map: Warp-level (16x16 tile data structures, parallel compute primitives) -> Block-level (LCSF template with load/compute/store/finish functions) -> Grid-level (Persistent launch support, block order optimization)
- Critical path: Tile definition → Layout selection → Template function implementation → Grid parameter tuning
- Design tradeoffs:
  - Tile size vs. bank conflicts: Larger tiles reduce instruction overhead but may increase conflicts
  - Pipeline depth vs. synchronization: Deeper pipelines hide more latency but require more complex synchronization
  - Occupancy vs. resource contention: Higher occupancy improves utilization but can exhaust registers/shared memory
  - Block order vs. L2 reuse: Different orders trade off between memory access patterns and cache locality
- Failure signatures:
  - Bank conflicts: Unexpected performance degradation, especially in shared memory operations
  - Register spills: Kernel crashes or severe performance degradation when occupancy is too high
  - Memory bandwidth exhaustion: Low TFLOPS despite high occupancy, indicating HBM bottleneck
  - L2 cache thrashing: Performance varies significantly with block order changes
- First 3 experiments:
  1. Implement GEMM kernel with default tile size and observe baseline performance against CuBLAS
  2. Vary pipeline stages (1-4) and measure impact on performance and register usage
  3. Test different block orders for GEMM and measure HBM bandwidth utilization and TFLOPS

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does ThunderKittens' performance compare to future GPU architectures beyond H100?
- Basis in paper: The paper benchmarks TK on H100 80GB SXM GPUs but doesn't test on newer architectures
- Why unresolved: The framework's effectiveness depends on specific GPU features like tensor cores and TMA instructions
- What evidence would resolve it: Benchmarking TK on newer architectures like H200 or B100 and comparing performance to native implementations

### Open Question 2
- Question: What is the maximum complexity of AI kernels that can be effectively expressed using TK's abstractions?
- Basis in paper: The paper demonstrates TK works for several AI operations but doesn't explore the limits of its expressiveness
- Why unresolved: The framework's three-level abstraction might become limiting for highly specialized or novel AI operations
- What evidence would resolve it: Implementing increasingly complex AI operations in TK and identifying where the abstractions become insufficient

### Open Question 3
- Question: How does the performance of TK kernels change with different batch sizes and sequence lengths?
- Basis in paper: The paper shows performance for specific batch sizes and sequence lengths but doesn't systematically explore the scaling behavior
- Why unresolved: Performance characteristics may vary significantly across different workload configurations
- What evidence would resolve it: Comprehensive benchmarking across a wide range of batch sizes and sequence lengths for all supported operations

### Open Question 4
- Question: What is the exact trade-off between TK's simplicity and the potential performance gains from more specialized implementations?
- Basis in paper: The paper claims TK achieves state-of-the-art performance but doesn't quantify what might be lost compared to more complex approaches
- Why unresolved: The abstractions may leave some performance on the table that could be captured with more specialized techniques
- What evidence would resolve it: Detailed profiling of TK kernels versus hand-optimized implementations for the same operations

### Open Question 5
- Question: How well does TK handle emerging AI operations that don't fit traditional matrix multiplication patterns?
- Basis in paper: While TK shows success with several AI operations, the paper doesn't explore edge cases or unconventional operations
- Why unresolved: The framework's effectiveness may break down for operations with irregular access patterns or non-standard computations
- What evidence would resolve it: Attempting to implement a diverse set of emerging AI operations in TK and measuring both performance and development effort

## Limitations
- Performance claims lack baseline comparisons for state space models and linear attention
- Evaluation focuses primarily on NVIDIA GPUs with no discussion of AMD or other accelerator compatibility
- Framework's effectiveness for large-scale distributed training scenarios remains unclear

## Confidence
- High Confidence: Core abstractions are technically sound and follow established GPU programming principles
- Medium Confidence: Performance claims relative to specific baselines appear reasonable but require independent verification
- Low Confidence: Claims about outperforming all existing kernels by 10-40% in attention backwards require more detailed methodology

## Next Checks
1. Reproduce Core Kernels: Implement the attention and GEMM kernels from scratch using the TK framework and verify the claimed performance matches against CuBLAS and FlashAttention-3 on identical hardware
2. Layout Optimization Validation: Systematically test the automatic layout selection algorithm by implementing all three layout strategies for various tile sizes and measuring bank conflict rates and performance impact
3. Scalability Assessment: Test the framework's performance across multiple NVIDIA GPU generations and measure how well the abstractions adapt to different tensor core configurations and memory hierarchies