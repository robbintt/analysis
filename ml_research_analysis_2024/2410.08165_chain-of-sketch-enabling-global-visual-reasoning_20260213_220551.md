---
ver: rpa2
title: 'Chain-of-Sketch: Enabling Global Visual Reasoning'
arxiv_id: '2410.08165'
source_url: https://arxiv.org/abs/2410.08165
tags:
- task
- tasks
- maze
- reasoning
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a suite of global visual reasoning tasks\u2014\
  including cycles, strings, mazes, and image pointer value retrieval\u2014that are\
  \ difficult for both large vision models and multimodal LLMs due to their high globality\
  \ degree. To address this, the authors propose chain-of-sketch (CoS), a method that\
  \ breaks down complex visual reasoning into intermediate visual steps."
---

# Chain-of-Sketch: Enabling Global Visual Reasoning

## Quick Facts
- arXiv ID: 2410.08165
- Source URL: https://arxiv.org/abs/2410.08165
- Authors: Aryo Lotfi; Enrico Fini; Samy Bengio; Moin Nabi; Emmanuel Abbe
- Reference count: 40
- Key outcome: Inductive chain-of-sketch achieves strong out-of-distribution generalization for global visual reasoning tasks that challenge both large vision models and multimodal LLMs.

## Executive Summary
This paper introduces chain-of-sketch (CoS), a method that enables vision transformers to tackle global visual reasoning tasks by breaking them down into intermediate visual steps. The authors identify that tasks like cycles, strings, mazes, and image pointer value retrieval have high "globality degree" - requiring holistic reasoning across many image patches - which makes them difficult for standard models. CoS reduces this complexity by decomposing tasks into sequential frames with lower globality. The inductive CoS variant, which uses a Markovian sequential generation of frames with adaptive halting, achieves superior out-of-distribution generalization and enables smaller models to learn tasks that other CoS variants cannot.

## Method Summary
The paper proposes chain-of-sketch (CoS) as a visual reasoning framework that decomposes global tasks into intermediate visual steps. Three variants are explored: single-frame CoS (predicting one sketch frame), multi-frame CoS (predicting all intermediate frames in parallel), and inductive CoS (recurrently generating frames with adaptive halting). The approach is built on top of vision transformer backbones, with additional linear layers predicting sketch images through pixel-wise MSE loss. The inductive variant imposes a Markovian structure where each frame depends only on the previous one, enabling better OOD generalization to tasks requiring more reasoning steps than seen during training.

## Key Results
- Standard ViT models struggle with high-globality tasks, achieving near-random performance on cycles 12
- Single-frame CoS significantly improves performance by reducing globality degree of intermediate steps
- Inductive CoS achieves superior OOD generalization, successfully handling cycles 16 when trained on cycles 12
- Smaller models with inductive CoS can learn tasks that larger models cannot learn without CoS
- The adaptive halting mechanism in inductive CoS provides efficient inference with fewer reasoning steps

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The globality degree measure explains why standard vision models fail on these tasks.
- **Mechanism**: Globality degree quantifies the minimum number of patches needed to achieve non-trivial mutual information with the target. Tasks with high globality degree require holistic reasoning across many patches, which standard models struggle with.
- **Core assumption**: That the learning complexity scales with n^(k*) where k* is the globality degree.
- **Evidence anchors**:
  - [abstract]: "We explain this learning inefficiency by means of the 'globality degree' measure."
  - [section 2.1]: Formal definition of globality degree and empirical validation showing cycles 12 requires 70% of patches vs 10% for ImageNet.
  - [corpus]: Weak correlation with related work on global visual perception evaluation.
- **Break condition**: If patches contain redundant information or if the target is permutation invariant, the globality degree measure may not accurately predict learning difficulty.

### Mechanism 2
- **Claim**: Chain-of-sketch breaks down global tasks into intermediate visual steps with reduced globality.
- **Mechanism**: By decomposing the target into sequential frames, each intermediate step has lower globality degree, making it learnable by the model.
- **Core assumption**: That each CoS frame can be predicted with constant globality given the previous frame.
- **Evidence anchors**:
  - [abstract]: "Similar to the chain-of-thought and scratchpad techniques used in language models, CoS breaks the original task into intermediate visual steps."
  - [section 2.3]: Explanation of how CoS reduces globality degree and enables hierarchical learning.
  - [corpus]: Direct connection to scratchpad techniques in text, but visual implementation is novel.
- **Break condition**: If the intermediate frames cannot be predicted with significantly reduced globality, or if the sequence becomes too long.

### Mechanism 3
- **Claim**: Inductive CoS achieves better OOD generalization by learning a Markovian sequence of reasoning steps.
- **Mechanism**: The recurrent model generates frames sequentially based only on the previous frame, making the reasoning process independent of the total number of steps required.
- **Core assumption**: That the CoS generation process is Markovian and that each step depends only on the previous one.
- **Evidence anchors**:
  - [abstract]: "Our key insight is to impose a Markovian structure on the CoS frames. This leads to the introduction of 'inductive CoS' which achieves better out-of-distribution generalization."
  - [section 3.2]: Description of the recurrent module and Markovian structure.
  - [section 4.2]: Experimental results showing superior OOD performance of inductive CoS.
- **Break condition**: If the CoS generation process has long-range dependencies that violate the Markov assumption.

## Foundational Learning

- **Concept**: Globality degree and its relationship to learning complexity
  - **Why needed here**: Understanding why standard models fail on global tasks and how CoS addresses this
  - **Quick check question**: What is the globality degree of a task where 3 patches provide 90% of the information about the target?

- **Concept**: Chain-of-thought reasoning and its extension to visual domains
  - **Why needed here**: CoS is the visual analog of CoT, so understanding the underlying principle is crucial
  - **Quick check question**: How does breaking a task into intermediate steps with lower globality enable learning?

- **Concept**: Markovian sequences and their role in generalization
  - **Why needed here**: Inductive CoS relies on Markovian structure for OOD generalization
  - **Quick check question**: Why does a Markovian sequence of reasoning steps generalize better to longer instances?

## Architecture Onboarding

- **Component map**: Input image -> ViT encoder -> CLS token -> (label prediction) + (CoS frame prediction) -> (recurrent module for inductive CoS) -> halting signal

- **Critical path**:
  1. Input image → ViT encoder → CLS token
  2. CLS token → label prediction (linear layer + softmax)
  3. CLS token → CoS frame prediction (linear layer + pixel-wise MSE loss)
  4. For inductive CoS: recurrent application with halting condition

- **Design tradeoffs**:
  - Model size vs. learning capability (smaller models work with inductive CoS)
  - Training complexity (multi-frame vs. single-frame supervision)
  - Inference compute (inductive CoS requires adaptive compute time)
  - Data requirements (CoS needs intermediate frames as supervision)

- **Failure signatures**:
  - Random accuracy indicates model cannot learn task even with CoS
  - Poor OOD performance suggests memorization rather than reasoning
  - High training loss but low validation loss indicates overfitting
  - Halting mechanism fails to terminate → infinite recursion

- **First 3 experiments**:
  1. Train no-CoS baseline on cycles 12 task to establish baseline performance
  2. Train single-frame CoS on cycles 12 task to verify globality reduction works
  3. Train inductive CoS on cycles 12 task and test OOD on cycles 16 task to verify generalization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the globality degree concept be formalized and proven to be a strict upper bound on the learning complexity of vision transformers for tasks with high globality?
- Basis in paper: Explicit - The paper discusses the globality degree as a measure of task difficulty and relates it to learning complexity, but theoretical proofs are lacking.
- Why unresolved: The paper only provides empirical evidence and conjectures about the relationship between globality degree and learning complexity. A rigorous theoretical framework is needed to formally establish this connection.
- What evidence would resolve it: A mathematical proof showing that tasks with high globality degree cannot be learned efficiently by vision transformers, even with polynomially large models and training time.

### Open Question 2
- Question: How does the chain-of-sketch methodology generalize to more complex, real-world visual reasoning tasks that involve multiple objects, scenes, and reasoning steps?
- Basis in paper: Inferred - The paper demonstrates the effectiveness of CoS on synthetic datasets with controlled complexity. It suggests potential applications to real-world tasks but does not explore them.
- Why unresolved: The current CoS implementations are tailored to specific, well-defined tasks. Adapting them to handle the complexity and variability of real-world visual reasoning remains an open challenge.
- What evidence would resolve it: Successful application of CoS to real-world visual reasoning tasks, such as solving complex geometry problems or understanding dynamic scenes in videos, with comparable performance to human experts.

### Open Question 3
- Question: What is the optimal strategy for generating intermediate visual steps in the chain-of-sketch framework for tasks where the reasoning process is not as straightforward as in the proposed datasets?
- Basis in paper: Explicit - The paper discusses different variants of CoS, including single-frame and multi-frame approaches. It suggests that not all CoS strategies are equally effective and that the optimal strategy may depend on the task.
- Why unresolved: The paper provides examples of CoS for specific tasks but does not offer a general methodology for generating intermediate steps for arbitrary visual reasoning tasks.
- What evidence would resolve it: A systematic study comparing different CoS generation strategies across a wide range of visual reasoning tasks, identifying the factors that influence the effectiveness of each strategy.

### Open Question 4
- Question: How does the performance of the inductive CoS model scale with the number of reasoning steps required for a task? Is there a limit to the complexity of tasks that can be learned using this approach?
- Basis in paper: Explicit - The paper demonstrates the effectiveness of inductive CoS for tasks requiring multiple reasoning steps. However, it does not explore the scalability of the approach to tasks with a very large number of steps.
- Why unresolved: The computational complexity of the inductive CoS model increases with the number of reasoning steps. It is unclear whether the approach can scale to tasks requiring hundreds or thousands of steps.
- What evidence would resolve it: Experiments showing the performance of inductive CoS on tasks with an increasing number of reasoning steps, identifying the point at which the approach becomes computationally infeasible or ineffective.

## Limitations

- Dataset specification gaps exist, particularly in Bézier curve calculations for strings and maze wall insertion logic for disconnected components
- Analysis of computational complexity and training efficiency across different model sizes is limited
- All tasks are synthetic with clear geometric structures, limiting generalizability to real-world visual reasoning problems

## Confidence

- **High Confidence**: The core mechanism of chain-of-sketch reducing globality degree for intermediate steps is well-supported by both theoretical analysis and experimental evidence
- **Medium Confidence**: The superiority of inductive CoS for OOD generalization is demonstrated on synthetic tasks, but the Markovian assumption needs further validation
- **Medium Confidence**: The claim that CoS enables smaller models to learn tasks that larger models cannot learn without CoS is supported but could be strengthened by more systematic ablation studies

## Next Checks

1. **Dataset Implementation Verification**: Implement the dataset generation code for all four tasks, paying particular attention to the Bézier curve calculations for strings and maze wall insertion logic. Compare generated samples against the paper's examples to ensure correct implementation.

2. **No-CoS Baseline Performance Analysis**: Train the No-CoS baseline on the cycles 12 task across all model sizes (Small, Base, Large, Huge) and analyze the learning curves. This will validate whether the globality degree analysis correctly predicts the learning difficulty and whether smaller models indeed struggle more than larger ones.

3. **OOD Generalization Stress Test**: Extend the OOD evaluation beyond cycles 16 to include even longer cycles (e.g., cycles 20, 24) and test whether inductive CoS maintains its performance advantage. Additionally, test the same inductive CoS model on strings and mazes to assess cross-task generalization of the reasoning patterns learned.