---
ver: rpa2
title: Persuasion Games using Large Language Models
arxiv_id: '2408.15879'
source_url: https://arxiv.org/abs/2408.15879
tags:
- user
- agent
- persuasion
- insurance
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a multi-agent framework for persuasion using
  large language models (LLMs). The framework includes a primary sales agent that
  engages in persuasive dialogue with user agents, supported by auxiliary agents for
  information retrieval, response analysis, and strategy development.
---

# Persuasion Games using Large Language Models

## Quick Facts
- arXiv ID: 2408.15879
- Source URL: https://arxiv.org/abs/2408.15879
- Reference count: 40
- Primary result: Multi-agent LLM persuasion framework achieved 71% positive perspective shift in baseline, reducing to 56% with emotion modifiers

## Executive Summary
This paper introduces a multi-agent framework leveraging large language models for persuasive dialogue across insurance, banking, and retail domains. The system employs specialized agents including a primary sales agent, advisor, moderator, and retrieval agent to engage with user personas while adapting to emotional states and resistance strategies. Through experiments with 25 simulated user personas and 300 conversations, the framework demonstrated significant persuasion effectiveness measured through surveys, user actions, and LLM-generated quality scores.

## Method Summary
The research developed a four-agent LLM system where a primary sales agent engages in persuasive dialogue while auxiliary agents handle information retrieval, strategy development, and response validation. The framework analyzes user emotions and resistance strategies in real-time, adapting persuasion approaches accordingly. Experiments were conducted across three domains using 25 user personas with varying emotional states, measuring persuasion effectiveness through pre/post surveys, binary action decisions (buy/visit/no-buy), and LLM-generated conversation quality metrics. A/B testing compared baseline neutral scenarios against emotion-modifier enabled conditions.

## Key Results
- Sales agents achieved 71% positive shift in user perspectives in baseline scenarios
- Persuasion effectiveness dropped to 56% when emotion modifiers were introduced
- System induced positive purchase decisions in 35% of baseline conversations and 28% with emotion modifiers enabled

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The multi-agent framework improves persuasion by separating concerns into specialized roles (conversation agent, advisor agent, moderator, retrieval agent).
- Mechanism: Specialized agents handle different tasks - the conversation agent manages dialogue flow, advisor agent provides strategy input, moderator validates responses, and retrieval agent fetches relevant information. This division allows parallel processing and reduces cognitive load on any single agent.
- Core assumption: Task specialization leads to better overall performance than a monolithic agent approach.
- Evidence anchors:
  - [abstract]: "a consortium of agents operate in collaborative manner. The primary agent engages directly with user agents through persuasive dialogue, while the auxiliary agents perform tasks such as information retrieval, response analysis, development of persuasion strategies, and validation of facts."
  - [section]: "The chat application consists of 4 different agents; Conversation agent, Advisor Agent, Moderator and a Retrieval Agent."
- Break condition: If communication overhead between agents exceeds the benefits of specialization, or if agents provide conflicting information.

### Mechanism 2
- Claim: Real-time emotion and resistance analysis enables adaptive persuasion strategies.
- Mechanism: The system continuously analyzes user messages for emotional states and resistance strategies (counterarguments, source derogation, reactance, etc.) and maps these to appropriate persuasion counter-strategies using rule-based or LLM-based techniques.
- Core assumption: Detecting and responding to user resistance in real-time improves persuasion outcomes compared to static approaches.
- Evidence anchors:
  - [abstract]: "We continuously analyze the resistance of the user agent to persuasive efforts and counteract it by employing a combination of rule-based and LLM-based resistance-persuasion mapping techniques."
  - [section]: "The analyzer agent tries to classify the emotion, resistance strategies if any from the last user message."
- Break condition: If emotion detection is inaccurate or if the resistance-persuasion mapping fails to account for complex user motivations.

### Mechanism 3
- Claim: Action-driven metrics provide more concrete measures of persuasion effectiveness than linguistic analysis alone.
- Mechanism: The system measures persuasion through binary user actions (buy, visit site, no-buy) combined with pre/post surveys and LLM-generated conversation quality scores, with action weighted most heavily in the final score.
- Core assumption: User decisions to take specific actions are stronger indicators of persuasion success than linguistic features alone.
- Evidence anchors:
  - [abstract]: "Persuasion is quantified via measurable surveys before and after interaction, LLM-generated scores on conversation, and user decisions (purchase or non-purchase)."
  - [section]: "We measure the effectiveness of persuasion using 3 different metrics... Action: We also measure the 'call for action' based metric by providing the users with a set of purchase decision to choose from."
- Break condition: If users take actions for reasons unrelated to persuasion (external factors, technical issues, etc.) or if the action options don't capture nuanced user responses.

## Foundational Learning

- Concept: Multi-agent systems and task decomposition
  - Why needed here: Understanding how specialized agents can collaborate to solve complex problems like persuasive dialogue
  - Quick check question: What are the advantages and disadvantages of using multiple specialized agents versus a single monolithic agent for a complex task?

- Concept: Persuasion resistance strategies and countermeasures
  - Why needed here: The system must recognize when users resist persuasion and adapt accordingly
  - Quick check question: What are the main categories of resistance strategies identified in persuasion research, and how might each be countered?

- Concept: Emotion detection and sentiment analysis
  - Why needed here: The framework adapts its approach based on detected user emotions
  - Quick check question: How can emotional states influence a person's susceptibility to persuasion, and what techniques can be used to detect emotions from text?

## Architecture Onboarding

- Component map: Conversation Agent → Advisor Agent → Moderator → Retrieval Agent → User Agent → Fact Checker
- Critical path: User message → Analyzer (emotion/resistance detection) → Strategist (counter-strategy selection) → Sales Agent (response generation) → Fact Checker (validation) → User
- Design tradeoffs: Specialized agents provide better performance but add communication overhead and complexity; real-time analysis improves adaptation but requires more computational resources
- Failure signatures: Agent miscommunication leading to inconsistent responses; failure to detect resistance leading to ineffective persuasion; over-reliance on one metric (e.g., linguistic analysis) while ignoring others
- First 3 experiments:
  1. Run baseline conversations with only the primary sales agent (no auxiliary agents) to establish performance without the multi-agent framework
  2. Enable only the emotion detection and resistance analysis components to measure the impact of adaptive strategies
  3. Test different weighting schemes for the final persuasion score to optimize the balance between action metrics, surveys, and linguistic analysis

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do specific persuasion strategies (e.g., rational persuasion vs. emotional appeal) perform differently across various user emotions and resistance strategies?
- Basis in paper: [explicit] The paper mentions using different persuasion strategies based on user resistance but does not compare their relative effectiveness across different emotional states.
- Why unresolved: The paper reports overall persuasion success rates but does not analyze which specific strategies work best for particular combinations of user emotions and resistance behaviors.
- What evidence would resolve it: A detailed analysis showing conversion rates for each persuasion strategy type (rational, emotional, social proof, etc.) across different user emotional states and resistance strategies.

### Open Question 2
- Question: What is the long-term impact of LLM-driven persuasion on user belief systems and future purchasing decisions?
- Basis in paper: [inferred] The paper mentions updating user knowledge bases after conversations but does not measure whether these changes persist or influence future interactions.
- Why unresolved: The experimental design only measures immediate post-conversation changes without tracking users over time or across multiple sessions to see if persuasion effects endure.
- What evidence would resolve it: Longitudinal studies tracking the same user personas across multiple conversation sessions over time, measuring belief persistence and cumulative persuasion effects.

### Open Question 3
- Question: How does the multi-agent framework's performance compare to single-agent LLM systems without auxiliary support?
- Basis in paper: [explicit] The paper mentions using A/B testing to compare with and without auxiliary agents but does not report these comparative results.
- Why unresolved: The experimental results only show performance of the full multi-agent system without baseline comparisons to simpler single-agent approaches.
- What evidence would resolve it: Direct performance comparisons between the multi-agent system and equivalent single-agent LLM systems on the same conversation tasks and user personas.

### Open Question 4
- Question: What are the ethical implications and potential harms of deploying LLM persuasion systems in real-world scenarios?
- Basis in paper: [inferred] The paper acknowledges persuasion applications in sensitive domains like insurance and finance but does not address ethical considerations or potential misuse.
- Why unresolved: The research focuses on technical effectiveness without examining the broader societal impact, potential for manipulation, or need for ethical safeguards.
- What evidence would resolve it: Analysis of potential negative consequences, guidelines for ethical deployment, and frameworks for preventing misuse in sensitive application areas.

## Limitations

- Reliance on simulated user personas rather than real human participants may not capture genuine human complexity
- Significant communication overhead and coordination complexity in multi-agent framework not fully quantified
- Emotion detection and resistance analysis accuracy depends on underlying NLP models, introducing potential cascading errors

## Confidence

- **High confidence**: The multi-agent framework architecture and its basic operational principles are well-specified and supported by experimental results showing measurable improvements in persuasion outcomes.
- **Medium confidence**: The effectiveness of emotion and resistance analysis in improving persuasion, as the paper demonstrates correlation but doesn't fully isolate this mechanism from other factors.
- **Low confidence**: The generalizability of results across different domains and real-world scenarios, given the use of simulated personas and controlled experimental conditions.

## Next Checks

1. **External validation**: Test the persuasion framework with actual human participants across the same three domains to compare performance against simulated personas and validate the external validity of findings.

2. **Ablation study**: Systematically disable individual auxiliary agents (advisor, moderator, retrieval) in controlled experiments to quantify their specific contributions to persuasion effectiveness and identify the most critical components.

3. **Longitudinal testing**: Conduct extended conversations beyond 20 turns and measure persuasion effectiveness over multiple interaction sessions to assess whether initial success translates to sustained persuasion outcomes.