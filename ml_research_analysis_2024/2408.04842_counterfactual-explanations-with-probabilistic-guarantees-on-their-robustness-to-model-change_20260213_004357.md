---
ver: rpa2
title: Counterfactual Explanations with Probabilistic Guarantees on their Robustness
  to Model Change
arxiv_id: '2408.04842'
source_url: https://arxiv.org/abs/2408.04842
tags:
- betarce
- robustness
- robust
- counterfactual
- base
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a probabilistic framework for assessing\
  \ counterfactual robustness to model change, defining (\u03B4, \u03B1)-robustness\
  \ where counterfactuals maintain their validity with probability \u03B4 at confidence\
  \ level \u03B1. The authors propose BETARCE, a post-hoc method that enhances robustness\
  \ by moving counterfactuals toward more stable regions using a Bayesian approach."
---

# Counterfactual Explanations with Probabilistic Guarantees on their Robustness to Model Change

## Quick Facts
- arXiv ID: 2408.04842
- Source URL: https://arxiv.org/abs/2408.04842
- Reference count: 40
- Primary result: BETARCE achieves probabilistic guarantees on counterfactual robustness with interpretable hyperparameters

## Executive Summary
This paper addresses the critical issue of counterfactual explanation (CFE) robustness to model changes by introducing a probabilistic framework for quantifying and enhancing robustness guarantees. The authors define (δ, α)-robustness, where counterfactuals maintain their validity with probability δ at confidence level α, and propose BETARCE, a post-hoc method that enhances robustness by moving counterfactuals toward more stable regions using a Bayesian approach. The method demonstrates superior robustness compared to baselines while preserving explanation quality across multiple datasets and model types.

## Method Summary
BETARCE is a post-hoc method that takes an existing counterfactual generated by any base method and iteratively moves it in feature space until it satisfies (δ, α)-robustness. The approach uses Bayesian posterior estimation with Beta-Bernoulli conjugacy to estimate the probability that a counterfactual remains valid under model changes. The method samples from the space of admissible models and uses bootstrap verification to calculate credible intervals, enabling probabilistic guarantees on robustness. BETARCE maintains the properties of the base counterfactual while ensuring validity and robustness through GROWING SPHERES optimization.

## Key Results
- BETARCE successfully generates counterfactuals meeting probabilistic robustness bounds across different model change scenarios
- The method demonstrates superior empirical robustness compared to baselines while maintaining better proximity to original explanations
- BETARCE achieves 100% Empirical Robustness on several datasets while baselines fail to reach this threshold
- The approach requires minimal hyperparameter tuning with only three interpretable parameters (δ, α, k)

## Why This Works (Mechanism)

### Mechanism 1: Bayesian posterior estimation of robustness probability
- **Claim:** BETARCE achieves probabilistic guarantees on counterfactual robustness by leveraging Bayesian posterior estimation of robustness probability δ using a Beta distribution as conjugate prior for Bernoulli trials.
- **Core assumption:** The space of admissible models can be sampled to approximate the true distribution of model changes, and robustness is a binary random variable following a Bernoulli distribution.
- **Evidence anchors:** The paper establishes theoretical framework for (δ, α)-robustness and demonstrates how BETARCE stems from this theory using Beta distribution for confidence estimation.

### Mechanism 2: Post-hoc enhancement preserving base properties
- **Claim:** BETARCE's post-hoc nature preserves the properties of the base counterfactual while adding robustness guarantees.
- **Core assumption:** Small perturbations in feature space can move a counterfactual to a more robust region while maintaining its validity and proximity to the original input.
- **Evidence anchors:** BETARCE is described as taking an existing counterfactual and making small perturbations to enhance robustness beyond what the base method provides.

### Mechanism 3: Interpretable hyperparameter control
- **Claim:** BETARCE's three interpretable hyperparameters (δ, α, k) provide intuitive control over robustness guarantees without requiring extensive tuning.
- **Core assumption:** Users can meaningfully interpret and select these statistical parameters based on their needs, with δmax formula accurately reflecting achievable robustness.
- **Evidence anchors:** The paper emphasizes that BETARCE's parametrization is tied to probabilistic expectations, enabling users to select expected robustness more naturally than methods requiring extensive tuning of not-interpretable hyperparameters.

## Foundational Learning

- **Concept: Bayesian posterior estimation with Beta-Bernoulli conjugacy**
  - Why needed here: BETARCE relies on estimating the probability that a counterfactual remains valid under model changes using Bayesian methods with Beta prior and Bernoulli likelihood.
  - Quick check question: Why is the Beta distribution the natural choice for modeling uncertainty about a probability parameter in a Bernoulli process?

- **Concept: Counterfactual explanation properties (validity, proximity, plausibility)**
  - Why needed here: BETARCE must maintain these core properties while adding robustness, so understanding their definitions and tradeoffs is essential for proper implementation and evaluation.
  - Quick check question: How does the concept of plausibility differ from proximity in counterfactual explanations, and why might both be important for practical use?

- **Concept: Model-agnostic approaches in explainable AI**
  - Why needed here: BETARCE is designed to work with any underlying model type, requiring understanding of how to query black-box models without relying on model-specific internals.
  - Quick check question: What are the key challenges in designing a method that works with any machine learning model, and how does BETARCE address them?

## Architecture Onboarding

- **Component map:** Base CFE generator (e.g., DICE, GROWING SPHERES) -> BETARCE wrapper -> Bootstrap verification module -> GROWING SPHERES optimizer -> Admissible model space sampler
- **Critical path:** 1) Generate base counterfactual using chosen method, 2) Initialize warmup phase of GROWING SPHERES to find lower bound on distance, 3) Iteratively sample candidates in expanding sphere, 4) For each candidate, check validity and robustness using bootstrap verification, 5) Return first valid and robust counterfactual found
- **Design tradeoffs:** Number of estimators k vs. computational cost (higher k gives more precise estimates but increases runtime); choice of base CFE method vs. final counterfactual properties; sphere expansion parameters (η, n) affect search efficiency and solution quality
- **Failure signatures:** High distance to base counterfactual indicates poor preservation of base CFE properties; empirical robustness consistently below theoretical lower bound suggests issues with bootstrap estimation; very long optimization times may indicate poor choice of initial sphere radius or sampling parameters
- **First 3 experiments:** 1) Validate (δ, α)-robustness bounds hold in practice using synthetic data with known model changes, 2) Test sensitivity of BETARCE to hyperparameter choices (δ, α, k) on a simple dataset, 3) Compare empirical robustness achieved by BETARCE vs. baseline methods on a standard benchmark dataset

## Open Questions the Paper Calls Out

### Open Question 1: Sensitivity to base CFE method choice
- Question: How sensitive is BETARCE's performance to the choice of the base CFE generation method when different user requirements for explanation properties are prioritized?
- Basis in paper: The paper states "the selection of the most appropriate counterfactual strongly depends on user preferences" but does not empirically compare different base methods.
- Why unresolved: Experiments only use DICE and GROWING SPHERES without comparing against other popular methods like FACE or WACHTER.
- What evidence would resolve it: Systematic experiments comparing BETARCE with multiple base CFE generation methods across different datasets and user preference scenarios.

### Open Question 2: Theoretical relationship between k and δmax
- Question: What is the theoretical relationship between the number of estimators k and the maximum verifiable δ, and how does this relationship change with different prior distributions?
- Basis in paper: Theorem 2 provides a formula for δmax but the proof sketch is incomplete, and the paper only uses Jeffreys prior without exploring how different priors affect the relationship.
- Why unresolved: The paper provides the formula but does not fully prove it or explore how different prior distributions would affect the maximum achievable robustness guarantees.
- What evidence would resolve it: Complete mathematical proof of Theorem 2 with detailed derivation, and experimental validation across different prior distributions.

### Open Question 3: Performance with misdefined admissible model space
- Question: How does BETARCE perform when the space of admissible model changes is misdefined or contains model changes that are substantially different from those encountered during training?
- Basis in paper: The paper mentions additional experiments in Appendix F.4 investigating this scenario, finding that while probabilistic bounds don't hold for out-of-distribution changes, BETARCE often still provides practical robustness.
- Why unresolved: The appendix results show BETARCE generalizes reasonably well to different model change types, but the paper does not provide a systematic framework for quantifying the degradation in robustness guarantees when the admissible model space is misspecified.
- What evidence would resolve it: Theoretical analysis of how robustness guarantees degrade with increasing divergence between training and testing model change spaces.

## Limitations
- Performance on categorical and mixed-type features not evaluated
- Scalability to high-dimensional feature spaces not tested
- Dependence on quality of base counterfactuals may limit effectiveness when base CFEs are already in unstable regions
- Experimental focus on tabular data with numerical features only

## Confidence

- **Theoretical framework for (δ, α)-robustness:** High
- **BETARCE implementation and optimization:** Medium
- **Empirical results across diverse scenarios:** Medium

## Next Checks

1. Test BETARCE on datasets with categorical features to assess handling of mixed data types
2. Evaluate scalability by testing on high-dimensional datasets (>100 features)
3. Compare performance when using different base CFE methods as input to BETARCE