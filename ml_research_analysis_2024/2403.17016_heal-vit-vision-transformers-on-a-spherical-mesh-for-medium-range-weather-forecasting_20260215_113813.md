---
ver: rpa2
title: 'HEAL-ViT: Vision Transformers on a spherical mesh for medium-range weather
  forecasting'
arxiv_id: '2403.17016'
source_url: https://arxiv.org/abs/2403.17016
tags:
- mesh
- nodes
- heal-vit
- each
- grid
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents HEAL-ViT, a novel Vision Transformer (ViT)
  architecture for medium-range weather forecasting that operates on a spherical mesh.
  Unlike traditional ViT models that use rectilinear grids (which distort data near
  the poles), HEAL-ViT uses the HEALPix mesh to represent weather data more efficiently
  on a sphere.
---

# HEAL-ViT: Vision Transformers on a spherical mesh for medium-range weather forecasting

## Quick Facts
- arXiv ID: 2403.17016
- Source URL: https://arxiv.org/abs/2403.17016
- Authors: Vivek Ramavajjala
- Reference count: 5
- Key outcome: Novel Vision Transformer architecture using HEALPix spherical mesh achieves comparable RMSE to GraphCast and FuXi while using 25% fewer nodes, 15% fewer attention windows, and improving bias accumulation and blurring metrics

## Executive Summary
HEAL-ViT introduces a novel Vision Transformer architecture for medium-range weather forecasting that operates on a spherical HEALPix mesh rather than traditional rectilinear grids. By representing weather data on an equal-area spherical mesh, the model eliminates pole distortion while maintaining computational efficiency through reduced node and window counts. The architecture maps weather data between longitude-latitude grids and HEALPix representations using graph networks, processes it with SWIN transformers featuring shifted windows, and maps results back to standard grids.

## Method Summary
HEAL-ViT uses a three-component architecture: an encoder that maps 721×1440 rectilinear grid data (110 channels including 54 features × 2 time steps + 2 static features) to a HEALPix mesh (49,152 nodes × 256 channels) via bipartite graph networks, a processor that uses U-Net architecture with SWIN transformers (2 blocks → downsample → 48 blocks → upsample → 2 blocks) maintaining the spherical representation, and a decoder that maps back to the rectilinear grid (54 output channels). The model is pre-trained for 80k steps then fine-tuned with a 4-step auto-regressive curriculum using AdamW optimizer with weight decay, minimizing latitude-weighted L1 loss.

## Key Results
- Achieves comparable RMSE to leading models GraphCast and FuXi
- Uses 25% fewer nodes (49,152 vs 64,800) and 15% fewer attention windows than rectilinear approaches
- Outperforms baselines in bias accumulation and reduces blurring as measured by zonal energy spectra
- Maintains equal-area representation across the sphere, eliminating pole distortion

## Why This Works (Mechanism)

### Mechanism 1
- Claim: HEAL-ViT reduces pole distortion by using a spherical mesh where each node represents equal area, unlike rectilinear grids where nodes near poles represent much smaller areas.
- Mechanism: The HEALPix mesh divides the sphere into equal-area quadrilateral pixels at all refinement levels. This spatial homogeneity means attention windows contain the same "true" area of weather data regardless of latitude, avoiding the disproportionate computational load at poles seen in rectilinear approaches.
- Core assumption: Equal-area pixelation provides sufficient spatial resolution for weather forecasting while eliminating polar distortion.
- Evidence anchors:
  - [abstract]: "weather data is inherently spherical and thus heavily distorted at the poles on a rectilinear grid, leading to disproportionate compute being used to model data near the poles"
  - [section]: "As all HEALPix windows have equal area, all mesh nodes attend on equal amounts of input context. In contrast, on a rectilinear grid, even though all windows contain the same number of mesh nodes, windows near the poles represent smaller areas which reduces the 'true' context for self-attention near the poles"
  - [corpus]: Weak - related papers discuss transformer architectures but don't specifically address spherical mesh advantages for pole distortion
- Break condition: If weather phenomena require higher resolution at specific latitudes than equal-area sampling provides, or if the HEALPix subdivision creates artifacts in weather pattern representation.

### Mechanism 2
- Claim: HEAL-ViT achieves computational efficiency by reducing both the number of nodes and attention windows compared to rectilinear approaches while maintaining or improving forecast quality.
- Mechanism: The HEAL-ViT architecture uses refinement level n=26 with 49,152 nodes versus rectilinear meshes with 64,800 nodes (25% reduction). Window parameter w=3 creates 768 windows versus 900 in rectilinear approaches (15% reduction), while each node represents smaller area (0.91° × 0.91° vs 1° × 1° at equator).
- Core assumption: Reducing nodes and windows while maintaining adequate resolution provides computational savings without sacrificing forecast accuracy.
- Evidence anchors:
  - [section]: "Compared to the rectilinear mesh, the HEAL-ViT mesh has 25% fewer nodes while also having each node represent a smaller area. 15% fewer windows are needed to cover the mesh, while being of a similar size to the windows in the rectilinear mesh"
  - [abstract]: "It also uses 25% fewer nodes and 15% fewer attention windows than rectilinear mesh approaches, making it more computationally efficient"
  - [corpus]: Weak - related papers discuss transformer efficiency but not specifically the computational benefits of spherical mesh reduction
- Break condition: If the reduced node count creates insufficient resolution for capturing critical weather features, or if the window reduction impairs the model's ability to learn long-distance relationships.

### Mechanism 3
- Claim: HEAL-ViT improves forecast quality by reducing bias accumulation and blurring compared to other ML weather prediction models.
- Mechanism: The combination of spherical mesh uniformity and transformer attention mechanisms allows HEAL-ViT to better capture weather dynamics without the distortions that lead to bias accumulation and spectral blurring in other approaches.
- Core assumption: The spherical mesh and attention architecture together provide better representation of weather dynamics than either graph-based or rectilinear transformer approaches alone.
- Evidence anchors:
  - [abstract]: "HEAL-ViT achieves comparable RMSE to leading models like GraphCast and FuXi while outperforming them in bias accumulation and reducing blurring (as measured by zonal energy spectra)"
  - [section]: "HEAL-ViT is comparable in performance with other MLWPs in terms of error reduction, but shows improved performance in both bias accumulation and blurring, as measured by zonal energy spectra"
  - [corpus]: Weak - related papers discuss bias and blurring but don't provide direct comparisons with HEAL-ViT
- Break condition: If the spherical mesh introduces new types of bias or if the attention mechanism fails to adequately capture the complex dynamics of weather systems.

## Foundational Learning

- Concept: Spherical geometry and coordinate systems
  - Why needed here: Understanding why rectilinear grids distort weather data at poles requires grasping spherical geometry fundamentals
  - Quick check question: Why does a rectilinear grid (latitude-longitude) create distortion at the poles while a spherical mesh like HEALPix does not?

- Concept: Transformer architectures and attention mechanisms
  - Why needed here: HEAL-ViT uses SWIN transformers with shifted windows, requiring understanding of how attention mechanisms work and their computational complexity
  - Quick check question: How does shifting windows in SWIN transformers allow cross-window connections while maintaining computational efficiency?

- Concept: Graph neural networks and message passing
  - Why needed here: The encoder and decoder use graph networks to map between rectilinear and spherical representations
  - Quick check question: How does a bipartite graph connect longitude-latitude grid nodes to HEALPix mesh nodes, and why is this mapping necessary?

## Architecture Onboarding

- Component map: Input (110-channel rectilinear grid) → Encoder (graph network) → Processor (SWIN transformer blocks) → Decoder (graph network) → Output (54-channel rectilinear grid)

- Critical path: Encoder → Processor (SWIN blocks with window shifting) → Decoder, with spherical mesh representation maintained throughout processing

- Design tradeoffs: 
  - Equal-area HEALPix mesh vs. computational complexity of spherical transformations
  - Window size parameter w balancing local context vs. computational efficiency
  - 256 latent channels vs. model capacity and memory constraints
  - 4-step auto-regressive fine-tuning vs. longer sequences for stability

- Failure signatures:
  - Pole distortion artifacts in forecasts indicate encoder/decoder mapping issues
  - Excessive memory usage suggests window parameter w too large or refinement level n too high
  - Poor RMSE with good ACC indicates bias accumulation problems
  - Spectral blurring suggests processor not capturing small-scale dynamics

- First 3 experiments:
  1. Compare RMSE and bias accumulation of HEAL-ViT vs. baseline rectilinear transformer on T2M variable only, using single A100 GPU to verify computational efficiency claims
  2. Test different window size parameters (w=2, w=3, w=4) on computational cost and forecast quality to find optimal tradeoff
  3. Implement and test simplified encoder/decoder using nearest-neighbor mapping instead of bipartite graphs to isolate processor performance impact

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does HEAL-ViT's performance compare to other MLWPs when initialized at 00UTC and 12UTC, similar to GraphCast?
- Basis in paper: [explicit] The paper notes that GraphCast is initialized at both 00UTC and 12UTC, while other MLWPs including HEAL-ViT are only initialized at 00UTC. The authors state that a like-for-like comparison is difficult due to this difference in initialization.
- Why unresolved: The paper does not provide performance metrics for HEAL-ViT when initialized at 12UTC, making it impossible to directly compare its performance to GraphCast under the same initialization conditions.
- What evidence would resolve it: Evaluating HEAL-ViT's performance when initialized at both 00UTC and 12UTC and comparing the results to GraphCast's performance under the same conditions.

### Open Question 2
- Question: What is the impact of incorporating prior knowledge about the absolute relative positions of mesh and grid nodes in the encoder and decoder components of HEAL-ViT?
- Basis in paper: [explicit] The authors mention that the encoder and decoder use rudimentary graphs that do not contain any prior knowledge about the absolute relative positions of mesh and grid nodes, unlike the graphs used by GraphCast. They suggest that incorporating such inductive biases could improve the quality of the encoder, decoder, and overall model.
- Why unresolved: The paper does not provide any experimental results or analysis of how incorporating prior knowledge about the absolute relative positions of mesh and grid nodes would affect the performance of HEAL-ViT.
- What evidence would resolve it: Implementing and evaluating HEAL-ViT with encoder and decoder components that incorporate prior knowledge about the absolute relative positions of mesh and grid nodes, and comparing the results to the current implementation.

### Open Question 3
- Question: How would incorporating advancements made in the field of computer vision, such as learnable relative position biases, post-layer normalization, scaled cosine attention, and scheduled DropPath, affect the performance of HEAL-ViT?
- Basis in paper: [explicit] The authors suggest that any improvements made to ViT architectures, including the incorporation of advancements made in the field of computer vision, are likely to improve the performance of HEAL-ViT as well.
- Why unresolved: The paper does not provide any experimental results or analysis of how incorporating these specific advancements would affect the performance of HEAL-ViT.
- What evidence would resolve it: Implementing and evaluating HEAL-ViT with the incorporation of learnable relative position biases, post-layer normalization, scaled cosine attention, and scheduled DropPath, and comparing the results to the current implementation.

## Limitations

- The computational efficiency claims lack detailed runtime benchmarks comparing HEAL-ViT to baseline approaches on identical hardware configurations
- The paper doesn't extensively validate performance on extreme weather events or rare phenomena that might stress the spherical mesh representation
- Real-world deployment considerations such as training stability across different weather regimes and model generalization to climate change scenarios are not addressed

## Confidence

**High Confidence**: The core architectural innovation of using HEALPix mesh for weather forecasting is well-supported by the mathematical foundations of spherical geometry and the clear problem statement about polar distortion in rectilinear grids. The 25% node reduction and 15% window reduction are directly verifiable from the mesh specifications provided.

**Medium Confidence**: Claims about improved bias accumulation and reduced blurring are supported by comparisons to GraphCast and FuXi, but the paper doesn't provide ablation studies isolating the impact of the spherical mesh versus the transformer architecture itself. The computational efficiency gains are plausible but not rigorously benchmarked.

**Low Confidence**: The paper's claims about operational readiness and scalability to production weather forecasting systems lack concrete validation. While the architecture is theoretically sound, real-world deployment considerations such as training stability across different weather regimes and model generalization to climate change scenarios are not addressed.

## Next Checks

1. **Ablation study on mesh vs. transformer contributions**: Train and evaluate three variants - (a) HEAL-ViT with spherical mesh and transformer, (b) rectilinear mesh with same transformer architecture, and (c) spherical mesh with simplified CNN architecture. This would isolate whether the spherical mesh or the transformer design drives the performance improvements.

2. **Computational benchmarking on identical hardware**: Implement HEAL-ViT and a baseline rectilinear transformer model on the same GPU configuration (e.g., A100-80GB) and measure training throughput, inference latency, and memory usage across different batch sizes and sequence lengths. Include wall-clock time for training to convergence.

3. **Stress testing on extreme weather events**: Evaluate HEAL-ViT's performance on historical extreme weather events (hurricanes, heat waves, polar vortexes) and compare against baseline models. Measure both accuracy metrics and the model's ability to correctly predict event onset, duration, and intensity. This would validate the architecture's robustness beyond average-case performance.