---
ver: rpa2
title: Random Representations Outperform Online Continually Learned Representations
arxiv_id: '2402.08823'
source_url: https://arxiv.org/abs/2402.08823
tags:
- learning
- continual
- randumb
- online
- random
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper challenges the assumption that online continual learning
  algorithms produce superior representations by comparing them to a simple random
  projection method. The proposed RanDumb approach projects raw pixels using fixed
  random Fourier features (approximating an RBF kernel) and trains a linear classifier
  using Mahalanobis distance and nearest class mean.
---

# Random Representations Outperform Online Continually Learning Representations

## Quick Facts
- arXiv ID: 2402.08823
- Source URL: https://arxiv.org/abs/2402.08823
- Reference count: 40
- Primary result: Random projections outperform state-of-the-art continual learning methods

## Executive Summary
This paper challenges the prevailing assumption that online continual learning algorithms produce superior representations by introducing a simple random projection method called RanDumb. The approach uses fixed random Fourier features to approximate an RBF kernel and trains a linear classifier using Mahalanobis distance and nearest class mean. Despite its simplicity, RanDumb consistently outperforms sophisticated online continual learning methods across multiple benchmarks. The findings suggest that current continual learning benchmarks may be overly constrained and that representation learning in continual learning scenarios is less effective than previously assumed.

## Method Summary
The RanDumb method projects raw pixel inputs using fixed random Fourier features to approximate an RBF kernel, then trains a linear classifier using Mahalanobis distance with nearest class mean classification. The approach requires no backpropagation during training and uses only the exemplar budget specified by each benchmark. Random Fourier features are generated once and kept fixed throughout training, making the method computationally efficient and straightforward to implement. The simplicity of the approach stands in stark contrast to the complex continual learning methods it outperforms.

## Key Results
- RanDumb outperforms state-of-the-art online continual learning methods across multiple benchmarks
- Random representations match or exceed learned representations in low-exemplar and online settings
- Current continual learning benchmarks may be overly constrained, limiting the effectiveness of learned representations

## Why This Works (Mechanism)
The effectiveness of random projections stems from the universal approximation properties of random Fourier features when approximating RBF kernels. By projecting data into a higher-dimensional space through random Fourier features, the method implicitly creates a feature space where linear separation becomes more feasible. The nearest class mean classification with Mahalanobis distance then provides a simple yet effective way to classify in this transformed space without requiring complex optimization or backpropagation.

## Foundational Learning
- Random Fourier Features: Used to approximate RBF kernels through random projections; needed because direct RBF computation is expensive, quick check: verify kernel approximation quality
- Mahalanobis Distance: Measures distance between points in a metric space accounting for correlations; needed for scale-invariant classification, quick check: validate distance metric properties
- Nearest Class Mean: Simple classification strategy assigning points to closest class centroid; needed for computational efficiency, quick check: test centroid stability across tasks

## Architecture Onboarding

**Component Map:**
Raw pixels -> Random Fourier Features -> Mahalanobis Distance + Nearest Class Mean Classifier

**Critical Path:**
1. Input preprocessing (normalization)
2. Random Fourier feature projection
3. Class mean calculation per task
4. Mahalanobis distance computation during inference
5. Nearest class mean classification

**Design Tradeoffs:**
- Fixed random features vs. learned representations (simplicity vs. adaptability)
- No backpropagation vs. gradient-based optimization (speed vs. potential performance)
- Linear classifier vs. complex neural networks (efficiency vs. representational power)

**Failure Signatures:**
- Poor performance on datasets requiring complex feature interactions
- Sensitivity to kernel width hyperparameter selection
- Degraded accuracy when class distributions overlap significantly in random feature space

**First 3 Experiments to Run:**
1. Ablation study varying random feature dimensionality
2. Sensitivity analysis for RBF kernel width parameter
3. Comparison against non-continual learning baselines

## Open Questions the Paper Calls Out
None

## Limitations
- Results primarily validated in low-exemplar and online settings; generalizability to resource-rich scenarios unclear
- Benchmark selection may not capture full complexity of real-world continual learning scenarios
- Random Fourier features require careful kernel width tuning, potentially offsetting simplicity advantages

## Confidence
- Random representations outperforming learned ones: Medium
- Method's simplicity advantage: High
- Benchmark validity critique: Medium
- Generalizability to complex scenarios: Low

## Next Checks
1. Test RanDumb on more complex, long-tailed distributions and real-world datasets (e.g., CORe50) with varying exemplar budgets
2. Investigate sensitivity of performance to random projection dimensionality and kernel width parameters
3. Compare against non-continual learning baselines to determine if advantage stems from continual learning or general representation quality