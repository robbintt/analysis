---
ver: rpa2
title: Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information
  Retrieval
arxiv_id: '2407.03585'
source_url: https://arxiv.org/abs/2407.03585
tags:
- user
- chatbot
- children
- persuabot
- save
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PersuaBot, a zero-shot persuasive chatbot
  that leverages Large Language Models (LLMs) to generate natural responses and extract
  persuasion strategies. To ensure factual accuracy, the chatbot uses information
  retrieval to replace unsubstantiated claims in the LLM-generated responses with
  verified facts.
---

# Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval

## Quick Facts
- arXiv ID: 2407.03585
- Source URL: https://arxiv.org/abs/2407.03585
- Reference count: 13
- Primary result: Zero-shot persuasive chatbot achieving up to 26.6% improvement in factuality while maintaining persuasiveness across three domains

## Executive Summary
This paper introduces PersuaBot, a zero-shot persuasive chatbot that leverages Large Language Models (LLMs) to generate natural responses and extract persuasion strategies. To ensure factual accuracy, the chatbot uses information retrieval to replace unsubstantiated claims in the LLM-generated responses with verified facts. Experiments across three domains—donation solicitation, recommendations, and health intervention—demonstrate that PersuaBot is more persuasive than existing methods while achieving higher factual accuracy than state-of-the-art knowledge-oriented chatbots.

## Method Summary
PersuaBot uses an LLM to generate initial persuasive responses, then extracts strategies from these responses. A fact-checking module evaluates each claim against an external corpus, replacing unsupported claims with retrieved facts that maintain the original persuasive intent. The system employs a dual-module architecture with Strategy Maintenance Module (SMM) for strategy preservation and Question Handling Module (QHM) for user queries. The approach adapts seamlessly to different domains without requiring task-specific training data.

## Key Results
- Achieved up to 26.6% improvement in factuality compared to knowledge-oriented chatbots
- Demonstrated domain adaptation across three different tasks (donation, recommendations, health) using the same pipeline
- Outperformed existing persuasive chatbots in persuasiveness while maintaining higher factual accuracy

## Why This Works (Mechanism)

### Mechanism 1: Strategy Extraction + Fact-Check Pipeline
PersuaBot maintains persuasive intent while improving factuality by extracting strategies from LLM responses and replacing unsubstantiated claims with retrieved facts. The pipeline generates a response, decomposes it into strategy-labeled sections, checks factual claims against an external corpus, and retrieves replacement facts that preserve persuasive function.

### Mechanism 2: Domain-Adaptive Strategy Generation
The system adapts to different domains without task-specific training data by leveraging LLM's ability to generate domain-relevant strategies. The same prompt and few-shot examples are used across all three domains, allowing the LLM to generate diverse strategies specific to each domain's context.

### Mechanism 3: Parallel Module Architecture (SMM + QHM)
The dual-module architecture ensures both strategic persuasiveness and factual accuracy while handling user requests. Strategy Maintenance Module (SMM) handles strategy preservation and fact-checking, while Question Handling Module (QHM) retrieves information for user-initiated queries. Results are merged with strategy preservation as priority.

## Foundational Learning

- Concept: Chain-of-thought prompting
  - Why needed here: Used in fact-checking to guide LLM reasoning when evaluating claims against retrieved evidence
  - Quick check question: How does chain-of-thought prompting help LLMs verify factual claims more reliably than direct yes/no questions?

- Concept: Information retrieval with ColBERT
  - Why needed here: Enables efficient retrieval of relevant facts from domain-specific corpora to replace unsubstantiated claims
  - Quick check question: What advantage does ColBERT's late interaction model provide over traditional keyword matching for this application?

- Concept: Strategy decomposition and labeling
  - Why needed here: Allows separation of persuasive intent from factual claims, enabling targeted fact-checking while preserving persuasive function
  - Quick check question: Why is it important to maintain the original strategy structure when replacing factual claims with retrieved information?

## Architecture Onboarding

- Component map: LLM Generation -> Strategy Extraction -> Fact-Check & IR -> Merging Results -> Final Response
- Critical path: LLM Generation → Strategy Extraction → Fact-Check & IR → Merging Results
- Design tradeoffs:
  - Strategy preservation vs. complete fact replacement: The system prioritizes maintaining persuasive strategies even when facts need replacement
  - Response rewriting vs. claim substitution: Complete rewriting ensures consistency but requires more computation
  - Strategy diversity vs. predefined strategies: Generated strategies are more nuanced but less predictable than predefined ones

- Failure signatures:
  - LLM fails to extract coherent strategies: Check prompt clarity and few-shot examples
  - Fact-checking produces too many unsupported claims: Verify corpus coverage and IR relevance
  - Merging produces incoherent responses: Check strategy-fact alignment and response coherence
  - Poor persuasiveness despite strategy extraction: Evaluate if retrieved facts maintain persuasive intent

- First 3 experiments:
  1. Test strategy extraction pipeline on known good and bad responses to verify strategy labeling accuracy
  2. Evaluate fact-checking accuracy by comparing LLM judgments against human annotations on sample claims
  3. Measure factuality improvement by comparing claim accuracy before and after IR replacement in controlled conversations

## Open Questions the Paper Calls Out

### Open Question 1
How would PersuaBot perform with different base LLMs like GPT-4 or Claude, and what impact would this have on persuasiveness and factuality? The experiments only tested GPT-3.5 and Llama 3, leaving uncertainty about performance with other state-of-the-art LLMs.

### Open Question 2
What is the optimal balance between strategy maintenance and information retrieval in PersuaBot to maximize persuasiveness without compromising factuality? The current implementation uses a fixed approach for both components without exploring how adjusting their relative importance might affect performance.

### Open Question 3
How does PersuaBot's performance scale across different languages and cultural contexts? All experiments were conducted in English, and the paper suggests domain adaptability, but doesn't explore multilingual or cross-cultural applications.

## Limitations

- Performance depends on carefully curated domain-specific corpora, creating barriers to immediate deployment in new domains
- Evaluation relies on crowd worker judgments, which may not fully capture nuanced differences between human and AI persuasion effectiveness
- System's performance with genuinely open-domain conversations remains untested

## Confidence

**Confidence: Medium** - Clear improvements demonstrated, but reliance on curated corpora and prompt engineering creates deployment barriers
**Confidence: Low** - 26.6% improvement figure represents relative improvement without baseline factuality rates
**Confidence: High** - Zero-shot approach validated across three domains, but extensive prompt engineering required

## Next Checks

1. **Strategy Preservation Validation**: Test whether retrieved facts actually maintain persuasive intent through A/B testing of strategy-preserved versus generic factual corrections
2. **Corpus Coverage Analysis**: Measure percentage of LLM-generated claims that cannot be verified due to insufficient corpus coverage across all domains
3. **Cross-Domain Transferability Test**: Implement in a fourth domain using exact same prompts to validate zero-shot claims hold for genuinely novel domains