---
ver: rpa2
title: 'PreRoutGNN for Timing Prediction with Order Preserving Partition: Global Circuit
  Pre-training, Local Delay Learning and Attentional Cell Modeling'
arxiv_id: '2403.00012'
source_url: https://arxiv.org/abs/2403.00012
tags:
- graph
- timing
- circuit
- delay
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses pre-routing timing prediction in chip design,
  aiming to estimate pin-level slack and edge-level delays without time-consuming
  routing. The authors propose a two-stage approach: (1) global circuit pre-training
  with a graph auto-encoder to learn global graph embeddings, and (2) local delay
  learning using a novel residual message passing scheme following topological sorting
  order, combined with an attention-based cell modeling mechanism.'
---

# PreRoutGNN for Timing Prediction with Order Preserving Partition: Global Circuit Pre-training, Local Delay Learning and Attentional Cell Modeling

## Quick Facts
- arXiv ID: 2403.00012
- Source URL: https://arxiv.org/abs/2403.00012
- Authors: Ruizhe Zhong, Junjie Ye, Zhentao Tang, Shixiong Kai, Mingxuan Yuan, Jianye Hao, Junchi Yan
- Reference count: 21
- One-line primary result: Achieves R² of 0.93 for slack prediction, significantly improving upon the previous best of 0.59

## Executive Summary
This paper addresses pre-routing timing prediction in chip design, aiming to estimate pin-level slack and edge-level delays without time-consuming routing. The authors propose a two-stage approach: (1) global circuit pre-training with a graph auto-encoder to learn global graph embeddings, and (2) local delay learning using a novel residual message passing scheme following topological sorting order, combined with an attention-based cell modeling mechanism. To handle large-scale circuits efficiently, they introduce an order-preserving graph partition scheme. Experiments on 21 real-world circuits achieve a new state-of-the-art R² of 0.93 for slack prediction, significantly surpassing the previous best of 0.59. The method effectively addresses signal decay and error accumulation issues in long timing paths while maintaining computational efficiency.

## Method Summary
The proposed PreRoutGNN method employs a two-stage approach to address pre-routing timing prediction. First, it uses a graph auto-encoder for global circuit pre-training to learn node and global graph embeddings. This is followed by local delay learning using residual message passing that follows topological sorting order, combined with a multi-head joint attention mechanism for cell modeling. To handle large-scale circuits efficiently, the method incorporates an order-preserving graph partition scheme with padding. The approach specifically targets the challenge of signal decay and error accumulation in long timing paths, which are critical issues in pre-routing timing estimation. The model is trained to predict arrival time, slew, net delay, and cell delay, which are then used to compute slack values for timing verification.

## Key Results
- Achieves R² of 0.93 for un-flattened slack prediction, surpassing previous best of 0.59
- Demonstrates significant improvement in handling signal decay and error accumulation in long timing paths
- Successfully applies order-preserving graph partitioning to manage large-scale circuit graphs efficiently

## Why This Works (Mechanism)
The method's effectiveness stems from its two-stage architecture that separates global structure learning from local timing prediction. The global pre-training captures circuit-level dependencies and long-range relationships, while the residual local learning with topological ordering preserves signal propagation properties. The attention-based cell modeling allows the network to focus on critical timing elements. The order-preserving partitioning maintains temporal relationships during computation, preventing the loss of important timing constraints that can occur with random partitioning. This combination addresses the fundamental challenge of signal decay in timing prediction by ensuring that local predictions are informed by accurate global context while maintaining computational tractability.

## Foundational Learning
- **Graph Neural Networks for EDA**: Neural networks that operate on graph-structured data are essential for circuit representation and analysis. They enable the model to capture complex relationships between circuit elements. Quick check: Verify the graph representation correctly handles heterogeneous node and edge types.
- **Heterogeneous DAGs**: Circuits are naturally represented as directed acyclic graphs with different node types (cells, pins, nets) and edge types. This representation preserves the topological structure and timing relationships. Quick check: Confirm the DAG structure is maintained throughout processing and that topological sorting is correctly implemented.
- **Liberty File Format**: Industry-standard format for cell library characterization containing lookup tables for timing, power, and area. Essential for accurate delay and slew prediction. Quick check: Validate the Liberty file parsing correctly extracts and interpolates delay/slew values.
- **Topological Sorting**: Linear ordering of vertices in a DAG such that for every directed edge (u,v), vertex u comes before v. Critical for preserving signal propagation order in timing analysis. Quick check: Ensure the topological order is correctly computed and maintained throughout the residual message passing.
- **Residual Message Passing**: A GNN variant where local predictions are added to propagated messages, helping to mitigate signal decay in long paths. Quick check: Verify the residual connections are properly implemented and that the local delay predictor is correctly initialized.
- **Order-Preserving Graph Partitioning**: Partitioning technique that maintains topological relationships while reducing graph size for computational efficiency. Essential for scaling to large circuits. Quick check: Confirm the partitioning algorithm maintains all necessary dependencies and that padding is correctly handled.

## Architecture Onboarding

**Component Map**: Graph Auto-Encoder (Global Pre-training) -> PreRoutGNN (Local Delay Learning with Residual MP and Attention) -> Order-Preserving Partitioning

**Critical Path**: Circuit graph input → Global pre-training → Topological sorting → Residual message passing with local prediction → Attention-based cell modeling → Slack computation

**Design Tradeoffs**: 
- Global pre-training vs. end-to-end training: Global pre-training provides better initialization and captures long-range dependencies but requires additional computation
- Residual connections vs. pure message passing: Residual connections help with signal decay but add complexity
- Order-preserving partitioning vs. random partitioning: Order-preserving maintains timing relationships but may create less balanced partitions

**Failure Signatures**:
- Poor R² scores indicate issues with topological ordering, residual connections, or attention mechanism
- Memory overflow suggests partitioning is not correctly applied
- Signal decay persistence indicates residual learning or topological sorting issues

**First 3 Experiments**:
1. Train the graph auto-encoder on a small circuit and verify reconstruction quality and embedding quality
2. Test the residual message passing with topological sorting on a simple chain graph to verify signal preservation
3. Validate the order-preserving partitioning on a medium-sized circuit to ensure correct dependency preservation and padding handling

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- The method requires significant computational resources for global pre-training on large circuit graphs
- Performance may be sensitive to the quality of the Liberty file characterization and interpolation method
- The order-preserving partitioning algorithm details are not fully specified, which could affect reproducibility

## Confidence
**High** confidence in the core technical claims regarding the PreRoutGNN architecture and its performance improvements, based on the detailed methodology description and comparison with established baselines. The two-stage approach (global pre-training + local delay learning) and the use of order-preserving graph partitioning are well-specified and align with state-of-the-art practices in GNN-based EDA. The R² score of 0.93 represents a substantial improvement over previous work, and the methodology appears sound.

**Medium** confidence concerns regarding exact reproducibility due to two key implementation details that remain unspecified: the Liberty file format for cell delay/slew lookup tables and the precise implementation of the order-preserving graph partitioning algorithm. These details could affect exact numerical reproduction but are unlikely to change the qualitative conclusions about the method's effectiveness.

## Next Checks
1. Verify the Liberty file parsing implementation matches industry standards, particularly the LUT interpolation method used for cell delay/slew prediction
2. Test the order-preserving partitioning algorithm on circuits of varying sizes to confirm the padding mechanism correctly excludes padded nodes from loss computation
3. Replicate the timing corner (EL/RF) setup and confirm the four-corner averaging procedure matches the specification in TimingGCN