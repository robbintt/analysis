---
ver: rpa2
title: A Theory of Machine Learning
arxiv_id: '2407.05520'
source_url: https://arxiv.org/abs/2407.05520
tags:
- 'true'
- machines
- probability
- learning
- learn
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper critically examines three major theories of machine\
  \ learning\u2014the possible worlds theory, the recognition theory, and the operation\
  \ theory\u2014and identifies fundamental problems in each. The authors propose a\
  \ new theory defining machine learning as successful computation of a function,\
  \ challenging common assumptions that learning true probabilities is equivalent\
  \ to correct calculation or almost-sure convergence."
---

# A Theory of Machine Learning

## Quick Facts
- arXiv ID: 2407.05520
- Source URL: https://arxiv.org/abs/2407.05520
- Reference count: 40
- This paper proposes a new theory defining machine learning as successful computation of a function, challenging common assumptions about probability learning.

## Executive Summary
This paper critically examines three major theories of machine learning—the possible worlds theory, the recognition theory, and the operation theory—and identifies fundamental problems in each. The authors propose a new theory defining machine learning as successful computation of a function, challenging common assumptions that learning true probabilities is equivalent to correct calculation or almost-sure convergence. They prove that learning requires more than obtaining true facts by luck, and that observational equivalence in machine behavior under different probability measures prevents direct measurement of true probability learning. The paper presents two case studies: natural language processing (where true probabilities are directly observable and learnable) and macroeconomics (where true probabilities like r-star are unobservable and unlearnable). The work provides a foundational framework for understanding machine learning as both computational and epistemic, with implications for algorithm design and theoretical limits of learning.

## Method Summary
The paper presents a theoretical framework for machine learning without involving experiments or code. It critically reviews existing theories, proposes a new definition of learning as successful computation, and proves several theorems about the limitations of probability learning. The work includes two conceptual case studies (natural language processing and macroeconomics) to illustrate when true probabilities are learnable versus unlearnable. No specific datasets, training procedures, or metrics are provided, as the focus is entirely on theoretical implications rather than empirical validation.

## Key Results
- The paper proves that almost-sure convergence to a probability function does not guarantee learning, as machines cannot determine the selection criterion for data collection
- Machine behaviors under different probability measures are observationally equivalent, preventing measurement of true probability learning
- Learning true probabilities requires direct observability, which is possible in domains like NLP but impossible in macroeconomics where parameters like r-star are unobservable

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The paper challenges the assumption that learning true probabilities is equivalent to obtaining correct calculations or almost-sure convergence by constructing counterexamples where convergence occurs but learning does not.
- Mechanism: Learning requires more than mathematical convergence—it demands successful computation that is both reliable (correct most of the time) and doxastic (self-assured of correctness). The paper proves that even when probability functions converge almost surely, machines cannot learn if they cannot determine the selection criterion for data collection.
- Core assumption: The definition of learning must include both epistemic (knowledge acquisition) and computational (successful calculation) components, not just statistical convergence.
- Evidence anchors:
  - [abstract]: "This paper critically examines three major theories of machine learning... and identifies fundamental problems in each... learning requires more than obtaining true facts by luck"
  - [section 3.3]: "Third, machine learning of true probabilities is not equivalent to obtaining almost-sure convergence to them by machines"
  - [corpus]: Weak evidence - corpus contains related papers but no direct counterexamples to convergence assumptions
- Break condition: If the selection criterion for data collection becomes directly observable (as in Case 1 with natural language processing), then the counterexample no longer applies and learning becomes possible.

### Mechanism 2
- Claim: The operation theory fails because machine behaviors under different probability measures are observationally equivalent, preventing measurement of true probability learning.
- Mechanism: When machines solve optimization problems under uncertainty, they can achieve the same optimal behavior under different probability measures. The paper proves that unless the Radon-Nikodym derivative is an identity function, we cannot distinguish whether machines learned the true probability or some other measure.
- Core assumption: Practical significance of theoretical learning results requires observational distinguishability of machine performance under different probability measures.
- Evidence anchors:
  - [section 4]: "There exists observational equivalence in machine behaviors under various probability measures... machines cannot learn the true probability under Definition 4"
  - [abstract]: "we cannot exclusively measure machine performance by learning the true probability"
  - [corpus]: Weak evidence - corpus contains related work but no direct experimental validation of observational equivalence
- Break condition: If machines directly estimate true probabilities rather than solving optimization problems under uncertainty, the observational equivalence problem disappears (as shown in Theorem 8).

### Mechanism 3
- Claim: Learning true probabilities requires direct observability of the probability function, which is possible in some domains (like natural language processing) but impossible in others (like macroeconomics).
- Mechanism: The paper defines direct observability as the ability to collect data from a true population where the identical distribution is already endowed. When this is possible (Case 1), machines can learn true probabilities by calculating empirical distributions. When impossible (Case 2), machines cannot learn regardless of approximation methods.
- Core assumption: Direct observability of true probabilities is a necessary condition for learning, not just a sufficient one.
- Evidence anchors:
  - [section 5]: "Machines directly observe P(At+1|ßt) from the true population W at t* if... a true population W is in principle available to the machines"
  - [abstract]: "natural language processing (where true probabilities are directly observable and learnable) and macroeconomics (where true probabilities like r-star are unobservable and unlearnable)"
  - [corpus]: Moderate evidence - corpus contains related work on probability learning but no direct population observability studies
- Break condition: If the true population becomes indirectly observable through auxiliary variables (as attempted with r-star), but the paper proves this indirect approach also fails.

## Foundational Learning

- Concept: Epistemic vs Behavioral Approaches to Learning
  - Why needed here: The paper distinguishes between theories that define learning through knowledge acquisition (epistemic) versus behavior (behavioral), showing fundamental problems in both approaches.
  - Quick check question: What is the key difference between how the possible worlds theory and operation theory define machine learning?

- Concept: Direct Observability of Probability Functions
  - Why needed here: The paper proves that learning true probabilities requires direct observability, which is domain-dependent, creating a framework for understanding when machine learning is theoretically possible.
  - Quick check question: According to the paper, what two conditions must be satisfied for a true probability to be directly observable by machines?

- Concept: Success Criterion for Computational Learning
  - Why needed here: The paper introduces a new definition of learning that requires both reliability (correct most of the time) and doxastic assurance (self-assured of correctness), distinguishing it from mere correct calculation.
  - Quick check question: How does the paper's Success Criterion for learning differ from simply requiring correct probability calculations?

## Architecture Onboarding

- Component map: Critical review of existing theories -> New learning definition -> Case studies demonstrating direct observability requirements
- Critical path: Start with understanding the epistemic vs behavioral distinction, then examine the counterexamples proving why common assumptions fail, then study the direct observability framework, finally analyze the case studies
- Design tradeoffs: The paper trades mathematical elegance (simple convergence conditions) for practical applicability (observability requirements), and trades universality (single learning definition) for domain specificity (learnable vs unlearnable cases)
- Failure signatures: Learning fails when (1) probability functions converge but selection criteria are unknowable, (2) machine behaviors are observationally equivalent under different measures, or (3) true probabilities are not directly observable from available populations
- First 3 experiments:
  1. Construct a counterexample similar to the paper's where a probability sequence converges almost surely but machines cannot learn the underlying distribution due to unknowable selection criteria
  2. Implement optimization problems under uncertainty and demonstrate observational equivalence of machine behavior under different probability measures
  3. Compare natural language processing tasks (where word frequencies are directly observable) with macroeconomics forecasting tasks (where model parameters like r-star are not directly observable) to demonstrate the direct observability framework

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what formal conditions can machines successfully compute a target function, and how does this relate to the epistemic notion of learning?
- Basis in paper: [explicit] The paper defines machine learning as successful computation of a function and presents the Success Criterion for Machines to Learn a target function
- Why unresolved: The paper establishes the necessary conditions but doesn't fully characterize the sufficient conditions for successful computation across all possible function classes
- What evidence would resolve it: Formal proofs showing exactly when and why machines can successfully compute various types of functions, including proofs of both necessity and sufficiency

### Open Question 2
- Question: What alternative methods could be developed to forecast macroeconomic evolution when direct learning of probability functions like r-star is impossible?
- Basis in paper: [explicit] The paper proves that machines cannot learn or approximate true probability of r-star and asks about alternative forecasting methods
- Why unresolved: The paper identifies the impossibility but doesn't propose specific alternative approaches
- What evidence would resolve it: Development and validation of new forecasting methods that don't rely on learning true probability functions

### Open Question 3
- Question: How can real machines approximate directly observable probabilities in practice, and what are the theoretical limits of such approximations?
- Basis in paper: [explicit] The paper discusses the case study of N-gram models where true probabilities are directly observable, but notes that real machines must approximate
- Why unresolved: The paper establishes that direct observation is possible in principle but doesn't explore the practical approximation methods or their limits
- What evidence would resolve it: Empirical studies comparing approximation methods and theoretical bounds on approximation error for various learning algorithms

## Limitations
- The theoretical nature of the work means practical applicability remains uncertain without empirical validation
- Observational equivalence claims, though mathematically sound, have not been tested with real optimization problems
- The paper doesn't propose specific alternative methods for domains where true probability learning is impossible

## Confidence
- High: Logical consistency of theoretical arguments
- Medium: Mathematical proofs of learning limitations
- Low: Practical applicability of theoretical results

## Next Checks
1. Construct a concrete optimization problem where machine behavior under different probability measures is observationally equivalent, then attempt to distinguish between them using standard evaluation metrics
2. Apply the direct observability framework to a real natural language processing task (e.g., word frequency estimation) and verify whether true probabilities can be learned as predicted
3. Design an experiment testing whether machines can learn unobservable macroeconomic parameters by attempting to estimate them from observable economic indicators, then compare results against the paper's theoretical predictions