---
ver: rpa2
title: 'FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models'
arxiv_id: '2406.02224'
source_url: https://arxiv.org/abs/2406.02224
tags:
- slms
- knowledge
- clients
- server
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FedMKT introduces a federated mutual knowledge transfer framework
  that enables bidirectional knowledge transfer between server-side large language
  models (LLMs) and client-side small language models (SLMs) in heterogeneous environments.
  The framework uses minimum edit distance for token alignment and selective knowledge
  distillation based on cross-entropy losses to facilitate efficient knowledge transfer
  while preserving data privacy.
---

# FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models

## Quick Facts
- arXiv ID: 2406.02224
- Source URL: https://arxiv.org/abs/2406.02224
- Reference count: 10
- Primary result: Achieves 5-34% SLM performance improvement while maintaining LLM performance comparable to centralized fine-tuning through bidirectional knowledge transfer

## Executive Summary
FedMKT introduces a federated mutual knowledge transfer framework that enables bidirectional knowledge exchange between server-side large language models (LLMs) and client-side small language models (SLMs) in heterogeneous environments. The framework addresses key challenges in federated learning by using minimum edit distance for token alignment and selective knowledge distillation based on cross-entropy losses. This approach preserves data privacy while achieving performance gains that rival centralized fine-tuning methods, with experimental results showing SLM improvements of 5-34% on QA tasks.

## Method Summary
FedMKT employs bidirectional token alignment using minimum edit distance to handle tokenizer mismatches between heterogeneous models. The framework implements selective knowledge transfer through a DualMinCE strategy that uses cross-entropy losses to determine beneficial knowledge flow. Parameter-efficient fine-tuning with LoRA adapters minimizes communication overhead by transmitting only logits instead of full model parameters. The system operates in three distinct scenarios: Heterogeneous (different model architectures), Homogeneous (same architecture), and One-to-One (direct pairing), demonstrating flexibility across deployment contexts.

## Key Results
- SLMs achieve 5-34% performance improvement on QA tasks compared to standalone training
- LLM performance matches centralized fine-tuning (82.3% vs 85.9% on RTE in Heterogeneous setting)
- Communication overhead reduced by transmitting only logits instead of model parameters
- Framework preserves data privacy through knowledge distillation rather than parameter sharing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Selective knowledge distillation based on cross-entropy losses enables bidirectional transfer while preserving privacy
- Mechanism: DualMinCE strategy computes cross-entropy losses for both LLM and SLM predictions, transferring knowledge from the model with minimum loss to the other
- Core assumption: Cross-entropy loss reliably indicates model quality for selective transfer, and public dataset provides sufficient diversity
- Evidence anchors: Abstract mentions "selective knowledge distillation based on cross-entropy losses"; section describes DualMinCE comparing prediction distributions with gold labels
- Break condition: If cross-entropy doesn't correlate with model quality or public dataset lacks diversity, poor knowledge may be transferred

### Mechanism 2
- Claim: Minimum edit distance enables effective knowledge transfer despite tokenizer mismatches
- Mechanism: MinED dynamically maps tokens between different tokenizers using minimal edit operations to align output logits distributions
- Core assumption: Tokens from different tokenizers have minimal disparities that can be effectively aligned while preserving information
- Evidence anchors: Abstract mentions "minimum edit distance for token alignment"; section describes using dynamic programming to minimize tokenizer mismatch impact
- Break condition: If token sequences differ substantially or MinED introduces too much noise, knowledge transfer quality degrades

### Mechanism 3
- Claim: LoRA adapters significantly reduce communication overhead while maintaining performance
- Mechanism: Instead of transmitting full parameters, only adapter weights are shared, reducing communication to floating-point numbers for public dataset logits
- Core assumption: LoRA adapters capture sufficient knowledge for effective transfer without compromising training stability
- Evidence anchors: Abstract mentions "transmitting only logits instead of model parameters"; section describes clients sharing only output logits and cross-entropy losses
- Break condition: If LoRA adapters are too small to capture necessary knowledge or overhead reduction impacts stability

## Foundational Learning

- **Knowledge distillation**: Transfer knowledge from one model to another using soft labels rather than parameters; needed because FedMKT fundamentally relies on distillation techniques for privacy-preserving transfer; quick check: How does knowledge distillation differ from parameter transfer, and why is it preferred in privacy-preserving federated learning?

- **Tokenization and interoperability**: Different models use different tokenizers, creating fundamental challenges for knowledge transfer; needed because FedMKT must solve tokenizer mismatches through MinED alignment; quick check: How do different tokenizers segment the same text differently, and what problems does this create when transferring knowledge between models?

- **Parameter-efficient fine-tuning (PEFT)**: Techniques like LoRA that update only small adapter weights instead of full model parameters; needed because FedMKT uses LoRA to minimize communication overhead; quick check: How do LoRA adapters work compared to full fine-tuning, and what are the tradeoffs in terms of performance and efficiency?

## Architecture Onboarding

- **Component map**: Server LLM (fψ) with adapter (ω) -> Public dataset (Dp) -> MinED alignment module -> DualMinCE selection module -> Client SLMs (gϕk) with adapters (θk) -> Private datasets (Dk) -> Communication channel
- **Critical path**: Client trains θk on Dk → Client computes logits/losses on Dp → Server receives and aligns tokens → Server updates ω via selective distillation → Server computes logits/losses on Dp → Clients receive and align tokens → Clients update θk via selective distillation
- **Design tradeoffs**: LoRA adapter size vs. knowledge capture capability, frequency of communication rounds vs. training efficiency, strictness of token alignment vs. information preservation
- **Failure signatures**: SLMs show no performance improvement, LLM performance degrades instead of improving, communication overhead remains high, training becomes unstable
- **First 3 experiments**:
  1. Implement MinED token alignment between two different tokenizers on a small dataset and verify alignment quality
  2. Test LoRA adapter training on a single client with a small public dataset to verify parameter efficiency
  3. Run a simplified version of the full pipeline with two clients and verify bidirectional knowledge transfer on a toy dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FedMKT's performance scale with larger model sizes and more clients, and what are the practical limitations in real-world deployments?
- Basis in paper: [explicit] Authors state current study is constrained by computational and storage resources, preventing exploration of larger model sizes
- Why unresolved: Paper only tests with specific model sizes and three clients, leaving uncertainty about performance at scale
- What evidence would resolve it: Experimental results showing FedMKT performance with models like GPT-4/5 and varying numbers of clients (10, 100, 1000), including communication overhead measurements

### Open Question 2
- Question: What is the impact of heterogeneous data distributions across clients on FedMKT's knowledge transfer effectiveness?
- Basis in paper: [inferred] Paper evaluates three scenarios but doesn't analyze relationship between data distribution heterogeneity and transfer effectiveness
- Why unresolved: Paper shows performance results across scenarios but doesn't explore how varying data distributions affect knowledge transfer quality
- What evidence would resolve it: Systematic experiments varying data distribution similarity across clients while keeping model architectures constant

### Open Question 3
- Question: How robust is FedMKT's token alignment using minimum edit distance when dealing with extreme tokenizer mismatches or rare vocabulary items?
- Basis in paper: [explicit] Authors acknowledge tokenizers can mismatch significantly and use MinED, but don't evaluate performance under extreme divergence
- Why unresolved: Paper validates MinED on typical mismatches but doesn't test edge cases like completely different tokenization strategies
- What evidence would resolve it: Experiments comparing FedMKT performance with various tokenizer combinations under controlled token mismatch scenarios

## Limitations

- **Token alignment robustness**: MinED-based alignment may face practical challenges with significantly different tokenization schemes, especially for morphologically rich languages or specialized vocabularies
- **Selective transfer efficacy**: DualMinCE strategy's reliance on cross-entropy loss as proxy for model quality may not hold universally, risking propagation of suboptimal knowledge
- **Communication overhead claims**: Actual bandwidth savings depend heavily on number of public samples and communication frequency, requiring empirical validation across different scales

## Confidence

**High Confidence**: Core mechanism of bidirectional knowledge transfer using LoRA adapters is well-established; experimental setup and evaluation methodology appear sound with clear baselines and comparative metrics
**Medium Confidence**: MinED token alignment approach is innovative but lacks extensive validation; assumption that cross-entropy loss reliably indicates model quality is reasonable but not universally proven
**Low Confidence**: Framework's behavior in highly heterogeneous environments with diverse client capabilities is not fully characterized; long-term stability of bidirectional transfer process is not thoroughly investigated

## Next Checks

1. **Token Alignment Stress Test**: Implement MinED alignment on datasets with varying linguistic complexity (technical documents, morphologically rich languages) and measure alignment accuracy and correlation with downstream performance, comparing against embedding-based matching

2. **Selective Transfer Robustness**: Create controlled experiments where public dataset contains varying degrees of noise and bias, measure how DualMinCE strategy performs, and compare against random selection and fixed-quality selection baselines

3. **Communication Efficiency Analysis**: Conduct empirical measurements of actual communication overhead across different client scales (10, 50, 100 clients) and network conditions, comparing total data transmitted in FedMKT against traditional federated fine-tuning and centralized approaches