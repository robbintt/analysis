---
ver: rpa2
title: Real-Time 3D Object Detection Using InnovizOne LiDAR and Low-Power Hailo-8
  AI Accelerator
arxiv_id: '2412.05594'
source_url: https://arxiv.org/abs/2412.05594
tags:
- hailo
- detection
- lidar
- hardware
- object
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work demonstrates real-time 3D object detection using InnovizOne
  LiDAR data processed on a low-power Hailo-8 AI accelerator. The approach adapted
  the PointPillars model for deployment on edge hardware, achieving approximately
  5 Hz inference speed with 0.91% F1 score, a mere 0.2% degradation compared to high-power
  RTX 2080 Ti.
---

# Real-Time 3D Object Detection Using InnovizOne LiDAR and Low-Power Hailo-8 AI Accelerator

## Quick Facts
- arXiv ID: 2412.05594
- Source URL: https://arxiv.org/abs/2412.05594
- Reference count: 13
- Primary result: Real-time 3D object detection achieved at ~5 Hz with 0.91% F1 score on low-power Hailo-8 AI accelerator

## Executive Summary
This work demonstrates real-time 3D object detection using InnovizOne LiDAR data processed on a low-power Hailo-8 AI accelerator. The approach adapted the PointPillars model for deployment on edge hardware, achieving approximately 5 Hz inference speed with 0.91% F1 score, a mere 0.2% degradation compared to high-power RTX 2080 Ti. Data from InnovizOne LiDAR was annotated for cars and optimized for the Hailo chip using ONNX export, quantization, and hardware-specific compilation. The method proves that effective 3D object detection can be deployed on cost-efficient, low-power hardware, advancing accessibility for autonomous driving technologies. Source code and pre-trained models are available for replication.

## Method Summary
The method involves adapting the PointPillars 3D object detection model for deployment on the low-power Hailo-8 AI accelerator. The process begins with InnovizOne LiDAR data capture and preprocessing into point clouds annotated with 3D bounding boxes for cars. The PointPillars model is trained using OpenPCDet framework, then exported to ONNX format and optimized for Hailo hardware through quantization and compilation using Hailo SDK. The 2D convolutional layers of the PointPillars backbone are offloaded to the Hailo-8 accelerator while remaining operations run on the CPU. The optimized model achieves real-time inference at approximately 5 Hz with accuracy comparable to running on more powerful hardware like the RTX 2080 Ti.

## Key Results
- Achieved real-time inference at ~5 Hz on low-power Hailo-8 AI accelerator
- Maintained high detection accuracy of 0.91% F1 score
- Only 0.2% accuracy degradation compared to RTX 2080 Ti baseline
- Successfully demonstrated 3D object detection deployment on cost-efficient hardware

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Hailo-8 AI accelerator can effectively offload 2D convolutional layers from the PointPillars network, enabling real-time inference at 5 Hz on low-power hardware.
- Mechanism: The PointPillars model architecture naturally separates 2D convolutional operations (backbone and dense head) from 3D-specific processing. These 2D layers are computationally intensive but well-suited for the Hailo-8's hardware optimization, allowing them to be processed on the accelerator while the remaining operations run on the CPU.
- Core assumption: The 2D convolutional layers constitute the primary computational bottleneck and are compatible with Hailo's hardware architecture.
- Evidence anchors:
  - [abstract] "We successfully achieved real-time inference at a rate of approximately 5Hz with a high accuracy of 0.91% F1 score, with only -0.2% degradation compared to running the same model on an NVIDIA GeForce RTX 2080 Ti."
  - [section] "The LiDAR sensor used in this study is the InnovizOne sensor, which captures objects in higher quality compared to spinning LiDAR techniques, especially for distant objects."
  - [corpus] No direct evidence found in corpus about Hailo-8 performance with PointPillars specifically. Weak signal.
- Break condition: If the 2D convolutional layers cannot be cleanly separated from the 3D processing pipeline, or if Hailo's hardware cannot efficiently handle the specific layer types in PointPillars.

### Mechanism 2
- Claim: InnovizOne LiDAR provides sufficient point cloud quality and resolution to enable effective 3D object detection for autonomous driving applications.
- Mechanism: The InnovizOne sensor captures higher-resolution 3D point clouds compared to traditional spinning LiDARs, particularly for distant objects, providing more detailed spatial information that improves detection accuracy.
- Core assumption: Higher point cloud resolution directly translates to better object detection performance, especially for critical distant objects.
- Evidence anchors:
  - [abstract] "The LiDAR sensor used in this study is the InnovizOne sensor, which captures objects in higher quality compared to spinning LiDAR techniques, especially for distant objects."
  - [section] "The LiDAR sensor used in this study is the InnovizOne sensor, which captures objects in higher quality compared to spinning LiDAR techniques, especially for distant objects."
  - [corpus] Weak signal. No direct evidence in corpus about InnovizOne performance characteristics.
- Break condition: If point cloud sparsity or noise levels exceed the detection model's tolerance thresholds, or if the sensor fails to capture sufficient detail for critical object classes.

### Mechanism 3
- Claim: ONNX export and quantization optimization enable efficient model deployment on Hailo hardware while maintaining detection accuracy.
- Mechanism: The model conversion pipeline (PyTorch → ONNX → Hailo format) with quantization reduces model size and computational requirements while preserving essential detection capabilities, allowing deployment on resource-constrained hardware.
- Core assumption: The quantization process can maintain model accuracy within acceptable bounds while significantly reducing computational load.
- Evidence anchors:
  - [section] "To further optimize the model for Hailo hardware, a quantization process was performed. This process involved creating a calibration dataset from the spatial features input to the 2D backbone."
  - [section] "The optimized model on the Hailo chip achieved a processing rate of approximately 5 Hz, with detection accuracy comparable to running on more powerful hardware."
  - [corpus] No direct evidence in corpus about ONNX quantization for LiDAR detection models. Weak signal.
- Break condition: If quantization causes unacceptable accuracy degradation, or if the model conversion pipeline introduces incompatibilities that prevent successful execution on Hailo hardware.

## Foundational Learning

- Concept: 3D object detection from point clouds
  - Why needed here: Understanding how 3D bounding boxes are predicted from unstructured point cloud data is fundamental to this work.
  - Quick check question: How does PointPillars convert unordered point clouds into structured pseudo-images for 2D convolution operations?

- Concept: Model quantization and optimization for edge hardware
  - Why needed here: The process of reducing model precision while maintaining accuracy is critical for deploying deep learning models on low-power accelerators.
  - Quick check question: What is the difference between floating-point and quantized model representations, and how does this affect inference speed?

- Concept: Sensor fusion and data preprocessing
  - Why needed here: Converting raw LiDAR point clouds into a format suitable for deep learning models requires understanding of coordinate systems, data normalization, and augmentation techniques.
  - Quick check question: What preprocessing steps are typically required to convert raw point cloud data into the format expected by PointPillars?

## Architecture Onboarding

- Component map:
  Data Acquisition: InnovizOne LiDAR sensor capturing 3D point clouds
  Preprocessing: Point cloud segmentation, normalization, and augmentation
  Model: PointPillars detector with 2D backbone offloaded to Hailo-8
  Inference Engine: Hailo-8 AI accelerator processing 2D convolutions
  Post-processing: Bounding box refinement and filtering
  Output: Detected 3D bounding boxes for cars

- Critical path:
  1. LiDAR data capture → Point cloud segmentation
  2. Preprocessing and normalization
  3. Feature extraction (2D convolutions on Hailo)
  4. Detection head processing (on Hailo)
  5. Post-processing and output generation
  This path determines the 5 Hz inference rate and must be optimized for latency.

- Design tradeoffs:
  - Model complexity vs. inference speed: PV-RCNN offers higher accuracy but is too computationally heavy for Hailo-8
  - Point cloud resolution vs. processing requirements: Higher resolution improves detection but increases computational load
  - Quantization level vs. accuracy: More aggressive quantization improves speed but may reduce detection performance

- Failure signatures:
  - Inference rate drops below 5 Hz: Indicates bottleneck in either data preprocessing or Hailo processing
  - Significant accuracy degradation (>0.5% F1 score): Suggests quantization or model adaptation issues
  - System crashes during model loading: Points to compatibility issues between ONNX model and Hailo SDK

- First 3 experiments:
  1. Measure baseline inference speed and accuracy on RTX 2080 Ti without Hailo integration to establish performance reference.
  2. Test ONNX export and Hailo compilation pipeline with a simplified model to verify the conversion process works end-to-end.
  3. Run inference on Hailo with calibration dataset to measure quantization impact on accuracy and identify acceptable quantization parameters.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the detection accuracy and inference speed scale with different point cloud densities from the InnovizOne LiDAR?
- Basis in paper: [explicit] The paper mentions that InnovizOne LiDAR captures objects in higher quality compared to spinning LiDAR techniques, especially for distant objects, but does not evaluate performance across different point cloud densities.
- Why unresolved: The study used a fixed dataset without exploring how varying point cloud density affects detection accuracy and inference speed on the Hailo-8 accelerator.
- What evidence would resolve it: Experiments varying the point cloud density (e.g., subsampling the point clouds) while measuring F1 score, recall, precision, and inference rate would clarify this relationship.

### Open Question 2
- Question: What is the impact of extending the object detection to multiple classes (e.g., pedestrians, cyclists) beyond cars?
- Basis in paper: [inferred] The paper focuses on car detection and mentions that PointPillars can estimate oriented 3D boxes for objects such as cars, pedestrians, and cyclists, but only cars were annotated and evaluated.
- Why unresolved: The annotation and evaluation were limited to cars, leaving the performance of the model and pipeline on other object classes untested.
- What evidence would resolve it: Annotating the dataset for additional object classes and retraining/evaluating the model on these classes would provide insights into multi-class detection performance.

### Open Question 3
- Question: How does the real-time performance change when integrating additional sensor modalities (e.g., radar, camera) with the LiDAR data?
- Basis in paper: [explicit] The discussion mentions the potential to integrate with various sensor types to improve system robustness, but does not provide experimental results.
- Why unresolved: The study only used LiDAR data without exploring sensor fusion techniques or their impact on detection performance and inference speed.
- What evidence would resolve it: Implementing sensor fusion with radar or camera data and evaluating the combined system's accuracy and inference rate would address this question.

## Limitations

- InnovizOne LiDAR's performance advantages over spinning LiDARs are stated without comparative data or quantitative metrics.
- The quantization process's impact on accuracy is minimized in reporting, with only a -0.2% F1 score degradation mentioned, but no breakdown of which model components were most affected.
- The 5 Hz inference rate achievement is specific to the Hailo-8 hardware and may not generalize to other edge accelerators without similar architectural optimizations.

## Confidence

- **High confidence**: The feasibility of deploying PointPillars on Hailo-8 hardware with minimal accuracy loss (0.91% F1 score vs 0.93% on RTX 2080 Ti) is well-supported by the reported results.
- **Medium confidence**: The claim that 2D convolutional layers can be effectively offloaded to Hailo-8 is plausible given the architecture but lacks detailed performance profiling evidence.
- **Low confidence**: The InnovizOne LiDAR's superiority for distant object detection is asserted without comparative data or quantitative validation.

## Next Checks

1. **Quantization sensitivity analysis**: Systematically vary quantization parameters and measure corresponding accuracy degradation across different model components to identify sensitivity thresholds and optimization opportunities.

2. **Cross-hardware performance validation**: Deploy the optimized model on alternative edge AI accelerators (e.g., Google Coral, NVIDIA Jetson) to assess hardware dependency and identify architectural bottlenecks.

3. **LiDAR comparison study**: Conduct controlled experiments comparing InnovizOne with spinning LiDARs under identical conditions, measuring point cloud quality, detection accuracy, and range performance for distant objects.