---
ver: rpa2
title: Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive
  EHR Modelling with Hierarchical Regularisation
arxiv_id: '2401.11648'
source_url: https://arxiv.org/abs/2401.11648
tags:
- medical
- codes
- data
- multimodal
- clinical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces NECHO, a medical code-centric multimodal contrastive
  EHR learning framework with hierarchical regularisation, to predict next visit diagnoses.
  NECHO integrates medical codes, demographics, and clinical notes using a tailored
  network and bimodal contrastive losses, centralising around medical code representation.
---

# Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation

## Quick Facts
- arXiv ID: 2401.11648
- Source URL: https://arxiv.org/abs/2401.11648
- Reference count: 20
- Next visit diagnosis prediction with 71.45% top-30 accuracy

## Executive Summary
NECHO introduces a medical code-centric multimodal contrastive EHR learning framework for predicting next visit diagnoses. The model integrates medical codes, demographics, and clinical notes using a tailored network design with bimodal contrastive losses centered around medical code representation. Hierarchical regularisation using parental-level ICD-9 codes enhances the model's ability to learn the structure of EHR data. Experiments on MIMIC-III demonstrate superior performance over existing baselines, achieving 71.45% top-30 accuracy.

## Method Summary
NECHO is a multimodal contrastive learning framework for next visit diagnosis prediction that uses medical codes as the primary modality. The framework employs modality-specific encoders (simple embeddings for codes/demos, BioWord2Vec + CNN for notes), cross-modal transformers, and a code-centric multimodal adaptation gate for fusion. Bimodal contrastive losses align medical codes with demographics and clinical notes, while hierarchical regularisation using parental-level ICD-9 codes regularises each modality-specific encoder. The model is trained with cross-entropy loss, bimodal contrastive losses, and hierarchical regularisation using the Adam optimizer.

## Key Results
- Achieved 71.45% top-30 accuracy on MIMIC-III dataset for next visit diagnosis prediction
- Demonstrated superior performance over existing baselines through ablation studies
- Medical code-centric strategies and hierarchical regularisation significantly enhance predictive accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Medical code-centric multimodal fusion improves predictive accuracy by positioning medical codes as the primary modality
- Mechanism: The framework uses medical codes as the central anchor for fusing demographics and clinical notes through cross-modal transformers and bimodal contrastive losses, ensuring that supplementary modalities enhance rather than dilute the primary signal
- Core assumption: Medical code representations contain the most discriminative information for diagnosis prediction, and other modalities can effectively supplement this information without introducing noise
- Evidence anchors:
  - [abstract] "we integrate multifaceted information encompassing medical codes, demographics, and clinical notes using a tailored network design and a pair of bimodal contrastive losses, all of which pivot around a medical code representation."
  - [section] "we empirically observe that the medical code representations show the best performance."
- Break condition: If medical codes do not contain the most discriminative information for diagnosis prediction, or if other modalities introduce noise rather than useful supplementary information

### Mechanism 2
- Claim: Hierarchical regularisation using parental-level medical codes improves model performance by injecting general information from the medical ontology
- Mechanism: Each modality-specific encoder is trained to predict parental-level ICD-9 codes in addition to its primary task, forcing the model to learn hierarchical relationships and general patterns in the medical data
- Core assumption: Medical ontologies contain meaningful hierarchical relationships that can be leveraged to improve model generalization and prevent error propagation
- Evidence anchors:
  - [abstract] "We also regularise modality-specific encoders using a parental level information in medical ontology to learn hierarchical structure of EHR data."
  - [section] "we introduce a regularisation strategy for each modality-specialised encoder to learn parental level of ICD-9 codes."
- Break condition: If the hierarchical structure of medical ontologies does not contain meaningful relationships, or if the additional task interferes with the primary prediction objective

### Mechanism 3
- Claim: Bimodal contrastive losses align multimodal representations by anchoring them to medical code representations
- Mechanism: Two asymmetric contrastive losses are applied between medical codes and each of the other modalities, forcing their representations to be semantically consistent while preserving modality-specific characteristics
- Core assumption: Patient-level representations share similar patterns across visits, making contrastive learning effective at the patient level rather than the visit level
- Evidence anchors:
  - [abstract] "we apply two bimodal contrastive losses to further intricately entangle the different modalities by anchoring on the medical code representations."
  - [section] "we consider at the patient level rather than at the visit level. This is because patient level representations share similar patterns between their visits."
- Break condition: If patient-level representations do not share consistent patterns across visits, or if contrastive learning at this level does not improve semantic alignment

## Foundational Learning

- Concept: Multimodal fusion strategies in deep learning
  - Why needed here: The paper combines three distinct data modalities (medical codes, demographics, clinical notes) which requires sophisticated fusion techniques to integrate their complementary information effectively
  - Quick check question: What are the key differences between symmetric and asymmetric multimodal fusion approaches, and why might asymmetric approaches be preferable when modalities have different levels of importance?

- Concept: Contrastive learning principles
  - Why needed here: The framework employs contrastive losses to align representations from different modalities, which requires understanding how InfoNCE loss works and how it can be applied to multimodal settings
  - Quick check question: How does temperature scaling in contrastive loss affect the concentration of the learned representations, and what considerations should guide the choice of temperature value?

- Concept: Medical ontology and hierarchical classification
  - Why needed here: The model leverages ICD-9 medical ontology's hierarchical structure for regularisation, requiring understanding of how medical codes are organized and how hierarchical relationships can be exploited for machine learning tasks
  - Quick check question: What are the key differences between ICD-9 and ICD-10 coding systems, and how might the hierarchical structure differ between them?

## Architecture Onboarding

- Component map:
  - Medical code extraction → Cross-modal attention → Self-attention → MAG fusion → Prediction
- Critical path: Medical code extraction → Cross-modal attention → Self-attention → MAG fusion → Prediction
- Design tradeoffs: Simple encoders vs. complex encoders, patient-level vs. visit-level contrastive learning, hard vs. soft hierarchical regularisation
- Failure signatures: Poor performance on top-k accuracy metrics, unstable training loss, inability to learn meaningful parental-level predictions
- First 3 experiments:
  1. Train with only medical codes to establish baseline performance
  2. Add one supplementary modality (demographics) to test fusion effectiveness
  3. Add the second supplementary modality (clinical notes) to evaluate full multimodal integration

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does NECHO perform on other clinical event prediction tasks like mortality prediction or readmission prediction?
- Basis in paper: [inferred] The paper mentions NECHO hasn't been extended to other tasks like mortality, readmissions, and length of stay, where different modalities might take main status
- Why unresolved: The paper focuses on next visit diagnosis prediction and doesn't provide results or analysis for other clinical event prediction tasks
- What evidence would resolve it: Testing NECHO on other clinical event prediction tasks and comparing its performance to state-of-the-art models for those specific tasks

### Open Question 2
- Question: How does the performance of NECHO change when handling missing or incomplete data modalities for some patients?
- Basis in paper: [explicit] The paper states that NECHO assumes all data modalities are readily and consistently available for every patient, but this assumption is impractical as data availability can be compromised
- Why unresolved: The paper doesn't discuss how NECHO handles missing or incomplete data modalities or provide results on its performance in such scenarios
- What evidence would resolve it: Evaluating NECHO's performance when some modalities are missing or incomplete for certain patients and comparing it to other models that handle missing data

### Open Question 3
- Question: How does the performance of NECHO vary with different values of the hierarchical regularization coefficient (λhrchy)?
- Basis in paper: [explicit] The paper conducts experiments on different values of λhrchy (0.01, 0.1, 1) and reports that λhrchy = 0.1 enhances the overall model performance the most
- Why unresolved: The paper only provides results for a limited range of λhrchy values and doesn't explore the full spectrum of possible values or their impact on performance
- What evidence would resolve it: Conducting a more extensive analysis of NECHO's performance across a wider range of λhrchy values to determine the optimal range and understand its impact on the model's performance

## Limitations

- The framework assumes all data modalities are readily and consistently available for every patient, which is impractical in real-world scenarios
- The medical code-centric approach may not generalize well to other clinical event prediction tasks where different modalities might take main status
- The effectiveness of hierarchical regularisation depends on the quality and completeness of the ICD-9 medical ontology

## Confidence

- **High confidence**: The multimodal fusion approach and overall framework design are well-supported by experimental results and ablation studies. The code-centric strategy demonstrates clear advantages over alternative fusion methods.
- **Medium confidence**: The hierarchical regularisation mechanism shows promise, but its effectiveness may be context-dependent and requires further validation across different medical ontologies and healthcare systems.
- **Medium confidence**: The patient-level contrastive learning approach is theoretically sound, but the specific hyperparameters (temperature τ, weighting α) and their optimal values across different datasets remain somewhat empirical.

## Next Checks

1. **Cross-institutional validation**: Test NECHO on EHR data from different healthcare systems or countries to assess generalizability beyond MIMIC-III, particularly focusing on whether the code-centric approach remains effective with different coding standards (e.g., ICD-10).

2. **Ablation of hierarchical regularisation**: Conduct controlled experiments removing the hierarchical regularisation component to quantify its exact contribution to performance gains and assess whether similar improvements can be achieved through alternative regularisation strategies.

3. **Alternative ontology structures**: Evaluate the framework using different hierarchical medical ontologies (e.g., SNOMED-CT, MeSH) to determine whether the benefits of hierarchical regularisation are specific to ICD-9 or represent a more general principle applicable across medical knowledge representations.