---
ver: rpa2
title: 'Latxa: An Open Language Model and Evaluation Suite for Basque'
arxiv_id: '2403.20266'
source_url: https://arxiv.org/abs/2403.20266
tags:
- language
- latxa
- basque
- arxiv
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Latxa addresses the challenge of building effective language models
  for low-resource languages like Basque by continuing pretraining of Llama 2 models
  using a carefully curated Basque corpus of 4.3M documents and 4.2B tokens. The approach
  combines existing and newly collected data sources, applying thorough deduplication
  and quality filtering.
---

# Latxa: An Open Language Model and Evaluation Suite for Basque

## Quick Facts
- **arXiv ID:** 2403.20266
- **Source URL:** https://arxiv.org/abs/2403.20266
- **Reference count:** 19
- **Primary result:** 70B parameter Latxa achieves 61.08 average accuracy on multiple-choice benchmarks, outperforming Llama 2 by 25.18 points

## Executive Summary
Latxa addresses the challenge of building effective language models for low-resource languages like Basque by continuing pretraining of Llama 2 models using a carefully curated Basque corpus of 4.3M documents and 4.2B tokens. The approach combines existing and newly collected data sources, applying thorough deduplication and quality filtering. The resulting Latxa family (7B, 13B, 70B parameters) outperforms all previous open models on multiple-choice benchmarks by a large margin, with the 70B variant achieving 61.08 average accuracy and outperforming Llama 2 by 25.18 points. Notably, Latxa excels in Basque language proficiency tasks, surpassing even GPT-4 Turbo in this domain, demonstrating that language model capabilities in a specific language are not solely determined by linguistic competence.

## Method Summary
The researchers continued pretraining of Llama 2 models using a carefully curated Basque corpus of 4.3M documents and 4.2B tokens. The corpus combines existing and newly collected data sources, with thorough deduplication and quality filtering applied. The resulting Latxa family of models (7B, 13B, 70B parameters) was evaluated on multiple-choice benchmarks, demonstrating significant improvements over previous open models for Basque language tasks.

## Key Results
- 70B parameter Latxa achieves 61.08 average accuracy on multiple-choice benchmarks
- Outperforms Llama 2 by 25.18 points on the same benchmarks
- Surpasses GPT-4 Turbo in Basque language proficiency tasks

## Why This Works (Mechanism)
Assumption: The effectiveness of Latxa stems from its domain-specific pretraining on a large, high-quality Basque corpus that combines diverse data sources. By continuing pretraining from Llama 2's general language understanding capabilities, Latxa leverages transfer learning to adapt to Basque linguistic patterns while maintaining general reasoning abilities. The thorough deduplication and quality filtering processes likely contribute to improved performance by ensuring the model learns from clean, representative data.

## Foundational Learning
Unknown: The paper does not explicitly discuss foundational learning principles or how the model's architecture supports continued learning from the Basque corpus.

## Architecture Onboarding
Unknown: The paper does not provide specific details about architecture onboarding or how the pretraining process adapts the base Llama 2 architecture for Basque language modeling.

## Open Questions the Paper Calls Out
None provided in the original report

## Limitations
- Corpus composition details remain incomplete with specific contributions of each data source not quantified
- Deduplication and quality filtering processes lack transparency in implementation details
- Comparison with GPT-4 Turbo relies on API calls rather than reproducible local evaluation
- Limited evaluation scope on general English tasks, with most testing focused on Basque-specific benchmarks

## Confidence
- **Latxa outperforms previous models on Basque benchmarks**: High confidence - supported by comprehensive multi-choice evaluations with clear numerical improvements
- **Latxa matches GPT-4 Turbo on Basque tasks**: Medium confidence - API-based evaluation introduces reproducibility concerns and potential variability
- **Latxa maintains general capabilities while excelling in Basque**: Medium confidence - limited evaluation scope on general English tasks, with most testing focused on Basque-specific benchmarks

## Next Checks
1. Conduct blind third-party evaluation of Latxa models on Basque and English benchmarks using standardized protocols
2. Perform ablation studies to quantify the impact of different corpus components on final model performance
3. Evaluate model outputs for potential hallucinations and factual accuracy in Basque language generation tasks, particularly for cultural and local knowledge questions