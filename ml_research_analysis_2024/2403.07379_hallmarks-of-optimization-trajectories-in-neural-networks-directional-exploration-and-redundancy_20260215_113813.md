---
ver: rpa2
title: 'Hallmarks of Optimization Trajectories in Neural Networks: Directional Exploration
  and Redundancy'
arxiv_id: '2403.07379'
source_url: https://arxiv.org/abs/2403.07379
tags:
- trajectory
- optimization
- figure
- networks
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes the directional structure of optimization trajectories
  in neural networks by proposing a trajectory map that captures the cosine similarity
  between parameter checkpoints. The authors introduce quantitative hallmarks like
  mean directional similarity and angular measures to characterize trajectory complexity.
---

# Hallmarks of Optimization Trajectories in Neural Networks: Directional Exploration and Redundancy

## Quick Facts
- arXiv ID: 2403.07379
- Source URL: https://arxiv.org/abs/2403.07379
- Reference count: 40
- Primary result: Momentum, weight decay, and batch size encourage directional exploration in optimization trajectories, while scale acts as a regularizer increasing cosine similarity between checkpoints.

## Executive Summary
This paper analyzes the directional structure of optimization trajectories in neural networks by introducing a trajectory map that captures cosine similarity between parameter checkpoints. The authors propose quantitative hallmarks including Mean Directional Similarity (MDS) and angular measures to characterize trajectory complexity. They demonstrate that hyperparameters like momentum, weight decay, and batch size promote directional exploration (lower cosine similarity), while increasing model scale acts as a regularizer (higher cosine similarity). The work provides insights into implicit biases of optimization and suggests potential for efficient training via trajectory structure exploitation.

## Method Summary
The paper analyzes optimization trajectories by saving parameter checkpoints during training and computing cosine similarities between all checkpoint pairs to create trajectory maps. Quantitative hallmarks include Mean Directional Similarity (MDS), angular measures between consecutive updates, and norm-based measures. The authors conduct experiments across ResNet50 on ImageNet, VGG on CIFAR10, ViT on ImageNet, and GPT-NeoX models (14M to 12B parameters) on the Pile dataset, systematically varying hyperparameters like momentum, weight decay, and batch size while measuring their effects on trajectory structure.

## Key Results
- Disabling momentum and weight decay in ResNet50 training reduces top-1 accuracy from 76% to 10% and increases cosine similarity from 0.764 to 0.979
- Increasing scale from 14M to 12B parameters in GPT-NeoX increases cosine similarity from 0.650 to 0.815
- Larger batch sizes decrease MDS scores, indicating more directional exploration when combined with proportionally scaled learning rates
- Weight decay and momentum interact to create oscillatory behavior along the largest Hessian eigenvector direction, promoting exploration

## Why This Works (Mechanism)

### Mechanism 1: Momentum-Weight Decay Interaction
Weight decay and momentum interact to create directional exploration by increasing the angle between consecutive parameter updates. The interaction creates oscillatory behavior along the largest Hessian eigenvector direction, with weight decay pulling parameters toward the origin while momentum adds inertia to previous gradients, causing larger angles at the origin.

### Mechanism 2: Scale as Regularizer
Scale acts as a regularizer by reducing directional exploration in optimization trajectories. As model size increases, parameter updates become proportionally smaller relative to initialization scale, causing cosine similarity to approach 1 in the large-width limit where updates align with initialization.

### Mechanism 3: Batch Size Effects
Batch size affects directional exploration through its interaction with learning rate and momentum. Larger batch sizes, when combined with proportionally scaled learning rates, create more obtuse angles between consecutive updates and between updates and current parameter locations, leading to lower mean directional similarity.

## Foundational Learning

- **Directional similarity and cosine similarity in high dimensions**: Understanding why neural network parameters violate the expectation that random vectors become orthogonal in high dimensions. Quick check: Why does cosine similarity between two random vectors in high dimensions approach zero, and why do neural network parameters violate this expectation?

- **Implicit bias in over-parameterized networks**: The principle that optimization algorithms follow inherently regular trajectories despite non-convex landscapes. Quick check: How does implicit bias explain why deep networks find generalizing solutions despite having many local minima?

- **Edge of Stability (EoS) phenomenon**: Understanding how learning rates adapt to the largest Hessian eigenvalue. Quick check: What happens to the largest eigenvalue of the Hessian when the learning rate approaches the EoS threshold, and how does this affect optimization stability?

## Architecture Onboarding

- **Component map**: Trajectory Map visualization (qualitative hallmark) -> Quantitative hallmarks: MDS, angular measures, norm-based measures -> Experimental framework: ResNet50/VGG/ViT/GPT-NeoX -> Analysis pipeline: checkpoint saving -> kernel matrix computation -> cosine similarity calculation

- **Critical path**: 1. Save parameter checkpoints at regular intervals during training 2. Compute kernel matrices K = ΘΘT and C = normalized cosine similarity matrix 3. Calculate quantitative hallmarks (MDS, angles, norms) 4. Visualize trajectory maps and analyze hyperparameter effects 5. Scale analysis for LLM behavior comparison

- **Design tradeoffs**: Checkpoint frequency vs storage cost (coarser granularity saves space but loses detail) vs exact computation vs approximations for billion-parameter models (accuracy vs efficiency) vs linear kernel vs more complex kernels (simplicity vs potential richer information)

- **Failure signatures**: Extremely high MDS values (>0.95) indicate lack of exploration, potentially underfitting vs very low MDS values (<0.5) suggest chaotic optimization, possibly overfitting or instability vs trajectory maps showing uniform dark grids indicate parameter alignment without feature learning

- **First 3 experiments**: 1. Train ResNet50 with standard hyperparameters and visualize the trajectory map 2. Disable momentum and observe the increase in MDS and darkening of trajectory map 3. Train VGG16 with varying batch sizes (16, 64, 256, 1024) while scaling learning rates proportionally and compare trajectory maps

## Open Questions the Paper Calls Out

### Open Question 1
How does the directional exploration induced by hyperparameters like momentum and weight decay relate to the final generalization performance of neural networks? The paper observes correlation between trajectory structure and hyperparameters but doesn't establish a causal link between trajectory complexity and generalization. What evidence would resolve it: Systematic experiments varying hyperparameters to create trajectories with different complexities and measuring their generalization performance across multiple datasets and architectures.

### Open Question 2
Can the trajectory structure be exploited for more efficient training through techniques like selective parameter updates or line searches? The authors suggest high cosine similarity indicates redundancy that could be exploited for efficiency but don't implement specific techniques. What evidence would resolve it: Implementation and evaluation of training algorithms that leverage trajectory structure compared to standard training.

### Open Question 3
What is the mechanistic explanation for why increasing model scale leads to more aligned trajectories? The paper provides theoretical argument based on large-width limit but doesn't fully account for feature learning in larger models. What evidence would resolve it: Empirical studies of feature learning dynamics across different scales, and theoretical analysis extending beyond the large-width limit.

## Limitations
- Core claims rely on assumptions about Hessian eigenvalue structure and initialization schemes that are not empirically validated across diverse architectures
- Theoretical mechanisms explaining momentum-weight decay interactions and scale effects rely on strong assumptions warranting further empirical validation
- Findings from image classification may not generalize to LLMs due to different loss landscapes and optimization challenges in language modeling

## Confidence
- **High confidence**: The quantitative hallmarks (MDS, angular measures) and trajectory map visualization methodology are well-defined and reproducible
- **Medium confidence**: Theoretical mechanisms explaining momentum-weight decay interactions and scale effects are mathematically plausible but rely on strong assumptions
- **Medium confidence**: Generalization of findings from image classification to LLMs assumes similar optimization dynamics

## Next Checks
1. **Cross-architecture validation**: Test directional exploration mechanisms on architectures with different initialization schemes and varying depth/width ratios to verify scale-as-regularizer hypothesis
2. **Adaptive optimizer comparison**: Repeat trajectory analysis using AdamW and other adaptive optimizers to determine if momentum-weight decay interaction effects are specific to SGD
3. **Out-of-distribution generalization**: Evaluate whether models with different trajectory map characteristics (high vs low MDS) show different generalization behaviors on out-of-distribution test sets