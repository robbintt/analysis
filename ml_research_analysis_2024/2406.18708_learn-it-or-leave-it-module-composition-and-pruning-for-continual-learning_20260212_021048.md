---
ver: rpa2
title: 'Learn it or Leave it: Module Composition and Pruning for Continual Learning'
arxiv_id: '2406.18708'
source_url: https://arxiv.org/abs/2406.18708
tags:
- task
- learning
- continual
- mocl-p
- module
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses catastrophic forgetting, knowledge transfer,
  and parameter efficiency in continual learning for language models. The authors
  propose MOCL-P, which uses task representation-guided module composition with adaptive
  pruning to maintain a lightweight model while avoiding forgetting and enabling knowledge
  transfer.
---

# Learn it or Leave it: Module Composition and Pruning for Continual Learning

## Quick Facts
- arXiv ID: 2406.18708
- Source URL: https://arxiv.org/abs/2406.18708
- Authors: Mingyang Wang; Heike Adel; Lukas Lange; Jannik Strötgen; Hinrich Schütze
- Reference count: 21
- Primary result: MOCL-P achieves state-of-the-art continual learning performance while using up to 3x fewer parameters than prior methods

## Executive Summary
This paper addresses the critical challenges in continual learning for language models: catastrophic forgetting, knowledge transfer, and parameter efficiency. The authors propose MOCL-P, a novel approach that combines task representation-guided module composition with adaptive pruning. By using trainable task feature vectors to guide the composition of new and existing modules, MOCL-P selectively reuses relevant knowledge while avoiding interference. The adaptive pruning strategy further maintains efficiency by removing redundant modules, resulting in models that are both performant and lightweight.

## Method Summary
MOCL-P uses parameter-efficient fine-tuning (PEFT) modules, specifically prefix-tuning, for each new task. For each task, it learns a task feature vector and computes matching weights between the current task input embeddings and past task representations using cosine similarity. These weights determine how existing modules are combined with the new module for training. After training, MOCL-P prunes modules with matching weights below a threshold, removing redundant information while preserving task-specific knowledge. The method is evaluated on three benchmarks with up to 176 tasks, demonstrating state-of-the-art performance with significantly reduced parameter counts.

## Key Results
- Achieves state-of-the-art performance on three continual learning benchmarks
- Uses up to 3x fewer parameters compared to prior methods
- Successfully prevents catastrophic forgetting across 176 tasks on WikiAnn benchmark
- Demonstrates effective knowledge transfer with task representation-guided module composition

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Task representation-guided module composition enables knowledge transfer while avoiding catastrophic forgetting
- Mechanism: The model uses trainable task feature vectors to compute matching weights between current task input embeddings and past task representations. These weights determine how existing modules are combined with the new module for training, allowing the model to selectively reuse relevant knowledge.
- Core assumption: The cosine similarity between task input embeddings and task feature vectors effectively captures the relevance between current task and past tasks
- Evidence anchors:
  - [abstract]: "MOCL-P integrates task representation-guided module composition with adaptive pruning"
  - [section 4.2]: "We introduce trainable feature vectors V ∈ RN ×D as task representations to capture the features of each task in the CL sequence"
  - [corpus]: Weak evidence - corpus mentions composition-based methods but lacks specific validation of cosine similarity effectiveness

### Mechanism 2
- Claim: Adaptive pruning maintains parameter efficiency by removing redundant modules
- Mechanism: After training each new task, MOCL-P compares the matching weight of the new module against a threshold. If the weight is below threshold, the module is discarded as it adds redundant information; otherwise it's preserved for future reuse.
- Core assumption: Small matching weights indicate that the new module doesn't contribute unique information beyond what existing modules provide
- Evidence anchors:
  - [abstract]: "MOCL-P adopts an adaptive pruning strategy by removing modules with redundant information"
  - [section 4.3]: "we compare αm, the matching weight of the new module Pm, with a threshold to decide whether to prune Pm or leave it"
  - [corpus]: No direct corpus evidence for the specific pruning threshold approach

### Mechanism 3
- Claim: Learnable task feature vectors outperform static representations for module composition
- Mechanism: Unlike static approaches that use Gaussian distributions or mean embeddings, MOCL-P learns task feature vectors that can focus on salient features necessary for effective module composition while ignoring irrelevant information.
- Core assumption: The model can learn to capture the most relevant task features for module composition through training
- Evidence anchors:
  - [section 6.2]: "We believe that this degradation is due to the fact that both of these task representations are static and are solely based on the input embeddings"
  - [section 6.2]: "Trainable task representations are a better choice because not all information in the input embedding is relevant for module composition"
  - [corpus]: Weak evidence - corpus mentions composition-based methods but lacks specific validation of learnable vs static representations

## Foundational Learning

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: MOCL-P needs to understand why simply fine-tuning on new tasks degrades performance on old tasks
  - Quick check question: What happens to neural network weights when training on a new task without any protection mechanism?

- Concept: Parameter isolation for continual learning
  - Why needed here: MOCL-P uses parameter isolation with PEFT modules, so understanding how isolating parameters prevents interference is crucial
  - Quick check question: How does freezing previously trained parameters help maintain knowledge from earlier tasks?

- Concept: Task representation learning
  - Why needed here: MOCL-P learns task feature vectors for module composition, requiring understanding of how representations can capture task similarities
  - Quick check question: What properties should a good task representation have to enable effective knowledge transfer?

## Architecture Onboarding

- Component map:
  - PLM backbone (frozen)
  - Task-specific PEFT modules (prefix-tuning)
  - Task feature vector bank (trainable)
  - Module composition layer (weighted sum)
  - Pruning controller (threshold comparison)

- Critical path:
  1. Compute task matching weights via cosine similarity
  2. Compose new and existing modules based on weights
  3. Train new PEFT module and task feature vector
  4. Evaluate pruning decision based on new module weight

- Design tradeoffs:
  - Module granularity vs parameter efficiency: Smaller modules mean more pruning opportunities but may lose expressive power
  - Matching weight sensitivity vs robustness: Lower thresholds preserve more modules but reduce efficiency gains
  - Task representation dimensionality vs computational cost: Higher dimensions may capture better task distinctions but increase computation

- Failure signatures:
  - Performance plateaus despite adding new tasks → pruning threshold too aggressive
  - Gradual performance decay on old tasks → module composition not properly isolating interference
  - No efficiency gains despite pruning → threshold too lenient or task representations not learning effectively

- First 3 experiments:
  1. Run MOCL-P with zero pruning threshold on a small benchmark to establish baseline performance without efficiency gains
  2. Vary pruning threshold from 0 to 0.5 in increments of 0.1 to find optimal balance point
  3. Compare learnable task features vs static mean embeddings on a simple two-task scenario to validate representation choice

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does MOCL-P's performance scale with even longer task sequences beyond 176 tasks?
- Basis in paper: [inferred] The paper evaluates MOCL-P on benchmarks with up to 176 tasks, but doesn't explore scaling to hundreds or thousands of tasks.
- Why unresolved: The paper doesn't provide experimental results or theoretical analysis for task sequences longer than 176 tasks.
- What evidence would resolve it: Experimental results on benchmarks with 500+ tasks, or theoretical analysis of parameter efficiency and performance degradation as task sequence length increases.

### Open Question 2
- Question: How does MOCL-P perform on generative tasks compared to discriminative tasks?
- Basis in paper: [explicit] The paper states "we do not include generative tasks for evaluation" due to following prior work's evaluation setup.
- Why unresolved: The paper only evaluates on classification and named entity recognition tasks, leaving generative tasks unexplored.
- What evidence would resolve it: Experimental results comparing MOCL-P's performance on both generative and discriminative tasks across various benchmarks.

### Open Question 3
- Question: What is the impact of different task similarity distributions on MOCL-P's module pruning effectiveness?
- Basis in paper: [inferred] The paper notes that MTL15 tasks share lower similarity compared to AfriSenti and WikiAnn, resulting in weaker reusability of task modules.
- Why unresolved: The paper doesn't systematically vary task similarity distributions or analyze how different similarity patterns affect pruning decisions.
- What evidence would resolve it: Controlled experiments varying task similarity distributions while measuring pruning effectiveness and overall performance across different benchmarks.

## Limitations

- Limited empirical validation of the cosine similarity mechanism for task relevance
- Reliance on a single hyperparameter (pruning threshold) without theoretical grounding
- Evaluation only on discriminative tasks, leaving generative tasks unexplored
- Potential evaluation stability issues with 176-task sequences

## Confidence

**High Confidence**: The parameter efficiency claims are well-supported, with clear evidence that MOCL-P uses 2-3x fewer parameters than prior methods while maintaining competitive performance. The basic architecture design is sound and follows established patterns in continual learning.

**Medium Confidence**: The catastrophic forgetting prevention mechanism has reasonable theoretical support through parameter isolation, but the specific module composition approach needs more rigorous validation. The knowledge transfer claims are supported by benchmark results but could benefit from ablation studies showing the contribution of each component.

**Low Confidence**: The adaptive pruning strategy's effectiveness is the weakest link, as it relies heavily on a single hyperparameter (the threshold) without sufficient theoretical or empirical justification for its selection. The learnable task representation advantage over static methods is suggested but not conclusively proven.

## Next Checks

1. **Ablation on Pruning Threshold Sensitivity**: Systematically vary the pruning threshold from 0 to 0.5 in small increments on the MTL15 benchmark to quantify how sensitive performance and parameter efficiency are to this hyperparameter. This would reveal whether the pruning mechanism is robust or requires careful tuning.

2. **Alternative Similarity Measures**: Replace the cosine similarity between task input embeddings and task feature vectors with alternative measures (dot product, learned attention, or learned similarity functions) to determine if the specific choice of similarity measure is critical to MOCL-P's success.

3. **Static vs Learnable Representations**: Conduct a controlled experiment on a simple two-task scenario where the only difference between conditions is whether task feature vectors are learned or set to static mean embeddings. This would provide direct evidence for the claimed advantage of learnable representations.