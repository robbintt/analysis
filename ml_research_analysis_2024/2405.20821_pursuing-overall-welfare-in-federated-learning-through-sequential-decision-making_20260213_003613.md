---
ver: rpa2
title: Pursuing Overall Welfare in Federated Learning through Sequential Decision
  Making
arxiv_id: '2405.20821'
source_url: https://arxiv.org/abs/2405.20821
tags:
- learning
- federated
- decision
- clients
- regret
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes AAggFF, a fairness-aware federated learning
  method that addresses client-level fairness by treating the mixing coefficient update
  as an online convex optimization (OCO) problem. The key insight is unifying existing
  fairness-aware aggregation strategies into an OCO framework and improving their
  design.
---

# Pursuing Overall Welfare in Federated Learning through Sequential Decision Making

## Quick Facts
- arXiv ID: 2405.20821
- Source URL: https://arxiv.org/abs/2405.20821
- Reference count: 40
- This paper proposes AAggFF, a fairness-aware federated learning method that addresses client-level fairness by treating the mixing coefficient update as an online convex optimization (OCO) problem.

## Executive Summary
This paper introduces AAggFF, a novel framework for improving client-level fairness in federated learning by unifying existing fairness-aware aggregation strategies into an online convex optimization (OCO) framework. The method treats the central server's sequential decision making process as an OCO problem, where mixing coefficients are updated based on client feedback using either Online Newton Step for cross-silo settings or a doubly robust estimator for cross-device settings. Theoretical analyses guarantee sublinear regret bounds, and experiments on six benchmark datasets demonstrate AAggFF consistently achieves better fairness metrics while maintaining competitive average performance compared to baselines.

## Method Summary
AAggFF addresses client-level fairness in federated learning by treating the mixing coefficient update as an online convex optimization problem. The framework unifies existing fairness-aware aggregation strategies and introduces two variants: AAggFF-S for cross-silo settings using Online Newton Step algorithm, and AAggFF-D for cross-device settings using a doubly robust estimator to handle partially observed responses from client sampling. The method employs a Follow-The-Regularized-Leader objective to maintain history of decision losses and adapts mixing coefficients over time. Response transformation using CDF is applied to bound unbounded local losses, and theoretical regret bounds of O(√T log K) for cross-device and O(K log T) for cross-silo settings are established.

## Key Results
- AAggFF consistently achieves lower Gini coefficient and accuracy parity gap compared to baselines like FedAvg, AFL, q-FedAvg, TERM, FedMGDA, and PropFair
- The method maintains competitive average performance while improving client-level fairness across six benchmark datasets
- AAggFF demonstrates plug-and-play compatibility with other FL algorithms like FedAdam and FedYogi

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AAggFF treats the mixing coefficient update as an online convex optimization (OCO) problem to achieve client-level fairness in federated learning.
- Mechanism: The central server sequentially updates mixing coefficients by minimizing a decision loss based on client feedback, using online optimization algorithms like Online Newton Step (ONS) for cross-silo and a doubly robust estimator for cross-device settings.
- Core assumption: The OCO framework can effectively handle the sample-deficient setting where only client-level signals (losses) are available for updating mixing coefficients.
- Evidence anchors:
  - [abstract] "Our work reveals that existing fairness-aware aggregation strategies can be unified into an online convex optimization framework, in other words, a central server's sequential decision making process."
  - [section 3.2] "For sequentially updating a status in this sample-deficient situation, the Online Convex Optimization (OCO) framework is undoubtedly the best solution."
  - [corpus] Weak evidence - corpus mentions related concepts like "Federated Learning" and "Machine Learning" but lacks specific discussion of OCO framework application.
- Break condition: If the decision loss function is not strictly convex or Lipschitz continuous, the regret bounds may not hold, leading to suboptimal fairness performance.

### Mechanism 2
- Claim: AAggFF improves upon existing fairness-aware methods by adopting a stateful sequential decision making approach using Follow-The-Regularized-Leader (FTRL) objective.
- Mechanism: Instead of using static mixing coefficients, AAggFF maintains a history of decision losses and uses a time-varying regularizer to adapt mixing coefficients based on accumulated feedback.
- Core assumption: Stateful sequential decision making using FTRL can better capture the dynamics of client performance over time compared to stateless methods.
- Evidence anchors:
  - [section 3.3] "In designing an OCO algorithm, two main frameworks are mainly considered: Online Mirror Descent (OMD) and Follow-The-Regularized-Leader (FTRL)... Since these OPS algorithms are proven to perform well when the decision is a probability vector, we adopt them for finding adaptive mixing coefficients to achieve performance fairness in FL."
  - [section 4.1] "As a remedy for handling a) and b), the OMD objective for the server (i.e., (2)) can be replaced as follows... This is also known as FTRL objective..."
  - [corpus] No direct evidence - corpus does not discuss FTRL or stateful decision making approaches.
- Break condition: If the time-varying regularizer is not properly designed, the algorithm may fail to converge or may not achieve the desired fairness improvements.

### Mechanism 3
- Claim: AAggFF addresses the challenges of the cross-device setting by using a doubly robust estimator to handle partially observed responses from client sampling.
- Mechanism: When only a subset of clients participate in each round, AAggFF uses a doubly robust estimator that combines inverse probability weighting and imputation to estimate the effect of unobserved clients on the mixing coefficient update.
- Core assumption: The doubly robust estimator can provide an unbiased estimate of the response vector even when only a subset of clients are observed.
- Evidence anchors:
  - [section 4.2.2] "To make a new decision using a partially observed response vector, the effect of unobserved entries should be appropriately estimated. We solve this problem by adopting a doubly robust (DR) estimator..."
  - [section 4.2.2] "Lemma 4.3. Denote C = P[i ∈ S(t)] as a client sampling probability... The DR estimator ˘r(t), of which element is defined in (10) is an unbiased estimator of given partially observed response vector r(t). i.e., E[˘r(t)i] = r(t)."
  - [corpus] No direct evidence - corpus does not discuss doubly robust estimators or handling partial observations in federated learning.
- Break condition: If the client sampling probability is not known or if the sampling is not random, the doubly robust estimator may introduce bias into the mixing coefficient update.

## Foundational Learning

- Concept: Online Convex Optimization (OCO) framework
  - Why needed here: OCO provides a theoretical foundation for sequential decision making under uncertainty, which is essential for updating mixing coefficients based on limited client feedback.
  - Quick check question: What is the regret bound for the Online Newton Step algorithm used in the cross-silo setting?

- Concept: Follow-The-Regularized-Leader (FTRL) objective
  - Why needed here: FTRL allows the algorithm to maintain a history of decision losses and adapt mixing coefficients based on accumulated feedback, improving fairness over time.
  - Quick check question: How does the FTRL objective differ from the Online Mirror Descent (OMD) objective in terms of handling decision losses?

- Concept: Doubly Robust (DR) estimator
  - Why needed here: DR estimator handles the challenge of partially observed responses in the cross-device setting by combining inverse probability weighting and imputation.
  - Quick check question: Under what conditions is the doubly robust estimator an unbiased estimator of the response vector?

## Architecture Onboarding

- Component map:
  Central server -> Clients -> Communication channel -> Response transformation -> Decision making module -> Updated mixing coefficients

- Critical path:
  1. Central server initializes global model and mixing coefficients
  2. Clients participate in FL round, compute local losses
  3. Server receives local losses, transforms to bounded responses
  4. Server updates mixing coefficients using AAggFF algorithm
  5. Server aggregates local updates with new mixing coefficients
  6. Repeat steps 2-5 for T rounds

- Design tradeoffs:
  - ONS vs EG variant: ONS provides better regret bounds but higher computational complexity; EG variant is faster but has worse regret bounds
  - Response transformation: Different CDFs may yield different fairness improvements; choice affects sensitivity to outliers
  - Client sampling: Higher sampling rate improves accuracy but increases communication cost

- Failure signatures:
  - If mixing coefficients become degenerate (e.g., all weight on one client), check response transformation and Lipschitz continuity
  - If fairness does not improve, verify that decision loss is strictly convex and that history of losses is being properly maintained
  - If algorithm fails to converge, check that time-varying regularizer is properly designed and that step sizes are appropriately chosen

- First 3 experiments:
  1. Verify ONS algorithm on cross-silo dataset with full client participation, compare regret bounds to theoretical expectations
  2. Test EG variant with doubly robust estimator on cross-device dataset, measure impact of client sampling probability on fairness
  3. Compare different CDFs for response transformation on a small dataset, measure impact on mixing coefficient updates and fairness improvements

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the text.

## Limitations
- The Online Newton Step algorithm's computational complexity may become prohibitive in cross-silo settings with large client populations
- The doubly robust estimator's effectiveness depends heavily on accurate estimation of client sampling probabilities
- The choice of CDF for response transformation is not fully explored, and different distributions may yield varying fairness improvements

## Confidence
- OCO framework unification and theoretical regret bounds: High
- Cross-silo AAggFF-S algorithm effectiveness: Medium
- Cross-device AAggFF-D algorithm with doubly robust estimator: Medium
- Plug-and-play compatibility with other FL algorithms: Low (limited empirical validation)

## Next Checks
1. **Stress Test Sampling Robustness**: Systematically vary client sampling probabilities in cross-device experiments to quantify the doubly robust estimator's performance degradation as sampling becomes more sparse.

2. **Computational Scaling Analysis**: Measure the actual runtime overhead of AAggFF-S with increasing client counts in cross-silo settings to determine practical scalability limits.

3. **CDF Sensitivity Study**: Conduct controlled experiments comparing different response transformation distributions (Gaussian, Logistic, Student's t) to identify which distributions yield the most robust fairness improvements across diverse datasets.