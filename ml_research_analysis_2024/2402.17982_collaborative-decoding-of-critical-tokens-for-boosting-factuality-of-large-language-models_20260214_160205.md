---
ver: rpa2
title: Collaborative decoding of critical tokens for boosting factuality of large
  language models
arxiv_id: '2402.17982'
source_url: https://arxiv.org/abs/2402.17982
tags:
- token
- aligned
- pretrained
- decoding
- critical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the factuality hallucination problem in large
  language models (LLMs) caused by alignment processes and sampling decoding strategies.
  The proposed method introduces a collaborative decoding framework that leverages
  the high factuality of pretrained models while maintaining the instruction-following
  capabilities of aligned models.
---

# Collaborative decoding of critical tokens for boosting factuality of large language models

## Quick Facts
- arXiv ID: 2402.17982
- Source URL: https://arxiv.org/abs/2402.17982
- Authors: Lifeng Jin; Baolin Peng; Linfeng Song; Haitao Mi; Ye Tian; Dong Yu
- Reference count: 13
- Primary result: Achieves 4.5% and 5.7% improvements in factual consistency metrics over strong baselines

## Executive Summary
This work addresses the factuality hallucination problem in large language models (LLMs) caused by alignment processes and sampling decoding strategies. The proposed method introduces a collaborative decoding framework that leverages the high factuality of pretrained models while maintaining the instruction-following capabilities of aligned models. The core idea involves using a critical token classifier to identify factual tokens and selectively use either the aligned model with sampling or the pretrained model with greedy decoding for each token. Experiments with different models and datasets show significant reductions in model hallucination, with the proposed approach outperforming existing baselines.

## Method Summary
The paper proposes a collaborative decoding framework that combines a pretrained model (for factual accuracy) and an aligned model (for instruction following) through a critical token classifier. The approach identifies factual tokens that require high factuality and uses greedy decoding from the pretrained model for these tokens, while using sampling from the aligned model for non-factual tokens. This selective decoding strategy maintains the aligned model's instruction-following capabilities while improving factuality. The method demonstrates robustness against random sampling and achieves high factuality without sacrificing response diversity. Notably, the approach allows for knowledge updates through continual training of the pretrained model without impacting the aligned model.

## Key Results
- Achieves 4.5% and 5.7% improvements in factual consistency metrics over strong baselines
- Demonstrates robustness against random sampling while maintaining response diversity
- Shows significant reductions in model hallucination across different models and datasets
- Allows for knowledge updates through continual training without impacting the aligned model

## Why This Works (Mechanism)
The approach works by strategically combining the strengths of pretrained and aligned models. Pretrained models excel at factual accuracy due to their focus on maximum likelihood training, while aligned models are better at following instructions but may hallucinate facts due to sampling-based decoding. By using a critical token classifier to identify factual tokens, the method applies greedy decoding (which favors factual accuracy) from the pretrained model only where needed, while using sampling from the aligned model for the remaining tokens. This selective approach maintains instruction-following capabilities while significantly reducing hallucinations.

## Foundational Learning

**Token-level factuality**: The ability to assess the factual accuracy of individual tokens rather than entire responses. *Why needed*: Enables precise identification of where factual errors occur. *Quick check*: Evaluate classifier accuracy on known factual vs non-factual tokens.

**Greedy vs sampling decoding**: Understanding the trade-offs between deterministic (greedy) and probabilistic (sampling) generation strategies. *Why needed*: Different decoding strategies have different impacts on factuality and diversity. *Quick check*: Compare output distributions from both methods on factual prompts.

**Model alignment impact**: How instruction-tuning affects model behavior, particularly factuality. *Why needed*: Understanding why aligned models hallucinate helps design better solutions. *Quick check*: Measure factuality degradation after alignment on same model.

## Architecture Onboarding

**Component map**: Critical Token Classifier -> Pretrained Model (Greedy) + Aligned Model (Sampling) -> Output Decoder

**Critical path**: Input text → Critical token classifier → Token-by-token routing decision → Appropriate model decoding → Merged output

**Design tradeoffs**: The method trades additional computational overhead for improved factuality, but this is offset by reduced sampling complexity. The dual-model approach requires maintaining both models but allows for independent updates.

**Failure signatures**: Classifier misclassification could route factual tokens to sampling model, degrading factuality. Over-reliance on pretrained model could reduce instruction-following capabilities.

**First experiments**: 1) Test classifier accuracy on factual vs non-factual tokens; 2) Compare factuality metrics with and without collaborative decoding; 3) Evaluate response diversity retention across different domains.

## Open Questions the Paper Calls Out

None

## Limitations

- Evaluation relies primarily on synthetic datasets rather than comprehensive real-world factuality testing
- Critical token classifier generalization to out-of-domain scenarios remains unclear
- Additional computational overhead through classifier and dual-model inference

## Confidence

- Factuality improvements: High
- Response diversity maintenance: Medium-High
- Computational efficiency claims: Medium
- Real-world applicability: Medium

## Next Checks

1. **Real-world factuality testing**: Evaluate the approach on diverse real-world knowledge-intensive tasks beyond synthetic datasets, including open-domain question answering and document summarization, to assess practical effectiveness.

2. **Cross-domain classifier generalization**: Test the critical token classifier's performance on out-of-domain data and analyze its robustness to different knowledge domains and task types.

3. **Computational overhead analysis**: Conduct comprehensive benchmarking of the approach's inference time and resource requirements compared to standard decoding, particularly for different model sizes and hardware configurations.