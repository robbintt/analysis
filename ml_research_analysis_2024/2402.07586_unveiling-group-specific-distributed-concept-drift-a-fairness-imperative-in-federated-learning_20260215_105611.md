---
ver: rpa2
title: 'Unveiling Group-Specific Distributed Concept Drift: A Fairness Imperative
  in Federated Learning'
arxiv_id: '2402.07586'
source_url: https://arxiv.org/abs/2402.07586
tags:
- concept
- drift
- group-specific
- fairness
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces and formalizes the problem of group-specific
  concept drift and its distributed counterpart in federated learning, where fairness
  can be compromised when one group experiences concept drift while another does not.
  The authors propose FairFedDrift, an algorithm that uses a multi-model approach,
  local group-specific drift detection, and continuous clustering of models to address
  this challenge.
---

# Unveiling Group-Specific Distributed Concept Drift: A Fairness Imperative in Federated Learning

## Quick Facts
- arXiv ID: 2402.07586
- Source URL: https://arxiv.org/abs/2402.07586
- Authors: Teresa Salazar; João Gama; Helder Araújo; Pedro Henriques Abreu
- Reference count: 26
- One-line primary result: FairFedDrift effectively detects and manages group-specific distributed concept drift in federated learning, achieving high fairness (B-ACC) and accuracy (ACC) compared to baselines.

## Executive Summary
This paper introduces the problem of group-specific concept drift and its distributed counterpart in federated learning, where fairness can be compromised when one group experiences concept drift while another does not. The authors propose FairFedDrift, an algorithm that uses a multi-model approach, local group-specific drift detection, and continuous clustering of models to address this challenge. Experimental results on datasets like MNIST, FashionMNIST, and Adult demonstrate that FairFedDrift effectively detects and manages group-specific distributed concept drift, achieving high fairness (B-ACC) and accuracy (ACC) compared to baselines. The study highlights the importance of group-specific loss monitoring in maintaining fairness, especially in imbalanced datasets.

## Method Summary
FairFedDrift is an algorithm designed to detect and manage group-specific distributed concept drift in federated learning. It employs a multi-model approach based on group-specific loss monitoring, where each client calculates losses for all available global models and assigns itself to the model with the lowest sum of group losses. The algorithm uses local group-specific drift detection mechanisms and continuously clusters models over time, creating new models when necessary and merging models that correspond to the same concept. FairFedDrift aims to maintain both high accuracy and fairness by adapting to changing data distributions and preserving fairness across sensitive groups.

## Key Results
- FairFedDrift effectively detects and manages group-specific distributed concept drift in federated learning, achieving high fairness (B-ACC) and accuracy (ACC) compared to baselines.
- The algorithm's approach of considering the sum of group losses for model assignment helps in maintaining fairness across different representation scenarios of the unprivileged group.
- FairFedDrift's performance is robust across various group imbalance levels, with its effectiveness increasing as the unprivileged group becomes more underrepresented.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FairFedDrift's multi-model approach based on group-specific loss monitoring effectively detects and adapts to group-specific distributed concept drift in federated learning.
- Mechanism: By calculating and using the loss of each group s ∈ S separately, FairFedDrift can identify when a specific group experiences concept drift while others remain stable. This allows for the creation of multiple global models, each tailored to a specific concept or group of clients experiencing similar drift patterns.
- Core assumption: The loss of a group experiencing concept drift will differ significantly from its previous loss, while the loss of other groups remains relatively stable.
- Evidence anchors:
  - [abstract]: "The findings from our experiments highlight the importance of addressing group-specific concept drift and its distributed counterpart to advance fairness in machine learning."
  - [section]: "It is important to highlight that the exploration and comprehensive understanding of group-specific distributed concept drift in the context of federated learning has not been introduced and explored in the existing literature."
  - [corpus]: Weak. No direct evidence found in corpus about the effectiveness of multi-model approaches based on group-specific loss monitoring.
- Break condition: If the loss of all groups changes similarly over time, making it difficult to distinguish between group-specific concept drift and general concept drift.

### Mechanism 2
- Claim: The continuous clustering of models over time in FairFedDrift allows for the dynamic adaptation to changing data distributions in federated learning.
- Mechanism: FairFedDrift continuously clusters clients based on their group-specific losses, creating new global models when necessary and merging models that correspond to the same concept. This dynamic clustering allows the system to adapt to evolving data distributions and maintain fairness over time.
- Core assumption: Clients experiencing similar group-specific concept drifts can be clustered together, and their local models can be aggregated to create a global model that represents the shared concept.
- Evidence anchors:
  - [abstract]: "leveraging insights from prior research, we adapt an existing distributed concept drift adaptation algorithm to tackle group-specific distributed concept drift which utilizes a multi-model approach, a local group-specific drift detection mechanism, and continuous clustering of models over time."
  - [section]: "The merging process combines the two models with the lowest distances in the matrix (as long as they do not reach ∞) and unifies cluster identities by averaging their models, with the weighting based on the size of each model's training dataset."
  - [corpus]: Weak. No direct evidence found in corpus about the effectiveness of continuous model clustering in federated learning.
- Break condition: If the concept drift patterns are too complex or rapidly changing, making it difficult to maintain stable clusters over time.

### Mechanism 3
- Claim: FairFedDrift's approach of considering the sum of group losses for model assignment helps in maintaining fairness across different representation scenarios of the unprivileged group.
- Mechanism: By assigning clients to global models based on the sum of group losses, FairFedDrift ensures that clients experiencing similar group-specific concept drifts are grouped together, regardless of the overall loss trends. This approach helps maintain fairness even when the unprivileged group is underrepresented.
- Core assumption: The sum of group losses is a better indicator of concept drift than the overall loss, especially when the unprivileged group is underrepresented.
- Evidence anchors:
  - [abstract]: "Our experimental results demonstrate the efficacy of FairFedDrift in effectively detecting and managing group-specific distributed concept drift in federated learning."
  - [section]: "FairFedDrift's approach to considering the loss of all groups proves crucial. However, as α assumes higher values, the global loss undergoes more significant changes, allowing FedDrift to achieve results that closely match those of FairFedDrift."
  - [corpus]: Weak. No direct evidence found in corpus about the effectiveness of using the sum of group losses for model assignment in federated learning.
- Break condition: If the group-specific losses are highly correlated, making the sum of group losses redundant or less informative.

## Foundational Learning

- Concept: Group-specific concept drift
  - Why needed here: Understanding the concept of group-specific concept drift is crucial for grasping the problem that FairFedDrift aims to solve. It refers to situations where one group experiences changes in the data distribution over time while another group remains unaffected, leading to a decrease in fairness.
  - Quick check question: How does group-specific concept drift differ from general concept drift, and why is it particularly challenging for maintaining fairness in federated learning?

- Concept: Federated learning
  - Why needed here: Federated learning is the framework in which FairFedDrift operates. It allows multiple clients to collaboratively train models using their local data while preserving privacy, but it also introduces challenges when dealing with distributed concept drift.
  - Quick check question: What are the key characteristics of federated learning that make it suitable for addressing group-specific distributed concept drift, and what are the main challenges it introduces?

- Concept: Fairness metrics in machine learning
  - Why needed here: Understanding fairness metrics, such as balanced accuracy (B-ACC), is essential for evaluating the effectiveness of FairFedDrift in maintaining fairness across different groups in the presence of concept drift.
  - Quick check question: How does balanced accuracy differ from standard accuracy, and why is it a more appropriate metric for evaluating fairness in the context of group-specific distributed concept drift?

## Architecture Onboarding

- Component map:
  - Multi-model approach: FairFedDrift maintains multiple global models, each representing a specific concept or group of clients experiencing similar drift patterns.
  - Group-specific loss monitoring: The algorithm calculates and uses the loss of each group separately to detect and adapt to group-specific concept drift.
  - Continuous clustering: FairFedDrift continuously clusters clients based on their group-specific losses, creating new global models when necessary and merging models that correspond to the same concept.

- Critical path:
  1. At each timestep, each client receives new data and calculates its group-specific losses on all available global models.
  2. Clients assign themselves to the model with the lowest sum of group losses, provided the loss difference of each group between the current and previous timestep does not exceed a predefined threshold.
  3. If no suitable model is found, a new global model is created.
  4. The algorithm performs model merging by creating a distance matrix and combining models with the lowest distances.
  5. The global models are updated through iterative optimization based on the contributions from associated clients.

- Design tradeoffs:
  - Accuracy vs. fairness: FairFedDrift aims to maintain both high accuracy and fairness, but there may be scenarios where these objectives conflict.
  - Model complexity vs. adaptability: Maintaining multiple global models allows for better adaptation to group-specific concept drift but increases the overall complexity of the system.

- Failure signatures:
  - Excessive model creation: If the algorithm creates too many global models, it may indicate that the concept drift patterns are too complex or rapidly changing.
  - Poor clustering: If the continuous clustering process fails to create meaningful clusters, it may suggest that the group-specific losses are not sufficiently distinct.

- First 3 experiments:
  1. Evaluate FairFedDrift's performance on a synthetic dataset with known group-specific concept drift patterns, comparing its accuracy and fairness metrics against FedAvg and FedDrift.
  2. Test FairFedDrift's ability to handle varying levels of group imbalance by adjusting the α parameter and observing its impact on fairness and accuracy.
  3. Analyze FairFedDrift's model creation and merging behavior on a real-world dataset, such as Adult-GDrift, to understand how it adapts to complex concept drift scenarios.

## Open Questions the Paper Calls Out
- How can the hyperparameter selection process for FairFedDrift be automated to improve its practical application across diverse scenarios?
- What specialized fairness metrics can be developed to evaluate concept drift in distributed learning settings?
- How does the performance of FairFedDrift compare to other fairness-aware federated learning algorithms under different types of concept drift, such as sudden and gradual drift?

## Limitations
- The effectiveness of group-specific loss monitoring as a drift detection mechanism is not extensively validated, with limited empirical evidence from the corpus supporting this approach.
- The algorithm's performance in highly imbalanced scenarios and its behavior under rapidly changing drift patterns remain unclear.
- There is uncertainty about the optimal threshold settings for model assignment and merging, which may affect the algorithm's performance in practice.

## Confidence
- Confidence in the multi-model approach for handling group-specific drift: Medium
- Confidence in the continuous clustering mechanism: Medium
- Confidence in the overall fairness improvements: High for the tested datasets, but generalizability to other domains remains to be proven.

## Next Checks
1. Test FairFedDrift's performance on additional real-world datasets with known fairness issues to evaluate generalizability beyond the current experimental setup.
2. Conduct ablation studies to quantify the individual contributions of group-specific loss monitoring, multi-model approach, and continuous clustering to overall performance.
3. Evaluate the algorithm's behavior under extreme group imbalance (α approaching 0 or 1) to identify potential failure modes and limitations.