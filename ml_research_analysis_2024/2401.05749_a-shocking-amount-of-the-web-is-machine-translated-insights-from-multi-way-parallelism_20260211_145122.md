---
ver: rpa2
title: 'A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way
  Parallelism'
arxiv_id: '2401.05749'
source_url: https://arxiv.org/abs/2401.05749
tags:
- translation
- multi-way
- languages
- machine
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper reveals that a substantial portion of web content in
  low-resource languages is machine-translated, primarily from low-quality English
  sources. The authors create MWccMatrix, the largest multi-way parallel corpus to
  date (6.4B sentences in 90 languages), and use quality estimation to show that highly
  multi-way parallel translations (3+ languages) are of significantly lower quality
  than 2-way parallel translations, suggesting they are predominantly machine-generated.
---

# A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism

## Quick Facts
- arXiv ID: 2401.05749
- Source URL: https://arxiv.org/abs/2401.05749
- Reference count: 40
- Key finding: A substantial portion of web content in low-resource languages is machine-translated, primarily from low-quality English sources

## Executive Summary
This study reveals that a significant portion of web content in low-resource languages is machine-translated, predominantly from low-quality English sources. The authors created MWccMatrix, the largest multi-way parallel corpus to date (6.4B sentences in 90 languages), and used quality estimation to demonstrate that highly multi-way parallel translations (3+ languages) are of significantly lower quality than 2-way parallel translations. This suggests that low-quality English content is being mass-translated into many languages, likely for ad revenue. The findings raise concerns about using web-scraped data for training multilingual models, as it may contain less fluent and less accurate content, potentially leading to more hallucinations in generated text.

## Method Summary
The authors created MWccMatrix, a multi-way parallel corpus containing 6.4 billion sentences across 90 languages, by identifying sentences that have translations into three or more languages. They employed both reference-based and reference-free quality estimation methods to evaluate translation quality across different parallelisms. The study compared 2-way parallel data (translated into one other language) with higher parallelism data (translated into 3+ languages) to assess quality degradation. They also analyzed content characteristics and topic distributions to identify selection bias in the corpus.

## Key Results
- Highly multi-way parallel translations (3+ languages) show significantly lower quality than 2-way parallel translations
- The web contains substantial amounts of machine-translated content, especially for low-resource languages
- Shorter, more predictable content (particularly from the "Conversation/Opinion" topic) is overrepresented in multi-way parallel data
- Low-quality English content is being mass-translated into many languages, likely for ad revenue purposes

## Why This Works (Mechanism)
The mechanism relies on identifying patterns in translation quality across different levels of parallelism. By comparing translation quality between 2-way and multi-way parallel data, the study leverages the principle that human-translated content is typically created for specific language pairs, while machine translation can be easily scaled to multiple languages. The quality degradation in multi-way parallel data serves as a proxy for machine translation, as human translators typically produce higher-quality work when focusing on specific language pairs rather than mass translation across many languages.

## Foundational Learning

**Multi-way parallel corpora**: Collections of texts with translations in multiple languages, needed to understand cross-linguistic patterns and train multilingual models. Quick check: Verify corpus contains sentences with consistent translations across target languages.

**Quality estimation**: Methods to evaluate translation quality without reference translations, essential for assessing large-scale web data where reference translations are unavailable. Quick check: Ensure quality estimation model is validated against known quality benchmarks.

**Selection bias**: The phenomenon where certain types of content are more likely to be translated and appear in parallel corpora, critical for understanding corpus composition and potential model training impacts. Quick check: Analyze topic distribution across different parallelism levels.

**Cross-lingual embeddings**: Vector representations that capture semantic similarity across languages, needed to identify parallel sentences across language pairs. Quick check: Verify embedding space maintains semantic relationships across languages.

## Architecture Onboarding

**Component map**: Web scraping → Sentence alignment → Parallelism identification → Quality estimation → Analysis

**Critical path**: The quality estimation phase is critical, as it provides the primary evidence for machine translation detection. This involves running both reference-based and reference-free quality estimation models across the entire corpus.

**Design tradeoffs**: The study prioritizes corpus size and coverage over perfect quality control, accepting some noise in exchange for discovering broad patterns. This tradeoff enables detection of large-scale phenomena but may miss subtle quality differences.

**Failure signatures**: Poor quality estimation performance in low-resource languages could lead to misclassification of translation quality. Over-reliance on English as a pivot language might create artifacts in the analysis.

**3 first experiments**:
1. Compare quality estimation scores between 2-way and 3+ way parallel sentences to establish baseline quality degradation
2. Analyze topic distribution differences between 2-way and multi-way parallel content
3. Evaluate correlation between sentence length and translation quality across different parallelisms

## Open Questions the Paper Calls Out
None

## Limitations
- Quality estimation models may not perfectly capture all aspects of translation quality, particularly for low-resource languages
- Analysis focuses on web-scraped data, which may not represent all parallel corpora used in model training
- Does not investigate whether certain domains or website types are more likely to host machine-translated content

## Confidence

**High confidence**: Primary claims about the prevalence of low-quality machine translation in multi-way parallel web data, supported by robust quality estimation metrics.

**Medium confidence**: Attribution of content to specific business models (ad revenue generation), based on indirect evidence about content characteristics.

## Next Checks

1. **Domain-specific validation**: Analyze whether certain website categories (e.g., news, e-commerce, forums) show systematically different patterns of machine translation quality and content characteristics.

2. **Temporal analysis**: Track changes in the prevalence and quality of multi-way parallel content over time to determine if the observed patterns are stable or evolving.

3. **Cross-corpus comparison**: Compare MWccMatrix findings with other major parallel corpora (e.g., ParaCrawl, CCMatrix) to assess whether the observed quality degradation is specific to web-scraped data or represents a broader trend in multi-way parallel corpora.