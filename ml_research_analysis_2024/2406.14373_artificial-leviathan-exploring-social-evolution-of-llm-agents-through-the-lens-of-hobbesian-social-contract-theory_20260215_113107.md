---
ver: rpa2
title: 'Artificial Leviathan: Exploring Social Evolution of LLM Agents Through the
  Lens of Hobbesian Social Contract Theory'
arxiv_id: '2406.14373'
source_url: https://arxiv.org/abs/2406.14373
tags:
- agents
- agent
- social
- food
- simulation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper explores whether LLM agents can model the emergence\
  \ of social structures predicted by Hobbes\u2019s Social Contract Theory. In a sandbox\
  \ survival simulation, agents with psychological drives choose between farming,\
  \ trading, robbing, or donating."
---

# Artificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory

## Quick Facts
- arXiv ID: 2406.14373
- Source URL: https://arxiv.org/abs/2406.14373
- Reference count: 40
- Agents with psychological drives simulate Hobbes’s state of nature, forming social contracts and authorizing a sovereign

## Executive Summary
This paper explores whether LLM agents can model the emergence of social structures predicted by Hobbes’s Social Contract Theory. In a sandbox survival simulation, agents with psychological drives choose between farming, trading, robbing, or donating. Initially, agents engage in conflict, but gradually form concessionary relationships and authorize a single sovereign, mirroring the transition from a "state of nature" to a peaceful commonwealth. Experiments varied agent traits and environmental factors to understand how social evolution emerges from individual incentives and interactions.

## Method Summary
The simulation uses GPT-3.5-turbo to control 9 agents in a resource-constrained environment, each with psychological traits (aggressiveness, covetousness, strength, intelligence) and memory of recent interactions. Agents choose daily actions (farm, rob, trade, donate) based on prompts incorporating their traits and memory. The simulation tracks behavioral evolution from initial conflict toward commonwealth formation, varying parameters like memory depth, population size, and intelligence to test Hobbesian predictions about social contract emergence.

## Key Results
- Agents transition from a "state of nature" to a commonwealth through incremental concessionary relationships
- Agent behaviors are shaped by their innate psychological drives and memory of past interactions
- Higher intelligence reduces the likelihood of agents conceding, delaying or preventing commonwealth formation

## Why This Works (Mechanism)

### Mechanism 1
Agents transition from a "state of nature" to a commonwealth through incremental concessionary relationships. Initial competition for scarce resources forces agents to either resist or concede robberies. Repeated losses make resistance increasingly costly, pushing agents to concede and form superior-subordinate bonds. Over time, all agents converge on a single sovereign, establishing order.

### Mechanism 2
Agent behaviors are shaped by their innate psychological drives and memory of past interactions. Agents are instantiated with traits (aggressiveness, covetousness, strength, intelligence) and make decisions based on these traits plus their recent memory. This memory guides their evaluation of future actions, influencing whether they choose to rob, trade, farm, or concede.

### Mechanism 3
Higher intelligence reduces the likelihood of agents conceding, delaying or preventing commonwealth formation. Intelligence, controlled by GPT temperature or Top P parameters, influences the randomness of the LLM's responses. Higher intelligence means more deterministic, "rational" responses that favor resistance over concession, even when concession might be safer in the long run.

## Foundational Learning

- Concept: Evolutionary Game Theory (EGT)
  - Why needed here: Provides the theoretical grounding for understanding how individual incentives, resource scarcity, and adaptive behaviors drive societal dynamics
  - Quick check question: How does EGT explain the shift from competition to cooperation in a resource-constrained environment?

- Concept: Social Contract Theory (SCT)
  - Why needed here: The lens through which the simulation outcomes are evaluated, comparing agent behavior to Hobbes's predictions about the transition from a "state of nature" to a commonwealth
  - Quick check question: What are the key benchmarks used to assess whether agents' behavior aligns with SCT?

- Concept: LLM prompting and parameter tuning
  - Why needed here: The primary mechanism for influencing agent behavior; understanding how to craft prompts and adjust parameters is crucial for controlling the simulation
  - Quick check question: How do temperature and Top P affect the randomness and determinism of LLM responses, and why does this matter for agent intelligence?

## Architecture Onboarding

- Component map: Agents (traits, memory) -> LLM (GPT-3.5 Turbo) -> Actions (farm, rob, trade, donate) -> Environment (resources) -> User Interface (stats, relationships, logs)

- Critical path: Initialize agents with traits and memory → Each day, agents respond to incoming actions and initiate one action → LLM generates responses based on prompts and parameters → Update agent stats, memory, and relationships → Repeat until commonwealth forms or simulation ends

- Design tradeoffs: Memory depth vs. token limits (deeper memory provides richer learning but risks exceeding GPT's input token limit); Agent count vs. computational cost (more agents create more complex dynamics but increase simulation time and cost); Intelligence tuning (higher intelligence reduces randomness but may prevent commonwealth formation; lower intelligence increases randomness but risks nonsensical actions)

- Failure signatures: Commonwealth never forms (likely due to insufficient memory depth, too high intelligence, or agents failing to concede); Agents produce nonsensical actions (intelligence set too low); Simulation crashes (memory or token limit exceeded, or invalid LLM responses)

- First 3 experiments: 1) Baseline: Run 4 trials with default parameters to verify commonwealth formation; 2) Memory depth variation: Reduce memory depth to 20, 10, and 1 to observe impact on concession and commonwealth formation; 3) Intelligence variation: Adjust temperature and Top P to explore how intelligence affects agent behavior and commonwealth formation

## Open Questions the Paper Calls Out

### Open Question 1
What specific combination of agent parameters most reliably leads to the formation of a commonwealth, and how do these parameters interact to influence the speed and stability of this transition? The paper discusses varying agent parameters but does not specify the optimal combination or the precise nature of their interactions.

### Open Question 2
How does the depth of agent memory influence the development of social contracts and the overall stability of the commonwealth, and is there an optimal memory depth that balances adaptability with the formation of stable social structures? The paper shows a correlation between memory depth and behavior but does not determine the optimal memory depth for balancing adaptability and stability.

### Open Question 3
How does the size of the agent population affect the dynamics of resource competition, the formation of social contracts, and the likelihood of achieving a commonwealth, and are there threshold population sizes that significantly alter these dynamics? While the paper tests different population sizes, it does not identify if there are specific thresholds where population size becomes a critical factor.

## Limitations

- The exact prompt templates and formatting used to generate agent decisions are not fully detailed, creating uncertainty about faithful reproduction
- The relationship between LLM parameters and agent intelligence is described conceptually but lacks quantitative mapping
- The simulation assumes a linear progression from state of nature to commonwealth, potentially missing cycles, fragmentation, and alternative equilibria

## Confidence

- High confidence: The basic mechanism of agents transitioning from conflict to concession based on memory and perceived strength is well-supported by experimental results
- Medium confidence: Agent behaviors are shaped by psychological drives and memory, but the specific weighting and interaction of these factors are not fully characterized
- Medium confidence: The relationship between intelligence parameters and agent behavior shows clear patterns, but the underlying mechanism needs more rigorous validation

## Next Checks

1. **Prompt Template Replication**: Create a systematic prompt engineering experiment to determine which specific prompt formats reliably generate the described agent behaviors, testing variations in trait descriptions, memory presentation, and action options

2. **Parameter Sensitivity Analysis**: Conduct a controlled grid search over temperature and Top P values to map the quantitative relationship between these parameters and agent intelligence, aggression, and concession rates

3. **Alternative Social Dynamics**: Modify the simulation to test whether commonwealth formation is the only stable outcome by introducing periodic resets, varying resource regeneration rates, or allowing multiple competing sovereigns to emerge