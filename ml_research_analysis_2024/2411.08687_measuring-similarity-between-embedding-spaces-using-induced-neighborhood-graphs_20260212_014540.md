---
ver: rpa2
title: Measuring similarity between embedding spaces using induced neighborhood graphs
arxiv_id: '2411.08687'
source_url: https://arxiv.org/abs/2411.08687
tags:
- similarity
- photo
- nngs
- point
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Nearest Neighborhood Graph Similarity (NNGS),
  a method for measuring similarity between paired embedding spaces by comparing the
  structural similarity of their induced k-nearest-neighbor graphs. The approach uses
  Jaccard similarity between neighborhoods to evaluate how well embeddings preserve
  local structure, and can be tuned to focus on local or global scales by adjusting
  k.
---

# Measuring similarity between embedding spaces using induced neighborhood graphs

## Quick Facts
- arXiv ID: 2411.08687
- Source URL: https://arxiv.org/abs/2411.08687
- Reference count: 28
- Primary result: NNGS correlates strongly with task-specific accuracy, outperforming CKA in analogy and CLIP-based tasks.

## Executive Summary
This paper introduces Nearest Neighborhood Graph Similarity (NNGS), a method for measuring similarity between paired embedding spaces by comparing the structural similarity of their induced k-nearest-neighbor graphs. The approach uses Jaccard similarity between neighborhoods to evaluate how well embeddings preserve local structure, and can be tuned to focus on local or global scales by adjusting k. Experiments with GloVe embeddings in analogy tasks and CLIP embeddings in zero-shot classification show that NNGS correlates strongly with task-specific accuracy (Pearson's ρ = 0.86 for analogies, ρ = 0.77–0.90 for CLIP), outperforming Centered Kernel Alignment (CKA) in these contexts. The method is invariant to dimensionality changes and allows interpretable assessment of embedding quality, offering potential applications in model evaluation, prompt engineering, and early stopping strategies.

## Method Summary
NNGS measures similarity between embedding spaces by constructing k-nearest-neighbor (k-NN) graphs for each embedding and comparing the neighborhoods using Jaccard similarity. For each point in the embedding, the k nearest neighbors are identified, and the overlap between neighborhoods in two different embeddings is computed. This yields a pairwise similarity matrix, which is then aggregated into a single NNGS score. The method is designed to be invariant to dimensionality changes and can be tuned to focus on local (small k) or global (large k) structure preservation. Experiments demonstrate that NNGS correlates strongly with downstream task accuracy, particularly in analogy tasks and zero-shot classification, and outperforms CKA in these contexts.

## Key Results
- NNGS achieves Pearson's ρ = 0.86 correlation with analogy task accuracy for GloVe embeddings.
- NNGS correlates with CLIP zero-shot classification accuracy at ρ = 0.77–0.90, outperforming CKA.
- The method is shown to be invariant to dimensionality changes and interpretable in terms of local structure preservation.

## Why This Works (Mechanism)
NNGS leverages the idea that embeddings which preserve local neighborhoods will induce similar k-NN graphs, even if the global geometry differs. By comparing the overlap of neighborhoods via Jaccard similarity, the method captures how well the relative ordering and proximity of points are maintained across embedding spaces. This is particularly relevant for tasks where local structure (e.g., semantic similarity) is crucial. The invariance to dimensionality arises because the method compares graph structures rather than raw vector distances, making it robust to changes in embedding space size.

## Foundational Learning
- **Jaccard Similarity**: Measures overlap between sets; needed to quantify neighborhood similarity. Quick check: verify that J(A,B) = |A∩B| / |A∪B| for sets A and B.
- **k-Nearest Neighbors (k-NN)**: Graph construction method; needed to define local neighborhoods. Quick check: ensure k is appropriate for dataset size to avoid degenerate neighborhoods.
- **Centered Kernel Alignment (CKA)**: Baseline similarity metric; needed for comparison. Quick check: confirm CKA is computed correctly for fair benchmarking.
- **Pearson Correlation**: Statistical measure of linear relationship; needed to assess NNGS-task accuracy alignment. Quick check: validate that correlations are computed on appropriately normalized data.
- **Zero-shot Classification**: Task using CLIP embeddings; needed to demonstrate practical utility. Quick check: ensure prompt templates and evaluation metrics are consistent across experiments.
- **Analogy Tasks**: Semantic reasoning task; needed to validate NNGS on GloVe embeddings. Quick check: confirm analogy completion accuracy is computed as described in literature.

## Architecture Onboarding

**Component Map**
- Embeddings A, B -> k-NN graph construction -> Neighborhood sets -> Jaccard similarity computation -> NNGS score

**Critical Path**
1. Construct k-NN graphs for both embeddings.
2. Compute Jaccard similarity for each pair of corresponding points.
3. Aggregate similarities into a single NNGS score.

**Design Tradeoffs**
- Choice of k: Small k emphasizes local structure, large k global; must balance sensitivity and stability.
- Aggregation method: Mean Jaccard vs. other statistics; affects robustness to outliers.
- Graph sparsity: Very sparse graphs may yield unreliable similarity estimates; consider dataset density.

**Failure Signatures**
- NNGS near zero: Neighborhoods do not overlap; embeddings are structurally dissimilar.
- High variance in pairwise Jaccard scores: Inconsistent neighborhood preservation; may indicate noise or instability.
- Low correlation with task accuracy: NNGS may not capture the relevant structure for the task at hand.

**First Experiments**
1. Compute NNGS for two identical embeddings (expect score near 1).
2. Vary k and observe NNGS stability and correlation with task accuracy.
3. Compare NNGS to CKA on a small, controlled dataset with known structural differences.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but it implicitly raises several: how NNGS behaves with contextual embeddings (e.g., BERT), whether it generalizes to clustering or semantic similarity tasks, and the optimal choice of k for different embedding families and dataset sizes.

## Limitations
- Limited evaluation to GloVe and CLIP embeddings; generalizability to other embedding types is unclear.
- Sensitivity to k parameter and dataset density not thoroughly explored.
- Lack of empirical validation for dimensionality invariance claim.

## Confidence

**High**
- Methodological description and experimental setup are clear and reproducible.

**Medium**
- Claim that NNGS outperforms CKA is supported but limited to specific tasks and models.

**Low**
- Generalizability to other embedding types and tasks is uncertain due to narrow experimental scope.

## Next Checks
1. **Parameter Sensitivity Analysis**: Systematically evaluate how NNGS scores vary with different values of k and dataset sizes, and determine optimal parameter ranges for different embedding families.
2. **Cross-Model Generalization**: Test NNGS on a wider variety of embedding models (e.g., BERT, FastText) and downstream tasks (e.g., semantic similarity, clustering) to assess robustness and transferability.
3. **Dimensionality Invariance Validation**: Empirically verify that NNGS remains stable and meaningful when applied to embeddings of varying dimensionalities, including extreme cases (e.g., 2D vs 1024D).