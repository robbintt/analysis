---
ver: rpa2
title: Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives
arxiv_id: '2403.18301'
source_url: https://arxiv.org/abs/2403.18301
tags:
- selmix
- mixup
- recall
- learning
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of optimizing non-decomposable
  objectives like worst-case recall and fairness constraints for deep learning models
  on long-tailed imbalanced datasets. The authors propose SelMix, a selective mixup-based
  fine-tuning technique that determines a sampling distribution to perform mixups
  between samples from particular classes, thereby optimizing the desired objective.
---

# Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives

## Quick Facts
- arXiv ID: 2403.18301
- Source URL: https://arxiv.org/abs/2403.18301
- Reference count: 40
- Primary result: SelMix achieves 5% improvement in min recall on CIFAR-10 LT compared to state-of-the-art methods

## Executive Summary
This paper addresses the challenge of optimizing non-decomposable objectives like worst-case recall and fairness constraints in deep learning models trained on long-tailed imbalanced datasets. The authors propose SelMix, a selective mixup-based fine-tuning technique that determines an optimal sampling distribution for performing mixups between samples from particular classes to optimize the desired objective. SelMix significantly improves performance across various practical non-decomposable objectives and benchmarks, outperforming both empirical and theoretically principled methods while being robust to mismatches between labeled and unlabeled data distributions.

## Method Summary
SelMix is a selective mixup-based fine-tuning technique that optimizes non-decomposable objectives by computing a gain matrix that estimates the improvement in the target metric from mixing samples of different classes. The method derives a sampling distribution PSelMix using softmax scaling of the gain matrix, which balances exploration and exploitation. During fine-tuning, samples are drawn from classes according to this distribution and mixed to update the classifier weights via SGD. The framework can optimize both linear and non-linear non-decomposable objectives through a reformulation of the confusion matrix, addressing limitations of existing works.

## Key Results
- Achieves 5% improvement in min recall on CIFAR-10 LT compared to state-of-the-art methods
- Outperforms empirical and theoretically principled methods across various non-decomposable objectives
- Robust to mismatches between labeled and unlabeled data distributions (ρl ≠ ρu)
- Compatible with multiple mixup variants (CutMix, PuzzleMix) beyond standard feature mixup

## Why This Works (Mechanism)

### Mechanism 1
SelMix selectively chooses which classes to mixup based on expected gain in the non-decomposable objective. The algorithm computes a gain matrix where each entry (i,j) represents the improvement in the target metric from mixing samples of class i and j. It then samples mixup pairs from a softmax-scaled distribution over this gain matrix, favoring pairs that most improve the objective. The linear approximation of metric change along mixup-induced weight directions is assumed to be accurate enough for practical optimization.

### Mechanism 2
The sampling distribution PSelMix balances exploration and exploitation through temperature scaling. PSelMix is defined as a softmax of the gain matrix with inverse temperature parameter s. Small s leads to near-uniform sampling (exploration), large s to greedy selection of highest gain pairs (exploitation), and intermediate s balances both. The softmax-scaled distribution is assumed to provide a good practical compromise between pure exploration and greedy exploitation for metric optimization.

### Mechanism 3
SelMix can optimize both linear and non-linear non-decomposable objectives through reformulation of the confusion matrix. By introducing an unconstrained confusion matrix ˜C and expressing the metric in terms of it, SelMix can compute gradients even for non-linear metrics like G-mean and H-mean, which are not expressible as simple linear functions of confusion matrix entries. The reformulation using ˜C is assumed to preserve the optimization landscape sufficiently for gradient-based methods to work.

## Foundational Learning

- **Concept**: Non-decomposable metrics and their optimization challenges
  - Why needed here: The paper addresses optimization of metrics like min-recall, G-mean, and H-mean that cannot be decomposed into per-sample losses, requiring specialized techniques.
  - Quick check question: What distinguishes a decomposable metric from a non-decomposable one, and why does this distinction matter for optimization?

- **Concept**: Mixup data augmentation and its variants
  - Why needed here: SelMix builds on mixup by selectively choosing which classes to mix, so understanding mixup's mechanics and limitations is essential.
  - Quick check question: How does feature mixup differ from input mixup, and what are the theoretical justifications for mixup's effectiveness?

- **Concept**: Semi-supervised learning and pseudo-labeling
  - Why needed here: SelMix operates in semi-supervised settings where unlabeled data is leveraged through pseudo-labels, so understanding this paradigm is crucial.
  - Quick check question: What are the key challenges in semi-supervised learning with imbalanced data, and how do techniques like FixMatch address them?

## Architecture Onboarding

- **Component map**: Pre-trained feature extractor g -> Linear classification layer W -> Gain computation module -> Sampling distribution module -> Mixup and training loop -> Validation set for gain estimation

- **Critical path**:
  1. Compute centroids zk for each class from validation set
  2. Compute gain matrix G using feature centroids and metric derivatives
  3. Compute PSelMix distribution from G
  4. Sample mixup pairs from PSelMix
  5. Perform mixup and update W via SGD
  6. Periodically refresh pseudo-labels

- **Design tradeoffs**:
  - Feature extractor frozen vs. fine-tuned (frozen is more stable but less adaptive)
  - Gain matrix recomputation frequency (more frequent is more responsive but more expensive)
  - Temperature parameter s in PSelMix (affects exploration/exploitation balance)

- **Failure signatures**:
  - Gains become uniformly small or negative → poor feature extractor or inappropriate metric
  - Training instability → temperature s too high or mixup magnitude too large
  - Slow convergence → insufficient gain matrix updates or inappropriate sampling distribution

- **First 3 experiments**:
  1. Run SelMix on CIFAR-10 LT with mean recall objective, compare against baseline without SelMix
  2. Vary the temperature parameter s and observe effect on convergence speed and final performance
  3. Test SelMix with different mixup variants (CutMix, PuzzleMix) to verify compatibility

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SelMix perform in extreme class imbalance scenarios, such as datasets with a very small number of samples in minority classes?
- Basis in paper: The paper mentions long-tailed imbalanced datasets as a benchmark, but does not explore scenarios with extremely small minority class sample sizes.
- Why unresolved: The paper focuses on evaluating SelMix on standard long-tailed benchmarks without explicitly testing its performance on datasets with extremely few samples in minority classes.
- What evidence would resolve it: Conducting experiments on datasets with an even more extreme class imbalance, such as those with only a handful of samples in minority classes, and comparing SelMix's performance to other methods.

### Open Question 2
- Question: Can SelMix be effectively combined with other semi-supervised learning techniques beyond FixMatch?
- Basis in paper: The paper mentions that SelMix can be combined with other mixup variants like CutMix and PuzzleMix, but does not explore its combination with other semi-supervised learning techniques.
- Why unresolved: The paper primarily focuses on demonstrating SelMix's effectiveness when combined with FixMatch, leaving the question of its compatibility with other semi-supervised learning methods open.
- What evidence would resolve it: Conducting experiments to integrate SelMix with other semi-supervised learning techniques, such as Mean Teacher or MixMatch, and evaluating the performance on various non-decomposable objectives.

### Open Question 3
- Question: What is the theoretical generalization bound for classifiers obtained through SelMix?
- Basis in paper: The paper mentions the potential for future work to characterize the classifier obtained through SelMix using a generalization bound, but does not provide one.
- Why unresolved: The paper focuses on the empirical validation of SelMix and does not delve into the theoretical analysis of its generalization capabilities.
- What evidence would resolve it: Deriving a theoretical generalization bound for classifiers trained using SelMix, similar to existing work on mixup-based methods for accuracy optimization.

## Limitations

- The theoretical foundation for SelMix's gain computation relies on accurate feature representations and stable metric gradients, which may not hold in all scenarios
- The temperature parameter s in the sampling distribution PSelMix significantly affects performance but lacks clear theoretical guidance for selection
- The paper claims robustness to label distribution mismatches (ρl ≠ ρu) but provides limited empirical validation of this claim

## Confidence

- **Medium**: The theoretical foundation for SelMix's gain computation relies on accurate feature representations and stable metric gradients
- **Medium**: The temperature parameter s in the sampling distribution PSelMix significantly affects performance but lacks clear theoretical guidance for selection
- **Low**: The paper claims robustness to label distribution mismatches (ρl ≠ ρu) but provides limited empirical validation

## Next Checks

1. Implement monitoring of the gain matrix entries and their gradients during training to verify that the linear approximation remains valid throughout optimization, particularly for metrics with non-linear formulations.

2. Systematically vary the temperature parameter s across multiple orders of magnitude and different datasets to establish guidelines for appropriate scaling based on problem characteristics.

3. Design experiments where the labeled and unlabeled data have deliberately mismatched class distributions to quantify the degradation in SelMix performance and identify thresholds where the method fails.