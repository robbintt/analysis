---
ver: rpa2
title: An Explainable Proxy Model for Multiabel Audio Segmentation
arxiv_id: '2401.08268'
source_url: https://arxiv.org/abs/2401.08268
tags:
- speech
- proxy
- segmentation
- audio
- teacher
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces an explainable proxy model for multilabel
  audio segmentation, addressing speech, music, noise, and overlapped speech detection.
  The core idea uses non-negative matrix factorization (NMF) to map embeddings from
  a pre-trained teacher model to the frequency domain, enabling identification of
  relevant frequency bins for classification.
---

# An Explainable Proxy Model for Multiabel Audio Segmentation

## Quick Facts
- arXiv ID: 2401.08268
- Source URL: https://arxiv.org/abs/2401.08268
- Authors: Théo Mariotte; Antonio Almudévar; Marie Tahon; Alfonso Ortega
- Reference count: 0
- Primary result: WavLM-based proxy with pre-learned NMF dictionary matches teacher F1-scores (96.8% speech, 79.5% noise, 93.1% music, 61.4% overlap on DiHard III)

## Executive Summary
This work introduces an explainable proxy model for multilabel audio segmentation that detects speech, music, noise, and overlapped speech. The approach uses non-negative matrix factorization (NMF) to map teacher model embeddings to the frequency domain, enabling identification of relevant frequency bins for classification. Two proxy architectures are explored: one using spectrograms and another using WavLM features. The WavLM-based proxy with pre-learned NMF dictionary achieves performance matching the teacher model while providing interpretable frequency-domain explanations.

## Method Summary
The method employs teacher-student knowledge distillation where a pre-trained WavLM model acts as the teacher. The proxy model learns to mimic the teacher's multilabel segmentation outputs (speech, music, noise, overlapped speech) while incorporating an NMF layer that maps its embeddings to reconstruct input spectrograms. This reconstruction enables frequency-domain interpretability. Two proxy architectures are evaluated: one using log-spectrograms as input with four TCN blocks, and another using WavLM features as input with two TCN blocks. The NMF dictionary is pre-trained on a subset of AragonRadio to ensure stable reconstruction quality. Training combines classification loss (KL divergence), NMF reconstruction loss, and L1 sparsity regularization.

## Key Results
- WavLM-based proxy with pre-learned NMF dictionary matches teacher F1-scores of 96.8% (speech), 79.5% (noise), 93.1% (music), and 61.4% (overlapped speech) on DiHard III
- Spectrogram-based proxy underperforms WavLM-based version due to limited feature richness
- NMF relevance scoring identifies frequency components most correlated with class decisions (speech: 100Hz-1kHz, music: 200Hz-4kHz)
- Pre-learning NMF dictionary avoids high-frequency reconstruction errors seen with joint training

## Why This Works (Mechanism)

### Mechanism 1
WavLM features capture richer semantic information than spectrograms, enabling better mimicry of teacher decision boundaries. Pre-learning the NMF dictionary avoids high-frequency reconstruction errors. Core assumption: WavLM embeddings contain sufficient information to reconstruct meaningful frequency-domain representations via NMF. Evidence: Using WavLM features drastically improves segmentation performance; pre-learned dictionary delivers similar or better performance than joint training. Break condition: If WavLM features don't align with NMF factorization space or pre-trained dictionary doesn't generalize.

### Mechanism 2
NMF embedding acts as interpretable bottleneck preserving discriminative frequency components for each class. NMF decomposition extracts sparse activations highlighting which frequency bins are active for each class. Core assumption: Class-discriminative information is encoded in specific frequency bands that NMF can isolate. Evidence: Relevant components for speech located between 100Hz and 1kHz; relevance scoring identifies components most correlated with class decisions. Break condition: If class boundaries rely on temporal patterns rather than frequency localization.

### Mechanism 3
Two-stage training (teacher → proxy with NMF) enables high performance and interpretability without retraining teacher. Teacher provides soft labels while NMF enforces frequency-domain reconstruction loss aligning proxy's embedding with physically meaningful spectral patterns. Core assumption: Teacher's logits contain sufficient distributional information for proxy to learn without direct signal supervision. Evidence: Similar performances to pre-trained black box model while showing strong explainability features. Break condition: If teacher logits are too noisy or not discriminative enough.

## Foundational Learning

- Concept: Non-negative Matrix Factorization (NMF)
  - Why needed here: Decomposes embedding into additive frequency components enabling direct mapping from latent features to interpretable spectral patterns
  - Quick check question: If X is a log-spectrogram, what does the factorization X ≈ WH represent in terms of signal components?

- Concept: Teacher-student knowledge distillation
  - Why needed here: Allows proxy to mimic teacher's decision boundaries without requiring labeled data for each task, leveraging teacher's learned representations
  - Quick check question: In binary KL divergence LKD, what does matching teacher's output distribution achieve for the proxy?

- Concept: Multilabel classification with sigmoid outputs
  - Why needed here: Each frame can belong to multiple classes (e.g., speech + overlap), so sigmoid activations are needed instead of softmax
  - Quick check question: How does sigmoid output differ from softmax in the context of multilabel vs multiclass segmentation?

## Architecture Onboarding

- Component map:
  - Teacher: WavLM Large → bottleneck → 3 TCN blocks → linear → sigmoid
  - Proxy (WavLM input): WavLM features → 2 TCN blocks → H (K×T) → Θ (linear) → sigmoid
  - Proxy (Spectrogram input): log-spectrogram → 4 TCN blocks → H (K×T) → Θ (linear) → sigmoid
  - NMF layer: H → W (pre-trained) → X̃ (reconstruction)

- Critical path:
  1. Input audio → feature extraction (WavLM or spectrogram)
  2. TCN encoder → sparse embedding H
  3. Linear classifier Θ → multilabel logits
  4. NMF reconstruction WH → loss comparison to input spectrogram

- Design tradeoffs:
  - Using WavLM vs spectrogram: richer features vs simpler pipeline
  - Pre-learned vs trained W: stable reconstruction vs adaptability
  - Sparsity γ: cleaner explanations vs potential loss of information

- Failure signatures:
  - Low reconstruction quality → poor frequency-domain explanations
  - Proxy logits diverging from teacher → training instability
  - Sparse H collapsing to zeros → no discriminative components

- First 3 experiments:
  1. Train spectrogram-based proxy and evaluate reconstruction loss to confirm NMF integration
  2. Train WavLM-based proxy with pre-learned W; compare F1 scores to teacher
  3. Vary NMF rank K and sparsity γ; observe effect on segmentation performance and explanation clarity

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on pre-trained NMF dictionary that may not generalize across diverse acoustic environments
- Limited validation of cross-domain dictionary transfer to domains not represented in training subset
- Tradeoff between sparsity for explanation clarity and potential loss of classification performance not fully characterized

## Confidence
**High Confidence**: Experimental results demonstrating comparable F1-scores between WavLM-based proxy and teacher model; NMF mechanism for frequency-domain interpretability is well-supported.

**Medium Confidence**: Claim that pre-learned NMF dictionaries consistently outperform jointly trained ones across different datasets; limited testing on significantly different acoustic conditions.

**Low Confidence**: Assertion that NMF relevance scoring provides meaningful global interpretability through class prototypes; limited validation that frequency components identified as relevant correspond to actual decision-making processes.

## Next Checks
1. Cross-domain dictionary validation: Test pre-learned NMF dictionary on audio from domains not represented in training subset to quantify generalization limits.

2. Ablation study on sparsity: Systematically vary sparsity coefficient γ across wider range and measure tradeoff between explanation quality and classification performance to identify optimal operating points.

3. Alternative interpretability validation: Compare NMF-based relevance scores against gradient-based saliency methods or attention visualization to verify identified frequency components correspond to decision-critical regions.