---
ver: rpa2
title: 'Dense Passage Retrieval: Is it Retrieving?'
arxiv_id: '2402.11035'
source_url: https://arxiv.org/abs/2402.11035
tags:
- knowledge
- bert
- retrieval
- training
- pre-trained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether dense passage retrieval (DPR) models
  are truly retrieving new knowledge or merely improving access to existing knowledge
  stored in large language models (LLMs). The authors use a combination of probing,
  layer activation analysis, and model editing to analyze DPR-trained models.
---

# Dense Passage Retrieval: Is it Retrieving?

## Quick Facts
- arXiv ID: 2402.11035
- Source URL: https://arxiv.org/abs/2402.11035
- Reference count: 26
- DPR training decentralizes knowledge storage but doesn't add new knowledge to the model

## Executive Summary
This paper investigates whether dense passage retrieval (DPR) models truly retrieve new knowledge or merely improve access to existing knowledge stored in large language models. Through probing, layer activation analysis, and model editing experiments, the authors demonstrate that DPR training decentralizes how knowledge is stored in the network by creating multiple access pathways while maintaining the same volume of stored knowledge. The study concludes that DPR's retrieval ability is bounded by the pre-trained model's internal knowledge, suggesting that DPR fine-tuning restructures knowledge access patterns rather than adding new facts.

## Method Summary
The authors analyze DPR-trained BERT models using three main approaches: linear probing across all layers to compare discriminative features between pre-trained and DPR-trained models, neuron activation analysis with knowledge attribution methods to examine changes in knowledge storage patterns, and model editing techniques to test whether DPR training adds new knowledge by removing facts from pre-trained BERT and checking if they reappear after DPR training. The experiments use BERT-base backbone, Natural Questions dataset for probing, and 21M Wikipedia passages for retrieval experiments.

## Key Results
- DPR training increases the number of weakly activated neurons while maintaining the same volume of stored knowledge
- Knowledge removal experiments show 81-100% consistency between pre-trained and DPR-trained models, indicating DPR doesn't add new knowledge
- DPR improves retrieval by making knowledge more "retrievable" through better semantic matching, not by increasing overall knowledge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DPR fine-tuning decentralizes knowledge storage by increasing the number of weakly activated neurons while maintaining the same volume of stored knowledge.
- Mechanism: DPR training expands the set of "keys" available to access semantic knowledge while decreasing the accessible volume of syntactic knowledge, creating multiple access pathways to the same information.
- Core assumption: The model's internal knowledge remains constant during DPR fine-tuning; only the access patterns change.
- Evidence anchors: Abstract states DPR decentralizes knowledge storage; section explains DPR expands access keys while reducing syntactic knowledge volume; corpus found 25 related papers.

### Mechanism 2
- Claim: DPR training does not add new knowledge to the model; its retrieval ability is bounded by the pre-existing knowledge in the pre-trained model.
- Mechanism: Knowledge removal experiments demonstrate that facts successfully removed from pre-trained BERT are also absent in DPR-trained BERT, indicating DPR training doesn't recover or add back removed knowledge.
- Core assumption: The model's ability to retrieve information is limited to what it already knows internally.
- Evidence anchors: Abstract states internal knowledge bounds retrieval; section shows 81-100% consistency in removed facts between models; limited corpus evidence specifically addressing knowledge addition.

### Mechanism 3
- Claim: DPR training improves retrieval by making knowledge more "retrievable" through better semantic matching, not by increasing the model's overall knowledge.
- Mechanism: DPR training restructures how knowledge is accessed, allowing morphologically distinct but semantically related text to trigger the same knowledge through more neuron activations per query.
- Core assumption: The model's retrieval performance improves due to better access to existing knowledge, not due to learning new facts.
- Evidence anchors: Abstract states DPR enhances alignment between queries and relevant textual data; section shows DPR increases strongly activated neurons for better information access; weak corpus evidence for specific semantic matching mechanisms.

## Foundational Learning

- Concept: Knowledge Representation in Neural Networks
  - Why needed here: Understanding how neural networks store and access knowledge is crucial for interpreting the effects of DPR training on knowledge decentralization.
  - Quick check question: How do feedforward layers in transformer architectures act as key-value memory stores of knowledge?

- Concept: Contrastive Learning
  - Why needed here: DPR employs contrastive training to align query and passage embeddings, which is fundamental to understanding its training mechanism.
  - Quick check question: What is the role of contrastive loss in aligning query and passage embeddings during DPR training?

- Concept: Linear Probing
  - Why needed here: Linear probing is used to evaluate the discriminative features of pre-trained and DPR-trained models, helping to assess knowledge consistency.
  - Quick check question: How does linear probing reveal the mutual information between a model's primary training task and a probing task?

## Architecture Onboarding

- Component map: Pre-trained BERT backbone -> Query encoder (for embedding queries) -> Context encoder (for embedding passages) -> Contrastive loss function -> Knowledge attribution method (for analyzing neuron activations) -> Model editing techniques (for knowledge removal experiments)

- Critical path: 1. Initialize pre-trained BERT model 2. Apply DPR fine-tuning to align query and passage embeddings 3. Analyze changes in knowledge storage and retrieval using probing, activation analysis, and model editing 4. Interpret results to understand DPR's effects on knowledge decentralization and retrieval boundaries

- Design tradeoffs: DPR training improves retrieval but doesn't add new knowledge, limiting effectiveness for queries requiring facts not already in the model; decentralizing knowledge storage increases pathways to access information but may reduce precision of individual neuron activations

- Failure signatures: If DPR training fails to improve retrieval performance, it may indicate issues with fine-tuning process or knowledge base quality; if knowledge removal experiments show DPR recovers removed facts, it would suggest DPR adds new knowledge

- First 3 experiments: 1. Linear probing to compare discriminative features between pre-trained and DPR-trained BERT 2. Neuron activation analysis to examine changes in knowledge storage patterns 3. Knowledge removal experiments to test whether DPR training adds new knowledge to the model

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does DPR training actually add new knowledge to the model or only restructure existing knowledge?
- Basis in paper: [explicit] The authors found that facts removed from BERT before DPR training remained absent after DPR training, suggesting DPR does not add new knowledge.
- Why unresolved: While experiments show facts stay removed, it's unclear if DPR could potentially add novel facts under different training conditions or with larger datasets.
- What evidence would resolve it: Experiments testing DPR training with diverse, extensive knowledge sources and measuring any newly acquired factual knowledge post-training.

### Open Question 2
- Question: How does the decentralized knowledge structure created by DPR training affect retrieval performance in different domains or languages?
- Basis in paper: [inferred] The paper shows DPR creates multiple access pathways to knowledge, but only tests on English Wikipedia data.
- Why unresolved: The effectiveness of this decentralized structure across different types of knowledge bases or languages remains untested.
- What evidence would resolve it: Comparative studies of DPR performance across multiple languages and domain-specific knowledge bases.

### Open Question 3
- Question: Can the knowledge uncertainty in DPR models be quantified and used to improve retrieval accuracy?
- Basis in paper: [explicit] The authors suggest modeling and incorporating knowledge uncertainty as a future direction.
- Why unresolved: Current DPR models don't explicitly handle uncertainty, and the paper doesn't explore methods to measure or utilize it.
- What evidence would resolve it: Development and testing of uncertainty-aware DPR models that show improved performance over standard DPR.

## Limitations

- The analysis focuses primarily on BERT architecture, which may not generalize to other transformer variants with different attention mechanisms
- The study uses static knowledge attribution methods that may not capture dynamic, context-dependent knowledge access patterns during actual retrieval queries
- The claim that DPR exclusively decentralizes knowledge access without adding new knowledge rests on a single knowledge removal experiment

## Confidence

- **High Confidence**: DPR training decentralizes knowledge storage by increasing the number of weakly activated neurons while maintaining constant knowledge volume
- **Medium Confidence**: DPR training does not add new knowledge to the model
- **Medium Confidence**: DPR improves retrieval by making knowledge more retrievable through better semantic matching

## Next Checks

1. **Knowledge Type Specificity Test**: Design experiments to determine whether DPR training shows different behavior for different knowledge types (factual, procedural, contextual) to verify the universality of the decentralization mechanism.

2. **Cross-Architecture Generalization**: Apply the same analysis pipeline to DPR-trained models based on other transformer architectures (e.g., RoBERTa, DeBERTa) to assess whether the decentralization pattern holds across different model families.

3. **Dynamic Knowledge Access Analysis**: Implement runtime monitoring of knowledge access patterns during actual retrieval queries to capture context-dependent variations that static analysis might miss, particularly for semantically complex queries.