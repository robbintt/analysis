---
ver: rpa2
title: A Collocation-based Method for Addressing Challenges in Word-level Metric Differential
  Privacy
arxiv_id: '2407.00638'
source_url: https://arxiv.org/abs/2407.00638
tags: []
core_contribution: "The study addresses the challenge of semantic incoherence and\
  \ length variability in word-level Metric Differential Privacy (MLDP) mechanisms\
  \ for text privatization. It proposes using collocations\u2014multi-word expressions\u2014\
  as the basis for perturbations instead of individual words."
---

# A Collocation-based Method for Addressing Challenges in Word-level Metric Differential Privacy

## Quick Facts
- arXiv ID: 2407.00638
- Source URL: https://arxiv.org/abs/2407.00638
- Authors: Stephen Meisenbacher; Maulik Chevli; Florian Matthes
- Reference count: 40
- Primary result: Collocation-based perturbations improve utility (average F1 scores up to 94.3%) and preserve semantic similarity (cosine similarity up to 0.96) compared to word-level approaches

## Executive Summary
This paper addresses the challenge of semantic incoherence and length variability in word-level Metric Differential Privacy (MLDP) mechanisms for text privatization. The authors propose using collocations—multi-word expressions—as the basis for perturbations instead of individual words. By extracting bigram and trigram collocations using PMI scores, training joint n-gram embedding models, and applying MLDP mechanisms at the collocation level, the method achieves improved utility, better semantic preservation, and comparable privacy guarantees.

## Method Summary
The method involves extracting collocations from a large corpus using PMI scores, training joint n-gram embedding models (300-dim Word2Vec) using Greedy Sequential Tokenization (GST) and Max Score Tokenization (MST) algorithms, and applying MLDP mechanisms to tokenized text. The approach is evaluated on four GLUE datasets using micro F1 scores, cosine similarity, and privacy metrics including macro F1 for authorship/gender identification tasks. Document-level privacy budgets are used with fine-tuning of DEBERTA-V3-BASE models for 1 epoch on each dataset variant.

## Key Results
- Collocation-based perturbations achieve average F1 scores up to 94.3%, significantly outperforming word-level approaches
- Semantic similarity between original and privatized texts reaches cosine similarity up to 0.96
- Privacy preservation shows relative gain up to 0.15 while maintaining utility
- Entailment tasks like RTE remain challenging post-perturbation but show improvement over word-level methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Collocation-level tokenization preserves semantic coherence better than word-level because collocations bundle meaning and grammar, reducing isolated word substitutions.
- Mechanism: By replacing single words with frequently occurring multi-word expressions (bigrams/trigrams) and perturbing these as atomic units, the privatization process maintains contextual relationships.
- Core assumption: Semantic coherence is preserved when perturbations occur on multi-word units rather than individual words.
- Evidence anchors:
  - [abstract] "collocation-based perturbations improve utility (average F1 scores up to 94.3%), preserve semantic similarity (cosine similarity up to 0.96)"
  - [section 4.1] "collocations represent groups of words with bundled meaning, and within a collocation, proper grammar must be upheld"
  - [corpus] Weak - no direct neighbor studies explicitly testing semantic coherence from collocation-based DP, but related works on n-gram embeddings support this.
- Break condition: If collocations are incorrectly extracted (e.g., using poor association measures), the semantic coherence benefit is lost and grammatical errors may increase.

### Mechanism 2
- Claim: Joint n-gram embedding models provide richer search spaces, improving utility and privacy by reducing self-perturbation.
- Mechanism: Training a single embedding space containing unigrams, bigrams, and trigrams allows perturbations to map to a wider variety of token types, decreasing the chance of mapping back to the original token.
- Core assumption: Expanding the embedding space beyond single words increases the probability of meaningful replacements and reduces privacy leakage.
- Evidence anchors:
  - [abstract] "leveraging collocations enhances the effectiveness of MLDP mechanisms while addressing key limitations of word-level privatization"
  - [section 4.2] "joint training process improves the quality of single-word embeddings" and "n-gram embeddings can improve a variety of NLP tasks"
  - [corpus] Weak - the neighbor corpus does not contain studies on embedding space expansion for DP, but n-gram embedding literature supports this assumption.
- Break condition: If the embedding space is too large relative to the available data, embeddings may become noisy and degrade utility.

### Mechanism 3
- Claim: Collocation-based perturbation achieves better privacy-utility trade-off by reducing the number of perturbations needed.
- Mechanism: By perturbing fewer, larger units (collocations instead of individual words), the same privacy budget achieves more effective obfuscation with less utility loss.
- Core assumption: Fewer perturbations with the same budget yield better privacy and utility outcomes than many small perturbations.
- Evidence anchors:
  - [abstract] "maintain comparable privacy (relative gain up to 0.15)" and "improve output text coherence, introduce generated length variability, and boost utility"
  - [section 5.5] "texts perturbed via S2 hold tighter document-level privacy guarantees than S3/4, yet they are still able to preserve utility better on average"
  - [corpus] Weak - no direct neighbor studies comparing perturbation counts, but the composition theorem in DP supports this reasoning.
- Break condition: If collocations are too long, they may be too rare to perturb meaningfully, reducing effectiveness.

## Foundational Learning

- Concept: Pointwise Mutual Information (PMI)
  - Why needed here: PMI is used to identify meaningful collocations by measuring how much the presence of one word tells us about another.
  - Quick check question: What does a high PMI score between two words indicate about their co-occurrence?

- Concept: Differential Privacy (DP) composition
  - Why needed here: Understanding how privacy budgets compose across tokens is critical for allocating budgets correctly at the collocation level.
  - Quick check question: If a document-level budget ε is divided equally among n tokens, what is the budget per token under basic composition?

- Concept: Embedding space metrics
  - Why needed here: The distance metric in the embedding space (e.g., Euclidean) determines how perturbations are calibrated and affects privacy guarantees.
  - Quick check question: In Metric DP, how does the distance between two tokens influence the probability ratio of perturbing to the same output?

## Architecture Onboarding

- Component map: Collocation extraction module (PMI-based, GST and MST algorithms) -> Joint n-gram embedding model trainer -> MLDP mechanism adapter -> Evaluation pipeline

- Critical path: 1) Extract collocations from corpus using PMI 2) Train joint embedding model on tokenized corpus 3) Apply tokenization algorithm to input text 4) Run MLDP mechanism on tokenized text 5) Evaluate privatized outputs

- Design tradeoffs:
  - PMI threshold vs. number of collocations: higher threshold reduces noise but may miss useful collocations
  - Embedding dimension vs. training time: larger dimensions may improve quality but increase resource needs
  - Greedy vs. Max Score tokenization: greedy is faster but may not maximize PMI score

- Failure signatures:
  - Low utility: embedding model may be too sparse or PMI extraction too aggressive
  - Poor privacy: too few perturbations or embeddings too close together
  - Grammatical errors: collocations incorrectly extracted (e.g., containing connectors)

- First 3 experiments:
  1. Run GST and MST on a small sample corpus and inspect extracted collocations for validity
  2. Train a joint embedding model on the sample and check nearest neighbors for semantic coherence
  3. Apply MADLIB mechanism with word-level vs collocation-level embeddings on a small dataset and compare F1 scores

## Open Questions the Paper Calls Out

- Question: How does the use of collocations affect the trade-off between privacy and utility compared to word-level methods across different types of NLP tasks (e.g., sentiment analysis vs. entailment tasks)?
- Basis in paper: Explicit - The paper demonstrates that collocation-based perturbations improve utility and preserve semantic similarity compared to word-level approaches, but notes that entailment tasks like RTE are more challenging post-perturbation.
- Why unresolved: While the paper shows improved utility and semantic coherence, it does not provide a comprehensive analysis of how these benefits vary across different NLP task types.
- What evidence would resolve it: A detailed comparative study across a broader range of NLP tasks, analyzing both utility and privacy outcomes for collocation-based vs. word-level perturbations.

## Limitations

- The privacy analysis relies on relative gain metrics that may not capture all leakage scenarios, particularly in the context of emerging reconstruction attacks on differentially private text.
- The choice of PMI threshold (≥2.0) and exclusion of connector words may arbitrarily eliminate meaningful collocations.
- The study does not explore alternative collocation extraction methods beyond PMI, leaving potential improvements unexamined.

## Confidence

- High confidence in the core utility findings (F1 scores up to 94.3%) due to direct experimental evidence from GLUE benchmark tasks
- Medium confidence in the semantic similarity claims (cosine similarity up to 0.96) as these depend on the quality of the embedding models and evaluation methodology
- Low confidence in the privacy guarantees (relative gain up to 0.15) given the limited scope of the privacy evaluation and lack of robustness testing against advanced reconstruction techniques

## Next Checks

1. Extract collocations from a corpus more aligned with GLUE datasets (e.g., Wikipedia or news articles) and re-run the utility experiments to assess robustness to domain shift.

2. Implement a reconstruction attack using a large language model on the privatized outputs and measure the success rate in recovering original sensitive attributes compared to the word-level baseline.

3. Replace PMI with other collocation extraction methods (e.g., chi-squared test, t-score) and compare the resulting utility and privacy trade-offs to validate that the observed benefits are not specific to PMI.