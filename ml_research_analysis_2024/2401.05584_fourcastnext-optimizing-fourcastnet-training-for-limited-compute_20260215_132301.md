---
ver: rpa2
title: 'FourCastNeXt: Optimizing FourCastNet Training for Limited Compute'
arxiv_id: '2401.05584'
source_url: https://arxiv.org/abs/2401.05584
tags: []
core_contribution: FourCastNeXt optimizes the FourCastNet global weather forecasting
  model, achieving comparable accuracy to the baseline while reducing training compute
  requirements by ~95%. Key innovations include data augmentation for larger training
  sets, deep-norm initialization for stable training, smaller 4x4 patch embeddings,
  temporal flow field prediction to reduce learning complexity, and multi-step fine-tuning
  with prior preservation.
---

# FourCastNeXt: Optimizing FourCastNet Training for Limited Compute

## Quick Facts
- **arXiv ID**: 2401.05584
- **Source URL**: https://arxiv.org/abs/2401.05584
- **Reference count**: 0
- **Primary result**: ~95% reduction in training compute while maintaining comparable accuracy

## Executive Summary
FourCastNeXt optimizes the FourCastNet global weather forecasting model to achieve comparable accuracy while reducing training compute requirements by approximately 95%. The model was trained on just four V100 GPUs in 35 hours versus 32 A100 GPUs for the baseline. FourCastNeXt achieves an average RMSE of 27.08 across 20 atmospheric variables, compared to 38.42 for the baseline, with particular improvements in surface pressure and 50 hPa geopotential height. The key innovations include data augmentation for larger training sets, deep-norm initialization for stable training, smaller 4x4 patch embeddings, temporal flow field prediction to reduce learning complexity, and multi-step fine-tuning with prior preservation.

## Method Summary
FourCastNeXt implements a series of architectural and training optimizations to FourCastNet. The model uses 4x4 patch embeddings instead of 8x8 for better fine-grained feature capture, applies deep-norm initialization to stabilize post-norm transformer training, and introduces temporal flow field prediction to reduce learning complexity by predicting pixel-wise differences between time steps. The training process involves two stages: single-step pretraining followed by multi-step fine-tuning with prior preservation to prevent catastrophic forgetting. The model was trained using the LAMB optimizer, cosine learning rate schedule, and fp16 mixed precision on a distributed setup with four V100 GPUs.

## Key Results
- Average RMSE of 27.08 across 20 atmospheric variables versus 38.42 for baseline
- Trained on four V100 GPUs in 35 hours versus 32 A100 GPUs for baseline
- Achieved RMSE of 43.66 on surface pressure (sp) versus 137.29 for baseline
- Achieved RMSE of 78.30 on 50 hPa geopotential height (z50) versus 79.49 for baseline

## Why This Works (Mechanism)

### Mechanism 1: Data Augmentation for Training Set Expansion
Expanding the training set from 50k examples to over 1 billion via random time step selection, random spatial cropping, and on-the-fly training example generation enables better model generalization and reduces overfitting without pre-computing and storing all examples.

### Mechanism 2: Deep-Norm Initialization for Stable Training
Modifying FourCastNet to use post-norm for residual branches of AFNO blocks and applying deep-norm initialization stabilizes early training while maintaining the performance benefits of post-norm transformers, allowing for faster convergence.

### Mechanism 3: Temporal Flow Field Prediction for Reduced Learning Complexity
Learning temporal flow fields reduces complexity by having the model predict pixel-wise differences between time steps rather than absolute values. The model predicts both value and flow fields separately, with the flow head initialized with near-zero weights to start with identity warping.

## Foundational Learning

- **Concept: Fourier Neural Operators (FNO)**
  - Why needed here: FourCastNeXt uses Adaptive Fourier Neural Operators (AFNO) blocks, which are based on FNO. Understanding FNO is crucial for grasping how FourCastNeXt modifies the architecture.
  - Quick check question: What is the key advantage of FNO over traditional convolutional approaches for weather modeling?

- **Concept: Vision Transformers and Patch Embeddings**
  - Why needed here: FourCastNeXt modifies the patch size from 8x8 to 4x4 for better fine-grained feature capture. Understanding vision transformer architecture and patch embeddings is essential.
  - Quick check question: How does reducing patch size from 8x8 to 4x4 affect the model's receptive field and computational complexity?

- **Concept: Catastrophic Forgetting in Fine-tuning**
  - Why needed here: FourCastNeXt uses multi-step fine-tuning with prior preservation to prevent catastrophic forgetting when adapting from single-step to multi-step prediction.
  - Quick check question: What is catastrophic forgetting, and why is it particularly problematic when fine-tuning from single-step to multi-step weather forecasting?

## Architecture Onboarding

- **Component map**: ERA5 data (721x1440 spatial, 20 variables) -> 4x4 patch embedding -> AFNO blocks (post-norm, deep-norm) -> Value and flow field heads -> Temporal warping + residual -> Output predictions

- **Critical path**: 
  1. Data loading and augmentation (on-the-fly generation)
  2. Patch embedding (4x4 patches)
  3. AFNO blocks with post-norm and deep-norm initialization
  4. Value and flow field heads
  5. Temporal warping and residual computation
  6. Loss computation (L2 loss on predictions vs. ground truth)

- **Design tradeoffs**:
  - Patch size: 4x4 vs 8x8 - smaller patches capture more fine-grained features but increase computational cost
  - Normalization: Post-norm vs pre-norm - post-norm offers better performance but requires stabilization techniques
  - Temporal modeling: Direct prediction vs flow field - flow field reduces complexity but adds another prediction head
  - Fine-tuning strategy: Single-step vs multi-step - multi-step enables longer forecasts but requires careful handling of catastrophic forgetting

- **Failure signatures**:
  - Training divergence: Often indicates issues with learning rate, deep-norm initialization, or data pipeline
  - Poor single-step performance: Could indicate problems with embedding patch size or AFNO block configuration
  - Degradation during fine-tuning: Suggests catastrophic forgetting or improper prior preservation
  - Memory issues: May result from patch size reduction or insufficient gradient checkpointing

- **First 3 experiments**:
  1. Reproduce baseline: Train NVLab FourCastNet baseline with 1% compute to verify understanding of the original architecture
  2. Single improvement: Implement and test just the 4x4 patch size change while keeping other components baseline
  3. Flow field ablation: Train with and without the temporal flow field prediction to quantify its impact on convergence and accuracy

## Open Questions the Paper Calls Out

### Open Question 1
**Question**: What is the physical significance of the improved performance on surface pressure (sp) and 50 hPa geopotential height (z50) variables in FourCastNeXt compared to the baseline?
**Basis in paper**: The paper reports that FourCastNeXt achieves lower RMSE on sp (43.66 vs 137.29) and z50 (78.30 vs 79.49) compared to the baseline, with particular improvements in these variables.
**Why unresolved**: The paper does not provide any physical interpretation or analysis of why these specific variables show greater improvement, or what this means for weather forecasting applications.
**What evidence would resolve it**: Physical analysis comparing the predicted vs actual patterns for sp and z50, sensitivity analysis of these variables to input features, and comparison with meteorological experts on the significance of these improvements.

### Open Question 2
**Question**: How does the model's performance degrade when predicting beyond 4 time steps, and what architectural changes could enable longer-range forecasting?
**Basis in paper**: The paper notes that "Fine-tuning more steps does not yield better results" and attributes this to "the model architecture lacks the ability to capture long-range temporal dependencies."
**Why unresolved**: The paper does not explore specific architectural modifications or provide detailed analysis of performance degradation patterns beyond 4 steps.
**What evidence would resolve it**: Comparative analysis of prediction errors at different time horizons, ablation studies testing various architectural modifications (e.g., attention mechanisms, recurrence), and experiments with different temporal resolutions.

### Open Question 3
**Question**: How would the FourCastNeXt optimization techniques generalize to other atmospheric variables or different climate domains beyond weather forecasting?
**Basis in paper**: The authors state "we hypothesize that the techniques employed in this work are general" and plan to investigate "the possibility of generalizing these techniques to other model architectures in the climate and weather domain."
**Why unresolved**: The paper only tests the methods on the specific set of ERA5 variables used in FourCastNet, without exploring generalization to other domains or variables.
**What evidence would resolve it**: Experiments applying the optimization techniques to different climate datasets (oceanography, hydrology), testing on variables not included in the original FourCastNet, and cross-domain performance comparisons.

## Limitations
- The model architecture lacks the ability to capture long-range temporal dependencies, limiting performance beyond 4 time steps
- Some implementation details, particularly the prior preservation loss in multi-step fine-tuning, are not fully specified
- The effectiveness of deep-norm initialization for post-norm transformers in weather forecasting applications requires further validation

## Confidence

- **High Confidence**: The 95% reduction in compute requirements is well-supported by the specific hardware and training time comparisons provided
- **Medium Confidence**: The improvements in specific variables (sp, z50) are demonstrated but may depend on the particular weather patterns in the test period
- **Medium Confidence**: The temporal flow field approach shows theoretical promise but lacks extensive ablation studies to quantify its contribution

## Next Checks

1. **Architecture Ablation**: Systematically remove each key innovation (deep-norm, 4x4 patches, flow field, fine-tuning strategy) individually to quantify their separate contributions to the final performance

2. **Weather Regime Testing**: Evaluate model performance across different atmospheric conditions (tropical, polar, mid-latitude) to assess generalization beyond the specific test period

3. **Compute-Efficiency Trade-off**: Train the model with varying levels of compute (2, 4, 8 GPUs) to establish the relationship between resource allocation and accuracy, identifying the point of diminishing returns