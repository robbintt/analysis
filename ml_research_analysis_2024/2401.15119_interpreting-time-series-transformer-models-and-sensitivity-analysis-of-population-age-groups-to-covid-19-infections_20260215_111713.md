---
ver: rpa2
title: Interpreting Time Series Transformer Models and Sensitivity Analysis of Population
  Age Groups to COVID-19 Infections
arxiv_id: '2401.15119'
source_url: https://arxiv.org/abs/2401.15119
tags: []
core_contribution: This paper interprets transformer-based time series models using
  local attribution methods to understand the impact of individual features on predictions.
  The authors apply this framework to COVID-19 infection forecasting using three years
  of daily case data across 3,142 US counties, with 13 input features from the past
  two weeks used to predict cases for the next two weeks.
---

# Interpreting Time Series Transformer Models and Sensitivity Analysis of Population Age Groups to COVID-19 Infections

## Quick Facts
- arXiv ID: 2401.15119
- Source URL: https://arxiv.org/abs/2401.15119
- Reference count: 10
- One-line primary result: Applied perturbation-based interpretation framework to COVID-19 forecasting, identifying FEDformer as best model and Morris Sensitivity as best interpretation method

## Executive Summary
This paper develops a framework for interpreting transformer-based time series models using local attribution methods to understand how individual features impact predictions. The authors apply this framework to COVID-19 infection forecasting using three years of daily case data across 3,142 US counties, with 13 input features from the past two weeks used to predict cases for the next two weeks. They evaluate six transformer models and eight interpretation methods, finding FEDformer performs best (MAE 30.19, RMSE 182.2) and Morris Sensitivity excels at capturing feature importance. A novel contribution is evaluating age group sensitivity using weekly CDC case data, demonstrating the framework's ability to capture age-specific infection patterns.

## Method Summary
The authors develop a perturbation-based local attribution framework that masks individual features or groups of features and measures the resulting change in model output to quantify feature importance. They apply this framework to COVID-19 infection forecasting, using three years of daily case data for 3,142 US counties with 13 input features from the past two weeks to predict cases for the next two weeks. The framework evaluates six transformer models (TimesNet, PatchTST, FEDformer, Autoformer, Crossformer) and eight interpretation methods (Feature Ablation, Feature Permutation, Morris Sensitivity, Feature Occlusion, Augmented Feature Occlusion, Deep Lift, Integrated Gradients, Gradient Shap). They use the Area Over the Perturbation Curve for Regression (AOPCR) metric to evaluate interpretation methods and compare predicted age group attribution scores against actual CDC COVID-19 case data by age groups.

## Key Results
- FEDformer selected as best-performing transformer model (MAE 30.19, RMSE 182.2, RMSLE, R2-score 0.481)
- Morris Sensitivity method performs best on comprehensiveness metrics for interpretation
- Framework successfully captures age-specific infection patterns using weekly CDC case data by age groups
- Method validated on UCI Electricity and Traffic datasets, demonstrating generalizability across domains

## Why This Works (Mechanism)

### Mechanism 1
The perturbation-based local attribution framework works by measuring prediction sensitivity to feature changes in multivariate time series. The framework systematically masks individual features or groups of features and measures the resulting change in model output. For each feature, it computes the absolute difference between predictions with and without that feature. This creates an importance matrix showing how much each feature contributes to predictions at different time steps and horizons.

Core assumption: The change in model output after feature masking is proportional to the feature's importance for that prediction.

### Mechanism 2
The framework's effectiveness comes from using comprehensive evaluation metrics (AOPCR) to compare interpretation methods. Instead of relying on ground truth interpretation, the framework uses the Area Over the Perturbation Curve for Regression (AOPCR) metric. It measures how much the model's prediction changes when top-k% important features are masked (comprehensiveness) versus when only those features are kept (sufficiency).

Core assumption: The model's prediction should degrade more when masking truly important features than when masking less important ones.

### Mechanism 3
The framework captures age group sensitivity by leveraging ground truth COVID-19 case data by age groups from CDC. The framework uses weekly CDC data on COVID-19 cases broken down by 8 age groups as ground truth. It compares the predicted age group attribution scores against actual infection rates, measuring differences using MAE, RMSE, and NDCG metrics.

Core assumption: The age group attribution scores from the model should correlate with actual infection patterns in the population.

## Foundational Learning

- Concept: Time series forecasting with transformer models
  - Why needed here: The framework interprets transformer-based time series models, so understanding how these models work is essential for grasping the interpretation methods
  - Quick check question: How does a transformer model process sequential data differently from traditional recurrent neural networks?

- Concept: Local vs global interpretability methods
  - Why needed here: The framework specifically uses local interpretation methods to explain individual predictions, distinguishing it from methods that explain overall model behavior
  - Quick check question: What's the key difference between explaining a single prediction versus explaining the model's overall behavior?

- Concept: Feature importance and attribution methods
  - Why needed here: The framework uses various methods (Feature Ablation, Morris Sensitivity, etc.) to quantify how much each feature contributes to predictions
  - Quick check question: How does the Morris Sensitivity method differ from simple feature permutation in measuring feature importance?

## Architecture Onboarding

- Component map: COVID-19 data preprocessing -> Transformer model training -> Interpretation method application -> AOPCR evaluation -> Age group sensitivity analysis
- Critical path: Data preprocessing → Model training and selection → Interpretation method application → Evaluation using AOPCR or ground truth comparison
- Design tradeoffs: The framework prioritizes model-agnostic interpretability over model-specific explanations, allowing application across different transformer architectures but potentially missing architecture-specific insights
- Failure signatures: Poor interpretation results may indicate feature redundancy, complex feature interactions, or temporal dependencies not captured by the masking approach
- First 3 experiments:
  1. Run all 8 interpretation methods on a small subset of the test data to compare their execution times and basic outputs
  2. Apply the AOPCR evaluation to determine which interpretation method performs best on the COVID-19 dataset
  3. Compare the age group sensitivity predictions against the CDC ground truth for a single week to validate the framework's accuracy

## Open Questions the Paper Calls Out

### Open Question 1
How do higher-order interactions between input features impact model predictions, and can these be captured by current interpretation methods?
Basis in paper: [explicit] The authors state "Future works include capturing higher-order relations between the input features" in the conclusion section.
Why unresolved: The current interpretation methods focus on individual feature importance and pairwise interactions, but do not explicitly model complex higher-order feature interactions that may exist in multivariate time series data.

### Open Question 2
How does the interpretation of transformer models vary across different spatiotemporal scales, and what are the implications for understanding disease spread patterns?
Basis in paper: [explicit] The authors mention "understanding spatiotemporal interpretations better" as future work, and their current work shows different age group sensitivities at weekly US-level aggregation.
Why unresolved: The paper only evaluates interpretations at the county level for predictions and weekly US-level aggregation for age group sensitivity, but does not explore how interpretations change when analyzing different spatial or temporal scales.

### Open Question 3
How do the interpretation results generalize to other time series domains beyond COVID-19 infection forecasting, electricity consumption, and traffic data?
Basis in paper: [explicit] The authors apply their framework to electricity and traffic datasets and state it is "generic and can be applied to other time-series domains," but only provide results for these three domains.
Why unresolved: While the authors demonstrate the framework works on three different time series datasets, they do not provide a comprehensive evaluation across diverse domains to establish the breadth of its applicability.

## Limitations

- Interpretation framework may not capture complex feature interactions in COVID-19 forecasting task
- Age group sensitivity analysis limited by availability of weekly CDC data at national level only
- Ground truth interpretation validation constrained by temporal and spatial resolution of available data

## Confidence

- High confidence: Selection of FEDformer as best-performing transformer model (MAE 30.19, RMSE 182.2) is well-supported by comprehensive metrics
- Medium confidence: Perturbation-based interpretation framework shows promise, but assumption that feature masking accurately captures feature importance may not hold for complex non-linear relationships
- Low confidence: Age group sensitivity analysis is constrained by availability of weekly CDC data at national level only

## Next Checks

1. **Feature Interaction Validation**: Test the interpretation framework on synthetic datasets with known feature interactions to verify that the perturbation-based methods can accurately capture both individual feature importance and interaction effects.

2. **Temporal Resolution Enhancement**: Attempt to obtain more granular COVID-19 case data by age groups at county or state level to enable more precise validation of the age sensitivity analysis framework.

3. **Cross-Model Consistency**: Apply the interpretation framework to the five alternative transformer models (TimesNet, PatchTST, Autoformer, Crossformer) and compare the consistency of age group sensitivity patterns across different architectures.