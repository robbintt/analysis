---
ver: rpa2
title: Dirichlet-Based Prediction Calibration for Learning with Noisy Labels
arxiv_id: '2401.07062'
source_url: https://arxiv.org/abs/2401.07062
tags:
- learning
- noise
- labels
- loss
- example
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of learning with noisy labels
  in deep neural networks, where the softmax function's translation invariance leads
  to over-confident predictions that hinder accurate example selection and label correction.
  The proposed Dirichlet-based Prediction Calibration (DPC) method introduces a calibrated
  softmax function that breaks translation invariance by adding a constant term, combined
  with a Dirichlet-based training loss that encourages distinct logits for different
  classes.
---

# Dirichlet-Based Prediction Calibration for Learning with Noisy Labels

## Quick Facts
- arXiv ID: 2401.07062
- Source URL: https://arxiv.org/abs/2401.07062
- Authors: Chen-Chen Zong; Ye-Wen Wang; Ming-Kun Xie; Sheng-Jun Huang
- Reference count: 12
- Primary result: State-of-the-art performance on CIFAR-10/100 with synthetic noise and real-world noisy datasets

## Executive Summary
This paper addresses the problem of learning with noisy labels in deep neural networks, where the softmax function's translation invariance leads to over-confident predictions that hinder accurate example selection and label correction. The proposed Dirichlet-based Prediction Calibration (DPC) method introduces a calibrated softmax function that breaks translation invariance by adding a constant term, combined with a Dirichlet-based training loss that encourages distinct logits for different classes. Experiments on CIFAR-10/100 with synthetic noise and real-world noisy datasets (CIFAR-10N, CIFAR-100N, WebVision) show DPC achieves state-of-the-art performance, with test accuracy improvements of 1.8% on CIFAR-100 symmetric noise and superior results on real-world noisy datasets.

## Method Summary
DPC breaks the translation invariance of softmax by adding a constant γ to the exponent term, ensuring logits with small absolute values produce lower probabilities. The method uses an Evidence Deep Learning (EDL) loss that encourages positive and sufficiently large logits for the given label while penalizing negative and small logits for other labels. A large-margin criterion is used for example selection, defining the margin as the difference between the given class logit and the largest logit among complementary classes. The training employs a two-head network architecture with separate heads for supervised and unsupervised loss, using GMM fitting to partition clean and mislabeled examples.

## Key Results
- DPC achieves 1.8% improvement on CIFAR-100 with symmetric noise
- State-of-the-art performance on real-world noisy datasets (CIFAR-10N, CIFAR-100N, WebVision)
- Large-margin criterion outperforms small-loss criterion in calibrated models
- Ablation studies confirm the importance of breaking softmax translation invariance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Breaking softmax translation invariance reduces overconfident predictions that mislead example selection.
- Mechanism: Adding a constant γ to the exponent term in the calibrated softmax function ensures that logits with small absolute values produce lower probabilities, making the model less likely to confidently predict on uncertain examples.
- Core assumption: The translation invariance of softmax is the root cause of over-confidence in noisy label learning.
- Evidence anchors:
  - [abstract] "identify the translation invariance of the softmax function as the underlying cause of this problem and propose the Dirichlet-based Prediction Calibration (DPC) method as a solution"
  - [section] "Based on these findings, we can conclude that the translation invariance of the softmax function would lead to the over-confidence phenomenon in noisy label learning"
  - [corpus] Weak evidence - only general calibration papers found, no direct corpus support for translation invariance claim
- Break condition: If the calibration constant γ is poorly chosen (too small or too large), the benefits of breaking translation invariance may be lost or the model may become under-confident.

### Mechanism 2
- Claim: Dirichlet-based training with EDL loss ensures logits are sufficiently separated for better example selection.
- Mechanism: The EDL loss encourages positive logits for the given label and negative logits for other labels, creating a larger margin between clean and mislabeled examples.
- Core assumption: More distinct logits lead to better separation between clean and mislabeled examples in the margin space.
- Evidence anchors:
  - [abstract] "encourages positive and sufficiently large logits for the given label, while penalizing negative and small logits for other labels, leading to more distinct logits and facilitating better example selection based on a large-margin criterion"
  - [section] "the calibrated softmax needs to provide a logit distribution with greater differentiation than the commonly used softmax function"
  - [corpus] Weak evidence - only general EDL papers found, no direct corpus support for this specific training approach
- Break condition: If the hyperparameter β balancing the NLL and KL terms is not properly tuned, the EDL loss may not effectively separate logits.

### Mechanism 3
- Claim: Large-margin criterion outperforms small-loss criterion for example selection in calibrated models.
- Mechanism: The margin is defined as the difference between the given class logit and the largest logit among complementary classes, providing a more discriminative measure than loss.
- Core assumption: In calibrated models with distinct logits, margin is a better indicator of example cleanliness than loss.
- Evidence anchors:
  - [abstract] "facilitating better example selection based on a large-margin criterion"
  - [section] "the proposed large-margin criterion can produce more discriminative results" (Figure 2d)
  - [corpus] No direct evidence - large-margin criterion appears to be novel to this work
- Break condition: If the model fails to produce sufficiently distinct logits, the margin criterion may not be more discriminative than loss.

## Foundational Learning

- Concept: Translation invariance of softmax
  - Why needed here: Understanding this property is crucial to grasping why standard softmax leads to over-confidence in noisy label learning
  - Quick check question: If you add the same constant to all logits, what happens to the softmax probabilities?

- Concept: Dirichlet distribution for probability modeling
  - Why needed here: The Dirichlet distribution is used to model the uncertainty in predicted probabilities and enable EDL training
  - Quick check question: What does a sharp Dirichlet distribution concentrated at a corner of the simplex represent?

- Concept: Evidence deep learning (EDL)
  - Why needed here: EDL provides the theoretical framework for training with Dirichlet distributions and the proposed EDL loss
  - Quick check question: How does EDL treat the predicted probability differently from standard neural networks?

## Architecture Onboarding

- Component map:
  Input -> Network (with calibrated softmax) -> EDL Loss (NLL + KL) -> Output
  Input -> Network -> Large-margin criterion -> GMM fitting -> Clean/Mislabeled partition

- Critical path:
  1. Forward pass through network to get logits
  2. Apply calibrated softmax to get probabilities
  3. Compute EDL loss (NLL + KL)
  4. Backward pass to update weights
  5. After each epoch, compute margins and fit GMM
  6. Partition examples based on GMM predictions

- Design tradeoffs:
  - Single vs two classification heads: Two heads prevent conflict between supervised and unsupervised objectives but increase complexity
  - Value of γ: Larger γ breaks translation invariance more but may lead to under-confidence
  - Value of β: Higher β emphasizes KL term more but may lead to unstable training

- Failure signatures:
  - Over-confidence persists: Check if γ is too small
  - Training instability: Check if β is too large
  - Poor example selection: Check if logits are not sufficiently distinct
  - Calibration degrades: Check if temperature scaling is needed

- First 3 experiments:
  1. Verify calibrated softmax breaks translation invariance by testing with shifted logits
  2. Test EDL loss with synthetic logits to ensure it encourages separation
  3. Compare margins vs losses on a small clean dataset to validate large-margin criterion

## Open Questions the Paper Calls Out
None

## Limitations
- The translation invariance claim as the root cause of over-confidence lacks direct empirical validation beyond ablation studies
- The effectiveness of the large-margin criterion depends on proper calibration through γ and EDL loss, creating potential fragility
- The two-head architecture introduces additional complexity and hyperparameter tuning requirements

## Confidence

**High Confidence**: The experimental results demonstrating DPC's superior performance on CIFAR-10/100 with synthetic noise and real-world noisy datasets.

**Medium Confidence**: The proposed mechanism of breaking softmax translation invariance as the primary driver of improved performance.

**Medium Confidence**: The effectiveness of the large-margin criterion for example selection.

## Next Checks

1. **Translation Invariance Stress Test**: Systematically test DPC's performance across different values of γ to empirically validate the claim that breaking translation invariance improves noisy label learning.

2. **Cross-Dataset Generalization**: Evaluate DPC on additional real-world noisy datasets beyond CIFAR-10N, CIFAR-100N, and WebVision to assess whether the method's effectiveness generalizes to different types of label noise distributions.

3. **Comparison with Alternative Calibrations**: Compare DPC against other calibration methods (temperature scaling, Dirichlet calibration, etc.) on the same noisy label benchmarks to isolate whether the improvements come from calibration specifically.