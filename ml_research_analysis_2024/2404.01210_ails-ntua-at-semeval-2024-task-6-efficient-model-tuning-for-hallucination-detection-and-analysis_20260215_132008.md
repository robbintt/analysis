---
ver: rpa2
title: 'AILS-NTUA at SemEval-2024 Task 6: Efficient model tuning for hallucination
  detection and analysis'
arxiv_id: '2404.01210'
source_url: https://arxiv.org/abs/2404.01210
tags:
- hallucination
- task
- model-aware
- model-agnostic
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses hallucination detection in natural language
  generation tasks by fine-tuning models pre-trained on hallucination detection and
  natural language inference. The approach uses an ensemble of these models to classify
  samples as hallucinated or not, achieving accuracy rates of 77.8% and 79.9% on model-agnostic
  and model-aware datasets respectively.
---

# AILS-NTUA at SemEval-2024 Task 6: Efficient model tuning for hallucination detection and analysis

## Quick Facts
- arXiv ID: 2404.01210
- Source URL: https://arxiv.org/abs/2404.01210
- Reference count: 7
- Primary result: Achieved 77.8% accuracy on model-agnostic dataset and 79.9% on model-aware dataset for hallucination detection

## Executive Summary
This work addresses the challenge of detecting hallucinations in natural language generation tasks by developing an efficient ensemble approach. The method fine-tunes models pre-trained on hallucination detection and natural language inference tasks, then combines them through ensembling to classify text samples as hallucinated or not. The approach operates in a fully black-box setting, requiring only input-output pairs from language models, making it practical for real-world deployment. The resulting model achieves 77.8% accuracy on model-agnostic datasets and 79.9% on model-aware datasets, outperforming the baseline accuracy of 74.5%.

## Method Summary
The approach uses an ensemble of two pre-trained models: one trained specifically for hallucination detection and another trained on natural language inference (NLI) tasks. These models are fine-tuned on the SemEval-2024 Task 6 datasets, then their predictions are combined through ensembling. The ensemble aggregates individual model predictions to produce a final classification. The method is designed to be computationally efficient and works in a black-box setting where only input-output pairs from language models are available, without requiring access to the underlying model architecture or parameters.

## Key Results
- Achieved 77.8% accuracy on model-agnostic hallucination detection dataset
- Achieved 79.9% accuracy on model-aware hallucination detection dataset
- Outperformed baseline accuracy of 74.5%
- Demonstrated effectiveness of ensemble approach combining hallucination detection and NLI models

## Why This Works (Mechanism)
The ensemble approach leverages complementary strengths of different pre-trained models to improve hallucination detection performance. By combining a model specifically trained for hallucination detection with one trained on natural language inference, the ensemble captures both task-specific patterns and broader semantic relationships. This multi-perspective approach helps identify hallucinations that might be missed by a single model, as different models may excel at detecting different types of hallucinations based on their training objectives.

## Foundational Learning
- **Hallucination Detection**: Identifying when language models generate factually incorrect or unsupported information; needed to understand the core task being addressed; quick check: can distinguish between supported and unsupported statements
- **Natural Language Inference (NLI)**: Determining logical relationships between premise and hypothesis; needed to provide semantic reasoning capabilities; quick check: can classify entailment, contradiction, and neutral relationships
- **Model Ensembling**: Combining multiple models' predictions to improve overall performance; needed to leverage complementary strengths; quick check: improves accuracy over individual models
- **Black-box Evaluation**: Assessing model outputs without access to internal parameters; needed for practical deployment scenarios; quick check: works with only input-output pairs
- **Fine-tuning**: Adapting pre-trained models to specific tasks; needed to specialize general models for hallucination detection; quick check: improves performance on target datasets

## Architecture Onboarding

**Component Map**: Pre-trained HD Model -> Fine-tuning -> HD Component; Pre-trained NLI Model -> Fine-tuning -> NLI Component; HD Component + NLI Component -> Ensemble Layer -> Final Prediction

**Critical Path**: Input text -> HD model prediction + NLI model prediction -> Ensemble aggregation -> Final binary classification

**Design Tradeoffs**: 
- Ensemble approach trades increased model complexity for improved accuracy
- Black-box design limits access to model internals but increases practical applicability
- Binary classification simplifies the task but loses granularity about hallucination severity

**Failure Signatures**: 
- Poor performance on out-of-domain texts not represented in training data
- Difficulty distinguishing subtle hallucinations from correct but unusual statements
- Potential overfitting to specific patterns in SemEval-2024 Task 6 datasets

**3 First Experiments**:
1. Evaluate individual model performance before ensembling to establish baseline contributions
2. Test ensemble performance with different weighting schemes for component models
3. Assess performance on a held-out validation set to check for overfitting

## Open Questions the Paper Calls Out
None specified in the provided material.

## Limitations
- Evaluation limited to SemEval-2024 Task 6 datasets, potentially limiting generalizability
- Modest improvement over baseline (77.8-79.9% vs 74.5%) raises questions about practical significance
- Binary classification approach doesn't address hallucination severity or type distinctions

## Confidence
- **Ensemble Approach Effectiveness**: High confidence - clear methodology and direct baseline comparison
- **Computational Efficiency**: Medium confidence - claimed but specific metrics not provided
- **Black-box Applicability**: High confidence - explicitly stated and demonstrated

## Next Checks
1. Test ensemble model on additional hallucination detection datasets beyond SemEval-2024 Task 6 to assess generalizability across different domains and generation tasks.

2. Conduct ablation studies to quantify individual contributions of hallucination detection and NLI pre-trained models to ensemble performance.

3. Evaluate model performance on datasets with varying hallucination severity to determine if binary classification captures meaningful practical distinctions.