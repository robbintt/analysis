---
ver: rpa2
title: 'Rethinking Pruning for Backdoor Mitigation: An Optimization Perspective'
arxiv_id: '2405.17746'
source_url: https://arxiv.org/abs/2405.17746
tags:
- backdoor
- pruning
- neurons
- mitigation
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes an Optimized Neuron Pruning (ONP) method that
  uses Graph Neural Networks (GNN) and Reinforcement Learning (RL) to mitigate backdoor
  attacks in Deep Neural Networks (DNNs). The method models the DNN as graphs based
  on neuron connectivity and uses GNN-based RL agents to learn graph embeddings and
  find a suitable pruning policy.
---

# Rethinking Pruning for Backdoor Mitigation: An Optimization Perspective

## Quick Facts
- arXiv ID: 2405.17746
- Source URL: https://arxiv.org/abs/2405.17746
- Reference count: 35
- The paper proposes an Optimized Neuron Pruning (ONP) method that uses Graph Neural Networks (GNN) and Reinforcement Learning (RL) to mitigate backdoor attacks in Deep Neural Networks (DNNs).

## Executive Summary
This paper introduces an Optimized Neuron Pruning (ONP) method that addresses backdoor attacks in deep neural networks through an optimization-based approach using Graph Neural Networks (GNN) and Reinforcement Learning (RL). The method models DNNs as graphs based on neuron connectivity patterns and uses GNN-based RL agents to learn graph embeddings and determine optimal pruning policies. ONP demonstrates state-of-the-art performance in backdoor mitigation, achieving less than 1% attack success rate with minimal clean accuracy degradation on CIFAR-10 and Tiny ImageNet datasets across multiple attack types.

## Method Summary
ONP mitigates backdoor attacks by first modeling the target DNN as graphs based on neuron connectivity, where nodes represent channels/filters and edges represent connection strengths measured by l1-norm of convolutional kernels. A GNN-based RL agent then learns from these graph embeddings to find optimal pruning policies through iterative trial-and-error optimization. The method balances backdoor mitigation (reducing attack success rate) with clean accuracy preservation by using a reward function that considers both factors. The approach is particularly effective for ResNet architectures, pruning the last two blocks for most attacks, and demonstrates superior performance compared to existing pruning-based methods.

## Key Results
- Reduces average attack success rate (ASR) to 1.26% with less than 1% clean accuracy (CA) drop on CIFAR-10
- Outperforms existing methods like ANP, CLP, and RNP on multiple benchmark datasets
- Effective across 6 different backdoor attack types including BadNets, Trojan, Blend, Clean Label, Dynamic, and WaNet
- Competitive performance on Tiny ImageNet and other architectures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph Neural Networks can model neuron connectivity to expose backdoor neurons
- Mechanism: The method constructs graphs where nodes represent channels/filters and edges represent connection strength (measured by l1-norm of convolutional kernels). This captures topological information about neuron connectivity patterns, which tend to differ between backdoor and clean neurons.
- Core assumption: Backdoor neurons exhibit distinct connectivity patterns compared to clean neurons
- Evidence anchors:
  - [abstract] "ONP first models the target DNN as graphs based on neuron connectivity, and then uses GNN-based RL agents to learn graph embeddings and find a suitable pruning policy"
  - [section] "we have find that backdoor neurons tend to form strong connections with other backdoor neurons in the previous layer to amplify backdoor activation, while clean neurons show minimal connections with these backdoor neurons"
- Break condition: If backdoor neurons don't form distinct connectivity patterns, the graph representation becomes ineffective at distinguishing them

### Mechanism 2
- Claim: Reinforcement Learning can optimize pruning policies beyond rule-based approaches
- Mechanism: RL agents learn from graph embeddings to determine which neurons to prune through trial-and-error, optimizing for a reward function that balances backdoor mitigation (reducing ASR) with clean accuracy preservation
- Core assumption: The optimal pruning policy can be learned through iterative optimization rather than defined by fixed rules
- Evidence anchors:
  - [abstract] "we propose an Optimized Neuron Pruning (ONP) method combined with Graph Neural Network (GNN) and Reinforcement Learning (RL) to repair backdoor models"
  - [section] "We define pruning for backdoor mitigation as an optimization problem and introduce Reinforcement Learning (RL) to solve it"
- Break condition: If the reward function cannot adequately capture the tradeoff between ASR reduction and CA preservation, or if the optimization space is too large for practical learning

### Mechanism 3
- Claim: Residual connections create channel relevance that affects backdoor behavior
- Mechanism: In ResNet architectures, residual connections cause channel relevance across layers, meaning backdoor neurons activated in one block often have corresponding activated channels in subsequent blocks, which the pruning strategy must account for
- Core assumption: Residual connections create meaningful channel relevance patterns that persist across layers
- Evidence anchors:
  - [section] "we have conducted a simple investigation... the indices of the activated channels are almost the same, which proves the channel relevance exists in deep layers and holds for backdoor activation"
  - [section] "Accelerating ONP with Group-based Pruning... For ResNet, a group corresponds to a ResNet block comprising more than two residual blocks"
- Break condition: If residual connections don't create consistent channel relevance patterns across different architectures or attack types

## Foundational Learning

- Concept: Graph Neural Networks and their variants (like Graph Attention Networks)
  - Why needed here: To extract topological information from neuron connectivity patterns and learn node embeddings that help identify backdoor neurons
  - Quick check question: How does a GAT differ from a standard GCN in handling dynamic graphs?

- Concept: Reinforcement Learning and policy optimization (specifically PPO)
  - Why needed here: To iteratively find optimal pruning policies through trial-and-error rather than relying on predefined rules
  - Quick check question: What distinguishes PPO from other policy gradient methods in terms of stability and convergence?

- Concept: Convolutional neural network architecture and residual connections
  - Why needed here: To understand how neuron connectivity works within CNNs and how residual connections create channel relevance that affects pruning strategies
  - Quick check question: How do residual connections in ResNet affect the propagation of activations through the network?

## Architecture Onboarding

- Component map:
  Graph Construction Module -> GNN-based RL Agent -> Pruning Execution Layer -> Reward Computation System -> Trigger Synthesis Component

- Critical path:
  1. Construct graphs from infected DNN
  2. Initialize RL agent with GAT and MLP
  3. Execute pruning actions on both graph and DNN
  4. Compute rewards from clean/backdoor performance
  5. Update RL policy based on rewards
  6. Iterate until convergence or episode limit

- Design tradeoffs:
  - Graph construction granularity (node/channel level) vs computational cost
  - Number of RL agents (one per layer vs one per block) vs performance
  - Defense data size vs trigger synthesis quality and reward accuracy
  - Pruning aggressiveness vs clean accuracy preservation

- Failure signatures:
  - If ASR reduction plateaus despite pruning, the agent may be overly conservative
  - If CA drops significantly, the reward function may be unbalanced
  - If convergence is slow, the state representation or action space may be inefficient
  - If results vary widely across attacks, the method may be overfitting to specific patterns

- First 3 experiments:
  1. Test basic graph construction on a simple infected model and visualize connectivity patterns
  2. Run RL agent with a simplified reward function (only ASR reduction) to validate learning capability
  3. Compare pruning policies from rule-based methods vs RL agent on the same infected model

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do residual connections affect the distribution and connectivity of backdoor neurons across different layers in ResNet architectures?
- Basis in paper: [explicit] The paper mentions investigating the impact of residual connections on backdoor activation and channel relevance, but does not provide a comprehensive analysis of how these connections influence backdoor neuron distribution.
- Why unresolved: The paper only provides a preliminary observation that the last two residual blocks in ResNet-18 are activated similarly by backdoor triggers, but does not explore the underlying mechanisms or extend this analysis to other ResNet variants or architectures.
- What evidence would resolve it: Detailed experiments analyzing the activation patterns, connectivity graphs, and pruning strategies across multiple ResNet variants and comparing them with other architectures like VGG or DenseNet.

### Open Question 2
- Question: What are the limitations of trigger synthesis methods like Neural Cleanse in dynamic backdoor attacks, and how can these limitations be addressed?
- Basis in paper: [explicit] The paper acknowledges that ONP's performance is limited by the quality of backdoor trigger synthesis, especially for dynamic attacks like Dynamic and WaNet, where the synthesized trigger may not effectively represent the actual backdoor behavior.
- Why unresolved: The paper does not propose or evaluate alternative trigger synthesis methods or discuss the fundamental challenges in synthesizing triggers for dynamic backdoor attacks.
- What evidence would resolve it: Comparative analysis of different trigger synthesis methods, including their effectiveness in dynamic attacks, and proposed improvements or new methods that can better capture the trigger patterns in these attacks.

### Open Question 3
- Question: How does the choice of graph construction parameters (ϵ and δ) impact the effectiveness of ONP in identifying backdoor neurons, and are there adaptive methods to optimize these parameters?
- Basis in paper: [explicit] The paper mentions that ϵ and δ influence graph construction and suggests adaptive settings to conserve 5% edges and 50% nodes, but does not provide a detailed analysis of how different values affect the pruning performance.
- Why unresolved: The paper only provides general recommendations for parameter settings without exploring the sensitivity of ONP to these parameters or proposing methods to automatically optimize them.
- What evidence would resolve it: Experiments varying ϵ and δ across different attacks and architectures, sensitivity analysis of ONP's performance, and the development of adaptive algorithms to optimize these parameters based on the specific characteristics of the backdoor attack and model.

## Limitations
- Lacks detailed hyperparameter specifications for both graph construction (ϵ and δ thresholds) and RL training (learning rates, batch sizes)
- Graph construction method's effectiveness across diverse DNN architectures beyond ResNet remains unclear
- Computational overhead of GNN-based pruning versus simpler rule-based methods is not thoroughly quantified

## Confidence

**High Confidence**: ONP's ability to reduce ASR below 1% on CIFAR-10 and Tiny ImageNet with minimal CA drop (supported by experimental results)

**Medium Confidence**: The claim that GNN-based RL learns superior pruning policies compared to rule-based methods (requires more extensive ablation studies)

**Medium Confidence**: The generalizability of ONP across different backdoor attack types (demonstrated on 6 attacks but not exhaustive)

## Next Checks
1. Implement ONP with various hyperparameter settings to determine sensitivity and optimal configuration
2. Compare computational efficiency against state-of-the-art methods using wall-clock time metrics
3. Test ONP on architectures beyond ResNet (e.g., VGG, MobileNet) to validate architectural generalizability