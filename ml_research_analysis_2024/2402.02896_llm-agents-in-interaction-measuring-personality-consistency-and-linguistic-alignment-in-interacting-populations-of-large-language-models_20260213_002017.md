---
ver: rpa2
title: 'LLM Agents in Interaction: Measuring Personality Consistency and Linguistic
  Alignment in Interacting Populations of Large Language Models'
arxiv_id: '2402.02896'
source_url: https://arxiv.org/abs/2402.02896
tags:
- agents
- personality
- writing
- language
- interaction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether personality-conditioned large language
  model (LLM) agents maintain consistent personality traits and language use during
  interactions. Using GPT-3.5, the authors create two groups of agents (creative and
  analytical) through personality prompts and measure their Big Five Inventory (BFI)
  scores and linguistic patterns.
---

# LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models

## Quick Facts
- arXiv ID: 2402.02896
- Source URL: https://arxiv.org/abs/2402.02896
- Reference count: 12
- Key outcome: This study investigates whether personality-conditioned large language model (LLM) agents maintain consistent personality traits and language use during interactions.

## Executive Summary
This study investigates whether personality-conditioned large language model (LLM) agents maintain consistent personality traits and language use during interactions. Using GPT-3.5, the authors create two groups of agents (creative and analytical) through personality prompts and measure their Big Five Inventory (BFI) scores and linguistic patterns. In non-interactive conditions, creative agents show higher consistency than analytical agents. During interactive conditions, creative agents align more strongly toward analytical agents' linguistic patterns, while analytical agents show weaker alignment. Linguistic alignment is measured through LIWC categories, with classification accuracy dropping from 98.5% (non-interactive) to 66.15% (interactive). The findings highlight the importance of developing more robust methods for maintaining personality consistency in interactive LLM agents.

## Method Summary
The study uses GPT-3.5-turbo-0613 to generate responses from two personality-conditioned groups (creative and analytical) using temperature sampling (0.7). Agents complete Big Five Inventory (BFI) tests before and after writing tasks, and their linguistic patterns are analyzed using LIWC categories. The experiment includes both non-interactive writing tasks and interactive collaborative writing between groups. BFI scores, LIWC counts, and classification accuracy are measured to assess personality consistency and linguistic alignment, with statistical analysis using ANOVA, Spearman correlation, and point-biserial correlation.

## Key Results
- Creative agents show higher BFI consistency than analytical agents in non-interactive conditions
- Classification accuracy for distinguishing agent groups drops from 98.5% to 66.15% after interaction
- Creative agents align more strongly toward analytical agents' linguistic patterns during interaction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Personality-conditioned LLMs exhibit measurable consistency in Big Five Inventory (BFI) trait responses before interaction.
- Mechanism: Explicit personality prompting induces trait-specific response distributions that diverge statistically from other personas.
- Core assumption: Personality prompts are strong enough to shape response patterns in a measurable, stable way before external influences.
- Evidence anchors:
  - [abstract] "agents in the creative group give more consistent responses to BFI questionnaires than those in the analytical group"
  - [section] "differences in BFI scores obtained before the writing task are substantial across four out of five personality traits"
  - [corpus] Weak: only 0 citations, but related papers confirm personality conditioning effects.
- Break condition: If BFI score distributions overlap significantly (p > 0.05), prompt conditioning is insufficient.

### Mechanism 2
- Claim: Linguistic alignment occurs in interaction, but is asymmetric between personas.
- Mechanism: Agents adjust lexical and LIWC category usage toward conversational partners, with stronger shifts in high-openness personas.
- Core assumption: Linguistic adaptation is driven by underlying trait openness, which modulates susceptibility to partner influence.
- Evidence anchors:
  - [abstract] "creative agents align more strongly toward analytical agents' linguistic patterns"
  - [section] "creative agents use more words expressing negative emotions, sadness and discrepancy than before interaction"
  - [corpus] Moderate: related work confirms alignment but not asymmetric strength.
- Break condition: If classification accuracy post-interaction remains near pre-interaction levels (>80%), alignment is negligible.

### Mechanism 3
- Claim: Non-interactive writing tasks can erode personality consistency in certain personas.
- Mechanism: Task engagement shifts internal trait representations, especially for low-openness personas.
- Core assumption: Task prompts interact with personality conditioning to induce drift in trait self-reporting.
- Evidence anchors:
  - [section] "a simple non-interactive writing task can negatively affect consistency...BFI scores on all five personality traits increase significantly after writing"
  - [abstract] "creative agents show higher consistency than analytical agents"
  - [corpus] Weak: no direct citations on task-induced drift.
- Break condition: If BFI scores remain stable across conditions, task influence is minimal.

## Foundational Learning

- Concept: Big Five Inventory (BFI) measurement framework
  - Why needed here: Enables quantifiable trait comparison across persona groups.
  - Quick check question: What scale range is used for each BFI dimension?
- Concept: Linguistic Inquiry and Word Count (LIWC) categories
  - Why needed here: Provides fine-grained linguistic feature vectors to detect alignment.
  - Quick check question: Which LIWC category correlates positively with openness in non-interactive writing?
- Concept: Statistical significance testing (ANOVA, Spearman correlation)
  - Why needed here: Determines whether observed differences are reliable, not random noise.
  - Quick check question: What p-value threshold indicates significant BFI difference between groups?

## Architecture Onboarding

- Component map: Prompt → LLM → BFI test → LIWC vector → Classification → Alignment metrics
- Critical path: Prompt conditioning → Trait stability measurement → Interaction simulation → Linguistic alignment detection
- Design tradeoffs: Temperature sampling vs. deterministic generation for population diversity; simple prompts vs. fine-tuned models for robustness.
- Failure signatures: High overlap in BFI score distributions; low classification accuracy after interaction; no change in LIWC correlations.
- First 3 experiments:
  1. Generate two persona groups, run BFI tests, verify trait divergence before writing.
  2. Run non-interactive writing task, re-run BFI tests, check for drift in analytical group.
  3. Conduct cross-group interaction, measure LIWC alignment and BFI consistency post-interaction.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do multi-turn interactive dialogues affect personality consistency and linguistic alignment compared to single-turn interactions?
- Basis in paper: [inferred] from limitations section mentioning future work should investigate "more naturalistic multi-turn dialogic interactions"
- Why unresolved: The current study only examines one-turn interactions where agents write stories based on partners' previous outputs, limiting understanding of how personality consistency evolves through extended dialogue
- What evidence would resolve it: Experiments comparing personality test scores and linguistic features across multiple interaction turns would show whether alignment effects strengthen, weaken, or stabilize over time

### Open Question 2
- Question: Do more nuanced personality profiles (with mixed high/low BFI traits) show different alignment patterns than the extreme creative/analytical profiles tested?
- Basis in paper: [explicit] authors state they plan to "introduce more diverse and fine-grained personality profiles" in future work
- Why unresolved: The study uses artificial extreme profiles (all high or all low BFI traits) that don't reflect real human personality distributions, limiting ecological validity
- What evidence would resolve it: Testing agents with varied personality combinations and measuring alignment strength between different profile pairs would reveal whether certain personality configurations are more or less susceptible to alignment

### Open Question 3
- Question: Which prompting strategies most effectively maintain personality consistency during interactions?
- Basis in paper: [explicit] conclusion states "Future research should also focus on designing methods (e.g., different prompting strategies) that offer better guarantees on personality consistency"
- Why unresolved: The study uses simple persona prompts without exploring variations in prompt structure, strength, or reinforcement techniques that might preserve personality traits during alignment
- What evidence would resolve it: Comparing personality consistency metrics across different prompt designs (refresher prompts, trait reminders, contextual constraints) would identify which approaches best resist conversational partner influence

## Limitations

- The study uses a relatively small sample size with unspecified exact numbers per group
- Results are limited to GPT-3.5 architecture without testing generalization to other LLMs
- The study relies entirely on automated BFI and LIWC analysis without human validation

## Confidence

- **High confidence**: The finding that personality-conditioned agents show measurable trait differences before interaction is well-supported by statistical analysis (ANOVA results, classification accuracy of 98.5% in non-interactive conditions). The LIWC methodology for detecting linguistic alignment is standard and the directional patterns (creative agents using more negative emotion words post-interaction) are consistent across analyses.

- **Medium confidence**: The claim that non-interactive writing tasks erode personality consistency in analytical agents is supported by pre/post BFI comparisons, but the effect size and generalizability across different tasks remains uncertain. The asymmetric alignment pattern is statistically significant but requires replication with different personality dimensions and interaction scenarios.

- **Low confidence**: The assertion that personality conditioning through simple prompts is sufficient for maintaining trait consistency in interactive settings is not well-supported. The substantial drop in classification accuracy (98.5% to 66.15%) after interaction suggests current methods are inadequate, but the study doesn't explore alternative conditioning approaches or more robust personality maintenance techniques.

## Next Checks

1. **Replication with diverse persona types**: Conduct the same experiment using additional personality dimensions beyond creative/analytical (e.g., extraversion, agreeableness) to determine whether asymmetric alignment is a general phenomenon or specific to the tested traits.

2. **Human validation study**: Have human raters independently assess agent responses for personality consistency and alignment, comparing their judgments with automated BFI and LIWC metrics to establish external validity of the measurements.

3. **Alternative conditioning approaches**: Test whether fine-tuning on personality-specific corpora or using more detailed prompts produces stronger personality maintenance during interactions, comparing BFI consistency and classification accuracy against the current temperature-sampling approach.