---
ver: rpa2
title: 'Metric-DST: Mitigating Selection Bias Through Diversity-Guided Semi-Supervised
  Metric Learning'
arxiv_id: '2411.18442'
source_url: https://arxiv.org/abs/2411.18442
tags:
- bias
- samples
- selection
- learning
- metric-dst
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Metric-DST introduces a semi-supervised learning framework that
  addresses selection bias by combining metric learning with diversity-guided self-training.
  The approach learns a class-contrastive embedding space and selects pseudo-labeled
  samples that are both diverse and confidently predicted, thereby mitigating confirmation
  bias.
---

# Metric-DST: Mitigating Selection Bias Through Diversity-Guided Semi-Supervised Metric Learning

## Quick Facts
- **arXiv ID:** 2411.18442
- **Source URL:** https://arxiv.org/abs/2411.18442
- **Reference count:** 40
- **Key outcome:** Metric-DST introduces a semi-supervised learning framework that addresses selection bias by combining metric learning with diversity-guided self-training.

## Executive Summary
Metric-DST is a semi-supervised learning framework designed to mitigate selection bias by integrating metric learning with diversity-guided self-training. The approach learns a class-contrastive embedding space and selects pseudo-labeled samples that are both diverse and confidently predicted, thereby reducing confirmation bias. Tested across synthetic and real-world datasets with induced bias, as well as a molecular biology task with inherent bias, Metric-DST consistently improved model robustness compared to conventional self-training and supervised learning.

## Method Summary
Metric-DST combines metric learning with diversity-guided self-training to mitigate selection bias. The framework learns a class-contrastive embedding using a neural network with contrastive loss, then applies weighted kNN for pseudo-labeling unlabeled samples. Diversity is introduced by generating random points in the embedding space and selecting the nearest pseudo-labeled samples above a relaxed confidence threshold. This approach balances confidence and diversity while enforcing class balance, with performance evaluated using AUROC on benchmark datasets and AUPRC on synthetic lethality prediction tasks.

## Key Results
- Metric-DST consistently improved model robustness compared to conventional self-training and supervised learning across synthetic and real-world datasets with induced bias.
- Performance gains were most notable when selection bias significantly impacted baseline models, with statistically significant improvements observed in multiple bias scenarios.
- On molecular biology tasks with inherent bias, Metric-DST demonstrated superior performance, particularly in maintaining class balance during pseudo-label selection.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Metric-DST improves model robustness by selecting pseudo-labeled samples that are both confident and diverse in the learned embedding space.
- **Mechanism:** After metric learning creates a class-contrastive embedding, Metric-DST generates random points in the latent space and assigns them to the nearest pseudo-labeled sample. Only samples above a relaxed confidence threshold are added, ensuring diversity without sacrificing confidence.
- **Core assumption:** The metric learning transformation meaningfully separates classes while preserving meaningful distance structure in the embedding space.
- **Evidence anchors:**
  - [abstract] "Metric-DST learned more robust models in the presence of selection bias for generated and real-world datasets with induced bias, as well as a molecular biology prediction task with intrinsic bias."
  - [section] "Diversity is introduced via metric learning of a class-contrastive representation, which facilitates the pseudo-labeling and identification of dissimilar unlabeled samples to include in the training."
  - [corpus] Weak evidence: corpus includes only tangentially related semi-supervised and fairness papers without direct experimental validation of this diversity-guided selection.
- **Break condition:** If the learned embedding space collapses distances or becomes uninformative, random point selection will not yield meaningful diversity, and performance will degrade to that of vanilla self-training.

### Mechanism 2
- **Claim:** The use of a relaxed confidence threshold (µ) balances confidence and diversity, preventing the model from reinforcing existing bias.
- **Mechanism:** By lowering the confidence threshold relative to standard self-training, Metric-DST admits more samples into the training set, but the diversity selection step ensures that these are not concentrated in already overrepresented regions.
- **Core assumption:** Relaxing the threshold does not introduce too many mislabeled samples to harm learning; the diversity selection offsets this risk.
- **Evidence anchors:**
  - [section] "Selection of diverse pseudo-labeled samples: Metric-DST performs diversity-guided self-training (DST), which introduces sample diversity and class balancing into the selection of pseudo-labeled samples using the learned metric embedding."
  - [section] "The selection pseudo-labeled sample is designated for inclusion in the labeled train set for the subsequent iteration if the confidence on its prediction surpasses a predefined relaxed threshold µ."
  - [corpus] No direct evidence; corpus lacks studies on confidence threshold tuning in semi-supervised bias mitigation.
- **Break condition:** If µ is set too low, noisy pseudo-labels dominate and the diversity mechanism cannot recover, leading to degraded performance.

### Mechanism 3
- **Claim:** The combination of metric learning and kNN prediction leverages the embedding space for both accurate pseudo-labeling and effective diversity selection.
- **Mechanism:** The metric embedding is used to find nearest neighbors for pseudo-label prediction via weighted kNN, and the same embedding distances guide random point selection for diversity.
- **Core assumption:** The embedding space is sufficiently discriminative that kNN predictions are reliable and Euclidean distances meaningfully reflect class separation.
- **Evidence anchors:**
  - [section] "The transformation model fθ learned from the labeled data cannot be directly used to make predictions and thus assign pseudo-labels to unlabeled samples. To classify the unlabeled samples, Metric-DST applies a weighted version of k nearest neighbors (kNN) to the embedding matrix Z(t)."
  - [section] "The learned transformation serves the dual purpose of predicting pseudo-labels and assessing sample diversity to counter the data bias."
  - [corpus] Weak evidence: corpus includes general semi-supervised learning but no explicit experimental support for dual-use embeddings in bias mitigation.
- **Break condition:** If the embedding space fails to preserve class structure, kNN predictions become unreliable and diversity selection based on Euclidean distances will not capture true diversity.

## Foundational Learning

- **Concept:** Metric learning with contrastive loss
  - Why needed here: Creates a bounded latent space where distances reflect class membership, enabling meaningful diversity selection.
  - Quick check question: What is the effect of the positive and negative margins in the contrastive loss on intra- and inter-class distances?
- **Concept:** Semi-supervised self-training with pseudo-labels
  - Why needed here: Allows incorporation of unlabeled data to improve representation of the underlying population distribution.
  - Quick check question: How does self-training typically reinforce bias when using only high-confidence samples?
- **Concept:** Class-aware sample selection
  - Why needed here: Ensures that pseudo-labeled samples are balanced across classes, preventing class imbalance from amplifying bias.
  - Quick check question: What would happen if Metric-DST did not enforce class balance in its diversity selection step?

## Architecture Onboarding

- **Component map:** Metric learning module -> Embedding transformation function fθ -> Weighted kNN classifier -> Random point generator -> Confidence threshold µ -> Class balance enforcement
- **Critical path:**
  1. Train metric embedding on labeled data
  2. Transform labeled and unlabeled data to embedding space
  3. Apply kNN to assign pseudo-labels and confidence scores
  4. Generate random points and select nearest pseudo-labeled samples above µ
  5. Add selected samples to labeled set for next iteration
- **Design tradeoffs:**
  - Relaxing µ increases diversity but risks noisy labels; tightening µ reduces noise but limits diversity gains.
  - Larger p increases training data but may slow convergence and amplify errors if µ is too low.
  - Using kNN vs. a parametric classifier trades off flexibility for embedding adaptation vs. computational cost.
- **Failure signatures:**
  - If embedding space collapses: pseudo-labels become random, diversity selection ineffective.
  - If µ too low: high variance in performance, frequent noisy samples degrade model.
  - If p too large relative to available confident samples: class imbalance reintroduced, bias reappears.
- **First 3 experiments:**
  1. Run Metric-DST on moons dataset with delta bias (∆0 = ∆1 = (0,0), 100 samples) and compare AUROC vs. Metric-ST and Supervised.
  2. Apply Metric-DST to a real-world benchmark (e.g., Breast Cancer) with hierarchy bias (b=0.9, 60 samples) and record AUROC and variance.
  3. Evaluate Metric-DST on synthetic lethality prediction using randomized split for BRCA, measuring AUPRC improvement over Supervised.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Metric-DST scale with increasing dimensionality and feature complexity in high-dimensional datasets?
- Basis in paper: [explicit] The paper tested Metric-DST on datasets with 16, 32, 64, and 128 dimensions, but did not systematically explore performance trends across this range.
- Why unresolved: The experiments provided limited insights into how Metric-DST's effectiveness changes as dimensionality increases, particularly in relation to the ratio of informative to uninformative features.
- What evidence would resolve it: Additional experiments systematically varying dimensionality and feature ratios, along with ablation studies isolating the impact of these factors on Metric-DST's performance.

### Open Question 2
- Question: What is the impact of different neural network architectures and loss functions on Metric-DST's ability to mitigate selection bias?
- Basis in paper: [explicit] The paper used a specific neural network architecture (single hidden layer) and contrastive loss, but acknowledged that future work could explore different architectures and loss functions.
- Why unresolved: The current experiments did not investigate the sensitivity of Metric-DST's performance to architectural choices or alternative loss functions that might better capture class-separability in the embedding space.
- What evidence would resolve it: Comparative studies using various neural network architectures (e.g., deeper networks, convolutional layers) and loss functions (e.g., triplet loss, margin-based losses) to assess their impact on Metric-DST's bias mitigation capabilities.

### Open Question 3
- Question: How does Metric-DST perform on multi-class classification tasks with selection bias, and what modifications might be necessary?
- Basis in paper: [inferred] The paper focused exclusively on binary classification tasks, but the selection bias problem and Metric-DST's core principles could be applicable to multi-class scenarios.
- Why unresolved: The paper did not address whether Metric-DST's diversity selection mechanism and metric learning approach can be effectively extended to multi-class problems, or what challenges might arise in such settings.
- What evidence would resolve it: Experiments applying Metric-DST to multi-class datasets with induced selection bias, along with analysis of any modifications needed to the selection mechanism or metric learning formulation to handle multiple classes effectively.

## Limitations

- The framework's scalability to very high-dimensional spaces remains untested, with unclear performance as dimensionality increases.
- Limited empirical validation on diverse real-world datasets beyond the molecular biology task, raising questions about generalization.
- No systematic hyperparameter analysis for the relaxed confidence threshold µ across different bias types and data distributions.

## Confidence

- **Major uncertainties remain around generalization to high-dimensional and real-world settings** (Medium)
- **Claims about bias mitigation in controlled synthetic scenarios are reasonably supported** (Medium)
- **Claims about real-world applicability have Low confidence due to limited empirical breadth** (Low)

## Next Checks

1. Test Metric-DST on additional real-world datasets with known selection bias (e.g., credit scoring, medical diagnosis) to assess generalization beyond molecular biology.
2. Perform ablation studies removing the metric learning component to quantify its contribution to performance gains versus vanilla diversity selection.
3. Conduct sensitivity analysis across different values of µ and p to establish robust hyperparameter ranges for practical deployment.