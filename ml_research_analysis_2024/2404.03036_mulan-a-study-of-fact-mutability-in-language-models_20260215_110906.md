---
ver: rpa2
title: 'MuLan: A Study of Fact Mutability in Language Models'
arxiv_id: '2404.03036'
source_url: https://arxiv.org/abs/2404.03036
tags:
- mutable
- language
- facts
- immutable-n
- relations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MULAN, a benchmark for evaluating language
  models' ability to handle time-contingent facts. It addresses the challenge of identifying
  mutable facts (e.g., current presidents, championship winners) versus immutable
  ones.
---

# MuLan: A Study of Fact Mutability in Language Models

## Quick Facts
- arXiv ID: 2404.03036
- Source URL: https://arxiv.org/abs/2404.03036
- Reference count: 30
- Language models handle mutable facts differently than immutable ones, showing lower confidence and better updateability for time-contingent information.

## Executive Summary
This paper introduces MULAN, a benchmark for evaluating how language models handle time-contingent facts. The authors investigate whether mutable facts (like current presidents or championship winners) are encoded differently than immutable ones in language models. Through systematic evaluation of six popular models, they find consistent patterns: mutable facts elicit lower confidence scores, have more separable representations, and are more successfully updated through in-context learning. These findings suggest that while time awareness isn't easily detected through prompting, it's present in model representations, informing future work on knowledge injection and updates.

## Method Summary
The authors create MULAN, a benchmark containing 47k queries across 35 relations (12 Immutable-1, 10 Immutable-N, 13 Mutable) with 5 templates per query. They evaluate models using greedy decoding with beam=1, measuring F1 scores through maximum overlap with ground truth objects. Confidence is computed as the probability of the first predicted token. Probe classifiers with MDL compression are trained to distinguish mutable from immutable facts based on model representations. In-context learning is used to test update capabilities, measuring success rates for different fact types.

## Key Results
- LLaMA shows significantly lower F1 scores for mutable facts (24.6) compared to immutable facts (55.1)
- Probe classifiers achieve >0.85 accuracy in distinguishing mutable from immutable representations
- Alpaca successfully updates mutable facts 84.5% of the time versus 73.4% for immutable-1 facts

## Why This Works (Mechanism)

### Mechanism 1
Language models encode time-contingent facts differently in their representations, enabling easier updates. The distinct representation patterns for mutable facts make them more amenable to in-context editing. Evidence shows lower confidence scores and better separability for mutable facts. Break condition: If probe classifiers fail to achieve high accuracy or confidence scores don't consistently differ between fact types.

### Mechanism 2
In-context learning leverages the distinct representation of mutable facts to facilitate updates, resulting in higher success rates compared to immutable facts. This mechanism relies on the model's ability to recognize and modify representations associated with mutable knowledge. Evidence includes higher update success rates for mutable facts. Break condition: If in-context learning fails to update mutable facts more effectively than immutable ones.

### Mechanism 3
The inherent uncertainty in time-contingent facts leads to lower confidence scores and F1 scores for predictions involving these facts. This mechanism suggests that models naturally assign less certainty to mutable information. Evidence shows consistent differences in confidence between mutable and immutable predictions. Break condition: If confidence scores and F1 scores don't consistently differ between fact types.

## Foundational Learning

- **Time-contingent facts**: Facts that change over time (e.g., current presidents). Needed to understand the benchmark design and experimental setup. Quick check: What makes "current president of France" different from "capital of France"?

- **Language model representations**: How models encode factual knowledge in their internal states. Crucial for understanding the hypothesis about different encoding of mutable facts. Quick check: How might a model represent "Barack Obama was president" versus "Joe Biden is president"?

- **In-context learning**: Updating model knowledge by providing examples within the input prompt. Important for understanding the update mechanism evaluation. Quick check: How does in-context learning differ from fine-tuning for knowledge updates?

## Architecture Onboarding

- **Component map**: MULAN benchmark -> Language model evaluation -> Probe classifier training -> In-context learning update testing
- **Critical path**: 1) Create MULAN benchmark by selecting relations and generating queries 2) Evaluate language models on MULAN to measure performance and confidence 3) Train probe classifiers to distinguish mutable/immutable facts 4) Update knowledge using in-context learning and measure success rates
- **Design tradeoffs**: Dataset size vs. quality (balancing query quantity with fact accuracy), probe classifier complexity vs. interpretability, in-context learning effectiveness vs. computational cost
- **Failure signatures**: Low probe classifier accuracy (representations don't encode mutability), inconsistent confidence scores (model certainty isn't reliably different), low update success rates (in-context learning ineffective)
- **First 3 experiments**: 1) Evaluate a language model on MULAN to measure performance differences 2) Train a probe classifier to distinguish fact types and analyze representations 3) Update model knowledge using in-context learning for both fact types and compare success rates

## Open Questions the Paper Calls Out

### Open Question 1
How do language models acquire time awareness given that they are trained on shuffled data? The paper demonstrates that LLMs encode mutability but doesn't explain the mechanism by which this occurs during training on temporally unordered data. Detailed analysis of training processes and internal representations could reveal how temporal information is implicitly learned.

### Open Question 2
How can we improve the completeness of the MULAN dataset to better capture all valid completions of mutable facts over time? Current dataset limitations affect evaluation as some mutable examples only have one target answer despite having multiple potential answers in reality. A more comprehensive dataset integrating additional sources could better represent dynamic fact nature.

### Open Question 3
What are the most effective methods for updating LLM knowledge beyond in-context learning, especially for mutable facts? The paper only explores in-context learning, which may not be the most efficient approach for maintaining up-to-date information. Comparative studies of various knowledge updating techniques would identify optimal methods.

## Limitations

- Limited to 35 relations from Wikidata, which may not capture full spectrum of fact types and complexities
- Cannot definitively establish causal relationship between fact mutability and model representations
- Study focuses on popular models but broader evaluation would strengthen generalizability conclusions

## Confidence

- **High Confidence**: Empirical findings regarding performance differences (F1 scores, confidence levels) between mutable and immutable facts across multiple models
- **Medium Confidence**: Interpretation that distinct representations enable easier updates
- **Medium Confidence**: Generalizability of findings to other language models and fact types

## Next Checks

1. Conduct temporal analysis varying time distance between fact states to understand temporal aspects of fact mutability encoding
2. Evaluate same models on different dataset of time-contingent facts from another domain to test robustness of observed patterns
3. Design intervention study where models are explicitly trained to distinguish between mutable and immutable facts to determine if this improves handling of time-contingent knowledge