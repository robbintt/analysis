---
ver: rpa2
title: 'Cendol: Open Instruction-tuned Generative Large Language Models for Indonesian
  Languages'
arxiv_id: '2404.06138'
source_url: https://arxiv.org/abs/2404.06138
tags:
- cendol
- language
- indonesian
- llms
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Cendol is a collection of large language models tailored for Indonesian
  languages, addressing the quality gap in low-resource languages. The models, spanning
  from 300M to 13B parameters, were instruction-tuned using a diverse dataset of ~50M
  prompts across 23 tasks and 10 languages.
---

# Cendol: Open Instruction-tuned Generative Large Language Models for Indonesian Languages

## Quick Facts
- arXiv ID: 2404.06138
- Source URL: https://arxiv.org/abs/2404.06138
- Reference count: 18
- Primary result: Cendol models achieve 20% improvement in NLU and NLG tasks compared to existing multilingual and Indonesian LLMs

## Executive Summary
Cendol addresses the quality gap in low-resource languages by developing a collection of instruction-tuned large language models specifically for Indonesian and underrepresented languages. The models span from 300M to 13B parameters and were trained on a diverse corpus of ~50M prompts across 23 tasks and 10 languages. Cendol demonstrates significant performance improvements over existing models while showing strong generalization to unseen tasks and languages, with safety transferability from English to Indonesian.

## Method Summary
Cendol models were developed through a multi-phase instruction tuning approach using a diverse corpus of 53.5M prompts across 23 tasks and 10 languages. The training employed decoder-only models (LLaMA-2 7B, 13B) and encoder-decoder models (mT5 variants from small to XXL), with full fine-tuning for models under 10B parameters and LoRA for larger models. Training was conducted on GPU clusters (4x40GB A100 for most models, 8x80GB A100 for LLaMA2-7B), followed by comprehensive evaluation covering NLU, NLG, generalization, local knowledge, and safety tasks.

## Key Results
- 20% improvement in NLU and NLG tasks compared to existing multilingual and Indonesian LLMs
- Larger models show better performance on unseen tasks and languages
- Vocabulary adaptation achieves 21.28% improvement in token efficiency for Indonesian text
- Safety transferability from English to Indonesian without additional fine-tuning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Instruction tuning on a diverse multilingual corpus significantly improves NLU and NLG performance for underrepresented languages.
- Mechanism: Large language models learn generalizable linguistic patterns during pre-training, and instruction tuning fine-tunes these patterns for specific tasks and languages. By training on a corpus that includes Indonesian and local languages across various tasks, the model learns to map instructions to appropriate responses in these languages, closing the quality gap compared to multilingual models that underrepresent these languages.
- Core assumption: The pre-trained model has sufficient capacity to learn and generalize from the instruction-tuned data across languages and tasks.
- Evidence anchors:
  - [abstract] "The models, spanning from 300M to 13B parameters, were instruction-tuned using a diverse dataset of ~50M prompts across 23 tasks and 10 languages. Cendol models achieved a 20% improvement in NLU and NLG tasks compared to existing multilingual and Indonesian LLMs."
  - [section 3] Details the composition of the Cendol Collection, covering 23 tasks and 10 languages.
- Break condition: If the pre-trained model lacks capacity or the instruction-tuned data is insufficient or unrepresentative, the performance improvement will not be achieved.

### Mechanism 2
- Claim: Larger model sizes lead to better performance on unseen tasks and languages.
- Mechanism: Larger models have more parameters, allowing them to capture more complex linguistic patterns and relationships. This increased capacity enables them to generalize better to new tasks and languages that were not explicitly seen during training. The paper shows that larger Cendol models consistently outperform smaller ones on unseen language NLU tasks.
- Core assumption: The scaling of model size directly correlates with the model's ability to capture and generalize linguistic patterns.
- Evidence anchors:
  - [section 6.2] "The NLU performance to unseen languages follows the scaling law of LLMs. The performance improvements on NLG tasks are less apparent..."
  - [section 6] Mentions that larger Cendol models perform better on unseen tasks and languages.
- Break condition: If the model architecture or training data quality does not scale proportionally with model size, or if the scaling reaches a point of diminishing returns, the performance improvement may plateau or degrade.

### Mechanism 3
- Claim: Vocabulary adaptation can improve inference efficiency without significantly sacrificing downstream performance.
- Mechanism: Standard subword tokenization often leads to longer sequences for low-resource languages, increasing computational cost. By adapting the vocabulary to better represent the target language (Indonesian in this case), the tokenization becomes more efficient, reducing the number of tokens and thus the computational load during inference. The paper shows that this adaptation leads to a 21.28% improvement in token efficiency for Indonesian text without significant performance degradation.
- Core assumption: The adapted vocabulary can adequately represent the target language while maintaining semantic and syntactic information necessary for downstream tasks.
- Evidence anchors:
  - [section D] "By adapting the vocabulary to better represent the target language (Indonesian in this case), the tokenization becomes more efficient, reducing the number of tokens and thus the computational load during inference."
  - [section D] "This token efficiency results in improvements in both training and inference with around ∼11.50% and ∼18.71% efficiency improvement, respectively."
- Break condition: If the adapted vocabulary fails to capture important linguistic nuances or if the averaging method for embedding initialization is inadequate, the downstream performance may degrade significantly.

## Foundational Learning

- Concept: Language model pre-training and fine-tuning
  - Why needed here: Understanding how pre-trained language models can be adapted for specific languages and tasks is crucial for comprehending the Cendol model development process.
  - Quick check question: What is the difference between pre-training and fine-tuning in the context of language models, and why is each step necessary?

- Concept: Instruction tuning and zero-shot generalization
  - Why needed here: Instruction tuning is the key technique used to adapt Cendol models for Indonesian languages and various tasks. Understanding how it enables zero-shot generalization is essential for evaluating the model's capabilities.
  - Quick check question: How does instruction tuning enable a language model to perform tasks it hasn't been explicitly trained on, and what are the limitations of this approach?

- Concept: Parameter-efficient fine-tuning methods (e.g., LoRA)
  - Why needed here: The paper discusses the ineffectiveness of LoRA for language adaptation, highlighting the importance of choosing the right fine-tuning method. Understanding LoRA and its limitations is crucial for interpreting the results.
  - Quick check question: What is LoRA, and why might it be less effective for language adaptation compared to full fine-tuning in certain scenarios?

## Architecture Onboarding

- Component map:
  - Pre-trained models (decoder-only: LLaMA-2 7B, 13B; encoder-decoder: mT5 variants from small to XXL)
  - Instruction-tuning corpus (Cendol Collection: ~50M prompts across 23 tasks and 10 languages)
  - Fine-tuning strategy (full fine-tuning for models <10B parameters, LoRA for larger models)
  - Evaluation suite (Indonesian indigenous evaluation, local knowledge and cultural commonsense evaluation, safety evaluation)

- Critical path:
  1. Select appropriate pre-trained model based on desired scale and architecture.
  2. Prepare the Cendol Collection corpus, ensuring diversity in tasks and languages.
  3. Implement the multi-phase instruction tuning process (NLP task-based prompts first, then general knowledge and human-centric prompts).
  4. Evaluate the model on the Indonesian indigenous evaluation suite to assess performance on seen and unseen tasks and languages.
  5. Conduct local knowledge and cultural commonsense evaluation to assess cultural understanding.
  6. Perform safety evaluation to ensure the model does not generate harmful or unsafe content.

- Design tradeoffs:
  - Model size vs. computational resources: Larger models offer better performance but require more computational power for training and inference.
  - Full fine-tuning vs. LoRA: Full fine-tuning generally yields better performance but is more computationally expensive, while LoRA is more efficient but may sacrifice some performance, especially for language adaptation.
  - Vocabulary adaptation vs. standard tokenization: Vocabulary adaptation can improve efficiency but requires careful initialization and may impact performance if not done correctly.

- Failure signatures:
  - Poor performance on Indonesian and local languages: Indicates insufficient representation in the pre-training data or instruction-tuning corpus.
  - Degraded performance on unseen tasks or languages: Suggests the model has not learned to generalize effectively.
  - Inefficient inference: May indicate the need for vocabulary adaptation or optimization of the tokenization process.
  - Safety issues: Highlights the importance of incorporating safety considerations during both pre-training and fine-tuning.

- First 3 experiments:
  1. Evaluate the performance of Cendol models on a small subset of the Indonesian indigenous evaluation suite to assess their initial capabilities and identify areas for improvement.
  2. Compare the performance of Cendol models with different sizes (e.g., mT5 small vs. mT5 large) on the same evaluation tasks to understand the impact of model scale.
  3. Implement and evaluate the effectiveness of vocabulary adaptation on a smaller model (e.g., mT5 small) to assess its impact on efficiency and performance before applying it to larger models.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can human alignment techniques be effectively integrated into instruction-tuned LLMs to improve their ability to generate responses aligned with human values and preferences?
- Basis in paper: [explicit] The paper discusses the limitations of Cendol models in capturing human-aligned responses, noting that supervised fine-tuning alone is insufficient and that reinforcement learning from human feedback (RLHF) or reinforcement learning with AI feedback (RLAIF) is necessary for generating human-aligned responses.
- Why unresolved: The paper highlights the need for better human alignment but does not explore specific methods or their effectiveness beyond mentioning RLHF and RLAIF as potential approaches.
- What evidence would resolve it: Comparative studies evaluating the effectiveness of different human alignment techniques, such as RLHF, RLAIF, or other alignment methods, on the performance and alignment of Cendol models with human values and preferences.

### Open Question 2
- Question: What are the specific challenges and strategies for capturing local cultural values and nuances in underrepresented languages using LLMs?
- Basis in paper: [explicit] The paper identifies the limitation of Cendol models in capturing local cultural values in Indonesia, attributing this to the underrepresentation of diverse cultural contexts in the training datasets.
- Why unresolved: The paper acknowledges the issue but does not provide detailed strategies or solutions for effectively capturing local cultural values and nuances in underrepresented languages.
- What evidence would resolve it: Research exploring methods for incorporating diverse cultural contexts into LLM training datasets and evaluating their impact on the models' ability to accurately reflect local cultural values and nuances.

### Open Question 3
- Question: How can safety evaluations for LLMs be made more culturally relevant and effective for underrepresented languages?
- Basis in paper: [explicit] The paper notes that current safety evaluations for Cendol models rely on translated versions of English safety corpora, which may not fully capture local and cultural nuances, suggesting the need for locally sourced Indonesian safety corpora.
- Why unresolved: The paper identifies the limitations of current safety evaluations but does not propose specific approaches for developing culturally relevant safety evaluations for underrepresented languages.
- What evidence would resolve it: Development and evaluation of safety corpora and evaluation methods that are specifically designed for underrepresented languages, incorporating local cultural and social contexts to provide more accurate insights into potential safety risks.

## Limitations

- Low-resource language representation may be insufficient for all Indonesian indigenous languages, as the instruction-tuning corpus covers only 10 languages out of 700+ local languages
- Safety evaluation artifacts due to reliance on translated English datasets, which may not capture cultural nuances and safety perceptions specific to Indonesian contexts
- Parameter-efficient tuning effectiveness uncertainty, as LoRA was found ineffective for language adaptation but this conclusion is based on limited experimentation

## Confidence

**High Confidence:**
- Cendol models achieve 20% improvement over existing multilingual and Indonesian LLMs on NLU and NLG tasks
- Larger models consistently show better performance on unseen tasks and languages
- Vocabulary adaptation improves inference efficiency without significant performance degradation
- Safety transferability from English to Indonesian without additional fine-tuning

**Medium Confidence:**
- The effectiveness of instruction tuning for closing the quality gap in low-resource languages
- The generalization capabilities to truly unseen languages and tasks
- The cultural relevance of safety evaluation using translated datasets

**Low Confidence:**
- The scalability of Cendol's approach to all Indonesian indigenous languages
- The absolute performance levels compared to proprietary models that were not directly tested
- The long-term effectiveness of vocabulary adaptation as models continue to scale

## Next Checks

1. **Cross-lingual generalization test:** Evaluate Cendol models on a carefully curated set of truly unseen Indonesian indigenous languages (those not present in the instruction-tuning corpus) to validate the claimed generalization capabilities beyond the 10 languages in the training data.

2. **Cultural safety validation:** Conduct native speaker evaluation of safety responses, particularly for culturally specific prompts, to validate the safety transferability claims and identify potential cultural misalignments in the translated safety datasets.

3. **Parameter-efficient tuning optimization:** Systematically explore LoRA hyperparameters (rank, alpha, initialization strategies) specifically for language adaptation scenarios to determine whether the ineffectiveness finding is robust or could be overcome with better configuration.