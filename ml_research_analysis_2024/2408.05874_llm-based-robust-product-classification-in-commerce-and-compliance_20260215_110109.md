---
ver: rpa2
title: LLM-Based Robust Product Classification in Commerce and Compliance
arxiv_id: '2408.05874'
source_url: https://arxiv.org/abs/2408.05874
tags: []
core_contribution: The research introduces a data perturbation framework to simulate
  real-world product classification challenges like abbreviated or incomplete product
  descriptions. It proposes using LLM-based approaches with in-context learning to
  improve classification robustness under such perturbations.
---

# LLM-Based Robust Product Classification in Commerce and Compliance

## Quick Facts
- arXiv ID: 2408.05874
- Source URL: https://arxiv.org/abs/2408.05874
- Reference count: 19
- Key outcome: GPT-4 with few-shot prompting achieves state-of-the-art product classification robustness under data perturbations, maintaining 85.7% F1-score vs. 46.0% for supervised models

## Executive Summary
This paper introduces a data perturbation framework to simulate real-world product classification challenges in e-commerce, including abbreviated and incomplete product descriptions. The authors propose using large language models (LLMs) with in-context learning to improve classification robustness under such perturbations. Experiments on Icecat and WDC-222 datasets demonstrate that GPT-4 significantly outperforms traditional supervised models like DeBERTaV3-base when data attacks are present, achieving up to 93.5% macro F1-score on clean data and maintaining 85.7% even with combined attacks.

## Method Summary
The research introduces a data perturbation framework that simulates real-world product classification challenges through synthetic attacks including abbreviation, misspelling, and stopword removal. The approach leverages LLM-based methods with in-context learning, specifically using GPT-4 with few-shot prompting. The methodology is evaluated on two datasets (Icecat and WDC-222) to assess classification performance under both clean and perturbed conditions, comparing against traditional supervised models like DeBERTaV3-base.

## Key Results
- GPT-4 achieves up to 93.5% macro F1-score on clean data and maintains 85.7% with combined attacks
- Supervised models drop from 88.5% to 46.0% under combined perturbations
- LLMs significantly outperform on the more complex WDC-222 dataset, demonstrating generalization across heterogeneous data sources

## Why This Works (Mechanism)
The mechanism relies on LLMs' ability to understand context and semantics even when product descriptions are incomplete or noisy. Unlike traditional models that require clean, structured input, LLMs can infer meaning from partial information through few-shot prompting, maintaining classification accuracy despite data perturbations that would typically confuse supervised models.

## Foundational Learning

**Data Perturbation Framework**: Simulating real-world noise in product descriptions through controlled attacks (abbreviation, misspelling, stopword removal) to test model robustness.
*Why needed*: Real e-commerce data is inherently noisy and incomplete, requiring models to handle imperfect inputs.
*Quick check*: Verify perturbation types cover realistic e-commerce scenarios beyond synthetic examples.

**In-Context Learning**: LLMs' ability to learn from examples provided in the prompt without parameter updates.
*Why needed*: Enables zero/few-shot adaptation to classification tasks without expensive fine-tuning.
*Quick check*: Test performance degradation as number of shots decreases.

**Robustness Metrics (∆r)**: Measuring classification accuracy drop between clean and perturbed data to quantify model resilience.
*Why needed*: Traditional accuracy metrics don't capture real-world performance under data quality variations.
*Quick check*: Compare ∆r across different perturbation intensities.

## Architecture Onboarding

**Component Map**: Input Data -> Perturbation Framework -> LLM Prompting Engine -> Classification Output

**Critical Path**: Product description → Perturbation application → Few-shot prompt construction → GPT-4 inference → Category prediction

**Design Tradeoffs**: LLM-based approaches offer superior robustness but at higher computational cost and potential privacy concerns versus traditional supervised models that require less compute but fail under data perturbations.

**Failure Signatures**: Supervised models show sharp accuracy drops (from 88.5% to 46.0%) under combined perturbations; LLM performance degrades more gradually, indicating better handling of noisy inputs.

**First 3 Experiments**:
1. Baseline classification on clean Icecat dataset to establish performance ceiling
2. Single perturbation type testing (abbreviation only) to identify weakest points
3. Combined perturbation testing to simulate realistic noisy conditions

## Open Questions the Paper Calls Out
None

## Limitations
- Synthetic perturbations may not fully capture real-world e-commerce data quality issues
- Comparison primarily against single supervised baseline (DeBERTaV3-base) limits generalizability
- Dataset complexity claims need more detailed justification regarding what makes WDC-222 "complex"

## Confidence

| Claim | Confidence |
|-------|------------|
| GPT-4 maintains higher accuracy under tested perturbations vs DeBERTaV3-base | High |
| LLM superiority in commerce classification more broadly | Medium |
| Applicability to "complex" WDC-222 data | Low |

## Next Checks
1. Test the perturbation framework with real-world product description errors from actual e-commerce platforms, not just synthetic attacks
2. Compare GPT-4 performance against multiple supervised baselines including domain-specific fine-tuned models and ensemble approaches
3. Evaluate cross-dataset generalization by training on Icecat and testing on WDC-222 (and vice versa) to assess true domain robustness