---
ver: rpa2
title: 'NUMCoT: Numerals and Units of Measurement in Chain-of-Thought Reasoning using
  Large Language Models'
arxiv_id: '2406.02864'
source_url: https://arxiv.org/abs/2406.02864
tags:
- hundred
- question
- answer
- english
- following
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how well Large Language Models (LLMs) handle
  numeral conversions and units of measurement. The authors construct four datasets
  to evaluate tasks such as converting between numerals and words, and converting
  between different units of measurement.
---

# NUMCoT: Numerals and Units of Measurement in Chain-of-Thought Reasoning using Large Language Models

## Quick Facts
- arXiv ID: 2406.02864
- Source URL: https://arxiv.org/abs/2406.02864
- Authors: Ancheng Xu; Minghuan Tan; Lei Wang; Min Yang; Ruifeng Xu
- Reference count: 40
- Primary result: LLMs struggle with numeral and unit conversions, with performance varying by language and task complexity.

## Executive Summary
This paper investigates how well Large Language Models (LLMs) handle numeral conversions and units of measurement. The authors construct four datasets to evaluate tasks such as converting between numerals and words, and converting between different units of measurement. They also include bilingual math word problems and ancient Chinese arithmetic problems to test LLMs' performance across languages and contexts. The study finds that while ChatGPT excels in numeral conversion tasks, it and other LLMs struggle with unit conversions and more complex reasoning involving rare knowledge. The introduction of Chain-of-Thought prompting often deteriorates performance, especially for simpler tasks. Overall, the research highlights significant gaps in LLMs' abilities to process numerals and units, indicating areas for further improvement in training and benchmarking.

## Method Summary
The authors construct four datasets to evaluate LLM performance on numeral and unit conversion tasks. These datasets include numeral conversion (words to numerals and vice versa), unit conversion (length, weight, and volume), bilingual math word problems, and ancient Chinese arithmetic problems (SUANJING). The study evaluates three state-of-the-art LLMs (ChatGPT, Llama2-7B, Llama2-13B) using both standard and Chain-of-Thought (CoT) prompting. Performance is measured using exact match accuracy, with additional analysis of error patterns and the impact of CoT prompting.

## Key Results
- ChatGPT achieves high accuracy on numeral conversion tasks but struggles with unit conversions.
- CoT prompting often degrades performance on simpler tasks but can help with complex unit conversions.
- LLMs show language-dependent performance, with Chinese tasks generally more challenging than English ones.
- SUANJING problems require specialized knowledge, and providing external knowledge through prompts can improve performance.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CoT prompting can improve performance on unit conversion tasks by explicitly exposing the scaling relationships.
- Mechanism: When unit conversion involves multiple scaling steps (e.g., tons to kilograms to grams), CoT helps the model lay out each intermediate conversion, reducing cognitive load and error propagation.
- Core assumption: The scaling relationships are well-known and memorizable; the main challenge is systematic application.
- Evidence anchors:
  - [abstract] "LLMs consistently struggle to memorize conversion ratios between different units"
  - [section 4.2] "Introducing CoT significantly mitigates the occurrence of such errors but still requires further refinement"
  - [corpus] weak: no direct mention of CoT improving memorization
- Break condition: If scaling relationships are not memorized or if CoT introduces additional steps that compound errors, performance can degrade.

### Mechanism 2
- Claim: Performance on numeral conversion tasks is language-dependent due to differences in number system transparency.
- Mechanism: Chinese and English numeral systems have different syntactic structures (e.g., grouping by thousands vs. ten-thousands), which affects how well the model can parse and generate numerals in each language.
- Core assumption: The training corpus is skewed toward one language, leading to better performance in that language.
- Evidence anchors:
  - [section 4.1] "Both Chinese and English have relative high number system transparency... This partially shows that either training corpus is skewed or numeral conversions knowledge is less transferable across languages"
  - [corpus] weak: no explicit corpus analysis provided
- Break condition: If the model is trained on balanced multilingual data or if numeral conversion rules are highly transferable, language dependency may diminish.

### Mechanism 3
- Claim: Introducing external knowledge through few-shot CoT prompts can improve performance on SUANJING problems.
- Mechanism: SUANJING problems require specialized knowledge of ancient Chinese units and fractions, which can be provided in the prompt to guide the model's reasoning.
- Core assumption: The model can effectively utilize provided external knowledge when prompted correctly.
- Evidence anchors:
  - [section 4.3] "We employ three state-of-the-art models... to evaluate the performance of LLMs on MWPs and SUANJING"
  - [section 4.4] "This long tail problem can be addressed by introducing external knowledge in the prompt"
  - [corpus] weak: no direct mention of SUANJING-specific external knowledge
- Break condition: If the model cannot effectively integrate provided knowledge or if the knowledge is too specialized, performance may not improve.

## Foundational Learning

- Concept: Number system transparency
  - Why needed here: Understanding how different languages represent numbers affects model performance on numeral conversion tasks.
  - Quick check question: What is the main difference between English and Chinese number systems in terms of grouping?
- Concept: Unit conversion scaling
  - Why needed here: Recognizing the scaling relationships between units is crucial for accurate conversions.
  - Quick check question: How many grams are in a kilogram?
- Concept: Chain-of-Thought reasoning
  - Why needed here: CoT can help break down complex problems into manageable steps, especially for unit conversions.
  - Quick check question: What is the primary benefit of using CoT in unit conversion tasks?

## Architecture Onboarding

- Component map:
  Input preprocessing -> Tokenization -> Prompt construction -> Model inference -> Output parsing -> Answer validation
- Critical path:
  Input → Tokenization → Prompt construction → Model inference → Output parsing → Answer validation
- Design tradeoffs:
  Few-shot examples vs. CoT instructions: Balance between guidance and model autonomy
  Language-specific prompts: Tradeoff between model performance and prompt engineering complexity
- Failure signatures:
  Incorrect numeral parsing: Misidentification of magnitude or zero handling
  Unit conversion errors: Incorrect scaling relationships or calculation mistakes
  SUANJING-specific failures: Lack of ancient unit knowledge or fraction handling issues
- First 3 experiments:
  1. Compare performance on numeral conversion tasks with and without CoT prompts
  2. Test language-specific prompts on numeral conversion tasks in English and Chinese
  3. Evaluate the impact of providing external knowledge for SUANJING problems through few-shot CoT prompts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of numeral conversion knowledge on the reasoning performance of large language models (LLMs) in mathematical word problems, and how can this be further investigated?
- Basis in paper: [explicit] The paper discusses the impact of numeral conversion knowledge on the reasoning performance of LLMs in mathematical word problems, particularly in the SUANJING dataset, where errors are often made in recognizing numbers and performing numerical calculations.
- Why unresolved: The paper highlights the challenges LLMs face in handling comprehensive problems involving numeral conversions and units of measurement, but it does not provide a detailed investigation into the specific impact of numeral conversion knowledge on reasoning performance.
- What evidence would resolve it: Further experiments could be conducted to systematically vary the complexity of numeral conversions in mathematical word problems and measure the impact on LLM reasoning performance. Additionally, analyzing the types of errors made by LLMs in numeral conversions could provide insights into how this knowledge affects their reasoning.

### Open Question 2
- Question: How can the performance of LLMs be improved for tasks involving numeral conversions and units of measurement, especially in handling rare knowledge and complex reasoning steps?
- Basis in paper: [explicit] The paper mentions that LLMs struggle with tasks involving numeral conversions and units of measurement, particularly when rare knowledge is required. It suggests that introducing external knowledge and Chain-of-Thought (CoT) prompting can help but does not fully resolve the issues.
- Why unresolved: While the paper identifies the challenges and suggests potential solutions, it does not provide a comprehensive approach to improving LLM performance in these tasks.
- What evidence would resolve it: Developing and testing new training methods or prompt engineering techniques that specifically target numeral conversions and units of measurement could provide insights into improving LLM performance. Additionally, evaluating the effectiveness of different types of external knowledge and CoT strategies in various contexts could help identify the most effective approaches.

### Open Question 3
- Question: How do the numeral conversion and unit measurement challenges in LLMs differ across languages, and what are the implications for multilingual model development?
- Basis in paper: [explicit] The paper discusses the performance of LLMs in numeral conversions and units of measurement across different languages, noting that there is a noticeable performance gap between Chinese and English tasks.
- Why unresolved: The paper highlights the differences in performance across languages but does not explore the underlying reasons for these differences or their implications for multilingual model development.
- What evidence would resolve it: Comparative studies of LLM performance on numeral conversions and units of measurement across multiple languages could help identify language-specific challenges and inform the development of more effective multilingual models. Additionally, analyzing the training data and linguistic features of different languages could provide insights into how these factors influence LLM performance.

## Limitations
- The study does not provide a detailed analysis of the training corpus used for the LLMs, which limits our understanding of potential biases or gaps in numeral and unit conversion knowledge.
- The performance degradation observed when using Chain-of-Thought (CoT) prompting for simpler tasks is not fully explained.
- The evaluation of SUANJING problems relies on providing external knowledge through prompts, but the effectiveness of this approach is not thoroughly validated.

## Confidence
- High confidence: The general finding that LLMs struggle with unit conversions and complex reasoning involving rare knowledge.
- Medium confidence: The observation that CoT prompting often deteriorates performance for simpler tasks.
- Low confidence: The specific claims about language-dependent performance on numeral conversion tasks.

## Next Checks
1. Conduct a detailed analysis of the training corpus to identify potential biases or gaps in numeral and unit conversion knowledge.
2. Perform ablation studies to isolate the effects of different components of the CoT prompts on performance for various task types.
3. Evaluate the effectiveness of providing external knowledge for SUANJING problems by systematically varying the specificity and relevance of the provided information.