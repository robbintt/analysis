---
ver: rpa2
title: Measuring Fairness in Large-Scale Recommendation Systems with Missing Labels
arxiv_id: '2406.05247'
source_url: https://arxiv.org/abs/2406.05247
tags:
- uni00000013
- fairness
- traffic
- random
- recommendation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of measuring fairness in large-scale
  recommendation systems when user preference labels are missing for most items. Existing
  methods that treat missing labels as negative are shown to produce significantly
  misleading fairness metrics.
---

# Measuring Fairness in Large-Scale Recommendation Systems with Missing Labels

## Quick Facts
- **arXiv ID:** 2406.05247
- **Source URL:** https://arxiv.org/abs/2406.05247
- **Reference count:** 40
- **Primary result:** Proposed method uses random traffic to probe unrecommended items, enabling accurate fairness measurement where existing methods fail

## Executive Summary
This paper addresses the critical challenge of measuring fairness in large-scale recommendation systems when user preference labels are missing for most items. Traditional approaches that treat missing labels as negative significantly distort fairness metrics, potentially leading to misleading conclusions about system equity. The authors propose a novel framework that uses randomized traffic to probe the unrecommended subset, enabling accurate estimation of fairness metrics like Ranking-based Equal Opportunity (REO). They provide theoretical bounds on estimation error and develop efficient algorithms for computing fairness metrics and conducting statistical significance tests in A/B experiments.

## Method Summary
The proposed method involves two types of traffic: default traffic (standard recommendations) and random traffic (uniform random item sampling for a small fraction of requests). Group utilities are computed using the formula Ûk = Q̂k/P̂k, where P̂k and Q̂k are sample means from random and default traffic respectively. Fairness metrics including REO penalty and relative group utilities are calculated using Algorithm 1 for confidence intervals. The approach enables accurate measurement of treatment effects in A/B tests through efficient significance testing using the delta method.

## Key Results
- Random traffic is essential for accurate fairness measurement; treating missing labels as negative produces significantly misleading metrics
- The proposed method provides reliable confidence intervals for fairness metrics in A/B testing without computationally expensive bootstrap resampling
- Experiments on synthetic and real TikTok data validate effectiveness, showing improved accuracy over existing approaches
- Orthogonal traffic assignment allows the same random traffic to measure fairness metrics across multiple concurrent A/B tests

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Random traffic is necessary to accurately estimate fairness metrics when labels are missing for most items.
- **Mechanism:** Without probing the unrecommended subset via random traffic, the Ranking-based Equal Opportunity (REO) metrics are unidentifiable because two datasets with identical recommended subsets can have drastically different fairness values depending on the unrecommended subset.
- **Core assumption:** The user-item pairs in the recommended subset do not fully represent the preference distribution in the entire user-item space.
- **Evidence anchors:**
  - [abstract]: "Existing methods that treat missing labels as negative are shown to produce significantly misleading fairness metrics."
  - [section]: "Previous methods often treat these samples missing labels as negative, which can significantly deviate from the ground truth fairness metrics."
  - [corpus]: Weak evidence; related papers focus on fairness in recommendation systems but do not directly address missing labels.
- **Break condition:** If the platform has access to full preference labels for all user-item pairs (e.g., through explicit feedback mechanisms), random traffic is no longer necessary for fairness measurement.

### Mechanism 2
- **Claim:** The proposed delta method-based significance test is computationally efficient and accurate for A/B testing fairness metrics.
- **Mechanism:** By leveraging the asymptotic normality of the estimators and using delta method, the method derives confidence intervals in a single pass without the need for computationally expensive bootstrap resampling.
- **Core assumption:** The estimators of the underlying probabilities (p_k and q_k) are asymptotically normal due to the law of large numbers.
- **Evidence anchors:**
  - [abstract]: "Our work also studies the treatment effect in A/B tests through estimating and testing difference of fairness metrics."
  - [section]: "We also provide fast and reliable significance tests for treatment effects in A/B tests in Algorithm 2."
  - [corpus]: Weak evidence; related papers discuss fairness in A/B testing but do not detail computational efficiency.
- **Break condition:** If the sample sizes are too small for the asymptotic normality assumption to hold, the delta method may produce inaccurate confidence intervals.

### Mechanism 3
- **Claim:** The platform can use orthogonal traffic assignment to measure fairness metrics across multiple A/B tests without sacrificing recommendation relevance.
- **Mechanism:** By assigning random traffic orthogonally to different A/B test groups, the same random traffic can be used to estimate fairness metrics for all experiments running on those users, avoiding the need to increase random traffic volume and hurt relevance.
- **Core assumption:** The random traffic is independent of the default traffic and can be assigned orthogonally without introducing bias.
- **Evidence anchors:**
  - [section]: "A good aspect of orthogonal traffic assignment is that the same random traffic can be used to measure the REO-related metrics for all experiments running on these users."
  - [section]: "A/B tests can concurrently occur on the platform with a very high number of distinct configurations."
  - [corpus]: No direct evidence; this appears to be a platform-specific design choice.
- **Break condition:** If the number of concurrent A/B tests is very large, the random traffic may become insufficient to accurately estimate fairness metrics for all tests.

## Foundational Learning

- **Concept:** Ranking-based Equal Opportunity (REO) fairness
  - **Why needed here:** REO is the fairness metric being measured, and understanding its definition is crucial for implementing the measurement method.
  - **Quick check question:** What is the difference between REO and traditional Equal Opportunity in binary classification?

- **Concept:** Random traffic and its role in debiasing
- **Concept:** Delta method for variance propagation
  - **Why needed here:** The delta method is used to derive confidence intervals for the fairness metrics, which is essential for A/B testing and monitoring.
  - **Quick check question:** How does the delta method propagate variance from the underlying probabilities to the fairness metrics?

## Architecture Onboarding

- **Component map:** Data collection (default and random traffic) -> Metric computation (REO, group utilities) -> Significance testing (delta method)
- **Critical path:** The computation of fairness metrics from collected data determines the accuracy and timeliness of fairness monitoring
- **Design tradeoffs:** Between random traffic volume (affects measurement accuracy) and recommendation relevance (affects user experience)
- **Failure signatures:** Inaccurate fairness measurements, long computation times for significance testing, user experience degradation due to excessive random traffic
- **First 3 experiments:**
  1. Verify metric computation correctness by comparing estimated REO values with ground truth on synthetic dataset
  2. Test delta method accuracy by comparing confidence intervals with bootstrap resampling on synthetic dataset
  3. Implement orthogonal traffic assignment and measure REO values for multiple concurrent A/B tests

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the optimal random traffic volume vary across different A/B tests and what factors influence this variation?
- **Basis in paper:** [explicit] Section I.2 discusses that the required sample size for accurate estimation depends on pk and qk values, which can vary based on treatment and control strategies
- **Why unresolved:** The paper mentions this dependency but doesn't provide specific guidelines or empirical results on how to determine optimal volumes for different scenarios
- **What evidence would resolve it:** Empirical studies comparing estimation accuracy across different random traffic volumes and strategy configurations

### Open Question 2
- **Question:** What are the long-term effects of random traffic on user engagement and platform revenue beyond the immediate recommendation relevance?
- **Basis in paper:** [explicit] Section I.3 mentions random traffic can boost recommendation diversity and increase daily stay time, but focuses on short-term effects
- **Why unresolved:** The paper acknowledges potential benefits but doesn't quantify long-term trade-offs between fairness measurement accuracy and business metrics
- **What evidence would resolve it:** Longitudinal studies tracking user engagement, revenue, and fairness metrics over extended periods with varying random traffic levels

### Open Question 3
- **Question:** How can the proposed fairness measurement framework be extended to handle dynamic sensitive attributes that change over time?
- **Basis in paper:** [inferred] The current framework assumes static sensitive attributes, but real-world scenarios may involve attributes like user location or time-based preferences
- **Why unresolved:** The paper focuses on static attributes like age groups but doesn't address scenarios where sensitive attributes evolve
- **What evidence would resolve it:** Extension of the theoretical bounds and algorithms to handle time-varying attribute distributions and their impact on estimation accuracy

### Open Question 4
- **Question:** What is the computational complexity of the proposed algorithms when scaling to extremely large recommendation systems with millions of users and items?
- **Basis in paper:** [explicit] Section J mentions experiments were conducted on a machine with 64GB memory, but doesn't provide complexity analysis for larger scales
- **Why unresolved:** The paper validates effectiveness on TikTok data but doesn't analyze performance bottlenecks or optimization strategies for massive-scale deployments
- **What evidence would resolve it:** Detailed complexity analysis and empirical benchmarks on systems with varying scales, including memory usage and runtime comparisons

### Open Question 5
- **Question:** How do the fairness measurement results compare when using different utility functions beyond REO, such as fairness of exposure or user-side fairness metrics?
- **Basis in paper:** [explicit] Section H discusses alternative fairness metrics but doesn't provide comparative empirical results
- **Why unresolved:** The paper focuses on REO but acknowledges other metrics exist without evaluating their relative merits in practice
- **What evidence would resolve it:** Comparative experiments measuring multiple fairness metrics on the same datasets to evaluate their consistency and sensitivity to random traffic

## Limitations

- Reliance on random traffic introduces computational overhead and potential relevance degradation
- Theoretical bounds assume independence between random and default traffic, which may not hold in practice
- Paper doesn't provide clear threshold for "sufficient" random traffic volume
- Effectiveness depends heavily on platform-specific implementation details not fully disclosed

## Confidence

- **High Confidence:** Treating missing labels as negative produces misleading fairness metrics - well-supported by theoretical analysis and experimental validation
- **Medium Confidence:** Delta method-based significance test is computationally efficient - shown to work but accuracy in small samples needs validation
- **Medium Confidence:** Orthogonal traffic assignment is practical - presented as solution but effectiveness depends on platform-specific implementation

## Next Checks

1. Conduct sensitivity analysis on random traffic volume to determine minimum threshold needed for reliable fairness metric estimation across different recommendation domains
2. Compare delta method confidence intervals against bootstrap resampling on real-world datasets with varying sample sizes to validate asymptotic assumptions
3. Implement orthogonal traffic assignment in production-like environment with concurrent A/B tests to measure actual variance reduction and fairness metric accuracy