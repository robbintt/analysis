---
ver: rpa2
title: On the development of a practical Bayesian optimisation algorithm for expensive
  experiments and simulations with changing environmental conditions
arxiv_id: '2402.03006'
source_url: https://arxiv.org/abs/2402.03006
tags:
- wind
- function
- optimisation
- algorithm
- environmental
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper extends Bayesian optimisation to handle expensive experiments
  and simulations with changing environmental conditions. The core idea is to fit
  a global surrogate model over all controllable and environmental variables, but
  optimise only the controllable parameters conditional on measurements of the uncontrollable
  variables.
---

# On the development of a practical Bayesian optimisation algorithm for expensive experiments and simulations with changing environmental conditions

## Quick Facts
- arXiv ID: 2402.03006
- Source URL: https://arxiv.org/abs/2402.03006
- Reference count: 38
- The paper extends Bayesian optimisation to handle expensive experiments and simulations with changing environmental conditions, achieving up to 88% better performance than benchmarks in terms of annual energy production for different wind directions.

## Executive Summary
This paper addresses the challenge of optimising expensive experiments and simulations where some input parameters (environmental variables) cannot be controlled but significantly impact the objective function. The authors propose ENVBO, an extension of Bayesian optimisation that fits a global surrogate model over both controllable and environmental variables, then optimises only the controllable parameters conditional on measured environmental values. The algorithm is validated on synthetic test functions and applied to a wind farm simulator, demonstrating superior sample efficiency and performance compared to standard Bayesian optimisation and gradient-based methods, particularly when environmental conditions fluctuate during the optimisation process.

## Method Summary
The ENVBO algorithm extends standard Bayesian optimisation to handle experiments where some variables are uncontrollable but measurable. It fits a Gaussian process surrogate model over all variables (both controllable and environmental), then at each iteration measures the current environmental state and optimises only the controllable parameters conditional on those measurements. The algorithm uses expected improvement as the acquisition function and restricts initial training data to a single observation rather than a space-filling design. This approach allows the algorithm to find optimal solutions across the full range of environmental conditions encountered during the optimisation process, rather than optimising for a fixed environmental state.

## Key Results
- ENVBO achieves up to 88% better performance than benchmarks in terms of annual energy production for different wind directions in a wind farm simulator
- The algorithm uses a fraction of the evaluation budget compared to optimisation algorithms that only focus on a fixed environmental value
- ENVBO finds solutions for the full domain of the environmental variable that outperform results from benchmarks in all but one case
- The method demonstrates superior sample efficiency by sharing information across environmental conditions through the global surrogate model

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The global surrogate model trained on all controllable and uncontrollable variables improves sample efficiency by sharing information across environmental conditions.
- Mechanism: By fitting a Gaussian process surrogate over both controllable and uncontrollable variables, the model learns correlations between different environmental states. This allows predictions for new environmental conditions without requiring separate optimisation runs for each condition.
- Core assumption: Environmental conditions are correlated across the domain and observations from different conditions contain transferable information.
- Evidence anchors:
  - [abstract]: "The extension fits a global surrogate model over all controllable and environmental variables"
  - [section]: "The extension can be broken down into three parts... (a) fitting a global surrogate model over all controllable and uncontrollable variables"
  - [corpus]: Weak - No direct evidence in corpus papers about global surrogate models for environmental conditions
- Break Condition: If environmental conditions are completely uncorrelated across the domain, the global model provides no benefit over separate models.

### Mechanism 2
- Claim: Conditional optimisation on measured environmental variables enables finding optimal controllable parameters for any environmental state within the explored domain.
- Mechanism: At each iteration, environmental variables are measured, and the acquisition function is maximized only over controllable parameters while treating environmental variables as fixed. This creates a slice through the full model space, allowing optimization of controllable parameters conditional on current environmental measurements.
- Core assumption: Environmental variables remain stable during the brief period between measurement and function evaluation.
- Evidence anchors:
  - [section]: "the acquisition function is maximised conditional on these values for the environmental inputs max xC |xE Î± (xC )"
  - [section]: "Conditional maximisation essentially means that the environmental variables xE are treated as fixed for the maximisation of the acquisition function for one iteration"
  - [corpus]: Weak - Corpus papers focus on standard Bayesian optimization without conditional optimization on uncontrollable variables
- Break Condition: If environmental variables change rapidly between measurement and evaluation, the conditional optimization becomes invalid.

### Mechanism 3
- Claim: Restricting initial training data to a single observation prevents wasted evaluations on unreachable parameter combinations.
- Mechanism: Instead of generating a space-filling design over all controllable and uncontrollable variables (many of which may be unreachable due to environmental constraints), the algorithm starts with one observation where environmental variables are measured and controllable parameters are randomly sampled. Subsequent points are generated via Bayesian optimization.
- Core assumption: The space-filling design approach used in standard Bayesian optimization is inefficient when some variables are uncontrollable.
- Evidence anchors:
  - [section]: "Algorithm 2 uses one training data point x0 instead of multiple points generated from a space-filling design"
  - [section]: "To resolve this issue, Algorithm 2 uses one training data point x0 instead of multiple points generated from a space-filling design"
  - [corpus]: Weak - No direct evidence in corpus papers about restricting initial training data for environmental variables
- Break Condition: If environmental variables can be controlled or if initial space-filling design provides valuable information, this restriction may reduce performance.

## Foundational Learning

- Gaussian Processes
  - Why needed here: They provide the surrogate model that captures correlations between controllable and uncontrollable variables, enabling predictions for any environmental condition within the explored domain.
  - Quick check question: How does a Gaussian process predict the output for a new input point, and what does the uncertainty represent?

- Expected Improvement Acquisition Function
  - Why needed here: It guides the search toward promising areas by quantifying the expected improvement over the current best observation, balancing exploration and exploitation.
  - Quick check question: What is the difference between expected improvement and upper confidence bound acquisition functions in terms of exploration-exploitation tradeoff?

- Conditional Probability and Slicing
  - Why needed here: The algorithm conditions on measured environmental values, effectively slicing the full surrogate model to optimize only over controllable parameters for specific environmental states.
  - Quick check question: How does conditioning a multivariate Gaussian distribution on some variables affect the distribution of the remaining variables?

## Architecture Onboarding

- Component map:
  - Data collection module: Handles measurement of uncontrollable variables and evaluation of controllable parameters
  - Gaussian process model: Surrogate model trained on all controllable and uncontrollable variables
  - Conditional optimization engine: Maximizes acquisition function over controllable parameters given environmental measurements
  - Acquisition function module: Implements expected improvement calculation
  - Random walk generator: Simulates environmental variable fluctuations

- Critical path:
  1. Measure current environmental variables
  2. Maximize expected improvement acquisition function conditional on measured environmental values
  3. Evaluate objective function at proposed controllable parameters
  4. Update Gaussian process model with new observation
  5. Repeat until budget exhausted

- Design tradeoffs:
  - Global vs. separate models: Global model shares information but requires more complex modeling; separate models are simpler but less sample efficient
  - Single vs. multiple initial observations: Single observation saves budget but may provide less initial information
  - Random walk vs. fixed environmental values: Random walk explores full environmental space but may require more evaluations

- Failure signatures:
  - Poor performance on environmental conditions outside the explored domain (extrapolation failure)
  - Degradation in performance as environmental fluctuation increases
  - Degradation in performance as number of uncontrollable variables increases

- First 3 experiments:
  1. Implement the two-dimensional Levy function example from the paper to verify basic functionality
  2. Test with different levels of environmental fluctuation (varying parameter 'a' in the random walk) to understand sensitivity
  3. Compare performance against standard Bayesian optimization on a simple synthetic function with one uncontrollable variable

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does ENVBO scale with high-dimensional environmental spaces, especially when the number of uncontrollable variables grows significantly?
- Basis in paper: [inferred] The paper mentions that the input space of environmental variables grows exponentially with nE and requires exponentially more training points to cover the input space equally well as lower nE.
- Why unresolved: The study only investigated up to 3 uncontrollable variables, which is not representative of real-world applications that might have 10 or more environmental variables.
- What evidence would resolve it: Experimental results showing ENVBO's performance on problems with 10+ uncontrollable variables, comparing it to alternative methods in terms of sample efficiency and solution quality.

### Open Question 2
- Question: What are the theoretical bounds on the regret of ENVBO with non-linear and non-additive covariance structures for environmental variables?
- Basis in paper: [explicit] The paper mentions that the approach does not assume different covariance structures for controllable and environmental variables, unlike [19] who focus on a linear and additive covariance structure and derive theoretical bounds.
- Why unresolved: The paper provides empirical evidence of ENVBO's performance but does not establish theoretical guarantees on its regret.
- What evidence would resolve it: A mathematical proof establishing the regret bounds of ENVBO for various covariance structures, including non-linear and non-additive ones.

### Open Question 3
- Question: How does the performance of ENVBO change when the environmental variables have different fluctuation levels and correlation structures?
- Basis in paper: [explicit] The paper investigates the effects of different fluctuation levels and variability in the environmental variables, but does not consider different correlation structures.
- Why unresolved: The study only considers uncorrelated environmental variables, which is a simplifying assumption that might not hold in real-world applications.
- What evidence would resolve it: Experimental results showing ENVBO's performance on problems with correlated environmental variables, comparing it to alternative methods in terms of sample efficiency and solution quality.

## Limitations

- The algorithm's performance depends critically on the stability of environmental variables between measurement and evaluation, which may not hold in highly dynamic environments
- The paper only demonstrates performance on problems with up to 3 uncontrollable variables, leaving scalability questions for high-dimensional environmental spaces
- The wind farm simulator validation, while practical, may not fully represent the range of real-world environmental variability encountered in other applications

## Confidence

- **High confidence**: The core algorithmic framework (conditional optimization on measured environmental variables) is sound and well-established within Bayesian optimization literature
- **Medium confidence**: The sample efficiency claims are supported by synthetic benchmarks but would benefit from more diverse real-world applications
- **Medium confidence**: The restriction to single initial observation is justified theoretically but lacks empirical comparison to space-filling designs in the environmental context

## Next Checks

1. **Environmental stability test**: Systematically vary the time between environmental measurement and function evaluation to quantify the impact of environmental drift on algorithm performance
2. **Multi-dimensional environmental test**: Extend validation to problems with 2+ uncontrollable variables to assess scalability and interaction effects between environmental dimensions
3. **Cross-validation on held-out environmental conditions**: Train the global surrogate on a subset of environmental conditions and evaluate performance on held-out conditions to measure extrapolation capability