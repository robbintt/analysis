---
ver: rpa2
title: Heterogeneous Graph Neural Networks with Post-hoc Explanations for Multi-modal
  and Explainable Land Use Inference
arxiv_id: '2406.13724'
source_url: https://arxiv.org/abs/2406.13724
tags:
- land
- graph
- data
- node
- urban
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework for inferring urban land use
  from multi-modal mobility data using heterogeneous graph neural networks (HGNs)
  combined with explainable AI techniques. The framework addresses the challenges
  of fusing diverse mobility data, capturing spatial dependencies, and improving model
  interpretability.
---

# Heterogeneous Graph Neural Networks with Post-hoc Explanations for Multi-modal and Explainable Land Use Inference

## Quick Facts
- arXiv ID: 2406.13724
- Source URL: https://arxiv.org/abs/2406.13724
- Reference count: 40
- Key outcome: Achieves MAE reductions up to 68.35% for office and sustenance land use indicators using HGT with explainability

## Executive Summary
This paper presents a framework that combines heterogeneous graph neural networks with explainable AI techniques to infer urban land use from multi-modal mobility data. The approach integrates mobility data from tube, bus, and bike-sharing networks with road topology to predict land use intensities. By leveraging the spatial dependencies and heterogeneity among different mobility services, the model significantly outperforms baseline methods. The incorporation of feature attribution and counterfactual explanations enhances model transparency, providing insights into the factors influencing land use predictions and potential interventions to achieve balanced urban development.

## Method Summary
The framework processes multi-modal mobility data (tube, bus, bike-sharing) and road topology into a heterogeneous graph structure. A Heterogeneous Graph Transformer (HGT) model is then applied to learn node representations through type-specific attention mechanisms and aggregation functions. The model is trained using AdamW optimizer to predict land use intensities as a multi-task regression problem. Feature attribution explanations are generated using Integrated Gradients, and counterfactual explanations are derived using a local subgraph dissimilarity measure to identify minimal changes needed to achieve balanced land use.

## Key Results
- HGT model achieves significant improvements over baseline methods (NN, GCN, GAT, GraphSage, RGCN)
- MAE reductions of up to 68.35% for office and sustenance land use indicators
- Feature attribution and counterfactual explanations align with human activity patterns in London
- Model provides insights into necessary changes for achieving balanced land use

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Heterogeneous graph neural networks capture spatial dependencies and heterogeneity among different mobility services
- Mechanism: The HGN model encodes multi-modal mobility data into a heterogeneous graph structure where different node types (tube, bus, bike stations) and edge types (road network, transit network) are processed through type-specific attention mechanisms. The model learns to aggregate information from neighboring nodes based on both node types and edge types, allowing it to capture the complex relationships between different mobility services.
- Core assumption: The spatial relationships between mobility nodes reflect actual land use patterns
- Evidence anchors:
  - [abstract] "The proposed HGN model achieves significant improvements over baseline methods, particularly for office and sustenance land use indicators"
  - [section] "The HGN module aims to learn node representations through predetermined meta-relations. To model the influence of various node types, we utilise a multi-head attention mechanism"
- Break condition: If mobility patterns do not correlate with land use (e.g., in areas with non-standard commuting patterns or mixed-use zones)

### Mechanism 2
- Claim: Feature attribution explanations reveal which mobility patterns influence land use predictions
- Mechanism: The model uses Integrated Gradients to compute attribution scores for each input feature (15-minute interval ridership data), quantifying how much each mobility pattern contributes to the predicted land use. This provides transparency into the model's decision-making process.
- Core assumption: The gradient-based attribution methods accurately capture feature importance
- Evidence anchors:
  - [abstract] "Feature attribution and counterfactual explanations enhance model transparency, aligning predictions with human activity patterns"
  - [section] "We use two different feature attribution methods for explaining our HGN model — Gradient · Input and Integrated Gradients"
- Break condition: If the model's feature importance doesn't align with domain knowledge or if gradients are shattered due to model complexity

### Mechanism 3
- Claim: Counterfactual explanations identify minimal changes needed to achieve balanced land use
- Mechanism: The model defines a local subgraph dissimilarity measure that considers node features, node types, edge types, and graph structure. It then finds the nearest subgraph with the desired "mixed" land use prediction, revealing what changes would be needed in the input data.
- Core assumption: The dissimilarity measure accurately captures the effort required to change land use patterns
- Evidence anchors:
  - [abstract] "The analysis of the counterfactual explanations reveals that variations in node features and types are primarily responsible for the differences observed between the predicted land use distribution and the ideal mixed state"
  - [section] "Given an input heterogeneous graph G = (V, E), two 1-hop complete subgraphs Gi = (Vi, Ei) and Gj = (Vj, Ej) for nodes vi, vj ∈ V, respectively, the local subgraph dissimilarity between Gi and Gj is: d(Gi, Gj) = dV(Gi, Gj) + dA(Gi, Gj) + dR(Gi, Gj) + dG(Gi, Gj)"
- Break condition: If the counterfactual explanations suggest unrealistic changes or if the model's predictions are not sensitive to the suggested modifications

## Foundational Learning

- Concept: Heterogeneous Graph Neural Networks
  - Why needed here: To process the multi-modal mobility data with different types of nodes and edges while capturing spatial dependencies
  - Quick check question: How does an HGN differ from a homogeneous GNN in handling node and edge heterogeneity?

- Concept: Explainable AI (XAI) techniques
  - Why needed here: To provide transparency and trust in the model's predictions for urban planning applications where stakeholders need to understand the reasoning behind recommendations
  - Quick check question: What's the difference between feature attribution and counterfactual explanations in terms of what they reveal about model behavior?

- Concept: Graph attention mechanisms
  - Why needed here: To weigh the importance of different neighbors based on their types and the relationships between them, rather than treating all neighbors equally
  - Quick check question: How does the multi-head attention mechanism in HGT differ from standard GAT?

## Architecture Onboarding

- Component map: Data ingestion -> Heterogeneous Graph -> HGT Encoder -> Prediction -> Explanations
- Critical path: Data → Heterogeneous Graph → HGT Encoder → Prediction → Explanations
- Design tradeoffs:
  - Complexity vs. interpretability: HGT is more complex than standard GNNs but provides better explanations
  - Computational cost: Multi-head attention and type-specific processing increase computational requirements
  - Granularity vs. coverage: Finer time intervals (15 minutes) provide more detail but increase data volume
- Failure signatures:
  - Poor performance on certain land use types (e.g., leisure) suggests missing features or inadequate modeling of non-commuting patterns
  - Counterfactual explanations suggesting unrealistic changes indicate issues with the dissimilarity measure or model sensitivity
  - Feature attributions that don't align with domain knowledge suggest issues with the explanation method or model behavior
- First 3 experiments:
  1. Test HGT performance with different numbers of attention heads (1, 2, 4) to find optimal balance between performance and computational cost
  2. Compare Integrated Gradients vs. InputX-Gradient explanations to validate which better aligns with domain knowledge
  3. Run ablation studies removing different node types (e.g., bike stations only) to quantify their contribution to overall performance

## Open Questions the Paper Calls Out
1. How does the performance of HGT models vary when using different catchment radii for land use labeling?
2. How do counterfactual explanations change when considering multi-step transfer relationships among urban mobility facilities?
3. How does the inclusion of inflow data, in addition to outflow data, affect the performance and explainability of the land use inference model?

## Limitations
- Model effectiveness depends on quality and representativeness of mobility data
- Computational complexity may limit scalability to larger urban areas or real-time applications
- Counterfactual explanations rely on custom dissimilarity measure whose sensitivity to parameter changes remains unclear

## Confidence
- **High confidence**: Improved performance metrics (MAE reductions up to 68.35%) and general validity of heterogeneous graph neural networks for spatial data processing
- **Medium confidence**: Interpretability of feature attribution methods, as gradient-based explanations can sometimes produce counterintuitive results in complex models
- **Medium confidence**: Practical utility of counterfactual explanations for urban planning, as the realism of suggested changes needs empirical validation

## Next Checks
1. Conduct structured interviews with urban planners to evaluate whether model's feature attributions and counterfactual explanations align with professional knowledge and practical constraints
2. Evaluate model performance across different time periods and seasons to assess sensitivity to temporal variations in mobility patterns
3. Test framework on mobility data from a different city (e.g., New York or Tokyo) to evaluate generalizability beyond London