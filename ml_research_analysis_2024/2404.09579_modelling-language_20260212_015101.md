---
ver: rpa2
title: Modelling Language
arxiv_id: '2404.09579'
source_url: https://arxiv.org/abs/2404.09579
tags:
- language
- llms
- linguistic
- will
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper argues that large language models (LLMs) can serve as
  scientific models of external, social languages (E-languages), rather than just
  theories of cognitive linguistic competence. It addresses objections that LLMs merely
  track performance data or replicate training corpora by showing they capture group-level
  linguistic conventions and generalize beyond their training data.
---

# Modelling Language

## Quick Facts
- arXiv ID: 2404.09579
- Source URL: https://arxiv.org/abs/2404.09579
- Reference count: 8
- Primary result: LLMs can serve as scientific models of external, social languages (E-languages), capturing group-level linguistic conventions and generalizing beyond training data

## Executive Summary
This paper presents a philosophical argument that large language models (LLMs) should be understood as scientific models of external, social languages (E-languages) rather than merely theories of cognitive linguistic competence. The author addresses key objections to this view, including concerns that LLMs only track performance data or replicate their training corpora. By distinguishing E-languages from internal (I-languages) and defending pluralism about language ontology, the paper argues that LLMs trained on vast linguistic data can capture linguistic conventions and features. The proposal includes using explainable AI (XAI) techniques and evaluation tasks to develop a "construal" that assigns parts of LLMs to represent aspects of E-languages, with iterative refinement.

## Method Summary
The paper employs a philosophical argumentation approach, analyzing the ontological status of language and the representational capabilities of LLMs. It draws on existing philosophical literature about language ontology, particularly the distinction between E-languages and I-languages, and applies this framework to contemporary LLM capabilities. The methodology includes defending against specific objections through theoretical analysis and proposing a practical framework for developing and validating LLM-based models of E-languages using XAI techniques and evaluation tasks.

## Key Results
- LLMs capture group-level linguistic conventions and can generalize beyond their training data
- XAI techniques and evaluation tasks can be used to develop a "construal" mapping LLM components to linguistic features
- LLMs can inform linguistic inquiry by modeling E-languages as social entities rather than just cognitive competence

## Why This Works (Mechanism)
The paper argues that LLMs work as models of E-languages because they are trained on vast amounts of linguistic data that inherently contains social conventions, patterns, and group-level features. Unlike models that only track individual performance, LLMs learn statistical regularities that reflect how language is actually used across communities. The mechanism relies on the emergent properties of neural networks trained on diverse linguistic data, which can capture not just surface patterns but deeper structural and conventional aspects of language use.

## Foundational Learning
- **E-language vs I-language distinction**: Needed to understand the ontological framework for treating LLMs as models of social language rather than cognitive competence; quick check: can you explain the key differences between these concepts in your own words?
- **Linguistic convention and social meaning**: Essential for grasping how LLMs capture group-level features; quick check: identify examples of linguistic conventions in different social contexts.
- **Explainable AI (XAI) techniques**: Required for the proposed methodology of mapping LLM components to linguistic features; quick check: name at least two XAI methods and their limitations.
- **Language pluralism**: Important for understanding the paper's defense of multiple valid ways to conceptualize language; quick check: can you articulate arguments for and against language pluralism?
- **Statistical learning in neural networks**: Fundamental to understanding how LLMs capture linguistic patterns; quick check: explain how statistical patterns relate to linguistic conventions.

## Architecture Onboarding
- **Component map**: Training data (vast linguistic corpora) -> Neural network architecture (Transformer-based) -> Learned representations -> Output predictions
- **Critical path**: Data ingestion and preprocessing -> Model training -> Feature extraction through XAI -> Construal development -> Validation through evaluation tasks
- **Design tradeoffs**: The paper acknowledges the tension between treating LLMs as black boxes versus developing interpretable models, opting for an iterative approach using XAI
- **Failure signatures**: LLMs may capture only surface patterns without genuine understanding of conventions; XAI interpretations may be unreliable or superficial
- **Three first experiments**: 1) Test LLM predictions against established linguistic corpora across multiple languages; 2) Apply XAI to specific components and evaluate interpretability; 3) Design controlled experiments testing social context understanding

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions beyond those inherent in the philosophical arguments presented. However, it implicitly raises questions about the reliability of XAI techniques for linguistic interpretation, the extent to which LLMs truly capture social conventions versus statistical patterns, and how to validate construals of LLM components as representations of linguistic features.

## Limitations
- The E-language vs I-language distinction remains philosophically contested and may not be universally accepted in linguistics
- XAI techniques currently have significant limitations in interpretability and may not provide sufficient precision for mapping to linguistic features
- The generalization capacity of LLMs beyond training data is poorly understood and may vary significantly across different domains and models

## Confidence
- **High**: LLMs capture statistical patterns in language data and can generalize beyond training examples
- **Medium**: LLMs can model group-level linguistic conventions, but this requires more empirical validation across diverse phenomena
- **Low**: The philosophical claim that LLMs constitute valid scientific models of E-languages depends on accepting specific ontological commitments about language

## Next Checks
1. Conduct systematic comparisons between LLM predictions and established linguistic corpora across multiple languages and dialects to quantify how well they capture genuine linguistic conventions versus surface patterns.
2. Apply current XAI techniques to specific LLM components and evaluate whether the resulting interpretations correspond to recognized linguistic features and structures in a way that would satisfy linguistic experts.
3. Design controlled experiments where LLMs are tested on linguistic phenomena that require understanding of social context and conventions, comparing their performance against human judgments of what constitutes appropriate linguistic behavior in those contexts.