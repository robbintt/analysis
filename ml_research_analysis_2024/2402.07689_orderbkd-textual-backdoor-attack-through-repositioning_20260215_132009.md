---
ver: rpa2
title: 'OrderBkd: Textual backdoor attack through repositioning'
arxiv_id: '2402.07689'
source_url: https://arxiv.org/abs/2402.07689
tags:
- attack
- attacks
- backdoor
- sentence
- trigger
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes OrderBkd, a backdoor attack that triggers model
  misbehavior by repositioning words in text, using part-of-speech rules to preserve
  semantics. Compared to existing methods that insert or generate content, OrderBkd
  maintains high attack success rates (up to 0.97 ASR) on SST-2 and AG datasets while
  significantly improving perplexity and semantic similarity to clean samples.
---

# OrderBkd: Textual backdoor attack through repositioning

## Quick Facts
- arXiv ID: 2402.07689
- Source URL: https://arxiv.org/abs/2402.07689
- Reference count: 34
- Attack success rate up to 0.97 ASR on SST-2 and AG datasets

## Executive Summary
OrderBkd introduces a novel textual backdoor attack that triggers model misbehavior by repositioning words within sentences rather than inserting or generating new content. The attack specifically targets adverbs and determiners as repositioning candidates, using part-of-speech rules to maintain semantic meaning while exploiting model sensitivity to word position. By minimizing perplexity through strategic word repositioning, OrderBkd achieves high attack success rates while preserving naturalness and semantic similarity to clean samples, making it more stealthy than traditional backdoor methods.

## Method Summary
The OrderBkd attack works by identifying adverbs or determiners in sentences and repositioning them to minimize perplexity while maintaining grammatical structure. The attack uses a POS tagger (spaCy-stanza) to identify candidate words, then computes perplexity using GPT-2 to find the optimal repositioning that preserves naturalness. The poisoned dataset is then used to train models with weighted loss combining clean and backdoor samples. The method achieves high attack success rates while maintaining semantic similarity and perplexity close to clean samples, and demonstrates robustness against the ONION defense method.

## Key Results
- Achieves attack success rate up to 0.97 on SST-2 and AG datasets
- Significantly improves perplexity and semantic similarity compared to existing methods
- Demonstrates robustness against ONION defense method
- Maintains clean accuracy while achieving high attack rates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The attack preserves semantic meaning while changing word order by targeting adverbs and determiners specifically.
- Mechanism: The attack identifies candidate words (adverbs or determiners) and repositions them to minimize perplexity while maintaining sentence structure, exploiting the fact that these parts of speech are less semantically critical than nouns or verbs.
- Core assumption: Certain POS categories (adverbs, determiners) can be moved without substantially altering meaning, while other POS categories cannot.
- Evidence anchors:
  - [abstract] "By designing and applying specific part-of-speech (POS) based rules for selecting these tokens, we maintain high attack success rate"
  - [section III-B] "we choose a strategy based on words, where an 'adverb' wadv is chosen as the category of a part of speech, since it has been proven that the permutation of just such a candidate preserves the original meaning of the text"
  - [corpus] Weak evidence - no direct corpus citation of POS-specific attacks
- Break condition: If the sentence lacks both adverbs and determiners, or if moving these words causes significant grammatical disruption that affects model interpretation.

### Mechanism 2
- Claim: The attack exploits model sensitivity to word position rather than word content, making it harder to detect than content-based attacks.
- Mechanism: By only changing word positions rather than inserting or generating new content, the attack maintains natural language patterns while still triggering the backdoor, leveraging the model's positional encoding sensitivity.
- Core assumption: Transformer-based models (BERT, XLNet, etc.) are sensitive to word position in ways that can be exploited without semantic changes.
- Evidence anchors:
  - [abstract] "Our main difference from the previous work is that we use the reposition of a two words in a sentence as a trigger"
  - [section IV-B] "the main difference of which from previous works is the idea to be based on the analysis of the features of words and best position in a sentence"
  - [corpus] Weak evidence - no direct corpus citation of position-based backdoor attacks
- Break condition: If the model's positional encoding mechanism neutralizes the effect of word repositioning, or if defenses specifically target positional anomalies.

### Mechanism 3
- Claim: The attack remains effective against ONION defense because it doesn't insert outlier tokens that ONION detects.
- Mechanism: Since OrderBkd only repositions existing words rather than inserting new ones, the resulting text doesn't contain the "outlier words" that ONION's perplexity-based detection targets.
- Core assumption: ONION's defense mechanism primarily detects inserted content based on perplexity anomalies, not positional changes.
- Evidence anchors:
  - [abstract] "We experimentally show the robustness of our attack to the ONION defense method"
  - [section IV] "we consider ONION [11], which detects and deletes trigger words as outlier words measured by the perplexity"
  - [corpus] No corpus evidence available
- Break condition: If ONION or similar defenses are enhanced to detect positional anomalies or if new defense mechanisms specifically target word reordering patterns.

## Foundational Learning

- Concept: Part-of-speech tagging and its role in NLP
  - Why needed here: The attack relies on identifying specific POS categories (adverbs, determiners) to select repositioning candidates
  - Quick check question: What POS tag would "quickly" receive in the sentence "He quickly ran to the store"?

- Concept: Perplexity as a measure of text naturalness
  - Why needed here: The attack uses perplexity minimization to find optimal repositioning that preserves naturalness
  - Quick check question: If a text has perplexity of 20, is it more or less natural than a text with perplexity of 200?

- Concept: Backdoor attacks in machine learning
  - Why needed here: Understanding the threat model and how triggers activate model misbehavior
  - Quick check question: What's the difference between a backdoor attack and a standard adversarial attack?

## Architecture Onboarding

- Component map:
  - POS tagger (spaCy-stanza) → Candidate selection → GPT-2 perplexity scorer → Model training pipeline → Evaluation metrics
  - Key components: poison_data.py (poisoning logic), train.py (model training), evaluate.py (metrics calculation)

- Critical path: Candidate word identification → Position optimization (perplexity minimization) → Dataset poisoning → Model training → Attack success evaluation

- Design tradeoffs:
  - Using adverbs vs. determiners: Adverbs preserve meaning better but are less frequent; determiners are more common but may cause more grammatical disruption
  - Perplexity-based optimization vs. semantic similarity: Sometimes minimizing perplexity conflicts with maintaining semantic similarity
  - Attack success rate vs. stealthiness: Higher attack rates may require more aggressive repositioning, reducing stealth

- Failure signatures:
  - Attack success rate drops below 0.7
  - Clean accuracy drops by more than 0.05
  - Perplexity increases by more than 200 points
  - Semantic similarity drops below 0.9

- First 3 experiments:
  1. Run baseline test: Apply OrderBkd to 100 SST-2 samples and measure perplexity increase vs. semantic similarity
  2. Defense testing: Apply ONION defense to OrderBkd-poisoned model and measure attack success rate degradation
  3. Ablation study: Compare adverb-only repositioning vs. determiner-only repositioning on both metrics and attack success

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective is the OrderBkd attack when applied to other NLP tasks beyond text classification, such as sentiment analysis, named entity recognition, or machine translation?
- Basis in paper: [inferred] The paper focuses solely on text classification tasks (SST-2 and AG's News) and does not explore the attack's effectiveness on other NLP tasks.
- Why unresolved: The paper does not provide any evidence or experiments to support the attack's effectiveness on other NLP tasks beyond text classification.
- What evidence would resolve it: Conducting experiments on various NLP tasks (e.g., sentiment analysis, named entity recognition, machine translation) and comparing the attack's performance across these tasks would provide evidence of its generalizability.

### Open Question 2
- Question: How does the OrderBkd attack perform against more advanced defense methods, such as those based on adversarial training or input sanitization techniques?
- Basis in paper: [explicit] The paper only evaluates the attack's robustness against the ONION defense method, which detects and deletes trigger words as outlier words measured by perplexity.
- Why unresolved: The paper does not explore the attack's effectiveness against other defense methods, such as adversarial training or input sanitization techniques, which could potentially mitigate the attack.
- What evidence would resolve it: Conducting experiments against various defense methods, including adversarial training and input sanitization techniques, and comparing the attack's success rates would provide evidence of its robustness against different defenses.

### Open Question 3
- Question: How does the choice of part-of-speech tags for repositioning affect the attack's success rate and stealthiness? Are there other POS tags that could potentially yield better results?
- Basis in paper: [explicit] The paper justifies the choice of adverbs and determiners for repositioning based on their impact on perplexity and USE similarity, but does not explore other POS tags.
- Why unresolved: The paper does not provide a comprehensive analysis of the impact of different POS tags on the attack's success rate and stealthiness.
- What evidence would resolve it: Conducting experiments with various POS tags (e.g., adjectives, nouns, verbs) and comparing the attack's performance in terms of success rate and stealthiness would provide evidence of the optimal POS tags for the attack.

## Limitations

- Experimental evaluation focuses primarily on ASR and PPL metrics without comprehensive human evaluation of semantic preservation
- Attack's effectiveness across diverse linguistic structures and domains remains untested
- Defense evaluation against ONION is limited to a single defense method, with unknown robustness against other defenses
- The assumption that ONION only detects inserted content (not repositioned words) is plausible but untested

## Confidence

**High Confidence**: The core claim that word repositioning can achieve high ASR (0.97 on SST-2) is well-supported by the experimental results. The methodology for selecting adverbs and determiners, combined with perplexity-based position optimization, is clearly described and produces measurable results.

**Medium Confidence**: The claim that OrderBkd maintains semantic similarity while achieving high attack success is supported by quantitative metrics (USE similarity scores) but lacks human validation. The trade-off between stealth (low PPL) and effectiveness is demonstrated statistically but not empirically verified across diverse sentence types.

**Low Confidence**: The robustness claim against ONION defense is based on a single experiment without exploring alternative defense mechanisms or adaptive attacks. The assumption that ONION only detects inserted content (not repositioned words) is plausible but untested against other defense strategies.

## Next Checks

1. **Human Evaluation of Semantic Preservation**: Conduct a blind human study where annotators rate semantic similarity between original and repositioned sentences. Compare human judgments with the automated USE similarity scores to validate whether the model's perception of semantic preservation aligns with human judgment.

2. **Cross-Domain Robustness Testing**: Apply OrderBkd to datasets from different domains (e.g., biomedical texts, legal documents, technical manuals) to test whether the attack generalizes beyond sentiment analysis and news classification. Measure ASR, PPL, and semantic similarity across these diverse domains.

3. **Defense Against Alternative Methods**: Test OrderBkd against a battery of defense methods including ONION variants, adversarial training, and input sanitization techniques. Specifically, evaluate whether defenses that target positional anomalies or grammatical consistency can detect and mitigate the attack.