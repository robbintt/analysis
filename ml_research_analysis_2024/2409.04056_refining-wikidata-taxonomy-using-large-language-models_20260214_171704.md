---
ver: rpa2
title: Refining Wikidata Taxonomy using Large Language Models
arxiv_id: '2409.04056'
source_url: https://arxiv.org/abs/2409.04056
tags:
- taxonomy
- classes
- wikidata
- entity
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces WiKC, a cleaned version of the Wikidata taxonomy
  generated by combining zero-shot prompting on an open-source LLM (Mixtral-8x7B-Instruct-v0.1)
  with graph mining techniques. The method addresses several known issues in Wikidata's
  taxonomy, including ambiguity between instances and classes, redundancy, inaccurate
  taxonomic paths, and complexity.
---

# Refining Wikidata Taxonomy using Large Language Models

## Quick Facts
- **arXiv ID:** 2409.04056
- **Source URL:** https://arxiv.org/abs/2409.04056
- **Reference count:** 28
- **Primary result:** WiKC achieves 70% entity typing accuracy vs 43% for original Wikidata

## Executive Summary
This paper introduces WiKC, a cleaned version of the Wikidata taxonomy created by applying zero-shot prompting on Mixtral-8x7B-Instruct-v0.1 combined with graph mining techniques. The refined taxonomy addresses multiple issues in Wikidata including ambiguity between instances and classes, redundancy, inaccurate taxonomic paths, and complexity. WiKC contains approximately 17k classes and 20k links, representing a significant reduction from the original 4M classes and 4.8M links. Intrinsic evaluation shows WiKC is more concise and simpler than the original taxonomy, while extrinsic evaluation demonstrates 70% accuracy on entity typing compared to 43% for the original.

## Method Summary
The authors extracted the Wikidata taxonomy and applied a series of refinement operations using zero-shot LLM classification and graph mining techniques. The process involved cutting irrelevant links, resolving reversed links, reducing transitive links, merging equivalent classes, rewiring links, and filtering non-informative and rare classes. The LLM (Mixtral-8x7B-Instruct-v0.1) was used for zero-shot classification tasks to identify and correct taxonomic issues. The resulting WiKC taxonomy contains approximately 17k classes and 20k links, compared to the original 4M classes and 4.8M links in Wikidata.

## Key Results
- WiKC taxonomy contains ~17k classes and ~20k links vs original 4M classes and 4.8M links
- Entity typing accuracy: 70% for WiKC vs 43% for original Wikidata taxonomy
- WiKC is more concise and simpler than original taxonomy based on intrinsic evaluation

## Why This Works (Mechanism)
The approach leverages the strong semantic understanding capabilities of large language models to classify and correct taxonomic relationships in knowledge graphs. By using zero-shot prompting, the method avoids the need for extensive labeled training data while still achieving high accuracy in identifying incorrect or redundant taxonomic links. The combination of LLM-based classification with graph mining techniques allows for systematic refinement of the taxonomy structure, addressing multiple types of errors simultaneously.

## Foundational Learning
1. **Zero-shot classification**: Using LLMs to classify data without task-specific training; needed for applying taxonomy refinement without labeled examples; quick check: test classification accuracy on held-out examples
2. **Graph mining techniques**: Algorithms for analyzing and modifying graph structures; needed for identifying and correcting taxonomic patterns; quick check: verify connectivity and hierarchy properties
3. **Taxonomy structure evaluation**: Metrics for assessing taxonomic quality like conciseness and simplicity; needed for measuring refinement effectiveness; quick check: compare path lengths and class counts

## Architecture Onboarding

### Component Map
Knowledge Graph Extraction -> LLM Classification -> Graph Mining Operations -> Refined Taxonomy

### Critical Path
The critical path is Knowledge Graph Extraction -> LLM Classification -> Graph Mining Operations, where the LLM classification step is the primary bottleneck due to API costs and latency, followed by the computational complexity of graph operations on the large initial taxonomy.

### Design Tradeoffs
- Single LLM vs ensemble approach: Using Mixtral-8x7B-Instruct-v0.1 provides consistency but may miss edge cases that other models could catch
- Aggressive pruning vs conservative refinement: Significant reduction from 4M to 17k classes improves conciseness but may lose useful distinctions
- Zero-shot vs few-shot prompting: Zero-shot avoids need for labeled data but may be less accurate than few-shot approaches

### Failure Signatures
- Over-pruning leading to loss of important taxonomic distinctions
- Incorrect classification of class-instance relationships by LLM
- Creation of disconnected components in the taxonomy
- Introduction of cyclic dependencies in the hierarchical structure

### First Experiments to Run
1. Apply the same refinement pipeline to a different knowledge graph (e.g., DBpedia) to test generalizability
2. Conduct ablation study removing each graph mining operation to assess individual contributions
3. Test entity typing accuracy on a separate test set to validate generalization beyond the evaluation set

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on single LLM (Mixtral-8x7B-Instruct-v0.1) raises questions about generalizability across different models
- Limited manual validation of only 100 taxonomic paths provides incomplete coverage of the 17k-class taxonomy
- Significant reduction from 4M to 17k classes may eliminate useful taxonomic distinctions for certain applications

## Confidence
- Taxonomy refinement methodology: High
- Entity typing performance improvements: High
- Intrinsic quality metrics: Medium
- Generalizability to other knowledge graphs: Low

## Next Checks
1. Test WiKC's performance across multiple NLP tasks beyond entity typing, including question answering and relation extraction
2. Conduct ablation studies to isolate the impact of each refinement operation on taxonomy quality
3. Evaluate robustness by applying the same methodology to other knowledge graphs and comparing results