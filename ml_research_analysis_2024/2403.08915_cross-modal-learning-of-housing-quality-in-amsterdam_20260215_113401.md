---
ver: rpa2
title: Cross-Modal Learning of Housing Quality in Amsterdam
arxiv_id: '2403.08915'
source_url: https://arxiv.org/abs/2403.08915
tags:
- images
- aerial
- flickr
- quality
- ground-level
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This research explores the use of cross-modal learning combining
  ground-level and aerial imagery to predict housing quality scores in Amsterdam.
  The study compares Google StreetView (GSV) and Flickr images as ground-level data
  sources, finding that GSV performs best, achieving a 30% improvement in Kendall's
  tau over aerial-only predictions.
---

# Cross-Modal Learning of Housing Quality in Amsterdam

## Quick Facts
- arXiv ID: 2403.08915
- Source URL: https://arxiv.org/abs/2403.08915
- Reference count: 17
- Primary result: GSV + aerial achieves 30% better Kendall's tau than aerial-only

## Executive Summary
This research explores the use of cross-modal learning combining ground-level and aerial imagery to predict housing quality scores in Amsterdam. The study compares Google StreetView (GSV) and Flickr images as ground-level data sources, finding that GSV performs best, achieving a 30% improvement in Kendall's tau over aerial-only predictions. However, through careful filtering and use of a pre-trained Place Pulse 2 model, Flickr images combined with aerial imagery can close half the performance gap to GSV. The results suggest that while GSV provides the most accurate predictions, filtered Flickr images offer a viable and more accessible alternative for urban quality assessment, especially given GSV's acquisition challenges. The study highlights the potential of using crowdsourced social media data for large-scale urban liveability monitoring.

## Method Summary
The study uses a multimodal CNN model with ResNet-50 architectures for both aerial and ground-level imagery. Aerial imagery is pre-trained on Dutch housing quality data, while ground-level imagery uses ImageNet or Place Pulse 2 pre-training. Features are merged via element-wise addition, followed by batch normalization and fully connected layers to predict housing quality scores. The model is trained on a 100m grid covering Amsterdam, with aerial patches (500x500 pixels) and ground-level images (GSV or filtered Flickr) centered on each grid cell. Training involves 25 epochs with the ground-level feature extractor frozen for the first 3 epochs, then fine-tuning the aerial branch while keeping the ground-level branch frozen.

## Key Results
- GSV + aerial achieves 30% improvement in Kendall's tau over aerial-only predictions
- Filtered Flickr + aerial closes half the performance gap to GSV (reducing from 30% to 15%)
- Pre-trained Place Pulse 2 features outperform ImageNet for ground-level imagery

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Combining aerial imagery with carefully filtered Flickr images improves housing quality prediction over using aerial imagery alone.
- Mechanism: Ground-level images provide fine-grained visual context (building conditions, façades, streetscape features) that aerial imagery cannot capture, and when merged with aerial features, they compensate for each other's limitations.
- Core assumption: The spatial co-location of ground-level images and aerial patches ensures relevant context for predicting housing quality scores.
- Evidence anchors:
  - [abstract] "Flickr image features combined with aerial image features are able to halve the performance gap to GSV features from 30% to 15%."
  - [section] "We do this to ensure that the model has the context needed to recreate the housing score, as the scores were created by using data from a 200m2 square meter radius from the cell center."
- Break condition: If Flickr images are poorly distributed spatially, especially in less-photographed areas like the north of Amsterdam, the performance gap cannot be closed.

### Mechanism 2
- Claim: Pre-training on Place Pulse 2 (PP2) rather than ImageNet yields better features for housing quality prediction.
- Mechanism: PP2 is a dataset for urban sentiment analysis using GSV images, so its features are tuned to capture perceptual and aesthetic urban attributes relevant to housing quality, unlike ImageNet which is general-purpose.
- Core assumption: Housing quality perception correlates with urban aesthetic and safety cues, which PP2 explicitly models.
- Evidence anchors:
  - [abstract] "by using the right pre-trained model, Flickr image features combined with aerial image features are able to halve the performance gap"
  - [section] "For ground-level features, we use a ResNet-50 pre-trained ImageNet model, as well as a pre-trained ResNet-50 Place Pulse 2 (PP2) model."
- Break condition: If housing quality is more about structural or statistical factors than visual/perceptual ones, ImageNet features might perform equally well.

### Mechanism 3
- Claim: Filtering Flickr images to focus on building-related scenes improves prediction accuracy.
- Mechanism: Social media images include many irrelevant scenes (parks, people, events); filtering to retain only building-centric images reduces noise and aligns the dataset with the prediction task.
- Core assumption: Only images with strong building content contribute useful features for housing quality prediction.
- Evidence anchors:
  - [section] "We apply a pre-trained Places365 model for scene classification... select images that have at least one scene strongly related to buildings above a given threshold"
  - [section] "Using either the Flickr Outdoors subset or only ImageNet pre-training results in a loss of performance"
- Break condition: If building quality is inferred from contextual cues (like street greenery or neighborhood activity), overly aggressive filtering might remove useful information.

## Foundational Learning

- Concept: Multimodal deep learning with feature fusion
  - Why needed here: The task requires integrating complementary information from aerial and ground-level imagery, which is naturally handled by multimodal architectures.
  - Quick check question: What is the role of the merge layer in the multimodal model, and why use element-wise addition rather than concatenation?

- Concept: Pre-trained convolutional neural networks (CNNs) for feature extraction
  - Why needed here: Directly training from scratch on limited labeled data would underfit; pre-trained models provide rich, generalizable features.
  - Quick check question: Why does the model freeze the ground-level feature extractor during training but fine-tune the aerial branch?

- Concept: Evaluation metrics for ordinal regression (Kendall's tau)
  - Why needed here: Housing quality scores are ordinal, so ranking accuracy is more informative than raw regression error.
  - Quick check question: How does Kendall's tau differ from Spearman's rank correlation, and why is it appropriate here?

## Architecture Onboarding

- Component map: Aerial ResNet-50 → 2048-dim feature vector; Ground-level ResNet-50 (pre-trained) → average-pooled 2048-dim vector; Element-wise addition merge → 2048-dim merged vector; BatchNorm → 100-dim FC → 1-dim output (housing score).
- Critical path: Image preprocessing → feature extraction (aerial + ground) → merge → FC layers → prediction.
- Design tradeoffs: Using pre-trained models avoids data-hungry training but may introduce domain mismatch; element-wise addition reduces parameter count versus concatenation but may lose some cross-modal interactions.
- Failure signatures: Poor spatial coverage in Flickr images leads to performance drop in underrepresented areas; mismatched feature scales cause training instability; overfitting on training tiles due to small dataset size.
- First 3 experiments:
  1. Train unimodal aerial-only model to establish baseline.
  2. Train unimodal GSV-only model to confirm ground-level benefit.
  3. Train multimodal model with GSV + aerial to check for synergy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific factors contribute to the 15% performance gap between GSV and filtered Flickr image features when predicting housing quality?
- Basis in paper: [explicit] The paper states that Flickr images combined with aerial imagery can close half the performance gap to GSV features from 30% to 15%.
- Why unresolved: While the paper identifies that filtering and using the right pre-trained model can improve Flickr performance, it does not specify which factors (e.g., image quality, orientation, or content) most significantly impact the remaining 15% gap.
- What evidence would resolve it: Conducting a detailed analysis comparing the characteristics of GSV and filtered Flickr images (e.g., image resolution, building coverage, lighting conditions) and their correlation with prediction accuracy would clarify the remaining performance gap.

### Open Question 2
- Question: How does the performance of housing quality prediction models generalize to cities with different urban layouts or socioeconomic conditions compared to Amsterdam?
- Basis in paper: [inferred] The study focuses exclusively on Amsterdam, but urban environments vary widely in terms of architecture, density, and socioeconomic factors.
- Why unresolved: The paper does not test the model on other cities, so its generalizability to diverse urban contexts remains unknown.
- What evidence would resolve it: Applying the same model and methodology to housing quality datasets from multiple cities with varying characteristics (e.g., New York, Tokyo, or smaller towns) and comparing performance metrics would address this question.

### Open Question 3
- Question: What is the impact of temporal changes in Flickr images (e.g., seasonal variations or urban development) on the accuracy of housing quality predictions?
- Basis in paper: [inferred] The paper uses Flickr images taken between 2004 and 2020 but does not analyze how temporal variations affect model performance.
- Why unresolved: The study does not account for the potential influence of time-based changes in the urban environment on prediction accuracy.
- What evidence would resolve it: Analyzing model performance using Flickr images from specific time periods (e.g., before and after urban development projects) or across different seasons would clarify the impact of temporal changes.

## Limitations
- The study's findings are limited by the uneven spatial distribution of Flickr images, with better coverage in central Amsterdam than outlying areas.
- The 15% performance gap between GSV and filtered Flickr images remains substantial and may be critical for practical applications.
- The assertion that Place Pulse 2 pre-training is superior to ImageNet may be dataset-specific and not generalizable to other urban quality prediction tasks.

## Confidence
- High confidence: The finding that GSV outperforms aerial-only predictions (30% improvement in Kendall's tau) is well-supported by the experimental results and multiple validation runs.
- Medium confidence: The claim that filtered Flickr images can close half the performance gap is supported but depends heavily on the quality of the filtering process and spatial coverage.
- Low confidence: The assertion that Place Pulse 2 pre-training is superior to ImageNet for this task, while supported by results, may be dataset-specific and not generalizable to other urban quality prediction tasks.

## Next Checks
1. Test the multimodal model on cities with different Flickr usage patterns to assess generalizability beyond Amsterdam.
2. Conduct ablation studies with varying Flickr filtering thresholds to determine optimal balance between coverage and relevance.
3. Compare Place Pulse 2 versus ImageNet performance on a held-out test set with known ground truth to validate the pre-training advantage.