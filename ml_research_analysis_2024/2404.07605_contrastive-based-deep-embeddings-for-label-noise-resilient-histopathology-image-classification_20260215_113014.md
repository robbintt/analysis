---
ver: rpa2
title: Contrastive-Based Deep Embeddings for Label Noise-Resilient Histopathology
  Image Classification
arxiv_id: '2404.07605'
source_url: https://arxiv.org/abs/2404.07605
tags:
- learning
- noise
- label
- image
- deep
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of label noise in histopathology
  image classification, which arises from errors or inaccuracies in annotations and
  can severely degrade the performance of deep learning models. The authors propose
  a method based on contrastive learning to improve robustness to label noise.
---

# Contrastive-Based Deep Embeddings for Label Noise-Resilient Histopathology Image Classification

## Quick Facts
- arXiv ID: 2404.07605
- Source URL: https://arxiv.org/abs/2404.07605
- Reference count: 20
- Primary result: Contrastive embeddings from histopathology-specific foundation models significantly improve label noise resilience compared to non-contrastive embeddings and standard noise-resilient methods.

## Executive Summary
This paper addresses the challenge of label noise in histopathology image classification by leveraging contrastive learning. The authors propose extracting embeddings from foundation models trained in a self-supervised contrastive manner and training a linear classifier on these embeddings. This approach demonstrates superior label noise resilience compared to training on original images using state-of-the-art methods. The method is evaluated on six public benchmark histopathology datasets under various uniform and asymmetric label noise scenarios, consistently outperforming non-contrastive embeddings and commonly used noise-resilient methods.

## Method Summary
The proposed method extracts embeddings from pre-trained foundation models using contrastive learning, then trains a simple linear classifier head on these embeddings. The key innovation is using frozen embeddings from histopathology-specific models, which preserves the robust structure learned through contrastive pretraining. This approach avoids fine-tuning the backbone, reducing overfitting to noisy labels while leveraging the discriminative power of contrastive representations.

## Key Results
- Contrastive embeddings consistently outperform non-contrastive embeddings under both uniform and asymmetric label noise across all six benchmark datasets
- Histopathology-specific contrastive models (RetCCL, CTransPath, PathoDuet) show superior performance compared to general-purpose models (Lunit-BT, Phikon, Lunit-DINO)
- The method achieves up to 20% higher accuracy than commonly used noise-resilient methods under high noise rates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contrastive embeddings preserve clean label signal better than non-contrastive embeddings when labels are noisy.
- Mechanism: Contrastive learning creates a latent space where semantically similar samples are pulled together and dissimilar ones are pushed apart. This structure amplifies the gap between clean and noisy labels, allowing a linear classifier to separate them more easily.
- Core assumption: The contrastive backbone learns representations where clean labels align with dominant singular vectors, while noisy labels scatter away from them.
- Evidence anchors:
  - [abstract] "Through thorough empirical analyses across multiple datasets, we exhibit the label noise resilience property of embeddings extracted from foundation models trained in a self-supervised contrastive manner."
  - [section 2.2] "Xue et al. (2022) demonstrated that contrastive learning yields a representation matrix characterized by a significant gap between the prominent singular values and the remaining ones, along with a considerable alignment between the prominent singular vectors and the accurate labels."
- Break condition: If the dataset is too small or highly imbalanced, the singular vector alignment may collapse, reducing noise resilience.

### Mechanism 2
- Claim: Using frozen embeddings with a simple linear head reduces overfitting to label noise compared to end-to-end fine-tuning.
- Mechanism: The embedding extraction is fixed, so only the classifier parameters are trained. This limits the model's capacity to memorize noisy labels and forces it to rely on the robust structure of the embedding space.
- Core assumption: The contrastive backbone's embeddings are already discriminative enough for the classification task, so no further adaptation is needed.
- Evidence anchors:
  - [abstract] "We demonstrate that training with such embeddings substantially enhances label noise robustness when compared to non-contrastive-based ones as well as commonly used noise-resilient methods."
  - [section 3.2] "The main advantage of this training approach is that it allows to use the same pre-trained feature extractor g for multiple datasets, and only train a separate classifier hi for each dataset i = 1, ..., M."
- Break condition: If the embeddings are not well-aligned with the target dataset, the linear classifier will underperform regardless of label noise resilience.

### Mechanism 3
- Claim: Contrastive embeddings from histopathology-specific models perform better than those from general-purpose models under label noise.
- Mechanism: Domain-specific pretraining captures histology-specific visual patterns that align better with clean labels, making the contrastive structure more discriminative in the target domain.
- Core assumption: Histopathology data has unique visual characteristics (tissue textures, cell morphologies) that ImageNet models may not capture well.
- Evidence anchors:
  - [abstract] "We demonstrate that training with such embeddings substantially enhances label noise robustness when compared to non-contrastive-based ones as well as commonly used noise-resilient methods."
  - [section 4.2] "Across all datasets, the accuracies of Phikon and Lunit-DINO (non-contrastive) consistently exhibit sharper declines compared to others."
- Break condition: If the domain gap is small or the dataset is very large, general-purpose models may perform comparably.

## Foundational Learning

- Concept: Singular value decomposition of representation matrices.
  - Why needed here: Understanding how contrastive learning shapes the spectrum of learned representations explains why clean labels align with top singular vectors.
  - Quick check question: If you compute SVD on a contrastive embedding matrix, where would you expect the clean-label-aligned singular vectors to appear in the spectrum?

- Concept: Transfer learning with frozen backbones.
  - Why needed here: The method relies on using pre-trained embeddings without fine-tuning, so understanding the limits and benefits of this approach is critical.
  - Quick check question: What is the main risk of freezing a backbone that was not pre-trained on your target domain?

- Concept: Noise types in classification (uniform vs asymmetric).
  - Why needed here: The experiments explicitly compare these two noise models, so distinguishing them is necessary to interpret results.
  - Quick check question: In asymmetric noise, why might certain classes be more prone to confusion than others?

## Architecture Onboarding

- Component map: Image → Backbone (frozen contrastive model) → Embedding (768 or 2048 dims) → Classifier (4-layer MLP) → Loss (cross-entropy) → Update classifier only
- Critical path: Image → Backbone → Embedding → Classifier → Loss → Update classifier only
- Design tradeoffs:
  - Frozen backbone limits overfitting but may hurt performance if embeddings are suboptimal
  - Linear classifier is fast and noise-resilient but may underfit complex decision boundaries
  - Contrastive pretraining is expensive upfront but reusable across datasets
- Failure signatures:
  - Sharp accuracy drop with increasing noise rate → backbone not noise-resilient enough
  - Consistent underperformance vs end-to-end training → embeddings not discriminative enough
  - High variance across runs → unstable embedding extraction or small dataset
- First 3 experiments:
  1. Verify embedding extraction pipeline works: extract embeddings from a small validation set and visualize with t-SNE
  2. Compare frozen backbone vs fine-tuned backbone under no noise to confirm embeddings are usable
  3. Test linear classifier accuracy on clean labels only to establish baseline before introducing noise

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do contrastive learning methods show superior label noise resilience compared to non-contrastive methods, and what specific mechanisms in contrastive learning contribute to this resilience?
- Basis in paper: [explicit] The paper notes that contrastive-based backbones trained in a self-supervised manner exhibit enhanced robustness to label noise, but the reasons behind this enhancement are not fully understood.
- Why unresolved: The paper mentions that only one study (Xue et al., 2022) has explored the theoretical understanding of this phenomenon, suggesting that the field lacks comprehensive research on the underlying mechanisms.
- What evidence would resolve it: Detailed theoretical analysis and empirical studies that specifically investigate the internal representations and learning dynamics of contrastive models under various noise conditions would provide clarity.

### Open Question 2
- Question: How do the proposed methods perform on real-world datasets with inherent label noise compared to synthetic noise scenarios?
- Basis in paper: [inferred] The paper acknowledges that synthetic label noise was used in experiments and suggests that a validation study using real-world noisy datasets could provide insights into the effectiveness of contrastive embeddings in handling label noise.
- Why unresolved: Real-world datasets often contain more complex and varied noise patterns than synthetic noise, which may affect the performance of the proposed methods differently.
- What evidence would resolve it: Comparative studies using real-world datasets with known noise characteristics would demonstrate the practical applicability and robustness of the methods in real scenarios.

### Open Question 3
- Question: Can combining contrastive embeddings with other noise resilience techniques, such as label cleaning or robust loss functions, further improve performance?
- Basis in paper: [explicit] The paper suggests exploring the combination of contrastive embeddings with other noise resilience methods as a potential avenue for future research.
- Why unresolved: The paper does not investigate the potential synergies or interactions between contrastive learning and other noise resilience techniques, leaving this area unexplored.
- What evidence would resolve it: Experimental studies that systematically evaluate the combined effects of contrastive embeddings with other noise resilience techniques would provide insights into their potential benefits and limitations.

## Limitations
- The frozen backbone approach may limit the model's ability to learn dataset-specific nuances, especially for extremely large histopathology datasets
- The assumption that histopathology-specific contrastive models always outperform general-purpose models lacks strong empirical support in the literature
- Reliance on synthetic uniform and asymmetric noise models may not fully capture the complexity of real-world label noise in histopathology annotations

## Confidence

**Confidence labels:**
- High confidence in the claim that contrastive embeddings improve label noise resilience compared to non-contrastive embeddings, supported by consistent empirical results across multiple datasets
- Medium confidence in the mechanism that frozen backbones reduce overfitting to label noise, as this is a well-established transfer learning principle but not explicitly validated for histopathology under noise
- Low confidence in the claim that histopathology-specific contrastive models outperform general-purpose models under label noise, due to lack of direct comparative evidence in the corpus

## Next Checks

1. Test the method on a large-scale histopathology dataset (e.g., TCGA) to assess scalability and generalization
2. Compare histopathology-specific and general-purpose contrastive embeddings under varying noise rates to validate the domain-specific advantage
3. Evaluate the method under realistic label noise scenarios (e.g., crowd-sourced annotations) to ensure practical applicability