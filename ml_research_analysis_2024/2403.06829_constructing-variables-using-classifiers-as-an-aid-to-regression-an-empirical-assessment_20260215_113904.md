---
ver: rpa2
title: 'Constructing Variables Using Classifiers as an Aid to Regression: An Empirical
  Assessment'
arxiv_id: '2403.06829'
source_url: https://arxiv.org/abs/2403.06829
tags:
- regression
- variables
- vector
- proposed
- used
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to automatically create additional
  explanatory variables to complement the initial input vector in regression problems.
  The method discretizes the target variable into intervals, trains classifiers to
  predict whether the target value is below each threshold, and concatenates the classifier
  outputs as an additional vector.
---

# Constructing Variables Using Classifiers as an Aid to Regression: An Empirical Assessment

## Quick Facts
- arXiv ID: 2403.06829
- Source URL: https://arxiv.org/abs/2403.06829
- Authors: Colin Troisemaine; Vincent Lemaire
- Reference count: 23
- Primary result: Method improves RMSE performance for regression models by augmenting features with classifier outputs

## Executive Summary
This paper proposes a method to automatically create additional explanatory variables to complement the initial input vector in regression problems. The method discretizes the target variable into intervals, trains classifiers to predict whether the target value is below each threshold, and concatenates the classifier outputs as an additional vector. This augmented vector is then used as input to standard regressors. Experiments on 33 regression datasets using 5 different regressors show that the proposed method improves RMSE performance, especially for linear regression, decision trees, and selective Naïve Bayes.

## Method Summary
The proposed method works by transforming a regression problem into multiple binary classification problems. The target variable is discretized into intervals, and for each threshold, a classifier is trained to predict whether the target value falls below that threshold. The conditional probabilities from these classifiers are concatenated with the original features to form an augmented input vector. This augmented vector is then used as input to standard regression models. The method aims to capture richer information about the target variable's distribution by leveraging classification algorithms that can model non-linear relationships.

## Key Results
- The proposed method improves RMSE performance across 33 regression datasets
- Linear regression, decision trees, and selective Naïve Bayes show the most significant improvements
- Performance gains are most pronounced at the beginning and plateau after a certain number of thresholds
- The method is particularly effective when simpler models with limited capacity to capture complex relationships are used

## Why This Works (Mechanism)

### Mechanism 1
Transforming a regression problem into multiple binary classification problems allows the model to capture richer information about the target variable's distribution. By discretizing the continuous target variable into intervals and training classifiers to predict whether values fall below each threshold, the method generates a set of conditional probability estimates that form an augmented feature vector. The conditional probabilities predicted by classifiers contain additional predictive information that can improve regression performance.

### Mechanism 2
The method is particularly beneficial for simpler regression models that cannot capture complex non-linear relationships in the original feature space. By augmenting the feature space with classifier outputs, linear models and simpler algorithms gain access to non-linear representations of the target variable's distribution without changing their fundamental structure. Simpler models have limited capacity to model complex relationships in the original feature space but can benefit from additional engineered features.

### Mechanism 3
The number of discretization thresholds is a critical hyperparameter that balances the trade-off between information richness and classification difficulty. Increasing the number of thresholds provides more granular information about the target variable's distribution but also increases the difficulty of the classification subproblems. There exists an optimal number of thresholds that maximizes the benefit of the augmentation without overwhelming the classifiers.

## Foundational Learning

- Concept: Discretization of continuous variables
  - Why needed here: The method requires converting the continuous target variable into discrete intervals to enable classification
  - Quick check question: What are the differences between equal-width and equal-frequency discretization methods, and when would each be appropriate?

- Concept: Binary classification and conditional probability estimation
  - Why needed here: Each threshold requires a binary classifier that estimates P(y ≤ threshold | X)
  - Quick check question: How do different classifiers (e.g., Random Forest vs. Logistic Regression) estimate conditional probabilities differently?

- Concept: Feature engineering and augmentation
  - Why needed here: The classifier outputs serve as new features that augment the original feature space
  - Quick check question: What are the potential risks of feature augmentation, such as multicollinearity or overfitting?

## Architecture Onboarding

- Component map: Discretization module -> Multiple binary classifiers -> Feature concatenation layer -> Regression model
- Critical path: Discretize target → train binary classifiers → generate conditional probability features → concatenate with original features → train regressor
- Design tradeoffs: More thresholds provide richer information but increase computational cost and classification difficulty; simpler classifiers are faster but may reduce accuracy
- Failure signatures: Poor performance improvement indicates conditional probabilities lack additional predictive information, poor discretization choice, or ineffective use of augmented features by the regression model
- First 3 experiments:
  1. Implement basic pipeline with single regression dataset and 4-8 thresholds, using Random Forest classifiers and linear regression
  2. Compare performance with and without augmentation across different numbers of thresholds (2, 4, 8, 16, 32)
  3. Test different regression models (linear, decision tree, random forest) to identify which benefit most from augmentation

## Open Questions the Paper Calls Out

- Question: How does the performance of the proposed method vary with different discretization techniques (e.g., EqualWidth, clustering-based) compared to EqualFreq?
  - Basis: The paper uses EqualFreq for discretization and mentions that different methods exist, but does not compare their impact on performance
  - Why unresolved: The paper does not provide experimental results comparing EqualFreq with other discretization methods
  - What evidence would resolve it: Experimental results showing RMSE performance using different discretization methods across the same datasets

- Question: What is the impact of using different classifiers (e.g., SVM, neural networks) instead of Random Forests for generating the additional variables?
  - Basis: The paper uses Random Forests but mentions that any powerful and robust classifier could be used, without exploring alternatives
  - Why unresolved: Only Random Forests were tested; other classifiers were not evaluated
  - What evidence would resolve it: Comparative experiments using various classifiers (SVM, neural networks, etc.) with the proposed method across the datasets

## Limitations

- The method's effectiveness varies with dataset size and complexity, showing poor performance on datasets with very small or very large number of individuals
- The optimal number of thresholds is not predetermined and requires tuning, as performance gain plateaus after a certain point
- The computational overhead of training multiple classifiers and the potential for overfitting with too many thresholds are concerns

## Confidence

- **High confidence**: The experimental methodology is sound and the observed RMSE improvements are statistically significant across multiple datasets and regressors
- **Medium confidence**: The claim that simpler models benefit most from augmentation is supported by results but lacks theoretical explanation for why this occurs
- **Low confidence**: The mechanism explanation for how conditional probability features improve regression performance is primarily intuitive rather than rigorously justified

## Next Checks

1. **Ablation study on classifier types**: Test whether the choice of classifier (Random Forest, SVM, Neural Network) significantly impacts the augmentation benefit to isolate whether the improvement comes from the classifier architecture or the conditional probability concept itself

2. **Threshold sensitivity analysis**: Systematically vary the number of thresholds (2, 4, 8, 16, 32, 64) across all datasets to precisely map the relationship between threshold count and performance gain, identifying the optimal point where benefits plateau

3. **Feature importance analysis**: Use SHAP values or similar methods to quantify how much each augmented feature contributes to predictions, helping validate whether the classifier outputs are indeed capturing meaningful distributional information beyond the original features