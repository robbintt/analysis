---
ver: rpa2
title: Towards Training A Chinese Large Language Model for Anesthesiology
arxiv_id: '2403.02742'
source_url: https://arxiv.org/abs/2403.02742
tags:
- data
- medical
- arxiv
- anesthesia
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Hypnos, a Chinese large language model fine-tuned
  for anesthesiology. The authors address the challenge of limited high-quality medical
  data by introducing a cross-filtering strategy to filter noisy generated data from
  existing LLMs.
---

# Towards Training A Chinese Large Language Model for Anesthesiology

## Quick Facts
- **arXiv ID**: 2403.02742
- **Source URL**: https://arxiv.org/abs/2403.02742
- **Reference count**: 40
- **Key outcome**: Hypnos, a Chinese LLM fine-tuned for anesthesiology, outperforms other medical LLMs on anesthesiology tasks using a cross-filtering strategy and general-to-specific training.

## Executive Summary
This paper introduces Hypnos, a Chinese large language model fine-tuned for anesthesiology. The authors address the challenge of limited high-quality medical data by introducing a cross-filtering strategy to filter noisy generated data from existing LLMs. Hypnos also employs a general-to-specific training strategy, first fine-tuning on general medical data and then on anesthesiology-specific data. The model is evaluated on a newly introduced benchmark consisting of multiple-choice questions, basic knowledge Q&A, and real cases. Hypnos outperforms other medical LLMs in anesthesiology on various metrics, GPT-4 evaluation, and human evaluation.

## Method Summary
The authors collect 8 million general medical Q&A pairs and 24K anesthesiology Q&A pairs, then generate additional anesthesiology data using GPT-3.5-turbo and Claude with cross-filtering for quality control. They extend Llama's vocabulary for Chinese medical terms and use LORA for efficient general medical fine-tuning, followed by full fine-tuning on anesthesiology data. The model is evaluated on a custom benchmark with automated metrics and human/GPT-4 judgments.

## Key Results
- Hypnos achieves the highest scores on the AneQA benchmark across BLEU, ROUGE, GLEU, and Distinct metrics
- Hypnos outperforms other medical LLMs on the AneCQ multiple-choice question benchmark
- Human and GPT-4 evaluations show Hypnos is more useful, less harmful, and less redundant than baseline models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-filtering with multiple LLMs improves data quality by reducing noise in generated medical content.
- Mechanism: The authors generate medical Q&A pairs using two different LLMs (GPT-3.5-turbo and Claude), then use one to score the output of the other. Low-scoring examples are filtered out, resulting in a cleaner training dataset.
- Core assumption: One LLM can reliably evaluate the correctness or quality of another LLM's generated content.
- Evidence anchors:
  - [abstract] "Hypnos implements a cross-filtering strategy to improve the data quality. This strategy involves using one LLM to assess the quality of the generated data from another LLM and filtering out the data with low quality."
  - [section] "The generated data still contains noises. Therefore, we designed another type of prompt to enable LLMs to have the ability to evaluate the quality or the correctness of the generated data... Since the data generated from one LLM is generally considered high-quality by itself, we require one LLM to score the quality of data generated by another LLM."
  - [corpus] Weak evidence—no direct citations, but the neighbor query shows related papers on Chinese medical LLMs using filtering or quality control strategies.
- Break condition: If the evaluation LLM is biased or unable to judge domain-specific correctness, the filtering will fail.

### Mechanism 2
- Claim: General-to-specific training strategy allows the model to first learn broad medical knowledge and then specialize in anesthesiology without losing domain specificity.
- Mechanism: First fine-tune on 8 million general medical Q&A pairs, then refine on 217k anesthesiology-specific data. This avoids the domain-specific knowledge being overwhelmed by the general data.
- Core assumption: General medical knowledge is complementary and beneficial for understanding specialized medical subdomains like anesthesiology.
- Evidence anchors:
  - [abstract] "Hypnos employs a general-to-specific training strategy that starts by fine-tuning LLMs using the general medicine data and subsequently improving the fine-tuned LLMs using data specifically from Anesthesiology."
  - [section] "Knowledge of general medicine may benefit the understanding of Anesthesiology... Therefore, Hypnos adopts a general-to-specific training strategy that first tunes LLMs using data from the general medical domain and then refines the tuned LLM using the data from Anesthesiology."
  - [corpus] Weak—no direct neighbor citations, but common practice in domain adaptation literature.
- Break condition: If general medical data is too dissimilar from anesthesiology, the fine-tuning may confuse rather than help the model.

### Mechanism 3
- Claim: Chinese vocabulary extension improves token representation and model performance on Chinese medical text.
- Mechanism: Additional Chinese tokens are added to the base Llama vocabulary using SentencePiece BPE. New tokens are initialized by fusing UTF-8 character embeddings weighted by character order.
- Core assumption: Expanding the vocabulary with domain-relevant tokens improves encoding of medical terms and concepts.
- Evidence anchors:
  - [section] "To enhance the efficiency of Chinese encoding, we extend the original vocabulary of Llama by adding more Chinese vocabulary... Each Chinese word can be represented by three UTF-8 characters... The initialized embedding is obtained by fusing the vectors of the UTF-8 characters..."
  - [corpus] No direct citations in corpus, but related neighbor papers show common practice in Chinese LLMs.
- Break condition: If the new tokens are not properly initialized or the vocabulary size is too large, model performance may degrade.

## Foundational Learning

- Concept: Cross-filtering strategy for data quality
  - Why needed here: Medical data is sensitive; noisy or incorrect data can lead to harmful outputs in clinical contexts.
  - Quick check question: Why is it better to use two different LLMs for cross-filtering instead of one?

- Concept: Fine-tuning vs. full fine-tuning
  - Why needed here: LORA allows efficient adaptation of large models by training low-rank adapters instead of all parameters, saving memory and time.
  - Quick check question: What is the trade-off between parameter efficiency and final model performance in LORA?

- Concept: BLEU, ROUGE, GLEU, Distinct metrics
  - Why needed here: Different metrics evaluate different aspects of generated text—similarity to reference, fluency, and diversity.
  - Quick check question: Which metric would you prioritize if you care most about factual correctness in medical Q&A?

## Architecture Onboarding

- Component map: Data collection → Cross-filtering → Vocabulary extension → General fine-tuning (LORA) → Specific fine-tuning (full) → Evaluation
- Critical path: Data → Cross-filtering → Training pipeline (LORA + full) → Benchmark evaluation
- Design tradeoffs: Cross-filtering adds evaluation cost but improves data quality; LORA saves compute but may limit final performance; Chinese vocab expansion increases tokenization quality but model size.
- Failure signatures: Low Distinct scores suggest overfitting; high BLEU but low ROUGE may indicate fluency without correctness; GPT-4 evaluation variance may signal positional bias.
- First 3 experiments:
  1. Run cross-filtering on a small subset and manually inspect quality before full scale.
  2. Compare LORA vs full fine-tuning on a dev set for general → specific transfer.
  3. Evaluate the effect of Chinese vocab expansion by comparing tokenization coverage before and after.

## Open Questions the Paper Calls Out

- **Open Question 1**: How can the cross-filtering strategy be improved to reduce bias in data quality evaluation?
  - Basis in paper: [explicit] The paper mentions that the scores obtained from an LLM may still contain bias and suggests obtaining a more comprehensive judgment from multiple LLMs as a future work.
  - Why unresolved: The current cross-filtering strategy relies on individual LLMs to evaluate data quality, which may introduce bias and inaccuracies.
  - What evidence would resolve it: A comprehensive study comparing different cross-filtering strategies, including those using multiple LLMs, to determine the most effective method for reducing bias and improving data quality evaluation.

- **Open Question 2**: How does the general-to-specific training strategy impact the model's performance on other medical domains beyond anesthesiology?
  - Basis in paper: [explicit] The paper introduces a general-to-specific training strategy that first tunes LLMs using general medicine data and then refines them using anesthesiology-specific data.
  - Why unresolved: The paper focuses on the impact of this strategy on anesthesiology performance but does not explore its effectiveness on other medical domains.
  - What evidence would resolve it: Comparative studies evaluating the performance of models trained with the general-to-specific strategy on various medical domains to determine its broader applicability and effectiveness.

- **Open Question 3**: What are the long-term effects of using model-generated data on the accuracy and reliability of the LLM?
  - Basis in paper: [explicit] The paper discusses the use of model-generated data to supplement the limited real-world data in anesthesiology but does not address the potential long-term effects on the model's performance.
  - Why unresolved: The impact of relying heavily on model-generated data over time is not explored, including potential issues such as data drift or the propagation of errors.
  - What evidence would resolve it: Longitudinal studies tracking the performance of LLMs trained with model-generated data over extended periods to identify any degradation in accuracy or reliability and to develop strategies for mitigating these issues.

## Limitations

- The paper lacks transparency in key methodological details, including exact prompt templates for data generation and quality scoring.
- The human evaluation methodology is described only at a high level, without details on evaluator expertise or procedures.
- The GPT-4 evaluation approach lacks details on prompt engineering and handling of subjective judgments.

## Confidence

- **High confidence**: General-to-specific training strategy's effectiveness
- **Medium confidence**: Cross-filtering strategy's impact on data quality
- **Low confidence**: Chinese vocabulary extension's contribution

## Next Checks

1. Reproduce the cross-filtering pipeline on a small dataset: Implement the cross-filtering process with the described LLM scoring mechanism on a subset of data (e.g., 100 examples) and manually evaluate whether the filtered output shows meaningful quality improvement compared to unfiltered generation.

2. Ablation study on training strategy: Train three versions of the model—one with only general medical data, one with only anesthesiology data, and one with the general-to-specific approach—then compare performance on both general medical and anesthesiology-specific benchmarks to isolate the contribution of each phase.

3. Chinese vocabulary impact analysis: Compare tokenization coverage and model performance on Chinese medical terms before and after vocabulary extension by measuring out-of-vocabulary rates on a medical terminology dataset and evaluating downstream task performance with and without the extended vocabulary.