---
ver: rpa2
title: Word Importance Explains How Prompts Affect Language Model Outputs
arxiv_id: '2403.03028'
source_url: https://arxiv.org/abs/2403.03028
tags:
- word
- importance
- suffix
- prompt
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces a method to improve explainability of large
  language models (LLMs) by systematically masking individual words in system prompts
  and measuring their impact on model outputs using various text scores. Inspired
  by permutation importance for tabular data, the approach evaluates how masking each
  word affects metrics like readability, verbosity, and topic relevance.
---

# Word Importance Explains How Prompts Affect Language Model Outputs

## Quick Facts
- arXiv ID: 2403.03028
- Source URL: https://arxiv.org/abs/2403.03028
- Reference count: 24
- Primary result: Word importance scores positively correlate with the impact of added suffixes on LLM outputs, demonstrating effectiveness in identifying influential prompt words.

## Executive Summary
This study introduces a method to improve explainability of large language models by systematically masking individual words in system prompts and measuring their impact on model outputs. Inspired by permutation importance for tabular data, the approach evaluates how masking each word affects metrics like readability, verbosity, and topic relevance. Experiments with GPT-3.5 Turbo and Llama2-13B show that word importance scores correlate with the impact of added suffixes on model outputs, demonstrating the method's effectiveness in identifying influential prompt words. This provides a practical tool for understanding and optimizing LLM behavior, enhancing transparency and accountability in their applications.

## Method Summary
The method measures word importance by sequentially masking each word in a system prompt with an underscore, generating outputs with both masked and non-masked prompts, and calculating the average absolute difference in text scores between these outputs. Text scores include readability (Flesch reading-ease), verbosity (word count), and topic similarity (cosine similarity of text embeddings). The process is repeated for multiple user inputs and outputs to compute reliable importance scores for each word in the prompt.

## Key Results
- Word importance scores calculated by masking individual prompt words show positive correlation with the impact of added suffixes on model outputs
- The method works across different scoring functions (readability, verbosity, topic similarity) and model architectures (GPT-3.5 Turbo, Llama2-13B)
- Results demonstrate that word importance can decompose the impact of prompts into specific measures of interest including bias, reading level, and verbosity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Masking individual words in a prompt and observing changes in model output allows identification of influential words.
- Mechanism: By systematically replacing each word in a system prompt with an underscore and comparing the resulting outputs to the original using various text scores, the relative importance of each word can be quantified. This is inspired by permutation importance in tabular data analysis.
- Core assumption: The change in output scores when a word is masked directly reflects that word's influence on the model's behavior for the given task.
- Evidence anchors:
  - [abstract] "Unlike classical attention, word importance measures the impact of prompt words on arbitrarily-defined text scores, which enables decomposing the importance of words into the specific measures of interest–including bias, reading level, verbosity, etc."
  - [section] "The importance score for every word from the prompt with regard to the selected text score is computed by comparing these results with the results from using the original system prompt."
- Break condition: If the model's output is highly sensitive to small prompt variations beyond the masked word, or if the scoring functions do not reliably capture the desired aspects of output behavior.

### Mechanism 2
- Claim: Word importance scores correlate with the impact of added suffixes on model outputs.
- Mechanism: When suffixes are added to system prompts, words within those suffixes that have high importance scores should correspond to the overall impact of the suffix on the output. This is tested by comparing the maximum word importance within a suffix to the total impact of the suffix.
- Core assumption: The presence of a highly important word within a suffix indicates that the suffix will have a significant impact on the output.
- Evidence anchors:
  - [abstract] "Experiments with GPT-3.5 Turbo and Llama2-13B show that word importance scores positively correlate with the impact of added suffixes on model outputs"
  - [section] "Results show that word importance scores are closely related to the expected suffix importances for multiple scoring functions."
- Break condition: If multiple words in a suffix have opposing effects that cancel out, leading to a neutral suffix impact despite individual word importance.

### Mechanism 3
- Claim: The method works across different scoring functions and model architectures.
- Mechanism: By using various text evaluation metrics (e.g., readability scores, word count, topic similarity) and testing on different models (GPT-3.5 Turbo, Llama2-13B), the method demonstrates broad applicability for understanding prompt influence.
- Core assumption: Different models and scoring functions will reveal consistent patterns in word importance that reflect genuine prompt influence.
- Evidence anchors:
  - [abstract] "This procedure also enables measuring impact when attention weights are not available."
  - [section] "This methodology is text score agnostic – any scoring function for assessing the output text can be used to ascertain word importance."
- Break condition: If the method produces inconsistent or contradictory results across different models or scoring functions.

## Foundational Learning

- Concept: Permutation importance in machine learning
  - Why needed here: The word importance method is directly inspired by permutation importance, which assesses feature importance by measuring the degradation in model performance when features are randomly shuffled.
  - Quick check question: In permutation importance, what does a large drop in model performance after shuffling a feature indicate about that feature's importance?

- Concept: Text embeddings and similarity measures
  - Why needed here: Topic similarity scores are computed using cosine similarity between text embeddings, which requires understanding how embeddings represent semantic content.
  - Quick check question: If two texts have a cosine similarity of 0.9, what does this indicate about their semantic relationship?

- Concept: Readability metrics (e.g., Flesch reading-ease)
  - Why needed here: Readability scores are used as one type of text evaluation metric to assess how prompt words influence the complexity of generated text.
  - Quick check question: What does a high Flesch reading-ease score indicate about a text's readability?

## Architecture Onboarding

- Component map: System prompt -> Word masking -> LLM output generation -> Text scoring functions -> Importance score calculation
- Critical path: The most critical path is the iterative process of masking each word, generating outputs, and computing the change in scores relative to the baseline.
- Design tradeoffs: Masking words with underscores is simple but may not capture the full impact of word substitution. Using more sophisticated masking (e.g., synonym replacement) could provide more nuanced insights but would increase complexity.
- Failure signatures: Inconsistent word importance scores across runs, low correlation between word importance and suffix impact, or failure to detect expected changes in output characteristics.
- First 3 experiments:
  1. Test the method on a simple prompt with a known influential word (e.g., "Answer concisely") and verify that masking "concisely" increases verbosity scores.
  2. Apply the method to a prompt with a suffix known to affect output length and check if the words in the suffix have high importance for word count scores.
  3. Compare word importance scores across two different models (e.g., GPT-3.5 Turbo and Llama2-13B) using the same prompt and scoring function to assess consistency.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the word importance method perform when using more complex or nuanced text scoring functions beyond Flesch reading-ease, word count, and topic similarity?
- Basis in paper: [explicit] The authors mention that the method is "text score agnostic" and could be applied to various text evaluation metrics, including "human feedback reward models, or estimates of factual accuracy."
- Why unresolved: The experiments only used three relatively simple text scores. The method's effectiveness for more complex scoring functions remains untested.
- What evidence would resolve it: Experiments applying the word importance method to a wider range of text scoring functions, including those measuring factual accuracy, bias, or human-like quality, would demonstrate the method's broader applicability.

### Open Question 2
- Question: Can the word importance method be extended to analyze the combined effect of system prompt words and user input words on LLM outputs?
- Basis in paper: [inferred] The authors note a limitation that they "exclude the effect of words in the user prompt on the output or the combination of the two." They suggest this could be an extension to analyze the effect of words in a single materialized prompt.
- Why unresolved: The current method only considers the impact of individual words in the system prompt, not how they interact with user input words or the combined effect on the final output.
- What evidence would resolve it: An extended version of the method that systematically masks words from both the system prompt and user input, and analyzes their combined impact on model outputs, would demonstrate this capability.

### Open Question 3
- Question: How does the choice of N (number of completions generated per prompt) affect the reliability and computational cost of the word importance method?
- Basis in paper: [explicit] The authors mention using N=3 and note that "To compute word importance scores more quickly, N could be reduced to one output or, for more reliable scores, increased to five outputs per combination."
- Why unresolved: The paper does not explore how different values of N affect the method's results or computational efficiency. The optimal balance between reliability and cost is unclear.
- What evidence would resolve it: Experiments varying N (e.g., 1, 3, 5, 10) and analyzing the stability of word importance scores, correlation with suffix impacts, and computational costs would help determine the optimal N value for different use cases.

## Limitations

- The method's effectiveness depends heavily on the choice of text scoring functions, and the study only evaluates three specific metrics (readability, verbosity, and topic relevance)
- The approach may not capture all aspects of prompt influence, particularly for tasks where output quality is subjective or multi-dimensional
- The study's artificial data generation process and the generalizability of findings to real-world applications remain unclear due to limited details about the experimental setup

## Confidence

- **High Confidence**: The core mechanism of masking words and measuring output changes is technically sound and well-implemented. The correlation between word importance scores and suffix impacts is demonstrated with statistical significance across multiple experiments.
- **Medium Confidence**: The method's effectiveness across different model architectures and prompt types, while suggested by the results, requires further validation with a broader range of tasks and models.
- **Low Confidence**: The study's artificial data generation process and the generalizability of findings to real-world applications remain unclear due to limited details about the experimental setup.

## Next Checks

1. **Cross-task validation**: Apply the word importance method to prompts from diverse NLP tasks (e.g., summarization, translation, code generation) to assess its effectiveness beyond the current experimental scope.

2. **Alternative masking strategies**: Compare the underscore masking approach with other word substitution methods (e.g., synonym replacement, word deletion) to evaluate whether the choice of masking technique affects the reliability of importance scores.

3. **Human evaluation correlation**: Conduct human studies to validate whether high word importance scores correspond to words that humans would intuitively identify as influential in the prompt, establishing ground truth for the automated method.