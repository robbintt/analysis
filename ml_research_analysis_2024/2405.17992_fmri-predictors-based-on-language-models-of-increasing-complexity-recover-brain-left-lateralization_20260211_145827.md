---
ver: rpa2
title: fMRI predictors based on language models of increasing complexity recover brain
  left lateralization
arxiv_id: '2405.17992'
source_url: https://arxiv.org/abs/2405.17992
tags:
- brain
- language
- correlation
- gyrus
- parameters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated the left-right asymmetry in language processing
  using fMRI and increasingly complex language models. The authors analyzed fMRI data
  from participants listening to naturalistic text, using 28 pretrained models ranging
  from 124M to 14.2B parameters.
---

# fMRI predictors based on language models of increasing complexity recover brain left lateralization

## Quick Facts
- arXiv ID: 2405.17992
- Source URL: https://arxiv.org/abs/2405.17992
- Reference count: 40
- Primary result: Scaling law shows brain correlation increases linearly with model size, stronger in left hemisphere

## Executive Summary
This study investigates the relationship between language model complexity and brain-language alignment using fMRI data from participants listening to naturalistic text. The authors analyze brain activity using 28 pretrained language models ranging from 124M to 14.2B parameters, finding a linear scaling relationship between model size and brain correlation. Crucially, they demonstrate that this alignment effect is significantly stronger in the left hemisphere, with the lateralization difference following its own scaling law with model size. This provides computational evidence for the classical observation of left hemisphere dominance in language processing.

## Method Summary
The study uses fMRI data from 100 participants listening to naturalistic text while their brain activity is recorded. Twenty-eight pretrained language models of varying complexity (124M to 14.2B parameters) are used to generate language representations. These representations are then correlated with brain activity patterns across different regions. The analysis focuses on identifying scaling relationships between model size and brain correlation, and comparing left versus right hemisphere alignment patterns. The study employs statistical methods to establish the significance of observed scaling laws and lateralization effects.

## Key Results
- Brain correlation with language models scales linearly with the logarithm of model parameters
- Left hemisphere shows significantly stronger alignment with language models than right hemisphere
- Left-right lateralization difference itself follows a scaling law with model size
- Higher alignment in left hemisphere occurs particularly in regions associated with high-level language comprehension

## Why This Works (Mechanism)
The scaling relationship between model complexity and brain alignment likely reflects how larger language models develop more sophisticated representations of linguistic structure that better match the hierarchical and compositional nature of human language processing in the brain. The left hemisphere dominance emerges because larger models more effectively capture the syntactic and semantic processing that characterizes left-lateralized language networks, particularly in regions like Broca's area and the temporal lobe.

## Foundational Learning

1. **fMRI signal processing**
   - Why needed: Understanding how BOLD signals relate to neural activity during language tasks
   - Quick check: Signal-to-noise ratio, temporal resolution limits, spatial localization accuracy

2. **Language model representations**
   - Why needed: Different model architectures encode linguistic information at varying levels of abstraction
   - Quick check: Embedding dimensionality, attention mechanisms, contextual representation quality

3. **Brain lateralization**
   - Why needed: Left hemisphere specialization for language processing is a fundamental neuroanatomical principle
   - Quick check: Broca's area, Wernicke's area, hemispheric specialization patterns

4. **Scaling laws in AI**
   - Why needed: Understanding how model performance improves predictably with size and data
   - Quick check: Parameter-count to performance relationships, diminishing returns

5. **Brain-language alignment metrics**
   - Why needed: Quantifying correspondence between computational and neural representations
   - Quick check: Representational similarity analysis, encoding models, correlation metrics

## Architecture Onboarding

**Component Map:**
Language Model (28 variants) -> Feature Extraction -> Brain Region Alignment -> Correlation Analysis -> Lateralization Assessment

**Critical Path:**
Model Parameter Scaling → Brain Correlation Improvement → Hemisphere Comparison → Lateralization Quantification

**Design Tradeoffs:**
- Model complexity vs. interpretability
- Individual vs. group-level analysis
- Naturalistic vs. controlled stimuli
- Left hemisphere focus vs. bilateral consideration

**Failure Signatures:**
- Absence of scaling relationship would suggest poor model-brain correspondence
- No lateralization difference would contradict established neuroscience
- Nonlinear scaling would indicate different representational principles

**First Experiments:**
1. Test whether fine-tuning models on neuroimaging data improves alignment beyond scaling relationship
2. Compare alignment across different language tasks (reading, speaking vs. listening)
3. Analyze individual differences in lateralization patterns and their relationship to model alignment

## Open Questions the Paper Calls Out
None

## Limitations
- Sample size of 100 participants may not capture full individual variability in language lateralization
- Focus on naturalistic text listening limits generalizability to other language modalities
- Exclusive use of pretrained models without fine-tuning may leave potential alignment improvements unexplored

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Scaling law relationship between model size and brain correlation | High |
| Stronger effect in left hemisphere with scaling | High |
| Larger models better capture left hemisphere language representations | Medium |
| Generalizability to non-listening language tasks | Low |

## Next Checks
1. Replicate the study with a larger, more diverse sample to assess individual differences in lateralization patterns and model alignment
2. Extend the analysis to include other language modalities (reading, speaking) to determine if the scaling relationship holds across different language processing types
3. Test the effect of fine-tuning language models on neuroimaging data to evaluate whether model-brain alignment can be further improved beyond the scaling relationship observed with pretrained models