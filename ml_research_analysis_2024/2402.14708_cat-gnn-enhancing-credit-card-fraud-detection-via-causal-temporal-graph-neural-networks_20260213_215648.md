---
ver: rpa2
title: 'CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph Neural
  Networks'
arxiv_id: '2402.14708'
source_url: https://arxiv.org/abs/2402.14708
tags:
- causal
- nodes
- graph
- fraud
- cat-gnn
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses credit card fraud detection using graph neural
  networks (GNNs) and identifies a key limitation: GNNs often overlook the causal
  effect of a node''s local structure on predictions. The proposed method, CaT-GNN
  (Causal Temporal Graph Neural Network), leverages causal invariant learning to reveal
  inherent correlations within transaction data.'
---

# CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph Neural Networks

## Quick Facts
- arXiv ID: 2402.14708
- Source URL: https://arxiv.org/abs/2402.14708
- Reference count: 15
- Primary result: Achieves AUC scores of 0.9035, 0.9706, and 0.8281 on YelpChi, Amazon, and S-FFSD datasets respectively

## Executive Summary
CaT-GNN addresses a critical limitation in graph neural networks for fraud detection: the inability to distinguish causal from spurious correlations in local graph structures. By integrating causal inference theory with temporal graph neural networks, CaT-GNN decomposes the detection process into discovery and intervention phases. The discovery phase uses attention mechanisms to identify environment (non-causal) nodes, while the intervention phase applies causal mixup to enhance model robustness. Evaluated on three datasets, CaT-GNN demonstrates superior performance compared to existing methods, with the approach providing both improved detection accuracy and interpretability through its causal framework.

## Method Summary
CaT-GNN is a two-phase framework that enhances credit card fraud detection by addressing spurious correlations in graph data. The discovery phase employs a Temporal GAT to compute attention scores for nodes, identifying environment nodes (bottom re% by importance) versus causal nodes. The intervention phase then applies a causal mixup strategy, blending each environment node with the top-k most important causal nodes using learned coefficients. This process implements a backdoor adjustment via do-calculus to ensure causal invariance. The model is trained using Adam optimizer with learning rate 0.003, batch size 256, dropout ratio 0.2, 4 attention heads, and hidden dimension 256 for 100 epochs with early stopping.

## Key Results
- Achieved AUC of 0.9035 on YelpChi dataset
- Achieved AUC of 0.9706 on Amazon dataset  
- Achieved AUC of 0.8281 on S-FFSD dataset
- Outperformed baseline methods including GNN, GAT, and Mixup approaches
- Demonstrated improved robustness to distribution shifts through causal intervention

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Causal-Inspector identifies causal vs environment nodes using temporal attention scores
- Mechanism: Computes attention weights via GAT, normalizes them, ranks nodes by importance, selects bottom re% as environment nodes
- Core assumption: Attention weights reflect causal importance in transaction graphs
- Evidence anchors:
  - [abstract] "Causal-Inspector utilizes attention weights in the temporal attention mechanism to identify causal and environment nodes"
  - [section] "Utilizing the popular node-attention metrics... we employ attention score to locate key nodes, designated as causal and environment nodes"
  - [corpus] Weak - corpus neighbors don't mention attention-based node selection
- Break condition: If attention scores don't correlate with actual causal structure, environment nodes will be misidentified

### Mechanism 2
- Claim: Causal-Intervener enhances environment nodes by mixing them with top causal nodes
- Mechanism: For each environment node, linearly combines it with k highest-importance causal nodes using learned weights
- Core assumption: Blending environment nodes with causal nodes improves robustness to distribution shifts
- Evidence anchors:
  - [abstract] "Causal-Intervener performs a causal mixup enhancement on environment nodes based on the set of nodes"
  - [section] "The Causal-Intervener performs a causal mixup enhancement on environment nodes... weighted by their respective coefficients"
  - [corpus] Weak - corpus neighbors don't mention mixup-based augmentation
- Break condition: If mixup weights don't reflect true causal influence, model may amplify noise

### Mechanism 3
- Claim: Backdoor adjustment via do-calculus ensures causal invariance
- Mechanism: Applies do-calculus to adjust for confounder E, estimating P(Y|do(Ĉ)) to eliminate spurious associations
- Core assumption: The graph structure satisfies backdoor criterion with respect to causal nodes
- Evidence anchors:
  - [abstract] "This approach can further be understood as a back-door adjustment in causal theory"
  - [section] "P(Y|do(Ĉ)) = Σ_i P(Y|do(Ĉ), E=Ei) P(E=Ei|do(Ĉ))"
  - [corpus] Weak - corpus neighbors don't discuss causal theory or backdoor adjustment
- Break condition: If backdoor criterion isn't satisfied, adjustment may introduce bias

## Foundational Learning

- Graph Neural Networks
  - Why needed here: Core model architecture for learning node representations from transaction graphs
  - Quick check question: How does GAT aggregation differ from GCN aggregation?

- Causal Inference Theory
  - Why needed here: Provides theoretical foundation for distinguishing causal vs spurious correlations
  - Quick check question: What is the backdoor criterion and when does it apply?

- Attention Mechanisms
  - Why needed here: Used to identify node importance scores for causal/environment node separation
  - Quick check question: How are attention scores computed and normalized in multi-head attention?

## Architecture Onboarding

- Component map:
  Input graph -> Temporal GAT -> Attention score computation -> Node ranking -> Environment node selection -> Mixup enhancement -> Aggregate -> Classification

- Critical path:
  Input graph → Temporal GAT → Attention score computation → Node ranking → Environment node selection → Mixup enhancement → Aggregate → Classification

- Design tradeoffs:
  - re parameter balances exploration of environment nodes vs focus on causal nodes
  - Mixup vs deletion of environment nodes: trade-off between robustness and information loss
  - Fixed vs proportional environment node selection: simplicity vs adaptability

- Failure signatures:
  - Poor AUC/F1 scores indicate mixup isn't helping or is introducing noise
  - Performance drops when training/test distributions differ significantly
  - If re=0 or re=1, performance should match or drop below non-causal baseline

- First 3 experiments:
  1. Run without causal intervention (N-CaT variant) to establish baseline
  2. Run with fixed environment node selection (CaT-GNN-FI) vs proportional selection
  3. Vary re parameter (5%, 15%, 25%) to find optimal environment node ratio

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does CaT-GNN perform on datasets with different graph structures (e.g., highly connected vs. sparse graphs)?
- Basis in paper: [inferred] The paper mentions that the effectiveness of causal intervention may vary based on the complexity of local structures and the prevalence of unlabeled nodes, suggesting that performance could be influenced by graph structure.
- Why unresolved: The paper evaluates CaT-GNN on three specific datasets but does not systematically explore performance across varying graph structures.
- What evidence would resolve it: Conduct experiments on a diverse set of datasets with varying graph structures, including highly connected and sparse graphs, to assess CaT-GNN's performance across these scenarios.

### Open Question 2
- Question: What is the impact of the environment nodes ratio (re) on CaT-GNN's performance, and is there an optimal range for this parameter?
- Basis in paper: [explicit] The paper includes a parameter sensitivity analysis with respect to different environmental ratios, indicating that the choice of re affects performance.
- Why unresolved: While the paper explores the impact of re, it does not identify an optimal range or provide guidelines for selecting this parameter in different contexts.
- What evidence would resolve it: Perform a more extensive sensitivity analysis across a wider range of datasets and graph structures to determine the optimal re values and provide guidelines for parameter selection.

### Open Question 3
- Question: How does CaT-GNN handle dynamic graphs where the structure and node attributes change over time?
- Basis in paper: [inferred] The paper focuses on temporal graphs but does not explicitly address scenarios where the graph structure and attributes evolve over time.
- Why unresolved: The paper does not explore the adaptability of CaT-GNN to dynamic changes in graph structure and attributes.
- What evidence would resolve it: Develop and evaluate CaT-GNN on dynamic graph datasets to assess its ability to adapt to changes in structure and attributes over time, and propose modifications if necessary.

## Limitations
- Theoretical claims about causal invariance rely heavily on the assumption that attention weights can reliably identify causal nodes, which may not hold in all graph structures
- Performance gains on private financial data cannot be independently verified due to dataset unavailability
- Causal mixup strategy's effectiveness depends on proper selection of the re parameter, which is not extensively explored across different dataset characteristics

## Confidence
- High confidence: AUC performance improvements on public datasets (YelpChi, Amazon, S-FFSD)
- Medium confidence: Theoretical framework of causal intervention and backdoor adjustment
- Low confidence: Generalizability of attention-based causal node identification across different fraud detection scenarios

## Next Checks
1. Implement ablation study comparing attention-based causal node identification vs random node selection to verify the importance of attention scores
2. Test model performance across different re parameter values (5%, 15%, 25%, 35%) to determine optimal environment node ratio
3. Evaluate model robustness by testing on distribution-shifted data (e.g., temporal splits or domain adaptation scenarios)