---
ver: rpa2
title: 'pEBR: A Probabilistic Approach to Embedding Based Retrieval'
arxiv_id: '2410.19349'
source_url: https://arxiv.org/abs/2410.19349
tags:
- items
- retrieval
- queries
- query
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of inefficient fixed-size retrieval
  in embedding-based retrieval systems, which leads to insufficient recall for head
  queries and low precision for tail queries. The authors propose pEBR, a probabilistic
  approach that models item distributions conditioned on each query, enabling dynamic
  retrieval thresholds derived from cumulative distribution functions.
---

# pEBR: A Probabilistic Approach to Embedding Based Retrieval

## Quick Facts
- arXiv ID: 2410.19349
- Source URL: https://arxiv.org/abs/2410.19349
- Authors: Han Zhang; Yunjiang Jiang; Mingming Li; Haowei Yuan; Yiming Qiu; Wen-Yun Yang
- Reference count: 18
- One-line primary result: Probabilistic approach models item distributions conditioned on each query, achieving significant improvements in precision and recall for both head and tail queries through dynamic threshold selection

## Executive Summary
This paper addresses the problem of inefficient fixed-size retrieval in embedding-based retrieval systems, which leads to insufficient recall for head queries and low precision for tail queries. The authors propose pEBR, a probabilistic approach that models item distributions conditioned on each query, enabling dynamic retrieval thresholds derived from cumulative distribution functions. The method introduces two instances: ExpNCE using truncated exponential distributions and BetaNCE using Beta distributions. Experiments demonstrate significant improvements in both precision and recall across different query types, with pEBR outperforming traditional fixed-threshold approaches. Ablation studies confirm the effectiveness of probabilistic modeling in capturing query popularity differences. Online A/B testing shows a 0.19% increase in user conversion rate. The method is shown to be model-agnostic and effective across different backbone architectures and training data sizes.

## Method Summary
pEBR introduces a probabilistic framework for embedding-based retrieval that learns item distributions conditioned on each query. Instead of using fixed thresholds, pEBR computes dynamic thresholds via cumulative distribution functions (CDF) of learned distributions. The method proposes two instances: ExpNCE using truncated exponential distributions and BetaNCE using Beta distributions. During training, pEBR optimizes these probabilistic models using noise contrastive estimation. At inference, CDF values determine retrieval cutoffs, allowing more items for head queries and fewer, more relevant items for tail queries. The approach is model-agnostic and compatible with two-tower retrieval architectures, primarily modifying the loss function rather than the model architecture.

## Key Results
- pEBR achieves significant improvements in recall@1500 and precision@1500 compared to fixed-threshold baselines (DSSM-topk and DSSM-score)
- Dynamic thresholding benefits head queries by retrieving more items and tail queries by improving precision
- Ablation studies confirm probabilistic formulation effectively captures inherent differences between head-to-tail queries
- Online A/B testing shows 0.19% increase in user conversion rate

## Why This Works (Mechanism)

### Mechanism 1
- Claim: pEBR improves retrieval by modeling item distributions conditioned on each query, allowing dynamic threshold selection based on query popularity.
- Mechanism: Instead of using a fixed threshold for all queries, pEBR learns a probabilistic model of the relevance distribution for each query. This distribution is then used to derive a dynamic threshold via the cumulative distribution function (CDF), ensuring optimal recall for head queries and precision for tail queries.
- Core assumption: Different queries have different item relevance distributions, and these distributions can be effectively modeled and used to determine optimal retrieval thresholds.
- Evidence anchors:
  - [abstract]: "Our method models the item distribution conditioned on each query, enabling the use of a dynamic cosine similarity threshold derived from the cumulative distribution function (CDF) of the probabilistic model."
  - [section]: "Importantly, the density for relevant items p(rd+,q|q) =f θ,q(rd+,q) and irrelevant items p(d−|q) =h θ,q(rd−,q) are both query dependent. This is a useful generalization from fixed density since different queries have different semantic scopes."
- Break condition: If the learned item distributions do not meaningfully differ across queries or if the CDF-based thresholding does not lead to better retrieval performance.

### Mechanism 2
- Claim: The probabilistic formulation effectively captures the inherent differences between head-to-tail queries, leading to improved retrieval performance.
- Mechanism: By modeling the item distribution for each query, pEBR can differentiate between queries with many relevant items (head queries) and those with few (tail queries). This allows for adaptive thresholding that retrieves more items for head queries and fewer, more relevant items for tail queries.
- Core assumption: The differences in item distributions between head and tail queries are significant enough to impact retrieval performance and can be captured by the probabilistic model.
- Evidence anchors:
  - [abstract]: "Furthermore, ablation studies reveal that the probabilistic formulation effectively captures the inherent differences between head-to-tail queries."
  - [section]: "Specifically, compared to DSSM-topk, pEBR achieves improvements on head queries, torso queries and tail queries respectively. This is because head queries normally have many more relevant items than tail queries; thus, a dynamic cutoff threshold could benefit head queries to retrieve more items significantly."
- Break condition: If the model fails to learn distinct distributions for head and tail queries, or if the differences are not sufficient to improve retrieval performance.

### Mechanism 3
- Claim: pEBR is model-agnostic and can be applied to different backbone architectures, including transformer-based models.
- Mechanism: The core innovation of pEBR lies in the probabilistic loss function and dynamic thresholding, which are independent of the specific architecture used for generating query and item embeddings. This allows pEBR to be seamlessly integrated into various two-tower retrieval models.
- Core assumption: The effectiveness of pEBR does not depend on the specific architecture used for generating embeddings, as long as the embeddings are suitable for retrieval tasks.
- Evidence anchors:
  - [section]: "Our method is compatible with most two-tower retrieval models since it primarily modifies the loss function rather than the model architecture."
  - [corpus]: Weak - corpus does not provide direct evidence for model-agnosticism. The related papers focus on different aspects of retrieval and do not directly address the model-agnostic nature of pEBR.
- Break condition: If the performance gains from pEBR are significantly reduced or eliminated when applied to certain backbone architectures.

## Foundational Learning

- Concept: Probabilistic modeling and noise contrastive estimation (NCE)
  - Why needed here: pEBR is built on the principles of probabilistic modeling and NCE, which allow it to learn the item distributions conditioned on each query and optimize the retrieval process.
  - Quick check question: What is the difference between maximum likelihood estimation and noise contrastive estimation, and how are they applied in pEBR?

- Concept: Cumulative distribution function (CDF) and its use in threshold selection
  - Why needed here: The CDF of the learned item distributions is used to determine dynamic retrieval thresholds, which is a key component of pEBR's improved performance.
  - Quick check question: How is the CDF used to derive a dynamic threshold in pEBR, and why is this better than using a fixed threshold?

- Concept: Beta and exponential distributions
  - Why needed here: pEBR proposes two instances, BetaNCE and ExpNCE, which use Beta and exponential distributions, respectively, to model the item distributions.
  - Quick check question: What are the properties of Beta and exponential distributions that make them suitable for modeling item distributions in pEBR?

## Architecture Onboarding

- Component map: Query encoder -> Item encoder -> Probabilistic loss function -> Dynamic thresholding module -> Retrieval system

- Critical path:
  1. Encode queries and items into embedding vectors
  2. Compute cosine similarities between query and item embeddings
  3. Apply probabilistic loss function to learn item distributions
  4. Compute CDF values from learned distributions
  5. Use CDF values to determine dynamic retrieval thresholds
  6. Retrieve items based on cosine similarity and dynamic thresholds

- Design tradeoffs:
  - Model complexity: pEBR introduces additional complexity through probabilistic modeling, which may increase training time and computational requirements
  - Flexibility: pEBR is model-agnostic, but its performance may vary depending on the backbone architecture used
  - Hyperparameter tuning: The choice of distribution (Beta or exponential) and related parameters may require careful tuning for optimal performance

- Failure signatures:
  - Poor retrieval performance: If the learned item distributions do not meaningfully differ across queries or if the CDF-based thresholding does not lead to better retrieval performance
  - Increased training time: If the probabilistic modeling and dynamic thresholding add significant overhead to the training process
  - Model instability: If the chosen distribution (Beta or exponential) is not well-suited for the data or if the hyperparameters are not properly tuned

- First 3 experiments:
  1. Compare pEBR with fixed-threshold baselines (DSSM-topk and DSSM-score) on a small dataset to validate the core concept
  2. Evaluate the impact of different distributions (BetaNCE vs. ExpNCE) on retrieval performance
  3. Test the model-agnostic nature of pEBR by applying it to different backbone architectures (e.g., DSSM and transformer-based models)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does pEBR's probabilistic cutoff threshold generalize to retrieval tasks with non-uniform or long-tail item distributions beyond the e-commerce domain?
- Basis in paper: [explicit] The paper demonstrates pEBR's effectiveness in e-commerce search with query popularity differences (head vs. tail queries) but doesn't explore other domains with different item distribution characteristics.
- Why unresolved: The experiments focus on a specific e-commerce dataset where item relevance patterns are tied to product categories and user behavior. Other domains like scientific literature retrieval or social media content may have fundamentally different item distribution structures.
- What evidence would resolve it: Systematic evaluation of pEBR across multiple retrieval domains (academic papers, news articles, social media posts) with varying item distribution characteristics, measuring how well the probabilistic threshold adapts to domain-specific relevance patterns.

### Open Question 2
- Question: What is the computational overhead of dynamically computing CDF thresholds during inference compared to fixed threshold approaches?
- Basis in paper: [inferred] The paper proposes using CDF values for dynamic cutoff but only mentions that Beta distribution CDF requires numerical integration, while truncated exponential is simpler.
- Why unresolved: The paper doesn't provide runtime comparisons or analyze the trade-off between improved retrieval quality and increased computational cost during serving time.
- What evidence would resolve it: Benchmarking studies comparing inference latency and throughput of pEBR versus fixed threshold approaches under realistic serving conditions, including profiling of CDF computation costs for both BetaNCE and ExpNCE variants.

### Open Question 3
- Question: How sensitive is pEBR's performance to the choice of underlying item distribution family (Beta vs. truncated exponential)?
- Basis in paper: [explicit] The paper proposes two instances (ExpNCE and BetaNCE) but primarily uses BetaNCE for main experiments, only briefly mentioning ExpNCE.
- Why unresolved: The paper doesn't provide comparative analysis of when each distribution type performs better or whether the choice should depend on query characteristics.
- What evidence would resolve it: Systematic ablation studies comparing ExpNCE and BetaNCE across different query types and datasets, identifying scenarios where each distribution excels and potentially developing heuristics for automatic distribution selection.

## Limitations

- Offline-only evaluation on proprietary 87M user click dataset, with limited online validation showing only 0.19% UCVR improvement
- Comparison against only two baseline methods (DSSM-topk and DSSM-score) limits generalizability of performance claims
- Reliance on CDF-based thresholding introduces computational overhead during inference, though not quantified in the paper

## Confidence

**High Confidence:** The core mechanism of using probabilistic modeling with dynamic thresholds based on CDF is well-supported by both theoretical derivation and experimental evidence. The improvements in precision and recall metrics are clearly demonstrated.

**Medium Confidence:** The claim of model-agnosticism is supported by testing on DSSM and BGE backbones, but the extent to which pEBR generalizes to other architectures (e.g., more complex transformer variants) remains uncertain without broader validation.

**Low Confidence:** The online A/B testing results showing only 0.19% UCVR improvement raise questions about the practical significance of the method in real-world scenarios, particularly given the substantial offline gains reported.

## Next Checks

1. **Distribution Sensitivity Analysis:** Systematically test pEBR with different distribution families beyond Beta and exponential (e.g., Gaussian, Pareto) to determine if the performance gains are distribution-specific or if the probabilistic framework itself is the key innovation.

2. **Cross-Domain Transferability:** Evaluate pEBR on datasets from different domains (e.g., image retrieval, document search) to verify whether the method's benefits extend beyond the e-commerce click-log context presented in the paper.

3. **Threshold Calibration Study:** Conduct ablation experiments varying the CDF percentile thresholds (e.g., 0.9 vs 0.95 vs 0.99) to determine optimal operating points and understand the sensitivity of performance to threshold selection across different query categories.