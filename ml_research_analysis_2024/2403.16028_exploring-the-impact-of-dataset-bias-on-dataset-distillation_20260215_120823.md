---
ver: rpa2
title: Exploring the Impact of Dataset Bias on Dataset Distillation
arxiv_id: '2403.16028'
source_url: https://arxiv.org/abs/2403.16028
tags:
- dataset
- biased
- datasets
- synthetic
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how dataset bias affects dataset distillation
  (DD), a technique for synthesizing smaller datasets that preserve essential information
  from larger ones. The authors identify that existing DD methods assume unbiased
  datasets, overlooking potential bias issues.
---

# Exploring the Impact of Dataset Bias on Dataset Distillation

## Quick Facts
- arXiv ID: 2403.16028
- Source URL: https://arxiv.org/abs/2403.16028
- Reference count: 40
- Primary result: Dataset bias significantly impacts dataset distillation performance, with extreme bias ratios (near 100%) paradoxically improving results

## Executive Summary
This paper investigates how dataset bias affects dataset distillation (DD), a technique for synthesizing smaller datasets that preserve essential information from larger ones. The authors identify that existing DD methods assume unbiased datasets, overlooking potential bias issues. To address this gap, they construct two biased datasets (CMNIST-DD and CCIFAR10-DD) with varying bias ratios (0%, 10%, 50%, 80%, 95%, and 100%) to systematically study the impact of bias on DD. Experiments using representative DD methods (DC, DSA, and DM) demonstrate that dataset bias significantly impacts DD performance in most cases, especially at higher bias ratios. The authors propose a reformulation of DD within the context of biased datasets, termed "biased DD," which aims to extract unbiased attributes while minimizing the impact of biased attributes.

## Method Summary
The authors constructed two biased datasets (CMNIST-DD and CCIFAR10-DD) with varying bias ratios from 0% to 100%. They applied three DD methods (DC, DSA, and DM) to these datasets, training models on the resulting synthetic datasets and evaluating performance on unbiased test sets. The experiments used standard training parameters (SGD, batch size 256, weight decay 0.0005, epochs 150, momentum 0.9, initial LR 0.01) with 50 synthetic images per class. Results were reported as mean and standard deviation across 3 runs.

## Key Results
- Dataset bias significantly impacts DD performance in most cases, with performance degradation correlating with increasing bias ratios
- Synthetic datasets generated from biased datasets exhibit less diversity and encode spurious correlations between bias attributes and labels
- At extreme bias ratios (exceeding 95%), synthetic datasets can outperform original datasets, suggesting potential for debiasing applications

## Why This Works (Mechanism)

### Mechanism 1
Dataset bias causes synthetic datasets to encode spurious correlations rather than task-relevant features. When bias attributes (zb) are strongly correlated with labels in the original dataset, DD methods optimize to match gradients/trajectories using these biased samples, leading synthetic data to inherit and amplify these correlations. Core assumption: DD methods treat all samples equally during optimization without distinguishing between bias-aligned and bias-conflicting samples.

### Mechanism 2
Higher bias ratios reduce synthetic dataset diversity by compressing biased attributes. As bias ratio increases, synthetic samples converge toward encoding dominant bias attributes (e.g., specific colors) rather than diverse task-relevant features, reducing generalization capability. Core assumption: DD optimization prioritizes minimizing loss on biased samples due to their stronger correlation with labels.

### Mechanism 3
Extreme bias ratios (near 100%) paradoxically improve DD performance by reducing noise. When nearly all samples share the same bias, DD can focus on learning the remaining task-relevant features without competing with conflicting bias signals, effectively denoising the dataset. Core assumption: Some bias attributes may align with true task-relevant features, or extreme bias creates a simpler optimization landscape.

## Foundational Learning

- **Concept**: Dataset bias definition and identification
  - Why needed: Understanding how bias attributes correlate with labels is fundamental to analyzing their impact on DD
  - Quick check: Given a dataset where 90% of cat images have green backgrounds and 10% have red backgrounds, what is the bias attribute and how would it affect model learning?

- **Concept**: Dataset distillation optimization objectives
  - Why needed: Knowing how DD methods optimize (gradient matching, trajectory matching, distribution matching) is crucial for understanding how bias propagates through the process
  - Quick check: How would a gradient-matching DD method differ from a distribution-matching method when processing a biased dataset?

- **Concept**: Evaluation metrics for bias detection
  - Why needed: Assessing bias impact requires quantitative measures of bias presence and model performance degradation
  - Quick check: What metrics would you use to quantify bias in a synthetic dataset compared to its original biased counterpart?

## Architecture Onboarding

- **Component map**: Dataset construction (CMNIST-DD, CCIFAR10-DD) -> DD method implementations (DC, DSA, DM) -> Evaluation pipeline (training on synthetic datasets, testing on unbiased data) -> Analysis tools (bias ratio calculation, diversity metrics)

- **Critical path**: 1) Construct biased datasets with varying bias ratios, 2) Run DD methods on each biased dataset, 3) Evaluate synthetic dataset performance on unbiased test set, 4) Analyze performance degradation patterns across bias ratios

- **Design tradeoffs**: Dataset complexity vs. bias control (simpler datasets allow precise bias control but may not generalize to complex scenarios); DD method selection (gradient-matching methods may propagate bias differently than distribution-matching methods); Evaluation strategy (testing on unbiased data reveals bias impact but may not reflect real-world deployment scenarios)

- **Failure signatures**: Synthetic datasets with uniform color patterns when bias ratio is high; performance degradation correlating with bias ratio increase; synthetic datasets showing less diversity than original biased datasets

- **First 3 experiments**: 1) Replicate CMNIST-DD experiments with DC method at bias ratios 0%, 50%, and 100% to observe color encoding patterns, 2) Compare DSA and DM performance on CCIFAR10-DD across all bias ratios to identify method-specific bias sensitivity, 3) Test extreme bias scenario (99% ratio) on both datasets to verify performance improvement phenomenon

## Open Questions the Paper Calls Out

- **Open Question 1**: Why do synthetic datasets outperform original datasets under extreme bias rates (nearly 100%)? The paper observes this phenomenon but does not investigate the underlying mechanisms or provide explanations for why this performance improvement occurs.

- **Open Question 2**: How can the impact of biased samples on synthetic datasets during the DD process be effectively eliminated or mitigated? While the paper identifies this as a key challenge and proposes a theoretical reformulation of biased DD, it does not provide specific implementation methods or empirical validation.

- **Open Question 3**: How do dataset bias effects vary across different DD methods beyond the three representative methods tested (DC, DSA, DM)? The paper only tests three representative DD methods but notes that many subsequent studies have introduced various matching losses to improve the performance of synthetic datasets.

## Limitations
- Dataset construction reproducibility is limited due to unspecified exact bias injection mechanisms and severity level parameters
- Results are based on two specific datasets (MNIST and CIFAR10) with controlled biases, which may not capture the complexity of real-world dataset biases
- The study uses only three DD methods, and the sensitivity to bias may vary significantly across different DD approaches

## Confidence
- **High confidence**: The observation that dataset bias affects DD performance is well-supported by experimental results across multiple bias ratios and both datasets
- **Medium confidence**: The mechanism explanations (spurious correlation inheritance and diversity reduction) are plausible but require further theoretical grounding
- **Medium confidence**: The paradoxical performance improvement at extreme bias ratios is observed but the underlying mechanism needs more rigorous analysis

## Next Checks
1. Implement quantitative bias metrics (e.g., mutual information between bias attributes and predictions) to confirm that synthetic datasets inherit bias from original datasets
2. Test the bias-DD relationship on additional datasets with different bias types (e.g., geographic, temporal, or demographic biases) to assess the generality of findings
3. Evaluate additional DD methods beyond DC, DSA, and DM to determine if bias sensitivity is method-specific or a universal DD phenomenon