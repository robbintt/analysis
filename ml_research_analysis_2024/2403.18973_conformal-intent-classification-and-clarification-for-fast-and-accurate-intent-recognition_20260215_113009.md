---
ver: rpa2
title: Conformal Intent Classification and Clarification for Fast and Accurate Intent
  Recognition
arxiv_id: '2403.18973'
source_url: https://arxiv.org/abs/2403.18973
tags:
- card
- intent
- cicc
- prediction
- conformal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Conformal Intent Classification and Clarification (CICC) is a framework
  for fast and accurate intent classification in task-oriented dialogue systems. It
  uses conformal prediction to turn a model's predictive uncertainty into prediction
  sets that contain the true intent at a predefined confidence level.
---

# Conformal Intent Classification and Clarification for Fast and Accurate Intent Recognition

## Quick Facts
- arXiv ID: 2403.18973
- Source URL: https://arxiv.org/abs/2403.18973
- Reference count: 40
- One-line primary result: CICC outperforms heuristic baselines in coverage and CQ size on intent classification datasets.

## Executive Summary
Conformal Intent Classification and Clarification (CICC) is a framework for fast and accurate intent classification in task-oriented dialogue systems. It uses conformal prediction to turn a model's predictive uncertainty into prediction sets that contain the true intent at a predefined confidence level. This allows the framework to generate small clarification questions that disambiguate between likely intents, enabling quick and accurate resolution of user queries. CICC was evaluated on seven intent recognition datasets and three IC models, outperforming heuristic approaches to predictive uncertainty quantification in all cases, particularly for ambiguous inputs. The framework also handles inputs that are too ambiguous for intent classification naturally. An augmented version, CICC-OOS, was proposed for out-of-scope detection and showed good performance on this task.

## Method Summary
CICC uses conformal prediction to quantify predictive uncertainty for intent classification in dialogue systems. The framework takes a trained intent classification model and applies conformal prediction to its softmax outputs, generating prediction sets that contain the true intent with a predefined coverage (e.g., 90%). If the prediction set has a single intent, the framework responds with that intent. If the set is too large (exceeding a threshold th), the input is rejected as too ambiguous. Otherwise, a clarification question (CQ) is generated by an LLM, asking the user to disambiguate between the intents in the prediction set. The framework also includes a variant, CICC-OOS, for out-of-scope detection, which tunes the error rate α and threshold th on a calibration set to maximize F1-score for detecting OOS inputs. CICC was evaluated on seven intent recognition datasets using fine-tuned BERT models and a custom BERT-like model, comparing its performance to heuristic baselines in terms of coverage, CQ size, and rejection rate.

## Key Results
- CICC achieved coverage of 90-99% across datasets, with average clarification question sizes of 2-3 intents.
- CICC outperformed heuristic baselines in all cases, particularly for ambiguous inputs, and rejected 0-11% of inputs as too ambiguous.
- The augmented CICC-OOS variant showed good performance on out-of-scope detection, with high F1-score and AUROC on the B77-OOS dataset.

## Why This Works (Mechanism)
CICC works by leveraging conformal prediction to quantify predictive uncertainty in intent classification models. Conformal prediction provides a rigorous way to generate prediction sets that contain the true intent with a predefined coverage level. By setting an appropriate error rate α, CICC can ensure that its prediction sets cover the true intent at least (1 - α) of the time. When the prediction set has a single intent, CICC can confidently respond with that intent. When the set is small (but larger than 1), CICC can ask a clarification question to disambiguate between the likely intents. By rejecting inputs with too large prediction sets, CICC avoids making incorrect predictions on highly ambiguous inputs. The use of an LLM for generating clarification questions allows for natural language interaction with the user to resolve ambiguity.

## Foundational Learning
- Conformal prediction: A framework for quantifying predictive uncertainty by generating prediction sets that contain the true label with a predefined coverage level. Why needed: To provide a rigorous way to handle uncertainty in intent classification and generate meaningful clarification questions. Quick check: Verify that the prediction sets generated by conformal prediction have the desired coverage on a held-out calibration set.
- Marginal conformal prediction: A type of conformal prediction that uses the entire calibration set to estimate the quantile of nonconformity scores. Why needed: To provide a simple and effective way to apply conformal prediction to intent classification without requiring class-conditional information. Quick check: Compare the performance of marginal conformal prediction to other variants (e.g., jackknife+, CV+) on the calibration set.
- Out-of-scope detection: The task of identifying inputs that do not belong to any of the known intent classes. Why needed: To handle inputs that are too ambiguous or unrelated to the task at hand, preventing the system from making incorrect predictions. Quick check: Evaluate the performance of CICC-OOS on a dataset with labeled out-of-scope examples, using metrics like F1-score and AUROC.

## Architecture Onboarding

Component map: User utterance -> Intent classification model -> Conformal prediction -> Prediction set -> [Single intent -> Respond] OR [Large set -> Reject] OR [Small set -> LLM-based CQ generation]

Critical path: The critical path in CICC is the generation of the prediction set using conformal prediction and the subsequent decision based on the set size. If the set has a single intent, the system responds immediately. If the set is small (but larger than 1), the system generates a clarification question using an LLM. If the set is too large, the system rejects the input as too ambiguous.

Design tradeoffs: CICC trades off between coverage and clarification question size by adjusting the error rate α. A lower α increases coverage but may result in larger clarification questions. The framework also trades off between accuracy and rejection rate by setting the threshold th. A lower th reduces the rejection rate but may increase the number of incorrect predictions.

Failure signatures: CICC may fail when the intent classification model is poorly calibrated or when the LLM generates unhelpful clarification questions. Poor calibration can lead to prediction sets that do not cover the true intent or are too large, resulting in incorrect predictions or unnecessary rejections. Unhelpful clarification questions can confuse the user and lead to incorrect intent recognition.

First experiments:
1. Evaluate the coverage of CICC on a held-out test set, comparing it to the desired coverage (1 - α) and to the coverage of heuristic baselines.
2. Analyze the size of the clarification questions generated by CICC, comparing it to the average number of intents in the prediction sets and to the CQ size of heuristic baselines.
3. Test the performance of CICC-OOS on a dataset with labeled out-of-scope examples, using metrics like F1-score and AUROC to evaluate its ability to detect OOS inputs.

## Open Questions the Paper Calls Out
1. How can CICC be extended to include stopping criteria for dialogues based on the number and size of clarification questions asked? The paper suggests that investigating stopping criteria based on the number and size of CQs asked could be an interesting direction for future research, as the current framework lacks a mechanism for stopping the dialogue.

2. How can the quality of clarification questions generated by the LLM be systematically evaluated and improved? The paper states that the quality of CQs produced by the LLM was not thoroughly investigated and is considered a pluggable component. Systematic evaluation and improvement of the generated questions could enhance the user experience and the overall effectiveness of CICC.

3. Can CICC be adapted for unsupervised out-of-scope detection without requiring labeled OOS data? The paper suggests that fully unsupervised approaches based on hierarchical Bayesian modeling or parameters that yield good performance across datasets could be explored, as the current CICC-OOS variant requires labeled OOS data for optimization.

## Limitations
- The evaluation focuses primarily on the relative performance of CICC compared to heuristic baselines rather than absolute performance, limiting understanding of the practical impact.
- The study uses a relatively small set of seven datasets, all of which are standard intent classification benchmarks, which may not fully capture the diversity of real-world dialogue scenarios.
- The evaluation of CICC-OOS is limited to a single dataset (B77-OOS) with synthetic out-of-scope examples added, which may not accurately reflect the distribution of truly out-of-scope inputs encountered in practice.
- The LLM-based clarification question generation is not extensively analyzed, and the paper does not provide examples of the generated questions or evaluate their quality and usefulness from a user perspective.
- The impact of the calibration set size on the performance of CICC is not explored, which could be a concern if the available data is limited.

## Confidence
- High: CICC outperforms heuristic baselines in coverage and CQ size on the evaluated datasets.
- High: CICC provides a principled approach to asking short and specific clarification questions based on model uncertainty.
- Medium: CICC handles inputs that are too ambiguous for intent classification naturally by rejecting them.
- Medium: CICC-OOS shows good performance on out-of-scope detection on the B77-OOS dataset.
- Low: The LLM-generated clarification questions are of high quality and usefulness in practice.

## Next Checks
1. Evaluate CICC on a wider range of dialogue datasets, including those with more complex and ambiguous user utterances, to assess its generalizability.
2. Conduct a user study to evaluate the quality and usefulness of the LLM-generated clarification questions in practice, comparing them to human-generated questions.
3. Analyze the impact of calibration set size on the performance of CICC, exploring how performance changes with limited training data.