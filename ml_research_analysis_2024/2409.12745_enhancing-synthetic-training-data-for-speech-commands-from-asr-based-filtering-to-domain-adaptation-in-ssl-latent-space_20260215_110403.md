---
ver: rpa2
title: 'Enhancing Synthetic Training Data for Speech Commands: From ASR-Based Filtering
  to Domain Adaptation in SSL Latent Space'
arxiv_id: '2409.12745'
source_url: https://arxiv.org/abs/2409.12745
tags:
- speech
- data
- synthetic
- real
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of using synthetic speech for
  training speech command classification systems, noting that synthetic speech can
  contain hallucinations and artifacts that degrade model performance. The authors
  propose an ASR-based filtering method to improve the quality of synthetic data by
  removing poorly synthesized audio samples.
---

# Enhancing Synthetic Training Data for Speech Commands: From ASR-Based Filtering to Domain Adaptation in SSL Latent Space

## Quick Facts
- arXiv ID: 2409.12745
- Source URL: https://arxiv.org/abs/2409.12745
- Reference count: 0
- Primary result: ASR filtering improves synthetic speech command accuracy from 89% to 92.6%

## Executive Summary
This paper addresses the challenge of using synthetic speech for training speech command classification systems, noting that synthetic speech can contain hallucinations and artifacts that degrade model performance. The authors propose an ASR-based filtering method to improve the quality of synthetic data by removing poorly synthesized audio samples. They also explore the use of self-supervised learning features and propose a CycleGAN for domain adaptation to bridge the gap between synthetic and real speech representations. Using the Google Speech Commands dataset, they demonstrate that their ASR filtering method significantly improves performance, achieving 92.6% accuracy with synthetic data compared to 89% without filtering. Additionally, they show that SSL features can still distinguish between synthetic and real speech, and their CycleGAN approach further improves accuracy to 96.5%, narrowing the gap with real speech training data.

## Method Summary
The authors propose a multi-stage approach to improve synthetic speech command data quality. First, they use an ASR-based filtering method where synthesized audio is passed through a speech recognition model, and samples with low confidence scores (below 0.7) or mismatched transcriptions are discarded. Second, they leverage self-supervised learning (SSL) features from wav2vec2 to analyze the domain gap between synthetic and real speech. Finally, they implement a CycleGAN architecture for domain adaptation, mapping synthetic speech features into the real speech feature space to reduce domain discrepancy.

## Key Results
- ASR filtering improves synthetic speech command accuracy from 89% to 92.6%
- SSL features from wav2vec2 can still distinguish synthetic from real speech
- CycleGAN domain adaptation further improves accuracy to 96.5%, approaching real speech training performance

## Why This Works (Mechanism)
The ASR filtering works by leveraging the fact that poorly synthesized speech will produce low-confidence transcriptions or incorrect text from a speech recognition model. By removing these samples, the training data quality improves. The SSL features capture high-level semantic information about the speech, revealing that synthetic and real speech occupy different regions in the feature space. The CycleGAN then learns to map synthetic speech features into the real speech feature space, effectively reducing this domain gap and improving classifier performance on real-world data.

## Foundational Learning
- **ASR-based filtering**: Why needed - removes low-quality synthetic samples that would degrade model training. Quick check - verify that filtered samples have significantly lower confidence scores than retained samples.
- **Self-supervised learning features**: Why needed - provides rich semantic representations that capture domain differences. Quick check - confirm that t-SNE visualizations show clear separation between synthetic and real speech in SSL feature space.
- **CycleGAN architecture**: Why needed - learns bidirectional mappings between synthetic and real feature distributions. Quick check - verify that CycleGAN can reconstruct both synthetic and real features accurately.
- **Confidence thresholding**: Why needed - provides a quantitative criterion for sample selection. Quick check - test multiple threshold values to find optimal balance between data retention and quality.
- **Domain adaptation**: Why needed - bridges the performance gap between synthetic and real speech data. Quick check - measure feature distribution similarity before and after CycleGAN adaptation.

## Architecture Onboarding

**Component map**: Synthetic speech -> ASR filter -> SSL feature extractor -> CycleGAN -> Speech command classifier

**Critical path**: The ASR filtering stage is critical as it directly impacts data quality, followed by the CycleGAN adaptation which reduces domain discrepancy for improved classification performance.

**Design tradeoffs**: The approach trades computational overhead (running ASR filtering and CycleGAN training) for improved data quality and performance. The fixed vocabulary constraint limits applicability to other command sets.

**Failure signatures**: Poor ASR filtering thresholds lead to either excessive data loss or insufficient quality improvement. Ineffective CycleGAN training results in minimal domain adaptation and persistent performance gaps.

**3 first experiments**:
1. Test ASR filtering with confidence thresholds of 0.6, 0.7, and 0.8 to identify optimal quality-vs-quantity tradeoff
2. Compare CycleGAN performance with and without SSL feature preprocessing
3. Evaluate classifier performance using only filtered synthetic data versus combined filtered and real data

## Open Questions the Paper Calls Out
None

## Limitations
- ASR filtering relies on fixed confidence thresholds that may not generalize to more complex command sets
- CycleGAN requires careful hyperparameter tuning and may not scale well to larger vocabularies
- Study focuses exclusively on Google Speech Commands dataset with 35 classes, limiting external validity

## Confidence

**Major claim clusters and confidence levels:**
- ASR filtering effectiveness: High confidence - results are clear and reproducible with the provided methodology
- SSL feature distinguishability between synthetic and real speech: Medium confidence - while t-SNE visualizations are convincing, quantitative validation is limited
- CycleGAN domain adaptation performance: Medium confidence - improvements are demonstrated but the method requires careful tuning and validation across diverse conditions

## Next Checks

1. Test ASR filtering thresholds across multiple confidence levels (0.6, 0.7, 0.8) to assess robustness and identify optimal trade-offs between data retention and quality
2. Evaluate the CycleGAN approach on synthetic speech with varying levels of acoustic distortion to test generalization beyond the current dataset conditions
3. Conduct ablation studies comparing different SSL feature extractors (wav2vec2, HuBERT, etc.) to determine if the observed domain gap is feature-specific or universal across SSL approaches