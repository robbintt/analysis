---
ver: rpa2
title: 'AdvNF: Reducing Mode Collapse in Conditional Normalising Flows using Adversarial
  Learning'
arxiv_id: '2401.15948'
source_url: https://arxiv.org/abs/2401.15948
tags:
- samples
- distribution
- advnf
- mode
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses mode collapse in conditional normalizing flows
  (NFs) when modeling high-dimensional physical distributions, which leads to biased
  sample statistics. The authors propose an adversarial training approach, AdvNF,
  which combines NF modeling with a discriminator network to better capture all modes
  of the target distribution.
---

# AdvNF: Reducing Mode Collapse in Conditional Normalising Flows using Adversarial Learning

## Quick Facts
- arXiv ID: 2401.15948
- Source URL: https://arxiv.org/abs/2401.15948
- Authors: Vikas Kanaujia; Mathias S. Scheurer; Vipul Arora
- Reference count: 40
- Primary result: AdvNF reduces mode collapse in conditional normalizing flows for physical systems, achieving up to 1100x improvement in negative log-likelihood compared to standard approaches

## Executive Summary
This paper addresses mode collapse in conditional normalizing flows when modeling high-dimensional physical distributions, particularly in lattice field theory and statistical mechanics. The authors propose AdvNF, which combines conditional normalizing flow modeling with adversarial training to better capture all modes of the target distribution. The method is evaluated on synthetic datasets (MOG-4, MOG-8, Rings-4) and the XY model in two spatial dimensions, showing significant improvements in sample quality and thermodynamic observables.

## Method Summary
AdvNF combines conditional normalizing flows with adversarial training to reduce mode collapse. The model uses a bijective transformation conditioned on external parameters (e.g., temperature) and is trained using reverse KL divergence with an additional adversarial loss. An independent Metropolis-Hastings algorithm is applied post-training to remove bias from the learned flow. The approach alternates between updating the generator (conditional NF) and discriminator, with the generator receiving both KL and adversarial losses.

## Key Results
- AdvNF (RKL) achieves up to 1100x improvement in negative log-likelihood compared to CNF-MH (RKL) on synthetic datasets
- For the XY model, AdvNF produces more accurate thermodynamic observables (mean magnetization and energy) with lower Earth Mover Distance
- The method shows reduced dependence on large training ensemble sizes compared to standard conditional NF approaches
- Better coverage of all modes observed in synthetic datasets with up to 8 modes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adversarial training adds an explicit diversity penalty that counteracts mode-seeking behavior in RKL-based NF training.
- Mechanism: The discriminator D is trained to distinguish real samples from model samples. When RKL alone would collapse to a single mode, the adversarial loss pushes the model to generate samples that the discriminator cannot easily classify as fake, encouraging exploration of all modes.
- Core assumption: The discriminator can detect mode collapse even when it occurs in high-dimensional latent space, and the generator can learn to fool it without simply memorizing modes.
- Evidence anchors:
  - [abstract] states that "adversarial training for NFs to ameliorate these problems" and that "AdvNF (RKL) achieves up to 1100x improvement in negative log-likelihood compared to CNF-MH (RKL)."
  - [section] describes "adding adversarial loss to one or both of these improves the model performance" and that "it allows the model to better explore and learn the unseen modes."
  - [corpus] shows related work on "Mitigating mode collapse in normalizing flows" and "SCORENF: Score-based Normalizing Flows" but lacks direct citation of adversarial training for this specific purpose.
- Break condition: If the discriminator overfits to training modes or the generator exploits the discriminator's weaknesses without improving mode coverage, mode collapse may persist.

### Mechanism 2
- Claim: The Independent Metropolis-Hastings algorithm removes bias from the learned flow, ensuring samples are exact even if the flow itself is imperfect.
- Mechanism: Samples from the trained flow are treated as proposals in a Markov chain. The acceptance probability depends on the ratio of true density to proposal density, rejecting samples that are too unlikely under the true distribution.
- Core assumption: The flow can approximate the true density up to a proportionality constant, and the acceptance probability can be computed efficiently.
- Evidence anchors:
  - [section] explicitly describes the IMH algorithm and states "samples are generated from the trained model distribution, which acts as the proposal distribution and is stochastically accepted or rejected based on acceptance probabilities."
  - [section] notes that "Since the generator introduces bias in the samples due to approximation errors, we eliminate the bias by applying the independent Metropolis-Hastings algorithm."
  - [corpus] mentions "Reducing normalizing flow complexity for MCMC preconditioning" but doesn't provide direct evidence for IMH in this context.
- Break condition: If the flow proposal is too dissimilar from the true distribution, acceptance rates become extremely low, making sampling inefficient.

### Mechanism 3
- Claim: Conditioning on external parameters (e.g., temperature) allows a single model to capture the full phase space of the physical system, reducing the need for repeated training.
- Mechanism: The bijective transformation T takes both latent variable z and condition c as inputs, allowing the same network to model different distributions for different parameter values.
- Core assumption: The relationship between the distribution and the external parameters is smooth enough to be learned by the same network architecture.
- Evidence anchors:
  - [section] explains that "the parametric bijective transformation T, conditioned on an external parameter c, is expressed as x = T(z; c)" and discusses applications to XY model where "we train our proposed model, AdvNF, conditioned on temperature(T)."
  - [abstract] notes experiments on "XY spin models in two spatial dimensions" with conditioning on temperature.
  - [corpus] lacks direct evidence of this specific conditioning approach, only mentioning general "Conditional Normalising Flows" in titles.
- Break condition: If the conditional relationship is too complex or discontinuous, a single model may fail to capture all regimes effectively.

## Foundational Learning

- Concept: KL Divergence (Forward vs Reverse)
  - Why needed here: Understanding why RKL causes mode collapse while FKL causes high variance is central to the paper's motivation.
  - Quick check question: If p(x) is a bimodal distribution and q(x) is unimodal, which KL direction (p||q or q||p) would cause q to try to cover both modes?

- Concept: Normalizing Flows and Change of Variables
  - Why needed here: The entire model is built on the idea that complex distributions can be modeled via invertible transformations of simple distributions.
  - Quick check question: Given z ~ N(0,I) and an invertible transformation T, how do you compute the density of x = T(z)?

- Concept: Adversarial Training Objectives
  - Why needed here: The core innovation is adding adversarial loss to NF training, which requires understanding GAN-style objectives.
  - Quick check question: In the adversarial loss L_adv(T,D;c) = -E_{x~p}[log(D(x;c))] - E_{z~q}[log(1-D(T(z;c);c))], which network is being trained to minimize this expression?

## Architecture Onboarding

- Component map:
  - Latent variable z -> Conditional NF (Generator) -> Samples x -> Discriminator -> Real/Fake classification
  - Conditional NF (Generator) -> Log-determinant -> Model density computation
  - Samples x and true samples -> Independent Metropolis-Hastings -> De-biased samples

- Critical path:
  1. Sample z from base distribution
  2. Apply conditional NF to get x and log-det
  3. Compute model density using change of variables
  4. Train discriminator on real vs generated samples
  5. Update generator with combined loss (adversarial + KL terms)
  6. Apply IMH to final samples

- Design tradeoffs:
  - RKL vs FKL: RKL doesn't require true samples but causes mode collapse; FKL requires true samples but covers all modes
  - Adversarial weight λ1: Too high causes instability; too low doesn't prevent mode collapse
  - Coupling layers vs other architectures: Coupling layers are invertible but may limit expressiveness

- Failure signatures:
  - Low acceptance rate after IMH: Flow is too dissimilar from true distribution
  - High NLL but good visual coverage: Model covers modes but assigns incorrect probabilities
  - Discriminator loss goes to zero: Generator has collapsed or discriminator is overfitting

- First 3 experiments:
  1. Train CNF-MH(RKL) on MOG-4 dataset, visualize mode coverage failure
  2. Add adversarial training with high λ1, observe mode recovery
  3. Apply IMH to both models, compare acceptance rates and NLL

## Open Questions the Paper Calls Out

- Question: How does the AdvNF approach scale to higher-dimensional physical systems beyond the XY and extended XY models studied here?
  - Basis in paper: [inferred] The paper tests on 2D synthetic datasets and 2D lattice models (XY, extended XY), but does not investigate higher dimensions.
  - Why unresolved: The paper does not provide theoretical or empirical evidence for how mode collapse reduction and performance improvements would hold in higher dimensions.
  - What evidence would resolve it: Testing AdvNF on 3D lattice models or other high-dimensional physical systems, comparing performance metrics like NLL, %OL, and EMD against baselines.

- Question: What is the optimal balance between adversarial loss weight (λ1) and KL divergence losses (λ2, λ3) for different physical systems and dataset characteristics?
  - Basis in paper: [explicit] The paper discusses hyperparameter tuning and shows that AdvNF (RKL) performs best, but does not systematically study the optimal λ1 scheduling for different datasets.
  - Why unresolved: The paper uses fixed λ1 schedules for each dataset but does not explore how these schedules should be adapted for different system sizes, dimensionalities, or multi-modal structures.
  - What evidence would resolve it: Systematic ablation studies varying λ1 schedules across multiple physical systems, showing how optimal hyperparameters depend on system properties.

- Question: Can the AdvNF framework be extended to quantum systems where the target distribution is not directly observable but must be inferred from measurements?
  - Basis in paper: [explicit] The paper concludes by suggesting it would be interesting to evaluate the approach on quantum systems.
  - Why unresolved: The paper focuses exclusively on classical statistical mechanics models with known probability distributions.
  - What evidence would resolve it: Implementing AdvNF for quantum spin systems or fermionic models, using measurement data to train the model and evaluating thermodynamic observables against exact solutions or high-precision simulations.

## Limitations
- Effectiveness depends heavily on discriminator's ability to detect mode collapse in high-dimensional spaces
- Computational overhead from adversarial training and IMH post-processing may limit scalability
- Critical dependence on hyperparameter choices for adversarial loss weights without extensive exploration

## Confidence
- High Confidence: The core mechanism of combining adversarial training with conditional NFs to reduce mode collapse
- Medium Confidence: The effectiveness of IMH in removing bias from imperfect flows
- Medium Confidence: The scalability of the approach to larger lattice sizes and more complex physical systems

## Next Checks
1. Apply AdvNF to larger lattice sizes (e.g., 32×32 or 64×64) to evaluate computational scaling and mode collapse reduction in higher dimensions
2. Conduct systematic ablation studies varying λ1, λ2, and λ3 across orders of magnitude to determine robustness
3. Test alternative discriminator architectures (e.g., convolutional vs. fully connected) or training objectives for improved mode detection