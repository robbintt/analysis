---
ver: rpa2
title: Expandable Subspace Ensemble for Pre-Trained Model-Based Class-Incremental
  Learning
arxiv_id: '2403.12030'
source_url: https://arxiv.org/abs/2403.12030
tags:
- uni00000013
- uni00000024
- uni00000027
- uni00000048
- uni00000055
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes EASE, an expandable subspace ensemble approach
  for pre-trained model-based class-incremental learning (CIL). EASE addresses the
  stability-plasticity dilemma in CIL by creating lightweight task-specific adapters
  that span high-dimensional feature spaces without overwriting old knowledge.
---

# Expandable Subspace Ensemble for Pre-Trained Model-Based Class-Incremental Learning

## Quick Facts
- arXiv ID: 2403.12030
- Source URL: https://arxiv.org/abs/2403.12030
- Authors: Da-Wei Zhou; Hai-Long Sun; Han-Jia Ye; De-Chuan Zhan
- Reference count: 40
- The paper proposes EASE, an expandable subspace ensemble approach for pre-trained model-based class-incremental learning (CIL). EASE addresses the stability-plasticity dilemma in CIL by creating lightweight task-specific adapters that span high-dimensional feature spaces without overwriting old knowledge. To handle expanding features without exemplars, it synthesizes old class classifiers via semantic-guided prototype complement using class-wise similarities in the co-occurrence space. Extensive experiments on seven benchmark datasets show EASE achieves state-of-the-art performance, outperforming current methods by 4-7.5% while maintaining low memory cost comparable to prompt-based methods.

## Executive Summary
EASE addresses the fundamental challenge of class-incremental learning (CIL) by introducing an expandable subspace ensemble approach. The method creates lightweight task-specific adapters for each new task that span high-dimensional feature spaces without overwriting old knowledge. To handle expanding features without exemplars, EASE synthesizes old class classifiers through semantic-guided prototype complement using class-wise similarities in the co-occurrence space. This approach achieves state-of-the-art performance on seven benchmark datasets while maintaining low memory costs comparable to prompt-based methods.

## Method Summary
EASE proposes an expandable subspace ensemble approach for pre-trained model-based class-incremental learning. The method employs lightweight adapter modules trained for each new task to create task-specific subspaces, enabling joint decision-making across multiple subspaces without modifying the frozen pre-trained backbone. When new classes arrive, EASE synthesizes old class classifiers through semantic-guided prototype complement using class-wise similarities in the co-occurrence space, eliminating the need for exemplars. The final predictions are generated through a subspace ensemble with reweighting that emphasizes the matching subspace where the adapter was specifically trained for the current task.

## Key Results
- EASE achieves state-of-the-art performance on seven benchmark datasets, outperforming current methods by 4-7.5%
- The method maintains low memory cost comparable to prompt-based methods while achieving superior performance
- EASE effectively addresses the stability-plasticity dilemma in CIL by creating task-specific subspaces without overwriting old knowledge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Task-specific adapters span high-dimensional feature spaces without overwriting old knowledge.
- Mechanism: Lightweight adapter modules are trained for each new task and concatenated with the frozen PTM backbone to create task-specific subspaces. This enables joint decision-making across multiple subspaces without modifying the frozen weights that preserve old knowledge.
- Core assumption: Task-specific information can be effectively encoded in lightweight adapter branches without needing to modify the pre-trained backbone.
- Evidence anchors:
  - [abstract]: "train a distinct lightweight adapter module for each new task, aiming to create task-specific subspaces"
  - [section]: "we train a distinct lightweight adapter module for each new task, aiming to create task-specific subspaces. These adapters span a high-dimensional feature space, enabling joint decision-making across multiple subspaces."
  - [corpus]: Weak evidence. The corpus contains related works on adapter tuning but lacks direct experimental validation of this specific mechanism.
- Break condition: If adapters cannot effectively encode task-specific information or if the concatenated features create interference rather than complementarity, the mechanism fails.

### Mechanism 2
- Claim: Semantic-guided prototype complement synthesizes old class classifiers without exemplars.
- Mechanism: Class-wise similarities in the co-occurrence space are extracted and used to reconstruct prototypes of old classes in new subspaces through weighted combination of new class prototypes.
- Core assumption: Class-wise semantic relationships are preserved across different embedding subspaces, allowing similarity patterns from one subspace to inform prototype synthesis in another.
- Evidence anchors:
  - [abstract]: "we design a semantic-guided prototype complement strategy that synthesizes old classes' new features without using any old class instance"
  - [section]: "we utilize class-wise similarities in the co-occurrence space to guide the classifier mapping in the target space"
  - [corpus]: Weak evidence. The corpus mentions prototype-based methods but doesn't provide strong validation of semantic-guided cross-subspace mapping.
- Break condition: If semantic relationships change significantly across subspaces or if class-wise similarities in the co-occurrence space don't generalize to new subspaces, the synthesis fails.

### Mechanism 3
- Claim: Subspace ensemble with reweighting creates robust predictions by emphasizing core features.
- Mechanism: Predictions from different subspaces are combined with higher weights assigned to the matching subspace (where the adapter was specifically trained for the current task), creating a reweighted ensemble.
- Core assumption: The adapter specifically trained for a task is better suited to extract relevant features for that task's classes than other adapters.
- Evidence anchors:
  - [section]: "we transform Eq. 11 by assigning higher weights to the matching subspace: P⊤b,bϕ(x; Ab) + αP i̸=b P⊤b,iϕ(x; Ai)"
  - [corpus]: Moderate evidence. Ensemble methods are common in machine learning, but specific validation of this reweighting strategy is limited in the corpus.
- Break condition: If the matching subspace doesn't consistently provide the most relevant features or if the weighting parameter α is poorly chosen, ensemble performance degrades.

## Foundational Learning

- Concept: Class-Incremental Learning (CIL)
  - Why needed here: EASE specifically addresses the stability-plasticity dilemma in CIL where new class learning can overwrite old class knowledge
  - Quick check question: What is the main challenge in class-incremental learning that EASE aims to solve?

- Concept: Adapter tuning
  - Why needed here: Adapters provide a parameter-efficient way to create task-specific subspaces without modifying the frozen pre-trained backbone
  - Quick check question: How do adapters differ from full fine-tuning in terms of parameter usage and knowledge preservation?

- Concept: Prototype-based classification
  - Why needed here: Prototypes serve as class representatives that can be completed across subspaces without exemplars through semantic mapping
  - Quick check question: What role do prototypes play in the classification process when exemplars are unavailable?

## Architecture Onboarding

- Component map: Pre-trained backbone (frozen) → Task-specific adapters (one per task) → Concatenated embeddings → Prototype-based classifier (completed via semantic mapping) → Subspace ensemble with reweighting
- Critical path: Adapter training → Prototype extraction → Semantic mapping → Reweighting → Classification
- Design tradeoffs: Parameter efficiency vs. representational capacity; memory savings vs. potential information loss in semantic mapping
- Failure signatures: Degraded performance on old classes; inconsistent prototype synthesis; overfitting to new tasks
- First 3 experiments:
  1. Test adapter training effectiveness by comparing feature separability across subspaces
  2. Validate semantic mapping by checking prototype reconstruction accuracy in controlled settings
  3. Evaluate reweighting strategy by comparing ensemble performance with and without task-specific emphasis

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does EASE's semantic-guided prototype complement strategy scale to datasets with significantly more classes or tasks? Is there a theoretical limit to its effectiveness?
- Basis in paper: [explicit] The paper mentions utilizing class-wise similarities in the co-occurrence space to guide the synthesis of old class classifiers, but does not discuss scalability to very large datasets.
- Why unresolved: The paper focuses on experiments with datasets containing up to 300 classes (OmniBenchmark) and 10-40 incremental stages. It does not explore the performance of EASE when dealing with hundreds or thousands of classes or tasks.
- What evidence would resolve it: Experiments comparing EASE's performance on datasets with vastly different numbers of classes (e.g., 1000+ classes) or tasks (e.g., 100+ incremental stages) would demonstrate its scalability and potential limitations.

### Open Question 2
- Question: What is the impact of the adapter's bottleneck dimension (r) on EASE's performance and computational efficiency? Is there an optimal value of r that balances performance and efficiency?
- Basis in paper: [explicit] The paper mentions setting the projection dimension r in the adapter to 16 and reports robustness experiments with different values of r, but does not provide an in-depth analysis of the relationship between r and performance.
- Why unresolved: The paper only shows that EASE's performance is robust to changes in r, but does not explore the optimal value of r or the trade-off between performance and computational efficiency.
- What evidence would resolve it: A detailed study examining EASE's performance and computational efficiency across a wide range of r values would reveal the optimal choice of r for different scenarios.

### Open Question 3
- Question: How does EASE's performance compare to exemplar-based methods when the number of exemplars per class is significantly reduced or increased? Is there a threshold below which exemplar-based methods become less effective than EASE?
- Basis in paper: [explicit] The paper mentions that EASE does not use any exemplars, while comparing it to exemplar-based methods that use 20 exemplars per class. It does not explore the performance of EASE when exemplars are available in limited or abundant quantities.
- Why unresolved: The paper only compares EASE to exemplar-based methods with a fixed number of exemplars (20 per class), but does not investigate how the availability of exemplars affects the relative performance of EASE and exemplar-based methods.
- What evidence would resolve it: Experiments comparing EASE's performance to exemplar-based methods with varying numbers of exemplars per class (e.g., 1, 5, 10, 20, 50) would demonstrate the threshold below which EASE outperforms exemplar-based methods.

## Limitations
- The semantic-guided prototype complement strategy relies on the assumption that class-wise semantic relationships remain stable across different embedding subspaces, which may not hold for all datasets or class distributions
- The effectiveness of the reweighting strategy depends on careful tuning of the parameter α, though the paper doesn't specify the optimization procedure for this hyperparameter
- Experiments are conducted primarily on vision datasets with pre-trained ViT models, limiting generalizability to other modalities or backbone architectures

## Confidence
- High: Adapter-based task-specific subspace creation and its parameter efficiency
- Medium: Semantic-guided prototype synthesis mechanism and its cross-subspace applicability
- Medium: Subspace ensemble reweighting strategy for final predictions

## Next Checks
1. Conduct ablation studies to quantify the individual contribution of semantic-guided prototype complement versus exemplar-based methods
2. Test the method's robustness across different pre-trained backbone architectures (e.g., ResNet, ConvNeXt) and different initial training conditions
3. Evaluate performance degradation under varying degrees of semantic drift between old and new subspaces