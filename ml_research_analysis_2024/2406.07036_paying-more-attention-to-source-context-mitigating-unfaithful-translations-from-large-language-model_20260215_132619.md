---
ver: rpa2
title: 'Paying More Attention to Source Context: Mitigating Unfaithful Translations
  from Large Language Model'
arxiv_id: '2406.07036'
source_url: https://arxiv.org/abs/2406.07036
tags: []
core_contribution: 'This paper identifies the issue of insufficient focus on source
  context in decoder-only large language models (LLMs) when applied to machine translation,
  leading to unfaithful translations. The authors propose three methods to address
  this: 1) reweight attention to adjust source context attention weights, 2) contrastive
  decoding to suppress irrelevant target prefix influence, and 3) target-constrained
  tuning to prevent over-reliance on target prefixes during instruction tuning.'
---

# Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model

## Quick Facts
- arXiv ID: 2406.07036
- Source URL: https://arxiv.org/abs/2406.07036
- Reference count: 40
- Primary result: Proposed methods improve BLEU by 2.1 points and COMET by 4.7 points over vanilla zeroshot prompting

## Executive Summary
This paper identifies insufficient focus on source context as a key cause of unfaithful translations in decoder-only LLMs. The authors propose three complementary methods - reweight attention, contrastive decoding, and target-constrained tuning - to enhance source context attention and reduce hallucinations. Experiments show substantial improvements in both automatic metrics and human evaluations across multiple language pairs and domains.

## Method Summary
The paper presents three novel approaches to improve translation faithfulness by enhancing source context attention in decoder-only LLMs. First, reweight attention adjusts attention weights to emphasize source context during decoding. Second, contrastive decoding suppresses irrelevant target prefix influence by comparing multiple decoding candidates. Third, target-constrained tuning modifies the instruction tuning process to prevent over-reliance on target prefixes. These methods can be used individually or in combination to address the root cause of unfaithful translations.

## Key Results
- Reweight attention improves BLEU scores by 2.1 points and COMET scores by 4.7 points over vanilla zeroshot prompting
- Target-constrained tuning outperforms vanilla instruction tuning with an average gain of 1.05 BLEU and 0.58 COMET points
- Human evaluation confirms significant reduction in hallucinatory translations and improved faithfulness to source context

## Why This Works (Mechanism)
The methods work by directly addressing the core issue of insufficient source context attention in decoder-only LLMs. By reweighting attention, suppressing target prefix influence, and constraining training objectives, the model learns to prioritize source information during translation generation. This results in more faithful translations that better preserve the original meaning while reducing hallucinations.

## Foundational Learning

1. **Decoder-only LLM Architecture** - Needed because translation requires generation without explicit encoder context; Quick check: Verify model uses only transformer decoder blocks

2. **Attention Mechanisms** - Critical for understanding how models weigh source vs target information; Quick check: Confirm attention weights can be modified during inference

3. **Contrastive Learning** - Enables comparison between different decoding candidates; Quick check: Validate multiple candidates can be generated and scored

4. **Instruction Tuning** - Understanding how models learn translation tasks; Quick check: Verify model was fine-tuned with translation instructions

5. **BLEU and COMET Metrics** - Standard evaluation metrics for translation quality; Quick check: Confirm metrics align with human judgment

6. **Hallucination Detection** - Identifying when translations introduce unsupported content; Quick check: Validate synthetic test sets capture real translation errors

## Architecture Onboarding

Component Map: Input Text -> Attention Mechanism -> Reweight Layer -> Contrastive Decoder -> Target-Constrained Tuner -> Output Translation

Critical Path: Source text flows through modified attention layers, undergoes contrastive decoding comparisons, and benefits from target-constrained training to produce faithful translations.

Design Tradeoffs: The methods trade computational efficiency for improved faithfulness, with reweight attention and contrastive decoding adding inference overhead but providing significant quality gains.

Failure Signatures: Insufficient source attention, over-reliance on target prefixes, and hallucination generation indicate where these methods would be most beneficial.

First Experiments:
1. Baseline translation with vanilla zeroshot prompting to establish performance floor
2. Individual method implementation (reweight attention only) to measure isolated impact
3. Full pipeline with all three methods combined to assess cumulative benefits

## Open Questions the Paper Calls Out

None

## Limitations
- Evaluation relies heavily on synthetic unfaithful translation data that may not reflect real-world complexity
- Proposed methods introduce additional computational overhead during inference
- Experiments focus primarily on specific language pairs and domains, limiting generalizability
- Limited analysis of method interactions and potential trade-offs between faithfulness and fluency

## Confidence

High confidence in the identification of source context insufficiency as a root cause of unfaithful translations

Medium confidence in the effectiveness of the proposed methods based on experimental results

Medium confidence in the human evaluation findings due to limited sample size and potential rater bias

Low confidence in the long-term robustness and generalization across diverse translation scenarios

## Next Checks

1. Conduct extensive human evaluation across multiple language pairs and domains to verify robustness of the proposed methods

2. Perform ablation studies to quantify the individual contributions of each method and their potential interactions

3. Evaluate the computational overhead and latency impact of the proposed methods in real-world deployment scenarios