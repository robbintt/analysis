---
ver: rpa2
title: Adversarial Training via Adaptive Knowledge Amalgamation of an Ensemble of
  Teachers
arxiv_id: '2405.13324'
source_url: https://arxiv.org/abs/2405.13324
tags:
- adversarial
- samples
- training
- at-aka
- teachers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses two key challenges in adversarial training
  (AT): poor robustness in smaller models and limited generalization to unseen attacks
  due to lack of diversity in adversarial samples. To tackle these issues, the authors
  propose Adversarial Training via Adaptive Knowledge Amalgamation of an Ensemble
  of Teachers (AT-AKA).'
---

# Adversarial Training via Adaptive Knowledge Amalgamation of an Ensemble of Teachers

## Quick Facts
- **arXiv ID**: 2405.13324
- **Source URL**: https://arxiv.org/abs/2405.13324
- **Reference count**: 40
- **Primary result**: AT-AKA outperforms state-of-the-art adversarial training methods on CIFAR-10/100 while maintaining high clean accuracy

## Executive Summary
The paper addresses two key challenges in adversarial training (AT): poor robustness in smaller models and limited generalization to unseen attacks due to lack of diversity in adversarial samples. To tackle these issues, the authors propose Adversarial Training via Adaptive Knowledge Amalgamation of an Ensemble of Teachers (AT-AKA). This method uses Stein Variational Gradient Descent (SVGD) to generate diverse adversarial samples, which are fed into an ensemble of teacher models. The logits of these teachers are then adaptively amalgamated to train a robust student model. The authors also introduce Collaborative AT-AKA (CAT-AKA), which extends the framework to collaborative knowledge distillation. Experiments on CIFAR-10 and CIFAR-100 datasets demonstrate that AT-AKA outperforms state-of-the-art methods in terms of adversarial robustness while maintaining high clean accuracy.

## Method Summary
AT-AKA addresses limitations in adversarial training by combining SVGD-generated diverse adversarial samples with ensemble knowledge distillation. The method generates diverse adversarial examples using SVGD with Gaussian RBF kernel, trains multiple teacher models on these diverse samples, and then adaptively amalgamates the teachers' logits to train a robust student model. The adaptive amalgamation can use either soft combination or Pareto-optimal weighting schemes. CAT-AKA extends this to collaborative settings where multiple students learn simultaneously from the ensemble. The approach is evaluated on CIFAR-10 and CIFAR-100 using ResNet-18 and MobileNetV2 as students, with WideResNet-34-10 or WideResNet-70-16 as teachers.

## Key Results
- AT-AKA achieves significant improvements in robustness against various attacks including AutoAttack compared to traditional AT methods
- The method maintains high clean accuracy while improving adversarial robustness, addressing the typical trade-off in AT
- Experiments show that the diversity introduced by SVGD-generated samples leads to better generalization to unseen attacks
- AT-AKA outperforms adversarial robustness distillation techniques while being more computationally efficient

## Why This Works (Mechanism)
The core mechanism works by addressing the fundamental limitation of standard adversarial training: the lack of diversity in adversarial examples. By using SVGD to generate diverse adversarial samples, AT-AKA ensures that the ensemble of teachers sees a broader range of perturbations, leading to more robust feature representations. The adaptive amalgamation of teacher logits then allows the student to learn from the complementary strengths of each teacher, rather than being limited to a single teacher's perspective. This ensemble approach effectively captures multiple modes of adversarial robustness, which translates to better generalization against unseen attacks.

## Foundational Learning
- **Stein Variational Gradient Descent (SVGD)**: A non-parametric inference method that uses gradient-based updates to transform a set of particles to match a target distribution. Why needed: To generate diverse adversarial samples rather than the deterministic samples produced by standard attacks. Quick check: Generated samples should show high pairwise diversity (measured by l∞ distances).

- **Knowledge Distillation**: A technique where a student model learns from the softened logits of a teacher model. Why needed: To transfer robustness from larger teacher models to smaller student models efficiently. Quick check: Student should achieve similar or better robustness than teachers while being more parameter-efficient.

- **Adaptive Logit Amalgamation**: Combining multiple teachers' outputs using weighted combinations based on their relative strengths. Why needed: To leverage the complementary robustness properties of different teachers rather than relying on a single teacher. Quick check: Different weighting schemes should yield measurable performance differences.

- **Collaborative Learning**: Multiple models learning simultaneously from shared knowledge. Why needed: To extend the benefits of knowledge amalgamation to multiple students in distributed settings. Quick check: All students should show improved robustness compared to individual training.

## Architecture Onboarding

**Component Map**: SVGD Generator -> Teacher Ensemble -> Adaptive Amalgamation -> Student Training

**Critical Path**: Clean data → SVGD (generate diverse adversarial samples) → Teacher training (each on different SVGD samples) → Logit amalgamation (soft/Pareto-optimal) → Student training (distill amalgamated knowledge)

**Design Tradeoffs**: The method trades computational cost of training multiple teachers for improved student robustness. Using SVGD adds complexity compared to standard PGD but provides diversity benefits. The choice between soft and Pareto-optimal amalgamation involves balancing simplicity with potential performance gains.

**Failure Signatures**: Poor diversity in adversarial samples (indicated by low pairwise l∞ distances between SVGD samples), vanishing gradients during logit amalgamation (teacher losses collapsing to similar values), or student robustness not exceeding that of individual teachers.

**First Experiments**: 1) Generate SVGD adversarial samples and verify diversity exceeds standard PGD samples, 2) Train individual teachers and measure their distinct robustness profiles, 3) Implement and test simple soft amalgamation before moving to Pareto-optimal schemes.

## Open Questions the Paper Calls Out
### Open Question 1
- **Question**: How does the performance of AT-AKA vary with different kernel functions in SVGD, and what is the optimal kernel choice for maximizing adversarial robustness?
- **Basis in paper**: The paper uses Gaussian RBF kernel in SVGD and mentions that when deploying Gaussian RBF kernel, by letting the kernel width approach +∞, the update formula of SVGD asymptotically reduces to gradient descent.
- **Why unresolved**: The paper does not explore the impact of different kernel functions on the performance of AT-AKA, leaving open the question of whether other kernels could yield better robustness.
- **What evidence would resolve it**: Empirical results comparing the adversarial robustness of AT-AKA using various kernel functions (e.g., Gaussian RBF, Laplace, polynomial) would provide insight into the optimal kernel choice.

### Open Question 2
- **Question**: What is the effect of the number of adversarial samples generated by SVGD on the robustness of the student model, and is there an optimal number that balances computational efficiency and adversarial robustness?
- **Basis in paper**: The paper generates a set of adversarial samples using SVGD and feeds them to an ensemble of teachers, but does not investigate how the number of samples affects the final robustness.
- **Why unresolved**: The paper does not provide an analysis of how varying the number of adversarial samples impacts the robustness of the student model, leaving this as an open question.
- **What evidence would resolve it**: Experiments that vary the number of adversarial samples generated by SVGD and measure the resulting adversarial robustness of the student model would clarify the relationship between sample number and robustness.

### Open Question 3
- **Question**: How does the performance of AT-AKA compare to other ensemble methods that use diverse adversarial samples, such as those based on different attack algorithms or data augmentation techniques?
- **Basis in paper**: The paper mentions that previous studies have utilized ensembles of sub-models to generate diverse adversarial examples but notes that these methods still face challenges in achieving the desired level of robustness.
- **Why unresolved**: The paper does not directly compare AT-AKA to other ensemble methods that also aim to generate diverse adversarial samples, leaving open the question of how AT-AKA stacks up against these alternatives.
- **What evidence would resolve it**: Comparative experiments between AT-AKA and other ensemble methods that use diverse adversarial samples (e.g., different attack algorithms, data augmentation) would provide insight into the relative performance of these approaches.

## Limitations
- Critical implementation details like exact SVGD iteration counts and temperature parameters are not fully specified, limiting reproducibility
- The method requires training multiple teacher models, increasing computational cost compared to standard AT
- The paper does not explore how AT-AKA performs on larger datasets or more diverse model architectures beyond CIFAR experiments

## Confidence

**High**: The core conceptual framework combining SVGD diversity with ensemble knowledge distillation is well-explained and methodologically sound.

**Medium**: The overall experimental setup and benchmark selection are appropriate, though some implementation specifics are missing.

**Low**: Exact parameter choices for SVGD iterations, temperature scaling in soft targets, and specific data augmentation details are not provided.

## Next Checks
1. Verify that SVGD-generated adversarial samples show significantly higher pairwise diversity (measured by l∞ distances) compared to standard PGD-generated samples before proceeding with teacher training.
2. Monitor teacher loss values during amalgamation to ensure they remain distinct enough for meaningful adaptive weighting - losses that collapse to similar values would indicate poor diversity or training instability.
3. Compare the student's clean accuracy vs. robust accuracy trade-off against standard AT baselines to ensure the proposed method doesn't sacrifice generalization for robustness.