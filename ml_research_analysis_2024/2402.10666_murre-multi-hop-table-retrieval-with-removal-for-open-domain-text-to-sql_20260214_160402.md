---
ver: rpa2
title: 'MURRE: Multi-Hop Table Retrieval with Removal for Open-Domain Text-to-SQL'
arxiv_id: '2402.10666'
source_url: https://arxiv.org/abs/2402.10666
tags:
- tables
- table
- question
- retrieval
- murre
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MURRE addresses the problem of retrieving relevant tables for open-domain
  text-to-SQL by overcoming schema linking limitations in single-hop retrieval methods,
  specifically the issues of similar irrelevant entities and domain mismatch. The
  core method employs multi-hop retrieval with removal, where previously retrieved
  information is removed from the question to guide the retriever toward unretrieved
  relevant tables, combined with question rewriting using LLM to reduce domain gaps.
---

# MURRE: Multi-Hop Table Retrieval with Removal for Open-Domain Text-to-SQL

## Quick Facts
- **arXiv ID:** 2402.10666
- **Source URL:** https://arxiv.org/abs/2402.10666
- **Reference count:** 6
- **Primary result:** MURRE achieves new state-of-the-art results with an average improvement of 6.38% in retrieval performance for open-domain text-to-SQL tasks.

## Executive Summary
MURRE introduces a novel multi-hop table retrieval approach with removal strategy to address the limitations of single-hop retrieval methods in open-domain text-to-SQL tasks. The method specifically tackles schema linking challenges caused by similar irrelevant entities and domain mismatches by iteratively removing retrieved information from questions and rewriting queries to guide retrievers toward previously missed relevant tables. Through extensive experiments on SpiderUnion and BirdUnion+ datasets, MURRE demonstrates significant improvements in retrieval performance, achieving state-of-the-art results and highlighting the effectiveness of its multi-hop approach in overcoming traditional schema linking limitations.

## Method Summary
MURRE employs a multi-hop retrieval framework that iteratively refines table search through three key components: removal, question rewriting, and beam search. The removal component eliminates previously retrieved information from the question to guide the retriever toward unretrieved relevant tables. Question rewriting using LLM reduces domain gaps by reformulating queries to better match table schema language. Beam search maintains multiple retrieval lists at each hop, focusing on low-ranked tables that might contain relevant information missed in single-hop approaches. This combination effectively addresses the schema linking limitations of single-hop methods by ensuring comprehensive table coverage and reducing the impact of similar irrelevant entities.

## Key Results
- Achieved new state-of-the-art results with an average improvement of 6.38% in retrieval performance
- Demonstrated effectiveness in overcoming schema linking limitations in open-domain text-to-SQL tasks
- Showed significant improvements on both SpiderUnion and BirdUnion+ benchmark datasets

## Why This Works (Mechanism)
MURRE's effectiveness stems from its ability to iteratively refine table retrieval by removing already-retrieved information from questions, which prevents the retriever from repeatedly selecting the same tables and guides it toward previously missed relevant ones. The question rewriting component bridges domain gaps by using LLM to reformulate queries in terms that better match table schema language. Beam search maintains multiple retrieval paths, ensuring that potentially relevant tables that might be overlooked in single-hop approaches are not missed. This combination addresses the fundamental limitations of single-hop retrieval where similar irrelevant entities and domain mismatches prevent effective schema linking.

## Foundational Learning
1. **Multi-hop retrieval** - Why needed: Single-hop methods struggle with complex queries requiring information from multiple sources. Quick check: Verify retrieval accuracy improves with additional hops.
2. **Question rewriting with LLM** - Why needed: Domain mismatches between natural language queries and table schema terminology reduce retrieval effectiveness. Quick check: Compare retrieval performance with and without rewriting.
3. **Beam search for retrieval** - Why needed: Single-best retrieval lists may miss relevant tables. Quick check: Measure coverage improvement with multiple retrieval lists.
4. **Information removal strategy** - Why needed: Prevents repeated selection of same tables and guides toward new relevant ones. Quick check: Track diversity of retrieved tables across hops.

## Architecture Onboarding
**Component Map:** Query -> Multi-Hop Retriever -> Removal Module -> Question Rewriter -> Beam Search -> Retrieved Tables
**Critical Path:** The core pipeline follows: original query → first hop retrieval → information removal → query rewriting → subsequent hops → final table set
**Design Tradeoffs:** The removal strategy must balance eliminating irrelevant information while preserving semantic context; beam search increases coverage but also computational cost
**Failure Signatures:** Retrieval may fail if removal eliminates too much context, if rewriting introduces domain biases, or if beam search ranking function poorly captures semantic relationships
**First 3 Experiments to Run:**
1. Ablation study removing each component (removal, rewriting, beam search) to quantify individual contributions
2. Test performance on datasets with varying domain distributions to assess generalization
3. Evaluate downstream impact on text-to-SQL generation accuracy and execution correctness

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Reliance on heuristic removal strategies may not effectively eliminate irrelevant information while preserving semantic context
- LLM-based question rewriting could introduce domain-specific biases or fail to adequately bridge domain gaps for complex queries
- Performance improvements need evaluation for practical significance in downstream text-to-SQL generation quality

## Confidence
- **High confidence:** Multi-hop retrieval with removal effectively improves schema linking in open-domain text-to-SQL
- **Medium confidence:** Question rewriting strategy consistently reduces domain gaps across diverse queries
- **Medium confidence:** Beam search maintaining multiple retrieval lists improves coverage of relevant tables
- **Low confidence:** Scalability to extremely large table corpora or highly complex multi-hop queries

## Next Checks
1. Conduct ablation studies to quantify individual contributions of removal, question rewriting, and beam search components
2. Test MURRE on additional open-domain text-to-SQL datasets with varying domain distributions
3. Evaluate impact of MURRE's improved retrieval on actual text-to-SQL generation accuracy and execution correctness