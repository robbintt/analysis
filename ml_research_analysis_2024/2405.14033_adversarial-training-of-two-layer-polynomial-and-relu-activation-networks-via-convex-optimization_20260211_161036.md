---
ver: rpa2
title: Adversarial Training of Two-Layer Polynomial and ReLU Activation Networks via
  Convex Optimization
arxiv_id: '2405.14033'
source_url: https://arxiv.org/abs/2405.14033
tags:
- convex
- training
- adversarial
- networks
- polynomial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper develops a convex semidefinite program (SDP) for adversarial\
  \ training of two-layer polynomial activation neural networks. The key contribution\
  \ is proving that this convex formulation achieves the same globally optimal solution\
  \ as its nonconvex counterpart while improving robust test accuracy against \u2113\
  \u221E attacks."
---

# Adversarial Training of Two-Layer Polynomial and ReLU Activation Networks via Convex Optimization

## Quick Facts
- arXiv ID: 2405.14033
- Source URL: https://arxiv.org/abs/2405.14033
- Reference count: 40
- One-line primary result: Convex SDP formulation for adversarial training achieves same globally optimal solution as nonconvex counterpart while improving robust test accuracy

## Executive Summary
This paper develops a convex semidefinite program (SDP) for adversarial training of two-layer polynomial activation neural networks. The key contribution is proving that this convex formulation achieves the same globally optimal solution as its nonconvex counterpart while improving robust test accuracy against ℓ∞ attacks. The authors provide exact solvers for small-scale problems and scalable PyTorch implementations for both polynomial and ReLU networks. Empirical results show that retraining the final two layers of a Pre-Activation ResNet-18 model with their convex adversarial training achieves significantly higher robust test accuracies than sharpness-aware minimization.

## Method Summary
The authors reformulate adversarial training as a convex SDP using the S-procedure and neural decomposition techniques. For polynomial activation networks, they prove that the convex formulation achieves the same globally optimal solution as the nonconvex problem. For ReLU networks, they extend the approach using a polynomial approximation to ReLU and sampling sign patterns. The method involves solving a semidefinite program to find optimal weights and worst-case perturbations, then recovering the neural network weights through neural decomposition.

## Key Results
- The convex SDP formulation achieves the same globally optimal solution as its nonconvex counterpart for polynomial activation networks
- Retraining the final two layers of Pre-Activation ResNet-18 with convex adversarial training achieves higher robust test accuracy than SAM
- PyTorch implementation scales to large datasets while maintaining competitive performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The convex SDP formulation achieves the same globally optimal solution as the nonconvex adversarial training problem
- Mechanism: The paper uses the S-procedure (a duality result for quadratic constraints) to convert the nonconvex adversarial training constraints into convex semidefinite constraints, while maintaining equivalence through Lagrange duality
- Core assumption: The neural decomposition procedure from Bartan & Pilanci (2021) can be applied to recover the optimal neural network weights from the optimal SDP solutions
- Evidence anchors:
  - [abstract]: "prove that the convex SDP achieves the same globally optimal solution as its nonconvex counterpart"
  - [section 3.1]: "We propose a convex reformulation of (10), which is solvable to global optimality in fully polynomial time"
  - [corpus]: Weak evidence - the corpus papers discuss related convex formulations but don't directly address the equivalence proof
- Break condition: If the S-procedure conditions are violated (strict feasibility not satisfied) or if the neural decomposition procedure fails to recover valid weights

### Mechanism 2
- Claim: The convex formulation provides a lower bound on the optimal value of the nonconvex problem, which is then shown to be tight
- Mechanism: Through Lagrangian duality, the paper derives the dual problem of the nonconvex formulation, which turns out to be the proposed convex SDP. The optimal value of this dual problem provides a lower bound, and the neural decomposition shows this bound is achievable
- Core assumption: The Lagrangian dual of the relaxed nonconvex problem has the same optimal value as the original nonconvex problem
- Evidence anchors:
  - [section 3.1]: "we obtain (23), which is the dual to the inner problem of (21)"
  - [section 3.1]: "we recover the proposed convex adversarial training problem (11)"
  - [corpus]: No direct evidence in corpus - this is a specific duality argument not covered by related papers
- Break condition: If the duality gap is non-zero or if the relaxation in the nonconvex problem changes the optimal value

### Mechanism 3
- Claim: The convex formulation enables efficient computation of the distance to the decision boundary
- Mechanism: By reformulating the distance to the decision boundary as a convex optimization problem using the S-procedure, the paper enables exact computation in polynomial time for polynomial activation networks
- Core assumption: The decision boundary constraint yf(γ) ≤ 0 can be relaxed without changing the optimal value of the distance computation
- Evidence anchors:
  - [section C]: "We define the ℓ2-distance from an example x to D... For an example x with label y, suppose that f correctly classifies x"
  - [section C]: "Recognizing that γ∗ = arg minγ:yf(γ)≤0 ||x − γ||2 = arg minγ:yf(γ)≤0 ||x − γ||22"
  - [corpus]: Weak evidence - related papers discuss decision boundaries but not this specific convex formulation approach
- Break condition: If the classifier doesn't take on both positive and negative values, making the strict feasibility assumption invalid

## Foundational Learning

- Concept: Convex optimization and semidefinite programming
  - Why needed here: The entire approach relies on reformulating nonconvex problems as convex SDPs, requiring understanding of convex duality, S-procedure, and semidefinite constraints
  - Quick check question: What conditions must be satisfied for the S-procedure to convert quadratic constraints into semidefinite constraints?

- Concept: Neural decomposition for two-layer networks
  - Why needed here: The paper uses neural decomposition to recover the optimal neural network weights from the SDP solution, which is crucial for the equivalence proof
  - Quick check question: How does the neural decomposition procedure recover the original network weights from the Z and Z' matrices?

- Concept: Adversarial training and robustness metrics
  - Why needed here: Understanding why minimizing the worst-case output in ℓ2 balls around training examples leads to robust classifiers
  - Quick check question: What does it mean for a classifier to have positive worst-case output wi for a training example?

## Architecture Onboarding

- Component map:
  - Input layer: Training data (X, y) and hyperparameters (r, β)
  - Core optimization: Convex SDP formulation (11) for polynomial networks or (15) for ReLU networks
  - Output layer: Optimal weights {uj, αj} and worst-case outputs w
  - Integration layer: Replacing final layers of deep networks (e.g., ResNet-18)
  - Evaluation layer: Robust accuracy testing against ℓ∞ attacks

- Critical path:
  1. Preprocess data and choose hyperparameters
  2. Solve convex SDP to optimality using exact solver (small scale) or PyTorch implementation (large scale)
  3. Recover neural network weights using neural decomposition
  4. Integrate into larger network architecture if needed
  5. Evaluate robust accuracy against adversarial attacks

- Design tradeoffs:
  - Exact solvers (CVXPY) provide global optimality but don't scale to large problems
  - PyTorch implementations scale but may have constraint violations requiring penalty terms
  - Polynomial vs ReLU: Polynomial networks work better with limited data, ReLU networks scale better
  - Choice of r (robust radius) affects both robustness and clean accuracy

- Failure signatures:
  - Constraint violations in PyTorch implementation (check if penalty terms are needed)
  - Poor robust accuracy despite convergence (may indicate insufficient network width m ≥ m*)
  - Degraded clean accuracy (common in adversarial training, may require hyperparameter tuning)
  - Slow convergence in exact solvers (may indicate ill-conditioned problem)

- First 3 experiments:
  1. Small-scale binary classification on Wisconsin Breast Cancer dataset using exact solver, compare clean vs robust accuracy for varying r values
  2. Replace final layer of pre-trained ResNet-18 on CIFAR-10 subset, compare with standard and SAM-trained models
  3. Scale PyTorch implementation to full CIFAR-10, test different values of P (number of sampled sign patterns) for ReLU networks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the convex SDP formulation extend to multi-class classification with polynomial activation networks?
- Basis in paper: [explicit] The authors mention in Section 3.2 that "With further tolerance for unwieldy notation, (7) and (15) can be generalized to the multi-class regime under multimargin loss" but do not provide the formulation.
- Why unresolved: The paper only proves the main theorem (Theorem 3.1) for binary classification and defers the multi-class extension as a possibility without providing details.
- What evidence would resolve it: A complete convex SDP formulation for multi-class polynomial activation networks with proof that it achieves the same optimal value as its nonconvex counterpart.

### Open Question 2
- Question: How does the choice of polynomial coefficients (a=0.09, b=0.5, c=0.47) affect the performance of the convex adversarial training formulation?
- Basis in paper: [explicit] The authors state these coefficients are "chosen so that σ(x) best approximates the ReLU activation function ReLU(x) = max{x, 0} in the least-squares sense" but don't explore sensitivity to this choice.
- Why unresolved: The paper uses fixed coefficients without exploring how different approximations to ReLU might impact robust test accuracy or the properties of the convex reformulation.
- What evidence would resolve it: Empirical results showing robust test accuracy for different polynomial coefficient choices, or theoretical analysis of how coefficient selection affects the convex reformulation's properties.

### Open Question 3
- Question: Can the convex adversarial training approach be extended to deeper neural network architectures?
- Basis in paper: [inferred] The authors demonstrate benefits on two-layer networks and suggest "Future research directions could include layer-wise convex adversarial training for deep neural networks" in the conclusion.
- Why unresolved: The current theoretical results and implementations are limited to two-layer networks, and the paper acknowledges this limitation while suggesting it as future work.
- What evidence would resolve it: A convex formulation for adversarial training of deeper networks (e.g., three or more layers) with proof of global optimality, or empirical results showing the approach's effectiveness on deeper architectures.

## Limitations

- The approach relies on the S-procedure's strict feasibility assumption, which may not hold for all problem instances
- PyTorch implementation may suffer from constraint violations due to numerical precision limitations
- Current results are limited to two-layer networks with no extension to deeper architectures

## Confidence

- Theoretical equivalence proof: **High**
- Practical PyTorch implementation: **Medium**
- Empirical robust accuracy improvements: **Medium**

## Next Checks

1. Verify strict feasibility conditions empirically across diverse datasets and network widths
2. Test constraint satisfaction in the PyTorch implementation using the exact solver as ground truth
3. Evaluate the impact of slack variables on robust accuracy for ReLU networks compared to the theoretically exact polynomial formulation