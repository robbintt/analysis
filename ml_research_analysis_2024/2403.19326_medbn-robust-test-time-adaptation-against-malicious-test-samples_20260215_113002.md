---
ver: rpa2
title: 'MedBN: Robust Test-Time Adaptation against Malicious Test Samples'
arxiv_id: '2403.19326'
source_url: https://arxiv.org/abs/2403.19326
tags:
- medbn
- attack
- samples
- layer
- malicious
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the vulnerability of test-time adaptation (TTA)
  methods to data poisoning attacks, where malicious samples manipulate batch normalization
  statistics to degrade model performance. The authors propose Median Batch Normalization
  (MedBN), which uses the median instead of the mean to estimate batch statistics,
  providing robustness against adversarial manipulation.
---

# MedBN: Robust Test-Time Adaptation against Malicious Test Samples

## Quick Facts
- **arXiv ID**: 2403.19326
- **Source URL**: https://arxiv.org/abs/2403.19326
- **Reference count**: 40
- **Primary result**: Median Batch Normalization (MedBN) reduces attack success rates by up to 98% while maintaining comparable performance without attacks

## Executive Summary
This paper addresses the vulnerability of test-time adaptation (TTA) methods to data poisoning attacks, where malicious samples manipulate batch normalization statistics to degrade model performance. The authors propose Median Batch Normalization (MedBN), which uses the median instead of the mean to estimate batch statistics, providing robustness against adversarial manipulation. Experiments on CIFAR10-C, CIFAR100-C, and ImageNet-C datasets show that MedBN significantly improves robustness against targeted and indiscriminate attacks, reducing attack success rates by up to 98% and error rates by up to 12%, while maintaining comparable performance without attacks. The method is algorithm-agnostic and easily integrates with existing TTA frameworks.

## Method Summary
The paper proposes Median Batch Normalization (MedBN) as a robust alternative to standard batch normalization for test-time adaptation. MedBN replaces the mean-based calculation of batch statistics with median-based estimation: η_c = median{z_bchw} and ρ²_c = mean{(z_bchw - η_c)²}. This modification prevents malicious samples from disproportionately influencing normalization parameters while maintaining adaptation performance. The method integrates seamlessly with existing TTA frameworks like TeBN, TENT, ETA, SAR, SoTTA, sEMA, and mDIA without requiring additional training.

## Key Results
- MedBN reduces attack success rates by up to 98% against data poisoning attacks
- Error rates improve by up to 12% under indiscriminate attacks while maintaining comparable performance without attacks
- The method is algorithm-agnostic and integrates with existing TTA frameworks
- Robustness holds across multiple datasets (CIFAR10-C, CIFAR100-C, ImageNet-C) and attack scenarios (targeted/indiscriminate, instant/cumulative)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Replacing mean with median in batch normalization statistics estimation makes the method robust against adversarial manipulation.
- Mechanism: The median is statistically robust to outliers, while the mean can be arbitrarily shifted by even a single malicious sample. By using median instead of mean for estimating batch statistics, the method prevents malicious samples from disproportionately influencing the normalization parameters.
- Core assumption: The benign samples in the batch will constitute at least 50% of the data, making the median resistant to manipulation.

### Mechanism 2
- Claim: The method maintains performance in benign scenarios while providing robustness against attacks.
- Mechanism: The median provides a robust estimate of the central tendency of the batch statistics without introducing significant bias when the batch contains mostly benign samples. This allows the model to maintain adaptation performance while being resistant to attacks.

### Mechanism 3
- Claim: The method can be integrated with existing TTA frameworks without requiring additional training.
- Mechanism: The median-based normalization replaces the mean-based calculation in existing batch normalization layers, making it a drop-in replacement that works with any TTA method that adapts BN layers.

## Foundational Learning

- **Statistical robustness and outlier resistance**
  - Why needed here: Understanding why median is more robust than mean to adversarial manipulation
  - Quick check question: If a batch contains 40 benign samples and 10 malicious samples, which statistic (mean or median) would be more affected by the malicious samples?

- **Batch normalization in neural networks**
  - Why needed here: Understanding how batch normalization works and why it's commonly adapted in TTA
  - Quick check question: In batch normalization, what are the two statistics that are typically estimated from the batch?

- **Data poisoning attacks**
  - Why needed here: Understanding the threat model and how malicious samples can manipulate model behavior
  - Quick check question: What is the primary goal of a data poisoning attack in the context of test-time adaptation?

## Architecture Onboarding

- **Component map**: Input layer → Feature extraction → Batch normalization (median-based) → Activation → Subsequent layers
- **Critical path**: Data enters batch normalization layer → Statistics are calculated using median instead of mean → Normalized features are passed to subsequent layers → Model adaptation occurs based on these normalized features
- **Design tradeoffs**: Computational overhead: Median calculation is slightly more expensive than mean calculation; Statistical accuracy: Median may be less precise than mean for normally distributed data; Robustness: Median provides significant protection against adversarial manipulation
- **Failure signatures**: If the batch contains >50% malicious samples, the median can be manipulated; If the benign data distribution is highly non-normal, the median may not provide optimal normalization; Integration issues may arise with TTA methods that don't use batch normalization
- **First 3 experiments**: 1) Replace mean with median in batch normalization of a simple CNN and test on CIFAR10-C without attacks to verify performance parity; 2) Introduce malicious samples (10-20% of batch) and measure the shift in batch statistics for both mean and median approaches; 3) Integrate the median-based BN into a TTA method like TeBN and test robustness against targeted attacks on CIFAR10-C

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the Median Batch Normalization (MedBN) method maintain its robustness against data poisoning attacks when the proportion of malicious samples in a batch exceeds 50%?
- Basis in paper: The paper states that "The median is robust against malicious samples unless they are not the majority, i.e., for any 1 ≤ m < n/2" in Theorem 1.
- Why unresolved: The paper only considers attack scenarios with up to 40 malicious samples out of 200 total, which is less than 20% of the batch. The robustness of MedBN when the majority of samples are malicious is not explored.

### Open Question 2
- Question: How does the performance of MedBN compare to other robust batch normalization techniques, such as those using the median absolute deviation (MAD), across different types of distribution shifts and attack scenarios?
- Basis in paper: The paper mentions that using MAD shows strong defense but substantial performance drop in Section 5.1.
- Why unresolved: While the paper briefly mentions MAD, it does not provide a comprehensive comparison of MedBN with other robust normalization techniques across various benchmarks and attack scenarios.

### Open Question 3
- Question: Can the principles of MedBN be extended to other normalization layers beyond batch normalization, such as layer normalization or group normalization, to provide robustness against data poisoning attacks in different neural network architectures?
- Basis in paper: The paper focuses on batch normalization layers and their vulnerability to data poisoning attacks. The theoretical analysis and proposed solution are specific to batch normalization.

## Limitations

- The method's robustness depends on benign samples constituting at least 50% of the batch; if malicious samples dominate, the median can be manipulated
- Performance against attack types beyond Distribution Invading Attack (DIA) is not explicitly evaluated
- Computational overhead of median calculation, while mentioned as slight, is not quantified

## Confidence

**High Confidence**: The core mechanism of using median instead of mean for batch normalization statistics is well-established in robust statistics literature and the theoretical analysis in the paper is sound. The improvement in attack success rate reduction (up to 98%) is convincingly demonstrated through extensive experiments.

**Medium Confidence**: The claim that MedBN maintains comparable performance to standard BN in benign scenarios is supported by experimental results, but the paper could benefit from more diverse testing conditions to fully validate this across different distributions and corruption types.

**Low Confidence**: The generalizability of the method to other types of adversarial attacks beyond DIA is uncertain, as the paper focuses primarily on one attack vector. The long-term effectiveness against adaptive attackers who may develop strategies to overcome median-based defenses remains an open question.

## Next Checks

1. **Batch Composition Analysis**: Systematically test MedBN performance when malicious samples constitute 40%, 45%, 48%, and 49% of the batch to identify the exact threshold where robustness begins to degrade.

2. **Cross-Attack Evaluation**: Implement and evaluate MedBN against at least two additional data poisoning attack methods (e.g., feature collision attacks, label flipping attacks) to assess generalizability beyond DIA.

3. **Computational Overhead Measurement**: Conduct precise benchmarking to measure the actual computational overhead introduced by median calculation compared to mean calculation across different batch sizes and hardware configurations.