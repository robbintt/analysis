---
ver: rpa2
title: A Geometric Explanation of the Likelihood OOD Detection Paradox
arxiv_id: '2403.18910'
source_url: https://arxiv.org/abs/2403.18910
tags: []
core_contribution: This work investigates why likelihood-based deep generative models
  (DGMs) often assign higher likelihoods to out-of-distribution (OOD) data from simpler
  sources, despite never generating such data. The authors explain this paradox by
  showing that OOD data from simpler manifolds concentrates in regions of low probability
  mass.
---

# A Geometric Explanation of the Likelihood OOD Detection Paradox

## Quick Facts
- arXiv ID: 2403.18910
- Source URL: https://arxiv.org/abs/2403.18910
- Reference count: 40
- Primary result: Likelihood-based DGMs assign high likelihoods to OOD data from simpler manifolds due to low probability mass concentration, solved via dual thresholding on likelihood and local intrinsic dimension

## Executive Summary
This work resolves the paradox where likelihood-based deep generative models (DGMs) assign higher likelihoods to out-of-distribution (OOD) data from simpler sources, despite never generating such data. The authors show this occurs because OOD data from simpler manifolds concentrates in regions of low probability mass, even when assigned high likelihood. To detect OOD samples, they propose combining likelihood estimates with local intrinsic dimension (LID) estimates obtained from a pre-trained DGM. Their dual-threshold method classifies points as OOD if they have either low likelihood or low LID, achieving state-of-the-art OOD detection performance on standard benchmarks.

## Method Summary
The method uses pre-trained normalizing flows or score-based diffusion models to estimate both log-likelihood pθ(x) and local intrinsic dimension (LID) for OOD detection. LID is estimated by computing the rank of the Jacobian matrix (for NFs) or score function matrix (for DMs) and applying singular value thresholding. Points are classified as OOD if either the likelihood is below threshold ψL or the LID is below threshold ψLID. The LID threshold is calibrated using LPCA on training data to ensure LID estimates match intrinsic dimension estimates from a linear method.

## Key Results
- OOD data from simpler manifolds concentrates in low-probability-mass regions even when assigned high likelihood
- LID estimates identify regions of low probability mass, enabling detection of pathological high-likelihood OOD cases
- Dual-threshold method (likelihood + LID) achieves state-of-the-art OOD detection performance, matching or surpassing single-threshold likelihood baselines on FMNIST vs MNIST, CIFAR10 vs SVHN, and other standard benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** OOD data from simpler manifolds concentrates in low-probability-mass regions even when assigned high likelihood
- **Mechanism:** Simpler OOD manifolds have lower intrinsic dimension, allowing pθ to assign high density while maintaining negligible probability mass due to the vanishing volume of low-dimensional regions
- **Core assumption:** The manifold hypothesis holds—natural data lies on low-dimensional submanifolds of the ambient space
- **Evidence anchors:** [abstract] "Our primary observation is that high-likelihood regions will not be generated if they contain minimal probability mass." [section] "Our key insight is that when OOD data is 'simpler' in the sense that it concentrates on a manifold of lower dimension than in-distribution data, the phenomenon depicted in Figure 1 becomes completely consistent with empirical observations."
- **Break condition:** If the manifold hypothesis fails (data is not concentrated on low-dimensional manifolds), this mechanism breaks

### Mechanism 2
- **Claim:** Local Intrinsic Dimension (LID) estimates identify regions of low probability mass
- **Mechanism:** LIDθ(x) is inversely related to the contiguous volume assigned by pθ around x. Small LIDθ(x) implies negligible probability mass even if pθ(x) is large, enabling OOD detection
- **Core assumption:** LID can be estimated from a pre-trained DGM without requiring access to OOD samples
- **Evidence anchors:** [abstract] "We also show that this scenario can be identified through local intrinsic dimension (LID) estimation." [section] "A small LIDθ(x) makes it possible in practice for pθ(x) to be high, despite pθ assigning negligible probability mass around x."
- **Break condition:** If LID estimation becomes inaccurate (e.g., due to numerical instability or poor model fit), OOD detection performance degrades

### Mechanism 3
- **Claim:** Dual thresholding on likelihood and LID effectively separates OOD from in-distribution data
- **Mechanism:** Classifying points as OOD when either likelihood is low OR LID is small captures both cases where pθ(x) is small (non-pathological) and where pθ(x) is large but probability mass is negligible (pathological)
- **Core assumption:** The combination of high likelihood and large LID indicates non-pathological regions with substantial probability mass
- **Evidence anchors:** [abstract] "Our method can be applied to normalizing flows and score-based diffusion models, and obtains results which match or surpass state-of-the-art OOD detection benchmarks using the same DGM backbones." [section] "We now discuss the situation illustrated in Figure 1... This leads to our proposed dual threshold OOD detection method."
- **Break condition:** If the relationship between likelihood, LID, and probability mass breaks down (e.g., due to model architecture changes), dual thresholding may fail

## Foundational Learning

- **Concept:** Manifold hypothesis
  - Why needed here: The entire geometric explanation relies on data concentrating on low-dimensional manifolds
  - Quick check question: Can you explain why natural image data is expected to lie on low-dimensional manifolds in pixel space?

- **Concept:** Probability mass vs. density
  - Why needed here: The paradox is resolved by distinguishing between high density and low probability mass
  - Quick check question: Why can a density function assign high values to a region while the integrated probability mass over that region remains small?

- **Concept:** Local intrinsic dimension estimation
  - Why needed here: LID is the key geometric feature used to detect OOD data
  - Quick check question: How does the rank of the Jacobian matrix relate to the intrinsic dimension of a manifold?

## Architecture Onboarding

- **Component map:** Pre-trained DGM (NF or DM) -> LID estimator (SVD on Jacobian/score matrix) -> Dual thresholding classifier -> OOD/in-distribution output

- **Critical path:** 1. Load pre-trained DGM 2. Compute log pθ(x) for query point 3. Compute LID estimate dLIDθ(x) using singular value decomposition 4. Compare against calibrated thresholds 5. Return OOD/in-distribution classification

- **Design tradeoffs:**
  - Single vs. dual thresholding: Dual thresholding captures both low-likelihood and low-LID OOD cases but requires tuning two thresholds
  - Constant vs. data-dependent LID threshold: Constant thresholds are simpler but data-dependent thresholds adapt better to different datasets
  - Computational cost: LID estimation via SVD adds overhead but remains tractable for moderate dimensions

- **Failure signatures:**
  - Poor OOD detection when LID estimates collapse to ambient dimension due to insufficient threshold setting
  - False positives when in-distribution data has artificially low LID (e.g., highly structured datasets)
  - Numerical instability in Jacobian computation for points near model boundaries

- **First 3 experiments:**
  1. Verify that log pθ(x) ranks OOD data higher than in-distribution data on a pathological dataset pair
  2. Confirm that LID estimates are consistently lower for OOD data compared to in-distribution data
  3. Test dual thresholding performance on a non-pathological dataset pair where likelihoods alone work correctly

## Open Questions the Paper Calls Out

- **Open Question 1:** How do the inductive biases in diffusion models lead to the pathological behavior of likelihoods on generated samples?
  - Basis in paper: [explicit] The paper notes this as an open question, stating "studying the inductive biases in DMs that lead to this new pathological behaviour of likelihoods on generated data is an interesting open question requiring future research."
  - Why unresolved: While the paper suggests that DMs might prioritize high-frequency features in earlier timesteps (similar to NFs), the evidence presented does not adequately address why generated samples, which should be similar to in-distribution data, also exhibit this pathology
  - What evidence would resolve it: Detailed analysis of the score network's behavior across timesteps, particularly examining the features learned in early timesteps and their impact on likelihoods for generated samples

- **Open Question 2:** Can the dual threshold OOD detection method be extended to energy-based models (EBMs) to match or surpass their state-of-the-art performance?
  - Basis in paper: [inferred] The paper identifies extending the method to EBMs as a "particularly promising direction for future research," noting that EBMs achieve state-of-the-art likelihood-based OOD detection
  - Why unresolved: The current incarnation of the method is limited to NFs and DMs due to the tractability of LID estimation. Extending it to EBMs would require developing new methods for estimating LID from these models
  - What evidence would resolve it: Development and validation of LID estimation techniques for EBMs, followed by experimental results comparing the dual threshold method's performance on EBMs to existing state-of-the-art approaches

- **Open Question 3:** How can the LID estimator for diffusion models be improved to achieve more accurate estimates and better OOD detection performance?
  - Basis in paper: [explicit] The paper states that "the LID estimates from Stanczuk et al. (2022) are not sufficiently accurate" and suggests that "Further improving DM-based LID estimators is a promising avenue to boost performance."
  - Why unresolved: The current LID estimator for DMs, based on the work of Stanczuk et al. (2022), produces estimates that differ significantly from those obtained by other methods, and this discrepancy might impact the performance of the dual threshold method
  - What evidence would resolve it: Development of a new LID estimator for DMs that produces estimates more consistent with established methods, followed by experimental validation showing improved OOD detection performance when using this new estimator with the dual threshold method

## Limitations

- The geometric explanation relies heavily on the manifold hypothesis, which may not hold for all data types
- Dual thresholding requires careful calibration of two hyperparameters, increasing complexity
- Performance improvements over single-threshold methods, while statistically significant, are relatively modest (AUC improvements of 0.02-0.05)

## Confidence

- Geometric explanation of paradox: Medium
- LID estimation effectiveness: Medium
- Dual thresholding performance: High (based on empirical results)

## Next Checks

1. Test the method on real-world distribution shifts (e.g., natural vs. synthetic images) where the relationship between data complexity and manifold dimension is not artificially controlled
2. Evaluate the sensitivity of LID estimates to hyperparameter choices (τ threshold, singular value cutoff) across different datasets
3. Compare against alternative OOD detection methods that don't rely on the manifold hypothesis (e.g., energy-based methods, representation learning approaches)