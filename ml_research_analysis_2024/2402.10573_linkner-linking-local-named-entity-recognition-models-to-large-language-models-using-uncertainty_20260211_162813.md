---
ver: rpa2
title: 'LinkNER: Linking Local Named Entity Recognition Models to Large Language Models
  using Uncertainty'
arxiv_id: '2402.10573'
source_url: https://arxiv.org/abs/2402.10573
tags:
- entity
- linkner
- uncertainty
- local
- entities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LinkNER, a framework that combines fine-tuned
  local NER models with large language models (LLMs) to improve named entity recognition
  performance, especially for unseen entities. The core method uses uncertainty estimation
  to detect difficult entities that the local model cannot confidently classify, then
  routes them to an LLM for classification.
---

# LinkNER: Linking Local Named Entity Recognition Models to Large Language Models using Uncertainty

## Quick Facts
- arXiv ID: 2402.10573
- Source URL: https://arxiv.org/abs/2402.10573
- Authors: Zhen Zhang; Yuhua Zhao; Hang Gao; Mengting Hu
- Reference count: 40
- Primary result: Combines fine-tuned local NER models with LLMs using uncertainty estimation to improve NER performance, especially for unseen entities

## Executive Summary
LinkNER introduces a framework that combines fine-tuned local Named Entity Recognition (NER) models with large language models (LLMs) to improve NER performance, particularly for unseen entities. The core method uses uncertainty estimation to detect difficult entities that the local model cannot confidently classify, then routes them to an LLM for classification. Experiments on standard NER datasets and noisy social media data show LinkNER notably outperforms state-of-the-art models in robustness tests, with improvements of 3.04% to 21.30% F1 score on challenging datasets. The framework demonstrates that uncertainty estimation enables effective collaboration between local models and LLMs, where local models provide entity detection and LLMs handle uncertain entity classification.

## Method Summary
LinkNER fine-tunes a local NER model (SpanNER) with uncertainty estimation methods, then uses a Recognition-Detection-Classification (RDC) strategy to route uncertain entities to LLMs for classification. The framework determines optimal uncertainty thresholds through validation, then combines local model predictions with LLM classifications for final output. The approach leverages in-context learning to enable LLMs to specialize in NER without fine-tuning, while uncertainty estimation serves as the routing mechanism between local models and LLMs.

## Key Results
- LinkNER achieves 3.04% to 21.30% F1 score improvements over state-of-the-art models on challenging datasets
- The framework shows particular effectiveness on noisy social media data (WNUT'17, TweetNER, JNLPBA)
- Multiple uncertainty estimation methods (Confidence, Entropy, Monte Carlo Dropout, Evidential-based learning) are evaluated, with varying performance across datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Uncertainty estimation enables reliable detection of unseen entities for LLM re-classification.
- Mechanism: The local NER model outputs entities with uncertainty scores; entities exceeding a threshold are routed to LLM for re-classification, leveraging LLM's broader knowledge.
- Core assumption: Higher uncertainty correlates with unseen or ambiguous entities.
- Evidence anchors: [abstract] "The core method uses uncertainty estimation to detect difficult entities that the local model cannot confidently classify, then routes them to an LLM for classification."
- Break condition: If uncertainty estimation fails to distinguish unseen entities from seen ones, routing will be ineffective.

### Mechanism 2
- Claim: RDC (Recognition-Detection-Classification) bridges the "lack of knowledge" in local models and "lack of specialty" in LLM.
- Mechanism: Local model handles recognition and detection; LLM handles classification of uncertain entities, making tasks simpler and more accurate.
- Core assumption: LLM excels at classification when provided entity spans and context but struggles with direct NER.
- Evidence anchors: [abstract] "Uncertainty serves as the catalyst for LLM to undergo a paradigm shift in NER tasks, transitioning from entity recognition to entity classification."
- Break condition: If LLM misclassifies despite correct spans, the bridge fails to improve overall performance.

### Mechanism 3
- Claim: In-context learning enables LLM to specialize in NER without fine-tuning.
- Mechanism: Label descriptions and few-shot examples guide LLM to understand entity types and data distribution for accurate classification.
- Core assumption: LLM can learn task-specific patterns from context without parameter updates.
- Evidence anchors: [abstract] "We also quantitatively analyze the influence of key components like uncertainty estimation methods, LLMs, and in-context learning on diverse NER tasks."
- Break condition: If context examples are insufficient or noisy, LLM may not learn the correct classification patterns.

## Foundational Learning

- Concept: Uncertainty quantification in classification
  - Why needed here: Determines when to route entities to LLM for re-classification.
  - Quick check question: What are the differences between confidence-based, sampling-based, and distribution-based uncertainty methods?
- Concept: Span-based NER modeling
  - Why needed here: Local model detects entity boundaries before LLM classification.
  - Quick check question: How does span-based NER differ from token-based NER in handling OOV entities?
- Concept: In-context learning in LLMs
  - Why needed here: Enables LLM to specialize in NER without fine-tuning.
  - Quick check question: What is the impact of few-shot examples on LLM's task performance?

## Architecture Onboarding

- Component map: Local NER model (SpanNER) → Uncertainty estimator → Threshold filter → LLM (GPT-3.5/Llama 2-Chat) → Final aggregation
- Critical path: Input sentence → Local model recognition → Uncertainty calculation → Entity filtering → LLM classification → Output combination
- Design tradeoffs: Higher uncertainty threshold reduces LLM workload but risks missing difficult entities; lower threshold increases LLM workload but improves recall on unseen entities
- Failure signatures: Poor uncertainty estimation → Incorrect routing → LLM overwork or missed entities; insufficient context examples → LLM misclassification despite correct spans
- First 3 experiments:
  1. Compare local model F1 scores with and without uncertainty estimation on CoNLL'03
  2. Test different uncertainty thresholds on CoNLL'03 validation set to find optimal point
  3. Evaluate LLM-only classification vs. LinkNER on noisy datasets (WNUT'17, TweetNER)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal uncertainty threshold for different types of unseen entities (OOV vs OOD) and how does this vary across different NER datasets?
- Basis in paper: [explicit] The paper mentions selecting uncertainty thresholds through an intersection method and provides different thresholds for different datasets (Table 7), but doesn't fully explore the optimal threshold selection methodology.
- Why unresolved: The paper uses a heuristic threshold selection method but doesn't systematically investigate how different uncertainty threshold values affect performance across various types of unseen entities and datasets.
- What evidence would resolve it: A comprehensive study varying threshold values across different dataset types (ID, OOV, OOD) and entity categories, showing the relationship between threshold selection and performance improvements.

### Open Question 2
- Question: How does the computational cost and latency of LinkNER compare to standalone local models and LLMs, and what is the trade-off between performance improvement and computational overhead?
- Basis in paper: [inferred] The paper mentions that MCD consumes local model reasoning resources and that overly "cautious" uncertainty scores consume more LLM reasoning resources, but doesn't provide detailed computational cost analysis.
- Why unresolved: While the paper demonstrates performance improvements, it doesn't quantify the additional computational cost or latency introduced by the linking framework and uncertainty estimation methods.
- What evidence would resolve it: Empirical measurements of inference time, memory usage, and computational costs for LinkNER compared to baseline methods, along with analysis of the performance-overhead trade-off.

### Open Question 3
- Question: How well does LinkNER generalize to languages other than English and what modifications would be needed for cross-lingual NER tasks?
- Basis in paper: [explicit] The paper focuses exclusively on English NER datasets (CoNLL'03, OntoNotes 5.0, WNUT'17, etc.) and doesn't explore multilingual capabilities.
- Why unresolved: The framework's effectiveness on English data doesn't guarantee similar performance on other languages, especially considering linguistic differences in entity naming conventions and morphological complexity.
- What evidence would resolve it: Experimental results on multilingual NER datasets, analysis of language-specific challenges, and modifications needed to adapt LinkNER for different language families.

## Limitations
- Uncertainty in threshold selection could make the framework less robust in practice, with performance improvements varying significantly (3.04% to 21.30%) depending on threshold choice
- Heavy LLM dependency raises concerns about computational overhead and API costs for production deployment
- Generalizability of uncertainty methods across different local model architectures and cross-domain scenarios remains unclear

## Confidence
- High Confidence: The core claim that LinkNER improves NER performance on challenging datasets (3.04% to 21.30% F1 improvement) is well-supported by experimental results
- Medium Confidence: The effectiveness of uncertainty estimation as a routing mechanism is demonstrated but threshold selection methodology could be more robust
- Low Confidence: Claims about computational efficiency and production readiness are not quantitatively supported

## Next Checks
1. Validate threshold stability across different dataset domains by testing LinkNER on cross-domain NER benchmarks
2. Measure actual computational overhead and latency compared to standalone local models and LLMs
3. Test LinkNER performance on multilingual NER datasets to assess cross-lingual generalization