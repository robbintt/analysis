---
ver: rpa2
title: Hybrid Convolutional Neural Networks with Reliability Guarantee
arxiv_id: '2405.05146'
source_url: https://arxiv.org/abs/2405.05146
tags:
- safety
- execution
- reliable
- reliability
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a hybrid CNN architecture that integrates reliable
  execution of certain convolutional layers with non-reliable execution of others
  to improve safety and dependability in edge-AI applications. The core method involves
  partitioning the CNN into a dependable CNN (DCNN) and a non-dependable CNN, with
  reliable execution applied only to critical layers.
---

# Hybrid Convolutional Neural Networks with Reliability Guarantee

## Quick Facts
- arXiv ID: 2405.05146
- Source URL: https://arxiv.org/abs/2405.05146
- Authors: Hans Dermot Doran; Suzana Veljanovska
- Reference count: 40
- Key outcome: Proposes hybrid CNN architecture integrating reliable execution of critical layers with non-reliable execution of others to improve safety in edge-AI applications.

## Executive Summary
This paper introduces a hybrid CNN architecture that selectively applies reliable execution mechanisms to critical layers while allowing non-critical layers to execute without redundancy. The approach partitions the CNN into a dependable CNN (DCNN) and non-dependable CNN, focusing computational expense only where safety guarantees are strictly necessary. The authors implement this using a modified AlexNet architecture, replacing the first convolution layer with Sobel filters for edge detection and integrating rollback mechanisms at the operation level. While preliminary results demonstrate feasibility, the current Python implementation shows significant computational overhead (301.91s for reliable multiplication vs 0.05s baseline).

## Method Summary
The method involves partitioning a standard CNN into dependable and non-dependable components, with reliable execution applied only to critical layers through checkpointing and rollback mechanisms. The authors implement this approach using AlexNet, replacing the first convolution layer with Sobel filters initialized to extract edge features. Reliable convolution operations are implemented with redundant execution and comparison-based fault detection, where failed operations trigger rollback to the last checkpoint. The approach is integrated with TensorFlow execution paths and tested on the German Traffic Sign Recognition Benchmark (GTSRB) dataset, with results showing feasibility but significant computational overhead in software implementation.

## Key Results
- Hybrid CNN approach demonstrates feasibility of selective reliable execution for safety-critical applications
- Reliable convolution execution increases computation time from 0.05s to 301.91s for multiplication and 648.87s for redundant multiplication in Python implementation
- Sobel filter initialization for edge detection shows classification accuracy is maintained whether kernels are replaced after training or set before training and re-set after each epoch
- Integration of rollback mechanisms on an operation-execution basis successfully preserves computational value of previous executions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Partitioning the CNN into dependable (DCNN) and non-dependable (CNN) components allows selective application of reliability mechanisms, reducing computational overhead while maintaining safety guarantees for critical outputs.
- Mechanism: By executing only a subset of CNN layers (e.g., the first convolution layer) with redundant execution and rollback mechanisms, the system ensures reliable feature extraction for safety-critical classifications (e.g., stop sign detection) without duplicating the entire network.
- Core assumption: The reliability requirements for certain output classes can be met by ensuring reliability only in the feature extraction layers that feed into those classes.
- Evidence anchors:
  - [abstract] "integrate reliable model execution with non-reliable execution, focusing that additional computational expense only where it is strictly necessary."
  - [section] "A (convolutional) neural network may be understood as a mapping function, each layer mapping input data to a set of dimensions. Adding reliability to this mapping function is possible but computationally expensive. Our insight is that not all classifications may be relevant for reliability purposes and hence not all layers or portions of layers need be executed reliably."
- Break condition: If the safety-critical features are not adequately isolated to the reliably executed layers, or if the feature dependencies span across unreliable layers, the reliability guarantees will fail.

### Mechanism 2
- Claim: Integrating rollback mechanisms on an operation-execution basis allows recovery from transient faults without requiring full network re-execution, improving system availability.
- Mechanism: When a fault is detected in a critical operation (e.g., a multiplication in the convolution layer), the system rolls back to the last checkpoint and re-executes only the failed operation, preserving computational resources compared to full redundancy.
- Core assumption: Individual operations in the critical path can be reliably detected and isolated, and the cost of rollback is less than the cost of redundant execution for the entire layer.
- Evidence anchors:
  - [section] "In a convolution layer which consists largely of multiplications and additions, the rollback-distance can be reduced to one operation. That is, for instance, a redundantly executed multiplication with result comparison (checkpoint) and a re-multiplication (rollback) should the first have failed."
  - [section] "We also find that the principle of a hybrid CNN is feasible."
- Break condition: If the fault rate exceeds the rollback recovery rate, or if the rollback mechanism itself introduces significant overhead, the system availability will degrade.

### Mechanism 3
- Claim: Pre-initializing CNN filters with reliability-oriented features (e.g., Sobel filters for edge detection) allows the training process to benefit from dependability-related data without requiring separate training workflows.
- Mechanism: By initializing certain filters with deterministic feature extractors and maintaining their values during training, the network learns to preserve these features while adapting other parts of the network for classification, creating a hybrid approach that benefits from both reliability and generalization.
- Core assumption: The initialized filters retain their functional properties during training and contribute positively to the overall classification accuracy.
- Evidence anchors:
  - [section] "We then begin pre-initializing one of the three-dimensional AlexNet filters to Sobel filters and train the network keeping this initialisation constant."
  - [section] "The accuracy of the model is not affected whether the kernels are replaced after training is completed or set before training has begun and re-set after every epoch or batch."
- Break condition: If the training process modifies the initialized filters in ways that degrade their reliability properties, or if the accuracy impact is negative, the approach will fail.

## Foundational Learning

- Concept: Redundancy techniques in computing systems
  - Why needed here: The paper relies on redundant execution and rollback mechanisms to achieve reliable execution of critical CNN layers.
  - Quick check question: What are the two main approaches to redundancy mentioned in the paper, and what are their respective tradeoffs in terms of latency and hardware requirements?

- Concept: Convolutional Neural Networks and their architecture
  - Why needed here: The paper modifies a standard CNN (AlexNet) by replacing certain layers with reliability-oriented alternatives, requiring understanding of CNN structure and operation.
  - Quick check question: In the AlexNet architecture, what is the function of the first convolutional layer, and why is it targeted for reliability enhancement in this work?

- Concept: Functional safety and dependability concepts
  - Why needed here: The paper operates in the context of functional safety requirements, using concepts like "safety of the intended function" and "low probability of failure on demand."
  - Quick check question: According to the paper, what is the target failure probability for safety functions, and how does this influence the design of the reliable execution mechanisms?

## Architecture Onboarding

- Component map: Input → DCNN (reliable) → CNN (standard) → Qualifier → Output
- Critical path: Input preprocessing → DCNN (reliable) → CNN (standard) → Qualifier module → Output combination
- Design tradeoffs:
  - Reliability vs. computational cost: Reliable execution increases computation time from 0.05s to several hundred seconds in Python implementation
  - Feature extraction vs. classification: Reliability is applied to feature extraction layers, assuming safety-critical features can be isolated
  - Hardware abstraction vs. optimization: Software-based approach allows generality but may sacrifice performance compared to hardware-specific implementations
- Failure signatures:
  - Single operation failures in critical layers trigger rollback and re-execution
  - Persistent failures increment error counter beyond threshold, leading to system error state
  - Shape recognition failures in qualifier module result in no safety qualification for outputs
- First 3 experiments:
  1. Implement Algorithm 1 (non-reliable multiplication) and Algorithm 2 (reliable multiplication) in the target hardware platform to measure baseline and reliable execution times
  2. Replace the first AlexNet convolution layer with Sobel filters and compare classification accuracy against the original model on the GTSRB dataset
  3. Integrate the rollback mechanism into the convolution operation and test with injected faults to verify recovery behavior and error counter functionality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can subsequent layers of the CNN be harnessed to determine input compliance to a dependable model?
- Basis in paper: [explicit] The paper states "We believe it is worthwhile investigating under what conditions subsequent layers of the CNN can be harnessed to determine input compliance to a dependable model."
- Why unresolved: The paper only focuses on the first convolution layer and does not explore how deeper layers can contribute to dependability.
- What evidence would resolve it: Experiments showing improved dependability when leveraging subsequent layers, or theoretical analysis of how later layers could enhance reliability.

### Open Question 2
- Question: What is the optimal balance between the computational complexity of an application-specific qualification block and the general computational complexity of the CNN?
- Basis in paper: [explicit] The paper mentions "Optimisation with respect to balancing the generation and computational complexity of an application-specific qualification block with the general computational complexity of the CNN."
- Why unresolved: The paper does not provide a method for determining this balance, leaving it as an open problem.
- What evidence would resolve it: Empirical studies comparing different balances of qualification block complexity vs CNN complexity, or a mathematical model for optimal balance.

### Open Question 3
- Question: How can ONNX be extended to facilitate the platform-agnostic description of hybrid CNNs?
- Basis in paper: [explicit] The paper suggests "focus should be placed on researching extensions to the ONNX standard to facilitate the platform-agnostic description of hybrid-CNNs."
- Why unresolved: The paper does not propose specific extensions or demonstrate how ONNX could be modified to support hybrid CNNs.
- What evidence would resolve it: A proposed extension to the ONNX standard that supports hybrid CNN descriptions, or a proof-of-concept implementation using extended ONNX.

## Limitations

- The Python implementation shows extreme computational overhead (300+ seconds for reliable multiplication vs 0.05 seconds baseline), suggesting the approach may not be practical without significant hardware optimization
- No quantitative reliability metrics or safety case arguments are provided beyond qualitative descriptions
- The architecture assumes safety-critical features can be isolated to reliably executed layers, but this dependency mapping is not validated
- Only one CNN architecture (AlexNet) and dataset (GTSRB) are evaluated

## Confidence

- **High**: The hybrid CNN concept is feasible and the integration of rollback mechanisms on an operation basis is technically sound
- **Medium**: The architectural partitioning approach could reduce computational overhead in safety-critical applications
- **Low**: The practical utility and real-world safety guarantees of the approach remain unproven

## Next Checks

1. Implement the reliable convolution algorithm on FPGA hardware to measure actual performance overhead and determine practical feasibility
2. Conduct fault injection experiments to quantify the reliability improvement and verify the rollback mechanism works as intended under realistic fault conditions
3. Test the hybrid approach across multiple CNN architectures and safety-critical datasets to validate generalizability of the reliability partitioning strategy