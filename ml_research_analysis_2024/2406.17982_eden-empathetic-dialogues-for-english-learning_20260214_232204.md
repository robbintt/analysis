---
ver: rpa2
title: 'EDEN: Empathetic Dialogues for English learning'
arxiv_id: '2406.17982'
source_url: https://arxiv.org/abs/2406.17982
tags:
- feedback
- english
- chatbot
- conversation
- grit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EDEN, an empathetic English-teaching chatbot
  that provides grammatical and empathetic feedback to improve student persistence
  in language learning. The authors develop a specialized grammar correction model
  for spoken utterances and an open-domain conversation model for diverse topics.
---

# EDEN: Empathetic Dialogues for English learning

## Quick Facts
- arXiv ID: 2406.17982
- Source URL: https://arxiv.org/abs/2406.17982
- Authors: Li Siyan; Teresa Shao; Zhou Yu; Julia Hirschberg
- Reference count: 40
- Primary result: Adaptive empathetic feedback in EDEN chatbot leads to higher perceived affective support, which correlates with positive changes in L2 grit

## Executive Summary
This paper introduces EDEN, an empathetic English-teaching chatbot designed to improve student persistence in language learning by providing both grammatical and empathetic feedback. The authors develop a specialized grammar correction model for spoken utterances and an open-domain conversation model for diverse topics. A user study comparing adaptive, fixed, and no empathetic feedback strategies shows that adaptive empathetic feedback results in higher perceived affective support from the chatbot, which correlates with positive changes in student L2 grit (passion and perseverance for language learning).

## Method Summary
The EDEN system consists of a speech input module, negative sentiment and pause detection, empathetic feedback generation (adaptive or fixed), grammar correction specialized for spoken utterances, an open-domain conversation model, ChatGPT query handling, and personalization. The grammar correction model is trained on transcribed spoken utterances from native Mandarin speakers, while the conversation model is fine-tuned on synthesized dialogue data. Adaptive empathetic feedback is generated via ChatGPT using optimized prompts. The system was evaluated through a user study with native Mandarin speakers comparing three feedback conditions.

## Key Results
- Adaptive empathetic feedback leads to significantly higher perceived affective support compared to fixed feedback
- Higher perceived affective support correlates with positive changes in L2 grit (weak to intermediate correlation)
- Users with lower initial proficiency showed more improvement in L2 grit when receiving adaptive empathetic feedback

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adaptive empathetic feedback leads to higher perceived affective support (PAS) from the chatbot.
- Mechanism: Personalized feedback generated by ChatGPT in response to user distress signals (negative sentiment, prolonged pauses) is more contextually relevant and empathetic than generic pre-defined phrases, leading users to feel more understood and supported.
- Core assumption: Users perceive tailored, context-specific feedback as more empathetic and supportive than generic feedback, even if the underlying emotional recognition is imperfect.
- Evidence anchors:
  - [abstract]: "Results show that adaptive empathetic feedback leads to higher perceived affective support from the chatbot"
  - [section 5.1]: "Adaptive outperforms Fixed for all PAS-related metrics. This is expected, as a generic phrase is unlikely to elicit as much perceived empathy as a tailored, adaptive piece of feedback."
  - [corpus]: Weak - only 5 related papers found, none directly validating this specific mechanism for adaptive vs. fixed feedback in educational chatbots.
- Break condition: If the adaptive feedback generation becomes too formulaic or the context recognition fails, users may perceive it as robotic and less supportive than fixed phrases.

### Mechanism 2
- Claim: Higher chatbot PAS correlates with positive changes in student L2 grit (passion and perseverance for language learning).
- Mechanism: When students perceive the chatbot as more supportive and empathetic (higher PAS), they feel more encouraged and motivated to persist in their language learning efforts, leading to improvements in their L2 grit.
- Core assumption: The relationship between perceived support and increased grit observed in human teacher-student relationships (Wu et al., 2023) extends to chatbot-student interactions.
- Evidence anchors:
  - [abstract]: "Results show that adaptive empathetic feedback leads to higher perceived affective support from the chatbot, which correlates with positive changes in student grit"
  - [section 5.2]: "Our results showcase some components of PAS being weak to intermediate predictors for positive L2 grit changes... Higher PAS still weakly correlates with positive L2 grit changes"
  - [corpus]: Weak - no direct evidence in corpus papers for this specific mechanism in chatbot settings; relies on extrapolation from human teacher studies.
- Break condition: If the chatbot's supportiveness does not translate into genuine encouragement or if students do not internalize the chatbot's feedback as supportive, the correlation may not hold.

### Mechanism 3
- Claim: Tailored grammatical feedback for spoken utterances improves the quality of feedback and user experience.
- Mechanism: By training a grammar correction model on transcribed spoken utterances from native Mandarin speakers, the system can better identify and correct common grammatical errors specific to this user group, providing more relevant and helpful feedback.
- Core assumption: Spoken dialogue has distinct grammatical error patterns compared to written text, and models trained on spoken data will perform better for this use case.
- Evidence anchors:
  - [section 3.1.2]: "We find that the two models usually both provide valid corrections, with the Llama-2 model slightly out-performing" in human evaluations comparing to GPT-4.
  - [section 3.1]: "There is a lack of dialogue grammar correction datasets for spoken conversations. We bridge this gap by training a grammar correction model specialized for transcribed spoken utterances."
  - [corpus]: Weak - only mentions general grammar correction work, no specific evidence for spoken utterance specialization in educational chatbots.
- Break condition: If the spoken utterance data is not representative of the target user population or if the error patterns change significantly, the specialized model may not provide better feedback than general models.

## Foundational Learning

- Concept: Perceived Affective Support (PAS)
  - Why needed here: PAS is the key mediating variable between empathetic feedback and L2 grit changes; understanding its components is crucial for interpreting results.
  - Quick check question: What are the four components of PAS measured in the study (ENC, LIST, CARE, APP) and how are they defined?

- Concept: L2 Grit
  - Why needed here: L2 grit is the outcome variable of interest; knowing its definition and measurement is essential for understanding the study's goals.
  - Quick check question: According to Teimouri et al. (2022), what are the key characteristics of L2 grit and how is it measured in the survey?

- Concept: Empathetic Feedback Mechanisms
  - Why needed here: Different types of empathetic feedback (adaptive vs. fixed) are the independent variables being tested; understanding their implementation is key to interpreting the results.
  - Quick check question: How does the adaptive empathetic feedback mechanism work in EDEN, and what triggers it?

## Architecture Onboarding

- Component map: Speech input → Whisper transcription → Negative sentiment/pause detection → Empathetic feedback (adaptive/fixed) → Grammar correction → Conversation model → ChatGPT query handler → Output
- Critical path: User input → Speech processing → Feedback trigger detection → (Empathetic feedback OR Grammar feedback) → Conversation continuation → ChatGPT query handling (if needed) → Output
- Design tradeoffs: Using local models for grammar correction vs. GPT-4 API for speed and cost; adaptive feedback requires more complex generation but may be more effective; personalization adds complexity but improves user experience.
- Failure signatures: Network errors disrupting conversation flow; grammar model generating incorrect corrections; empathetic feedback sounding unnatural or irrelevant; personalization preferences not being respected.
- First 3 experiments:
  1. Test the grammar correction model on a held-out set of spoken utterances to verify accuracy.
  2. Compare user preferences for adaptive vs. fixed empathetic feedback in a small pilot study.
  3. Measure the correlation between PAS and L2 grit in a larger user study with balanced experimental conditions.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the perceived affective support from chatbots lead to measurable improvements in L2 grit beyond correlational effects?
- Basis in paper: [explicit] The authors hypothesize that higher chatbot PAS correlates with positive changes in L2 grit and find weak-to-intermediate correlations, but do not establish causation.
- Why unresolved: The study design is correlational, not experimental, and the sample size is small (31 participants). Confounding variables like initial proficiency or motivation are not controlled.
- What evidence would resolve it: A longitudinal randomized controlled trial where chatbot PAS is experimentally manipulated (e.g., adaptive vs. no feedback) and L2 grit is measured over time, with controls for baseline proficiency and motivation.

### Open Question 2
- Question: How does the specificity and naturalness of empathetic feedback affect its impact on perceived affective support and learning outcomes?
- Basis in paper: [inferred] The study compares adaptive vs. fixed empathetic feedback, finding adaptive feedback yields higher PAS, but doesn't analyze the role of specificity or naturalness in feedback content.
- Why unresolved: The analysis focuses on feedback type but not on linguistic features (e.g., personalization, tone, concreteness) that might drive the PAS effect.
- What evidence would resolve it: A within-subjects experiment varying feedback specificity (generic vs. personalized) and naturalness (formal vs. colloquial) while measuring PAS and learning outcomes.

### Open Question 3
- Question: Does the relationship between perceived affective support and L2 grit generalize to learners with different proficiency levels or cultural backgrounds?
- Basis in paper: [explicit] The study sample is limited to intermediate-proficiency Mandarin speakers in the US, raising concerns about sampling bias and generalizability.
- Why unresolved: The sample lacks diversity in proficiency and cultural background, and the authors note difficulty recruiting from Mainland China due to connectivity issues.
- What evidence would resolve it: Replication studies with diverse proficiency levels and cultural backgrounds, particularly including learners from different regions and educational contexts.

## Limitations

- Limited generalizability due to sample consisting only of native Mandarin speakers in the US
- Weak evidence supporting specific mechanisms through corpus analysis
- Small sample size (31 participants) for correlational claims about PAS and L2 grit

## Confidence

- **High confidence**: Adaptive empathetic feedback leads to higher perceived affective support (PAS) - supported by direct study results showing adaptive feedback outperforms fixed feedback across all PAS metrics.
- **Medium confidence**: Higher PAS correlates with positive L2 grit changes - the correlation exists but is described as "weak to intermediate," and relies on extrapolation from human teacher studies.
- **Low confidence**: The specific mechanisms of adaptive feedback superiority and spoken utterance grammar correction effectiveness - minimal direct evidence in the corpus, mostly theoretical assumptions.

## Next Checks

1. Conduct a larger-scale user study with diverse linguistic backgrounds to verify if the adaptive feedback → higher PAS → improved L2 grit relationship holds across different user populations.
2. Perform ablation studies comparing EDEN's specialized spoken utterance grammar correction model against general grammar correction models on a held-out test set of spoken dialogues to quantify performance differences.
3. Implement and test alternative empathetic feedback strategies (e.g., rule-based vs. LLM-generated) to determine if the observed benefits are specific to ChatGPT-based adaptive feedback or generalizable to other adaptive approaches.