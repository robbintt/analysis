---
ver: rpa2
title: Decision-Focused Evaluation of Worst-Case Distribution Shift
arxiv_id: '2407.03557'
source_url: https://arxiv.org/abs/2407.03557
tags:
- distribution
- worst-case
- loss
- optimization
- individuals
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a novel framework for identifying worst-case
  distribution shifts in predictive resource allocation settings by capturing shifts
  both within and across optimization instances. The method addresses the combinatorial
  complexity of joint decisions by reformulating the problem as a submodular optimization
  task, enabling efficient approximations.
---

# Decision-Focused Evaluation of Worst-Case Distribution Shift

## Quick Facts
- arXiv ID: 2407.03557
- Source URL: https://arxiv.org/abs/2407.03557
- Authors: Kevin Ren; Yewon Byun; Bryan Wilder
- Reference count: 29
- Key outcome: Introduces framework for identifying worst-case distribution shifts in predictive resource allocation by reformulating as submodular optimization

## Executive Summary
This paper addresses the challenge of evaluating model robustness to distribution shifts in predictive resource allocation settings. The authors propose a decision-focused framework that captures shifts both within and across optimization instances, recognizing that traditional individual-level metrics may fail to identify shifts that most impact downstream optimization decisions. By reformulating the worst-case distribution shift identification problem as submodular optimization, the framework enables efficient approximation even in the face of combinatorial complexity. The method demonstrates that worst-case shifts identified through traditional metrics can significantly diverge from those identified through decision-focused metrics, emphasizing the importance of considering downstream optimization tasks when evaluating robustness.

## Method Summary
The framework reformulates worst-case distribution shift identification as a submodular optimization problem, enabling efficient approximation through the Frank-Wolfe algorithm. The key insight is that the decision cost function $c(\hat{x}, x^*)$, which measures the impact of prediction errors on optimization outcomes, can be expressed in a form amenable to submodular optimization techniques. This allows the method to efficiently search through the space of possible distribution shifts to identify those that would most negatively impact downstream optimization decisions. The approach is evaluated on real-world data, demonstrating both computational efficiency and the ability to identify distribution shifts that traditional metrics miss.

## Key Results
- Worst-case shifts identified by traditional individual-level metrics often diverge significantly from those identified by decision-focused metrics
- Frank-Wolfe algorithm efficiently approaches solutions found by polynomial solvers
- Framework empirically outperforms worst-case theoretical guarantees in real-world experiments

## Why This Works (Mechanism)
The framework works by capturing the interaction between prediction errors and their downstream impact on optimization decisions. Traditional robustness evaluation methods focus on individual prediction errors without considering how these errors compound when fed into optimization problems. By incorporating the decision cost function $c(\hat{x}, x^*)$ directly into the shift identification process, the framework can identify shifts that create the most severe degradation in optimization outcomes, even when individual prediction errors might appear modest. The submodular structure of the problem enables efficient search through the combinatorial space of possible shifts.

## Foundational Learning
- Submodular optimization: Needed because the worst-case objective can be expressed in submodular form, enabling efficient approximation algorithms. Quick check: Verify submodularity conditions hold for specific cost functions.
- Predict-then-optimize framework: Needed to understand how prediction errors propagate through downstream optimization tasks. Quick check: Confirm the optimization problem structure matches the framework assumptions.
- Distribution shift characterization: Needed to properly define the space of possible shifts to search over. Quick check: Validate that the shift space captures realistic scenarios from validation data.

## Architecture Onboarding

Component map: Input data -> Shift space definition -> Decision cost function -> Submodular optimization -> Worst-case shift identification

Critical path: The method's effectiveness depends on the accurate specification of the decision cost function $c(\hat{x}, x^*)$, which must properly capture the downstream optimization task's sensitivity to prediction errors.

Design tradeoffs: The framework trades computational tractability (via submodular approximation) against the possibility of missing some worst-case shifts that would only be revealed through exhaustive search. This enables practical application to large-scale problems while accepting some approximation error.

Failure signatures: If the decision cost function is misspecified, the method may identify shifts that are not truly impactful for the downstream optimization task. Additionally, if the shift space is too restrictive, the method may miss important real-world distribution changes.

First experiments:
1. Verify submodularity of the objective function for simple linear optimization problems
2. Compare worst-case shifts identified by individual-level vs decision-focused metrics on synthetic data
3. Evaluate computational efficiency gains over brute-force enumeration on small-scale problems

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness critically depends on accurate specification of the decision cost function $c(\hat{x}, x^*)$
- Assumes access to representative validation set for characterizing distribution shifts
- Theoretical approximation guarantees rely on submodularity assumptions that may not hold for all problem structures
- Computational efficiency gains come at cost of potentially missing some worst-case shifts

## Confidence
- High confidence: Theoretical formulation of worst-case distribution shift as submodular optimization problem
- Medium confidence: Empirical demonstration of divergence between decision-focused and individual-level metrics
- Medium confidence: Frank-Wolfe algorithm's effectiveness in approaching polynomial solver solutions
- Low confidence: Generalizability to optimization problems beyond tested domains

## Next Checks
1. Test framework on broader range of optimization problems including non-linear objectives and constraints to verify submodularity assumptions
2. Conduct sensitivity analysis on choice of decision cost function to understand impact of specification errors
3. Compare against alternative approaches like domain adaptation or meta-learning methods for handling distribution shifts in predict-then-optimize settings