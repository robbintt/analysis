---
ver: rpa2
title: Building another Spanish dictionary, this time with GPT-4
arxiv_id: '2406.11218'
source_url: https://arxiv.org/abs/2406.11218
tags:
- words
- definitions
- dictionary
- lemmas
- spanish-bff-2
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors constructed an AI-generated Spanish dictionary (Spanish-BFF-2)
  using GPT-4-turbo, replacing the prior GPT-3-based version. They prompted the model
  with a curated list of 94,472 lemmas in batches, requesting definitions and example
  sentences over ~90 hours.
---

# Building another Spanish dictionary, this time with GPT-4

## Quick Facts
- arXiv ID: 2406.11218
- Source URL: https://arxiv.org/abs/2406.11218
- Reference count: 0
- The authors constructed an AI-generated Spanish dictionary (Spanish-BFF-2) using GPT-4-turbo, improving definition quality and reducing lexicographic errors compared to a prior GPT-3 version, but coverage of polysemy remains limited.

## Executive Summary
The paper describes the creation of a large-scale Spanish dictionary using GPT-4-turbo, building upon a prior GPT-3-based effort. By processing a curated list of 94,472 lemmas in batches and prompting the model for definitions and example sentences, the authors produced a dictionary covering 77,093 lemmas. Quantitative evaluation against the official DLE shows significant improvements in definition quality for monosemous words (cosine similarity increased from 0.3400 to 0.4422) and a dramatic reduction in self-referential definitions. However, the system still struggles with polysemy, generating only one sense for most polysemous words and achieving a recall of just 9.8%.

## Method Summary
The method involves submitting batches of 32 lemmas to GPT-4-turbo via OpenAI API, using a prompt that includes lexicographic instructions (define without using the word, provide an example) and two few-shot examples. The model's raw text responses are parsed into structured lemma-definition-example triplets. The final dictionary excludes lemmas where definitions failed to generate. Quality is evaluated by comparing generated definitions to the official DLE using cosine similarity of sentence embeddings, measuring definition lengths, and assessing polysemy recall and precision.

## Key Results
- GPT-4-turbo improved monosemous definition quality: mean cosine similarity vs. DLE increased from 0.3400 (GPT-3) to 0.4422.
- Self-referential definitions were drastically reduced (<0.5% vs. ~11% in GPT-3).
- Polysemy recall remains low at 9.8%, with only 3,405 polysemous entries generated vs. 27,150 in DLE.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Structured few-shot prompting with a curated lemma list enables GPT-4-turbo to generate dictionary-style definitions and examples at scale.
- **Mechanism:** The system submits batches of 32 lemmas with a fixed prompt template that includes lexicographic instructions and few-shot examples, constraining the model's output to a predictable format.
- **Core assumption:** GPT-4-turbo's instruction-following capabilities allow it to consistently apply the specified lexicographic format across a vast list of lemmas.
- **Evidence anchors:** Section 4 describes the experimental setup with batches and prompt specifications; section 5.1 notes the model's "commendable lexicographic capabilities" and format adherence.

### Mechanism 2
- **Claim:** Improved model scale and training (GPT-4-turbo vs. GPT-3) significantly reduces specific lexicographic errors like self-referential definitions.
- **Mechanism:** The shift to a more advanced model variant enhances its understanding of the "no circular definition" constraint, likely due to better RLHF tuning and refined internal representations.
- **Core assumption:** The reduction in error is causally linked to the inherent capabilities of the newer model architecture and alignment.
- **Evidence anchors:** Abstract states self-referential definitions reduced from ~11% to <0.5%; section 5.1 and Appendix A show examples of correct format adherence.

### Mechanism 3
- **Claim:** The model's definition generation is frequency-sensitive, preferentially capturing the most common (primary) senses of a word, but fails to systematically enumerate all senses for polysemous lemmas.
- **Mechanism:** The model's internal knowledge associates a lemma most strongly with its highest-frequency senses; the single-turn prompt does not force the model to search for less frequent senses, leading to a "first-sense bias."
- **Core assumption:** The model's parametric knowledge contains polysemous information, but the prompting strategy lacks a mechanism to elicit exhaustive sense listing.
- **Evidence anchors:** Section 5.2.2 and Figure 1 show GPT-4-turbo fits the statistical trend of meanings better; section 5.2.3 shows polysemy recall is very low (9.8%) despite high precision (79.8%).

## Foundational Learning

- **Concept: Lexicographic Microstructure**
  - **Why needed here:** The engineer must understand standard dictionary entry components (POS tag, definition without the definiendum, example sentence) to craft an effective prompt and evaluate output quality.
  - **Quick check question:** What are the three core components of a monolingual dictionary microstructure, and why is avoiding the lemma in its own definition a key principle?

- **Concept: LLM Prompt Engineering for Structured Output**
  - **Why needed here:** The system's success depends on converting an open-ended language model into a structured data generator.
  - **Quick check question:** How does including two example definitions in the prompt (few-shot learning) differ in purpose from simply stating "do not use the word in the definition"?

- **Concept: Evaluation via Distributional Semantic Similarity**
  - **Why needed here:** The primary quantitative evaluation uses cosine similarity of sentence embeddings between generated and gold-standard definitions.
  - **Quick check question:** Why is a high mean cosine similarity for monosemous words a positive signal, but a similarly high score for a polysemous word's single generated definition can be misleading?

## Architecture Onboarding

- **Component map:** Curated Lemma List -> (Batch 32) -> Prompt Template -> API Call -> Raw Text Response -> Parser -> Structured Entry -> Storage
- **Critical path:** Lemma List → (Batch 32) → Prompt Template → API Call → Raw Text Response → Parser → Structured Entry → Storage. Failure at parsing or API limits halts progress.
- **Design tradeoffs:**
  - **Batch Size (32) vs. Context Window/Latency:** Larger batches reduce API calls but increase prompt length and risk truncation or slower responses.
  - **Prompt Complexity vs. Consistency:** A richer few-shot set might improve quality but increases token use and cost.
  - **Single-pass vs. Iterative:** Non-iterative is fast but cannot elicit multiple senses; an iterative loop would increase cost and complexity but might improve polysemy recall.
- **Failure signatures:**
  1. **Refusal Output:** Model returns "I don't have information" for a lemma (17,379 cases). Signature: Parser finds no definition/example pattern.
  2. **Format Drift:** Output mixes definitions/examples or uses different punctuation. Signature: Parser fails to split on expected delimiters.
  3. **Hallucinated Polysemy:** Model invents a second sense where none exists (699 cases). Signature: High cosine similarity to DLE definition but DLE lists only one sense.
- **First 3 experiments:**
  1. **Single-Lemma Sanity Check:** Prompt the model with one rare, one common, and one polysemous lemma. Verify format adherence, absence of self-reference, and quality of example sentence.
  2. **Batch Processing & Parsing:** Run a batch of 32 diverse lemmas. Measure API latency, parse success rate, and identify common formatting anomalies.
  3. **Error Class Profiling:** Manually inspect 50 failed entries and 50 low-similarity definitions. Categorize failures: rare word, formatting issue, hallucination type.

## Open Questions the Paper Calls Out

- **How can we improve polysemy detection and coverage in AI-generated dictionaries?** Problem is clearly identified but no investigation into why GPT-4-turbo resists multiple senses despite explicit prompting, nor testing of architectural or prompting solutions.
- **What explains the ~15% failure rate in generating definitions, and can it be reduced?** Missing definitions noted but not characterized by linguistic properties or attempted mitigation strategies.
- **How can AI dictionary generation adapt for languages without comprehensive lemma lists?** Authors admit lemma-list approach "is limited to languages with substantial resources" and suggest corpus+lemmatizer alternatives but don't evaluate them.

## Limitations

- **Polysemy Coverage:** The system only generates a single sense for most polysemous words, achieving a recall of just 9.8%, which limits the dictionary's depth compared to traditional resources.
- **Reproducibility:** Key details like the exact lemma list, prompt template (especially few-shot examples), and DLE scraping method are not specified, making faithful reproduction difficult.
- **Evaluation Scope:** The use of cosine similarity for semantic closeness is useful but cannot capture the precision of sense distinction or identify when a single generated definition conflates multiple distinct senses.

## Confidence

- **High Confidence:** The quantitative improvement in monosemous definition quality (cosine similarity increase from 0.3400 to 0.4422) and the dramatic reduction in self-referential errors (<0.5% vs. ~11%) are well-supported.
- **Medium Confidence:** The reported improvements in definition length and general adherence to lexicographic format are reasonable but less rigorously assessed than the quantitative scores.
- **Low Confidence:** The specific failure rate of 17,379 lemmas and the exact distribution of lexicographic errors are difficult to verify without the original prompt and API logs.

## Next Checks

1. **Replicate Prompt Engineering:** Obtain or reconstruct the exact prompt template (including the two few-shot examples) and run a test batch of 50 lemmas through GPT-4-turbo. Measure the success rate, format compliance, and self-referential error rate to verify the reported <0.5% figure.
2. **Polysemy Generation Experiment:** For a fixed set of 20 known polysemous lemmas from the DLE, modify the prompt to explicitly request "all senses" or "multiple meanings if they exist." Compare the number and quality of senses generated versus the single-pass method.
3. **Hallucination Audit:** Select 30 lemmas with the lowest cosine similarity scores to their DLE definitions. Manually verify each generated definition and example sentence against independent lexicographic sources. Classify each as correct, plausible hallucination, or over-derivation.