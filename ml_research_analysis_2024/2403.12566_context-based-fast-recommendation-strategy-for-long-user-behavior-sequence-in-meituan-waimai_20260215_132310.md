---
ver: rpa2
title: Context-based Fast Recommendation Strategy for Long User Behavior Sequence
  in Meituan Waimai
arxiv_id: '2403.12566'
source_url: https://arxiv.org/abs/2403.12566
tags:
- user
- contexts
- context
- cofars
- preferences
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of modeling long user behavior
  sequences in the Meituan Waimai recommender system. The authors propose a novel
  Context-based Fast Recommendation Strategy (CoFARS) that leverages context information
  and a two-stage approach to efficiently filter and model relevant user interactions.
---

# Context-based Fast Recommendation Strategy for Long User Behavior Sequence in Meituan Waimai

## Quick Facts
- **arXiv ID**: 2403.12566
- **Source URL**: https://arxiv.org/abs/2403.12566
- **Reference count**: 40
- **Primary result**: CoFARS achieves 4.6% increase in CTR and 4.2% boost in GMV in online A/B testing

## Executive Summary
The paper addresses the challenge of modeling long user behavior sequences in the Meituan Waimai recommender system. The authors propose a novel Context-based Fast Recommendation Strategy (CoFARS) that leverages context information and a two-stage approach to efficiently filter and model relevant user interactions. CoFARS employs a prototype-based approach to identify contexts with similar user preferences, using JS divergence as a measure of similarity. It also incorporates a graph-based temporal aggregator to integrate temporal information into the model. Experiments show that CoFARS outperforms existing methods, achieving significant improvements in CTR and GMV.

## Method Summary
The proposed Context-based Fast Recommendation Strategy (CoFARS) uses a prototype-based approach to identify contexts with similar user preferences using Jensen-Shannon (JS) divergence. It integrates temporal information via a graph-based temporal aggregator and uses target attention for fine-grained modeling. The method selects a sub-sequence based on contexts with similar preferences to the target context, independent of candidate items, reducing computational complexity. The model is trained to minimize JS divergence between estimated and ground truth distributions, with additional independence loss to ensure prototype diversity.

## Key Results
- CoFARS achieves a 4.6% increase in Click-Through Rate (CTR) and a 4.2% boost in Gross Merchandise Volume (GMV) in online A/B testing
- The model outperforms existing methods on offline evaluation metrics including AUC for CTR and CTCVR
- Ablation studies demonstrate the effectiveness of each component, with prototype-based context matching and temporal graph aggregation contributing significantly to performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The prototype-based approach with JS divergence similarity enables efficient identification of contexts with similar user preferences without needing to compare against all candidate items.
- Mechanism: CoFARS uses a probability encoder to convert context preference representations into probability distributions over PoI attributes. JS divergence then measures similarity between these distributions, which is symmetric and interpretable. Prototypes serve as centroids that group semantically similar contexts, allowing the model to select relevant sub-sequences based on context similarity rather than individual items.
- Core assumption: User preferences in different contexts can be effectively represented as probability distributions over PoI attributes, and these distributions are sufficient to capture preference similarity.
- Evidence anchors:
  - [abstract] "We employ Jensen–Shannon (JS) divergence of PoI attributes such as categories and prices as a measure of similarity between contexts."
  - [section 3.2] "we employ Jensen-Shannon (JS) divergence to measure the similarity of PoI attribute distributions across different contexts, enhancing interpretability and accuracy."
  - [corpus] Weak - corpus neighbors don't directly address JS divergence or prototype-based context modeling.

### Mechanism 2
- Claim: The graph-based temporal aggregator preserves sequential dynamics while enabling efficient message passing across context nodes.
- Mechanism: A temporal graph is constructed where nodes represent contexts and edges connect adjacent contexts. Prototype nodes are integrated into this graph and connected to context nodes based on similarity scores above a threshold. Graph Attention Networks then aggregate information across the graph, embedding temporal information into node representations.
- Core assumption: The sequential order of contexts contains meaningful temporal patterns that can be captured through graph-based message passing.
- Evidence anchors:
  - [section 3.3] "we construct a temporal graph based on the sequential order of contexts, wherein nodes denote contexts, and edges signify the co-occurrences among adjacent contexts."
  - [section 3.3] "we utilize Graph Attention Network [31], which could deal with directed graphs and unseen nodes, to aggregate the graph and embed temporal information into the node representation."
  - [corpus] Weak - corpus neighbors don't directly address temporal graph aggregation in the context of long sequences.

### Mechanism 3
- Claim: The two-stage approach with candidate-agnostic sub-sequence selection reduces computational complexity while maintaining recommendation quality.
- Mechanism: The first stage identifies contexts with similar preferences to the target context using prototypes and JS divergence. The second stage uses target attention on the filtered sub-sequence to model user interest. This approach avoids comparing against all candidate items in the first stage, reducing complexity from O(B·n) to O(r + |O|).
- Core assumption: Filtering based on context similarity is sufficient to identify relevant sub-sequences without examining individual candidate items.
- Evidence anchors:
  - [abstract] "This approach eliminates the necessity to select a sub-sequence for every candidate PoI, thereby avoiding high time complexity."
  - [section 3.4] "The proposed CoFARS method selects a sub-sequence based on contexts with similar preferences to the target context independent of candidate items."
  - [section 3.4] "In the offline phase, it calculates the similarity between prototypes and context preferences with a time complexity of O(|C| · |O|), where |C| is much smaller than the sequence length n, and |O| is a constant."
  - [corpus] Weak - corpus neighbors don't directly address candidate-agnostic two-stage approaches for long sequences.

## Foundational Learning

- Concept: Probability distributions over PoI attributes
  - Why needed here: The model represents user preferences in contexts as probability distributions over attributes like categories and prices, using these to measure similarity between contexts.
  - Quick check question: How would you convert a set of user interactions in a context into a probability distribution over PoI categories?

- Concept: JS divergence as a similarity measure
  - Why needed here: JS divergence provides a symmetric, interpretable way to measure similarity between probability distributions, which the model uses to compare context preferences.
  - Quick check question: What is the key difference between JS divergence and KL divergence, and why is this important for measuring context similarity?

- Concept: Graph Attention Networks for temporal aggregation
  - Why needed here: GNNs are used to aggregate information across the temporal graph of contexts, embedding temporal patterns into node representations.
  - Quick check question: How does a Graph Attention Network differ from a standard Graph Convolutional Network in terms of edge weighting?

## Architecture Onboarding

- Component map:
  - Probability Encoder: Converts context preference representations to probability distributions
  - Prototype System: Groups similar contexts using JS divergence
  - Temporal Graph: Connects contexts in sequence order with prototype nodes
  - Graph Attention Network: Aggregates temporal information
  - Target Attention: Models user interest on filtered sub-sequence

- Critical path: User context → Probability encoder → Prototype matching → Temporal graph → GNN aggregation → Sub-sequence filtering → Target attention → Prediction

- Design tradeoffs:
  - Prototype number vs. performance: More prototypes improve granularity but increase computational cost
  - Graph density vs. efficiency: Higher similarity thresholds reduce graph size but may lose connections
  - Temporal aggregation depth vs. overfitting: More GNN layers capture longer dependencies but risk overfitting

- Failure signatures:
  - Poor prototype selection: JS divergence alignment loss increases during training
  - Ineffective temporal modeling: Similarity scores between adjacent contexts become uniform
  - Sub-sequence filtering issues: CTR/ CTCVR metrics drop significantly compared to baseline

- First 3 experiments:
  1. Vary the number of prototypes (1, 10, 20, 30, 40, 60, 80) and measure impact on CTR/ CTCVR metrics
  2. Test different similarity thresholds for prototype-context connections in the temporal graph
  3. Compare performance with and without the independence loss constraint on prototypes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the CoFARS model handle cold-start contexts where no prior user interactions exist within that context?
- Basis in paper: [explicit] The paper mentions the challenge of cold-start contexts but does not detail how CoFARS addresses this issue.
- Why unresolved: The authors acknowledge the problem but do not provide a detailed solution or strategy for handling cold-start contexts within the model.
- What evidence would resolve it: A detailed explanation or experiment results showing how CoFARS performs with cold-start contexts, including any specific techniques or adaptations used to handle them.

### Open Question 2
- Question: What is the impact of varying the number of prototypes on the model's performance, and is there an optimal number?
- Basis in paper: [explicit] The paper discusses the effect of prototype numbers but does not provide a clear optimal number or a detailed analysis of its impact on performance.
- Why unresolved: While the authors mention tuning the number of prototypes, they do not explore the full range of impacts or provide a definitive optimal setting.
- What evidence would resolve it: A comprehensive analysis or experiment results showing performance variations with different numbers of prototypes, identifying an optimal number for the best results.

### Open Question 3
- Question: How does the temporal graph-based aggregator compare to other methods of incorporating temporal information, such as RNNs or transformers?
- Basis in paper: [inferred] The paper introduces a temporal graph-based aggregator but does not compare its effectiveness to other temporal modeling techniques.
- Why unresolved: The authors do not provide a comparative analysis between the temporal graph-based aggregator and other temporal modeling approaches, leaving its relative effectiveness unclear.
- What evidence would resolve it: Experimental results or a detailed comparison showing the performance of the temporal graph-based aggregator against RNNs or transformers in modeling temporal information.

## Limitations
- The model's effectiveness relies heavily on the quality of prototype selection and the assumption that context preferences can be adequately captured through attribute distributions
- The online A/B testing results show strong performance gains, but the offline ablation studies could be more comprehensive in isolating the contributions of individual components
- The JS divergence-based prototype matching may struggle with cold-start scenarios where user preference distributions are sparse or noisy

## Confidence

- **High confidence**: The two-stage computational efficiency gains and the basic prototype-based filtering approach
- **Medium confidence**: The effectiveness of JS divergence for context similarity measurement in real-world settings
- **Medium confidence**: The graph-based temporal aggregation improvements over simpler sequential models
- **Low confidence**: The specific hyperparameter choices (prototype count, similarity thresholds) generalizability across different domains

## Next Checks

1. Conduct controlled ablation studies varying the number of prototypes (1, 10, 20, 30, 40, 60, 80) to identify optimal granularity vs. performance tradeoffs
2. Test the model's performance on cold-start scenarios with limited user history to assess prototype matching reliability
3. Compare JS divergence-based context similarity against alternative measures (cosine similarity, Euclidean distance) on the same dataset to validate the choice of similarity metric