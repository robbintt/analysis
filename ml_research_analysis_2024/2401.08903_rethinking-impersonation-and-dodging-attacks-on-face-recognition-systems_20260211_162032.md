---
ver: rpa2
title: Rethinking Impersonation and Dodging Attacks on Face Recognition Systems
arxiv_id: '2401.08903'
source_url: https://arxiv.org/abs/2401.08903
tags:
- adversarial
- attacks
- attack
- face
- dodging
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper identifies a fundamental gap in adversarial attacks
  on face recognition (FR) systems: previous impersonation attacks do not necessarily
  succeed in dodging attacks, especially in black-box settings. The authors propose
  Adversarial Pruning (Adv-Pruning), a three-stage method (Priming, Pruning, and Restoration)
  that enhances dodging attack capabilities while maintaining impersonation performance.'
---

# Rethinking Impersonation and Dodging Attacks on Face Recognition Systems

## Quick Facts
- **arXiv ID**: 2401.08903
- **Source URL**: https://arxiv.org/abs/2401.08903
- **Reference count**: 40
- **Key outcome**: Proposed Adversarial Pruning (Adv-Pruning) significantly improves dodging ASR while maintaining impersonation ASR in black-box settings

## Executive Summary
This paper identifies a critical gap in adversarial attacks on face recognition systems: previous impersonation attacks often fail to achieve effective dodging performance, particularly in black-box scenarios. The authors propose Adv-Pruning, a three-stage method that addresses this limitation by selectively pruning adversarial perturbations and introducing dodging-favorable perturbations. Experiments demonstrate that Adv-Pruning significantly enhances dodging attack success rates while maintaining impersonation capabilities across multiple datasets and face recognition models.

## Method Summary
Adv-Pruning introduces a three-stage approach to adversarial attacks: Priming, Pruning, and Restoration. The method first generates an initial adversarial perturbation through standard attacks, then quantifies the importance of each perturbation element to the attack success. During Pruning, less impactful perturbations are removed, creating space for dodging-favorable perturbations. The Restoration stage employs Biased Gradient Adaptation to reintroduce perturbations that enhance dodging capabilities while preserving impersonation performance. This selective approach allows the attack to optimize for both objectives simultaneously, addressing the fundamental limitation where impersonation-focused attacks fail to achieve strong dodging results.

## Key Results
- Adv-Pruning significantly improves dodging ASR (Attack Success Rate) while maintaining impersonation ASR compared to state-of-the-art methods
- The method proves effective across multiple datasets including LFW, CelebA-HQ, FFHQ, and BUPT-Balancedface
- Adv-Pruning maintains effectiveness under JPEG compression and against adversarial robust face recognition models

## Why This Works (Mechanism)
Adv-Pruning works by recognizing that impersonation and dodging attacks have fundamentally different optimization objectives. Impersonation requires minimizing the distance between the adversarial example and the target identity, while dodging requires maximizing distance from the original identity. By quantifying perturbation importance and selectively pruning less critical elements, the method creates space to optimize for the dodging objective without compromising impersonation success. The Biased Gradient Adaptation specifically targets the vacated regions with perturbations that favor dodging performance, effectively balancing both attack goals.

## Foundational Learning
- **Adversarial Perturbation**: Small, carefully crafted changes to input data that cause machine learning models to make mistakes. Why needed: Understanding perturbation mechanics is crucial for both attack and defense strategies.
- **Black-box Attack Setting**: Attack scenario where the adversary has no access to the target model's architecture or parameters. Why needed: Most real-world FR systems are black-box, making this setting practically relevant.
- **Attack Success Rate (ASR)**: Metric measuring the percentage of successful adversarial attacks. Why needed: Provides quantitative evaluation of attack effectiveness for both impersonation and dodging objectives.
- **Gradient-based Optimization**: Optimization technique using gradient information to iteratively improve solutions. Why needed: Core mechanism for generating and refining adversarial perturbations.
- **Adversarial Robustness**: Model's resistance to adversarial attacks. Why needed: Understanding robustness helps in designing more effective attack strategies and evaluating real-world security.

## Architecture Onboarding

**Component Map**: Input Image -> Initial Attack -> Perturbation Prioritization -> Pruning -> Biased Gradient Adaptation -> Final Adversarial Example

**Critical Path**: The attack pipeline follows Priming (initial adversarial generation) -> Pruning (perturbation selection) -> Restoration (dodging optimization) sequence, with each stage building on the previous one's output.

**Design Tradeoffs**: The three-stage approach increases computational overhead but provides superior performance compared to one-stage attacks. The pruning mechanism balances attack effectiveness with stealth by reducing unnecessary perturbations.

**Failure Signatures**: Attacks may fail when gradient information becomes uninformative after extensive pruning, or when the FR model employs highly adaptive defenses that counter pruning-based strategies.

**3 First Experiments**:
1. Baseline comparison of impersonation vs. dodging ASR on IR152 model using LFW dataset
2. Ablation study testing Adv-Pruning with and without Biased Gradient Adaptation
3. JPEG compression robustness evaluation comparing Adv-Pruning against traditional attacks

## Open Questions the Paper Calls Out
None

## Limitations
- The three-stage Adv-Pruning process increases computational overhead compared to simpler one-stage attacks
- The Biased Gradient Adaptation mechanism assumes gradient directions remain informative after pruning, which may not hold for all FR models
- Improvements may be dataset and model-specific rather than universally applicable

## Confidence
- **High confidence**: Previous impersonation attacks' failure to achieve strong dodging performance is well-supported by experimental evidence
- **Medium confidence**: Adv-Pruning's effectiveness in improving dodging ASRs while maintaining impersonation capabilities is demonstrated but may be context-dependent
- **Medium confidence**: JPEG robustness claims are based on controlled experiments but may not generalize to all real-world compression scenarios

## Next Checks
1. Test Adv-Pruning's effectiveness against adaptive defense mechanisms specifically designed to counter pruning-based attacks
2. Evaluate computational overhead and runtime efficiency compared to baseline attacks across different hardware configurations
3. Validate performance on additional diverse face datasets beyond those used in the study, particularly datasets with different demographic distributions