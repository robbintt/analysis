---
ver: rpa2
title: Augmented Risk Prediction for the Onset of Alzheimer's Disease from Electronic
  Health Records with Large Language Models
arxiv_id: '2405.16413'
source_url: https://arxiv.org/abs/2405.16413
tags:
- prediction
- llms
- data
- samples
- medical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a collaborative pipeline combining traditional
  supervised learning (SL) models and large language models (LLMs) for risk prediction
  of Alzheimer's disease and related dementias (ADRD) from electronic health records
  (EHRs). The pipeline leverages SLs for confident predictions and LLMs with in-context
  learning for complex cases.
---

# Augmented Risk Prediction for the Onset of Alzheimer's Disease from Electronic Health Records with Large Language Models

## Quick Facts
- **arXiv ID:** 2405.16413
- **Source URL:** https://arxiv.org/abs/2405.16413
- **Reference count:** 40
- **Primary result:** Collaborative pipeline combining supervised learning models with large language models achieves significant improvements in ADRD risk prediction, particularly for challenging samples where traditional models struggle

## Executive Summary
This paper proposes a novel collaborative pipeline for predicting Alzheimer's disease and related dementias (ADRD) risk using electronic health records (EHRs). The approach combines traditional supervised learning models with large language models (LLMs) in a hybrid architecture where SLMs handle confident predictions and LLMs address complex cases through in-context learning. Experiments on a large real-world EHR dataset from OHSU Hospital demonstrate that this collaborative approach significantly outperforms traditional supervised learning alone, particularly for challenging samples where conventional models struggle.

The research addresses a critical gap in ADRD risk prediction by leveraging the strengths of both statistical machine learning and modern language models. The findings suggest that neither larger LLM sizes nor medical domain fine-tuning consistently improves performance, indicating that the collaborative architecture itself is the key innovation rather than model scale or specialization. This work has important implications for clinical decision support systems and could improve early detection of cognitive decline in aging populations.

## Method Summary
The proposed method employs a hybrid collaborative pipeline that strategically combines supervised learning (SL) models with large language models (LLMs) for ADRD risk prediction from EHRs. The pipeline operates by first using traditional SL models to make initial risk predictions on patient data. For cases where SL models show low confidence in their predictions, the pipeline routes these challenging samples to LLMs, which leverage in-context learning capabilities to process complex clinical narratives and unstructured text data from EHRs.

The architecture is designed to optimize both performance and computational efficiency by allowing SL models to handle the majority of straightforward cases while reserving LLM processing for edge cases where traditional models struggle. This selective routing mechanism ensures that the computational overhead of LLM inference is only incurred when necessary. The approach addresses the inherent limitations of both methods: SL models excel at structured data patterns but struggle with complex, nuanced clinical narratives, while LLMs can process unstructured text effectively but may lack the statistical precision of trained medical prediction models.

## Key Results
- The collaborative pipeline achieves significant performance improvements over traditional supervised learning alone, particularly for challenging samples where SL models show low confidence
- Experimental results on OHSU Hospital's EHR dataset demonstrate consistent gains across multiple evaluation metrics, validating the effectiveness of the hybrid approach
- Neither increasing LLM model size nor fine-tuning on medical data consistently improves predictive performance, suggesting the collaborative architecture itself is the primary driver of improvements

## Why This Works (Mechanism)
The collaborative pipeline works by strategically leveraging the complementary strengths of supervised learning models and large language models. Supervised learning models excel at identifying patterns in structured EHR data and making confident predictions when clear statistical relationships exist. However, they often struggle with complex cases involving subtle clinical indicators, rare conditions, or nuanced temporal patterns in patient histories. Large language models, with their ability to process unstructured clinical narratives and understand context from in-context examples, can identify subtle indicators of cognitive decline that may be missed by traditional models.

The mechanism relies on a confidence-based routing system where SL models first process all cases and flag those where their confidence scores fall below a threshold. These complex cases are then passed to LLMs, which use in-context learning to analyze the full clinical context, including physician notes, family history descriptions, and other unstructured text that may contain critical indicators of ADRD risk. The LLM's ability to understand natural language and contextual relationships allows it to identify patterns and risk factors that are difficult to capture in structured data alone, particularly for cases involving atypical presentations or subtle early warning signs.

## Foundational Learning
- **Electronic Health Records (EHRs):** Structured and unstructured clinical data containing patient histories, diagnoses, medications, and clinical notes - needed for comprehensive patient risk assessment; quick check: understand typical EHR schema and common data elements
- **Supervised Learning for Medical Prediction:** Traditional ML approaches trained on labeled medical outcomes - needed for baseline risk prediction models; quick check: familiarity with common medical prediction algorithms and evaluation metrics
- **Large Language Models (LLMs):** Foundation models capable of processing and understanding natural language - needed for analyzing unstructured clinical text; quick check: understand LLM architecture basics and in-context learning capabilities
- **In-Context Learning:** LLM's ability to perform tasks using provided examples without fine-tuning - needed for efficient adaptation to medical prediction tasks; quick check: understand how few-shot learning works in practice
- **Collaborative AI Systems:** Hybrid approaches combining multiple AI paradigms - needed for optimal performance by leveraging complementary strengths; quick check: understand basic ensemble and hybrid model concepts
- **Clinical Risk Prediction:** Assessment of future health outcomes based on current data - needed for framing the medical application; quick check: understand common risk prediction frameworks in healthcare

## Architecture Onboarding

**Component Map:** EHR Data -> Supervised Learning Model -> Confidence Assessment -> LLM (for low-confidence cases) -> Risk Prediction Output

**Critical Path:** The critical path involves initial processing by supervised learning models, confidence threshold evaluation, routing of complex cases to LLMs, and final risk prediction synthesis. This path must ensure low-latency processing for high-confidence cases while maintaining accuracy for complex cases requiring LLM intervention.

**Design Tradeoffs:** The architecture trades computational efficiency for improved accuracy by using SL models for most predictions while reserving expensive LLM inference for challenging cases. This creates a dual-path system that balances real-time performance requirements with the need for high accuracy on complex clinical scenarios.

**Failure Signatures:** Potential failures include incorrect confidence threshold settings leading to unnecessary LLM processing or missed complex cases, LLM hallucination affecting risk predictions, and data quality issues in EHRs causing both models to fail. The system must also handle cases where neither model type performs well.

**First Experiments:** 1) Baseline evaluation of supervised learning models alone on the EHR dataset, 2) LLM-only performance assessment for ADRD prediction from clinical text, 3) Confidence threshold optimization to minimize LLM invocation while maximizing accuracy gains.

## Open Questions the Paper Calls Out
None

## Limitations
- The study lacks comparison against alternative collaborative approaches such as ensemble methods or knowledge distillation, making it unclear if the proposed pipeline is optimal
- Experimental results are based on a single institutional dataset (OHSU Hospital), limiting generalizability to other healthcare systems with different patient populations and EHR structures
- The paper does not provide detailed analysis of what specific features or patterns LLMs leverage to improve predictions on complex cases, nor does it discuss computational costs and latency implications for clinical deployment

## Confidence
- **Main performance claims:** Medium - results show improvements but are limited to single institutional dataset without broader validation
- **Generalizability claims:** Medium - effectiveness on challenging samples demonstrated but lacks cross-institutional validation
- **Computational efficiency claims:** Low - no discussion of latency or resource requirements for clinical deployment
- **No improvement from larger models/fine-tuning:** Medium - limited experimentation and acknowledged need for further investigation

## Next Checks
1. Conduct cross-institutional validation using EHR data from multiple healthcare systems to assess generalizability across different patient demographics, clinical practices, and documentation patterns.

2. Perform ablation studies comparing the proposed collaborative pipeline against alternative hybrid approaches (ensemble methods, knowledge distillation, different LLM integration strategies) to establish relative performance advantages.

3. Implement detailed feature importance and attention analysis to understand what specific information LLMs leverage from clinical text that traditional models miss, particularly for the "complex cases" that show improvement.