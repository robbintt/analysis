---
ver: rpa2
title: 'TSOM: Small Object Motion Detection Neural Network Inspired by Avian Visual
  Circuit'
arxiv_id: '2404.00855'
source_url: https://arxiv.org/abs/2404.00855
tags:
- motion
- object
- small
- neurons
- objects
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents TSOM, a small object motion detection neural
  network inspired by the avian visual circuit. The authors mathematically model the
  Retina-OT-Rt neural circuit to extract motion features of small objects.
---

# TSOM: Small Object Motion Detection Neural Network Inspired by Avian Visual Circuit

## Quick Facts
- **arXiv ID**: 2404.00855
- **Source URL**: https://arxiv.org/abs/2404.00855
- **Reference count**: 19
- **Primary result**: TSOM outperforms traditional methods in small object detection accuracy across various scenarios using biologically-inspired neural architecture

## Executive Summary
This paper presents TSOM, a biologically-inspired neural network for detecting small moving objects in complex backgrounds. The model mimics the avian visual system's Retina-OT-Rt neural circuit, using four layers (Retina, SGC dendritic, SGC Soma, Rt) to extract motion features from small objects. Extensive experiments on pigeon neurophysiological data and synthetic/real-world datasets demonstrate TSOM's effectiveness in detecting small objects from high-altitude perspectives while maintaining biological interpretability.

## Method Summary
TSOM implements a four-layer neural network architecture that mathematically models the avian visual circuit. The Retina layer projects input content accurately, the SGC dendritic layer encodes spatiotemporal information and detects motion energy, the SGC Soma layer applies spatial lateral inhibition to enhance small object contrast while suppressing background motion, and the Rt layer integrates motion information from multiple directions to determine object positions. The model uses scale-selective and direction-selective mechanisms inspired by avian visual neurons to enhance detection of small objects in complex backgrounds.

## Key Results
- TSOM achieves higher Detection Rate (DR) and lower False Alarm Rate (FA) compared to traditional methods (Frame Difference, Optical Flow, Mixture of Gaussians, apg-STMD) on both BEVS and RIST datasets
- The model effectively extracts small object motion features from complex high-altitude backgrounds while maintaining biological interpretability
- TSOM demonstrates superior performance in detecting objects smaller than 5 pixels, which is critical for small object motion detection applications

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The TSOM model successfully detects small object motion by mimicking the avian visual pathway's motion-sensitive neural circuits.
- Mechanism: The model uses a multi-layer architecture (Retina, SGC dendritic, SGC Soma, Rt) to process spatiotemporal information. The SGC Soma layer applies spatial lateral inhibition to enhance contrast between small objects and background, while the Rt layer integrates motion information from multiple directions to determine object positions.
- Core assumption: The biological properties of the avian visual system, particularly the Retina-OT-Rt circuit, are effective for small object motion detection in complex backgrounds.
- Evidence anchors:
  - [abstract] "Extensive experiments on pigeon neurophysiological data and image sequences demonstrate that TSOM is biologically interpretable and effectively extracts reliable small object motion features from complex high-altitude backgrounds."
  - [section] "The Retina-OT-Rt neural circuit plays a vital role in the feature extraction of small moving objects, essential for calculating visual saliency within the avian visual pathway."
  - [corpus] Weak evidence: Related papers focus on infrared small object detection and aerial object detection, but not specifically on avian-inspired neural networks for small object motion detection.

### Mechanism 2
- Claim: The SGC Soma layer's scale-selective characteristics enhance the detection of small objects by suppressing background motion.
- Mechanism: The SGC Soma layer applies a spatial lateral inhibition scale-selection kernel function to the motion energy map, which strongly responds to objects smaller than the response area and inhibits larger objects or background motion.
- Core assumption: The scale-selective properties of SGC neurons in the avian visual system can be effectively modeled and applied to small object detection in artificial neural networks.
- Evidence anchors:
  - [abstract] "The SGC Soma layer computes complex motion information and extracts small objects"
  - [section] "The receptive fields of SGCs exhibit relatively small excitatory centers surrounded by larger inhibitory surrounds, which respond strongly to minute, high-speed stimuli."
  - [corpus] Weak evidence: Related papers focus on small object detection in remote sensing imagery and sports object tracking, but not specifically on scale-selective mechanisms inspired by the avian visual system.

### Mechanism 3
- Claim: The two-stage projection from SGC to Rt neurons in the TSOM model increases the receptive field size and enhances small object detection.
- Mechanism: The model uses max-pooling to simulate the increased receptive field size of Rt neurons, which coarsens the precise spatial map and retains more texture information of small objects while suppressing smooth background information.
- Core assumption: The two-stage projection mechanism in the avian visual system can be effectively modeled and applied to artificial neural networks for small object detection.
- Evidence anchors:
  - [abstract] "The Rt layer integrates and decodes motion information from multiple directions to determine the position of small objects."
  - [section] "The projection of neurons from SGC to Rt neurons causes an increase in its receptive field, which results in the precise spatial map becoming coarser in the Rt."
  - [corpus] Weak evidence: Related papers focus on object detection and tracking, but not specifically on two-stage projection mechanisms inspired by the avian visual system.

## Foundational Learning

- **Avian visual system and the Retina-OT-Rt neural circuit**
  - Why needed here: Understanding the biological basis for the TSOM model's architecture and mechanisms
  - Quick check question: What are the main components of the avian visual system's Retina-OT-Rt neural circuit, and how do they contribute to small object motion detection?

- **Spatiotemporal information processing in neural networks**
  - Why needed here: Understanding how the TSOM model processes spatiotemporal information to detect small object motion
  - Quick check question: How does the TSOM model use spatiotemporal information processing to enhance small object detection in complex backgrounds?

- **Scale-selective and direction-selective mechanisms in neural networks**
  - Why needed here: Understanding how the TSOM model's SGC Soma and Rt layers use scale-selective and direction-selective mechanisms to enhance small object detection
  - Quick check question: How do the scale-selective and direction-selective mechanisms in the TSOM model's SGC Soma and Rt layers contribute to small object detection?

## Architecture Onboarding

- **Component map**: Input image → Retina layer → SGC dendritic layer → SGC Soma layer → Rt layer → Output motion feature map
- **Critical path**: Image sequences flow through four biological-inspired layers, with motion information being progressively encoded, enhanced, and integrated to produce final object position outputs
- **Design tradeoffs**: Balancing model complexity with biological interpretability, choosing appropriate scale-selective and direction-selective mechanisms, and managing computational efficiency versus detection accuracy
- **Failure signatures**: Inability to detect small objects in complex backgrounds, poor performance on objects of different scales or velocities, and reduced accuracy when object-background contrast is low
- **First 3 experiments**:
  1. Validate the biological consistency of the TSOM model's layers with corresponding neurons using synthetic image data
  2. Evaluate the TSOM model's performance on detecting small object motion in different scenarios using synthetic and real-world datasets
  3. Compare the TSOM model's performance with other small object detection methods using quantitative metrics such as detection rate and false alarm rate

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of TSOM vary when the object size is larger than 13 pixels, considering the model's selectivity for objects smaller than 5 pixels?
- Basis in paper: [explicit] "In the TSOM model, representing a single SGC neuron, the convolution kernel size is 13 pixels, which is selective for objects smaller than 5 pixels. Therefore, when the object radius is larger than 13 pixels, it exceeds the receptive field size of a single SGC neuron, activating surrounding neurons and consequently leading to a gradual increase in the correctness rate."
- Why unresolved: The paper discusses the model's performance with object sizes up to 13 pixels, but does not provide experimental results or analysis for object sizes larger than 13 pixels.
- What evidence would resolve it: Experimental results showing the model's performance with object sizes larger than 13 pixels, and a discussion of how the model handles these larger objects.

### Open Question 2
- Question: How does the TSOM model handle scenarios where there is low contrast between the small object and the surrounding background, particularly in the presence of high-contrast areas in the background?
- Basis in paper: [inferred] The paper mentions that "the proposed method’s ability to extract small objects is affected when there is low contrast between the small object and the surrounding background, particularly in the presence of high-contrast areas in the background, leading to decreased accuracy."
- Why unresolved: The paper acknowledges this limitation but does not provide a detailed analysis of how the model performs in such scenarios or potential solutions to improve performance.
- What evidence would resolve it: Experimental results showing the model's performance in scenarios with low contrast between the object and background, and a discussion of potential improvements to handle such cases.

### Open Question 3
- Question: How does the TSOM model's performance compare to other state-of-the-art methods in detecting small objects in scenarios with complex background motion and varying object velocities?
- Basis in paper: [explicit] The paper compares TSOM's performance to other methods (Frame Difference Method, Optical Flow, Mixture of Gaussians Background Modeling, and apg-STMD) in the BEVS and RIST datasets, but does not provide a comprehensive comparison with all state-of-the-art methods.
- Why unresolved: The paper provides a comparison with a limited set of methods and datasets, but does not explore the model's performance against a broader range of state-of-the-art methods or in more diverse scenarios.
- What evidence would resolve it: A comprehensive comparison of TSOM's performance against a wide range of state-of-the-art methods in various scenarios with complex background motion and varying object velocities.

## Limitations
- Limited ablation studies to isolate contributions of individual biological mechanisms
- Lack of comparisons against modern deep learning approaches beyond traditional computer vision methods
- Unclear generalization across different object scales and velocities

## Confidence
- **Biological interpretability claim**: High confidence - supported by detailed neurophysiological grounding and experimental validation with pigeon data
- **Effectiveness claim**: Medium confidence - supported by quantitative results on BEVS and RIST datasets but lacking broader benchmarking against state-of-the-art deep learning methods
- **Generalization claim**: Low confidence - not thoroughly evaluated across diverse scenarios and object characteristics

## Next Checks
1. **Ablation Study**: Systematically remove individual biological mechanisms (scale-selective filtering, two-stage projection, direction selectivity) to quantify their independent contributions to detection performance.

2. **Modern Method Comparison**: Benchmark TSOM against contemporary deep learning approaches like YOLO variants and transformer-based detectors on the same datasets to establish relative performance.

3. **Cross-Scale Generalization**: Test TSOM's robustness across multiple object size ranges and velocity categories using a comprehensive parameter sweep to identify performance boundaries.