---
ver: rpa2
title: Causality Extraction from Nuclear Licensee Event Reports Using a Hybrid Framework
arxiv_id: '2404.05656'
source_url: https://arxiv.org/abs/2404.05656
tags:
- causal
- text
- causality
- data
- cause
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of extracting causal relationships
  from nuclear licensee event reports (LERs) using a hybrid framework combining deep
  learning and knowledge-based approaches. The authors compiled a corpus of 20,129
  text samples from 92 LERs, developed an interactive tool for labeling cause-effect
  pairs, and implemented a two-stage approach for causality detection and extraction.
---

# Causality Extraction from Nuclear Licensee Event Reports Using a Hybrid Framework

## Quick Facts
- arXiv ID: 2404.05656
- Source URL: https://arxiv.org/abs/2404.05656
- Reference count: 13
- Key outcome: Hybrid deep learning and knowledge-based framework extracts causal relationships from nuclear licensee event reports with 99.1% detection accuracy and 181/252 extraction accuracy

## Executive Summary
This paper addresses the challenge of extracting causal relationships from nuclear licensee event reports (LERs) using a hybrid framework combining deep learning and knowledge-based approaches. The authors compiled a corpus of 20,129 text samples from 92 LERs, developed an interactive tool for labeling cause-effect pairs, and implemented a two-stage approach for causality detection and extraction. The framework successfully identifies causal sentences with high accuracy (99.1% test accuracy) and extracts cause-effect pairs using handcrafted patterns, achieving 181 correct pairs out of 252 attempts. The main limitation was difficulty handling implicit and embedded causality. The framework enables interpretation of complex narratives in nuclear operating experience reports, which is crucial for reliability and risk modeling in nuclear power plants.

## Method Summary
The framework employs a two-stage approach: first, a deep learning model based on bidirectional LSTM with convolutional layers detects whether sentences contain causal relationships; second, a knowledge-based system uses 39 handcrafted causal patterns to extract specific cause-effect pairs from identified causal sentences. The deep learning component processes preprocessed text through embedding and convolutional layers before bidirectional LSTM processing to capture contextual patterns indicative of causality. The pattern-based extraction component identifies linguistic markers such as "due to," "caused by," and "resulted in" to segment text into cause and effect components. The approach was trained on 80% of the data and validated on the remaining 20%, with manual evaluation of extracted cause-effect pairs by nuclear experts.

## Key Results
- Deep learning model achieved 99.1% test accuracy in detecting causal sentences from LERs
- Pattern-based extraction correctly identified 181 out of 252 causal pairs in the test set
- Model achieved 91.0% recall and 77.0% precision on the test set, deliberately prioritizing recall to uncover all possible causal relations
- The framework successfully processed 92 nuclear licensee event reports containing 20,129 text samples

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The hybrid framework effectively handles explicit causality through pattern-based extraction
- Mechanism: The knowledge-based approach uses handcrafted causal patterns (e.g., "due to", "caused by", "resulted in") to identify cause-effect segments in text
- Core assumption: Explicit causal relationships follow predictable linguistic patterns that can be captured through pattern matching
- Evidence anchors:
  - Two groups of causal patterns were defined, as shown in TABLE I. The C-E type defines patterns with cause and effect on the left and right segments of the sentence, respectively. The E-C type defines them in the opposite manner.
  - After identifying these phrases, the algorithm extracted text segments indicative of cause and effect, organizing them into pairs based on their contextual relationships.
- Break condition: When causal relationships are expressed through novel patterns not included in the handcrafted list, or when causality is implicit/embedded rather than explicit

### Mechanism 2
- Claim: Deep learning effectively detects causal sentences through contextual pattern recognition
- Mechanism: The bidirectional LSTM architecture learns to identify subtle patterns and contextual nuances indicative of causal relationships across multiple sentences
- Core assumption: Causal relationships create distinctive patterns in text that can be learned through representation learning
- Evidence anchors:
  - Causal relation extraction using deep learning represents a significant frontier in the field of natural language processing (NLP), and is crucial since it enables the interpretation of intricate narratives and connections contained within vast amounts of written information.
  - The heart of the proposed model lies in the two bidirectional long short-term memory layers. These are adept at remembering and using both past (backward) and future (forward) information in a sentence.
- Break condition: When causal relationships are expressed through novel linguistic constructions or when the context requires domain knowledge beyond what the model was trained on

### Mechanism 3
- Claim: The two-stage approach provides robustness by separating detection from extraction
- Mechanism: First stage (deep learning) identifies whether sentences contain causal relationships, then second stage (pattern-based) extracts specific cause-effect pairs from those identified sentences
- Core assumption: Separating the detection and extraction tasks allows each to specialize, improving overall performance
- Evidence anchors:
  - This paper proposed a hybrid framework for causality detection and extraction from nuclear licensee event reports. The main contributions include: (1) we compiled an LER corpus with 20,129 text samples for causality analysis, (2) developed an interactive tool for labeling cause effect pairs, (3) built a deep-learning-based approach for causal relation detection, and (4) developed a knowledge based cause-effect extraction approach.
  - This two-stage approach not only detects the existence of causality but also defines the precise sections of text that reflect such relationships.
- Break condition: When the detection stage misses causal sentences or when the extraction stage fails to properly pair causes with effects in complex sentences

## Foundational Learning

- Concept: Text preprocessing and tokenization
  - Why needed here: Clean text is essential for both the deep learning model and pattern-based extraction to function properly
  - Quick check question: What preprocessing steps are applied to the LER documents before they enter the causality classification model?

- Concept: Bidirectional LSTM networks
  - Why needed here: These networks capture context from both directions in the text, crucial for understanding complex causal relationships that may span multiple sentences
  - Quick check question: Why does the model use bidirectional LSTM layers instead of unidirectional ones for this task?

- Concept: Pattern-based information extraction
  - Why needed here: After detecting causal sentences, specific cause-effect pairs need to be extracted using linguistic patterns
  - Quick check question: How does the algorithm determine whether to assign the left or right segment as the cause versus the effect?

## Architecture Onboarding

- Component map: Data preprocessing -> Causality classification (deep learning) -> Cause-effect extraction (pattern-based) -> Evaluation
- Critical path: The deep learning model must accurately detect causal sentences before the pattern-based extraction can identify cause-effect pairs
- Design tradeoffs: The hybrid approach trades some precision (false positives in detection) for higher recall (finding all causal relations), which is appropriate for safety-critical nuclear applications
- Failure signatures: High false positives from detection stage indicate patterns too broad; extraction failures suggest pattern list is incomplete or complex sentence structures aren't handled
- First 3 experiments:
  1. Test the deep learning model on sentences with varying complexity to establish detection accuracy baseline
  2. Validate pattern-based extraction on single-sentence causal statements to confirm basic functionality
  3. Run end-to-end test on a small set of LERs to verify the integration between detection and extraction stages

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal balance between precision and recall for causal sentence detection in LER analysis, and how would adjusting this trade-off affect downstream reliability assessments?
- Basis in paper: The authors deliberately prioritized recall over precision (91.0% recall vs 77.0% precision on test set) to uncover all possible causal relations despite higher false positives.
- Why unresolved: The paper acknowledges this trade-off but does not explore alternative thresholds or cost-benefit analysis for different application scenarios.
- What evidence would resolve it: Comparative analysis of different precision-recall trade-offs across multiple nuclear plant datasets, with evaluation of impact on subsequent reliability model parameters and decision-making accuracy.

### Open Question 2
- Question: How can the framework be extended to handle implicit and embedded causality more effectively, which currently represent the main source of extraction errors?
- Basis in paper: The authors note that "the main errors that arose were from pairing causes and effects in embedded causal sentences" and that "future effort is needed for better extracting and matching cause-effect pairs in terms of implicit and embedded causality."
- Why unresolved: The current knowledge-based approach relies on explicit patterns and struggles with contextual inference required for implicit causality.
- What evidence would resolve it: Development and validation of hybrid approaches combining deep learning contextual understanding with pattern matching, tested on a larger corpus with comprehensive annotation of implicit causality cases.

### Open Question 3
- Question: What is the minimum required dataset size for achieving robust causal relation extraction performance, and how does dataset size impact model generalization across different types of nuclear equipment failures?
- Basis in paper: The authors note their dataset was "small, with a limited number of manually labeled cause-effect pairs" and plan to "increase the text corpus size, label more causal samples."
- Why unresolved: The current study used 343 labeled pairs from 92 reports, but the impact of dataset scale on performance and generalization is not quantified.
- What evidence would resolve it: Systematic scaling experiments varying dataset size and diversity, measuring performance metrics across different equipment types and failure modes to determine minimum viable training data requirements.

## Limitations
- Framework struggles with implicit and embedded causality, which were identified as the primary source of extraction errors
- Knowledge-based extraction relies on handcrafted patterns that may miss novel causal expressions
- Performance on multi-sentence causal relationships remains uncertain as evaluation focused primarily on single-sentence extraction
- Dataset of 92 LERs may not fully represent the diversity of causal expressions found in broader nuclear operational contexts

## Confidence
- High confidence in the detection accuracy (99.1% test accuracy) due to robust evaluation methodology and clear reporting
- Medium confidence in the extraction accuracy (181/252 correct pairs) as this metric depends heavily on the completeness of handcrafted patterns
- Medium confidence in the overall framework utility for safety-critical applications, pending validation on diverse datasets

## Next Checks
1. Test the framework on a separate validation set of LERs containing known implicit causality to quantify the performance gap in this domain
2. Evaluate the pattern-based extraction component independently on sentences with varying linguistic complexity to identify specific failure modes
3. Conduct a cross-domain validation by applying the trained model to causality extraction in related safety-critical domains (e.g., chemical processing or aerospace incident reports) to assess generalizability