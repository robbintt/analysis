---
ver: rpa2
title: Metamorphic Evaluation of ChatGPT as a Recommender System
arxiv_id: '2411.12121'
source_url: https://arxiv.org/abs/2411.12121
tags:
- prompt
- evaluation
- recommender
- metamorphic
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The study applies metamorphic testing to evaluate ChatGPT as a
  recommender system. It introduces a framework to control LLM randomness and tests
  four metamorphic relations: rating multiplication/shifting (RS perspective) and
  adding spaces/random words (LLM perspective) on the MovieLens dataset using GPT-3.5.'
---

# Metamorphic Evaluation of ChatGPT as a Recommender System

## Quick Facts
- arXiv ID: 2411.12121
- Source URL: https://arxiv.org/abs/2411.12121
- Reference count: 24
- Primary result: LLM-based recommender systems show low similarity scores under metamorphic relations, requiring different evaluation approaches than traditional systems

## Executive Summary
This study applies metamorphic testing to evaluate ChatGPT (GPT-3.5) as a recommender system using the MovieLens 100k dataset. The authors introduce a framework to control LLM randomness through prompt engineering and test four metamorphic relations from both recommender system and LLM perspectives. Results show significantly low similarity scores (Kendall œÑ: 0.48-0.50 for rating modifications, 0.06-0.23 for language modifications) compared to baseline, indicating that LLM-based recommender systems exhibit different behaviors than traditional systems when subjected to metamorphic testing.

## Method Summary
The study uses metamorphic testing to evaluate GPT-3.5 as a recommender system on MovieLens 100k. Authors control LLM randomness by fixing prompt parameters (l=20 items, k=5 recommendations) and define four metamorphic relations: rating multiplication (MR1), rating shifting (MR2), adding spaces (MR3), and adding random words (MR4). They compare outputs against a baseline using similarity metrics (Kendall œÑ, RBO, overlap ratio) across 10 iterations for statistical significance.

## Key Results
- Rating multiplication/shifting metamorphic relations show moderate similarity drops (Kendall œÑ: 0.48-0.50, RBO: 0.85-0.85)
- Language-based metamorphic relations (adding spaces/random words) show severe similarity drops (Kendall œÑ: 0.06-0.23, RBO: 0.47-0.68)
- LLM-based MRs performed worse than RS-based MRs in maintaining recommendation consistency
- Results indicate LLM-based recommender systems require different evaluation approaches than traditional systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Controlling LLM randomness via prompt engineering (fixing $l$ and $k$) enables reproducible metamorphic testing.
- Mechanism: By constraining the number of items in the prompt ($l=20$) and the number of top-k recommendations ($k=5$), the variability in ChatGPT's outputs is minimized, allowing consistent similarity metrics across iterations.
- Core assumption: LLM randomness is primarily driven by prompt length and output size, and can be mitigated by careful selection of these parameters.
- Evidence anchors:
  - [section] "To check for the impact on these variables on the recommendations and randomness during different iterations, similarity metrics were used - Kendall ùúè, Ranking Biased Overlap and overlap between the lists."
  - [section] "The results for ùëò is shown in Table 2. In the prompt construction here, we used all movies in user history if their corresponding ratings are greater than 3, which indicates a positive preference."
- Break condition: If the LLM's randomness is influenced by factors beyond prompt length and output size (e.g., temperature, internal state), this mechanism may not fully control variability.

### Mechanism 2
- Claim: Metamorphic relations defined from both RS and LLM perspectives reveal different failure modes in LLM-based recommender systems.
- Mechanism: RS-based MRs (rating multiplication/shifting) test consistency in user preference representation, while LLM-based MRs (adding spaces/random words) test robustness to linguistic variations. The differing impacts of these MRs highlight the need for diverse evaluation approaches.
- Core assumption: LLM-based recommender systems have distinct failure modes under RS-centric versus LLM-centric metamorphic relations.
- Evidence anchors:
  - [abstract] "Specifically, we examined the MRs from both RS and LLMs perspectives, including rating multiplication/shifting in RS and adding spaces/randomness in the LLMs prompt via prompt perturbation."
  - [section] "Table 4 shows the results of evaluating different Metamorphic Relations (MRs)...MR1 and MR2 performed better than MR3 and MR4."
- Break condition: If the LLM's architecture inherently handles linguistic variations well, the distinction between RS and LLM MRs may not reveal meaningful differences.

### Mechanism 3
- Claim: Low similarity scores in metamorphic testing indicate that LLM-based recommender systems require different evaluation approaches than traditional systems.
- Mechanism: The significant drop in Kendall ùúè and RBO scores when applying metamorphic relations demonstrates that LLM-based systems do not satisfy the same consistency expectations as traditional recommender systems.
- Core assumption: Traditional recommender systems are evaluated under the assumption that certain input perturbations should not significantly affect the output ranking.
- Evidence anchors:
  - [abstract] "Results show low similarity scores (Kendall ùúè: 0.48-0.50 for rating modifications, 0.06-0.23 for language modifications; RBO: 0.85-0.85 for rating modifications, 0.47-0.68 for language modifications) compared to baseline, indicating that LLM-based recommender systems require different evaluation approaches than traditional systems."
  - [section] "The generated lists were compared against a baseline list consisting of one iteration of top-5 recommendations generated using 20 movies with no modifications."
- Break condition: If the low similarity scores are due to the specific LLM model (GPT-3.5) rather than a general characteristic of LLM-based recommender systems, the conclusion may not be generalizable.

## Foundational Learning

- Concept: Metamorphic Testing
  - Why needed here: Metamorphic Testing is used to evaluate LLM-based recommender systems by defining metamorphic relations between inputs and checking if these relations hold in the outputs, addressing the test oracle problem.
  - Quick check question: What is the primary purpose of metamorphic testing in the context of LLM-based recommender systems?

- Concept: Prompt Engineering
  - Why needed here: Prompt engineering is used to control the randomness in LLM outputs by carefully constructing prompts with specific parameters, enabling reproducible metamorphic testing.
  - Quick check question: How does prompt engineering help in controlling the randomness of LLM outputs during metamorphic testing?

- Concept: Similarity Metrics (Kendall ùúè, RBO)
  - Why needed here: Similarity metrics like Kendall ùúè and RBO are used to measure the consistency of recommendation lists generated under different metamorphic relations, quantifying the impact of these relations on the system's output.
  - Quick check question: What do Kendall ùúè and RBO measure in the context of evaluating LLM-based recommender systems?

## Architecture Onboarding

- Component map: Prompt Construction -> Metamorphic Relations -> Output Refinement -> Evaluation Metrics -> Analysis of Results
- Critical path: Prompt Construction ‚Üí Metamorphic Relations ‚Üí Output Refinement ‚Üí Evaluation Metrics ‚Üí Analysis of Results
- Design tradeoffs: Balancing the need for comprehensive evaluation (multiple MRs, larger $l$ and $k$) with the need for reproducibility and computational efficiency (controlled randomness, smaller $l$ and $k$)
- Failure signatures: Low similarity scores (Kendall ùúè, RBO) when applying metamorphic relations indicate that the LLM-based recommender system does not satisfy the expected consistency, requiring different evaluation approaches
- First 3 experiments:
  1. Vary $l$ (number of items in prompt) and measure similarity metrics to determine optimal value for controlling randomness
  2. Apply RS-based MRs (rating multiplication/shifting) and measure similarity to assess consistency in user preference representation
  3. Apply LLM-based MRs (adding spaces/random words) and measure similarity to assess robustness to linguistic variations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different LLM architectures (e.g., GPT-4, Claude, LLaMA) perform when subjected to the same metamorphic evaluation framework?
- Basis in paper: [explicit] The study only evaluates GPT-3.5 and notes that different LLMs may exhibit varying degrees of robustness to metamorphic relations
- Why unresolved: The paper focuses exclusively on GPT-3.5 without comparing performance across different LLM architectures
- What evidence would resolve it: Comparative experiments applying the same metamorphic relations (MR1-MR4) to multiple LLM models using identical datasets and evaluation metrics

### Open Question 2
- Question: What is the relationship between the number of training examples in prompts and the consistency of LLM-based recommender system outputs?
- Basis in paper: [inferred] The study uses a fixed number of items (l=20) in prompts but doesn't explore how varying this parameter affects recommendation consistency
- Why unresolved: The paper only tests one configuration (l=20, k=5) without systematically varying the number of prompt examples
- What evidence would resolve it: Experiments systematically varying the number of items in prompts while measuring similarity metrics across different configurations

### Open Question 3
- Question: How do metamorphic relations affect LLM-based recommender systems differently than traditional collaborative filtering systems?
- Basis in paper: [explicit] The authors conclude that LLM-based RS require different evaluation approaches than traditional systems, but don't directly compare metamorphic testing results
- Why unresolved: The study focuses exclusively on LLM-based systems without comparing metamorphic evaluation results to traditional RS approaches
- What evidence would resolve it: Direct comparison applying the same metamorphic relations to both LLM-based and traditional collaborative filtering recommender systems using identical datasets

## Limitations
- Limited scope of MRs: Only four metamorphic relations tested, potentially missing other important failure modes
- Single LLM model and dataset: Results may not generalize beyond GPT-3.5 and MovieLens 100k
- Unknown mechanisms of LLM randomness: Exact mechanisms by which GPT-3.5 generates recommendations remain opaque

## Confidence
- High confidence: The methodology of using metamorphic testing to evaluate LLM-based recommender systems is sound, and the results (low similarity scores) are clearly presented
- Medium confidence: The conclusion that LLM-based recommender systems require different evaluation approaches than traditional systems is supported by the results, but the generalizability is limited by the study's scope
- Low confidence: The specific mechanisms by which the LLM generates recommendations and the exact impact of controlling $l$ and $k$ on randomness are not fully understood

## Next Checks
1. Expand the scope of metamorphic relations by testing additional MRs that cover broader failure modes including temporal dynamics and content diversity
2. Evaluate the framework on multiple LLM models (GPT-4, Claude) and datasets (Netflix Prize, Book-Crossing) to assess generalizability
3. Investigate the impact of temperature and other LLM parameters on randomness and framework effectiveness