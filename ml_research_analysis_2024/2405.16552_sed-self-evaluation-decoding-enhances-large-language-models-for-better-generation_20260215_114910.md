---
ver: rpa2
title: 'SED: Self-Evaluation Decoding Enhances Large Language Models for Better Generation'
arxiv_id: '2405.16552'
source_url: https://arxiv.org/abs/2405.16552
tags:
- decoding
- evaluation
- answer
- token
- chaotic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of large language models (LLMs)
  making suboptimal token selections at uncertain points during autoregressive decoding,
  which can significantly degrade the quality of generated text. The authors propose
  Self-Evaluation Decoding (SED), a method that mimics human decision-making by having
  LLMs first speculate on potential tokens at uncertain points, then evaluate those
  speculations, and finally select the token with the highest propensity score based
  on self-evaluation.
---

# SED: Self-Evaluation Decoding Enhances Large Language Models for Better Generation

## Quick Facts
- arXiv ID: 2405.16552
- Source URL: https://arxiv.org/abs/2405.16552
- Reference count: 38
- Key outcome: SED consistently outperforms greedy search, beam search, and nuclear sampling on QA and math tasks, e.g., 41.5% vs. 33.6% accuracy on XieZhi for llama2-7b-chat-hf.

## Executive Summary
This paper addresses the problem of large language models making suboptimal token selections at uncertain points during autoregressive decoding, which can significantly degrade the quality of generated text. The authors propose Self-Evaluation Decoding (SED), a method that mimics human decision-making by having LLMs first speculate on potential tokens at uncertain points, then evaluate those speculations, and finally select the token with the highest propensity score based on self-evaluation. The evaluation ability of the LLMs is enhanced through a data synthesis strategy that combines multi-model ensembling and supervised fine-tuning. Experiments across various tasks (HotpotQA, XieZhi, and GSM8K) using different LLMs (falcon-7b-instruct, llama2-7b-chat-hf, and gemma-7b-it) demonstrate that SED consistently outperforms standard decoding methods like greedy search, beam search, and nuclear sampling, achieving higher accuracy scores. For example, llama2-7b-chat-hf with SED achieves 41.5% accuracy on XieZhi compared to 33.6% with greedy search.

## Method Summary
The paper proposes Self-Evaluation Decoding (SED), a method that improves LLM decoding by introducing a speculation and self-evaluation loop at uncertain token positions. When the model detects uncertainty (via heuristic), it generates a set of candidate tokens, then uses an enhanced evaluation head to score each candidate's propensity. The candidate with the highest score is selected. The evaluation ability is boosted by a data synthesis pipeline combining multi-model ensembling and supervised fine-tuning on synthetic data. This approach is tested across three tasks (HotpotQA, XieZhi, GSM8K) and three 7B-parameter model families.

## Key Results
- SED consistently outperforms greedy search, beam search, and nuclear sampling across all tested tasks and models.
- For llama2-7b-chat-hf, SED achieves 41.5% accuracy on XieZhi versus 33.6% with greedy search.
- Improvements are observed for both reasoning (HotpotQA, GSM8K) and knowledge-based (XieZhi) tasks.

## Why This Works (Mechanism)
SED improves LLM decoding by deferring token choice at uncertain points and using a self-evaluation mechanism to select among speculative candidates. By leveraging synthetic data to enhance the model's evaluation capability, SED reduces the risk of suboptimal token selections that can degrade generation quality.

## Foundational Learning
- **Autoregressive decoding** (why needed: LLM generation proceeds one token at a time; quick check: trace token-by-token generation in a simple prompt)
- **Token uncertainty heuristics** (why needed: identify when model is unsure to trigger SED; quick check: inspect model logits for high entropy positions)
- **Multi-model ensembling for data synthesis** (why needed: generate diverse, high-quality training signals; quick check: compare synthetic vs. human data quality)
- **Propensity scoring** (why needed: quantify likelihood of a token being correct; quick check: compute and compare scores for top candidates)
- **Supervised fine-tuning (SFT)** (why needed: adapt model to improved evaluation capability; quick check: evaluate SFT impact on perplexity)
- **Speculation loop in decoding** (why needed: explore alternatives before committing to a token; quick check: run decoding with and without speculation)

## Architecture Onboarding
- **Component map:** Input text -> Uncertainty detection -> Speculation (generate candidates) -> Evaluation head (score candidates) -> Select highest propensity token -> Output token
- **Critical path:** Text → Uncertainty check → Speculative candidates → Evaluation scoring → Token selection → Next position
- **Design tradeoffs:** SED increases decoding time and computational cost due to speculation and scoring, but aims for higher generation quality; simpler heuristics for uncertainty detection trade off precision for speed
- **Failure signatures:** If uncertainty detection is too aggressive, SED may slow decoding without benefit; if evaluation scoring is poor, wrong tokens may still be selected
- **3 first experiments:**
  1. Run SED vs. greedy decoding on a held-out QA sample and compare accuracy
  2. Profile inference time and memory overhead for SED versus standard decoding
  3. Perform ablation: disable synthetic data SFT and measure drop in SED performance

## Open Questions the Paper Calls Out
None

## Limitations
- Only 7B-parameter models tested; scalability to larger models unclear
- Gains may stem partly from synthetic data rather than SED itself
- Inference efficiency and memory overhead not reported
- Uncertainty detection is heuristic and not rigorously justified
- No comparison with state-of-the-art decoding strategies like contrastive decoding or self-consistency

## Confidence
- High: Reported accuracy gains for SED versus greedy search/beam search are well supported by experimental tables and methodology is detailed for replication
- Medium: Claim of SED being "more effective than existing decoding methods" plausible but not conclusively shown due to lack of comparisons with SOTA decoding strategies
- Medium: Explanation that SED's advantage comes from deferring token choice at "uncertain points" is reasonable but not fully validated across diverse generation settings

## Next Checks
1. Benchmark SED against state-of-the-art decoding methods such as contrastive decoding and self-consistency on the same tasks to establish relative gains
2. Conduct ablation studies isolating the impact of the synthetic data used to enhance evaluation ability from the core SED mechanism
3. Test SED on larger-scale models (e.g., 70B+ parameters) and in open-ended generation tasks (e.g., story completion) to assess scalability and broader applicability