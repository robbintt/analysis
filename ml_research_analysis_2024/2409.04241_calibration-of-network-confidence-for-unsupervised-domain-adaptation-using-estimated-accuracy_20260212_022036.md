---
ver: rpa2
title: Calibration of Network Confidence for Unsupervised Domain Adaptation Using
  Estimated Accuracy
arxiv_id: '2409.04241'
source_url: https://arxiv.org/abs/2409.04241
tags:
- target
- domain
- accuracy
- calibration
- network
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the problem of calibrating network confidence
  while adapting a model trained on a source domain to a target domain using unlabeled
  target data. The key challenge is that the absence of target labels makes it impossible
  to directly calibrate the adapted network on the target domain.
---

# Calibration of Network Confidence for Unsupervised Domain Adaptation Using Estimated Accuracy

## Quick Facts
- arXiv ID: 2409.04241
- Source URL: https://arxiv.org/abs/2409.04241
- Reference count: 35
- Calibrates network confidence in unsupervised domain adaptation by estimating target domain accuracy from unlabeled data

## Executive Summary
This paper addresses the problem of calibrating network confidence when adapting models from a source domain to a target domain using only unlabeled target data. The key challenge is that without target labels, it's impossible to directly measure or calibrate confidence on the target domain. The authors propose UTDC (Unsupervised Target Domain Calibration), which estimates target domain accuracy by comparing source and target confidence distributions, then uses this estimate to calibrate the network directly on the target domain.

The method significantly outperforms existing importance weighting approaches on four standard domain adaptation benchmarks. UTDC achieves calibration errors nearly as good as an oracle method with access to target labels, improving adaECE from 31.34 to 7.93 on Office-home tasks, from 29.97 to 7.78 on Office-31, and from 31.63 to 7.84 on VisDA.

## Method Summary
UTDC estimates target domain accuracy using methods like Meta, ATC, or PN, then divides both source and target data into M equal-size bins by confidence. It computes source binwise accuracy and rescales it by the overall accuracy ratio to estimate target binwise accuracy. The method finds the optimal temperature that minimizes UDA-adaECE (the disparity between estimated accuracy and computed confidence on the target domain) via grid search, then applies temperature scaling to the network. The approach works because adaECE has a minimum near the true accuracy ratio, creating tolerance for estimation errors.

## Key Results
- UTDC significantly outperforms importance weighting methods on Office-home, Office-31, VisDA-2017, and DomainNet benchmarks
- Calibration error (adaECE) improves from 31.34 to 7.93 on Office-home tasks
- UTDC achieves calibration nearly as good as oracle methods with access to target labels
- Temperature scaling calibration on target domain outperforms calibration on source domain followed by importance weighting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The key innovation is estimating target domain accuracy from unlabeled data and using it to calibrate confidence directly on the target domain.
- Mechanism: The method divides both source and target data into bins based on confidence values. It then estimates target binwise accuracy by rescaling source binwise accuracy according to the overall accuracy ratio between domains (Equation 4). This estimated accuracy is used to minimize the disparity between estimated accuracy and computed confidence on the target domain (UDA-adaECE).
- Core assumption: The accuracy ratio between source and target domains is similar across confidence bins.
- Evidence anchors:
  - [abstract] "The network accuracy is first computed on the labeled source data and then is modified to represent the actual accuracy of the model on the target domain."
  - [section] "We next demonstrate the UDA calibration principle in the case of TS calibration. We can determine the temperature that minimizes the UDA-adaECE measure (Eq. (5)) by conducting a grid search on the possible values."
  - [corpus] Weak - related papers focus on distribution alignment but don't directly address the calibration gap estimation mechanism.
- Break condition: If the accuracy ratio varies significantly across confidence bins, the rescaling would produce incorrect estimates.

### Mechanism 2
- Claim: Importance weighting methods fail because they rely on an overly optimistic accuracy estimation from source domain data.
- Mechanism: Existing importance weighting methods use unlabeled target data only to train a binary source/target classifier, but the actual calibration is done on source domain data while ignoring target domain data. This leads to calibration temperatures that are too small.
- Core assumption: The network's accuracy on the source domain is consistently higher than on the target domain, even after adaptation.
- Evidence anchors:
  - [section] "Fig. 2 presents the accuracy on the source and target domains for three UDA techniques. It shows that even after adaptation to the target, the model's performance on the source samples is consistently better than its performance on the target samples."
  - [section] "Tab. 7 compares the optimal temperatures computed by the calibration methods. In all the baseline methods the computed calibration temperature was lower than the optimal value."
  - [corpus] Weak - related papers discuss domain adaptation but don't specifically analyze why importance weighting fails for calibration.
- Break condition: If the domain adaptation perfectly bridges the domain gap, source and target accuracies would be similar, making importance weighting viable.

### Mechanism 3
- Claim: UTDC is robust to errors in target accuracy estimation because adaECE has a minimum near the true accuracy ratio.
- Mechanism: The calibration method searches for the temperature that minimizes UDA-adaECE as a function of the accuracy ratio R. The adaECE reaches a minimum near R(true) and R(estimated), creating a tolerance for error in estimating target accuracy.
- Core assumption: The adaECE function is smooth and has a well-defined minimum in the region of plausible accuracy ratios.
- Evidence anchors:
  - [section] "Fig. 3 shows the adaECE measure on the target data after temperature scaling by ˆT (R) as a function of the ratio R for the task Office-home A → C. It shows that with the appropriate choice of R we can achieve the calibration level of the Oracle TS-target algorithm."
  - [section] "In addition, the adaECE reaches a minimum near R(true) and R(estimated). Finally, there is a range of correction ratios where UTDC is better by a large margin than other baselines, thus providing a tolerance for error and resilience in estimating ˜Atarget."
  - [corpus] Weak - related papers don't discuss the mathematical properties of adaECE under accuracy ratio perturbations.
- Break condition: If adaECE is too sensitive to accuracy ratio errors, small estimation errors would lead to poor calibration.

## Foundational Learning

- Concept: Expected Calibration Error (ECE) and Adaptive ECE (adaECE)
  - Why needed here: These metrics measure the discrepancy between predicted confidence and actual accuracy, which is the core problem UTDC addresses.
  - Quick check question: What's the difference between ECE and adaECE, and why does UTDC use adaECE instead of ECE?

- Concept: Temperature Scaling for calibration
  - Why needed here: UTDC uses temperature scaling as its calibration method, applying it directly on the target domain rather than the source domain.
  - Quick check question: How does temperature scaling modify the network's logits to produce calibrated probabilities?

- Concept: Domain adaptation and domain shift
  - Why needed here: The method operates in the unsupervised domain adaptation setting where a model trained on a source domain is adapted to a target domain without labels.
  - Quick check question: Why is it particularly challenging to calibrate confidence in unsupervised domain adaptation compared to standard supervised learning?

## Architecture Onboarding

- Component map: Adapted model -> Confidence computation on target -> Accuracy estimation on target -> AdaECE minimization -> Temperature scaling

- Critical path: Model → Confidence computation on target → Accuracy estimation on target → AdaECE minimization → Temperature scaling

- Design tradeoffs:
  - Choice of target accuracy estimation method (Meta is most accurate but computationally expensive; ATC is simpler but less precise)
  - Number of bins M (too few bins lose granularity; too many bins lead to sparse statistics)
  - Grid search resolution for temperature T (finer resolution increases accuracy but computational cost)

- Failure signatures:
  - Calibration performance worse than uncalibrated model (suggests incorrect accuracy estimation or bin size mismatch)
  - adaECE plateaus at high values across temperature range (suggests fundamental mismatch between source and target distributions)
  - Temperature optimization gets stuck at boundary values (suggests need for wider temperature search range)

- First 3 experiments:
  1. Implement UTDC with Meta accuracy estimation on Office-home A→R task, compare adaECE with uncalibrated and Source-TS baselines
  2. Test sensitivity to number of bins by running with M=5, 10, 15, 20 and measuring calibration degradation
  3. Implement UTDC with ATC accuracy estimation and compare results to Meta-based UTDC on the same tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different target domain accuracy estimation methods (Meta, ATC, PN) compare in terms of computational efficiency and calibration performance across various domain adaptation tasks?
- Basis in paper: [explicit] Section 5 discusses different target accuracy estimation methods and their impact on UTDC performance
- Why unresolved: The paper shows UTDC-Meta performs best but doesn't provide detailed computational complexity analysis or extensive comparison across diverse tasks
- What evidence would resolve it: Systematic benchmark comparing runtime, memory usage, and calibration performance of all three methods across multiple datasets with varying domain shifts

### Open Question 2
- Question: Can the UTDC framework be extended to non-parametric calibration methods like conformal prediction for domain adaptation?
- Basis in paper: [inferred] Section 6 mentions "domain shift problems in non-parametric calibration methods such as conformal prediction" as a future research direction
- Why unresolved: The paper focuses exclusively on parametric calibration methods (temperature scaling) and doesn't explore non-parametric alternatives
- What evidence would resolve it: Implementation and evaluation of UTDC principles applied to conformal prediction methods, demonstrating calibration improvement in UDA scenarios

### Open Question 3
- Question: How does the UTDC method perform when applied to regression and segmentation tasks under domain shift?
- Basis in paper: [inferred] Section 6 suggests exploring UTDC in regression and segmentation tasks as future work
- Why unresolved: All experiments and analysis are limited to classification tasks, with no investigation of continuous output or structured prediction problems
- What evidence would resolve it: Experiments applying UTDC to regression and segmentation benchmarks, measuring calibration quality and task performance under domain adaptation

### Open Question 4
- Question: What is the theoretical relationship between the accuracy ratio correction and the optimal calibration temperature across different domain adaptation scenarios?
- Basis in paper: [explicit] Section 5 analyzes sensitivity of UTDC to accuracy ratio estimation and shows adaECE minimum near true ratio
- Why unresolved: While empirical results show good performance near true ratio, there's no theoretical analysis of the relationship between accuracy ratio estimation error and optimal temperature
- What evidence would resolve it: Mathematical derivation connecting accuracy ratio estimation error to calibration temperature error, potentially leading to adaptive correction methods

## Limitations
- Effectiveness heavily depends on accurate estimation of target domain accuracy without labels
- Performance may be sensitive to the number of bins used for dividing confidence distributions
- Assumes accuracy ratio between domains is similar across confidence bins, which may not hold for large domain shifts

## Confidence
- **High confidence**: The mathematical formulation of UDA-adaECE and temperature scaling approach are sound and well-defined
- **Medium confidence**: Experimental results show significant improvements over baseline methods, but evaluation is limited to specific datasets and adaptation methods
- **Low confidence**: Theoretical guarantees for accuracy estimation methods and their robustness to estimation errors are not established

## Next Checks
1. Conduct ablation studies varying the number of bins (M) and grid search resolution for temperature optimization to quantify sensitivity to these hyperparameters.

2. Test UTDC on additional domain adaptation datasets and with different adaptation methods to assess generalizability beyond the four benchmark datasets used in the paper.

3. Implement error analysis for each target accuracy estimation method (Meta, ATC, PN) by comparing their estimates against ground truth accuracy when labels become available in a subset of target data.