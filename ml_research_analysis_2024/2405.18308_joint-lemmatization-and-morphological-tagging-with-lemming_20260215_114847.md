---
ver: rpa2
title: Joint Lemmatization and Morphological Tagging with LEMMING
arxiv_id: '2405.18308'
source_url: https://arxiv.org/abs/2405.18308
tags: []
core_contribution: This paper introduces LEMMING, a joint log-linear model for lemmatization
  and morphological tagging. The method uses a modular log-linear model that supports
  arbitrary global features on lemmas and can be trained on corpora annotated with
  gold standard tags and lemmas.
---

# Joint Lemmatization and Morphological Tagging with LEMMING

## Quick Facts
- **arXiv ID**: 2405.18308
- **Source URL**: https://arxiv.org/abs/2405.18308
- **Reference count**: 35
- **Primary result**: Joint log-linear model achieves state-of-the-art token-based lemmatization and morphological tagging across six languages

## Executive Summary
This paper introduces LEMMING, a joint log-linear model for lemmatization and morphological tagging that sets a new state of the art on six languages. The method uses a modular log-linear model that supports arbitrary global features on lemmas and can be trained on corpora annotated with gold standard tags and lemmas. LEMMING employs edit trees for candidate selection and includes features such as edit trees, alignment, dictionary entries, and morphological attributes. The joint modeling approach significantly improves both lemmatization and tagging accuracy, with Czech lemma errors reduced by over 60% and joint accuracy improvements for four out of six languages.

## Method Summary
LEMMING is a joint log-linear model for lemmatization and morphological tagging that uses edit trees for candidate selection and incorporates multiple feature types including edit trees, alignments, dictionary entries, and morphological attributes. The model generates lemma candidates using edit trees, extracts features for each form-lemma pair, and jointly decodes tags and lemmas using a tree-structured CRF. It is trained using SGD with belief propagation inference and initialized with a pretrained tagging model for joint training. The method does not require morphological dictionaries or analyzers, relying only on annotated corpora and external lexical resources like Wikipedia frequency data and ASPELL dictionaries.

## Key Results
- LEMMING sets new state of the art in token-based statistical lemmatization on six languages
- Czech lemma errors reduced from 4.05% to 1.58% (over 60% reduction)
- Joint accuracy improvements for four out of six languages (>6% for joint tag+lemma accuracy)
- Strong performance on unknown forms across all languages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Joint modeling of morphological tags and lemmas improves both tasks because morphological attributes disambiguate lemma forms and lemma forms disambiguate morphological tags.
- Mechanism: The log-linear model integrates tag and lemma prediction in a tree-structured CRF, allowing features from one task to inform the other. This coupling reduces errors compared to pipelined approaches.
- Core assumption: The mutual dependency between lemma and tag disambiguation is strong enough to produce measurable gains.
- Evidence anchors: Joint modeling significantly improves both lemmatization and tagging accuracy, reducing lemma errors by more than 37% for Czech and more than 6% for joint accuracy for four out of six languages.

### Mechanism 2
- Claim: Edit trees enable generalization from known form-lemma pairs to unknown forms by capturing orthographic transformations.
- Mechanism: The model pre-extracts edit trees that represent common substitution operations between inflected forms and their lemmas, allowing the system to apply these transformations to unseen forms.
- Core assumption: Edit trees extracted from training data are generalizable to unseen forms and sufficient to cover morphological variations.
- Evidence anchors: To generate candidates, the model applies all edit trees and adds all lemmata seen with the form in training. Edit trees encode substitution nodes and prefix/suffix lengths.

### Mechanism 3
- Claim: Global features on the lemma (such as dictionary membership and morphological attributes) improve lemmatization accuracy by providing additional constraints.
- Mechanism: The model incorporates features like whether a candidate lemma appears in Wikipedia or a dictionary, and whether it matches morphological attribute patterns, to score lemma candidates more accurately.
- Core assumption: External lexical resources and morphological patterns provide reliable signals for lemma selection.
- Evidence anchors: Features include whether lemmas occur >5 times in Wikipedia and whether they occur in the ASPELL dictionary, along with morphological attribute conjunctions.

## Foundational Learning

- **Log-linear models and CRFs**: Why needed - The paper uses a log-linear model for lemmatization and a CRF for joint tag and lemma prediction. Quick check: What is the difference between a log-linear model and a linear chain CRF in terms of structure and normalization?

- **Edit distance and string alignment**: Why needed - Edit trees are built using longest common substring (LCS) and alignment between forms and lemmas. Quick check: How does the longest common substring algorithm work, and why is it useful for morphological analysis?

- **Feature engineering for sequence labeling**: Why needed - The model uses multiple feature types including edit trees, alignment features, dictionary features, and morphological attributes. Quick check: What are the benefits and drawbacks of using conjunctions between features in sequence labeling models?

## Architecture Onboarding

- **Component map**: Candidate generation (edit trees) -> Feature extraction (edit tree, alignment, dictionary, morphological features) -> Log-linear model for lemmatization -> CRF component for morphological tagging -> Joint decoding (belief propagation)

- **Critical path**: 1. Preprocess training data to extract edit trees 2. Generate lemma candidates for each form using edit trees 3. Extract features for each form-lemma pair 4. Train log-linear lemmatization model 5. Train CRF for morphological tagging 6. Jointly decode tags and lemmas using tree-structured CRF

- **Design tradeoffs**: Edit trees vs. other candidate generation methods (edit trees provide good coverage with reasonable computational cost); Pipeline vs. joint modeling (joint modeling improves accuracy but increases model complexity); Feature richness vs. overfitting (more features capture more patterns but may overfit)

- **Failure signatures**: Low lemma accuracy (poor candidate selection or insufficient feature coverage); High unknown word error rate (edit trees not covering morphological patterns of unseen forms); Degraded performance with morphology (feature engineering issues with morphological attribute handling)

- **First 3 experiments**: 1. Test edit tree coverage on development data - calculate what percentage of correct lemmas are generated as candidates 2. Ablation study on feature types - train models with different feature combinations to identify most important features 3. Compare pipeline vs. joint performance on a single language - measure improvements in both lemma and tag accuracy

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but based on the limitations and scope of the research, several questions remain unexplored: How would joint modeling perform on low-resource languages? What is the impact of different alignment strategies on lemmatization accuracy? How does performance scale with increasing morphological complexity beyond the six languages studied?

## Limitations
- Edit tree coverage is limited, with only 92% coverage on Czech development data, dropping further for unknown words
- Feature engineering effectiveness varies significantly across languages, with modest gains for some languages
- Joint modeling benefits are not uniform across all languages, improving accuracy for only four out of six languages

## Confidence

- **High Confidence**: Edit trees provide reasonable candidate coverage for known forms, evidenced by 92% coverage on Czech development data
- **Medium Confidence**: Joint modeling improves accuracy compared to pipeline approaches, based on consistent improvements across four languages
- **Low Confidence**: External lexical features are universally beneficial, as their effectiveness depends heavily on resource availability and quality

## Next Checks

1. **Edit Tree Coverage Analysis**: Calculate edit tree coverage percentages on development sets for all six languages, particularly focusing on unknown word performance. If coverage falls below 90% for any language, investigate whether alternative candidate generation methods are needed.

2. **Cross-Lingual Feature Importance**: Perform ablation studies isolating each feature type (edit trees, alignment, dictionary, morphological attributes) separately for each language. Compare feature importance rankings across languages to identify which features are truly universal versus language-specific.

3. **Pipeline vs. Joint Performance Decomposition**: For languages showing no joint accuracy improvement, conduct detailed error analysis to determine whether the joint model makes different types of errors than the pipeline, or simply redistributes existing errors. This would reveal whether the joint approach's benefits are task-dependent.