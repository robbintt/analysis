---
ver: rpa2
title: 'TeamCraft: A Benchmark for Multi-Modal Multi-Agent Systems in Minecraft'
arxiv_id: '2412.05255'
source_url: https://arxiv.org/abs/2412.05255
tags:
- task
- agents
- bot1
- bot2
- actions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TeamCraft is a benchmark for evaluating multi-modal multi-agent
  systems using Minecraft as a simulation environment. It introduces complex tasks
  like building, clearing, farming, and smelting, requiring agents to collaborate
  using visual observations and multi-modal prompts.
---

# TeamCraft: A Benchmark for Multi-Modal Multi-Agent Systems in Minecraft

## Quick Facts
- arXiv ID: 2412.05255
- Source URL: https://arxiv.org/abs/2412.05255
- Reference count: 40
- TeamCraft is a benchmark for evaluating multi-modal multi-agent systems using Minecraft as a simulation environment.

## Executive Summary
TeamCraft introduces a comprehensive benchmark for evaluating multi-modal multi-agent systems in Minecraft, focusing on complex collaborative tasks such as building, clearing, farming, and smelting. The benchmark generates 55,000 procedurally-generated task variants and tests agents' abilities to coordinate using visual observations and multi-modal prompts. Experiments reveal significant challenges in task success rates, particularly in decentralized settings, highlighting limitations in current vision-language-action models' spatial reasoning and inter-agent communication capabilities.

## Method Summary
The benchmark employs Minecraft as a simulation environment where agents must collaborate to complete complex tasks. Agents receive visual observations and multi-modal prompts, requiring them to coordinate actions across different roles. The system evaluates generalization across novel goals, scenes, and varying numbers of agents. Task success is measured through completion rates, with particular attention to decentralized coordination challenges.

## Key Results
- Vision-language-action models show significant challenges in task success rates within decentralized multi-agent settings
- Inter-agent communication and spatial reasoning emerge as critical bottlenecks for current approaches
- The benchmark's 55,000 procedurally-generated task variants demonstrate substantial generalization challenges for existing multi-modal multi-agent systems

## Why This Works (Mechanism)
TeamCraft's effectiveness stems from its realistic multi-agent coordination requirements in a complex environment. The Minecraft setting provides rich visual observations and spatial reasoning challenges that mirror real-world collaborative scenarios. The multi-modal prompts force agents to integrate language understanding with visual perception and action planning, creating a comprehensive evaluation framework for multi-agent system capabilities.

## Foundational Learning
- Multi-modal integration: Why needed - Combines vision, language, and action for realistic task completion; Quick check - Verify agents can process and integrate different input modalities
- Spatial reasoning: Why needed - Essential for navigation and object manipulation in 3D environments; Quick check - Test agent's ability to locate and interact with objects in varied scenes
- Decentralized coordination: Why needed - Mimics real-world scenarios where agents must cooperate without central control; Quick check - Evaluate task success rates in purely decentralized settings

## Architecture Onboarding

Component map:
VLA Model -> Multi-Agent Coordination -> Task Execution -> Performance Evaluation

Critical path:
Visual observation intake → Multi-modal prompt processing → Action decision → Inter-agent communication → Task completion

Design tradeoffs:
Centralized vs decentralized coordination - centralized offers better coordination but less scalability; decentralized is more scalable but harder to coordinate
Vision resolution vs processing speed - higher resolution provides better spatial understanding but increases computational cost
Communication frequency vs bandwidth - more frequent communication improves coordination but consumes more resources

Failure signatures:
Low task completion rates indicate poor spatial reasoning or coordination
High communication overhead with low success suggests inefficient coordination mechanisms
Task-specific failures point to limitations in particular skill areas (building, farming, etc.)

First experiments:
1. Test single-agent performance to establish baseline capabilities
2. Evaluate agent coordination in simple two-agent scenarios
3. Measure performance degradation as task complexity increases

## Open Questions the Paper Calls Out
None

## Limitations
- Current approaches show significant limitations in decentralized multi-agent coordination
- Vision-language-action models struggle with complex spatial reasoning requirements
- The benchmark may not fully capture all aspects of real-world multi-agent collaboration

## Confidence

| Claim | Confidence |
|-------|------------|
| TeamCraft provides a challenging benchmark for multi-modal multi-agent systems | High |
| Current VLA models struggle with spatial reasoning and inter-agent communication | Medium |
| TeamCraft's 55,000 procedurally-generated task variants ensure robust evaluation | Medium |

## Next Checks
1. Conduct ablation studies to isolate the impact of different components (vision, language, action) on task success rates
2. Test additional multi-agent coordination mechanisms beyond the current decentralized approach
3. Evaluate the benchmark's scalability by testing with larger numbers of agents and more complex task dependencies