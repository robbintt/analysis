---
ver: rpa2
title: 'CoLafier: Collaborative Noisy Label Purifier With Local Intrinsic Dimensionality
  Guidance'
arxiv_id: '2401.05458'
source_url: https://arxiv.org/abs/2401.05458
tags:
- label
- noise
- noisy
- colafier
- labels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "CoLafier introduces a novel approach to handling noisy labels\
  \ in deep learning by leveraging Local Intrinsic Dimensionality (LID) to distinguish\
  \ between correctly and incorrectly labeled instances. The framework employs two\
  \ subnets\u2014LID-dis and LID-gen\u2014that process dual augmented views of each\
  \ instance."
---

# CoLafier: Collaborative Noisy Label Purifier With Local Intrinsic Dimensionality Guidance

## Quick Facts
- arXiv ID: 2401.05458
- Source URL: https://arxiv.org/abs/2401.05458
- Reference count: 40
- Primary result: Achieves 84.42% accuracy on CIFAR-10 under 80% symmetric label noise

## Executive Summary
CoLafier introduces a novel approach to handling noisy labels in deep learning by leveraging Local Intrinsic Dimensionality (LID) to distinguish between correctly and incorrectly labeled instances. The framework employs two subnets—LID-dis and LID-gen—that process dual augmented views of each instance. LID-dis, trained to predict labels using both features and labels, generates enhanced representations from which LID scores are computed to differentiate label correctness. LID-gen operates as a standard classifier on features alone. During training, CoLafier assigns instance-specific weights to the loss function using LID scores from both views and refines labels by comparing LID scores and prediction discrepancies between the two subnets. Extensive evaluations on CIFAR-10 datasets under symmetric, asymmetric, and instance-dependent noise conditions demonstrate that CoLafier achieves state-of-the-art performance, with prediction accuracy surpassing existing methods, particularly under severe noise conditions. For instance, under 80% symmetric noise, CoLafier attains 84.42% accuracy, outperforming competing approaches. The dual-view and dual-subnet design effectively mitigates error accumulation and enhances robustness, making CoLafier a reliable solution for real-world noisy label scenarios.

## Method Summary
CoLafier processes each instance through two augmentation views (random crop+flip and random crop+flip+RandAugment) and two subnets (LID-dis and LID-gen). LID-dis takes both features and labels as input to generate enhanced representations, from which LID scores are computed to distinguish label correctness. LID-gen operates as a standard classifier on features alone. The framework assigns instance-specific weights based on LID scores, with clean instances trained using standard cross-entropy, noisy instances using robust losses (GCE) or CutMix, and hard instances using CutMix. Labels are refined by comparing LID scores and prediction discrepancies between the two subnets. The system is trained using AdamW optimizer (lr=0.001, weight_decay=0.001) for 200 epochs with 15-epoch warmup using cross-entropy loss before applying LID-based weighting and label correction.

## Key Results
- Achieves 84.42% accuracy on CIFAR-10 under 80% symmetric noise, outperforming competing approaches
- Demonstrates superior performance across symmetric (20%/50%/80%), asymmetric (40%), and instance-dependent (20%/40%/60%) noise conditions
- Shows consistent improvements on real-world noisy datasets like CIFAR-10N
- The dual-view and dual-subnet design effectively reduces error accumulation and enhances overall robustness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LID-dis learns enhanced representations that distinguish true-labeled from false-labeled instances based on their Local Intrinsic Dimensionality (LID) scores.
- Mechanism: LID-dis takes both features and labels as input, creating an enhanced representation where LID scores effectively separate instances with correct vs incorrect labels. This occurs because true-labeled instances have lower LID scores reflecting the data's intrinsic structure, while false-labeled instances have higher LID scores indicating overfitting to noise.
- Core assumption: The intrinsic dimensionality of data is lower when labels are correct, and increases when labels are incorrect due to the model fitting to label noise rather than data structure.
- Evidence anchors:
  - [abstract] "We observe that LID scores computed from this representation effectively distinguish between correct and incorrect labels across various noise scenarios."
  - [section] "false-labeled instances tend to have higher LID scores compared to true-labeled instances"
  - [corpus] Weak - corpus papers discuss LID for outlier detection and graph embeddings but don't directly validate this specific claim about label noise.
- Break condition: If the label noise pattern is such that incorrect labels still align with the data's intrinsic structure, LID scores may not effectively differentiate between correct and incorrect labels.

### Mechanism 2
- Claim: Dual-view and dual-subnet design reduces error accumulation by cross-validating label correctness across multiple perspectives.
- Mechanism: Two augmented views per instance are processed by both LID-dis and LID-gen. LID scores from both views are used to weight the loss function, while prediction discrepancies between the two subnets inform label update decisions. This redundancy ensures no single view or subnet dominates the decision-making process.
- Core assumption: Label noise is not perfectly correlated across different augmented views, and different subnet architectures will have different error patterns that can be exploited for cross-validation.
- Evidence anchors:
  - [abstract] "This dual-view and dual-subnet approach significantly reduces the risk of errors and enhances the overall effectiveness of the framework."
  - [section] "This dual-view and dual-subnet approach significantly reduces the risk of errors and enhances the overall effectiveness of the framework."
  - [corpus] Weak - corpus papers discuss graph embeddings and outlier detection but don't validate this specific dual-view, dual-subnet error reduction mechanism.
- Break condition: If the noise pattern is perfectly correlated across augmented views or if both subnets have identical failure modes, the cross-validation benefit disappears.

### Mechanism 3
- Claim: Instance-specific weighting based on LID scores allows adaptive handling of different noise levels within the same batch.
- Mechanism: Instances with low LID scores receive higher clean weights and are trained with standard cross-entropy loss, while instances with high LID scores receive higher noisy weights and are trained with robust losses (GCE) or CutMix augmentation. This ensures the model focuses more on likely correct labels while still extracting useful information from noisy labels.
- Core assumption: LID scores are reliable indicators of label correctness at the instance level, allowing for meaningful differentiation between clean and noisy instances within the same batch.
- Evidence anchors:
  - [abstract] "CoLafier considers the LID scores from the two views as produced by LID-dis to assign weights in an adapted loss function for both subnets."
  - [section] "Using the two LID scores from last step, CoLafier allocates weights to each instance. Every instance is endowed with three distinct weights: clean, noisy, hard weights"
  - [corpus] Weak - corpus papers discuss LID for various applications but don't validate this specific instance-specific weighting approach for noisy label learning.
- Break condition: If LID scores become unreliable predictors of label correctness (e.g., due to severe noise or specific noise patterns), the weighting mechanism may assign incorrect priorities to instances.

## Foundational Learning

- Concept: Local Intrinsic Dimensionality (LID)
  - Why needed here: LID provides a theoretically grounded measure of how the data's intrinsic structure changes when labels are correct vs incorrect, forming the basis for distinguishing true-labeled from false-labeled instances.
  - Quick check question: What does a higher LID score indicate about the relationship between a data point and its local neighborhood in feature-label space?

- Concept: Dual-view augmentation
  - Why needed here: Creating multiple views of each instance allows the framework to cross-validate label correctness and reduces the risk of error accumulation by ensuring decisions aren't based on a single perspective.
  - Quick check question: Why does using two different augmentation strategies (random cropping + horizontal flipping vs random cropping + horizontal flipping + RandAugment) help in distinguishing label noise?

- Concept: Instance-dependent weighting
  - Why needed here: Different instances in a batch may have different levels of label noise, requiring adaptive treatment rather than uniform handling across all samples.
  - Quick check question: How does the framework determine which instances should be treated as clean, hard, or noisy during training?

## Architecture Onboarding

- Component map: Input → Augmentation (view1: random crop+flip, view2: random crop+flip+RandAugment) → LID-dis (feature+label input) and LID-gen (feature-only input) → LID score calculation → Weight assignment (clean/noisy/hard) → Loss computation (cross-entropy/GCE/CutMix) → Label update decision → Model update
- Critical path: Each instance passes through dual augmentation, dual subnet processing, LID score computation, instance-specific weighting, and label correction before model parameter updates
- Design tradeoffs: Using LID-dis with feature+label input creates enhanced representations but adds complexity compared to standard approaches; dual-view design improves robustness but doubles computational cost
- Failure signatures: If LID scores fail to distinguish correct from incorrect labels, weight assignment becomes ineffective; if both subnets make identical errors, cross-validation fails; if augmentation strategies are too similar, dual-view benefits diminish
- First 3 experiments:
  1. Test LID score distribution on CIFAR-10 with controlled label noise (e.g., 20% symmetric) to verify Mechanism 1
  2. Compare single-view vs dual-view performance on a simple noise scenario to validate Mechanism 2
  3. Evaluate instance-specific weighting by visualizing weight distributions across clean vs noisy instances

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of CoLafier change when using different backbone architectures, particularly for non-image data?
- Basis in paper: [inferred] The paper mentions that CutMix augmentation was designed for images and suggests that other augmentation methods like Mixup might be considered for non-image data.
- Why unresolved: The paper does not provide experimental results for non-image datasets or different backbone architectures beyond ResNet-18 and ResNet-34 for image datasets.
- What evidence would resolve it: Conducting experiments with CoLafier on non-image datasets using different backbone architectures and augmentation methods would provide insights into its generalizability and performance across different data types.

### Open Question 2
- Question: What is the impact of varying the number of nearest neighbors (k) used in the LID calculation on CoLafier's performance?
- Basis in paper: [explicit] The paper describes the LID calculation method but does not explore the sensitivity of the results to the choice of k.
- Why unresolved: The paper does not provide a sensitivity analysis for the hyperparameter k in the LID calculation.
- What evidence would resolve it: Performing experiments with different values of k in the LID calculation and analyzing the impact on CoLafier's performance would help determine the optimal setting for k.

### Open Question 3
- Question: How does CoLafier's performance compare to other state-of-the-art methods when dealing with label noise in datasets with more than 10 classes?
- Basis in paper: [inferred] The paper evaluates CoLafier on CIFAR-10, which has 10 classes, but does not explore its performance on datasets with more classes.
- Why unresolved: The paper does not provide experimental results on datasets with more than 10 classes.
- What evidence would resolve it: Conducting experiments with CoLafier on datasets with more than 10 classes and comparing its performance to other state-of-the-art methods would provide insights into its scalability and effectiveness for multi-class classification problems.

## Limitations
- The framework's effectiveness relies heavily on the assumption that LID scores reliably distinguish between correctly and incorrectly labeled instances across all noise types and severities, which may break down under extreme conditions.
- The dual-view and dual-subnet design doubles computational requirements, potentially limiting practical deployment on resource-constrained systems.
- The framework's performance advantage is primarily demonstrated on CIFAR-10 datasets, with limited validation on diverse real-world scenarios and non-image data.

## Confidence
- **High Confidence**: The core mechanism of using LID scores for instance weighting and label correction is well-grounded in the mathematical properties of intrinsic dimensionality.
- **Medium Confidence**: The dual-view and dual-subnet architecture's error reduction benefits are demonstrated empirically but lack theoretical guarantees across all noise scenarios.
- **Medium Confidence**: The framework's performance advantage over baselines is clearly shown for CIFAR-10 datasets, but generalization to other datasets and real-world scenarios requires further validation.

## Next Checks
1. Test LID score reliability across varying noise severities (10%-90%) to establish operational boundaries where the framework maintains effectiveness.
2. Evaluate computational overhead by measuring training time and memory usage compared to single-view, single-subnet baselines across different hardware configurations.
3. Conduct ablation studies removing either the dual-view or dual-subnet components to quantify their individual contributions to overall performance.