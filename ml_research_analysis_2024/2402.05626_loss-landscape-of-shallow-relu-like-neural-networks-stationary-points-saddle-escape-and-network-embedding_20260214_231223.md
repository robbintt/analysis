---
ver: rpa2
title: 'Loss Landscape of Shallow ReLU-like Neural Networks: Stationary Points, Saddle
  Escape, and Network Embedding'
arxiv_id: '2402.05626'
source_url: https://arxiv.org/abs/2402.05626
tags:
- loss
- networks
- neurons
- stationary
- local
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the loss landscape of shallow ReLU-like neural
  networks with empirical squared loss. It characterizes stationary points by introducing
  directional derivatives and proves that stationary points without escape neurons
  are local minima, while the presence of escape neurons ensures the stationary point
  is not a local minimum.
---

# Loss Landscape of Shallow ReLU-like Neural Networks: Stationary Points, Saddle Escape, and Network Embedding

## Quick Facts
- arXiv ID: 2402.05626
- Source URL: https://arxiv.org/abs/2402.05626
- Reference count: 40
- Primary result: Characterizes stationary points in shallow ReLU-like networks, proves escape neurons determine local minima status, and analyzes saddle escape dynamics and network embedding effects

## Executive Summary
This paper provides a comprehensive theoretical analysis of the loss landscape for shallow ReLU-like neural networks trained with empirical squared loss. The authors characterize stationary points using directional derivatives and establish that the presence of escape neurons determines whether a stationary point is a local minimum. They demonstrate that saddle escaping during training must involve changes to escape neurons, providing insights into the saddle-to-saddle training dynamics. Additionally, the paper investigates how different network embedding methods affect stationary points and proves conditions for preserving stationarity and local minimality.

## Method Summary
The paper studies one-hidden-layer neural networks with ReLU-like activation functions (rho(z) = alpha+ * z>=0 * z + alpha- * z<0 * z where alpha+ â‰  alpha-) trained on empirical data using squared loss. The analysis employs gradient descent with vanishing initialization (parameters initialized independently with law N(0, (5 * 10^-6)^2)). The theoretical framework introduces directional derivatives to characterize stationary points and proves that points without escape neurons are local minima while those with escape neurons are not. The saddle escaping dynamics are analyzed through the behavior of escape neurons during training.

## Key Results
- Stationary points without escape neurons are proven to be local minima
- The presence of escape neurons guarantees a stationary point is not a local minimum
- Saddle escaping in training dynamics must involve parameter changes of escape neurons
- Network embedding methods can preserve stationarity and local minimality under specific conditions

## Why This Works (Mechanism)
The theoretical framework works by introducing directional derivatives to characterize stationary points in the loss landscape. By analyzing how these directional derivatives behave based on the presence or absence of escape neurons, the authors can determine whether a stationary point is a local minimum. The saddle escaping mechanism is explained through the amplitude-increasing process of effective neurons, where neurons with small amplitudes can escape saddles and contribute to the loss reduction. Network embedding methods work by preserving the critical properties of the original network's stationary points through specific mathematical transformations.

## Foundational Learning
- Directional derivatives: Why needed - to characterize stationary points beyond first-order conditions; Quick check - verify that all directional derivatives are non-negative at stationary points
- Escape neurons: Why needed - to distinguish between local minima and other stationary points; Quick check - identify neurons with non-zero directional derivatives at stationary points
- Saddle escaping dynamics: Why needed - to understand the training trajectory from one saddle to another; Quick check - track amplitude changes of effective neurons during training
- Network embedding: Why needed - to understand how architecture changes affect the loss landscape; Quick check - verify stationarity preservation under embedding transformations

## Architecture Onboarding
Component map: Input -> Hidden layer (ReLU-like neurons) -> Output
Critical path: Training data -> Forward pass computation -> Loss calculation -> Gradient computation -> Parameter update
Design tradeoffs: Vanishing initialization favors low-rank solutions but may slow convergence; larger initialization can speed up training but may affect generalization
Failure signatures: Getting stuck at local minima (insufficient escape neurons), failure to escape saddles (inadequate initialization), loss landscape topology changes (improper embedding)
First experiments: 1) Train network with varying initialization scales and count escape neurons; 2) Visualize loss landscape around stationary points; 3) Apply different embedding methods and test stationarity preservation

## Open Questions the Paper Calls Out
**Open Question 1**: Can type-2 local minima exist with high probability for scalar-output networks, or are they rare or non-existent? The paper suggests they are unlikely due to strong Hessian conditions but rigorous verification is left for future work.

**Open Question 2**: How do the amplitude-increasing processes of different effective neurons interact with each other during training? The paper provides initial insights but lacks a complete description of the trajectory from one saddle to another.

**Open Question 3**: What is the minimal initialization scale that yields zero loss, and how does it relate to the low-rank bias and fitting performance? The paper mentions this tradeoff but does not provide concrete analysis or results.

## Limitations
- Specific training targets y_k are not provided, making exact reproduction difficult
- Implementation details of gradient descent (learning rate schedule) are unspecified
- The theoretical framework assumes ReLU-like activations with specific properties that may not generalize to all activation functions
- The analysis is limited to shallow networks and may not extend to deeper architectures

## Confidence
- High: Theoretical analysis of stationary points and escape neurons
- Medium: Characterization of saddle escaping dynamics in training
- Low: Conditions for preserving stationarity under network embedding methods

## Next Checks
1. Verify theoretical predictions by training networks with different initialization scales and analyzing escape neuron presence
2. Investigate the effect of varying training sample numbers and distributions on loss landscape topology and saddle escaping
3. Compare performance of different network embedding methods in preserving stationarity and local minimality under various experimental settings