---
ver: rpa2
title: Curated Datasets and Neural Models for Machine Translation of Informal Registers
  between Mayan and Spanish Vernaculars
arxiv_id: '2404.07673'
source_url: https://arxiv.org/abs/2404.07673
tags:
- languages
- mayan
- language
- mayanv
- spanish
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the severe underrepresentation of Mayan languages
  in digital and NLP resources. It develops, curates, and publicly releases MayanV,
  a set of parallel corpora between several Mayan languages and Spanish, focusing
  on informal, day-to-day, and non-domain-specific language.
---

# Curated Datasets and Neural Models for Machine Translation of Informal Registers between Mayan and Spanish Vernaculars

## Quick Facts
- arXiv ID: 2404.07673
- Source URL: https://arxiv.org/abs/2404.07673
- Reference count: 22
- Key outcome: MayanV-trained models significantly outperform baselines, demonstrating that informal register data improves Mayan-Spanish translation quality

## Executive Summary
This paper addresses the severe underrepresentation of Mayan languages in digital and NLP resources by developing MayanV, a set of parallel corpora between several Mayan languages and Spanish focused on informal, day-to-day language. The authors perform dialectometric analysis to characterize lexical variation between Spanish in MayanV and standard Spanish in existing resources. They then train neural machine translation models, comparing baseline models trained on existing resources with models trained on MayanV. The results show significant improvements in translation performance when using MayanV, indicating that existing resources do not accurately capture common, real-life language usage by native Mayan speakers.

## Method Summary
The authors curated MayanV by extracting parallel sentences from the Academia de las Lenguas Mayas de Guatemala's online materials, performing post-extraction editing to correct encoding errors. They conducted dialectometric analysis using synonym frequency vectors and cosine distance to quantify lexical divergence between MayanV Spanish and standard Spanish. For model training, they used fairseq with Transformer base configuration, training bilingual and multilingual models, and fine-tuning NLLB-200. Models were trained with label smoothing (α=0.1), Adam optimizer (β1=0.9, β2=0.999), and byte-pair encoding for subword tokenization. Evaluation used BLEU and chrF2 scores on held-out MayanV test sets.

## Key Results
- MayanV-trained models outperform baseline models trained on existing resources (jw.org, OPUS) across all language pairs
- Multilingual models with MayanV data outperform bilingual models in all but one instance, showing positive transfer effects
- Fine-tuned NLLB-200 models outperform from-scratch models for most language pairs, despite NLLB-200 not being trained on any Mayan language
- Dialectometric analysis reveals significant lexical divergence between MayanV Spanish and standard Spanish in existing resources

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using informal, day-to-day language in the training corpus improves translation performance for Mayan-to-Spanish and Spanish-to-Mayan tasks compared to using formal or domain-specific resources.
- Mechanism: The informal register in MayanV closely matches the linguistic patterns and vocabulary used in everyday communication by native Mayan speakers, thereby reducing the semantic and syntactic gap between training data and real-world usage.
- Core assumption: Translation quality is strongly correlated with the similarity between the training corpus register and the target usage context.
- Evidence anchors:
  - [abstract]: "existing resources do not seem to improve translation performance, indicating that many such resources may not accurately capture common, real-life language usage"
  - [section 4.2]: dialectometric analysis shows lexical divergence between MayanV Spanish and standard Spanish in jw.org, suggesting register mismatch in other resources
  - [corpus]: MayanV corpora extracted from ALMG materials described as "informal, familial, and non-domain-specific"
- Break condition: If the majority of Mayan speakers begin using formal or standardized language in daily contexts, the advantage of informal register training data would diminish.

### Mechanism 2
- Claim: Multilingual training with MayanV data provides better translation performance than bilingual training for low-resource Mayan languages.
- Mechanism: Multilingual models leverage positive transfer from related languages and benefit from larger effective training sets, which is particularly advantageous when individual language pairs have limited data.
- Evidence anchors:
  - [section 5.2]: "when comparing bilingual and multilingual models, the latter outperform the former in all but one instance"
  - [section 5.2]: "the inclusion of other languages in the training run acts as favourable leverage in that we are able to benefit from the performance boost and positive transfer of multilingual models"
  - [corpus]: MayanV corpora for multiple Mayan languages combined in multilingual training setup
- Break condition: If the languages in the multilingual model are too linguistically distant or if the model capacity is insufficient to capture cross-lingual patterns.

### Mechanism 3
- Claim: Fine-tuning NLLB-200 for bilingual Mayan-Spanish translation yields better results than training from scratch for most language pairs.
- Mechanism: Pre-trained models like NLLB-200 have learned general translation patterns and linguistic representations that can be adapted to specific low-resource language pairs, providing a stronger starting point than random initialization.
- Evidence anchors:
  - [section 5.2]: "NLLB-200 model fine-tuned to each individual language pair outperforms models trained from scratch in almost all instances"
  - [section 5.2]: "NLLB-200 was not trained over any member of the Mayan language family, which limits the effects of positive transfer"
  - [corpus]: Comparison of NLLB-200 fine-tuning results with from-scratch models
- Break condition: If the pre-trained model's linguistic representations are too dissimilar from the target languages, making fine-tuning less effective than training from scratch.

## Foundational Learning

- Concept: Register and dialect variation in language
  - Why needed here: The paper's key insight is that translation quality depends on matching the register and dialect of training data to real-world usage. Understanding linguistic registers and dialects is essential to grasp why MayanV outperforms other resources.
  - Quick check question: What is the difference between a language register and a dialect, and why might both matter for machine translation quality?

- Concept: Low-resource machine translation challenges
  - Why needed here: The paper addresses the specific difficulties of training MT systems for languages with limited parallel corpora, which affects model architecture choices and evaluation approaches.
  - Quick check question: What are the main challenges when training machine translation models for languages with limited parallel data, and how do multilingual approaches help address these challenges?

- Concept: Dialectometry and lexical distance metrics
  - Why needed here: The paper uses dialectometric analysis to quantify the lexical divergence between Spanish varieties in different corpora, providing empirical support for the register-matching hypothesis.
  - Quick check question: How does cosine distance between synonym frequency vectors help characterize dialectal variation between two corpora?

## Architecture Onboarding

- Component map:
  Data extraction pipeline (PDF parsing → text cleaning → sentence alignment) → Dialectometric analysis module (synonym frequency vectors → cosine distance computation) → NMT training framework (fairseq/Transformers → bilingual and multilingual models) → Evaluation pipeline (BLEU/chrF2 scoring on held-out MayanV test sets)

- Critical path: Extract MayanV corpora → Perform dialectometric analysis → Train baseline models without MayanV → Train models with MayanV → Evaluate and compare performance

- Design tradeoffs:
  - Using informal register data improves real-world performance but may reduce performance on formal text translation tasks
  - Multilingual models improve overall performance but increase training complexity and resource requirements
  - Fine-tuning large pre-trained models requires significant GPU memory but provides better starting points than training from scratch

- Failure signatures:
  - Poor BLEU scores despite large training data → potential register mismatch between training and test data
  - Multilingual model performs worse than bilingual → possible negative transfer from linguistically distant languages
  - Fine-tuning fails to converge → insufficient model capacity or inappropriate pre-trained model choice

- First 3 experiments:
  1. Compare BLEU scores of bilingual models trained with and without MayanV on held-out test sets for each language pair
  2. Evaluate multilingual model performance against bilingual baselines for languages with varying amounts of MayanV data
  3. Fine-tune NLLB-200 for each Mayan language pair and compare against from-scratch models using identical training data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific linguistic features or contextual cues contribute to the improved translation performance of MayanV-trained models compared to models trained on existing resources?
- Basis in paper: [explicit] The paper states that MayanV-trained models outperform baseline models trained on existing resources, suggesting that MayanV captures more relevant linguistic features and contextual cues.
- Why unresolved: The paper does not delve into the specific linguistic features or contextual cues that make MayanV more effective. It only provides a general observation of improved performance.
- What evidence would resolve it: A detailed linguistic analysis of the texts in MayanV and existing resources, identifying the specific features and cues that contribute to improved translation performance.

### Open Question 2
- Question: How do the dialectal variations within Mayan languages and between Mayan and Spanish impact the effectiveness of NMT models trained on MayanV?
- Basis in paper: [inferred] The paper mentions dialectal variation within Mayan languages and between Mayan and Spanish, suggesting that this could be a factor in NMT model performance.
- Why unresolved: The paper does not explore the specific impact of dialectal variation on model performance. It only acknowledges its existence.
- What evidence would resolve it: Experiments comparing the performance of NMT models trained on MayanV data from different dialects, or comparing models trained on MayanV data to those trained on data from a single dialect.

### Open Question 3
- Question: What are the ethical implications of using NMT models trained on MayanV for communication between Mayan speakers and non-Mayan speakers, particularly in domains like healthcare and governance?
- Basis in paper: [inferred] The paper discusses the potential benefits of NMT models for Mayan languages, including improved access to information and services. However, it does not explicitly address the ethical implications of their use.
- Why unresolved: The paper focuses on the technical aspects of developing NMT models and does not explore the broader societal and ethical implications of their deployment.
- What evidence would resolve it: Case studies or surveys examining the experiences of Mayan speakers using NMT models in different contexts, including potential benefits and challenges.

## Limitations

- The paper cannot definitively prove that register matching is the sole cause of improved translation performance, as other factors like data quality and quantity may contribute
- The study focuses on specific Mayan languages and may not generalize to all low-resource language pairs
- The informal register approach may limit performance on formal text translation tasks, creating a potential tradeoff that isn't fully explored

## Confidence

- **High Confidence**: The empirical results showing improved BLEU/chrF2 scores when using MayanV data compared to baselines are directly measurable and reproducible
- **Medium Confidence**: The mechanism linking informal register matching to translation quality improvement is plausible and supported by evidence, but alternative explanations cannot be fully ruled out
- **Low Confidence**: Generalizability claims about low-resource MT approaches to other language families are speculative and would require additional validation studies beyond the Mayan language family

## Next Checks

1. **Controlled Register Experiment**: Create synthetic parallel corpora where the same semantic content is expressed in both formal and informal registers, then train separate models to isolate the effect of register matching on translation quality while controlling for content and domain.

2. **Cross-Domain Performance Evaluation**: Test the MayanV-trained models on formal text domains (legal, medical, academic) to quantify the potential performance tradeoff between informal and formal register specialization, establishing the boundaries of the approach's effectiveness.

3. **Transfer Learning Analysis**: Conduct ablation studies where different portions of the pre-training data are removed from NLLB-200 to determine which linguistic features are most critical for successful fine-tuning on Mayan languages, validating the mechanism behind the transfer learning approach.