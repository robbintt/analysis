---
ver: rpa2
title: Noise misleads rotation invariant algorithms on sparse targets
arxiv_id: '2403.02697'
source_url: https://arxiv.org/abs/2403.02697
tags: []
core_contribution: The paper proves that rotation-invariant algorithms, such as standard
  fully-connected neural networks with rotationally symmetric initializations, cannot
  efficiently learn sparse linear targets when noise is present, even when the number
  of training examples exceeds the input dimension. A lower bound is established via
  a Bayesian argument showing that the expected error of any rotation-invariant algorithm
  on the original sparse problem is at least $\frac{d-1}{d} \cdot \frac{\sigma^2}{\sigma^2
  + m}$, where $d$ is the input dimension, $\sigma^2$ is the noise variance, and $m$
  is the number of copies of the input matrix.
---

# Noise misleads rotation invariant algorithms on sparse targets

## Quick Facts
- arXiv ID: 2403.02697
- Source URL: https://arxiv.org/abs/2403.02697
- Reference count: 40
- Primary result: Rotation-invariant algorithms cannot efficiently learn sparse linear targets with noise, even when examples exceed input dimension

## Executive Summary
This paper proves that rotation-invariant algorithms, such as standard fully-connected neural networks with rotationally symmetric initializations, cannot efficiently learn sparse linear targets when noise is present. The key insight is that rotation invariance prevents these algorithms from specializing to the sparse solution, even when the number of training examples exceeds the input dimension. In contrast, non-rotation-invariant algorithms like multiplicative updates (EG±), the "spindly" network, and the priming method can achieve much lower error rates. The analysis includes closed-form gradient flow trajectories that reveal how different algorithms' inductive biases lead to varying proximity to the sparse target during training.

## Method Summary
The paper establishes lower bounds for rotation-invariant algorithms via a Bayesian argument on a rotationally symmetrized problem. It proves that the expected error of any rotation-invariant algorithm is at least $\frac{d-1}{d} \cdot \frac{\sigma^2}{\sigma^2 + m}$, where $d$ is input dimension, $\sigma^2$ is noise variance, and $m$ is the number of input matrix copies. For non-rotation-invariant methods, upper bounds are derived for algorithms like EG±, spindly network, and priming method. The analysis also includes closed-form gradient flow trajectories showing how different algorithms' paths through weight space affect their ability to learn sparse solutions.

## Key Results
- Rotation-invariant algorithms have expected error at least $\frac{d-1}{d} \cdot \frac{\sigma^2}{\sigma^2 + m}$ on sparse targets with noise
- Non-rotation-invariant algorithms like EG±, spindly network, and priming method achieve error rates of $O(\frac{\sigma^2 \log d}{md})$
- Gradient flow trajectory analysis reveals that some algorithms pass close to the sparse target while others go straight to the least squares solution
- Fashion MNIST experiments confirm rotation-invariant networks are more susceptible to noise and less able to exploit informative features

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Rotation invariance prevents efficient learning of sparse targets when noise is present, even when the number of examples exceeds the input dimension.
- **Mechanism:** The lower bound analysis uses a Bayesian setup where the problem is sampled uniformly from all rotated versions. A rotation-invariant algorithm must perform equally well on all rotations, preventing it from specializing to the sparse solution.
- **Core assumption:** The input distribution is rotationally symmetric, meaning pin(˜X) = pin(˜XU⊤) for any orthogonal matrix U.
- **Evidence anchors:**
  - [abstract] "rotation-invariant algorithms cannot efficiently learn sparse linear targets when noise is present, even when the number of training examples exceeds the input dimension"
  - [section 1.2] "We prove this via a lower bound for the Bayes optimal algorithm on a rotationally symmetrized problem"
  - [corpus] No direct evidence found in corpus papers for this specific mechanism
- **Break condition:** The lower bound breaks when the input distribution is not rotationally symmetric, allowing algorithms to exploit directional structure in the data.

### Mechanism 2
- **Claim:** Non-rotation-invariant algorithms like multiplicative updates (EG±), the "spindly" network, and the priming method can achieve much lower error rates than rotation-invariant algorithms.
- **Mechanism:** These algorithms have inductive biases that favor sparse solutions, breaking the symmetry that rotation-invariant algorithms are constrained by. The "spindly" network replaces each weight wi with a product ui⊙vi, creating a non-rotation-invariant parameterization.
- **Core assumption:** The algorithms can exploit the sparsity structure in the target without being penalized for favoring one direction over others.
- **Evidence anchors:**
  - [abstract] "non-rotation-invariant algorithms like multiplicative updates (EG±), the 'spindly' network, and the priming method can achieve much lower error rates"
  - [section 2.2] "We then prove our main upper bound for the unnormalized EGU±"
  - [corpus] No direct evidence found in corpus papers for this specific mechanism
- **Break condition:** If the target is not sparse or if the noise structure prevents the algorithms from identifying the sparse components, the advantage may diminish.

### Mechanism 3
- **Claim:** The gradient flow trajectories of different algorithms reveal how their inductive biases lead to varying proximity to the sparse target during training.
- **Mechanism:** By deriving closed-form solutions for the continuous-time gradient flow trajectories, we can analyze how different algorithms' paths through weight space affect their ability to learn sparse solutions. Some algorithms (like EGU± and priming) pass close to the sparse target while others (like standard GD) go straight to the least squares solution.
- **Core assumption:** The continuous-time approximation accurately captures the behavior of the discrete-time algorithms.
- **Evidence anchors:**
  - [abstract] "closed-form gradient flow trajectories that reveal how different algorithms' inductive biases lead to varying proximity to the sparse target during training"
  - [section 3.2] "We derive analytic trajectories for the simple linear regression problem"
  - [corpus] No direct evidence found in corpus papers for this specific mechanism
- **Break condition:** If the learning rate is too high or too low, or if the noise structure is very different from the assumptions, the trajectory analysis may not accurately predict performance.

## Foundational Learning

- **Concept:** Rotation invariance
  - **Why needed here:** Understanding why rotation-invariant algorithms are fundamentally limited in learning sparse targets is central to the paper's contribution.
  - **Quick check question:** Can you explain why a neural network with fully-connected input layer initialized with rotationally symmetric weights is rotation invariant?

- **Concept:** Bayesian lower bound technique
  - **Why needed here:** The proof technique of symmetrizing the problem and analyzing the Bayes optimal algorithm on this symmetrized problem is novel and crucial for establishing the lower bounds.
  - **Quick check question:** How does the Bayesian setup with rotated versions of the problem help establish lower bounds for rotation-invariant algorithms?

- **Concept:** Gradient flow analysis
  - **Why needed here:** The closed-form solutions for gradient flow trajectories provide insight into how different algorithms' inductive biases affect their learning dynamics.
  - **Quick check question:** What does it mean for an algorithm's trajectory to "veer toward or away from the sparse targets"?

## Architecture Onboarding

- **Component map:** The paper analyzes several algorithm families:
  - Rotation-invariant algorithms: standard GD on fully-connected networks
  - Non-rotation-invariant algorithms: EG±, spindly network, priming method
  - Adaptive algorithms: Adagrad, Adam (diagonalized versions)
  - Each has different inductive biases affecting sparse target learning

- **Critical path:** The key experimental setup is:
  1. Create synthetic sparse linear regression problem with noise
  2. Compare rotation-invariant vs non-rotation-invariant algorithms
  3. Analyze gradient flow trajectories
  4. Validate with Fashion MNIST experiments

- **Design tradeoffs:** 
  - Rotation invariance vs sparsity exploitation
  - Normalized vs unnormalized multiplicative updates
  - Continuous-time vs discrete-time analysis
  - Theoretical bounds vs practical performance

- **Failure signatures:** 
  - Rotation-invariant algorithms show no advantage on sparse problems
  - Adaptive algorithms like Adagrad may show opposite bias (away from sparsity)
  - Theoretical bounds may be conservative compared to practical performance

- **First 3 experiments:**
  1. Implement the synthetic sparse regression problem and compare rotation-invariant vs EG±
  2. Visualize gradient flow trajectories for different algorithms on 2D toy problem
  3. Run Fashion MNIST experiments with fully-connected vs spindly network architectures

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do adaptive learning rate algorithms like Adagrad and Adam perform on sparse targets in deep neural networks with multiple hidden layers?
- Basis in paper: [explicit] The paper analyzes the behavior of these algorithms on linear neurons and shows they have a bias away from sparsity. However, the authors acknowledge this is a major open problem to determine if these differences persist in deeper networks.
- Why unresolved: The paper only derives closed-form solutions for gradient flow trajectories in the linear case, and extending this analysis to deep networks is noted as challenging.
- What evidence would resolve it: Experiments comparing the performance of Adagrad, Adam, and other adaptive algorithms on sparse regression tasks using deep neural networks with varying numbers of hidden layers and widths.

### Open Question 2
- Question: Can the lower bounds for rotationally invariant algorithms be extended to the classification setting when the number of examples exceeds the VC dimension?
- Basis in paper: [explicit] The authors mention this as a possibility but note technical challenges due to the additional loss in the VC dimension/Rademacher complexity having a square root term that may make the bounding methodology non-optimal in the noisy case.
- Why unresolved: The current lower bound proofs rely on specific properties of the regression setting that may not directly translate to classification.
- What evidence would resolve it: Development of a new lower bound proof technique that can handle the classification setting and the additional complexity introduced by the VC dimension.

### Open Question 3
- Question: How does the performance of the priming method compare to the approximated EGU± algorithm on sparse regression tasks with general input matrices?
- Basis in paper: [explicit] The paper shows the priming method achieves a better upper bound on the error than the approximated EGU±, but only for the special case of input matrices consisting of multiple copies of a scaled rotation matrix.
- Why unresolved: The authors note that allowing arbitrary covariance structure in the input matrix makes the analysis much more complicated and is left for future research.
- What evidence would resolve it: Experiments comparing the performance of the priming method and approximated EGU± on sparse regression tasks using input matrices with various covariance structures, including general positive definite matrices.

## Limitations
- The rotation invariance assumption requires exact symmetry in the input distribution, which may not hold in practice
- The lower bound proof relies on a Bayesian symmetrization technique that may not capture all practical failure modes
- The continuous-time gradient flow analysis assumes infinitesimal learning rates and may not perfectly predict discrete-time behavior

## Confidence

**Confidence labels:**
- **High**: The impossibility result for rotation-invariant algorithms is mathematically proven and the mechanism (symmetry prevents specialization to sparse solutions) is well-understood
- **Medium**: The upper bounds for non-rotation-invariant algorithms are established, but depend on specific algorithm choices and parameter settings
- **Medium**: The gradient flow trajectory analysis provides qualitative insights but the continuous-time approximation may not perfectly match discrete-time behavior

## Next Checks

1. Test the rotation invariance lower bound on input distributions with slight asymmetries to understand how robust the effect is to broken symmetry
2. Implement and compare multiple non-rotation-invariant algorithms (EG±, spindly, priming) on the same sparse regression problems to validate the relative performance claims
3. Run finite-step gradient descent experiments to compare against the continuous-time trajectory predictions and quantify the approximation error