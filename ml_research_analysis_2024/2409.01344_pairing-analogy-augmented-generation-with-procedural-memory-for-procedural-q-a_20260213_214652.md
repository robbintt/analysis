---
ver: rpa2
title: Pairing Analogy-Augmented Generation with Procedural Memory for Procedural
  Q&A
arxiv_id: '2409.01344'
source_url: https://arxiv.org/abs/2409.01344
tags:
- custom
- input
- tool
- agent
- langchain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a formalism for procedural knowledge and a
  system, AAG, that uses analogical reasoning to solve procedural Q&A tasks. The approach
  retrieves and adapts procedures from memory to answer new tasks, inspired by human
  analogical reasoning.
---

# Pairing Analogy-Augmented Generation with Procedural Memory for Procedural Q&A

## Quick Facts
- arXiv ID: 2409.01344
- Source URL: https://arxiv.org/abs/2409.01344
- Reference count: 40
- Primary result: AAG system outperforms baselines in pairwise LLM evaluation and human evaluation for RecipeNLG, demonstrating improved coherence and completeness of generated procedures.

## Executive Summary
This paper introduces AAG (Analogy-Augmented Generation), a system that uses analogical reasoning to solve procedural question-answering tasks. The approach retrieves and adapts procedures from a custom memory store to answer new procedural tasks, inspired by how humans use past experiences to solve new problems. Experiments on LCStep, RecipeNLG, and CHAMP datasets demonstrate that AAG outperforms traditional baselines like zero-shot, few-shot, RAG, and ReAct approaches in generating coherent and complete procedural knowledge.

## Method Summary
AAG is a procedural Q&A system that retrieves and adapts analogical procedures from memory to answer new tasks. It breaks down input queries into sub-queries about individual steps, retrieves relevant procedures for each sub-query, and synthesizes the retrieved knowledge into a coherent procedure. The system also incorporates iterative refinement with self-critique, where the LLM acts as its own critic to evaluate and improve the generated procedure across multiple dimensions. The approach uses a structured representation of procedural knowledge as (input, output, steps) tuples, enabling composability and reducing noise in the retrieval process.

## Key Results
- AAG outperforms baselines in pairwise LLM evaluation across LCStep, RecipeNLG, and CHAMP datasets
- Human evaluation on RecipeNLG shows AAG generates more coherent and complete procedures
- The iterative refinement with self-critique improves procedure quality through multiple evaluation dimensions
- AAG shows particular strength in domains with clear procedural analogies available in memory

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The AAG system improves procedural knowledge generation by retrieving and adapting analogical procedures from memory, similar to how humans use past experiences to solve new problems.
- Mechanism: The system breaks down the input query into sub-queries about individual steps, retrieves relevant procedures for each sub-query, and then synthesizes the retrieved knowledge into a coherent procedure.
- Core assumption: The steps required to solve a new procedural task are similar enough to steps in existing procedures that can be retrieved and adapted.
- Evidence anchors:
  - [abstract]: "AAG uses a custom procedure memory store to retrieve and adapt specialized domain knowledge to answer new procedural tasks."
  - [section]: "To approximate this in our system, we first prompt the LLM to generate a high-level outline of the steps in the required procedure...followed by asking it to formulate questions for them that can be answered through analogical examples in the memory."
  - [corpus]: Weak evidence - no direct mentions of analogical reasoning in the retrieved papers.
- Break condition: If the procedural memory store does not contain relevant procedures for the sub-queries, or if the steps in the new task are too dissimilar from existing procedures.

### Mechanism 2
- Claim: The iterative refinement with self-critique improves the quality of generated procedures by identifying areas for improvement and suggesting edits.
- Mechanism: After generating an initial procedure, the LLM acts as a critic, evaluating the procedure across several dimensions and suggesting edits. The LLM then performs the suggested edits and the cycle continues for a maximum of 3 iterations.
- Core assumption: LLMs can effectively act as their own critics and provide useful feedback for improvement.
- Evidence anchors:
  - [abstract]: "We augment the AAG system with an iterative refinement procedure guided by the same LLM-based critic for its output."
  - [section]: "LLMs have been shown to act as powerful self-critics for their own outputs, evaluating them across several dimensions and suggesting feedback crucial to improving them."
  - [corpus]: Weak evidence - no direct mentions of iterative refinement or self-critique in the retrieved papers.
- Break condition: If the LLM fails to identify areas for improvement or suggests unhelpful edits.

### Mechanism 3
- Claim: The structured representation of procedural knowledge as a linear chain graph reduces noise and isolates essential procedural information, improving data quality for enhancing LLMs' reasoning and planning.
- Mechanism: The formalism defines a procedure as (x, y, (s1, ..., sk)) where x is the input, y is the output, and (s1, ..., sk) is a sequence of ordered steps. This structure makes it easier for LLMs to grasp task-relevant patterns.
- Core assumption: Representing procedural knowledge in a structured format improves LLMs' ability to reason about and plan procedures.
- Evidence anchors:
  - [section]: "Our approach retains composability: two procedures (x, y, (s1, ..., sk)) and (y, z, (t1, ..., tℓ)) can be combined into (x, z, (s1, ..., sk, t1, ..., tℓ)). This supports the generation of (s1, ..., sk) from x and y, for example, generating recipe steps from a title and ingredient list."
  - [corpus]: Weak evidence - no direct mentions of structured representation of procedural knowledge in the retrieved papers.
- Break condition: If the structured representation does not improve LLMs' ability to reason about and plan procedures, or if it introduces unnecessary complexity.

## Foundational Learning

- Concept: Analogical reasoning
  - Why needed here: The AAG system is inspired by human analogical reasoning, which involves mapping knowledge from one situation (base) into another (target) based on the similarity in relationships between objects.
  - Quick check question: How does analogical reasoning differ from simple pattern matching or rule-based reasoning?

- Concept: Retrieval-augmented generation (RAG)
  - Why needed here: RAG is a popular approach to keep information up-to-date by leveraging external data, but the AAG system builds upon RAG by adding analogical reasoning and iterative refinement.
  - Quick check question: What are the key differences between the AAG system and traditional RAG approaches?

- Concept: Iterative refinement
  - Why needed here: The AAG system uses iterative refinement with self-critique to improve the quality of generated procedures by identifying areas for improvement and suggesting edits.
  - Quick check question: How does iterative refinement with self-critique differ from traditional fine-tuning or prompt engineering approaches?

## Architecture Onboarding

- Component map: Input query -> Query generator -> Procedural memory store -> Answer generator -> Initial procedure -> Iterative refinement with self-critic -> Updated procedure -> LLM critic -> Final output

- Critical path:
  1. Input query is received and broken down into sub-queries.
  2. Sub-queries are used to retrieve relevant procedures from the procedural memory store.
  3. Retrieved procedures are synthesized into an initial candidate procedure.
  4. Initial procedure is evaluated by the LLM critic and suggestions for improvement are generated.
  5. Suggested edits are incorporated into the procedure.
  6. Updated procedure is re-evaluated by the LLM critic.
  7. Steps 4-6 are repeated for a maximum of 3 iterations.
  8. Final procedure is output.

- Design tradeoffs:
  - Structured vs. unstructured representation of procedural knowledge: The AAG system uses a structured representation to reduce noise and improve LLMs' reasoning, but this may introduce complexity.
  - Number of sub-queries: More sub-queries may lead to more relevant procedures being retrieved, but may also increase the computational cost and complexity of the system.
  - Number of iterative refinement cycles: More cycles may lead to higher quality procedures, but may also increase the computational cost and time required.

- Failure signatures:
  - Procedural memory store contains irrelevant or insufficient procedures for the sub-queries.
  - LLM fails to effectively break down the input query into meaningful sub-queries.
  - LLM fails to effectively synthesize the retrieved procedures into a coherent procedure.
  - LLM fails to effectively act as a self-critic and provide useful feedback for improvement.

- First 3 experiments:
  1. Test the system on a simple procedural task with a small procedural memory store to verify the basic functionality.
  2. Vary the number of sub-queries generated by the query generator to find the optimal balance between retrieval quality and computational cost.
  3. Test the system on a more complex procedural task with a larger procedural memory store to evaluate the system's scalability and robustness.

## Open Questions the Paper Calls Out

Here is my analysis of the comparison between the two procedures:
1. Both procedures accomplish the user goal of setting up a custom input schema for a tool with strict requirements and custom validation logic using an LLM.
2. Procedure 1 is more concise and provides the essential steps, while Procedure 2 includes more detailed explanations and examples for each step, making it easier to understand and follow.
3. Procedure 2 adds a testing step at the end, which is important to ensure the custom input schema is working as expected. This is a valuable addition not present in Procedure 1.
4. Procedure 2 provides examples of defining the function with custom validation logic and implementing the custom LLM class, which can be helpful for users to better understand and implement the steps.
5. Both procedures use all the resources mentioned in the user goal (an LLM), so there is no difference in terms of resource utilization.
Based on this analysis, I believe Procedure 2 is the preferred choice because it provides more comprehensive and detailed steps, including examples and a testing step, making it more practical and easier to follow for users. However, Procedure 1 is also a valid and concise approach to achieving the user goal.
Choice: [[2]]

## Limitations

- The retrieval mechanism's effectiveness depends heavily on the quality and relevance of procedures in the memory store, which may limit performance in domains with sparse procedural knowledge.
- The system shows variable performance across domains, with CHAMP (mathematics) being particularly challenging where filtering retrieved procedures removes crucial information.
- LLM-based evaluation methods used for comparison have inherent biases and limitations compared to human evaluation, which was only conducted on one dataset.

## Confidence

- High Confidence: Mechanism 1 (Analogical reasoning for procedural retrieval) - The basic architecture and retrieval mechanism are clearly specified and the empirical results show consistent improvements over baselines.
- Medium Confidence: Mechanism 2 (Iterative refinement with self-critique) - While the concept is sound and the iterative approach is well-defined, the paper provides limited evidence that the self-critique mechanism specifically contributes to the improvements.
- Medium Confidence: Mechanism 3 (Structured representation benefits) - The formalism is clearly defined and has theoretical advantages, but the empirical evidence for its contribution to performance improvements is indirect.

## Next Checks

1. **Cross-domain generalization test**: Evaluate AAG on a new procedural domain (e.g., technical troubleshooting, educational tutorials) not seen in the original experiments to assess whether the analogical reasoning mechanism generalizes beyond the tested datasets.

2. **Ablation study on retrieval quality**: Systematically vary the quality and relevance of procedures in the memory store to determine how much the retrieval mechanism contributes to overall performance, separating this effect from the generation and refinement components.

3. **Long-tail procedure handling**: Test AAG on procedural tasks where retrieved analogies are only partially relevant (low similarity cases) to evaluate whether the adaptation mechanism can effectively bridge gaps between source and target procedures, or whether performance degrades predictably.