---
ver: rpa2
title: 'Estimating before Debiasing: A Bayesian Approach to Detaching Prior Bias in
  Federated Semi-Supervised Learning'
arxiv_id: '2405.19789'
source_url: https://arxiv.org/abs/2405.19789
tags:
- data
- bias
- clients
- learning
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses prediction bias in federated semi-supervised
  learning (FSSL) caused by class imbalance in heterogeneous client data. The authors
  propose FedDB, a Bayesian debiasing method that tackles this issue at both local
  and global levels.
---

# Estimating before Debiasing: A Bayesian Approach to Detaching Prior Bias in Federated Semi-Supervised Learning

## Quick Facts
- arXiv ID: 2405.19789
- Source URL: https://arxiv.org/abs/2405.19789
- Reference count: 7
- Key outcome: FedDB reduces prediction bias in federated semi-supervised learning by debiasing pseudo-labeling and aggregation using Average Prediction Probability of Unlabeled Data (APP-U), achieving up to 67.32% accuracy on CIFAR10 in IID settings.

## Executive Summary
This paper addresses prediction bias in federated semi-supervised learning (FSSL) caused by class imbalance in heterogeneous client data. The authors propose FedDB, a Bayesian debiasing method that tackles this issue at both local and global levels. Locally, FedDB uses Average Prediction Probability of Unlabeled Data (APP-U) to refine pseudo-labeling through Bayes' theorem, reducing label prior bias. Globally, it employs APP-U from participating clients to formulate unbiased aggregation weights, mitigating bias in the global model. Experiments on CIFAR10, SVHN, and CIFAR100 datasets show that FedDB consistently outperforms existing FSSL methods.

## Method Summary
FedDB operates through two complementary mechanisms: Debiased Pseudo-Labeling (DPL) and Debiased Model Aggregation (DMA). DPL uses APP-U as an approximation of the biased prior to recalibrate pseudo-labels via Bayes' theorem, promoting balanced training data. DMA formulates aggregation weights based on client APP-U values to minimize divergence from uniform distribution during global model aggregation. The method is designed as a plug-in that can improve existing FSSL methods by reducing overconfident predictions on majority classes and enhancing minority class representation.

## Key Results
- FedDB achieves up to 67.32% accuracy on CIFAR10 in IID settings and 55.00% in Non-IID settings (Î´=0.3)
- Consistent improvement across all tested data distributions and heterogeneity levels
- Outperforms existing FSSL methods including FedAvg, FedMD, and FedZKT
- Reduces prediction bias as measured by Jensen-Shannon divergence from uniform distribution

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FedDB reduces prior bias by debiasing pseudo-labeling using APP-U as an approximation of the biased prior.
- Mechanism: APP-U estimates the skewed prediction probabilities from unlabeled data, which FedDB uses in Bayes' theorem to recalibrate pseudo-labels, thereby promoting balanced training data.
- Core assumption: The APP-U accurately reflects the label prior bias in heterogeneous, class-imbalanced data.
- Evidence anchors:
  - [abstract] "FedDB utilizes the Average Prediction Probability of Unlabeled Data (APP-U) to approximate the biased prior."
  - [section 4.3] "we discover that the prior bias can be effectively approximated by the Average Prediction Probability on Unlabeled Data (APP-U)."
  - [corpus] No direct corpus evidence; relies on experimental claims in paper.
- Break condition: If APP-U no longer correlates with true prior bias due to extreme data heterogeneity or model collapse.

### Mechanism 2
- Claim: FedDB mitigates global model bias through debiased model aggregation (DMA) using client APP-U values.
- Mechanism: DMA formulates aggregation weights to minimize the divergence between the aggregated APP-U and a uniform distribution, thus aligning the global model's predictions across all classes.
- Core assumption: Aggregation weights derived from APP-U can effectively steer the global model toward balanced class performance.
- Evidence anchors:
  - [abstract] "During the model aggregation, FedDB uses APP-U from participating clients to formulate unbiased aggregate weights."
  - [section 4.4] "DMA utilizes APP-U from the participating clients to determine optimal aggregation weights."
  - [corpus] No corpus evidence found; claim based on internal analysis.
- Break condition: If participating clients' APP-U values are themselves highly biased or non-representative of the overall distribution.

### Mechanism 3
- Claim: DPL acts as a plug-in to improve existing FSSL methods that use pseudo-labeling.
- Mechanism: By recalibrating pseudo-labels via Bayes' theorem, DPL reduces overconfident predictions on majority classes and enhances minority class representation during local training.
- Core assumption: Adjusting pseudo-labels with APP-U does not harm the discriminative power of the model.
- Evidence anchors:
  - [abstract] "This approach promotes a more balanced pseudo-labeling process."
  - [section 4.3] "Eq. (14) serves as a regularization term that smooths the prediction probabilities of the majority classes and sharpens these of the minority classes."
  - [corpus] No supporting corpus evidence; claim from paper experiments.
- Break condition: If over-regularization causes underfitting or loss of discriminative features.

## Foundational Learning

- Concept: Bayes' theorem and posterior probability adjustment.
  - Why needed here: FedDB uses Bayes' theorem to debias model predictions by correcting the prior distribution with APP-U.
  - Quick check question: In Bayes' theorem, what role does the prior play, and how does correcting it affect the posterior?

- Concept: Federated averaging and weighted aggregation.
  - Why needed here: DMA builds on FedAvg but introduces adaptive weights based on APP-U to counteract bias in heterogeneous client data.
  - Quick check question: How does weighted aggregation differ from standard FedAvg, and what is the goal of introducing weights?

- Concept: Semi-supervised learning with pseudo-labeling.
  - Why needed here: FedDB leverages pseudo-labeling to incorporate unlabeled data, which is central to FSSL.
  - Quick check question: What are the risks of pseudo-labeling, and how can biased priors exacerbate them?

## Architecture Onboarding

- Component map:
  Client side (DPL) -> Local model training -> Model and APP-U upload
  Server side (DMA) -> Weighted aggregation -> Global model broadcast

- Critical path:
  1. Client computes APP-U from unlabeled data.
  2. Client applies DPL to generate balanced pseudo-labels.
  3. Client trains local model using both labeled and pseudo-labeled data.
  4. Client sends model and APP-U to server.
  5. Server runs DMA to compute weighted aggregation.
  6. Server broadcasts updated global model.

- Design tradeoffs:
  - Computational overhead of APP-U computation vs. accuracy gains.
  - Number of aggregation epochs (Eaggr) affects convergence but increases communication rounds.
  - Trade-off between debiasing strength and potential underfitting.

- Failure signatures:
  - Degraded performance on minority classes.
  - High variance in model updates across clients.
  - Increased communication rounds without accuracy improvement.

- First 3 experiments:
  1. Run FedDB on CIFAR10 IID with small labeled data to verify baseline accuracy improvement.
  2. Test DPL alone on an existing FSSL method (e.g., FixMatch) to isolate its effect.
  3. Evaluate DMA impact by comparing with FedAvg and uniform weighting.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several remain unresolved based on the experimental setup and results presented.

## Limitations
- No ablation studies separating DPL and DMA contributions, making it unclear which mechanism drives improvements
- Limited to synthetic class imbalance; real-world dataset performance remains untested
- No analysis of computational or communication overhead introduced by additional aggregation epochs

## Confidence
- High confidence in the problem formulation and motivation (class imbalance in FSSL is well-documented)
- Medium confidence in the effectiveness of DPL mechanism (supported by experiments but lacks ablation)
- Medium confidence in DMA mechanism (theoretical justification present but no comparative analysis with simpler baselines)
- Low confidence in generalizability beyond CIFAR-like datasets (only tested on image classification benchmarks)

## Next Checks
1. Run ablation experiments isolating DPL and DMA contributions by testing each component separately on existing FSSL methods
2. Verify APP-U correlation with true prior bias across different levels of class imbalance and heterogeneity
3. Test FedDB on non-image datasets (e.g., text or tabular data) to assess cross-domain applicability