---
ver: rpa2
title: Graph Pruning for Enumeration of Minimal Unsatisfiable Subsets
arxiv_id: '2402.15524'
source_url: https://arxiv.org/abs/2402.15524
tags:
- problems
- pruning
- formulas
- enumeration
- muses
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents a graph-based neural pruning method, GRAPE-MUST,
  to accelerate MUS enumeration by reducing the size of unsatisfiable CNF formulas.
  It converts formulas into attributed graphs and learns a graph neural network to
  predict which clauses to prune while maintaining unsatisfiability.
---

# Graph Pruning for Enumeration of Minimal Unsatisfiable Subsets

## Quick Facts
- **arXiv ID**: 2402.15524
- **Source URL**: https://arxiv.org/abs/2402.15524
- **Reference count**: 39
- **Primary result**: GRAPE-MUST uses graph neural networks to prune clauses from unsatisfiable formulas, achieving significant speedups in MUS enumeration across random formulas, logistics planning, graph coloring, and real-world SAT competition problems.

## Executive Summary
This work introduces GRAPE-MUST, a graph-based neural pruning method that accelerates MUS enumeration by reducing the size of unsatisfiable CNF formulas. The method converts formulas into attributed graphs and learns a graph neural network to predict which clauses to prune while maintaining unsatisfiability. Notably, GRAPE-MUST trains on random formulas without requiring labeled data, using only SAT checks on pruned instances to provide weak supervision. The approach demonstrates significant speedups across multiple benchmark categories and shows strong generalization to larger problems and different data distributions without retraining.

## Method Summary
GRAPE-MUST represents CNF formulas as literal-clause graphs where variables and clauses are nodes connected by edges based on their relationships. A graph neural network processes this heterogeneous graph to predict pruning probabilities for each clause, followed by a binary search to find the optimal pruning threshold that maintains unsatisfiability. The model trains on randomly generated formulas using a score function estimator for gradient computation, requiring only SAT checks rather than MUS enumeration during training. This enables efficient MUS enumeration on real-world problems without the need for task-specific training data.

## Key Results
- GRAPE-MUST achieves significant speedups in MUS enumeration across random formulas, logistics planning, graph coloring, and real-world SAT competition problems
- The model generalizes well to larger problems and different data distributions without requiring retraining
- Different MUS enumeration algorithms benefit differently from pruning, with REMUS showing the largest improvements while TOME sometimes performs worse

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Graph neural networks can learn to prune non-critical clauses from unsatisfiable formulas without destroying MUSes
- **Mechanism**: The GNN processes literal-clause graphs and learns to assign low pruning probabilities to critical clauses through SAT checking on pruned formulas
- **Core assumption**: Critical clauses tend to appear in many MUSes and their removal makes formulas satisfiable
- **Evidence anchors**:
  - [abstract]: "Importantly, our algorithm does not require data labeling by only checking the satisfiability of pruned formulas"
  - [section]: "Critical clauses are important in MUS enumeration as they tend to be involved in many MUSes of C"
  - [corpus]: Weak - no direct corpus evidence for this specific claim about GNN learning patterns
- **Break condition**: If the GNN fails to learn the distinction between critical and non-critical clauses, pruning will either be too aggressive (making formulas satisfiable) or too conservative (providing no speedup)

### Mechanism 2
- **Claim**: Training on random formulas generalizes to real-world problems without retraining
- **Mechanism**: The randomized formula generation procedure creates problems with similar statistical properties (clause lengths, clause-to-variable ratios) to real problems
- **Core assumption**: MUS enumeration problems share common structural patterns that can be learned from random distributions
- **Evidence anchors**:
  - [abstract]: "It does not even require training data from the target application because it extrapolates to data with different distributions"
  - [section]: "This procedure yields problems that resemble the data distribution in clause lengths and clause-to-variable ratios"
  - [corpus]: Missing - no corpus evidence for this generalization claim
- **Break condition**: If real-world problems have fundamentally different structural properties than the generated random formulas, the model will fail to generalize

### Mechanism 3
- **Claim**: Binary search for optimal pruning threshold is computationally efficient compared to enumeration
- **Mechanism**: The pruning procedure uses O(log k) SAT calls where k is a hyperparameter, while enumeration requires many more SAT calls
- **Core assumption**: The computational cost of pruning is negligible compared to the time saved in enumeration
- **Evidence anchors**:
  - [section]: "In the worst case, t = max(µ) will give S′ = S without pruning. There are O(log k) SAT calls, which is typically much less than SAT calls in MUS searching algorithms"
  - [abstract]: "The pruning procedure only takes a small fraction of the overall running time that includes the enumeration time"
  - [corpus]: Weak - no direct corpus evidence for this specific efficiency claim
- **Break condition**: If the pruned formulas remain too large for the enumeration algorithm to benefit, or if k is too large making the pruning procedure expensive

## Foundational Learning

- **Concept**: Graph neural networks for heterogeneous graphs
  - **Why needed here**: The method represents CNF formulas as literal-clause graphs with different node types (variables/clauses) and edge types (variable-clause connections, negation connections)
  - **Quick check question**: Can you explain how message passing works differently for variable nodes versus clause nodes in a heterogeneous graph?

- **Concept**: Weak supervision and score function estimators
  - **Why needed here**: The model trains without labeled data by using SAT checks as weak supervision, requiring gradient estimation through the score function estimator
  - **Quick check question**: What is the main drawback of using the score function estimator for gradient computation?

- **Concept**: Binary search optimization
  - **Why needed here**: The pruning threshold is optimized through binary search to find the most aggressive pruning that maintains unsatisfiability
  - **Quick check question**: How does binary search reduce the number of SAT calls compared to linear search for the optimal threshold?

## Architecture Onboarding

- **Component map**: CNF formula → Literal-clause graph → GNN embedding → Clause probability prediction → Binary search threshold → Pruned formula → MUS enumeration
- **Critical path**: CNF formula → Literal-clause graph → GNN embedding → Clause probability prediction → Binary search threshold → Pruned formula → MUS enumeration
- **Design tradeoffs**:
  - Lightweight GNN vs. deeper/more complex models for scalability
  - Conservative-to-aggressive training strategy vs. immediate aggressive pruning
  - Random formula generation vs. task-specific training data
  - Potential MUS destruction vs. enumeration speedup
- **Failure signatures**:
  - SAT solver always returns unsatisfiable during pruning (model too conservative)
  - Pruning removes too many clauses making formulas satisfiable (model too aggressive)
  - No speedup observed despite successful pruning (enumeration algorithm not bottlenecked)
  - Poor generalization to new problem distributions
- **First 3 experiments**:
  1. Train on random formulas with 100 variables, test pruning on formulas of same size, measure reduction in clause count
  2. Evaluate enumeration speedup on random formulas with 1-second timeout using MARCO solver
  3. Test generalization to logistics planning problems with model trained only on random formulas

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How can we develop more scalable techniques to reduce variance in the score function estimator used for training?
- **Basis in paper**: [explicit] The paper notes that while the score function estimator works well in experiments, it often has large variance and mentions exploring techniques to reduce this variance as future work.
- **Why unresolved**: The current training objective uses the score function estimator which has high variance, limiting scalability and convergence speed.
- **What evidence would resolve it**: Empirical demonstration of improved training stability and convergence speed using variance reduction techniques like control variates or REINFORCE with baseline.

### Open Question 2
- **Question**: Can we design a differentiable loss function that explicitly preserves MUSes during pruning?
- **Basis in paper**: [inferred] The paper uses a loss function that avoids searching for MUSes during training for scalability, but acknowledges this may destroy MUSes and notes this as a limitation worth further discussion.
- **Why unresolved**: The current loss function only ensures unsatisfiability and encourages pruning, but doesn't guarantee MUS preservation which is important for MUS enumeration applications.
- **What evidence would resolve it**: A differentiable training objective that provably maintains MUSes while still being computationally efficient, validated by experimental comparison showing improved MUS enumeration performance.

### Open Question 3
- **Question**: What is the optimal underlying MUS enumeration algorithm to pair with graph pruning for maximum performance gain?
- **Basis in paper**: [explicit] The paper shows different enumeration algorithms benefit differently from pruning, with REMUS consistently showing the largest improvements while TOME sometimes performs worse.
- **Why unresolved**: The paper only tests three enumeration algorithms and finds varying results, suggesting the interaction between pruning strategy and enumeration algorithm choice is complex and problem-dependent.
- **What evidence would resolve it**: Systematic comparison of graph pruning with all major MUS enumeration algorithms across diverse problem domains, identifying conditions under which different combinations perform optimally.

## Limitations

- The claim of generalization across data distributions without retraining lacks experimental validation
- The efficiency advantage of binary search over enumeration is not validated with corpus evidence
- The method does not address how MUS size distribution affects pruning effectiveness

## Confidence

- **Mechanism 1 (GNN pruning without destroying MUSes)**: Medium - the approach is sound but effectiveness depends on the GNN's ability to learn clause criticality
- **Mechanism 2 (Generalization to real-world problems)**: Low - claimed but not experimentally validated in the abstract
- **Mechanism 3 (Binary search efficiency)**: Medium - theoretically sound but lacks corpus validation

## Next Checks

1. Validate the generalization claim by testing the model trained on random formulas on a diverse set of real-world MUS problems from different domains
2. Measure the actual SAT calls during binary search versus direct enumeration to confirm the efficiency advantage
3. Analyze the impact of pruning on MUS size distribution and verify that the pruned formulas retain representative MUSes of the original problem