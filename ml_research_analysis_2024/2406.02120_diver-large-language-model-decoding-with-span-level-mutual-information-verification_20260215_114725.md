---
ver: rpa2
title: 'Diver: Large Language Model Decoding with Span-Level Mutual Information Verification'
arxiv_id: '2406.02120'
source_url: https://arxiv.org/abs/2406.02120
tags:
- diver
- decoding
- llms
- tasks
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Diver, a method for improving large language
  model decoding through span-level mutual information verification. Diver identifies
  divergence points during generation, generates multiple candidate spans, and selects
  the optimal span based on PMI scores, which measure the log-likelihood gains of
  the input if the candidate spans are generated.
---

# Diver: Large Language Model Decoding with Span-Level Mutual Information Verification

## Quick Facts
- **arXiv ID**: 2406.02120
- **Source URL**: https://arxiv.org/abs/2406.02120
- **Reference count**: 27
- **Primary result**: Diver improves faithfulness in LLM outputs by 11.77 average scores on E2E dataset vs vanilla decoding

## Executive Summary
This paper introduces Diver, a decoding method that improves faithfulness of LLM outputs by verifying span-level mutual information between generated text and input context. Diver identifies divergence points during generation, generates multiple candidate spans, and selects the optimal span based on PMI scores measuring log-likelihood gains. The method addresses the critical problem of LLMs generating content unfaithful to their input. Extensive experiments across code generation, machine translation, text summarization, dialogue response generation, and story generation demonstrate consistent improvements over baseline decoding methods.

## Method Summary
Diver operates by first identifying divergence points where the generated content may drift from the input context. At each divergence point, the model generates multiple candidate spans and evaluates them using pointwise mutual information (PMI) scores, which quantify the log-likelihood gains if those spans were generated given the input. The span with the highest PMI score is selected and integrated into the ongoing generation process. This verification mechanism ensures that generated content maintains stronger alignment with the input throughout the decoding process. The approach can be integrated with existing LLMs without requiring model retraining or architectural modifications.

## Key Results
- Diver achieves 11.77 average score improvement on E2E dataset compared to vanilla decoding
- Consistently outperforms greedy search, nucleus sampling, contrastive decoding, and context-aware decoding across multiple tasks
- Shows substantial gains in code generation and machine translation where input faithfulness is critical
- Demonstrates effectiveness across diverse NLP tasks including summarization, dialogue, and story generation

## Why This Works (Mechanism)
Diver works by introducing a verification layer that measures semantic alignment between candidate generations and the original input. By calculating PMI scores at divergence points, the method quantifies how much each candidate span contributes to explaining the relationship between input and potential output. This mutual information verification acts as a consistency check that prevents the model from drifting into unfaithful generations. The span-level granularity allows for precise corrections while maintaining fluency, as only problematic segments are re-evaluated rather than entire sequences.

## Foundational Learning
- **Pointwise Mutual Information (PMI)**: Measures association between two events; needed to quantify input-output alignment; quick check: verify PMI calculation between input and candidate spans
- **Divergence Point Detection**: Identifies where generation may deviate from input context; needed to target verification where most beneficial; quick check: confirm divergence detection accuracy on validation data
- **Span Generation**: Creates multiple candidate continuations at critical points; needed to provide alternatives for selection; quick check: ensure candidate diversity while maintaining coherence
- **Log-Likelihood Gain**: Quantifies improvement from selecting specific spans; needed to rank candidates objectively; quick check: validate log-likelihood calculations against reference implementations
- **Faithfulness Verification**: Ensures generated content aligns with input; needed to solve the core problem of unfaithful generation; quick check: measure input-output alignment metrics
- **Multi-candidate Selection**: Chooses optimal span from alternatives; needed to improve over single-path decoding; quick check: compare selection accuracy against random choice baseline

## Architecture Onboarding

**Component Map**: Input Context -> Divergence Detector -> Span Generator -> PMI Calculator -> Span Selector -> Output Generator

**Critical Path**: The critical execution path follows: input context flows to divergence detector, which identifies points requiring verification. At each point, the span generator produces multiple candidates, the PMI calculator scores each candidate's alignment with input, the selector chooses the highest-scoring span, and this selected span is integrated into the output generator for continued generation.

**Design Tradeoffs**: The method trades computational overhead (generating multiple candidates per divergence point) for improved faithfulness. This creates a balance between accuracy and efficiency, as more candidates provide better selection options but increase computation time. The span-level granularity provides precise control but may miss longer-range inconsistencies that cross multiple spans.

**Failure Signatures**: The method may fail when PMI scores are ambiguous (multiple candidates with similar scores), when divergence detection misses subtle drifts, or when the span generator fails to produce viable alternatives. It may also struggle with tasks requiring creative deviation from input or when input-output relationships are inherently weak.

**First Experiments**: 1) Run baseline comparison on a single dataset (e.g., E2E) with greedy search, nucleus sampling, and Diver to establish performance differential, 2) Test divergence detection accuracy by measuring how often it identifies known problematic generation points, 3) Evaluate candidate diversity by measuring overlap between top-scoring spans across multiple runs.

## Open Questions the Paper Calls Out
None specified in the provided information.

## Limitations
- PMI-based selection may not generalize well to tasks requiring creative or subjective outputs where faithfulness is less critical
- Computational overhead from generating and evaluating multiple candidate spans could impact scalability for very large models
- Method does not address potential biases introduced by PMI-based selection that could favor safer, less diverse outputs

## Confidence
- **High**: Code generation and machine translation tasks with substantial empirical improvements across multiple datasets
- **Medium**: Text summarization, dialogue response generation, and story generation due to fewer comparative baselines and less diverse evaluation metrics

## Next Checks
1) Test Diver on tasks with high subjectivity (e.g., creative writing) to assess trade-offs between faithfulness and creativity
2) Evaluate the method's computational efficiency on larger models (e.g., GPT-4) to confirm scalability
3) Investigate whether PMI-based selection introduces bias by analyzing output diversity and novelty across tasks