---
ver: rpa2
title: 'Game of Trojans: Adaptive Adversaries Against Output-based Trojaned-Model
  Detectors'
arxiv_id: '2402.08695'
source_url: https://arxiv.org/abs/2402.08695
tags:
- trojan
- adversary
- samples
- trojaned
- clean
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We show that a Trojaned DNN model can effectively evade SOTA output-based
  Trojan detection methods while maintaining high accuracy on both clean and trigger-embedded
  samples. We model the interaction between an adaptive adversary and detector as
  a min-max optimization game.
---

# Game of Trojans: Adaptive Adversaries Against Output-based Trojaned-Model Detectors

## Quick Facts
- **arXiv ID:** 2402.08695
- **Source URL:** https://arxiv.org/abs/2402.08695
- **Reference count:** 40
- **Key outcome:** Adaptive adversaries can effectively evade state-of-the-art output-based Trojan detection methods while maintaining high accuracy on both clean and trigger-embedded samples.

## Executive Summary
This paper introduces an adaptive adversarial framework to evade output-based Trojan detection methods in deep neural networks. The authors formulate the interaction between an adaptive adversary and detector as a min-max optimization game, where the adversary updates Trojaned model parameters to minimize detection probability while maintaining accuracy, and the detector updates its parameters to maximize detection. The theoretical framework proves that solving this game leads to identical output distributions from clean and Trojaned models, making them indistinguishable. The paper also provides a greedy algorithm for minimal sample selection with provable performance guarantees.

## Method Summary
The authors model the interaction between an adaptive adversary and Trojan detection methods as a min-max optimization game. The adversary updates the parameters of a Trojaned model to minimize detection probability while maintaining high accuracy on both clean and trigger-embedded samples. Simultaneously, the detector updates its parameters to maximize detection accuracy. The key theoretical result shows that under optimal conditions, the output distributions of clean and Trojaned models become identical, making detection impossible. A greedy algorithm is proposed for selecting a minimal set of samples for trigger embedding, which provides provable performance guarantees when using cross-entropy or log-likelihood loss functions. The approach is validated across multiple datasets (MNIST, CIFAR-10, CIFAR-100, SpeechCommand) against four state-of-the-art detectors (MNTD, NeuralCleanse, STRIP, TABOR).

## Key Results
- The adaptive adversary successfully evades four state-of-the-art output-based Trojan detectors across multiple datasets
- Theoretical proof demonstrates that optimal solutions to the min-max game yield indistinguishable output distributions between clean and Trojaned models
- The greedy sample selection algorithm achieves provable performance guarantees for cross-entropy and log-likelihood loss functions
- Trojaned models maintain high accuracy on both clean and trigger-embedded samples while evading detection

## Why This Works (Mechanism)
The approach works by leveraging min-max optimization to find a saddle point where the adversary's updates to the Trojaned model parameters minimize detection probability while maintaining accuracy, and the detector's updates maximize detection. The theoretical proof shows that at this equilibrium, the output distributions of clean and Trojaned models become identical, making them statistically indistinguishable. The greedy algorithm for sample selection ensures that trigger embedding affects the model's behavior minimally while still achieving the desired backdoor functionality.

## Foundational Learning
1. **Min-max optimization in adversarial settings**: Understanding the mathematical framework for modeling adaptive adversaries and defenders
   - Why needed: Forms the theoretical foundation for the adaptive adversary approach
   - Quick check: Verify convergence properties of the optimization game

2. **Output distribution analysis**: Statistical comparison of model outputs under different conditions
   - Why needed: Central to proving indistinguishability between clean and Trojaned models
   - Quick check: Compare KL divergence between output distributions

3. **Greedy algorithms for sample selection**: Approximation methods for NP-hard optimization problems
   - Why needed: Enables efficient selection of trigger embedding samples with theoretical guarantees
   - Quick check: Validate approximation ratio bounds for the greedy approach

4. **Trojan detection methods**: Understanding state-of-the-art detection techniques and their vulnerabilities
   - Why needed: Essential for designing effective adaptive evasion strategies
   - Quick check: Analyze detection methods' sensitivity to output distribution changes

## Architecture Onboarding

**Component Map:** Adaptive Adversary -> Trojaned Model -> Detector -> Loss Function -> Model Parameters

**Critical Path:** Sample Selection → Trigger Embedding → Min-Max Optimization → Output Distribution Analysis → Detection Evasion

**Design Tradeoffs:** Computational complexity of min-max optimization vs. detection evasion performance; sample selection efficiency vs. provable guarantees; model accuracy maintenance vs. trigger effectiveness

**Failure Signatures:** 
- Non-convergence of min-max optimization
- Significant accuracy degradation on clean samples
- Inconsistent trigger activation across similar inputs
- Detection accuracy remaining above random chance

**First Experiments:**
1. Validate min-max optimization convergence on a simple binary classification problem with synthetic detectors
2. Test the greedy sample selection algorithm's approximation ratio on a small dataset with known optimal solution
3. Evaluate output distribution indistinguishability using statistical tests (e.g., t-test, KS test) on a controlled setup

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical proof relies on optimal conditions that may not be achievable in practice with finite data and computational constraints
- Assumes the adversary has access to detector's internal parameters, which may not reflect realistic threat models
- Greedy algorithm's practical performance may not scale well to large datasets or complex models
- Experimental results are primarily based on controlled laboratory conditions without extensive real-world validation

## Confidence

**High confidence in:** Theoretical framework and min-max optimization formulation
**Medium confidence in:** Greedy algorithm's practical performance guarantees and experimental results under controlled conditions
**Low confidence in:** Real-world applicability without additional validation

## Next Checks
1. Test the adaptive adversary against a detector that incrementally updates its parameters during the game, simulating a more realistic adaptive defense scenario
2. Evaluate the Trojaned models' performance on out-of-distribution samples and other security-relevant metrics beyond accuracy and detection evasion
3. Conduct a scalability analysis of the greedy sample selection algorithm on larger datasets and more complex model architectures to assess computational feasibility