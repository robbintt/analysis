---
ver: rpa2
title: 'TaskGen: A Task-Based, Memory-Infused Agentic Framework using StrictJSON'
arxiv_id: '2407.15734'
source_url: https://arxiv.org/abs/2407.15734
tags:
- agent
- taskgen
- function
- functions
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TaskGen is an open-sourced agentic framework that breaks down complex
  tasks into manageable subtasks, each mapped to an Equipped Function or Inner Agent
  for execution. To enhance efficiency and reduce token usage, TaskGen employs StrictJSON
  for structured, type-checked JSON outputs and implements Shared Memory for context
  sharing on a need-to-know basis.
---

# TaskGen: A Task-Based, Memory-Infused Agentic Framework using StrictJSON

## Quick Facts
- arXiv ID: 2407.15734
- Source URL: https://arxiv.org/abs/2407.15734
- Reference count: 40
- Key result: TaskGen achieves high performance across diverse environments with 100% solve rate in dynamic maze navigation, 96% in TextWorld escape rooms, and strong results on MATH and NaturalQuestions datasets

## Executive Summary
TaskGen is an open-source agentic framework designed to break down complex tasks into manageable subtasks using a combination of Equipped Functions and Inner Agents. The framework employs StrictJSON for structured, type-checked JSON outputs to enhance efficiency and reduce token usage, while implementing Shared Memory for context sharing on a need-to-know basis. TaskGen incorporates Global Context for dynamic environmental awareness and a Memory Bank for abstraction-level memory storage and retrieval. Empirical evaluations demonstrate TaskGen's versatility and effectiveness across diverse environments, achieving impressive performance metrics across multiple benchmark tasks.

## Method Summary
TaskGen employs a task-based approach where complex tasks are decomposed into subtasks, each mapped to specific Equipped Functions or Inner Agents for execution. The framework uses StrictJSON to enforce structured, type-checked JSON outputs, reducing verbosity and token consumption. Shared Memory enables context sharing between agents only when necessary, while Global Context provides dynamic environmental awareness. The Memory Bank stores and retrieves information at different abstraction levels. The system was evaluated across multiple environments including dynamic maze navigation, TextWorld escape rooms, web browsing tasks, mathematical problem-solving, and retrieval-augmented generation tasks.

## Key Results
- Achieved 100% solve rate in dynamic maze navigation tasks
- Demonstrated 96% success rate in TextWorld escape room challenges
- Recorded 71% accuracy on MATH dataset problems and 47.03% F1 score on NaturalQuestions dataset

## Why This Works (Mechanism)
TaskGen's effectiveness stems from its structured decomposition of complex tasks into manageable subtasks, each handled by specialized components. The StrictJSON implementation enforces type safety and reduces token usage by eliminating unnecessary verbosity. Shared Memory allows agents to access context only when needed, preventing information overload. The combination of Global Context for environmental awareness and Memory Bank for abstraction-level storage creates a comprehensive memory system that enhances decision-making and problem-solving capabilities across diverse environments.

## Foundational Learning
**Task Decomposition**: Breaking complex tasks into manageable subtasks - needed to handle complexity systematically; quick check: can any task be mapped to subtasks
**StrictJSON**: Type-checked JSON outputs for efficiency - needed to reduce token usage and enforce structure; quick check: outputs conform to JSON schema
**Shared Memory**: Context sharing on need-to-know basis - needed to prevent information overload; quick check: memory access patterns follow need-to-know principle
**Global Context**: Dynamic environmental awareness - needed for adaptive decision-making; quick check: context updates reflect environmental changes
**Memory Bank**: Abstraction-level memory storage - needed for efficient information retrieval; quick check: memory retrieval matches abstraction requirements

## Architecture Onboarding

Component Map:
Task Decomposition -> Equipped Functions/Inner Agents -> StrictJSON Output -> Shared Memory Access -> Global Context Update -> Memory Bank Storage/Retrieval

Critical Path:
Complex Task → Task Decomposition → Subtask Assignment → Agent Execution → StrictJSON Output → Memory Update → Result Aggregation

Design Tradeoffs:
- Structured vs. flexible output formats (StrictJSON vs. free-form)
- Centralized vs. distributed memory systems
- Rule-based vs. LLM-based component selection
- Individual vs. collaborative agent approaches

Failure Signatures:
- Subtask decomposition failures leading to incomplete task execution
- StrictJSON validation errors causing agent communication breakdowns
- Memory access conflicts in Shared Memory system
- Global Context desynchronization with environmental changes

First Experiments:
1. Simple task decomposition with basic Equipped Functions
2. StrictJSON validation with increasing complexity
3. Shared Memory access patterns with multiple agents

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does TaskGen's performance scale when dealing with significantly larger context lengths, beyond the tested environments?
- Basis in paper: [inferred] The paper notes that "an increase in context length generally leads to poorer performance" and that TaskGen aims to be "less verbose" to mitigate this issue.
- Why unresolved: The paper evaluates TaskGen on specific environments with relatively limited context lengths. It does not provide empirical evidence of TaskGen's performance on tasks requiring extremely long context lengths.
- What evidence would resolve it: Testing TaskGen on tasks requiring very long context lengths (e.g., multi-document summarization, long-form question answering) and comparing its performance to other frameworks under similar conditions.

### Open Question 2
- Question: What is the optimal balance between rule-based components and LLM-based components in TaskGen's architecture for different task types?
- Basis in paper: [inferred] The paper mentions that "full end-to-end agentic workflows may not always provide the best performance" and suggests a hybrid approach combining fixed processes with flexible agentic process selection. It also notes that pathfinding tasks are "best done by rule-based deterministic methods."
- Why unresolved: The paper does not provide a systematic analysis of when to use rule-based vs. LLM-based components within TaskGen for optimal performance across various task types.
- What evidence would resolve it: A comprehensive study comparing TaskGen's performance with different ratios of rule-based to LLM-based components across a wide range of task types, identifying optimal configurations for each.

### Open Question 3
- Question: How does TaskGen's multi-agent collaboration approach with memory-sharing compare to other multi-agent frameworks in terms of efficiency and accuracy?
- Basis in paper: [explicit] The paper states that "multiple agents with different skills and biases collaborating with one another" is a future direction for TaskGen and mentions exploring "multiple agents with past memory, and some agents without any past memory."
- Why unresolved: The paper does not compare TaskGen's multi-agent approach to other existing multi-agent frameworks or provide empirical evidence of its efficiency and accuracy in collaborative settings.
- What evidence would resolve it: Benchmarking TaskGen's multi-agent collaboration against other established multi-agent frameworks on tasks requiring distributed problem-solving, measuring both task completion rates and resource usage (tokens, time).

## Limitations
- Lack of external validation or independent reproduction of reported results
- Insufficient technical depth in architectural claims regarding StrictJSON and memory implementations
- Limited empirical evidence for token usage reduction claims without baseline comparisons

## Confidence
- Framework architecture and design principles: Medium confidence
- Performance metrics: Low confidence
- Memory management effectiveness: Medium confidence

## Next Checks
1. Independent reproduction of benchmark results using publicly available code and datasets to verify the claimed performance metrics.
2. Ablation studies comparing StrictJSON implementation against standard JSON outputs to quantify actual token usage reduction and efficiency gains.
3. Scalability testing with larger, more diverse task environments and multi-agent scenarios to evaluate framework robustness beyond the reported test cases.