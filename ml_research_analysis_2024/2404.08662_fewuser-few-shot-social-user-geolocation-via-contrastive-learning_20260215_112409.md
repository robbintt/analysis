---
ver: rpa2
title: 'FewUser: Few-Shot Social User Geolocation via Contrastive Learning'
arxiv_id: '2404.08662'
source_url: https://arxiv.org/abs/2404.08662
tags:
- user
- geolocation
- fewuser
- learning
- social
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of social user geolocation when
  labeled data is scarce. The authors propose FewUser, a framework that leverages
  contrastive learning between users and locations to improve geolocation performance
  in zero-shot and few-shot settings.
---

# FewUser: Few-Shot Social User Geolocation via Contrastive Learning

## Quick Facts
- arXiv ID: 2404.08662
- Source URL: https://arxiv.org/abs/2404.08662
- Authors: Menglin Li; Kwan Hui Lim
- Reference count: 34
- Key result: Achieves 26.95% and 41.62% absolute improvements on TwiU and FliU datasets in 1-shot setting

## Executive Summary
This paper addresses the challenge of social user geolocation when labeled data is scarce. The authors propose FewUser, a framework that leverages contrastive learning between users and locations to improve geolocation performance in zero-shot and few-shot settings. Key components include a user representation module with various input integration and feature fusion strategies, and a geographical prompting module with hard, soft, and semi-soft prompts to align PLM knowledge with geographical data. FewUser is trained using a contrastive loss and a matching loss with hard negative mining. The authors construct two new datasets, TwiU and FliU, with richer metadata than existing benchmarks. Extensive experiments show that FewUser significantly outperforms state-of-the-art methods, achieving absolute improvements of 26.95% and 41.62% on TwiU and FliU respectively in a 1-shot setting.

## Method Summary
FewUser combines a user representation module that integrates user profiles, tweets, and metadata using six different strategies, with a geographical prompting module that injects location-specific context into the text encoder through hard, soft, or semi-soft prompts. The framework uses SimCSE as the text encoder and employs a contrastive learning approach with InfoNCE loss to align user embeddings with geographic locations. Training involves both a contrastive loss and a matching loss with hard negative mining, where negative samples are selected using multinomial sampling based on distance to the positive sample. The model is evaluated on two newly constructed datasets, TwiU and FliU, which contain richer metadata than existing benchmarks.

## Key Results
- Achieves 26.95% and 41.62% absolute improvements on TwiU and FliU datasets in 1-shot setting
- Outperforms ClassUser (no contrastive learning) across all few-shot settings
- Semi-soft prompts show superior performance compared to hard and soft prompts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contrastive learning between user embeddings and location embeddings improves geolocation performance under data scarcity
- Mechanism: The framework learns to minimize distance between matched user-location pairs and maximize distance for mismatched pairs using InfoNCE loss
- Core assumption: Geographic proximity correlates with semantic similarity in the embedding space, and this relationship can be learned through contrastive training
- Evidence anchors:
  - [abstract] "We incorporate a contrastive learning strategy between users and locations to improve geolocation performance with no or limited training data."
  - [section] "Contrastive learning is implemented through a contrastive loss and a matching loss, inspired by ALBEF [11], based on user and location representations."
  - [corpus] Found related work on few-shot geolocation using contrastive learning, suggesting this is an active research direction
- Break condition: If geographic proximity does not correlate with embedding similarity, or if the contrastive loss dominates and creates false correlations

### Mechanism 2
- Claim: Geographical prompting modules (hard, soft, semi-soft) bridge the knowledge gap between PLMs and geographical data
- Mechanism: Prompts inject location-specific context into the text encoder, helping it better encode geographic information. Semi-soft prompts learn optimal prompt representations during training
- Core assumption: PLMs lack sufficient geographical knowledge and need explicit prompting to encode location information effectively
- Evidence anchors:
  - [abstract] "To bridge the gap between PLM's knowledge and geographical data, we introduce a geographical prompting module with hard, soft, and semi-soft prompts, to enhance the encoding of location information."
  - [section] "Inspired by OptiPrompt [31], we refine this estimate by directly optimizing the representation of prompts in a continuous embedding space."
  - [corpus] Related work exists on prompting methods for PLMs, supporting the plausibility of this approach
- Break condition: If prompts do not improve location encoding or if learned prompts overfit to training data

### Mechanism 3
- Claim: Rich metadata in TwiU and FliU datasets enables better user representation learning than existing benchmarks
- Mechanism: Additional profile and tweet metadata provides more diverse and informative signals for geolocation, allowing the model to learn more robust user representations
- Core assumption: More metadata fields contain useful geolocation signals that are absent in simpler datasets like GeoText
- Evidence anchors:
  - [abstract] "We construct two datasets TwiU and FliU, containing richer metadata than existing benchmarks, to enable a deep exploration of user representation on geolocation performance."
  - [section] "TwiU builds upon the WNUT16 dataset [3], which we further enhance by querying Twitter's API to retrieve user profiles, text and metadata of tweets using tweet IDs."
  - [corpus] The constructed datasets are unique in the corpus, providing evidence of their novelty
- Break condition: If additional metadata introduces noise or irrelevant signals that degrade performance

## Foundational Learning

- Concept: Contrastive learning and InfoNCE loss
  - Why needed here: Enables learning from limited labeled data by using semantic similarity as a training signal
  - Quick check question: How does the temperature hyperparameter τ affect the contrastive loss behavior?

- Concept: Prompt engineering for PLMs
  - Why needed here: Bridges the gap between general language knowledge and domain-specific geographical knowledge
  - Quick check question: What's the difference between hard prompts and soft prompts in terms of optimization?

- Concept: User representation fusion techniques
  - Why needed here: Combines multiple input sources (profile, tweets, metadata) into a single embedding for geolocation
  - Quick check question: Why might mean pooling outperform LSTM for user feature fusion in this task?

## Architecture Onboarding

- Component map: User representation module → Geographical prompting module → Contrastive learning with two losses → Hard negative mining
- Critical path: Input integration → Text encoding with prompts → User feature fusion → Contrastive/matching loss computation → Parameter update
- Design tradeoffs: Simple integration (In1) vs. complex integration for better alignment in contrastive space; parameter-free mean pooling vs. learned fusion methods
- Failure signatures: Poor performance on zero-shot setting indicates prompting issues; failure to improve with more training data suggests contrastive learning not learning meaningful representations
- First 3 experiments:
  1. Baseline comparison: Run FewUser vs. ClassUser (no contrastive learning) on 1-shot setting to verify contrastive learning contribution
  2. Prompt ablation: Compare hard, soft, and semi-soft prompts on TwiU to find optimal prompting strategy
  3. Integration comparison: Test all six integration strategies (In1-InT, etc.) to identify best approach for this task

## Open Questions the Paper Calls Out
None

## Limitations
- Performance claims based on newly constructed datasets (TwiU and FliU) that lack independent verification
- Limited ablation studies on critical design choices, particularly prompt types and number of tweets used
- Semi-soft prompting effectiveness across diverse geographical contexts needs further investigation

## Confidence
- **High confidence**: Contrastive learning framework architecture and loss formulation are clearly specified and follow established patterns from ALBEF
- **Medium confidence**: Performance improvements are substantial but rely on newly constructed datasets that lack independent verification
- **Low confidence**: Semi-soft prompting mechanism's effectiveness across diverse geographical contexts and potential for overfitting remain unclear

## Next Checks
1. Test FewUser on established geolocation benchmarks like GeoText or GeoNames to verify performance claims generalize beyond the constructed TwiU and FliU datasets

2. Systematically vary the number of tweets (2, 4, 6, 8) and prompt types (hard vs soft vs semi-soft) on TwiU to determine sensitivity of performance to these design choices

3. Evaluate FewUser on users from regions not represented in the training data to assess whether the model has learned generalizable geographical patterns or merely memorized location-specific features