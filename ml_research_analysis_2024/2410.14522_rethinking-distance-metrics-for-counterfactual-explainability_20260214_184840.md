---
ver: rpa2
title: Rethinking Distance Metrics for Counterfactual Explainability
arxiv_id: '2410.14522'
source_url: https://arxiv.org/abs/2410.14522
tags:
- counterfactual
- distribution
- explanations
- counterfactuals
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the limitations of standard counterfactual\
  \ explanation methods, which often generate explanations that lie outside the data\
  \ distribution by treating counterfactuals as independent samples around a reference\
  \ point. The authors propose a new framework that models counterfactuals as jointly\
  \ sampled with the reference from the underlying data distribution using a Gaussian\
  \ prior with correlation parameter \u03B1."
---

# Rethinking Distance Metrics for Counterfactual Explainability

## Quick Facts
- arXiv ID: 2410.14522
- Source URL: https://arxiv.org/abs/2410.14522
- Reference count: 40
- This paper addresses limitations of standard counterfactual explanation methods by modeling counterfactuals as jointly sampled with references from the underlying data distribution using a Gaussian prior with correlation parameter α.

## Executive Summary
This paper identifies a fundamental limitation in standard counterfactual explanation methods: they often generate counterfactuals that lie outside the data distribution by treating them as independent samples around a reference point. The authors propose a new framework that models counterfactuals as jointly sampled with their reference from the underlying data distribution using a Gaussian prior with correlation parameter α. This approach ensures counterfactuals remain within plausible regions while allowing nuanced control over similarity to the reference through α. The method is evaluated across multiple datasets using the CARLA benchmark, showing improved faithfulness to the data distribution without significant degradation in other metrics. Qualitative evaluations demonstrate more semantically meaningful counterfactuals compared to standard methods, and a user study provides insights into human preferences for different explanation approaches.

## Method Summary
The method proposes a new distance metric for counterfactual explanations based on modeling counterfactuals as jointly distributed with their reference points from a Gaussian distribution. The key innovation is introducing a correlation parameter α that controls the dependency between reference and counterfactual, allowing for a spectrum from perfect correlation (α=1) to independence (α=0). The framework naturally incorporates actionability constraints by manipulating the prior covariance structure, setting immutable features to have perfect correlation and modeling mutable-but-non-actionable features through causal dependencies. Counterfactuals are generated by sampling from the conditional Gaussian posterior distribution, and the method is evaluated across image and tabular datasets using metrics like l2 distance, yNN (number of nearest neighbors with desired label), redundancy, and diversity.

## Key Results
- The proposed method improves faithfulness to the data distribution (measured by yNN metric) across multiple datasets without significant degradation in other metrics
- Qualitative evaluations on MNIST and Fashion MNIST show more semantically meaningful counterfactual images compared to standard methods
- A user study with 1503 pairwise comparisons across three datasets found no universal preference for any method, highlighting the importance of accounting for feature dependencies and individual cost perceptions
- The correlation parameter α provides effective control over the trade-off between similarity to reference and achieving desired predictions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The proposed framework ensures counterfactuals remain within the data distribution by modeling them as jointly sampled with the reference from the underlying distribution.
- **Mechanism**: Instead of treating counterfactuals as independent draws from a region around the reference point, the method uses a Gaussian prior with correlation parameter α to express the codependency between reference and counterfactual. This creates a joint distribution that naturally constrains counterfactuals to regions of high probability under the data distribution.
- **Core assumption**: The underlying data distribution can be reasonably approximated as Gaussian, and counterfactuals should be viewed as jointly distributed with their reference rather than independently generated.
- **Evidence anchors**:
  - [abstract]: "models counterfactuals as jointly sampled with the reference from the underlying data distribution using a Gaussian prior with correlation parameter α"
  - [section 3]: "The key idea of our approach is that while counterfactuals are often considered to be wholly dependent on the reference... we should treat x and x′ as dependent on one another"
  - [corpus]: Weak - corpus papers focus on different aspects of counterfactuals but don't directly address this joint sampling approach
- **Break condition**: If the data distribution is highly non-Gaussian or has complex dependencies that cannot be captured by the correlation parameter α, the method may fail to generate realistic counterfactuals.

### Mechanism 2
- **Claim**: The correlation parameter α allows nuanced control over the similarity between reference and counterfactual while maintaining data plausibility.
- **Mechanism**: By scaling α from 1 to 0, the method controls how tightly the counterfactual is constrained to the reference versus how much emphasis is placed on achieving the desired prediction. When α=1, counterfactuals are perfectly correlated with the reference; when α=0, they are independent draws from the data distribution.
- **Core assumption**: There exists a meaningful spectrum between preserving reference similarity and achieving desired predictions that can be controlled through a single correlation parameter.
- **Evidence anchors**:
  - [section 3]: "Scaling α from 1 to 0 scales the similarity between reference and counterfactual"
  - [abstract]: "allowing nuanced control over similarity to the reference"
  - [corpus]: Missing - corpus papers don't discuss this specific parameterization approach
- **Break condition**: If the optimal trade-off between similarity and prediction accuracy requires a non-linear relationship that cannot be captured by α, the method may produce suboptimal counterfactuals.

### Mechanism 3
- **Claim**: The method naturally incorporates actionability constraints through manipulation of the prior covariance structure.
- **Mechanism**: Immutable features are enforced by setting their correlation to 1 (perfect correlation), while mutable-but-non-actionable features are modeled as causal descendants of other features. This is achieved by adjusting the correlation matrix W in the Gaussian prior.
- **Core assumption**: Actionability constraints can be effectively encoded as correlations in a Gaussian distribution.
- **Evidence anchors**:
  - [section 4.1]: "We set features as immutable through the following adjustment to W" and "We express these features, through a prior that encodes causal dependencies"
  - [abstract]: "the method is evaluated across multiple datasets using CARLA benchmark, showing improved faithfulness to the data distribution"
  - [corpus]: Weak - corpus papers discuss actionability but not through this specific Gaussian prior manipulation approach
- **Break condition**: If actionability constraints involve complex logical or combinatorial relationships that cannot be expressed through Gaussian correlations, the method may fail to generate truly actionable counterfactuals.

## Foundational Learning

- **Concept**: Gaussian distributions and their properties
  - Why needed here: The entire framework relies on modeling both the data distribution and the joint distribution of reference-counterfactual pairs as Gaussian
  - Quick check question: Given a multivariate Gaussian with mean μ and covariance Σ, what is the form of the conditional distribution p(x|y)?

- **Concept**: Probabilistic graphical models and d-separation
  - Why needed here: The method is motivated by showing how the standard PGM for counterfactuals fails to represent data distribution, and how the proposed PGM fixes this
  - Quick check question: In a Bayesian network, if node A is d-separated from node B given node C, what does this imply about their conditional independence?

- **Concept**: Mahalanobis distance and its relationship to Gaussian distributions
  - Why needed here: The proposed distance metric is essentially a Mahalanobis distance that accounts for the data covariance structure
  - Quick check question: How does Mahalanobis distance differ from Euclidean distance, and why is it more appropriate for comparing points in a Gaussian distribution?

## Architecture Onboarding

- **Component map**: Data preprocessing → Prior estimation → Counterfactual generation → Evaluation
- **Critical path**: Data → Prior estimation → Counterfactual generation → Evaluation
- **Design tradeoffs**:
  - Gaussian assumption vs. flexibility: The method assumes Gaussian data which may not hold for all datasets
  - Computational cost: Sampling from Gaussian posteriors is efficient, but estimating accurate priors can be expensive for high-dimensional data
  - Interpretability vs. performance: The method provides clear probabilistic interpretation but may sacrifice some predictive accuracy

- **Failure signatures**:
  - Counterfactuals fall outside plausible ranges (indicates poor prior estimation)
  - Very high l2 distances to reference (indicates α is too low)
  - Low yNN scores (indicates poor coverage of data distribution)
  - Counterfactuals are identical to reference (indicates α is too high)

- **First 3 experiments**:
  1. Generate counterfactuals for a simple 2D Gaussian dataset with known parameters, varying α to observe the trade-off between similarity and prediction accuracy
  2. Compare the proposed method against standard Euclidean distance on a tabular dataset, measuring yNN and l2 distance
  3. Apply the method to image data (e.g., Fashion MNIST), visualizing how counterfactuals change as α varies from 0 to 1

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of correlation parameter α affect the quality and interpretability of counterfactual explanations across different domains (tabular, image, text)?
- Basis in paper: [explicit] The paper discusses varying α from 1 to 0 to control similarity between reference and counterfactual, showing different effects on MNIST and Fashion MNIST datasets.
- Why unresolved: The evaluation only covers a few datasets and shows qualitative examples. A systematic study across diverse domains and tasks would reveal whether there are universal patterns or domain-specific optimal α values.
- What evidence would resolve it: Empirical studies testing different α values on multiple datasets across domains, measuring both quantitative metrics (yNN, l2 distance) and qualitative interpretability through user studies.

### Open Question 2
- Question: What is the impact of modeling feature dependencies using causal relationships versus correlation-based approaches on the actionability and plausibility of counterfactual explanations?
- Basis in paper: [explicit] Section 4.1 discusses incorporating causal dependencies for mutable, non-actionable features and mentions potential benefits for actionability.
- Why unresolved: The paper mentions the approach but doesn't provide empirical comparisons between causal and correlation-based methods for feature dependencies.
- What evidence would resolve it: Comparative experiments measuring actionability (recourse feasibility) and plausibility metrics between methods using causal relationships versus those using only correlation-based priors.

### Open Question 3
- Question: How does the proposed framework perform when the underlying data distribution assumption (Gaussian) is violated in real-world applications?
- Basis in paper: [inferred] The paper applies the method to MNIST and Fashion MNIST by applying logit transforms, but doesn't evaluate performance when the Gaussian assumption is significantly violated.
- Why unresolved: The evaluation focuses on cases where Gaussian assumptions can be reasonably approximated, but doesn't test performance degradation when these assumptions are strongly violated.
- What evidence would resolve it: Systematic experiments testing the method on non-Gaussian datasets (e.g., highly skewed, multimodal distributions) and comparing performance to methods that don't rely on Gaussian assumptions.

### Open Question 4
- Question: How does the proposed framework compare to adversarial attack methods in terms of the semantic meaning and plausibility of generated examples?
- Basis in paper: [explicit] Section 2.3 mentions that counterfactual generation methods can be framed as adversarial attacks, and Section 6.2 shows qualitative comparisons with VAE-based methods.
- Why unresolved: While the paper shows qualitative differences, there's no systematic comparison of the framework against adversarial attack methods in terms of semantic meaning and plausibility.
- What evidence would resolve it: Controlled experiments comparing counterfactual explanations generated by the proposed framework against those generated by adversarial attack methods, using both automated semantic similarity metrics and human evaluations of plausibility.

## Limitations
- The assumption that data distributions can be reasonably approximated as Gaussian remains untested on highly non-Gaussian datasets
- The user study results suggest no universal preference for any method, raising questions about the practical significance of improved data faithfulness
- The method's performance on high-dimensional, sparse datasets (like text) is not evaluated

## Confidence
- **High**: The mathematical framework for joint sampling and its relationship to Mahalanobis distance
- **Medium**: The empirical results showing improved yNN scores across datasets
- **Low**: The generalizability of user study findings to real-world deployment scenarios

## Next Checks
1. Test the method on datasets with known non-Gaussian distributions (e.g., mixture models, heavy-tailed distributions) to assess robustness
2. Conduct ablation studies varying α across its full range (0 to 1) to map the exact trade-off between data faithfulness and prediction accuracy
3. Implement the method on a high-dimensional sparse dataset (e.g., text classification) to evaluate scalability beyond image and tabular data