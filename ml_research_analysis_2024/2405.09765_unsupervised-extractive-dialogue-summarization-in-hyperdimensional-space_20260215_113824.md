---
ver: rpa2
title: Unsupervised Extractive Dialogue Summarization in Hyperdimensional Space
arxiv_id: '2405.09765'
source_url: https://arxiv.org/abs/2405.09765
tags: []
core_contribution: HyperSum introduces an extractive summarization framework using
  hyperdimensional computing (HDC) to create efficient and representative sentence
  embeddings. By leveraging the pseudo-orthogonality property of high-dimensional
  random vectors, HyperSum constructs sentence embeddings through word bundling and
  applies k-medoids clustering to extract summary sentences.
---

# Unsupervised Extractive Dialogue Summarization in Hyperdimensional Space

## Quick Facts
- arXiv ID: 2405.09765
- Source URL: https://arxiv.org/abs/2405.09765
- Reference count: 0
- Key outcome: HyperSum achieves state-of-the-art unsupervised extractive summarization performance while being 10-100x faster than neural baselines

## Executive Summary
HyperSum introduces an extractive summarization framework using hyperdimensional computing (HDC) to create efficient and representative sentence embeddings. By leveraging the pseudo-orthogonality property of high-dimensional random vectors, HyperSum constructs sentence embeddings through word bundling and applies k-medoids clustering to extract summary sentences. The method achieves superior ROUGE scores across multiple dialogue summarization benchmarks while offering significant computational efficiency gains compared to both traditional and neural approaches.

## Method Summary
HyperSum constructs sentence embeddings by bundling thermometer hypervectors for each word in utterances, incorporating position encoding through majority vote operations. The method applies alternating k-medoids clustering to find representative sentences (medoids) that form the summary. Using D=10,000 dimensions, the framework processes dialogue documents by splitting them into utterances, tokenizing words, assigning thermometer hypervectors, constructing sentence embeddings, and extracting summaries through clustering. The approach is evaluated on four dialogue summarization benchmarks: AMI, ICSI, Behance, and ELITR.

## Key Results
- Achieves state-of-the-art ROUGE scores across multiple dialogue summarization benchmarks
- Demonstrates 10-100x faster execution times compared to neural baselines
- Shows competitive faithfulness metrics (ExtEval) while maintaining superior efficiency
- Outperforms both traditional and transformer-based summarization methods

## Why This Works (Mechanism)
HyperSum leverages the pseudo-orthogonality property of high-dimensional random vectors, where random hypervectors in sufficiently high dimensions are nearly orthogonal with high probability. This allows for efficient bundling operations (majority vote) to create meaningful sentence representations that capture semantic similarity. The k-medoids clustering then identifies representative sentences that best summarize the dialogue content. The thermometer encoding provides a distributed representation for words that, when bundled, preserves semantic relationships through the algebraic properties of HD vectors.

## Foundational Learning
- **Pseudo-orthogonality principle**: Random high-dimensional vectors are nearly orthogonal with high probability, enabling efficient similarity computations through bundling operations
- **Thermometer encoding**: Maps discrete values to binary vectors with a specific pattern of ones, creating distributed representations suitable for HDC operations
- **Majority vote bundling**: Combines multiple hypervectors by selecting the most frequent bit at each position, creating a composite representation that preserves semantic information
- **k-medoids clustering**: Partitioning algorithm that identifies representative data points (medoids) to summarize clusters, suitable for the discrete nature of HD vectors

## Architecture Onboarding
**Component Map**: Document -> Utterance splitting -> Word tokenization -> Thermometer hypervector assignment -> Sentence embedding construction -> k-medoids clustering -> Summary extraction
**Critical Path**: Sentence embedding construction (bundling operations) and k-medoids clustering are the computational bottlenecks that determine overall runtime
**Design Tradeoffs**: Higher dimensional vectors (D=10,000) provide better pseudo-orthogonality but increase memory requirements; k-medoids provides discrete summaries but requires careful initialization
**Failure Signatures**: Poor ROUGE scores indicate issues with hypervector construction or clustering parameters; runtime spikes suggest inefficient bundling operations or inappropriate clustering initialization
**First Experiments**: 1) Verify pseudo-orthogonality by measuring cosine similarity between random hypervectors, 2) Test bundling operations with synthetic sentences to ensure semantic preservation, 3) Validate k-medoids convergence on small synthetic datasets

## Open Questions the Paper Calls Out
- How do HyperSum's embeddings compare to transformer-based embeddings for extractive summarization in terms of computational efficiency and quality?
- How does HyperSum's performance scale with longer documents and more complex sentence structures?
- Can HyperSum be adapted for abstractive summarization or other NLP tasks beyond extractive summarization?

## Limitations
- Reproducibility concerns around alternating k-medoids clustering implementation details, particularly initialization strategy and convergence criteria
- Absence of ablation studies examining hypervector dimension impact on different dataset characteristics
- Limited validation of multilingual performance claims beyond English benchmarks

## Confidence
**High Confidence**: Core claims about state-of-the-art performance and runtime efficiency are well-supported by quantitative results across four distinct benchmarks
**Medium Confidence**: Faithfulness evaluation shows competitive performance but metric sensitivity to dialogue-specific phenomena is not thoroughly examined
**Low Confidence**: Generalizability across language pairs lacks sufficient validation, with evaluation focusing primarily on English benchmarks

## Next Checks
1. Systematically vary hypervector dimension D and position encoding schemes across benchmarks to quantify parameter impact on performance and efficiency
2. Implement full pipeline on additional non-English dialogue datasets to validate cross-lingual performance claims
3. Compare thermometer encoding against alternative HDC encoding strategies to isolate contribution to performance gains