---
ver: rpa2
title: Towards Open-set Camera 3D Object Detection
arxiv_id: '2406.17297'
source_url: https://arxiv.org/abs/2406.17297
tags:
- object
- unknown
- objects
- detection
- known
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses open-set 3D object detection, where a detector
  must identify both known and unknown objects that may appear during inference but
  were not seen during training. The proposed OS-Det3D framework introduces a two-stage
  training approach.
---

# Towards Open-set Camera 3D Object Detection

## Quick Facts
- arXiv ID: 2406.17297
- Source URL: https://arxiv.org/abs/2406.17297
- Authors: Zhuolin He; Xinrun Li; Heng Gao; Jiachen Tang; Shoumeng Qiu; Wenfu Wang; Lvjian Lu; Xuchong Qiu; Xiangyang Xue; Jian Pu
- Reference count: 40
- One-line primary result: OS-Det3D improves detection of both known and unknown objects, achieving 23.2% recall and 0.7% AP for unknown objects on nuScenes while improving known object mAP by 2.1%

## Executive Summary
This paper addresses open-set 3D object detection, where a detector must identify both known and unknown objects that may appear during inference but were not seen during training. The proposed OS-Det3D framework introduces a two-stage training approach that first discovers unknown objects using geometric cues, then retrains the camera detector with pseudo-ground truth labels for these unknowns. Experiments on nuScenes and KITTI datasets demonstrate that OS-Det3D improves detection of both known and unknown objects, outperforming existing methods.

## Method Summary
OS-Det3D is a two-stage framework for open-set 3D object detection. In Stage 1, a 3D Object Discovery Network (ODN3D) is trained using only geometric cues (position, scale, rotation) in a class-agnostic manner to propose 3D object regions. ODN3D uses GeoHungarian matching that considers only geometric similarity without classification, and incorporates a 3D objectness score to improve detection of unknown objects. In Stage 2, a Joint Objectness Selection (JOS) module combines ODN3D's objectness scores with camera feature attention values to select high-quality pseudo-ground truth labels for unknown objects. These pseudo-labels are then used to retrain the camera 3D detector (BEVFormer) with an additional class for unknowns, using soft weighting based on objectness scores to prevent interference with known object detection.

## Key Results
- On nuScenes: 23.2% recall and 0.7% AP for unknown objects, while improving known object mAP by 2.1%
- On KITTI: ODN3D achieves 74.4% recall and 33.2% AP for unknown objects, significantly outperforming prior work
- Two-stage training with pseudo-labeling effectively improves both known and unknown object detection compared to single-stage approaches

## Why This Works (Mechanism)

### Mechanism 1
ODN3D learns geometric features of unknown objects through GeoHungarian matching and 3D objectness scoring. By using a classification-free GeoHungarian matching algorithm that only considers geometric cues (position and scale), ODN3D avoids penalizing the model for detecting unlabeled objects. The 3D objectness score (sobj) measures localization and scale quality, providing positive reinforcement for geometric accuracy regardless of class.

### Mechanism 2
JOS uses dual attention signals to identify unknown objects from ODN3D proposals. JOS combines ODN3D's objectness scores (measuring geometric quality) with camera feature attention values (measuring known object likelihood). High objectness + low feature attention indicates unknown objects. The joint objectness score sjos = s'obj · (1 - satt) effectively ranks candidates.

### Mechanism 3
Two-stage training enables gradual adaptation from known to open-set detection. Stage 1 trains ODN3D and camera detector on known objects only. Stage 2 uses JOS-selected pseudo-GT from ODN3D proposals to train the camera detector to recognize unknowns, with soft weighting using ODN3D objectness scores. This avoids catastrophic forgetting while adding open-set capability.

## Foundational Learning

- Concept: Geometric representation learning
  - Why needed here: ODN3D relies entirely on geometric cues (position, scale, rotation) rather than appearance features to discover objects across categories
  - Quick check question: How would you modify the GeoHungarian matching if you wanted to include orientation consistency in the geometric matching?

- Concept: Pseudo-labeling for open-set learning
  - Why needed here: JOS generates pseudo-ground truth labels for unknown objects by combining objectness scores with feature attention, enabling training without explicit unknown annotations
  - Quick check question: What would happen to the unknown detection performance if ku were set too high (e.g., 50 instead of 10)?

- Concept: Multi-stage training pipelines
  - Why needed here: The two-stage approach first builds geometric detection capability, then refines the camera detector with pseudo-labels, preventing interference between tasks
  - Quick check question: Why does the paper train BEVFormer for 18 epochs in Stage 1 but only 6 epochs in Stage 2?

## Architecture Onboarding

- Component map: LiDAR frame → voxel features → ODN3D encoder-decoder → GeoHungarian matching → objectness scores → GT filtering → top-ko candidates → JOS (BEV feature attention) → top-ku pseudo-GT → camera detector training
- Critical path: LiDAR frame → voxel features → ODN3D encoder-decoder → GeoHungarian matching → objectness scores → GT filtering → top-ko candidates → JOS (BEV feature attention) → top-ku pseudo-GT → camera detector training
- Design tradeoffs: Using geometric-only matching improves unknown detection but may reduce known object accuracy compared to classification-aware matching; two-stage training adds complexity but enables gradual adaptation
- Failure signatures: High mAPknown but zero Recallunk indicates JOS is not selecting unknown candidates; low Recallunk but high APunk suggests poor geometric proposal quality from ODN3D
- First 3 experiments:
  1. Run ODN3D alone on validation set to verify geometric proposal quality (check Recallunk)
  2. Test JOS with ground truth filtering removed to see if objectness + attention combination works
  3. Compare one-stage vs two-stage training to measure benefit of gradual adaptation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of unknown object candidates (ku) to select from the 3D object region candidates for effective training of the camera detector?
- Basis in paper: [explicit] The paper discusses sensitivity analysis on ku in Table 4, but does not definitively conclude the optimal value.
- Why unresolved: The paper provides a range of ku values and their impact on performance, but does not establish a clear optimal value.
- What evidence would resolve it: A comprehensive study comparing the detection performance (mAPknown, APunk, Recallunk) for various ku values across multiple datasets and object categories would help determine the optimal value.

### Open Question 2
- Question: How does the performance of OS-Det3D vary with different objectness score functions for 3D objects?
- Basis in paper: [explicit] The paper compares different 3D objectness scores in Table 6, but does not explore the full range of potential score functions.
- Why unresolved: The paper only tests a few objectness score functions, leaving the possibility of better-performing functions unexplored.
- What evidence would resolve it: Extensive experimentation with various objectness score functions, including those from other domains or novel designs, would reveal the best-performing function for open-set 3D object detection.

### Open Question 3
- Question: How does the inclusion of LiDAR data during training affect the performance of OS-Det3D in a purely camera-based inference scenario?
- Basis in paper: [explicit] The paper mentions that the inference stage uses a camera-only pipeline, but the training process still requires LiDAR data.
- Why unresolved: The paper does not investigate the impact of excluding LiDAR data from the training process on the final detection performance.
- What evidence would resolve it: Training and evaluating OS-Det3D using only camera data for both training and inference, then comparing the results to the current approach, would clarify the importance of LiDAR data in the training process.

## Limitations
- The two-stage training procedure requires careful hyperparameter tuning, particularly for ku (number of unknown pseudo-GTs per frame) and the objectness score weighting
- The geometric-only approach may struggle with objects that have similar spatial configurations but different semantic meanings
- Reliance on pseudo-ground truth generation introduces uncertainty in the quality of unknown object training data, as errors in JOS selection propagate to the camera detector

## Confidence
- Effectiveness of two-stage training: High
- Geometric-only matching for unknown detection: Medium
- Pseudo-label quality for unknown objects: Medium
- Generalization to other datasets: Low

## Next Checks
1. Run ODN3D alone on validation set to verify geometric proposal quality (check Recallunk)
2. Test JOS with ground truth filtering removed to see if objectness + attention combination works
3. Compare one-stage vs two-stage training to measure benefit of gradual adaptation