---
ver: rpa2
title: 'Towards Realistic Synthetic User-Generated Content: A Scaffolding Approach
  to Generating Online Discussions'
arxiv_id: '2408.08379'
source_url: https://arxiv.org/abs/2408.08379
tags:
- thread
- post
- data
- threads
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of generating realistic synthetic
  discussion threads for user-generated content platforms. The core idea is to use
  large language models (LLMs) with a scaffold-based generation pipeline to improve
  realism.
---

# Towards Realistic Synthetic User-Generated Content: A Scaffolding Approach to Generating Online Discussions

## Quick Facts
- arXiv ID: 2408.08379
- Source URL: https://arxiv.org/abs/2408.08379
- Reference count: 40
- Primary result: Scaffold-based LLM generation significantly outperforms direct generation in producing realistic synthetic discussion threads

## Executive Summary
This paper tackles the challenge of generating realistic synthetic discussion threads for user-generated content platforms. The core idea is to use large language models (LLMs) with a scaffold-based generation pipeline to improve realism. First, topics are extracted and sampled from real threads. Then, either directly or through scaffold generation (a compact representation of the thread), synthetic threads are created with LLM-generated content for each post. To ensure quality, the paper introduces a suite of evaluation measures, including a novel LLM-based realism metric, to compare synthetic and real threads. Experiments on Reddit and Wikipedia Talk Pages demonstrate that the scaffolded approach significantly outperforms direct generation in producing valid and realistic threads, especially in capturing thread structure and coherence. Fine-tuning the LLM on scaffolds further improves results. Overall, the approach shows promise for creating synthetic UGC data at scale from limited real data.

## Method Summary
The method employs a scaffold-based generation pipeline using LLMs. It begins with topic extraction and sampling from real threads, followed by thread generation using either direct generation or scaffold generation. Scaffolds are compact representations of thread structure and post summaries. LLMs generate realistic post content based on these scaffolds. The approach is evaluated using a suite of metrics, including Jensen-Shannon divergence, structural measures, MAUVE for content, and a novel LLM-based realism metric. Fine-tuning the LLM on thread scaffolds improves the validity of generated thread structures.

## Key Results
- Scaffold-based generation significantly outperforms direct generation in producing valid and realistic threads
- Fine-tuning LLMs on thread scaffolds improves structural validity compared to few-shot prompting
- Conditional topic sampling produces more realistic topic combinations than independent sampling
- The novel LLM-based realism metric correlates with human judgments of thread coherence

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The scaffold-based approach improves the realism of synthetic threads by first encoding thread structure and post summaries, then generating realistic post content.
- Mechanism: The scaffold captures the structural relationships between posts (parent-child relationships, depth, breadth) and summarizes each post's intent. This compressed representation guides the LLM to generate coherent, on-topic content that aligns with the discussion flow.
- Core assumption: A compact representation of thread structure can guide realistic content generation without losing important contextual information.
- Evidence anchors:
  - [abstract] "We therefore propose a multi-step generation process, predicated on the idea of creating compact representations of discussion threads, referred to as scaffolds."
  - [section 4.3] "A key idea in this paper is to provide more control over the thread generation process by performing it in two steps: (1) generating a compact representation, called scaffold, that encodes the structure of the discussion along with the summary of each post, and (2) generating the actual content of each post, based on its summary."
  - [corpus] Weak evidence - no direct corpus citations available for this specific scaffold mechanism.

### Mechanism 2
- Claim: Fine-tuning the LLM on thread scaffolds improves the validity of generated thread structures compared to few-shot prompting.
- Mechanism: By training the LLM directly on real thread scaffolds, the model learns to internalize valid thread structures (e.g., correct parent-child relationships, valid post sequences). This reduces the likelihood of generating structurally invalid threads compared to few-shot prompting which relies on random examples.
- Core assumption: The LLM can learn valid thread structures from scaffold training examples, leading to improved structural validity in generated threads.
- Evidence anchors:
  - [section 4.3.3] "In a second approach, we investigate fine-tuning an LLM directly on thread scaffolds generated from real data. This fine-tuning strategy focuses on improving the degree to which the model internalizes the valid structure of thread scaffolds, increasing the likelihood well-formed outputs."
  - [section 7] "Surprisingly, the threads produced from fine-tuned scaffolding were as successful as threads produced from few-shot scaffolding. This means that our fine-tuned model was able to generate valid threads at the same rate as a few-shot-prompted frozen model."
  - [corpus] Weak evidence - no direct corpus citations available for this specific fine-tuning mechanism.

### Mechanism 3
- Claim: The conditional topic sampling approach produces more realistic topic combinations compared to independent sampling.
- Mechanism: By considering the co-occurrence frequencies of topic pairs in real threads, the conditional sampling approach generates topic sets that are more likely to be discussed together in realistic conversations, avoiding unlikely topic combinations.
- Core assumption: Topic co-occurrence patterns in real threads reflect realistic topic combinations that should be preserved in synthetic threads.
- Evidence anchors:
  - [section 4.1.3] "Assuming independence between topics in one discussion is clearly an oversimplification and might result in a set of topics that are extremely unlikely to be discussed together. Therefore, we present an improved topic sampling approach that also considers how frequently any given pair of topics is discussed together."
  - [section 7] "There are opportunities for future work fine-tuning LLMs on real discussion towards faithfully replicating the discussed topics."
  - [corpus] Weak evidence - no direct corpus citations available for this specific conditional sampling mechanism.

## Foundational Learning

- Concept: Large Language Model (LLM) prompting techniques
  - Why needed here: The entire synthetic thread generation pipeline relies on carefully crafted prompts to guide LLMs in generating realistic discussion content and structure.
  - Quick check question: What are the key differences between zero-shot, few-shot, and fine-tuned prompting approaches in LLM applications?

- Concept: Graph structure representation
  - Why needed here: Discussion threads are modeled as directed acyclic graphs, and understanding graph metrics (depth, breadth, virality) is crucial for evaluating thread realism.
  - Quick check question: How would you represent a Reddit thread as a graph, and what graph metrics would you use to evaluate its structure?

- Concept: Topic modeling and text classification
  - Why needed here: Extracting and sampling topics is a core component of the generation pipeline, requiring understanding of topic modeling techniques and classification models.
  - Quick check question: What are the trade-offs between using unsupervised topic modeling versus supervised text classification for topic extraction in this context?

## Architecture Onboarding

- Component map:
  Topic Extraction Module → Topic Sampling Module → Thread Generation Module (Baseline/Fine-tuned) → Scaffold Generation Module → Content Generation Module → Evaluation Suite
  Data Flow: Real threads → Topic extraction → Training examples → Synthetic thread generation → Evaluation against real threads
  Key Components: LLM (PaLM 2), Topic classification model (Google Cloud Natural Language), Evaluation metrics (structural, topical, content, realism)

- Critical path:
  1. Topic extraction from real threads
  2. Training example creation (scaffolds and few-shot examples)
  3. Topic sampling for new threads
  4. Scaffold generation (few-shot or fine-tuned)
  5. Content generation based on scaffolds
  6. Evaluation of synthetic vs. real threads

- Design tradeoffs:
  - Scaffold vs. Direct generation: Scaffolds provide more control but add complexity; direct generation is simpler but less reliable
  - Few-shot vs. Fine-tuned: Few-shot is more flexible but may have lower validity; fine-tuning improves validity but requires training resources
  - Independent vs. Conditional topic sampling: Independent is simpler but may produce unrealistic topic combinations; conditional is more realistic but requires co-occurrence statistics

- Failure signatures:
  - Low success rate (< 0.5) indicates structural generation problems
  - High J-S divergence (> 0.8) indicates topic distribution mismatch
  - Low MAUVE scores (< 0.5) indicate content quality issues
  - Realism scores significantly below training data baseline indicate coherence problems

- First 3 experiments:
  1. Baseline thread generation (few-shot) on a small subreddit to establish baseline performance and identify structural validity issues
  2. Scaffold generation (few-shot) on the same subreddit to compare validity improvements
  3. Conditional topic sampling vs. independent sampling comparison to evaluate topic realism improvements

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the scaffolded generation approach compare to other graph generation methods in terms of scalability and efficiency?
- Basis in paper: [inferred] The paper mentions that the scaffolded approach outperforms direct generation in producing valid and realistic threads, especially in capturing thread structure and coherence. However, it does not provide a direct comparison with other graph generation methods.
- Why unresolved: The paper focuses on comparing the scaffolded approach to the baseline direct generation method, but does not explore its performance relative to other graph generation techniques. This leaves a gap in understanding the scalability and efficiency of the scaffolded approach in comparison to existing methods.
- What evidence would resolve it: Conducting experiments that compare the scaffolded approach with other graph generation methods, such as those based on neural networks or probabilistic models, would provide insights into its scalability and efficiency. Analyzing the computational complexity and resource requirements of each method would also be valuable.

### Open Question 2
- Question: Can the scaffolded generation approach be extended to handle multi-turn conversations with more complex structures, such as those involving multiple threads or nested replies?
- Basis in paper: [inferred] The paper demonstrates the effectiveness of the scaffolded approach in generating realistic discussion threads. However, it does not explore its applicability to more complex conversation structures beyond single threads with nested replies.
- Why unresolved: The paper focuses on generating synthetic threads within a single discussion platform, but does not investigate how the scaffolded approach can be adapted to handle more intricate conversation scenarios. This leaves open the question of its generalizability to real-world situations where conversations often involve multiple threads or nested replies.
- What evidence would resolve it: Conducting experiments that evaluate the scaffolded approach's performance in generating multi-turn conversations with complex structures would provide insights into its generalizability. Analyzing the quality and coherence of the generated conversations in such scenarios would be crucial.

### Open Question 3
- Question: How does the choice of the large language model (LLM) impact the quality and diversity of the generated synthetic threads?
- Basis in paper: [explicit] The paper mentions that the scaffolded approach leverages LLMs in several key stages, but does not explore the impact of different LLM choices on the generated threads.
- Why unresolved: The paper assumes the use of a pre-trained, instruction-tuned LLM but does not investigate how the choice of LLM affects the quality and diversity of the generated synthetic threads. This leaves open the question of whether certain LLM architectures or training strategies are more suitable for this task.
- What evidence would resolve it: Conducting experiments that compare the performance of different LLMs in generating synthetic threads would provide insights into their impact on quality and diversity. Analyzing the generated threads in terms of their coherence, relevance, and adherence to the target platform's characteristics would be valuable.

## Limitations
- Limited corpus validation: The mechanisms described lack direct citations from related work, relying instead on weak evidence from the authors' own experiments.
- Evaluation metric concerns: The novel LLM-based realism metric, while promising, is not extensively validated against human judgments.
- Topic sampling generalization: The conditional topic sampling approach depends on co-occurrence statistics from the training data, but it's unclear how well these statistics generalize to new topic combinations or different domains.

## Confidence
- High confidence: The scaffold-based generation pipeline and its implementation details are well-specified and internally consistent. The experimental results showing improved validity and realism compared to direct generation are robust within the tested datasets.
- Medium confidence: The claim that fine-tuning on scaffolds improves validity is supported by the experimental results, but the mechanism could benefit from more extensive ablation studies to isolate the effect of fine-tuning from other factors.
- Low confidence: The assertion that the LLM-based realism metric is a reliable proxy for human judgment of coherence is the weakest link, as it relies on a single correlation study without broader validation.

## Next Checks
1. **Human evaluation study**: Conduct a human study comparing the LLM-based realism scores to human judgments of thread coherence and plausibility. This would validate whether the automated metric aligns with human perceptions of realistic discussion threads.
2. **Cross-domain generalization test**: Apply the scaffold-based generation pipeline to a new domain (e.g., Twitter threads or forum discussions) not used in the original experiments. Compare the validity and realism of synthetic threads to those generated from the original Reddit and Wikipedia datasets.
3. **Ablation study on topic sampling**: Perform an ablation study comparing independent, conditional, and hybrid topic sampling approaches. Vary the co-occurrence threshold for conditional sampling and measure the impact on topic realism and thread coherence. This would help identify the optimal balance between realistic topic combinations and generation diversity.