---
ver: rpa2
title: 'Time Distributed Deep Learning Models for Purely Exogenous Forecasting: Application
  to Water Table Depth Prediction using Weather Image Time Series'
arxiv_id: '2409.13284'
source_url: https://arxiv.org/abs/2409.13284
tags:
- time
- data
- water
- layer
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of predicting groundwater levels
  in the Grana-Maira catchment (Piedmont, Italy) using purely exogenous weather data,
  given the scarcity and irregular availability of direct groundwater measurements.
  The authors propose two deep learning models that process weather image time series
  to forecast weekly water table depth at three sensor locations.
---

# Time Distributed Deep Learning Models for Purely Exogenous Forecasting: Application to Water Table Depth Prediction using Weather Image Time Series

## Quick Facts
- arXiv ID: 2409.13284
- Source URL: https://arxiv.org/abs/2409.13284
- Reference count: 40
- Predicts weekly water table depth in Grana-Maira catchment using weather image time series

## Executive Summary
This paper addresses the challenge of predicting groundwater levels in the Grana-Maira catchment (Piedmont, Italy) using purely exogenous weather data, given the scarcity and irregular availability of direct groundwater measurements. The authors propose two deep learning models that process weather image time series to forecast weekly water table depth at three sensor locations. Both models demonstrated strong performance, with TDC-LSTM focusing on minimizing bias and TDC-UnPWaveNet excelling in capturing temporal dynamics and correlation.

## Method Summary
The core method involves a Time Distributed Convolutional Neural Network (TDC) that encodes spatial weather patterns from images at each time step into vector representations. The first model, TDC-LSTM, uses a Long Short-Term Memory (LSTM) layer to learn temporal dynamics from these encoded representations. The second model, TDC-UnPWaveNet, adapts the WaveNet architecture for many-to-one forecasting by introducing a new Channel Distributed (CD) layer to handle output sequences shorter and shifted into the future compared to the input. Both models were trained as ensembles of 10 runs per sensor location.

## Key Results
- TDC-LSTM achieved BIAS of -0.18 and correlation (ρ) of 0.93 on average across all sensors
- TDC-UnPWaveNet achieved BIAS of -0.25 and ρ of 0.96 on average across all sensors
- TDC-LSTM showed superior performance in bias reduction while TDC-UnPWaveNet excelled in capturing temporal dynamics and correlation
- Both architectures demonstrated the potential of deep learning for groundwater prediction using only exogenous weather data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Time Distributed CNN (TDC) module enables effective spatial feature extraction from weather images while preserving temporal ordering for downstream sequential modeling.
- Mechanism: The TDC applies identical convolutional operations to each frame in the input video, extracting spatial patterns from weather images and encoding them into a fixed-length vector representation. This creates a time-distributed hidden representation that maintains temporal sequence while embedding spatial information.
- Core assumption: Spatial patterns in weather images at each time step contain predictive information about groundwater levels that can be captured by convolutional filters.
- Evidence anchors: [abstract] "Both the models are made of a first Time Distributed Convolutional Neural Network (TDC) which encodes the images into hidden vectors."; [section] "The TDC module is responsible for learning a vectorial representation of the images available at each time step. Thus, it converts the input image time series (i.e. video) into a classical multivariate time series."; [corpus] Weak evidence - corpus papers focus on exogenous variables in time series forecasting but don't specifically address spatial image processing for hydrology.

### Mechanism 2
- Claim: The UnPWaveNet architecture adapts dilated convolutions for many-to-one forecasting by removing causal constraints and introducing Channel Distributed layers to handle sequence length mismatches.
- Mechanism: By removing causal padding, the architecture allows output sequences to be shorter and completely shifted into the future relative to inputs. The Channel Distributed layer applies transformations to each channel individually, enabling the network to compress temporal dimensions while maintaining channel information across layers with different sequence lengths.
- Core assumption: Dilated convolutions can effectively capture long-term temporal dependencies in groundwater level data when causal constraints are removed.
- Evidence anchors: [abstract] "The second model, TDC-UnPWaveNet uses instead a new version of the WaveNet architecture, adapted here to output a sequence shorter and completely shifted in the future with respect to the input one."; [section] "To deal with the different sequence lengths in the UnPWaveNet, we have designed a new Channel Distributed layer, that acts like a Time Distributed one but on the channel dimension."; [corpus] Weak evidence - corpus focuses on exogenous variables but doesn't address WaveNet adaptations for many-to-one tasks.

### Mechanism 3
- Claim: The ensemble approach with multiple random initializations improves model robustness and reduces variance in predictions for groundwater forecasting.
- Mechanism: Training each model 10 times with different random initializations and using the ensemble mean as final prediction reduces the impact of initialization effects and captures more stable patterns in the data.
- Core assumption: Model predictions are sensitive to random initialization, and averaging over multiple runs reduces this variance while maintaining predictive accuracy.
- Evidence anchors: [section] "To take into account the uncertainty of the random initialization of the weight we have initialized and trained 10 times each local model independently. We have considered the ensemble mean as the final prediction for each local model."; [section] "In [31] authors found the LSTM-based model more robust against initialization effects than CNN. We have found soft evidence of this."; [corpus] No direct evidence - corpus papers don't mention ensemble methods or initialization sensitivity.

## Foundational Learning

- Concept: Time Distributed Layers
  - Why needed here: To apply the same spatial feature extraction operations to each frame in a video while maintaining temporal sequence for sequential modeling.
  - Quick check question: If you have a video with 100 frames and apply a TD CNN that outputs 16-dimensional vectors, what is the dimensionality of the resulting time series?

- Concept: Dilated Convolutions
  - Why needed here: To exponentially expand the receptive field of the network, allowing it to capture long-term temporal dependencies in groundwater data without requiring excessively deep networks.
  - Quick check question: How does the receptive field of a dilated convolution with kernel size 3 and dilation rate 2 compare to a standard convolution with the same kernel size?

- Concept: Channel Distributed Layers
  - Why needed here: To handle sequence length mismatches in the UnPWaveNet architecture by applying transformations to each channel individually while compressing temporal dimensions.
  - Quick check question: What is the key difference between how Time Distributed and Channel Distributed layers process multivariate time series?

## Architecture Onboarding

- Component map: TDC module (4-layer CNN with spatial pooling) → Sequential module (LSTM or UnPWaveNet) → Output layer
- Critical path: Weather images → TDC spatial encoding → Temporal modeling → Water table depth prediction
- Design tradeoffs: TDC-LSTM prioritizes bias reduction with simpler architecture; TDC-UnPWaveNet prioritizes correlation with more complex WaveNet adaptation
- Failure signatures: High bias indicates poor spatial feature extraction; low correlation indicates inadequate temporal modeling; high variance suggests initialization sensitivity
- First 3 experiments:
  1. Test TDC module independently on synthetic weather data to verify spatial feature extraction
  2. Compare LSTM vs UnPWaveNet performance on simple synthetic temporal data
  3. Validate ensemble approach by comparing single-run vs ensemble predictions on validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of TDC-UnPWaveNet compare to Transformer-based architectures for groundwater level prediction tasks?
- Basis in paper: [inferred] The paper mentions that Transformer architectures were not included due to the substantial work already done on developing the proposed models, but suggests future work should investigate UnPWaveNet's performance against other architectures like Transformers.
- Why unresolved: The study only compared TDC-UnPWaveNet to TDC-LSTM, leaving the relative performance against Transformers unexplored.
- What evidence would resolve it: Direct experimental comparison of TDC-UnPWaveNet against Transformer models using the same dataset and evaluation metrics.

### Open Question 2
- Question: To what extent does incorporating autoregressive terms (past water table depth values) improve the predictive performance of the proposed models in practical scenarios where water table data is available more frequently?
- Basis in paper: [explicit] The authors deliberately excluded autoregressive terms due to practical constraints (water table data updated only semi-annually), but acknowledged that including them could enhance performance, especially during anomalous events like the 2022 drought.
- Why unresolved: The models were designed and tested without autoregressive inputs, so their potential contribution remains theoretical.
- What evidence would resolve it: Retraining and evaluating the models with daily water table depth data as autoregressive inputs and comparing performance metrics.

### Open Question 3
- Question: How do the proposed models perform when applied to regions with different climatic conditions and hydrogeological characteristics compared to the Grana-Maira catchment?
- Basis in paper: [inferred] The study focuses on a specific catchment in Piedmont, Italy, and while the models show promising results, the authors note that hydrological responses can be highly context-dependent.
- Why unresolved: The models were only validated on one catchment, limiting generalizability claims.
- What evidence would resolve it: Application and evaluation of the models on groundwater prediction tasks in catchments with varying climatic and hydrogeological conditions.

## Limitations

- The exact spatial ROI coordinates for clipping weather images are not fully specified, requiring estimation
- The specific implementation details of the UnPWaveNet architecture and Channel Distributed layer are not fully described
- The ensemble method's optimal number of runs (10) is not rigorously justified

## Confidence

- **High Confidence**: The core methodology of using Time Distributed CNNs for spatial feature extraction from weather images, and the general performance trends showing TDC-LSTM's bias reduction and TDC-UnPWaveNet's correlation improvement.
- **Medium Confidence**: The specific architectural adaptations of UnPWaveNet for many-to-one forecasting and the exact impact of ensemble averaging on prediction stability.
- **Low Confidence**: The generalizability of results to other catchments or time horizons, given the study's focus on a single watershed and weekly predictions.

## Next Checks

1. **Independent Validation on Synthetic Data**: Test the TDC module separately on synthetic weather-like data with known spatial patterns to verify it correctly extracts and encodes spatial features into temporal sequences.
2. **Ablation Study on Architecture Components**: Systematically remove or modify key components (e.g., TD CNN layers, CD layers in UnPWaveNet) to quantify their individual contributions to model performance.
3. **Cross-Catchment Transferability Test**: Apply the trained models to groundwater data from a different but similar watershed to assess the robustness and generalizability of the purely exogenous forecasting approach.