---
ver: rpa2
title: 'Cool-chic video: Learned video coding with 800 parameters'
arxiv_id: '2402.03179'
source_url: https://arxiv.org/abs/2402.03179
tags: []
core_contribution: This paper proposes Cool-chic video, a lightweight learned video
  codec with extremely low decoding complexity (900 multiplications per decoded pixel)
  while maintaining competitive compression performance. The codec builds upon the
  Cool-chic image codec by adding an inter coding module that performs motion compensation
  and residual coding to leverage temporal redundancies.
---

# Cool-chic video: Learned video coding with 800 parameters

## Quick Facts
- arXiv ID: 2402.03179
- Source URL: https://arxiv.org/abs/2402.03179
- Reference count: 0
- Primary result: Achieves competitive rate-distortion performance with only 800 decoder parameters and 900 multiplications per pixel

## Executive Summary
Cool-chic video presents a lightweight learned video codec that achieves remarkably low decoder complexity while maintaining competitive compression performance. The codec builds upon the Cool-chic image codec by adding an inter coding module that leverages temporal redundancies through motion compensation and residual coding. Unlike other overfitted codecs, it supports frame-wise encoding enabling both low-delay and random access configurations. The key innovation is using feature maps rather than network weights for information representation, resulting in only 800 decoder parameters.

## Method Summary
The Cool-chic video codec extends the Cool-chic image codec by incorporating an inter coding module that exploits temporal redundancies between frames. The codec operates by first encoding each frame independently using the base image codec, then applying motion compensation to exploit temporal correlations. The inter coding module performs motion estimation to identify correspondences between frames, generates motion vectors, and encodes residual information for pixels that cannot be accurately predicted through motion compensation. This hybrid approach maintains the lightweight decoder architecture while improving compression efficiency through temporal modeling.

## Key Results
- Achieves rate-distortion performance close to AVC and better than overfitted codecs like FFNeRV on CLIC24 dataset
- Maintains extremely low decoder complexity with only 800 parameters and 900 multiplications per decoded pixel
- Supports frame-wise encoding enabling both low-delay and random access configurations
- Outperforms traditional codecs at low bitrates while maintaining competitive performance at higher rates

## Why This Works (Mechanism)
The codec's efficiency stems from its hybrid architecture that combines spatial and temporal coding while maintaining minimal decoder complexity. By using feature maps rather than network weights for information representation, the codec achieves compression efficiency without requiring complex decoding operations. The inter coding module specifically targets temporal redundancies through motion compensation, which is particularly effective for natural video content where objects and scenes exhibit coherent motion across frames. The frame-wise encoding capability ensures flexibility in deployment scenarios while avoiding the computational overhead of traditional temporal prediction structures.

## Foundational Learning
- **Feature maps for parameter efficiency**: Using learned feature maps instead of explicit network weights reduces decoder complexity while maintaining representation power. Quick check: Verify parameter count matches claimed 800 decoder parameters.
- **Motion compensation in learned codecs**: Incorporating traditional video coding concepts like motion estimation into neural architectures bridges the gap between classical and learned approaches. Quick check: Validate motion vector accuracy against ground truth.
- **Hybrid spatial-temporal coding**: Combining intra-frame coding with inter-frame motion compensation leverages both spatial and temporal redundancies. Quick check: Compare performance with and without inter coding module.
- **Frame-wise encoding architecture**: Supporting independent frame decoding enables random access and low-delay operation. Quick check: Measure random access performance compared to GOP-based codecs.
- **Rate-distortion optimization in neural codecs**: Jointly optimizing for rate and distortion during training ensures balanced performance. Quick check: Analyze RD curves across different bitrate ranges.

## Architecture Onboarding
- **Component map**: Input Frames -> Intra Coding Module -> Motion Estimation -> Inter Coding Module -> Entropy Coding -> Bitstream
- **Critical path**: Frame encoding → Motion estimation → Residual coding → Entropy coding → Transmission
- **Design tradeoffs**: The codec trades some compression efficiency at high bitrates for significantly reduced decoder complexity. The motion estimation module adds computational overhead during encoding but keeps decoding lightweight.
- **Failure signatures**: Performance degradation occurs with complex motion patterns, high-frequency textures, and at high bitrates where residual coding becomes dominant. Random access may suffer with long-term temporal dependencies.
- **First experiments**: 1) Test encoding speed vs traditional codecs, 2) Measure decoder parameter count verification, 3) Evaluate RD performance across different content types

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions, but implicit challenges include scalability to higher resolutions, handling of complex motion patterns, and performance at high bitrates. The limited evaluation on short video sequences also raises questions about long-term temporal modeling capabilities.

## Limitations
- Performance at high bitrates remains a challenge, though specific quantitative details are not provided
- Motion estimation module complexity and accuracy not fully characterized
- Limited evaluation scope (single dataset, short sequences) raises questions about generalizability
- Scalability to higher resolutions and longer temporal dependencies uncertain

## Confidence
- **Decoder complexity claims**: High confidence - mathematical formulation and parameter count are clearly presented and verifiable
- **Rate-distortion performance**: Medium confidence - experimental results support claims but limited to single dataset and short sequences
- **Generalizability**: Low confidence - lack of evaluation on diverse datasets and longer sequences limits confidence in broader applicability

## Next Checks
1. Evaluate the codec on additional datasets including UVG, MCL-JCV, and DIV2K to verify robustness across different content types and resolutions
2. Conduct ablation studies specifically measuring the contribution of the inter coding module versus the baseline Cool-chic image codec
3. Compare decoding speed and complexity against traditional codecs (HEVC, VVC) on representative hardware platforms to validate the claimed efficiency advantages