---
ver: rpa2
title: 'Graph Representation Learning Strategies for Omics Data: A Case Study on Parkinson''s
  Disease'
arxiv_id: '2406.14442'
source_url: https://arxiv.org/abs/2406.14442
tags: []
core_contribution: "This study compares graph representation learning models for Parkinson\u2019\
  s disease classification using omics data. It evaluates sample similarity networks\
  \ and molecular interaction networks (PPI, MMI) with models like GCN, ChebyNet,\
  \ GAT, and graph transformers."
---

# Graph Representation Learning Strategies for Omics Data: A Case Study on Parkinson's Disease

## Quick Facts
- **arXiv ID:** 2406.14442
- **Source URL:** https://arxiv.org/abs/2406.14442
- **Reference count:** 25
- **Primary result:** Sample similarity networks outperformed molecular interaction networks, especially in metabolomics, with graph transformers showing superior performance to traditional GNNs

## Executive Summary
This study compares graph representation learning models for Parkinson's disease classification using transcriptomics and metabolomics data. The authors evaluate sample similarity networks and molecular interaction networks (PPI, MMI) with models including GCN, ChebyNet, GAT, and graph transformers. Sample similarity networks consistently outperformed molecular interaction networks, particularly in metabolomics. GNNs generally outperformed MLPs, demonstrating their ability to capture complex dependencies in omics profiles. Feature selection with LASSO improved performance, while deeper networks led to overfitting. The study identifies mitochondrial shuttle genes and acylcarnitine metabolites as relevant biomarkers through GNN-Explainer.

## Method Summary
The study uses PPMI (14,548 gene expression features, 378 samples) and LUXPARK (1,079 metabolite profiles, 1,136 subjects) datasets for Parkinson's disease case-control classification. Data preprocessing includes scaling and LASSO feature selection to reduce dimensionality. Graph construction uses either sample similarity networks (cosine similarity with threshold) or molecular interaction networks from STRING (PPI) and STITCH (MMI). GNN models (GCN, ChebyNet, GAT, Graph U-Net, Graph Transformers) are trained with 10-fold cross-validation, comparing AUC and F1 scores. GNN-Explainer is used for interpretability to identify relevant biomarkers.

## Key Results
- Sample similarity networks consistently outperformed molecular interaction networks, particularly in the LUXPARK metabolomics dataset
- GNNs generally outperformed MLPs, highlighting their ability to capture complex dependencies and interactions in omics profiles
- Graph transformers showed superior performance to traditional GNNs, leveraging edge attributes through attention mechanisms
- LASSO feature selection improved performance across models
- Deeper networks led to overfitting, with shallower architectures performing better

## Why This Works (Mechanism)

### Mechanism 1
Sample similarity networks (SSNs) outperform molecular interaction networks (MINs) because SSNs capture patient-level variability that is directly relevant to PD pathology, while MINs are incomplete and may not reflect disease-specific interactions. SSNs construct edges based on pairwise cosine similarity among samples, creating a topology that directly reflects the phenotypic distance between patients. This patient-centric graph structure allows GNNs to learn patterns that distinguish PD from controls more effectively than MINs, which are based on healthy individual interactions and suffer from incompleteness (e.g., only 44% of metabolites mapped in MMI). The core assumption is that the sample similarity graph edges contain more discriminative information for case-control classification than the edges in molecular interaction networks.

### Mechanism 2
GNNs outperform MLPs because they can capture complex dependencies and interactions in omics profiles that MLPs miss. GNNs propagate feature information through graph structures, allowing nodes to aggregate information from their neighbors iteratively. This enables the model to learn higher-order relationships and interactions that exist in the data, which is particularly important for omics data where genes, proteins, and metabolites interact in complex ways. The core assumption is that the graph structure contains information that cannot be effectively captured by treating samples independently as MLPs do.

### Mechanism 3
Graph transformers outperform traditional GNNs because they are more expressive and can leverage edge attributes through attention mechanisms. Graph transformers use attention mechanisms that can weigh the importance of different neighbors and incorporate edge attributes (like similarity scores) directly into the learning process. This allows them to capture nuanced relationships and adapt to the specific characteristics of the data, unlike traditional GNNs which use fixed aggregation functions. The core assumption is that the attention mechanism in graph transformers can effectively utilize the edge attributes (similarity scores) to improve classification performance.

## Foundational Learning

- **Graph Neural Networks**
  - Why needed here: Omics data naturally forms graphs (sample-sample similarities, molecular interactions), and GNNs are designed to learn from such structured data.
  - Quick check question: What is the key difference between how GNNs and traditional neural networks process data?

- **Graph Attention Networks**
  - Why needed here: GAT allows the model to weigh the importance of different neighbors dynamically, which is useful when some relationships in the data are more relevant than others.
  - Quick check question: How does the attention mechanism in GAT differ from the fixed aggregation in GCN?

- **Feature Selection with LASSO**
  - Why needed here: Omics data is high-dimensional with many irrelevant features; LASSO helps select the most relevant features to improve model performance and reduce overfitting.
  - Quick check question: What is the main advantage of using LASSO for feature selection in high-dimensional data?

## Architecture Onboarding

- **Component map:** Data preprocessing (scaling, LASSO feature selection) -> Graph construction (adjacency matrix from cosine similarity or molecular interaction databases) -> GNN models (GCN, ChebyNet, GAT, Graph U-Net, Graph Transformers) -> Explainability (GNN-Explainer) -> Evaluation (10-fold cross-validation with AUC and F1 metrics)

- **Critical path:** 1. Preprocess data (scaling and feature selection) 2. Construct appropriate graph (SSN or MIN) 3. Select and train GNN model 4. Evaluate performance 5. Use GNN-Explainer for biological insights

- **Design tradeoffs:** SSN vs MIN: SSNs capture patient-level variability but require similarity computation; MINs provide biological context but may be incomplete; GNN depth: Deeper networks risk overfitting with limited samples; Feature selection: LASSO improves performance but may discard potentially relevant features

- **Failure signatures:** Performance similar to random: Graph structure may be too sparse or random; Overfitting: Model performs well on training but poorly on validation; Poor feature selection: Important biological signals are lost during preprocessing

- **First 3 experiments:** 1. Compare GCN with MLP on SSN using the same preprocessed data to verify the benefit of graph structure 2. Test different similarity thresholds for SSN construction to find optimal graph density 3. Evaluate GAT vs GCN to assess the benefit of attention mechanisms for this specific dataset

## Open Questions the Paper Calls Out
The study does not explicitly call out open questions, but several important questions emerge from the work:

1. How do different graph representation learning strategies perform on multi-omics data compared to single-omics data for Parkinson's disease classification?
2. What is the optimal network topology (density and edge weights) for sample similarity networks in omics data classification?
3. How does medication status affect the performance and interpretability of graph models in metabolomics data for Parkinson's disease?

## Limitations
- The incompleteness of molecular interaction networks (particularly metabolite-metabolite interactions with only 44% mapping) may have artificially inflated the apparent superiority of sample similarity networks
- The graph transformer models lack detailed architectural specifications, making exact reproduction challenging
- The relatively small sample sizes (378 for transcriptomics, 1,136 for metabolomics) limit generalizability
- The hyperparameter tuning process is not fully documented

## Confidence
- **High confidence**: GNNs outperform MLPs for omics classification (supported by clear performance metrics and multiple model comparisons)
- **Medium confidence**: Sample similarity networks outperform molecular interaction networks (valid but potentially influenced by network incompleteness)
- **Medium confidence**: Graph transformers show superior performance (based on results but with limited architectural details)

## Next Checks
1. Compare performance using random edge baselines to determine if sample similarity network advantages persist beyond simple connectivity
2. Replicate key findings with alternative feature selection methods (e.g., mutual information vs LASSO) to isolate the effect of feature selection from graph structure
3. Conduct ablation studies on graph transformer attention mechanisms to quantify the contribution of edge attributes versus node features