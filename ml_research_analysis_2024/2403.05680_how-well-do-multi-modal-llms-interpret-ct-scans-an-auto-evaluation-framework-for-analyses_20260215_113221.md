---
ver: rpa2
title: How Well Do Multi-modal LLMs Interpret CT Scans? An Auto-Evaluation Framework
  for Analyses
arxiv_id: '2403.05680'
source_url: https://arxiv.org/abs/2403.05680
tags:
- gpt-4
- vision-based
- these
- evaluation
- radiology
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a novel evaluation framework, GPTRadScore,
  to assess the capabilities of multi-modal large language models (LLMs) in generating
  accurate descriptions of CT scan findings. The framework employs GPT-4 to decompose
  the generated descriptions into specific aspects (body part, location, type, and
  attributes) and evaluates their accuracy against gold-standard annotations.
---

# How Well Do Multi-modal LLMs Interpret CT Scans? An Auto-Evaluation Framework for Analyses

## Quick Facts
- arXiv ID: 2403.05680
- Source URL: https://arxiv.org/abs/2403.05680
- Reference count: 25
- Primary result: Novel GPTRadScore framework evaluates multi-modal LLM performance in CT scan interpretation, demonstrating superior correlation with clinician assessments compared to traditional metrics

## Executive Summary
This study introduces GPTRadScore, an innovative evaluation framework that uses GPT-4 to assess multi-modal large language models' ability to generate accurate descriptions of medical imaging findings. The framework decomposes generated descriptions into specific aspects (body part, location, type, and attributes) and evaluates their accuracy against gold-standard annotations. When applied to four prominent multi-modal models, the approach reveals significant performance variations while demonstrating high correlation with clinician assessments, suggesting its potential as a standardized evaluation tool for medical AI systems.

## Method Summary
The GPTRadScore framework employs GPT-4 to systematically evaluate medical image descriptions generated by multi-modal LLMs. The process involves decomposing each description into four key aspects: body part, location, type, and attributes. GPT-4 then assesses the accuracy of each aspect by comparing it against gold-standard annotations. The framework uses a "few-shot" approach with specially designed prompts to guide GPT-4 in both decomposition and scoring tasks. The overall score is calculated as the mean of the four aspect scores, providing a comprehensive evaluation metric that captures different dimensions of medical image interpretation accuracy.

## Key Results
- GPTRadScore framework achieved Spearman's correlation coefficients of 0.64-0.77 with clinician assessments, outperforming traditional evaluation metrics
- Among evaluated models, GPT-4V and Gemini Pro Vision demonstrated superior performance compared to LLaVA-Med and RadFM
- Fine-tuning RadFM resulted in substantial accuracy improvements, validating the effectiveness of the proposed evaluation approach

## Why This Works (Mechanism)
The framework's effectiveness stems from its systematic decomposition of medical image descriptions into analyzable components, allowing for granular assessment of model performance. By leveraging GPT-4's natural language understanding capabilities, the framework can capture nuanced aspects of medical imaging interpretation that traditional metrics often miss. The correlation with clinician assessments validates that this automated approach aligns with human expert judgment, making it a reliable proxy for evaluating model performance in real-world medical scenarios.

## Foundational Learning
- **Medical imaging interpretation**: Understanding how medical professionals analyze CT scans and describe findings - needed for creating relevant evaluation criteria and gold-standard annotations
- **Multi-modal LLM architecture**: Knowledge of how models process both visual and textual information - essential for understanding model capabilities and limitations
- **Evaluation metrics in AI**: Familiarity with traditional and novel assessment approaches - required to appreciate the framework's advantages over existing methods
- **Few-shot prompting**: Understanding how to effectively guide LLM behavior with limited examples - crucial for implementing the decomposition and scoring tasks
- **Correlation analysis**: Knowledge of statistical methods to validate evaluation frameworks - needed to interpret the results and their significance

## Architecture Onboarding

**Component map:**
RadFM/LLaVA-Med/GPT-4V/Gemini Pro Vision -> GPTRadScore decomposition module -> GPT-4 scoring module -> Accuracy scores

**Critical path:**
Image input -> Multi-modal LLM generation -> Description output -> GPTRadScore decomposition -> Aspect scoring -> Overall evaluation

**Design tradeoffs:**
The framework trades computational complexity for comprehensive evaluation, using GPT-4's advanced capabilities to achieve more nuanced assessment at the cost of increased processing time and potential model bias. The few-shot approach balances between requiring extensive training data and maintaining flexibility for different medical imaging tasks.

**Failure signatures:**
- Low correlation with clinician assessments may indicate model bias in GPT-4's evaluation
- Inconsistent decomposition across different prompts suggests prompt engineering challenges
- Poor performance on specific aspects (e.g., location) may reveal limitations in spatial reasoning capabilities
- High variance in scores across similar cases might indicate sensitivity to input variations

**3 first experiments:**
1. Test framework consistency by evaluating the same description multiple times with different random seeds
2. Compare GPTRadScore results with traditional metrics (BLEU, ROUGE) on the same dataset
3. Evaluate framework performance across different medical imaging modalities beyond CT scans

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but implicit areas for future research include expanding the framework to more diverse medical imaging tasks, validating the approach across different model architectures, and exploring methods to reduce potential bias from using GPT-4 for both scoring and gold-standard generation.

## Limitations
- The framework's reliance on GPT-4 for both decomposition and scoring introduces potential circularity and model bias
- Focus on three specific fracture types and chest X-ray nodules limits generalizability to broader medical imaging tasks
- The evaluation of only four multi-modal models may not capture the full landscape of available approaches

## Confidence

**Major claim clusters confidence:**
- **High confidence**: The framework's ability to decompose and evaluate medical image descriptions across multiple aspects is technically sound and well-validated
- **Medium confidence**: The framework's correlation with clinician assessments is demonstrated but could benefit from larger-scale validation
- **Medium confidence**: The comparative performance results between different models are robust within the tested scope but may not generalize to all multi-modal LLMs

## Next Checks
1. Conduct cross-validation using different LLM architectures for both scoring and gold-standard generation to assess potential model bias
2. Expand the evaluation to include additional medical imaging tasks beyond fractures and nodules to test generalizability
3. Implement a blinded multi-clinician assessment to establish more robust ground truth and validate the framework's correlation with human expert judgment