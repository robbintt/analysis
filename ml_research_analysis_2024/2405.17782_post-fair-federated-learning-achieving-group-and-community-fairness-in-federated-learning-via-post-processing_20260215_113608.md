---
ver: rpa2
title: 'Post-Fair Federated Learning: Achieving Group and Community Fairness in Federated
  Learning via Post-processing'
arxiv_id: '2405.17782'
source_url: https://arxiv.org/abs/2405.17782
tags:
- fairness
- community
- learning
- group
- federated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a post-processing method called post-FFL to
  achieve both group fairness and community fairness in federated learning. The key
  idea is to formulate a linear program that enforces both fairness constraints while
  maximizing model utility.
---

# Post-Fair Federated Learning: Achieving Group and Community Fairness in Federated Learning via Post-processing

## Quick Facts
- arXiv ID: 2405.17782
- Source URL: https://arxiv.org/abs/2405.17782
- Reference count: 40
- Primary result: Post-processing method achieving both group and community fairness in federated learning with minimal communication overhead

## Executive Summary
This paper introduces post-FFL, a post-processing framework that achieves both group fairness (Equal Opportunity) and community fairness (Fair Resource Allocation) in federated learning. The method applies after standard FedAvg training by formulating a linear program that enforces fairness constraints while maximizing model utility. By requiring only local statistics transmission rather than multiple rounds of model aggregation, post-FFL achieves superior fairness improvements with 2-3 orders of magnitude fewer communication rounds compared to in-processing methods.

## Method Summary
Post-FFL operates in two phases: first, it trains an optimal predictor using FedAvg across heterogeneous client communities; second, it applies post-processing by collecting local statistics from each community and solving a linear program to determine optimal randomized fair outcome predictors. The framework enforces both Equal Opportunity Difference (EOD) and Accuracy Disparity (AD) constraints through probability adjustments to the model's outputs, allowing users to control the trade-off between fairness and accuracy via relaxation parameters.

## Key Results
- Post-FFL achieves significant reductions in EOD (up to 4.5× improvement) and AD (up to 3.1× improvement) across three real-world datasets
- The method maintains competitive accuracy while requiring 2-3 orders of magnitude fewer communication rounds than in-processing fair FL methods
- Theoretical bounds guarantee that accuracy loss from enforcing fairness constraints remains bounded under reasonable conditions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Post-processing achieves group and community fairness by adjusting the model's outputs using a randomized transformation derived from a linear program.
- Mechanism: The post-processing framework first trains an optimal predictor using FedAvg. It then calculates local statistics and constructs a linear program that enforces equal opportunity and community fairness constraints while minimizing accuracy loss. The solution to this LP determines the probability with which each local community should accept or reject the optimal predictor's output to achieve fairness.
- Core assumption: The LP always has a non-negative solution that can simultaneously satisfy both fairness constraints.
- Evidence anchors:
  - [abstract]: "Post-FFL uses a linear program to simultaneously enforce group and community fairness while maximizing the utility of the global model."
  - [section 3]: "Theorem 3.5. (Appendix C.2) The linear program (12) always has non-negative solutions."
  - [corpus]: Weak - related papers focus on different fairness concepts (local vs global) but don't provide direct evidence for this LP-based mechanism.
- Break condition: If the data statistics violate the necessary conditions for ∆-accurate fair outcome predictors (Theorem 3.6), or if the LP becomes infeasible due to extreme data heterogeneity.

### Mechanism 2
- Claim: The framework can flexibly control the trade-off between fairness and accuracy through relaxation parameters.
- Mechanism: By adjusting the relaxation parameters (ϵ for group fairness, δ for community fairness) in the linear program, the framework can produce predictors that are not strictly fair but have better accuracy. This allows users to balance fairness requirements with model performance needs.
- Core assumption: The relaxation parameters can be adjusted to find an optimal balance point for specific application requirements.
- Evidence anchors:
  - [abstract]: "Moreover, post-FFL outperforms the existing in-processing fair federated learning in terms of improving both notions of fairness, communication efficiency and computation cost."
  - [section 5.1]: "These results show that with fixed ϵ, decreasing δ reduces AD and Avg-Acc, indicating the model is fairer with respect to community fairness but has poorer performance."
  - [corpus]: Weak - while other papers mention trade-offs, they don't specifically discuss this LP-based relaxation approach.
- Break condition: If the relaxation parameters are set too high, the model may fail to meet fairness requirements; if set too low, the accuracy may degrade unacceptably.

### Mechanism 3
- Claim: Post-processing requires significantly less communication and computation than in-processing methods.
- Mechanism: Since post-FFL only needs to send local statistics to the server after FedAvg training (rather than multiple rounds of weighted aggregation), it achieves the same fairness improvements with 2-3 orders of magnitude fewer communication rounds and comparable or better single-round computation time.
- Core assumption: The communication cost of sending statistics is negligible compared to sending model parameters in each round.
- Evidence anchors:
  - [abstract]: "Compared to in-processing fair federated learning methods, post-FFL achieves superior fairness improvements with lower communication and computational costs."
  - [section 5.2]: "The results in Table 4 show that the number of communication rounds required by post-FFL is 2-3 orders of magnitude lower than that required by q-FedAvg and one order of magnitude lower than what FairFed required."
  - [corpus]: Moderate - several related papers discuss communication efficiency but don't provide direct comparisons with post-processing approaches.
- Break condition: If the local statistics calculation becomes computationally expensive for very large datasets, or if network bandwidth is severely constrained.

## Foundational Learning

- Concept: Linear Programming for Constrained Optimization
  - Why needed here: The core fairness enforcement mechanism relies on formulating and solving a linear program with multiple constraints.
  - Quick check question: Can you explain why the feasible region for a linear program with equality constraints is a convex set?

- Concept: Federated Learning with FedAvg
  - Why needed here: The framework builds upon standard FedAvg as the base training algorithm before applying post-processing.
  - Quick check question: What happens to the global model aggregation when the local datasets have very different class distributions?

- Concept: Fairness Metrics (Equal Opportunity and Community Fairness)
  - Why needed here: The framework specifically targets these two fairness concepts and requires understanding how to measure them.
  - Quick check question: How would you calculate Equal Opportunity Difference between two groups given confusion matrices?

## Architecture Onboarding

- Component map:
  - FedAvg Training Module → Statistics Collection → Linear Program Construction → Solution Distribution → Post-processing Application
  - Global Server: LP solver, parameter aggregation
  - Local Communities: Model training, statistics computation, fair prediction application

- Critical path: FedAvg convergence → Statistics transmission → LP solution → Fair prediction deployment
  The bottleneck is typically FedAvg training time, as post-processing adds minimal overhead.

- Design tradeoffs:
  - Accuracy vs Fairness: Adjustable through relaxation parameters
  - Communication vs Computation: Post-processing trades computation for communication efficiency
  - Flexibility vs Optimality: Fixed set of transformations vs learned fair model

- Failure signatures:
  - Infeasible LP: Indicates extreme data imbalance or conflicting fairness requirements
  - Poor accuracy after post-processing: Suggests relaxation parameters too strict
  - Convergence issues in FedAvg: May indicate heterogeneous data requiring more local epochs

- First 3 experiments:
  1. Baseline test: Run FedAvg alone on Adult dataset, measure EOD and AD
  2. Post-processing test: Apply post-FFL with (ϵ=0, δ=0) on same dataset, compare metrics
  3. Trade-off exploration: Vary (ϵ, δ) parameters systematically, plot accuracy vs fairness curves

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the post-FFL framework be extended to handle multi-class classification tasks with more than two protected attributes?
- Basis in paper: [explicit] The paper mentions that post-FFL can be extended to multi-class classification tasks, but it doesn't explore scenarios with more than two protected attributes.
- Why unresolved: The paper only considers binary protected attributes (e.g., gender) and doesn't investigate the performance of post-FFL when dealing with multiple protected attributes simultaneously.
- What evidence would resolve it: Experimental results comparing post-FFL's performance on multi-class tasks with varying numbers of protected attributes would provide insights into its scalability and effectiveness.

### Open Question 2
- Question: How does the choice of fairness metric (e.g., demographic parity, equalized odds) impact the effectiveness of post-FFL?
- Basis in paper: [explicit] The paper focuses on Equal Opportunity and Fair Resource Allocation, but it doesn't explore other fairness metrics.
- Why unresolved: The paper doesn't investigate how different fairness metrics might affect the trade-off between fairness and accuracy in post-FFL.
- What evidence would resolve it: Comparative experiments using different fairness metrics would reveal the sensitivity of post-FFL to the choice of fairness criteria.

### Open Question 3
- Question: What is the impact of using different local models (e.g., neural networks, decision trees) on the performance of post-FFL?
- Basis in paper: [explicit] The paper uses logistic regression and CNN models, but it doesn't explore the impact of using different model architectures.
- Why unresolved: The paper doesn't investigate how the choice of local models might affect the fairness and accuracy of post-FFL.
- What evidence would resolve it: Experiments comparing post-FFL's performance using various local model architectures would provide insights into its robustness and generalizability.

## Limitations

- The method's effectiveness depends on accurate computation and communication of local statistics, which may be challenging in privacy-sensitive settings
- The linear program formulation requires specific conditions on input statistics for feasibility, potentially limiting applicability to extreme data imbalances
- Theoretical bounds on accuracy loss assume ideal conditions that may not hold in practice

## Confidence

- **High Confidence**: The post-processing mechanism itself (LP formulation and solution application) is well-defined and theoretically sound, with provable bounds on accuracy loss.
- **Medium Confidence**: The empirical superiority over in-processing methods is demonstrated but based on a limited set of datasets and scenarios.
- **Medium Confidence**: The communication efficiency claims are supported but may vary significantly with dataset characteristics and network conditions.

## Next Checks

1. **Robustness Testing**: Evaluate post-FFL performance on datasets with extreme class imbalance and varying levels of label noise to test the LP feasibility conditions.
2. **Scalability Assessment**: Measure the computational overhead of the LP solver on very large community sets (e.g., >100 communities) to verify claimed efficiency gains.
3. **Privacy Impact Analysis**: Quantify the information leakage from local statistics transmission to assess privacy implications beyond what's discussed in the paper.