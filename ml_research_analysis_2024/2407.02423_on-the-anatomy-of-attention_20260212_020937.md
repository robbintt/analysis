---
ver: rpa2
title: On the Anatomy of Attention
arxiv_id: '2407.02423'
source_url: https://arxiv.org/abs/2407.02423
tags:
- attention
- which
- monoidal
- diagrams
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a category-theoretic diagrammatic formalism
  for representing and reasoning about machine learning models. The key idea is to
  use string diagrams to visually depict architectures, where wires represent spaces
  and boxes represent functions.
---

# On the Anatomy of Attention

## Quick Facts
- arXiv ID: 2407.02423
- Source URL: https://arxiv.org/abs/2407.02423
- Reference count: 40
- Primary result: Attention variants perform comparably on word-level language modeling despite structural differences

## Executive Summary
This paper introduces a category-theoretic diagrammatic formalism for representing and reasoning about machine learning models, using string diagrams to visually depict architectures. The key contribution is a rewrite system based on the Universal Approximation Theorem that enables comparing different architectures by substituting universal approximators with equivalent functions. The authors use this framework to trace attention mechanism evolution and conduct an empirical study where they exhaustively recombine attention components to create 14 distinct variants.

## Method Summary
The authors develop a categorical diagrammatic language where wires represent spaces and boxes represent functions, allowing formal reasoning about ML architectures. They create a rewrite system that leverages the Universal Approximation Theorem to establish equivalences between different architectural components. For their empirical test, they identify recurring anatomical components of attention mechanisms and systematically recombine them to explore the design space. All variants are evaluated on word-level language modeling using the Penn Treebank corpus with identical training procedures and hyperparameters.

## Key Results
- All 14 attention variants perform comparably on Penn Treebank word-level language modeling
- The best variant slightly outperforms classic scaled dot-product attention, but the performance gap is narrow
- Despite significant structural differences, variants show similar perplexity scores
- The study suggests that any expressive method of exchanging data between tokens might suffice for good performance

## Why This Works (Mechanism)
The Universal Approximation Theorem provides the theoretical foundation that allows different architectural choices to be functionally equivalent if they can approximate the same class of functions. The diagrammatic formalism enables systematic exploration of the design space by treating architectural components as interchangeable building blocks that can be formally related through the rewrite system.

## Foundational Learning
- **Category Theory**: Needed to understand the mathematical framework; quick check: can represent functions and their compositions formally
- **String Diagrams**: Visual representation of morphisms between objects; quick check: wires = spaces, boxes = functions
- **Universal Approximation Theorem**: Guarantees that sufficiently complex networks can approximate any continuous function; quick check: enables architectural equivalences
- **Attention Mechanisms**: Core NLP architecture for token interaction; quick check: query-key-value computation pattern
- **Language Modeling**: Task of predicting next token given context; quick check: perplexity as evaluation metric
- **Architectural Rewrites**: Systematic transformation between equivalent structures; quick check: maintain functional behavior while changing form

## Architecture Onboarding

Component Map: Input -> Token Embeddings -> Attention Variant -> Feed-Forward Network -> Output

Critical Path: Token embeddings flow through chosen attention variant, then through position-wise feed-forward layers, with residual connections at each stage.

Design Tradeoffs: The framework allows exploration of architectural variations while maintaining functional equivalence, but requires careful consideration of computational efficiency versus representational power.

Failure Signatures: Performance degradation would manifest as increased perplexity, particularly on long-range dependencies or complex syntactic structures.

First Experiments:
1. Test variants on masked language modeling to assess bidirectional context understanding
2. Evaluate on sequence-to-sequence tasks to measure generation quality
3. Benchmark on vision transformers for image classification to test cross-domain generalization

## Open Questions the Paper Calls Out
None

## Limitations
- Empirical validation limited to single word-level language modeling task on Penn Treebank
- Theoretical framework assumes continuous functions may not capture discrete architectural choices
- Complexity of categorical formalism may limit practical adoption by ML practitioners
- Claims about attention structure not being crucial extend beyond empirical evidence

## Confidence

High confidence: Multiple attention variants perform comparably on tested task with well-supported experimental results.

Medium confidence: Theoretical framework's ability to systematically relate architectures is rigorous but practical utility remains unproven.

Low confidence: Broader claim that attention structure is not crucial for performance requires validation across diverse tasks and model scales.

## Next Checks

1. Test attention variants on multiple tasks beyond language modeling, including vision transformers for image classification, BERT-style masked language modeling, and sequence-to-sequence translation tasks.

2. Evaluate performance when scaled to larger model sizes (12-24 layer transformers) to determine if architectural differences become more pronounced at scale.

3. Implement and test attention variants with different computational constraints to determine if architectural differences manifest in efficiency metrics.