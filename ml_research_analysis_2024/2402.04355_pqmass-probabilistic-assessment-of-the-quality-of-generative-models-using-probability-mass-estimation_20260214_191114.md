---
ver: rpa2
title: 'PQMass: Probabilistic Assessment of the Quality of Generative Models using
  Probability Mass Estimation'
arxiv_id: '2402.04355'
source_url: https://arxiv.org/abs/2402.04355
tags:
- samples
- pqmass
- generative
- data
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes PQMass, a likelihood-free method for assessing
  generative model quality using probability mass estimation. The method partitions
  the sample space into non-overlapping regions (via Voronoi tessellation) and applies
  chi-squared tests to compare data sample counts across regions, producing a p-value
  that measures the probability the two sample sets are drawn from the same multinomial
  distribution.
---

# PQMass: Probabilistic Assessment of the Quality of Generative Models using Probability Mass Estimation

## Quick Facts
- arXiv ID: 2402.04355
- Source URL: https://arxiv.org/abs/2402.04355
- Authors: Pablo Lemos; Sammy Sharief; Nikolay Malkin; Salma Salhi; Connor Stone; Laurence Perreault-Levasseur; Yashar Hezaveh
- Reference count: 30
- Primary result: A likelihood-free method for assessing generative model quality using probability mass estimation with Voronoi tessellation and chi-squared testing

## Executive Summary
PQMass is a likelihood-free method for assessing generative model quality by estimating probability mass through Voronoi tessellation and applying chi-squared tests. The approach partitions sample space into non-overlapping regions and compares data sample counts across regions to produce a p-value measuring whether two sample sets come from the same multinomial distribution. This method requires no assumptions about the true distribution's density and avoids auxiliary model training while scaling well to moderately high-dimensional data.

## Method Summary
The PQMass method works by first partitioning the sample space using Voronoi tessellation, which creates non-overlapping regions based on proximity to data points. It then counts the number of samples from both the real data and generated samples that fall into each region. Using these counts, it applies a chi-squared test to determine if the two sample sets are drawn from the same multinomial distribution, producing a p-value that quantifies the similarity between real and generated data distributions. The method is likelihood-free, requiring no assumptions about the underlying data distribution, and avoids the need for training auxiliary models.

## Key Results
- Effectively assesses quality, novelty, and diversity on synthetic data
- Validates sampling methods and tracks generative model training progress
- Demonstrates strong correlation with human evaluation on CIFAR-10 images
- Shows computational efficiency compared to MMD with RBF kernels

## Why This Works (Mechanism)
PQMass leverages the principle that if two distributions are identical, their samples should be distributed similarly across any reasonable partitioning of the sample space. By using Voronoi tessellation, it creates a data-driven partitioning that adapts to the local density of samples. The chi-squared test then provides a statistical framework to quantify whether the observed differences in sample counts across regions are likely due to chance or indicate genuine distributional differences. This approach avoids the curse of dimensionality that affects many distance-based methods while maintaining sensitivity to both local and global distributional features.

## Foundational Learning

**Voronoi Tessellation**: A space partitioning technique that divides space into regions based on proximity to a set of points. Needed to create non-overlapping regions for probability mass estimation without requiring density estimation. Quick check: Verify that each region contains exactly one seed point and that regions partition the entire space.

**Chi-squared Test**: A statistical hypothesis test that compares observed frequencies to expected frequencies. Required to determine if sample counts across regions are consistent with samples coming from the same distribution. Quick check: Ensure expected counts in each region are sufficiently large (typically â‰¥5) for the chi-squared approximation to be valid.

**Multinomial Distribution**: A generalization of the binomial distribution for multiple categories. Provides the theoretical foundation for treating region counts as draws from a multinomial distribution. Quick check: Confirm that total sample counts sum to the same value for both real and generated data when computing expected frequencies.

## Architecture Onboarding

**Component Map**: Data samples -> Voronoi tessellation -> Region assignment -> Count aggregation -> Chi-squared test -> p-value

**Critical Path**: The core computation involves creating Voronoi regions from combined real and generated samples, assigning each sample to its nearest region, counting samples per region, and computing the chi-squared statistic and p-value.

**Design Tradeoffs**: The method trades computational complexity (quadratic in sample size) for avoiding density estimation and auxiliary model training. It also trades some statistical power for scalability to higher dimensions compared to kernel-based methods like MMD.

**Failure Signatures**: Low p-values indicating distributional differences when models are actually good (false positives) may occur with small sample sizes or inappropriate region counts. High p-values when models are poor (false negatives) may happen with too few regions that fail to capture distributional differences.

**First Experiments**:
1. Generate two samples from the same simple distribution (e.g., Gaussian) and verify p-values are high
2. Generate samples from different distributions and verify p-values are low
3. Apply to a trained generative model and track p-value changes during training

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical guarantees depend on sample sizes being sufficiently large for chi-squared approximation
- Computational complexity is quadratic in sample size, limiting scalability for very large datasets
- Manual selection of region counts and neighbor parameters introduces hyperparameter sensitivity
- Empirical evaluation relies on standard benchmark datasets without testing extreme cases

## Confidence

**High confidence**: The core theoretical foundation (Voronoi tessellation + chi-squared testing) is sound and the method's advantages over density-based and MMD approaches are well-established for the tested scenarios.

**Medium confidence**: The method's performance claims across diverse generative modeling tasks are supported by experiments, though broader testing on more challenging distributions would strengthen these claims.

**Low confidence**: The method's behavior with very high-dimensional data (>1000 dimensions) and its sensitivity to hyperparameter choices across different data types remain uncertain based on the current evaluation.

## Next Checks
1. Test PQMass on datasets with known challenging properties (e.g., highly imbalanced classes, heavy-tailed distributions) to evaluate robustness limits
2. Conduct systematic ablation studies varying the number of Voronoi regions and neighbor parameters across different data modalities
3. Evaluate performance degradation as dimensionality increases beyond the tested range to establish practical scaling limits