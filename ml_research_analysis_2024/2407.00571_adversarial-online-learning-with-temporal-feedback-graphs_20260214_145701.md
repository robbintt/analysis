---
ver: rpa2
title: Adversarial Online Learning with Temporal Feedback Graphs
arxiv_id: '2407.00571'
source_url: https://arxiv.org/abs/2407.00571
tags:
- bound
- program
- slash
- disp
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel framework for online learning with
  temporal feedback graphs, where a learner's action at each round can only depend
  on losses from a specific subset of rounds determined by a directed feedback graph.
  The key contribution is an algorithm based on partitioning losses across sub-cliques
  (orders) of the feedback graph and running multiplicative weights in parallel for
  each order.
---

# Adversarial Online Learning with Temporal Feedback Graphs

## Quick Facts
- **arXiv ID**: 2407.00571
- **Source URL**: https://arxiv.org/abs/2407.00571
- **Reference count**: 25
- **Primary result**: Introduces online learning framework with temporal feedback graphs achieving O(UB(S)√log K) regret

## Executive Summary
This paper presents a novel framework for online learning where feedback is constrained by temporal dependencies encoded in directed graphs. The key innovation is an algorithm that partitions losses across sub-cliques (orders) of the feedback graph and runs multiplicative weights in parallel for each order. The approach achieves regret bounds that are within a constant factor of optimal for important graph classes like transitive feedback graphs, which include batched learning and delayed feedback scenarios.

## Method Summary
The authors introduce a new online learning framework where a learner's action at each round can only depend on losses from a specific subset of rounds determined by a directed feedback graph. Their algorithm partitions losses across sub-cliques (orders) of the feedback graph and runs multiplicative weights in parallel for each order. The regret is bounded by O(UB(S)√log K), where UB(S) is the optimal value of a convex program defined by the feedback graph structure.

## Key Results
- Algorithm achieves O(UB(S)√log K) regret bound
- For transitive feedback graphs, algorithm is within a constant factor of optimal
- Efficient construction of sparse solutions to convex program for transitive graphs
- Tight lower bound matching upper bound for transitive graphs

## Why This Works (Mechanism)
The algorithm works by decomposing the complex feedback structure into simpler sub-cliques and handling each independently with multiplicative weights. This decomposition allows the algorithm to leverage the structure of the feedback graph while maintaining low regret. The convex program formulation captures the inherent constraints of the feedback structure, and the parallel processing across orders enables efficient handling of temporal dependencies.

## Foundational Learning
- **Temporal feedback graphs**: Directed graphs encoding which past losses are available at each time step - needed to model realistic feedback constraints
- **Multiplicative weights algorithm**: Online learning algorithm that maintains weight distribution and updates multiplicatively - quick check: verify update rule converges
- **Sub-cliques (orders)**: Decompositions of feedback graph into simpler components - needed for tractable algorithm design
- **Convex programming**: Optimization framework for regret bounds - quick check: verify feasibility conditions
- **Transitive graphs**: Special feedback graph class with path independence property - needed for tight bounds
- **Regret bounds**: Performance metric measuring cumulative loss vs. optimal fixed action - quick check: verify dependence on graph structure

## Architecture Onboarding

**Component map**: Convex program → Sparse solution construction → Multiplicative weights per order → Parallel processing → Regret bound

**Critical path**: 
1. Define feedback graph structure
2. Solve convex program for UB(S)
3. Construct sparse solution
4. Run parallel multiplicative weights
5. Combine results for final regret bound

**Design tradeoffs**: 
- Parallel processing across orders vs. sequential processing
- Sparse vs. dense solution to convex program
- General feedback graphs vs. restricted transitive case

**Failure signatures**:
- Infeasible convex program solution
- High regret despite theoretical bounds
- Computational bottleneck in large graphs

**First experiments**:
1. Verify regret bound on synthetic transitive graphs
2. Test sparse solution construction efficiency
3. Compare against baseline algorithms on delayed feedback tasks

## Open Questions the Paper Calls Out
None

## Limitations
- Assumes full knowledge of feedback graph structure upfront
- Convex program may be computationally challenging for large-scale graphs
- Constant-factor optimality relies on specific transitive graph properties

## Confidence
- **High**: Regret bounds for transitive feedback graphs (O(UB(S)√log K))
- **Medium**: Constant-factor optimality claim (1/2-approximation guarantee)
- **Medium**: Efficiency of sparse solution construction for transitive graphs
- **Low**: General lower bound tightness for non-transitive graphs

## Next Checks
1. Empirical evaluation on real-world temporal feedback scenarios to verify practical regret performance
2. Benchmark comparison against alternative approaches for non-transitive feedback graphs
3. Stress testing of convex program solver on large-scale feedback graphs to measure computational overhead