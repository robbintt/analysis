---
ver: rpa2
title: 'DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language Models
  (Exemplified as A Video Agent)'
arxiv_id: '2401.08392'
source_url: https://arxiv.org/abs/2401.08392
tags:
- video
- arxiv
- doraemongpt
- action
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DoraemonGPT addresses the challenge of understanding dynamic scenes
  in videos using large language models (LLMs). It constructs a task-related symbolic
  memory by decoupling spatial-temporal attributes and querying them via sub-task
  tools.
---

# DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language Models (Exemplified as A Video Agent)

## Quick Facts
- arXiv ID: 2401.08392
- Source URL: https://arxiv.org/abs/2401.08392
- Authors: Zongxin Yang; Guikun Chen; Xiaodi Li; Wenguan Wang; Yi Yang
- Reference count: 40
- Key outcome: 55.7% accuracy on NExT-QA benchmark, outperforming ViperGPT (45.5%)

## Executive Summary
DoraemonGPT addresses the challenge of understanding dynamic scenes in videos using large language models (LLMs) by constructing a task-related symbolic memory through spatial-temporal decoupling. The system employs a novel Monte Carlo Tree Search (MCTS) planner to efficiently explore the large planning space for scheduling various tools, enabling it to handle complex video understanding tasks. Evaluation on three benchmarks demonstrates DoraemonGPT's superiority over recent LLM-driven agents like ViperGPT and VideoChat.

## Method Summary
DoraemonGPT converts input videos into a task-related symbolic memory that stores spatial-temporal attributes, decoupling them into space-dominant and time-dominant memories based on the task's requirements. Sub-task tools (What, Why, How, When, Count, Other) query specific information from this memory, while knowledge tools provide external information. An MCTS planner explores the large planning space by iteratively finding feasible solutions through backpropagation of node rewards, ultimately generating multiple solutions and summarizing them into an improved final answer.

## Key Results
- Achieves 55.7% accuracy on NExT-QA benchmark versus 45.5% for ViperGPT
- Competitive performance in referring video object segmentation with 65.9% J&F score
- Successfully handles in-the-wild tasks involving complex reasoning and video editing

## Why This Works (Mechanism)

### Mechanism 1
DoraemonGPT improves dynamic scene understanding by decoupling spatial-temporal attributes into task-related symbolic memory. The system constructs two types of symbolic memory—space-dominant (instance-aware) and time-dominant (time-frame-based)—tailored to the task's spatial or temporal focus. This decoupling reduces irrelevant information and allows targeted querying via SQL-like symbolic language.

### Mechanism 2
The MCTS planner efficiently explores the large planning space for dynamic video tasks by iteratively finding feasible solutions through backpropagation of node rewards. The planner treats the planning space as a tree where each node is a tool call. MCTS selects expandable nodes probabilistically based on rewards, expands branches with different tool choices, and backpropagates outcomes to guide future selections toward higher-reward paths.

### Mechanism 3
Sub-task tools compact the planner's context and improve effectiveness by querying specific spatial-temporal reasoning tasks via specialized LLM-driven agents. Instead of passing the entire memory to the planner, DoraemonGPT defines six sub-task tools (When, Why, What, How, Count, Other) that each answer a specific type of question by generating SQL queries to the appropriate memory.

## Foundational Learning

- **Concept**: Monte Carlo Tree Search (MCTS)
  - Why needed here: Dynamic video tasks have large, combinatorial planning spaces where naive greedy search may miss optimal tool sequences.
  - Quick check question: What are the four phases of MCTS and how does backpropagation guide future node selection?

- **Concept**: Symbolic Memory with SQL Querying
  - Why needed here: Videos contain rich spatial-temporal data; symbolic memory allows LLMs to query only relevant attributes without overwhelming context.
  - Quick check question: How does the system decide between space-dominant and time-dominant memory for a given question?

- **Concept**: Sub-task Decomposition via LLM Agents
  - Why needed here: Complex video questions often require multiple reasoning steps; sub-task tools enable modular, targeted reasoning.
  - Quick check question: What are the six sub-task tool types and what reasoning aspect does each address?

## Architecture Onboarding

- **Component map**: Video → Task Analysis → Symbolic Memory Construction → Sub-task/Knowledge Tools → MCTS Planner → Multiple Solutions → Final Answer
- **Critical path**: Memory construction → Tool selection via MCTS → Chain execution → Answer summarization
- **Design tradeoffs**:
  - Memory decoupling vs. completeness: Decoupling reduces noise but may miss cross-modal dependencies.
  - MCTS exploration vs. latency: More iterations improve quality but increase inference time.
  - Tool specialization vs. flexibility: Specialized tools improve accuracy but require manual definition.
- **Failure signatures**:
  - Memory construction failure: Wrong memory type selected → SQL queries return no relevant data.
  - MCTS failure: LLM generates identical tool calls → exploration diversity collapses.
  - Tool execution failure: Sub-task LLM fails to parse question → SQL generation error.
- **First 3 experiments**:
  1. Ablation: Run without symbolic memory (pass raw video to planner) and measure accuracy drop.
  2. MCTS vs. greedy: Compare performance when N=1 (greedy) vs. N>1 (MCTS exploration).
  3. Tool count impact: Test with only 3 sub-task tools vs. full 6-tool set to measure accuracy vs. simplicity tradeoff.

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of DoraemonGPT scale with increasing video length, and what are the computational bottlenecks when handling long-form videos? The paper mentions that processing time increases linearly with video length, but does not provide detailed analysis on performance degradation or scalability limits.

### Open Question 2
How does the choice of foundation models (e.g., YOLOv8, Deep OC-sort, BLIP-2) affect the performance of DoraemonGPT, and are there specific models that consistently outperform others across different tasks? The paper discusses the impact of captioning models on DoraemonGPT's performance but does not provide a comprehensive analysis of the impact of different foundation models on various tasks.

### Open Question 3
How does the performance of DoraemonGPT compare to state-of-the-art supervised models on video understanding tasks, and what are the limitations of using an LLM-driven approach compared to supervised learning? The paper compares DoraemonGPT to recent LLM-driven competitors but does not provide a direct comparison with state-of-the-art supervised models on video understanding tasks.

## Limitations

- Relies heavily on foundation models for symbolic memory construction without ablation studies on their impact
- Performance improvements (55.7% vs 45.5%) still indicate significant room for improvement on NExT-QA
- Claims about handling complex in-the-wild tasks lack systematic evaluation and rely on qualitative examples

## Confidence

- **High Confidence**: The core architectural approach of decoupling spatial-temporal attributes into symbolic memory and using MCTS for planning exploration is well-supported.
- **Medium Confidence**: Performance improvements over baseline models are supported by quantitative results, but reproducibility is uncertain due to lack of detailed implementation information.
- **Low Confidence**: Claims about handling complex in-the-wild tasks are supported by qualitative examples but lack systematic evaluation.

## Next Checks

1. **Ablation Study on Foundation Models**: Replace YOLOv8, BLIP, and Whisper with alternative models to measure the impact of foundation model quality on symbolic memory construction and final accuracy.

2. **MCTS Parameter Sensitivity Analysis**: Systematically vary the number of iterations (N), exploration constant (c), and reward aggregation method in the MCTS planner to identify optimal configurations.

3. **Sub-task Tool Coverage Analysis**: Manually categorize questions from the NExT-QA benchmark by reasoning type and evaluate whether the current six sub-task tools adequately cover all question types.