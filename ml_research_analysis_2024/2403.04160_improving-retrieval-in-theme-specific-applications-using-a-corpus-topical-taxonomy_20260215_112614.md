---
ver: rpa2
title: Improving Retrieval in Theme-specific Applications using a Corpus Topical Taxonomy
arxiv_id: '2403.04160'
source_url: https://arxiv.org/abs/2403.04160
tags:
- retrieval
- taxonomy
- topic
- toter
- corpus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ToTER, a framework for improving document
  retrieval in theme-specific applications by leveraging a corpus topical taxonomy.
  ToTER addresses the challenges of specialized terminology, incomplete query contexts,
  and specialized user interests in domains like academic paper search and product
  search.
---

# Improving Retrieval in Theme-specific Applications using a Corpus Topical Taxonomy

## Quick Facts
- **arXiv ID**: 2403.04160
- **Source URL**: https://arxiv.org/abs/2403.04160
- **Reference count**: 40
- **Primary result**: ToTER framework improves document retrieval in theme-specific applications by leveraging topical taxonomy, consistently outperforming baselines in both zero-shot and few-shot scenarios

## Executive Summary
This paper introduces ToTER, a framework designed to improve document retrieval in theme-specific applications by leveraging a corpus topical taxonomy. The key insight is that specialized domains like academic paper search and product search have unique terminology and incomplete query contexts that standard retrieval models struggle with. ToTER addresses these challenges by using a topical taxonomy to identify central topics of queries and documents, then exploiting their topical relatedness to supplement missing contexts. The framework achieves consistent performance improvements across two real-world datasets in scenarios with both no labeled data and limited labels.

## Method Summary
ToTER is a framework that enhances retrieval in theme-specific applications by integrating topical taxonomy knowledge. It operates through three main stages: first, it generates silver labels for documents using top-down taxonomy traversal; second, it trains a class relevance estimator that learns topic distributions using both individual document features and collective knowledge distillation from semantically similar documents; third, it applies three inference strategies during retrieval - SSA for binary topic overlap filtering, CRM for distribution-based reranking, and QEP for phrase-based query enrichment. The framework can operate in zero-shot mode using only the topical taxonomy or be fine-tuned with limited labeled data.

## Key Results
- ToTER consistently improves retrieval accuracy across two real-world datasets in both zero-shot and few-shot learning scenarios
- The framework outperforms various baseline methods including traditional BM25, PLM-based retrievers, and other knowledge-enhanced approaches
- Collective knowledge distillation and query enrichment components contribute significant performance gains, with ablation studies showing their individual impact

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using topical taxonomy to identify central topics of queries and documents compensates for incomplete contexts in theme-specific applications
- Mechanism: The topical taxonomy provides high-level topic hierarchy that reveals the latent topic structure of the corpus. By computing topic class relevance between queries and documents, ToTER identifies shared thematic contexts that may be omitted by expert users who assume implicit domain knowledge
- Core assumption: Topical taxonomy construction accurately captures user-interested aspects and domain-specific terminology that PLMs trained on general corpora miss
- Evidence anchors:
  - [abstract] "uses a topical taxonomy to identify the central topics of queries and documents, and exploits their topical relatedness to supplement missing contexts"
  - [section] "The taxonomy provides a high-level topic hierarchy of the entire corpus. To harness this corpus-level knowledge for retrieval, we first link it to individual documents"
  - [corpus] Weak - the paper assumes taxonomy quality but only briefly explores robustness to taxonomy impairments in Â§5.4.2
- Break condition: If the topical taxonomy fails to capture domain-specific terminology or user-interested aspects, the topical relatedness signals become noisy and misleading

### Mechanism 2
- Claim: Collective knowledge distillation complements incomplete silver labels in topic class relevance learning
- Mechanism: Instead of relying solely on imperfect silver labels generated through top-down taxonomy traversal, ToTER uses semantically similar documents to generate collective relevance labels. These collective labels average predictions from similar documents, providing richer supervision that reveals topic classes not captured by individual document assignments
- Core assumption: Documents with high semantic similarity share similar topical distributions, making collective averaging more stable than individual predictions
- Evidence anchors:
  - [section] "Our core idea is that the topic distribution of a document can be inferred from semantically similar documents"
  - [section] "Unlike yð‘  which consists of binary values, yð‘ reveals the soft probability of a document's relevance to each class"
  - [corpus] Moderate - ablation shows collective knowledge distillation improves performance, but doesn't test against alternative semi-supervised approaches in detail
- Break condition: If semantically similar documents don't share topical distributions (e.g., in highly specialized subfields), collective averaging introduces noise rather than improving signal quality

### Mechanism 3
- Claim: Query enrichment by core phrases improves fine-grained reranking by leveraging topic-specific phrase knowledge
- Mechanism: ToTER identifies core phrases that frequently appear in top-ranked documents within relevant topic classes. These phrases capture domain-specific terminology and nuanced distinctions between documents sharing similar topics, enabling more precise query enrichment for the reranker
- Core assumption: Core phrases extracted from relevant documents within topic classes provide more informative context than general topic class names or PLM-generated topics
- Evidence anchors:
  - [section] "we use phrase-level knowledge to enrich queries...identify core phrases to enrich the query using both the topic class knowledge and top-ranked retrieved documents"
  - [section] "we found that they are often too coarse-grained, thus bringing limited information for fine-grained rankings"
  - [corpus] Moderate - ablation shows core phrase identification outperforms using only topic class names, but doesn't compare against more sophisticated phrase extraction methods
- Break condition: If top-ranked documents don't contain distinctive phrases or if phrase frequencies don't correlate with relevance, query enrichment may add noise instead of useful context

## Foundational Learning

- Concept: Topic taxonomy construction and completion methods
  - Why needed here: ToTER relies on high-quality corpus topical taxonomies that reflect user-interested aspects and domain-specific knowledge
  - Quick check question: What distinguishes recent taxonomy completion approaches from traditional hierarchical clustering of term clusters?

- Concept: Multi-stage retrieval pipeline (retrieve-then-rerank)
  - Why needed here: ToTER is designed as a plug-and-play framework that enhances both retrieval and reranking stages through topical knowledge integration
  - Quick check question: How do dual-encoder retrievers differ from cross-encoder rerankers in their approach to relevance estimation?

- Concept: Contrastive learning and negative sampling strategies
  - Why needed here: ToTER's class relevance estimator training and the effectiveness of hard negative mining impact the quality of topical relatedness signals
  - Quick check question: Why might denoising using a cross-encoder improve contrastive learning for dense retrieval compared to simple in-batch negatives?

## Architecture Onboarding

- Component map: Topical taxonomy T + Corpus D -> Silver label generation -> Class relevance estimator -> Inference (SSA, CRM, QEP) -> Enhanced retrieval
- Critical path: Silver label generation â†’ Class relevance estimator training â†’ Inference with SSA â†’ CRM â†’ QEP
- Design tradeoffs:
  - Taxonomy-guided vs. semantic-only relevance estimation: Taxonomy provides domain-specific context but may be less flexible than pure semantic matching
  - Binary vs. real-valued topic representations: Binary enables efficient bitwise operations for SSA but loses nuance
  - Collective vs. individual knowledge distillation: Collective is more stable but computationally heavier
  - Phrase-based vs. topic-only query enrichment: Phrases provide specificity but require additional computation
- Failure signatures:
  - SSA performance degrades when topic overlap is insufficient to distinguish relevant from irrelevant documents
  - CRM fails when semantic similarity and topical relatedness conflict significantly
  - QEP introduces noise when top-ranked documents don't contain discriminative phrases
  - Overall performance drops when taxonomy quality is poor (incomplete coverage or low term coherence)
- First 3 experiments:
  1. Verify silver label generation quality by comparing generated labels against small manually annotated sample
  2. Test class relevance estimator performance on held-out documents with known topic assignments
  3. Evaluate each inference strategy (SSA, CRM, QEP) independently to identify which contributes most to performance gains

## Open Questions the Paper Calls Out
None explicitly stated in the provided content

## Limitations
- The approach depends heavily on the quality of the topical taxonomy, which is not extensively validated and remains a critical weak point
- Collective knowledge distillation assumes semantic similarity correlates with topical relatedness, but this assumption isn't thoroughly tested against alternative semi-supervised approaches
- Query enrichment via core phrases assumes extracted phrases capture discriminative information, but doesn't validate against other phrase extraction methods

## Confidence

**High confidence**: The core claim that topical taxonomy can improve retrieval in theme-specific applications is well-supported by the experimental results across two real-world datasets. The performance improvements over baseline methods are consistent and statistically significant.

**Medium confidence**: The effectiveness of collective knowledge distillation and query enrichment mechanisms has moderate support. While ablation studies show these components contribute to performance gains, the underlying assumptions about semantic similarity and phrase discriminative power aren't thoroughly validated.

**Low confidence**: The paper's claims about taxonomy quality requirements and the robustness of the approach to taxonomy imperfections have weak support. The brief exploration in Â§5.4.2 doesn't provide sufficient evidence for how the framework performs with varying taxonomy quality.

## Next Checks

1. **Taxonomy quality impact study**: Systematically vary taxonomy quality (completeness, coherence, coverage) and measure corresponding impact on retrieval performance. Compare ToTER's performance with taxonomies generated by different construction methods to establish how critical taxonomy quality is to the approach.

2. **Alternative semi-supervised comparison**: Replace the collective knowledge distillation component with alternative semi-supervised learning approaches (e.g., consistency regularization, self-training) and compare performance to isolate whether the improvement comes from semi-supervision itself or the specific collective averaging mechanism.

3. **Phrase extraction method comparison**: Test ToTER with alternative phrase extraction methods (e.g., TextRank, RAKE, supervised keyphrase extraction) to determine whether the specific core phrase identification approach is optimal or if simpler methods could achieve similar gains.