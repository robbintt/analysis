---
ver: rpa2
title: Revisiting Multi-modal Emotion Learning with Broad State Space Models and Probability-guidance
  Fusion
arxiv_id: '2404.17858'
source_url: https://arxiv.org/abs/2404.17858
tags:
- emotion
- fusion
- feature
- multi-modal
- recognition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of Multi-modal Emotion Recognition
  in Conversation (MERC) by proposing a novel approach that combines Broad Learning
  Systems (BLS) and State Space Models (SSM). The authors argue that long-range contextual
  semantic information should be extracted in the feature disentanglement stage and
  inter-modal semantic information consistency should be maximized in the feature
  fusion stage.
---

# Revisiting Multi-modal Emotion Learning with Broad State Space Models and Probability-guidance Fusion

## Quick Facts
- arXiv ID: 2404.17858
- Source URL: https://arxiv.org/abs/2404.17858
- Authors: Yuntao Shou; Tao Meng; Fuchen Zhang; Nan Yin; Keqin Li
- Reference count: 40
- Primary result: Achieves SOTA on IEMOCAP and MELD datasets with 1.40% improvement in weighted accuracy and 0.80% in F1 score on MELD

## Executive Summary
This paper addresses Multi-modal Emotion Recognition in Conversation (MERC) by proposing a novel approach combining Broad Learning Systems (BLS) and State Space Models (SSM). The authors argue that traditional methods fail to adequately capture long-range contextual semantic information during feature disentanglement and maintain inter-modal semantic consistency during feature fusion. Their proposed solution, Broad Mamba, integrates SSMs for emotional representation compression with BLS for exploring data distributions in broad space. Additionally, they introduce a probability-guided fusion mechanism designed to maximize consistency between modalities.

## Method Summary
The proposed method addresses MERC challenges by implementing a two-stage approach: feature disentanglement and feature fusion. During disentanglement, State Space Models are employed to compress emotional representations while capturing long-range contextual dependencies. The Broad Learning System component then explores potential data distributions across a broad feature space, enabling more comprehensive representation learning. In the fusion stage, a probability-guided mechanism is designed to maximize semantic consistency between different modalities. This approach aims to overcome limitations of traditional transformer-based methods by providing both efficiency and effectiveness in capturing emotional nuances across multiple modalities.

## Key Results
- Achieves state-of-the-art performance on IEMOCAP and MELD datasets
- Improves weighted accuracy by 1.40% and F1 score by 0.80% on MELD dataset compared to best baselines
- Demonstrates low computational consumption while maintaining high performance
- Shows effectiveness of probability-guided fusion in maintaining inter-modal consistency

## Why This Works (Mechanism)
The method's effectiveness stems from its dual approach to addressing MERC challenges. By employing State Space Models for representation compression, the approach captures long-range contextual dependencies that are often missed by traditional attention mechanisms. The Broad Learning System component expands the representational capacity across a broader feature space, allowing for more nuanced emotion detection. The probability-guided fusion mechanism ensures that information consistency between modalities is maximized, preventing information loss during the fusion process. This combination allows the model to effectively leverage complementary information from different modalities while maintaining computational efficiency.

## Foundational Learning

**State Space Models (SSM)**
- Why needed: Capture long-range dependencies more efficiently than transformers
- Quick check: Verify SSM can compress sequences while preserving temporal relationships

**Broad Learning Systems (BLS)**
- Why needed: Explore high-dimensional feature spaces for better representation
- Quick check: Confirm BLS can identify non-linear patterns across modalities

**Probability-guided Fusion**
- Why needed: Ensure consistent information flow between modalities
- Quick check: Validate fusion mechanism maintains probability distributions

## Architecture Onboarding

**Component Map:**
Text features -> SSM compression -> BLS expansion -> Probability fusion -> Emotion classification

**Critical Path:**
SSM compression → BLS expansion → Probability-guided fusion

**Design Tradeoffs:**
- Computational efficiency vs. representational capacity
- Modality-specific vs. shared representations
- Early fusion vs. late fusion strategies

**Failure Signatures:**
- Over-smoothing in SSM compression leading to loss of emotion-specific features
- BLS expansion creating spurious correlations
- Probability fusion failing to maintain modality consistency

**First 3 Experiments:**
1. Ablation study removing SSM component to measure impact on contextual understanding
2. Ablation study removing probability-guided fusion to assess modality consistency
3. Comparative analysis with transformer-based baselines on computational requirements

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Computational efficiency claims lack rigorous quantification through parameter counts, FLOPs, or inference time comparisons
- Method evaluation limited to only two datasets (IEMOCAP and MELD) without broader validation
- Absence of ablation studies to demonstrate necessity of each component in the proposed architecture
- Insufficient justification for advantages over established transformer-based approaches for long-range dependency capture

## Confidence

**Major Claim Clusters - Confidence Labels:**
- State-of-the-art performance claims: Medium confidence
- Computational efficiency claims: Low confidence
- Broad Learning System + SSM integration benefits: Medium confidence

## Next Checks

1. Conduct ablation studies removing either the Broad Learning component or the probability-guided fusion to isolate their individual contributions to performance gains
2. Perform statistical significance testing on the reported improvements to verify they are not due to random variation
3. Benchmark computational requirements (parameters, FLOPs, inference time) against the baseline methods to substantiate efficiency claims