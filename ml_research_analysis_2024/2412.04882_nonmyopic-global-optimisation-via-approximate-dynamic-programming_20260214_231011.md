---
ver: rpa2
title: Nonmyopic Global Optimisation via Approximate Dynamic Programming
arxiv_id: '2412.04882'
source_url: https://arxiv.org/abs/2412.04882
tags: []
core_contribution: This paper extends nonmyopic acquisition principles from Bayesian
  optimisation to deterministic global optimisation strategies using inverse distance
  weighting (IDW) and radial basis functions (RBFs). The authors formulate these surrogate
  models as dynamical systems and develop dynamic programming-based paradigms including
  rollout and multi-step scenario-based optimisation to enable lookahead acquisition.
---

# Nonmyopic Global Optimisation via Approximate Dynamic Programming

## Quick Facts
- arXiv ID: 2412.04882
- Source URL: https://arxiv.org/abs/2412.04882
- Authors: Filippo Airaldi; Bart De Schutter; Azita Dabiri
- Reference count: 40
- One-line primary result: Nonmyopic methods using IDW and RBF surrogate models with dynamic programming achieve better final optimality gaps with statistical significance compared to myopic approaches

## Executive Summary
This paper extends nonmyopic acquisition principles from Bayesian optimisation to deterministic global optimisation using inverse distance weighting (IDW) and radial basis functions (RBFs) as surrogate models. The authors formulate these models as dynamical systems and develop dynamic programming-based paradigms including rollout and multi-step scenario-based optimisation to enable lookahead acquisition. These methods optimize a sequence of query points over a horizon by predicting the evolution of the surrogate model, systematically managing the exploration-exploitation trade-off. The approach is validated on synthetic benchmark functions and real-world hyperparameter tuning problems, demonstrating superior performance compared to conventional myopic approaches.

## Method Summary
The method extends Bayesian optimisation principles to deterministic global optimisation using IDW and RBF surrogate models. These surrogate models are formulated as dynamical systems where the state represents the regression model at iteration k. Dynamic programming paradigms (rollout and multi-step scenario-based optimisation) are developed to optimize a sequence of query points over a horizon H by predicting the evolution of the surrogate model. The rollout algorithm uses a lookahead window to optimize the cumulative reward over H steps, while the multi-step algorithm considers multiple possible scenarios using quadrature or Monte Carlo sampling. The reward function balances exploration and exploitation through coefficients λ and μ, with exploration quantified by the surrogate model's uncertainty.

## Key Results
- Nonmyopic methods achieve better final optimality gaps with statistical significance compared to myopic approaches
- Rollout with Monte Carlo sampling shows slightly better empirical performance than rollout with Gauss-Hermite quadrature
- Longer horizon windows do not necessarily relate to better performance, indicating a trade-off between lookahead benefits and computational complexity
- The methods converge faster to superior solutions on both synthetic benchmark functions and real-world hyperparameter tuning problems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: IDW and RBF surrogate models provide computationally lighter alternatives to Gaussian processes for high-dimensional spaces
- Mechanism: These models construct deterministic approximations without requiring posterior computation, reducing computational overhead
- Core assumption: Approximation accuracy is sufficient to guide optimization effectively
- Evidence anchors: Abstract states these models "offer competitive, computationally lighter solutions" and section explains they provide "deterministic approximations"

### Mechanism 2
- Claim: Dynamic programming-based paradigms enable systematic lookahead acquisition
- Mechanism: These methods optimize query point sequences over horizons by predicting surrogate model evolution
- Core assumption: Surrogate model dynamics can be accurately predicted over the lookahead horizon
- Evidence anchors: Abstract mentions "dynamic programming-based paradigms, including rollout and multi-step scenario-based optimisation schemes" and section explains they "inherently manage the exploration-exploitation trade-off"

### Mechanism 3
- Claim: Nonmyopic strategies outperform myopic approaches by considering surrogate model evolution and cumulative costs
- Mechanism: Dynamic programming optimizes query point selection over multiple steps, balancing exploration and exploitation
- Core assumption: Reward function effectively quantifies exploration-exploitation benefits
- Evidence anchors: Abstract states "these nonmyopic methods outperform conventional myopic approaches" and section explains how observing new function values "advance[s] the state of the model"

## Foundational Learning

- Concept: Dynamic Programming
  - Why needed here: Used to formulate global optimization as sequential decision-making for nonmyopic acquisition strategies
  - Quick check question: How does dynamic programming help in managing the exploration-exploitation trade-off in global optimization?

- Concept: Surrogate Modeling
  - Why needed here: Provides approximations of unknown objective functions without expensive evaluations
  - Quick check question: What are the advantages of using IDW and RBFs over Gaussian processes in high-dimensional spaces?

- Concept: Acquisition Functions
  - Why needed here: Guide query point selection, balancing exploration and exploitation to find global optimum efficiently
  - Quick check question: How do nonmyopic acquisition functions differ from myopic ones in terms of their decision-making process?

## Architecture Onboarding

- Component map: Surrogate models (IDW/RBF) -> Dynamic programming algorithms (rollout/multi-step) -> Acquisition functions -> Query point selection -> Objective function evaluation -> Model update
- Critical path: Update surrogate model with new data → Optimize acquisition function → Select next query point → Evaluate objective function → Repeat until convergence
- Design tradeoffs: IDW vs RBF affects computational efficiency and accuracy; horizon length impacts lookahead benefits vs computational complexity
- Failure signatures: Poor surrogate model accuracy, inaccurate dynamics prediction, ineffective reward function design
- First 3 experiments:
  1. Implement basic IDW surrogate model and test on simple optimization problem
  2. Develop rollout algorithm using IDW model and compare to myopic baseline
  3. Extend rollout to use RBFs and compare results with IDW-based approach

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice between GH quadrature and MC sampling affect nonmyopic method performance across different problem types and dimensions?
- Basis in paper: Explicit observation that rollout with MC sampling shows slightly better performance than GH quadrature
- Why unresolved: Paper provides empirical observations without theoretical justification for performance differences
- What evidence would resolve it: Systematic theoretical analysis comparing MC and GH sampling error propagation, plus empirical studies across broader problem classes

### Open Question 2
- Question: What is the optimal horizon length H for nonmyopic methods across different problem characteristics?
- Basis in paper: Explicit statement that longer horizons don't necessarily improve performance
- Why unresolved: Paper demonstrates horizon effects but provides no guidance for selecting optimal horizons
- What evidence would resolve it: Theoretical analysis of lookahead benefits vs model uncertainty accumulation, coupled with empirical studies mapping problem characteristics to optimal horizons

### Open Question 3
- Question: How can nonmyopic deterministic strategies be extended to handle unknown constraint functions in constrained black-box optimization?
- Basis in paper: Explicit mention as future work for constrained global optimization
- Why unresolved: Paper acknowledges this extension without providing concrete approaches
- What evidence would resolve it: Development and validation of algorithms modeling both objective and constraint functions while maintaining nonmyopic lookahead property

## Limitations
- Generalizability to extremely high-dimensional spaces where IDW/RBF approximation accuracy may degrade
- Computational complexity scaling poorly with problem dimension and horizon length
- Reward function design relies on empirical tuning rather than theoretical principles

## Confidence
- Confidence in core claims is Medium
- Empirical results show statistically significant improvements over myopic baselines
- Sample size of tested problems is limited
- Paper lacks theoretical guarantees for convergence rates or performance bounds
- Claim of "systematic" trade-off management requires further validation across diverse landscapes

## Next Checks
1. Test proposed methods on synthetic functions with known high-dimensional properties to assess scalability and robustness
2. Conduct ablation studies systematically varying λ and μ coefficients to quantify their impact on convergence and solution quality
3. Implement theoretical analysis to derive convergence rates and characterize conditions where nonmyopic approach guarantees improvement over myopic methods