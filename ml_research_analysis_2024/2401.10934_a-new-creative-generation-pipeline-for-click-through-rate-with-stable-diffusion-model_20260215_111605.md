---
ver: rpa2
title: A New Creative Generation Pipeline for Click-Through Rate with Stable Diffusion
  Model
arxiv_id: '2401.10934'
source_url: https://arxiv.org/abs/2401.10934
tags:
- image
- creatives
- prompt
- creative
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new creative generation pipeline (CG4CTR)
  for improving click-through rate (CTR) in online advertising. The method applies
  the inpainting mode of stable diffusion to generate creative images while keeping
  the main product unchanged.
---

# A New Creative Generation Pipeline for Click-Through Rate with Stable Diffusion Model

## Quick Facts
- arXiv ID: 2401.10934
- Source URL: https://arxiv.org/abs/2401.10934
- Authors: Hao Yang; Jianxin Yuan; Shuai Yang; Linhe Xu; Shuo Yuan; Yifan Zeng
- Reference count: 40
- Key outcome: Proposes CG4CTR pipeline using Stable Diffusion inpainting to generate creatives, showing significant CTR and revenue improvements over traditional methods.

## Executive Summary
This paper introduces a creative generation pipeline (CG4CTR) for improving click-through rate (CTR) in online advertising by leveraging Stable Diffusion's inpainting mode. The method generates background images while preserving the main product, using a self-cyclic training framework with a prompt model for user personalization and a reward model for CTR prediction. Experimental results demonstrate substantial improvements in CTR and revenue compared to traditional methods, with ablation studies confirming the effectiveness of the self-cycling training and user information integration.

## Method Summary
The CG4CTR pipeline uses Stable Diffusion's inpainting mode to generate background images while keeping the main product unchanged, identified by a saliency detection network. A self-cyclic training framework iteratively improves both a LoRA model (fine-tuned on advertising data) and a prompt model that generates individualized prompts based on user information. A reward model predicts CTR scores for generated creatives using multimodal features, and top-k creatives are selected to guide the training of both models. This process alternates between updating the LoRA and prompt models to ensure convergence and improve creative quality.

## Key Results
- Significant CTR and revenue improvements compared to traditional methods
- Self-cyclic training and user information integration are key factors for performance
- The pipeline generates high-quality, diverse creatives while preserving product identity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Inpainting mode in Stable Diffusion allows background generation without altering the main product, preserving product identity while enhancing visual appeal.
- Mechanism: The saliency detection network masks the main product pixels, and the inpainting mode of Stable Diffusion generates only the background pixels, maintaining the original product integrity.
- Core assumption: Saliency detection accurately identifies and isolates the main product, and the inpainting mode can generate realistic and attractive backgrounds conditioned on the prompt.
- Evidence anchors:
  - [abstract] "The inpainting mode in stable diffusion is firstly applied to creative generation task in online advertising scene. A self-cyclic generation pipeline is proposed to ensure the convergence of training."
  - [section 3.2] "To generate one image with a higher quality while leaving the main content of original product unchanged, we can get the pixels (referred as ùêºùë†ùëéùëô ) of the main product image ùêº by using the saliency detection network [38]. The pre-trained saliency detection network can point out the main product locations and then ùêºùë†ùëéùëô are masked and only background pixels ùêºùëèùëòùëî are generated by SD method in inpainting mode [41]."

### Mechanism 2
- Claim: The self-cyclic training pipeline iteratively improves the LoRA model and prompt model by using the reward model's predictions to select high-quality creatives and provide feedback for training.
- Mechanism: Generated creatives are ranked by the reward model, top-k creatives are used to train the LoRA model, and the corresponding prompts are used as positive samples to train the prompt model, alternating between the two models for iterative improvement.
- Core assumption: The reward model accurately predicts CTR scores, and the selected top-k creatives and prompts are indeed of higher quality and more likely to improve CTR.
- Evidence anchors:
  - [abstract] "A self-cyclic generation pipeline is proposed to ensure the convergence of training. Prompt model is designed to generate individualized creatives for different user groups, which can further improve the diversity and quality."
  - [section 3.1] "The LoRA model and prompt model are updated iteratively. Precisely, in first step, only parameters in LoRA model are updated while parameters in prompt model are fixed; in second step, parameters in LoRA model are fixed while parameters in prompt model are updated, ensuring the convergence of the entire framework."

### Mechanism 3
- Claim: Considering user information in the prompt model allows for individualized creative generation, catering to diverse user preferences and improving CTR.
- Mechanism: User attributes, item attributes, and contextual attributes are input into the prompt model, which outputs CTR scores for each token, and the top-p tokens are selected to form a prompt that generates a creative tailored to the user group.
- Core assumption: Different user groups have distinct preferences for creative styles, and the prompt model can effectively learn and incorporate these preferences to generate appropriate prompts.
- Evidence anchors:
  - [abstract] "Prompt model is designed to generate individualized creative images for different user groups, which can further improve the diversity and quality."
  - [section 3.3] "To improve the quality and stability of the generated creative, the LoRA model and prompt model are updated iteratively. Precisely, in first step, only parameters in LoRA model are updated while parameters in prompt model are fixed; in second step, parameters in LoRA model are fixed while parameters in prompt model are updated, ensuring the convergence of the entire framework."

## Foundational Learning

- Concept: Stable Diffusion and its inpainting mode
  - Why needed here: Stable Diffusion is the core generative model used to create the background images for the creatives, and the inpainting mode is crucial for preserving the main product while enhancing the background.
  - Quick check question: How does the inpainting mode of Stable Diffusion differ from the normal mode, and why is it important for this application?

- Concept: LoRA (Low-Rank Adaptation) for fine-tuning
  - Why needed here: LoRA allows for efficient fine-tuning of the large Stable Diffusion model on the specific dataset, enabling the generation of creatives that are more aligned with the target domain and user preferences.
  - Quick check question: What is the advantage of using LoRA over fine-tuning the entire Stable Diffusion model, and how does it contribute to the overall performance of the pipeline?

- Concept: CTR prediction and reward modeling
  - Why needed here: The reward model predicts the CTR scores for the generated creatives, which are used to select high-quality creatives for training and to guide the iterative improvement of the LoRA and prompt models.
  - Quick check question: How does the reward model incorporate multimodal features (image, text, and caption) to predict CTR scores, and why is this important for the self-cyclic training process?

## Architecture Onboarding

- Component map:
  - Original image ‚Üí Saliency detection ‚Üí Stable Diffusion with inpainting ‚Üí Generated creative ‚Üí Reward model prediction ‚Üí Top-k selection ‚Üí LoRA and prompt model training ‚Üí Improved creatives

- Critical path:
  - Original image ‚Üí Saliency detection ‚Üí Stable Diffusion with inpainting ‚Üí Generated creative ‚Üí Reward model prediction ‚Üí Top-k selection ‚Üí LoRA and prompt model training ‚Üí Improved creatives

- Design tradeoffs:
  - Using inpainting mode preserves the main product but may limit the extent of background modification compared to full image generation.
  - Fine-tuning the entire Stable Diffusion model may yield better results but is computationally expensive, while LoRA offers a more efficient alternative with potentially slightly lower performance.
  - Incorporating user information in the prompt model increases personalization but also adds complexity to the model and training process.

- Failure signatures:
  - If the saliency detection fails to accurately identify the main product, the background generation may modify the product, leading to poor user experience.
  - If the reward model's predictions are inaccurate, the self-cyclic training may reinforce low-quality creatives and prompts, degrading the overall performance.
  - If the prompt model cannot effectively learn to generate appropriate prompts for different user groups, the individualized generation may not improve CTR.

- First 3 experiments:
  1. Evaluate the performance of the inpainting mode in Stable Diffusion on a held-out test set of original images, measuring the quality of generated backgrounds and the preservation of the main product.
  2. Compare the performance of the LoRA model with the full Stable Diffusion model on a small subset of the dataset, assessing the trade-off between computational efficiency and creative quality.
  3. Test the impact of incorporating user information in the prompt model by generating creatives for different user groups and measuring the CTR improvement compared to non-personalized generation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the CG4CTR pipeline differ when integrated at the item recommendation stage (A-stage) versus the item ranking stage (B-stage)?
- Basis in paper: [explicit] The paper discusses two potential integration points for the CG4CTR pipeline: after item recommendation (A-stage) and before item ranking (B-stage). It notes that A-stage may lead to reduced performance as the ranking model can only consider the original image, while B-stage may offer better performance but requires higher online time consumption.
- Why unresolved: The paper mentions these two stages but does not provide experimental results comparing their performance.
- What evidence would resolve it: Experimental results comparing the CTR and revenue improvements of the CG4CTR pipeline when integrated at A-stage versus B-stage would provide evidence to resolve this question.

### Open Question 2
- Question: How do different styles of LoRA models impact the quality and diversity of generated creatives in the CG4CTR pipeline?
- Basis in paper: [explicit] The paper suggests exploring the use of various styles of LoRA models instead of a single LoRA model to generate creatives with enhanced styles and superior quality. It mentions that these styles can be provided by designers as initial samples to train LoRA models.
- Why unresolved: The paper proposes this idea but does not provide experimental results or analysis of the impact of different LoRA styles on creative quality and diversity.
- What evidence would resolve it: Experimental results comparing the quality and diversity of creatives generated by different styles of LoRA models in the CG4CTR pipeline would provide evidence to resolve this question.

### Open Question 3
- Question: What are the potential methods for generating creatives beyond modifying the background image in the CG4CTR pipeline?
- Basis in paper: [explicit] The paper mentions that more ways to generate creatives rather than modifying the background need to be investigated in the same framework.
- Why unresolved: The paper acknowledges the need for exploring alternative methods but does not provide specific suggestions or experimental results.
- What evidence would resolve it: Research and experimental results on alternative methods for generating creatives in the CG4CTR pipeline, such as modifying the main product image or incorporating additional design elements, would provide evidence to resolve this question.

## Limitations
- Limited experimental validation with only high-level performance metrics reported
- Self-cyclic training heavily relies on reward model accuracy without thorough examination of noise sensitivity
- Computational cost of generating individualized creatives for large user populations not addressed

## Confidence
- **High**: The core mechanism of using Stable Diffusion inpainting to preserve product identity while generating backgrounds is technically sound and well-established.
- **Medium**: The self-cyclic training framework is plausible but lacks sufficient empirical validation to confirm convergence properties and effectiveness.
- **Low**: The claim that user information integration significantly improves CTR is supported by comparison to a single baseline without rigorous ablation or statistical significance testing.

## Next Checks
1. Conduct ablation studies to isolate the contribution of each component (inpainting, self-cyclic training, user information integration) to CTR improvement.
2. Evaluate the sensitivity of self-cyclic training to reward model accuracy by testing with artificially degraded reward predictions.
3. Measure the computational efficiency and generation latency of the full pipeline to assess real-time deployment feasibility at scale.