---
ver: rpa2
title: 'Connect, Collapse, Corrupt: Learning Cross-Modal Tasks with Uni-Modal Data'
arxiv_id: '2401.08567'
source_url: https://arxiv.org/abs/2401.08567
tags:
- image
- embeddings
- modality
- text
- contrastive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of learning cross-modal tasks
  (e.g., image captioning) from uni-modal data, which is difficult due to limited
  paired multi-modal data. The authors propose a three-step method, C^3 (Connect,
  Collapse, Corrupt), to bridge the modality gap in multi-modal contrastive representation
  spaces, enabling the interchangeability of embeddings from different modalities.
---

# Connect, Collapse, Corrupt: Learning Cross-Modal Tasks with Uni-Modal Data

## Quick Facts
- arXiv ID: 2401.08567
- Source URL: https://arxiv.org/abs/2401.08567
- Authors: Yuhui Zhang; Elaine Sui; Serena Yeung-Levy
- Reference count: 40
- Primary result: Achieves BLEU-1 scores of 71.0 on image captioning and FID scores of 19.6 on text-to-image generation from uni-modal data

## Executive Summary
This paper addresses the challenge of learning cross-modal tasks (e.g., image captioning) from uni-modal data by bridging the modality gap in multi-modal contrastive representation spaces. The authors propose a three-step method called C³ (Connect, Collapse, Corrupt) that significantly improves cross-modal learning performance. By leveraging pre-trained multi-modal contrastive encoders and applying targeted operations to address modality gaps and alignment noise, the method achieves state-of-the-art results on zero-shot image/audio/video captioning and text-to-image generation tasks.

## Method Summary
The C³ method works by first extracting embeddings from uni-modal data using frozen pre-trained multi-modal contrastive encoders (like CLIP), then applying two key operations: Collapse (subtracting the mean embedding per modality to eliminate the constant modality gap) and Corrupt (adding Gaussian noise during training to make the decoder robust to alignment noise). A decoder model (like GPT-2 or StyleGAN2) is trained on this processed uni-modal data, and during inference, the collapse operation is applied before decoding from the other modality's embeddings.

## Key Results
- Achieves BLEU-1 score of 71.0 on zero-shot image captioning
- Achieves FID score of 19.6 on zero-shot text-to-image generation
- Outperforms previous approaches across multiple cross-modal tasks including image/audio/video captioning

## Why This Works (Mechanism)

### Mechanism 1
Dimensional collapse at initialization creates a modality gap that persists during contrastive optimization because gradients only update effective dimensions. Only a subset of dimensions contribute to variance (effective dimensions), while remaining dimensions stay constant across modalities, creating a gap that gradients cannot reduce.

### Mechanism 2
The contrastive loss has a stable region where small margins between matched and hardest negative pairs result in near-zero loss, causing alignment noise. When similarity differences exceed a threshold determined by temperature, optimization effectively stops, leaving residual noise in the alignment.

### Mechanism 3
The collapse operation removes the modality gap by subtracting the mean embedding from each modality, while the corrupt operation adds Gaussian noise to make the decoder robust to alignment noise. Subtracting the mean embedding difference eliminates the constant gap vector, and adding noise during training makes the decoder invariant to small perturbations from alignment noise.

## Foundational Learning

- Concept: Multi-modal contrastive learning geometry
  - Why needed here: Understanding the modality gap and alignment noise is essential to grasp why C³ works and what problems it solves
  - Quick check question: What are the two main sources of non-alignment in the multi-modal contrastive representation space according to the paper?

- Concept: Dimensional collapse
  - Why needed here: This phenomenon explains why the modality gap exists at initialization and persists during optimization
  - Quick check question: How does dimensional collapse lead to different constant values in the ineffective dimensions for different modalities?

- Concept: Stable regions in optimization
  - Why needed here: Understanding why contrastive optimization stops before perfect alignment helps explain the source of alignment noise
  - Quick check question: How does the temperature parameter in contrastive loss affect the size of the stable region?

## Architecture Onboarding

- Component map: Pre-trained multi-modal contrastive encoders (frozen) -> C³ operations (Collapse, Corrupt) -> Decoder (trained) -> Target modality output

- Critical path: 1) Extract embeddings from uni-modal data using frozen pre-trained encoders 2) Apply collapse operation (subtract mean embedding per modality) 3) Apply corrupt operation (add Gaussian noise) 4) Train decoder to reconstruct target modality 5) During inference, apply collapse operation and decode from the other modality's embeddings

- Design tradeoffs: Freezing pre-trained encoders preserves the multi-modal representation space but limits adaptability; the choice of noise level σ in corrupt operation requires tuning; mean subtraction assumes the modality gap is constant across the dataset

- Failure signatures: Poor cross-modal performance despite good uni-modal training suggests the collapse operation isn't working properly; degraded uni-modal performance indicates the corrupt operation is too aggressive; no improvement over baseline suggests the pre-trained encoders don't have the assumed geometry

- First 3 experiments: 1) Verify the modality gap exists by computing the mean difference between paired embeddings from different modalities 2) Test the effect of the collapse operation alone by training with and without mean subtraction 3) Test the effect of the corrupt operation alone by training with and without Gaussian noise addition at different noise levels

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal strategy for mitigating the modality gap and alignment noise in multi-modal contrastive learning?
- Basis in paper: Explicit
- Why unresolved: The paper proposes the C³ method to address these issues, but the effectiveness of different strategies is not fully explored
- What evidence would resolve it: A comprehensive ablation study comparing different methods for mitigating the modality gap and alignment noise, with a focus on their impact on downstream tasks

### Open Question 2
- Question: How does the depth of the neural network architecture affect the degree of dimensional collapse and the resulting modality gap?
- Basis in paper: Inferred
- Why unresolved: The paper provides theoretical insights into the causes of dimensional collapse, but does not investigate how the depth of the network impacts this phenomenon
- What evidence would resolve it: Experiments varying the depth of the network architecture and measuring the resulting modality gap and dimensional collapse

### Open Question 3
- Question: Can the C³ method be extended to other multi-modal tasks beyond image captioning and text-to-image generation?
- Basis in paper: Explicit
- Why unresolved: The paper demonstrates the effectiveness of C³ on a limited set of tasks, but does not explore its generalizability to other multi-modal applications
- What evidence would resolve it: Experiments applying the C³ method to a diverse range of multi-modal tasks, such as audio-to-text transcription or video-to-text summarization

## Limitations

- The method's performance appears sensitive to the choice of pre-trained encoders and their specific representation geometries
- The empirical validation doesn't directly verify the geometric claims about the modality gap's orthogonality or the effectiveness of the collapse operation at the dimensional level
- The theoretical analysis relies heavily on idealized assumptions about dimensional collapse and stable regions in optimization

## Confidence

**High Confidence**: The empirical results showing significant improvements over baselines on zero-shot cross-modal tasks, particularly the BLEU-1 score of 71.0 for image captioning and FID of 19.6 for text-to-image generation.

**Medium Confidence**: The theoretical explanation of why the modality gap persists during contrastive optimization through dimensional collapse and stable regions.

**Low Confidence**: The claim that the collapse and corrupt operations work precisely because they address the identified modality gap and alignment noise.

## Next Checks

1. **Geometry Verification**: Measure and visualize the modality gap in the representation space before and after applying the collapse operation. Compute the mean difference between paired embeddings from different modalities and verify that this gap is eliminated by mean subtraction.

2. **Noise Sensitivity Analysis**: Systematically vary the noise level σ in the corrupt operation and measure its effect on both cross-modal task performance and alignment noise. Plot performance curves as a function of noise level to identify optimal ranges.

3. **Cross-Encoder Generalization**: Test the method with different pre-trained multi-modal encoders beyond CLIP (e.g., BLIP, OpenCLIP, or ImageBind) to evaluate whether the C³ operations consistently improve cross-modal learning across different representation geometries.