---
ver: rpa2
title: Uncertainty Quantification for cross-subject Motor Imagery classification
arxiv_id: '2403.09228'
source_url: https://arxiv.org/abs/2403.09228
tags: []
core_contribution: This study investigates Uncertainty Quantification (UQ) methods
  for predicting misclassifications in cross-subject Motor Imagery Brain Computer
  Interfaces. Using the BCI Competition IV dataset 2a with 9 subjects performing 4
  motor imagery tasks, the research applies various UQ techniques including Deep Ensembles,
  MC-Dropout, MC-DropConnect, Flipout, and Deterministic Uncertainty Quantification
  (DUQ) to a Shallow ConvNet architecture.
---

# Uncertainty Quantification for cross-subject Motor Imagery classification

## Quick Facts
- arXiv ID: 2403.09228
- Source URL: https://arxiv.org/abs/2403.09228
- Reference count: 31
- One-line primary result: No UQ method performed better than standard CNNs at identifying uncertain predictions across subjects in cross-subject Motor Imagery classification

## Executive Summary
This study investigates Uncertainty Quantification (UQ) methods for predicting misclassifications in cross-subject Motor Imagery Brain Computer Interfaces. Using the BCI Competition IV dataset 2a with 9 subjects performing 4 motor imagery tasks, the research applies various UQ techniques including Deep Ensembles, MC-Dropout, MC-DropConnect, Flipout, and Deterministic Uncertainty Quantification (DUQ) to a Shallow ConvNet architecture. The methods are evaluated using leave-one-subject-out cross-validation with separate within-population and cross-subject test sets. While Deep Ensembles achieved the highest classification accuracy (59.05% cross-population), surprisingly, no UQ method performed better than standard CNNs with Softmax output at identifying uncertain predictions across subjects. The study found that measures of aleatoric uncertainty were as effective as those designed to capture epistemic uncertainty, suggesting that cross-subject variability introduces epistemic uncertainty that current models fail to adequately represent.

## Method Summary
The study preprocesses EEG data from the BCI Competition IV dataset 2a by dropping EOG channels, converting to microvolts, applying exponential moving standardization, and epoching from 0.5s before trial cue to 6s. A Shallow ConvNet architecture serves as the base model, with various UQ adaptations including MC-Dropout, MC-DropConnect, Deep Ensembles, Flipout, and DUQ. The evaluation uses leave-one-subject-out cross-validation with within-population test sets, generating uncertainty estimates through T forward passes (T=50) for stochastic models. Classification accuracy and Area Under the ROC curve (AUROC) for uncertainty estimation are calculated for both within and cross-population test sets to compare performance across methods and uncertainty measures.

## Key Results
- Deep Ensembles achieved the highest classification accuracy (59.05% cross-population)
- No UQ method performed better than standard CNNs with Softmax output at identifying uncertain predictions across subjects
- Measures of aleatoric uncertainty were as effective as those designed to capture epistemic uncertainty for cross-subject rejection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Epistemic uncertainty does not effectively identify cross-subject misclassifications because the underlying assumptions of discriminative models may not align with the nature of inter-subject variability in motor imagery.
- Mechanism: Discriminative models learn decision boundaries that separate classes, but cross-subject variability introduces uncertainty that doesn't align with proximity to these boundaries. The study found that no UQ method performed better than standard CNNs at identifying uncertain predictions across subjects, suggesting that the epistemic uncertainty captured by these methods doesn't correspond well with the actual generalization error introduced by subject differences.
- Core assumption: Epistemic uncertainty captured by Bayesian methods (MC-Dropout, MC-DropConnect, Deep Ensembles, Flipout) should correlate with generalization error in cross-subject classification.
- Evidence anchors:
  - [abstract]: "no UQ method performed better than standard CNNs with Softmax output at identifying uncertain predictions across subjects"
  - [section]: "While Deep Ensembles achieved the highest classification accuracy (59.05% cross-population), surprisingly, no UQ method performed better than standard CNNs with Softmax output at identifying uncertain predictions across subjects"
  - [corpus]: Weak - only one related paper on uncertainty quantification, suggesting limited prior work in this specific application
- Break condition: If the cross-subject variability pattern is fundamentally different from what discriminative models assume, or if the uncertainty is predominantly aleatoric rather than epistemic.

### Mechanism 2
- Claim: The combination of aleatoric and epistemic uncertainty in cross-subject classification makes it difficult to disentangle and utilize epistemic uncertainty alone for rejection.
- Mechanism: The study found that measures of aleatoric uncertainty were as effective as those designed to capture epistemic uncertainty, suggesting that cross-subject variability introduces uncertainty that current models fail to adequately represent as purely epistemic. When predictive entropy is disentangled into aleatoric and epistemic components, epistemic uncertainty based thresholding is consistently slightly worse than aleatoric uncertainty based thresholding.
- Core assumption: Aleatoric and epistemic uncertainty can be effectively disentangled in cross-subject motor imagery classification, and epistemic uncertainty should be more useful for identifying misclassifications.
- Evidence anchors:
  - [abstract]: "The study found that measures of aleatoric uncertainty were as effective as those designed to capture epistemic uncertainty, suggesting that cross-subject variability introduces epistemic uncertainty that current models fail to adequately represent"
  - [section]: "It can be seen that epistemic uncertainty based thresholding is consistently slightly worse than aleatoric uncertainty based thresholding"
  - [corpus]: Weak - limited corpus coverage of UQ methods in motor imagery context
- Break condition: If the disentanglement methods are flawed, or if the nature of cross-subject uncertainty fundamentally differs from assumptions in current UQ frameworks.

### Mechanism 3
- Claim: The Shallow ConvNet architecture and its UQ adaptations may not be sufficiently complex or appropriate for capturing the epistemic uncertainty introduced by cross-subject variability.
- Mechanism: The study used a specific Shallow ConvNet architecture with various UQ adaptations (MC-Dropout, MC-DropConnect, Deep Ensembles, Flipout, DUQ). Despite these adaptations, no method substantially outperformed standard softmax models. The architecture's inability to capture complex inter-subject variability patterns may explain why epistemic uncertainty measures fail to identify misclassifications effectively.
- Core assumption: The Shallow ConvNet architecture, even with UQ adaptations, is capable of learning representations that capture subject-specific variability and can distinguish epistemic from aleatoric uncertainty.
- Evidence anchors:
  - [section]: "Overall we can conclude that adding UQ methods did not result in better uncertainty estimation than standard (softmax) models for the purposes of rejecting difficult samples cross-subject"
  - [section]: "It can be seen that no BNN method is substantially better than another at uncertainty quantification. Only DUQ performs substantially worse than other methods"
  - [corpus]: Weak - limited comparison with alternative architectures in related work
- Break condition: If the architecture is fundamentally limited in its capacity to model the variability, or if different architectural choices (deeper networks, different feature extractors) would yield better uncertainty representation.

## Foundational Learning

- Concept: Bayesian Neural Networks and their approximations
  - Why needed here: The study relies heavily on various approximations of Bayesian Neural Networks (MC-Dropout, MC-DropConnect, Deep Ensembles, Flipout) to capture epistemic uncertainty. Understanding how these methods approximate Bayesian inference and what assumptions they make is crucial for interpreting why they may fail to identify cross-subject misclassifications.
  - Quick check question: What is the fundamental difference between a standard CNN and a Bayesian Neural Network in terms of how they handle uncertainty, and why might this difference not translate to better cross-subject classification performance?

- Concept: Aleatoric vs. Epistemic uncertainty
  - Why needed here: The paper distinguishes between these two types of uncertainty and attempts to disentangle them. Understanding their definitions, how they manifest in EEG data, and why one might dominate the other in cross-subject settings is essential for interpreting the results where aleatoric uncertainty measures performed as well as epistemic ones.
  - Quick check question: How do aleatoric and epistemic uncertainty differ in their sources and implications for BCI systems, and why might aleatoric uncertainty be more prevalent in cross-subject motor imagery classification?

- Concept: Cross-subject variability in EEG
  - Why needed here: The study's core premise is that cross-subject variability introduces epistemic uncertainty that should be capturable by UQ methods. Understanding the nature of this variability (anatomical differences, cognitive strategies, signal quality variations) and how it affects model generalization is key to understanding why current UQ methods may fail.
  - Quick check question: What are the primary sources of cross-subject variability in motor imagery EEG, and how might these sources manifest differently than the uncertainty patterns that discriminative models are designed to capture?

## Architecture Onboarding

- Component map:
  Data pipeline -> Model architecture -> Uncertainty computation -> Evaluation

- Critical path:
  1. Load and preprocess EEG data (drop EOG, convert to ÂµV, standardize, epoch)
  2. Split data using leave-one-subject-out with within-population test sets
  3. Train base Shallow ConvNet model
  4. Implement UQ adaptations for each method
  5. Generate uncertainty estimates for both within and cross-population test sets
  6. Calculate classification accuracy and uncertainty AUROC
  7. Compare performance across methods and uncertainty measures

- Design tradeoffs:
  - Shallow ConvNet vs. deeper architectures: Simplicity and interpretability vs. potential for better feature extraction
  - Number of forward passes (T=50): Computational cost vs. convergence of uncertainty estimates
  - Within-population test set: Realistic estimate of performance vs. potential overfitting to subject-specific patterns
  - Leave-one-subject-out: Comprehensive evaluation vs. computational intensity

- Failure signatures:
  - No improvement in cross-population accuracy despite UQ methods
  - Similar performance between epistemic and aleatoric uncertainty measures
  - Consistent underperformance of DUQ compared to BNN-based methods
  - Higher uncertainty AUROC within-population than cross-population

- First 3 experiments:
  1. Reproduce the baseline Shallow ConvNet performance on within-population and cross-population sets to establish performance baseline
  2. Implement MC-Dropout and compare its uncertainty estimates and rejection performance against the baseline softmax model
  3. Test different values of T (number of forward passes) to determine optimal tradeoff between computational cost and uncertainty estimate quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do Bayesian Neural Networks (BNNs) fail to capture epistemic uncertainty better than standard CNNs in cross-subject classification tasks?
- Basis in paper: [explicit] The study found that none of the BNN methods (MC-Dropout, MC-DropConnect, Flipout, Ensembles) performed substantially better than standard CNNs with Softmax output for identifying uncertain predictions in cross-subject classification.
- Why unresolved: The paper acknowledges this finding contradicts expectations but does not provide a definitive explanation. It suggests possible reasons (prevalence of aleatoric uncertainty, limitations in how uncertainty is modeled) but cannot conclusively determine which is correct.
- What evidence would resolve it: Comparative studies using alternative uncertainty disentanglement methods (e.g., explicit modeling of aleatoric and epistemic uncertainty as separate outputs), or experiments that systematically vary the degree of inter-subject variability to observe how uncertainty measures scale.

### Open Question 2
- Question: Does the inability of BNNs to capture epistemic uncertainty in cross-subject classification generalize to other domains with domain shift or transfer learning scenarios?
- Basis in paper: [inferred] The findings show BNNs do not outperform standard CNNs specifically for cross-subject EEG classification, where epistemic uncertainty should theoretically increase due to inter-subject variability.
- Why unresolved: The study is limited to one specific domain (motor imagery EEG classification). While the findings suggest a potential limitation of BNNs for cross-domain scenarios, this needs verification across different domains and types of domain shift.
- What evidence would resolve it: Replication studies applying the same uncertainty quantification methods to cross-domain classification tasks in computer vision, natural language processing, or other domains with known domain shift problems.

### Open Question 3
- Question: Would alternative uncertainty quantification methods, such as evidential deep learning or Dirichlet-based approaches, perform better at capturing epistemic uncertainty in cross-subject classification?
- Basis in paper: [explicit] The study only investigates BNNs (MC-Dropout, MC-DropConnect, Flipout, Ensembles) and DUQ, finding that none of these approaches effectively capture epistemic uncertainty better than standard CNNs.
- Why unresolved: The study does not explore other uncertainty quantification frameworks that may have different theoretical foundations for modeling uncertainty, such as evidential deep learning or Dirichlet-based methods.
- What evidence would resolve it: Comparative experiments applying evidential deep learning or Dirichlet-based uncertainty quantification methods to the same cross-subject classification task and comparing their performance against the methods tested in this study.

## Limitations
- The Shallow ConvNet architecture may not be sufficiently expressive to capture complex inter-subject variability patterns
- Limited corpus coverage (only one related paper on uncertainty quantification in this context) suggests the field lacks established baselines
- The study's focus on a single dataset with 9 subjects limits generalizability

## Confidence

- High confidence: The empirical observation that no UQ method outperformed standard CNNs at identifying cross-subject misclassifications
- Medium confidence: The interpretation that this failure stems from epistemic uncertainty not aligning with cross-subject variability patterns
- Low confidence: The specific mechanisms proposed for why current UQ methods fail in this context

## Next Checks

1. Test alternative architectures (deeper networks, different feature extractors) to determine if the Shallow ConvNet is the limiting factor in capturing inter-subject variability
2. Conduct ablation studies on the uncertainty disentanglement methods to verify that aleatoric and epistemic components are being correctly separated and that the comparison between them is valid
3. Evaluate the same UQ methods on multiple motor imagery datasets with varying numbers of subjects to assess generalizability and determine if the findings are dataset-specific