---
ver: rpa2
title: 'FeatUp: A Model-Agnostic Framework for Features at Any Resolution'
arxiv_id: '2403.10516'
source_url: https://arxiv.org/abs/2403.10516
tags:
- features
- image
- featup
- conference
- upsampling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FeatUp is a task- and model-agnostic framework for upsampling deep
  features to any resolution. It uses multiview consistency across low-resolution
  "jitter" views of features to train an upsampling network, drawing inspiration from
  3D reconstruction methods like NeRF.
---

# FeatUp: A Model-Agnostic Framework for Features at Any Resolution

## Quick Facts
- arXiv ID: 2403.10516
- Source URL: https://arxiv.org/abs/2403.10516
- Authors: Stephanie Fu; Mark Hamilton; Laura Brandt; Axel Feldman; Zhoutong Zhang; William T. Freeman
- Reference count: 40
- Primary result: FeatUp significantly improves semantic segmentation, depth estimation, and class activation maps by upsampling deep features to any resolution

## Executive Summary
FeatUp is a model-agnostic framework that enables upsampling of deep features to any resolution, inspired by 3D reconstruction methods like NeRF. The framework introduces multiview consistency across low-resolution "jitter" views of features to train an upsampling network. It offers two variants: a fast feedforward upsampler based on a novel generalization of Joint Bilateral Upsampling (JBU) and an implicit network that overfits to a single image. FeatUp can be applied to any deep learning task without retraining, improving performance in applications such as semantic segmentation, depth estimation, and class activation maps.

## Method Summary
FeatUp leverages multiview consistency across low-resolution "jitter" views of features, drawing inspiration from 3D reconstruction methods like NeRF. The framework trains an upsampling network using this consistency principle, allowing it to learn to upsample features at any resolution. FeatUp offers two variants: a fast feedforward upsampler based on a novel generalization of Joint Bilateral Upsampling (JBU) and an implicit network that overfits to a single image. Both variants can be applied to any deep learning task without retraining, making FeatUp a versatile tool for improving feature resolution in various applications.

## Key Results
- FeatUp significantly outperforms existing methods in semantic segmentation, depth estimation, and class activation map generation
- The framework achieves state-of-the-art results in linear probe transfer learning, with mIoU scores of 47.37 and 43.41 on COCO-Stuff for implicit and JBU variants respectively
- FeatUp improves depth estimation RMSE by up to 0.04 compared to baselines

## Why This Works (Mechanism)
FeatUp's effectiveness stems from its ability to leverage multiview consistency across low-resolution "jitter" views of features. This approach, inspired by 3D reconstruction methods like NeRF, allows the framework to learn robust upsampling patterns that generalize well across different tasks and resolutions. By training on multiple views of the same feature, FeatUp can capture fine-grained details and spatial relationships that are often lost in standard downsampling operations.

## Foundational Learning
1. Multiview Consistency:
   - Why needed: Ensures the upsampling network learns robust features that are consistent across different viewpoints
   - Quick check: Verify that upsampled features maintain consistency across multiple low-resolution views of the same image

2. Joint Bilateral Upsampling (JBU):
   - Why needed: Provides a fast, feedforward upsampling method that preserves spatial relationships
   - Quick check: Compare JBU-based upsampling speed and quality against other methods

3. Implicit Networks:
   - Why needed: Allows the framework to overfit to a single image, capturing fine details
   - Quick check: Assess the ability of the implicit network to reconstruct fine details in complex scenes

## Architecture Onboarding

Component Map:
Image -> Feature Extractor -> Low-Resolution Features -> FeatUp Upsampler -> High-Resolution Features -> Task-Specific Network

Critical Path:
Feature extraction -> Low-resolution feature generation -> Multiview jitter augmentation -> FeatUp upsampling -> High-resolution feature output

Design Tradeoffs:
- Implicit network variant offers higher quality upsampling but requires more computation
- JBU-based variant provides faster upsampling at the cost of some detail preservation
- Multiview jitter augmentation improves consistency but increases training complexity

Failure Signatures:
- Inconsistent upsampling across different views of the same image
- Loss of fine-grained details in the upsampled features
- Slow upsampling performance with the implicit network variant

First Experiments:
1. Compare upsampling quality of FeatUp against baseline methods on a small dataset
2. Evaluate the consistency of upsampled features across multiple views of the same image
3. Measure the computational overhead of both FeatUp variants compared to existing methods

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation primarily focuses on semantic segmentation and depth estimation, potentially limiting generalizability to other computer vision tasks
- Computational overhead and runtime comparisons with baseline methods are not extensively discussed
- The method's dependence on multiview jitter augmentation may limit effectiveness on static scenes or when significant viewpoint changes are impractical

## Confidence
- High confidence: The framework's task-agnostic nature and demonstrated improvements over existing methods are well-supported by experimental results
- Medium confidence: Claims about state-of-the-art performance in linear probe transfer learning, as comparisons with all relevant baselines are not exhaustive
- Medium confidence: The assertion that upsampled features can be "dropped into existing applications" without retraining, as this may depend on specific implementation details

## Next Checks
1. Evaluate FeatUp's performance on additional computer vision tasks beyond semantic segmentation and depth estimation, such as object detection or instance segmentation
2. Conduct comprehensive runtime and computational complexity analysis comparing both FeatUp variants with existing upsampling methods across different hardware configurations
3. Test the framework's robustness on real-world scenarios where multiview jitter augmentation may be limited, such as static scenes or videos with minimal motion