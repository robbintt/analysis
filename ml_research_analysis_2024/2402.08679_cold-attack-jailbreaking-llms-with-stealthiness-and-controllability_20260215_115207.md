---
ver: rpa2
title: 'COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability'
arxiv_id: '2402.08679'
source_url: https://arxiv.org/abs/2402.08679
tags: []
core_contribution: COLD-Attack is a framework for generating stealthy and controllable
  adversarial prompts to jailbreak large language models. It adapts the Energy-based
  Constrained Decoding with Langevin Dynamics (COLD) algorithm, a state-of-the-art
  controllable text generation method, to solve the controllable attack generation
  problem.
---

# COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability

## Quick Facts
- arXiv ID: 2402.08679
- Source URL: https://arxiv.org/abs/2402.08679
- Authors: Xingang Guo; Fangxu Yu; Huan Zhang; Lianhui Qin; Bin Hu
- Reference count: 40
- Primary result: Achieved 100% attack success rate on Vicuna, Guanaco, and Mistral for suffix attacks while maintaining low perplexity (26.24-32.96)

## Executive Summary
COLD-Attack is a framework for generating stealthy and controllable adversarial prompts to jailbreak large language models. It adapts the Energy-based Constrained Decoding with Langevin Dynamics (COLD) algorithm, a state-of-the-art controllable text generation method, to solve the controllable attack generation problem. The framework unifies and automates the search for adversarial attacks under various control requirements such as fluency, stealthiness, sentiment, and left-right-coherence. COLD-Attack achieves high attack success rates while maintaining low perplexity and strong controllability, outperforming existing methods like AutoDAN-Zhu in fluency and stealthiness, and being significantly more efficient than GCG-type methods.

## Method Summary
COLD-Attack adapts the COLD algorithm to generate adversarial prompts for jailbreaking LLMs. It uses energy functions to capture multiple constraints (attack success, fluency, sentiment, coherence) and optimizes them using Langevin dynamics in continuous logit space. The framework samples discrete text attacks once at the end using guided decoding, enabling non-autoregressive generation that incorporates complex constraints while maintaining fluency. The approach is tested on various LLMs (Llama-2, Mistral, Vicuna, Guanaco, GPT-3.5) using the AdvBench dataset, demonstrating high success rates, strong controllability, and good transferability.

## Key Results
- Achieved 100% ASR on Vicuna, Guanaco, and Mistral for suffix attacks
- Maintained low perplexity (26.24-32.96) across different attack settings
- Demonstrated strong controllability with BERTScore improvements (e.g., 81.43 vs 80.25 for sentiment control)
- Showed good transferability across different LLM architectures
- Was approximately 10× faster than GCG-type methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: COLD-Attack achieves high attack success rates while maintaining fluency by unifying controllability and stealthiness through energy-based constrained decoding.
- Mechanism: The framework adapts the COLD algorithm to incorporate multiple energy functions that simultaneously enforce attack success, fluency, and additional control requirements. By using Langevin dynamics in continuous logit space and a guided decoding process, it generates discrete text attacks that satisfy all constraints.
- Core assumption: The energy functions can effectively capture and balance the different control requirements needed for successful jailbreaks.
- Evidence anchors:
  - [abstract]: "COLD-Attack is a framework for generating stealthy and controllable adversarial prompts to jailbreak large language models."
  - [section]: "The controllability enabled by COLD-Attack leads to diverse new jailbreak scenarios which not only cover the standard setting of generating fluent suffix attacks, but also allow us to address new controllable attack settings."
  - [corpus]: Weak evidence - no direct comparisons to similar energy-based approaches in the corpus.

### Mechanism 2
- Claim: COLD-Attack outperforms existing methods like AutoDAN-Zhu in fluency and stealthiness by using non-autoregressive generation.
- Mechanism: Unlike AutoDAN-Zhu's autoregressive token-by-token generation, COLD-Attack samples the discrete text attack once in the end using Langevin dynamics. This enables incorporating complex constraints like left-right-coherence while maintaining fluency.
- Core assumption: Non-autoregressive generation can produce more fluent attacks with better constraint satisfaction than autoregressive methods.
- Evidence anchors:
  - [section]: "COLD-Attack can be viewed as an energy-based method where one can impose various controls on the sampling of LLM attacks via using properly-designed energy functions."
  - [section]: "Diverging from the discrete token-level optimization in GCG, COLD-Attack leverages Langevin dynamics to perform efficient gradient-based sampling in the continuous logit space."
  - [corpus]: Moderate evidence - some related work on non-autoregressive generation exists in the corpus, but direct comparisons to autoregressive methods are limited.

### Mechanism 3
- Claim: COLD-Attack demonstrates strong transferability to other models and robustness against perplexity and paraphrasing defenses.
- Mechanism: By generating attacks that are both fluent and satisfy multiple constraints, COLD-Attack produces prompts that can transfer across different LLMs and evade common defense mechanisms.
- Core assumption: The generated attacks capture universal patterns that work across different model architectures while avoiding detection by defense mechanisms.
- Evidence anchors:
  - [abstract]: "COLD-Attack achieves high attack success rates (e.g., 100% on Vicuna, Guanaco, and Mistral for suffix attacks) while maintaining low perplexity (e.g., 26.24-32.96) and strong controllability."
  - [section]: "Our extensive experiments on various LLMs (Llama-2, Mistral, Vicuna, Guanaco, GPT-3.5) show COLD-Attack's broad applicability, strong controllability, high success rate, and attack transferability."
  - [corpus]: Weak evidence - the corpus contains related work on transferability and defenses, but specific comparisons to COLD-Attack are absent.

## Foundational Learning

- Concept: Energy-based models for text generation
  - Why needed here: COLD-Attack uses energy functions to represent and balance multiple constraints on generated text, requiring understanding of how energy-based models work in NLP.
  - Quick check question: How do energy functions in text generation differ from traditional loss functions, and why are they particularly suited for multi-constraint problems?

- Concept: Langevin dynamics for sampling
  - Why needed here: The algorithm uses Langevin dynamics to optimize the sample distribution in continuous logit space, which is crucial for understanding the generation process.
  - Quick check question: What role does the noise term play in Langevin dynamics, and how does it affect the convergence to the target distribution?

- Concept: Gradient-based optimization in discrete vs continuous spaces
  - Why needed here: COLD-Attack operates in continuous logit space rather than discrete token space, requiring understanding of the trade-offs and advantages of this approach.
  - Quick check question: What are the computational and optimization advantages of working in continuous logit space versus discrete token space for text generation?

## Architecture Onboarding

- Component map:
  - Energy function formulation module -> Langevin dynamics sampler -> Guided decoding process -> LLM interface -> Constraint evaluator

- Critical path: Energy function formulation → Langevin dynamics sampling → Guided decoding → Attack success evaluation

- Design tradeoffs:
  - Number of energy functions vs. computational complexity
  - Sampling iterations vs. attack success rate
  - Constraint strictness vs. fluency of generated attacks
  - Batch size for sampling vs. memory usage

- Failure signatures:
  - Low attack success rates: Energy functions may not be properly weighted or designed
  - Incoherent output: Langevin dynamics may not converge properly or decoding process may fail
  - Poor transferability: Generated attacks may be too model-specific
  - High perplexity: Energy functions may not adequately enforce fluency

- First 3 experiments:
  1. Test basic suffix attack generation on a single LLM with only attack success and fluency constraints
  2. Add sentiment control to the same setup and measure constraint satisfaction
  3. Test transferability by generating attacks on one model and evaluating on another

## Open Questions the Paper Calls Out

Open Question 1
- Question: How can the controllability of attacks be further diversified by exploring new choices of constraints ci(·) beyond fluency, sentiment, and left-right-coherence?
- Basis in paper: [explicit] The paper mentions that "it will be really beneficial if we can come up with general methods for solving (3.1)" and that "The flexible choices of ci(·) will allow us to generate attacks with diverse features."
- Why unresolved: The paper focuses on three specific attack settings (fluent suffix attack, paraphrase attack, and attack with left-right-coherence) and does not explore other potential constraints that could be imposed on the attacks.
- What evidence would resolve it: Empirical results demonstrating the effectiveness of COLD-Attack in generating attacks with new types of constraints, such as lexical constraints, format constraints, or style constraints, would provide evidence for the broader applicability of the framework.

Open Question 2
- Question: How can the efficiency of COLD-Attack be further improved, particularly in terms of reducing the computational cost and time required for generating attacks?
- Basis in paper: [explicit] The paper mentions that "COLD-Attack is much faster than GCG-type methods due to the removal of the greedy search step" but also acknowledges that "executing COLD-Attack for a single request using a single NVIDIA V100 GPU takes about 20 minutes."
- Why unresolved: While COLD-Attack is more efficient than some existing methods, there is still room for improvement in terms of reducing the computational cost and time required for generating attacks, especially for real-time applications.
- What evidence would resolve it: Empirical results demonstrating the effectiveness of COLD-Attack in generating attacks with reduced computational cost and time, while maintaining high attack success rates and controllability, would provide evidence for the improved efficiency of the framework.

Open Question 3
- Question: How can the transferability of COLD-Attack be further improved, particularly in terms of its effectiveness against different types of language models and defense mechanisms?
- Basis in paper: [explicit] The paper mentions that "COLD-Attack also displays a degree of transferability to such proprietary models" but also acknowledges that "prompts from less secure LLMs exhibit limited effectiveness against more secure models."
- Why unresolved: While COLD-Attack shows some transferability across different language models, there is still room for improvement in terms of its effectiveness against different types of models and defense mechanisms.
- What evidence would resolve it: Empirical results demonstrating the effectiveness of COLD-Attack in generating attacks that are transferable across a wider range of language models and defense mechanisms, while maintaining high attack success rates and controllability, would provide evidence for the improved transferability of the framework.

## Limitations

- Limited to English-language prompts and evaluation
- Requires access to local copies of target LLMs
- Energy function formulations and weighting schemes are not fully specified
- Relies heavily on automated evaluation metrics (GPT-4 for ASR-G)

## Confidence

**High Confidence:** Claims about achieving 100% ASR on specific models for suffix attacks are well-supported by experimental results.

**Medium Confidence:** Claims about strong transferability across different LLM architectures are supported but limited to a relatively small set of models.

**Low Confidence:** The assertion that COLD-Attack is "significantly more efficient than GCG-type methods" in all scenarios is based on the specific settings tested.

## Next Checks

1. Conduct ablation studies varying the weights and formulations of individual energy functions to quantify their contribution to overall performance and identify potential overfitting to specific constraint combinations.

2. Evaluate COLD-Attack's performance on non-English prompts and culturally diverse instruction sets to assess generalization beyond the English-centric evaluation.

3. Test COLD-Attack against more sophisticated defense mechanisms, including those that dynamically adapt to attack patterns or employ semantic analysis beyond simple perplexity and paraphrasing checks.