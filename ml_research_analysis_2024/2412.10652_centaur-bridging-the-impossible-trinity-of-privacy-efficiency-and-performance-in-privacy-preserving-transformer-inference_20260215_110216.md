---
ver: rpa2
title: 'CENTAUR: Bridging the Impossible Trinity of Privacy, Efficiency, and Performance
  in Privacy-Preserving Transformer Inference'
arxiv_id: '2412.10652'
source_url: https://arxiv.org/abs/2412.10652
tags:
- inference
- centaur
- data
- ppti
- privacy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CENTAUR addresses the "impossible trinity" in privacy-preserving
  transformer inference (PPTI) by combining random permutation and SMPC. It protects
  model parameters with permutation while securing inference data with secret sharing.
---

# CENTAUR: Bridging the Impossible Trinity of Privacy, Efficiency, and Performance in Privacy-Preserving Transformer Inference

## Quick Facts
- arXiv ID: 2412.10652
- Source URL: https://arxiv.org/abs/2412.10652
- Reference count: 40
- Achieves plaintext-level accuracy while improving inference speed by 5.0-30.4× compared to state-of-the-art frameworks

## Executive Summary
CENTAUR addresses the fundamental challenge in privacy-preserving transformer inference (PPTI) of balancing privacy, efficiency, and performance. The framework combines random permutation and secure multi-party computation (SMPC) to protect both model parameters and inference data. By leveraging efficient algorithms for linear and nonlinear layers, CENTAUR converts costly matrix multiplications between secret shares into communication-free operations. The result is a system that achieves privacy guarantees comparable to existing methods while significantly improving inference speed and maintaining model accuracy.

## Method Summary
CENTAUR uses a hybrid approach combining random permutation for model parameter protection and SMPC for inference data privacy. The model developer permutes model parameters using random permutation matrices and shares them with a cloud platform. During inference, the client generates secret shares of the input data, which are processed by the cloud using privacy-preserving algorithms. CENTAUR implements efficient protocols for linear layers (using permutation matrices to enable communication-free operations) and nonlinear layers (converting between secret-sharing and permutation states to enable efficient computation). The framework achieves this without requiring modifications to existing transformer architectures.

## Key Results
- Achieves plaintext-level accuracy on downstream tasks while protecting both model parameters and inference data
- Improves inference speed by 5.0-30.4× compared to state-of-the-art frameworks like MPCFormer and SecFormer
- Successfully resists model inversion attacks through the combination of permutation and SMPC
- Demonstrates efficient inference across different network settings (LAN/WAN) with varying communication volumes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Random permutation protects model parameters by making brute-force recovery infeasible
- Mechanism: Large permutation matrices create factorial explosion of possibilities; for n=1280, probability of correct recovery is 1/1280! ≈ 1/211372
- Core assumption: The permutation matrices are truly random and the adversary lacks structural knowledge of the original parameter layout
- Evidence anchors:
  - [abstract] states Centaur uses random permutations to protect model parameters and inference data with SMPC, achieving privacy guarantees
  - [section 6.1] explains the probability of recovering original parameters from permuted ones is 1/d! or 1/d!k! depending on parameter type
  - [corpus] no direct evidence; this is a standard cryptographic assumption
- Break condition: If the permutation matrix is leaked or if the adversary exploits model structure (e.g., sparsity patterns) to reduce search space

### Mechanism 2
- Claim: Secret sharing ensures privacy of inference data by splitting it into random shares that reveal nothing individually
- Mechanism: Data is split into two shares [X]0 and [X]1 such that X = ([X]0 + [X]1) mod L; neither share reveals information about X alone
- Core assumption: The semi-honest adversary follows protocol but may analyze shares; shares are computationally indistinguishable from random
- Evidence anchors:
  - [abstract] states Centaur secures inference data with SMPC
  - [section 2.2] describes 2-out-of-2 additive secret sharing framework where each party holds a share of private data
  - [section 6.2] proves intermediate results in secret-sharing state do not leak inference data privacy through simulation-based security proof
- Break condition: If more than the required number of shares are compromised, or if the secret-sharing scheme has implementation flaws

### Mechanism 3
- Claim: Converting secret shares to permuted state enables efficient privacy-preserving nonlinear operations
- Mechanism: Shares of permuted input [Xπ]j are sent to cloud platform, which reconstructs Xπ and performs plaintext nonlinear computation, then reshare results
- Core assumption: The conversion process maintains privacy and the nonlinear operation is element-wise, preserving permutation properties
- Evidence anchors:
  - [abstract] states Centaur leverages conversion between secret-shared and randomly permuted states of intermediate results
  - [section 5.2.1] describes how Centaur converts secret shares into randomly permuted state to allow plaintext computations of element-wise nonlinear operations
  - [section 5.2.1] explains this conversion requires two rounds of communication for transmitting shares of input and output
- Break condition: If the conversion protocol is implemented incorrectly or if the permutation property doesn't hold for the specific nonlinear operation

## Foundational Learning

- Concept: Secure Multi-Party Computation (SMPC) basics
  - Why needed here: Understanding how secret sharing works and why it provides privacy is fundamental to Centaur's design
  - Quick check question: If a value x is split into shares [x]0 and [x]1 where x = ([x]0 + [x]1) mod L, what can an adversary learn from seeing only [x]0?

- Concept: Permutation matrix properties
  - Why needed here: Centaur relies on permutation matrices being orthogonal (ππ⊤ = I) and having factorial search space to protect model parameters
  - Quick check question: Given a permutation matrix π and vector x, what is the relationship between fe(xπ) and fe(x)π for any element-wise function fe?

- Concept: Privacy-preserving matrix multiplication protocols
  - Why needed here: Centaur uses different protocols (ΠScalM ul vs ΠM atM ul) depending on whether one operand is plaintext or both are secret shares
  - Quick check question: Why does ΠScalM ul (plaintext-times-share multiplication) have zero communication overhead while ΠM atM ul (share-times-share multiplication) requires communication?

## Architecture Onboarding

- Component map:
  - Model Developer (P0) -> Cloud Platform (P1) -> Client (P2)
  - Model Developer generates permutation matrices and permutes model parameters
  - Cloud Platform executes privacy-preserving inference using CrypTen framework
  - Client generates secret shares of inference data and reconstructs final results

- Critical path: Client generates shares → Cloud and Model Developer execute privacy-preserving inference → Client reconstructs result

- Design tradeoffs:
  - Privacy vs efficiency: Using permutation for model parameters enables efficient linear layers but requires careful handling of intermediate results
  - Communication vs computation: Converting between secret-sharing and permutation states adds communication rounds but enables efficient nonlinear operations
  - Model compatibility vs performance: Centaur works with any Transformer architecture but requires no modifications to maintain performance

- Failure signatures:
  - Privacy breach: Intermediate results in permuted state can be attacked if conversion protocol is flawed
  - Performance degradation: Incorrect implementation of ΠP P SM/GeLU/LN can lead to wrong results
  - Efficiency loss: Using ΠM atM ul instead of ΠScalM ul for linear layers would significantly increase communication

- First 3 experiments:
  1. Verify permutation matrix properties: Test that fe(Xπ) = fe(X)π holds for Softmax, GeLU, and LayerNorm on small examples
  2. Validate conversion protocol: Test that converting [Xπ] from secret-sharing to permutation state and back preserves the original value
  3. Benchmark communication overhead: Compare ΠScalM ul vs ΠM atM ul on matrix multiplication with varying dimensions to confirm communication-free property

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Centaur's hybrid approach compare to future potential methods that might combine permutation and SMPC in different ways?
- Basis in paper: [explicit] The paper states "It is challenging to break the 'impossible trinity' of privacy, efficiency, and performance in PPTI using a single technique" and proposes Centaur as a solution
- Why unresolved: The paper only evaluates Centaur against existing frameworks, not against theoretical future hybrid approaches
- What evidence would resolve it: Benchmarking Centaur against newer hybrid methods as they are developed, or theoretical analysis of the limits of permutation-SMPC hybrid approaches

### Open Question 2
- Question: Can Centaur's security guarantees hold against more powerful adversaries than the semi-honest model?
- Basis in paper: [explicit] "We assume that all parties follow the protocol as specified and will not deviate from the prescribed steps of the protocol"
- Why unresolved: The paper only proves security under semi-honest assumptions, but real-world adversaries might be malicious
- What evidence would resolve it: Extending Centaur's security proofs to malicious adversaries, or demonstrating vulnerabilities against active attacks

### Open Question 3
- Question: How does Centaur's performance scale with increasingly larger transformer models beyond those tested?
- Basis in paper: [inferred] The experiments test BERTBASE/LARGE and GPT-2BASE/LARGE models, but don't explore extreme scaling
- Why unresolved: The paper doesn't analyze computational complexity or test with frontier-scale models like GPT-4
- What evidence would resolve it: Theoretical scaling analysis and experimental results with trillion-parameter models

## Limitations

- Security proofs are limited to semi-honest adversaries, not covering malicious attacks
- Experimental validation only covers BERTBASE/LARGE and GPT-2BASE/LARGE models, not scaling to larger models
- Claims of plaintext-level accuracy assume underlying models are already optimized for target tasks

## Confidence

- Privacy guarantees: Medium confidence (theoretical proofs exist but no comprehensive end-to-end security analysis)
- Efficiency claims: High confidence (detailed communication complexity analysis and empirical measurements provided)
- Performance claims: High confidence (reported F1 scores demonstrate plaintext-level accuracy)

## Next Checks

1. **End-to-end security analysis**: Conduct a comprehensive security evaluation by attempting to recover model parameters or inference data from intermediate results using state-of-the-art attack methods (gradient-based, reconstruction-based, or model inversion attacks) on the full Centaur pipeline.

2. **Scalability validation**: Implement and benchmark Centaur on larger transformer models (BERTLARGE, GPT-2LARGE, or modern LLMs) to verify that the claimed efficiency improvements (5.0-30.4× speedup) scale proportionally with model size and complexity.

3. **Cross-architecture compatibility**: Test Centaur on transformer architectures beyond BERT and GPT-2 (e.g., RoBERTa, T5, or domain-specific transformers) to validate the claimed compatibility with any Transformer architecture without modifications while maintaining the performance improvements.