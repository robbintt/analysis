---
ver: rpa2
title: Wasserstein Differential Privacy
arxiv_id: '2401.12436'
source_url: https://arxiv.org/abs/2401.12436
tags:
- privacy
- wasserstein
- proof
- proposition
- differential
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Wasserstein Differential Privacy (WDP), a new
  framework that measures privacy leakage risk using Wasserstein distance between
  probability distributions. Unlike existing DP frameworks based on divergence measures,
  WDP satisfies metric properties including symmetry and triangle inequality, enabling
  better theoretical properties and more stable privacy budget accounting.
---

# Wasserstein Differential Privacy

## Quick Facts
- arXiv ID: 2401.12436
- Source URL: https://arxiv.org/abs/2401.12436
- Authors: Chengyi Yang; Jiayin Qi; Aimin Zhou
- Reference count: 40
- Key outcome: Proposes Wasserstein Differential Privacy (WDP) framework that measures privacy leakage using Wasserstein distance, achieving more stable privacy budget accounting and faster deep learning convergence with lower privacy budgets.

## Executive Summary
This paper introduces Wasserstein Differential Privacy (WDP), a novel framework that measures privacy loss using Wasserstein distance between probability distributions instead of traditional divergence measures. The framework satisfies metric properties including symmetry and triangle inequality, enabling superior theoretical properties and more stable privacy budget accounting. The authors develop a Wasserstein accountant applicable to SGD scenarios with subsampling and demonstrate through experiments that WDP produces more stable privacy budgets less influenced by composition order while effectively alleviating overestimation compared to existing frameworks.

## Method Summary
The authors propose WDP as an alternative to traditional differential privacy frameworks by measuring privacy loss through Wasserstein distance rather than divergence measures. They develop a Wasserstein accountant based on the framework's metric properties, implement basic mechanisms (Laplace and Gaussian) under RDP and WDP, and conduct experiments on composition scenarios using synthetic gradients and deep learning tasks on image classification datasets. The framework leverages the triangle inequality property to enable simpler privacy accounting and demonstrates improved stability and reduced overestimation compared to existing approaches.

## Key Results
- WDP satisfies metric properties (symmetry, triangle inequality) enabling superior theoretical foundations
- Privacy budgets obtained through Wasserstein accountant are more stable and less influenced by composition order
- WDP effectively alleviates overestimation of privacy budgets compared to divergence-based frameworks
- Achieves faster convergence in deep learning tasks while requiring lower privacy budgets for the same accuracy levels

## Why This Works (Mechanism)

### Mechanism 1
- Claim: WDP satisfies metric properties enabling superior theoretical properties
- Mechanism: Uses Wasserstein distance (a valid metric) instead of divergence measures
- Core assumption: Wasserstein distance satisfies triangle inequality
- Evidence anchors:
  - [abstract] "WDP satisfies the properties of symmetry and triangle inequality"
  - [section] "WDP satisfies all the conditions to become a metric"
  - [corpus] Weak evidence - corpus neighbors focus on applications but not metric validation

### Mechanism 2
- Claim: WDP enables more stable privacy budget accounting
- Mechanism: Triangle inequality allows simple addition of privacy budgets
- Core assumption: Privacy loss is additive under WDP
- Evidence anchors:
  - [abstract] "privacy budgets obtained by Wasserstein accountant are relatively stable"
  - [section] "basic sequential composition...derived from triangle inequality"
  - [corpus] No direct corpus evidence - novel contribution

### Mechanism 3
- Claim: WDP effectively alleviates overestimation
- Mechanism: Wasserstein distance focuses on individual-level differences
- Core assumption: Individual-level protection is more accurate than distribution-level
- Evidence anchors:
  - [abstract] "overestimation on privacy budgets can be effectively alleviated"
  - [section] "WDP focuses on individuals within the distribution"
  - [corpus] Weak evidence - mentions "Differentially Private Wasserstein Barycenters" but not budget overestimation

## Foundational Learning

- Concept: Wasserstein distance and optimal transport theory
  - Why needed here: Forms mathematical foundation for measuring privacy loss
  - Quick check question: What distinguishes Wasserstein distance from KL divergence?

- Concept: Differential privacy and privacy loss accounting
  - Why needed here: Provides context for existing framework limitations
  - Quick check question: How does composition theorem differ between traditional DP and WDP?

- Concept: Subgaussian distributions and privacy loss moments
  - Why needed here: Critical for advanced composition and privacy accounting
  - Quick check question: Why does assuming subgaussian privacy loss enable tighter bounds?

## Architecture Onboarding

- Component map: Define Wasserstein distance -> Prove metric properties -> Develop privacy mechanisms -> Create accountant -> Validate through experiments
- Critical path: Implement basic mechanisms under RDP/WDP -> Test composition properties -> Develop accountant -> Evaluate on deep learning tasks
- Design tradeoffs: Better theoretical properties vs potential computational overhead
- Failure signatures: Conservative budgets (overestimation), triangle inequality violations, implementation errors in Wasserstein calculations
- First 3 experiments:
  1. Test Laplace mechanism under WDP with varying orders to verify monotonicity
  2. Compare composition privacy budgets between WDP and traditional DP frameworks
  3. Evaluate deep learning convergence speed using WDP vs traditional DP frameworks

## Open Questions the Paper Calls Out

- How does WDP perform with extremely small datasets where individual data points significantly influence the distribution?
- Can the Wasserstein accountant be extended to handle complex privacy scenarios beyond SGD?
- What is the computational complexity of Kummer's confluent hypergeometric function in Lemma 1?
- How sensitive is WDP to the choice of order parameter Î¼ across different data distributions?

## Limitations

- Limited empirical validation against real-world privacy attacks
- Computational overhead of Wasserstein distance calculations not fully characterized
- Practical superiority in real-world applications remains unverified

## Confidence

- **High confidence**: Metric properties (symmetry, triangle inequality) - follow directly from mathematical definitions
- **Medium confidence**: Privacy budget stability and reduced overestimation - supported by experiments but limited to benchmarks
- **Low confidence**: Practical superiority in real-world applications - theoretical advantages not yet validated against sophisticated attacks

## Next Checks

1. Test WDP against membership inference and reconstruction attacks on real-world datasets
2. Benchmark Wasserstein accountant performance against traditional accountants across varying dataset sizes
3. Evaluate WDP privacy guarantees when applied to non-standard distributions with outliers and heavy tails