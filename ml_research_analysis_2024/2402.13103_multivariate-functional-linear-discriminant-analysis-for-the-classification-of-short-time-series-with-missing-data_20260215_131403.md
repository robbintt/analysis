---
ver: rpa2
title: Multivariate Functional Linear Discriminant Analysis for the Classification
  of Short Time Series with Missing Data
arxiv_id: '2402.13103'
source_url: https://arxiv.org/abs/2402.13103
tags:
- data
- time
- algorithm
- missing
- mudra
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a multivariate functional linear discriminant
  analysis algorithm called MUDRA to tackle the challenge of classifying short time
  series with missing data. MUDRA extends FLDA to multivariate and incomplete data
  by modeling observations as a noisy linear combination of spline functions, incorporating
  multiple features.
---

# Multivariate Functional Linear Discriminant Analysis for the Classification of Short Time Series with Missing Data

## Quick Facts
- arXiv ID: 2402.13103
- Source URL: https://arxiv.org/abs/2402.13103
- Reference count: 12
- Introduces MUDRA, a multivariate functional linear discriminant analysis algorithm for classifying short time series with missing data

## Executive Summary
This paper introduces MUDRA (Multivariate Univariate Discriminant Analysis), a novel algorithm that extends functional linear discriminant analysis to handle multivariate time series with missing data. The method models observations as a noisy linear combination of spline functions while incorporating multiple features, using an efficient ECM algorithm for parameter inference. MUDRA generates a low-dimensional representation suitable for both classification and dimension reduction tasks. The authors demonstrate improved performance over state-of-the-art methods, particularly in scenarios with large proportions of missing data, which is especially relevant for medical and psychological datasets where incomplete observations are common.

## Method Summary
MUDRA extends traditional functional linear discriminant analysis (FLDA) to handle multivariate time series with missing data by modeling observations as a linear combination of spline basis functions with added noise. The method uses an Expectation-Conditional Maximization (ECM) algorithm to iteratively estimate model parameters while handling incomplete observations. The approach projects high-dimensional time series into a lower-dimensional functional space where linear discriminant analysis can be effectively applied. This framework allows for simultaneous classification and dimension reduction while accommodating the challenges posed by missing data patterns commonly found in real-world applications.

## Key Results
- MUDRA consistently outperforms ROCKET for both low and high dimensionality when dealing with large amounts of missing data
- The algorithm shows particular effectiveness on the "Articulary Word Recognition" dataset with missing values
- Performance improvements are most pronounced in medical and psychological datasets where missing data is prevalent

## Why This Works (Mechanism)
Assumption: The effectiveness of MUDRA stems from its ability to model multivariate time series as smooth functional representations through spline basis expansions. By projecting high-dimensional observations into a lower-dimensional functional space, the method preserves essential discriminatory information while reducing noise and computational complexity. The ECM algorithm's iterative approach allows for robust parameter estimation even with incomplete data, effectively handling missing values during both the imputation and classification phases. This dual capability of simultaneous imputation and classification appears to be particularly advantageous when dealing with large proportions of missing data, where traditional methods struggle to maintain performance.

## Foundational Learning
- **Functional Data Analysis**: Needed to understand how continuous functions can be represented and analyzed as data points; quick check: verify understanding of basis function expansions
- **Expectation-Conditional Maximization (ECM)**: Required for parameter estimation in the presence of missing data; quick check: confirm understanding of ECM vs EM algorithm differences
- **Spline Functions**: Essential for modeling smooth functional representations of time series; quick check: ensure familiarity with spline basis properties and regularization
- **Linear Discriminant Analysis**: Core classification framework being extended; quick check: verify understanding of Fisher's discriminant criterion

## Architecture Onboarding
- **Component Map**: Data -> Spline Basis Expansion -> ECM Parameter Estimation -> Low-dimensional Projection -> Classification
- **Critical Path**: Missing data imputation through spline modeling → Parameter estimation via ECM → Discriminant analysis in functional space
- **Design Tradeoffs**: Flexibility of spline functions vs computational complexity; dimensionality reduction vs information preservation; handling missing data vs model simplicity
- **Failure Signatures**: Poor performance with non-smooth signals; sensitivity to spline basis selection; potential overfitting with high-dimensional features
- **First Experiments**: 1) Test on synthetic data with controlled missingness patterns, 2) Compare performance across different spline basis functions, 3) Evaluate sensitivity to missing data mechanisms (MCAR vs MAR)

## Open Questions the Paper Calls Out
Unknown: The paper does not explicitly identify open questions, but several areas warrant further investigation: 1) How does MUDRA perform on datasets with different types of missing data mechanisms beyond MCAR? 2) What is the impact of choosing different spline basis functions on classification performance? 3) Can the method be extended to handle irregularly sampled time series data?

## Limitations
- Evaluation is limited to only two datasets (synthetic and one speech dataset), restricting generalizability
- Comparison methods don't cover the full spectrum of time series classification approaches
- The synthetic data generation process may not reflect typical real-world missing data scenarios
- Limited discussion of computational complexity and scalability to larger datasets
- No sensitivity analysis for different spline basis functions or regularization parameters

## Confidence
- **High confidence**: Mathematical formulation and ECM algorithm description
- **Medium confidence**: Performance claims relative to baseline methods
- **Medium confidence**: Practical utility for medical and psychological applications

## Next Checks
1. Evaluate MUDRA on additional real-world datasets with varying levels of missingness and different data characteristics
2. Compare MUDRA against a broader range of time series classification methods, including deep learning approaches that handle missing data
3. Conduct sensitivity analysis to assess MUDRA's performance across different missing data mechanisms (MCAR, MAR, MNAR) and missingness proportions
4. Investigate computational complexity and scalability to larger datasets
5. Evaluate the impact of different spline basis functions on classification performance