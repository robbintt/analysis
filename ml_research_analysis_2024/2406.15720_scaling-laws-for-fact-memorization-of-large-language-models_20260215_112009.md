---
ver: rpa2
title: Scaling Laws for Fact Memorization of Large Language Models
arxiv_id: '2406.15720'
source_url: https://arxiv.org/abs/2406.15720
tags: []
core_contribution: This paper analyzes the scaling laws and behaviors of fact memorization
  in large language models (LLMs). The authors define fact memorization as a triple-value
  prediction task and quantify memorization rates using exact match.
---

# Scaling Laws for Fact Memorization of Large Language Models

## Quick Facts
- arXiv ID: 2406.15720
- Source URL: https://arxiv.org/abs/2406.15720
- Authors: Xingyu Lu, Xiaonan Li, Qinyuan Cheng, Kai Ding, Xuanjing Huang, Xipeng Qiu
- Reference count: 32
- One-line primary result: LLMs' fact memorization capacity scales linearly with model size and follows a negative exponential law with training epochs.

## Executive Summary
This paper analyzes the scaling laws and behaviors of fact memorization in large language models (LLMs). The authors define fact memorization as a triple-value prediction task and quantify memorization rates using exact match. They find that LLMs' fact capacity scales linearly with model size and follows a negative exponential law with training epochs. To memorize all Wikidata facts, a model with 1000B non-embed parameters trained for 100 epochs would be required, which is impractical. The study also reveals that LLMs struggle to efficiently memorize redundant facts unless they have the same direction and structure, and they show a preference for memorizing more frequent and difficult facts. Additionally, the authors find that LLMs can generalize on unseen fact knowledge, with generalization scaling laws similar to general pre-training.

## Method Summary
The authors train LLMs to predict values given key-attribute pairs using cross-entropy loss on datasets of atomic fact triples. They evaluate memorization rates using exact match accuracy and analyze scaling laws with model size, training epochs, and different types of facts. Experiments are conducted on controlled datasets of company information and Wikidata triples to isolate the effects of model size, redundancy, preference, and generalization on fact memorization.

## Key Results
- Fact capacity scales linearly with model size and follows a negative exponential law with training epochs.
- LLMs struggle to efficiently memorize redundant facts unless they have the same direction and structure.
- LLMs show a preference for memorizing more frequent and difficult facts, and subsequent facts can overwrite prior ones.
- LLMs can generalize on unseen fact knowledge, with generalization scaling laws similar to general pre-training.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fact memorization capacity in LLMs scales linearly with model size and follows a negative exponential law with training epochs.
- Mechanism: Larger models have more parameters to store distinct fact triples, while more training epochs allow the model to consolidate fact representations until saturation.
- Core assumption: Facts are atomic, distinct units and can be encoded independently in model parameters.
- Evidence anchors:
  - [abstract] "LLMs' fact knowledge capacity has a linear and negative exponential law relationship with model size and training epochs, respectively."
  - [section] "We find that LLM's fact capacity linearly scales with its size under the same training epochs."
  - [corpus] The corpus neighbor "A Fictional Q&A Dataset for Studying Memorization and Knowledge Acquisition" supports that memorization can be studied at the atomic fact level, aligning with this paper's approach.
- Break condition: If facts are highly correlated or derivable, the linear scaling assumption breaks down due to interference and redundancy.

### Mechanism 2
- Claim: LLMs prefer to memorize more frequent and difficult facts, and subsequent facts overwrite prior facts.
- Mechanism: During training, repeated exposure to frequent facts strengthens their representations, while difficult facts may require more attention to encode. Later training examples can overwrite earlier ones if not sufficiently reinforced.
- Core assumption: Training data is presented in a sequential manner with variable frequencies.
- Evidence anchors:
  - [abstract] "For preference, the LLM pays more attention to memorizing more frequent and difficult facts, and the subsequent facts can overwrite prior facts' memorization."
  - [section] "We find that LLMs pay more attention to memorizing more frequent and difficult facts."
  - [corpus] The corpus neighbor "Injecting New Knowledge into Large Language Models via Supervised Fine-Tuning" implies that knowledge injection can be overwritten, supporting the overwrite claim.
- Break condition: If training data is shuffled or balanced, the overwrite effect may diminish.

### Mechanism 3
- Claim: LLMs can generalize on unseen fact knowledge based on the correlation between input (key) and output (value).
- Mechanism: When there is a strong correlation between keys and values in training facts, the model can learn a mapping function that generalizes to unseen keys with similar patterns.
- Core assumption: Fact knowledge contains predictable patterns that can be abstracted beyond exact memorization.
- Evidence anchors:
  - [abstract] "Meanwhile, we find that LLMs can generalize on unseen fact knowledge and its scaling law is similar to general pre-training."
  - [section] "We observe that facts on most of the attributes have a generalization accuracy greater than zero, which indicates that LLMs can generalize on unseen fact knowledge to a certain level."
  - [corpus] The corpus neighbor "Meaningful Learning: Enhancing Abstract Reasoning in Large Language Models via Generic Fact Guidance" suggests that LLMs can leverage generic facts for reasoning, supporting the generalization mechanism.
- Break condition: If facts are purely random or have no correlation between keys and values, generalization will fail.

## Foundational Learning

- Concept: Exact match evaluation for fact memorization
  - Why needed here: To accurately quantify whether the LLM has fully memorized a specific fact triple.
  - Quick check question: What metric is used to evaluate fact memorization in this paper?

- Concept: Negative exponential scaling law
  - Why needed here: To model how fact capacity saturates with increasing training epochs.
  - Quick check question: What type of function is used to fit the relationship between fact capacity and training epochs?

- Concept: Redundancy in fact knowledge
  - Why needed here: To understand how correlated or derivable facts impact memorization efficiency.
  - Quick check question: What are the three types of redundant facts analyzed in the paper?

## Architecture Onboarding

- Component map: LLM architecture (Qwen-1.5) → Fact memorization training loop → Evaluation (exact match) → Analysis (scaling laws, redundancy, preference, generalization)
- Critical path: Model initialization → Fact triple generation → Training with cross-entropy loss → Memorization rate calculation → Scaling law fitting
- Design tradeoffs: Using atomic fact triples simplifies memorization analysis but may not capture the full complexity of real-world unstructured text.
- Failure signatures: Low memorization rates indicate insufficient model capacity or training epochs; inconsistent generalization suggests weak key-value correlations.
- First 3 experiments:
  1. Measure memorization rate vs. number of training facts to identify capacity limits.
  2. Compare memorization of forward vs. reverse fact directions to test compatibility.
  3. Analyze memorization preference by varying fact frequencies and difficulties.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LLMs memorize facts with different formats (e.g., different templates, natural language descriptions) as effectively as with standardized templates?
- Basis in paper: [explicit] The paper notes that using various numbers of templates leads to consistent results, but does not explore memorization of facts described in different natural language formats.
- Why unresolved: The experiments use a single template per attribute for simplicity, leaving open whether the LLM's fact memorization generalizes to facts described in diverse natural language formats.
- What evidence would resolve it: Experiments comparing memorization rates of facts described with multiple natural language templates versus a single standardized template.

### Open Question 2
- Question: How does the presence of redundant facts in the pre-training corpus affect the LLM's ability to memorize and retrieve factual knowledge?
- Basis in paper: [explicit] The paper discusses LLMs' struggles with efficiently memorizing redundant facts, but does not explore the impact of redundant facts in pre-training on memorization and retrieval.
- Why unresolved: The experiments use controlled datasets without redundancy to isolate the effects of redundancy on memorization. The impact of redundant facts in pre-training is not investigated.
- What evidence would resolve it: Experiments training LLMs on pre-training corpora with varying levels of redundant facts and evaluating their fact memorization and retrieval performance.

### Open Question 3
- Question: Can LLMs generalize on unseen fact knowledge beyond the types of facts they were trained on?
- Basis in paper: [explicit] The paper shows that LLMs can generalize on unseen facts of the same types they were trained on, but does not explore generalization to completely new types of facts.
- Why unresolved: The experiments focus on generalization within the same attribute types used in training. The ability to generalize to novel fact types is not investigated.
- What evidence would resolve it: Experiments training LLMs on a subset of fact types and evaluating their ability to generalize to completely unseen fact types.

## Limitations
- The controlled experimental setup using atomic fact triples may not fully capture how LLMs memorize facts in real-world applications where facts are embedded within complex, contextual narratives.
- The assumption that facts are independent units may not hold in practice, as facts often have dependencies and correlations that could affect scaling behavior.
- The focus on exact match accuracy as the sole metric for memorization may not generalize to scenarios where approximate or contextually relevant knowledge retrieval is acceptable.

## Confidence
- **High Confidence**: The finding that fact capacity scales linearly with model size and follows a negative exponential law with training epochs is well-supported by experimental evidence and aligns with general scaling law observations in LLMs.
- **Medium Confidence**: The observation that LLMs prefer to memorize frequent and difficult facts, and that subsequent facts can overwrite prior ones, is plausible but depends on specific training data characteristics and presentation order.
- **Medium Confidence**: The claim that LLMs can generalize on unseen fact knowledge is supported by the experiments, but the extent and practical utility of this generalization require further validation.

## Next Checks
1. Test the independence assumption: Conduct experiments where facts have varying degrees of correlation and redundancy to validate whether the linear scaling law holds under realistic conditions with correlated facts.
2. Validate generalization beyond exact match: Evaluate the practical utility of fact generalization by testing whether the model can apply generalized knowledge to tasks that require reasoning or inference, rather than just exact recall.
3. Compare memorization in structured vs. unstructured text: Replicate the memorization experiments using naturally occurring text (e.g., Wikipedia passages) to assess how well the controlled findings translate to real-world scenarios where facts are embedded in context.