---
ver: rpa2
title: 'Distal Interference: Exploring the Limits of Model-Based Continual Learning'
arxiv_id: '2402.08255'
source_url: https://arxiv.org/abs/2402.08255
tags:
- interference
- function
- learning
- distal
- trainable
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper explores how catastrophic interference in continual\
  \ learning is driven by non-local parameter updates across distant input points\u2014\
  a phenomenon termed distal interference. It proves that models robust to such interference\
  \ must have exponentially large parameter spaces if they are both uniformly trainable\
  \ and max-distal orthogonal."
---

# Distal Interference: Exploring the Limits of Model-Based Continual Learning

## Quick Facts
- arXiv ID: 2402.08255
- Source URL: https://arxiv.org/abs/2402.08255
- Authors: Heinrich van Deventer; Anna Sergeevna Bosman
- Reference count: 18
- Primary result: Models robust to distal interference require exponential complexity; ABEL-Splines achieve polynomial complexity with min-distal orthogonality

## Executive Summary
This paper introduces distal interference as a fundamental limitation in continual learning, where parameter updates on one input point affect predictions at distant points, causing catastrophic forgetting. The authors prove that models with strong guarantees against this interference must have exponentially large parameter spaces. To address this, they propose ABEL-Splines, a novel architecture combining sparse B-spline bases with antisymmetric exponential layers that achieves universal approximation with only polynomial complexity. Experiments show ABEL-Splines have bounded gradients and zero min-distal interference, but still suffer catastrophic forgetting without data augmentation, leading to the conjecture that polynomial models need augmented training for effective continual learning.

## Method Summary
The paper proposes ABEL-Splines, a neural network architecture designed to minimize distal interference while maintaining polynomial complexity. It combines B-spline basis functions with a novel antisymmetric bounded exponential layer. The architecture uses z-density B-spline bases that partition input space into cardinal regions, with each region assigned to specific neurons. The antisymmetric bounded exponential layer uses K=6 terms with k⁻² scaling to ensure bounded outputs. The model is trained on synthetic 2D regression data (sin(4πx₁)·sin(4πx₂)) partitioned into 16 regions, with optional pseudo-rehearsal augmentation combining current data with model-sampled pseudo-samples.

## Key Results
- Proved that max-distal orthogonal models require exponential complexity in parameter space
- ABEL-Splines achieve zero min-distal interference while maintaining polynomial complexity
- ABEL-Splines successfully approximate complex 2D functions with smooth checkered patterns
- Without data augmentation, ABEL-Splines still experience catastrophic interference in sequential learning tasks

## Why This Works (Mechanism)
Distal interference occurs when parameter updates for one input point affect predictions at distant points in input space. This happens because standard neural networks have dense parameter coupling across the entire input domain. ABEL-Splines mitigate this by using sparse B-spline bases that localize parameter influence to specific regions, combined with antisymmetric exponential layers that ensure bounded outputs and minimize cross-region interference. The z-density basis functions create a partition of unity where each input point is influenced by only a small number of basis functions, limiting how far parameter updates can propagate.

## Foundational Learning
**Continual Learning**: Learning sequential tasks without forgetting previous ones. Needed to understand the problem context of catastrophic forgetting.
Quick check: Can you explain why sequential training on disjoint tasks causes performance degradation?

**Catastrophic Interference**: When learning new tasks disrupts previously learned knowledge. Central to understanding why distal interference matters.
Quick check: What's the difference between catastrophic interference and catastrophic forgetting?

**Distal Interference**: Parameter updates affecting distant input points. The core phenomenon this paper analyzes.
Quick check: How does distal interference differ from local gradient effects?

**Universal Approximation**: Ability to approximate any continuous function. Critical for evaluating whether ABEL-Splines maintain sufficient expressive power.
Quick check: What conditions must a neural network satisfy to be a universal approximator?

**Orthogonality in Parameter Space**: Minimizing correlation between parameter updates across different regions. Key to understanding the theoretical bounds.
Quick check: Why would orthogonal parameter updates help with continual learning?

## Architecture Onboarding

**Component Map**: Input → z-density B-spline basis functions → Antisymmetric bounded exponential layers → Output

**Critical Path**: The combination of z-density B-splines with the antisymmetric bounded exponential layer creates the min-distal orthogonality property while maintaining universal approximation.

**Design Tradeoffs**: 
- B-splines provide localization but limit smoothness across regions
- Antisymmetric exponential layers ensure bounded outputs but add computational complexity
- Polynomial complexity achieved at the cost of potentially weaker interference guarantees than exponential models

**Failure Signatures**:
- z-Spline ANNs failing to approximate target function (check for expected smooth checkered pattern)
- Catastrophic interference in sequential learning (significant performance drop across tasks)
- Gradients that don't remain bounded (indicates violation of antisymmetry assumptions)

**First Experiments**:
1. Train z-Spline ANN on synthetic 2D data and verify smooth checkered pattern output
2. Compare model perturbation between ReLU ANN and ABEL-Spline during sequential training
3. Measure distal interference using Monte Carlo integration for both architectures

## Open Questions the Paper Calls Out

**Open Question 1**: Can polynomial complexity models with augmented training (data or algorithms) achieve effective continual learning without exponential complexity?
The paper concludes that "continual learning with a polynomial complexity model trained with gradient descent requires augmentation of data or training procedures." While showing ABEL-Splines fail without augmentation, it doesn't definitively prove augmentation is necessary for all polynomial models or explore the full space of possible augmentations.

**Open Question 2**: What is the minimal level of distal orthogonality (between min and max) required for effective continual learning in polynomial complexity models?
The paper notes that "min-distal orthogonality is too weak to substantially improve model-only continual learning" while max-distal orthogonality requires exponential complexity, but doesn't explore intermediate forms of orthogonality or their relationship to continual learning performance.

**Open Question 3**: How does the geometry of parameter updates (distal interference) in neural networks relate to other known failure modes like vanishing gradients or exploding gradients?
The paper introduces distal interference as a novel explanatory mechanism and notes that "Finite precision and optimisers that modify update vectors can violate orthogonality assumptions," but doesn't comprehensively analyze how it interacts with other optimization pathologies.

## Limitations
- Theoretical results rely on strong assumptions about uniform trainability and max-distal orthogonality
- ABEL-Spline effectiveness limited to synthetic regression tasks, not tested on real-world datasets
- Conjecture about polynomial models requiring augmented training remains unproven and may depend heavily on task partitioning

## Confidence
- High confidence in theoretical lower bounds for max-distal orthogonal networks
- Medium confidence in practical effectiveness of ABEL-Splines for synthetic regression tasks
- Low confidence in general applicability of conjecture to real-world continual learning scenarios

## Next Checks
1. Test ABEL-Splines on real-world sequential learning benchmarks (e.g., split CIFAR, Split Mini-ImageNet) to evaluate generalization beyond synthetic data
2. Experimentally validate the conjecture by testing polynomial models with varying degrees on tasks requiring different levels of interference resistance
3. Investigate sensitivity of results to different partition schemes and task boundaries in the synthetic 2D regression setup