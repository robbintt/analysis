---
ver: rpa2
title: Block-As-Domain Adaptation for Workload Prediction from fNIRS Data
arxiv_id: '2405.00213'
source_url: https://arxiv.org/abs/2405.00213
tags:
- data
- different
- fnirs
- same
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of classifying cognitive workload
  levels from fNIRS brain signals across different subjects and sessions, a task complicated
  by high inter-subject and intra-subject variability. The authors propose a novel
  method called Class-Aware Block-Aware Domain Adaptation (CABA-DA) that treats different
  blocks from the same session/subject as separate domains, minimizing intra-class
  domain discrepancy and maximizing inter-class domain discrepancy.
---

# Block-As-Domain Adaptation for Workload Prediction from fNIRS Data

## Quick Facts
- arXiv ID: 2405.00213
- Source URL: https://arxiv.org/abs/2405.00213
- Reference count: 40
- Primary result: MLPMixer with Class-Aware Block-Aware Domain Adaptation (CABA-DA) improves cross-subject fNIRS workload classification accuracy by 0.58%-4.43% over baselines

## Executive Summary
This paper addresses the challenge of classifying cognitive workload levels from fNIRS brain signals across different subjects and sessions. The authors propose a novel method called Class-Aware Block-Aware Domain Adaptation (CABA-DA) that treats different blocks from the same session/subject as separate domains, minimizing intra-class domain discrepancy while maximizing inter-class domain discrepancy. They introduce a new MLPMixer-based architecture adapted for fNIRS data, replacing CNNs to better capture the interconnected nature of brain regions. Experiments on three public datasets show that the proposed method outperforms three baseline models, with accuracy improvements ranging from 0.58% to 4.43% across tasks and datasets.

## Method Summary
The paper proposes an MLPMixer-based classifier with Class-Aware Block-Aware Domain Adaptation (CABA-DA) for cognitive workload classification from fNIRS data. The method treats different blocks from the same session/subject as separate domains and uses a combination of contrastive learning methods to minimize intra-class domain discrepancy and maximize inter-class domain discrepancy. The MLPMixer architecture processes the entire spatial dimension as a single token and performs mixing along temporal and channel dimensions, avoiding the spatial invariance assumptions of CNNs. The model is trained with cross-entropy loss plus domain adaptation terms using Adam optimizer, with α parameter tuned via grid search.

## Key Results
- MLPMixer baseline outperforms CNN-based baselines (DeepConv, EEGNet) by 0.58%-4.43% on three datasets
- CABA-DA consistently improves performance across different classifier types (CNNs, RNNs, MLPs)
- Block-aware domain adaptation is more effective than subject/session-only domain adaptation for cross-subject generalization
- The proposed method achieves mean accuracy improvements of 1.71%-4.43% on TUberlin dataset across different tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Treating different blocks from the same subject/session as separate domains reduces intra-class variance more effectively than treating only subjects or sessions as domains.
- Mechanism: By explicitly minimizing the distance between samples from different blocks of the same class (using the CABA term), the model learns features that are invariant to block-level variability while preserving class-discriminative information.
- Core assumption: Block-level variations in fNIRS data introduce variance comparable to subject or session-level variations.
- Evidence anchors:
  - [abstract] "we propose a block-aware loss to also align samples across different blocks to improve the generalization of models."
  - [section] "the performance of the models is also significantly affected by the intra-subject variance across different blocks...This variability is as influential as the variability of new sessions, as well as new subjects."
  - [corpus] No direct evidence found; assumption based on paper's experimental results.
- Break condition: If block-level variance is actually smaller than subject/session variance, this approach would overfit to noise and hurt generalization.

### Mechanism 2
- Claim: MLPMixer architecture outperforms CNNs for fNIRS workload classification because it avoids the parameter-sharing assumption that doesn't hold for brain signal data.
- Mechanism: MLPMixer processes the entire spatial dimension as a single token and performs mixing along temporal and channel dimensions, better capturing the interconnected nature of brain regions without assuming spatial invariance.
- Core assumption: Brain workload patterns depend on specific, interconnected brain areas rather than spatially invariant features.
- Evidence anchors:
  - [abstract] "we propose an MLPMixer-based model for cognitive load classification...instead of using CNNs...the parameter sharing aspect of CNNs is based on the assumption that a valid patch of weights working for one position also works for other regions."
  - [section] "the assumption of CNNs that a patch of weights learnt from one spatial or temporal position can be used in another region does not always hold."
  - [corpus] No direct evidence found; assumption based on paper's architectural reasoning.
- Break condition: If fNIRS workload patterns actually exhibit spatial invariance, CNNs would outperform MLPMixer.

### Mechanism 3
- Claim: The combination of CABA-DA with MLPMixer provides better generalization than either component alone because CABA-DA addresses block-level variance while MLPMixer handles the spatial structure of fNIRS data appropriately.
- Mechanism: CABA-DA reduces block-level domain shift while MLPMixer extracts features that respect the interconnected nature of brain regions, resulting in complementary improvements.
- Core assumption: Both block-level variance and inappropriate spatial assumptions are significant contributors to poor cross-subject generalization.
- Evidence anchors:
  - [abstract] "Experimental results demonstrate the proposed model has better performance compared with three different baseline models on three public-available datasets"
  - [section] "Our experimental results have shown that MLPMixer as the baseline model...has achieved a significant improvement...Our proposed CABA-DA has consistently enhanced the performance of three out of four models"
  - [corpus] No direct evidence found; assumption based on paper's combined results.
- Break condition: If either block-level variance or spatial assumptions are not significant contributors, the combined approach would provide no additional benefit over addressing just one issue.

## Foundational Learning

- Concept: Domain adaptation and domain discrepancy measures
  - Why needed here: The paper treats different blocks as domains and uses discrepancy measures to align them, which requires understanding how domain adaptation works
  - Quick check question: What is the difference between MMD and CDD in measuring domain discrepancy?

- Concept: fNIRS signal characteristics and preprocessing
  - Why needed here: Understanding how fNIRS data is collected, filtered, and structured is crucial for implementing the model correctly
  - Quick check question: What are the typical sampling rates and filtering approaches for fNIRS data in cognitive workload studies?

- Concept: MLPMixer architecture and modifications
  - Why needed here: The paper modifies MLPMixer for fNIRS data by projecting the entire spatial dimension to a token, which requires understanding the original architecture
  - Quick check question: How does the original MLPMixer process image patches differently from how this paper processes fNIRS channels?

## Architecture Onboarding

- Component map: Input (2×T×D) → FC layer (spatial projection) → N Mixer layers (temporal-mixing MLP + channel-mixing MLP) → Global average pooling → Classifier, with domain adaptation losses computed between mini-batches

- Critical path: Input → FC layer → Mixer layers → Global average pooling → Classifier, with domain adaptation losses computed between mini-batches

- Design tradeoffs:
  - Using MLPMixer instead of CNN trades spatial locality assumptions for parameter efficiency
  - Treating blocks as domains increases computational cost during training but not inference
  - The CABA term specifically addresses block variance but may overfit if block variance is not significant

- Failure signatures:
  - Accuracy doesn't improve when switching from subject/session DA to block DA
  - Model performs well on same-subject same-session data but poorly on cross-subject data
  - Training loss decreases but validation loss plateaus or increases

- First 3 experiments:
  1. Train MLPMixer with only cross-entropy loss on TUberlin dataset and compare to DeepConv baseline
  2. Add CABA-DA to MLPMixer and measure improvement on TUberlin dataset
  3. Test the trained model on a held-out subject to verify cross-subject generalization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different block-wise domain adaptation approaches compare to subject-wise and session-wise domain adaptation in terms of computational efficiency and practical implementation in real-time BCI systems?
- Basis in paper: [explicit] The paper discusses the proposed CABA-DA method which treats different blocks from the same session/subject as separate domains, and mentions that the computational cost at inference is minimal, but doesn't provide detailed comparison with other domain adaptation methods.
- Why unresolved: The paper only mentions that CABA-DA doesn't add extra modules to networks and that the computational cost is minimal, but doesn't provide a comprehensive comparison of computational efficiency between different domain adaptation approaches.
- What evidence would resolve it: Detailed computational analysis and comparison of different domain adaptation approaches (block-wise, subject-wise, session-wise) in terms of training time, inference time, and memory requirements, along with their impact on real-time BCI system performance.

### Open Question 2
- Question: What are the optimal window sizes and sliding step sizes for fNIRS data preprocessing that maximize classification accuracy across different cognitive workload tasks?
- Basis in paper: [explicit] The paper mentions that they used different window sizes for different datasets (2 seconds for TUBerlin, 10 seconds for FFT, 15 seconds for Tufts) but doesn't explore the impact of different window sizes on classification performance.
- Why unresolved: The paper doesn't provide a systematic analysis of how different window sizes and sliding step sizes affect classification accuracy across different cognitive workload tasks.
- What evidence would resolve it: Comprehensive experiments varying window sizes and sliding step sizes across multiple cognitive workload tasks, with detailed analysis of the trade-offs between temporal resolution and classification accuracy.

### Open Question 3
- Question: How does the proposed MLPMixer architecture perform on other types of brain signal data (e.g., EEG, MEG) compared to traditional CNN and RNN-based architectures?
- Basis in paper: [explicit] The paper proposes an MLPMixer-based model adapted for fNIRS data and compares it with CNN and RNN-based baselines on fNIRS data, but doesn't explore its performance on other types of brain signal data.
- Why unresolved: The paper only evaluates the MLPMixer architecture on fNIRS data and doesn't investigate its generalizability to other brain signal modalities.
- What evidence would resolve it: Systematic evaluation of the proposed MLPMixer architecture on multiple brain signal modalities (e.g., EEG, MEG) compared to traditional CNN and RNN-based architectures, with analysis of performance differences across modalities.

## Limitations
- Performance improvements (0.58%-4.43%) are modest but consistent, suggesting the method is robust but not transformative
- Core innovation of treating blocks as domains relies on assumption that block-level variance is significant, which is stated but not empirically validated against other sources of variance
- MLPMixer architecture choice is justified theoretically but lacks direct empirical comparison with CNN ablations on the same datasets

## Confidence

**High:** The experimental methodology (k-fold cross-subject validation) is sound and the results are statistically meaningful

**Medium:** The CABA-DA mechanism appears to work as described, but the relative contribution of block-aware vs class-aware components is unclear

**Low:** The assumption that MLPMixer is inherently superior to CNNs for fNIRS data is plausible but not rigorously tested

## Next Checks

1. Conduct ablation studies comparing CABA-DA with block-aware only, class-aware only, and subject/session-only domain adaptation to isolate which component drives performance

2. Test the model on datasets with different block durations to verify the assumption about block-level variance significance

3. Implement CNN ablations with varying receptive fields and spatial assumptions to directly test the MLPMixer architecture claims