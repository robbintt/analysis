---
ver: rpa2
title: Probing the Category of Verbal Aspect in Transformer Language Models
arxiv_id: '2406.02335'
source_url: https://arxiv.org/abs/2406.02335
tags:
- aspect
- contexts
- probing
- verb
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how transformer language models encode
  the grammatical category of verbal aspect in Russian. Aspect, which expresses how
  an action extends over time, is challenging to encode due to its tight connection
  with verb semantics and the existence of "alternative contexts" where both perfective
  and imperfective forms are grammatically acceptable.
---

# Probing the Category of Verbal Aspect in Transformer Language Models

## Quick Facts
- **arXiv ID**: 2406.02335
- **Source URL**: https://arxiv.org/abs/2406.02335
- **Reference count**: 39
- **Primary result**: Transformer models encode verbal aspect predominantly in final layers, with boundedness interventions affecting aspect predictions predictably

## Executive Summary
This paper investigates how transformer language models encode the grammatical category of verbal aspect in Russian, focusing on BERT and RoBERTa models. Aspect expresses how actions extend over time and presents unique challenges due to its connection with verb semantics and the existence of alternative contexts where both perfective and imperfective forms are grammatically acceptable. The authors employ two probing methods: behavioral probing to evaluate model predictions of aspect forms, and causal probing to intervene in model representations and observe effects on aspect prediction. Experiments reveal that aspect encoding is concentrated in the final layers of these models, and interventions targeting the semantic feature of "boundedness" produce effects consistent with linguistic theory—perfective forms are positively affected by boundedness while imperfective forms are negatively affected.

## Method Summary
The authors conducted behavioral probing using iterative masking and aspect inference to evaluate how well transformer models predict aspect forms in context. They also performed causal probing by manipulating contextual representations to isolate the effect of the semantic feature "boundedness" on aspect prediction, using Iterative Null-space Projection (INLP) to generate counterfactual representations. The study examined Russian BERT-base, BERT-large, and RoBERTa-large models across datasets containing alternative and non-alternative contexts with aspect pairs. Additionally, they fine-tuned BERT for aspect prediction to assess the effectiveness of training on different model layers. The analysis focused on identifying where in the model architecture aspect information is encoded and how interventions in semantic representations affect aspect predictions.

## Key Results
- Transformer models (BERT and RoBERTa) encode aspect information predominantly in their final layers
- Fine-tuning only the final layers of BERT for aspect prediction yields improved performance and faster convergence
- Models exhibit high uncertainty about aspect in alternative contexts, where both perfective and imperfective forms are grammatically acceptable
- Causal interventions affecting boundedness produce effects consistent with linguistic theory: perfective is positively affected by boundedness, while imperfective is negatively affected

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformer language models encode the grammatical category of verbal aspect predominantly in their final layers.
- Mechanism: The model's capacity to differentiate between perfective and imperfective aspect forms emerges after several intermediate layers and peaks in the final layers. Early layers process lower-level linguistic features while later layers capture higher-level semantic distinctions like aspect.
- Core assumption: Aspect encoding is a complex semantic task that requires integrating information across the full context, which necessitates deeper layers for full development.
- Evidence anchors:
  - [abstract]: "Experiments show that BERT and RoBERTa do encode aspect—mostly in their final layers."
  - [section]: "Fine-tuning only the final layers of BERT for aspect prediction results in improved performance, confirming our first finding."

### Mechanism 2
- Claim: Interventions in sentence semantics cause effects consistent with linguistic theory of aspect: shifting representations toward "bounded" space positively affects prediction of perfective forms.
- Mechanism: By manipulating the semantic feature of "boundedness" in contextual representations, the model's predictions about aspect shift predictably. Bounded actions align with perfective aspect while unbounded actions align with imperfective aspect.
- Core assumption: The boundedness feature is a fundamental semantic dimension that directly influences aspect choice, and this relationship is captured in the model's learned representations.
- Evidence anchors:
  - [abstract]: "The counterfactual interventions affect perfective and imperfective in opposite ways, which is consistent with grammar: perfective is positively affected by adding the meaning of boundedness, and vice versa."
  - [section]: "Shifting representations toward the 'bounded' sub-space improves the predictions of imperfective aspect and significantly increases the error in predictions of perfective aspect; moving representations in the opposite direction of the 'bounded' sub-space has the opposite effect."

### Mechanism 3
- Claim: Models exhibit high uncertainty about aspect in alternative contexts where multiple aspect forms are grammatically and semantically acceptable.
- Mechanism: When both perfective and imperfective forms fit the context equally well, the model cannot confidently prefer one aspect over the other, resulting in high predictive variance.
- Core assumption: The absence of explicit semantic cues (like cue words indicating boundedness) makes aspect prediction inherently uncertain, both for humans and models.
- Evidence anchors:
  - [abstract]: "The model has high predictive uncertainty about aspect in alternative contexts, which tend to lack explicit hints about the boundedness of the described action."
  - [section]: "BERT is consistently uncertain about aspect forms in alternative contexts. Causal interventions also have a stronger effect in such contexts."

## Foundational Learning

- Concept: Semantic feature manipulation through counterfactual interventions
  - Why needed here: To test whether specific semantic features (boundedness) causally influence aspect prediction
  - Quick check question: What happens to aspect prediction when you shift context representations toward "bounded" vs "unbounded" semantic spaces?

- Concept: Masked Language Model probing techniques
  - Why needed here: To evaluate how well models predict aspect forms in context without additional classifiers
  - Quick check question: How does iterative masking differ from aspect inference in evaluating aspect prediction?

- Concept: Linear information removal via Iterative Null-space Projection (INLP)
  - Why needed here: To create counterfactual representations that isolate the effect of boundedness on aspect prediction
  - Quick check question: What is the purpose of training multiple orthogonal classifiers in the INLP method?

## Architecture Onboarding

- Component map: Context -> Token embeddings -> Transformer layers -> Final layer representations -> Aspect prediction head -> Evaluation metrics
- Critical path: Context -> Token embeddings -> Transformer layers -> Final layer representations -> Aspect prediction
- Design tradeoffs: Fine-tuning entire model vs. only final layers (speed vs. potential performance)
- Failure signatures: High uncertainty in alternative contexts, minimal performance improvement after fine-tuning middle layers
- First 3 experiments:
  1. Compare aspect prediction accuracy using iterative masking vs. aspect inference across all layers
  2. Apply INLP interventions at different layers and measure changes in aspect prediction accuracy
  3. Fine-tune only final layers vs. entire model and compare convergence speed and performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific linguistic features beyond boundedness influence the choice of aspect in Russian, particularly in alternative contexts where both perfective and imperfective forms are grammatically acceptable?
- Basis in paper: [inferred] The paper notes that alternative contexts often lack explicit hints about the boundedness of the described action, and the model has high predictive uncertainty in these contexts. It also mentions that other types of contextual evidence must be present in the context.
- Why unresolved: The paper only investigates the influence of boundedness on aspect prediction. Other potential linguistic features influencing aspect choice, such as tense, adverbial modifiers, or syntactic constructions, are not explored.
- What evidence would resolve it: A comprehensive analysis of alternative contexts identifying the presence or absence of various linguistic cues (beyond boundedness) and their correlation with aspect choice would be needed. Additionally, causal probing experiments targeting these features would help determine their causal impact on aspect prediction.

### Open Question 2
- Question: How does the encoding of aspect in transformer language models vary across different languages with varying aspectual systems?
- Basis in paper: [explicit] The paper explicitly states that aspectual systems vary significantly across languages and that adding a new language requires linguistic expertise and a new experimental setting.
- Why unresolved: The paper only investigates Russian, which has a complex aspectual system with perfective and imperfective forms. Other languages may have different aspectual distinctions (e.g., progressive, perfect) or may not make aspectual distinctions at all.
- What evidence would resolve it: Probing experiments similar to those conducted for Russian should be performed on other languages with different aspectual systems. Comparing the results across languages would reveal how the encoding of aspect varies depending on the linguistic features of the language.

### Open Question 3
- Question: What is the impact of attention weights on aspect prediction in transformer language models, and how do they interact with the contextual representations?
- Basis in paper: [inferred] The paper mentions that future work plans to investigate the impact of interventions in attention weights on aspect prediction, indicating that this aspect has not been explored yet.
- Why unresolved: The paper focuses on interventions in contextual representations but does not investigate how attention weights contribute to aspect prediction. Understanding the role of attention weights could provide insights into the model's reasoning process.
- What evidence would resolve it: Causal probing experiments targeting attention weights, similar to those performed on contextual representations, would be needed to determine their causal impact on aspect prediction. Analyzing the attention patterns in alternative vs. non-alternative contexts could also reveal how the model allocates attention to different parts of the context when predicting aspect.

## Limitations

- The study is limited to Russian language and may not generalize to languages with different aspectual systems
- Manual annotation of alternative vs. non-alternative contexts introduces potential subjectivity and may miss subtle contextual cues
- Causal probing methodology, while theoretically sound, depends on the quality of counterfactual representations and cannot definitively prove causation

## Confidence

**High Confidence**:
- Transformer models encode verbal aspect predominantly in their final layers
- Fine-tuning only final layers is faster and more effective for aspect prediction
- Models show higher uncertainty in alternative contexts compared to non-alternative contexts

**Medium Confidence**:
- Causal interventions affecting boundedness cause predictable changes in aspect prediction
- The boundedness feature is a primary driver of aspect choice in these models
- Performance differences between iterative masking and aspect inference methods

**Low Confidence**:
- Generalizability of findings to other languages with aspectual systems
- The complete isolation of boundedness from other semantic features in causal probing
- The extent to which model behavior mirrors human aspect processing

## Next Checks

1. **Cross-linguistic Validation**: Replicate the behavioral and causal probing experiments with transformer models trained on languages with different aspectual systems (e.g., English with progressive vs. simple aspects, or Slavic languages with more complex aspectual oppositions) to assess the generalizability of the findings about layer-wise aspect encoding and the role of boundedness.

2. **Intervention Specificity Analysis**: Design a follow-up experiment to test whether the causal effects observed from boundedness interventions can be replicated by interventions targeting other semantic features (such as telicity or duration) that might be correlated with boundedness, to better establish the specificity of the boundedness-aspect relationship.

3. **Human-Model Comparison Study**: Conduct a controlled experiment comparing human native speakers' aspect choices and uncertainty levels in the same alternative and non-alternative contexts used for model evaluation, to determine whether the models' uncertainty patterns reflect genuine linguistic ambiguity or model limitations.