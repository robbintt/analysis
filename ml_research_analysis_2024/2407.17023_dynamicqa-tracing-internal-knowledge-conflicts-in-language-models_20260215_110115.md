---
ver: rpa2
title: 'DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models'
arxiv_id: '2407.17023'
source_url: https://arxiv.org/abs/2407.17023
tags:
- context
- uncertainty
- knowledge
- facts
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work explores knowledge conflicts in large language models,\
  \ distinguishing between conflicts within the model\u2019s internal memory (intra-memory\
  \ conflicts) and conflicts between the model\u2019s memory and external context\
  \ (context-memory conflicts). A new dataset, DynamicQA, is introduced to study these\
  \ conflicts, featuring static facts alongside temporal and disputable facts that\
  \ reflect real-world knowledge changes."
---

# DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models

## Quick Facts
- arXiv ID: 2407.17023
- Source URL: https://arxiv.org/abs/2407.17023
- Reference count: 23
- Primary result: Introduces DynamicQA dataset and CP score to study knowledge conflicts in LLMs

## Executive Summary
This paper introduces a structured framework for understanding how large language models handle knowledge conflicts, distinguishing between conflicts within the model's internal memory (intra-memory conflicts) and conflicts between the model's memory and external context (context-memory conflicts). The authors develop a new dataset called DynamicQA that captures three types of facts—static, temporal, and disputable—to enable controlled experiments on knowledge updateability. A novel Coherent Persuasion (CP) score is introduced to quantify how effectively context can persuade a model to change its output, revealing that static facts are most easily updated while highly dynamic facts resist contextual persuasion.

## Method Summary
The research introduces a methodology to study knowledge conflicts in language models by creating the DynamicQA dataset containing static, temporal, and disputable facts. The authors measure context-memory conflicts using a Coherent Persuasion (CP) score, which quantifies how well external context can sway a model's output. For intra-memory conflicts, they evaluate semantic entropy as a potential proxy. The study systematically tests three language models across different fact types to understand how model architecture and knowledge dynamics interact during knowledge conflicts.

## Key Results
- Static facts are most easily updated with context, while temporal and disputable facts are harder to persuade
- CP score effectively captures the impact of context on model output
- Semantic uncertainty alone is not a reliable indicator of intra-memory conflict

## Why This Works (Mechanism)
The approach works by creating controlled experimental conditions where knowledge conflicts can be systematically studied. By distinguishing between static facts (unchanging information), temporal facts (time-dependent information), and disputable facts (controversial information), the researchers create a spectrum of knowledge dynamicity. The CP score provides a quantitative measure of how effectively context can resolve conflicts by measuring changes in model output when presented with contradictory information.

## Foundational Learning
1. **Knowledge Dynamicity** - Why needed: Understanding how different types of knowledge change over time; Quick check: Verify facts are correctly categorized as static, temporal, or disputable
2. **Coherent Persuasion Score** - Why needed: To quantify context effectiveness in resolving conflicts; Quick check: Ensure CP score calculations are consistent across different fact types
3. **Semantic Entropy** - Why needed: As a potential proxy for measuring internal model uncertainty; Quick check: Validate entropy calculations correlate with known conflict scenarios
4. **Context-Memory Conflict** - Why needed: To understand how external information interacts with internal knowledge; Quick check: Test model responses with and without contradictory context
5. **Intra-Memory Conflict** - Why needed: To detect inconsistencies within the model's own knowledge; Quick check: Compare model confidence levels across conflicting statements
6. **Retrieval-Augmented Generation** - Why needed: To understand limitations when updating dynamic knowledge; Quick check: Measure update success rates across different fact types

## Architecture Onboarding

**Component Map**: DynamicQA dataset -> Model input -> CP score calculation -> Entropy measurement -> Conflict analysis

**Critical Path**: Input fact → Model generation → Context application → CP score computation → Conflict classification

**Design Tradeoffs**: The paper uses GPT-4 as an oracle for CP scoring, which provides high-quality judgments but introduces potential bias and limits reproducibility. The choice of LLaMA-3-8B as the primary model tested provides good performance but may not generalize to other architectures.

**Failure Signatures**: Low CP scores may indicate either model resistance to updating or context that fails to effectively contradict internal knowledge. High semantic entropy without corresponding CP changes suggests intra-memory conflict without effective external persuasion.

**First Experiments**:
1. Test CP score sensitivity by varying the degree of contradiction between context and model knowledge
2. Compare entropy-based conflict detection across multiple fact types to validate its limitations
3. Evaluate whether fact length (beyond 10 words) affects conflict detection and resolution

## Open Questions the Paper Calls Out
None

## Limitations
- The study tests only three models, limiting generalizability across different architectures
- Reliance on GPT-4 for CP scoring introduces potential bias and oracle dependency
- Focus on 10-word fact constraints may not capture more complex knowledge scenarios
- Limited model architecture diversity (primarily LLaMA-3-8B) restricts broader applicability

## Confidence
- **High**: The distinction between conflict types and the design of DynamicQA are methodologically sound
- **Medium**: The CP score effectively captures context impact, but its reliance on GPT-4 introduces uncertainty
- **Medium**: Semantic entropy is not a reliable proxy for intra-memory conflict, though this is based on limited model testing

## Next Checks
1. Replicate CP score experiments using a non-GPT-4 baseline to assess robustness and reduce oracle bias
2. Expand model diversity (e.g., include BERT, GPT-2, or open-source alternatives) to test generalizability of conflict findings
3. Test fact sets beyond 10-word constraints to evaluate whether results hold for more complex or nuanced knowledge