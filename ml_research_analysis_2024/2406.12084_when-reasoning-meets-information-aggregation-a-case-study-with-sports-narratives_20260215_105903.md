---
ver: rpa2
title: 'When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives'
arxiv_id: '2406.12084'
source_url: https://arxiv.org/abs/2406.12084
tags:
- reasoning
- narratives
- llms
- sports
- game
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores the critical role of information aggregation
  in reasoning by requiring large language models (LLMs) to analyze sports narratives.
  The task involves inferring points from actions, identifying related entities, attributing
  points accurately to players and teams, and compiling key statistics to draw conclusions.
---

# When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives

## Quick Facts
- arXiv ID: 2406.12084
- Source URL: https://arxiv.org/abs/2406.12084
- Reference count: 40
- Primary result: Most LLMs struggle with accurate basketball score aggregation due to frequent scoring patterns, with divide-and-conquer strategies showing promise.

## Executive Summary
This study investigates how large language models perform on analytical reasoning tasks that require aggregating information from sports narratives. Using NBA basketball data, the research team systematically evaluates whether LLMs can accurately track scoring events, attribute points to players and teams, and compile key statistics. The findings reveal that even state-of-the-art models like GPT-4o frequently fail at accurate score aggregation, particularly when dealing with narratives containing frequent scoring patterns. To address these challenges, the researchers introduce a synthetic data generation method called SPORTS GEN that allows for controlled testing of model capabilities across varying narrative complexities.

## Method Summary
The study employs a comprehensive evaluation framework using both real NBA play-by-play data (28,492 games from 2002-2023) and synthetic narratives generated by the SPORTS GEN method. The research tests multiple leading LLMs including GPT-4o, Claude-3-Opus, and various Llama3 models using different processing strategies: monolithic processing of full narratives, batch-centric division (dividing games into fixed-size play batches), and player-centric division (focusing on individual players). Performance is measured using both traditional accuracy and a novel Discounted Cumulative Accuracy (DCA) metric that incorporates tolerance for small errors. The SPORTS GEN method synthesizes game narratives with controllable scoring-to-non-scoring ratios (1:2, 1:3, 1:4, 1:5) to systematically stress-test model reasoning capabilities.

## Key Results
- Most models, including GPT-4o, fail to accurately aggregate basketball scores due to frequent scoring patterns
- Open-source models like Llama-3 suffer from significant score hallucinations, especially with short narratives
- Divide-and-conquer strategies improve performance but require careful optimization of batch sizes
- Performance degrades as information density increases, with notable sensitivity to narrative length and complexity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Divide-and-conquer strategies reduce cognitive load by breaking long sports narratives into manageable chunks
- Mechanism: Processing smaller batches (e.g., 10 plays at a time) allows LLMs to focus on a narrower scope, reducing the risk of losing track of key scoring events in lengthy play-by-play descriptions
- Core assumption: The performance of LLMs in information aggregation tasks scales inversely with narrative length
- Evidence anchors:
  - [abstract]: "Our findings show that most models, including GPT-4o, often fail to accurately aggregate basketball scores due to frequent scoring patterns"
  - [section 5.1]: "Our findings revealed two key insights. First, the optimal batch size varies between models... Finding the right balance between accuracy per batch and the total number of batches is crucial for achieving optimal results"
  - [corpus]: Weak; the corpus mentions "analytical reasoning" and "reasoning in language models" but does not explicitly discuss chunking or divide-and-conquer strategies
- Break condition: If batch size becomes too small, narrative context may be lost, causing models to hallucinate or miss inter-play dependencies

### Mechanism 2
- Claim: Introducing tolerance (e.g., DCA metric with T=5 or T=10) improves evaluation fairness by rewarding near-accurate predictions
- Mechanism: DCA assigns diminishing scores for predictions that deviate from the true value, thus reducing the harsh penalty of exact-match accuracy when dealing with numerical data
- Core assumption: Small errors in point totals are less harmful than large ones, and the margin of error should be accounted for in performance evaluation
- Evidence anchors:
  - [abstract]: "Our findings show that most models, including GPT-4o, often fail to accurately aggregate basketball scores due to frequent scoring patterns"
  - [section 5.1]: "We introduce the discounted cumulative accuracy metric, which differs from traditional accuracy by allowing a small margin of error... This approach draws inspiration from the DCG (Järvelin and Kekäläinen, 2002)"
  - [corpus]: Weak; the corpus contains general mentions of reasoning and sports narratives but does not address tolerance in scoring predictions
- Break condition: If tolerance is set too high, the metric loses discriminative power and fails to highlight significant performance gaps

### Mechanism 3
- Claim: Synthetic data generation (SPORTS GEN) enables systematic control over narrative complexity and information density
- Mechanism: By adjusting parameters such as S:NS ratio and turn length, SPORTS GEN can create game narratives that systematically vary in difficulty, allowing for more rigorous stress testing of LLMs
- Core assumption: Controlling narrative complexity allows for more precise measurement of LLM reasoning capabilities across different levels of information density
- Evidence anchors:
  - [abstract]: "By synthesizing data, we can rigorously evaluate LLMs' reasoning capabilities under complex scenarios with varying narrative lengths and density of information"
  - [section 4]: "Our approach, SPORTS GEN, enhances the control over narrative complexity when compared to human-written game narratives and few-shot prompting"
  - [corpus]: Weak; the corpus mentions "synthetic data generation" and "generating faithful synthetic data" but does not specifically discuss control over narrative complexity in sports contexts
- Break condition: If the synthetic narratives deviate too far from natural language patterns, model performance may be artificially depressed due to unfamiliarity with the synthetic format

## Foundational Learning

- Concept: Analytical reasoning in sports narratives
  - Why needed here: LLMs must track scoring events, attribute them to players/teams, and aggregate totals accurately
  - Quick check question: Can you explain the difference between a "field goal" and a "three-pointer" in basketball?

- Concept: Information aggregation
  - Why needed here: Correctly summing up points across multiple plays and batches is essential for accurate final scores
  - Quick check question: How would you calculate the total score for a team if you have a list of individual player scores?

- Concept: Divide-and-conquer strategies
  - Why needed here: Breaking down long narratives into smaller segments helps LLMs process information without losing track of key events
  - Quick check question: What might happen if you divide a game into batches that are too small?

## Architecture Onboarding

- Component map: Real/synthetic data input → SPORTS GEN synthesis (if synthetic) → LLM inference (with prompt) → Score aggregation → Evaluation (accuracy/DCA)
- Critical path: Prompt generation → LLM inference → Result parsing → Score validation
- Design tradeoffs: Smaller batch sizes reduce cognitive load but may lose context; higher tolerance in DCA evaluation improves fairness but may mask errors; synthetic data offers control but may lack natural language realism
- Failure signatures: Hallucinations in low batch sizes; performance drop with high information density; sensitivity to narrative length and complexity
- First 3 experiments:
  1. Run LLM inference on full narrative vs. divided into batches of 10; compare accuracy
  2. Vary S:NS ratio in synthetic data; measure performance change
  3. Test different tolerance levels (T=0, T=5, T=10) in DCA metric; observe impact on rankings

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do LLMs perform on sports data from other sports with different scoring patterns and game dynamics compared to basketball?
- Basis in paper: [inferred] The paper focuses on basketball data with frequent scoring patterns, but acknowledges that other sports may have different dynamics and scoring patterns
- Why unresolved: The study only examined basketball data and did not test LLMs on other sports with different scoring patterns and game dynamics
- What evidence would resolve it: Experiments testing LLMs on sports data from various sports (e.g., soccer, baseball, football) with different scoring patterns and game dynamics, comparing their performance to basketball data

### Open Question 2
- Question: What is the impact of different tolerance levels (T) on the DCA metric for evaluating LLMs' performance in analytical reasoning tasks?
- Basis in paper: [explicit] The paper introduces the DCA metric and experiments with varying tolerance levels (T = 0, 1, 3, 5, 10) to assess their impact on model performance
- Why unresolved: While the paper tests different tolerance levels, it does not provide a comprehensive analysis of how the choice of tolerance level affects the evaluation of LLMs' performance across different scenarios and models
- What evidence would resolve it: A detailed study analyzing the relationship between tolerance levels and DCA scores across various models, scenarios, and analytical reasoning tasks, providing guidelines for selecting appropriate tolerance levels

### Open Question 3
- Question: How does the performance of LLMs in analytical reasoning tasks change when using a combination of divide-and-conquer strategies (e.g., player-centric and batch-centric divisions) compared to using them individually?
- Basis in paper: [inferred] The paper explores two divide-and-conquer strategies (player-centric and batch-centric divisions) separately, but does not investigate their combined effects on LLM performance
- Why unresolved: The study only examines the performance of LLMs using individual divide-and-conquer strategies, without exploring the potential benefits of combining these strategies
- What evidence would resolve it: Experiments testing LLMs using various combinations of divide-and-conquer strategies (e.g., player-centric followed by batch-centric, or vice versa) and comparing their performance to using each strategy individually

## Limitations
- The synthetic data generation method may not fully capture the linguistic complexity and variability of real sports narratives
- The study focuses exclusively on basketball, limiting generalizability to other sports with different scoring patterns
- The optimal batch size for divide-and-conquer strategies appears to be model-specific and requires careful calibration

## Confidence

High confidence: The core finding that LLMs struggle with basketball score aggregation due to frequent scoring patterns is well-supported by experimental results across multiple models and evaluation metrics.

Medium confidence: The effectiveness of divide-and-conquer strategies shows promise but may depend heavily on optimal batch size selection, which varies by model and appears sensitive to narrative characteristics.

Low confidence: The synthetic data approach's ability to generalize to real-world sports narratives remains uncertain without direct comparison studies between synthetic and authentic game descriptions.

## Next Checks

1. Conduct a head-to-head comparison of model performance on synthetic SPORTS GEN data versus authentic NBA play-by-play narratives to quantify any performance gaps attributable to synthetic data limitations.

2. Perform ablation studies varying batch sizes systematically (e.g., 5, 10, 15, 20 plays per batch) across all tested models to identify universal optimal batch size ranges versus model-specific preferences.

3. Test the DCA metric's sensitivity by artificially manipulating model outputs with controlled error margins to determine whether the tolerance threshold appropriately balances fairness with discriminative power.