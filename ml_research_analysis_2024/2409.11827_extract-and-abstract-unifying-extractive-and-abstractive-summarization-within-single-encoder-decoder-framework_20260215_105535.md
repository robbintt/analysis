---
ver: rpa2
title: 'Extract-and-Abstract: Unifying Extractive and Abstractive Summarization within
  Single Encoder-Decoder Framework'
arxiv_id: '2409.11827'
source_url: https://arxiv.org/abs/2409.11827
tags:
- extabs
- mask
- bart
- saliency
- summary
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel parameter-free highlight method, the
  saliency mask, for the extract-then-abstract paradigm by augmenting attention in
  the decoder. The saliency mask replaces the vanilla attention mask with a binary
  mask for salient tokens, forcing the decoder to only attend to salient parts of
  the input.
---

# Extract-and-Abstract: Unifying Extractive and Abstractive Summarization within Single Encoder-Decoder Framework

## Quick Facts
- arXiv ID: 2409.11827
- Source URL: https://arxiv.org/abs/2409.11827
- Reference count: 40
- Key outcome: Proposed ExtAbs framework jointly performs extractive and abstractive summarization within a single encoder-decoder model, achieving superior extractive performance and comparable or better abstractive performance than vanilla models.

## Executive Summary
This paper introduces the extract-and-abstract paradigm (ExtAbs) that unifies extractive and abstractive summarization within a single encoder-decoder framework. The key innovation is a parameter-free saliency mask that constrains decoder attention to only salient tokens, improving both extractive selection and abstractive generation. By jointly training an augmented encoder (which extracts salient segments) and a modified decoder (which uses the saliency mask), the framework reduces error accumulation and duplicate encoding compared to separate extractor-abstractor pipelines. Experiments on CNN/DM, Reddit, and PubMed datasets demonstrate significant improvements in extractive performance and competitive abstractive results.

## Method Summary
The ExtAbs framework augments standard encoder-decoder models by adding a self-attentive span extractor and classification layer to the encoder for saliency prediction, while modifying the decoder to use a binary saliency mask in cross-attention. The saliency mask is created by selecting the top-z segments with highest predicted saliency scores, forcing the decoder to attend only to these salient parts. The model is trained jointly using a multi-task loss combining extractive (classification) and abstractive (generation) objectives. The framework supports both sentence-level and EDU-level (Elementary Discourse Unit) granularity for saliency masks, with EDU-level showing superior performance.

## Key Results
- EDU-level saliency mask outperforms sentence-level masks on ROUGE scores
- ExtAbs achieves superior extractive performance compared to vanilla models
- ExtAbs generates comparable or better abstractive summaries than baseline models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The saliency mask reduces overconfidence in decoder attention by constraining the cross-attention scope to only salient tokens.
- Mechanism: By replacing the vanilla encoder attention mask with a binary mask for salient tokens, the decoder is forced to focus only on salient parts of the input, leading to a more balanced attention distribution over a narrowed-down attentive scope.
- Core assumption: The vanilla encoder attention mask (non-padded token mask) is too permissive and leads to overfitting or attending to irrelevant tokens, especially in long documents.
- Evidence anchors:
  - [abstract]: "replacing the encoder attention mask with a saliency mask in the cross-attention module to force the decoder to focus only on salient parts of the input"
  - [section]: "Whereas with the proposed saliency mask, the model generates a more balanced attention distribution over the explicitly narrowed-down attentive scope"
  - [corpus]: Weak - no direct corpus evidence found; relies on ablation showing performance drop when mask is removed.
- Break condition: If the saliency mask is too restrictive (e.g., too few tokens marked salient), the decoder may lose necessary context and performance degrades.

### Mechanism 2
- Claim: Joint training of extractor and abstractor within a single encoder-decoder model reduces error accumulation and duplicate encoding.
- Mechanism: The augmented encoder performs both saliency classification (extractive task) and provides contextualized representations for the decoder (abstractive task), enabling shared learning signals and avoiding functional independence between extractor and abstractor.
- Core assumption: Training extractor and abstractor separately leads to error propagation and redundant computation; joint training enables mutual improvement.
- Evidence anchors:
  - [abstract]: "jointly and seamlessly performs Extractive and Abstractive summarization tasks within single encoder-decoder model to reduce error accumulation"
  - [section]: "Jointly training the augmented encoder and decoder enables the extract-and-abstract paradigm within a single encoder-decoder framework, removing the functional independence between the extractor and abstractor, along with duplicate encoding and error accumulation"
  - [corpus]: Weak - no direct corpus evidence; inference drawn from ablation showing improvement when joint training is used.
- Break condition: If the multi-task objective is poorly balanced (α, β, γ hyperparameters), one task may dominate and harm the other.

### Mechanism 3
- Claim: EDU-level granularity for saliency masks is more effective than sentence-level for extractive summarization.
- Mechanism: EDUs (Elementary Discourse Units) provide finer-grained semantic units than sentences, allowing more precise identification of salient information and better extractive performance.
- Core assumption: EDUs capture discourse structure more accurately than sentences, making them better units for saliency classification.
- Evidence anchors:
  - [abstract]: "EDU-level saliency mask outperforms all three other highlight methods and the sentence-level saliency mask on ROUGE scores"
  - [section]: "EDU is defined as the terminal node in the Rhetorical Structure Theory (RST) and has been widely applied in summarization models"
  - [corpus]: Weak - no direct corpus evidence; conclusion based on experimental comparison in Table 1.
- Break condition: If the EDU segmentation is noisy or inconsistent, the finer granularity may introduce more errors than it resolves.

## Foundational Learning

- Concept: Cross-attention mechanism in encoder-decoder models
  - Why needed here: The saliency mask is applied in the cross-attention module to constrain which encoder tokens the decoder attends to.
  - Quick check question: What is the difference between self-attention and cross-attention in a transformer decoder?

- Concept: Multi-task learning and loss balancing
  - Why needed here: The model optimizes both extractive (classification) and abstractive (generation) losses simultaneously, requiring careful hyperparameter tuning.
  - Quick check question: How does KL divergence regularization help stabilize training when using a saliency mask?

- Concept: Text granularity and discourse structure (EDUs vs sentences)
  - Why needed here: The choice between EDU-level and sentence-level saliency masks significantly impacts extractive performance.
  - Quick check question: What is an Elementary Discourse Unit (EDU) and how does it differ from a sentence?

## Architecture Onboarding

- Component map: Document -> Encoder -> Token representations -> Span extractor -> Segment representations -> Classification layer -> Saliency scores -> Top-z segments -> Saliency mask creation -> Saliency mask + Encoder output + Decoder -> Abstractive summary generation

- Critical path:
  1. Document → Encoder → Token representations
  2. Token representations → Span extractor → Segment representations
  3. Segment representations → Classification layer → Saliency scores
  4. Top-z segments → Saliency mask creation
  5. Saliency mask + Encoder output + Decoder → Abstractive summary generation

- Design tradeoffs:
  - Granularity choice (EDU vs sentence) affects precision vs. computational cost
  - Number of salient segments (z) balances information preservation vs. noise reduction
  - Multi-task loss weighting (α, β, γ) requires tuning to prevent task interference

- Failure signatures:
  - Low extractive performance: Saliency mask too restrictive or classifier poorly trained
  - Hallucination in abstractive output: Saliency mask missing critical context tokens
  - Degraded performance on long documents: Saliency mask unable to capture distributed information

- First 3 experiments:
  1. Compare vanilla BART vs. ExtAbs(BART) on CNN/DM with fixed hyperparameters to verify abstractive improvement
  2. Ablation: Remove saliency mask from ExtAbs to measure its contribution
  3. Vary z (number of salient segments) to find optimal tradeoff for each dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of the saliency mask vary across different document lengths and types?
- Basis in paper: [inferred] The paper mentions that the saliency mask improves abstractive summarization performance, but does not extensively explore how its effectiveness varies with document length or type.
- Why unresolved: The paper primarily focuses on three datasets (CNN/DM, Reddit, and PubMed) without explicitly analyzing the impact of document length or type on the saliency mask's effectiveness.
- What evidence would resolve it: Conducting experiments on a diverse set of documents with varying lengths and types, and analyzing the performance of the saliency mask across these variations.

### Open Question 2
- Question: Can the saliency mask be effectively integrated with decoder-only models like GPT-4 for extractive summarization?
- Basis in paper: [explicit] The paper acknowledges that the saliency mask is designed for encoder-decoder models and cannot be directly extended to decoder-only models.
- Why unresolved: The paper does not explore potential methods to adapt the saliency mask for decoder-only models, leaving this as an open question for future research.
- What evidence would resolve it: Developing and testing an integration method for the saliency mask with decoder-only models, followed by evaluating its performance on extractive summarization tasks.

### Open Question 3
- Question: How does the granularity of textual segments (e.g., sentences vs. EDUs) impact the performance of the extract-and-abstract paradigm?
- Basis in paper: [explicit] The paper compares sentence-level and EDU-level saliency masks, finding that EDUs provide better performance for extractive summarization.
- Why unresolved: While the paper provides initial insights, it does not fully explore the impact of different granularities on the overall performance of the extract-and-abstract paradigm.
- What evidence would resolve it: Conducting comprehensive experiments with various granularities of textual segments and analyzing their impact on both extractive and abstractive summarization tasks within the extract-and-abstract framework.

## Limitations
- Architecture complexity and implementation burden: ExtAbs requires substantial modifications to standard encoder-decoder architectures, increasing model complexity significantly.
- Hyperparameter sensitivity: The model introduces multiple new hyperparameters (z for number of salient segments, α, β, γ for loss weighting) that require careful tuning.
- Granularity assumption validity: The superiority of EDU-level granularity assumes reliable EDU segmentation is available, which may not hold in all scenarios.

## Confidence
- High Confidence (80-100%): The saliency mask as a parameter-free highlight method is technically sound and demonstrably improves extractive performance when properly implemented; Joint training of extractor and abstractor within a single framework is feasible and provides performance benefits over separate training.
- Medium Confidence (50-80%): The claim that ExtAbs achieves "superior extractive performance" is supported by ROUGE scores but may not generalize to all document types or domains; The assertion that "ExtAbs generates comparable or even better abstractive summaries than vanilla models" is supported by automatic metrics but human evaluation shows mixed results.
- Low Confidence (0-50%): The claim that EDU-level saliency masks are universally superior to sentence-level masks lacks sufficient cross-domain validation; The assertion that this approach represents a fundamental advance in "unifying" summarization paradigms overstates the practical significance given the implementation complexity.

## Next Checks
1. **Ablation study on granularity levels**: Systematically compare EDU-level, sentence-level, and token-level saliency masks across diverse datasets to validate whether EDU-level granularity is truly optimal or domain-dependent. This should include datasets where EDU segmentation may be unreliable.

2. **Cross-domain generalization test**: Evaluate ExtAbs on additional domains (legal documents, technical manuals, social media) to assess whether the performance improvements observed on CNN/DM, Reddit, and PubMed generalize to different document types and writing styles.

3. **Implementation complexity vs. benefit analysis**: Compare the performance gain of ExtAbs against simpler baselines like using pre-trained extractive models (e.g., BERT extractive summarizer) followed by abstractive refinement. This would quantify whether the architectural complexity is justified by the performance benefits.