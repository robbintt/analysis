---
ver: rpa2
title: 'Learning to Defer to a Population: A Meta-Learning Approach'
arxiv_id: '2403.02683'
source_url: https://arxiv.org/abs/2403.02683
tags:
- expert
- learning
- probability
- l2d-pop
- overlap
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of learning to defer (L2D) in settings
  where the human expert may change from training to test time. The authors propose
  a meta-learning approach called "learning to defer to a population" (L2D-Pop) that
  can quickly adapt to new experts using a small context set of their past decisions.
---

# Learning to Defer to a Population: A Meta-Learning Approach

## Quick Facts
- arXiv ID: 2403.02683
- Source URL: https://arxiv.org/abs/2403.02683
- Authors: Dharmesh Tailor; Aditya Patra; Rajeev Verma; Putra Manggala; Eric Nalisnick
- Reference count: 40
- Key outcome: Meta-learning approach for adapting to new human experts in learning-to-defer setting, with experiments showing significant improvements over baseline methods

## Executive Summary
This paper addresses the challenge of learning to defer (L2D) when human experts change between training and deployment. The authors propose a meta-learning framework called "learning to defer to a population" (L2D-Pop) that can quickly adapt to new experts using a small context set of their past decisions. The approach is evaluated across three task domains: image recognition, traffic sign detection, and skin lesion diagnosis. Results demonstrate that L2D-Pop significantly outperforms a baseline that models the population average, particularly as expert variability increases.

## Method Summary
The authors propose a meta-learning approach for learning to defer to a population of experts that may change between training and deployment. The framework uses a small context set of an expert's past decisions to quickly adapt the deferral policy. Two meta-learning variants are explored: a fine-tuning approach that updates model parameters using the context set, and a model-based approach using a neural process with an optional cross-attention mechanism. The neural process variant aims to identify experts' strengths on similar test instances by comparing context set examples to the current instance.

## Key Results
- L2D-Pop significantly outperforms population average baseline across all three task domains
- Performance gains increase with higher expert variability
- Neural process variant with cross-attention further improves performance by better identifying experts' strengths on similar instances
- Diminishing returns observed as number of context examples increases

## Why This Works (Mechanism)
The approach works by leveraging meta-learning to quickly adapt to new experts based on their historical decision patterns. The neural process variant with cross-attention identifies which experts are likely to be most helpful for specific test instances by comparing them to similar examples in the context set. This allows the system to route queries to the most appropriate expert rather than relying on a one-size-fits-all population average.

## Foundational Learning
- **Meta-learning**: Why needed - enables quick adaptation to new experts with limited data; Quick check - verify that adaptation occurs within few gradient steps
- **Learning to defer**: Why needed - allows AI systems to recognize when human expertise is needed; Quick check - ensure deferral decisions improve overall accuracy
- **Neural processes**: Why needed - provides a model-based approach for handling variable-sized context sets; Quick check - verify that predictions are consistent across different context set sizes
- **Cross-attention mechanisms**: Why needed - helps identify which experts are strongest on similar instances; Quick check - confirm that attention weights correlate with expert expertise

## Architecture Onboarding

**Component Map**
L2D-Pop -> Context Set Processor -> Meta-Learner (Fine-tune or Neural Process) -> Deferral Policy -> Expert Selection

**Critical Path**
1. Expert context set is processed
2. Meta-learner updates parameters or generates predictions
3. Deferral policy determines whether to defer or predict
4. If deferring, expert selection routes to appropriate expert

**Design Tradeoffs**
- Fine-tuning vs. neural process: computational efficiency vs. flexibility
- Context set size vs. adaptation quality
- Cross-attention complexity vs. identification of expert strengths

**Failure Signatures**
- Poor performance when expert strengths are inconsistent across similar instances
- Diminishing returns with increasing context set size
- Computational bottlenecks with large expert populations

**First 3 Experiments**
1. Evaluate performance across varying levels of expert variability
2. Compare fine-tuning vs. neural process variants
3. Test cross-attention effectiveness in identifying expert strengths

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- Evaluation uses synthetic expert variability rather than real-world expert diversity
- Performance gains show diminishing returns as context examples increase
- Computational overhead of neural process variant with cross-attention not quantified
- Assumes experts' strengths are consistent across similar instances

## Confidence

**High confidence in:**
- Core methodology and experimental setup
- Meta-learning framework validity
- Ablation studies showing relative importance of components
- Consistency of improvements across all three task domains

**Medium confidence in:**
- Generalization to real-world expert variability patterns
- Scalability to larger populations of experts
- Performance on more complex task domains

**Low confidence in:**
- Practical computational overhead in deployment settings

## Next Checks
1. Test the approach on a real-world dataset with naturally occurring expert variability rather than synthetic mixing of difficulty levels, such as a medical diagnosis dataset with multiple actual clinicians.

2. Evaluate the computational overhead and inference time of the neural process variant with cross-attention compared to the simpler fine-tuning approach, particularly as the number of context examples increases.

3. Assess the robustness of the approach when the assumption about experts' consistent strengths across similar instances is violated, by introducing controlled adversarial variations in expert behavior.