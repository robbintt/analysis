---
ver: rpa2
title: On Using Secure Aggregation in Differentially Private Federated Learning with
  Multiple Local Steps
arxiv_id: '2407.19286'
source_url: https://arxiv.org/abs/2407.19286
tags: []
core_contribution: The paper addresses the challenge of combining differential privacy
  (DP) and secure aggregation (SecAgg) in federated learning (FL) when clients perform
  multiple local optimization steps. Existing techniques require either single local
  steps or sacrifice the privacy benefits of SecAgg.
---

# On Using Secure Aggregation in Differentially Private Federated Learning with Multiple Local Steps

## Quick Facts
- **arXiv ID**: 2407.19286
- **Source URL**: https://arxiv.org/abs/2407.19286
- **Reference count**: 40
- **Primary result**: Introduces a method for combining DP and SecAgg in FL with multiple local steps using sum-dominating noise mechanisms

## Executive Summary
This paper addresses a fundamental limitation in combining differential privacy with secure aggregation in federated learning: existing approaches require either single local optimization steps or sacrifice the privacy benefits of secure aggregation. The authors propose a novel analysis showing that when using sum-dominating mechanisms (Gaussian, Skellam, Poisson-binomial), multiple local steps can be performed while preserving the joint noise scaling benefits of secure aggregation. The key insight is that releasing the sum of per-step updates is privacy-equivalent to releasing each step individually. Experiments demonstrate significant utility improvements (e.g., CIFAR-10 accuracy improving from ~0.55 to ~0.75) when using multiple local steps compared to single steps under fixed privacy and communication budgets.

## Method Summary
The paper introduces a technique for combining differential privacy with secure aggregation in federated learning when clients perform multiple local optimization steps. The core innovation is recognizing that sum-dominating noise mechanisms (those with infinitely divisible noise distributions) allow the privacy cost of multiple local steps to be equivalent to that of a single step. By releasing the sum of all per-step updates rather than individual updates, the approach maintains the joint noise scaling benefits of secure aggregation while enabling more efficient local computation. The method is evaluated across Fashion MNIST, CIFAR-10, and ACS Income datasets with varying model complexities, demonstrating consistent utility improvements under fixed privacy budgets.

## Key Results
- CIFAR-10 test accuracy improves from ~0.55 to ~0.75 when using multiple local steps vs. single steps
- Consistent utility improvements observed across Fashion MNIST, CIFAR-10, and ACS Income datasets
- Robust performance across different model architectures and data distributions
- Achieves better privacy-utility tradeoffs under fixed privacy and communication budgets

## Why This Works (Mechanism)
The paper leverages the mathematical property of sum-dominating noise mechanisms where the privacy cost of releasing the sum of multiple updates equals the cost of releasing each update individually. This allows secure aggregation to maintain its joint noise scaling benefits even when clients perform multiple local optimization steps. The infinitely divisible noise distributions (Gaussian, Skellam, Poisson-binomial) ensure that the accumulated noise maintains the required properties for both differential privacy and secure aggregation to work together effectively.

## Foundational Learning

**Differential Privacy**: A framework for quantifying privacy guarantees by limiting information leakage about individual data points. Needed to protect client data in federated learning while still enabling model training.

**Secure Aggregation**: A cryptographic technique that allows servers to compute aggregate statistics without learning individual client contributions. Essential for protecting individual client updates during the aggregation phase.

**Sum-dominating mechanisms**: Noise distributions where the privacy cost of releasing the sum of multiple updates equals the cost of releasing each update individually. Critical for enabling multiple local steps while preserving secure aggregation benefits.

**Local steps in FL**: When clients perform multiple optimization steps on their local data before sending updates to the server. Important for reducing communication costs and leveraging local data more effectively.

**Infinitely divisible noise**: Noise distributions that can be decomposed into sums of identically distributed random variables. Required property for the privacy analysis to hold across multiple local steps.

## Architecture Onboarding

**Component map**: Clients -> Local computation (multiple steps) -> Sum aggregation -> Secure aggregation -> Global model update

**Critical path**: Client local computation -> Sum of updates -> Secure aggregation -> Privacy accounting

**Design tradeoffs**: The approach trades increased local computation (multiple steps) for reduced communication frequency and improved utility, while maintaining the privacy benefits of secure aggregation.

**Failure signatures**: Privacy guarantees break if non-sum-dominating noise mechanisms are used, or if clients fail to properly sum their per-step updates before aggregation.

**First experiments**:
1. Verify the privacy accounting holds for Gaussian noise with multiple local steps on a simple logistic regression task
2. Test the approach on non-IID data distributions to confirm robustness
3. Measure communication efficiency gains by comparing update frequencies between single and multiple step approaches

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Assumes honest-but-curious server model; does not address malicious participants
- Focuses on specific noise distributions without discussing practical implementation considerations
- Communication efficiency benefits are mentioned but not quantitatively validated
- Does not address sensitivity analysis for models with non-differentiable activation functions

## Confidence
- **High**: The core theoretical insight about sum-dominating mechanisms preserving secure aggregation benefits
- **Medium**: Experimental results showing utility improvements, though limited to specific datasets
- **Low**: Claims about communication efficiency without quantitative support

## Next Checks
1. Test the approach on non-IID data distributions to verify robustness beyond synthetic data splits
2. Conduct experiments measuring actual communication savings from reduced update frequency
3. Evaluate Byzantine robustness by simulating malicious clients attempting to break privacy guarantees