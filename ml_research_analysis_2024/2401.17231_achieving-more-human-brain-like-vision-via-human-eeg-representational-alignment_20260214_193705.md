---
ver: rpa2
title: Achieving More Human Brain-Like Vision via Human EEG Representational Alignment
arxiv_id: '2401.17231'
source_url: https://arxiv.org/abs/2401.17231
tags:
- human
- neural
- realnet
- similarity
- brain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents ReAlnet, the first vision model aligned with
  human brain activity based on non-invasive EEG data, addressing the gap between
  artificial and human visual processing. The core innovation is an image-to-brain
  multi-layer encoding framework that simultaneously optimizes multiple model layers,
  enabling the model to learn and mimic human brain's visual representational patterns
  across object categories and neural modalities.
---

# Achieving More Human Brain-Like Vision via Human EEG Representational Alignment

## Quick Facts
- arXiv ID: 2401.17231
- Source URL: https://arxiv.org/abs/2401.17231
- Reference count: 39
- Primary result: First vision model aligned with human EEG data showing 8% higher similarity to brain representations

## Executive Summary
This study introduces ReAlnet, a vision model aligned with human brain activity using non-invasive EEG data, addressing the gap between artificial and human visual processing. The core innovation is an image-to-brain multi-layer encoding framework that simultaneously optimizes multiple model layers, enabling the model to learn and mimic human brain's visual representational patterns across object categories and neural modalities. ReAlnet demonstrates significantly higher similarity to human brain representations than traditional models like CORnet, ResNet-101, and CLIP, with up to 8% similarity improvement and 80% improvement ratio at peak similarity timepoints. The model also shows improved cross-modality alignment with fMRI data and increased adversarial robustness.

## Method Summary
The study develops an EEG-based alignment framework using CORnet-S as the base architecture, adding an EEG generation module that connects each visual layer to layer-encoders. The model is trained using a combination of classification loss and generation loss (MSE + contrastive loss) on the THINGS dataset with pseudo-labels from pre-trained CORnet-S. Training involves 40 models across 10 subjects and 4 generation loss weights, optimized using Adam with learning rate 0.00002 for 30 epochs. Evaluation uses Representational Similarity Analysis (RSA) to compare model representations with human EEG and fMRI data.

## Key Results
- ReAlnet achieves 8% higher similarity to human brain representations compared to traditional models
- Model shows 80% improvement ratio at peak similarity timepoints (200ms)
- Cross-modality alignment with fMRI data is significantly improved
- ReAlnet demonstrates increased adversarial robustness against white-box FGSA attacks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ReAlnet's multi-layer encoding alignment framework improves similarity to human brain representations by simultaneously optimizing multiple model layers with EEG generation.
- Mechanism: The framework adds an EEG generation module that connects each visual layer to a layer-encoder, which are concatenated and processed through a multi-layer visual encoder and an EEG encoder. This setup allows the model to learn brain-like representations across different layers and object categories.
- Core assumption: EEG signals contain sufficient information to guide the model in learning human brain's visual representational patterns.
- Evidence anchors:
  - [abstract] "Our innovative image-to-brain multi-layer encoding framework advances human neural alignment by optimizing multiple model layers and enabling the model to efficiently learn and mimic human brain's visual representational patterns across object categories and different modalities."
  - [section 2.3] "In addition to the original recurrent CNN structure, we have added an EEG generation module designed to construct an image-to-brain encoding model for generating realistic human EEG signals."
- Break condition: If EEG signals do not capture the necessary visual processing information, the model will fail to learn brain-like representations.

### Mechanism 2
- Claim: The contrastive loss component in the alignment framework aids ReAlnet in extracting more cross-modality brain visual representation features.
- Mechanism: The contrastive loss brings the generated EEG signals from the same image closer to the corresponding real human EEG signals and makes the generated signals from different images more distinct. This encourages the model to learn consistent brain information processing patterns across subjects and modalities.
- Core assumption: The contrastive loss can effectively guide the model to learn cross-modality brain representations.
- Evidence anchors:
  - [section 2.3] "LG is the generation loss, which includes a mean squared error (MSE) loss LM SE and a contrastive loss LCont between the generated and real EEG signals."
  - [section 3.6] "The results of the control experiments reveal: (1) W/o ContLoss models still exhibit an improvement in human brain similarity compared to CORnet. However, while the similarity to human EEG did not decrease compared to ReAlnet, the similarity to cross-modality human fMRI significantly decreased."
- Break condition: If the contrastive loss does not effectively guide the model to learn cross-modality representations, the model will fail to improve fMRI similarity.

### Mechanism 3
- Claim: Aligning with human neural representations improves the model's adversarial robustness.
- Mechanism: By learning brain-like representations, ReAlnet becomes more robust to adversarial attacks, as it has learned to extract features that are more similar to human visual processing, which is inherently more robust.
- Core assumption: Brain-like representations are inherently more robust to adversarial attacks.
- Evidence anchors:
  - [abstract] "The model also shows improved cross-modality alignment with fMRI data and increased adversarial robustness, making it more similar to human brain processing."
  - [section 3.4] "Using white-box FGSA, we also discovered that ReAlnets, aligned with human neural representations, have increased adversarial robustness against adversarial attacks."
- Break condition: If brain-like representations do not improve adversarial robustness, the model will not show increased robustness compared to non-aligned models.

## Foundational Learning

- Concept: Representational Similarity Analysis (RSA)
  - Why needed here: RSA is used to compare the representational similarity between models and human brains, which is the core evaluation method for ReAlnet.
  - Quick check question: How is the representational similarity between models and human brains calculated in this study?

- Concept: Adversarial Robustness
  - Why needed here: Adversarial robustness is one of the key findings of ReAlnet, showing that aligning with human neural representations improves the model's robustness.
  - Quick check question: What type of adversarial attacks were used to evaluate the robustness of ReAlnet?

- Concept: EEG Signal Processing
  - Why needed here: EEG signals are the primary neural data used to align ReAlnet with human brain representations, and understanding their processing is crucial for implementing the alignment framework.
  - Quick check question: How were the EEG signals preprocessed before being used in the alignment framework?

## Architecture Onboarding

- Component map:
  - Input image to CORnet-S
  - Pass through each visual layer (V1, V2, V4, IT)
  - Each visual layer output to corresponding layer-encoder (N×128)
  - Concatenate layer-encoder outputs to form N×512 multi-layer visual encoder
  - Pass through multi-layer visual encoder and EEG encoder to generate predicted EEG signals
  - Calculate alignment loss and update model parameters

- Critical path:
  1. Input image to CORnet-S
  2. Pass through each visual layer
  3. Each visual layer output to corresponding layer-encoder
  4. Concatenate layer-encoder outputs
  5. Pass through multi-layer visual encoder and EEG encoder to generate predicted EEG signals
  6. Calculate alignment loss and update model parameters

- Design tradeoffs:
  - Using EEG signals vs. fMRI signals: EEG has higher temporal resolution but lower spatial resolution compared to fMRI.
  - Multi-layer alignment vs. single-layer alignment: Multi-layer alignment allows learning brain-like representations across different stages of visual processing but may be more computationally expensive.

- Failure signatures:
  - Low similarity between ReAlnet and human EEG/fMRI representations
  - No improvement in adversarial robustness compared to non-aligned models
  - High variance in similarity across different subjects or layers

- First 3 experiments:
  1. Train ReAlnet with EEG data from a single subject and evaluate similarity to that subject's EEG and fMRI data.
  2. Train ReAlnet with EEG data from multiple subjects and evaluate similarity to each subject's EEG and fMRI data.
  3. Train ReAlnet with different generation loss weights (β) and evaluate similarity to EEG/fMRI data and adversarial robustness.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific information has ReAlnet learned from the alignment with human brains?
- Basis in paper: [inferred] The paper mentions that "different generation loss weights do not significantly impact the behavioral performance but do enhance its similarity to human brains suggests that nodes in the model, which originally did not encode category-specific information, may have been optimized."
- Why unresolved: The paper states that more analyses of the neural network's internal representations may be needed to delve into this, but it doesn't provide such analyses.
- What evidence would resolve it: Detailed analysis of the neural network's internal representations, such as activation patterns, feature maps, or saliency maps, could reveal what specific information ReAlnet has learned from the alignment.

### Open Question 2
- Question: How does the contrastive loss component in the alignment framework aid ReAlnet in extracting more cross-modality brain visual representation features?
- Basis in paper: [explicit] The paper mentions that "the contrastive loss component in our alignment framework aids ReAlnet in extracting more cross-modality brain visual representation features."
- Why unresolved: The paper doesn't provide a detailed explanation of how the contrastive loss achieves this.
- What evidence would resolve it: Experiments comparing the performance of ReAlnet with and without the contrastive loss component on cross-modality brain visual representation features could shed light on how the contrastive loss contributes to this improvement.

### Open Question 3
- Question: How can the alignment framework be extended to other neural modalities, such as fMRI and MEG?
- Basis in paper: [explicit] The paper mentions that "this alignment framework can be extended to other neural modalities, such as fMRI and MEG (dimensionality reduction might be necessary for extensive neural data features)."
- Why unresolved: The paper doesn't provide specific details on how to extend the framework to other modalities.
- What evidence would resolve it: Experiments applying the alignment framework to fMRI and MEG data and comparing the results with those obtained using EEG data could demonstrate the feasibility and effectiveness of extending the framework to other modalities.

## Limitations

- Reliance on EEG data with lower spatial resolution compared to fMRI, potentially limiting alignment precision
- Evaluation constrained to small datasets (10 subjects for EEG, 3 for fMRI) and specific brain regions
- Use of pseudo-labels from pre-trained models for training on THINGS dataset introduces potential bias

## Confidence

**High confidence** in core claim that ReAlnet achieves higher similarity to human brain representations than traditional models, supported by direct quantitative comparisons showing 8% similarity improvement and 80% improvement ratio at peak similarity timepoints.

**Medium confidence** in mechanism explanations, particularly regarding how multi-layer encoding framework specifically captures brain-like representations, as paper demonstrates correlation but doesn't fully establish causal mechanisms.

**Low confidence** in adversarial robustness findings as direct consequence of brain alignment, since paper shows correlation between alignment and robustness but doesn't exclude other contributing factors.

## Next Checks

1. **Temporal alignment validation**: Conduct RSA analysis at multiple time points (not just 200ms) to verify that claimed peak similarity is robust across full temporal dynamics of visual processing.

2. **Cross-dataset generalization**: Test ReAlnet's alignment performance on independent EEG/fMRI datasets not used in training to assess whether brain alignment generalizes beyond specific THINGS dataset.

3. **Ablation on layer contributions**: Systematically disable individual visual layers in multi-layer encoding framework to quantify specific contribution of each layer to overall brain alignment performance.