---
ver: rpa2
title: 'Ethos: Rectifying Language Models in Orthogonal Parameter Space'
arxiv_id: '2403.08994'
source_url: https://arxiv.org/abs/2403.08994
tags:
- task
- ethos
- knowledge
- pre-trained
- toxicity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of toxicity, bias, and privacy
  leakage in large language models (LMs) by proposing a new model editing method called
  Ethos. The core idea of Ethos is to distinguish between general beneficial knowledge
  and undesired knowledge in the orthogonal parameter space of LMs.
---

# Ethos: Rectifying Language Models in Orthogonal Parameter Space

## Quick Facts
- arXiv ID: 2403.08994
- Source URL: https://arxiv.org/abs/2403.08994
- Reference count: 21
- Primary result: Introduces Ethos, a novel method for unlearning undesired knowledge in language models using orthogonal parameter spaces, outperforming current task arithmetic methods in toxicity, bias, and memorization unlearning tasks while preserving model utility.

## Executive Summary
Ethos presents a new approach to rectifying large language models by unlearning undesired knowledge such as toxicity, bias, and memorization. The method leverages orthogonal parameter spaces to distinguish between beneficial and undesired knowledge, enabling targeted removal without compromising overall model performance. Evaluated on OPT-1.3B, Ethos demonstrates superior performance in unlearning tasks compared to existing methods, achieving near-complete removal of toxic content while maintaining perplexity close to the pre-trained model. This work addresses critical concerns in LM deployment and offers a promising direction for safer AI systems.

## Method Summary
Ethos operates by first obtaining principal components of the pre-trained model through singular value decomposition. It then projects task vectors onto these components to identify and filter out undesired knowledge in the orthogonal parameter space. The method involves calculating a task vector that represents the difference between models with and without the undesired behavior, projecting this vector onto the principal components, and removing the components associated with the undesired knowledge. The remaining components are used to reconstruct the model parameters, effectively unlearning the undesired behavior while preserving beneficial knowledge. Ethos is evaluated on toxicity, bias, and memorization unlearning tasks using the OPT-1.3B model.

## Key Results
- Achieved 0.0% toxicity ratio and 0.014 toxicity score in toxicity unlearning on OPT-1.3B
- Maintained perplexity close to pre-trained model levels after unlearning
- Outperformed current task arithmetic methods in removing undesired knowledge while preserving model utility

## Why This Works (Mechanism)
The mechanism behind Ethos relies on the assumption that beneficial and undesired knowledge in language models can be separated in the orthogonal parameter space. By using principal component analysis, Ethos identifies the directions in the parameter space that correspond to general, beneficial knowledge. The task vector, which represents the undesired behavior, is then projected onto these components. Components associated with the undesired knowledge are filtered out, while those representing beneficial knowledge are preserved. This selective removal allows for targeted unlearning without significantly impacting the model's overall performance on general tasks.

## Foundational Learning
1. **Principal Component Analysis (PCA)**: A dimensionality reduction technique used to identify the most significant directions in the parameter space. Why needed: To separate beneficial and undesired knowledge in the model's parameter space. Quick check: Verify that the principal components capture a high percentage of the variance in the pre-trained model's parameters.

2. **Singular Value Decomposition (SVD)**: A matrix factorization method used to compute the principal components. Why needed: To efficiently obtain the principal components for large language models. Quick check: Confirm that the singular values decay rapidly, indicating that most information is captured in the first few components.

3. **Task Arithmetic**: A method of modifying model behavior by adding or subtracting task vectors. Why needed: To create a baseline for comparison and to understand the limitations of existing unlearning methods. Quick check: Evaluate the effectiveness of task arithmetic in removing undesired knowledge while preserving model utility.

## Architecture Onboarding

Component Map:
Pre-trained Model -> Singular Value Decomposition -> Principal Components -> Task Vector Projection -> Undesired Component Filtering -> Parameter Reconstruction -> Unlearned Model

Critical Path:
The critical path in Ethos involves computing the principal components, projecting the task vector, filtering undesired components, and reconstructing the model parameters. This process must be efficient to be practical for large language models.

Design Tradeoffs:
- Computational cost vs. unlearning effectiveness: Using more principal components may improve unlearning but increase computation time
- Number of principal components retained vs. model utility preservation: Retaining more components may better preserve utility but could also retain some undesired knowledge
- Task vector quality vs. unlearning specificity: A more accurate task vector leads to better targeted unlearning but may be harder to obtain

Failure Signatures:
- Insufficient unlearning: If the task vector does not accurately represent the undesired behavior or if too many principal components are retained
- Significant loss of model utility: If too many principal components are removed, potentially including those representing beneficial knowledge
- Overfitting to specific unlearning tasks: If the model becomes too specialized in avoiding the undesired behavior at the cost of general performance

First Experiments:
1. Evaluate Ethos on a simple sentiment analysis task, unlearning a specific bias while maintaining overall classification accuracy
2. Test the method on a smaller language model (e.g., 125M parameters) to verify the approach before scaling up
3. Compare the computational efficiency of Ethos with other unlearning methods on models of increasing size

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions. However, potential areas for further investigation include the method's scalability to larger models, its effectiveness on a broader range of undesired knowledge types, and its performance in real-world deployment scenarios.

## Limitations
- Effectiveness relies heavily on the quality of principal component analysis and the assumption of clean separation between beneficial and undesired knowledge
- Evaluation focuses on a limited scope of unlearning tasks, potentially overlooking other forms of undesired content
- Method's scalability to larger models and performance in real-world scenarios are not fully explored

## Confidence
- Effectiveness of Ethos in unlearning tasks: High
- Generalizability of the orthogonal parameter space approach: Medium
- Preservation of overall model utility: High for tested tasks, uncertain for broader applicability

## Next Checks
1. Evaluate Ethos on a wider range of unlearning tasks, including more nuanced forms of bias and different types of toxic content
2. Conduct comprehensive testing on larger language models (e.g., 13B+ parameters) to assess scalability and performance
3. Implement a long-term stability test to evaluate if the unlearned knowledge resurfaces during continued fine-tuning or exposure to new data