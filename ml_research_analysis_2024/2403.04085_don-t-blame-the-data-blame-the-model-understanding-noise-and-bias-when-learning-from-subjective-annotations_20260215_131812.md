---
ver: rpa2
title: 'Don''t Blame the Data, Blame the Model: Understanding Noise and Bias When
  Learning from Subjective Annotations'
arxiv_id: '2403.04085'
source_url: https://arxiv.org/abs/2403.04085
tags:
- confidence
- label
- annotator
- data
- annotations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the correlation between human annotator
  disagreement and model confidence in subjective classification tasks. The authors
  analyze three datasets (DSI, DMHS, DMDA) containing social media posts annotated
  for toxicity, bias, and offensive language.
---

# Don't Blame the Data, Blame the Model: Understanding Noise and Bias When Learning from Subjective Annotations

## Quick Facts
- arXiv ID: 2403.04085
- Source URL: https://arxiv.org/abs/2403.04085
- Authors: Abhishek Anand, Negar Mokhberian, Prathyusha Naresh Kumar, Anweasha Saha, Zihao He, Ashwin Rao, Fred Morstatter, Kristina Lerman
- Reference count: 12
- One-line primary result: Multi-GT models like DisCo show improved confidence on minority votes for high-disagreement samples compared to Single-GT models

## Executive Summary
This paper investigates how human annotator disagreement correlates with model confidence in subjective classification tasks. Using three datasets containing social media posts annotated for toxicity, bias, and offensive language, the authors demonstrate that models trained on majority vote labels exhibit systematically lower confidence on instances with high annotator disagreement. They propose using Multi-GT models like DisCo that learn from individual annotator labels rather than aggregated ones. The results show that DisCo can extract useful signals from minority annotations, improving confidence on instances where human annotators disagree substantially.

## Method Summary
The authors analyze three datasets (DSI, DMHS, DMDA) using data cartography to map instances by model confidence and variability during training. They compare Single-GT models (trained on majority vote labels using RoBERTa-Base) with Multi-GT models like DisCo that incorporate annotator identity as conditioning information. DisCo learns annotator-specific decision boundaries by processing (text, annotator_id) pairs through shared text encoders and annotator-specific modules. Models are trained for 5 epochs each, and training dynamics are analyzed to understand how confidence and variability correlate with annotator agreement levels.

## Key Results
- Single-GT models trained on majority vote labels show systematically lower confidence on high-disagreement instances
- DisCo improves confidence on minority votes for samples characterized by substantial annotation disagreements
- Training dynamics (confidence and variability) can effectively identify noisy versus genuinely ambiguous instances in subjective tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Single-GT models underfit on high-disagreement instances because the majority vote aggregates away the minority signal that is actually correct.
- Mechanism: The model is trained only on the majority label; if that label is noisy or wrong for subjective tasks, the minority correct annotations are never seen, so confidence on those instances stays low.
- Core assumption: High annotator disagreement does not imply noise—sometimes the minority vote is the true label.
- Evidence anchors:
  - [abstract] "models that are only provided aggregated labels show low confidence on high-disagreement data instances"
  - [section] "instances of heightened disagreement among human annotators correspond to a persistent trend of lower model confidence"
  - [corpus] Weak - corpus neighbors focus on different bias/noise topics, not directly on annotator disagreement.
- Break condition: If majority vote is always correct (objective tasks), this mechanism collapses—high disagreement then truly signals noise.

### Mechanism 2
- Claim: DisCo's architecture, which conditions predictions on annotator identity, can recover the minority signal that Single-GT models discard.
- Mechanism: By feeding (text, annotator_id) pairs into annotator-specific modules, DisCo learns distinct decision boundaries per annotator, allowing it to assign high confidence to annotations that deviate from the majority when they are actually correct.
- Core assumption: Annotator identity is a meaningful signal for the label distribution.
- Evidence anchors:
  - [section] "incorporating annotator-specific modules into a classifier... leads to superior performance"
  - [abstract] "DisCo shows improved confidence on minority votes for high-disagreement samples"
  - [corpus] Weak - corpus papers do not address annotator-specific modeling.
- Break condition: If annotator identity is uninformative or collapsed into the text semantics, DisCo's performance gain disappears.

### Mechanism 3
- Claim: Confidence variability across epochs is a proxy for label ambiguity; low confidence with low variability flags noisy labels in Single-GT, but high confidence with low variability can also flag unambiguous minority votes in Multi-GT.
- Mechanism: Training dynamics track how probability mass for the gold label shifts; for Multi-GT, seeing the minority annotation as gold stabilizes confidence quickly, whereas Single-GT never stabilizes on that minority signal.
- Core assumption: Training dynamics capture label informativeness, not just noise.
- Evidence anchors:
  - [section] "Data Maps define two intuitive measures... confidence and variability... lower model confidences correlate with higher chances of mislabeling"
  - [section] "When using Multi-GT models... improved confidence among minority votes for samples characterized by substantial annotation disagreements"
  - [corpus] Weak - corpus does not discuss training dynamics for label informativeness.
- Break condition: If the minority vote is truly random noise, variability will remain high and confidence will stay low even in Multi-GT.

## Foundational Learning

- Concept: Majority vote aggregation vs. raw annotation modeling
  - Why needed here: Explains why Single-GT fails on subjective tasks and why Multi-GT succeeds.
  - Quick check question: If 60% of annotators say "offensive" and 40% say "not offensive," what label does Single-GT learn, and what does DisCo see?
- Concept: Training dynamics as data cartography
  - Why needed here: Provides a quantitative way to separate easy/hard/noisy instances without manual inspection.
  - Quick check question: In Data Maps, which quadrant (high confidence/low variability) contains "easy" samples?
- Concept: Annotator identity as a conditioning variable
  - Why needed here: Core to DisCo's ability to learn multiple perspectives; without it the model collapses to Single-GT.
  - Quick check question: How does DisCo's input differ from a standard text classifier's input?

## Architecture Onboarding

- Component map: (text, annotator_id) -> text encoder -> annotator embedding -> combined representation -> classifier head -> per-annotator label probabilities
- Critical path:
  1. Encode text → annotator embedding → combined representation
  2. Project to label space → compute probabilities
  3. Update weights to match annotator's label
- Design tradeoffs:
  - Memory vs. performance: storing annotator embeddings for thousands of annotators can be large; can use hashing or low-rank approximations.
  - Cold-start: unseen annotators during training get default embeddings, hurting confidence.
  - Label sparsity: annotators with few annotations lead to unstable module updates.
- Failure signatures:
  - Very low confidence across all annotators → likely noisy text or annotator confusion
  - High confidence only for majority annotators → model hasn't learned minority perspectives
  - Confidence jumps drastically between epochs → possible overfitting to few annotator examples
- First 3 experiments:
  1. Run Data Maps on Single-GT baseline; plot confidence vs. annotator agreement to confirm low confidence on high-disagreement samples.
  2. Train DisCo on the same data; compare confidence distributions for majority vs. minority annotations on high-disagreement samples.
  3. Ablate annotator conditioning (remove annotator_id input); verify performance drops to Single-GT level.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different Multi-GT models compare in their ability to handle high-disagreement instances, beyond just DisCo?
- Basis in paper: [explicit] The paper mentions that future research can explore models that learn from the distribution of labels for each item, rather than requiring annotator IDs.
- Why unresolved: The paper only evaluates DisCo, a specific Multi-GT model that requires annotator IDs, limiting the understanding of how other Multi-GT approaches might perform.
- What evidence would resolve it: Comparative studies of various Multi-GT models (e.g., those learning label distributions) on datasets with high disagreement, measuring their confidence on minority votes and overall performance.

### Open Question 2
- Question: How does the performance of Multi-GT models vary across different demographic groups of annotators, and does this impact the model's fairness?
- Basis in paper: [inferred] The paper mentions the ethical consideration that annotator pools may not represent diverse societal perspectives, and suggests exploring datasets with demographic details for annotators and targets.
- Why unresolved: The paper does not analyze the performance of Multi-GT models across different demographic groups, leaving open the question of potential biases in model predictions.
- What evidence would resolve it: Analysis of Multi-GT model performance on datasets with demographic information, stratified by annotator and target demographics, to identify potential disparities in confidence and accuracy.

### Open Question 3
- Question: What is the optimal number of annotations per annotator needed for Multi-GT models like DisCo to effectively learn individual perspectives?
- Basis in paper: [explicit] The paper observes that DisCo struggles with datasets where the average number of annotations per annotator is low (e.g., DMHS with <20 annotations per annotator), suggesting a need for more annotations.
- Why unresolved: The paper does not provide a specific threshold or study the relationship between annotations per annotator and model performance, leaving the optimal amount unclear.
- What evidence would resolve it: Experiments varying the number of annotations per annotator in training data, measuring the impact on Multi-GT model performance (e.g., confidence on minority votes, overall accuracy) to identify a performance plateau or optimal range.

## Limitations

- DisCo's performance depends heavily on having sufficient annotations per annotator; datasets with sparse annotator overlap (like DMHS) limit the model's ability to learn reliable annotator-specific patterns
- The analysis assumes minority votes contain useful signal but does not directly validate whether these minority annotations are actually "correct" through expert adjudication
- The training dynamics analysis relies on confidence and variability metrics that may not fully capture the complexity of model behavior on ambiguous instances

## Confidence

**High Confidence Claims:**
- Models trained on majority vote labels show systematically lower confidence on high-disagreement instances
- DisCo architecture improves confidence on minority votes for high-disagreement samples
- Annotator disagreement correlates with reduced model confidence in subjective classification tasks

**Medium Confidence Claims:**
- Multi-GT models extract useful signal from minority annotations rather than treating them as noise
- Confidence variability during training can distinguish between truly noisy and genuinely ambiguous instances

**Low Confidence Claims:**
- The specific percentage improvements in confidence metrics translate to meaningful real-world performance gains
- DisCo's approach generalizes to domains beyond social media toxicity and bias detection

## Next Checks

1. **Annotator-level ablation study**: Train DisCo with varying numbers of annotator-specific modules (5, 10, 20 annotators) to determine the minimum annotation count per annotator needed for reliable signal extraction, and measure confidence degradation as annotator coverage decreases.

2. **Expert validation of minority votes**: Select 100 high-disagreement instances where DisCo shows high confidence on minority votes, have human experts adjudicate the correct label, and calculate the accuracy rate to verify that DisCo is actually learning correct minority signals rather than overfitting to noise.

3. **Cross-dataset generalization test**: Train DisCo on two datasets (e.g., DSI and DMHS) and evaluate on the third (DMDA) without any fine-tuning to assess whether the learned annotator-specific patterns transfer across different social media domains and annotation schemas.