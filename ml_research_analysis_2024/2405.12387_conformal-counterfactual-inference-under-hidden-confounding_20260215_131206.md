---
ver: rpa2
title: Conformal Counterfactual Inference under Hidden Confounding
arxiv_id: '2405.12387'
source_url: https://arxiv.org/abs/2405.12387
tags:
- data
- coverage
- wtcp-dr
- interval
- conformal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of constructing confidence intervals
  for counterfactual outcomes under hidden confounding, a key challenge in causal
  inference for reliable decision-making. The proposed methods, wTCP-DR and wSCP-DR,
  leverage weighted conformal prediction with density ratio estimation to provide
  marginal coverage guarantees without requiring strong ignorability assumptions.
---

# Conformal Counterfactual Inference under Hidden Confounding

## Quick Facts
- **arXiv ID:** 2405.12387
- **Source URL:** https://arxiv.org/abs/2405.12387
- **Authors:** Zonghao Chen; Ruocheng Guo; Jean-FranÃ§ois Ton; Yang Liu
- **Reference count:** 40
- **Primary result:** Proposes conformal counterfactual prediction methods that achieve marginal coverage under hidden confounding without strong ignorability assumptions.

## Executive Summary
This paper addresses the critical challenge of constructing confidence intervals for counterfactual outcomes when hidden confounding is present. Traditional causal inference methods often assume strong ignorability, which fails when unmeasured confounders affect both treatment assignment and outcomes. The authors propose weighted conformal prediction methods that leverage density ratio estimation to adjust for hidden confounding, providing valid marginal coverage guarantees even when strong ignorability assumptions are violated.

The proposed wTCP-DR and wSCP-DR methods combine observational and interventional data through weighted conformal prediction, achieving both theoretical guarantees and practical improvements in coverage and efficiency. Through extensive experiments on synthetic and real-world datasets, including recommendation systems, the methods demonstrate superior performance compared to baseline approaches, achieving the desired 0.9 coverage level with significantly smaller confidence intervals.

## Method Summary
The paper proposes two conformal prediction methods for counterfactual inference under hidden confounding: wTCP-DR (weighted Two Conformal Prediction with Density Ratio) and wSCP-DR (weighted Split Conformal Prediction with Density Ratio). Both methods leverage density ratio estimation to reweight observational data, effectively adjusting for the covariate shift caused by hidden confounders between observational and interventional distributions.

wTCP-DR uses a two-stage conformal prediction approach where the first stage estimates conformal scores using observational data, and the second stage calibrates these scores using interventional data. wSCP-DR offers a computationally efficient alternative by splitting the data into training and calibration sets. Both methods require estimating the density ratio between interventional and observational distributions, which can be done using standard density ratio estimation techniques or by leveraging known treatment assignment probabilities.

## Key Results
- wTCP-DR achieves marginal coverage guarantees under hidden confounding without requiring strong ignorability assumptions
- Experimental results show wTCP-DR outperforms baseline methods across synthetic and real-world datasets, achieving 0.9 coverage with significantly smaller intervals
- wSCP-DR provides a computationally efficient alternative with similar coverage guarantees
- Methods perform particularly well when hidden confounding is weak or when effective sample size is large relative to interventional data

## Why This Works (Mechanism)
The methods work by recognizing that hidden confounding creates a covariate shift between observational and interventional distributions. By estimating the density ratio between these distributions, the methods can reweight observational data to approximate the interventional distribution. This allows conformal prediction to be performed on a distribution that better matches the interventional setting, maintaining valid coverage guarantees even when strong ignorability fails.

The key insight is that while we cannot directly observe or adjust for hidden confounders, we can leverage the fact that we have access to both observational data (where confounders may affect treatment) and interventional data (where treatment is randomized). The density ratio effectively captures the selection bias introduced by hidden confounders, allowing the methods to correct for this bias through appropriate reweighting.

## Foundational Learning

**Density Ratio Estimation**: Why needed - to quantify the covariate shift between observational and interventional distributions caused by hidden confounding. Quick check - verify the density ratio estimator performs well on held-out validation data and that estimated ratios are reasonable (e.g., not extreme values).

**Conformal Prediction Theory**: Why needed - provides the theoretical foundation for constructing prediction intervals with guaranteed coverage. Quick check - confirm the conformal scores satisfy exchangeability assumptions and that coverage holds on calibration data.

**Causal Inference under Hidden Confounding**: Why needed - understanding when and why standard causal identification fails motivates the need for alternative approaches. Quick check - assess sensitivity of results to different levels of hidden confounding through simulation studies.

## Architecture Onboarding

**Component Map**: Density Ratio Estimator -> Conformal Score Calculator -> Coverage Calibration -> Confidence Interval Construction

**Critical Path**: The most critical computational path involves density ratio estimation, as errors here propagate through the entire pipeline. The conformal score calculation depends on accurate density ratios, and coverage calibration assumes these ratios are correctly estimated.

**Design Tradeoffs**: wTCP-DR trades computational efficiency for potentially tighter intervals by using a two-stage approach, while wSCP-DR sacrifices some efficiency for computational speed through data splitting. The choice between them depends on available computational resources and desired interval tightness.

**Failure Signatures**: Poor density ratio estimation manifests as systematic under or over-coverage. Extreme density ratio estimates (very large or very small values) indicate potential issues with the estimator or regions of covariate space with insufficient data.

**First Experiments**: 1) Validate density ratio estimation on synthetic data with known ratios. 2) Test coverage guarantees on semi-synthetic data with varying levels of hidden confounding. 3) Compare computational efficiency of wTCP-DR vs wSCP-DR on moderate-sized datasets.

## Open Questions the Paper Calls Out

None identified in the provided content.

## Limitations

- Strong dependence on accurate density ratio estimation, with potential performance degradation under model misspecification
- Computational complexity of wTCP-DR may limit scalability to high-dimensional settings
- Effectiveness diminishes as hidden confounding becomes stronger, though the paper focuses on weak confounding scenarios
- Limited exploration of robustness to density ratio estimation errors in empirical evaluation

## Confidence

**High confidence** in theoretical framework and coverage guarantees, as these are rigorously derived and align with established conformal prediction principles.

**Medium confidence** in empirical performance claims, as experiments demonstrate strong results but are limited to specific datasets and scenarios.

**Low confidence** in scalability and robustness claims, particularly regarding high-dimensional settings and density ratio estimation under model misspecification.

## Next Checks

1. **Robustness Testing**: Evaluate method performance under varying degrees of density ratio estimation error, including scenarios with misspecified models or high-dimensional confounders.

2. **Scalability Analysis**: Assess computational efficiency and coverage guarantees for high-dimensional datasets, comparing wTCP-DR and wSCP-DR under resource constraints.

3. **Real-World Application**: Apply methods to a high-stakes decision-making domain (e.g., healthcare or policy) with known hidden confounding, validating coverage and efficiency in practice.