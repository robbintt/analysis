---
ver: rpa2
title: 'Graph Edits for Counterfactual Explanations: A comparative study'
arxiv_id: '2401.11609'
source_url: https://arxiv.org/abs/2401.11609
tags:
- graph
- counterfactual
- graphs
- kernel
- explanations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates the use of Graph Neural Networks (GNNs)
  for generating counterfactual explanations in image classification. It compares
  supervised and unsupervised GNN approaches, focusing on scene graphs as a more expressive
  representation than previous methods.
---

# Graph Edits for Counterfactual Explanations: A comparative study

## Quick Facts
- arXiv ID: 2401.11609
- Source URL: https://arxiv.org/abs/2401.11609
- Authors: Angeliki Dimitriou; Nikolaos Chaidos; Maria Lymperaiou; Giorgos Stamou
- Reference count: 5
- Key outcome: Supervised Graph Neural Networks, particularly GCN, outperform unsupervised methods for counterfactual explanations on scene graphs, with density significantly impacting performance.

## Executive Summary
This study investigates Graph Neural Networks (GNNs) for generating counterfactual explanations in image classification tasks. The authors compare supervised and unsupervised GNN approaches using scene graphs as a more expressive representation than pixel-level edits. They evaluate multiple GNN architectures (GCN, GAT, GIN) along with graph kernels and autoencoders on the Visual Genome dataset, finding that supervised methods achieve better performance in NDCG and precision metrics, especially on dense scene graph datasets.

## Method Summary
The study uses scene graphs extracted from the Visual Genome dataset and employs a pre-trained PLACES-360 classifier for label assignment. Two dataset splits are created: VG-DENSE (dense interconnected graphs) and VG-RANDOM (unrestricted density). Ground truth Graph Edit Distances (GED) are computed for supervised training. The authors evaluate GCN, GAT, and GIN architectures along with graph kernels and autoencoders, using cosine similarity in embedding space for retrieval. Performance is measured using NDCG and precision metrics.

## Key Results
- Supervised GNNs, particularly GCN, outperform other methods in NDCG and precision metrics
- Dense scene graph datasets (VG-DENSE) achieve significantly better results than random density datasets
- Unsupervised GNNs offer faster computation but lower accuracy compared to supervised approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph-based counterfactual explanations outperform pixel-level edits in semantic interpretability.
- Mechanism: Scene graphs encode object relationships and semantic context, allowing edits to reflect high-level conceptual changes rather than low-level pixel perturbations.
- Core assumption: The classification model's decision boundary depends on semantic relationships between objects, not just their presence or visual appearance.
- Evidence anchors:
  - [abstract] "scene graphs as a more expressive representation than previous methods"
  - [section] "a natural extension of the techniques of Filandrianos et al. (2022); Dervakos et al. (2023) suggests the optimal matching of scene graphs"
  - [corpus] Weak correlation; no direct evidence in cited neighbors about semantic superiority of graph-based approaches.
- Break condition: If the underlying classifier relies primarily on low-level visual features or texture patterns that are not captured in scene graphs, the semantic edits may not align with actual model behavior.

### Mechanism 2
- Claim: Supervised GNNs outperform unsupervised methods in counterfactual retrieval accuracy.
- Mechanism: Supervised GNNs are trained directly on ground truth graph edit distances, learning the specific patterns of minimal edits needed to change classification labels.
- Core assumption: The training data of labeled graph pairs adequately represents the true minimal edit paths between classes.
- Evidence anchors:
  - [section] "supervised GNN models demonstrate better performance in all ranking metrics, with the most successful variant being GCN"
  - [abstract] "Results show that supervised GNNs, particularly GCN, outperform other methods in terms of NDCG and precision metrics"
  - [corpus] No direct evidence in neighbors about supervised vs unsupervised GNN performance comparisons.
- Break condition: If the ground truth GED labels contain noise or if the training distribution doesn't match the test distribution, supervised models may overfit to specific patterns rather than learning generalizable edit rules.

### Mechanism 3
- Claim: Scene graph density significantly impacts model performance.
- Mechanism: Dense scene graphs provide more interconnections for message passing in GNNs, enabling better capture of object relationships and dependencies.
- Core assumption: More interconnections in scene graphs provide richer information for the model to learn meaningful semantic relationships.
- Evidence anchors:
  - [section] "By comparing ranking metrics across the two dataset splits, we can easily observe that best results overall were achieved in the DENSE split"
  - [abstract] "especially on dense scene graph datasets"
  - [corpus] No direct evidence in neighbors about the impact of graph density on model performance.
- Break condition: If the underlying classification task doesn't actually depend on complex object relationships, or if the dataset is inherently sparse, dense graph representations may not provide additional benefit.

## Foundational Learning

- Concept: Graph Edit Distance (GED) and its computational complexity
  - Why needed here: Understanding why graph kernels and GNNs are needed instead of direct GED calculation for counterfactual generation
  - Quick check question: Why is calculating exact GED between two graphs computationally expensive, and what is its time complexity?

- Concept: Scene graph representation and construction
  - Why needed here: Understanding how images are converted to graph representations that capture semantic relationships
  - Quick check question: What are the key components of a scene graph (nodes, edges, triples) and how do they relate to image semantics?

- Concept: Knowledge graph integration (WordNet)
  - Why needed here: Understanding how semantic distances are calculated between concepts for edit cost assignment
  - Quick check question: How does WordNet provide semantic distance measures between concepts, and why is this important for counterfactual explanations?

## Architecture Onboarding

- Component map:
  Image → Scene Graph Converter → Graph Edit Distance Calculator → Graph Machine Learning Models → Embedding Space + Similarity Search → Counterfactual Generator

- Critical path:
  1. Convert input image to scene graph
  2. Compute ground truth GED for training data (supervised) or use raw graphs (unsupervised)
  3. Train graph model to learn similarity in embedding space
  4. For new input, generate embedding and find closest counterfactual graph
  5. Compute edit path between input and counterfactual graphs

- Design tradeoffs:
  - Supervised GNNs: Higher accuracy but require O(N²) training pairs and expensive ground truth GED computation
  - Unsupervised GAEs: Lower accuracy but scalable with O(N) training data and no ground truth GED needed
  - Graph density: Dense graphs improve performance but may not be available for all datasets
  - Knowledge base: WordNet provides semantic consistency but may not cover all domain-specific concepts

- Failure signatures:
  - Poor counterfactual quality: May indicate inadequate scene graph representation or mismatch between semantic distances and actual model behavior
  - High computational cost: Could suggest inefficient model choice (supervised vs unsupervised) for available data size
  - Inconsistent results across models: Might indicate noisy ground truth labels or insufficient training data

- First 3 experiments:
  1. Implement scene graph extraction on a small subset of Visual Genome and verify basic graph structure
  2. Compute ground truth GED between sample graph pairs using optimized algorithms and validate with manual inspection
  3. Train a simple GCN on a small labeled dataset and evaluate retrieval performance against ground truth GED rankings

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal graph density threshold that maximizes the interpretability and accuracy of counterfactual explanations?
- Basis in paper: [inferred] The paper compares VG-DENSE (high density) and VG-RANDOM (variable density) datasets, showing better performance on dense graphs.
- Why unresolved: The paper doesn't specify an exact density threshold or analyze the relationship between graph density and explanation quality.
- What evidence would resolve it: Experiments testing multiple density thresholds and measuring both NDCG/Precision metrics and human interpretability scores.

### Open Question 2
- Question: How does the choice of knowledge graph (e.g., WordNet vs ConceptNet vs domain-specific ontologies) affect the quality and relevance of counterfactual explanations?
- Basis in paper: [explicit] The paper uses WordNet as the knowledge source for semantic distances but doesn't compare it to alternatives.
- Why unresolved: Only one knowledge graph is tested, and the paper doesn't analyze how different semantic hierarchies might impact explanation quality.
- What evidence would resolve it: Comparative experiments using different knowledge graphs while measuring both quantitative metrics and qualitative human evaluations.

### Open Question 3
- Question: What is the minimum dataset size required for unsupervised GNNs to match the performance of supervised GNNs in counterfactual explanation tasks?
- Basis in paper: [explicit] The paper notes that unsupervised approaches require fewer training samples but don't achieve the same performance as supervised methods.
- Why unresolved: The paper only tests one dataset size (N=500) and doesn't explore how performance scales with dataset size.
- What evidence would resolve it: Systematic experiments varying dataset size and measuring performance convergence points between supervised and unsupervised approaches.

## Limitations
- Limited generalization due to single dataset (Visual Genome) usage
- Reliance on ground truth GED calculations without external validation
- Single knowledge graph (WordNet) used for semantic distances

## Confidence
- **High Confidence**: The comparative methodology between different GNN architectures and the use of standard metrics (NDCG, precision) is methodologically sound.
- **Medium Confidence**: Claims about semantic interpretability advantages and density effects require external validation beyond the reported experiments.
- **Low Confidence**: The assertion that scene graphs are "more expressive" than previous methods lacks comparative evidence against specific baseline techniques.

## Next Checks
1. **Cross-Dataset Validation**: Apply the same GNN approaches to a different scene graph dataset (e.g., GQA or Open Images) to test generalization of density effects and supervised vs unsupervised performance differences.

2. **Ground Truth Verification**: Manually inspect a random sample of ground truth GED calculations to verify semantic consistency and identify potential systematic errors in the automated generation process.

3. **Classifier Behavior Analysis**: Use input saliency methods on the PLACES-360 classifier to verify that counterfactual edits actually target the features the classifier uses, rather than assumed semantic relationships.