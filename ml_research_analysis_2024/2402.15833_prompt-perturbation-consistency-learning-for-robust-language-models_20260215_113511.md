---
ver: rpa2
title: Prompt Perturbation Consistency Learning for Robust Language Models
arxiv_id: '2402.15833'
source_url: https://arxiv.org/abs/2402.15833
tags:
- llms
- performance
- data
- arxiv
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the robustness of large language models (LLMs)
  to input perturbations in sequence labeling tasks like intent classification and
  slot filling. The authors propose Prompt Perturbation Consistency Learning (PPCL),
  a method that regularizes the divergence between model predictions on clean and
  perturbed inputs during fine-tuning.
---

# Prompt Perturbation Consistency Learning for Robust Language Models

## Quick Facts
- **arXiv ID**: 2402.15833
- **Source URL**: https://arxiv.org/abs/2402.15833
- **Reference count**: 15
- **Primary result**: Recovers on average 59% of intent classification and 69% of slot filling performance drops due to oronym, synonym, and paraphrasing perturbations.

## Executive Summary
This paper addresses the robustness of large language models (LLMs) to input perturbations in sequence labeling tasks like intent classification and slot filling. The authors propose Prompt Perturbation Consistency Learning (PPCL), a method that regularizes the divergence between model predictions on clean and perturbed inputs during fine-tuning. PPCL is evaluated on three datasets (ATIS, SNIPS, MASSIVE) and shows significant improvements in robustness, recovering on average 59% of intent classification and 69% of slot filling performance drops due to oronym, synonym, and paraphrasing perturbations. PPCL outperforms data augmentation approaches while using ten times fewer augmented samples.

## Method Summary
PPCL combines standard cross-entropy loss with Jensen-Shannon divergence regularization to encourage consistency between predictions on clean and perturbed inputs. The method uses structured prompt formats with sentinel tokens to simplify sequence labeling tasks. Data augmentation is performed by generating oronym, synonym, and paraphrase perturbations, filtered by semantic similarity (BertScore > 0.85). The approach is evaluated on intent classification and slot filling tasks using three datasets.

## Key Results
- Recovers on average 59% of intent classification performance drops and 69% of slot filling performance drops due to perturbations
- Outperforms data augmentation baselines while using ten times fewer augmented samples
- Shows consistent improvements across three datasets (ATIS, SNIPS, MASSIVE) and three perturbation types (oronyms, synonyms, paraphrasing)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PPCL improves robustness by explicitly regularizing the divergence between predictions on clean and perturbed inputs.
- Mechanism: During fine-tuning, PPCL adds a Jensen-Shannon divergence term between the probability distributions of model outputs for clean and perturbed utterances.
- Core assumption: JS divergence provides a smooth, symmetric measure of similarity that effectively regularizes consistency between clean and perturbed inputs.
- Evidence anchors:
  - [section]: "We then apply JS divergence to quantify the similarity between y^c and y^p. JS is a symmetric variation of Kullback–Leibler divergence (KL), defined as: JS(y^c || y^p) = 1/2 (KL(y^c || y^m)+KL(y^p||y^m)), where y^m = 1/2 (y^c + y^p)."
  - [abstract]: "Finally, we propose an efficient mitigation approach, prompt perturbation consistency learning (PPCL), which works by regularizing the divergence between losses from clean and perturbed samples."
- Break condition: If perturbations change semantic meaning beyond the similarity threshold, the JS regularization could force incorrect consistency.

### Mechanism 2
- Claim: Sentinel-based structured prompt format improves sequence labeling performance by simplifying token tracking and reducing redundant input repetition.
- Mechanism: Sentinel tokens replace repeated original tokens in the target output, allowing the model to focus on learning the association between tokens and slot labels without explicit index tracking.
- Core assumption: Removing redundant tokens and using sentinels makes the decoding process more efficient and reduces hallucination potential.
- Evidence anchors:
  - [section]: "These sentinel markers enable us to avoid redundant inclusion of the original tokens in the target output. Instead, the sentinel tokens are employed to facilitate the learning of associations between tokens and their corresponding slot labels."
  - [section]: "Our constructed prompt formats offer several advantages: (1) The structured format efficiently arranges the input and output labels within a coherent structure, leading to improved learning ability for the models. (2) The sentinel-based formats eliminate the need for redundant input repetition, simplifying the decoding process and preventing hallucinations."
- Break condition: If the sentinel mapping becomes ambiguous or the model fails to learn the association between sentinels and original tokens.

### Mechanism 3
- Claim: Data augmentation with perturbations improves model generalization by exposing the model to diverse linguistic variations while maintaining semantic consistency.
- Mechanism: By generating perturbed versions of training data and filtering them based on semantic similarity (BertScore > 0.85), the model learns to handle real-world variations like ASR errors and linguistic differences.
- Core assumption: The filtered perturbations maintain semantic equivalence while providing sufficient variation to improve robustness.
- Evidence anchors:
  - [section]: "We also paraphrase the training data, providing LLMs with more examples to learn different ways of expressing the same content."
  - [section]: "To further ensure that clean and perturbed samples are semantically similar, we filter out perturbations with BERTScore (Zhang et al., 2019) with the original sample. We use a 0.85 threshold based on our empirical experimental studies."
  - [section]: "Our experiments show that PPCL can recover on an average 59% and 69% of the dropped performance for IC and SF tasks against perturbations, respectively."
- Break condition: If the semantic similarity threshold is too low, the model may learn incorrect associations; if too high, the variation may be insufficient for robustness.

## Foundational Learning

- **Concept: Jensen-Shannon Divergence**
  - Why needed here: JS divergence provides a symmetric, smoothed measure of similarity between probability distributions for clean and perturbed inputs, avoiding the asymmetry issues of KL divergence.
  - Quick check question: How does JS divergence differ from KL divergence, and why is this difference important for measuring similarity between clean and perturbed predictions?

- **Concept: Sequence Labeling vs Text Generation**
  - Why needed here: Understanding the fundamental difference between sequence labeling tasks and text generation tasks helps explain why traditional LLMs struggle with SF and why specialized prompt formats are needed.
  - Quick check question: What are the key differences between sequence labeling and text generation tasks, and how do these differences impact model architecture and training?

- **Concept: Data Augmentation Filtering**
  - Why needed here: The semantic filtering step (using BertScore > 0.85) is crucial for ensuring that augmented data maintains the correct semantic meaning while providing variation.
  - Quick check question: Why is semantic filtering important in data augmentation for NLP tasks, and what could go wrong if this step is skipped or the threshold is set incorrectly?

## Architecture Onboarding

- **Component map**: Clean utterance → Structured prompt → LLM prediction → Structured hypothesis extraction → Evaluation
- **Critical path**: The critical path is: clean utterance → structured prompt → LLM prediction → structured hypothesis extraction → evaluation. For PPCL, this extends to: clean utterance → perturbation generation → paired prediction (clean+perturbed) → JS regularization → final prediction.
- **Design tradeoffs**: The sentinel-based format improves SF performance but requires careful design of sentinel-token mappings. The semantic filtering threshold (0.85) balances variation vs correctness but may need tuning per dataset. PPCL requires additional computation for paired predictions but achieves better robustness than simple augmentation.
- **Failure signatures**: Performance drops on perturbed data indicate insufficient robustness; incorrect slot predictions suggest sentinel mapping issues; high variance in predictions across perturbations suggests inadequate regularization.
- **First 3 experiments**:
  1. Compare model performance on clean vs perturbed test sets to establish baseline robustness (IC-PDR and SF-PDR metrics).
  2. Evaluate different prompt formats (simple vs structured, tag-only vs sentinel-based) on IC-SF performance.
  3. Test PPCL with different loss weight combinations (λ1, λ2, λ3) to find optimal balance between standard loss and consistency regularization.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed Prompt Perturbation Consistency Learning (PPCL) framework perform on other structured prediction tasks beyond intent classification and slot filling (IC-SF)?
- Basis in paper: [inferred] The paper demonstrates PPCL's effectiveness on IC-SF tasks but does not explore its applicability to other structured prediction tasks like named entity recognition or part-of-speech tagging.
- Why unresolved: The paper focuses solely on evaluating PPCL on IC-SF tasks, leaving its performance on other structured prediction tasks unexplored.
- What evidence would resolve it: Conducting experiments to evaluate PPCL's performance on a diverse set of structured prediction tasks, such as named entity recognition, part-of-speech tagging, or semantic role labeling, would provide insights into its generalizability and effectiveness across different domains.

### Open Question 2
- Question: How does the performance of PPCL vary with different types and degrees of perturbations?
- Basis in paper: [explicit] The paper evaluates PPCL's performance against three types of perturbations (oronyms, synonyms, and paraphrases) but does not explore the impact of varying the degree or type of perturbation within each category.
- Why unresolved: The paper uses a fixed set of perturbations for evaluation, which may not fully capture the range of potential variations that models might encounter in real-world scenarios.
- What evidence would resolve it: Conducting experiments with a wider range of perturbations, including different types and degrees of perturbations within each category, would provide a more comprehensive understanding of PPCL's robustness and limitations.

### Open Question 3
- Question: How does PPCL's performance compare to other data augmentation techniques, such as back-translation or generative models, in terms of efficiency and effectiveness?
- Basis in paper: [inferred] The paper compares PPCL to data augmentation using perturbed samples but does not directly compare it to other data augmentation techniques like back-translation or generative models.
- Why unresolved: The paper focuses on comparing PPCL to a specific data augmentation approach but does not provide a comprehensive comparison with other widely used techniques.
- What evidence would resolve it: Conducting experiments to compare PPCL's performance with other data augmentation techniques, such as back-translation or generative models, in terms of both efficiency (computational cost) and effectiveness (improvement in model robustness) would provide valuable insights into its relative strengths and weaknesses.

## Limitations

- The sentinel-based prompt format requires careful design of sentinel-token mappings and may not generalize well to all sequence labeling tasks
- The semantic similarity threshold (0.85) is empirically chosen without systematic sensitivity analysis
- The approach requires additional computation for paired predictions during training, increasing training time and resource requirements

## Confidence

- **High confidence**: The overall effectiveness of PPCL in reducing performance drops (59% for IC, 69% for SF) and outperforming data augmentation baselines.
- **Medium confidence**: The specific mechanisms of JS divergence regularization, sentinel-based prompt formats, and the optimal threshold of 0.85 for semantic filtering.
- **Medium confidence**: The claim that PPCL achieves better results with ten times fewer augmented samples than pure data augmentation approaches.

## Next Checks

1. **Ablation study on semantic similarity threshold**: Systematically vary the BertScore threshold (0.75, 0.80, 0.85, 0.90, 0.95) and measure the tradeoff between perturbation diversity and semantic preservation. This would validate whether 0.85 is truly optimal or dataset-dependent.

2. **Sentinel mapping robustness analysis**: Create controlled test cases where the sentinel mapping could be ambiguous (e.g., repeated slot labels, complex slot hierarchies) and measure how often the model correctly resolves these ambiguities. This would validate the claim that sentinel formats simplify decoding.

3. **JS divergence sensitivity analysis**: Test PPCL with different divergence measures (KL, JS, Wasserstein) and regularization strengths (λ weights) to determine whether JS divergence is uniquely effective or if other measures could work equally well. This would validate the specific choice of JS divergence over alternatives.