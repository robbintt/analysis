---
ver: rpa2
title: 'Comprehensible Artificial Intelligence on Knowledge Graphs: A survey'
arxiv_id: '2404.03499'
source_url: https://arxiv.org/abs/2404.03499
tags:
- graph
- knowledge
- methods
- https
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The survey taxonomizes Comprehensible Artificial Intelligence (CAI)
  methods on Knowledge Graphs (KGs) into Interpretable Machine Learning (IML) and
  Explainable Artificial Intelligence (XAI). It argues that the distinction between
  these two concepts is often unclear and introduces CAI as a unifying term.
---

# Comprehensible Artificial Intelligence on Knowledge Graphs: A survey

## Quick Facts
- arXiv ID: 2404.03499
- Source URL: https://arxiv.org/abs/2404.03499
- Reference count: 40
- Comprehensible Artificial Intelligence (CAI) methods on Knowledge Graphs (KGs) are taxonomized into Interpretable Machine Learning (IML) and Explainable Artificial Intelligence (XAI)

## Executive Summary
This survey provides a comprehensive taxonomy of Comprehensible Artificial Intelligence (CAI) methods on Knowledge Graphs (KGs), unifying the often-confused concepts of Interpretable Machine Learning (IML) and Explainable Artificial Intelligence (XAI) under the umbrella term CAI. The taxonomy categorizes CAI methods based on their representation (symbolic, sub-symbolic, neuro-symbolic), task (link prediction, node clustering, graph clustering, recommendation), foundation (factorization machines, translational learning, rule-based learning, neural networks, reinforcement learning), and comprehensibility (IML or XAI). The survey reviews 55 selected publications and identifies key research gaps in the field, such as the need for more XAI methods for link prediction tasks and KG-specific XAI methods that leverage semantic information.

## Method Summary
The survey employs a systematic literature review approach to identify and categorize CAI methods on KGs. The authors selected 55 publications from various sources, including major conferences and journals in artificial intelligence and knowledge representation. The methods were then classified based on their representation, task, foundation, and comprehensibility. The survey also identifies research gaps and provides insights into the current state and future directions of CAI research on KGs.

## Key Results
- The survey introduces CAI as a unifying term for IML and XAI methods on KGs, addressing the often unclear distinction between these two concepts.
- The taxonomy categorizes CAI methods based on representation, task, foundation, and comprehensibility, providing a structured overview of the field.
- The survey identifies research gaps, including the need for more XAI methods for link prediction tasks and KG-specific XAI methods that leverage semantic information.

## Why This Works (Mechanism)
The survey's approach works by providing a comprehensive and structured taxonomy of CAI methods on KGs, which helps to clarify the often-confused concepts of IML and XAI. By categorizing methods based on their representation, task, foundation, and comprehensibility, the survey offers a clear framework for understanding the current state of CAI research on KGs and identifying areas for future work.

## Foundational Learning
1. Knowledge Graphs (KGs) - Why needed: KGs provide a structured representation of knowledge, enabling AI systems to reason and make decisions based on rich semantic information. Quick check: Verify that the survey's definition of KGs aligns with standard definitions in the literature.
2. Interpretable Machine Learning (IML) - Why needed: IML methods aim to provide insights into the decision-making process of AI models, making them more transparent and trustworthy. Quick check: Assess the survey's classification of IML methods and their applications on KGs.
3. Explainable Artificial Intelligence (XAI) - Why needed: XAI methods focus on explaining the outputs or behaviors of AI models to human users, enhancing their understanding and trust in the system. Quick check: Evaluate the survey's categorization of XAI methods and their specific use cases on KGs.

## Architecture Onboarding
Component map: Knowledge Graph -> CAI Methods -> Representation -> Task -> Foundation -> Comprehensibility
Critical path: The critical path involves the integration of CAI methods with KGs to provide interpretable and explainable AI solutions.
Design tradeoffs: The survey highlights the tradeoffs between different representations (symbolic, sub-symbolic, neuro-symbolic) and their impact on the comprehensibility of CAI methods.
Failure signatures: The survey identifies potential failure modes, such as the lack of XAI methods for link prediction tasks and KG-specific XAI methods that leverage semantic information.
First experiments:
1. Verify the survey's classification of a selected subset of CAI methods on KGs by independently reviewing their representation, task, foundation, and comprehensibility.
2. Conduct a citation analysis to determine the impact and adoption of the proposed taxonomy within the CAI and KG research communities.
3. Perform a systematic literature review to identify any significant CAI methods on KGs that may have been omitted from the survey, particularly focusing on recent publications.

## Open Questions the Paper Calls Out
The survey identifies several open questions and research gaps, including:
- The need for more XAI methods for link prediction tasks on KGs
- The lack of KG-specific XAI methods that leverage semantic information
- The potential for combining different representations (symbolic, sub-symbolic, neuro-symbolic) to enhance the comprehensibility of CAI methods

## Limitations
- The distinction between IML and XAI remains somewhat subjective, as these terms are often used interchangeably in practice.
- The categorization of methods based on their representation, task, foundation, and comprehensibility may not capture all nuances of the rapidly evolving field.
- The selection of 55 publications, while extensive, may not represent the complete landscape of CAI research on KGs.

## Confidence
High: The survey's taxonomy and categorizations based on representation and task are well-defined concepts in the literature.
Medium: The confidence in the foundation and comprehensibility categorizations is medium, given the overlapping nature of some methods and the potential for interpretation differences.

## Next Checks
1. Verify the survey's classification of selected methods by independently reviewing a subset of the 55 publications and assessing their representation, task, foundation, and comprehensibility categorizations.
2. Conduct a citation analysis of the survey's findings to determine the impact and adoption of the proposed taxonomy within the CAI and KG research communities.
3. Perform a systematic literature review to identify any significant CAI methods on KGs that may have been omitted from the survey, particularly focusing on recent publications that could expand the current taxonomy.