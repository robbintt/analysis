---
ver: rpa2
title: 'CORE: Mitigating Catastrophic Forgetting in Continual Learning through Cognitive
  Replay'
arxiv_id: '2402.01348'
source_url: https://arxiv.org/abs/2402.01348
tags:
- task
- forgetting
- tasks
- learning
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses catastrophic forgetting in continual learning,
  where neural networks lose previously learned knowledge when acquiring new tasks.
  The authors propose COgnitive REplay (CORE), which introduces two key strategies:
  Adaptive Quantity Allocation and Quality-Focused Data Selection.'
---

# CORE: Mitigating Catastrophic Forgetting in Continual Learning through Cognitive Replay

## Quick Facts
- arXiv ID: 2402.01348
- Source URL: https://arxiv.org/abs/2402.01348
- Reference count: 9
- Primary result: CORE achieves 37.95% average accuracy on split-CIFAR10, surpassing the best baseline by 6.52%

## Executive Summary
This paper addresses catastrophic forgetting in continual learning, where neural networks lose previously learned knowledge when acquiring new tasks. The authors propose COgnitive REplay (CORE), which introduces two key strategies: Adaptive Quantity Allocation and Quality-Focused Data Selection. These strategies dynamically allocate replay buffer space based on each task's forgetting rate and select representative data samples that best capture task characteristics. CORE is inspired by human cognitive review processes, specifically Targeted Recall and Spaced Repetition strategies. Experiments on split-MNIST, split-CIFAR10, and split-CIFAR100 datasets demonstrate CORE's effectiveness, achieving an average accuracy of 37.95% on split-CIFAR10, surpassing the best baseline method by 6.52%. Additionally, CORE significantly improves the accuracy of the poorest-performing task by 6.30% compared to the top baseline. The results highlight CORE's superiority in mitigating catastrophic forgetting and maintaining balanced performance across tasks.

## Method Summary
CORE introduces two key strategies to address catastrophic forgetting: Adaptive Quantity Allocation and Quality-Focused Data Selection. The Adaptive Quantity Allocation strategy dynamically allocates replay buffer space based on each task's forgetting rate, ensuring that tasks more prone to forgetting receive more memory resources. The Quality-Focused Data Selection strategy selects representative data samples that best capture the characteristics of each task, optimizing the use of limited buffer space. These strategies are inspired by human cognitive review processes, specifically Targeted Recall and Spaced Repetition, which prioritize the review of information based on its importance and the likelihood of forgetting. By combining these approaches, CORE effectively mitigates catastrophic forgetting while maintaining balanced performance across tasks in continual learning scenarios.

## Key Results
- CORE achieves 37.95% average accuracy on split-CIFAR10, outperforming the best baseline by 6.52%
- CORE significantly improves the accuracy of the poorest-performing task by 6.30% compared to the top baseline
- CORE demonstrates superiority in mitigating catastrophic forgetting and maintaining balanced performance across tasks

## Why This Works (Mechanism)
CORE works by dynamically managing replay buffer resources based on task-specific forgetting rates. The Adaptive Quantity Allocation strategy ensures that tasks more prone to forgetting receive proportionally more buffer space, preventing catastrophic forgetting in vulnerable tasks. The Quality-Focused Data Selection strategy optimizes buffer usage by selecting the most representative samples for each task, maximizing the information retained per unit of buffer space. This dual approach mirrors human cognitive strategies of Targeted Recall (focusing on information likely to be forgotten) and Spaced Repetition (optimizing review timing based on forgetting curves). By combining these mechanisms, CORE maintains a balance between preserving old knowledge and acquiring new information, effectively addressing the stability-plasticity dilemma in continual learning.

## Foundational Learning
- **Catastrophic forgetting**: The phenomenon where neural networks lose previously learned knowledge when trained on new tasks. Why needed: Core problem being addressed. Quick check: Observe performance degradation on earlier tasks when training on new tasks.
- **Replay buffers**: Memory structures that store samples from previous tasks for rehearsal during training. Why needed: Mechanism to prevent forgetting by maintaining exposure to old data. Quick check: Buffer size and sampling strategy impact performance.
- **Forgetting rate**: The rate at which performance on a task degrades over time without rehearsal. Why needed: Metric to guide adaptive resource allocation. Quick check: Track performance decay curves for each task.
- **Targeted Recall**: Cognitive strategy focusing review on information likely to be forgotten. Why needed: Inspiration for adaptive allocation strategy. Quick check: Prioritize high-forgetting-rate tasks for resource allocation.
- **Spaced Repetition**: Learning technique that optimizes review timing based on forgetting curves. Why needed: Inspiration for quality-focused selection strategy. Quick check: Select samples that maximize information retention per review.

## Architecture Onboarding

**Component Map**: Task Learner -> Forgetting Rate Monitor -> Buffer Manager -> Sample Selector -> Replay Buffer -> Task Learner

**Critical Path**: Task Learner -> Forgetting Rate Monitor -> Buffer Manager -> Sample Selector -> Replay Buffer -> Task Learner

**Design Tradeoffs**: CORE trades increased memory overhead for improved performance across tasks. The adaptive buffer allocation requires additional computation to monitor forgetting rates and adjust allocations dynamically, but this overhead is justified by the significant improvements in mitigating catastrophic forgetting and maintaining balanced performance.

**Failure Signatures**: 
- Insufficient buffer size leads to poor performance across all tasks
- Incorrect forgetting rate estimation results in suboptimal resource allocation
- Poor sample selection reduces the effectiveness of replay, even with adequate buffer space

**3 First Experiments**:
1. Compare CORE's performance against fixed-buffer baselines on split-MNIST to establish baseline effectiveness
2. Evaluate the impact of buffer size on CORE's performance across different dataset splits
3. Test CORE's ability to maintain performance on the first task after training on multiple subsequent tasks

## Open Questions the Paper Calls Out
None

## Limitations
- Experimental validation is restricted to image classification datasets, leaving unclear whether CORE's benefits extend to other domains like natural language processing or reinforcement learning
- The paper does not provide comprehensive ablations demonstrating the independent contribution of each proposed strategy
- While CORE claims to improve the worst-case task performance, the analysis lacks statistical significance testing to confirm that these improvements are not due to random variation

## Confidence
- High Confidence: The claim that CORE achieves 37.95% average accuracy on split-CIFAR10, outperforming the best baseline by 6.52%, is supported by experimental results presented in the paper
- Medium Confidence: The claim that CORE significantly improves the accuracy of the poorest-performing task by 6.30% compared to the top baseline is based on reported results but lacks statistical validation
- Low Confidence: The claim that CORE's benefits will generalize to domains beyond image classification is speculative, as the paper provides no evidence beyond the tested datasets

## Next Checks
1. Conduct statistical significance testing (e.g., paired t-tests) on task-wise performance improvements to verify that observed gains are not due to random variation
2. Implement ablations that isolate the Adaptive Quantity Allocation and Quality-Focused Data Selection strategies to quantify their individual contributions to overall performance
3. Evaluate CORE on non-vision datasets (e.g., text classification or time-series prediction) to assess domain generalizability and identify any domain-specific limitations