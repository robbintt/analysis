---
ver: rpa2
title: Automated Multi-Task Learning for Joint Disease Prediction on Electronic Health
  Records
arxiv_id: '2403.04086'
source_url: https://arxiv.org/abs/2403.04086
tags:
- task
- search
- tasks
- learning
- grouping
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AutoDP, an automated multi-task learning
  framework for joint disease prediction on electronic health records. The framework
  addresses limitations in existing multi-task learning approaches by simultaneously
  optimizing task grouping and model architectures.
---

# Automated Multi-Task Learning for Joint Disease Prediction on Electronic Health Records

## Quick Facts
- arXiv ID: 2403.04086
- Source URL: https://arxiv.org/abs/2403.04086
- Authors: Suhan Cui; Prasenjit Mitra
- Reference count: 40
- Key outcome: AutoDP achieves 13.43% average per-task gains in A VP and 2.80% in ROC over existing methods

## Executive Summary
This paper introduces AutoDP, an automated multi-task learning framework designed to address limitations in existing approaches for joint disease prediction on electronic health records. The framework simultaneously optimizes task grouping and model architectures through surrogate model-based optimization with progressive sampling. AutoDP demonstrates significant improvements over both hand-crafted and automated baselines on the MIMIC-IV dataset for predicting 25 diseases.

## Method Summary
AutoDP employs a novel approach that jointly optimizes task grouping and neural architectures for multi-task learning in disease prediction. The framework uses surrogate model-based optimization with progressive sampling to efficiently search the joint space of task combinations and neural architectures. A greedy search algorithm is implemented to derive near-optimal solutions from the large search space. The method is specifically designed to work with electronic health record data and addresses the challenge of optimizing multiple tasks simultaneously.

## Key Results
- Achieves average per-task gains of 13.43% in A VP compared to existing methods
- Improves ROC performance by 2.80% on average
- Demonstrates superior performance over both hand-crafted and automated baselines
- Maintains feasible computational costs while optimizing joint task and architecture space

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to simultaneously optimize task grouping and model architectures rather than treating these as separate problems. By using surrogate model-based optimization with progressive sampling, AutoDP can efficiently navigate the large search space of possible task combinations and neural architectures. This joint optimization allows the framework to discover task relationships and architectures that work well together, rather than optimizing them independently.

## Foundational Learning
1. **Multi-task Learning** - why needed: Essential for leveraging shared information across multiple disease predictions; quick check: understand how tasks can share representations
2. **Surrogate Model Optimization** - why needed: Required for efficient search in large joint spaces; quick check: know basic concepts of model-based optimization
3. **Progressive Sampling** - why needed: Helps manage computational cost in large search spaces; quick check: understand how sampling strategies affect optimization
4. **Electronic Health Records** - why needed: Domain-specific data characteristics affect model design; quick check: familiarity with EHR data structure and challenges
5. **Task Grouping** - why needed: Determines which diseases share information; quick check: understand relationship between task similarity and model performance
6. **Neural Architecture Search** - why needed: Optimizes model structure for specific task combinations; quick check: basic knowledge of different neural network architectures

## Architecture Onboarding
Component Map: EHR Data -> Task Grouping Module -> Neural Architecture Search -> Surrogate Model Optimization -> Progressive Sampling -> Joint Disease Prediction Output

Critical Path: The framework first processes EHR data, then determines optimal task groupings, searches for suitable neural architectures, and uses surrogate models with progressive sampling to find the best combination of tasks and architectures.

Design Tradeoffs: The main tradeoff is between computational cost and search space coverage. The progressive sampling strategy helps balance this by focusing on promising regions of the search space.

Failure Signatures: Poor performance may indicate suboptimal task groupings, inadequate neural architecture choices, or insufficient sampling coverage in the search space.

First Experiments:
1. Test basic task grouping on a subset of diseases to validate the grouping algorithm
2. Evaluate individual neural architectures on single tasks before combining
3. Verify surrogate model performance on smaller search spaces before scaling up

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to single dataset (MIMIC-IV), raising generalizability concerns
- Computational cost details not provided, making practical applicability assessment difficult
- Scalability to larger numbers of diseases beyond 25 remains unclear
- No discussion of model interpretability or clinical insights from learned task relationships

## Confidence
- Improvement over baselines: High
- Effectiveness of surrogate model-based optimization: Medium
- Feasibility of the greedy search algorithm: Medium

## Next Checks
1. Cross-dataset validation: Test AutoDP on multiple electronic health record datasets from different medical institutions to assess generalizability
2. Scalability study: Evaluate performance and computational requirements as the number of tasks/diseases increases beyond 25
3. Ablation study on optimization components: Conduct detailed analysis of individual contributions of task grouping and neural architecture search components