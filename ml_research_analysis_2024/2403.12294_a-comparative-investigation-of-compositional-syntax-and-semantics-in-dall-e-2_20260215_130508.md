---
ver: rpa2
title: A Comparative Investigation of Compositional Syntax and Semantics in DALL-E
  2
arxiv_id: '2403.12294'
source_url: https://arxiv.org/abs/2403.12294
tags:
- dall
- children
- page
- language
- murphy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compared DALL-E 2's ability to visually represent linguistic
  prompts with children's comprehension of the same sentences. Using prompts from
  language assessments for children aged 2-7, DALL-E 2 generated 20 images per item,
  which were evaluated by 9 adult judges.
---

# A Comparative Investigation of Compositional Syntax and Semantics in DALL-E 2

## Quick Facts
- **arXiv ID**: 2403.12294
- **Source URL**: https://arxiv.org/abs/2403.12294
- **Reference count**: 0
- **Primary result**: DALL-E 2 fails to capture semantic accuracy in key grammatical structures (reversible transitives, negation, embedded adjectives, passives) that children master, indicating lack of compositional sentence representation.

## Executive Summary
This study compared DALL-E 2's ability to visually represent linguistic prompts with children's comprehension of the same sentences. Using prompts from language assessments for children aged 2-7, DALL-E 2 generated 20 images per item, which were evaluated by 9 adult judges. Results showed that DALL-E 2 failed to capture semantic accuracy in key grammatical structures, including reversible transitives, negation, embedded adjectives, and passives. Children, even at the youngest ages, outperformed DALL-E 2 in all tasks. These findings indicate a fundamental lack of compositional sentence representation in DALL-E 2, suggesting it cannot reliably construct linguistically coherent meanings like human children.

## Method Summary
The study used 50 linguistic prompts from children's language assessment tests covering reversible transitives, negation, prepositions, embedded adjectives, and passives. DALL-E 2 generated 20 images per prompt (1000 total images). Nine adult judges evaluated each image on a 3-point scale (1=accurate, 2=partially accurate, 3=inaccurate). Children's comprehension data from existing studies (ages 2-7) on the same sentence types was used for comparison. The percentage of images judged as accurate and the average adequacy score were calculated and compared to children's percentage correct performance.

## Key Results
- DALL-E 2 failed to assign appropriate roles in reversible transitives and prepositional phrases, often reversing agent-patient relationships
- The model incorrectly assigned embedded adjectives to the wrong nouns in 62% of trials
- DALL-E 2 ignored implicit agents in passive constructions and failed on negation tasks where children succeeded

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DALL-E 2's image generation lacks a compositional semantic layer that maps linguistic structure to visual representations.
- Mechanism: When prompted with sentences containing syntactic dependencies (e.g., reversible transitives, embedded adjectives, passives), DALL-E 2 produces images that fail to preserve role assignments and semantic scope, indicating the model does not parse sentences into structured meaning representations.
- Core assumption: The absence of consistent errors in keyword-based retrieval implies a structural gap in compositional understanding rather than noise or ambiguity.
- Evidence anchors:
  - [abstract] "DALL-E 2 failed to assign the appropriate roles in reversible forms; it failed on negation... it often assigned the adjective to the wrong noun; it ignored implicit agents in passives."
  - [section] "DALL-E 2 failed to assign the appropriate roles in reversible transitive and prepositional phrase forms... it often assigned the adjective to the wrong noun; it ignored implicit agents in passives."
  - [corpus] Weak correlation with related works; corpus does not directly address compositional architecture.
- Break condition: If prompt structures were inherently ambiguous or if external text-image alignment data could explain the pattern, the compositional gap claim would weaken.

### Mechanism 2
- Claim: Human children outperform DALL-E 2 because they construct internal cognitive models linking syntax to world knowledge during comprehension.
- Mechanism: Children use innate grammatical competence and semantic binding to assign thematic roles and interpret embedded modifiers, whereas DALL-E 2 lacks such internal structured representations.
- Core assumption: Children's success on comprehension tasks depends on compositional parsing, not just visual pattern matching.
- Evidence anchors:
  - [abstract] "children, even at the youngest ages, outperformed DALL-E 2 in all tasks... This work points to a clear absence of compositional sentence representations for DALL-E 2."
  - [section] "Human children are able to construct a grammar with direct links to compositional meaning, connecting language to internal cognitive models of the world – an architecture that seems absent in DALL-E 2."
  - [corpus] Limited corpus support; related works focus on LLMs and logic but not direct child-model comparison.
- Break condition: If children's success could be attributed to simpler heuristics or if task demands favored pattern recognition over composition, the cognitive model hypothesis would weaken.

### Mechanism 3
- Claim: DALL-E 2's training paradigm, based on mapping text-image pairs, does not induce syntactic competence needed for compositional sentence interpretation.
- Mechanism: The model learns co-occurrence statistics between words and visual features but does not develop rules for how sentence structure governs meaning.
- Core assumption: Training on paired data without explicit syntactic supervision cannot induce compositional semantics.
- Evidence anchors:
  - [abstract] "previous work indicates limits to DALL-E 2's ability to handle syntactic information... suggesting that any success on syntax tasks may be partly illusory and due to semantic keyword searches."
  - [section] "We confirm and extend the findings from Leivada et al. (2023) that a fundamental aspect of human language – compositionality – is lacking from DALL-E 2."
  - [corpus] Weak; corpus does not provide direct evidence on training architecture or supervision signals.
- Break condition: If subsequent fine-tuning or architectural modifications introduced explicit compositional parsing, this mechanism would no longer apply.

## Foundational Learning

- Concept: Compositional semantics
  - Why needed here: Understanding how sentence structure maps to meaning is essential to diagnose why DALL-E 2 fails on tasks requiring role assignment and modifier scope.
  - Quick check question: If a sentence has the structure "A verb B," what determines which entity is the agent and which is the patient?

- Concept: Thematic role assignment
  - Why needed here: Reversible transitives and passives test whether the model can correctly assign agent and patient roles regardless of word order.
  - Quick check question: In "The cat was chased by the dog," who is the agent and who is the patient?

- Concept: Scope of modifiers
  - Why needed here: Embedded adjectives must be correctly scoped to the intended noun; failure here indicates a lack of syntactic parsing.
  - Quick check question: In "the boy with a red hat," does "red" modify "boy" or "hat"?

## Architecture Onboarding

- Component map: Input -> Text-to-image generation pipeline -> Generated image -> Human evaluation
- Critical path: Prompt → CLIP text encoder → CLIP image decoder → Image synthesis → Human evaluation
- Design tradeoffs: The model trades compositional precision for visual plausibility and stylistic consistency; it prioritizes global image coherence over fine-grained semantic fidelity.
- Failure signatures: Systematic misassignment of roles in reversible structures, incorrect scoping of modifiers, omission of implicit agents, and failure on negation.
- First 3 experiments:
  1. Test reversible transitives with varied nouns to confirm role assignment failures are not lexical.
  2. Vary adjective placement in prepositional phrases to isolate scoping errors.
  3. Introduce passive sentences with explicit and implicit agents to test agent representation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would DALL-E 2 perform on the same syntactic structures in languages other than English?
- Basis in paper: [explicit] The paper notes that "The considerable performance variation across languages other than English for DALL·E 2 (Reviriego & Merino-Gómez 2022) already points towards the potential lack of a fundamental compositional strategy to represent structured linguistic meaning."
- Why unresolved: The study only tested English sentences, leaving open whether DALL-E 2's compositional limitations are language-specific or universal.
- What evidence would resolve it: Testing DALL-E 2 on comparable syntactic structures in multiple languages and comparing performance across languages.

### Open Question 2
- Question: Would modifying DALL-E 2's architecture to include neurosymbolic approaches improve its compositional abilities?
- Basis in paper: [explicit] The paper suggests "The importance of syntax-specific inductive biases cannot be underestimated" and notes that "neurosymbolic approaches are offering the field (Trinh et al. 2024), which seem ripe for adaptation towards syntactic representations."
- Why unresolved: The study didn't test any architectural modifications to DALL-E 2, only its baseline performance.
- What evidence would resolve it: Implementing neurosymbolic elements in DALL-E 2's architecture and testing its performance on the same syntactic structures.

### Open Question 3
- Question: What specific aspects of compositional syntax-semantics are most challenging for DALL-E 2?
- Basis in paper: [inferred] While the paper identifies several structures where DALL-E 2 failed, it doesn't systematically analyze which specific linguistic features cause the most difficulty.
- Why unresolved: The study provided general performance metrics but didn't analyze error patterns or identify specific linguistic features that DALL-E 2 struggles with.
- What evidence would resolve it: Detailed error analysis of DALL-E 2's outputs, categorizing failures by specific linguistic features (e.g., role assignment, negation, scope, etc.).

## Limitations

- Reliance on human judgment for semantic accuracy introduces subjectivity despite standardization efforts
- Comparison with children's data is indirect, using existing comprehension studies with potentially different task demands
- Study does not control for image complexity, vocabulary familiarity, or cultural context that might affect evaluations

## Confidence

- **High confidence**: DALL-E 2 fails on reversible transitives, negation, embedded adjectives, and passives based on systematic human judgment data
- **Medium confidence**: Failures stem from lack of compositional semantics rather than training data bias or architectural constraints
- **Low confidence**: Direct comparison to children's performance due to task differences and indirect comparison method

## Next Checks

1. Conduct a controlled experiment with children performing both comprehension tasks (picture choice) and generation tasks (describing images) using the same sentence stimuli to directly compare comprehension vs. production abilities.

2. Test DALL-E 2 variants (e.g., DALL-E 3, fine-tuned models) on the same prompts to determine whether the compositional failures are model-specific or represent broader limitations in text-to-image architectures.

3. Implement automated semantic evaluation metrics (e.g., CLIP-based similarity, scene graph matching) to complement human judgment and assess whether the compositional failures persist across evaluation methods.