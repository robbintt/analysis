---
ver: rpa2
title: Optimizing contrastive learning for cortical folding pattern detection
arxiv_id: '2401.18035'
source_url: https://arxiv.org/abs/2401.18035
tags:
- cortical
- subjects
- folding
- pattern
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of characterizing the high variability
  in cortical folding patterns and relating them to behavioral characteristics or
  pathologies. The authors propose a self-supervised deep learning approach using
  contrastive learning (SimCLR) to detect folding patterns in the cingulate region.
---

# Optimizing contrastive learning for cortical folding pattern detection

## Quick Facts
- arXiv ID: 2401.18035
- Source URL: https://arxiv.org/abs/2401.18035
- Reference count: 28
- Primary result: First application of self-supervised deep learning to cortical skeletons for detecting folding patterns

## Executive Summary
This study addresses the challenge of characterizing high variability in cortical folding patterns and relating them to behavioral characteristics or pathologies. The authors propose a self-supervised deep learning approach using contrastive learning (SimCLR) to detect folding patterns in the cingulate region. By training on large datasets (Human Connectome Project and UKBioBank) with topological-based augmentations on cortical skeletons, they demonstrate that their approach can effectively learn representations suitable for detecting specific folding patterns, particularly the "double-parallel" pattern related to schizophrenia characteristics.

## Method Summary
The method uses SimCLR contrastive learning with topological augmentations on 3D cortical skeleton crops from the cingulate region. The approach employs branch-clipping augmentation, which removes random branches from the folding graph until at least 40% of voxels are removed. The best-performing model uses a six-layer convolutional network with a linear projection head and a 10-dimensional latent space. The model is trained on large datasets and evaluated using a linear SVC classifier with AUC as the primary metric.

## Key Results
- Best model achieves AUC of 0.76 for detecting the "double-parallel" folding pattern
- Performance increases with training set size (AUC of 0.76 with 21,070 subjects)
- Variability decreases from 0.04 to 0.01 when increasing training subjects from 551 to 21,070
- Six-layer convolutional network outperforms DenseNet and PointNet architectures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Topological augmentations improve contrastive learning performance for cortical folding pattern detection.
- Mechanism: Branch-clipping augmentation removes random branches from the cortical folding graph, forcing the model to learn robust features invariant to local topology variations. This improves generalization for detecting specific folding patterns.
- Core assumption: The cortical folding patterns of interest are identifiable even when some branches are removed.
- Evidence anchors:
  - [section] "The second augmentation method is called 'branch-clipping': for both views, it removes random branches from the folding graph until there are at least 40% of the voxels removed. All bottom voxels are removed."
  - [section] "We find the best model to be the six-layer convolutional network with a linear projection head, a latent space size (that is, the dimension of the latent space) of 10, and using the branch-clipping augmentation strategy."
- Break condition: If removing 40% of branches destroys the essential topology of the target pattern, making it impossible to detect.

### Mechanism 2
- Claim: Large-scale training datasets improve model stability and performance.
- Mechanism: Training on datasets with 21,070 subjects (UKBioBank) provides sufficient variability in cortical folding patterns, leading to a more stable and generalizable representation compared to smaller datasets.
- Core assumption: The increased sample size captures the full range of normal and pathological cortical folding variations.
- Evidence anchors:
  - [section] "Variability (measured as the standard deviation over 5 different SimCLR initializations) decreases from 0.04 for n=551 to 0.01 for n=21070, showing that increasing the number of training subjects significantly stabilizes the representation."
  - [section] "Then, when changing the training set size N, the performances increase. For UKBioBank, the AUC increases to 0.76 when training with 21070 subjects."
- Break condition: If the dataset contains significant bias or systematic errors that are not representative of the general population.

### Mechanism 3
- Claim: Self-supervised contrastive learning can learn meaningful representations without manual labels.
- Mechanism: SimCLR optimizes a latent space where similar views of the same cortical skeleton are close together while different skeletons are far apart, creating a representation suitable for downstream classification tasks.
- Core assumption: The augmentations preserve enough information about the underlying folding patterns while creating sufficiently different views.
- Evidence anchors:
  - [abstract] "We train a contrastive self-supervised model (SimCLR) on both Human Connectome Project (1101 subjects) and UKBioBank (21070 subjects) datasets with topological-based augmentations on the cortical skeletons."
  - [section] "The contrastive model used is SimCLR, an instance discrimination contrastive model."
- Break condition: If the augmentations destroy the distinguishing features of the target folding patterns, making it impossible to learn useful representations.

## Foundational Learning

- Concept: Contrastive learning and instance discrimination
  - Why needed here: The method relies on SimCLR, which learns representations by comparing different views of the same input (positive pairs) against views of different inputs (negative pairs).
  - Quick check question: What is the difference between supervised and self-supervised contrastive learning?

- Concept: Topological data analysis and graph-based representations
  - Why needed here: Cortical skeletons are represented as graphs, and the augmentations specifically manipulate this graph structure through branch-clipping.
  - Quick check question: How does branch-clipping augmentation work on a cortical skeleton graph?

- Concept: Evaluation metrics for classification (AUC)
  - Why needed here: The model's performance is evaluated using Area Under the ROC Curve (AUC) for binary classification of the double-parallel folding pattern.
  - Quick check question: What does an AUC of 0.76 mean in terms of classification performance?

## Architecture Onboarding

- Component map:
  Input: 3D cortical skeleton crops (17x40x38 resolution) -> Backbone options: ConvNet (6-layer), DenseNet (2 dense blocks), PointNet -> Augmentation strategies: Cutout, Branch-clipping -> Projection head: Linear or non-linear -> Output: Latent space representation -> Evaluation: Linear SVC classifier with AUC metric

- Critical path:
  1. Preprocessing: Generate cortical skeletons and extract cingulate region crops
  2. Augmentation: Apply branch-clipping to create positive pairs
  3. Training: Optimize SimCLR model on large dataset
  4. Evaluation: Train linear classifier on learned embeddings

- Design tradeoffs:
  - Simple ConvNet backbone vs. more complex DenseNet/PointNet: Simplicity vs. potential performance
  - 10-dimensional latent space: Balance between expressiveness and overfitting risk
  - Branch-clipping vs. cutout augmentation: Topology-specific vs. generic augmentation

- Failure signatures:
  - AUC performance plateaus at low values despite large training sets
  - High variance across different model initializations
  - Linear classifier performance significantly worse than expected from representation quality

- First 3 experiments:
  1. Compare AUC performance between branch-clipping and cutout augmentations on a subset of the data
  2. Test different latent space dimensions (4, 10, 30) with the best augmentation strategy
  3. Evaluate model performance on a held-out test set after training on the full training dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the SimCLR model generalize to detecting other cortical folding patterns beyond the double-parallel pattern in the cingulate region?
- Basis in paper: [explicit] The authors mention applying the model to other brain regions to detect other biomarkers as the next step.
- Why unresolved: The current study only evaluates the model on one specific folding pattern (double-parallel in the cingulate region).
- What evidence would resolve it: Testing the optimized SimCLR model on multiple manually labeled datasets containing various cortical folding patterns across different brain regions and comparing performance.

### Open Question 2
- Question: How can the model's representation quality be further improved by incorporating external information or other modalities?
- Basis in paper: [explicit] The authors suggest bringing external information into the model to improve representation quality.
- Why unresolved: The study only uses cortical skeletons as input and does not explore multimodal integration.
- What evidence would resolve it: Experiments comparing the current model's performance to versions incorporating additional MRI modalities (e.g., diffusion, functional) or non-imaging data through fusion techniques.

### Open Question 3
- Question: How can the remaining dataset effects (site and age) be further reduced in the model's representation?
- Basis in paper: [explicit] The authors note a dataset effect and suggest debiasing techniques or modified augmentations as possible solutions.
- Why unresolved: While the model shows some resilience to dataset differences, the authors acknowledge remaining effects.
- What evidence would resolve it: Comparing the current model's performance to versions trained with debiasing techniques or alternative augmentations designed to minimize site and age effects across multiple datasets.

## Limitations

- Focus on single folding pattern (double-parallel) limits generalizability to other patterns or brain regions
- Branch-clipping augmentation removes up to 40% of branches, but impact on pattern preservation remains unclear
- Method relies on cortical skeletons that discard intensity and curvature information from original MRI data

## Confidence

- **High Confidence**: The feasibility of using contrastive learning with topological augmentations for cortical skeleton representation learning
- **Medium Confidence**: The effectiveness of branch-clipping augmentation specifically for detecting the double-parallel pattern
- **Low Confidence**: The ability to detect other folding patterns or apply this approach to different brain regions

## Next Checks

1. **Generalization Test**: Apply the trained model to detect other known folding patterns in the cingulate region and across different brain regions, measuring AUC performance and comparing to baseline methods.

2. **Ablation Study**: Systematically vary the branch-clipping removal percentage (20%, 40%, 60%) to identify the optimal balance between augmentation strength and pattern preservation for the double-parallel pattern.

3. **Cross-Dataset Validation**: Test the model trained on UKBioBank data on an independent dataset from a different source to assess real-world robustness and identify potential dataset-specific biases.