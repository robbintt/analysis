---
ver: rpa2
title: A deep cut into Split Federated Self-supervised Learning
arxiv_id: '2406.08267'
source_url: https://arxiv.org/abs/2406.08267
tags:
- learning
- mocosfl
- monacosfl
- federated
- client
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper analyzes MocoSFL, a state-of-the-art method for federated
  self-supervised learning, and identifies its limitation: performance deteriorates
  when splitting the network at deeper layers. This is due to the misalignment between
  online and momentum models during synchronization, which is crucial for contrastive
  learning.'
---

# A deep cut into Split Federated Self-supervised Learning

## Quick Facts
- arXiv ID: 2406.08267
- Source URL: https://arxiv.org/abs/2406.08267
- Authors: Marcin Przewięźlikowski; Marcin Osial; Bartosz Zieliński; Marek Śmieja
- Reference count: 40
- Key outcome: This paper analyzes MocoSFL, a state-of-the-art method for federated self-supervised learning, and identifies its limitation: performance deteriorates when splitting the network at deeper layers. To address this, the authors propose MonAcoSFL, which synchronizes both online and momentum client models, achieving state-of-the-art accuracy while significantly reducing communication overhead.

## Executive Summary
This paper addresses a critical limitation in split federated learning (SFL) for self-supervised learning, specifically the performance degradation when splitting neural networks at deeper layers. The authors identify that this issue stems from misalignment between online and momentum models during synchronization, which is crucial for MoCo-style contrastive learning. They propose MonAcoSFL, which synchronizes both online and momentum client models, maintaining alignment and enabling effective training with deeper splits. This approach achieves state-of-the-art accuracy while significantly reducing communication overhead, making it more practical for real-world federated learning scenarios.

## Method Summary
MonAcoSFL extends the MocoSFL framework by synchronizing both online and momentum client models during the training procedure. The method uses ResNet-18 or MobileNetV2 backbones with the MoCo-v2 framework, training on CIFAR-10 and CIFAR-100 datasets with non-IID distribution across clients. The key innovation is that when online parameters are synchronized across clients, momentum parameters are also updated by averaging momentum models, preventing divergence between online and momentum models. This ensures that momentum models remain close to their corresponding online models, preserving the representation similarity assumption essential for contrastive learning.

## Key Results
- MonAcoSFL achieves state-of-the-art accuracy compared to MocoSFL across various split depths and client counts
- The method enables effective training with deeper splits (up to 17 layers), which MocoSFL fails to support
- Deeper splits in MonAcoSFL provide better privacy protection while reducing communication overhead
- MonAcoSFL demonstrates significant improvements in model inversion attack resistance for deeper splits

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Synchronizing both online and momentum client models maintains alignment between them, which is essential for MoCo-style contrastive learning to function correctly.
- Mechanism: In MonAcoSFL, when online parameters are synchronized, the momentum parameters are also updated by averaging momentum models across clients. This ensures that momentum models remain close to their corresponding online models, preserving the representation similarity assumption.
- Core assumption: The contrastive objective relies on online and momentum models producing similar embeddings for the same data.
- Evidence anchors:
  - [abstract] "MonAcoSFL, which aligns online and momentum client models during training procedure"
  - [section] "MonAcoSFL also synchronizes their momentum models. This change is crucial because it prevents the divergence of online and momentum models"
  - [corpus] Weak evidence - no direct corpus support found for this specific mechanism.
- Break condition: If the averaging frequency is too low, momentum models may still diverge significantly from online models despite synchronization.

### Mechanism 2
- Claim: Deeper splits reduce communication overhead by transmitting smaller activations while only slightly increasing synchronization overhead.
- Mechanism: As layers progress through a network like ResNet or MobileNet, spatial dimensions decrease while channel dimensions increase. Deeper splits transmit smaller representations (activations) but require more parameters to be synchronized. The trade-off favors deeper splits for efficiency.
- Core assumption: Communication overhead for activations dominates that of parameter synchronization in split learning.
- Evidence anchors:
  - [section] "Network architectures used in mobile devices...progressively downsample the spacial dimensions of representations...the overall representation size decreases with network depth"
  - [section] "splitting depth larger than7 is unreliable, and using a lower splitting depth poses concerns to privacy and communication overhead"
  - [corpus] Weak evidence - no direct corpus support for this specific trade-off analysis.
- Break condition: If model synchronization overhead becomes significantly larger than activation transmission, the efficiency advantage diminishes.

### Mechanism 3
- Claim: Higher layer activations contain less reconstructable information about input data, providing better privacy protection.
- Mechanism: As networks learn higher-level features, representations become more abstract and less directly tied to input appearance. This makes model inversion attacks less effective when splitting at deeper layers.
- Core assumption: Privacy risk is proportional to the reconstructability of input data from transmitted activations.
- Evidence anchors:
  - [section] "representations of low ResNet18 [18] layers highly resemble the respective input data, in contrast to the activations from the higher layers"
  - [section] "in principle, models that learn perceptive features...do not retain reconstructive features in their high representations"
  - [section] "using deeper cut-layers (9-13) is not only more efficient from the computational point of view but also increases the protection of client data"
- Break condition: If the model architecture or training objective preserves reconstructability in higher layers, this privacy advantage disappears.

## Foundational Learning

- Concept: Contrastive learning and the InfoNCE objective
  - Why needed here: Understanding how MoCoSFL and MonAcoSFL train representations is fundamental to grasping why model alignment matters
  - Quick check question: What is the key difference between online and momentum models in MoCo, and why does this asymmetry matter for the contrastive objective?

- Concept: Split federated learning architecture
  - Why needed here: The paper's contributions depend on understanding how model partitioning affects privacy and communication
  - Quick check question: In SFL, what two types of communication occur during training, and how do they differ from standard federated learning?

- Concept: Model inversion attacks and privacy metrics
  - Why needed here: The privacy evaluation section uses model inversion attacks to quantify privacy improvements
  - Quick check question: How does mean squared error between original and reconstructed images serve as a privacy metric in the context of split learning?

## Architecture Onboarding

- Component map:
  - Client-side: Online model (subset of layers), momentum model (same subset), local data, SGD optimizer
  - Server-side: Remaining model layers, memory bank for negative samples, global parameters for both online and momentum models
  - Communication channels: Activations from client to server, gradients from server to client, parameter synchronization between clients

- Critical path:
  1. Client processes local batch through online model
  2. Activations sent to server for forward pass through server-side layers
  3. Server computes InfoNCE loss using memory bank
  4. Gradients flow back to update server parameters
  5. Client updates online parameters locally
  6. Periodic synchronization of parameters across clients
  7. Momentum model updates via exponential moving average

- Design tradeoffs:
  - Split depth vs. privacy: Deeper splits provide better privacy but may affect model quality
  - Split depth vs. communication: Deeper splits reduce activation size but increase parameter synchronization
  - Synchronization frequency vs. stability: More frequent synchronization reduces model divergence but increases communication overhead

- Failure signatures:
  - Catastrophic accuracy drop with deeper splits (as observed in MocoSFL)
  - Rapid divergence between online and momentum models
  - High MSE in model inversion attacks for deeper splits
  - Communication overhead exceeding computational benefits

- First 3 experiments:
  1. Compare MocoSFL vs MonAcoSFL accuracy across different split depths (1, 3, 5, 7, 9, 11, 13, 15, 17 layers) on CIFAR-10
  2. Measure model inversion attack MSE for both methods at each split depth
  3. Profile communication overhead (activation size and parameter synchronization) for each split depth

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal splitting depth for balancing privacy and communication efficiency in federated self-supervised learning?
- Basis in paper: [explicit] The paper demonstrates that deeper splits provide better privacy protection but also discusses the trade-off with communication overhead and potential performance degradation.
- Why unresolved: While the paper identifies a trade-off and provides some insights, the optimal splitting depth likely depends on specific factors such as the dataset, model architecture, and privacy requirements.
- What evidence would resolve it: A comprehensive study varying these factors and measuring the resulting privacy, communication overhead, and model performance could identify optimal splitting depths for different scenarios.

### Open Question 2
- Question: How can the alignment between online and momentum models be maintained in federated self-supervised learning without sacrificing communication efficiency?
- Basis in paper: [explicit] The paper proposes MonAcoSFL to address the misalignment issue in MocoSFL, but the solution involves additional synchronization steps which could impact communication efficiency.
- Why unresolved: The paper presents a solution but doesn't explore alternative methods or optimize the synchronization strategy to minimize communication overhead while maintaining alignment.
- What evidence would resolve it: Investigating different synchronization strategies, exploring compression techniques for model updates, or developing novel alignment methods that don't require explicit synchronization could lead to more efficient solutions.

### Open Question 3
- Question: How does the performance of MonAcoSFL scale with the number of clients and the amount of non-IID data in federated self-supervised learning?
- Basis in paper: [explicit] The paper evaluates MonAcoSFL with up to 200 clients and mentions non-IID data, but the analysis could be extended to larger scales and more diverse data distributions.
- Why unresolved: The paper provides initial insights, but the scalability of MonAcoSFL to real-world federated learning scenarios with potentially thousands of clients and highly heterogeneous data remains unexplored.
- What evidence would resolve it: Extensive experiments scaling MonAcoSFL to larger numbers of clients and evaluating its performance under various degrees of data heterogeneity could reveal its scalability limitations and potential areas for improvement.

## Limitations

- The theoretical claims about model alignment benefits lack direct empirical validation through ablation studies
- Privacy analysis relies heavily on model inversion attacks without addressing potential adversarial scenarios beyond simple reconstruction
- The paper doesn't explore alternative synchronization strategies that might maintain alignment with lower communication overhead

## Confidence

- **High Confidence**: The experimental results demonstrating improved accuracy and reduced communication overhead for MonAcoSFL over MocoSFL are well-supported by the presented data.
- **Medium Confidence**: The mechanism explaining why deeper splits provide better privacy protection is plausible but requires further validation with diverse attack methods.
- **Low Confidence**: The claim that momentum model synchronization is the primary factor enabling deeper splits lacks direct ablation studies isolating this effect.

## Next Checks

1. **Ablation Study**: Implement MocoSFL with synchronized momentum models (without other MonAcoSFL changes) to isolate the impact of momentum alignment on deeper split performance.

2. **Robustness Testing**: Evaluate MonAcoSFL under realistic network conditions including packet loss and varying latency to verify performance claims hold in non-ideal scenarios.

3. **Extended Privacy Analysis**: Test against more sophisticated privacy attacks beyond model inversion, including membership inference and gradient-based reconstruction methods, to comprehensively assess the privacy benefits of deeper splits.