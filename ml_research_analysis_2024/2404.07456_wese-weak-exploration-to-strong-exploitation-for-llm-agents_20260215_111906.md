---
ver: rpa2
title: 'WESE: Weak Exploration to Strong Exploitation for LLM Agents'
arxiv_id: '2404.07456'
source_url: https://arxiv.org/abs/2404.07456
tags:
- tasks
- exploration
- agent
- information
- exploitation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: WESE proposes decoupling exploration and exploitation for LLM agents
  in open-world tasks. It employs a weak LLM for cost-effective exploration, storing
  knowledge in a graph, and a strong LLM for exploitation using task-relevant one-hop
  retrieved knowledge.
---

# WESE: Weak Exploration to Strong Exploitation for LLM Agents

## Quick Facts
- arXiv ID: 2404.07456
- Source URL: https://arxiv.org/abs/2404.07456
- Reference count: 5
- Primary result: WESE achieves 63% success rate on ALFWorld with 75.32$ cost, outperforming Act (43%, 98.60$) and SESE (67%, 146.69$)

## Executive Summary
WESE addresses the challenge of balancing exploration and exploitation in LLM agents for open-world tasks by explicitly decoupling these processes. The method employs a weak LLM for cost-effective exploration to gather global knowledge, which is then stored in a knowledge graph structure. A strong LLM subsequently uses this task-relevant knowledge to efficiently complete the exploitation phase. This approach significantly reduces resource consumption while maintaining or improving success rates across four interactive benchmarks.

## Method Summary
WESE introduces a two-phase approach where exploration and exploitation are handled by different LLM agents based on their reasoning complexity requirements. The weak exploration phase uses a 7B model to interact with the environment and extract knowledge triplets that form an environmental knowledge graph. During exploitation, task-relevant entities are identified and one-hop retrieval extracts pertinent knowledge for the strong LLM to complete the task. This decoupling strategy allows for substantial cost savings while preserving performance through strategic knowledge transfer and retrieval.

## Key Results
- WESE achieves 63% success rate on ALFWorld with 75.32$ cost, outperforming Act (43%, 98.60$) and SESE (67%, 146.69$)
- Across four interactive benchmarks, WESE demonstrates superior performance-efficiency trade-offs compared to state-of-the-art methods
- The weak exploration strategy reduces costs by approximately 24% compared to strong exploration while maintaining competitive success rates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decoupling exploration and exploitation reduces greedy decision-making by allowing agents to first gather comprehensive environmental knowledge before committing to actions.
- Mechanism: WESE explicitly separates exploration (using weak LLM) from exploitation (using strong LLM with retrieved knowledge), ensuring complete environmental prior before decision-making.
- Core assumption: Exploration and exploitation require different reasoning capabilities, with weaker LLMs sufficient for information gathering.
- Evidence anchors:
  - [abstract]: "WESE involves decoupling the exploration and exploitation process, employing a cost-effective weak agent to perform exploration tasks for global knowledge."
  - [section 3.1]: "Therefore, we investigate the strategy to decouple exploration and exploitation..."
  - [corpus]: Weak evidence - similar approaches exist but this specific decoupling strategy appears novel in the context of LLM agents.

### Mechanism 2
- Claim: Knowledge graph compression reduces token usage and filters irrelevant information while preserving task-relevant environmental knowledge.
- Mechanism: Environmental feedback is converted into knowledge triplets and stored in a graph structure, with one-hop retrieval extracting only task-relevant knowledge during exploitation.
- Core assumption: Environmental information exhibits sparsity with non-informative elements that can be compressed into structured triplets.
- Evidence anchors:
  - [abstract]: "A knowledge graph-based strategy is then introduced to store the acquired knowledge and extract task-relevant knowledge..."
  - [section 3.2]: "Benefiting from the superiority of LLM in relation-extraction tasks [Wadhwa et al. , 2023 ], we extract the knowledge from the received feedback..."
  - [corpus]: Weak evidence - KG-based compression is established in other domains but application to LLM agent exploration is novel.

### Mechanism 3
- Claim: Using a weaker LLM for exploration significantly reduces costs while maintaining comparable performance to strong exploration.
- Mechanism: Llama-2-7B handles exploration (less complex reasoning), while text-davinci-003 handles exploitation (complex reasoning).
- Core assumption: Exploration tasks are less complex than exploitation tasks and can be handled by weaker models without significant performance degradation.
- Evidence anchors:
  - [abstract]: "To further minimize resource consumption, we observe that a cost-effective weaker LLM (such as a 7B model) is fully capable of the less challenging exploratory tasks."
  - [section 3.3]: "Therefore, we propose to use a weaker agent for the exploration to mitigate resource consumption..."
  - [section 4.1]: "In WESE, the weak LLM agent undertakes the exploration process, resulting in cost savings for extensive exploration."
  - [corpus]: Moderate evidence - weak-to-strong generalization is explored in other contexts but application to exploration-exploitation is novel.

## Foundational Learning

- Concept: Exploration-Exploitation Trade-off
  - Why needed here: Open-world tasks require balancing information gathering (exploration) with decision-making (exploitation), which WESE explicitly manages through decoupling.
  - Quick check question: Why might embedding exploration and exploitation in a single reasoning step lead to suboptimal decisions?

- Concept: Knowledge Graph Construction and Retrieval
  - Why needed here: WESE uses knowledge graphs to compress and structure environmental information, enabling efficient retrieval of task-relevant knowledge during exploitation.
  - Quick check question: How does one-hop retrieval from a knowledge graph help filter irrelevant information compared to using raw environmental feedback?

- Concept: Weak-to-Strong Generalization
  - Why needed here: The approach leverages the principle that simpler tasks (exploration) can be handled by weaker models while reserving stronger models for complex reasoning (exploitation).
  - Quick check question: What are the potential risks of using a weak LLM for exploration, and how does WESE mitigate these risks?

## Architecture Onboarding

- Component map: Environment -> Weak LLM Agent -> Knowledge Graph Memory -> Strong LLM Agent -> Environment
- Critical path:
  1. Initialize environment and task
  2. Weak exploration (up to Ne steps): Agent interacts, extracts triplets, updates knowledge graph
  3. Task-relevant entity extraction from task description
  4. One-hop retrieval of relevant triplets from knowledge graph
  5. Strong exploitation (up to Nt steps): Agent uses retrieved knowledge to complete task
  6. Return success/failure and performance metrics

- Design tradeoffs:
  - Weak vs. Strong Exploration: Weak exploration reduces costs significantly but may miss some information; strong exploration provides more comprehensive knowledge at higher cost
  - Knowledge Graph vs. Raw Text: KG reduces noise and token usage but may lose some contextual information; raw text preserves context but introduces noise
  - Fixed vs. Adaptive Step Limits: Fixed limits (Ne, Nt) simplify implementation but may be suboptimal for task difficulty variation

- Failure signatures:
  - Exploration failure: Agent gets stuck in loops, fails to discover critical information, or gathers insufficient knowledge
  - Exploitation failure: Agent makes incorrect decisions despite having relevant knowledge, or knowledge graph retrieval misses critical information
  - Performance degradation: Success rate drops significantly compared to baselines, or cost increases unexpectedly

- First 3 experiments:
  1. Ablation study: Compare WESE with WESE without knowledge graph (raw feedback) to measure KG impact on success rate and efficiency
  2. Exploration strength comparison: Test WESE with weak, medium, and strong exploration LLMs to quantify the cost-performance tradeoff
  3. Retrieval method comparison: Compare one-hop retrieval with multi-hop retrieval and full knowledge graph injection to assess optimal knowledge transfer strategy

## Open Questions the Paper Calls Out
None

## Limitations
- The fixed step limits (Ne, Nt) may not adapt well to varying task complexities, potentially leading to either insufficient exploration or unnecessary exploitation steps
- The one-hop retrieval limitation may not capture all necessary information for complex tasks requiring multi-hop reasoning
- The approach's effectiveness in dynamic environments where knowledge becomes outdated during exploitation remains untested

## Confidence
- **High confidence**: The cost reduction mechanism (using weak LLM for exploration) is well-supported by experimental results showing consistent cost savings across all four benchmarks
- **Medium confidence**: The knowledge graph compression approach shows promise in reducing token usage and filtering noise, but the one-hop retrieval limitation may not capture all necessary information
- **Medium confidence**: The decoupling strategy itself is theoretically sound and supported by experimental evidence, but the optimal balance between exploration and exploitation remains task-dependent

## Next Checks
1. **Dynamic environment test**: Evaluate WESE in environments where knowledge becomes outdated during exploitation to assess whether the pre-gathered knowledge remains relevant and how quickly the system can adapt.

2. **Cross-task generalization study**: Apply WESE to tasks outside the four benchmarks, particularly those requiring multi-hop reasoning or real-time knowledge updates, to test the robustness of the decoupling strategy.

3. **Exploration strength ablation**: Systematically vary the weak LLM model size and capabilities to identify the minimum requirements for effective exploration while quantifying the impact on exploitation performance and overall efficiency.