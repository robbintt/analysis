---
ver: rpa2
title: 'Vision-and-Language Navigation Today and Tomorrow: A Survey in the Era of
  Foundation Models'
arxiv_id: '2407.07035'
source_url: https://arxiv.org/abs/2407.07035
tags:
- navigation
- language
- conference
- learning
- wang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey reviews vision-and-language navigation (VLN) in the
  era of foundation models, organizing challenges and solutions into three main areas:
  learning a world model to represent visual environments, learning a human model
  to interpret instructions, and learning a VLN agent for reasoning and planning.
  It highlights how foundation models like large language models and vision-language
  models have advanced VLN by enabling better generalization, handling ambiguous instructions,
  and improving planning and reasoning.'
---

# Vision-and-Language Navigation Today and Tomorrow: A Survey in the Era of Foundation Models

## Quick Facts
- **arXiv ID**: 2407.07035
- **Source URL**: https://arxiv.org/abs/2407.07035
- **Reference count**: 40
- **Primary result**: Comprehensive survey of vision-and-language navigation organized around world modeling, human modeling, and agent reasoning in the foundation model era

## Executive Summary
This survey provides a comprehensive review of vision-and-language navigation (VLN) research in the context of foundation models. The authors organize the field's challenges and solutions into three main areas: learning a world model to represent visual environments, learning a human model to interpret instructions, and learning a VLN agent for reasoning and planning. The paper highlights how foundation models like large language models and vision-language models have advanced VLN by enabling better generalization, handling ambiguous instructions, and improving planning and reasoning capabilities. The survey also discusses current limitations and identifies future directions for research.

## Method Summary
The paper synthesizes recent advances in VLN through a systematic categorization of challenges and solutions. The authors analyze how foundation models have transformed each component of VLN systems, examining their impact on visual perception, language understanding, and decision-making processes. They review existing benchmarks and evaluation protocols while identifying gaps between current capabilities and real-world deployment requirements. The survey methodology involves comprehensive literature analysis across multiple VLN datasets and approaches.

## Key Results
- Foundation models have significantly advanced VLN by improving generalization across environments and instruction variations
- Three core challenge areas identified: world modeling, human modeling, and agent reasoning/planning
- Current limitations include challenges in real-world deployment and need for more dynamic, realistic benchmarks
- Future directions include adapting foundation models for physical navigation and expanding evaluation to more realistic scenarios

## Why This Works (Mechanism)
The success of foundation models in VLN stems from their ability to capture rich semantic representations across vision and language modalities. Large language models provide strong instruction understanding and reasoning capabilities, while vision-language models enable robust perception of environmental features. These models leverage massive pre-training to develop transferable knowledge that helps navigate ambiguous instructions and generalize across diverse environments. The integration of these capabilities allows VLN agents to better interpret natural language instructions, understand spatial relationships, and make informed navigation decisions.

## Foundational Learning
**World Modeling**: Representing visual environments through spatial understanding - needed to map instructions to physical spaces; quick check: agent can localize and navigate using visual observations
**Human Modeling**: Interpreting natural language instructions - needed to bridge human communication and machine actions; quick check: agent correctly understands varied instruction phrasings
**Agent Reasoning**: Planning and decision-making - needed to execute navigation sequences; quick check: agent reaches target locations following instructions
**Cross-modal Alignment**: Integrating vision and language representations - needed for coherent instruction-following; quick check: visual and language embeddings support joint reasoning
**Generalization**: Adapting to new environments and instructions - needed for real-world applicability; quick check: performance holds across unseen scenarios

## Architecture Onboarding

**Component Map**: Foundation Model Integration -> World Model Construction -> Instruction Interpretation -> Navigation Planning -> Action Execution

**Critical Path**: The most critical sequence is: (1) visual input processing through vision-language models, (2) instruction understanding via large language models, (3) world model construction from sequential observations, and (4) planning decisions based on integrated representations. This path determines whether the agent can correctly interpret instructions and execute appropriate navigation actions.

**Design Tradeoffs**: Foundation models offer strong generalization but introduce computational overhead and potential biases. Traditional approaches provide efficiency but limited adaptability. The survey highlights the tension between model complexity and real-time performance requirements for physical deployment.

**Failure Signatures**: Common failure modes include: (1) misinterpreting ambiguous instructions due to context misunderstanding, (2) visual perception errors in complex environments, (3) planning failures from incomplete world models, and (4) inability to recover from navigation mistakes. These often manifest as early-stage deviations from intended paths.

**First Experiments**:
1. Compare VLN performance using different foundation model combinations versus traditional approaches across multiple benchmarks
2. Test cross-dataset generalization by training on one VLN dataset and evaluating on another
3. Evaluate instruction variation robustness by systematically modifying instruction phrasing while keeping environments constant

## Open Questions the Paper Calls Out
The survey identifies several open questions including: how to effectively adapt foundation models for real-world deployment challenges, what evaluation metrics best capture genuine semantic understanding versus pattern matching, how to handle biases in foundation models that affect navigation performance across different environments, and how to expand benchmarks to include more realistic and dynamic scenarios. The paper also questions how to bridge the gap between simulation results and physical robot deployment.

## Limitations
- Real-world deployment challenges are discussed briefly despite the complexity of physical navigation systems
- Limited discussion of evaluation metrics that distinguish genuine semantic understanding from superficial pattern matching
- Insufficient coverage of potential biases in foundation models affecting performance across different environments and user populations
- Many proposed future directions remain speculative without concrete validation studies

## Confidence
**High confidence**: The categorization of VLN challenges into world modeling, human modeling, and agent reasoning aligns well with established literature and provides a clear framework for understanding the field.

**Medium confidence**: The assessment of foundation models' impact on VLN shows promise but results vary significantly across different implementations, datasets, and evaluation protocols.

**Low confidence**: Many proposed future directions and potential solutions remain speculative without empirical validation, making it difficult to assess their practical viability.

## Next Checks
1. Conduct systematic ablation studies comparing VLN performance using different foundation model combinations versus traditional approaches across multiple benchmarks to quantify the actual contribution of foundation models.

2. Implement and evaluate the proposed real-world deployment scenarios with actual robots in physical environments to verify simulation-to-reality transfer claims and identify practical limitations.

3. Design and execute cross-dataset generalization tests to quantify how well foundation model-based VLN agents can handle instruction variations and environmental changes, measuring true generalization capability beyond memorization.