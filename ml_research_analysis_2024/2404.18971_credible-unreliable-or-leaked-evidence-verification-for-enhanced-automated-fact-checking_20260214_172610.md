---
ver: rpa2
title: 'Credible, Unreliable or Leaked?: Evidence Verification for Enhanced Automated
  Fact-checking'
arxiv_id: '2404.18971'
source_url: https://arxiv.org/abs/2404.18971
tags:
- evidence
- dataset
- articles
- information
- news
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the critical issue of verifying the quality
  of external evidence used in automated fact-checking (AFC) systems, particularly
  the presence of leaked and unreliable information. The authors construct CREDULE,
  a large-scale dataset of 91,632 news articles classified as Credible, Unreliable,
  or Fact-checked (Leaked).
---

# Credible, Unreliable or Leaked?: Evidence Verification for Enhanced Automated Fact-checking

## Quick Facts
- arXiv ID: 2404.18971
- Source URL: https://arxiv.org/abs/2404.18971
- Reference count: 40
- Primary result: EVVER-Net achieves up to 91.5% accuracy in detecting leaked/unreliable evidence

## Executive Summary
This study addresses a critical gap in automated fact-checking (AFC) systems by identifying and filtering unreliable and leaked evidence. The authors construct CREDULE, a large-scale dataset of 91,632 news articles classified as Credible, Unreliable, or Fact-checked (Leaked), and develop EVVER-Net, a neural network classifier that achieves high accuracy in detecting problematic evidence. Analysis reveals concerning rates of leaked and unreliable evidence in widely-used AFC datasets, highlighting the urgent need for evidence verification solutions to ensure robust AFC system performance.

## Method Summary
The authors created CREDULE, a dataset of 91,632 news articles automatically collected from various sources and classified as Credible, Unreliable, or Leaked (fact-checked). They developed EVVER-Net, a neural network classifier that leverages domain credibility scores and text analysis to detect and filter leaked and unreliable evidence. The model was trained and evaluated on CREDULE, demonstrating high accuracy in distinguishing between evidence quality categories. The methodology also included analysis of existing AFC datasets to assess the prevalence of problematic evidence.

## Key Results
- EVVER-Net achieves up to 91.5% accuracy using domain credibility scores with short texts
- EVVER-Net achieves up to 94.4% accuracy using domain credibility scores with long texts
- Analysis reveals concerning rates of leaked and unreliable evidence in widely-used AFC datasets

## Why This Works (Mechanism)
The approach works by leveraging domain credibility scores combined with text analysis to identify evidence quality issues. The CREDULE dataset provides a large-scale training ground with clear categorical distinctions between credible, unreliable, and leaked evidence. By training EVVER-Net on this dataset, the model learns to recognize patterns associated with each category, enabling effective filtering of problematic evidence before it enters AFC systems.

## Foundational Learning
- **Evidence quality classification**: Understanding the distinction between credible, unreliable, and leaked evidence is fundamental for maintaining AFC system integrity
  - Why needed: Without proper classification, AFC systems may incorporate flawed evidence leading to incorrect fact-checking results
  - Quick check: Can you identify examples of each evidence category in real news articles?

- **Domain credibility scoring**: Using external credibility metrics as features for evidence verification
  - Why needed: Provides an additional signal beyond text content to assess evidence reliability
  - Quick check: How would you verify a domain's credibility score using external sources?

- **Neural network evidence classification**: Applying deep learning to distinguish evidence quality categories
  - Why needed: Enables automated detection of problematic evidence at scale
  - Quick check: What architectural choices might affect classification performance for evidence verification?

## Architecture Onboarding

**Component Map:**
CREDULE Dataset Construction -> EVVER-Net Neural Network -> Evidence Filtering Module

**Critical Path:**
1. Data collection and classification from web sources
2. Neural network training on CREDULE dataset
3. Integration with AFC systems for evidence filtering

**Design Tradeoffs:**
- Automated scraping vs. manual curation: Speed and scale versus potential bias and quality control
- Domain-based vs. content-based features: Complementary signals with different strengths
- High accuracy vs. generalizability: Model performs well on constructed dataset but needs external validation

**Failure Signatures:**
- False positives on credible sources with poor domain reputation
- Inability to detect sophisticated misinformation campaigns
- Over-reliance on domain credibility when content quality differs

**3 First Experiments:**
1. Test EVVER-Net on a small sample of manually verified evidence from diverse sources
2. Compare EVVER-Net performance with baseline approaches using only domain scores
3. Evaluate the impact of evidence filtering on AFC system accuracy using controlled test cases

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Dataset construction relies on automatic web scraping without detailed source selection criteria documentation
- Classification of "leaked" evidence assumes perfect accuracy of fact-checking organizations
- Performance metrics reported without cross-validation details or external validation on independent datasets

## Confidence

**High confidence**: The fundamental observation that widely-used AFC datasets contain unreliable and leaked evidence is well-supported and critical for the field

**Medium confidence**: The CREDULE dataset construction methodology and its resulting quality metrics, given limited documentation of sampling procedures

**Medium confidence**: The EVVER-Net model's performance on the constructed test sets, though generalizability remains uncertain

**Low confidence**: Claims about the model's effectiveness in real-world AFC deployment without extensive field testing

## Next Checks

1. Conduct cross-validation using multiple independent fact-checking sources to verify the consistency of "leaked" evidence identification

2. Perform human evaluation studies to assess the practical utility and accuracy of EVVER-Net's filtering decisions in real AFC workflows

3. Test EVVER-Net's performance on AFC datasets not used in the original model training or validation to establish generalizability