---
ver: rpa2
title: 'FedAST: Federated Asynchronous Simultaneous Training'
arxiv_id: '2406.00302'
source_url: https://arxiv.org/abs/2406.00302
tags:
- training
- fedast
- clients
- client
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of efficiently training multiple
  machine learning models for different tasks in a federated learning setting, where
  clients collaboratively train models without sharing their private data. The proposed
  solution, FedAST, is a federated asynchronous simultaneous training algorithm that
  mitigates straggler delays from synchronous aggregation and dynamically allocates
  client resources across heterogeneous tasks.
---

# FedAST: Federated Asynchronous Simultaneous Training

## Quick Facts
- arXiv ID: 2406.00302
- Source URL: https://arxiv.org/abs/2406.00302
- Reference count: 40
- This paper addresses the challenge of efficiently training multiple machine learning models for different tasks in a federated learning setting, where clients collaboratively train models without sharing their private data.

## Executive Summary
This paper proposes FedAST, a federated asynchronous simultaneous training algorithm for training multiple models for different tasks in federated learning settings. The algorithm addresses straggler delays from synchronous aggregation and dynamically allocates client resources across heterogeneous tasks using buffered asynchronous aggregation and adaptive resource allocation. FedAST provides theoretical convergence guarantees for smooth non-convex objective functions and demonstrates up to 46.0% reduction in time to train multiple tasks to completion compared to existing approaches.

## Method Summary
FedAST employs buffered asynchronous aggregation to overcome bottlenecks from slow models and adaptively allocates client resources across heterogeneous tasks. The server maintains per-task buffers to store client updates, aggregates them when buffers fill, and periodically reallocates clients based on estimated task heterogeneity. The algorithm uses τ local SGD steps per client update and enforces staleness bounds to preserve convergence guarantees for non-convex objectives.

## Key Results
- FedAST outperforms existing simultaneous FL approaches with up to 46.0% reduction in time to train multiple tasks to completion
- Buffered asynchronous aggregation reduces straggler-induced delays compared to synchronous aggregation
- Dynamic client allocation based on task heterogeneity improves convergence for heterogeneous tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Buffered asynchronous aggregation reduces straggler-induced delays in multi-model federated training.
- Mechanism: Instead of waiting for the slowest client across all models, FedAST aggregates updates as soon as a buffer fills, decoupling client completion times from global synchronization points.
- Core assumption: The buffer size can be tuned to balance staleness and runtime, and the variance in update quality across tasks is bounded.
- Evidence anchors: [abstract] "buffered asynchronous federated simultaneous training algorithm that overcomes bottlenecks from slow models" [section 3] "To keep staleness in check, the server maintains a buffer Bm for task m, which stores the received client updates for model m"
- Break condition: If buffer size is too small, staleness spikes and model accuracy degrades; if too large, runtime advantage diminishes.

### Mechanism 2
- Claim: Dynamic client allocation based on estimated inter-client data heterogeneity accelerates convergence for heterogeneous tasks.
- Mechanism: FedAST periodically estimates task heterogeneity (σ²_g,m) from recent updates and reallocates active training requests so that more heterogeneous tasks receive proportionally more clients.
- Core assumption: The variance of updates is a reliable proxy for task heterogeneity and that the total client pool can be redistributed without violating system constraints.
- Evidence anchors: [section 3] "the server stores the last V updates... computes ˆσ²_g,m... and the optimal resource allocation emerges as the solution to the following constraints" [section 4] "the optimal resource allocation emerges as the solution to... the second set ensures the allocation of a larger number of training requests to clients with higher heterogeneity"
- Break condition: If the heterogeneity estimate becomes stale or noisy, dynamic allocation may worsen resource efficiency.

### Mechanism 3
- Claim: Combining buffered aggregation with multi-step local SGD preserves convergence guarantees for non-convex objectives.
- Mechanism: FedAST uses τ local SGD steps per client update, and the theoretical analysis shows that the buffer smooths out stochastic variance while τ steps improve per-client progress without increasing staleness beyond γ_max.
- Core assumption: Smoothness (L-smooth), bounded variance, and bounded heterogeneity assumptions hold, and the staleness bound γ_max is enforced in practice.
- Evidence anchors: [section 4] "We provide a theoretical convergence analysis of FedAST... improves previous analyses even in the single-model FL setting" [section 4] "The FedAvg Error - I and - II terms... capture the error bound for synchronous FedAvg... The third error term... arises due to asynchronous aggregation"
- Break condition: If local step count τ or buffer size b violates the learning rate conditions, convergence rate degrades.

## Foundational Learning

- Concept: Smoothness (L-smoothness) of loss functions
  - Why needed here: Required for bounding gradient changes and establishing convergence rates in Theorem 1.
  - Quick check question: What does L-smoothness guarantee about the relationship between gradients of two points?

- Concept: Stochastic gradient variance and unbiasedness
  - Why needed here: Ensures that client updates are unbiased estimators of true gradients and bounds variance terms in the convergence proof.
  - Quick check question: How does bounded variance of stochastic gradients affect the aggregation error in asynchronous FL?

- Concept: Heterogeneity across clients
  - Why needed here: Determines how different data distributions impact model updates and informs dynamic client allocation.
  - Quick check question: Why does higher inter-client heterogeneity justify allocating more clients to a task?

## Architecture Onboarding

- Component map:
  - Server: maintains per-task models, round indices, buffers, and learning rates; sends/receives updates; triggers dynamic allocation
  - Clients: queue and execute training requests; return updates; no need to store all models simultaneously
  - Buffer: stores received updates until size b_m is reached; controls staleness
  - Realloc: periodically adjusts R_m and b_m based on estimated heterogeneity

- Critical path:
  1. Server assigns training requests to randomly selected clients
  2. Clients perform τ local SGD steps and return updates
  3. Server buffers updates; when buffer fills, aggregates and updates model
  4. Server sends new requests (possibly adjusted by Realloc)
  5. Repeat until convergence

- Design tradeoffs:
  - Buffer size vs. staleness: larger buffers reduce aggregation frequency but increase staleness
  - Active request count vs. runtime: more requests shorten rounds but increase worst-case staleness
  - Static vs. dynamic allocation: static is simpler but may underutilize resources; dynamic adapts but adds overhead

- Failure signatures:
  - Accuracy plateaus or oscillates: likely staleness too high (buffer too small or R_m too large)
  - Convergence very slow: possible under-allocation of clients to a high-heterogeneity task
  - Training never completes: possible misconfigured learning rates violating theoretical bounds

- First 3 experiments:
  1. Single-task FedAST vs. FedAvg with varying buffer sizes to observe staleness/accuracy trade-off
  2. Two heterogeneous tasks with static allocation to confirm baseline behavior
  3. Two heterogeneous tasks with dynamic allocation to validate variance-based client reallocation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FedAST perform when the number of simultaneous tasks increases beyond 6, especially in terms of wall-clock time and model accuracy?
- Basis in paper: [inferred] The paper shows FedAST's performance with up to 6 simultaneous tasks and mentions that the advantage over synchronous methods increases with the number of tasks due to the straggler effect.
- Why unresolved: The paper only evaluates FedAST with 2, 4, and 6 simultaneous tasks, leaving the performance with more tasks unknown.
- What evidence would resolve it: Conducting experiments with 8 or more simultaneous tasks and comparing the wall-clock time and accuracy of FedAST to other baselines.

### Open Question 2
- Question: How does the choice of buffer size affect the convergence rate and final accuracy of FedAST in scenarios with varying levels of client heterogeneity?
- Basis in paper: [explicit] The paper mentions that the buffer size is crucial for mitigating staleness and that its optimal choice scales with the number of active requests, but it doesn't explore the effect of different buffer sizes on convergence and accuracy.
- Why unresolved: The paper uses a fixed buffer size ratio but doesn't investigate the impact of varying buffer sizes on performance.
- What evidence would resolve it: Performing experiments with different buffer sizes while keeping the number of active requests constant and measuring the convergence rate and final accuracy.

### Open Question 3
- Question: How does FedAST handle scenarios where the computational complexity and data heterogeneity of tasks change dynamically during training?
- Basis in paper: [explicit] The paper proposes a dynamic allocation strategy (option = D) to adapt to varying training progress and data heterogeneity, but it doesn't explore scenarios where these factors change unpredictably.
- Why unresolved: The experiments focus on static or slowly changing heterogeneity levels, not on rapid or unpredictable changes.
- What evidence would resolve it: Simulating scenarios where tasks' computational complexity and data heterogeneity fluctuate significantly during training and evaluating FedAST's ability to adapt and maintain performance.

### Open Question 4
- Question: How does the performance of FedAST compare to other asynchronous federated learning methods in non-i.i.d. data scenarios with high client heterogeneity?
- Basis in paper: [explicit] The paper compares FedAST to synchronous baselines and a no-buffer asynchronous version (FedAST-NoBuffer), but it doesn't compare it to other asynchronous FL methods designed for non-i.i.d. data.
- Why unresolved: The paper focuses on FedAST's advantages over synchronous methods and its own no-buffer version, leaving comparisons with other asynchronous FL methods unexplored.
- What evidence would resolve it: Implementing and comparing FedAST to other asynchronous FL methods like FedBuff or adaptive asynchronous approaches in non-i.i.d. data scenarios with high client heterogeneity.

## Limitations

- The effectiveness of variance-based heterogeneity estimation for client allocation lacks validation in related work
- The buffer size tuning strategy and its impact on staleness-accuracy tradeoff needs more empirical validation
- The learning rate conditions and their practical implementation may be challenging to satisfy

## Confidence

- High confidence in the mechanism of buffered asynchronous aggregation reducing straggler delays
- Medium confidence in the dynamic client allocation based on heterogeneity estimates
- Medium confidence in the convergence guarantees for non-convex objectives under stated assumptions

## Next Checks

1. **Buffer size sensitivity analysis**: Systematically vary buffer sizes (b_m) and active request counts (R_m) to identify the optimal ratio that minimizes staleness while maintaining convergence, particularly for the stated bound of ratio ≤ 37.

2. **Dynamic allocation effectiveness**: Implement and test the Realloc subroutine on heterogeneous tasks, comparing performance against both static allocation and uniform allocation baselines to validate the variance-based client redistribution approach.

3. **Convergence robustness testing**: Test FedAST with different τ values and learning rates to verify the theoretical convergence bounds hold in practice, especially examining whether the staleness bound γ_max can be maintained without degrading accuracy.