---
ver: rpa2
title: Frequency Enhanced Pre-training for Cross-city Few-shot Traffic Forecasting
arxiv_id: '2406.02614'
source_url: https://arxiv.org/abs/2406.02614
tags:
- traffic
- data
- forecasting
- domain
- few-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses cross-city few-shot traffic forecasting, where
  a model is pre-trained on abundant traffic data from a source city and fine-tuned
  on limited data from a target city. The key insight is that traffic data is more
  similar across cities in the frequency domain.
---

# Frequency Enhanced Pre-training for Cross-city Few-shot Traffic Forecasting

## Quick Facts
- arXiv ID: 2406.02614
- Source URL: https://arxiv.org/abs/2406.02614
- Authors: Zhanyu Liu; Jianrong Ding; Guanjie Zheng
- Reference count: 40
- Key outcome: FEPCross achieves up to 15.84% improvement in MAPE and 16.77% in MAE for cross-city few-shot traffic forecasting

## Executive Summary
This paper addresses the challenge of cross-city few-shot traffic forecasting, where models must transfer knowledge from a source city with abundant data to a target city with limited data. The key insight is that traffic patterns are more similar across cities in the frequency domain than in the time domain. FEPCross is proposed as a framework that first pre-trains on source city data using frequency domain information and contrastive learning, then fine-tunes on target city data with specialized modules to prevent overfitting. Extensive experiments on real-world datasets demonstrate state-of-the-art performance.

## Method Summary
FEPCross consists of a pre-training stage on source city data and a fine-tuning stage on target city data. During pre-training, traffic time series are transformed into frequency domain components (amplitude and phase), then processed through a Cross-Domain Spatial-Temporal Encoder that fuses time, amplitude, and phase information. The encoder is trained with reconstruction and contrastive losses, where the latter uses amplitude-swapping augmentation to encourage frequency-invariant representations. In fine-tuning, the model uses data enrichment techniques and a momentum-updated graph structure to adapt to the target city while preventing overfitting to the few available samples.

## Key Results
- FEPCross achieves up to 15.84% improvement in MAPE and 16.77% in MAE compared to state-of-the-art methods
- The method demonstrates effective cross-city transfer learning capabilities on real-world traffic datasets
- Frequency domain fusion outperforms time domain-only approaches for cross-city adaptation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-domain information fusion between time, amplitude, and phase domains captures shared frequency patterns across cities.
- Mechanism: The Cross-Domain Spatial-Temporal Encoder processes each domain separately through transformer blocks, then fuses them using a Cross-Domain Aggregator (another transformer layer) before spatial aggregation via a graph neural network. This hierarchical fusion preserves domain-specific features while learning cross-domain correlations.
- Core assumption: Frequency domain patterns are more similar across cities than time domain patterns, and this similarity can be leveraged for transfer learning.
- Evidence anchors:
  - [abstract] states "traffic data is more similar in the frequency domain between cities"
  - [section 1] shows cosine similarity comparisons demonstrating higher frequency domain similarity
  - [corpus] contains related work on cross-city traffic forecasting but no direct frequency-domain comparison studies
- Break condition: If cross-city similarity is actually higher in time domain than frequency domain, the fusion strategy would be misaligned with the actual data structure.

### Mechanism 2
- Claim: Contrastive learning with amplitude-swapped samples encourages learning frequency-invariant representations.
- Mechanism: During pre-training, for each sample in a batch, the amplitude domain is randomly replaced with another sample's amplitude while keeping time and phase domains unchanged. The encoder is then trained to bring the original and augmented sample embeddings closer in representation space.
- Core assumption: Traffic amplitude patterns contain the most city-specific information, while phase and temporal structure are more transferable across cities.
- Evidence anchors:
  - [section 4.1] describes the contrastive module with amplitude swapping
  - [abstract] mentions "contrastive objectives" as part of self-supervised training
  - [corpus] shows related work on contrastive learning for traffic forecasting but no specific amplitude-based approaches
- Break condition: If amplitude patterns are actually more transferable across cities than assumed, this augmentation would introduce noise rather than regularization.

### Mechanism 3
- Claim: Momentum-updated graph structure prevents overfitting to few-shot target city data while incorporating pre-trained knowledge.
- Mechanism: The target city's graph is iteratively updated using a convex combination of the meta-graph (derived from pre-trained encoder embeddings) and the previous iteration's graph, controlled by momentum parameter τ.
- Core assumption: The initial target city graph contains noise and the pre-trained encoder can provide more reliable inter-node relationships.
- Evidence anchors:
  - [section 4.2] describes the momentum graph update formula and purpose
  - [abstract] mentions "momentum-updated graph structure" to mitigate overfitting
  - [corpus] shows related work on graph neural networks for traffic forecasting but no momentum-based graph refinement approaches
- Break condition: If the initial target city graph is already accurate or the pre-trained knowledge is misaligned with target city structure, momentum updates could degrade rather than improve the graph.

## Foundational Learning

- Concept: Fourier Transform for signal decomposition
  - Why needed here: Enables extraction of frequency domain features (amplitude and phase) from traffic time series
  - Quick check question: What information is preserved in amplitude vs phase components after Fourier Transform?
- Concept: Self-supervised learning with reconstruction and contrastive losses
  - Why needed here: Allows pre-training on source city data without requiring labeled target city data
  - Quick check question: How do reconstruction and contrastive losses complement each other in representation learning?
- Concept: Graph neural networks for spatial dependency modeling
  - Why needed here: Captures relationships between traffic sensors/nodes within and across cities
  - Quick check question: What graph structure assumptions are being made about traffic sensor relationships?

## Architecture Onboarding

- Component map: Fourier Transform → Patch Masking → Three Domain Transformers → Cross-Domain Aggregator → Graph Neural Network → Cross-Domain Aggregator → Reconstruction/Contrastive Modules → STmodel + Forecasting
- Critical path: Pre-training encoder → Fine-tuning data enrichment and graph update → Final forecasting with STmodel
- Design tradeoffs: Frequency domain fusion adds complexity but enables cross-city transfer; momentum graph update adds robustness but requires careful hyperparameter tuning
- Failure signatures: Poor reconstruction accuracy indicates encoder capacity issues; high variance across runs suggests instability in contrastive learning or momentum updates
- First 3 experiments:
  1. Verify Fourier Transform correctly extracts amplitude and phase components with expected symmetry properties
  2. Test reconstruction accuracy on pre-training data with varying mask ratios to find optimal trade-off
  3. Evaluate contrastive learning effectiveness by measuring embedding similarity between original and amplitude-swapped samples

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of FEPCross scale with increasing differences in traffic patterns between source and target cities?
- Basis in paper: [inferred] The paper demonstrates effectiveness of FEPCross in cross-city transfer but does not explore performance degradation with increasing city dissimilarity.
- Why unresolved: The experiments use only four cities without systematically varying their similarity, making it unclear how robust the approach is to cities with highly divergent traffic patterns.
- What evidence would resolve it: Experiments systematically varying the similarity between source and target cities (e.g., by clustering cities based on traffic patterns and testing transfers between increasingly dissimilar clusters).

### Open Question 2
- Question: How sensitive is FEPCross to the choice of frequency domain parameters, such as the Fourier transform window size or the number of frequency components retained?
- Basis in paper: [explicit] The paper uses Fourier transform to extract amplitude and phase domains but does not explore sensitivity to these parameters or discuss how they were chosen.
- Why unresolved: The effectiveness of the frequency domain representation may vary significantly with parameter choices, yet the paper does not report ablation studies on these parameters.
- What evidence would resolve it: Systematic ablation studies varying Fourier transform parameters and reporting performance impact, or justification for the specific parameters chosen.

### Open Question 3
- Question: Can the frequency-enhanced pre-training approach generalize to other spatio-temporal domains beyond traffic forecasting?
- Basis in paper: [inferred] The paper focuses specifically on traffic data but discusses the general principle of frequency domain similarity across cities.
- Why unresolved: While the paper demonstrates success on traffic data, it does not test whether the approach works for other spatio-temporal domains like weather forecasting or crowd movement prediction.
- What evidence would resolve it: Applying FEPCross to other spatio-temporal domains and reporting performance, or theoretical analysis explaining why the approach should generalize.

## Limitations
- The frequency similarity assumption across cities lacks theoretical justification for why certain frequency components transfer more effectively than others
- The method's effectiveness for extremely low-shot scenarios (e.g., <10 samples) remains untested
- The amplitude-swapping augmentation strategy assumes amplitude patterns are most city-specific, which may not hold for all traffic scenarios or city types

## Confidence
- **High Confidence**: The core framework design (frequency domain decomposition, cross-domain fusion, contrastive learning) is well-specified and theoretically sound
- **Medium Confidence**: The empirical improvements over baselines are demonstrated but may be dataset-specific, as results are shown primarily on California and Chinese traffic datasets
- **Medium Confidence**: The claim that frequency domain patterns are more similar across cities is supported by cosine similarity analysis but lacks cross-validation on diverse city types

## Next Checks
1. **Cross-domain ablation study**: Remove the amplitude-swapping contrastive learning component and measure the impact on cross-city transfer performance to validate its contribution
2. **Frequency vs time domain comparison**: Systematically compare cross-city similarity in time vs frequency domains across multiple city pairs to verify the foundational assumption
3. **Low-shot boundary testing**: Evaluate FEPCross performance on extreme few-shot scenarios (1-10 samples) to determine the practical limits of the approach