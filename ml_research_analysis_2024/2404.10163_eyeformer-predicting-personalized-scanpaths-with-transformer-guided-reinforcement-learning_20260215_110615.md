---
ver: rpa2
title: 'EyeFormer: Predicting Personalized Scanpaths with Transformer-Guided Reinforcement
  Learning'
arxiv_id: '2404.10163'
source_url: https://arxiv.org/abs/2404.10163
tags:
- scanpath
- fixation
- scanpaths
- prediction
- viewer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EyeFormer, a novel scanpath prediction model
  that can generate both population-level and individual-level scanpaths across different
  types of stimuli. The key innovation is leveraging a Transformer architecture as
  a policy network to guide a deep reinforcement learning algorithm that controls
  gaze locations.
---

# EyeFormer: Predicting Personalized Scanpaths with Transformer-Guided Reinforcement Learning

## Quick Facts
- arXiv ID: 2404.10163
- Source URL: https://arxiv.org/abs/2404.10163
- Authors: Yue Jiang; Zixin Guo; Hamed Rezazadegan Tavakoli; Luis A. Leiva; Antti Oulasvirta
- Reference count: 40
- Primary result: Introduces EyeFormer, a novel scanpath prediction model leveraging Transformer architecture and reinforcement learning

## Executive Summary
EyeFormer is a novel scanpath prediction model that addresses critical limitations in existing methods by incorporating temporal information, enabling differentiable optimization, and capturing individual differences. The model uses a Transformer architecture as a policy network to guide deep reinforcement learning for controlling gaze locations. It achieves state-of-the-art performance on scanpath prediction metrics for both GUIs and natural scenes, and demonstrates the ability to predict personalized scanpaths for individual viewers given a few sample scanpaths. The model shows promise for applications in GUI layout optimization and personalized visual flow design.

## Method Summary
EyeFormer combines a Transformer-based policy network with reinforcement learning to predict scanpaths. The model uses a deep reinforcement learning algorithm where the Transformer architecture guides gaze location decisions. This approach enables the incorporation of temporal dependencies in scanpath prediction while allowing for differentiable optimization. The policy network is trained to maximize rewards based on scanpath similarity metrics, and can be fine-tuned for individual viewers using a small number of their personal scanpaths. The model is evaluated on both GUI and natural scene stimuli, demonstrating superior performance compared to existing methods.

## Key Results
- Achieves state-of-the-art performance on scanpath prediction metrics for GUI and natural scene stimuli
- Successfully generates both population-level and individual-level scanpaths
- Demonstrates personalized prediction capability with only 3-5 sample scanpaths per viewer

## Why This Works (Mechanism)
The paper introduces a novel approach to scanpath prediction by addressing three fundamental limitations in existing methods: temporal information incorporation, differentiable optimization, and individual difference capture. The Transformer architecture serves as a powerful mechanism for encoding spatial-temporal dependencies in visual attention patterns, while reinforcement learning provides a flexible framework for optimizing gaze control policies. By combining these elements, EyeFormer can learn complex patterns in how humans explore visual stimuli and generate predictions that reflect both general population trends and individual viewing behaviors.

## Foundational Learning

**Reinforcement Learning for Gaze Control**
- Why needed: Traditional optimization approaches struggle with the discrete nature of gaze selection
- Quick check: Verify that reward function properly captures scanpath similarity metrics

**Transformer Architecture for Temporal Dependencies**
- Why needed: Scanpaths are inherently sequential, requiring models that can capture long-range temporal relationships
- Quick check: Confirm attention mechanism effectively learns gaze transition patterns

**Policy Gradient Methods**
- Why needed: Direct optimization of scanpath generation policies requires gradient-based approaches
- Quick check: Ensure policy updates lead to consistent improvement in prediction accuracy

## Architecture Onboarding

**Component Map**
Input stimuli -> Feature extractor -> Transformer policy network -> Action selector -> Gaze location output

**Critical Path**
Feature extraction → Transformer encoding → Policy action → Gaze location selection

**Design Tradeoffs**
- Transformer depth vs. computational efficiency
- Exploration vs. exploitation in reinforcement learning
- Sample efficiency for personalized predictions

**Failure Signatures**
- Poor convergence during training indicates reward function issues
- Inability to capture individual differences suggests insufficient personalization capacity
- Temporal inconsistency in predictions reveals limitations in sequence modeling

**First Experiments**
1. Test scanpath prediction on a single stimulus type to establish baseline performance
2. Evaluate personalized prediction with varying numbers of sample scanpaths
3. Compare performance against baseline methods on established metrics

## Open Questions the Paper Calls Out
None

## Limitations
- Focus on GUI and natural scene stimuli leaves uncertainty about performance on other visual domains
- Requirement for multiple sample scanpaths (3-5) may limit real-world applicability
- Computational complexity of Transformer-based approach may constrain real-time applications

## Confidence

**High confidence**: Claims about state-of-the-art performance on established metrics for GUI and natural scene scanpath prediction

**Medium confidence**: Claims about the model's ability to capture individual differences and generate personalized scanpaths

**Medium confidence**: Claims about the Transformer architecture's superiority for incorporating temporal information compared to alternative approaches

## Next Checks

1. Evaluate EyeFormer's performance on specialized visual domains (medical imaging, text documents, data visualizations) to assess generalizability beyond GUI and natural scenes

2. Conduct ablation studies comparing the Transformer-based policy network against simpler recurrent architectures to quantify the actual contribution of the Transformer component

3. Test the personalized prediction capability with varying amounts of individual viewing data (from 1 to 10 sample scanpaths) to determine the minimum required samples for reliable personalization