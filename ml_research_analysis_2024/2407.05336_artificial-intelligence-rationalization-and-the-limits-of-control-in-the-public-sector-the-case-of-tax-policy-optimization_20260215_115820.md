---
ver: rpa2
title: 'Artificial intelligence, rationalization, and the limits of control in the
  public sector: the case of tax policy optimization'
arxiv_id: '2407.05336'
source_url: https://arxiv.org/abs/2407.05336
tags:
- systems
- policy
- social
- rationalization
- public
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper argues that the use of AI systems in the public sector
  is best understood as a continuation and intensification of long-standing rationalization
  and bureaucratization processes, whereby traditions are replaced by instrumental
  rationality to achieve policy objectives. The authors propose a thought experiment
  where AI systems optimize tax policy to reduce economic inequality.
---

# Artificial intelligence, rationalization, and the limits of control in the public sector: the case of tax policy optimization

## Quick Facts
- arXiv ID: 2407.05336
- Source URL: https://arxiv.org/abs/2407.05336
- Reference count: 11
- This paper argues that AI systems in the public sector intensify rationalization processes, using tax policy optimization as a case study to demonstrate technical feasibility but ethical concerns about excluding other values and undermining human self-determination.

## Executive Summary
This paper examines how AI systems in the public sector represent a continuation and intensification of rationalization and bureaucratization processes. The authors present a thought experiment where AI optimizes tax policy to reduce economic inequality, demonstrating that while technically feasible, such optimization excludes other political values and undermines citizens' non-instrumental obligations to each other. The analysis distinguishes between technical failures of AI systems and their social/ethical challenges, arguing these require different remedies. The paper concludes that AI-driven policy optimization necessitates making normative ends explicit and formalized, subjecting them to public scrutiny and debate.

## Method Summary
The authors employ a theoretical thought experiment methodology, constructing an AI-optimized tax policy scenario to explore the implications of instrumental rationality in public sector decision-making. They analyze the tension between technical optimization capabilities and the exclusion of other political values, drawing on concepts from Weber's rationalization theory and contemporary AI governance literature. The approach involves examining how AI systems transform policy objectives into formalized, executable rules while potentially overriding non-instrumental social relationships and democratic deliberation processes.

## Key Results
- AI systems intensify bureaucratic rationalization by replacing traditions with instrumental rationality to achieve policy objectives
- Technical feasibility of AI-driven tax optimization exists, but comes at the cost of excluding other political values and undermining human self-determination
- Social and ethical challenges of AI systems are distinct from technical failures and require different remedial approaches

## Why This Works (Mechanism)
The paper's argument works by demonstrating how AI systems operationalize Weber's concept of rationalization in contemporary governance contexts. The mechanism involves translating policy objectives into formalized optimization problems that AI systems can execute, which inherently prioritizes measurable outcomes over qualitative social values. This creates a feedback loop where bureaucratic processes become increasingly machine-like, as AI systems require explicit formalization of normative ends that were previously implicit in human decision-making.

## Foundational Learning
- Weberian rationalization theory - needed to understand historical context of bureaucracy and its intensification through AI; quick check: can trace how traditional decision-making has evolved toward instrumental rationality over time
- AI optimization principles - needed to grasp technical feasibility of policy optimization; quick check: can explain how objective functions translate into executable policies
- Democratic theory and deliberation - needed to evaluate how AI affects political participation; quick check: can articulate tension between optimization and deliberative democracy

## Architecture Onboarding
- Component map: Tax policy objectives -> Formalization layer -> AI optimization engine -> Policy implementation
- Critical path: Formalization of normative ends → AI optimization → Policy execution → Social impact
- Design tradeoffs: Technical precision vs. social values; efficiency vs. democratic deliberation; formalization vs. flexibility
- Failure signatures: Over-optimization of single metrics, exclusion of non-quantifiable values, erosion of citizen agency
- First experiments: 1) Map existing tax policies to formal optimization problems, 2) Test AI optimization on simplified tax models, 3) Conduct stakeholder workshops to identify excluded values

## Open Questions the Paper Calls Out
None

## Limitations
- Technical feasibility of exclusive equality-focused tax systems remains theoretical rather than empirically demonstrated
- Philosophical assumptions about non-instrumental social obligations may not be universally accepted
- Conflation of AI optimization tools with their applications may oversimplify potential for democratic enhancement

## Confidence
- High confidence: AI intensifies historical rationalization processes in public sector
- Medium confidence: Technical feasibility of AI-driven tax optimization is plausible but unproven
- Medium confidence: Distinction between technical and ethical AI challenges is reasonable but needs further exploration

## Next Checks
1. Empirical validation: Test AI tax optimization framework with real-world data to assess technical feasibility and unintended consequences
2. Comparative analysis: Examine AI implementation case studies across different public sector domains to evaluate consistency of rationalization effects
3. Stakeholder impact assessment: Conduct qualitative research with citizens and policymakers on how AI optimization affects their sense of agency and social obligations