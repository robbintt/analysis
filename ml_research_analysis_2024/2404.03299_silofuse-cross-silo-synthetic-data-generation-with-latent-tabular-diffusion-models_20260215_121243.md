---
ver: rpa2
title: 'SiloFuse: Cross-silo Synthetic Data Generation with Latent Tabular Diffusion
  Models'
arxiv_id: '2404.03299'
source_url: https://arxiv.org/abs/2404.03299
tags:
- data
- features
- training
- silofuse
- latent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SiloFuse addresses the challenge of generating high-quality synthetic
  tabular data from feature-partitioned data silos while preserving privacy. It introduces
  a distributed latent tabular diffusion architecture where autoencoders encode each
  client's features into continuous latent representations, which are then centralized
  for a diffusion model to learn cross-silo correlations.
---

# SiloFuse: Cross-silo Synthetic Data Generation with Latent Tabular Diffusion Models

## Quick Facts
- arXiv ID: 2404.03299
- Source URL: https://arxiv.org/abs/2404.03299
- Reference count: 40
- Primary result: SiloFuse achieves 43.8 and 29.8 percentage points higher resemblance and utility scores than GANs while maintaining constant communication costs

## Executive Summary
SiloFuse introduces a distributed latent tabular diffusion architecture for cross-silo synthetic data generation that preserves privacy while achieving high data quality. The method decouples autoencoder and diffusion model training through a stacked approach, reducing communication to a single round while maintaining strong theoretical privacy guarantees under vertical partitioning. Experiments across nine datasets demonstrate significant improvements over GAN baselines in both data resemblance and utility metrics.

## Method Summary
SiloFuse employs a two-step stacked training process where clients first train autoencoders locally on their feature subsets, then communicate latent representations to a coordinator which trains a diffusion model. The diffusion model generates synthetic latents that are decoded back to original feature space by client-side decoders. This approach masks actual data values during training, enables continuous latent representations to avoid sparsity issues, and provides formal privacy guarantees against reconstruction attacks under vertical partitioning assumptions.

## Key Results
- Achieves 43.8 and 29.8 percentage points higher resemblance and utility scores compared to GAN baselines
- Maintains constant communication costs regardless of training iterations through stacked training
- Demonstrates robustness to feature permutations and varying numbers of clients across nine benchmark datasets
- Provides formal privacy guarantees with theoretical impossibility proofs for data reconstruction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decoupling autoencoder and diffusion model training reduces communication to a single round.
- Mechanism: Autoencoders encode client features into latents locally, communicate them once to the coordinator, then the diffusion model trains independently on the centralized latents.
- Core assumption: Latents can be communicated in a single round without iterative gradient exchanges between clients and coordinator.
- Evidence anchors:
  - [abstract]: "stacked distributed training to improve communication efficiency, reducing the number of rounds to a single step."
  - [section]: "Autoencoders encode sensitive features into continuous latent representations, which are then centralized for a diffusion model to learn cross-silo correlations."
  - [corpus]: Weak - related works focus on federated GANs or diffusion models but do not explicitly confirm the single-round communication claim.
- Break condition: If autoencoders require iterative fine-tuning with the diffusion model, the single-round claim fails.

### Mechanism 2
- Claim: Latent space encoding avoids sparsity and feature expansion from one-hot encoding.
- Mechanism: Continuous latent embeddings replace one-hot vectors for categorical features, reducing dimensionality and sparsity in the data passed to the diffusion model.
- Core assumption: Autoencoders can effectively map both categorical and continuous features into a shared continuous latent space without losing essential information.
- Evidence anchors:
  - [abstract]: "autoencoders encode each client's features into continuous latent representations, masking their actual values."
  - [section]: "This allows for the novelty of decoupling the training of autoencoders and the DDPM, capturing cross-silo feature correlations within the latent space without real data leaving the silos."
  - [corpus]: Weak - related papers mention latent diffusion models but do not quantify sparsity reduction.
- Break condition: If latent encoding degrades feature expressiveness or reconstruction accuracy.

### Mechanism 3
- Claim: Vertical partitioning preserves privacy by preventing data reconstruction from latents alone.
- Mechanism: Theorem proves coordinator cannot reconstruct original samples from latents without decoder access; sharing synthetic features introduces privacy risks that are empirically quantified.
- Core assumption: Autoencoders and decoders remain private to clients, and latents alone are insufficient for reconstruction without knowledge of input domain or encoder/decoder mappings.
- Evidence anchors:
  - [abstract]: "we prove the impossibility of data reconstruction for vertically partitioned synthesis and quantify privacy risks through three attacks."
  - [section]: "Lemma 1 and Lemma 2 establish impossibility of reconstruction without domain knowledge or decoder access; Theorem 1 formalizes latent irreversibility."
  - [corpus]: Weak - related work mentions privacy but lacks formal impossibility proofs for vertical partitioning.
- Break condition: If adversary obtains decoder parameters or input domain information.

## Foundational Learning

- Concept: Autoencoders for mixed-type tabular data
  - Why needed here: Encode categorical and continuous features into continuous latents to avoid one-hot sparsity and enable latent diffusion.
  - Quick check question: How does an autoencoder handle categorical features differently from continuous ones during encoding and decoding?

- Concept: Denoising diffusion probabilistic models (DDPMs)
  - Why needed here: Generate synthetic latents by modeling forward noising and backward denoising processes in continuous latent space.
  - Quick check question: What is the role of the variance schedule in the forward noising process of DDPMs?

- Concept: Vertical federated learning privacy constraints
  - Why needed here: Ensure data remains on-premise and no raw features are shared; formal privacy guarantees rely on vertical partitioning.
  - Quick check question: Why does vertical partitioning provide stronger privacy than horizontal partitioning in this context?

## Architecture Onboarding

- Component map:
  - Clients: Local autoencoders (encoder + decoder pairs) trained privately on their feature subsets.
  - Coordinator: Diffusion model (generator) that trains on concatenated latents from all clients.
  - Communication: Single round of latent exchange post-autoencoder training; no iterative gradient exchange.

- Critical path:
  1. Train autoencoders locally on each client.
  2. Encode and send latents to coordinator once.
  3. Coordinator trains diffusion model on centralized latents.
  4. For synthesis, coordinator denoises noise to generate synthetic latents.
  5. Clients decode synthetic latents back to original feature space.

- Design tradeoffs:
  - Privacy vs utility: Keeping synthetic features vertically partitioned preserves privacy but limits independent downstream tasks.
  - Communication cost vs model quality: Stacked training minimizes communication but may slightly reduce cross-feature correlation capture compared to end-to-end training.
  - Latent dimensionality: Balancing latent size to capture correlations without excessive dimensionality.

- Failure signatures:
  - Poor reconstruction quality: Autoencoder underfitting or latent space too compressed.
  - Low synthetic data resemblance: Diffusion model fails to learn latent correlations.
  - High privacy leakage: Synthetic features shared post-generation reveal sensitive patterns.

- First 3 experiments:
  1. Train autoencoders on a small dataset and verify reconstruction quality and latent dimensionality reduction.
  2. Centralize latents and train diffusion model; evaluate synthetic data resemblance and utility on a simple downstream task.
  3. Test privacy by attempting attribute inference attacks on synthetic features shared across clients.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of different privacy metrics on the evaluation of synthetic data quality in SiloFuse?
- Basis in paper: [explicit] The paper mentions using three types of metrics for evaluation: resemblance, utility, and privacy. It also discusses the privacy risks associated with sharing synthetic features post-generation.
- Why unresolved: The paper does not provide a detailed analysis of how different privacy metrics affect the evaluation of synthetic data quality.
- What evidence would resolve it: A comprehensive study comparing the impact of different privacy metrics on the evaluation of synthetic data quality in SiloFuse.

### Open Question 2
- Question: How does SiloFuse perform in scenarios where the number of clients is significantly larger than the number of features?
- Basis in paper: [inferred] The paper discusses SiloFuse's robustness to varying numbers of clients but does not specifically address scenarios where the number of clients is much larger than the number of features.
- Why unresolved: The paper does not provide experimental results or theoretical analysis for such scenarios.
- What evidence would resolve it: Experimental results or theoretical analysis demonstrating SiloFuse's performance in scenarios with a large number of clients compared to the number of features.

### Open Question 3
- Question: What are the trade-offs between using different types of autoencoders (e.g., variational autoencoders, denoising autoencoders) in SiloFuse?
- Basis in paper: [inferred] The paper mentions using autoencoders to encode features into latent space but does not discuss the impact of using different types of autoencoders.
- Why unresolved: The paper does not provide a comparative analysis of different autoencoder types in the context of SiloFuse.
- What evidence would resolve it: A comparative study analyzing the performance of SiloFuse when using different types of autoencoders.

## Limitations
- Theoretical privacy guarantees rely on strict control of decoder parameters and input domain knowledge, with untested robustness against adaptive adversaries
- Single-round communication claim may face practical challenges in distributed systems with heterogeneous client capabilities or network constraints
- Limited exploration of extreme partitioning scenarios where the number of clients significantly exceeds the number of features

## Confidence
- High Confidence: The effectiveness of decoupling autoencoder and diffusion model training for communication efficiency, supported by clear experimental comparisons showing 43.8 and 29.8 percentage points improvement over GAN baselines.
- Medium Confidence: The privacy guarantees under vertical partitioning, as the formal proofs are provided but the practical implications against adaptive adversaries remain untested.
- Medium Confidence: The robustness to feature permutations and varying client numbers, demonstrated across nine datasets but with limited exploration of extreme partitioning scenarios.

## Next Checks
1. Conduct experiments where an adversary attempts to reconstruct decoder parameters through iterative queries of synthetic data, testing the practical limits of the theoretical privacy guarantees.
2. Evaluate the single-round communication claim under realistic network conditions with heterogeneous client capabilities, including clients with limited bandwidth or computational resources.
3. Test the model's performance when features are partitioned into many small subsets (e.g., one feature per client) to assess scalability and correlation capture in highly fragmented scenarios.