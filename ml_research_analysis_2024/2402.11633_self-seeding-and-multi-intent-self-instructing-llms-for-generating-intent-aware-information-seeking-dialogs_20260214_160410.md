---
ver: rpa2
title: Self-seeding and Multi-intent Self-instructing LLMs for Generating Intent-aware
  Information-Seeking dialogs
arxiv_id: '2402.11633'
source_url: https://arxiv.org/abs/2402.11633
tags:
- dialog
- intent
- dialogs
- intents
- solid
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents SOLID, a novel approach for zero-shot generation
  of intent-aware information-seeking dialogs using large language models (LLMs).
  SOLID leverages self-seeding and multi-intent self-instructing to improve dialog
  generation quality, generating over 300k dialogs.
---

# Self-seeding and Multi-intent Self-instructing LLMs for Generating Intent-aware Information-Seeking dialogs

## Quick Facts
- arXiv ID: 2402.11633
- Source URL: https://arxiv.org/abs/2402.11633
- Reference count: 40
- Generates over 300k intent-aware information-seeking dialogs using self-seeding and multi-intent self-instructing

## Executive Summary
This paper introduces SOLID, a novel approach for generating large-scale intent-aware information-seeking dialogs using large language models (LLMs) in a zero-shot setting. The method employs self-seeding and multi-intent self-instructing to improve dialog generation quality and scale. SOLID-RL, a variant trained on SOLID-generated data, achieves significant efficiency gains while maintaining quality through a length-based mixed-quality training strategy. Experiments demonstrate that information-seeking methods trained on SOLID and SOLID-RL data outperform those trained on human-generated dialogs.

## Method Summary
The paper presents SOLID, a framework that generates intent-aware information-seeking dialogs using LLMs through self-seeding and multi-intent self-instructing. The approach creates synthetic training data at scale, generating over 300k dialogs. SOLID-RL extends this by training on the generated data with a length-based mixed-quality strategy that improves efficiency while maintaining quality. The method operates in a zero-shot setting without requiring human-annotated dialogs for training.

## Key Results
- SOLID generates over 300k intent-aware information-seeking dialogs
- SOLID-RL achieves 11x efficiency gains compared to baseline approaches
- IP methods trained on SOLID and SOLID-RL data outperform those trained on human-generated dialogs

## Why This Works (Mechanism)
The approach works by leveraging LLMs' ability to generate coherent dialog sequences while using self-seeding to maintain consistency across dialog turns. Multi-intent self-instructing enables the generation of diverse dialog patterns by incorporating multiple user intents within single dialogs. The self-seeding mechanism ensures that generated dialogs maintain logical flow and intent alignment throughout conversations. By training SOLID-RL on this generated data with length-based quality mixing, the system learns to optimize both dialog quality and generation efficiency.

## Foundational Learning
- **Self-seeding**: A technique where generated outputs are used as seeds for subsequent generation steps; needed to maintain dialog consistency and reduce drift; quick check: monitor coherence across dialog turns
- **Multi-intent self-instructing**: The process of generating dialogs with multiple user intents in a single conversation; needed to create diverse and realistic information-seeking scenarios; quick check: verify intent diversity in generated dialogs
- **Zero-shot generation**: Creating data without any task-specific training or examples; needed to demonstrate the method's general applicability; quick check: validate output quality without task-specific tuning

## Architecture Onboarding

Component map: LLM -> Self-seeding Engine -> Multi-intent Generator -> Quality Filter -> SOLID-RL Trainer

Critical path: LLM generates initial dialog -> Self-seeding maintains consistency -> Multi-intent integration creates diversity -> Quality filtering selects optimal examples -> SOLID-RL training optimizes efficiency

Design tradeoffs: Zero-shot generation versus fine-tuning accuracy; volume of generated data versus quality control; efficiency gains versus potential introduction of synthetic artifacts

Failure signatures: Dialog coherence breakdown across turns; repetitive intent patterns; quality degradation in longer dialogs; inconsistent persona behavior

First experiments:
1. Generate 1,000 dialogs with single intent and evaluate coherence
2. Test multi-intent generation with 2-3 intents per dialog
3. Apply self-seeding to 100 dialog turns and measure consistency

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy dependence on LLM-generated data quality, which may contain subtle biases
- Zero-shot focus limits comparison with few-shot or fine-tuned approaches
- Reported efficiency gains need careful interpretation due to limited baseline details
- Mixed-quality training may introduce instability not fully characterized
- Current focus on English dialogs limits multilingual generalizability

## Confidence
**High confidence**: SOLID's ability to generate large volumes of dialog data (300k dialogs) and basic IP method performance improvements

**Medium confidence**: 11x efficiency gains and relative performance against human-generated dialogs

**Medium confidence**: Length-based mixed-quality training effectiveness

## Next Checks
1. Conduct ablation studies to isolate the contribution of each component (self-seeding, multi-intent self-instructing, length-based training) to the observed performance gains

2. Test SOLID's effectiveness across multiple domains and languages beyond information-seeking dialogs

3. Compare SOLID-RL's performance with fine-tuned LLMs using the same generated data to better understand the efficiency-quality tradeoff curve