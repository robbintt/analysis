---
ver: rpa2
title: Mitigating Exposure Bias in Score-Based Generation of Molecular Conformations
arxiv_id: '2409.14014'
source_url: https://arxiv.org/abs/2409.14014
tags:
- bias
- exposure
- molecular
- which
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the exposure bias problem in Score-Based Generative
  Models (SGMs) for molecular conformation generation, where discrepancies between
  training and inference phases lead to performance degradation. The authors propose
  a novel method to measure this exposure bias in SGMs, confirming its existence and
  quantifying its magnitude.
---

# Mitigating Exposure Bias in Score-Based Generation of Molecular Conformations

## Quick Facts
- arXiv ID: 2409.14014
- Source URL: https://arxiv.org/abs/2409.14014
- Authors: Sijia Wang; Chen Wang; Zhenhao Zhao; Jiqiang Zhang; Weiran Cai
- Reference count: 30
- This paper introduces Input Perturbation to mitigate exposure bias in Score-Based Generative Models for molecular conformation generation, achieving state-of-the-art performance.

## Executive Summary
This paper addresses the exposure bias problem in Score-Based Generative Models (SGMs) for molecular conformation generation, where discrepancies between training and inference phases lead to performance degradation. The authors propose a novel method to measure this exposure bias in SGMs, confirming its existence and quantifying its magnitude. They adapt the Input Perturbation technique from Diffusion Probabilistic Models (DPMs) to SGMs, introducing Gaussian noise during training to enhance model robustness. Experimental results demonstrate significant improvements in both accuracy and diversity of generated molecular conformations, with the enhanced Torsional Diffusion model achieving state-of-the-art performance on the GEOM-Drugs dataset.

## Method Summary
The method introduces Input Perturbation (IP) to SGMs by adding Gaussian noise to training inputs, making the model robust to input variations. The approach measures exposure bias through Algorithm 2, which tracks the discrepancy between ground truth and predicted samples across the sampling chain. During training, IP adds noise λ_t ξ to the input samples, forcing the model to learn representations invariant to small perturbations. The asymmetric training procedure (noisy inputs, clean generation) allows trajectories to stick closer to ground truth despite potential biases during generation. The enhanced Torsional Diffusion model is evaluated on GEOM-Drugs and GEOM-QM9 datasets using RMSD, COV, and MAT metrics.

## Key Results
- Input Perturbation technique significantly improves both accuracy and diversity of generated molecular conformations
- Enhanced Torsional Diffusion achieves state-of-the-art performance on GEOM-Drugs dataset
- Competitive results on GEOM-QM9 dataset demonstrate method's generalizability
- Exposure bias is confirmed and quantified through novel measurement methodology

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The exposure bias in Score-Based Generative Models (SGMs) arises from the discrepancy between training inputs (ground truth samples) and inference inputs (predicted samples) across the sampling chain.
- Mechanism: During training, SGMs receive clean ground truth samples perturbed with noise as input, while during inference they receive predicted samples from previous steps. This mismatch accumulates through the sampling chain, causing the generated conformations to deviate from the true distribution.
- Core assumption: The discrepancy between ground truth and predicted samples creates a systematic bias that grows with each sampling step.
- Evidence anchors:
  - [abstract] "However, the discrepancy between training and inference rises a critical problem known as the exposure bias."
  - [section] "Indeed, during the training process of SGMs, the input Ct to the network can be regarded as a ground truth sample (Eq. 2), while during the inference, the input is the predicted sample ˆCt along the Markov chain."
  - [corpus] Weak evidence - no direct confirmation in related papers about exposure bias in SGMs specifically.
- Break condition: If the sampling chain length is very short or the model is highly robust to input variations, the accumulated bias may become negligible.

### Mechanism 2
- Claim: Input Perturbation (IP) mitigates exposure bias by making the model robust to input variations during training.
- Mechanism: IP adds additional Gaussian noise to the input samples during training, forcing the model to learn representations that are invariant to small input perturbations. This makes the model more robust when it encounters predicted samples during inference.
- Core assumption: The exposure bias follows a Gaussian-like distribution, allowing noise injection during training to effectively counteract it.
- Evidence anchors:
  - [abstract] "We design a new compensation algorithm Input Perturbation (IP), which is adapted from a method originally designed for DPMs only."
  - [section] "Therefore, to mitigate the inconsistency between training and generation phases, we perturb the input with a Gaussian noise in the training of the score function to enhance its robustness [15]."
  - [corpus] Moderate evidence - IP has been shown effective for DPMs but adaptation to SGMs is novel.
- Break condition: If the noise level is too high during training, the model may learn to ignore meaningful signal or become unstable.

### Mechanism 3
- Claim: The asymmetric training procedure (noisy inputs, clean generation) allows trajectories to stick closer to the ground truth despite potential biases.
- Mechanism: By training with perturbed inputs but generating with clean predictions, the model learns to correct for the bias that accumulates during inference, effectively learning a "correction factor" implicitly.
- Core assumption: The model can learn to compensate for the systematic bias introduced by predicted inputs during inference.
- Evidence anchors:
  - [section] "This asymmetric procedure thus allows the trajectories to stick closer to the ground truth despite potential biases during generation."
  - [abstract] "Experimental results show that by introducing IP, SGM-based molecular conformation models can significantly improve both the accuracy and diversity of the generated conformations."
  - [corpus] Weak evidence - no direct confirmation of this specific mechanism in related literature.
- Break condition: If the model architecture cannot effectively learn the correction, or if the bias is too large to compensate for, performance may not improve.

## Foundational Learning

- Concept: Diffusion probabilistic models and score-based generative models
  - Why needed here: The paper builds on understanding how these models work and where exposure bias emerges in their training-inference discrepancy.
  - Quick check question: What is the key difference between training and inference inputs in diffusion models?

- Concept: Molecular conformation representation and evaluation metrics
  - Why needed here: The paper focuses on generating 3D molecular structures, requiring knowledge of RMSD, COV, and MAT metrics for evaluation.
  - Quick check question: How does RMSD measure the quality of generated molecular conformations?

- Concept: Rotational and translational invariance in molecular structures
  - Why needed here: The paper discusses how IP preserves these invariances while mitigating bias.
  - Quick check question: Why is it important that the IP method preserves rotational and translational equivariance?

## Architecture Onboarding

- Component map: Score network (s_θ) -> Noise scheduler -> Input perturbation module -> Sampling module
- Critical path:
  1. Training phase: Generate noisy inputs with IP → Train score network
  2. Inference phase: Start from prior → Iteratively denoise using trained score network
- Design tradeoffs:
  - Noise level selection: Higher noise during training increases robustness but may slow convergence
  - Sampling steps: More steps improve quality but increase computation time
  - Perturbation weight (λ): Must balance bias reduction with maintaining useful signal
- Failure signatures:
  - Performance degradation if λ is too high (model ignores signal)
  - No improvement if λ is too low (bias not adequately addressed)
  - Training instability if noise schedule is poorly designed
- First 3 experiments:
  1. Implement IP on a simple SGM toy task to verify bias reduction
  2. Test IP on ConfGF with QM9 dataset to confirm accuracy improvements
  3. Apply IP to Torsional Diffusion and compare against state-of-the-art on GEOM-Drugs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the Input Perturbation method be further optimized to reduce the computational overhead while maintaining its effectiveness in mitigating exposure bias?
- Basis in paper: [inferred] The paper demonstrates the effectiveness of Input Perturbation in improving the accuracy and diversity of generated molecular conformations, but does not explore computational efficiency optimizations.
- Why unresolved: The paper focuses on the effectiveness of the method but does not address potential computational costs or optimization strategies.
- What evidence would resolve it: Comparative studies showing the computational overhead of Input Perturbation versus its benefits, and experiments with optimized versions of the method.

### Open Question 2
- Question: How does the exposure bias in SGMs for molecular conformation generation compare to other types of generative models, such as GANs or VAEs?
- Basis in paper: [explicit] The paper confirms the existence of exposure bias in SGMs and adapts a compensation method from DPMs, but does not compare it to other generative models.
- Why unresolved: The paper focuses on SGMs and does not explore the presence or magnitude of exposure bias in other generative model architectures.
- What evidence would resolve it: Experimental studies measuring exposure bias in GANs, VAEs, and other generative models for molecular conformation generation.

### Open Question 3
- Question: What is the long-term impact of using Input Perturbation on the stability and reliability of generated molecular conformations in real-world applications?
- Basis in paper: [inferred] The paper shows short-term improvements in accuracy and diversity but does not discuss long-term stability or reliability in practical applications.
- Why unresolved: The paper does not address the sustainability of improvements over multiple generations or in diverse molecular contexts.
- What evidence would resolve it: Longitudinal studies tracking the performance of Input Perturbation-enhanced models over extended periods and in various application scenarios.

## Limitations

- The paper lacks direct empirical validation of exposure bias magnitude before and after IP application
- Hyperparameter selection (particularly λ) was done empirically through grid search without detailed justification of the search space
- The asymmetric training procedure's effectiveness is theoretically plausible but not rigorously proven through ablation studies
- No comparison of exposure bias between different generative model architectures (GANs, VAEs, etc.)

## Confidence

**High Confidence Claims:**
- Exposure bias exists as a discrepancy between training and inference inputs in SGMs (supported by clear theoretical framework and measurement methodology)
- IP technique can be adapted from DPMs to SGMs (demonstrated through successful implementation and performance gains)

**Medium Confidence Claims:**
- IP effectively mitigates exposure bias and improves conformation generation (supported by quantitative results but lacks detailed ablation studies)
- Asymmetric training procedure helps trajectories stick closer to ground truth (theoretically sound but not empirically validated)

**Low Confidence Claims:**
- The specific mechanism by which IP compensates for bias follows a Gaussian-like distribution (assumed but not proven)
- The magnitude of exposure bias reduction directly correlates with performance improvements (inferred but not explicitly measured)

## Next Checks

1. **Quantify Exposure Bias Before/After IP**: Measure the exposure bias magnitude (|et|) on baseline and IP-enhanced models across multiple sampling steps to establish the direct relationship between bias reduction and performance improvement.

2. **Hyperparameter Sensitivity Analysis**: Conduct a comprehensive grid search over λ values with statistical significance testing to determine the optimal range and verify that improvements are not due to lucky initialization or dataset-specific effects.

3. **Ablation Study on Asymmetric Training**: Compare performance between standard IP (noisy training, clean inference), reversed IP (clean training, noisy inference), and full IP to isolate the contribution of the asymmetric procedure to overall performance gains.