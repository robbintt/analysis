---
ver: rpa2
title: Synthetic Programming Elicitation for Text-to-Code in Very Low-Resource Programming
  and Formal Languages
arxiv_id: '2406.03636'
source_url: https://arxiv.org/abs/2406.03636
tags:
- language
- self
- code
- programming
- uclid5
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces SPEAC, a method to enable LLMs to generate
  syntactically correct code in very low-resource programming languages (VLPLs). SPEAC
  works by designing an intermediate language that LLMs naturally generate, then automatically
  repairing and compiling it to the target VLPL.
---

# Synthetic Programming Elicitation for Text-to-Code in Very Low-Resource Programming and Formal Languages

## Quick Facts
- arXiv ID: 2406.03636
- Source URL: https://arxiv.org/abs/2406.03636
- Reference count: 40
- The paper introduces SPEAC, achieving 84.8% syntactically correct code generation for very low-resource programming languages compared to 9.1% with fine-tuning and 12.1% with in-context learning baselines.

## Executive Summary
The paper addresses the challenge of generating syntactically correct code for very low-resource programming languages (VLPLs) using large language models (LLMs). Traditional approaches like fine-tuning and in-context learning struggle with VLPLs due to limited training data. SPEAC (Synthetic Programming Elicitation for Automated Compilation) introduces a novel approach that first identifies an intermediate language that LLMs naturally generate, then uses automated repair and compilation to convert this output to the target VLPL. The method was evaluated on UCLID5, a formal verification language, achieving 84.8% syntactically correct code generation compared to 9.1% with fine-tuning and 12.1% with in-context learning baselines.

## Method Summary
SPEAC works by first conducting synthetic programming elicitation studies to identify a parent language (P, typically Python) and a child language (C, a subset of P) that LLMs naturally generate when prompted with natural language task descriptions. The method then uses automated repair techniques, specifically MAX-SMT solvers, to fix LLM-generated code in P to conform to C's syntax constraints. Finally, the repaired code in C is compiled to the target VLPL. The approach avoids the need for large amounts of VLPL training data by leveraging LLMs' strong performance on more common languages and systematically bridging the gap through automated repair and compilation.

## Key Results
- Achieved 84.8% syntactically correct code generation for UCLID5 compared to 9.1% with fine-tuning and 12.1% with in-context learning baselines
- Maintained high semantic correctness (84.6%) while dramatically improving syntactic correctness
- Demonstrated the effectiveness of synthetic programming elicitation in identifying suitable intermediate languages for VLPLs

## Why This Works (Mechanism)
SPEAC works by recognizing that LLMs are better at generating syntactically correct code in common languages (like Python) than in VLPLs. By identifying a child language C that LLMs naturally generate and is syntactically close to the target VLPL, the method reduces the distance between what LLMs can produce and what is required. The MAX-SMT-based automated repair then systematically fixes any deviations from C's syntax, while the compilation step handles the final transformation to the target VLPL. This approach leverages the strengths of LLMs while compensating for their weaknesses through formal methods.

## Foundational Learning

**Synthetic Programming Elicitation**: A method to identify which programming languages LLMs naturally generate code in when given natural language prompts. Needed to find an intermediate language that bridges the gap between natural language and the target VLPL. Quick check: Run the elicitation study with different prompts and measure language distribution of generated code.

**MAX-SMT (Maximum Satisfiability Modulo Theories)**: A formal method for finding optimal solutions that satisfy a set of constraints. Used to automatically repair code to conform to the child language syntax. Needed to systematically fix syntactic errors without requiring hand-crafted rules. Quick check: Verify that the solver finds minimal changes to repair code while maintaining functionality.

**Formal Compilation**: The process of translating code from one formal language to another while preserving semantics. Used to convert the child language to the target VLPL. Needed to ensure that repaired code maintains its intended meaning during translation. Quick check: Validate compilation correctness using formal verification techniques.

## Architecture Onboarding

**Component Map**: Natural Language Task Description -> LLM Generation (Parent Language P) -> MAX-SMT Repair (Child Language C) -> Compilation (Target VLPL) -> Syntactically Correct Code

**Critical Path**: The key sequence is: prompt generation → LLM code generation → automated repair via MAX-SMT → compilation to VLPL. Each stage must succeed for the final output to be syntactically correct.

**Design Tradeoffs**: The method trades computational overhead (MAX-SMT solving, compilation) for improved syntactic correctness without requiring large amounts of VLPL training data. This is beneficial when VLPL examples are scarce but introduces runtime costs during code generation.

**Failure Signatures**: 
- LLM generates code outside C's syntax → automated repair fails
- MAX-SMT solver cannot find feasible repairs → no syntactically correct output
- Compilation from C to VLPL fails → semantic errors introduced

**First Experiments**:
1. Run synthetic programming elicitation with different prompt templates to identify the most suitable child language C
2. Test MAX-SMT repair on simple code snippets to verify it can fix common syntactic errors
3. Validate compilation from C to VLPL on manually written correct code in C

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on finding a suitable intermediate language that LLMs naturally generate, which may not exist for all VLPLs
- Computational overhead from MAX-SMT repair may limit practical deployment for larger programs
- Evaluation was conducted on a single VLPL (UCLID5), limiting generalizability to other VLPLs

## Confidence

**High Confidence**: The synthetic programming elicitation methodology and its application to selecting intermediate languages

**Medium Confidence**: The automated repair mechanism using MAX-SMT solvers and its integration with LLMs

**Medium Confidence**: The overall effectiveness of SPEAC in improving syntactic correctness while maintaining semantic correctness

## Next Checks

1. **Cross-language validation**: Test SPEAC on additional VLPLs beyond UCLID5, particularly those with different syntax and semantics (e.g., domain-specific languages, hardware description languages) to evaluate generalizability.

2. **Scalability assessment**: Evaluate the performance and computational overhead of the MAX-SMT repair component on larger codebases (beyond the current scope) to understand practical deployment limitations.

3. **Alternative intermediate languages**: Experiment with different parent languages beyond Python (e.g., JavaScript, Rust) to determine if the choice of intermediate language significantly impacts the method's effectiveness across different VLPLs.