---
ver: rpa2
title: Lifelong Event Detection with Embedding Space Separation and Compaction
arxiv_id: '2404.02507'
source_url: https://arxiv.org/abs/2404.02507
tags:
- event
- esco
- memory
- learning
- different
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes ESCO, a novel method for lifelong event detection
  that addresses catastrophic forgetting by separating and compacting embedding spaces.
  The method uses a margin-based loss to separate new data from previously learned
  embedding spaces, a memory calibration mechanism to improve intra-class compactness,
  and forward knowledge transfer by initializing new task parameters with previous
  ones.
---

# Lifelong Event Detection with Embedding Space Separation and Compaction

## Quick Facts
- arXiv ID: 2404.02507
- Source URL: https://arxiv.org/abs/2404.02507
- Reference count: 26
- Key outcome: ESCO achieves up to 57.35 F1 score, outperforming state-of-the-art baselines by 2-3% on lifelong event detection tasks

## Executive Summary
This paper addresses catastrophic forgetting in lifelong event detection by proposing ESCO, a method that separates and compacts embedding spaces. The approach uses a margin-based loss to maintain distance between new and previously learned embedding spaces, a memory calibration mechanism to improve intra-class compactness, and forward knowledge transfer through parameter initialization. Experiments on ACE05 and MA VEN datasets show significant performance improvements over existing methods, with ablation studies confirming the contribution of each proposed component.

## Method Summary
ESCO is a lifelong learning method for event detection that prevents catastrophic forgetting through embedding space separation. It employs a margin-based loss to force new event types away from previously learned embedding spaces, uses memory calibration to improve intra-class compactness, and facilitates forward knowledge transfer by initializing new task parameters with previous ones. The method combines these components in a weighted loss function that balances learning new tasks while preserving old knowledge through memory replay and embedding separation.

## Key Results
- ESCO achieves up to 57.35 F1 score on combined test sets, outperforming previous best method (KCN) at 54.39 F1
- The method shows consistent improvements across both ACE05 and MA VEN datasets with different task orderings
- Ablation studies confirm that all three proposed components (separation, calibration, transfer) contribute to performance gains

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Embedding space separation prevents catastrophic forgetting by forcing new event types to maintain distance from previously learned embedding space.
- **Mechanism:** The margin-based loss (Lsim) penalizes similarity between new samples and prototypes of learned event types, ensuring the new feature distribution stays away from the learned embedding space.
- **Core assumption:** Feature distributions of new event types and previously learned types will overlap without explicit separation constraints, leading to catastrophic forgetting.
- **Evidence anchors:**
  - [abstract] "Our method alleviates forgetting of previously learned tasks by forcing the feature distribution of new data away from the previous embedding space."
  - [section] "To ensure that the new feature distribution is away from the learned embedding space, we design a margin-based loss, which decreases the similarity scores between new samples and prototypes of learned event types"
- **Break condition:** The mechanism fails when margin value is too small (insufficient separation) or too large (hindering learning of new tasks).

### Mechanism 2
- **Claim:** Memory calibration mechanism mitigates overfitting on few memory samples by improving intra-class compactness.
- **Mechanism:** The calibration loss (Lcal) encourages memory samples to cluster around their class prototypes, making the learned distribution more representative of the true data distribution rather than being distorted by the limited memory samples.
- **Core assumption:** Models will overfit on the few memory samples after frequent replays, making learned distributions distorted and less generalizable.
- **Evidence anchors:**
  - [abstract] "It also mitigates overfitting by a memory calibration mechanism that encourages memory data to be close to its prototype to enhance intra-class compactness."
  - [section] "As the size of memory M is typically small, the model is prone to overfit on the few memory samples after frequent replays, making learned distributions distorted."
- **Break condition:** The mechanism fails when memory size is too small relative to class diversity, or when prototypes are poorly estimated due to insufficient memory samples.

### Mechanism 3
- **Claim:** Forward knowledge transfer through parameter initialization improves learning efficiency for new tasks.
- **Mechanism:** Initializing new task parameters with learned parameters from previous tasks provides a better starting point than random initialization, allowing the model to leverage previously acquired knowledge patterns that may be transferable.
- **Core assumption:** There exists transferable knowledge between consecutive tasks that can be leveraged through parameter initialization.
- **Evidence anchors:**
  - [abstract] "the learnable parameters of the new task are initialized by drawing upon acquired knowledge from the previously learned task to facilitate forward knowledge transfer."
  - [section] "To facilitate forward knowledge transfer (Qin and Joty, 2022b), we initialize soft prompts P ð‘˜ of the new task using learned prompts P ð‘˜âˆ’1 of the previous task."
- **Break condition:** The mechanism fails when tasks are too dissimilar (little transferable knowledge) or when initialization from poor-performing previous tasks propagates suboptimal parameters.

## Foundational Learning

- **Concept:** Catastrophic forgetting in neural networks
  - Why needed here: The entire method addresses this fundamental problem in lifelong learning where models forget previously learned knowledge when learning new tasks
  - Quick check question: What happens to a neural network's performance on previous tasks when trained sequentially on new tasks without any regularization?

- **Concept:** Prototype-based representation learning
  - Why needed here: The method relies on calculating and using class prototypes to measure distances and calibrate memory samples
  - Quick check question: How are prototypes calculated in this method and what role do they play in both separation and calibration?

- **Concept:** Margin-based contrastive learning
  - Why needed here: The separation mechanism uses a margin-based loss rather than traditional contrastive pairs to push new samples away from old prototypes
  - Quick check question: How does the margin-based loss differ from standard contrastive loss in terms of positive and negative pairs?

## Architecture Onboarding

- **Component map:** Input encoder (BERT with accumulated soft prompts) -> Span representation (FFN on start/end tokens) -> Prompt entanglement (inner product with soft prompts) -> Event type prediction -> Multiple loss computation (Lnew, Lmem, Lsim, Lcal) -> Parameter update
- **Critical path:** Input â†’ BERT encoding â†’ Prompt accumulation â†’ Span representation â†’ Event type prediction â†’ Multiple loss computation â†’ Parameter update
- **Design tradeoffs:** Separation vs. overfitting (strong separation might hinder learning new tasks), memory size vs. calibration quality (larger memory improves calibration but increases computational cost), forward transfer vs. task specificity (aggressive initialization might bias new tasks)
- **Failure signatures:** Performance plateaus or degrades on previous tasks (insufficient separation), new tasks learn slowly (over-separation), calibration loss dominates (overfitting on memory), forward transfer provides no benefit (tasks are too dissimilar)
- **First 3 experiments:**
  1. Ablation study: Remove margin-based loss to confirm separation contribution (expect 1-2% performance drop)
  2. Memory size sweep: Test with 5, 10, 15, 20, 25 memory samples per class to find optimal balance
  3. Initialization comparison: Compare random initialization vs. parameter transfer for new tasks on a single task sequence

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does ESCO perform in few-shot learning scenarios compared to its performance with sufficient training data?
- **Basis in paper:** [inferred] The paper mentions that ESCO focuses on settings where each task has enough training data and suggests exploring few-shot learning as future work.
- **Why unresolved:** The paper does not provide experimental results or analysis on ESCO's performance in few-shot learning settings.
- **What evidence would resolve it:** Conducting experiments on few-shot learning tasks with varying numbers of training examples per class and comparing ESCO's performance to other few-shot learning methods would provide evidence.

### Open Question 2
- **Question:** How does the performance of ESCO scale with the size of the memory module? Is there an optimal memory size that balances performance and computational efficiency?
- **Basis in paper:** [inferred] The paper mentions that the memory size might influence the performance gain of ESCO and conducts experiments with different memory sizes on ACE05.
- **Why unresolved:** The paper does not provide a comprehensive analysis of how ESCO's performance scales with memory size across different datasets and tasks.
- **What evidence would resolve it:** Conducting experiments with varying memory sizes on multiple datasets and tasks, and analyzing the trade-off between performance and computational efficiency, would provide evidence.

### Open Question 3
- **Question:** How does ESCO perform when combined with large language models (LLMs) compared to traditional backbone models like BERT and RoBERTa?
- **Basis in paper:** [inferred] The paper mentions that LLMs have shown impressive performance on various tasks and suggests exploring lifelong event detection with LLMs as future work.
- **Why unresolved:** The paper does not provide any experimental results or analysis on combining ESCO with LLMs.
- **What evidence would resolve it:** Conducting experiments on lifelong event detection tasks using ESCO combined with different LLMs and comparing the results to those obtained with traditional backbone models would provide evidence.

## Limitations

- The margin-based separation mechanism's sensitivity to the margin hyperparameter is not thoroughly explored, and the optimal value may be dataset-dependent
- The herding algorithm for memory selection, while theoretically sound, may introduce bias if the initial sample selection is suboptimal
- The forward knowledge transfer through parameter initialization assumes task similarity that may not hold across all lifelong learning scenarios

## Confidence

- **High confidence:** The core architecture design and overall performance improvements over baselines are well-supported by the experimental results
- **Medium confidence:** The specific contribution of each component (separation, calibration, transfer) is demonstrated through ablation, but the magnitude of individual effects could vary with different datasets
- **Medium confidence:** The claim that ESCO significantly outperforms state-of-the-art methods is supported, but the 57.35 F1 score improvement should be interpreted relative to the specific baselines tested

## Next Checks

1. **Cross-dataset robustness test:** Evaluate ESCO on additional event detection datasets with different characteristics (e.g., different domains, event type distributions) to assess generalizability beyond ACE05 and MA VEN
2. **Memory size sensitivity analysis:** Conduct a systematic study varying memory size from 1 to 30 samples per class to identify the optimal trade-off between memory overhead and performance gains
3. **Task order sensitivity:** Test ESCO with multiple random task orderings on the same dataset to verify that performance gains are consistent regardless of the sequence in which event types are introduced