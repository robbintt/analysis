---
ver: rpa2
title: 'The Artificial Intelligence Ontology: LLM-assisted construction of AI concept
  hierarchies'
arxiv_id: '2404.03044'
source_url: https://arxiv.org/abs/2404.03044
tags:
- https
- github
- page
- ontology
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The Artificial Intelligence Ontology (AIO) is a comprehensive framework
  for AI concepts, methodologies, and ethical considerations. Developed with LLM assistance,
  AIO addresses the rapidly evolving AI landscape by providing standardized terminology
  and concepts.
---

# The Artificial Intelligence Ontology: LLM-assisted construction of AI concept hierarchies

## Quick Facts
- arXiv ID: 2404.03044
- Source URL: https://arxiv.org/abs/2404.03044
- Reference count: 1
- One-line primary result: AIO is a comprehensive ontology for AI concepts, methodologies, and ethical considerations developed with LLM assistance.

## Executive Summary
The Artificial Intelligence Ontology (AIO) provides a standardized framework for AI concepts, methodologies, and ethical considerations, addressing the rapidly evolving AI landscape. Developed through manual curation with LLM assistance using the Ontology Development Kit (ODK), AIO contains 417 classes organized into six top-level branches: Networks, Layers, Functions, LLMs, Preprocessing, and Bias. The ontology demonstrates practical utility through annotation of AI methods data in Papers with Code and integration into BioPortal. AIO's modular structure supports composability while addressing bias as a first-class concept, making it a valuable resource for the AI community.

## Method Summary
AIO was developed using the Ontology Development Kit (ODK) with LLM-assisted curation, where LLM-generated suggestions populated ROBOT templates to accelerate ontology construction. The development process combined manual curation with LLM assistance using Claude3 Sonnet and GPT-4, with example ontology data rows serving as input for extension. The ontology was validated using ELK reasoner and integrated with Papers with Code methods data through OAK (Ontology Access Kit) for coverage evaluation. The workflow included Docker-based builds, GitHub Actions for CI/CD, and BioPortal integration for distribution.

## Key Results
- AIO contains 417 classes, 360 synonyms, and 414 is_a relationships across six top-level branches
- The ontology covers 37 of 313 Papers with Code collections with 205 out of 417 AIO terms found in paper titles and method fields
- 6,484 AIO annotations were generated across the Papers with Code dataset, demonstrating practical utility
- Bias is represented as a top-level class encompassing computational, historical, human, institutional, societal, and systemic biases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-assisted curation accelerates ontology development and keeps AIO aligned with rapidly evolving AI concepts.
- Mechanism: The Ontology Development Kit (ODK) provides a reproducible framework using ROBOT templates that can be populated by LLM-generated suggestions, enabling fast iteration and integration of new AI/ML terms.
- Core assumption: LLM outputs are accurate enough to be used as starting points for ontology classes, synonyms, and relationships without requiring complete manual verification at each step.
- Evidence anchors:
  - [abstract] "Developed via manual curation, with the additional assistance of large language models (LLMs)"
  - [section] "We developed the LLM and Preprocessing branches of the ontology using Claude3 Sonnet and GPT-4 with designed prompts and inputting example ontology data rows from the AIO sheet and requesting extension of this data with additional LLM method terms."
  - [corpus] Weak evidence: no direct citations to LLM-assisted ontology building in neighboring papers; mostly mentions ontologies and AI without LLM integration details.
- Break condition: LLMs generate inaccurate or inconsistent terms that break the ontology's semantic coherence or violate OBO Foundry principles.

### Mechanism 2
- Claim: The modular branch structure (Networks, Layers, Functions, LLMs, Preprocessing, Bias) supports composability and facilitates understanding of deep learning architectures.
- Mechanism: By separating concepts into top-level branches with is_a relationships and allowing layer and function reuse across networks, AIO mirrors the modular design of modern deep learning frameworks like PyTorch and TensorFlow.
- Core assumption: The composability in AIO is sufficient to represent most AI/ML methods without requiring full parameterization of models.
- Evidence anchors:
  - [abstract] "The ontology is structured around six top-level branches: Networks, Layers, Functions, LLMs, Preprocessing, and Bias"
  - [section] "The Network, Layer, and Function branches are interlinked, with many Network classes having a representation based on a series of Layer terms"
  - [corpus] No direct evidence in corpus about composability benefits; mentions modularity implicitly in related works but not tested.
- Break condition: Complex nonlinear architectures (e.g., with loops or skip connections) cannot be accurately represented within the current list-based layer model.

### Mechanism 3
- Claim: Integrating AIO with Papers with Code provides a reproducible evaluation pipeline that validates ontology coverage and utility.
- Mechanism: OAK (Ontology Access Kit) is used to match AIO class labels and synonyms against Papers with Code method fields, producing coverage metrics and annotation statistics.
- Core assumption: Lexical matching of class labels and synonyms is sufficient to measure ontology coverage in a real-world dataset.
- Evidence anchors:
  - [abstract] "The ontology's utility is demonstrated through the annotation of AI methods data in a catalog of AI research publications"
  - [section] "We used the OAK annotate command to identify exact matches of AIO class names as well as their synonyms across the different field values available in the Papers with Code methods data."
  - [corpus] No direct evidence in corpus about Papers with Code annotation; neighboring papers mention ontology evaluation but not with this specific dataset.
- Break condition: Coverage metrics drop significantly when evaluated against a different or more diverse AI/ML dataset, revealing limited generalizability.

## Foundational Learning

- Concept: Ontology Development Kit (ODK) and ROBOT templates
  - Why needed here: ODK provides a reproducible, Docker-based workflow with validation and serialization tools essential for building and maintaining AIO.
  - Quick check question: What command would you run to build the ontology from a ROBOT template in ODK?
- Concept: Lexical matching and synonym expansion
  - Why needed here: Matching AIO terms to external datasets (e.g., Papers with Code) requires understanding of exact matching vs. synonym expansion for coverage assessment.
  - Quick check question: How does OAK differentiate between exact matches and synonym matches when annotating a dataset?
- Concept: OBO Foundry principles and semantic validation
  - Why needed here: AIO aligns with OBO standards for interoperability, even if not part of the Foundry, ensuring it can be integrated with other biomedical ontologies.
  - Quick check question: What is the EL profile and why does AIO avoid complex OWL-DL constructs outside it?

## Architecture Onboarding

- Component map:
  - ODK Docker container (build environment) -> ROBOT templates (data-driven ontology generation) -> AIO Google Sheets (source content for templates) -> OAK framework (annotation and evaluation) -> BioPortal (distribution and API access) -> GitHub Actions (CI/CD and validation)
- Critical path:
  1. Update AIO Google Sheets with new terms.
  2. Run ODK build to generate OWL/JSON/OBO artifacts.
  3. Validate with ELK reasoner and ODK checks.
  4. Push to GitHub and trigger BioPortal update.
  5. Run OAK annotation against Papers with Code dataset.
- Design tradeoffs:
  - Modularity vs. completeness: avoiding parameterization to keep AIO usable vs. losing detail for specific models.
  - Lexical matching vs. semantic matching: simpler but less accurate coverage vs. more complex but precise.
  - LLM assistance vs. manual curation: faster updates but potential quality risks.
- Failure signatures:
  - Build fails due to ROBOT template syntax errors.
  - BioPortal integration breaks after GitHub release due to missing artifact.
  - OAK annotation produces zero matches indicating vocabulary drift.
- First 3 experiments:
  1. Run `robot template` on a small test sheet to confirm template parsing works.
  2. Execute `odk build` in Docker to verify end-to-end build pipeline.
  3. Run `oak annotate` on a sample Papers with Code JSON to confirm lexical matching works.

## Open Questions the Paper Calls Out
None

## Limitations
- The LLM-assisted approach may introduce inaccuracies or inconsistencies that compromise semantic coherence, as there's limited validation of LLM-generated terms against OBO Foundry principles.
- Coverage evaluation relies solely on lexical matching against Papers with Code, which may overestimate true semantic alignment by capturing superficial term matches rather than deep conceptual relationships.
- The modular branch structure has not been validated for representing complex deep learning architectures with skip connections or loops, potentially limiting its applicability to advanced models.

## Confidence
- **High confidence**: The technical implementation using ODK, ROBOT templates, and BioPortal integration is well-documented and reproducible. The basic ontology structure with 417 classes and the demonstrated coverage of 37 Papers with Code collections are verifiable facts.
- **Medium confidence**: The LLM-assisted development methodology and its claimed benefits for rapid iteration are plausible but lack comparative validation against purely manual approaches. The composability benefits of the modular branch structure are theoretically sound but not empirically tested.
- **Low confidence**: The claimed comprehensiveness of the bias representation and the ontology's ability to handle complex deep learning architectures have not been rigorously evaluated. The generalizability of coverage metrics beyond Papers with Code remains unknown.

## Next Checks
1. **Cross-dataset evaluation**: Evaluate AIO coverage against a different AI/ML dataset (e.g., ArXiv abstracts or conference proceedings) to assess vocabulary generalizability beyond Papers with Code.

2. **Semantic validation test**: Implement a manual review of 50 randomly selected AIO terms to verify that LLM-generated synonyms and definitions maintain semantic coherence and OBO Foundry compliance.

3. **Complex architecture representation**: Test AIO's ability to represent architectures with skip connections (e.g., ResNet) and loops (e.g., RNNs) to identify limitations in the current list-based layer model.