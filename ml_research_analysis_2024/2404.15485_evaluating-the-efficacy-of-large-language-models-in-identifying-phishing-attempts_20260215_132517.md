---
ver: rpa2
title: Evaluating the Efficacy of Large Language Models in Identifying Phishing Attempts
arxiv_id: '2404.15485'
source_url: https://arxiv.org/abs/2404.15485
tags:
- phishing
- emails
- email
- language
- these
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper evaluates the effectiveness of 15 large language models
  in detecting phishing attempts using a dataset of 419 scam emails. It employs a
  structured evaluation prompt and numerical scoring to assess model performance,
  with a focus on identifying phishing emails based on sender authenticity, tone,
  requests for personal information, and other red flags.
---

# Evaluating the Efficacy of Large Language Models in Identifying Phishing Attempts

## Quick Facts
- arXiv ID: 2404.15485
- Source URL: https://arxiv.org/abs/2404.15485
- Authors: Het Patel; Umair Rehman; Farkhund Iqbal
- Reference count: 0
- The paper evaluates the effectiveness of 15 large language models in detecting phishing attempts using a dataset of 419 scam emails.

## Executive Summary
This study systematically evaluates 15 large language models (LLMs) on their ability to detect phishing attempts using a dataset of 419 scam emails. Through a structured evaluation prompt and numerical scoring system, the research compares transformer-based and BERT-based models, revealing that GPT-based architectures (ChatGPT 3.5, GPT-3.5-Turbo-Instruct, and ChatGPT) significantly outperform BERT models in phishing detection. The findings highlight the importance of predictive text generation capabilities and contextual understanding in identifying phishing threats, with GPT models achieving accuracy scores of 8-10 on a 1-10 scale.

## Method Summary
The study employs a dataset of 15 randomly selected phishing emails from Kaggle's fraudulent email corpus, which is then processed through 15 different AI models accessed via Poe.com. A structured evaluation prompt is developed to standardize the assessment across all models, asking them to analyze each email for phishing indicators such as sender authenticity, tone, and requests for personal information. Each model provides a numerical score from 1-10, which is then analyzed using histograms and correlation matrices to compare performance across different architectures and parameter sizes.

## Key Results
- GPT-based models (ChatGPT 3.5, GPT-3.5-Turbo-Instruct, and ChatGPT) achieved the highest accuracy scores (8-10 on a 1-10 scale)
- Transformer-based models outperformed BERT-based models in phishing detection
- Models with over 175 billion parameters (ChatGPT 3.5 and ChatGPT 3.5-Turbo-Instruct) showed superior performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-based architectures outperform BERT-based models in phishing detection due to their predictive text generation capabilities.
- Mechanism: Decoder-only GPT models generate text by predicting upcoming words, allowing them to identify inconsistencies in phishing emails through contextual understanding and language pattern recognition.
- Core assumption: The ability to generate and predict text sequences is more effective for phishing detection than bidirectional encoding alone.
- Evidence anchors:
  - [abstract]: "Results show that transformer-based models, specifically ChatGPT 3.5, GPT-3.5-Turbo-Instruct, and ChatGPT, are most effective, achieving high accuracy scores (8-10 on a 1-10 scale). The study highlights the superiority of GPT-based architectures over BERT-based models for phishing detection, emphasizing the importance of predictive capabilities and contextual understanding."
  - [section]: "The GPT architecture primarily focuses on generating text by predicting the upcoming words in a sequence given all the previous words. By emphasizing this prediction mechanism, models with the decoder-only architecture demonstrated a profound strength in understanding and generating language patterns during the study."
  - [corpus]: Weak evidence - no direct comparison between GPT and BERT architectures in the corpus papers.
- Break condition: If phishing emails become too complex for pattern-based detection, or if attackers use GPT models to generate highly realistic phishing content.

### Mechanism 2
- Claim: Larger parameter sizes in language models correlate with better phishing detection performance.
- Mechanism: More parameters enable the model to recognize complex patterns and dependencies in text, improving its ability to identify subtle phishing indicators.
- Core assumption: The number of parameters directly impacts the model's capacity to learn and apply nuanced language patterns.
- Evidence anchors:
  - [abstract]: "ChatGPT 3.5 and ChatGPT 3.5-Turbo-Instruct were equipped with over 175 billion parameters. At the same time, ChatGPT 4 significantly exceeded this, having more than 1.7 trillion parameters."
  - [section]: "The parameters in a language model are the foundational elements that enable it to recognize complex patterns and more extensive dependencies. In terms of the model and parameter size among the leading models, both ChatGPT 3.5 and ChatGPT 3.5-Turbo-Instruct were equipped with over 175 billion parameters."
  - [corpus]: No direct evidence in corpus papers regarding parameter sizes and their impact on phishing detection.
- Break condition: If smaller models with efficient architectures outperform larger models, or if parameter size becomes less relevant due to architectural improvements.

### Mechanism 3
- Claim: Zero-/few-shot learning capabilities of GPT models make them effective for phishing detection without extensive fine-tuning.
- Mechanism: GPT models can apply their generalized pre-trained knowledge directly to phishing detection tasks, recognizing phishing attempts based on learned language patterns and context.
- Core assumption: Pre-trained language models have sufficient knowledge to identify phishing attempts without task-specific training.
- Evidence anchors:
  - [abstract]: "Unlike the BERT models, which require fine-tuning for specific tasks, this feature allows the GPT models to execute tasks without explicit fine-tuning and little to no extensive task-specific training."
  - [section]: "This means that these GPT models can effectively analyze and assess the legitimacy of communications to identify any potential phishing threats based on their understanding of language patterns, context, and anomalies learned during the training phase."
  - [corpus]: No direct evidence in corpus papers regarding zero-/few-shot learning for phishing detection.
- Break condition: If phishing tactics evolve beyond the scope of pre-trained knowledge, or if task-specific fine-tuning becomes necessary for high accuracy.

## Foundational Learning

- Concept: Understanding the differences between GPT and BERT architectures
  - Why needed here: To comprehend why certain models perform better in phishing detection
  - Quick check question: What is the primary difference between decoder-only (GPT) and encoder-only (BERT) architectures?

- Concept: Parameter scaling and its impact on model performance
  - Why needed here: To understand how model size affects phishing detection capabilities
  - Quick check question: How does increasing the number of parameters in a language model typically affect its performance?

- Concept: Zero-/few-shot learning capabilities
  - Why needed here: To grasp why GPT models can perform phishing detection without extensive fine-tuning
  - Quick check question: What is the key advantage of zero-/few-shot learning compared to traditional fine-tuning approaches?

## Architecture Onboarding

- Component map:
  Data acquisition module -> Evaluation prompt generator -> Language model interface -> Scoring system -> Analysis dashboard

- Critical path:
  1. Acquire and preprocess dataset
  2. Develop evaluation prompt
  3. Select and configure language models
  4. Evaluate each model on the dataset
  5. Analyze and visualize results

- Design tradeoffs:
  - Model selection: Balancing between transformer-based and BERT-based architectures
  - Dataset size: Managing computational limitations while ensuring representative samples
  - Prompt complexity: Creating comprehensive prompts without overwhelming models
  - Evaluation criteria: Choosing relevant indicators for phishing detection

- Failure signatures:
  - Low confidence scores across all models: Indicates dataset issues or prompt problems
  - Inconsistent scoring patterns: Suggests model calibration needs or prompt ambiguity
  - High false positive/negative rates: Indicates need for additional evaluation criteria or model fine-tuning

- First 3 experiments:
  1. Compare GPT and BERT model performance on a small, diverse phishing dataset
  2. Test the impact of parameter size by evaluating models of different scales
  3. Assess the effectiveness of zero-/few-shot learning by comparing GPT models with and without task-specific fine-tuning

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the performance characteristics of GPT-based models compare to BERT-based models in phishing detection tasks across different types of phishing attacks (e.g., spear phishing vs. mass phishing)?
- Basis in paper: [explicit] The paper contrasts GPT-based models' superior performance with BERT-based models in detecting phishing emails, highlighting differences in architecture and task-specific fine-tuning requirements.
- Why unresolved: The study focuses on a specific subset of phishing emails (419 Scam) and does not explore performance variations across different phishing attack types or the impact of model fine-tuning on detection efficacy.
- What evidence would resolve it: Comparative studies evaluating GPT and BERT models across diverse phishing attack scenarios, with and without task-specific fine-tuning, would clarify the impact of model architecture and training on detection performance.

### Open Question 2
- Question: What are the long-term implications of using large language models for phishing detection in terms of model adaptability to evolving phishing techniques and the potential for adversarial attacks?
- Basis in paper: [inferred] The paper discusses the predictive capabilities of LLMs in identifying phishing attempts but does not address how these models adapt to new phishing strategies or vulnerabilities to adversarial manipulation.
- Why unresolved: The study does not explore the dynamic nature of phishing tactics or the resilience of LLMs against adversarial attacks designed to bypass detection systems.
- What evidence would resolve it: Longitudinal studies tracking LLM performance over time against evolving phishing techniques, along with adversarial testing to assess model robustness, would provide insights into the sustainability and security of LLM-based phishing detection.

### Open Question 3
- Question: How does the computational cost of deploying large language models for real-time phishing detection compare to traditional rule-based or machine learning approaches, and what are the trade-offs in terms of accuracy and resource efficiency?
- Basis in paper: [inferred] The paper highlights the superior performance of LLMs in phishing detection but does not discuss the computational resources required for their deployment or compare them to other detection methods.
- Why unresolved: The study focuses on model effectiveness without considering the practical aspects of implementation, such as computational cost, scalability, and resource allocation.
- What evidence would resolve it: Comparative analyses of the computational requirements and detection accuracy of LLMs versus traditional approaches in real-world deployment scenarios would clarify the trade-offs involved in choosing a phishing detection strategy.

## Limitations
- Small evaluation dataset (15 emails) may not capture full diversity of phishing tactics
- Single evaluation prompt and scoring system may not fully capture phishing detection nuances
- API-based model access may introduce additional variability in model behavior

## Confidence
- High confidence in comparative performance ranking of GPT vs BERT architectures
- Medium confidence in parameter-size correlation claims
- Low confidence in zero-shot learning advantages without direct comparative evidence

## Next Checks
1. Replicate the evaluation with a larger, more diverse dataset (minimum 100+ phishing emails) to validate the robustness of the performance differences across model architectures.

2. Conduct a controlled experiment comparing zero-shot GPT performance against GPT models with task-specific fine-tuning on the same phishing detection task to quantify the actual advantage of zero-shot capabilities.

3. Test the evaluation prompt and scoring system with human experts to establish ground truth accuracy rates and identify potential biases or limitations in the automated assessment methodology.