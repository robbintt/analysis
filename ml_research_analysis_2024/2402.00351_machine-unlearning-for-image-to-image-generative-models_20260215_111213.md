---
ver: rpa2
title: Machine Unlearning for Image-to-Image Generative Models
arxiv_id: '2402.00351'
source_url: https://arxiv.org/abs/2402.00351
tags:
- retain
- unlearning
- forget
- images
- truth
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes the first framework for machine unlearning
  on image-to-image generative models. The method formulates unlearning as minimizing
  KL divergence on retain set and maximizing it on forget set, while deriving a bounded
  optimization problem with theoretical guarantees.
---

# Machine Unlearning for Image-to-Image Generative Models

## Quick Facts
- **arXiv ID**: 2402.00351
- **Source URL**: https://arxiv.org/abs/2402.00351
- **Reference count**: 40
- **Key outcome**: First framework for machine unlearning on image-to-image generative models using L2 loss optimization

## Executive Summary
This paper introduces the first framework for machine unlearning on image-to-image generative models, addressing the critical need for data privacy compliance. The method formulates unlearning as minimizing KL divergence on retain set while maximizing it on forget set, using L2 loss in the encoder representation space to avoid intractable computations. The approach achieves near-identical performance on retain set while effectively removing information from forget set across three major generative model architectures (diffusion models, VQ-GAN, and MAE), and works without requiring access to real retain samples.

## Method Summary
The method formulates unlearning as an optimization problem that minimizes KL divergence on retain set DR and maximizes it on forget set DF. Instead of directly computing intractable KL divergence between high-dimensional image distributions, the approach minimizes L2 distance between encoder outputs of the original and target models on retain set, and between encoder outputs of forget samples and Gaussian noise on forget set. The encoder parameters θ are updated while the decoder ϕ remains fixed from the original model, providing computational efficiency. The optimization uses a weighted combination of retain set and forget set losses, with α controlling the trade-off between preservation and removal.

## Key Results
- Achieves near-identical performance on retain set (minimal FID, IS, CLIP degradation) while effectively removing information from forget set
- Works across three major I2I generative architectures: diffusion models, VQ-GAN, and MAE
- Demonstrates effectiveness without requiring access to real retain samples, showing practical utility
- Reduces computational complexity by updating only encoder parameters rather than full model manipulation

## Why This Works (Mechanism)

### Mechanism 1
The L2 loss in encoder representation space provides an efficient proxy for KL divergence minimization. By minimizing L2 distance between encoder outputs of original and target models on retain set, and between forget sample encodings and Gaussian noise on forget set, the method avoids direct KL divergence computation. This works because encoder outputs can be normalized to unit length, allowing KL divergence to be bounded by L2 distance.

### Mechanism 2
Replacing forget samples with Gaussian noise effectively removes information while preserving statistical patterns. By minimizing L2 distance between encoder outputs of forget samples and Gaussian noise n ~ N(0,Σ), the method drives generated images toward a Gaussian distribution that shares the same mean and covariance as the original forget set. This preserves training set statistical patterns while making it statistically challenging to identify forget samples.

### Mechanism 3
Updating only encoder parameters provides computational efficiency while maintaining generation quality. The method updates only the encoder parameters θ while keeping the decoder ϕ fixed from the original model, reducing computational complexity compared to full model manipulation. Using the same decoder as the original model allows effective unlearning while being more efficient than manipulating the entire model.

## Foundational Learning

- **KL divergence and its computational intractability for high-dimensional distributions**: The method needs to minimize KL divergence between distributions but cannot compute it directly for image data. Quick check: Why can't we directly compute KL divergence between two sets of high-dimensional images?

- **Mutual information maximization as a variational bound for KL divergence**: The method uses mutual information maximization (via InfoNCE) to establish the theoretical connection between L2 loss and KL divergence minimization. Quick check: How does maximizing mutual information between original and generated images relate to minimizing KL divergence?

- **Encoder-decoder architecture in I2I generative models**: The method relies on the encoder producing normalized representation vectors that can be compared via L2 distance. Quick check: Why is it important that the encoder outputs can be normalized to unit length for this method to work?

## Architecture Onboarding

- **Component map**: Original model (hθ0,ϕ0) with fixed decoder ϕ0 and learnable encoder θ → Target model (hθ,ϕ) with same decoder ϕ0 and updated encoder θ → Retain set DR and forget set DF → Gaussian noise n ~ N(0,Σ)
- **Critical path**: Sample from retain and forget sets → Compute L2 loss between encoder outputs → Update encoder parameters → Generate images and evaluate performance
- **Design tradeoffs**: Encoder-only updates provide computational efficiency but may limit unlearning effectiveness compared to full model updates; Gaussian noise replacement simplifies optimization but may not perfectly preserve all statistical patterns
- **Failure signatures**: Performance degradation on retain set indicates over-aggressive unlearning; failure to remove information from forget set indicates insufficient unlearning; high computational cost suggests inefficient implementation
- **First 3 experiments**: 1) Implement basic encoder update with L2 loss on a small VQ-GAN model with synthetic data to verify optimization works; 2) Test Gaussian noise replacement by comparing generated images when using real forget samples vs. Gaussian noise as inputs; 3) Evaluate the trade-off between retain set preservation and forget set removal by varying the α parameter on a validation dataset

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the choice of covariance matrix Σ in the unlearning algorithm affect the quality of generated images on both retain and forget sets? The paper discusses using the identity matrix as an approximation for Σ due to computational constraints but does not empirically compare performance using different approximations.

- **Open Question 2**: How robust is the unlearning algorithm to variations in the input cropping ratio and pattern? The paper shows ablation studies on varying input cropping ratios and patterns, demonstrating robustness to these variations, but does not explore the limits of this robustness.

- **Open Question 3**: How does the proposed unlearning algorithm compare to other unlearning methods specifically designed for generative models? The paper acknowledges the lack of previous unlearning methods for generative models and adapts existing methods from classification tasks, but does not provide a direct comparison to other generative model-specific unlearning methods.

## Limitations

- Theoretical guarantees rely on specific assumptions about encoder normalization and Gaussian approximations that may not hold across all I2I generative architectures
- Method's effectiveness with real-world unlearning scenarios (where forget samples may have complex characteristics) remains uncertain
- Computational efficiency gains compared to full model updates need more extensive benchmarking across different hardware configurations

## Confidence

- **High Confidence**: The L2 loss optimization approach is technically sound and the empirical results on standard benchmarks are reproducible
- **Medium Confidence**: The theoretical bounds and KL divergence approximations work well for the tested architectures but may not generalize universally
- **Low Confidence**: The effectiveness of Gaussian noise replacement for preserving statistical patterns while removing information needs more rigorous validation with diverse data distributions

## Next Checks

1. Test the method on additional I2I generative architectures (e.g., VAE, autoregressive models) to verify generalization beyond the three tested models
2. Evaluate performance when forget sets contain complex patterns or structured data that deviate from Gaussian assumptions
3. Benchmark computational efficiency against state-of-the-art full-model unlearning approaches using standardized hardware and timing metrics