---
ver: rpa2
title: 'SketchINR: A First Look into Sketches as Implicit Neural Representations'
arxiv_id: '2403.09344'
source_url: https://arxiv.org/abs/2403.09344
tags:
- sketch
- sketches
- vector
- sketchinr
- strokes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SketchINR presents a novel implicit neural representation for vector
  sketches, enabling compact high-fidelity encoding of sequential stroke data. The
  method compresses variable-length sketches into fixed-size latent vectors, implicitly
  encoding the underlying shape as a function of time and strokes.
---

# SketchINR: A First Look into Sketches as Implicit Neural Representations

## Quick Facts
- arXiv ID: 2403.09344
- Source URL: https://arxiv.org/abs/2403.09344
- Authors: Hmrishav Bandyopadhyay; Ayan Kumar Bhunia; Pinaki Nath Chowdhury; Aneeshan Sain; Tao Xiang; Timothy Hospedales; Yi-Zhe Song
- Reference count: 40
- Primary result: Achieves 60x and 10x data compression over raster and vector sketches while providing higher fidelity than learned vector sketch representations

## Executive Summary
SketchINR presents a novel implicit neural representation for vector sketches that encodes variable-length stroke sequences into fixed-size latent vectors. The method learns a continuous function that maps time and stroke indices to xy-coordinates, enabling parallel decoding that is ~100x faster than autoregressive methods. Despite its simplicity, SketchINR demonstrates significant advantages over existing representations, achieving substantial compression ratios while maintaining higher fidelity than other learned vector sketch representations like SketchRNN. The representation uniquely enables sketch abstraction by controlling stroke complexity during reconstruction, allowing human-like reproduction with varying stroke complexity.

## Method Summary
SketchINR learns an implicit function fθ(t, s) that maps continuous time and stroke indices to xy-coordinates for vector sketches. The method encodes entire sketches into fixed-size latent vectors and trains with a combination of MSE and visual loss using intensity maps. During inference, the learned function can parallelly predict coordinates for all time and stroke indices, enabling fast decoding. The representation supports varying stroke counts for abstraction and can be extended with an optional VAE encoder for generative modeling.

## Key Results
- Achieves 60x and 10x data compression over raster and vector sketches respectively
- Provides ~100x faster parallel decoding compared to autoregressive vector sketch generators
- Enables sketch abstraction by controlling stroke complexity during reconstruction
- Demonstrates superior fidelity compared to other learned vector sketch representations like SketchRNN

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SketchINR's implicit neural representation enables parallel decoding that is ~100x faster than autoregressive methods
- Mechanism: By learning a continuous function fθ(tj, sk) that maps time and stroke indices to xy-coordinates, SketchINR can sample all points simultaneously rather than sequentially generating them
- Core assumption: The learned implicit function accurately captures the underlying sketch structure without needing sequential dependencies
- Evidence anchors:
  - [abstract]: "SketchINR supports parallelisation that can decode/render ∼100× faster than other learned vector representations such as SketchRNN"
  - [section 3.1]: "SketchINR can parallelly predict the xy-coordinates for all time and strokes"
- Break condition: If the implicit function cannot accurately model complex temporal dependencies, parallel sampling may produce incoherent sketches

### Mechanism 2
- Claim: SketchINR achieves 60x and 10x data compression over raster and vector sketches respectively while maintaining higher fidelity
- Mechanism: The implicit representation encodes sketches as fixed-size latent vectors that implicitly capture the shape information, eliminating redundancy in raw vector representations
- Core assumption: The latent space can compress sketch information without significant loss of essential features
- Evidence anchors:
  - [abstract]: "Encoding an entire sketch dataset into a fixed size latent vector, SketchINR gives 60× and 10× data compression over raster and vector sketches"
  - [section 4.1]: "Compared to raster sketches (256 × 256), SketchINR provides 128× storage compression"
- Break condition: If the compression ratio becomes too extreme, reconstruction quality will degrade significantly

### Mechanism 3
- Claim: SketchINR uniquely enables sketch abstraction by controlling stroke complexity during reconstruction
- Mechanism: The implicit function allows sampling with arbitrary time and stroke indices, enabling reconstruction at different levels of abstraction
- Core assumption: The learned function can generalize across different levels of detail and stroke counts
- Evidence anchors:
  - [abstract]: "SketchINR, for the first time, emulates the human ability to reproduce a sketch with varying abstraction in terms of number and complexity of strokes"
  - [section 3.1]: "We model fθ on an additional variable in the form of strokestamps {sk}K k=1, representing the sketch as ˆp = {fθ(0, 0), . . . , fθ(tj, sk), . . . , fθ( J−1 J , K−1 K )}"
- Break condition: If the function cannot maintain coherence when reducing stroke count, the abstraction becomes meaningless

## Foundational Learning

- Concept: Implicit Neural Representations (INRs)
  - Why needed here: SketchINR builds on INRs to represent vector sketches as continuous functions rather than discrete point sequences
  - Quick check question: What distinguishes an implicit representation from explicit vector representations in terms of data structure?

- Concept: Continuous function approximation
  - Why needed here: The core of SketchINR is learning a function fθ(t, s) that maps continuous time and stroke indices to coordinates
  - Quick check question: How does learning a continuous function enable SketchINR to support variable stroke counts and abstraction levels?

- Concept: Loss function design for visual fidelity
  - Why needed here: SketchINR uses a combination of MSE and visual loss to ensure reconstructed sketches match the visual appearance of ground truth
  - Quick check question: Why does SketchINR use both MSE and visual loss rather than MSE alone for training?

## Architecture Onboarding

- Component map: Encoder (optional VAE) -> Decoder (MLP fθ) -> Latent space -> Sampling mechanism -> Reconstructed sketch

- Critical path:
  1. Encode sketch → latent vector (if using encoder)
  2. Decode latent → continuous function fθ
  3. Sample coordinates using fθ(t, s) for desired time and stroke indices
  4. Apply visual loss during training to ensure reconstruction quality

- Design tradeoffs:
  - Parallel vs sequential decoding: Parallel is much faster but requires more complex modeling
  - Fixed vs variable smoothing factor γ: Fixed is simpler but variable might converge faster
  - Global vs local time modeling: Global provides smoother results but local might capture finer details

- Failure signatures:
  - Jittery or discontinuous strokes indicate poor function approximation
  - Loss of fine details suggests insufficient model capacity or training
  - Inconsistent abstraction across different stroke counts indicates model instability

- First 3 experiments:
  1. Train SketchINR on Vector-MNIST with varying latent dimensions (64, 128, 256) and compare reconstruction quality vs storage size
  2. Implement and compare global vs local time modeling on a simple dataset to observe visual differences
  3. Test parallel vs sequential decoding speed on a small sketch dataset to verify the ~100x speedup claim

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the convergence speed of SketchINR be improved, particularly addressing the slow optimization due to pixel space optimization?
- Basis in paper: [explicit] The paper mentions that SketchINR suffers from slow convergence due to pixel space optimization and suggests that better engineering of the implicit function could improve this.
- Why unresolved: The paper acknowledges the issue but does not provide a concrete solution or detailed investigation into how to improve convergence speed.
- What evidence would resolve it: Empirical results showing improved convergence speed through techniques like advanced optimization algorithms, better implicit function architectures, or hybrid optimization strategies combining pixel and vector space losses.

### Open Question 2
- Question: Can SketchINR be extended to handle cross-category generalization, allowing it to encode sketches from categories not seen during training?
- Basis in paper: [explicit] The paper notes that SketchINR, like other implicit representations, suffers from poor cross-category generalization and suggests this as a limitation.
- Why unresolved: The paper does not explore methods to improve cross-category generalization, such as meta-learning approaches or more sophisticated latent space designs.
- What evidence would resolve it: Successful encoding and reconstruction of sketches from entirely new categories using a SketchINR model trained on a different set of categories, demonstrating robust cross-category performance.

### Open Question 3
- Question: How would varying the smoothing factor γ during training, rather than using a fixed value, impact the optimization and reconstruction quality of SketchINR?
- Basis in paper: [explicit] The paper mentions that varying γ with a scheduler could theoretically improve optimization but notes that initial experiments showed only minor improvements.
- Why unresolved: The paper does not provide a detailed analysis or comprehensive experiments on the effects of varying γ during training.
- What evidence would resolve it: A thorough experimental study comparing fixed vs. varying γ strategies, including quantitative metrics (e.g., reconstruction error, training time) and qualitative assessments of sketch quality.

## Limitations

- The ~100x speedup claim compared to autoregressive methods needs empirical validation across different hardware configurations and sketch complexities
- While SketchINR achieves impressive compression ratios, the paper doesn't provide a detailed ablation study on the trade-off between compression level and reconstruction quality
- The method's performance on extremely complex sketches (beyond FS-COCO) remains untested, potentially limiting real-world applicability

## Confidence

- **High confidence**: SketchINR's ability to achieve 10-60x compression ratios while maintaining reasonable reconstruction quality is well-supported by quantitative metrics
- **Medium confidence**: The claim about enabling sketch abstraction through stroke complexity control is demonstrated but lacks rigorous evaluation of how human-like the abstracted sketches truly are
- **Medium confidence**: The parallel decoding speedup is theoretically sound but requires independent benchmarking to verify the claimed magnitude

## Next Checks

1. **Independent Benchmarking**: Replicate the parallel vs sequential decoding speed comparison on multiple hardware setups (CPU, GPU) with varying sketch complexities to validate the ~100x speedup claim

2. **Compression-Quality Tradeoff Analysis**: Systematically vary the latent dimension size and measure the reconstruction quality degradation curve to identify optimal compression points for different use cases

3. **Extreme Complexity Testing**: Test SketchINR on professional-grade vector illustrations (e.g., SVGs from design repositories) with thousands of strokes to evaluate scalability limits and identify failure modes beyond the FS-COCO dataset