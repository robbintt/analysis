---
ver: rpa2
title: On The Potential of The Fractal Geometry and The CNNs Ability to Encode it
arxiv_id: '2401.04141'
source_url: https://arxiv.org/abs/2401.04141
tags: []
core_contribution: This paper investigates whether deep convolutional neural networks
  (CNNs) can encode fractal features, which are useful for classification tasks where
  object structure is crucial. The authors extract fractal dimensions at different
  granularity levels from images and conduct correlation analysis using Canonical
  Correlation Analysis (CCA) and Centered Kernel Alignment (CKA) to compare fractal
  features with deep network representations.
---

# On The Potential of The Fractal Geometry and the CNNs Ability to Encode it

## Quick Facts
- arXiv ID: 2401.04141
- Source URL: https://arxiv.org/abs/2401.04141
- Reference count: 40
- Primary result: Fractal-based models achieve competitive classification performance with up to 84% less training time

## Executive Summary
This paper investigates whether deep convolutional neural networks can encode fractal features, which capture structural information crucial for classification tasks. The authors extract fractal dimensions at multiple granularity levels from images and compare these features with deep network representations using Canonical Correlation Analysis (CCA) and Centered Kernel Alignment (CKA). Their findings reveal that deep networks do not encode fractal features across different layers and architectures. The study then demonstrates that a shallow neural network trained solely on fractal features achieves classification performance comparable to or better than deep networks on steel defect detection, with up to 47% accuracy improvement in some cases and up to 84% reduction in training time.

## Method Summary
The researchers extract fractal dimensions at various granularity levels from images using box-counting methods. They conduct correlation analysis between these fractal features and deep network representations across different layers using CCA and CKA. To validate their findings, they train a shallow neural network using only fractal features and compare its performance against deep CNN architectures on classification tasks, particularly steel defect detection. Human evaluation is also performed to assess the difficulty of images misclassified by different approaches.

## Key Results
- Deep convolutional neural networks fail to encode fractal features across different layers and architectures
- Fractal-based models achieve classification performance comparable to or better than deep networks on steel defect detection
- Shallow networks trained on fractal features require up to 84% less training time while achieving up to 47% accuracy improvement

## Why This Works (Mechanism)
The study demonstrates that fractal dimensions capture essential structural information about objects in images that is sufficient for classification tasks. When deep networks fail to encode these fractal features, they miss critical structural information that could improve classification performance. The fractal-based approach directly leverages this structural information, bypassing the need for deep feature extraction and enabling faster training while maintaining or improving accuracy.

## Foundational Learning
- **Fractal dimension calculation**: Understanding how to quantify complexity in images using box-counting methods - needed to extract meaningful structural features from images; quick check: verify dimension values change meaningfully across different image complexities
- **Canonical Correlation Analysis (CCA)**: Statistical method to measure relationships between two sets of variables - needed to quantify the relationship between fractal features and deep network representations; quick check: ensure canonical correlations decrease appropriately when comparing unrelated feature sets
- **Centered Kernel Alignment (CKA)**: Similarity metric for comparing neural network representations - needed to validate CCA findings with an independent method; quick check: confirm CKA values align with CCA results across layers

## Architecture Onboarding
**Component Map**: Image -> Fractal Dimension Extraction -> Shallow Neural Network -> Classification Output

**Critical Path**: The extraction of fractal dimensions at multiple granularity levels followed by training a shallow neural network on these features represents the core innovation. This path bypasses deep feature extraction while capturing essential structural information.

**Design Tradeoffs**: The approach trades the hierarchical feature learning capability of deep networks for direct structural encoding through fractal dimensions. This results in faster training but may miss other useful features that deep networks might capture through their hierarchical processing.

**Failure Signatures**: Poor performance when fractal dimensions fail to capture discriminative features, such as in texture-less images or when object boundaries are ambiguous. Also fails when classification depends heavily on color information or fine-grained details beyond structural patterns.

**First 3 Experiments**:
1. Compare fractal dimension extraction on synthetic fractals versus natural images to validate the method
2. Test shallow network performance with varying numbers of fractal dimension levels
3. Evaluate human perception of misclassified images across fractal-based and deep network approaches

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided content.

## Limitations
- Focus on fractal dimension features may overlook other fractal-related characteristics that deep networks could encode differently
- Correlation analysis using CCA and CKA may not capture all forms of information encoding in deep networks
- Results are limited to grayscale images from specific datasets, limiting generalizability to color images and other domains

## Confidence
- High confidence: Fractal dimensions alone can achieve competitive classification performance with significantly reduced training time
- Medium confidence: Deep networks fail to encode fractal features, given the specific analytical methods used
- Medium confidence: Human evaluation results showing fractal-based misclassifications are perceived as more difficult

## Next Checks
1. Test the fractal-based approach on color images and diverse datasets to assess generalizability
2. Investigate whether deep networks encode other fractal-related features beyond dimension calculations using alternative analysis methods
3. Conduct ablation studies to determine which fractal features contribute most to classification performance across different architectures