---
ver: rpa2
title: 'Large Language Models for Constructing and Optimizing Machine Learning Workflows:
  A Survey'
arxiv_id: '2411.10478'
source_url: https://arxiv.org/abs/2411.10478
tags:
- data
- llms
- arxiv
- learning
- workflows
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey comprehensively reviews the use of large language models
  (LLMs) in constructing and optimizing machine learning workflows. It identifies
  key applications across data preprocessing, feature engineering, model selection,
  hyperparameter optimization, and workflow evaluation.
---

# Large Language Models for Constructing and Optimizing Machine Learning Workflows: A Survey

## Quick Facts
- arXiv ID: 2411.10478
- Source URL: https://arxiv.org/abs/2411.10478
- Reference count: 32
- Primary result: Comprehensive survey of LLM applications in ML workflow construction and optimization across data preprocessing, feature engineering, model selection, hyperparameter optimization, and evaluation

## Executive Summary
This survey provides a systematic overview of how large language models are being applied to construct and optimize machine learning workflows. The authors identify key application areas including data preprocessing, feature engineering, model selection, hyperparameter optimization, and workflow evaluation. The survey highlights both the advantages of LLM-driven approaches such as automation, enhanced flexibility, and improved interpretability, as well as limitations including computational costs, potential biases, and hallucination risks. By categorizing existing methods and discussing open challenges, the survey serves as a roadmap for future research in integrating LLMs into automated machine learning pipelines.

## Method Summary
The survey follows a comprehensive literature review approach, systematically examining existing research on LLM applications in ML workflow construction and optimization. The authors categorize applications across different stages of the machine learning pipeline and analyze both advantages and limitations of current approaches. The methodology involves identifying key themes, synthesizing findings across multiple studies, and organizing the information into a structured framework that highlights current capabilities and future research directions.

## Key Results
- LLMs demonstrate significant potential in automating ML workflow construction across data preprocessing, feature engineering, model selection, and hyperparameter optimization
- Key advantages include enhanced automation, improved flexibility in workflow design, and better interpretability of ML pipelines
- Major limitations include computational costs, potential biases in LLM outputs, and the risk of hallucinations in generated workflows

## Why This Works (Mechanism)
The survey identifies that LLMs work effectively for ML workflow construction due to their ability to understand natural language descriptions of ML tasks, their capacity to generate structured code from textual prompts, and their knowledge of best practices across different ML domains. The mechanism relies on LLMs' ability to translate high-level requirements into executable ML workflows, leveraging their training on diverse code and documentation sources to provide contextually appropriate solutions.

## Foundational Learning

**ML Workflow Components**
- Why needed: Understanding the standard stages of ML pipelines (data preprocessing, feature engineering, model selection, hyperparameter tuning)
- Quick check: Verify familiarity with common ML libraries and their typical usage patterns

**LLM Capabilities**
- Why needed: Understanding what LLMs can and cannot do with code generation and natural language processing
- Quick check: Test basic code generation tasks to assess LLM proficiency

**Workflow Optimization Metrics**
- Why needed: Knowing how to evaluate ML workflow quality and efficiency
- Quick check: Review standard evaluation metrics for ML models and pipeline performance

## Architecture Onboarding

**Component Map**
Data input -> LLM processing -> Workflow generation -> Validation -> Optimization loop

**Critical Path**
LLM processing -> Workflow generation -> Validation (bottleneck due to quality assurance needs)

**Design Tradeoffs**
- Automation vs. control: Fully automated vs. human-in-the-loop approaches
- General vs. specialized: Broad capability LLMs vs. domain-specific models
- Speed vs. quality: Rapid generation vs. thorough validation and optimization

**Failure Signatures**
- Hallucinations in generated code that compiles but produces incorrect results
- Biases in workflow recommendations based on training data distribution
- Computational inefficiency in generated pipelines

**First Experiments**
1. Simple classification task with basic preprocessing
2. Multi-step regression workflow with feature engineering
3. Hyperparameter optimization comparison between LLM-generated and traditional methods

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- Rapidly evolving field may render some applications and limitations outdated quickly
- Potential publication bias may affect coverage of recent developments
- Relative importance of identified limitations may vary across different applications and contexts

## Confidence
**High Confidence**: General categorization of LLM applications across data preprocessing, feature engineering, model selection, and hyperparameter optimization is well-established and supported by multiple studies.

**Medium Confidence**: Assessment of advantages such as automation benefits and improved flexibility is based on reported outcomes, though these may vary significantly depending on specific implementations and use cases.

**Medium Confidence**: Identified limitations including computational costs and potential biases are well-documented in literature, but their relative importance may differ across applications and contexts.

## Next Checks
1. Conduct a systematic review of recent preprints and conference proceedings (last 6-12 months) to identify emerging LLM applications in ML workflow optimization not captured in this survey.

2. Perform empirical validation studies comparing LLM-driven workflow construction approaches against traditional AutoML methods across multiple datasets and problem domains to quantify claimed advantages and limitations.

3. Investigate reproducibility of LLM-based workflow optimization by implementing and testing multiple approaches from the survey on standardized benchmark datasets, documenting variations in performance and reliability.