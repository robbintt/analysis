---
ver: rpa2
title: 'Domain-specific ReAct for physics-integrated iterative modeling: A case study
  of LLM agents for gas path analysis of gas turbines'
arxiv_id: '2406.07572'
source_url: https://arxiv.org/abs/2406.07572
tags: []
core_contribution: This study evaluates the feasibility of applying large language
  models (LLMs) with callable tools in the domain of energy and power engineering,
  specifically for gas path analysis of gas turbines. The authors develop a dual-agent
  tool-calling process integrating expert knowledge, predefined tools, and LLM reasoning.
---

# Domain-specific ReAct for physics-integrated iterative modeling: A case study of LLM agents for gas path analysis of gas turbines
## Quick Facts
- arXiv ID: 2406.07572
- Source URL: https://arxiv.org/abs/2406.07572
- Reference count: 40
- Large language models with ~100B parameters show promise for specialized domain applications when combined with fine-tuning and advanced prompt design

## Executive Summary
This study evaluates the application of large language models (LLMs) with callable tools in the energy and power engineering domain, specifically for gas path analysis of gas turbines. The authors develop a dual-agent tool-calling process that integrates expert knowledge, predefined tools, and LLM reasoning capabilities. Through testing various LLMs including Llama3, Qwen1.5, and GPT models on single-component and multi-component problems, the research demonstrates that larger models like Llama3-70B show superior performance in handling complex engineering tasks, while smaller models struggle with tool usage and parameter extraction.

The study concludes that LLMs with nearly 100 billion parameters, combined with fine-tuning and advanced prompt design, show promise for professional applications in specialized domains. However, even advanced models face significant challenges with complex, multi-component problems. The research provides valuable insights into the current capabilities and limitations of LLM-based agents in engineering applications, suggesting that while promising, substantial work remains to achieve reliable performance in real-world industrial settings.

## Method Summary
The research employs a dual-agent framework where one agent focuses on tool selection and the other on data processing, creating a collaborative system for gas path analysis. The methodology integrates domain-specific knowledge bases, predefined computational tools, and LLM reasoning capabilities through a structured ReAct (Reasoning and Action) approach. The study tests multiple LLM architectures across various problem complexities, from simple single-component calculations to intricate multi-component scenarios, evaluating their ability to correctly identify, extract, and process relevant parameters while utilizing appropriate tools.

## Key Results
- Smaller models (7B parameters) consistently failed to correctly identify and extract required parameters from problem statements
- Llama3-70B demonstrated superior capability in handling complex multi-component problems compared to other tested models
- All models showed significant challenges with complex, multi-component problems, indicating limitations in current LLM reasoning for intricate engineering tasks

## Why This Works (Mechanism)
The mechanism leverages domain-specific knowledge integration with tool-calling capabilities to bridge the gap between general language understanding and specialized engineering reasoning. The dual-agent architecture allows for task specialization, where one agent focuses on selecting appropriate tools while another processes the data, creating a division of labor that mimics expert team collaboration. The physics-integrated iterative modeling approach enables the system to break down complex problems into manageable components while maintaining awareness of the overall system constraints and relationships.

## Foundational Learning
- Gas path analysis fundamentals: Understanding the thermodynamic principles and measurement techniques used in gas turbine performance monitoring is essential for developing accurate domain-specific models. Quick check: Verify that the LLM can correctly identify key parameters like pressure ratios, temperature changes, and efficiency metrics from problem statements.
- Tool-calling mechanics: The ability to select and invoke appropriate computational tools based on problem requirements is critical for practical implementation. Quick check: Test if the model can correctly match problem types to available tools with appropriate parameter sets.
- Parameter extraction techniques: Accurate identification and extraction of relevant numerical values and variables from natural language problem descriptions is fundamental to the approach. Quick check: Validate that the model can consistently extract all required parameters from varied problem formulations.

## Architecture Onboarding
Component map: Problem Statement -> Dual-Agent Parser -> Tool Selector -> Computation Engine -> Result Validator -> Final Answer
Critical path: The most time-consuming step is parameter extraction from natural language descriptions, which becomes increasingly complex with multi-component problems and varied terminology.
Design tradeoffs: The study balances model size (computational cost) against performance, showing that while larger models perform better, the improvement diminishes beyond certain thresholds. The dual-agent approach adds complexity but enables better task specialization.
Failure signatures: Common failure modes include incorrect parameter identification, tool selection errors, and breakdown of reasoning chains in multi-component problems. These typically manifest as cascading errors where early mistakes propagate through subsequent calculations.
3 first experiments:
1. Test single-component problem solving with progressively larger models to establish baseline performance
2. Evaluate parameter extraction accuracy across different problem formulations and terminology variations
3. Assess tool selection accuracy by providing problems with clear tool requirements and varying complexity

## Open Questions the Paper Calls Out
None

## Limitations
- The experimental scope is restricted to gas turbine domain applications, potentially limiting generalizability to other engineering fields
- Evaluation focuses primarily on qualitative assessment rather than quantitative validation against ground truth data from actual gas turbine operations
- Testing is limited to a specific set of LLMs and tools without exploring alternative architectures or more extensive fine-tuning approaches

## Confidence
- Single-component problem solving: High confidence, as results consistently show smaller models struggle while larger models perform adequately
- Multi-component problem handling: Medium confidence, as even advanced models showed significant challenges with complex tasks
- Tool-calling effectiveness: Medium confidence, with clear evidence of improvement with model size but limited exploration of prompt engineering alternatives
- Domain-specific applicability: Medium confidence, based on the specific case study of gas path analysis without broader domain validation

## Next Checks
1. Conduct quantitative validation by comparing LLM-generated gas path analysis results against actual operational data from gas turbine systems
2. Test the proposed dual-agent framework with additional engineering domains beyond gas turbines to assess generalizability
3. Perform ablation studies comparing different prompt engineering techniques and tool integration strategies to isolate their impact on model performance