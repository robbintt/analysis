---
ver: rpa2
title: Role Prompting Guided Domain Adaptation with General Capability Preserve for
  Large Language Models
arxiv_id: '2403.02756'
source_url: https://arxiv.org/abs/2403.02756
tags: []
core_contribution: This paper proposes REGA (Role Prompting Guided Multi-Domain Adaptation),
  a strategy to adapt LLMs to multiple domains while preserving general capabilities.
  The core idea is to use self-distillation to generate general-domain exemplars,
  assign role prompts to minimize inter-domain confusion, and integrate domain-specific
  data under a central prompt to transfer domain knowledge.
---

# Role Prompting Guided Domain Adaptation with General Capability Preserve for Large Language Models

## Quick Facts
- arXiv ID: 2403.02756
- Source URL: https://arxiv.org/abs/2403.02756
- Reference count: 8
- Key outcome: REGA improves domain-specific performance while maintaining general capabilities in multi-domain LLM adaptation

## Executive Summary
This paper addresses the challenge of adapting large language models to multiple domains while preserving general capabilities. The authors propose REGA (Role Prompting Guided Multi-Domain Adaptation), which uses self-distillation to generate general-domain exemplars, assigns role prompts to minimize inter-domain confusion, and integrates domain-specific data under a central prompt to transfer domain knowledge. The method demonstrates improved domain-specific performance over standard fine-tuning while maintaining higher general performance, effectively addressing catastrophic forgetting and inter-domain confusion. Experiments show consistent gains across different model sizes and languages.

## Method Summary
REGA introduces a three-phase approach to multi-domain adaptation. First, self-distillation generates general-domain exemplars by prompting the model to produce outputs that represent its pre-trained knowledge. Second, role prompts are assigned to each domain to create distinct task contexts and minimize confusion between domains. Third, domain-specific data is integrated under a central prompt structure that allows the model to learn domain knowledge while maintaining a connection to general capabilities. This approach contrasts with standard fine-tuning by explicitly preserving a general capability anchor and using role-based separation to prevent catastrophic forgetting across domains.

## Key Results
- REGA outperforms standard fine-tuning on domain-specific tasks while maintaining higher general performance
- The method effectively addresses catastrophic forgetting, with only 0.4-1.3 point drops in general capability
- Consistent performance improvements observed across different model sizes and multiple languages
- Role prompting successfully minimizes inter-domain confusion compared to unified fine-tuning approaches

## Why This Works (Mechanism)
REGA works by creating a dual-representation system where the model maintains both domain-specific knowledge and general capabilities simultaneously. The self-distillation process generates exemplars that serve as anchors to the model's original knowledge, preventing complete overwriting during domain adaptation. Role prompts create distinct task contexts that the model can switch between, similar to how humans adopt different communication styles for different domains. The prompt-based integration architecture allows for knowledge transfer while maintaining clear boundaries between domains, preventing the catastrophic forgetting that typically occurs when fine-tuning on multiple domains sequentially.

## Foundational Learning
- **Catastrophic forgetting**: When models overwrite previous knowledge during new training, losing general capabilities - needed because standard fine-tuning degrades performance on non-domain tasks
- **Self-distillation**: Using the model itself to generate training exemplars that represent its current knowledge state - needed to create general-domain anchors without external data
- **Role prompting**: Assigning distinct prompt templates to different domains to create task context separation - needed to minimize confusion between domains during inference
- **Prompt-based learning**: Using soft prompts or template structures to guide model behavior without changing parameters - needed for flexible domain switching
- **Continual learning**: Training models on sequential tasks while maintaining performance on previous tasks - needed as the underlying challenge REGA addresses
- **Domain adaptation**: Adapting models to perform well on specific domains or tasks - needed as the primary objective

## Architecture Onboarding
Component map: General exemplars (self-distilled) -> Role prompts (domain-specific) -> Central prompt template -> Domain data integration -> Fine-tuning

Critical path: Self-distillation generation → Role prompt assignment → Prompt template construction → Domain-specific fine-tuning → Evaluation

Design tradeoffs: 
- Memory efficiency vs. performance: Using prompts instead of full parameter adaptation saves memory but may limit expressivity
- Task separation vs. knowledge transfer: Role prompts prevent confusion but may limit beneficial knowledge sharing
- Exemplar quality vs. computation: Self-distillation quality affects general capability preservation but requires additional inference steps

Failure signatures:
- General capability degradation indicates insufficient exemplar quality or over-aggressive fine-tuning
- Domain confusion suggests inadequate role prompt differentiation
- Performance plateaus may indicate prompt template limitations or insufficient domain data

First experiments:
1. Ablation study removing self-distillation to measure its contribution to general capability preservation
2. Cross-domain generalization test using a domain never seen during training
3. Scalability test comparing REGA performance across 7B, 13B, and 30B model sizes

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Limited testing to only 3 domains, which may not represent the complexity of real-world multi-domain scenarios
- Modest general capability drops (0.4-1.3 points) suggest potential room for improvement in preservation mechanisms
- Self-distillation effectiveness depends on exemplar quality, which wasn't thoroughly validated
- Role prompt strategy lacks ablation studies to confirm necessity versus simpler approaches

## Confidence
- Catastrophic forgetting prevention: Medium confidence (limited domain count, modest performance drops)
- Self-distillation mechanism: Medium confidence (effectiveness depends on exemplar quality)
- Role prompt contribution: Medium confidence (lacks ablation validation)
- Cross-model generalization: Medium confidence (tested across sizes but limited architecture diversity)
- Cross-language generalization: Medium confidence (tested but limited language family diversity)

## Next Checks
1. Conduct ablation studies to isolate the contribution of each component (self-distillation, role prompting, prompt-based integration)
2. Test REGA on a broader range of domains including more challenging domain shifts and diverse task types
3. Evaluate scalability and effectiveness on significantly larger model sizes (70B+ parameters) and more diverse language families beyond current scope