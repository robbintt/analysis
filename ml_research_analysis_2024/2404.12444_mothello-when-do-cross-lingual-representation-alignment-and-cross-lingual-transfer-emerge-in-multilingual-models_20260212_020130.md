---
ver: rpa2
title: 'mOthello: When Do Cross-Lingual Representation Alignment and Cross-Lingual
  Transfer Emerge in Multilingual Models?'
arxiv_id: '2404.12444'
source_url: https://arxiv.org/abs/2404.12444
tags:
- cross-lingual
- language
- alignment
- languages
- multilingual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates when cross-lingual representation alignment
  and transfer emerge in multilingual models using a synthetic Othello-based task.
  It finds that naive multilingual pretraining fails to align representations across
  all languages, while anchor tokens improve alignment but not transfer.
---

# mOthello: When Do Cross-Lingual Representation Alignment and Cross-Lingual Transfer Emerge in Multilingual Models?

## Quick Facts
- arXiv ID: 2404.12444
- Source URL: https://arxiv.org/abs/2404.12444
- Authors: Tianze Hua; Tian Yun; Ellie Pavlick
- Reference count: 10
- Primary result: Unified output space in multilingual pretraining induces both cross-lingual representation alignment and transfer

## Executive Summary
This paper investigates the emergence of cross-lingual representation alignment and transfer in multilingual models using a synthetic Othello-based task (mOthello). Through controlled experiments with different training approaches—naive multilingual pretraining, anchor tokens, and unified output space—the authors demonstrate that while anchor tokens can improve alignment, only the unified output space approach enables both representation alignment and cross-lingual transfer. The findings challenge common assumptions about the relationship between alignment and transfer, suggesting that the task objective (unified output space) is crucial for inducing language-neutral representations that facilitate transfer across languages.

## Method Summary
The authors created mOthello, a synthetic multilingual task based on the board game Othello, where different "languages" map game moves to unique tokens. They trained 8-layer GPT2-style transformer models using three approaches: naive multilingual pretraining, anchor tokens (shared tokens across languages), and unified output space (predicting in a shared token space). Cross-lingual alignment was measured using probes that reconstructed board states from representations in one language using a probe trained on another. Cross-lingual transfer was evaluated by pretraining on one language and finetuning on another.

## Key Results
- Naive multilingual pretraining fails to align representations across languages (>30% alignment probe accuracy)
- Anchor tokens improve cross-lingual alignment but do not enable cross-lingual transfer
- Unified output space approach achieves high cross-lingual alignment (>90% probe accuracy) and enables transfer performance across structurally different language pairs
- The unified output space method is more effective than traditional language-specific training objectives for enabling cross-lingual transfer

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-lingual representation alignment does not automatically emerge under naive multilingual pretraining.
- Mechanism: When models are trained on multiple languages without explicit alignment signals, the hidden representations across languages remain structurally separate, forming clusters of aligned languages rather than a fully shared space.
- Core assumption: The model's learning dynamics do not inherently induce alignment across languages unless given explicit cross-lingual cues.
- Evidence anchors:
  - [abstract] "models trained with naive multilingual pretraining fail to learn a language-neutral representation across all input languages"
  - [section] "we observe that for mOthelloGPTs trained on each of the three pairs of languages, there is a lack of strong alignment in the representations across the languages"
  - [corpus] Weak evidence: corpus does not directly confirm alignment failure, but related work on multilingual models suggests alignment is non-trivial.
- Break condition: If explicit alignment mechanisms (e.g., anchor tokens, unified output space) are introduced, the model will begin to align representations.

### Mechanism 2
- Claim: Anchor tokens facilitate cross-lingual representation alignment but do not guarantee cross-lingual transfer.
- Mechanism: Shared lexical items (anchor tokens) provide explicit alignment signals during training, encouraging the model to align representations for tokens that overlap across languages.
- Core assumption: Alignment at the token level translates to alignment at the representation level, but this does not necessarily enable transfer across tasks or languages.
- Evidence anchors:
  - [abstract] "the introduction of 'anchor tokens' (i.e., lexical items that are identical across languages) helps cross-lingual representation alignment"
  - [section] "as the number of shared anchor tokens across two languages increases, the alignment of representations increases"
  - [corpus] Related work shows anchor tokens improve alignment in multilingual models, but cross-lingual transfer remains task-dependent.
- Break condition: If anchor tokens are removed or replaced with non-shared tokens, alignment will degrade.

### Mechanism 3
- Claim: A unified output space during multilingual pretraining induces both representation alignment and cross-lingual transfer.
- Mechanism: Training the model to predict tokens in a shared output space forces it to learn language-neutral representations, enabling both alignment and transfer across languages.
- Core assumption: The model's task objective (predicting in a unified space) is sufficient to align representations and enable transfer, regardless of the underlying language structures.
- Evidence anchors:
  - [abstract] "multilingual pretraining with unified output space – that both induces the learning of language-neutral representation and facilitates cross-lingual transfer"
  - [section] "pretraining with unified output space brings mOthelloGPTs not only cross-lingual alignment, but also cross-lingual transfer ability"
  - [corpus] Weak evidence: corpus does not directly address unified output space, but similar ideas appear in intermediate-task training literature.
- Break condition: If the output space is split back into language-specific spaces, alignment and transfer will degrade.

## Foundational Learning

- Concept: Language-neutral representations
  - Why needed here: The study investigates whether models can learn shared representations across languages, which is central to cross-lingual transfer.
  - Quick check question: Can a model trained on multiple languages without explicit alignment signals still produce aligned representations?

- Concept: Cross-lingual transfer
  - Why needed here: The ultimate goal is to determine if aligned representations are sufficient for cross-lingual transfer, which is a key property of multilingual models.
  - Quick check question: Does a model finetuned on one language perform well on another language if its representations are aligned?

- Concept: Anchor tokens
  - Why needed here: Anchor tokens are introduced as a mechanism to test whether explicit alignment signals can improve representation alignment.
  - Quick check question: How do shared tokens across languages affect the alignment of representations in a multilingual model?

## Architecture Onboarding

- Component map: GPT2-style transformer (8 layers, 8 heads, 512 dim) -> Othello game sequences -> Next move prediction
- Critical path: Model consumes sequences in different languages -> Predicts next move -> Alignment probe measures cross-lingual alignment
- Design tradeoffs: Anchor tokens improve alignment but not transfer; unified output space induces both but may require more complex training dynamics
- Failure signatures: Low alignment probe accuracy indicates failed representation alignment; high alignment but poor transfer indicates aligned representations don't enable transfer
- First 3 experiments:
  1. Train a model with naive multilingual pretraining and measure cross-lingual alignment probe accuracy
  2. Introduce anchor tokens and measure both alignment and transfer performance
  3. Train a model with a unified output space and measure both alignment and transfer performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the findings from mOthello translate to real-world multilingual language models, given the significant differences in vocabulary size and model architecture?
- Basis in paper: [explicit] The paper acknowledges that mOthello uses a simplified synthetic task with a small token space (less than 180 tokens per language) compared to real-world languages, and that their experiments focus on decoder-only transformers while many state-of-the-art multilingual models use encoder-decoder or encoder-only architectures.
- Why unresolved: The paper explicitly states these limitations and notes that these factors should be considered when interpreting the applicability of their findings to broader linguistic contexts.
- What evidence would resolve it: Conducting similar experiments with larger vocabularies and different model architectures (encoder-decoder, encoder-only) on synthetic tasks that better approximate real-world languages would help determine the generalizability of these findings.

### Open Question 2
- Question: What is the mechanism by which anchor tokens facilitate cross-lingual representation alignment, and why doesn't this alignment lead to cross-lingual transfer?
- Basis in paper: [explicit] The paper shows that anchor tokens help align representations across languages but observes that this alignment alone is not sufficient for cross-lingual transfer, creating a surprising contradiction to common hypotheses.
- Why unresolved: While the paper demonstrates the empirical relationship between anchor tokens and alignment, and between alignment and transfer, it doesn't explain the underlying mechanisms or why alignment doesn't automatically enable transfer.
- What evidence would resolve it: Analyzing the learned representations to identify specific patterns or properties that distinguish aligned-but-non-transferring representations from aligned-and-transferring ones would help explain this phenomenon.

### Open Question 3
- Question: How can the unified output space approach be effectively implemented for natural languages, given the challenge of identifying language-neutral next tokens in real linguistic contexts?
- Basis in paper: [explicit] The paper acknowledges that while it's simple to identify a next token in the unified output space for mOthello, it's considerably more challenging to identify a language-neutral next token for each language-specific context in natural languages.
- Why unresolved: The paper proposes this approach as promising but notes it's difficult to implement for natural languages without providing concrete solutions for how to overcome this challenge.
- What evidence would resolve it: Developing and testing specific methods for creating language-neutral representations or output spaces for natural language tasks (such as machine translation or cross-lingual retrieval) would demonstrate whether and how this approach can be practically applied.

## Limitations
- Synthetic task dependency: Findings may not fully capture complexities of real-world multilingual modeling scenarios
- Corpus evidence strength: Several key claims rely on indirect evidence from related work rather than direct experimental validation
- Generalization across architectures: Findings may not generalize to other transformer architectures or larger models with different scaling properties

## Confidence

**High Confidence**: Experimental design is well-structured with clear ablation studies and controlled variables. Findings that unified output space induces both alignment and transfer are supported by direct experimental evidence.

**Medium Confidence**: Mechanism by which anchor tokens facilitate alignment but not transfer is plausible but requires additional validation. Experimental evidence shows correlation but could benefit from more extensive ablation studies.

**Low Confidence**: Claims about failure of naive multilingual pretraining to induce alignment rely heavily on synthetic task setup and may not fully translate to real-world multilingual pretraining scenarios.

## Next Checks
1. Replicate unified output space findings on a real multilingual task (e.g., multilingual machine translation) to verify mechanism holds beyond synthetic Othello domain
2. Test whether unified output space approach maintains effectiveness when scaling to larger transformer architectures (12+ layers, 16+ attention heads)
3. Conduct systematic ablation studies on anchor token distribution, frequency, and semantic content to determine minimum conditions required for alignment benefits