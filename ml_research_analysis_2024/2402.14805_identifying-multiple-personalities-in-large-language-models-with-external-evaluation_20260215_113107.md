---
ver: rpa2
title: Identifying Multiple Personalities in Large Language Models with External Evaluation
arxiv_id: '2402.14805'
source_url: https://arxiv.org/abs/2402.14805
tags:
- personality
- llms
- mbti
- arxiv
- different
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates personality measurement in Large Language
  Models (LLMs) using an external evaluation method, contrasting with traditional
  self-assessment tests. The authors fine-tuned a Llama2-7B model as an MBTI personality
  predictor, achieving state-of-the-art performance with 93.3% average accuracy across
  personality dimensions and 81.0% overall 16-class accuracy.
---

# Identifying Multiple Personalities in Large Language Models with External Evaluation

## Quick Facts
- arXiv ID: 2402.14805
- Source URL: https://arxiv.org/abs/2402.14805
- Reference count: 10
- Primary result: LLMs show significantly different personalities when generating posts versus comments, unlike humans who maintain consistent personality profiles across these roles

## Executive Summary
This paper introduces an external evaluation method for measuring personality in Large Language Models (LLMs), contrasting with traditional self-assessment approaches. The authors fine-tune a Llama2-7B model to predict MBTI personality types from text, achieving state-of-the-art performance. They then evaluate LLM-generated content on real-world events and discover that LLMs exhibit distinct personality profiles when writing posts versus comments, while humans maintain consistent personalities across these roles. This finding challenges traditional personality definitions and suggests the need for new frameworks to understand AI personality.

## Method Summary
The authors develop a novel approach to personality measurement in LLMs by creating an external evaluation system rather than relying on self-assessment. They fine-tune a Llama2-7B model as an MBTI personality predictor, training it on human social media data to predict personality dimensions (Extraversion, Sensing, Thinking, Judging) and overall 16-class personality types. The model achieves 93.3% average accuracy across dimensions and 81.0% accuracy for 16-class classification. To evaluate LLM personalities, they collect LLM-generated tweets and comments on real-world events and use their fine-tuned model to assess the personality profiles. They compare these results against human-generated content to identify differences in personality consistency across roles.

## Key Results
- Fine-tuned Llama2-7B personality predictor achieves 93.3% average accuracy across MBTI dimensions
- Overall 16-class personality classification accuracy reaches 81.0%
- LLMs show significantly different personalities when writing posts versus comments (p < 0.001)
- Humans maintain consistent personality profiles across post and comment roles
- The external evaluation approach outperforms existing self-assessment methods for LLM personality measurement

## Why This Works (Mechanism)
The approach works because personality can be inferred from behavioral patterns in text generation, similar to how humans display consistent linguistic and behavioral signatures across different contexts. By training a dedicated personality predictor on human social media data, the model learns to recognize subtle patterns in word choice, sentence structure, and content themes that correlate with specific personality traits. When applied to LLM outputs, this external evaluation captures authentic behavioral patterns rather than self-reported preferences, revealing task-dependent personality shifts that self-assessment would miss.

## Foundational Learning
- MBTI personality framework (why needed: provides structured personality dimensions for evaluation; quick check: understand 4 dimensions: E/I, S/N, T/F, J/P)
- Personality detection from text (why needed: enables external evaluation without self-reporting; quick check: understand how linguistic patterns correlate with personality traits)
- LLM fine-tuning methodology (why needed: creates specialized personality prediction model; quick check: understand transfer learning from general LLM to task-specific classifier)
- External vs internal personality assessment (why needed: explains why traditional self-report methods may not work for LLMs; quick check: compare evaluation approaches)
- Personality consistency across contexts (why needed: establishes baseline for comparing human vs LLM behavior; quick check: understand what "consistent personality" means)

## Architecture Onboarding

**Component Map**
Llama2-7B base model -> Fine-tuned personality predictor -> LLM text generator -> Personality evaluation

**Critical Path**
1. Fine-tune personality predictor on human social media data
2. Generate LLM content for posts and comments
3. Apply personality predictor to LLM outputs
4. Compare personality profiles across roles

**Design Tradeoffs**
The external evaluation approach sacrifices direct interpretability for better measurement accuracy. Self-assessment would provide clearer theoretical alignment with human personality testing but fails for LLMs that cannot meaningfully self-report. The choice of MBTI over other frameworks trades comprehensiveness for practical measurement feasibility.

**Failure Signatures**
- Poor predictor performance indicates insufficient training data or inadequate feature learning
- Inconsistent human personality scores suggest flawed ground truth or evaluation methodology
- Task-dependent personality shifts that are minimal or reversed would invalidate the main findings
- Model-specific personality patterns rather than task-dependent shifts would suggest model bias

**Three First Experiments**
1. Test predictor accuracy on held-out human data to validate measurement reliability
2. Compare personality consistency across multiple task types beyond posts and comments
3. Evaluate personality stability across different LLM generations and model sizes

## Open Questions the Paper Calls Out
The paper raises questions about whether traditional personality frameworks like MBTI are appropriate for AI systems, and whether personality should be considered a stable trait for LLMs given their task-dependent variations. It also questions how to develop more appropriate personality measurement methods for AI that account for their unique characteristics.

## Limitations
- Focuses exclusively on MBTI framework, ignoring other personality theories like Big Five or HEXACO
- Task-dependent personality differences may be context-specific rather than fundamental
- Human-generated tweets as ground truth may introduce social media presentation biases
- Limited evaluation of personality stability across time and different model generations

## Confidence

High confidence in measurement methodology and technical implementation
Medium confidence in interpretation of personality differences as fundamental distinctions
Low confidence in broader claims about needing to re-evaluate personality measurement without alternative frameworks

## Next Checks
1. Test the same personality detection model on multiple additional task types (creative writing, problem-solving, dialogue) to determine if personality shifts are consistent across contexts or task-specific
2. Compare personality stability across time by evaluating the same LLM on identical tasks with multiple model generations to assess temporal consistency
3. Apply alternative personality frameworks (Big Five, HEXACO) alongside MBTI to determine if observed differences persist across measurement systems or are framework-specific