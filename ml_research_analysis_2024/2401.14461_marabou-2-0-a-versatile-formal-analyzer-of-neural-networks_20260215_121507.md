---
ver: rpa2
title: 'Marabou 2.0: A Versatile Formal Analyzer of Neural Networks'
arxiv_id: '2401.14461'
source_url: https://arxiv.org/abs/2401.14461
tags:
- loops
- deepcert
- target6
- eps0
- marabou
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Marabou 2.0 is a versatile framework for formal analysis of neural
  networks, introducing significant improvements over its predecessor. It features
  an optimized core architecture, support for diverse activation functions, proof
  production, and a powerful Python API.
---

# Marabou 2.0: A Versatile Formal Analyzer of Neural Networks

## Quick Facts
- arXiv ID: 2401.14461
- Source URL: https://arxiv.org/abs/2401.14461
- Reference count: 40
- Marabou 2.0 achieves 2x-10x speedup on 417-670 benchmark instances compared to an early version

## Executive Summary
Marabou 2.0 is a significant update to the Marabou framework for formal analysis of neural networks, introducing a range of new features and optimizations. The tool features an optimized core architecture, support for diverse activation functions, proof production, and a powerful Python API. Marabou 2.0 employs advanced decision procedures and abstract interpretation techniques to efficiently verify various properties of neural networks. The framework has demonstrated superior performance in runtime and memory efficiency, winning second place overall in the VNN-COMP'23 competition while scoring highest among CPU-based verifiers.

## Method Summary
Marabou 2.0 employs a multi-faceted approach to neural network verification. The core verification engine uses a Simplex-based linear programming solver with optimizations to avoid costly tableau recomputations. The framework supports a wide range of activation functions and can handle non-linear constraints through an abstract interpretation layer that infers network topology automatically. For UNSAT results, Marabou can produce proof certificates using Farkas-based witnesses. The tool provides both Python and C++ APIs, supports parallel solving with split-and-conquer and portfolio modes, and can interface with external solvers like Gurobi. The architecture separates concerns into front-end parsers, an engine with preprocessing and reasoning components, and a back-end with the core solving algorithms.

## Key Results
- Achieved at least 2x speed-up on 417 benchmark instances and 10x on 253 instances compared to an early version
- Won second place overall in VNN-COMP'23 competition, scoring highest among CPU-based verifiers
- Demonstrated successful application in diverse domains including verifying learning-based robotic systems and producing formal explanations for neural networks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Marabou 2.0's performance gain comes from eliminating new equations in the Simplex tableau after initialization.
- Mechanism: By representing case splits and backtracking as bound updates instead of equation additions, the tableau state is preserved, avoiding costly recomputations.
- Core assumption: The underlying constraint structure remains compatible with bound-only updates during search.
- Evidence anchors:
  - [section] "One optimization in Marabou 2.0’s Simplex engine is that once the tableau has been initialized, it avoids introducing any new equations — a costly operation that requires re-computing the tableau from scratch."
  - [section] "This optimization reduces the runtime of the Simplex engine by over 50%."
- Break Condition: If new equations are required for correctness (e.g., due to non-linear constraints that cannot be encoded as bounds), the optimization fails and performance regresses.

### Mechanism 2
- Claim: Marabou 2.0's network-level reasoning automates inference of network topology, enabling powerful abstract interpretation passes.
- Mechanism: The NetworkLevelReasoner class automatically infers the feed-forward structure from linear and non-linear constraints, enabling layer-wise bound propagation without manual network description.
- Core assumption: The given constraints are sufficient to reconstruct the network architecture unambiguously.
- Evidence anchors:
  - [section] "the network architecture is automatically inferred from the given set of linear and non-linear constraints, via the constructNetworkLevelReasoner method."
  - [section] "The Network-level Reasoner is only initialized if such inference is successful."
- Break Condition: If constraints are insufficient or ambiguous, the NetworkLevelReasoner will not be initialized, losing the benefit of automated abstract interpretation.

### Mechanism 3
- Claim: Marabou 2.0's proof production capability enables formal verification of UNSAT results.
- Mechanism: The Proof module constructs proof trees using Farkas-based witnesses for each unsatisfiable sub-query, which can be checked by a trusted SMT solver or a formally verified checker.
- Core assumption: The underlying solving steps are sound and the proof witnesses are correctly generated.
- Evidence anchors:
  - [section] "A proof module has recently been introduced into Marabou, enabling it to optionally produce proof certificates after an unsatisfiable (UNSAT) result."
  - [section] "The proof vector corresponds to a linear equation that is violated by the variable bounds."
- Break Condition: If proof production is incompatible with certain features (e.g., parallel solving), proof generation will fail or be incomplete.

## Foundational Learning

- Concept: Context-dependent data structures
  - Why needed here: Efficiently save and restore solver states during case splitting and backtracking without manual bookkeeping.
  - Quick check question: How do context-dependent data structures differ from standard ones in Marabou 2.0?

- Concept: Abstract interpretation for neural networks
  - Why needed here: Provide incomplete but efficient over-approximations of network behavior for early pruning of infeasible regions.
  - Quick check question: Which abstract interpretation methods are implemented in the NetworkLevelReasoner?

- Concept: CEGAR (Counterexample-Guided Abstraction Refinement)
  - Why needed here: Handle non-linear constraints beyond piecewise-linear functions by iteratively refining linear abstractions.
  - Quick check question: Which activation functions are currently supported by the CEGAR solver in Marabou 2.0?

## Architecture Onboarding

- Component map: Input Query -> Preprocessor -> Network-level Reasoner -> SMT Solver -> Result/Proof
- Critical path: Input Query → Preprocessor → Network-level Reasoner → SMT Solver → Result/Proof
- Design tradeoffs:
  - Native Simplex vs. external LP solvers: speed vs. dependency
  - Proof production vs. feature compatibility: reliability vs. functionality
  - Parallelization modes: split-and-conquer vs. portfolio: load balancing vs. stochastic diversity
- Failure signatures:
  - No Network-level Reasoner initialized: constraints insufficient for topology inference
  - Proof production disabled: incompatible features enabled (e.g., parallel solving)
  - Slow performance: missing external solvers when configured for DeepSoI
- First 3 experiments:
  1. Load a simple ONNX network and verify a basic input-output property
  2. Enable proof production on an UNSAT instance and verify the certificate
  3. Test parallel solving with split-and-conquer on a large benchmark

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the integration of a full-blown CDCL mechanism impact Marabou's performance on complex neural network verification tasks?
- Basis in paper: [explicit] The paper mentions that integrating a CDCL mechanism is an ongoing effort and highlights its potential benefits for handling similar queries efficiently.
- Why unresolved: The paper does not provide any experimental results or analysis of the impact of CDCL integration on Marabou's performance.
- What evidence would resolve it: Comparative runtime and memory usage results between Marabou with and without CDCL integration on a diverse set of neural network verification benchmarks.

### Open Question 2
- Question: Can Marabou's proof production capabilities be extended to handle all features, including parallel solving mode, without significant performance overhead?
- Basis in paper: [explicit] The paper states that proof production mode is currently only compatible with a subset of Marabou's features and that adding support for the remaining features is an ongoing endeavor.
- Why unresolved: The paper does not provide any information on the feasibility or challenges of extending proof production to all features.
- What evidence would resolve it: A detailed analysis of the technical challenges and potential solutions for extending proof production to all Marabou features, along with experimental results demonstrating the impact on performance.

### Open Question 3
- Question: How effective are Marabou's abstract interpretation techniques in tightening bounds for complex neural network architectures with non-standard activation functions?
- Basis in paper: [explicit] The paper highlights the importance of abstract interpretation techniques and mentions the support for over ten types of non-linear constraints, but does not provide a detailed analysis of their effectiveness.
- Why unresolved: The paper does not provide a comprehensive evaluation of Marabou's abstract interpretation techniques on a wide range of neural network architectures and non-standard activation functions.
- What evidence would resolve it: Experimental results comparing the bound tightening achieved by Marabou's abstract interpretation techniques against other state-of-the-art methods on a diverse set of neural network architectures with various non-standard activation functions.

## Limitations
- Performance gains are based on specific benchmark instances with unknown generalization to other domains
- Proof production has known incompatibilities with parallel solving modes that limit practical applicability
- NetworkLevelReasoner relies on automatic topology inference that may fail on networks with complex or non-standard architectures

## Confidence

**Confidence Labels:**
- Performance claims: Medium confidence (based on limited benchmark scope)
- Proof production claims: Low confidence (known feature incompatibilities)
- Architecture automation claims: Medium confidence (dependent on constraint sufficiency)

## Next Checks

1. Test Marabou 2.0 on networks with non-standard activation functions and architectures to verify the NetworkLevelReasoner's inference capabilities across diverse scenarios.

2. Evaluate proof production on UNSAT instances using both the trusted SMT solver and the formally verified checker to assess practical usability.

3. Benchmark performance on a broader range of property types (not just adversarial robustness) to determine the framework's versatility across different verification tasks.