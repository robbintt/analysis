---
ver: rpa2
title: 'ExplainableDetector: Exploring Transformer-based Language Modeling Approach
  for SMS Spam Detection with Explainability Analysis'
arxiv_id: '2405.08026'
source_url: https://arxiv.org/abs/2405.08026
tags: []
core_contribution: This study employs transformer-based Large Language Models (LLMs)
  for SMS spam detection, addressing the challenges of unstructured data and class
  imbalance. The research optimizes and fine-tunes BERT variants, specifically DistilBERT
  and RoBERTa, achieving high accuracy in classifying spam and ham messages.
---

# ExplainableDetector: Exploring Transformer-based Language Modeling Approach for SMS Spam Detection with Explainability Analysis

## Quick Facts
- arXiv ID: 2405.08026
- Source URL: https://arxiv.org/abs/2405.08026
- Reference count: 6
- Key result: Achieved 99.84% accuracy using RoBERTa for SMS spam detection with XAI explanations

## Executive Summary
This study explores transformer-based language models for SMS spam detection, addressing challenges of unstructured data and class imbalance. The research optimizes and fine-tunes BERT variants, specifically DistilBERT and RoBERTa, achieving high accuracy in classifying spam and ham messages. The study also employs Explainable AI (XAI) techniques to enhance model transparency, calculating positive and negative coefficients to explain predictions. The RoBERTa model demonstrates exceptional performance on the benchmark dataset, providing a robust solution for detecting spam SMS messages while ensuring model interpretability.

## Method Summary
The research employs transformer-based language models (DistilBERT and RoBERTa) for SMS spam detection. The methodology involves preprocessing and cleaning SMS data, addressing class imbalance through back translation augmentation, and fine-tuning the transformer models with optimized hyperparameters. Explainable AI techniques (LIME and Transformers Interpret) are applied to generate interpretable explanations for model predictions by calculating positive and negative coefficients for each word's contribution to classification decisions.

## Key Results
- RoBERTa model achieved 99.84% accuracy on benchmark SMS spam dataset
- Successfully addressed class imbalance through text augmentation using back translation
- Generated interpretable explanations using LIME and Transformers Interpret techniques
- Demonstrated effectiveness of transformer-based models in cybersecurity applications for spam detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformer-based models like RoBERTa achieve high accuracy on SMS spam detection due to bidirectional context understanding and optimized pretraining.
- Mechanism: RoBERTa leverages bidirectional attention mechanisms to capture context from both left and right of each token, unlike unidirectional models. It also uses a larger training corpus, dynamic masking, and removes the NSP task to improve language representation quality.
- Core assumption: The unstructured nature of SMS data contains sufficient contextual cues that bidirectional models can exploit for accurate classification.
- Evidence anchors:
  - [abstract]: "The RoBERTa model achieves an impressive accuracy of 99.84% on the benchmark dataset."
  - [section]: "RoBERTa learns unsupervised from a large corpus of text data during its pre-training phase... Additionally, to enhance the caliber of learned representations, it does away with the NSP (Next Sentence Prediction) task and employs a larger training corpus with dynamic masking."
  - [corpus]: Weak. No direct evidence in corpus that RoBERTa's bidirectional nature is the key differentiator; related works use other models without citing this specific advantage.
- Break condition: If SMS content is extremely short or lacks context (e.g., "WIN NOW"), bidirectional context may not provide meaningful advantage over unidirectional models.

### Mechanism 2
- Claim: Explainable AI techniques (LIME and Transformers Interpret) improve user trust by highlighting influential words in predictions.
- Mechanism: LIME perturbs input text and fits a local interpretable model to approximate the black-box model's behavior near the instance. Transformers Interpret uses word attribution scores to show how each token contributes positively or negatively to the prediction.
- Core assumption: Users need transparent explanations to trust automated spam detection, especially when false positives could block legitimate messages.
- Evidence anchors:
  - [abstract]: "We also work with Explainable Artificial Intelligence (XAI) techniques to calculate the positive and negative coefficient scores which explore and explain the fine-tuned model transparency in this text-based spam SMS detection task."
  - [section]: "These tools approximate the model's behavior by analyzing each word's contribution in the SMS text toward the final prediction... Positive coefficients indicate that the presence of the word contributes towards predicting a certain class, while negative coefficients indicate the opposite."
  - [corpus]: Weak. Corpus papers focus on detection accuracy but do not discuss explainability or user trust mechanisms.
- Break condition: If explanations are too complex or numerous, users may not derive meaningful insights, reducing the utility of XAI.

### Mechanism 3
- Claim: Data balancing through text augmentation (back translation) improves model performance on minority classes.
- Mechanism: Back translation translates text to another language and back, creating paraphrased versions that preserve meaning but introduce lexical variation. This oversamples the minority spam class to balance the dataset.
- Core assumption: The original dataset has significant class imbalance that biases the model toward the majority class (ham), reducing spam detection capability.
- Evidence anchors:
  - [abstract]: "We use a benchmark SMS spam dataset... and solve the class imbalance problem using the text augmentation technique."
  - [section]: "Back translation enhances our dataset, making it easier to train robust models, improving performance on a range of natural language processing tasks, and producing text data with different terms while maintaining context."
  - [corpus]: Weak. Related works mention handling imbalance but do not specifically cite back translation as the technique used.
- Break condition: If augmented data introduces artifacts or changes meaning during translation, it could degrade model performance rather than improve it.

## Foundational Learning

- Concept: Bidirectional vs. unidirectional language models
  - Why needed here: Understanding why RoBERTa outperforms other models requires knowing how bidirectional attention captures context differently than left-to-right models.
  - Quick check question: What is the key difference between BERT's masked language modeling and traditional autoregressive language modeling?

- Concept: Attention mechanisms in transformers
  - Why needed here: The model's ability to weigh word importance depends on self-attention; understanding this helps explain why certain words are highlighted in XAI explanations.
  - Quick check question: How does the attention score between two tokens in a transformer layer get computed?

- Concept: Data augmentation techniques for text
  - Why needed here: The effectiveness of back translation depends on understanding how semantic preservation works across language translation cycles.
  - Quick check question: What potential issues could arise when translating SMS slang or abbreviations through back translation?

## Architecture Onboarding

- Component map:
  Raw SMS -> Preprocessing (cleaning, deduplication) -> Augmentation (back translation) -> Tokenization -> Model input
  Tokenizer -> Transformer encoder (DistilBERT/RoBERTa) -> Classification head -> Output probabilities
  LIME explainer -> Word attributions -> Visualization; Transformers Interpret -> Token attributions -> Visualization
  DataLoader -> Optimizer (AdamW) -> Loss calculation -> Backpropagation -> Parameter update

- Critical path:
  1. Load and preprocess SMS dataset
  2. Balance data using back translation
  3. Tokenize and batch data
  4. Fine-tune transformer model with optimized hyperparameters
  5. Evaluate model performance
  6. Generate XAI explanations for sample predictions

- Design tradeoffs:
  - Model size vs. inference speed: DistilBERT is smaller and faster but slightly less accurate than RoBERTa
  - Augmentation quality vs. computational cost: More back translation cycles improve balance but increase training time
  - XAI complexity vs. interpretability: More features in LIME explanations provide detail but may overwhelm users

- Failure signatures:
  - High accuracy on training but poor on test: Likely overfitting, check data leakage or insufficient regularization
  - XAI explanations highlight irrelevant words: Model may be picking up spurious correlations, retrain with more diverse data
  - Class imbalance persists after augmentation: Back translation may not be generating sufficiently diverse samples

- First 3 experiments:
  1. Train baseline model without data balancing; measure class-wise performance to confirm imbalance issue
  2. Apply back translation augmentation; verify class distribution becomes balanced
  3. Compare LIME vs. Transformers Interpret explanations on same samples to validate consistency of attributions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different transformer-based model architectures (BERT, RoBERTa, DistilBERT) compare in terms of interpretability and explainability for SMS spam detection?
- Basis in paper: [explicit] The paper mentions using LIME and Transformers Interpret techniques to explain the predictions of the RoBERTa model, but does not provide a comprehensive comparison with other transformer-based models.
- Why unresolved: The paper focuses on the RoBERTa model's performance and explainability, but does not directly compare its interpretability with other transformer-based models like BERT or DistilBERT.
- What evidence would resolve it: A comparative analysis of the interpretability and explainability of different transformer-based models using the same techniques (LIME and Transformers Interpret) on the same dataset.

### Open Question 2
- Question: How does the performance of transformer-based models for SMS spam detection vary across different languages and cultural contexts?
- Basis in paper: [inferred] The paper uses an English SMS spam dataset, but does not explore the performance of transformer-based models on SMS spam data in other languages or cultural contexts.
- Why unresolved: The study focuses on English SMS spam detection, and the generalizability of the results to other languages and cultural contexts is not addressed.
- What evidence would resolve it: Experiments using transformer-based models on SMS spam datasets in different languages and cultural contexts, comparing their performance and interpretability.

### Open Question 3
- Question: What is the optimal balance between model complexity and interpretability for SMS spam detection?
- Basis in paper: [explicit] The paper mentions using XAI techniques to explain the predictions of the RoBERTa model, but does not discuss the trade-off between model complexity and interpretability.
- Why unresolved: The study does not explore the relationship between model complexity and interpretability, which is an important consideration for practical applications.
- What evidence would resolve it: An analysis of the performance and interpretability of transformer-based models with varying levels of complexity, and a discussion of the trade-offs involved in choosing an optimal model for SMS spam detection.

## Limitations
- The reported 99.84% accuracy appears exceptionally high for a real-world SMS spam detection task, raising concerns about potential overfitting or unusually clean benchmark data.
- Explainability analysis relies on post-hoc XAI tools rather than inherently interpretable architectures, meaning explanations may be approximations rather than faithful representations.
- Back translation augmentation could introduce semantic drift if SMS-specific language (slang, abbreviations) does not translate well across language pairs.

## Confidence
- **High Confidence**: The core mechanism that transformer-based models can achieve high accuracy on text classification tasks is well-established in the literature.
- **Medium Confidence**: The specific claim of 99.84% accuracy on SMS spam detection requires validation, as this exceeds typical performance reported in similar tasks.
- **Low Confidence**: The practical utility of XAI explanations for SMS spam detection users is not empirically validated.

## Next Checks
1. **Benchmark Validation**: Reproduce results on multiple SMS spam datasets (SMS Spam Collection, SMS Spam Dataset, and other publicly available datasets) to verify that the 99.84% accuracy generalizes beyond a single benchmark. Compare performance against established baselines using standard metrics including precision, recall, F1-score, and confusion matrices.

2. **XAI Utility Testing**: Conduct user studies where participants with varying technical backgrounds interact with model predictions and explanations. Measure whether LIME and Transformers Interpret explanations actually help users distinguish between legitimate and spam messages better than raw predictions alone, using metrics like task completion time and accuracy in verification tasks.

3. **Semantic Preservation Analysis**: Systematically evaluate back translation augmentation by having human annotators verify whether translated SMS messages maintain their original meaning and spam/ham classification after translation cycles. Measure semantic drift using automated metrics like BLEU score and manual quality assessment to ensure augmentation improves rather than degrades model performance.