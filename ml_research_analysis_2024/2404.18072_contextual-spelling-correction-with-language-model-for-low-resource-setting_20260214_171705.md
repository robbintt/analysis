---
ver: rpa2
title: Contextual Spelling Correction with Language Model for Low-resource Setting
arxiv_id: '2404.18072'
source_url: https://arxiv.org/abs/2404.18072
tags:
- error
- word
- language
- words
- correction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses spelling correction in low-resource languages,
  focusing on Nepali. It proposes a noisy channel framework combining a small-scale
  word-based transformer language model and a probabilistic error model trained from
  text corpus.
---

# Contextual Spelling Correction with Language Model for Low-resource Setting

## Quick Facts
- arXiv ID: 2404.18072
- Source URL: https://arxiv.org/abs/2404.18072
- Authors: Nishant Luitel; Nirajan Bekoju; Anand Kumar Sah; Subarna Shakya
- Reference count: 29
- Primary result: Achieves 69.1% word accuracy and 74.4% character accuracy for Nepali spelling correction using noisy channel framework with small transformer LM

## Executive Summary
This paper addresses spelling correction in low-resource languages, focusing on Nepali. The authors propose a noisy channel framework that combines a small-scale word-based transformer language model with a probabilistic error model trained from text corpus. The method ranks candidate corrections using Bayesian inference, balancing contextual likelihood from the language model and error probabilities from the error model. The approach demonstrates effectiveness using only an unprocessed corpus, making it suitable for low-resource languages.

## Method Summary
The proposed method employs a noisy channel framework for contextual spelling correction. It consists of two main components: a small-scale word-based transformer language model and a probabilistic error model trained from text corpus. The language model provides contextual likelihood scores for candidate corrections, while the error model captures substitution, insertion, deletion, and transposition error probabilities. Candidate corrections are ranked using Bayesian inference, combining the contextual likelihood from the language model with error probabilities from the error model. The approach requires only an unprocessed corpus, making it particularly suitable for low-resource languages where large annotated datasets are unavailable.

## Key Results
- Achieves 69.1% word accuracy and 74.4% character accuracy for Nepali spelling correction
- Outperforms other variants including BERT-based models when using combination of transformer LM and Brill-Moore error model
- Ablation study shows error model alone captures many corrections effectively

## Why This Works (Mechanism)
The noisy channel framework works by treating spelling correction as a probabilistic inference problem. Given a misspelled word, the system generates candidate corrections and ranks them based on two probabilities: the likelihood of the correction given the context (from the language model) and the probability of the error occurring (from the error model). The Bayesian formulation P(correct|misspelled) ∝ P(misspelled|correct) × P(correct) naturally balances contextual appropriateness with realistic error patterns. The small transformer language model provides sufficient contextual understanding for a morphologically rich language like Nepali, while the error model captures language-specific error patterns learned directly from corpus data.

## Foundational Learning
- **Noisy Channel Framework**: Why needed - Provides principled probabilistic approach to spelling correction; Quick check - Verify candidate ranking follows Bayesian inference rules
- **Transformer Language Models**: Why needed - Captures contextual dependencies for accurate correction ranking; Quick check - Test perplexity reduction on validation set
- **Error Model Training**: Why needed - Learns language-specific error patterns without annotated data; Quick check - Validate error probabilities sum to 1 for each operation type
- **Bayesian Inference**: Why needed - Combines language model and error model probabilities optimally; Quick check - Confirm posterior scores correlate with correction accuracy
- **Low-resource Language Processing**: Why needed - Addresses lack of annotated data in many languages; Quick check - Test on languages with varying resource availability

## Architecture Onboarding

**Component Map**: Unprocessed Corpus -> Error Model Training -> Language Model Training -> Noisy Channel Framework -> Candidate Ranking

**Critical Path**: Misspelled word → Candidate generation → Language model scoring → Error model scoring → Bayesian combination → Final ranking

**Design Tradeoffs**: Small transformer LM vs BERT for computational efficiency; Corpus-derived error patterns vs manually defined rules; Bayesian combination vs neural end-to-end approaches

**Failure Signatures**: Poor performance on rare words (insufficient error pattern coverage); Over-correction of valid but uncommon words (language model bias); Slow inference (computational complexity); Language-specific error patterns not captured (corpus quality issues)

**3 First Experiments**:
1. Evaluate word and character accuracy on held-out test set with varying error types
2. Ablation study comparing language model only, error model only, and combined approaches
3. Scalability test measuring inference time and memory usage with increasing corpus size

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to single language (Nepali) and dataset size constrains generalizability
- Computational complexity analysis lacks detailed empirical measurements for inference scaling
- Error model training assumes sufficient error patterns exist in unprocessed corpora without validation across languages

## Confidence
- **High**: Core noisy channel framework theoretical soundness; Empirical effectiveness on Nepali
- **Medium**: Scalability claims; Relative performance comparisons with neural models
- **Low**: Generalizability across diverse low-resource language typologies; Sufficiency of corpus-derived error patterns

## Next Checks
1. Evaluate the method on at least three additional low-resource languages with varying morphological complexity and orthographic systems to test generalizability.
2. Conduct systematic ablation studies measuring inference time and memory usage across different corpus sizes to quantify scalability limitations.
3. Test hybrid approaches combining the noisy channel framework with pre-trained multilingual models to determine if complementary strengths exist.