---
ver: rpa2
title: Context versus Prior Knowledge in Language Models
arxiv_id: '2404.04633'
source_url: https://arxiv.org/abs/2404.04633
tags:
- entity
- query
- contexts
- susceptibility
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces two mutual information-based metrics to quantify
  how language models integrate prior knowledge and context when answering questions.
  The persuasion score measures how much a context changes a model's answer distribution
  for a specific entity, while the susceptibility score measures how easily an entity's
  answer distribution can be swayed by context across all contexts.
---

# Context versus Prior Knowledge in Language Models

## Quick Facts
- arXiv ID: 2404.04633
- Source URL: https://arxiv.org/abs/2404.04633
- Reference count: 40
- This paper introduces two mutual information-based metrics to quantify how language models integrate prior knowledge and context when answering questions.

## Executive Summary
This paper presents a framework for quantifying the relative influence of prior knowledge versus contextual information in language model question answering. The authors introduce two metrics - persuasion score and susceptibility score - that measure how much contexts change model answer distributions for specific entities and how easily entities' answer distributions can be swayed by context. Through experiments on Pythia models of varying sizes, they validate these metrics and demonstrate their utility in analyzing gender bias and friend-enemy stance detection. The results show that relevant contexts are more persuasive than irrelevant ones, and entities with higher frequency in training data show lower susceptibility to context.

## Method Summary
The authors construct a dataset of 122 relations from YAGO knowledge graph with 100 entities each, creating query templates and context templates for each relation. For each entity-query pair, they generate contexts and compute persuasion scores using half-pointwise mutual information between context and answer distributions. Susceptibility scores are computed by marginalizing persuasion scores over all contexts for each entity. The framework uses next token probabilities from Pythia models of various sizes (70m to 12b parameters) to estimate answer distributions. The analysis includes both real entities and synthetic "fake" entities to validate the metrics.

## Key Results
- Relevant contexts are consistently more persuasive than irrelevant ones for influencing model answers
- Entities appearing frequently in training data have lower susceptibility scores, indicating stronger prior biases
- Assertive contexts are more persuasive than base contexts for yes/no questions
- Friend duos are less susceptible than enemy duos in stance detection experiments

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Persuasion score measures how much a context changes a model's answer distribution for a specific entity.
- **Mechanism:** Persuasion score uses half-pointwise mutual information (half-PMI) between context and answer, conditioned on a query about an entity. This captures the KL-divergence between answer distributions with and without context.
- **Core assumption:** The change in answer distribution reflects the context's persuasive power on the model's behavior.
- **Evidence anchors:**
  - [abstract] "the persuasion score of a given context represents how much a model depends on the context in its decision"
  - [section] "π(c, q(e)) ≜ I(C = c; A | q(E) = q(e)) = KL(p(a | c, q(e)) || p(a | q(e)))"
- **Break condition:** If the model's answer distribution is not well-estimated (e.g., limited sampling), the KL-divergence calculation becomes noisy and unreliable.

### Mechanism 2
- **Claim:** Susceptibility score measures how easily an entity's answer distribution can be swayed by context across all contexts.
- **Mechanism:** Susceptibility score uses mutual information between context and answer, conditioned on a query about an entity. This captures the reduction in uncertainty about the answer when context is provided.
- **Core assumption:** The degree to which context reduces uncertainty about the answer reflects the entity's susceptibility to context.
- **Evidence anchors:**
  - [abstract] "the susceptibility score of a given entity represents how much the model can be swayed away from its original answer distribution about an entity"
  - [section] "σ(q(e)) ≜ I(C; A | q(E) = q(e)) = H(A | q(E) = q(e)) − H(A | C, q(E) = q(e))"
- **Break condition:** If the context distribution is not representative (e.g., biased sampling), the mutual information calculation becomes unreliable.

### Mechanism 3
- **Claim:** Relevant contexts are more persuasive than irrelevant ones.
- **Mechanism:** Relevant contexts mention the queried entity, providing direct information that can influence the model's answer. Irrelevant contexts do not mention the entity, so their persuasive power is limited.
- **Core assumption:** Contexts that mention the entity are more likely to contain information that can influence the model's answer about that entity.
- **Evidence anchors:**
  - [section] "we find evidence that relevant contexts are consistently more persuasive than irrelevant ones"
- **Break condition:** If the model has strong prior knowledge about the entity, even irrelevant contexts might influence its answer.

## Foundational Learning

- **Concept:** Mutual information and KL-divergence
  - Why needed here: These information-theoretic measures form the basis of the persuasion and susceptibility scores.
  - Quick check question: What is the relationship between mutual information and KL-divergence?

- **Concept:** Entity bias and context interaction
  - Why needed here: Understanding how a model's prior knowledge about entities interacts with contextual information is crucial for interpreting the susceptibility scores.
  - Quick check question: How does entity bias affect a model's susceptibility to context?

- **Concept:** Measurement modeling and construct validity
  - Why needed here: The validity and reliability of the persuasion and susceptibility scores are assessed using established measurement modeling methods.
  - Quick check question: What is the difference between face validity and construct validity?

## Architecture Onboarding

- **Component map:** Context templates (base, assertive, negation) -> Entity sampling (real and fake) -> Query templates (open and closed) -> Model (Pythia) -> Persuasion score calculation -> Susceptibility score calculation -> Analysis and visualization

- **Critical path:**
  1. Generate context templates and parameterize with entities
  2. Generate query templates and parameterize with entities
  3. Compute persuasion scores for each context-entity pair
  4. Compute susceptibility scores for each entity
  5. Analyze and visualize the results

- **Design tradeoffs:**
  - Using next token probabilities vs. sampling multiple outputs for answer distribution estimation
  - Sampling contexts vs. using all possible contexts
  - Using real vs. fake entities

- **Failure signatures:**
  - High variance in persuasion or susceptibility scores across seeds or query forms
  - Lack of significant differences between relevant and irrelevant contexts
  - Unexpected relationships between scores and entity frequency

- **First 3 experiments:**
  1. Reproduce the relevance test: Compare persuasion scores for relevant vs. irrelevant contexts.
  2. Reproduce the familiarity test: Compare susceptibility scores for real vs. fake entities.
  3. Explore the relationship between entity frequency and susceptibility scores.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How do persuasion scores differ between open and closed questions, and what underlying factors contribute to this difference?
- **Basis in paper:** [explicit] The paper notes that "we see similar patterns between the two, susceptibility and persuasion appear to have a stronger relationship with memorization ratio for open queries, while assertive contexts appear to be significantly more persuasive than base contexts primarily for closed queries."
- **Why unresolved:** The paper identifies a surprising difference in behavior between open and closed queries but does not fully explain the underlying reasons for this difference.
- **What evidence would resolve it:** Further experiments comparing the model's behavior on open vs closed questions with different context types, and analyzing the token biases and output space differences between the two question types.

### Open Question 2
- **Question:** How does the frequency of entity co-occurrence in the training data relate to the susceptibility score, and what is the precise nature of this relationship?
- **Basis in paper:** [explicit] The paper finds a significant negative correlation (Spearman ρ = -0.23) between frequency and susceptibility scores, but the relationship is not fully characterized.
- **Why unresolved:** While a correlation is established, the exact nature of the relationship (e.g., linear, logarithmic) and its implications for model behavior are not fully explored.
- **What evidence would resolve it:** Detailed analysis of the relationship between co-occurrence frequency and susceptibility scores across different model sizes and query types, including fitting different functional forms to the data.

### Open Question 3
- **Question:** How do the persuasion and susceptibility scores relate to each other, and what insights can be gained from their interplay?
- **Basis in paper:** [inferred] The paper introduces both metrics but does not explicitly explore their relationship or how they complement each other in understanding model behavior.
- **Why unresolved:** The paper focuses on validating each metric individually but does not investigate how they interact or provide a more comprehensive picture of model behavior when used together.
- **What evidence would resolve it:** Experiments analyzing the correlation between persuasion and susceptibility scores for the same contexts and entities, and exploring how their combination can provide more nuanced insights into model behavior.

## Limitations

- **Sampling methodology concerns:** The paper relies on sampled contexts and sampled answers from the model, which introduces uncertainty in the mutual information calculations.
- **Mutual information estimation challenges:** Computing KL-divergence and mutual information from discrete distributions requires sufficient sampling, and estimates may be noisy with limited context samples.
- **Novelty limitations:** The related work search returned papers with low citation counts, suggesting this specific combination of mutual information-based metrics may be novel territory with limited validation from the broader literature.

## Confidence

**High confidence** in the information-theoretic framework: The use of KL-divergence and mutual information as metrics is well-established in information theory.

**Medium confidence** in the convergent validity results: While the paper shows expected patterns, the analysis relies on simulated contexts rather than naturally occurring ones.

**Low confidence** in the causal interpretation of susceptibility scores: The claim that susceptibility measures "how much the model can be swayed away from its original answer distribution" assumes the original distribution reflects true prior knowledge.

## Next Checks

1. **Variance analysis across seeds and query forms:** Conduct a systematic analysis of how persuasion and susceptibility scores vary across different random seeds and query template variations. Quantify the variance and establish thresholds for when scores are statistically distinguishable.

2. **Correlation with independent knowledge measures:** Validate the susceptibility scores by correlating them with independent measures of entity familiarity, such as entity frequency in pretraining data or performance on entity-specific probing tasks.

3. **Out-of-distribution context testing:** Test the persuasion scores on naturally occurring contexts from diverse domains to assess whether the simulated context templates generalize to real-world scenarios where context-knowledge integration occurs.