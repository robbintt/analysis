---
ver: rpa2
title: Guiding Word Equation Solving using Graph Neural Networks (Extended Technical
  Report)
arxiv_id: '2411.15194'
source_url: https://arxiv.org/abs/2411.15194
tags:
- word
- graph
- equations
- algorithm
- proof
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DragonLi, a Graph Neural Network (GNN)-guided
  algorithm for solving word equations based on the Nielsen transformation. The algorithm
  iteratively rewrites word equations using a set of inference rules, creating a tree-like
  search space where split decisions significantly impact solving time.
---

# Guiding Word Equation Solving using Graph Neural Networks (Extended Technical Report)

## Quick Facts
- arXiv ID: 2411.15194
- Source URL: https://arxiv.org/abs/2411.15194
- Reference count: 40
- Primary result: GNN-guided algorithm solves 43.0% more SAT word equation problems than state-of-the-art solvers on the SWEN benchmark

## Executive Summary
This paper introduces DragonLi, a Graph Neural Network (GNN)-guided algorithm for solving word equations based on the Nielsen transformation. The algorithm iteratively rewrites word equations using a set of inference rules, creating a tree-like search space where split decisions significantly impact solving time. To optimize these decisions, the authors train GNNs to predict branch priorities at each split point, encoding word equations as five different graph representations. Experiments on artificial and real-world benchmarks show that DragonLi outperforms other state-of-the-art string solvers on satisfiable problems, solving 43.0% more SAT problems than the next best solver on one benchmark. While DragonLi performs comparably on conjunctions of multiple word equations, it struggles with unsatisfiable problems, requiring exhaustive proof tree exploration. The work highlights the potential of combining symbolic reasoning with deep learning in string constraint solving.

## Method Summary
The method trains Graph Neural Networks to predict branch priorities in a proof tree generated by the Nielsen transformation for word equations. The GNN is trained on proof trees from SAT problems, where each branching point is labeled with a priority score indicating which child branch leads to a solution most efficiently. During inference, the GNN predicts these priorities, allowing the solver to explore promising branches first. The approach uses five different graph representations of word equations, each capturing different structural relationships between variables and terminals. Three backtrack strategies control the depth of exploration before backtracking, with BT2 (depth-limited search with incremental depth increase) showing the best performance when combined with GNN predictions.

## Key Results
- DragonLi solves 43.0% more SAT problems than the next best solver (S3P) on the SWEN benchmark
- On the SLOG benchmark, DragonLi solves 8.2% more problems than S3P
- Different graph representations show varying performance, with Graph 5 offering relatively good performance despite higher computational overhead
- The method struggles with UNSAT problems, requiring exhaustive proof tree exploration in these cases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GNN-guided branch ordering improves solving time for satisfiable word equations by predicting which branch leads to a solution faster.
- Mechanism: The GNN model is trained on proof trees generated from SAT problems, where each branching point is labeled with a priority score indicating which child branch leads to a solution most efficiently. During inference, the GNN predicts these priorities, allowing the solver to explore promising branches first.
- Core assumption: Structural patterns in word equations that correlate with quick solutions can be learned from proof trees.
- Evidence anchors:
  - [abstract] "To address this, we present a heuristic that leverages deep learning to determine the exploration order of branches."
  - [section 4.3] "We construct the complete proof tree for given conjunctions of word equations, up to a certain depth... label each node v of the proof tree with multiple children is labelled based on two criteria: the satisfiability status (SAT, UNSAT, or UNKNOWN) of the formula, and the size of the proof sub-tree underneath each of the direct children."
- Break condition: If the GNN cannot learn meaningful patterns from the training data, or if the structural features captured by the graph representations are insufficient to predict solution paths.

### Mechanism 2
- Claim: Different graph representations of word equations capture varying levels of structural information, affecting GNN performance.
- Mechanism: Five graph representations (Graph 1-5) encode word equations with different levels of detail, from simple syntactic structures (Graph 1) to representations emphasizing variable-variable or letter-letter relationships (Graphs 3-5). The GNN learns from these representations to predict branch priorities.
- Core assumption: Certain graph structures better capture the semantic relationships in word equations that correlate with solution paths.
- Evidence anchors:
  - [section 4.1] "To understand the impact of the graph structure on our framework, we have designed five graph representations for word equations."
  - [section 5.5] "In terms of the five graph representations, Graph 1 has the simplest structure... Graph 5 considers the relationships for both terminals and variables, thus it has bigger overhead than Graphs 1, 3, and 4, but it offers relatively good performance."
- Break condition: If the graph representations fail to capture the essential structural features that distinguish between branches leading to solutions versus those that don't.

### Mechanism 3
- Claim: The combination of GNN guidance with specific backtrack strategies optimizes solving performance.
- Mechanism: Three backtrack strategies (BT1, BT2, BT3) control how deeply the solver explores the proof tree before backtracking. GNN guidance is integrated with these strategies, with BT2 (depth-limited search with incremental depth increase) showing the best performance when combined with GNN predictions.
- Core assumption: The interaction between branch ordering (via GNN) and exploration depth control (via backtrack strategies) significantly impacts solving efficiency.
- Evidence anchors:
  - [section 5.5] "In terms of backtrack strategies, BT1 performs a pure depth-first search, but it already has good performance. BT2 performs a depth-first search controlled by parameters lBT2 and lstepBT2, and in many cases, it delivers the best performance."
- Break condition: If the GNN predictions are consistently poor, or if the backtrack strategy parameters are not well-tuned for the problem characteristics.

## Foundational Learning

- Concept: Graph Neural Networks and message passing
  - Why needed here: GNNs are used to learn structural patterns in word equations and predict branch priorities in the proof tree.
  - Quick check question: How does message passing in GNNs allow nodes to aggregate information from their neighbors, and why is this important for capturing structural relationships in word equations?

- Concept: Nielsen transformation and proof systems for word equations
  - Why needed here: The algorithm is based on the Nielsen transformation, which provides the proof rules and proof tree structure that the GNN guides.
  - Quick check question: What are the key proof rules (R1-R9) used in the split algorithm, and how do they transform word equations during the solving process?

- Concept: Multi-classification tasks in machine learning
  - Why needed here: The GNN performs a multi-classification task at each split point to predict which branch should be explored first.
  - Quick check question: How is the multi-classification task formulated in this work (predicting branch priorities), and what is the loss function used to train the GNN?

## Architecture Onboarding

- Component map:
  Input word equations -> Graph representations (5 options) -> GNN model (trained on proof trees) -> Branch priority predictions -> Split algorithm with ordered branches -> SAT/UNSAT/UNKNOWN result

- Critical path:
  1. Convert input word equations to graph representation
  2. Feed graph to trained GNN model
  3. Get branch priority predictions from GNN
  4. Order branches based on GNN predictions
  5. Explore proof tree using ordered branches
  6. Return final result

- Design tradeoffs:
  - Graph representation complexity vs. computational overhead: More complex graphs (e.g., Graph 5) may capture more semantic information but incur higher computational costs during inference.
  - Backtrack strategy aggressiveness vs. completeness: BT1 is faster but may miss solutions; BT3 is complete but slower.
  - Training data quality vs. model generalization: Training only on SAT problems limits the model's ability to handle UNSAT cases.

- Failure signatures:
  - Poor GNN predictions leading to inefficient exploration (solver takes much longer than expected)
  - Solver gets stuck in infinite branches (indicates issue with backtrack strategy or GNN's inability to recognize non-terminating branches)
  - Solver fails to find solutions that simpler methods can find (indicates GNN's predictions are misleading)

- First 3 experiments:
  1. Compare solving time of DragonLi with and without GNN guidance on a small set of SAT word equations.
  2. Evaluate the impact of different graph representations (Graph 1 vs. Graph 5) on GNN prediction accuracy and overall solving performance.
  3. Test the performance of different backtrack strategies (BT1, BT2, BT3) in combination with GNN guidance on a benchmark of SAT problems.

## Open Questions the Paper Calls Out
The paper acknowledges several limitations and calls out specific areas for future work:
- Deciding which word equation to work on first is important for performance but currently uses only a predefined sequence
- The method struggles with unsatisfiable (UNSAT) problems, requiring exhaustive proof tree exploration
- Benchmarks were transformed by removing length constraints and regular expressions which are "not considered in this paper"

## Limitations
- The GNN model is trained exclusively on satisfiable (SAT) problems, which limits its effectiveness on unsatisfiable (UNSAT) instances where exhaustive proof tree exploration is required
- The approach shows significant performance degradation on benchmarks with conjunctions of multiple word equations, solving only 8.2% more problems than the baseline on the SLOG benchmark
- The method relies on proof trees generated up to a certain depth (3-5), which may not capture long-range dependencies crucial for complex word equations

## Confidence
- High confidence: The basic mechanism of using GNNs to guide branch ordering in word equation solving, supported by experimental results showing 43.0% improvement on individual SAT problems
- Medium confidence: The effectiveness of different graph representations, as results show Graph 5 performs best but with higher computational overhead, suggesting tradeoffs not fully explored
- Low confidence: Generalization to real-world string constraints, as the SLOG benchmark results show much smaller improvements (8.2%) compared to artificial benchmarks (43.0%)

## Next Checks
1. Evaluate the GNN model's performance on a validation set containing both SAT and UNSAT problems to assess generalization beyond the training distribution
2. Test the sensitivity of solving performance to different proof tree depths during training (currently fixed at 3-5) to determine if deeper trees improve guidance for complex equations
3. Compare the computational overhead of different graph representations (Graph 1 vs Graph 5) against their performance gains to establish optimal tradeoffs for practical deployment