---
ver: rpa2
title: Evaluating LLM -- Generated Multimodal Diagnosis from Medical Images and Symptom
  Analysis
arxiv_id: '2402.01730'
source_url: https://arxiv.org/abs/2402.01730
tags:
- medical
- images
- pathology
- image
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a two-step methodology for evaluating multimodal
  LLMs in medical diagnosis using Pathology MCQs with images. The method involves
  structured LLM interactions and domain-specific analysis via Image Metadata Analysis,
  Named Entity Recognition, and Knowledge Graphs.
---

# Evaluating LLM -- Generated Multimodal Diagnosis from Medical Images and Symptom Analysis

## Quick Facts
- arXiv ID: 2402.01730
- Source URL: https://arxiv.org/abs/2402.01730
- Authors: Dimitrios P. Panagoulias; Maria Virvou; George A. Tsihrintzis
- Reference count: 10
- One-line primary result: GPT-4-Vision-Preview achieved approximately 84% accuracy in multimodal medical diagnosis using Pathology MCQs

## Executive Summary
This paper proposes a two-step methodology for evaluating multimodal LLMs in medical diagnosis using Pathology MCQs with images. The method involves structured LLM interactions and domain-specific analysis via Image Metadata Analysis, Named Entity Recognition, and Knowledge Graphs. Using GPT-4-Vision-Preview, the study achieved approximately 84% accuracy across 79 questions. The analysis revealed weaknesses in cardiovascular, skin, and endocrine-related diagnoses, with incorrect responses linked to specific conditions like atherosclerosis and aneurysms. The methodology provides actionable insights for LLM optimization in medical domains.

## Method Summary
The study employs a two-step methodology to evaluate multimodal LLMs in medical diagnosis. First, GPT-4-Vision-Preview interacts with structured Pathology MCQs containing images and text-based symptoms. Second, domain-specific analysis is conducted using Image Metadata Analysis, Named Entity Recognition, and Knowledge Graph construction to identify the LLM's knowledge gaps and weaknesses. The approach focuses on revealing specific areas where the LLM struggles, providing insights for targeted optimization and improvement in medical diagnosis tasks.

## Key Results
- GPT-4-Vision-Preview achieved approximately 84% accuracy across 79 Pathology MCQ questions
- The analysis revealed specific weaknesses in cardiovascular, skin, and endocrine-related diagnoses
- Incorrect responses were linked to conditions such as atherosclerosis and aneurysms

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4-Vision-Preview can effectively integrate visual and textual medical information for diagnosis when structured MCQs are used.
- Mechanism: The LLM leverages its multimodal capabilities to process both the image and symptom text, applying its learned associations between visual patterns and disease entities to select the correct answer.
- Core assumption: The training data for GPT-4-Vision-Preview included sufficient medical imagery and associated text to enable accurate cross-modal reasoning.
- Evidence anchors:
  - [abstract] "GPT-4-Vision-Preview performed quite well, scoring approximately 84% of correct diagnoses."
  - [section] "In such multimodal systems, the model processes and integrates information from different sources. Specifically, it considers the textual input, such as a question or prompt, in conjunction with visual data from images."
- Break condition: The model's performance drops significantly when presented with novel pathologies not well-represented in its training data or when image quality is poor.

### Mechanism 2
- Claim: The proposed two-step evaluation methodology can reveal specific knowledge gaps in LLM medical diagnosis capabilities.
- Mechanism: By first evaluating the LLM's responses and then conducting domain-specific analysis (IMA, NER, KGs), the methodology can pinpoint where the LLM struggles and what types of knowledge it lacks.
- Core assumption: The combination of image metadata analysis, named entity recognition, and knowledge graph construction can effectively map the LLM's knowledge structure and identify weaknesses.
- Evidence anchors:
  - [abstract] "Weaknesses of GPT-4-Vision-Preview were revealed on specific knowledge paths, leading to a further understanding of its shortcomings in specific areas."
  - [section] "In the second step, the Rules Of Conduct are defined, which are the essential parts of the prompt enginneering, which requests the specific format of analysis and response from the chosen LLM."
- Break condition: If the LLM's knowledge is too sparse or fragmented, the knowledge graphs may not reveal meaningful patterns.

### Mechanism 3
- Claim: The evaluation methodology is generalizable to other LLMs and medical domains.
- Mechanism: The structured approach of multimodal evaluation followed by domain-specific analysis can be applied to any LLM with vision capabilities and any medical specialty.
- Core assumption: The core components of the methodology (structured MCQs, IMA, NER, KGs) are sufficiently flexible to adapt to different LLMs and medical domains.
- Evidence anchors:
  - [abstract] "Our methodology and findings are not limited to the use of GPT-4-Vision-Preview, but a similar approach can be followed to evaluate the usefulness and accuracy of other LLMs and, thus, improve their use with further optimization."
  - [corpus] Weak evidence; the corpus does not provide examples of the methodology being applied to other LLMs or domains.
- Break condition: If other medical domains have significantly different diagnostic processes or if other LLMs lack the necessary vision capabilities.

## Foundational Learning

- Concept: Medical image interpretation
  - Why needed here: The LLM must correctly interpret medical images to make accurate diagnoses.
  - Quick check question: What are the key features in a chest X-ray that would indicate congestive heart failure?

- Concept: Named Entity Recognition in medical texts
  - Why needed here: NER is used to identify and categorize medical entities in the LLM's responses and solution explanations.
  - Quick check question: What are the common entity types in medical NER (e.g., diseases, symptoms, body parts)?

- Concept: Knowledge graph construction and analysis
  - Why needed here: KGs are used to visualize the LLM's knowledge structure and identify areas of weakness.
  - Quick check question: How do you calculate the density of a knowledge graph, and what does a low density indicate?

## Architecture Onboarding

- Component map:
  - Data processing: MCQ selection and formatting
  - LLM interaction: Structured prompts with images and rules of conduct
  - Evaluation: Comparison of LLM responses to correct answers
  - Domain-specific analysis: IMA, NER, and KG construction

- Critical path:
  1. Select and format MCQs with images
  2. Interact with LLM using structured prompts
  3. Evaluate LLM responses
  4. Conduct domain-specific analysis
  5. Identify knowledge gaps and optimization opportunities

- Design tradeoffs:
  - Using MCQs limits the evaluation to predefined scenarios but ensures consistency and allows for direct comparison to expert answers.
  - The methodology relies on the quality and comprehensiveness of the MCQ dataset; limited coverage of certain pathologies may lead to incomplete evaluation.

- Failure signatures:
  - Low overall accuracy suggests fundamental issues with the LLM's medical knowledge or multimodal integration.
  - Specific patterns of errors (e.g., consistently incorrect in certain organ systems) indicate targeted knowledge gaps.

- First 3 experiments:
  1. Evaluate the LLM on a small subset of MCQs to establish a baseline accuracy.
  2. Conduct IMA on the LLM's incorrect responses to identify patterns in the types of images or pathologies that are problematic.
  3. Perform NER on the LLM's correct responses to understand what types of medical entities it can accurately identify and associate.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the LLM's performance in cardiovascular pathology, particularly in diagnosing conditions like atherosclerosis and aneurysms, be improved?
- Basis in paper: [explicit] The paper reveals weaknesses in GPT-4-Vision-Preview for cardiovascular-related diagnoses, with incorrect responses linked to specific conditions like atherosclerosis and aneurysms.
- Why unresolved: The paper identifies the weaknesses but does not provide a detailed plan for improving the LLM's performance in these specific areas.
- What evidence would resolve it: Evidence showing improved accuracy in cardiovascular diagnoses after implementing targeted fine-tuning or retraining strategies based on the identified weaknesses.

### Open Question 2
- Question: What specific strategies can be employed to enhance the LLM's understanding of complex medical images, particularly those related to the skin and endocrine system?
- Basis in paper: [explicit] The paper highlights inconsistencies in the LLM's responses to images related to skin and endocrine systems.
- Why unresolved: While the paper identifies the problem areas, it does not propose specific strategies to address these weaknesses.
- What evidence would resolve it: Evidence demonstrating improved accuracy in interpreting skin and endocrine-related images after applying targeted image analysis techniques or additional training data.

### Open Question 3
- Question: How can the integration of Knowledge Graphs (KGs) be optimized to improve the LLM's performance in medical diagnosis?
- Basis in paper: [explicit] The paper uses KGs to analyze the LLM's performance but suggests that further optimization is needed.
- Why unresolved: The paper constructs KGs but does not explore how to optimize their integration for better diagnostic accuracy.
- What evidence would resolve it: Evidence showing enhanced diagnostic accuracy after optimizing the integration of KGs with the LLM's knowledge base.

## Limitations
- The evaluation methodology relies on structured MCQs that may not fully capture the complexity of real-world medical diagnosis scenarios.
- The study only evaluates GPT-4-Vision-Preview, limiting generalizability to other LLMs and medical specialties.
- The confidence in results is medium due to the limited dataset size and single medical specialty focus.

## Confidence
- GPT-4-Vision-Preview's performance on Pathology MCQs: Medium confidence
- The effectiveness of the two-step evaluation methodology: Medium confidence
- The generalizability of the methodology to other LLMs and medical domains: Low confidence

## Next Checks
1. Validate the methodology's effectiveness on a larger, more diverse dataset of medical MCQs spanning multiple specialties and difficulty levels.
2. Apply the evaluation methodology to at least two other state-of-the-art multimodal LLMs (e.g., Claude 3, Gemini) to assess its generalizability and identify any model-specific strengths or weaknesses.
3. Conduct a qualitative analysis of the LLM's responses to open-ended medical queries, comparing its performance on structured MCQs versus free-form clinical scenarios to better understand the limitations of the current evaluation approach.