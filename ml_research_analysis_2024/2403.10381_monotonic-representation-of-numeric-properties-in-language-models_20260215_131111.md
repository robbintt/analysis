---
ver: rpa2
title: Monotonic Representation of Numeric Properties in Language Models
arxiv_id: '2403.10381'
source_url: https://arxiv.org/abs/2403.10381
tags:
- numeric
- properties
- representations
- year
- what
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work introduces a method to identify and edit low-dimensional\
  \ subspaces in language models that encode numeric properties (e.g., birth years,\
  \ population) monotonically. Using partial least squares regression, the authors\
  \ find that such properties are represented in 2\u20136 dimensional subspaces across\
  \ models (Llama 2 7B/13B, Falcon 7B, Mistral 7B)."
---

# Monotonic Representation of Numeric Properties in Language Models

## Quick Facts
- arXiv ID: 2403.10381
- Source URL: https://arxiv.org/abs/2403.10381
- Reference count: 40
- Authors: Benjamin Heinzerling; Kentaro Inui
- Primary result: Numeric properties (e.g., birth years, population) are encoded in low-dimensional, monotonic subspaces in language models, enabling predictable edits via activation patching

## Executive Summary
This work introduces a method to identify and edit low-dimensional subspaces in language models that encode numeric properties (e.g., birth years, population) monotonically. Using partial least squares regression, the authors find that such properties are represented in 2–6 dimensional subspaces across models (Llama 2 7B/13B, Falcon 7B, Mistral 7B). By causally intervening via activation patching, they show that edits along these directions yield predictable, monotonic changes in model output (e.g., shifting expressed birth years). This demonstrates that LMs learn to represent numeric properties in a way reflecting their natural structure, with implications for interpretability and control.

## Method Summary
The authors develop a pipeline to identify low-dimensional subspaces that encode numeric properties in language models. They use partial least squares (PLS) regression to find directions in the model's activation space that correlate with numeric ground truth values extracted from Wikipedia tables. For each property (e.g., birth year, population), they train a PLS model on activation vectors from the middle layer of the transformer. The resulting subspace directions are then used for causal interventions via activation patching, where they replace the original activations with edited versions along the identified direction. This intervention is designed to produce monotonic changes in the expressed numeric value in the model's output.

## Key Results
- Numeric properties are encoded in low-dimensional subspaces (2–6 dimensions) across multiple models and properties
- Activation patching along these subspaces yields predictable, monotonic changes in model output (e.g., birth years)
- The method generalizes across different model architectures (Llama 2, Falcon, Mistral) and numeric properties

## Why This Works (Mechanism)
The authors hypothesize that language models learn to represent numeric properties in a way that reflects their natural, ordered structure. By identifying the low-dimensional subspaces that encode these properties, they can manipulate the model's representations to produce controlled, monotonic changes in output. The PLS regression identifies the directions in activation space that best correlate with the ground truth numeric values, and the activation patching intervention allows them to edit these representations causally.

## Foundational Learning
- **Partial Least Squares (PLS) Regression**: A dimensionality reduction technique that finds directions in the input space that maximize covariance with the target variable. Needed to identify low-dimensional subspaces encoding numeric properties. Quick check: Verify that the PLS components capture meaningful variance in the target variable.
- **Activation Patching**: A causal intervention technique where activations at a specific layer are replaced with edited versions. Needed to test whether the identified subspaces are causally linked to model output. Quick check: Confirm that patching affects model output as expected.
- **Monotonicity**: The property that changes in the input lead to consistent changes in the output. Needed to evaluate whether edits along the identified subspaces produce predictable changes. Quick check: Measure the correlation between the magnitude of the edit and the change in output.
- **Ground Truth Extraction**: The process of extracting numeric values from external sources (e.g., Wikipedia tables) to train the regression models. Needed to provide the target values for PLS regression. Quick check: Validate the accuracy and consistency of the extracted ground truth data.
- **Representation Learning**: The ability of models to encode meaningful information in their internal representations. Needed to understand how numeric properties are represented in the model. Quick check: Analyze the distribution of activations along the identified subspaces.
- **Causal Inference**: The process of determining cause-and-effect relationships in data. Needed to establish that the identified subspaces causally influence model output. Quick check: Use ablation studies to confirm the causal link.

## Architecture Onboarding
- **Component Map**: Wikipedia table extraction -> Model activation collection -> PLS regression -> Subspace identification -> Activation patching -> Output analysis
- **Critical Path**: The PLS regression step is critical for identifying the low-dimensional subspaces that encode numeric properties. Without accurate identification of these subspaces, the activation patching interventions would not produce the desired monotonic changes.
- **Design Tradeoffs**: The choice of the middle layer for activation collection balances the need for semantic information with the desire to avoid noise from later layers. The use of PLS regression trades off interpretability for computational efficiency compared to more complex methods like sparse coding.
- **Failure Signatures**: If the identified subspaces are not low-dimensional, the activation patching interventions may not produce monotonic changes. If the ground truth data is noisy or inconsistent, the PLS regression may identify spurious correlations.
- **First Experiments**:
  1. Verify that the PLS regression identifies meaningful directions in activation space by analyzing the variance explained by the components.
  2. Confirm that the activation patching interventions produce monotonic changes in a controlled setting with synthetic data.
  3. Test the generalizability of the method by applying it to a new numeric property not seen during training.

## Open Questions the Paper Calls Out
None

## Limitations
- The study focuses on a limited set of numeric properties and model architectures, leaving open the question of generalization.
- The methodology relies on explicit numeric representation in model activations, which may not hold for all numeric reasoning tasks.
- The real-world impact of activation patching interventions on complex, multi-step reasoning tasks remains unclear.

## Confidence
- **High** for the claim that numeric properties can be represented in low-dimensional subspaces
- **Medium** for the claim that these representations are consistently monotonic across models and properties
- **Low** for the claim that activation patching interventions generalize to complex, real-world scenarios

## Next Checks
1. Test the subspace identification and editing methodology on additional numeric properties and larger or more diverse model architectures.
2. Evaluate whether the identified subspaces remain interpretable and monotonic when applied to out-of-distribution or adversarial prompts.
3. Assess the broader impact of activation patching interventions on model behavior in multi-step reasoning tasks or open-ended generation scenarios.