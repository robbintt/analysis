---
ver: rpa2
title: 'Deep Multimodal Learning with Missing Modality: A Survey'
arxiv_id: '2409.07825'
source_url: https://arxiv.org/abs/2409.07825
tags:
- missing
- modality
- modalities
- methods
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey comprehensively reviews Deep Multimodal Learning with
  Missing Modality (MLMM), a critical challenge in AI where some data modalities are
  absent due to sensor limitations, privacy concerns, or data loss. The paper categorizes
  MLMM methods into four types: modality imputation (composition/generation), representation-focused
  (coordinated/composition/generation), architecture-focused (attention/distillation/graph
  learning/MLLMs), and model combinations (ensemble/dedicated training/discrete scheduler).'
---

# Deep Multimodal Learning with Missing Modality: A Survey

## Quick Facts
- arXiv ID: 2409.07825
- Source URL: https://arxiv.org/abs/2409.07825
- Reference count: 40
- This survey comprehensively reviews Deep Multimodal Learning with Missing Modality (MLMM), categorizing methods and analyzing 315 papers from 2012-2025

## Executive Summary
This survey addresses the critical challenge of Deep Multimodal Learning with Missing Modality (MLMM), where AI systems must operate when some data modalities are absent due to sensor limitations, privacy concerns, or data loss. The paper provides a comprehensive taxonomy of MLMM methods, organizing them into four main categories: modality imputation, representation-focused, architecture-focused, and model combination approaches. The survey systematically analyzes 315 papers published between 2012 and 2025, identifying trends in methodology, application domains, and open challenges in the field.

The authors find that 75.5% of MLMM methods focus on recovering missing modality information, with the majority (45.8%) operating at the intermediate representation stage. The survey covers key application areas including affective computing, medical imaging, information retrieval, remote sensing, pervasive computing, and robotic vision. It also identifies critical open challenges such as developing efficient methods, handling realistic missingness patterns, establishing comprehensive benchmarks, and managing multimodal streaming data.

## Method Summary
The survey categorizes MLMM methods into four main types: modality imputation approaches (composition and generation), representation-focused methods (coordinated, composition, and generation), architecture-focused techniques (attention mechanisms, distillation, graph learning, and multimodal large language models), and model combination strategies (ensemble methods, dedicated training, and discrete schedulers). The analysis is based on a systematic review of 315 papers published from 2012 to 2025, with methodology distribution showing 48.3% at input level, 45.8% at intermediate representation level, and 6.0% at decision level. The authors also examine application domains, open challenges, and future directions for MLMM research.

## Key Results
- 75.5% of MLMM methods focus on recovering missing modality information
- 48.3% of methods operate at the input level, 45.8% at intermediate representation level, and 6.0% at decision level
- The survey identifies six key application domains: affective computing, medical imaging, information retrieval, remote sensing, pervasive computing, and robotic vision
- Major open challenges include efficient methods, realistic missingness patterns, benchmarking, and multimodal streaming data handling

## Why This Works (Mechanism)
Deep Multimodal Learning with Missing Modality works by leveraging the inherent redundancy and complementarity between different data modalities. When one modality is missing, the system can reconstruct or approximate the missing information using available modalities through various mechanisms including generative models, attention-based fusion, and knowledge distillation. The approach exploits correlations between modalities learned during training to maintain performance even when some inputs are unavailable.

## Foundational Learning
- **Modality Imputation**: Generation of missing data from available modalities through composition or generation techniques - needed for direct data reconstruction
- **Representation Learning**: Creation of unified feature spaces where missing modalities can be inferred from available ones - needed for efficient missing data handling
- **Attention Mechanisms**: Focus on relevant features across modalities while handling missing data - needed for adaptive feature weighting
- **Knowledge Distillation**: Transfer of knowledge from complete to incomplete data scenarios - needed for leveraging fully-observed training data
- **Graph Learning**: Modeling relationships between modalities as graph structures - needed for capturing complex modality dependencies
- **Multimodal Fusion**: Integration of information from multiple sources - needed for comprehensive understanding

## Architecture Onboarding
**Component Map**: Input Modalities -> Feature Extractors -> Fusion Layer -> Missing Modality Handler -> Output Layer
**Critical Path**: The fusion layer and missing modality handler are critical, as they directly determine how well the system can handle absent inputs while maintaining performance
**Design Tradeoffs**: Real-time performance vs. reconstruction accuracy, model complexity vs. generalization, computational efficiency vs. missing data handling capability
**Failure Signatures**: Performance degradation when multiple modalities are missing simultaneously, sensitivity to specific missing modality combinations, overfitting to training missing patterns
**First Experiments**:
1. Test modality imputation accuracy on benchmark datasets with controlled missing patterns
2. Evaluate representation learning effectiveness across different missing ratios
3. Assess architecture performance on streaming data with dynamic modality availability

## Open Questions the Paper Calls Out
- How to develop more efficient MLMM methods that reduce computational overhead
- How to handle realistic missingness patterns that occur in real-world scenarios
- What standardized benchmarks and evaluation metrics are needed for comprehensive MLMM assessment
- How to effectively process multimodal streaming data with variable modality availability
- How to improve robustness when multiple modalities are missing simultaneously

## Limitations
- The taxonomy may oversimplify complex hybrid approaches that span multiple categories
- Selection criteria for the 315 papers analyzed are not fully transparent, potentially introducing publication bias
- The categorization of methods into the four proposed types may not capture all nuances of MLMM approaches

## Confidence
- Taxonomy Analysis: Medium - based on authors' interpretation of methodological descriptions
- Methodology Coverage: Medium - relies on systematic review but may miss emerging approaches
- Application Domain Analysis: High - systematic identification of key application areas
- Open Challenges Identification: Medium - represents authors' synthesis of literature trends

## Next Checks
1. Conduct independent validation of the proposed taxonomy by having multiple researchers categorize random samples of MLMM papers to assess inter-rater reliability
2. Perform empirical comparison of representative methods from each category on standardized datasets with controlled missing modality patterns
3. Develop and release a benchmark suite with standardized evaluation metrics and realistic missingness patterns across multiple application domains