---
ver: rpa2
title: Round Trip Translation Defence against Large Language Model Jailbreaking Attacks
arxiv_id: '2402.13517'
source_url: https://arxiv.org/abs/2402.13517
tags:
- llms
- attacks
- adversarial
- attack
- prompts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes Round Trip Translation (RTT) as a novel defense
  against social-engineered jailbreaking attacks on large language models (LLMs).
  The key idea is to paraphrase and generalize adversarial prompts by translating
  them through multiple non-Indo-European languages and back to English, making it
  easier for LLMs to detect harmful behavior.
---

# Round Trip Translation Defence against Large Language Model Jailbreaking Attacks

## Quick Facts
- arXiv ID: 2402.13517
- Source URL: https://arxiv.org/abs/2402.13517
- Reference count: 5
- Key outcome: RTT3d achieves over 70% mitigation on PAIR attacks and provides first defense against MathAttack with 40% mitigation

## Executive Summary
This paper introduces Round Trip Translation (RTT) as a novel defense against social-engineered jailbreaking attacks on large language models. The method translates adversarial prompts through multiple non-Indo-European languages and back to English, effectively paraphrasing and generalizing the terminology to make harmful content more detectable. Experiments show RTT3d achieves over 70% attack mitigation on PAIR attacks and provides the first defense against MathAttack, while maintaining performance on benign queries. The approach is lightweight, transferable across different LLM architectures, and does not require model modifications.

## Method Summary
The Round Trip Translation defense works by translating adversarial prompts through three non-Indo-European languages using Google Translate API, then back to English. This process paraphrases the original prompt and generalizes specific terminology, making it easier for LLM safety filters to detect harmful content. The method is applied as a pre-processing step before input reaches the LLM, making it architecture-agnostic and requiring no model modifications. The approach uses a combination of languages from different linguistic families to maximize semantic transformation while preserving core meaning.

## Key Results
- RTT3d achieves over 70% attack mitigation rate on PAIR attacks
- Provides first defense against MathAttack with 40% mitigation rate
- Maintains LLM performance on benign queries from GSM8K dataset

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RTT reduces adversarial prompt effectiveness by paraphrasing and generalizing terminology
- Mechanism: Translating through multiple non-Indo-European languages forces text to use more common, general terms that are easier for LLM safety filters to detect
- Core assumption: Translation through structurally different languages will generalize specific terminology without losing semantic meaning
- Evidence anchors: Corpus shows 20% fewer non-Oxford 3000 words in RTT prompts, suggesting more general terminology usage

### Mechanism 2
- Claim: Non-Indo-European languages provide better generalization than random languages
- Mechanism: Languages from different linguistic families force more semantic transformation during translation
- Core assumption: Structural differences between language families cause more semantic drift during translation
- Evidence anchors: RTT3d achieves same ASR reduction as RTT5r with lower standard deviation

### Mechanism 3
- Claim: RTT is transferable across different LLM architectures without requiring model modifications
- Mechanism: As pre-processing technique, RTT operates on input text before it reaches LLM
- Core assumption: Input preprocessing can effectively defend against attacks regardless of underlying LLM architecture
- Evidence anchors: RTT3d performs consistently well across Vicuna, GPT4, Llama2, and Palm2 with average 70% mitigation rate

## Foundational Learning

- Concept: Adversarial prompt engineering
  - Why needed here: Understanding how social-engineered attacks work is crucial to designing effective defenses
  - Quick check question: What makes social-engineered attacks particularly difficult to defend against compared to other attack types?

- Concept: Language family classification
  - Why needed here: Choosing appropriate languages for RTT requires understanding linguistic relationships
  - Quick check question: Why would non-Indo-European languages potentially provide better generalization than Indo-European ones?

- Concept: Machine translation quality metrics
  - Why needed here: Translation quality directly impacts RTT effectiveness in preserving semantic meaning
  - Quick check question: How might poor translation quality affect the defense mechanism's ability to generalize harmful content?

## Architecture Onboarding

- Component map: Input text → RTT preprocessing → LLM safety filter → Response generation → Monitoring and evaluation system
- Critical path: Input text → RTT preprocessing → LLM safety filter → Response generation
- Design tradeoffs: Translation quality vs. processing speed; number of languages vs. semantic preservation
- Failure signatures: Increased false positives (benign queries flagged as harmful), reduced attack mitigation rates, performance degradation on benign inputs
- First 3 experiments:
  1. Test RTT on a small set of known adversarial prompts across different LLMs
  2. Measure semantic preservation by comparing original and RTT-processed benign queries
  3. Evaluate performance impact on benign input using benchmark datasets like GSM8K

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of RTT vary when using different translation algorithms beyond Google Translate?
- Basis in paper: The paper mentions Google Translate API was used for its high accuracy but notes results may vary with different translation algorithms
- Why unresolved: Only tested with Google Translate, effectiveness of other translation services remains unexplored
- What evidence would resolve it: Conducting experiments with various translation algorithms and comparing their impact on attack mitigation rates and benign query performance

### Open Question 2
- Question: Can RTT maintain its effectiveness when applied to adversarial prompts in languages other than English?
- Basis in paper: The paper suggests future work includes verifying if RTT can maintain performance on non-English adversarial prompts
- Why unresolved: Experiments conducted only on English prompts, effectiveness on multilingual adversarial prompts untested
- What evidence would resolve it: Testing RTT on adversarial prompts in multiple languages and measuring attack mitigation success rate across different language models

### Open Question 3
- Question: What is the impact of ensembling multiple RTT prompts on attack mitigation compared to using a single RTT prompt?
- Basis in paper: The paper mentions future work could involve creating aggregated processed prompt similar to SmoothLLM by ensembling multiple RTT prompts
- Why unresolved: Current RTT method uses single round-trip translation process, benefits of combining multiple RTT outputs unexplored
- What evidence would resolve it: Implementing ensemble of multiple RTT prompts and comparing its attack mitigation rate and impact on benign queries against single RTT approach

## Limitations

- Language Selection Uncertainty: Paper specifies "3 non-Indo-European languages" but doesn't identify which specific languages were used
- Attack Dataset Specificity: Limited details about complete adversarial prompt datasets used for evaluation
- Translation Quality Dependency: No metrics or analysis of translation quality degradation during round-trip process

## Confidence

- High Confidence: Basic premise that paraphrasing adversarial prompts reduces attack effectiveness; consistent mitigation across multiple LLM architectures
- Medium Confidence: Claim that non-Indo-European languages provide better generalization than random languages
- Low Confidence: Assertion that RTT3d is "first defense" against MathAttack

## Next Checks

1. **Language Family Sensitivity Analysis**: Test RTT with different combinations of non-Indo-European languages to determine which language families provide optimal attack mitigation while preserving semantic meaning

2. **Translation Quality Impact Study**: Measure semantic drift and translation quality degradation for each round-trip translation using metrics like BLEU scores and human evaluation, correlating translation quality with attack mitigation effectiveness

3. **Cross-Attack Generalization Test**: Apply RTT3d to broader range of attack types beyond PAIR and MathAttack, including chain-of-thought attacks, role-playing jailbreaks, and prompt injection attacks to evaluate defense's generalizability across attack landscape