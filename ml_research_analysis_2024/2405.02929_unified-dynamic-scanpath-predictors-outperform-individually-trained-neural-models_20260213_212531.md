---
ver: rpa2
title: Unified Dynamic Scanpath Predictors Outperform Individually Trained Neural
  Models
arxiv_id: '2405.02929'
source_url: https://arxiv.org/abs/2405.02929
tags:
- integration
- dataset
- fixation
- fusion
- individual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of predicting individual human
  scanpaths (gaze trajectories) in social videos, where personalized viewing patterns
  can significantly differ from group-based saliency models. The authors propose modifying
  a dynamic saliency model (GASP) to predict individual scanpaths by incorporating
  a fixation history module that maintains prior gaze points.
---

# Unified Dynamic Scanpath Predictors Outperform Individually Trained Neural Models

## Quick Facts
- **arXiv ID**: 2405.02929
- **Source URL**: https://arxiv.org/abs/2405.02929
- **Reference count**: 40
- **Primary result**: Unified model with fixation history performs as well as or better than individually trained models for scanpath prediction

## Executive Summary
This paper addresses the challenge of predicting individual human scanpaths in social videos, where personalized viewing patterns can differ significantly from group-based saliency models. The authors propose modifying the GASP dynamic saliency model by incorporating a fixation history module that maintains prior gaze points, enabling a single unified model to distinguish between observers' trajectories. Experiments compare late integration versus early fusion architectures and unified versus individual models using datasets of conversational videos. Results demonstrate that the unified model with fixation history performs comparably to or better than individually trained models, especially when trained on larger datasets, with late integration showing particular robustness for multi-step-ahead predictions.

## Method Summary
The method involves modifying the GASP dynamic saliency model by adding a fixation history module that maintains a queue of blurred fixation maps representing past gaze points. The model processes multiple social cues including video, audio, facial expressions, and gaze direction through modality encoders, then applies a Directed Attention Module (DAM) to gate weaker modalities. Two integration architectures are compared: early fusion using Attentive Recurrent GMU and late integration using concatenation followed by ALSTM. The unified model is trained on all observers' scanpaths simultaneously, while individual models are trained separately for each observer. Training uses negative log-likelihood loss and KL divergence with Adam optimizer, and evaluation employs AUCJ and NSS metrics for 1 vs 1 and 1 vs infinity comparisons.

## Key Results
- Unified model with fixation history performs on par with or better than individually trained models
- Late integration architecture outperforms early fusion when trained on larger datasets
- Fixation history is sufficient to differentiate individual scanpaths without needing separate models per observer
- Larger datasets stabilize multi-step-ahead predictions by reducing error accumulation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: A unified model with fixation history can match or exceed individually trained models for scanpath prediction.
- **Mechanism**: Fixation history acts as a sufficient prior to differentiate individual trajectories, allowing the unified model to learn both universal attention patterns and personalized attention.
- **Core assumption**: Scanpaths are sufficiently distinct across individuals that fixation history alone can disambiguate them.
- **Evidence anchors**: Abstract states unified model training is possible with fixation history; section reports unified model performs on par or better than individual models.
- **Break condition**: If fixation histories of different individuals are too similar, or if individual differences are dominated by transient factors.

### Mechanism 2
- **Claim**: Late integration architectures outperform early fusion for scanpath prediction on larger datasets.
- **Mechanism**: Late integration allows the model to first process individual modalities with their own recurrent pathways, then fuse them, preserving richer sequential information before integration.
- **Core assumption**: Sequential processing of modalities before fusion captures temporal dependencies better than early concatenation.
- **Evidence anchors**: Section reports late neural integration surpasses early fusion on large datasets; late integration consistently yields better results across both datasets.
- **Break condition**: On very small datasets, early fusion may suffice or even outperform due to parameter efficiency.

### Mechanism 3
- **Claim**: Larger datasets stabilize multi-step-ahead predictions by exposing the model to more variability.
- **Mechanism**: Training on more samples reduces the impact of error accumulation in autoregressive predictions, as the model has seen a wider distribution of gaze transitions.
- **Core assumption**: More diverse training data leads to better generalization for longer prediction horizons.
- **Evidence anchors**: Results indicate unified integration model exhibits higher robustness as number of steps ahead increases; hypothesis that models trained on more samples are less affected by error accumulation.
- **Break condition**: If dataset size increases but diversity does not, the stabilizing effect may not materialize.

## Foundational Learning

- **Concept: Fixation history as a temporal prior**
  - Why needed here: Scanpaths are inherently sequential; without remembering where an observer looked before, the model cannot predict where they will look next.
  - Quick check question: If you remove the fixation history module, what does the model predict and why does performance degrade?

- **Concept: Saliency vs. scanpath prediction distinction**
  - Why needed here: Saliency models predict group attention maps; scanpath models predict individual fixation sequences. Misunderstanding this leads to incorrect architectural choices.
  - Quick check question: How does the loss function differ when training for saliency vs. scanpath prediction in this framework?

- **Concept: Early vs. late fusion in multimodal models**
  - Why needed here: The choice affects how temporal dependencies are captured and how modality-specific features are integrated.
  - Quick check question: In this model, which fusion strategy preserves more temporal information and why?

## Architecture Onboarding

- **Component map**: Input modalities → Modality encoders → DAM → Fixation history integration → Sequential integration → Output prediction
- **Critical path**: Input modalities → Modality encoders → DAM → Fixation history integration → Sequential integration → Output prediction
- **Design tradeoffs**: Early fusion uses fewer parameters and is faster but may lose temporal nuance; late integration is better for long-range dependencies but requires more data and parameters; larger fixation history queues capture more context but increase memory and may introduce noise
- **Failure signatures**: Uniform predictions across individuals indicate fixation history not being used; overfitting to training observers suggests insufficient regularization or too small a dataset; poor multi-step-ahead performance indicates error accumulation needing more robust integration
- **First 3 experiments**: 1) Ablate fixation history to compare unified vs individual models and confirm history is the disambiguation prior; 2) Swap early and late integration to verify architecture choice based on dataset size; 3) Vary fixation history window size to test impact on individual differentiation and prediction stability

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Is fixation history a sufficient prior for distinguishing individual scanpath trajectories in social videos?
- **Basis in paper**: The paper states fixation history is the only prior available to differentiate scanpath trajectories and infers it is sufficient since unified model scores are on par or better than individual models.
- **Why unresolved**: While the unified model performs comparably to individual models with fixation history, the paper does not definitively prove fixation history is the only mechanism enabling this distinction.
- **What evidence would resolve it**: Testing unified models with alternative priors (e.g., observer IDs, personalized embeddings) while keeping fixation history fixed.

### Open Question 2
- **Question**: Does the late integration architecture maintain superiority over early fusion as the number of multi-step-ahead predictions increases beyond what was tested?
- **Basis in paper**: The paper reports late integration exhibits higher robustness as number of steps ahead increases and tends to outperform early fusion over longer horizons.
- **Why unresolved**: The paper tested up to t' + 4 steps ahead but did not explore whether the late integration advantage persists at much longer horizons.
- **What evidence would resolve it**: Evaluating both architectures at t' + 10, t' + 20, or even t' + 50 steps ahead.

### Open Question 3
- **Question**: How does the variability in starting context window position affect scanpath prediction performance?
- **Basis in paper**: The paper acknowledges that not every last frame preceding the prediction is equally challenging and that context containing few gaze shifts is inherently easier than contexts with multiple shifts.
- **Why unresolved**: The paper recognizes this variability but does not systematically test how different context window positions impact model performance.
- **What evidence would resolve it**: Conducting controlled experiments where context windows are systematically varied in terms of gaze shift density and position within the video sequence.

## Limitations
- The paper lacks direct comparisons with other unified scanpath models in the literature
- Fixation history mechanism has not been validated across diverse video types beyond social conversations
- Dataset size differences between MVV A and FindWho may confound some architectural comparisons

## Confidence
- **High**: Fixation history enables unified models to match individual models
- **Medium**: Late integration outperforms early fusion on larger datasets
- **Medium**: Multi-step-ahead predictions benefit from larger datasets

## Next Checks
1. **Cross-dataset generalization test**: Train unified models on MVV A and evaluate on FindWho (and vice versa) to quantify transfer capability and domain specificity of fixation history learning.

2. **Fixation history sensitivity analysis**: Systematically vary fixation history queue length (T' = 5, 10, 20) and evaluate impact on individual discrimination and prediction accuracy across both integration architectures.

3. **Architecture scaling study**: Train early and late integration models on progressively larger subsets of MVV A (10%, 25%, 50%, 100%) to quantify the dataset size threshold where late integration consistently outperforms early fusion.