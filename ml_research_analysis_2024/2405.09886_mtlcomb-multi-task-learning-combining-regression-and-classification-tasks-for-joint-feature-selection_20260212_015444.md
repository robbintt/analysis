---
ver: rpa2
title: 'MTLComb: multi-task learning combining regression and classification tasks
  for joint feature selection'
arxiv_id: '2405.09886'
source_url: https://arxiv.org/abs/2405.09886
tags:
- mtlcomb
- sepsis
- tasks
- data
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MTLComb is a multi-task learning algorithm for combining regression
  and classification tasks with joint feature selection. The key challenge addressed
  is the misalignment of regularization paths between task types due to different
  loss magnitudes, leading to biased feature selection.
---

# MTLComb: multi-task learning combining regression and classification tasks for joint feature selection

## Quick Facts
- arXiv ID: 2405.09886
- Source URL: https://arxiv.org/abs/2405.09886
- Reference count: 18
- Primary result: Analytical loss weighting scheme enables unbiased joint feature selection across mixed regression and classification tasks in multi-task learning

## Executive Summary
MTLComb addresses the challenge of joint feature selection when combining regression and classification tasks in multi-task learning. The key innovation is an analytical loss weighting scheme that balances the regularization paths between task types, preventing bias in feature selection caused by differing loss magnitudes. Using accelerated proximal gradient descent with adaptive Lipschitz estimation, MTLComb achieves provable convergence while maintaining computational efficiency. The method demonstrates superior prediction performance and feature selection accuracy compared to baselines, particularly in high-dimensional settings, while also providing greater biological interpretability in real biomedical applications.

## Method Summary
MTLComb combines regression and classification tasks through a joint feature selection framework using an L2,1 penalty plus mean-regularization. The core innovation is an analytical loss weighting scheme that normalizes the gradient magnitudes of different loss types (regression weighted by 0.5, classification weighted by 2) to align their regularization paths. The optimization employs accelerated proximal gradient descent with adaptive Lipschitz constant estimation, ensuring provable convergence. Cross-validation determines the regularization parameter Î», while Î± and Î² are set as constants. The method is specifically designed for linear models and high-dimensional problems where shared feature selection across heterogeneous task types is desired.

## Key Results
- Superior prediction performance and feature selection accuracy compared to baselines in simulated data, especially in high-dimensional settings
- Competitive cross-cohort prediction performance in sepsis case study with increased model stability
- Higher marker selection reproducibility and greater biological interpretability in schizophrenia case study

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Loss weighting scheme analytically balances regression and classification task losses to align regularization paths.
- Mechanism: By weighting classification loss by 2 and regression loss by 0.5, the magnitudes of the gradients are normalized so that both tasks contribute equally to the joint feature selection process during optimization.
- Core assumption: The optimal weighting constants can be determined analytically rather than learned adaptively.
- Evidence anchors:
  - [abstract] "We propose a provable loss weighting scheme that analytically determines the optimal weights for balancing regression and classification tasks."
  - [section] "By weighting Î–(ð‘Š) with 2 and R(W) with 0.5, we can quantify an identical form of lam_max satisfying both regression and classification tasks."
- Break condition: If the losses have distributions that are not approximately symmetric or if the data generating process violates linearity assumptions, the analytic weights may no longer align the paths.

### Mechanism 2
- Claim: Accelerated proximal gradient descent with adaptive Lipschitz estimation yields provable convergence and efficiency.
- Mechanism: The algorithm iteratively solves a quadratic approximation of the smooth part plus the non-smooth L2,1 penalty, using line search to estimate the Lipschitz constant and Nesterov momentum to accelerate convergence.
- Core assumption: The objective function is convex and the non-smooth part is separable across features.
- Evidence anchors:
  - [section] "We adopt the accelerated proximal gradient descent method to approximate the solution, yielding state-of-art efficiency."
  - [section] "Problem (3) is the second-order approximation of ð¹(. ) given the current standing point ð‘Šð‘–."
- Break condition: If the loss surfaces are highly non-convex due to strong feature correlations or if the data dimensionality is very low, convergence guarantees may weaken.

### Mechanism 3
- Claim: Joint L2,1 penalty plus mean-regularization promotes both sparsity and cross-task consistency in selected features.
- Mechanism: The L2,1 norm encourages rows of the coefficient matrix to be zero (joint sparsity across tasks), while the mean-regularized term (||WG||Â²â‚‚) encourages coefficients for the same feature to be similar across tasks, ensuring that selected features are shared predictors.
- Core assumption: The underlying true model has shared features across tasks.
- Evidence anchors:
  - [section] "MTLComb is designed for learning shared predictors among tasks of mixed types."
  - [section] "||ð‘Š||2,1 = âˆ‘ âˆš||ð‘¤(ð‘—)||2 2ð‘ ð‘—=1 is a sparse penalty term to promote the joint feature selection."
- Break condition: If tasks are unrelated or have disjoint relevant feature sets, forcing shared sparsity will hurt performance.

## Foundational Learning

- Concept: Regularization paths and their dependence on loss magnitude.
  - Why needed here: Understanding how Î» controls feature selection and how different losses create misaligned paths is key to grasping why analytic weighting solves the bias problem.
  - Quick check question: If classification loss is much larger than regression loss, which task will dominate the joint feature selection at high Î»?

- Concept: Proximal gradient methods and the role of the Lipschitz constant.
  - Why needed here: The solver relies on approximating the smooth part quadratically and using adaptive step sizes; knowing why this works ensures correct implementation.
  - Quick check question: What happens to the proximal step if the Lipschitz constant is underestimated?

- Concept: Multi-task learning with shared feature selection.
  - Why needed here: The goal is to find biomarkers relevant across heterogeneous tasks; understanding the assumptions behind joint sparsity is essential.
  - Quick check question: If tasks are completely independent, will joint sparsity still be beneficial?

## Architecture Onboarding

- Component map: Data preprocessing -> loss weighting (fixed) -> accelerated proximal gradient descent with adaptive Lipschitz estimation -> cross-validation for Î» -> model evaluation
- Critical path: Feature matrix preparation -> analytic weighting constants set -> optimization loop (proximal step + momentum + line search) -> Î» tuning via CV -> final model selection
- Design tradeoffs: Fixed analytic weights give provable alignment but may be suboptimal if loss distributions shift; adaptive weights could adapt but risk instability and added complexity
- Failure signatures: (1) Misaligned regularization paths despite weighting -> check loss scaling; (2) Slow convergence -> check Lipschitz estimation; (3) Sparsity pattern dominated by one task -> check weighting constants or feature correlation structure
- First 3 experiments:
  1. Simulate two regression tasks and one classification task; run MTLComb vs naive MTL; compare selected features and prediction errors
  2. Vary the ratio of classification to regression samples; observe effect on stability of Î» selection and feature overlap
  3. Introduce strong correlations among features; test whether mean-regularization term stabilizes coefficient similarity across tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal weighting scheme for more than two types of losses in multi-task learning?
- Basis in paper: [explicit] The paper discusses the loss weighting scheme for balancing regression and classification tasks, but mentions future work could extend MTLComb to incorporate additional types of losses.
- Why unresolved: The paper only proves the optimal weighting scheme for two types of losses and does not provide a generalizable solution for multiple loss types.
- What evidence would resolve it: A theoretical proof demonstrating how to analytically determine optimal weights for more than two types of losses in multi-task learning.

### Open Question 2
- Question: How does MTLComb perform compared to deep learning-based multi-task learning methods?
- Basis in paper: [inferred] The paper compares MTLComb to traditional machine learning methods but does not compare it to deep learning approaches, which are increasingly popular for multi-task learning.
- Why unresolved: The paper focuses on linear multi-task learning and does not explore how MTLComb compares to more complex, non-linear methods.
- What evidence would resolve it: Empirical comparisons between MTLComb and state-of-the-art deep learning-based multi-task learning methods on benchmark datasets.

### Open Question 3
- Question: How does MTLComb handle non-linear relationships between features and outcomes?
- Basis in paper: [explicit] The paper states that MTLComb is based on linear multi-task learning and has favorable properties for high-dimensional problems but limited improvement in low-dimensional scenarios.
- Why unresolved: The paper does not explore how MTLComb could be extended to capture non-linear relationships or what the performance implications would be.
- What evidence would resolve it: Experiments demonstrating the performance of MTLComb when extended to handle non-linear relationships, either through feature engineering or model modifications.

## Limitations
- Relies on fixed analytic loss weights that may not generalize when loss magnitudes vary significantly across tasks
- Convergence guarantees depend on convexity assumptions that may not hold in highly correlated feature spaces
- Performance claims based on synthetic and two real datasets; generalization to other domains requires validation

## Confidence
- **High Confidence**: Core optimization framework (accelerated proximal gradient descent) and theoretical convergence properties are well-established
- **Medium Confidence**: Loss weighting scheme effectiveness depends on specific data characteristics and may require adaptation for different problem domains
- **Medium Confidence**: Feature selection performance claims are based on synthetic and two real datasets; generalization to other domains requires validation

## Next Checks
1. Test MTLComb on datasets with varying ratios of regression to classification samples to assess robustness of the fixed weighting scheme
2. Evaluate performance when introducing strong feature correlations or non-linear relationships to test convergence and selection stability
3. Compare MTLComb against adaptive weighting approaches to quantify the tradeoff between analytic guarantees and potential performance gains from learning weights