---
ver: rpa2
title: Unsupervised detection of semantic correlations in big data
arxiv_id: '2411.02126'
source_url: https://arxiv.org/abs/2411.02126
tags:
- data
- correlations
- number
- binary
- dimension
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an algorithm to estimate the binary intrinsic
  dimension (BID) of high-dimensional datasets, specifically designed for binary data
  representations. The core idea is to model the Hamming distance distribution between
  binary strings using a linear approximation of the intrinsic dimension as a function
  of distance.
---

# Unsupervised detection of semantic correlations in big data

## Quick Facts
- arXiv ID: 2411.02126
- Source URL: https://arxiv.org/abs/2411.02126
- Authors: Santiago Acevedo; Alex Rodriguez; Alessandro Laio
- Reference count: 0
- Key outcome: Introduced an algorithm to estimate binary intrinsic dimension (BID) in high-dimensional binary datasets, revealing semantic correlations in deep neural network representations.

## Executive Summary
This paper presents a novel algorithm called BID (Binary Intrinsic Dimension) that estimates the intrinsic dimension of high-dimensional binary datasets. The method models the Hamming distance distribution between binary strings using a linear approximation of intrinsic dimension as a function of distance. This approach enables accurate BID estimation in extremely high-dimensional spaces (up to 10^5 dimensions) using only thousands of samples, circumventing the curse of dimensionality that affects most local neighborhood-based estimators. The algorithm was validated on spin systems from statistical physics and applied to deep neural network representations, successfully identifying semantic correlations in both image and text data.

## Method Summary
The BID algorithm estimates binary intrinsic dimension by modeling the Hamming distance distribution between binary strings. It assumes the intrinsic dimension varies linearly with Hamming distance (d(r) = d0 + d1*r) and uses Maximum Likelihood Estimation to minimize the Kullback-Leibler divergence between empirical and theoretical distributions. The method requires binarizing data using a sign function, computing all pairwise Hamming distances, building a distance histogram, and fitting the linear model to extract d0 as the BID estimate. This approach is particularly effective for extremely high-dimensional spaces where traditional local methods fail due to the curse of dimensionality.

## Key Results
- Successfully estimated BID in spaces up to 10^5 dimensions using only thousands of samples
- Identified phase transitions in Ising and Potts spin systems by analyzing BID scaling with system size and temperature
- Revealed semantic correlations in deep neural network representations, with BID per bit following power-law decay for long text sequences
- Demonstrated that binarization approximately preserves local neighborhoods in high-dimensional activations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The algorithm can estimate binary intrinsic dimension in extremely high-dimensional spaces (up to 10^5 dimensions) using only thousands of samples.
- Mechanism: By modeling the Hamming distance distribution between binary strings using a linear approximation of intrinsic dimension as a function of distance (d(r) = d0 + d1*r), the method avoids the curse of dimensionality that affects most local neighborhood-based ID estimators.
- Core assumption: The intrinsic dimension varies linearly with Hamming distance for small distances, allowing accurate estimation using only local distance statistics.
- Evidence anchors:
  - [abstract] "This approach allows for accurate BID estimation even in extremely high-dimensional spaces (up to 10^5 dimensions) using only thousands of samples, circumventing the curse of dimensionality."
  - [section] "We developed an intrinsic dimension estimator for binary data, called BID (from Binary Intrinsic Dimension) which, as we show below, can cope numerically with extremely large dimensionalities."
- Break condition: The linear approximation of d(r) fails when correlations have complex non-linear structure that cannot be captured by the first-order Taylor expansion.

### Mechanism 2
- Claim: BID scaling reveals semantic correlations in deep neural network representations.
- Mechanism: When representations contain correlated information, the BID scales sub-linearly with system size; when information is independent, BID scales linearly. This difference in scaling behavior indicates the presence and range of semantic correlations.
- Core assumption: Semantic correlations manifest as collective effects that reduce the effective dimensionality compared to independent features.
- Evidence anchors:
  - [abstract] "When applied to deep neural network representations, the BID scaling revealed semantic correlations in both image and text data, with the BID per bit following a power-law decay for long text sequences, indicating long-range semantic correlations."
  - [section] "If one would be able to estimate the ID as a function of text length (or as a function of the patch dimension, in the case of images) one would be able to detect the range of the correlation."
- Break condition: If the network representations are completely decorrelated or if binarization destroys the correlation structure, the scaling relationship would not hold.

### Mechanism 3
- Claim: Binarization approximately preserves local neighborhoods in high-dimensional activations.
- Mechanism: The sign function used for binarization retains the essential information about relative distances between data points, allowing the BID to capture the same correlation structure as the full-precision activations.
- Core assumption: In high-dimensional spaces, the sign of activations preserves the topology of local neighborhoods, even though global distances are altered.
- Evidence anchors:
  - [section] "Binarization has been shown to preserve the scalar product between the activations and weights... In Supp. Inf. we show that binarization also approximately preserves the local neighbourhoods computed using the full-precision activations inside a Large Language Model (LLM)."
  - [corpus] Weak evidence - the corpus does not directly address this mechanism, but the results in the paper suggest it works for the tested cases.
- Break condition: When the activation distributions are highly skewed or when the dimensionality is not sufficiently high, binarization may destroy important distance relationships.

## Foundational Learning

- Concept: Hamming distance and its distribution in binary spaces
  - Why needed here: The entire BID estimation relies on modeling the distribution of Hamming distances between binary strings
  - Quick check question: What is the probability distribution of Hamming distances between two uniformly random binary strings of length N?

- Concept: Curse of dimensionality and its effects on local methods
  - Why needed here: Understanding why traditional ID estimators fail in high dimensions explains the need for the BID approach
  - Quick check question: Why do most intrinsic dimension estimators require exponentially more samples as the dimension increases?

- Concept: Phase transitions and correlation length in statistical physics
  - Why needed here: The spin system benchmarks use physical intuition about correlations to validate the BID method
  - Quick check question: How does the correlation length behave near a critical temperature in the Ising model?

## Architecture Onboarding

- Component map: Data preprocessing -> Distance computation -> Histogram construction -> Model fitting -> Parameter optimization
- Critical path: Binarize data → Compute Hamming distances → Build distance histogram → Fit linear model → Extract d0 as BID estimate
- Design tradeoffs:
  - Precision vs. dimensionality: Binarization loses information but enables scaling to very high dimensions
  - Local vs. global estimation: Using only small distances makes the method robust but may miss long-range correlations
  - Sample efficiency vs. accuracy: Few samples enable high-dimensional estimation but may reduce precision
- Failure signatures:
  - Linear model fails to fit distance histogram (high KL divergence)
  - BID per bit scaling shows no clear pattern with system size
  - Results vary significantly with choice of meta-parameters (r* or rmin)
- First 3 experiments:
  1. Generate independent binary vectors of varying lengths and verify BID scales linearly
  2. Create correlated binary data with known correlation structure and verify BID captures it
  3. Apply to a small neural network representation and compare full-precision vs. binarized BID estimates

## Open Questions the Paper Calls Out

- Question: What is the relationship between the binary intrinsic dimension (BID) and the Shannon entropy estimated by compression algorithms?
  - Basis in paper: [explicit] The authors mention in the conclusion that it would be interesting to explore the relationship between BID and Shannon entropy estimated by compression algorithms.
  - Why unresolved: The paper does not provide any analysis or comparison between BID and entropy-based methods.
  - What evidence would resolve it: A systematic study comparing BID estimates with entropy estimates from compression algorithms across various datasets and domains.

- Question: How does the choice of binarization method (e.g., sign function vs. 2-bit quantization) affect the accuracy and interpretability of BID estimates?
  - Basis in paper: [explicit] The authors compare sign binarization with a 2-bit quantization method and observe similar scaling behavior, suggesting that binning retains essential information when intrinsic dimension is extremely large.
  - Why unresolved: The paper does not explore other binarization methods or provide a theoretical justification for why sign function works well.
  - What evidence would resolve it: A comprehensive comparison of different binarization methods on BID estimation accuracy and their effects on the interpretability of semantic correlations.

- Question: Can the BID approach be extended to non-binary data representations, and what would be the implications for estimating semantic correlations in real-world datasets?
  - Basis in paper: [inferred] The authors developed BID specifically for binary data but applied it to real-valued features by binarizing them using the sign function, showing that trends are preserved.
  - Why unresolved: The paper does not explore the theoretical basis or practical implementation of extending BID to continuous data directly.
  - What evidence would resolve it: Development of a general-purpose intrinsic dimension estimator that can handle both binary and continuous data, with validation on diverse datasets showing improved accuracy over current methods.

## Limitations

- The linear approximation of intrinsic dimension as a function of Hamming distance may fail when correlations have complex non-linear structure
- Binarization may not preserve all relevant correlation information, especially in cases with highly skewed activation distributions
- Results are sensitive to the choice of meta-parameters like r* and α*, which are not fully specified

## Confidence

- High confidence: The BID method successfully captures phase transitions in spin systems, as demonstrated by the clear critical temperature identification in both Ising and Potts models
- Medium confidence: The BID scaling reveals semantic correlations in neural network representations, though the binarization step introduces some uncertainty about whether the full correlation structure is preserved
- Medium confidence: The method's ability to estimate BID in extremely high-dimensional spaces (up to 10^5 dimensions) using only thousands of samples is validated, but may depend on specific data characteristics

## Next Checks

1. Test the BID estimator on synthetic datasets with known hierarchical correlation structures to evaluate whether the linear approximation captures multi-scale correlations
2. Compare BID estimates using different binarization thresholds (beyond simple sign function) to assess sensitivity to preprocessing choices
3. Apply the method to time-series data with known temporal correlations to validate its ability to detect long-range dependencies beyond the tested text sequences