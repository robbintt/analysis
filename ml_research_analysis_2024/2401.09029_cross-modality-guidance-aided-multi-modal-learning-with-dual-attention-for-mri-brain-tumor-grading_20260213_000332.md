---
ver: rpa2
title: Cross-modality Guidance-aided Multi-modal Learning with Dual Attention for
  MRI Brain Tumor Grading
arxiv_id: '2401.09029'
source_url: https://arxiv.org/abs/2401.09029
tags:
- tumor
- modalities
- feature
- features
- modality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of MRI brain tumor grading, which
  is crucial for accurate diagnosis and treatment planning. The authors propose a
  novel cross-modality guidance-aided multi-modal learning framework with dual attention
  to leverage complementary information from different MRI modalities.
---

# Cross-modality Guidance-aided Multi-modal Learning with Dual Attention for MRI Brain Tumor Grading

## Quick Facts
- arXiv ID: 2401.09029
- Source URL: https://arxiv.org/abs/2401.09029
- Authors: Dunyuan Xu; Xi Wang; Jinyue Cai; Pheng-Ann Heng
- Reference count: 40
- Primary result: AUC of 0.985±0.019 on BraTS2018 and 0.966±0.021 on BraTS2019 for brain tumor grading

## Executive Summary
This paper addresses the challenge of MRI brain tumor grading by proposing a novel cross-modality guidance-aided multi-modal learning framework with dual attention. The method leverages complementary information from four MRI modalities (T1, T1ce, T2, Flair) to improve grading accuracy. By using a primary modality (T1ce) to guide feature extraction of secondary modalities and applying dual attention to capture semantic interdependencies in spatial and slice dimensions, the proposed approach significantly outperforms both single modality and several state-of-the-art multi-modal methods on the BraTS2018 and BraTS2019 datasets.

## Method Summary
The proposed method employs ResNet Mix Convolution as the backbone for feature extraction from four MRI modalities. A cross-modality guidance module uses high-level features from the primary modality (T1ce) to guide the feature extraction of secondary modalities (T1, T2, Flair). Dual attention mechanisms capture semantic interdependencies in spatial and slice dimensions to amplify informative features. The model uses a cumulative learning strategy with weighted cross-entropy loss to handle class imbalance, training in two stages: first with the primary modality only, then with all modalities progressively integrated.

## Key Results
- Achieved AUC of 0.985±0.019 on BraTS2018 and 0.966±0.021 on BraTS2019
- Outperformed single modality approaches and state-of-the-art multi-modal methods
- Demonstrated effectiveness of cross-modality guidance and dual attention mechanisms

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dual attention improves model performance by forcing focus on informative regions and slices in MRI volumes.
- Mechanism: The dual attention module calculates attention maps for both spatial (channel × height × width) and slice (slice × slice) dimensions, then combines their results to amplify important features and suppress less informative ones.
- Core assumption: Brain tumor information is unevenly distributed across spatial regions and slices in MRI volumes.
- Evidence anchors:
  - [abstract] "dual attention is applied to capture the semantic interdependencies in spatial and slice dimensions"
  - [section] "Due to the uneven distribution of a brain tumor across slices, different slices are not equally important, so the dual attention mechanism is introduced"
  - [corpus] Weak - no direct corpus evidence found for dual attention mechanism in this specific context
- Break condition: If tumor distribution is uniform across slices or spatial regions, or if attention computation introduces too much overhead relative to gain.

### Mechanism 2
- Claim: Cross-modality guidance allows the primary modality to guide feature extraction of secondary modalities, reducing noise.
- Mechanism: High-level features from the primary modality (T1ce) are upsampled and concatenated with low-level features from secondary modalities, providing semantic guidance that helps the model selectively learn complementary information while minimizing noise.
- Core assumption: Primary modality contains the most diagnostic information and can provide effective semantic guidance to secondary modalities.
- Evidence anchors:
  - [abstract] "cross-modality guidance-aided module where the primary modality guides the other secondary modalities"
  - [section] "We design a cross-modality guidance-aided module that could effectively leverage multiple modalities for training, in which the main contribution of the primary modality could largely be maintained"
  - [corpus] Weak - no direct corpus evidence found for this specific guidance mechanism
- Break condition: If the semantic gap between primary and secondary modalities is too large for effective guidance, or if the guidance introduces bias that harms secondary modality learning.

### Mechanism 3
- Claim: Cumulative learning strategy with weighted cross-entropy loss handles class imbalance and improves classification.
- Mechanism: Primary modality features are processed first, then secondary modalities are progressively integrated in descending order of their individual performance, with weighted cross-entropy loss applied to account for class imbalance.
- Core assumption: Not all modalities contribute equally to classification, and class imbalance in the dataset requires weighted loss.
- Evidence anchors:
  - [abstract] "weighted cross-entropy loss is applied here for controlling the prediction output"
  - [section] "the weighted cross entropy loss is applied here for controlling the prediction output. The weighted cross entropy loss is formulated as follows"
  - [corpus] Weak - no direct corpus evidence found for this specific cumulative learning approach
- Break condition: If modality integration order doesn't matter, or if weighted loss doesn't improve performance over standard loss.

## Foundational Learning

- Concept: MRI modality characteristics
  - Why needed here: Different MRI modalities (T1, T1ce, T2, Flair) capture different tissue contrasts and tumor characteristics
  - Quick check question: What type of information does T1ce MRI typically emphasize compared to T2 MRI?

- Concept: Attention mechanisms in deep learning
  - Why needed here: Dual attention helps the model focus on the most informative spatial regions and slices for tumor grading
  - Quick check question: How does self-attention differ from spatial attention in convolutional neural networks?

- Concept: Cross-modal feature fusion
  - Why needed here: Effective fusion of complementary information from different modalities without introducing noise
  - Quick check question: What are the three main levels of multi-modal fusion (pixel, feature, decision) and their tradeoffs?

## Architecture Onboarding

- Component map: Input → 4 MRI modalities → RMC backbone → Dual attention → Primary modality SFE → Cross-modality guidance → Secondary modality LFE/HFE → Weighted cross-entropy loss → Classifier → Output
- Critical path: MRI input → RMC feature extraction → Dual attention application → Cross-modality guidance (primary to secondary) → Cumulative modality integration → Classification
- Design tradeoffs: Computational efficiency vs. model complexity, guidance effectiveness vs. semantic gap, attention granularity vs. overhead
- Failure signatures: Performance degradation when adding modalities, high variance across folds, model overfitting on training data
- First 3 experiments:
  1. Verify baseline RMC performance on each individual modality (T1, T1ce, T2, Flair)
  2. Test dual attention module alone on T1ce modality
  3. Implement and test cross-modality guidance with T1ce as primary and T2 as secondary modality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed cross-modality guidance mechanism perform on datasets with significantly different domain characteristics compared to BraTS2018/2019?
- Basis in paper: [inferred] The paper mentions that real-world data might contain more environmental noise and demonstrate a large domain shift, suggesting potential limitations of the method on different datasets.
- Why unresolved: The study only evaluated the method on two BraTS datasets, and did not test its performance on external datasets with different domain characteristics.
- What evidence would resolve it: Testing the model on multiple external MRI datasets with different acquisition protocols, scanners, and patient populations to assess its generalization capability.

### Open Question 2
- Question: Can the proposed method maintain its performance while significantly reducing the network size and computational complexity?
- Basis in paper: [explicit] The authors acknowledge that the model size is still gigantic and the training/inference process would be quite inefficient due to the large number of parameters in the four semantics feature extractors.
- Why unresolved: The paper does not explore methods to reduce the model size while maintaining performance, leaving the question of efficiency open.
- What evidence would resolve it: Developing and testing a more compact version of the network that achieves similar or better performance with fewer parameters and lower computational cost.

### Open Question 3
- Question: How would the performance of the proposed method change if different modalities were selected as the primary modality?
- Basis in paper: [explicit] The authors define primary and secondary modalities based on their performance in uni-modal models, but do not explore the impact of choosing different primary modalities on the overall performance.
- Why unresolved: The study only uses T1ce as the primary modality and does not investigate the effect of selecting other modalities as primary.
- What evidence would resolve it: Experimenting with different modalities as the primary modality and comparing the performance to determine the optimal choice for various scenarios.

## Limitations

- Performance gains from dual attention mechanism lack direct corpus evidence and ablation studies
- Cross-modality guidance details are underspecified, particularly regarding semantic guidance computation
- Model size and computational complexity remain significant limitations without efficiency exploration

## Confidence

- Dual attention mechanism: Low confidence - lack of direct corpus evidence for effectiveness in brain tumor grading context
- Cross-modality guidance: Low confidence - underspecified implementation details and semantic guidance computation
- Weighted cross-entropy loss: Medium confidence - reasonable methodology but selection of T1ce as primary lacks strong justification

## Next Checks

1. **Ablation testing**: Systematically remove dual attention and cross-modality guidance modules to quantify their individual contributions to performance gains.

2. **Modality ordering sensitivity**: Test alternative primary modality selections (T2 or Flair) to validate the assumption that T1ce is optimal for guidance.

3. **Generalization testing**: Evaluate the trained model on an external dataset or different MRI protocols to assess robustness beyond the BraTS datasets.