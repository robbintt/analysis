---
ver: rpa2
title: Evolutionary Multi-Objective Optimization of Large Language Model Prompts for
  Balancing Sentiments
arxiv_id: '2401.09862'
source_url: https://arxiv.org/abs/2401.09862
tags:
- prompt
- prompts
- nsga-ii
- sms-emoa
- hypervolume
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the problem of optimizing prompts for large
  language models to achieve balanced sentiments in generated texts. The proposed
  EMO-Prompts method employs evolutionary multi-objective optimization with custom
  crossover and mutation operators to generate prompts that elicit conflicting emotions
  simultaneously.
---

# Evolutionary Multi-Objective Optimization of Large Language Model Prompts for Balancing Sentiments

## Quick Facts
- arXiv ID: 2401.09862
- Source URL: https://arxiv.org/abs/2401.09862
- Reference count: 15
- Primary result: EMO-Prompts achieves hypervolume of 0.45 in sentiment balancing, exceeding target of 0.44

## Executive Summary
This paper introduces EMO-Prompts, a novel method for optimizing prompts to generate texts with balanced sentiments using evolutionary multi-objective optimization. The approach uses the LLM itself as crossover and mutation operators, combined with sentiment analysis as the objective function. Experiments with NSGA-II and SMS-EMOA algorithms demonstrate that EMO-Prompts can effectively generate prompts that guide LLMs to produce texts embodying pairs of conflicting emotions.

## Method Summary
EMO-Prompts employs evolutionary multi-objective optimization with custom crossover and mutation operators that use the LLM (Llama 2 7B) as the generative mechanism. The method initializes with 10 manually crafted prompts, then evolves them over 30 generations using NSGA-II or SMS-EMOA algorithms. Sentiment analysis via DistilBERT provides emotion probabilities (love, anger, joy, fear, sadness, surprise) as objective values for ranking individuals. The best prompts are selected based on hypervolume maximization, balancing two conflicting emotions simultaneously.

## Key Results
- EMO-Prompts with NSGA-II consistently yields higher average fitness function values than SMS-EMOA
- Peak fitness values of 0.45 achieved in 'surprise vs. fear' experiments, surpassing ideal benchmark of 0.44
- Method successfully generates prompts that guide LLMs to produce texts embodying pairs of conflicting emotions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EMO-Prompts uses the LLM itself as both a crossover and mutation operator, allowing for dynamic prompt evolution guided by model reasoning.
- Mechanism: Prompts are recombined or modified by feeding two prompts (crossover) or one prompt (mutation) into Llama 2 via structured instructions, which then outputs a new prompt. This is repeated across generations using NSGA-II or SMS-EMOA selection.
- Core assumption: The LLM can act as a generative operator to create semantically valid and useful prompts, not just generate texts.
- Evidence anchors:
  - [section 3.2]: "As can be seen in Figure 1, new crossover and mutation operator are developed, which are text prompts instructing the LLM to perform crossover or mutation."
  - [section 3.2]: Crossover Prompt example shows LLM is prompted to "Analyze the prompts and generate a better prompt based on this analysis."
- Break condition: If the LLM consistently produces invalid or semantically meaningless prompts, the evolutionary process will not converge toward balanced sentiments.

### Mechanism 2
- Claim: Sentiment analysis using DistilBERT acts as the objective function evaluator, providing real-valued fitness scores for conflicting emotions in generated texts.
- Mechanism: For each generated text, the DistilBERT model outputs emotion probabilities (love, anger, joy, fear, sadness, surprise). These are used as objective values for NSGA-II or SMS-EMOA to rank individuals.
- Core assumption: DistilBERT's emotion classification is accurate and consistent enough to guide evolutionary selection.
- Evidence anchors:
  - [section 4.1]: "The model is adept at identifying a spectrum of emotions from textual data, including 'sadness', 'anger', 'love', 'surprise', 'joy' and 'fear'."
  - [section 4.3]: Hypervolume results are reported using these emotion scores as objectives.
- Break condition: If the sentiment model misclassifies emotions or fails to detect subtle emotional nuances, the optimization will converge to suboptimal prompts.

### Mechanism 3
- Claim: Multi-objective evolutionary algorithms (NSGA-II and SMS-EMOA) enable simultaneous optimization for two conflicting emotions, producing a Pareto front of prompts.
- Mechanism: The algorithms maintain a population of prompts, evaluate each by the two sentiment scores, and evolve toward solutions that maximize both emotions without fully favoring one.
- Core assumption: The fitness landscape is smooth enough for evolutionary algorithms to navigate and find meaningful trade-offs between conflicting emotions.
- Evidence anchors:
  - [section 4.3]: Results show "EMO-Prompts utilizing NSGA-II consistently yields higher average fitness function values than SMS-EMOA."
  - [section 4.3]: "In the 'surprise vs. fear' experiments, EMO-Prompts attains peak fitness values of 0.45, surpassing the ideal benchmark of 0.44."
- Break condition: If the objectives are too conflicting or the population stagnates, the algorithm may fail to improve beyond initial random variance.

## Foundational Learning

- Concept: Multi-objective optimization and Pareto fronts
  - Why needed here: The method must balance two opposing emotions in generated texts, which is a classic multi-objective problem.
  - Quick check question: What does a point close to (0.5, 0.5) in the emotion space represent?

- Concept: Evolutionary algorithms (EA) and operators (crossover, mutation)
  - Why needed here: The approach uses EAs to explore the prompt space and generate new candidates.
  - Quick check question: How does NSGA-II differ from standard genetic algorithms in terms of selection?

- Concept: Large language model prompting and few-shot learning
  - Why needed here: The LLM is used both as a text generator and as an operator to create new prompts.
  - Quick check question: What is the purpose of a "system prompt" in the Modelfile configuration?

## Architecture Onboarding

- Component map:
  Initial population -> LLM (Llama 2 7B) -> Sentiment analysis (DistilBERT) -> Evolutionary algorithm (NSGA-II/SMS-EMOA) -> Output: Pareto-optimal prompts

- Critical path:
  1. Generate initial population of prompts
  2. For each prompt, generate text using Llama 2
  3. Analyze text for emotion scores using DistilBERT
  4. Apply crossover/mutation via LLM instructions
  5. Select top Âµ individuals using NSGA-II or SMS-EMOA
  6. Repeat for 30 generations

- Design tradeoffs:
  - Using Llama 2 7B for efficiency vs. larger models for quality
  - Fixed context window (512 tokens) limits text length
  - Temperature set to 0.7 for diversity vs. deterministic outputs
  - Two EA algorithms (NSGA-II vs SMS-EMOA) offer different convergence behaviors

- Failure signatures:
  - Hypervolume plateaus early or stays near zero
  - Generated texts lack emotional nuance or are off-topic
  - Prompts fail to evolve and population diversity collapses
  - Sentiment analysis model produces inconsistent scores

- First 3 experiments:
  1. Run a single generation with fixed prompts to verify text generation and sentiment scoring work
  2. Test crossover operator alone with two simple prompts and verify LLM generates a new prompt
  3. Test mutation operator alone with a single prompt and verify LLM generates a variation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of EMO-Prompts compare to other prompt optimization techniques like Chain-of-Thought Prompting or ReAct in terms of balancing sentiments?
- Basis in paper: [explicit] The paper states that popular prompt engineering techniques like Chain-of-Thought Prompting or ReAct often remain sub-optimal and focuses on comparing EMO-Prompts with NSGA-II and SMS-EMOA.
- Why unresolved: The paper does not provide a direct comparison between EMO-Prompts and other prompt engineering techniques.
- What evidence would resolve it: Conducting experiments comparing EMO-Prompts with other techniques on the same sentiment analysis tasks would provide evidence of its relative effectiveness.

### Open Question 2
- Question: Can EMO-Prompts be effectively applied to more complex tasks beyond sentiment analysis, such as generating domain-specific texts?
- Basis in paper: [explicit] The paper mentions plans to broaden the scope of EMO-Prompts to include generating more extensive texts and those tailored to specific domains.
- Why unresolved: The paper only demonstrates EMO-Prompts on sentiment analysis tasks and does not explore its application to more complex or domain-specific tasks.
- What evidence would resolve it: Applying EMO-Prompts to various domain-specific tasks and evaluating its performance would provide evidence of its broader applicability.

### Open Question 3
- Question: How does the choice of the LLM, such as using Llama 2 with 7B parameters, affect the performance of EMO-Prompts in generating balanced sentiments?
- Basis in paper: [explicit] The paper uses Llama 2 with 7B parameters due to computational intensity considerations but does not explore the impact of using different LLMs.
- Why unresolved: The paper does not investigate how different LLMs or parameter sizes might influence the effectiveness of EMO-Prompts.
- What evidence would resolve it: Experimenting with various LLMs and parameter sizes while using EMO-Prompts would provide insights into how these factors affect performance.

## Limitations
- The method's dependence on a 7B parameter model for both text generation and as a meta-operator introduces significant constraints on scalability and robustness
- Fixed 512-token context window may truncate longer emotional narratives, potentially skewing sentiment evaluation
- Use of a single sentiment model (DistilBERT) without ensemble or uncertainty quantification creates a single point of failure in the objective evaluation pipeline

## Confidence
- High Confidence: The core mechanism of using LLMs as crossover/mutation operators is well-supported by explicit textual evidence in the paper, and the experimental results showing hypervolume improvements are directly stated
- Medium Confidence: The claim that EMO-Prompts consistently outperforms SMS-EMOA with NSGA-II requires careful scrutiny, as the paper states NSGA-II performs better on average but provides limited statistical significance testing across multiple runs
- Low Confidence: The assertion that the method can reliably generate prompts for "any" pair of conflicting emotions is not empirically validated beyond the four emotion pairs tested, and the generalisability to other emotion combinations remains unproven

## Next Checks
1. Conduct ablation studies removing the LLM-as-operator component to quantify its contribution versus traditional evolutionary operators
2. Test the method across additional emotion pairs (e.g., joy vs sadness, anger vs love) to evaluate generalisability beyond the four pairs examined
3. Perform statistical significance testing across multiple independent runs to verify that observed performance differences between NSGA-II and SMS-EMOA are robust and not due to random variation