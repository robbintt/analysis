---
ver: rpa2
title: Modeling Output-Level Task Relatedness in Multi-Task Learning with Feedback
  Mechanism
arxiv_id: '2404.00885'
source_url: https://arxiv.org/abs/2404.00885
tags:
- task
- feedback
- mechanism
- tasks
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of capturing output-level task
  relatedness in multi-task learning (MTL) by incorporating a feedback mechanism into
  MTL models. The proposed approach leverages the output of one task as posterior
  information for another task, transforming static MTL models into dynamic ones.
---

# Modeling Output-Level Task Relatedness in Multi-Task Learning with Feedback Mechanism

## Quick Facts
- arXiv ID: 2404.00885
- Source URL: https://arxiv.org/abs/2404.00885
- Reference count: 24
- One-line primary result: Feedback mechanism incorporating output-level task relatedness significantly improves MTL performance

## Executive Summary
This paper addresses the challenge of capturing output-level task relatedness in multi-task learning by introducing a feedback mechanism where one task's output serves as posterior information for another task. The approach transforms static MTL models into dynamic ones through iterative feedback loops. To ensure stable training, a convergence loss function monitors output trends during iterations, while a Gumbel gating mechanism learns optimal feedback injection points. Experiments on spoken language understanding tasks demonstrate significant performance improvements over baseline MTL models.

## Method Summary
The method incorporates a feedback mechanism into MTL models where outputs of one task are transformed via amplifier blocks and injected into task-specific layers of another task. A convergence loss function measures the trend of task outputs across iterations to ensure stable training. The Gumbel gating mechanism determines optimal points for feedback signal integration. The model iterates K times, with task outputs from iteration k serving as inputs for iteration k+1, creating a dynamic system where tasks influence each other's learning.

## Key Results
- Significant performance improvements over baseline MTL models on spoken language understanding tasks
- Feedback mechanism enhances model performance both with and without Gumbel gating
- Convergence loss successfully stabilizes training of dynamic MTL models
- Optimal feedback injection points can be learned rather than fixed as hyperparameters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Feedback mechanism improves performance by leveraging posterior information from one task to enhance the learning of another.
- Mechanism: Outputs of one task (e.g., intent detection) are used as additional inputs to the model layers of another task (e.g., slot filling), creating a dynamic system where tasks influence each other during training.
- Core assumption: Task outputs are correlated and can provide useful posterior information to other tasks, beyond just shared features in hidden layers.
- Evidence anchors:
  - [abstract] "incorporating a feedback mechanism into MTL models, where the output of one task serves as a hidden feature for another task, thereby transforming a static MTL model into a dynamic one."
  - [section] "To model the output of Task 1, denoted by y1, as posterior information for Task 2, we branch and infuse it via an amplifier block, denoted by f12, as an extra input into the j-th block in the task-specific layers of Task 2, i.e., hj, 1 ≤ j ≤ m2, as is shown with the red dashed line in Fig. 1a."
  - [corpus] Weak evidence - no direct mention of feedback mechanisms in neighboring papers.
- Break condition: If task outputs are not correlated, or if the feedback introduces noise that outweighs the benefits, performance may degrade.

### Mechanism 2
- Claim: Convergence loss ensures stable training by monitoring the trend of task outputs during iterations.
- Mechanism: A loss function measures the difference between consecutive predictions of a task, penalizing large changes and encouraging the model to reach a steady state.
- Core assumption: Dynamic MTL models with feedback can become unstable without a mechanism to ensure outputs converge over iterations.
- Evidence anchors:
  - [abstract] "To ensure the training process converges, we introduce a convergence loss that measures the trend of a task's outputs during each iteration."
  - [section] "To measure the convergence of the output sequence, we propose a novel convergence loss function, i.e., L({yk i }K k=0) = PK−1 k=1 βK−k||yk+1 i − yk i ||F where β ∈ (0, 1) is a delay constant that controls the forget degree of previous predictions."
  - [corpus] Weak evidence - no direct mention of convergence loss in neighboring papers.
- Break condition: If β is set too high or too low, the loss may either over-constrain the model or fail to stabilize it.

### Mechanism 3
- Claim: Gumbel gating mechanism learns the optimal points to inject feedback signals, improving the model's ability to extract and utilize shared features.
- Mechanism: A gating mechanism based on the Gumbel distribution determines which layers should receive feedback signals, rather than fixing this as a hyperparameter.
- Core assumption: Not all layers benefit equally from feedback; the optimal injection points can be learned from data.
- Evidence anchors:
  - [abstract] "Additionally, a Gumbel gating mechanism is employed to determine the optimal projection of feedback signals."
  - [section] "To determine the optimal integration point for feedback information, we employ a gating mechanism based on the Gumbel distribution. This mechanism learns from data, identifying the most common features to extract and utilize."
  - [corpus] Weak evidence - no direct mention of Gumbel gating in neighboring papers.
- Break condition: If the gating mechanism fails to learn meaningful patterns, it may not improve performance over fixed injection points.

## Foundational Learning

- Concept: Multi-Task Learning (MTL) - training a single model on multiple related tasks simultaneously to improve generalization.
  - Why needed here: The paper builds on MTL by adding a feedback mechanism to model output-level task relatedness, which is a novel extension of traditional MTL approaches.
  - Quick check question: What is the primary benefit of MTL compared to training separate models for each task?

- Concept: Dynamic systems in neural networks - models where outputs at one step become inputs for the next step, creating temporal dependencies.
  - Why needed here: The feedback mechanism transforms the MTL model into a dynamic system, requiring careful handling of convergence and stability.
  - Quick check question: How does a dynamic system differ from a static model in terms of information flow?

- Concept: Gumbel-Max trick and continuous relaxation - a technique to sample from a categorical distribution in a differentiable way.
  - Why needed here: The Gumbel gating mechanism uses this trick to learn which layers should receive feedback signals in a differentiable manner.
  - Quick check question: Why is it important for the gating mechanism to be differentiable in a neural network?

## Architecture Onboarding

- Component map: Input -> Shared layers -> Task-specific layers (with feedback injection) -> Output, repeated for K iterations
- Critical path: Input → Shared layers → Task-specific layers (with feedback injection) → Output, repeated for K iterations
- Design tradeoffs:
  - Fixed vs. learned feedback injection points: Fixed points are simpler but may not be optimal; learned points require additional computation but can adapt to the data
  - Convergence loss weight: Too high may slow training; too low may not stabilize the model
  - Number of iterations K: More iterations may improve performance but increase training time and risk overfitting
- Failure signatures:
  - Performance degrades: Feedback may be introducing noise or the tasks may not be sufficiently related
  - Training instability: Convergence loss may be too weak or the model may not be reaching a steady state
  - No improvement with Gumbel gating: The gating mechanism may not be learning meaningful patterns
- First 3 experiments:
  1. Implement the feedback mechanism with fixed injection points and K=1 (no iteration) to establish a baseline
  2. Add the convergence loss to the fixed feedback model and tune the weight to stabilize training
  3. Replace fixed injection points with the Gumbel gating mechanism and compare performance to the fixed version

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the feedback mechanism perform in multi-task learning scenarios with more than three tasks, especially when the number of tasks grows exponentially?
- Basis in paper: [inferred] The paper discusses the scalability challenges of the feedback mechanism when applied to more than three tasks, mentioning that connection complexity might increase exponentially.
- Why unresolved: The paper only validates the feedback mechanism with up to three tasks (ID, SF, and NWP) and does not explore scenarios with a larger number of tasks.
- What evidence would resolve it: Experimental results demonstrating the performance of the feedback mechanism on MTL models with more than three tasks, including scalability analysis and comparison with other approaches.

### Open Question 2
- Question: How does the convergence loss function impact the training process and final model performance in different MTL architectures and datasets?
- Basis in paper: [explicit] The paper introduces a convergence loss function to ensure the stability of the training process and discusses its impact on the convergence of the training process through an ablation study.
- Why unresolved: The paper only conducts experiments on specific MTL models and datasets, and the impact of the convergence loss function on different architectures and datasets remains unclear.
- What evidence would resolve it: Comparative experiments evaluating the performance of MTL models with and without the convergence loss function across various architectures and datasets, along with an analysis of the trade-offs between convergence and efficiency.

### Open Question 3
- Question: What is the optimal number of iterations (K) for the feedback mechanism in different MTL scenarios, and how does it affect the trade-off between convergence and efficiency?
- Basis in paper: [explicit] The paper mentions the trade-off between convergence and efficiency for predictions and discusses the determination of the hyperparameter K in the feedback mechanism.
- Why unresolved: The paper does not provide a clear guideline for selecting the optimal number of iterations (K) in different MTL scenarios, and the impact of K on the trade-off between convergence and efficiency is not thoroughly explored.
- What evidence would resolve it: A comprehensive study investigating the relationship between the number of iterations (K) and model performance across various MTL scenarios, along with recommendations for selecting K based on specific task characteristics and computational constraints.

## Limitations
- Limited scalability to scenarios with many tasks due to potential exponential increase in connection complexity
- Additional hyperparameters (convergence loss weight, number of iterations K) that may require extensive tuning
- Experiments limited to spoken language understanding tasks, leaving generalizability to other domains unclear

## Confidence
- Feedback mechanism effectiveness: Medium - demonstrated improvements but lacks ablation studies
- Convergence loss stability: Medium - helps stabilize training but optimal settings unclear
- Gumbel gating utility: Medium - learns injection points but contribution not isolated
- Generalizability across domains: Low - only tested on spoken language understanding

## Next Checks
1. Conduct an ablation study to quantify the individual contributions of the feedback mechanism, convergence loss, and Gumbel gating to the overall performance improvements
2. Test the approach on a diverse set of task combinations across different domains (computer vision, reinforcement learning, etc.) to assess generalizability
3. Compare against other dynamic MTL approaches that model task interactions at different levels (feature, decision, parameter) to establish relative effectiveness