---
ver: rpa2
title: 'HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context Learning
  in Factuality Evaluation'
arxiv_id: '2402.09390'
source_url: https://arxiv.org/abs/2402.09390
tags:
- step
- answer
- hgot
- question
- president
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The HGOT framework addresses the challenge of improving the factuality
  and reducing hallucinations in large language models (LLMs) by introducing a hierarchical
  graph approach for retrieval-augmented in-context learning. The method dynamically
  constructs a multi-layered graph using LLMs' emergent planning capabilities to break
  down complex queries into manageable sub-queries, following a divide-and-conquer
  strategy.
---

# HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context Learning in Factuality Evaluation

## Quick Facts
- arXiv ID: 2402.09390
- Source URL: https://arxiv.org/abs/2402.09390
- Authors: Yihao Fang; Stephen W. Thomas; Xiaodan Zhu
- Reference count: 40
- Outperforms competing methods on FEVER by up to 7% and matches leading models on Open-SQuAD and HotPotQA

## Executive Summary
HGOT addresses the challenge of improving factuality and reducing hallucinations in large language models by introducing a hierarchical graph approach for retrieval-augmented in-context learning. The framework dynamically constructs a multi-layered graph using LLM emergent planning capabilities to break down complex queries into manageable sub-queries following a divide-and-conquer strategy. HGOT refines self-consistency majority voting by incorporating citation recall and precision metrics to assess thought quality, and introduces a scoring mechanism for evaluating retrieved passages based on citation frequency, quality, self-consistency confidence, and retrieval ranking.

## Method Summary
HGOT employs a hierarchical graph construction approach where complex queries are decomposed into sub-queries using LLM emergent planning capabilities. The framework constructs a directed acyclic graph (DAG) representing dependencies between sub-queries, then processes them in topological order. For each sub-query, the system retrieves passages, evaluates their quality using citation frequency and thought quality metrics, and generates answers. The final answer is selected through weighted self-consistency voting where answers are weighted by the quality of their underlying reasoning thoughts, measured through citation recall and precision.

## Key Results
- Outperforms competing methods on FEVER by up to 7% in exact match score
- Achieves performance comparable to state-of-the-art models on Open-SQuAD and HotPotQA datasets
- Demonstrates effectiveness of hierarchical graph approach in enhancing LLM factuality through improved retrieval and reasoning quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: HGOT improves factuality by dynamically constructing a hierarchical graph that breaks down complex queries into manageable sub-queries using LLM emergent planning capabilities.
- Mechanism: The LLM first plans by decomposing the main question into sub-queries organized in a directed acyclic graph (DAG) structure. Each sub-query can itself be further broken down into deeper levels, creating a multi-layered hierarchy. This decomposition allows focused retrieval and reasoning at each level, reducing the cognitive load on the LLM and improving the relevance of retrieved passages.
- Core assumption: LLMs possess emergent planning capabilities sufficient to decompose complex queries into logically structured sub-queries that maintain semantic coherence and dependencies.
- Evidence anchors:
  - [abstract] "The framework utilizes the emergent planning capabilities of LLMs, employing the divide-and-conquer strategy to break down complex queries into manageable sub-queries."
  - [section 3.1] "The HGOT framework utilizes the emergent planning ability of LLMs to break down complex queries into smaller, more manageable sub-queries, following a divide-and-conquer strategy."
- Break condition: If the LLM fails to generate coherent sub-queries or creates circular dependencies in the DAG, the graph construction breaks down, leading to incorrect or incomplete answers.

### Mechanism 2
- Claim: HGOT improves answer selection by weighting responses based on the citation quality of their underlying thoughts, using citation recall and precision metrics.
- Mechanism: For each generated thought (rationale) and corresponding answer, HGOT computes a quality score ρi that combines the thought's citation recall and precision with a base weight. During self-consistency voting, answers are weighted by the sum of their thought qualities rather than simple majority, prioritizing answers supported by higher-quality reasoning.
- Core assumption: The quality of an LLM's answer is directly related to the quality of its underlying thought, which can be measured by citation recall and precision.
- Evidence anchors:
  - [abstract] "It refines self-consistency majority voting for answer selection, which incorporates the recently proposed citation recall and precision metrics to assess the quality of thoughts, linking an answer's credibility intrinsically to the thought's quality."
  - [section 3.2] "The quality of a thought τi is determined by modifying the concepts of citation recall (REC) and citation precision (PREC)..."
- Break condition: If citation recall and precision metrics fail to accurately capture thought quality (e.g., when citations are relevant but reasoning is flawed), the weighted voting may prioritize poor answers.

### Mechanism 3
- Claim: HGOT improves retrieval quality by scoring passages based on citation frequency, citation quality, self-consistency confidence, and retrieval ranking.
- Mechanism: Each retrieved passage receives a quality score that combines its normalized weighted citation frequency (how often it's cited weighted by thought quality), the self-consistency confidence score, and the original retrieval model score. This multi-factor scoring ensures passages are selected based on both relevance and reliability.
- Core assumption: Passages that are frequently cited by high-quality thoughts and appear in confident reasoning chains are more likely to contain accurate information.
- Evidence anchors:
  - [abstract] "Additionally, we propose a scoring mechanism for evaluating retrieved passages, considering factors such as citation frequency and quality, self-consistency confidence, and the retrieval module's ranking."
  - [section 3.3] "The quality score of the passage p is updated repetitively... The formula is expressed as follows: σ(p, t + 1) ← ⃗ w^T · [σ(p, t), ν̄(p), CI]"
- Break condition: If the retrieval model consistently ranks irrelevant passages highly, or if thought quality metrics are unreliable, the scoring mechanism may prioritize poor passages.

## Foundational Learning

- Concept: Directed Acyclic Graphs (DAGs)
  - Why needed here: The hierarchical graph structure requires dependencies between sub-queries to form a DAG to avoid circular reasoning and ensure proper topological ordering during search.
  - Quick check question: What property of DAGs ensures that we can always find a topological ordering for the sub-queries?

- Concept: Topological Sorting
  - Why needed here: Once the dependency graph is constructed, topological sorting determines the order in which sub-queries should be processed, ensuring that dependencies are resolved before dependent steps.
  - Quick check question: If Step 2 depends on Step 1, and Step 3 depends on Step 2, what is the correct topological order?

- Concept: Self-Consistency in LLMs
  - Why needed here: Self-consistency voting aggregates multiple reasoning paths to improve answer reliability, and HGOT enhances this by weighting answers based on thought quality rather than simple majority voting.
  - Quick check question: How does weighted self-consistency differ from standard self-consistency voting?

## Architecture Onboarding

- Component map:
  Input Query → Plan Procedure → Dependency Graph Construction → Topological Sort → Search Procedure (recursive Probe, Plan, Search, Infer) → Probe → Retrieval Model → Passage Scoring (Citation Quality, Frequency, Confidence, Ranking) → Infer → Answer Prediction + Confidence Score → Thought Quality Assessment → Weighted Self-Consistency Voting → Output: Final Answer + Confidence

- Critical path: Query → Plan → Topological Sort → Search (recursive) → Probe (retrieval + scoring) → Infer (answer prediction) → Weighted voting → Final answer

- Design tradeoffs:
  - Depth vs. Breadth: Deeper hierarchies allow more granular reasoning but increase computational cost and risk of compounding errors.
  - Citation Quality vs. Frequency: Prioritizing high-quality citations may miss important but less-cited passages; prioritizing frequency may include noisy citations.
  - Self-Consistency vs. Individual Quality: Aggregating multiple reasoning paths improves robustness but may dilute high-quality individual responses.

- Failure signatures:
  - Incorrect answers with high confidence scores indicate issues with thought quality assessment or retrieval scoring.
  - Long processing times suggest inefficient graph construction or excessive recursion depth.
  - Low agreement between reasoning paths indicates poor prompt design or inadequate demonstrations.

- First 3 experiments:
  1. Test basic query decomposition on simple questions to verify the Plan procedure generates coherent sub-queries.
  2. Evaluate thought quality assessment by comparing weighted vs. unweighted self-consistency on a small dataset.
  3. Test passage scoring by manually inspecting top-ranked passages for relevance and accuracy on sample queries.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of HGOT vary when using different retrieval models, such as domain-specific databases or search engines like Microsoft Bing, Yahoo, and Baidu?
- Basis in paper: [inferred] The paper mentions that HGOT's performance could vary with different retrieval models and that its evaluation was conducted using the Google Search API from SerpApi.com.
- Why unresolved: The paper only evaluated HGOT using the Google Search API and did not explore the impact of using alternative retrieval models.
- What evidence would resolve it: Conducting experiments to compare the performance of HGOT using various retrieval models, including domain-specific databases and popular search engines, would provide evidence on how the choice of retrieval model affects HGOT's performance.

### Open Question 2
- Question: What is the impact of using different LLM architectures, such as Google's Gemini and Meta's Llama 2, on HGOT's performance?
- Basis in paper: [inferred] The paper states that HGOT employs OpenAI's ChatGPT as its language model and that the performance could differ when using alternative models.
- Why unresolved: The paper only evaluated HGOT using OpenAI's ChatGPT and did not explore the impact of using other LLM architectures.
- What evidence would resolve it: Conducting experiments to compare the performance of HGOT using different LLM architectures, such as Google's Gemini and Meta's Llama 2, would provide evidence on how the choice of LLM affects HGOT's performance.

### Open Question 3
- Question: How does the depth of the hierarchical graph in HGOT affect its performance on complex questions?
- Basis in paper: [inferred] The paper mentions that the "Plan" procedure in HGOT can be applied recursively to create a dependency graph at deeper levels, and that the "Search" procedure investigates the dependency graph topologically until a specified depth is achieved.
- Why unresolved: The paper does not provide insights into the optimal depth of the hierarchical graph for different types of questions or how the depth affects HGOT's performance.
- What evidence would resolve it: Conducting experiments to evaluate HGOT's performance with varying depths of the hierarchical graph, particularly for complex questions, would provide evidence on the impact of graph depth on performance.

### Open Question 4
- Question: How does the choice of hyperparameters (α, β, γ, w1, w2, w3) in HGOT affect its performance on different datasets?
- Basis in paper: [explicit] The paper discusses the role of these hyperparameters in the thought quality and retrieval quality scoring mechanisms and mentions an ablation study exploring their effects.
- Why unresolved: The paper only provides optimal hyperparameter values for the medium-length category of the Open-SQuAD dataset and does not discuss their impact on other datasets or categories.
- What evidence would resolve it: Conducting experiments to evaluate HGOT's performance with different hyperparameter values on various datasets and categories would provide evidence on how the choice of hyperparameters affects performance across different settings.

## Limitations
- Performance depends heavily on the quality of underlying LLM's planning capabilities, which may vary across model versions
- Computational overhead from recursive graph construction and multiple retrieval passes can be significant
- Citation-based quality assessment may be unreliable in domains with sparse or noisy citations

## Confidence
- High confidence: Core architectural design of hierarchical graph construction and weighted self-consistency voting
- Medium confidence: Effectiveness of citation-based thought quality assessment
- Low confidence: Specific hyperparameter choices and prompt engineering details

## Next Checks
1. **Cross-model validation**: Test HGOT's hierarchical graph construction and thought quality assessment with different LLM models (e.g., Claude, Gemini) to verify that the approach doesn't rely on ChatGPT-specific behaviors or emergent properties.

2. **Citation metric ablation**: Conduct controlled experiments removing citation recall/precision weighting from the self-consistency voting to quantify the actual contribution of thought quality assessment versus other HGOT components.

3. **Robustness to retrieval quality**: Evaluate HGOT performance when the underlying retrieval model is deliberately degraded or provided with noisy passages to assess the framework's resilience to poor retrieval results.