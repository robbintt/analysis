---
ver: rpa2
title: Conformal Risk Control for Ordinal Classification
arxiv_id: '2405.00417'
source_url: https://arxiv.org/abs/2405.00417
tags:
- risk
- prediction
- conformal
- ordinal
- control
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a conformal risk control method for ordinal
  classification tasks, which have broad applications in many real-world problems.
  The authors formulate the ordinal classification task within the conformal risk
  control framework and provide theoretical risk bounds.
---

# Conformal Risk Control for Ordinal Classification

## Quick Facts
- arXiv ID: 2405.00417
- Source URL: https://arxiv.org/abs/2405.00417
- Authors: Yunpeng Xu; Wenge Guo; Zhi Wei
- Reference count: 8
- Key outcome: Proposed conformal risk control method for ordinal classification with theoretical risk bounds and demonstrated effectiveness on three datasets

## Executive Summary
This paper introduces a conformal risk control framework for ordinal classification tasks, which have broad applications in real-world problems where class ordering matters. The authors formulate the problem within the conformal risk control framework and provide theoretical risk bounds for controlling expected loss. They propose two types of loss functions specially designed for ordinal classification: weight-based and divergence-based, and develop corresponding algorithms to construct prediction sets that satisfy risk constraints. The effectiveness is demonstrated through experiments on three datasets, showing the proposed algorithms can control risk at specified levels while satisfying key properties of prediction sets.

## Method Summary
The method involves training an ordinal classifier, then using a split conformal approach with binary search to find optimal threshold λ that controls expected risk. For each test instance, prediction sets are constructed using greedy algorithms that grow from the point prediction while maintaining ordinal structure. Two loss formulations are proposed: weight-based (assigning different weights to ordinal errors) and divergence-based (penalizing based on distance from true label). The calibration set is used to estimate risk and find λ, then test sets are processed using the thresholded algorithms.

## Key Results
- The proposed algorithms produce risk values very close to specified risk levels across three datasets
- Prediction sets satisfy three key conditions: contiguous sets, inclusion of point prediction, and nested sets for different α values
- Both weight-based and divergence-based loss functions effectively control risk in ordinal classification tasks
- The methods demonstrate practical utility on real-world problems including age recognition and diabetic retinopathy detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The conformal risk control method can control expected loss for ordinal classification by constructing prediction sets that satisfy risk constraints.
- Mechanism: The algorithm uses a threshold-based approach to select prediction sets from a sequence indexed by λ, ensuring the expected loss E[L(Ytest, Cˆλ(Xtest)] ≤ α.
- Core assumption: The loss function L(λ) is non-increasing in λ and right-continuous, with bounds 0 ≤ L(λ) ≤ B < ∞ almost surely.
- Evidence anchors:
  - [abstract] "provide theoretic risk bounds of the risk control method"
  - [section 2.2] "E[L(Ytest, Cˆλ(Xtest)] ≤ α"
  - [corpus] Weak evidence - related papers mention risk control but don't specifically address ordinal classification bounds
- Break condition: If the loss function is not non-increasing or has discontinuities that violate the bounded jump assumption, the risk control guarantee fails.

### Mechanism 2
- Claim: Two types of loss functions (weight-based and divergence-based) can be tailored to different ordinal classification scenarios.
- Mechanism: Weight-based loss assigns different weights to classes based on importance, while divergence-based loss penalizes prediction sets based on distance from true labels.
- Core assumption: The weight function g(Ytest, C(Xtest)) appropriately captures the relative importance of ordinal errors.
- Evidence anchors:
  - [section 2.1] "we propose two forms of weight functions: a weight-based loss function and a divergence-based loss function"
  - [section 2.3] "g(y, C(Xtest)) = h(y)" for weight-based, "g(Ytest, C(Xtest)) = inf{d(y, i) : i ∈ [l, u]}" for divergence-based
  - [corpus] Moderate evidence - related papers discuss conformal prediction for ordinal classification but don't detail these specific loss formulations
- Break condition: If the chosen weight function doesn't reflect the actual cost structure of ordinal errors, the risk control may be ineffective.

### Mechanism 3
- Claim: The greedy algorithm for constructing prediction sets ensures optimal coverage while satisfying ordinal constraints.
- Mechanism: Starting from the point prediction, the algorithm grows the prediction set by adding classes that minimize risk increase until the threshold λ is reached.
- Core assumption: The prediction set should be contiguous and include the point prediction to maintain ordinal structure.
- Evidence anchors:
  - [section 2.3.2] "Algorithm 1: Determine the prediction set for a given λ" with greedy growth approach
  - [section 2.4.2] "Algorithm 3: Determine the prediction set for a given λ" with similar greedy approach
  - [corpus] Moderate evidence - related papers mention prediction set construction but don't detail this specific greedy approach
- Break condition: If the classification model outputs are not reliable estimates of conditional probabilities, the greedy algorithm may construct suboptimal prediction sets.

## Foundational Learning

- Concept: Conformal prediction framework
  - Why needed here: Provides the theoretical foundation for constructing prediction sets with guaranteed coverage
  - Quick check question: What is the key exchangeability assumption in standard conformal prediction?

- Concept: Risk control in expectation
  - Why needed here: Extends conformal prediction from miscoverage rate to general bounded loss functions
  - Quick check question: How does controlling expected risk differ from controlling coverage probability?

- Concept: Ordinal classification
  - Why needed here: The ordering among classes creates unique challenges for error measurement and prediction set construction
  - Quick check question: Why can't standard multi-class conformal prediction be directly applied to ordinal problems?

## Architecture Onboarding

- Component map: Data preprocessing → Ordinal classifier training → Conformal risk control algorithm → Prediction set output → Calibration set for risk estimation → Binary search for optimal λ → Prediction set construction

- Critical path: 1. Train ordinal classifier on training data 2. Split data into calibration and test sets 3. Run conformal risk control algorithm on calibration set to find λ threshold 4. Construct prediction sets for test instances using thresholded algorithm

- Design tradeoffs:
  - Computational efficiency vs. prediction set optimality: Greedy algorithms vs. exhaustive search
  - Risk coverage vs. prediction set size: Tighter risk bounds produce larger sets
  - Weight function design vs. domain applicability: Custom weights improve performance but require domain knowledge

- Failure signatures:
  - Prediction sets consistently larger than expected → Risk threshold too conservative or model uncertainty underestimated
  - Risk bounds violated → Exchangeability assumption broken or calibration set too small
  - Nested property violated → Algorithm implementation error or model score inconsistencies

- First 3 experiments:
  1. Verify risk control on synthetic ordinal data with known class distributions
  2. Compare weight-based vs. divergence-based risks on balanced ordinal classification task
  3. Test nested property preservation across different α values on real ordinal dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of weight functions impact conditional coverage for each single class in ordinal classification?
- Basis in paper: [inferred] The paper mentions that they seek to control marginal risk, which is weaker than conditional risk control, and states that there are important questions remaining regarding the choice of weight functions and their impact on conditional coverage.
- Why unresolved: The paper does not provide an analysis of how different weight functions affect conditional coverage for individual classes in ordinal classification tasks.
- What evidence would resolve it: Empirical studies comparing the conditional coverage of different weight functions on various ordinal classification datasets would provide insights into how weight choices impact class-specific coverage.

### Open Question 2
- Question: What is the optimal way to choose weight functions and risk thresholds for specific ordinal classification problems?
- Basis in paper: [explicit] The paper states that there is a need to investigate how to choose the weight function and the risk threshold that are fit to the specific problem, which is mentioned as an important question remaining for future work.
- Why unresolved: The paper does not provide a methodology or guidelines for selecting appropriate weight functions and risk thresholds tailored to specific ordinal classification tasks.
- What evidence would resolve it: Developing a framework or set of principles for choosing weight functions and risk thresholds based on the characteristics of the ordinal classification problem, such as the importance of different classes or the desired level of risk control, would address this question.

### Open Question 3
- Question: How does the divergence-based risk function compare to other loss functions in terms of prediction accuracy and risk control for ordinal classification?
- Basis in paper: [inferred] The paper introduces a divergence-based risk function and demonstrates its effectiveness on simulated and real data, but does not provide a comprehensive comparison with other loss functions in terms of prediction accuracy and risk control.
- Why unresolved: The paper does not provide a thorough comparison of the divergence-based risk function with other loss functions commonly used in ordinal classification tasks, such as mean squared error or cross-entropy.
- What evidence would resolve it: Conducting a systematic comparison of the divergence-based risk function with other loss functions on a variety of ordinal classification datasets, evaluating both prediction accuracy and risk control, would provide insights into the relative performance of different loss functions.

## Limitations
- Experiments only demonstrate performance on three datasets with specific model architectures (MLP and ResNet34), limiting generalizability
- Lack of comparison with existing ordinal classification methods that don't use conformal prediction makes it difficult to assess relative benefit
- Computational complexity of binary search algorithm and greedy prediction set construction is not thoroughly analyzed

## Confidence
- High confidence in core risk control mechanism and theoretical framework
- Medium confidence in practical effectiveness due to limited experimental scope
- Low confidence in scalability analysis due to missing computational complexity evaluation

## Next Checks
1. Test the risk control algorithms on additional ordinal classification datasets with different class granularities and domain characteristics to verify robustness across varied scenarios.
2. Compare the proposed weight-based and divergence-based loss functions against each other and against standard ordinal classification approaches without conformal risk control to quantify the performance benefit.
3. Analyze the computational complexity and runtime performance of the binary search algorithm and greedy prediction set construction, particularly for datasets with larger numbers of classes or instances.