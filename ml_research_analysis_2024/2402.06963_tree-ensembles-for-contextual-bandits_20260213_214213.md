---
ver: rpa2
title: Tree Ensembles for Contextual Bandits
arxiv_id: '2402.06963'
source_url: https://arxiv.org/abs/2402.06963
tags:
- tree
- contextual
- ensemble
- uni00000013
- trees
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel framework for contextual multi-armed
  bandits using tree ensembles. The authors adapt Upper Confidence Bound (UCB) and
  Thompson Sampling (TS) methods to work with gradient-boosted decision trees (XGBoost)
  and random forests.
---

# Tree Ensembles for Contextual Bandits

## Quick Facts
- arXiv ID: 2402.06963
- Source URL: https://arxiv.org/abs/2402.06963
- Authors: Hannes Nilsson; Rikard Johansson; Niklas Åkerblom; Morteza Haghir Chehreghani
- Reference count: 40
- Primary result: Tree ensemble methods (TEUCB, TETS) outperform neural and linear baselines on contextual bandit problems with better computational efficiency

## Executive Summary
This paper introduces a novel framework for contextual multi-armed bandits using tree ensembles. The authors adapt Upper Confidence Bound (UCB) and Thompson Sampling (TS) methods to work with gradient-boosted decision trees (XGBoost) and random forests. The key innovation is a method to estimate uncertainty in tree ensemble predictions by calculating sample variances across individual tree outputs. Experiments on UCI benchmark datasets show that their TEUCB and TETS algorithms significantly outperform state-of-the-art methods including NeuralUCB, NeuralTS, LinUCB, LinTS, and TreeBootstrap, achieving lower cumulative regret and faster computational runtime.

## Method Summary
The authors propose using tree ensembles (XGBoost and random forests) with UCB and Thompson Sampling for contextual bandits. They estimate uncertainty by calculating sample variances across individual tree outputs, treating each tree as an independent and identically distributed random variable. The framework is extended to combinatorial bandits for navigation problems. Experiments use UCI datasets (Adult, Magic, Mushroom, Shuttle) with 10,000 time steps each, comparing against neural, linear, and tree bootstrap baselines. For road navigation, they apply the method to the Luxembourg road network with 2,247 vertices and 5,651 edges.

## Key Results
- TEUCB and TETS significantly outperform NeuralUCB, NeuralTS, LinUCB, LinTS, and TreeBootstrap on all UCI benchmark datasets
- Tree ensemble methods achieve lower cumulative regret while maintaining computational efficiency
- The framework extends to combinatorial bandits and demonstrates superior performance in real-world navigation over Luxembourg road networks
- Unified tree ensemble models generalize better across arms compared to arm-specific models like TreeBootstrap

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tree ensembles achieve superior regret minimization in contextual bandits compared to neural networks.
- Mechanism: The framework estimates uncertainty in predictions by calculating sample variances across individual tree outputs, allowing for effective exploration-exploitation balance.
- Core assumption: The output of each decision tree is an independent and identically distributed random variable with finite mean and variance.
- Evidence anchors:
  - [abstract] "We propose a novel method of estimating the uncertainty in tree ensemble predictions."
  - [section 3.2] "By this assumption, on is itself a random variable with mean µn and variance σ2n/cn."
  - [corpus] Weak evidence - no direct corpus mention of variance-based uncertainty estimation.
- Break condition: When tree outputs are highly correlated, violating the independence assumption and leading to underestimation of total variance.

### Mechanism 2
- Claim: Tree ensembles generalize better across arms than arm-specific models.
- Mechanism: Using a single tree ensemble to predict rewards for all arms allows the model to learn shared contextual features that impact rewards across different arms.
- Core assumption: Contextual features that influence rewards are shared across arms rather than being arm-specific.
- Evidence anchors:
  - [section 4.3] "TETS, TEUCB, NeuralTS, and NeuralUCB train one model with the possibility of generalizing the expected travel time predictions over different edges."
  - [section 4.2] "TEUCB and TETS significantly outperform the other methods" when using unified models.
  - [corpus] Weak evidence - no direct corpus mention of generalization across arms.
- Break condition: When arm-specific features dominate reward prediction and shared contextual information is irrelevant.

### Mechanism 3
- Claim: Tree ensemble methods are computationally more efficient than neural network approaches.
- Mechanism: Tree ensembles can be updated incrementally by tracking which leaves new observations fall into, avoiding full model retraining at each step.
- Core assumption: The computational cost of updating tree ensembles incrementally is significantly lower than retraining neural networks from scratch.
- Evidence anchors:
  - [section 4.2.1] "TEUCB and TETS do not build new tree ensembles from scratch at each time step. Instead, they only consider which leaves the latest observation assigned in each tree and update the corresponding on, s2n, and cn parameters."
  - [table 2] "TEUCB and TETS are significantly more efficient than their neural counterparts from a computational perspective."
  - [corpus] Weak evidence - no direct corpus mention of incremental updating efficiency.
- Break condition: When the tree architecture changes frequently enough that incremental updates become as expensive as full retraining.

## Foundational Learning

- Concept: Multi-armed bandit problem
  - Why needed here: Provides the foundational framework for sequential decision-making under uncertainty
  - Quick check question: What is the difference between cumulative reward maximization and regret minimization?

- Concept: Contextual bandits
  - Why needed here: Extends multi-armed bandits to incorporate side information that influences reward prediction
  - Quick check question: How does positional encoding work for transforming a classification problem into a contextual bandit?

- Concept: Tree ensemble methods (XGBoost, Random Forests)
  - Why needed here: These are the machine learning models that predict rewards based on context
  - Quick check question: What is the difference between bagging and boosting approaches in tree ensembles?

## Architecture Onboarding

- Component map: Context → Tree Ensemble Prediction → Uncertainty Estimation → Selection Rule → Arm Selection → Reward Observation → Parameter Update
- Critical path: Context → Tree Ensemble Prediction → Uncertainty Estimation → Selection Rule → Arm Selection → Reward Observation → Parameter Update
- Design tradeoffs:
  - Depth vs. accuracy: Deeper trees can capture more complex patterns but risk overfitting
  - Ensemble size vs. computation: More trees improve prediction stability but increase computational cost
  - Exploration factor vs. convergence speed: Higher exploration leads to better long-term performance but slower initial learning
- Failure signatures:
  - Over-exploration: High cumulative regret with slow convergence to optimal arm
  - Under-exploration: Rapid convergence but getting stuck in suboptimal arms
  - High variance in performance: Sensitive to initialization or hyperparameter choices
- First 3 experiments:
  1. Run TEUCB and TETS on a simple synthetic dataset with known optimal arm to verify they can learn correct behavior
  2. Compare TEUCB vs TETS on the same dataset to understand the impact of UCB vs Thompson Sampling exploration strategies
  3. Test different ensemble sizes (10, 50, 100 trees) to find the sweet spot between performance and computation time

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the independence assumption between trees in ensemble methods affect the accuracy of the uncertainty estimates, particularly for boosting algorithms like XGBoost where trees are sequentially dependent?
- Basis in paper: [explicit] The authors acknowledge that the independence assumption may not hold in practice, particularly for boosting methods, and discuss how correlations between trees could lead to underestimation of the total variance.
- Why unresolved: The paper provides theoretical motivation for the independence assumption and argues it yields a lower bound for variance, but does not empirically quantify how much the assumption deviates from reality or how this impacts regret minimization performance.
- What evidence would resolve it: Empirical comparison of TEUCB/TETS performance with theoretically correct variance estimates versus the independence-based approximation, particularly on boosting methods, would show the practical impact of this assumption.

### Open Question 2
- Question: What are the theoretical regret bounds for TEUCB and TETS, and how do they compare to established bounds for NeuralUCB, NeuralTS, LinUCB, and LinTS?
- Basis in paper: [explicit] The authors explicitly state "we did not provide a theoretical analysis of the regret" and note this as future work, despite demonstrating superior empirical performance.
- Why unresolved: The paper focuses on practical applicability and empirical results rather than theoretical guarantees, leaving a gap in understanding the fundamental limits and comparative theoretical performance of the proposed methods.
- What evidence would resolve it: Formal regret analysis proving upper bounds for TEUCB and TETS, with comparison to existing regret bounds for other bandit methods, would establish the theoretical foundation for their empirical success.

### Open Question 3
- Question: How does the performance of TEUCB and TETS scale with increasing numbers of arms, particularly in high-dimensional action spaces or combinatorial settings with very large super arm sets?
- Basis in paper: [inferred] The paper demonstrates strong performance on datasets with up to 7 arms and real-world navigation with ~5,000 edges, but does not systematically study the scaling behavior as the number of arms increases dramatically.
- Why unresolved: While the authors note that TEUCB and TETS generalize well across arms (unlike TreeBootstrap which uses separate models per arm), they do not investigate the computational or statistical efficiency limits as the action space grows exponentially.
- What evidence would resolve it: Systematic experiments varying the number of arms from small to very large scales, measuring both cumulative regret and computational runtime, would reveal the scaling properties and practical limits of the methods.

## Limitations

- The independence assumption between tree outputs may lead to underestimation of variance in practice, particularly for boosting methods like XGBoost
- Experimental comparisons use default neural network architectures rather than carefully tuned models, potentially overstating tree ensemble advantages
- The incremental update mechanism's efficiency gains are not rigorously benchmarked against alternative approaches

## Confidence

- High confidence: The mathematical formulation of uncertainty estimation and the algorithmic framework for TEUCB/TETS are well-defined and reproducible
- Medium confidence: Empirical performance claims are supported by experiments but could benefit from additional baselines and ablation studies
- Low confidence: The theoretical guarantees for the variance estimation approach and the independence assumptions underlying the method

## Next Checks

1. Test the independence assumption by measuring correlation between tree outputs on controlled synthetic datasets and analyzing how this affects variance estimation accuracy
2. Implement an ablation study comparing full model retraining versus incremental updates to quantify the claimed computational efficiency gains
3. Add experiments with deeper neural networks (more layers/hidden units) to establish whether the performance gap persists under stronger neural baselines