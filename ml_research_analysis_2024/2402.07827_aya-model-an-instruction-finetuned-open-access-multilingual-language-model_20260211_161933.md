---
ver: rpa2
title: 'Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model'
arxiv_id: '2402.07827'
source_url: https://arxiv.org/abs/2402.07827
tags:
- languages
- language
- arxiv
- flores-200
- spbleu
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The Aya model addresses linguistic inequality in large language
  models by instruction-finetuning a 13B mT5 model on 101 languages, over half of
  which are lower-resourced. It expands training data to 203M examples across 101
  languages using a mix of multilingual templates, human annotations, translated datasets,
  and synthetic generations.
---

# Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model
## Quick Facts
- arXiv ID: 2402.07827
- Source URL: https://arxiv.org/abs/2402.07827
- Reference count: 40
- Primary result: Aya model instruction-finetuned on 203M examples across 101 languages, outperforming mT0 and BLOOMZ on generative and discriminative tasks

## Executive Summary
The Aya model addresses linguistic inequality in large language models by instruction-finetuning a 13B mT5 model on 101 languages, with over half being lower-resourced. The model expands training data to 203M examples using multilingual templates, human annotations, translated datasets, and synthetic generations. Evaluation across 99 languages shows Aya outperforming mT0 and BLOOMZ on both generative and discriminative tasks, with 13.1% and 11.7% relative gains respectively.

Human and GPT-4 preference evaluations demonstrate 75-89% win rates over mT0, while safety mitigation via multilingual context distillation reduces harmful outputs by 78-89%. The model is released under Apache 2.0 license to support multilingual research and address representation gaps in existing language models.

## Method Summary
The Aya model is developed through instruction-finetuning of a 13B mT5 model on an expanded multilingual dataset. The training corpus combines 203M examples across 101 languages, including over half lower-resourced languages. The data mix consists of multilingual templates, human-annotated instructions, translated existing datasets, and synthetic generations produced through various techniques including chain-of-thought, code generation, and reasoning tasks. The model is evaluated on 99 languages across multiple tasks, comparing performance against mT0 and BLOOMZ baselines using both human preference judgments and GPT-4 evaluations. Safety improvements are achieved through multilingual context distillation approaches.

## Key Results
- 13.1% relative improvement over mT0 on generative tasks across 99 languages
- 11.7% relative improvement over mT0 on discriminative tasks
- 75-89% win rate in human and GPT-4 preference evaluations against mT0
- 78-89% reduction in harmful outputs through safety mitigation techniques

## Why This Works (Mechanism)
The model's success stems from its comprehensive multilingual approach that addresses both data quantity and quality across underrepresented languages. By combining diverse data sources including human annotations, translations, and synthetic generations, Aya captures instruction-following capabilities across linguistic and cultural contexts. The multilingual context distillation for safety ensures that harm reduction is effective across all supported languages rather than being limited to high-resource ones. The instruction-finetuning approach allows the model to better understand and respond to diverse user prompts while maintaining strong performance across both generative and discriminative tasks.

## Foundational Learning
- **Multilingual instruction-finetuning**: Adapting large language models to follow instructions across multiple languages simultaneously. Why needed: Existing models show significant performance degradation on non-English languages. Quick check: Compare zero-shot performance across language families.
- **Synthetic data generation**: Creating training examples programmatically to expand coverage of linguistic phenomena. Why needed: Limited availability of high-quality instruction data for many languages. Quick check: Measure diversity metrics across synthetic generations.
- **Multilingual context distillation**: Transferring safety knowledge across languages using contextual embeddings. Why needed: Safety interventions often fail on underrepresented languages. Quick check: Test harm reduction across language families.
- **Cross-lingual evaluation**: Assessing model performance across diverse linguistic and cultural contexts. Why needed: Aggregate metrics can mask significant performance gaps. Quick check: Analyze per-language performance distributions.
- **Preference-based evaluation**: Using human and automated judgments to compare model outputs. Why needed: Traditional metrics often fail to capture instruction-following quality. Quick check: Validate preference consistency across raters.

## Architecture Onboarding
**Component map**: Base mT5-13B model -> Multilingual instruction finetuning -> Synthetic data augmentation -> Safety distillation -> Preference evaluation
**Critical path**: Data preparation → Model finetuning → Safety mitigation → Evaluation pipeline
**Design tradeoffs**: The model prioritizes broad language coverage over maximum performance in any single language, accepting potential quality compromises to achieve representation across 101 languages.
**Failure signatures**: Performance degradation on languages with limited training data, potential safety gaps in underrepresented linguistic contexts, and possible contamination from synthetic data in evaluation sets.
**First experiments**:
1. Evaluate baseline mT5-13B performance across all 101 languages to establish performance gaps
2. Test safety mitigation effectiveness on a subset of underrepresented languages
3. Conduct ablation study removing synthetic data components to measure their contribution

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Potential contamination of evaluation datasets by synthetic training data, which could inflate performance metrics
- Preference-based evaluations may introduce bias when comparing across diverse linguistic and cultural contexts
- Safety mitigation lacks detailed analysis of specific harm categories and may have introduced new gaps in underrepresented languages

## Confidence
- **Outperformance claims (High)**: Quantitative metrics show consistent improvements over mT0 and BLOOMZ across multiple task types
- **Linguistic inequality impact (Medium-Low)**: Demonstrates technical progress but limited evidence of practical benefits for speakers of lower-resourced languages
- **Preference evaluation results (High)**: Strong win rates but require careful calibration for cross-cultural comparisons
- **Safety improvements (Medium)**: Technically sound approach but limited disclosure of testing methodologies and harm categories

## Next Checks
1. Conduct ablation studies removing synthetic data components to quantify their impact on performance gains and evaluate potential contamination effects
2. Implement blind third-party evaluations across diverse linguistic communities to validate preference metrics and safety claims
3. Perform comprehensive error analysis focusing on under-represented language families to identify systematic biases or performance gaps not captured in aggregate metrics