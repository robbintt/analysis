---
ver: rpa2
title: 'Reasoning Aware Self-Consistency: Leveraging Reasoning Paths for Efficient
  LLM Sampling'
arxiv_id: '2408.17017'
source_url: https://arxiv.org/abs/2408.17017
tags:
- reasoning
- rasc
- answer
- consistency
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Reasoning-Aware Self-Consistency (RASC),
  a framework that improves sampling efficiency and reasoning faithfulness in LLM
  reasoning tasks by dynamically evaluating both outputs and rationales. RASC assesses
  the quality of reasoning and consistency of answers for each generated sample, using
  these assessments to guide early stopping decisions and rationale selection.
---

# Reasoning Aware Self-Consistency: Leveraging Reasoning Paths for Efficient LLM Sampling

## Quick Facts
- arXiv ID: 2408.17017
- Source URL: https://arxiv.org/abs/2408.17017
- Authors: Guangya Wan; Yuqi Wu; Jie Chen; Sheng Li
- Reference count: 39
- Primary result: RASC reduces sample usage by ~70% while maintaining accuracy and improves rationale faithfulness through reasoning-quality-aware sampling

## Executive Summary
This paper introduces Reasoning-Aware Self-Consistency (RASC), a framework that improves sampling efficiency and reasoning faithfulness in LLM reasoning tasks by dynamically evaluating both outputs and rationales. RASC assesses the quality of reasoning and consistency of answers for each generated sample, using these assessments to guide early stopping decisions and rationale selection. The framework employs criteria-based stopping and weighted majority voting, enabling more informed choices on when to halt sampling and which rationale to select. Experiments across diverse question-answering datasets demonstrate that RASC outperforms existing methods, reducing sample usage by approximately 70% while maintaining accuracy. RASC also facilitates selection of high-fidelity rationales, thereby improving the faithfulness of LLM outputs.

## Method Summary
RASC implements a reasoning-aware self-consistency framework that evaluates both reasoning paths and final answers using a sufficiency scoring function combining reasoning quality and answer consistency features. The method dynamically manages a buffer of high-quality samples, stopping generation when the buffer reaches a predefined capacity determined by a sufficiency score threshold. Final answers and rationales are selected through weighted majority voting based on sufficiency scores, giving more influence to samples with higher-quality reasoning paths and more consistent answers.

## Key Results
- RASC achieves approximately 70% reduction in sample usage while maintaining accuracy across mathematical, commonsense, and symbolic reasoning tasks
- The framework consistently outperforms existing methods in sample efficiency while preserving or improving answer accuracy
- RASC demonstrates superior rationale selection quality, leading to more faithful chain-of-thought reasoning outputs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Higher-quality reasoning paths lead to better final answers and more efficient sampling decisions
- Mechanism: RASC evaluates both the reasoning paths and final answers using a sufficiency scoring function that combines reasoning quality and answer consistency features. This dual evaluation allows RASC to identify high-quality samples early and stop sampling when a consistent pattern emerges.
- Core assumption: There is a strong correlation between the quality of intermediate reasoning steps and the correctness of final answers
- Evidence anchors:
  - [abstract]: "RASC assesses the quality of reasoning and the consistency of answers for each generated sample, using these assessments to guide early stopping decisions and rationale selection"
  - [section 3.1]: "These features capture the coherence, relevance, and depth of the reasoning process" and "Our comprehensive ablation studies reveal the crucial interplay between reasoning-level and answer-level features"
  - [corpus]: Weak - The corpus shows related work on adaptive sampling but doesn't directly validate the reasoning-quality-to-answer-quality correlation

### Mechanism 2
- Claim: Weighted majority voting based on sufficiency scores improves answer selection over uniform voting
- Mechanism: RASC uses weighted majority voting where each sample's vote is weighted by its sufficiency score, giving more influence to samples with higher-quality reasoning paths and more consistent answers
- Core assumption: Samples with higher sufficiency scores are more likely to contain the correct answer and faithful reasoning
- Evidence anchors:
  - [abstract]: "RASC employs criteria-based stopping and weighted majority voting, enabling more informed choices on when to halt sampling and which rationale to select"
  - [section 3.2]: "RASC determines the final answer and reasoning path through weighted majority voting using the sufficiency scores"
  - [corpus]: Weak - Related work mentions weighted voting but doesn't provide evidence for sufficiency-score-based weighting specifically

### Mechanism 3
- Claim: Dynamic stopping based on sufficiency score thresholds reduces sample count while maintaining accuracy
- Mechanism: RASC maintains a buffer of high-quality samples and stops sampling when the buffer reaches a predefined capacity, determined by a sufficiency score threshold
- Core assumption: A small set of high-quality samples can achieve similar accuracy to larger sets of mixed-quality samples
- Evidence anchors:
  - [abstract]: "RASC outperforms existing methods, reducing sample usage by approximately 70% while maintaining accuracy"
  - [section 4.2]: "RASC consistently achieves superior sample efficiency while maintaining similar accuracy across mathematical, commonsense, and symbolic reasoning tasks"
  - [corpus]: Moderate - The corpus shows other adaptive stopping methods but doesn't specifically validate sufficiency-score-based stopping

## Foundational Learning

- Concept: Chain-of-Thought (CoT) prompting
  - Why needed here: RASC builds on CoT by evaluating the intermediate reasoning steps, not just final answers
  - Quick check question: What is the primary purpose of CoT prompting in LLM reasoning tasks?

- Concept: Self-consistency sampling
  - Why needed here: RASC extends self-consistency by adding reasoning quality evaluation to the sampling process
  - Quick check question: How does self-consistency typically select the final answer from multiple generated samples?

- Concept: Feature engineering for NLP
  - Why needed here: RASC relies on handcrafted features to evaluate reasoning quality and answer consistency
  - Quick check question: What types of features would capture the coherence between consecutive reasoning steps?

## Architecture Onboarding

- Component map: Input → LLM generation → Feature extraction (reasoning quality + answer consistency) → Sufficiency scoring → Buffer management → Weighted majority voting → Output
- Critical path: LLM generation → Feature extraction → Sufficiency scoring → Buffer management → Weighted majority voting
- Design tradeoffs: Balancing sufficiency score threshold (T) and buffer size (N) to optimize between efficiency and accuracy
- Failure signatures: Premature stopping (threshold too high), insufficient efficiency gains (threshold too low), poor rationale selection (scoring model inadequate)
- First 3 experiments:
  1. Compare RASC with different sufficiency scoring models (Logistic Regression vs Random vs HHEM) on a small dataset
  2. Test RASC with varying T and N parameters to find optimal efficiency-accuracy tradeoff
  3. Validate rationale selection quality by comparing RASC-selected rationales with human-annotated "golden" rationales using automated metrics and manual evaluation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the feature extraction process in RASC be optimized to reduce computational overhead while maintaining effectiveness?
- Basis in paper: [inferred] The paper mentions that the feature extraction process adds processing time, which could impact performance in scenarios requiring rapid responses or when handling large batches of simple queries.
- Why unresolved: The paper does not provide specific solutions or techniques to address this limitation, leaving room for further research.
- What evidence would resolve it: Experiments demonstrating reduced computational overhead with minimal impact on RASC's effectiveness, such as adaptive strategies that dynamically adjust feature computation based on runtime constraints.

### Open Question 2
- Question: What are the most effective ways to improve the faithfulness evaluation of RASC beyond automated metrics and limited human evaluation?
- Basis in paper: [explicit] The paper acknowledges that while improvements in faithfulness have been shown, the evaluation relies on automated metrics and limited human evaluation, suggesting a need for more extensive human evaluation.
- Why unresolved: The paper does not provide a detailed methodology for conducting more extensive human evaluation to strengthen the evidence of RASC's faithfulness improvements.
- What evidence would resolve it: Results from a comprehensive human evaluation study that provides stronger evidence on RASC's ability to select high-fidelity chain-of-thought reasoning.

### Open Question 3
- Question: How can the sufficiency scoring function in RASC be optimized to better capture reasoning quality and improve the decision to stop sampling?
- Basis in paper: [explicit] The paper suggests that future research could explore optimizing the structure of the function g(ri) via feature selection or more sophisticated scoring functions.
- Why unresolved: The paper does not provide specific methods or techniques to optimize the sufficiency scoring function, leaving this as an open area for further investigation.
- What evidence would resolve it: Experiments demonstrating improved performance of RASC with an optimized sufficiency scoring function, such as enhanced accuracy or reduced sample usage.

## Limitations

- The framework assumes correlation between reasoning quality and answer correctness, which may not hold across all reasoning types or LLM architectures
- Computational overhead from feature extraction and sufficiency scoring may offset some efficiency gains in resource-constrained environments
- Effectiveness on complex reasoning domains (scientific, legal, medical) remains untested beyond commonsense, mathematical, and symbolic reasoning

## Confidence

**High Confidence**: The mechanism of weighted majority voting based on sample quality scores is well-established and theoretically sound. The claim that RASC reduces sample usage by approximately 70% is supported by experimental results.

**Medium Confidence**: The correlation between reasoning quality and answer correctness, while intuitive, requires further validation across diverse reasoning tasks and LLM architectures. The effectiveness of the specific feature set for reasoning quality assessment may vary with different models.

**Low Confidence**: Claims about improved faithfulness of selected rationales are based on limited evaluation. The framework's performance on out-of-distribution tasks, while promising, needs more extensive validation.

## Next Checks

1. **Cross-Architecture Validation**: Test RASC with multiple LLM architectures (different base models and sizes) to verify that the sufficiency scoring function generalizes beyond the specific model used in initial experiments.

2. **Long-Horizon Reasoning**: Evaluate RASC on tasks requiring extended reasoning chains (20+ steps) to assess whether the reasoning quality features remain effective for longer, more complex reasoning processes.

3. **Human Evaluation of Rationale Faithfulness**: Conduct systematic human evaluation comparing RASC-selected rationales against those selected by existing methods, measuring both faithfulness and utility for human understanding of the reasoning process.