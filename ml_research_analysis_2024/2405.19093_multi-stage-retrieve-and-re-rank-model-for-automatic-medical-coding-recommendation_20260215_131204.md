---
ver: rpa2
title: Multi-stage Retrieve and Re-rank Model for Automatic Medical Coding Recommendation
arxiv_id: '2405.19093'
source_url: https://arxiv.org/abs/2405.19093
tags:
- codes
- label
- knowledge
- code
- auxiliary
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses automatic ICD coding, which assigns medical
  codes to electronic health records. Existing methods struggle with the large number
  of ICD codes and their imbalanced distribution.
---

# Multi-stage Retrieve and Re-rank Model for Automatic Medical Coding Recommendation

## Quick Facts
- arXiv ID: 2405.19093
- Source URL: https://arxiv.org/abs/2405.19093
- Reference count: 17
- Primary result: Proposes multi-stage retrieve and re-rank framework for ICD coding achieving SOTA on MIMIC-III

## Executive Summary
This paper addresses the challenge of automatic ICD coding by proposing a multi-stage retrieve and re-rank framework that significantly outperforms existing methods on the MIMIC-III benchmark. The approach first retrieves a candidate list of ICD codes using auxiliary knowledge (DRG, CPT, medications) combined with BM25, then re-ranks these candidates using contrastive learning guided by label co-occurrence patterns. The method demonstrates state-of-the-art performance across multiple evaluation metrics, particularly excelling in handling the long-tail distribution of ICD codes through its staged approach.

## Method Summary
The proposed method employs a two-stage framework for automatic ICD coding. First, a retrieval stage uses auxiliary knowledge from electronic health records (DRG codes, CPT codes, and drug prescriptions) combined with BM25 to efficiently collect high-quality candidate ICD codes from the full label space of ~8,000 codes down to ~1,300 candidates. Second, a re-ranking stage employs contrastive learning where Clinical-Longformer encodes clinical notes and Graphormer encodes label co-occurrence information, optimizing similarity between notes and their true ICD codes. The contrastive learning component pulls together related clinical-note/label pairs while pushing apart unrelated pairs to improve ranking accuracy.

## Key Results
- Achieves state-of-the-art performance on MIMIC-III benchmark across multiple metrics (F1-score, precision at K)
- Demonstrates significant improvements over existing methods by reducing label space from ~8,000 to ~1,300 candidates before ranking
- Shows both auxiliary knowledge retrieval and label co-occurrence components contribute significantly to improved performance
- Clinical-Longformer substantially outperforms Clinical-BERT, highlighting importance of handling longer clinical notes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The multi-stage retrieval and re-ranking framework improves performance by reducing the label space from ~8,000 ICD codes to ~1,300 candidates before ranking.
- Mechanism: By using auxiliary knowledge (DRG, CPT, medications) and BM25 in the retrieval stage, the system narrows the label space, then uses contrastive learning with code co-occurrence to rank candidates more accurately.
- Core assumption: Most ICD codes in the candidate list are more likely to be relevant than randomly sampled from the full label space.
- Evidence anchors:
  - [abstract] "The retrieval model is a hybrid of auxiliary knowledge of the electronic health records (EHR) and a discrete retrieval method (BM25), which efficiently collects high-quality candidates."
  - [section 3.2] "CBM25 ⊆ C auxiliary and Cauxiliary ⊆ Y"
  - [corpus] Weak - no direct citation supporting the size reduction claim.
- Break condition: If auxiliary knowledge is sparse or BM25 threshold too high, recall drops and the re-ranking stage cannot recover.

### Mechanism 2
- Claim: Contrastive learning with code co-occurrence improves ranking by pulling together clinical notes and their ground-truth ICD codes while pushing apart unrelated pairs.
- Mechanism: Graphormer encodes label co-occurrence into label representations; Clinical-Longformer encodes clinical notes; contrastive loss optimizes similarity between notes and their true codes.
- Core assumption: Code co-occurrence patterns in training data reflect true clinical relationships that can generalize to unseen notes.
- Evidence anchors:
  - [abstract] "we propose a label co-occurrence guided contrastive re-ranking model, which re-ranks the candidate labels by pulling together the clinical notes with positive ICD codes."
  - [section 3.3] "Contrastive learning aims to learn the effective representations by pulling together the clinical notes and its associated ICD codes."
  - [corpus] Weak - no direct citation supporting generalization claim.
- Break condition: If code co-occurrence graph is too sparse or noisy, contrastive learning may reinforce incorrect associations.

### Mechanism 3
- Claim: Using Clinical-Longformer instead of Clinical-BERT improves performance by handling longer clinical notes (average 1,596 tokens vs. 512 token limit).
- Mechanism: Longer sequence encoding captures more context from discharge summaries, improving representation quality for downstream classification.
- Core assumption: Longer input sequences contain clinically relevant information that shorter encodings miss.
- Evidence anchors:
  - [section 4.3] "Clinical-Longformer substantially outperforms Clinical-BERT, indicating the importance of the maximum token limit on language models in the automatic medical coding task."
  - [corpus] Weak - no direct citation supporting the 1,596 token claim.
- Break condition: If most clinical notes are shorter than 512 tokens, benefit diminishes.

## Foundational Learning

- Concept: Multi-label classification
  - Why needed here: ICD coding assigns multiple codes to each record, requiring modeling of label co-occurrence.
  - Quick check question: What distinguishes multi-label from multi-class classification?

- Concept: Contrastive learning
  - Why needed here: Pulls together related clinical-note/label pairs while pushing apart unrelated pairs to improve ranking.
  - Quick check question: How does contrastive loss differ from cross-entropy loss?

- Concept: BM25 retrieval
  - Why needed here: Efficiently retrieves candidate labels by matching clinical text with label descriptors before ranking.
  - Quick check question: What role does IDF play in BM25 scoring?

## Architecture Onboarding

- Component map: Clinical-Longformer (clinical note encoder) -> Graphormer (label co-occurrence encoder) -> Contrastive re-ranking layer -> ICD code recommendations
- Critical path: Retrieval stage (auxiliary knowledge + BM25) -> Re-ranking stage (contrastive learning) -> Final predictions
- Design tradeoffs: Retrieval stage reduces computation but may lose recall; contrastive learning adds training complexity but improves ranking quality
- Failure signatures: Low recall in retrieval stage -> poor overall performance; noisy co-occurrence graph -> contrastive learning degrades
- First 3 experiments:
  1. Remove auxiliary knowledge retrieval and measure impact on F1
  2. Replace Clinical-Longformer with Clinical-BERT and compare performance
  3. Remove code co-occurrence graph and measure impact on ranking accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed multi-stage retrieve and re-rank framework scale when extended to larger medical datasets or different medical coding systems?
- Basis in paper: [inferred] The paper evaluates the model on the MIMIC-III dataset, but the authors acknowledge that their study is constrained by evaluation limited to this dataset. They also mention the potential for extending the framework with more external knowledge sources like UMLS and code synonymy.
- Why unresolved: The paper does not provide experiments or analysis on how the framework would perform on larger datasets or different coding systems. Scaling to larger datasets may present challenges in terms of computational resources and model performance.
- What evidence would resolve it: Experiments comparing the framework's performance on multiple datasets of varying sizes and different medical coding systems would provide evidence of its scalability and generalizability.

### Open Question 2
- Question: How does the choice of threshold η for filtering noisy co-occurrences in the auxiliary knowledge retrieval stage impact the model's performance?
- Basis in paper: [explicit] The paper mentions that a threshold η is used to filter noisy correlations between ICD codes and auxiliary knowledge, and they set η = 0.005. They also discuss how the choice of η determines the candidate numbers and implicitly affects the overall performance.
- Why unresolved: The paper does not provide a detailed analysis of how different values of η impact the model's performance. It is unclear whether the chosen value of 0.005 is optimal or if there is a range of values that yield similar results.
- What evidence would resolve it: Experiments varying the threshold η and measuring the impact on model performance would provide insights into the sensitivity of the model to this hyperparameter and help determine an optimal range for η.

### Open Question 3
- Question: How does the proposed framework perform on rare diseases or infrequently occurring ICD codes?
- Basis in paper: [explicit] The paper acknowledges that the occurrence frequencies of ICD codes are imbalanced, with a long-tail distribution. They conduct experiments comparing their model's performance on ICD codes at different frequency levels, showing improvements on both frequent and infrequent labels.
- Why unresolved: While the paper demonstrates improvements on infrequent labels, it does not provide a comprehensive analysis of the framework's performance specifically on rare diseases. The authors mention that future work could benefit from a curated list of rare diseases validated by domain experts.
- What evidence would resolve it: Experiments specifically focusing on rare diseases or ICD codes with very low occurrence frequencies, using a curated list validated by domain experts, would provide evidence of the framework's effectiveness in handling rare cases.

## Limitations

- The framework's effectiveness depends on the availability of auxiliary knowledge (DRG, CPT codes, medications) which may not be present in all datasets
- Code co-occurrence patterns may propagate biases present in the training data and could degrade performance when applied to different clinical populations
- The multi-stage approach adds complexity and computational overhead compared to single-stage classification methods

## Confidence

- **High confidence**: The multi-stage framework architecture and its core components (BM25 retrieval, contrastive learning) are well-supported by the experimental results and ablation studies.
- **Medium confidence**: The specific contribution of Clinical-Longformer over Clinical-BERT is demonstrated, though the 1,596 token average claim lacks direct citation support.
- **Medium confidence**: The generalization of code co-occurrence patterns to unseen notes is assumed but not directly validated across different clinical populations.

## Next Checks

1. Perform cross-dataset validation by testing the model on a different ICD coding dataset (e.g., from a different hospital system) to assess generalizability beyond MIMIC-III.
2. Conduct an ablation study varying the BM25 threshold (θ) to identify the optimal balance between recall and precision in the retrieval stage.
3. Evaluate model performance on clinical notes from different demographic groups to assess potential bias propagation from the code co-occurrence graph.