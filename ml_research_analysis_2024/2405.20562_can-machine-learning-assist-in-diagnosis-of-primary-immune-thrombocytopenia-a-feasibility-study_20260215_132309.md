---
ver: rpa2
title: Can Machine Learning Assist in Diagnosis of Primary Immune Thrombocytopenia?
  A feasibility study
arxiv_id: '2405.20562'
source_url: https://arxiv.org/abs/2405.20562
tags:
- performance
- kollias
- blood
- demographic-aware
- demographic-unaware
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This feasibility study explored whether machine learning models
  could assist in diagnosing primary immune thrombocytopenia (ITP) using routine blood
  tests and demographic data from a non-acute outpatient setting. Multiple ML models,
  including Logistic Regression, Support Vector Machine, k-Nearest Neighbor, Decision
  Tree, and Random Forest, were applied to data from the UK Adult ITP Registry and
  a general hematology clinic.
---

# Can Machine Learning Assist in Diagnosis of Primary Immune Thrombocytopenia? A feasibility study

## Quick Facts
- arXiv ID: 2405.20562
- Source URL: https://arxiv.org/abs/2405.20562
- Reference count: 40
- Primary result: ML models (Random Forest, Decision Tree) achieved near-perfect predictive performance for ITP diagnosis using routine blood tests and demographic data

## Executive Summary
This feasibility study investigated whether machine learning models could assist in diagnosing primary immune thrombocytopenia (ITP) using routine blood tests and demographic data from a non-acute outpatient setting. The study applied multiple ML models to data from the UK Adult ITP Registry and a general hematology clinic, testing both blood test-only and combined demographic approaches. Decision Tree and Random Forest models demonstrated nearly perfect predictive performance and fairness scores, with platelet count identified as the most significant diagnostic variable. The findings suggest ML models could enhance ITP diagnostic processes, enabling earlier and more accurate diagnosis while reducing healthcare system burden.

## Method Summary
The study employed a retrospective analysis of routine blood test results and demographic data from the UK Adult ITP Registry and a general hematology clinic. Multiple machine learning models were applied including Logistic Regression, Support Vector Machine, k-Nearest Neighbor, Decision Tree, and Random Forest. Two modeling approaches were tested: one using only blood test results and another incorporating demographic information. Model performance was evaluated using standard metrics including accuracy, fairness scores, and variable importance analysis to identify the most predictive features for ITP diagnosis.

## Key Results
- Random Forest and Decision Tree models achieved near-perfect predictive performance and fairness scores
- Platelet count emerged as the most significant variable for ITP diagnosis
- Models without demographic information showed higher predictive accuracy but lower fairness scores, revealing a performance-fairness trade-off
- ML models demonstrated potential to enhance diagnostic accuracy and enable earlier ITP diagnosis

## Why This Works (Mechanism)
The effectiveness of ML models for ITP diagnosis stems from their ability to identify complex patterns in routine blood test data that correlate with the disease. The near-perfect performance suggests these models can effectively capture the characteristic features of ITP, particularly the low platelet counts that define the condition. The models' ability to process multiple variables simultaneously allows them to recognize subtle diagnostic patterns that might be missed by traditional clinical assessment methods.

## Foundational Learning
This study demonstrates that ML models can effectively learn diagnostic patterns from structured medical data, particularly when dealing with conditions that have clear quantitative markers like platelet counts. The research suggests that combining routine clinical measurements with appropriate ML algorithms can yield highly accurate diagnostic tools. The performance-fairness trade-off observed when including demographic variables provides important insight into how model design choices impact both accuracy and equity in healthcare applications.

## Architecture Onboarding
Component map: Data Collection -> Preprocessing -> Feature Engineering -> Model Training -> Performance Evaluation -> Fairness Assessment
Critical path: The sequence from data preprocessing through feature engineering to model training represents the most critical workflow, as data quality and feature selection directly impact model performance
Design tradeoffs: The study balanced predictive accuracy against fairness metrics, particularly when including demographic variables that could improve model performance but potentially introduce bias
Failure signatures: Overfitting risk due to high performance metrics on limited dataset size; potential sampling bias from single registry source
First experiments: 1) Cross-validation on independent ITP datasets from multiple centers, 2) Prospective clinical trial comparing ML-assisted vs standard diagnosis, 3) Subgroup analysis across demographic groups and disease subtypes

## Open Questions the Paper Calls Out
The study raises questions about the generalizability of these findings to different healthcare settings and populations. It remains unclear how well these models would perform with data from different countries, healthcare systems, or patient populations. Additionally, the study prompts questions about how to best integrate these ML tools into existing clinical workflows and whether the performance-fairness trade-off observed here would persist in larger, more diverse datasets.

## Limitations
- Single UK registry and outpatient clinic data limits generalizability to other healthcare settings
- Lack of detailed demographic breakdowns raises concerns about potential sampling bias
- Near-perfect performance metrics warrant scrutiny for possible overfitting given small dataset size typical of rare disease registries
- No external validation data to confirm real-world applicability

## Confidence
- Confidence in primary findings: Medium
- Methodology soundness: High
- Real-world applicability: Medium
- External validation status: Low

## Next Checks
1. External validation on independent ITP datasets from multiple centers to assess generalizability
2. Prospective clinical validation comparing ML-assisted diagnosis against standard clinical practice in real-time settings
3. Detailed subgroup analysis to confirm fairness metrics across different demographic groups and disease subtypes