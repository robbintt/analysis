---
ver: rpa2
title: 'Syntactic Language Change in English and German: Metrics, Parsers, and Convergences'
arxiv_id: '2402.11549'
source_url: https://arxiv.org/abs/2402.11549
tags:
- sentences
- english
- german
- dependency
- length
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates syntactic language change in English and
  German over the past 160 years using dependency parsers and 15 syntactic metrics.
  It addresses concerns about using single parsers by comparing five different parsers
  (Stanford CoreNLP, StackPointer, Biaffine, TowerParse, Stanza) on corpora of parliamentary
  debates.
---

# Syntactic Language Change in English and German: Metrics, Parsers, and Convergences

## Quick Facts
- arXiv ID: 2402.11549
- Source URL: https://arxiv.org/abs/2402.11549
- Reference count: 30
- Primary result: Different parsers yield different conclusions about diachronic syntactic trends, with only 4% of cases showing opposite trends between English and German

## Executive Summary
This paper investigates syntactic language change in English and German over 160 years using dependency parsers and 15 syntactic metrics. The study addresses concerns about using single parsers by comparing five different parsers (Stanford CoreNLP, StackPointer, Biaffine, TowerParse, Stanza) on parliamentary debate corpora. Results show that parser choice significantly affects observed syntactic trends, with moderate inter-parser agreement (0.4-0.6 Cohen's Kappa). German exhibits more syntactic changes than English, particularly at sentence length extremes, and overall syntactic convergence is observed with only 4% of cases showing opposite trends between languages.

## Method Summary
The study applies five dependency parsers to preprocessed English (Hansard) and German (DeuParl) parliamentary debate corpora spanning 1803-2021 and 1867-2022 respectively. After sentence-level cleaning and filtering, 15 syntactic metrics are calculated for each sentence. The Mann Kendall trend test identifies diachronic trends, which are compared across parsers and between languages. Parser performance is evaluated on UD treebanks and adversarially attacked test sets to assess robustness to historical spelling and OCR errors. Inter-parser agreement is measured using Cohen's Kappa, and trends are compared between English and German to assess convergence.

## Key Results
- Parser choice significantly affects observed syntactic change trends (moderate inter-parser agreement of 0.4-0.6 Cohen's Kappa)
- German shows more syntactic changes than English, particularly for metrics related to dependency distance and tree structure
- Only 4% of cases show opposite trends between English and German, indicating overall syntactic convergence
- Syntactic changes are more frequent at sentence length extremes (very short and very long sentences)

## Why This Works (Mechanism)

### Mechanism 1
Parser choice directly affects observed syntactic change trends. Different dependency parsers encode varying linguistic assumptions and training data biases. When applied to historical data with noise (OCR errors, spelling variations), these differences propagate to syntactic metrics, leading to divergent conclusions about diachronic trends. The syntactic changes being measured are subtle enough that parser variations can mask or exaggerate real trends.

### Mechanism 2
Sentence length normalization is critical for valid diachronic analysis. Sentence length strongly correlates with syntactic complexity metrics. Without controlling for length, apparent trends in metrics like dependency distance may simply reflect changing average sentence lengths rather than genuine syntactic change. The relationship between sentence length and complexity metrics remains stable across time periods.

### Mechanism 3
German exhibits more syntactic change than English due to higher historical noise. German has undergone more extensive spelling reforms and OCR challenges than English. This creates more opportunities for parsers to encounter unfamiliar forms, leading to greater variation in parsing output and measured syntactic metrics over time. The types of noise in German data (spelling variation, OCR errors) significantly impact parser performance compared to English.

## Foundational Learning

- **Dependency parsing**: Why needed here: The entire study relies on extracting syntactic relationships from raw text. Understanding how parsers work (transition-based vs. graph-based) is essential for interpreting results and evaluating parser choices.
  - Quick check question: What's the fundamental difference between transition-based and graph-based dependency parsers?

- **Statistical significance testing**: Why needed here: The study uses Mann-Kendall tests to identify trends. Understanding how these tests work and their limitations is crucial for correctly interpreting "significant" findings.
  - Quick check question: What p-value threshold does the study use to determine significant trends, and what are the implications of this choice?

- **Inter-rater agreement**: Why needed here: The study reports Cohen's Kappa values between parsers. Understanding what these values mean (moderate agreement = 0.4-0.6) is essential for evaluating the reliability of multi-parser approaches.
  - Quick check question: What Cohen's Kappa value would indicate "strong" agreement between parsers, and why is this important for the study's conclusions?

## Architecture Onboarding

- **Component map**: Data ingestion → Preprocessing pipeline → Sentence segmentation → Tokenization/POS tagging → Multiple parser execution → Metric calculation → Statistical trend analysis → Comparison across languages/parsers
- **Critical path**: Corpus preprocessing → Sentence extraction → Parser execution → Metric calculation → Trend analysis
- **Design tradeoffs**: Using multiple parsers increases computational cost but reduces bias from any single parser's limitations. The preprocessing pipeline trades simplicity for potential information loss.
- **Failure signatures**: Inconsistent trends across parsers suggest either real linguistic complexity or parser inadequacy. High inter-parser agreement might indicate the changes are robust to parsing choices.
- **First 3 experiments**:
  1. Run all five parsers on a small sample of sentences and compare their output dependency trees to identify structural disagreements
  2. Test the preprocessing pipeline on sentences with known issues (OCR errors, spelling variations) to measure error correction effectiveness
  3. Apply the Mann-Kendall test to synthetic data with known trends to verify the implementation correctly identifies increasing/decreasing patterns

## Open Questions the Paper Calls Out

### Open Question 1
How does the syntactic convergence between English and German evolve over time? Does the similarity increase or decrease? The paper notes that English and German show largely similar syntactic changes (only 4% of cases show opposite trends), suggesting convergence, but does not analyze temporal trends in this similarity. A time-series analysis comparing matching vs. opposing syntactic trends between English and German for each decade or 20-year period would resolve this.

### Open Question 2
What specific linguistic mechanisms drive the observed syntactic changes in both languages? Are these driven by dependency distance minimization (DDM), other language processing constraints, or external factors? The paper observes patterns but doesn't establish causal mechanisms or test competing hypotheses for why these changes occur. Experimental studies manipulating sentence length, dependency structures, and processing difficulty would help resolve this.

### Open Question 3
How do different text genres within parliamentary debates (e.g., questions, statements, rebuttals) differ in their syntactic change trajectories? The paper uses homogeneous political debate corpora to ensure comparability, but notes this as a limitation and doesn't analyze genre-specific patterns. Genre classification of debate sections followed by separate analysis of syntactic trends for each genre would resolve this.

## Limitations
- Parser sensitivity affects conclusions, with moderate agreement (0.4-0.6 Cohen's Kappa) between different parsers
- German corpus contains substantially more spelling issues and OCR errors than English (over 40% of sentences affected)
- Historical coverage gaps create temporal mismatches between English (1803-2021) and German (1867-2022) corpora

## Confidence
- **High Confidence**: Parser choice affects observed syntactic trends; German shows more syntactic changes than English
- **Medium Confidence**: Overall syntactic convergence between English and German; identification of specific metrics showing trends
- **Low Confidence**: Exact nature and timing of specific syntactic changes; causal mechanisms driving observed patterns

## Next Checks
- Conduct parser agreement analysis on contemporary vs. historical sentences to distinguish genuine syntactic evolution from parsing artifacts
- Apply the same methodology to a third language with different historical orthography to test generalizability
- Perform ablation studies removing preprocessing pipeline to quantify impact of data cleaning vs. genuine language evolution