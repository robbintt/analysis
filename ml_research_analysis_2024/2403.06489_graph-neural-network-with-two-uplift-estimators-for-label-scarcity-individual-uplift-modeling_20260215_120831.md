---
ver: rpa2
title: Graph Neural Network with Two Uplift Estimators for Label-Scarcity Individual
  Uplift Modeling
arxiv_id: '2403.06489'
source_url: https://arxiv.org/abs/2403.06489
tags:
- uplift
- data
- treatment
- methods
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of uplift modeling, which aims
  to measure the incremental effect of a strategy or action on users from randomized
  experiments or observational data. The authors propose a graph neural network-based
  framework with two uplift estimators, called GNUM, to learn from social graphs for
  uplift estimation.
---

# Graph Neural Network with Two Uplift Estimators for Label-Scarcity Individual Uplift Modeling

## Quick Facts
- arXiv ID: 2403.06489
- Source URL: https://arxiv.org/abs/2403.06489
- Reference count: 40
- One-line primary result: GNUM framework achieves 5-10% improvement in regression and 12-25% improvement in classification uplift estimation using social graphs.

## Executive Summary
This paper addresses the challenge of uplift modeling with scarce labeled data by proposing a Graph Neural Network-based framework (GNUM) that leverages social graph information. The framework introduces two novel uplift estimators: a class-transformed target estimator that works for all outcome types by simultaneously modeling treatment and control groups, and a partial-label-based estimator for discrete outcomes that utilizes more labeled data from both groups. The approach significantly outperforms state-of-the-art methods on both public and industrial datasets while demonstrating robustness to label scarcity.

## Method Summary
GNUM is a graph neural network framework designed for uplift estimation in scenarios with scarce labeled data. It consists of a graph-based representation learning component using breadth and depth aggregators to capture neighbor and multi-hop structural information, combined with two uplift estimators. The class-transformed target estimator works for all outcome types by transforming observed outcomes into a target that estimates uplift when taking expectations. For discrete outcomes, a partial-label-based estimator further improves performance by utilizing more labeled data through a three-group classification approach. The model is trained using backpropagation with cross-entropy and L2 regularization.

## Key Results
- GNUM achieves 5-10% improvement in regression uplift estimation compared to state-of-the-art methods
- GNUM achieves 12-25% improvement in classification uplift estimation on public and industrial datasets
- The framework demonstrates robustness to label scarcity, maintaining performance as labeled data decreases

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: GNUM's class-transformed target estimator works because it allows simultaneous use of treatment and control group data, enabling better capture of the relationship between the two groups.
- **Mechanism**: The class-transformed target zᵢ = yᵢᵒᵇˢ · tᵢ − p/(p(1-p)) transforms the observed outcome into a target that is equal to the uplift when taking expectations, allowing a single model to be trained on both treatment and control groups.
- **Core assumption**: The uplift can be estimated as the expected value of the class-transformed target given features and graph information.
- **Evidence anchors**:
  - [abstract]: "The estimator is general for all types of outcomes, and is able to comprehensively model the treatment and control group data together to approach the uplift."
  - [section]: Proposition 1 proves that the uplift of user i can be estimated as E(zᵢ|xᵢ, G).
  - [corpus]: Weak - related works focus on general uplift modeling but not specifically on the class-transformed target mechanism.
- **Break condition**: If the probability p is not correctly estimated (e.g., due to non-randomized treatment assignment or biased sampling), the class-transformed target becomes biased.

### Mechanism 2
- **Claim**: GNUM's partial-label-based estimator works by effectively utilizing more labeled data from both treatment and control groups when the outcome is discrete.
- **Mechanism**: Partial labels are created based on treatment assignment and observed outcome, allowing two classifiers to focus on different facets of the uplift problem while using data from both groups.
- **Core assumption**: The three groups (A, B, C) defined by treatment response patterns are mutually exclusive and collectively exhaustive.
- **Evidence anchors**:
  - [abstract]: "When the outcome is discrete, we further design the other uplift estimator based on our defined partial labels, which is able to utilize more labeled data from both the treatment and control groups."
  - [section]: "In this way, on the one hand, more labeled data can be utilized to train each classifier, ensuring a better performance especially when the labeled data is scarce."
  - [corpus]: Weak - partial label learning is mentioned but not specifically in the context of uplift modeling with graph data.
- **Break condition**: If the outcome is continuous or if the treatment effect is not strictly positive as assumed, the partial label definitions become invalid.

### Mechanism 3
- **Claim**: GNUM's graph-based representation learning works because social neighbors provide complementary information that captures unobserved factors affecting uplift.
- **Mechanism**: The breadth and depth aggregators in GNUM combine local neighbor information with multi-layer global structural information to create more informative node representations.
- **Core assumption**: Users with close social relationships have more similar uplifts than random users.
- **Evidence anchors**:
  - [abstract]: "Considering that the neighbors' features and the social relationships are very informative to characterize a user's uplift, we propose a graph neural network-based framework..."
  - [section]: "From the experiments, we also demonstrate that the uplift difference between users with friend relationships is much smaller than the difference between random users."
  - [corpus]: Weak - related works discuss graph-based methods for causal inference but not specifically for uplift modeling with label scarcity.
- **Break condition**: If the social graph is sparse or contains noise, the neighbor information becomes less reliable and may introduce noise rather than useful signal.

## Foundational Learning

- **Concept**: Uplift modeling
  - Why needed here: The paper addresses uplift modeling specifically, which requires understanding the difference between treatment and control outcomes.
  - Quick check question: What is the fundamental challenge in uplift modeling that makes it different from standard prediction tasks?

- **Concept**: Graph neural networks
  - Why needed here: GNUM uses GNNs to incorporate social graph information into uplift estimation.
  - Quick check question: How do GNNs differ from traditional neural networks in handling relational data?

- **Concept**: Partial label learning
  - Why needed here: The partial-label-based estimator uses this technique to handle the uncertainty in uplift classification when only one potential outcome is observed.
  - Quick check question: In what way does partial label learning differ from standard supervised learning?

## Architecture Onboarding

- **Component map**: Input features and graph → GNN (breadth + depth aggregators) → Uplift estimation (class-transformed or partial-label) → Output uplift values
- **Critical path**: Input → GNN representation learning → Uplift estimation → Output
  The GNN representation learning is the most critical component as it incorporates the social graph information.
- **Design tradeoffs**:
  - Using class-transformed target vs. separate treatment/control models: The former uses data more efficiently but requires correct probability estimation.
  - Breadth vs. depth aggregation: Breadth captures immediate neighbor information while depth captures multi-hop structural patterns.
  - Partial label complexity: The three-group partial label system adds complexity but enables better utilization of scarce labeled data.
- **Failure signatures**:
  - Poor performance on treatment group data only: Indicates the class-transformed target estimator is not working correctly.
  - Similar performance to non-graph methods: Suggests the social graph information is not being effectively utilized.
  - Degradation with more labeled data: May indicate overfitting in the GNN layers.
- **First 3 experiments**:
  1. Implement and test the class-transformed target estimator on a simple dataset with known uplift values to verify the mathematical relationship.
  2. Compare the breadth aggregator alone vs. breadth+depth aggregator on a small social graph to measure the contribution of depth information.
  3. Test the partial label system on a binary outcome dataset to verify that the three classifiers correctly partition the data and improve performance.

## Open Questions the Paper Calls Out
The paper acknowledges in its conclusion that "we expect to utilize more types of graphs to estimate the user uplift," suggesting interest in exploring how GNUM might perform with different graph structures beyond social relationships, such as user-item interaction graphs or knowledge graphs.

## Limitations
- The framework's effectiveness depends heavily on correctly estimating the probability p for the class-transformed target estimator
- The partial-label-based estimator is only validated for discrete outcomes and may not generalize to continuous outcomes
- Experiments are conducted on relatively small-scale datasets, leaving questions about scalability to larger graphs

## Confidence
- **High**: The theoretical foundations of the class-transformed target estimator are well-established
- **Medium**: The partial-label-based estimator shows promise but is validated on limited scenarios
- **Medium**: The graph neural network architecture is sound but its contribution relative to other methods needs more rigorous ablation studies

## Next Checks
1. Test the framework on larger-scale social networks with millions of nodes to verify scalability claims and examine how performance scales with graph size.
2. Conduct ablation studies isolating the contribution of the breadth aggregator vs. depth aggregator to quantify the marginal benefit of each component.
3. Implement a robustness test with biased treatment assignment (deviating from the randomized assumption) to measure sensitivity to probability estimation errors.