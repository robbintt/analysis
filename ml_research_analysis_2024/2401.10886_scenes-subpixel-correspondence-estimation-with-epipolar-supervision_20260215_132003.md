---
ver: rpa2
title: 'SCENES: Subpixel Correspondence Estimation With Epipolar Supervision'
arxiv_id: '2401.10886'
source_url: https://arxiv.org/abs/2401.10886
tags:
- epipolar
- dataset
- image
- matches
- camera
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SCENES presents a method for finetuning local feature matching
  networks without requiring ground-truth correspondences, instead using only epipolar
  geometry constraints derived from camera poses. The method replaces standard correspondence
  losses with epipolar losses that encourage putative matches to lie on the associated
  epipolar lines.
---

# SCENES: Subpixel Correspondence Estimation With Epipolar Supervision

## Quick Facts
- arXiv ID: 2401.10886
- Source URL: https://arxiv.org/abs/2401.10886
- Authors: Dominik A. Kloepfer; João F. Henriques; Dylan Campbell
- Reference count: 40
- Primary result: Finetunes local feature matching networks using only epipolar geometry constraints, achieving state-of-the-art results without ground-truth correspondences

## Executive Summary
SCENES presents a method for adapting local feature matching networks to new domains without requiring ground-truth correspondences. Instead of standard correspondence losses, the method uses epipolar geometry constraints derived from camera poses to supervise the training process. The approach includes a bootstrapping strategy that eliminates the need for known camera poses by estimating fundamental matrices from matches found by pre-trained models. Evaluated on challenging indoor and outdoor datasets, SCENES significantly improves pose estimation metrics compared to baseline models while requiring minimal supervision.

## Method Summary
SCENES replaces standard correspondence losses with epipolar losses that encourage putative matches to lie on the associated epipolar lines. The method uses camera poses and intrinsics to compute fundamental matrices, then applies epipolar classification and regression losses at both coarse and fine matching stages. A bootstrapping approach allows finetuning without any pose supervision by estimating fundamental matrices from matches found by pre-trained models. The total loss combines coarse and fine epipolar losses with a hyperparameter λ controlling their relative importance.

## Key Results
- On EuRoC-MA V dataset, finetuned models achieve up to 28.8% higher matching precision
- Pose estimation AUC improvements of 6.1-17.7% across 5°, 10°, and 20° thresholds
- Bootstrapping approach achieves strong performance without ground-truth pose information
- State-of-the-art results on challenging indoor drone and outdoor smartphone datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Epipolar losses serve as weaker but effective supervision for finetuning feature matching networks without ground-truth correspondences.
- **Mechanism:** Replaces correspondence losses with epipolar losses that encourage matches to lie on epipolar lines, using only camera poses and intrinsics instead of 3D structure.
- **Core assumption:** Epipolar constraint provides sufficient information to guide model toward correct matches.
- **Evidence anchors:**
  - [abstract]: "We relax this assumption by removing the requirement of 3D structure...by replacing correspondence losses with epipolar losses"
  - [section 3.2]: Reformulates losses to only require fundamental matrix F instead of ground-truth correspondences
- **Break condition:** If epipolar constraint becomes too loose (wide-baseline) or camera poses are highly inaccurate

### Mechanism 2
- **Claim:** Bootstrapping approach enables finetuning without pose supervision by estimating fundamental matrices from pre-trained model matches.
- **Mechanism:** Uses pre-trained model to find matches, then applies RANSAC to estimate fundamental matrices for epipolar supervision.
- **Core assumption:** Robust estimator can recover accurate fundamental matrix from inlier matches despite many incorrect ones.
- **Evidence anchors:**
  - [abstract]: "We further relax the assumption of known camera poses by using pose estimates in a novel bootstrapping approach"
  - [section 3.4]: "Apply pre-trained model to obtain (poor quality) image correspondences, then use RANSAC to estimate fundamental matrices"
- **Break condition:** If pre-trained model produces too few accurate matches for reliable fundamental matrix estimation

### Mechanism 3
- **Claim:** Combined coarse and fine epipolar losses provide complementary supervision improving both match quantity and quality.
- **Mechanism:** Coarse loss encourages high confidence on epipolar line, fine loss encourages predicted coordinates close to epipolar line.
- **Core assumption:** Both confidence assignment and coordinate refinement are necessary for good performance.
- **Evidence anchors:**
  - [section 3.2]: "Total epipolar loss is Lepi = (1 - λ)f(C, Mepi) + λ (1/m') Σ g(depi(xk1, xk2))"
  - [section 4.3]: "Mixture of both losses leads to overall most reliable performance"
- **Break condition:** Poor λ balancing sacrifices one aspect of matching performance for the other

## Foundational Learning

- **Concept: Epipolar Geometry**
  - Why needed here: Epipolar losses rely on fundamental matrix and epipolar lines for supervision
  - Quick check question: Given two camera matrices P1 and P2, how would you compute the fundamental matrix F?

- **Concept: RANSAC (Random Sample Consensus)**
  - Why needed here: Used in bootstrapping to robustly estimate fundamental matrix from noisy matches
  - Quick check question: What is main advantage of RANSAC over least-squares when dealing with outliers?

- **Concept: Camera Pose Estimation**
  - Why needed here: Method requires camera poses to compute fundamental matrices and evaluates performance via pose estimation
  - Quick check question: How would you estimate relative pose between two cameras given corresponding points?

## Architecture Onboarding

- **Component map:** Image pairs (I1, I2) -> Coarse feature extraction -> Confidence matrix C -> Coarse match selection -> Fine feature extraction -> Epipolar losses -> Refined matches

- **Critical path:**
  1. Extract coarse features from image pairs
  2. Compute confidence matrix C
  3. Select coarse matches
  4. Extract fine features around coarse matches
  5. Compute epipolar classification and regression losses
  6. Backpropagate through both stages

- **Design tradeoffs:**
  - Epipolar losses reduce supervision requirements but provide weaker signal
  - Bootstrapping eliminates pose requirements but introduces fundamental matrix estimation noise
  - λ parameter balancing crucial for optimal coarse/fine performance

- **Failure signatures:**
  - Poor wide-baseline performance (epipolar constraint too loose)
  - Degradation with inaccurate camera poses (misaligned epipolar lines)
  - Overfitting to training domain during bootstrapping
  - Convergence failure when removing argmax from epipolar classification

- **First 3 experiments:**
  1. Test λ parameter impact on coarse/fine loss balance using validation set
  2. Compare performance using ground-truth vs bootstrapped fundamental matrices
  3. Evaluate effect of removing argmax from epipolar classification loss

## Open Questions the Paper Calls Out

- **Open Question 1:** How much does performance degrade with noisy or incorrect camera poses?
  - Basis in paper: Performance lower with bootstrapped vs ground-truth poses; ablation study perturbs poses by 1-2 degrees
  - Why unresolved: No detailed analysis of performance vs noise level; limited perturbation range in ablation
  - What evidence would resolve it: Study varying noise levels in poses/fundamental matrices with synthetic data or analysis of real datasets with known pose noise

- **Open Question 2:** Can SCENES be extended to multi-view settings beyond two images?
  - Basis in paper: Method focuses on two-image case but mentions potential for more views; fundamental matrix can be estimated from point correspondences
  - Why unresolved: No exploration of multi-view extension; unclear how epipolar constraints generalize to multiple views
  - What evidence would resolve it: Extension to multi-view settings with clear supervision definition and evaluation on multi-view datasets

- **Open Question 3:** How does argmax choice in epipolar classification loss affect performance?
  - Basis in paper: Argmax leads to better performance than naive epipolar classification; ablation study confirms this
  - Why unresolved: No detailed analysis of why argmax is beneficial or sensitivity to choice; unclear if alternatives could perform better
  - What evidence would resolve it: Detailed analysis of argmax impact including alternative strategies for selecting ground-truth match location

## Limitations
- Epipolar geometry constraints become too loose in wide-baseline scenarios
- Performance sensitive to camera pose accuracy and fundamental matrix estimation quality
- Method may struggle with dataset-specific variations requiring careful hyperparameter tuning

## Confidence
- High confidence: Core mechanism of using epipolar losses instead of correspondence losses is well-established
- Medium confidence: Bootstrapping approach effectiveness across diverse domains demonstrated but may have limited generalizability
- Medium confidence: State-of-the-art claims supported by specific dataset results but lack broader cross-dataset validation

## Next Checks
1. Test bootstrapping approach on dataset with known camera poses to quantify accuracy loss from estimated fundamental matrices
2. Evaluate performance degradation on wide-baseline image pairs (baseline/mean depth > 1.0) to identify practical limits
3. Conduct ablation study on λ parameter across different datasets to determine optimal balancing and robustness