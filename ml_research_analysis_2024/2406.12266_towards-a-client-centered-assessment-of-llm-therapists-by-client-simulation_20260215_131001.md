---
ver: rpa2
title: Towards a Client-Centered Assessment of LLM Therapists by Client Simulation
arxiv_id: '2406.12266'
source_url: https://arxiv.org/abs/2406.12266
tags: []
core_contribution: This work proposes ClientCAST, a client-centered approach to assess
  LLM therapists using simulated clients. Simulated clients, implemented by LLMs with
  psychological profiles, interact with LLM therapists and complete questionnaires
  about the interaction.
---

# Towards a Client-Centered Assessment of LLM Therapists by Client Simulation

## Quick Facts
- arXiv ID: 2406.12266
- Source URL: https://arxiv.org/abs/2406.12266
- Authors: Jiashuo Wang; Yang Xiao; Yanran Li; Changhe Song; Chunpu Xu; Chenhao Tan; Wenjie Li
- Reference count: 40
- Primary result: ClientCAST assesses LLM therapists using simulated clients with psychological profiles, showing comparable therapeutic alliance scores but lower self-reported feelings scores compared to human therapists

## Executive Summary
This work introduces ClientCAST, a client-centered approach for assessing LLM therapists using simulated clients implemented by LLMs with psychological profiles. The method evaluates therapy sessions based on session outcomes, therapeutic alliance, and self-reported feelings through questionnaire completion. Experiments demonstrate that simulated clients can effectively mimic real clients' language styles and distinguish between high- and low-quality counseling sessions. When comparing LLM therapists to human therapists, results show comparable performance in building therapeutic alliance but lower scores in self-reported feelings, particularly in positivity and smoothness dimensions.

## Method Summary
The ClientCAST approach uses LLMs to simulate clients with psychological profiles containing problems, symptoms, and apparent traits. These simulated clients interact with LLM therapists and complete standardized questionnaires (SRS, CECS, SEQ, WAI-SR, HAQ-II) measuring session outcome, therapeutic alliance, and self-reported feelings. The assessment engine computes final scores based on questionnaire responses. The method was tested using two human-human therapy datasets and four LLMs (Claude-3, GPT-3.5, LLaMA3-70B, Mixtral 8×7B) to evaluate and compare LLM therapists against human therapists.

## Key Results
- Simulated clients successfully mimic real clients' language styles and symptoms when provided with psychological profiles
- The assessment approach effectively distinguishes between high- and low-quality counseling sessions
- LLM therapists achieve comparable therapeutic alliance scores but lower self-reported feelings scores than human therapists
- Claude-3 and Llama 3-70B simulated clients perform better than GPT-3.5 and Mixtral 8×7B across most metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Simulated clients can consistently mimic real clients' language styles and symptoms when provided with appropriate psychological profiles
- Mechanism: LLMs equipped with psychological profiles containing problems, reasons for visiting, symptoms, and apparent traits generate responses matching client characteristics
- Core assumption: The LLM's ability to maintain consistency depends on model strength and profile richness
- Evidence anchors: [abstract] "Experiments show simulated clients can mimic real clients' language styles and distinguish high- from low-quality sessions"; [section] "Clients simulated by Claude-3 and Llama 3-70B perform better"
- Break condition: If the LLM lacks sufficient training data or the psychological profile is incomplete, the simulation may fail to accurately represent the client's characteristics

### Mechanism 2
- Claim: The assessment can effectively distinguish between high- and low-quality counseling sessions
- Mechanism: Simulated clients complete questionnaires (SRS, CECS, SEQ, WAI-SR, HAQ-II) about session outcome, therapeutic alliance, and self-reported feelings
- Core assumption: These questionnaires are valid measures of counseling session quality
- Evidence anchors: [abstract] "Experiments show simulated clients can mimic real clients' language styles and distinguish high- from low-quality sessions"; [section] "High- and low-quality sessions can be distinguished clearly"
- Break condition: If simulated clients cannot accurately complete questionnaires or if questionnaires lack sensitivity to detect quality differences

### Mechanism 3
- Claim: LLM therapists achieve comparable therapeutic alliance scores but lower self-reported feelings scores than human therapists
- Mechanism: LLM therapists interact with simulated clients and are assessed on their ability to build therapeutic alliance and impact client feelings
- Core assumption: Therapeutic alliance is a key factor in counseling effectiveness measurable through questionnaires
- Evidence anchors: [abstract] "Results show they achieve comparable therapeutic alliance scores but lower self-reported feelings scores than human therapists"; [section] "LLM therapists can foster strong connections with clients"
- Break condition: If LLM therapists cannot build therapeutic alliance or questionnaires cannot detect differences between LLM and human therapists

## Foundational Learning

- Concept: Understanding the basics of counseling therapy and the role of simulated clients in clinical medical education
  - Why needed here: To comprehend the context and purpose of using simulated clients to assess LLM therapists
  - Quick check question: What is the primary purpose of using simulated clients in clinical medical education?

- Concept: Familiarity with the structure and purpose of the questionnaires used in the assessment (SRS, CECS, SEQ, WAI-SR, HAQ-II)
  - Why needed here: To understand how assessment results are derived from completed questionnaires
  - Quick check question: Which questionnaire is used to measure the therapeutic alliance in counseling sessions?

- Concept: Knowledge of psychological profile components (problems, reasons for visiting, symptoms, apparent traits) and their role in guiding LLM simulation
  - Why needed here: To understand how the LLM generates responses matching client characteristics
  - Quick check question: What are the four main components of the psychological profile used to guide the LLM's simulation of a client?

## Architecture Onboarding

- Component map: Simulated Client -> Interaction with LLM Therapist -> Questionnaire Completion -> Assessment Result Computation
- Critical path: Simulated Client → Interaction with LLM Therapist → Questionnaire Completion → Assessment Result Computation
- Design tradeoffs:
  - Using LLMs for client simulation reduces costs and ethical concerns compared to human actors but may introduce bias and inconsistency
  - The choice of questionnaires affects the comprehensiveness and reliability of the assessment
  - The system prompt used to instruct the LLM therapist influences their performance and assessment results
- Failure signatures:
  - Inconsistent language styles or symptom display by the simulated client
  - Inability to distinguish between high- and low-quality sessions based on questionnaire results
  - LLM therapists achieving lower scores than expected in therapeutic alliance or self-reported feelings
- First 3 experiments:
  1. Evaluate the consistency of simulated clients in mimicking real clients' language styles and symptoms across different LLM models
  2. Assess the ability of the questionnaires to distinguish between high- and low-quality counseling sessions when completed by simulated clients
  3. Compare the performance of LLM therapists with human therapists in terms of therapeutic alliance and self-reported feelings using the ClientCAST approach

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different LLM biases towards specific personality traits affect the quality of simulated client interactions and subsequent therapy assessments?
- Basis in paper: [explicit] The paper identifies that different LLMs exhibit inherent biases towards certain personality traits, such as GPT-3.5 and Mixtral 8x7B simulated clients being more resilient while Claude-3 and Llama 3-70B simulated clients are more sensitive and less enthusiastic
- Why unresolved: The paper acknowledges these biases but does not explore their implications on therapy outcomes or how they might systematically affect assessment results across different therapeutic scenarios
- What evidence would resolve it: A study comparing therapy outcomes and assessment scores when using LLMs with different trait biases to simulate clients in various therapeutic scenarios, tracking how these biases correlate with session quality metrics

### Open Question 2
- Question: What are the long-term implications of using LLM-simulated clients for therapy assessment compared to human simulated clients in terms of ecological validity?
- Basis in paper: [inferred] The paper discusses limitations of current LLM simulation including inconsistency in personality portrayal and the trade-off between imperfect simulation and cost reduction, but doesn't address long-term validity concerns
- Why unresolved: While the paper demonstrates short-term reliability, it doesn't examine whether LLM-simulated clients maintain validity over extended periods or how their behavior might diverge from human clients in complex therapeutic scenarios
- What evidence would resolve it: Longitudinal studies comparing therapy outcomes and assessment consistency when using LLM-simulated clients versus human simulated clients across multiple therapy sessions and complex cases over extended periods

### Open Question 3
- Question: How does the excessive emotional focus in LLM therapist responses impact therapeutic outcomes compared to human therapists?
- Basis in paper: [explicit] The paper notes that LLM therapists focus significantly more on emotions, particularly positive ones, compared to human therapists, and may inappropriately use phrases like "It is understandable..." excessively
- Why unresolved: While the paper identifies this behavioral difference, it doesn't investigate whether this emotional focus actually helps or hinders therapy outcomes, or how it affects the therapeutic alliance and session effectiveness
- What evidence would resolve it: Comparative analysis of therapy outcomes, client satisfaction, and therapeutic alliance scores between LLM and human therapists, specifically examining how the emotional focus affects different types of therapeutic interventions and client populations

## Limitations
- Limited external validation - no comparison with human-rated therapy sessions or expert assessments
- The psychological profiles are synthetically generated rather than drawn from real clinical cases
- The assessment focuses on a narrow set of outcome measures and may miss other important therapeutic dimensions
- The comparison between LLM and human therapists uses a small sample (only 20 sessions)

## Confidence

- High Confidence: Simulated clients can successfully interact with LLM therapists and complete questionnaires
- Medium Confidence: The approach can distinguish high- from low-quality sessions
- Low Confidence: The specific claim that LLM therapists achieve comparable therapeutic alliance scores but lower self-reported feelings scores than human therapists

## Next Checks

1. Conduct blind evaluation where human experts rate the same therapy sessions used in the study to verify alignment between simulated and human assessments
2. Test the approach across diverse therapeutic modalities and client populations to assess generalizability
3. Implement longitudinal validation where simulated clients interact with the same therapist across multiple sessions to evaluate consistency of the assessment