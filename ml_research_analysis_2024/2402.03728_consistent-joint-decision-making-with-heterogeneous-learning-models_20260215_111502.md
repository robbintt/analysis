---
ver: rpa2
title: Consistent Joint Decision-Making with Heterogeneous Learning Models
arxiv_id: '2402.03728'
source_url: https://arxiv.org/abs/2402.03728
tags:
- decisions
- dataset
- prior
- constraints
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel decision-making framework that promotes
  consistency among decisions made by diverse models while utilizing external knowledge.
  Leveraging the Integer Linear Programming (ILP) framework, we map predictions from
  various models into globally normalized and comparable values by incorporating information
  about decisions' prior probability, confidence (uncertainty), and the models' expected
  accuracy.
---

# Consistent Joint Decision-Making with Heterogeneous Learning Models

## Quick Facts
- arXiv ID: 2402.03728
- Source URL: https://arxiv.org/abs/2402.03728
- Reference count: 23
- Primary result: Novel ILP framework achieves superior performance on hierarchical classification and procedural reasoning tasks by normalizing heterogeneous model outputs using prior probability, confidence, and accuracy

## Executive Summary
This paper introduces a decision-making framework that promotes consistency among decisions made by diverse models while utilizing external knowledge. The framework leverages Integer Linear Programming (ILP) to map predictions from various models into globally normalized and comparable values by incorporating information about decisions' prior probability, confidence (uncertainty), and the models' expected accuracy. Empirical studies demonstrate the superiority of this approach over conventional baselines on multiple datasets including hierarchical classification and procedural reasoning tasks.

## Method Summary
The method uses an Integer Linear Programming framework to normalize predictions from heterogeneous models by incorporating three key factors: prior probability (inverse of output size), confidence (inverse of entropy), and expected model accuracy. The decision weight function G combines these factors to create globally comparable decision weights. Raw model probabilities are transformed through this scoring function and then optimized using ILP subject to logical constraints, ensuring globally optimal solutions that satisfy all constraints while maximizing weighted decision variables.

## Key Results
- Outperforms conventional baselines on multiple hierarchical classification datasets (Flickr, 20News, OK-VQA)
- Achieves superior performance on procedural reasoning task (Propara) compared to sequential decoding methods
- Demonstrates improved consistency through constraint satisfaction rate and set correctness metrics
- Shows robustness across different model types (ResNet, BERT, T5) and decision types

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incorporating prior probabilities and entropy into the ILP objective function enables more balanced global optimization across heterogeneous model outputs.
- Mechanism: The scoring function G normalizes raw probabilities by accounting for prior probability (inverse of output size) and confidence (inverse of entropy), creating globally comparable decision weights.
- Core assumption: Different models produce outputs with varying output sizes and confidence levels, making raw probabilities incomparable across models.
- Evidence anchors:
  - [abstract]: "by incorporating information about decisions' prior probability, confidence (uncertainty), and the models' expected accuracy"
  - [section]: "We propose incorporating the entropy of the label distribution as an additional factor to assess the model's decision-making confidence"
- Break condition: When all models have similar output sizes and confidence distributions, normalization may not provide significant benefit.

### Mechanism 2
- Claim: Weighting ILP variables by expected model accuracy improves overall system performance by reducing influence of lower-quality decisions.
- Mechanism: The decision weight function multiplies raw probabilities by the model's expected accuracy, giving more influence to decisions from more reliable models.
- Core assumption: Models have different levels of accuracy that can be estimated from validation data, and this accuracy correlates with decision quality.
- Evidence anchors:
  - [abstract]: "incorporating information about decisions' prior probability, confidence (uncertainty), and the models' expected accuracy"
  - [section]: "We define the decision weight function G as G(Pm, m) = Pm ∗ Accm, where Accm represents the accuracy of the corresponding model"
- Break condition: When models have similar accuracy or when accuracy estimates are unreliable, this weighting may not provide significant benefit.

### Mechanism 3
- Claim: The ILP framework ensures global constraint satisfaction while optimizing for the most probable consistent solution across heterogeneous model decisions.
- Mechanism: The ILP optimization maximizes weighted decision variables subject to logical constraints, finding the globally optimal solution that satisfies all constraints.
- Core assumption: Task constraints can be expressed as linear inequalities and the solution space can be explored efficiently.
- Evidence anchors:
  - [abstract]: "Leveraging the Integer Linear Programming (ILP) framework, we map predictions from various models into globally normalized and comparable values"
  - [section]: "ILP stands out as a robust approach... capable of producing globally optimal solutions"
- Break condition: When constraint space is too large or constraints are non-linear, ILP may become computationally intractable.

## Foundational Learning

- Concept: Integer Linear Programming (ILP)
  - Why needed here: ILP provides a framework for finding globally optimal solutions while satisfying logical constraints across heterogeneous model outputs.
  - Quick check question: How does ILP differ from beam search in handling constraints?

- Concept: Entropy as a confidence measure
  - Why needed here: Entropy quantifies the uncertainty in probability distributions, allowing the system to distinguish between confident and uncertain model predictions.
  - Quick check question: What does lower entropy indicate about a probability distribution?

- Concept: Model calibration and accuracy estimation
  - Why needed here: Expected accuracy estimates are required to weight model contributions appropriately in the joint decision framework.
  - Quick check question: How can we estimate model accuracy without using test labels during inference?

## Architecture Onboarding

- Component map:
  - Raw model outputs → Scoring function G → ILP weights → ILP solver → Consistent predictions
  - Supporting components: Accuracy estimation module, entropy calculation module, prior probability database

- Critical path:
  1. Collect raw model probabilities
  2. Calculate entropy and prior probabilities
  3. Estimate model accuracies
  4. Apply scoring function G
  5. Run ILP optimization
  6. Extract consistent predictions

- Design tradeoffs:
  - Accuracy estimation vs. computational overhead
  - Granularity of prior probability calculation vs. storage requirements
  - ILP solver selection vs. constraint complexity

- Failure signatures:
  - Inconsistent predictions persisting after ILP optimization
  - Dramatic performance degradation on certain datasets
  - ILP solver timeouts or infeasibility

- First 3 experiments:
  1. Baseline comparison: Run original models without ILP on hierarchical classification task
  2. Single-factor ILP: Implement ILP with only prior probability normalization
  3. Full system: Implement complete scoring function with all three factors and evaluate on procedural reasoning task

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed framework handle cases where decision spaces are already comparable or consist solely of boolean decisions?
- Basis in paper: [inferred] The paper mentions limitations in scenarios where decision spaces are already comparable or consist solely of boolean decisions.
- Why unresolved: The paper does not provide specific strategies or results for handling such cases.
- What evidence would resolve it: Experimental results showing the framework's performance on tasks with comparable or boolean decision spaces.

### Open Question 2
- Question: Can the framework be extended to handle continuous decision variables instead of just discrete ones?
- Basis in paper: [inferred] The paper focuses on discrete decision variables, but does not discuss continuous variables.
- Why unresolved: The paper does not explore the possibility of extending the framework to continuous variables.
- What evidence would resolve it: Implementation and evaluation of the framework on tasks with continuous decision variables.

### Open Question 3
- Question: How does the framework perform when applied to tasks with a large number of constraints and variables?
- Basis in paper: [explicit] The paper mentions the potential of the framework in complex tasks with interrelated decisions.
- Why unresolved: The paper does not provide specific results or analysis for tasks with a large number of constraints and variables.
- What evidence would resolve it: Experimental results showing the framework's performance on tasks with a large number of constraints and variables.

## Limitations

- ILP solver scalability remains uncertain for very large decision spaces or numerous heterogeneous models
- Accuracy estimation reliability is critical but not fully addressed, especially for unvalidated models
- Generalizability across diverse domains beyond hierarchical classification and procedural reasoning is unproven

## Confidence

- High Confidence: Core ILP mechanism for normalizing heterogeneous model outputs is theoretically sound and empirically supported
- Medium Confidence: Performance improvements over baselines are supported but vary significantly across datasets
- Low Confidence: Real-world deployment behavior with noisy data, concept drift, or massive model numbers remains unclear

## Next Checks

1. **Scalability Test**: Implement the framework with increasing numbers of models and constraints to empirically measure ILP solver performance and identify the breaking point where computational costs become prohibitive.

2. **Accuracy Estimation Sensitivity**: Systematically vary the accuracy estimates (both overestimation and underestimation) to quantify how sensitive the final decision quality is to errors in accuracy prediction.

3. **Cross-Domain Generalization**: Apply the framework to at least two additional problem domains not covered in the current work (e.g., medical diagnosis and autonomous driving decision-making) to test generalizability beyond the tested domains.