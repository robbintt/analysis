---
ver: rpa2
title: 'InterroGate: Learning to Share, Specialize, and Prune Representations for
  Multi-task Learning'
arxiv_id: '2402.16848'
source_url: https://arxiv.org/abs/2402.16848
tags:
- learning
- interrogate
- task
- layer
- task-specific
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: InterroGate introduces a novel multi-task learning architecture
  that learns optimal parameter sharing and specialization patterns through learnable
  gating mechanisms. The method balances shared and task-specific representations
  while optimizing inference computational efficiency, using sparsity regularization
  to control the trade-off between accuracy and efficiency.
---

# InterroGate: Learning to Share, Specialize, and Prune Representations for Multi-task Learning

## Quick Facts
- arXiv ID: 2402.16848
- Source URL: https://arxiv.org/abs/2402.16848
- Reference count: 35
- Key outcome: InterroGate introduces a novel multi-task learning architecture that learns optimal parameter sharing and specialization patterns through learnable gating mechanisms

## Executive Summary
InterroGate presents a novel multi-task learning (MTL) framework that addresses the fundamental challenge of task interference by learning optimal patterns of parameter sharing and specialization. The method uses learnable gating mechanisms to dynamically route channels between shared and task-specific branches during training, then converts to a static, pruned architecture at inference. By controlling sparsity regularization, the approach balances multi-task performance with computational efficiency, achieving state-of-the-art results across three benchmarks while reducing inference costs through parameter pruning.

## Method Summary
InterroGate employs a dynamic architecture where each task has learnable gating modules that select relevant channels from either shared (Ψ) or task-specific (Φ_t) parameters in each layer. During training, gates operate over the channel dimension, allowing tasks to choose between shared and specialized features. A sparsity regularizer controls the trade-off between performance and computational cost by encouraging efficient parameter usage. At inference, the learned gating patterns become fixed, enabling permanent removal of unselected parameters and converting the model to a static architecture optimized for both accuracy and efficiency.

## Key Results
- Achieves superior accuracy-efficiency trade-offs compared to existing methods on CelebA, NYUD-v2, and PASCAL-Context benchmarks
- Consistently outperforms single-task and uniform multi-task baselines while reducing computational costs
- Works effectively with both convolutional and transformer-based backbones
- Demonstrates that sparsity regularization provides meaningful control over the performance-efficiency curve

## Why This Works (Mechanism)

### Mechanism 1
InterroGate reduces task interference by allowing each task to dynamically select between shared and task-specific features at the channel level. Learnable gating modules (Gℓ_t) output binary vectors that route each channel to either shared (Ψℓ) or task-specific (Φℓ_t) parameters, preventing conflicting gradients from propagating through incompatible representations. Different tasks benefit from different proportions of shared versus specialized features, and this optimal balance varies across network layers.

### Mechanism 2
The learned gating patterns become static at inference, enabling parameter pruning for computational efficiency. Since gating modules don't depend on input data at inference, unselected parameters can be permanently removed, converting the dynamic architecture into a static, streamlined network. The optimal parameter selection patterns learned during training remain valid for all inference inputs, allowing for simplified deployment.

### Mechanism 3
Sparsity regularization controls the trade-off between MTL performance and inference computational cost. A hinge loss over gating activations (Lsparsity) encourages the model to use fewer task-specific parameters by penalizing active gates beyond a task-specific threshold τt. There exists a monotonic relationship between gate sparsity and computational efficiency that can be controlled through regularization, enabling users to balance accuracy and efficiency requirements.

## Foundational Learning

- **Task interference in multi-task learning**: Understanding why sharing all parameters uniformly degrades performance is essential for appreciating InterroGate's selective sharing approach. Quick check: Why might optimizing a single model for both face recognition and text detection lead to degraded performance on one or both tasks?

- **Dynamic versus static computation graphs**: InterroGate transitions from a dynamic architecture (during training) to a static one (at inference), which is crucial for understanding its efficiency gains. Quick check: What is the computational disadvantage of requiring a separate forward pass for each task in traditional dynamic MTL approaches?

- **Parameter pruning and model compression**: InterroGate's inference efficiency comes from removing unselected parameters based on learned gating patterns. Quick check: How does removing parameters that were never selected by any task's gating module affect the model's computational requirements at inference?

## Architecture Onboarding

- **Component map**: Input → Shared/task-specific feature selection → Feature transformation → Mixing operation → Next layer (repeat) → Task heads

- **Critical path**: Input flows through layers where gating modules select between shared (Ψ) and task-specific (Φt) parameters per channel, with feature mixing weights (βℓ) combining task-specific features for shared representations in subsequent layers.

- **Design tradeoffs**: More task-specific parameters improve performance but increase computational cost; stronger sparsity regularization reduces cost but may hurt accuracy; deeper gating mechanisms could provide finer control but add complexity.

- **Failure signatures**: All gates consistently select shared features (model behaves like standard MTL with no specialization); all gates consistently select task-specific features (model loses efficiency benefits and may overfit); gating patterns don't converge (training instability or poor hyperparameter choices).

- **First 3 experiments**: 1) Train with λs=0 (no sparsity regularization) to verify the gating mechanism works before adding computational efficiency constraints; 2) Vary λs across orders of magnitude to observe the performance-efficiency trade-off curve; 3) Test with different {τt} values to understand task-specific parameter allocation patterns.

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the learned gating pattern change when using different backbone architectures (e.g., ConvNeXt, EfficientNet)? The paper only tests on ResNet and ViT backbones, leaving the generalizability to other architectures unclear.

- **Open Question 2**: What is the impact of increasing the number of tasks beyond five (as tested in Pascal-Context) on the performance and efficiency of InterroGate? The experiments only tested up to five tasks, and the paper acknowledges this limitation.

- **Open Question 3**: How does the choice of the sparsity regularization loss (hinge vs L1) affect the convergence speed and final performance across different datasets? While the paper compares the two losses, it doesn't deeply analyze why hinge loss performs better or if this holds across all datasets.

- **Open Question 4**: Can the gating mechanism be extended to operate over structured dimensions (e.g., spatial regions) instead of just channel-wise, and what would be the impact on efficiency? The current gating is limited to channel-wise operations, and the paper suggests but doesn't explore spatial gating.

## Limitations
- The gating mechanism relies on the straight-through estimator for binary gates, which can introduce training instability and may not always converge to optimal patterns
- The assumption that learned gating patterns remain optimal at inference assumes stable data distributions, which may not hold in real-world deployment scenarios
- Computational efficiency gains are measured in FLOPs and parameter counts but lack wall-clock timing measurements on actual hardware

## Confidence
- **High confidence**: The core mechanism of using learnable gating to balance shared and task-specific representations is well-founded and empirically validated across multiple benchmarks
- **Medium confidence**: The computational efficiency claims based on FLOPs and parameter counts are reasonable but would benefit from hardware-specific measurements
- **Medium confidence**: The sparsity regularization approach for controlling the performance-efficiency trade-off shows consistent patterns but the optimal hyperparameters appear dataset-dependent

## Next Checks
1. Conduct ablation studies on the sparsity regularization strength (λs) across a wider range to better characterize the performance-efficiency Pareto frontier
2. Implement wall-clock timing measurements for the pruned models on GPU/CPU to validate theoretical FLOPs reductions translate to real speedups
3. Test the method on a dataset with significant domain shift between training and inference to evaluate robustness of static gating patterns