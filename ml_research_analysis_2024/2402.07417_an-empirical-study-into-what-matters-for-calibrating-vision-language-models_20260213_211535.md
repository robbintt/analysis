---
ver: rpa2
title: An Empirical Study Into What Matters for Calibrating Vision-Language Models
arxiv_id: '2402.07417'
source_url: https://arxiv.org/abs/2402.07417
tags:
- calibration
- vlms
- label
- vision
- calibrated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "VLMs are not inherently calibrated for uncertainty but temperature\
  \ scaling consistently improves their calibration, even across distribution shifts\
  \ and changes in label set. VLMs can be calibrated with very few samples\u2014less\
  \ than 100\u2014and do not require sophisticated prompting strategies; a simple\
  \ prompt like \u201Ca photo of a <class\u201D is sufficient."
---

# An Empirical Study Into What Matters for Calibrating Vision-Language Models

## Quick Facts
- arXiv ID: 2402.07417
- Source URL: https://arxiv.org/abs/2402.07417
- Reference count: 33
- Primary result: Temperature scaling significantly improves VLM calibration with very few samples

## Executive Summary
This study investigates the calibration of vision-language models (VLMs) for improved uncertainty estimation in zero-shot classification. Through extensive empirical evaluation across 35 VLMs and multiple datasets, the authors demonstrate that temperature scaling consistently improves calibration performance, even under distribution shifts and with different label sets. The research reveals that VLMs require surprisingly few samples for effective calibration - less than 100 examples - and can be calibrated using datasets with different label sets or hierarchy levels than the target. A notable finding is that synthetic calibration sets generated from class descriptions can effectively replace real labeled data in many cases.

## Method Summary
The study evaluates temperature scaling as the primary calibration method across 35 VLMs including CLIP, FLAVA, and BLIP variants with different architectures. Calibration is performed using small datasets (10-1000 samples) and evaluated using Expected Calibration Error (ECE) across multiple test sets including ImageNet, CIFAR-10, and various out-of-distribution benchmarks. The research systematically examines calibration effectiveness with different calibration set sizes, label sets, and hierarchy levels, while also testing synthetic calibration sets generated from class descriptions.

## Key Results
- Temperature scaling consistently improves VLM calibration across distribution shifts and different label sets
- VLMs can be effectively calibrated with fewer than 100 samples
- Calibration remains effective when using datasets with different label sets or hierarchy levels than the target
- Synthetic calibration sets generated from class descriptions can replace real labeled data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Temperature scaling corrects miscalibration by learning a scalar that adjusts confidence scores without altering predicted class
- Mechanism: Temperature scaling rescales logits before softmax, softening or sharpening output probability distribution. The scalar is optimized on small calibration set using negative log-likelihood, aligning predicted probabilities with empirical accuracy
- Core assumption: Miscalibration in VLMs is primarily due to probability distribution sharpness, not underlying decision boundary
- Evidence anchors: [abstract] "VLMs are not inherently calibrated for uncertainty, temperature scaling significantly and consistently improves calibration"; [section] "Scaling logits from g with temperature T modifies output probability sharpness"
- Break condition: If miscalibration is not primarily due to probability sharpness (e.g., feature space misalignment), temperature scaling alone may not suffice

### Mechanism 2
- Claim: VLMs maintain calibration effectiveness even when calibration set differs in label set or hierarchy level from target
- Mechanism: VLMs use natural language supervision to generate class weights for zero-shot classification, allowing adaptation to different label granularities through semantic relationships in language model
- Core assumption: Semantic relationships encoded in language model allow VLMs to generalize calibration across different label granularities
- Evidence anchors: [abstract] "VLMs can be calibrated on datasets with different label sets than the target set and can be calibrated at a higher or lower level of the label hierarchy"; [section] "VLMs perform zero-shot classification by generating query embeddings for each novel class from their natural language names"
- Break condition: If semantic gap between calibration and target label sets is too large, calibration effectiveness may degrade

### Mechanism 3
- Claim: VLMs require very few samples for effective calibration, making process data-efficient
- Mechanism: Calibration problem for VLMs is low-dimensional, likely because temperature scaling only adjusts single scalar parameter, meaning small number of samples provides sufficient signal to optimize temperature
- Core assumption: Miscalibration in VLMs is low-dimensional problem that can be corrected with single parameter
- Evidence anchors: [abstract] "VLMs can be calibrated with a very small set of examples. For example, VLMs can be calibrated using temperature scaling... with less than 100 samples"; [section] "The calibration error plateaus after 40-50 images and is already close to the error after calibration with entire set"
- Break condition: If miscalibration is high-dimensional (e.g., requires per-class adjustment), very few samples may not suffice

## Foundational Learning

- Concept: Expected Calibration Error (ECE)
  - Why needed here: ECE is primary metric used to quantify how well predicted probabilities align with empirical accuracy. Understanding ECE is crucial for evaluating effectiveness of calibration methods
  - Quick check question: If a model has an ECE of 0.1, what does that imply about average difference between predicted confidence and actual accuracy across bins?

- Concept: Temperature scaling and its optimization
  - Why needed here: Temperature scaling is core calibration method used in study. Understanding how it works and how temperature parameter is optimized is essential for implementing and interpreting results
  - Quick check question: How does increasing temperature affect sharpness of predicted probability distribution?

- Concept: Cross-label-set and cross-hierarchy calibration
  - Why needed here: Study investigates whether VLMs can be calibrated using datasets with different label sets or hierarchy levels. Understanding this concept is key to interpreting robustness findings
  - Quick check question: If a VLM is calibrated on "Animal" and tested on "Dog", what property of VLMs makes this possible?

## Architecture Onboarding

- Component map: Vision encoder (e.g., ViT, ConvNeXt) → Image features; Text encoder → Text embeddings for class names; Joint embedding space → Cosine similarity for zero-shot classification; Temperature scaling layer → Adjusts output probabilities; Calibration module → Optimizes temperature on small dataset

- Critical path: 1) Load VLM and extract features for calibration set; 2) Apply temperature scaling to logits; 3) Optimize temperature using NLL on calibration set; 4) Evaluate ECE on target test set

- Design tradeoffs: Using single temperature scalar vs. per-class temperatures (simpler but less flexible); Small calibration set vs. large calibration set (faster but potentially less accurate); Cross-label-set calibration vs. same-label-set calibration (more flexible but potentially less precise)

- Failure signatures: High ECE that doesn't decrease after temperature scaling → miscalibration not due to probability sharpness; ECE improves on calibration set but not on target set → distribution shift or label set mismatch; Calibration error plateaus at high value even with large calibration set → high-dimensional miscalibration

- First 3 experiments: 1) Apply temperature scaling to VLM and verify ECE decreases on same dataset; 2) Calibrate VLM on different label set (e.g., CIFAR-10) and evaluate on ImageNet; 3) Test calibration with varying numbers of samples (e.g., 10, 50, 100) to find minimum effective size

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do calibration methods perform when applied to VLMs for tasks beyond image classification, such as object detection and segmentation?
- Basis in paper: [inferred] Authors acknowledge scope is limited to calibrating classification confidence estimates for vanilla/backbone VLM networks, and findings may not transfer to other tasks like object detection and segmentation which require compound networks with additional modules
- Why unresolved: Paper does not explore calibration of VLMs for tasks beyond image classification, leaving uncertainty about applicability of findings to other tasks
- What evidence would resolve it: Experiments applying same calibration methods to VLMs used in object detection and segmentation tasks, comparing performance to non-VLM models

### Open Question 2
- Question: Do alternative calibration methods, such as ensemble approaches or pre-training strategies, improve upon temperature scaling for calibrating VLMs?
- Basis in paper: [inferred] Authors mention much research has been done on proposing algorithms to improve model calibration, including post-hoc rescaling, ensembling, and pre-training, but they primarily focus on temperature scaling
- Why unresolved: Paper does not compare performance of alternative calibration methods against temperature scaling for VLMs, leaving open question of whether better methods exist
- What evidence would resolve it: Comprehensive study comparing calibration performance of various methods (e.g., ensembling, pre-training) on VLMs across different datasets and tasks

### Open Question 3
- Question: How does calibration performance of VLMs compare to non-VLMs when using synthetic calibration sets generated from class descriptions?
- Basis in paper: [explicit] Authors demonstrate VLMs can be effectively calibrated using small number of synthetic images generated from class descriptions, but do not compare this to performance of non-VLMs using synthetic data
- Why unresolved: Paper only shows VLMs can be calibrated with synthetic data, but does not explore whether this approach is superior to using real labeled data or if non-VLMs can also benefit from synthetic calibration sets
- What evidence would resolve it: Experiments calibrating both VLMs and non-VLMs using synthetic datasets generated from class descriptions, comparing calibration performance to using real labeled data

## Limitations
- Study primarily focuses on CLIP variants, limiting generalizability to other VLM architectures
- Assumes access to even small labeled calibration set, which may not be available in all practical scenarios
- Findings may not transfer to other tasks like object detection and segmentation which require compound networks

## Confidence

- **High Confidence**: Temperature scaling consistently improves calibration across distribution shifts and different label sets
- **Medium Confidence**: VLMs require very few samples (<100) for effective calibration
- **Medium Confidence**: Cross-label-set and cross-hierarchy calibration effectiveness

## Next Checks

1. Test temperature scaling calibration on VLMs with fundamentally different architectures to assess generalizability beyond CLIP variants

2. Conduct experiments with varying calibration set sizes (e.g., 5, 10, 20, 50 samples) across different VLMs to precisely determine minimum effective sample size

3. Systematically evaluate quality and limitations of synthetic calibration sets by comparing their effectiveness against real labeled calibration sets across different dataset types and VLM architectures