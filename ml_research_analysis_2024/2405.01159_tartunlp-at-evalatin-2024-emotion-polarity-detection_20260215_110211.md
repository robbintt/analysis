---
ver: rpa2
title: 'TartuNLP at EvaLatin 2024: Emotion Polarity Detection'
arxiv_id: '2405.01159'
source_url: https://arxiv.org/abs/2405.01159
tags:
- labels
- task
- data
- training
- polarity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a submission to the EvaLatin 2024 shared task
  on emotion polarity detection for historical Latin texts. The authors employed two
  approaches to annotate training data: heuristic-based labeling using a provided
  polarity lexicon and LLM-based labeling using GPT-4.'
---

# TartuNLP at EvaLatin 2024: Emotion Polarity Detection

## Quick Facts
- arXiv ID: 2405.01159
- Source URL: https://arxiv.org/abs/2405.01159
- Reference count: 0
- Primary result: First place in emotion polarity detection task using LLM-generated annotations

## Executive Summary
This paper presents TartuNLP's submission to the EvaLatin 2024 shared task on emotion polarity detection for historical Latin texts. The authors employed two annotation approaches: heuristic-based labeling using a provided polarity lexicon and LLM-based labeling using GPT-4. They fine-tuned a multilingual RoBERTa model using parameter-efficient adapter training, experimenting with both monolingual and cross-lingual knowledge transfer. The submission with LLM-generated labels achieved the overall first place in the emotion polarity detection task, demonstrating the effectiveness of LLM-based annotations over lexicon-informed heuristics.

## Method Summary
The approach combined two data annotation strategies with adapter-based parameter-efficient fine-tuning. First, heuristic rules were applied to Latin sentences using a provided polarity lexicon to generate initial labels. Second, GPT-4 was used to annotate additional Latin sentences with emotion polarity labels. The XLM-RoBERTa base model was then fine-tuned using adapters: a language adapter trained on Latin text, a task adapter trained on English IMDB reviews for cross-lingual transfer, and final fine-tuning on the annotated Latin data. This parameter-efficient approach aimed to prevent overfitting on the limited Latin dataset while leveraging both monolingual and cross-lingual knowledge.

## Key Results
- Overall first place in the EvaLatin 2024 emotion polarity detection task
- LLM-based annotations outperformed lexicon-informed heuristic labels despite using fewer examples
- Adapter-based fine-tuning effectively prevented catastrophic forgetting while enabling task-specific adaptation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-generated annotations are of higher quality than lexicon-informed heuristics
- Mechanism: GPT-4 can simulate expert annotation by contextualizing sentiment beyond static polarity rules
- Core assumption: GPT-4's ability to reason about context and nuance in Latin texts surpasses rule-based lexicon lookups
- Evidence anchors:
  - [abstract] "Our results show that LLM-based annotations show promising results on texts in Latin."
  - [section 5] "This is despite the fact that the number of LLM-annotated examples was nearly twice as small, suggesting that the LLM annotations are of higher quality than the labels based on lexicon-informed heuristics."
  - [corpus] Weak evidence; the corpus neighbors do not directly support annotation quality claims
- Break condition: If GPT-4 cannot reliably interpret historical Latin sentiment or if context shifts make its annotations brittle

### Mechanism 2
- Claim: Adapter-based parameter-efficient fine-tuning avoids catastrophic forgetting while enabling task-specific adaptation
- Mechanism: Freezing most transformer parameters and training only small adapter modules preserves pre-trained knowledge while adapting to new tasks
- Core assumption: Adapters are sufficient to encode both language and task-specific features without full fine-tuning
- Evidence anchors:
  - [section 3] "Training adapters involves adding a small number of trainable parameters to the model while freezing the rest of the parameters."
  - [section 3] "adapters mitigate overfitting and catastrophic forgetting, which are common problems when dealing with small amounts of training data."
  - [corpus] Weak evidence; no direct corpus support for adapter effectiveness here
- Break condition: If adapters cannot capture complex interactions between language and task features

### Mechanism 3
- Claim: Cross-lingual knowledge transfer from English sentiment tasks improves Latin emotion polarity detection
- Mechanism: Pre-training on English IMDB reviews provides sentiment classification cues that transfer to Latin via shared semantic space in multilingual RoBERTa
- Core assumption: Sentiment patterns are transferable across languages in a multilingual model
- Evidence anchors:
  - [section 3] "We expected the model to benefit from both monolingual and cross-lingual knowledge transfer."
  - [section 4] "Cross-lingual knowledge transfer from the English IMDB sentiment dataset in training the task adapter."
  - [corpus] Weak evidence; no corpus support for cross-lingual transfer effectiveness
- Break condition: If language-specific sentiment expressions are too divergent for meaningful transfer

## Foundational Learning

- Concept: Heuristics-based sentiment annotation using polarity lexicons
  - Why needed here: Provides a baseline for data annotation without requiring large annotated datasets
  - Quick check question: How does averaging word polarities determine sentence sentiment in this approach?

- Concept: Parameter-efficient fine-tuning with adapters
  - Why needed here: Enables adaptation to low-resource Latin data without overfitting or catastrophic forgetting
  - Quick check question: What is the key difference between adapter training and full fine-tuning in terms of parameter updates?

- Concept: Cross-lingual knowledge transfer
  - Why needed here: Leverages pre-trained sentiment understanding from English to improve Latin emotion detection
  - Quick check question: How does a multilingual model facilitate transfer of sentiment patterns across languages?

## Architecture Onboarding

- Component map: XLM-RoBERTa base model → language adapter (Latin corpus) → task adapter (English IMDB) → task adapter (Latin LLM/heuristic annotations) → classification head (4 emotion polarity classes)
- Critical path: Annotate data → train language adapter → train task adapter on English → stack and fine-tune on Latin annotations → evaluate on test set
- Design tradeoffs: Adapters reduce computational cost and overfitting risk but may limit expressivity compared to full fine-tuning; cross-lingual transfer adds complexity but can improve performance when monolingual data is scarce
- Failure signatures: Low validation F1 scores indicating overfitting or poor annotation quality; disagreement between heuristic and LLM models suggesting annotation inconsistency; inability to distinguish mixed from neutral classes
- First 3 experiments:
  1. Train language adapter on Latin corpus only and evaluate on validation set to measure monolingual transfer benefit
  2. Train task adapter on English IMDB only and evaluate to assess cross-lingual sentiment transfer
  3. Combine both adapters and fine-tune on LLM-annotated Latin data, comparing to heuristic-annotated baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact cause of the observed discrepancy between micro-averaged and macro-averaged F1-scores in the model's performance?
- Basis in paper: [explicit] The paper mentions that "the scores obtained by the two models are quite close" but does not provide a detailed analysis of the discrepancy between micro-averaged and macro-averaged F1-scores
- Why unresolved: The paper only briefly mentions the discrepancy without delving into its underlying causes, such as class imbalance or the specific nature of the test data
- What evidence would resolve it: A detailed analysis of the class distribution in the test data and a comparison of the model's performance on each class could provide insights into the causes of the discrepancy

### Open Question 2
- Question: How do the LLM-generated annotations compare in quality to human annotations, particularly in terms of consistency and adherence to annotation guidelines?
- Basis in paper: [explicit] The paper states that "LLM-based annotations show promising results on texts in Latin" and that "the model with LLM-generated labels obtained better results than the model with lexicon-based heuristic labels," but it does not provide a direct comparison with human annotations
- Why unresolved: The paper does not include a comparison of LLM-generated annotations with human annotations, which would provide a benchmark for assessing the quality of the LLM-generated labels
- What evidence would resolve it: A side-by-side comparison of LLM-generated annotations and human annotations, along with an analysis of inter-annotator agreement, would help assess the quality of the LLM-generated labels

### Open Question 3
- Question: What is the impact of the context window size on the model's ability to correctly classify sentences with complex sentiment, such as those requiring understanding of broader context or sarcasm?
- Basis in paper: [inferred] The paper mentions that "the manual analysis of the examples shows that it is quite difficult to distinguish between mixed and neutral texts," which could be related to the model's ability to understand context
- Why unresolved: The paper does not discuss the impact of context window size on the model's performance, nor does it provide insights into how the model handles complex sentiment cases
- What evidence would resolve it: Experiments comparing the model's performance with different context window sizes, along with a detailed analysis of the model's behavior on complex sentiment cases, would provide insights into the impact of context window size

## Limitations

- Heavy dependence on GPT-4's ability to accurately annotate Latin sentiment, which may not generalize to other historical languages
- Small gold-standard validation set (44 sentences) limits the robustness of performance claims
- Cross-lingual transfer effectiveness from English IMDB data to Latin emotion detection remains empirically unverified

## Confidence

- **High confidence**: Adapter-based training approach effectively prevents catastrophic forgetting and enables parameter-efficient fine-tuning for low-resource languages. The overall first-place ranking in the shared task provides strong empirical validation.
- **Medium confidence**: LLM-generated annotations are of higher quality than heuristic-based labels, though this conclusion is based on limited validation data and assumes GPT-4's Latin sentiment understanding is reliable.
- **Low confidence**: Cross-lingual knowledge transfer from English sentiment data meaningfully improves Latin emotion detection, as this mechanism lacks direct empirical support in the paper.

## Next Checks

1. Test GPT-4's annotation consistency by having it re-label a subset of sentences and measuring inter-annotator agreement to verify annotation quality claims.
2. Evaluate adapter performance on a held-out test set with true gold labels (beyond the 44-sentence validation set) to confirm generalization beyond the competition setting.
3. Conduct an ablation study removing the English IMDB cross-lingual component to empirically measure its contribution to the final performance, as the current evidence for this mechanism is weak.