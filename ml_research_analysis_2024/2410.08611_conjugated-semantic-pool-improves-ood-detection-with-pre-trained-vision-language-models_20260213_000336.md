---
ver: rpa2
title: Conjugated Semantic Pool Improves OOD Detection with Pre-trained Vision-Language
  Models
arxiv_id: '2410.08611'
source_url: https://arxiv.org/abs/2410.08611
tags:
- semantic
- labels
- detection
- pool
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a theoretical framework for improving out-of-distribution\
  \ (OOD) detection using pre-trained vision-language models (VLMs). The key insight\
  \ is that expanding the semantic pool with conjugated semantic pool (CSP) labels\u2014\
  modified superclass names serving as cluster centers for samples with similar properties\
  \ across categories\u2014can increase OOD label activation probabilities while maintaining\
  \ low mutual dependence."
---

# Conjugated Semantic Pool Improves OOD Detection with Pre-trained Vision-Language Models

## Quick Facts
- arXiv ID: 2410.08611
- Source URL: https://arxiv.org/abs/2410.08611
- Reference count: 40
- Outperforms state-of-the-art NegLabel method by 7.89% in FPR95 on ImageNet-1k OOD detection benchmark

## Executive Summary
This paper addresses the challenge of out-of-distribution (OOD) detection using pre-trained vision-language models (VLMs) by proposing a theoretical framework centered on expanding the semantic pool. The key innovation is the Conjugated Semantic Pool (CSP), which uses modified superclass names as cluster centers for samples with similar properties across categories. By increasing the probability that OOD samples activate relevant labels while maintaining low mutual dependence, CSP significantly improves OOD detection performance over existing methods like NegLabel.

## Method Summary
The method constructs a conjugated semantic pool (CSP) by combining adjectives from a lexicon with superclass terms to create cluster centers for samples sharing similar properties across different categories. This CSP is combined with the original semantic pool and used with a pre-trained VLM (CLIP) to detect OOD samples. The approach uses prompt ensembles and NegMining algorithm for label selection, with a ratio r=15% for selecting OOD labels. The theoretical foundation relies on Lyapunov Central Limit Theorem to model the distribution of classification scores.

## Key Results
- Outperforms NegLabel by 7.89% in FPR95 on ImageNet-1k benchmark
- Improves AUROC across multiple OOD datasets (iNaturalist, SUN, Places, Textures)
- Demonstrates theoretical advantage over simple lexicon expansion strategies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Expanding the semantic pool with CSP increases the probability that OOD samples are correctly detected by providing more relevant cluster centers.
- Mechanism: CSP uses modified superclass names as cluster centers for samples with similar properties across different categories, increasing the expected probability of OOD label activation by OOD samples.
- Core assumption: OOD samples have varied visual properties that can be captured by superclass descriptions.
- Evidence anchors:
  - [abstract]: "we correspondingly construct a conjugated semantic pool (CSP) consisting of modified superclass names, each serving as a cluster center for samples sharing similar properties across different categories"
  - [section]: "Observing that the original semantic pool is comprised of unmodified specific class names... we correspondingly construct a conjugated semantic pool (CSP) consisting of modified superclass names, each serving as a cluster center for samples sharing similar properties across different categories"
  - [corpus]: Weak evidence - no direct neighbor papers discuss CSP specifically, but several mention OOD detection with VLMs.
- Break condition: If OOD samples share similar visual properties across categories, CSP labels will have low activation probability, reducing effectiveness.

### Mechanism 2
- Claim: CSP expansion maintains low mutual dependence among label activations, satisfying theoretical requirements.
- Mechanism: CSP labels are based on superclass property clusters that are distinctly different from original category cluster centers, resulting in relatively low mutual dependence between new and original labels.
- Core assumption: Labels based on superclass property clusters have different feature space distributions than category-specific labels.
- Evidence anchors:
  - [abstract]: "the distribution of these property cluster centers in the feature space is distinctly different from that of the original category cluster centers, resulting in a relatively low mutual dependence"
  - [section]: "the distribution of these property cluster centers in the feature space is distinctly different from that of the original category cluster centers. As a result, the mutual dependence between the new and original labels is relatively low"
  - [corpus]: Weak evidence - no neighbor papers specifically discuss mutual dependence in OOD detection.
- Break condition: If superclass property clusters overlap significantly with category clusters in feature space, mutual dependence increases, violating theoretical requirements.

### Mechanism 3
- Claim: Simple lexicon expansion fails because it introduces uncommon words with low activation probability and (near-)synonyms with high mutual dependence.
- Mechanism: Larger lexicons bring uncommon words whose expected probability of being activated by OOD images is minimal, reducing q2, and introduce (near-)synonyms leading to high mutual dependence.
- Core assumption: Uncommon words in lexicons have minimal semantic matching capability with OOD samples.
- Evidence anchors:
  - [section]: "larger lexicons bring numerous uncommon words, whose expected probability of being activated by OOD images are minimal, thus resulting in a reduction of q2"
  - [section]: "larger lexicons introduce plenty of (near-)synonyms for existing OOD label candidates, leading to a high degree of functional overlap with little additional benefit"
  - [corpus]: Moderate evidence - AdaNeg paper mentions negative labels, suggesting label selection impacts OOD detection.
- Break condition: If lexicon expansion maintains high activation probability for new words and low mutual dependence, simple expansion could work.

## Foundational Learning

- Concept: Lyapunov Central Limit Theorem and its application to OOD detection modeling
  - Why needed here: The paper uses Lyapunov CLT to approximate the distribution of classification scores for ID and OOD samples, which forms the theoretical foundation for performance analysis
  - Quick check question: What conditions must be satisfied for Lyapunov CLT to apply to the Poisson binomial distribution of OOD detection scores?

- Concept: Bernoulli random variables and their application to label activation modeling
  - Why needed here: The paper models whether an OOD label is activated for a given sample as a Bernoulli random variable, with parameters representing activation probabilities
  - Quick check question: How does the independence assumption between Bernoulli variables affect the validity of the theoretical framework?

- Concept: Semantic pool expansion strategies and their theoretical implications
  - Why needed here: Understanding why CSP works while simple lexicon expansion fails requires grasping the theoretical requirements for performance enhancement
  - Quick check question: What are the two key factors that must be increased concurrently while maintaining low mutual dependence for optimal OOD detection performance?

## Architecture Onboarding

- Component map:
  - Original semantic pool (WordNet nouns) -> CSP construction (adjective + superclass combinations) -> Expanded semantic pool -> NegMining label selection -> Pre-trained VLM (CLIP) -> Text-image similarity scores -> OOD score calculation -> Classification

- Critical path:
  1. Construct CSP by combining adjectives from lexicon with superclass terms
  2. Combine CSP with original semantic pool to create expanded pool
  3. Select OOD labels based on reverse-order similarity to ID labels
  4. Compute text-image similarities using pre-trained VLM
  5. Aggregate scores and classify samples as ID or OOD

- Design tradeoffs:
  - CSP size vs. specificity: Larger CSP provides more coverage but may include less relevant labels
  - Superclass selection: Choice of superclass terms affects the properties captured by CSP
  - Label selection ratio: Tradeoff between including more OOD labels and maintaining performance

- Failure signatures:
  - Performance degradation when OOD samples share similar visual properties
  - Reduced effectiveness when superclass property clusters overlap significantly with category clusters
  - Inconsistent results when lexicon expansion introduces many uncommon words

- First 3 experiments:
  1. Test CSP effectiveness with different superclass sets to identify optimal combinations
  2. Evaluate performance impact of varying label selection ratios to find optimal balance
  3. Compare CSP against simple lexicon expansion with controlled vocabulary sizes to demonstrate superiority

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of using CSP on OOD detection performance when OOD samples share similar visual properties, and how can this limitation be mitigated?
- Basis in paper: [explicit] The paper acknowledges that CSP's effectiveness depends on the assumption that OOD samples exhibit a variety of distinct visual properties. It mentions that when OOD samples share similar visual properties, like plant images in iNaturalist, the addition of CSP results in a slight performance decline.
- Why unresolved: The paper identifies this limitation but does not explore methods to reduce the dependency on this assumption or improve performance in cases where OOD samples share similar visual properties.
- What evidence would resolve it: Experiments comparing CSP performance on OOD datasets with varying degrees of visual diversity, and development of strategies to adapt CSP for datasets with limited visual diversity.

### Open Question 2
- Question: How does expanding the ID label set with additional labels from the semantic pool, including CSP, impact the identification of difficult ID samples and overall OOD detection performance?
- Basis in paper: [inferred] The paper mentions that there is a possibility that selecting additional labels from the semantic pool, including the CSP, to expand the ID label set could enhance the identification of difficult ID samples. This is presented as a promising direction for future exploration.
- Why unresolved: The paper focuses on optimizing the activation status of OOD labels and does not investigate the potential benefits of expanding the ID label set.
- What evidence would resolve it: Comparative experiments evaluating OOD detection performance with and without expanding the ID label set using labels from the semantic pool and CSP.

### Open Question 3
- Question: What are the optimal strategies for constructing the conjugated semantic pool (CSP) to maximize OOD detection performance, considering factors such as the selection of superclasses and the combination of adjectives?
- Basis in paper: [explicit] The paper mentions that the superclass set for constructing the CSP nearly encompasses all real-world objects and that numerous alternative selections can also yield significant performance improvements. It also states that the selection of different superclasses results in some performance fluctuations.
- Why unresolved: While the paper demonstrates the effectiveness of CSP, it does not provide a comprehensive analysis of the optimal strategies for constructing the CSP to maximize OOD detection performance.
- What evidence would resolve it: Experiments systematically evaluating the impact of different superclass sets and adjective combinations on OOD detection performance, and development of guidelines for constructing optimal CSP.

## Limitations

- Dataset-specific construction: CSP relies on manually curated superclasses and WordNet lexicons, making it less effective for domains with different semantic structures
- Theoretical assumptions: Framework depends on independent Bernoulli activations and normal approximations that may not hold in all scenarios
- Performance degradation: Effectiveness decreases when OOD samples share similar visual properties across categories

## Confidence

- **High confidence**: The core claim that CSP improves OOD detection over simple lexicon expansion, supported by empirical results showing 7.89% improvement in FPR95
- **Medium confidence**: The theoretical analysis based on Lyapunov CLT and mutual dependence requirements, which provides justification but depends on distributional assumptions
- **Medium confidence**: The effectiveness of NegMining algorithm for label selection, as implementation details are not fully specified

## Next Checks

1. **Dataset Transferability Test**: Evaluate CSP performance across diverse domains (medical imaging, satellite imagery, industrial inspection) to assess robustness beyond natural images.

2. **Dependency Analysis**: Measure actual mutual dependence between CSP labels and original categories in feature space to validate the low dependency assumption empirically.

3. **Alternative Semantic Pool Construction**: Implement and compare CSP against other semantic pool expansion strategies (hypernym expansion, attribute-based clustering) to isolate the contribution of the specific CSP construction method.