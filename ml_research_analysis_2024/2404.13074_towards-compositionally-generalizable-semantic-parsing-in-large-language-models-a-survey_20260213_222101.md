---
ver: rpa2
title: 'Towards Compositionally Generalizable Semantic Parsing in Large Language Models:
  A Survey'
arxiv_id: '2404.13074'
source_url: https://arxiv.org/abs/2404.13074
tags:
- generalization
- compositional
- parsing
- semantic
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a comprehensive survey of recent advances in
  compositional generalization for large language model (LLM)-based semantic parsing.
  It examines key factors affecting compositional generalization, such as the inherent
  limitations of vanilla sequence-to-sequence models, the autoregressive decoding
  bottleneck, distributional mismatch with pretraining corpora, and the effects of
  model size and mode of use.
---

# Towards Compositionally Generalizable Semantic Parsing in Large Language Models: A Survey

## Quick Facts
- arXiv ID: 2404.13074
- Source URL: https://arxiv.org/abs/2404.13074
- Authors: Amogh Mannekote
- Reference count: 3
- Primary result: Decomposing complex problems into simpler subproblems using prompting techniques like Least-to-Most (LTM) Prompting can significantly improve compositional generalization performance in LLM-based semantic parsing

## Executive Summary
This survey examines recent advances in compositional generalization for large language model (LLM)-based semantic parsing, identifying key limitations and promising approaches. Despite LLMs' success across NLP tasks, compositional generalization remains a frontier challenge. The paper analyzes fundamental issues including the lack of structural inductive biases in vanilla sequence-to-sequence models, autoregressive decoding bottlenecks, and distributional mismatch between pretraining corpora and symbolic forms. Various methods to address these challenges are reviewed, with particular emphasis on prompting techniques that decompose complex problems into simpler subproblems.

## Method Summary
The survey synthesizes findings from multiple studies examining LLM-based semantic parsing approaches. It evaluates benchmark datasets including SCAN, COGS, and CFQ, testing various models like BART, T5, and code-davinci-002 across different settings (fine-tuned, prompt-tuned, zero-shot). The analysis covers data augmentation strategies, neuro-symbolic models, and prompt-based techniques. A minimum viable reproduction would involve selecting a benchmark dataset, implementing a baseline LLM semantic parser, and applying compositional generalization methods like LTM Prompting while evaluating on test sets.

## Key Results
- Vanilla sequence-to-sequence models without structural inductive biases fail to generalize to unseen output structures
- Autoregressive decoding is lossy and prevents full utilization of structural information captured by encoders
- Prompting techniques that decompose problems into simpler subproblems (e.g., LTM Prompting) significantly improve compositional generalization
- Model size does not consistently improve compositional generalization performance, with larger models sometimes degrading
- Data augmentation methods that include demonstrations of various types of compositional generalization show promise

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs fail to generalize structurally because vanilla seq2seq models lack built-in structural inductive biases.
- Mechanism: Without structural biases, the decoder cannot infer recursive or nested patterns beyond the maximum depth seen in training.
- Core assumption: Training data must contain explicit demonstrations of structural recursion for the model to learn to generalize.
- Evidence anchors:
  - [section]: "vanilla seq2seq models, which lack structural inductive biases built into them, fail to generalize to unseen structures in the output"
  - [abstract]: "Despite the success of large language models (LLMs) in a wide range of NLP tasks, unlocking perfect compositional generalization still remains one of the few last unsolved frontiers."
  - [corpus]: Weak evidence; only general claims about seq2seq limitations, no specific structural failure data.
- Break condition: If training data contains sufficient structural recursion examples, the model may begin to generalize.

### Mechanism 2
- Claim: Autoregressive decoding is lossy, preventing full utilization of structural information captured by the encoder.
- Mechanism: The decoder fails to leverage encoded structural cues, leading to incomplete or incorrect output generation.
- Core assumption: The encoder can fully capture structural information if given enough capacity.
- Evidence anchors:
  - [section]: "the decoding step is lossy in nature and fails to make full use of it" (referring to structural information)
  - [abstract]: "they can harbor infinite complexity" (implying the need for effective structural decoding)
  - [corpus]: Weak; no decoder-specific empirical data provided.
- Break condition: If the decoding step is replaced with a non-autoregressive or grammar-guided approach, structural information may be better utilized.

### Mechanism 3
- Claim: Pretraining corpora dominated by natural language (not symbolic forms) creates distributional mismatch for semantic parsing.
- Mechanism: Reframing semantic parsing as text generation closer to natural language distribution may improve performance.
- Core assumption: Natural language outputs are closer to pretraining corpus distribution than symbolic forms.
- Evidence anchors:
  - [section]: "Since most LLMs are pretrained on corpora that disproportionately contain natural language (and not symbolic forms), the authors hypothesize that reframing semantic parsing as a text generation task...might prove to be distributionally closer to its training corpus"
  - [abstract]: "unlocking perfect compositional generalization still remains one of the few last unsolved frontiers"
  - [corpus]: No specific pretraining corpus analysis data provided.
- Break condition: If pretraining includes symbolic forms or balanced natural language and symbolic data, distributional mismatch may be reduced.

## Foundational Learning

- Concept: Compositional generalization
  - Why needed here: Understanding this concept is crucial for grasping why semantic parsing models struggle with unseen combinations of primitives.
  - Quick check question: What is the difference between a "primitive" and a "compound" in the context of compositional generalization?

- Concept: Sequence-to-sequence (seq2seq) models
  - Why needed here: These models are the foundation of many LLM-based semantic parsers, and their limitations are central to the survey's findings.
  - Quick check question: What are the main components of a seq2seq model, and how do they interact during training and inference?

- Concept: Data augmentation
  - Why needed here: Data augmentation is a key method proposed to improve compositional generalization, and understanding its principles is essential for implementing these approaches.
  - Quick check question: How does data augmentation help a model generalize to unseen combinations of primitives?

## Architecture Onboarding

- Component map: Input → Encoder → Decoder/Prompting → Output → Post-processing
- Critical path: Input → Encoder → Decoder/Prompting → Output → Post-processing
- Design tradeoffs:
  - Seq2seq vs. grammar-based parsing: Accuracy vs. flexibility
  - Autoregressive vs. non-autoregressive decoding: Complexity vs. speed
  - Fine-tuning vs. prompt-tuning: Data efficiency vs. task adaptability
- Failure signatures:
  - Inability to generate nested structures beyond training depth
  - Poor performance on compositional generalization benchmarks
  - Disproportionate errors on unseen combinations of primitives
- First 3 experiments:
  1. Evaluate vanilla seq2seq model on SCAN dataset to confirm structural generalization limitations
  2. Implement Least-to-Most prompting on SCAN to test decomposition-based improvement
  3. Compare fine-tuned vs. prompt-tuned models on COGS to assess scaling effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact relationship between autoregressive decoding and compositional generalization in LLMs?
- Basis in paper: [explicit] The paper mentions that "Yao and Koller (2022) also present a second finding pertaining to the question of whether the root cause of insufficient compositional generalization lies in the encoder or the decoder (or both). Using the well-established 'probe task methodology' over BART and T5 models, the authors establish that although the encoder is successful in capturing the structural information to a full extent, the decoding step is lossy in nature and fails to make full use of it."
- Why unresolved: The paper states that the decoding step is lossy, but does not provide a detailed explanation of why this is the case or how it specifically impacts compositional generalization.
- What evidence would resolve it: Further research could investigate the specific mechanisms by which the autoregressive decoding step affects compositional generalization, perhaps through detailed analysis of the decoding process or by comparing different decoding strategies.

### Open Question 2
- Question: How does the size of LLMs impact their compositional generalization capabilities, and is there an optimal model size?
- Basis in paper: [explicit] The paper mentions that "Qiu et al. (2022) present several findings about the relationship between compositional generalizability and 1) the model size and 2) the mode of use (fine-tuned, prompt-tuned, or zero-shot prompted). They find that the compositional generalization performance of fine-tuned LMs does not really increase (and sometimes even degrades) with size."
- Why unresolved: While the paper indicates that larger models do not necessarily perform better, it does not provide a clear explanation for this phenomenon or suggest an optimal model size.
- What evidence would resolve it: Further research could explore the relationship between model size and compositional generalization in more detail, perhaps by testing a wider range of model sizes or by investigating the specific factors that contribute to the observed trend.

### Open Question 3
- Question: What are the most effective data augmentation strategies for improving compositional generalization in LLMs?
- Basis in paper: [explicit] The paper mentions that "The most common data-augmentation method involves augmenting a dataset of (natural language, logical form) pairs in such a way as to include demonstrations of various types of compositional generalization (Ye et al., 2023)."
- Why unresolved: While the paper mentions data augmentation as a potential strategy, it does not provide a detailed comparison of different data augmentation techniques or their relative effectiveness.
- What evidence would resolve it: Further research could systematically compare different data augmentation strategies, perhaps by testing them on a variety of semantic parsing tasks or by analyzing their impact on different types of compositional generalization.

## Limitations

- Most empirical evaluations rely on synthetic benchmarks (SCAN, COGS, CFQ) which may not fully capture real-world compositional complexity
- The survey lacks unified implementation details and head-to-head comparisons of different compositional generalization methods
- Specific pretraining corpus analysis is missing to quantify distributional mismatch between natural and symbolic language forms

## Confidence

- **High confidence**: The identification of seq2seq limitations and autoregressive decoding issues is well-supported by existing literature and the survey's analysis of multiple studies
- **Medium confidence**: The distributional mismatch hypothesis is reasonable but lacks specific pretraining corpus analysis to quantify the gap between natural and symbolic language distributions
- **Medium confidence**: The effectiveness of decomposition-based approaches like LTM Prompting is demonstrated across multiple studies, though the survey doesn't provide unified implementation details or head-to-head comparisons

## Next Checks

1. Conduct controlled experiments comparing pretraining on balanced natural/symbolic corpora versus standard natural language corpora to quantify distributional mismatch effects
2. Implement a unified benchmark suite testing multiple compositional generalization methods (including LTM Prompting) on the same models with identical hyperparameters for direct comparison
3. Develop and evaluate a non-autoregressive decoding variant with grammar-guided constraints to test whether the autoregressive bottleneck can be overcome while maintaining output quality