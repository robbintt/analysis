---
ver: rpa2
title: Camera Agnostic Two-Head Network for Ego-Lane Inference
arxiv_id: '2404.12770'
source_url: https://arxiv.org/abs/2404.12770
tags:
- lane
- uncertainty
- camera
- line
- ego-lane
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a camera-agnostic two-head neural network
  for ego-lane inference from a single image, without requiring prior camera calibration.
  The model leverages vanishing point and line guided attention and evidential deep
  learning for uncertainty estimation to robustly infer the ego-vehicle's lane index
  in diverse environments and camera configurations, including mobile phone images.
---

# Camera Agnostic Two-Head Network for Ego-Lane Inference

## Quick Facts
- arXiv ID: 2404.12770
- Source URL: https://arxiv.org/abs/2404.12770
- Authors: Chaehyeon Song; Sungho Yoon; Minhyeok Heo; Ayoung Kim; Sujung Kim
- Reference count: 25
- Primary result: Achieves over 90% F1-score for ego-lane inference across diverse datasets without requiring camera calibration

## Executive Summary
This paper introduces a camera-agnostic two-head neural network for ego-lane inference from a single image. The model leverages vanishing point and line guided attention and evidential deep learning for uncertainty estimation to robustly infer the ego-vehicle's lane index in diverse environments and camera configurations, including mobile phone images. The two-head structure and uncertainty estimation enable reliable lane identification even when boundary lines are partially occluded or not fully visible.

## Method Summary
The proposed method uses a two-head neural network architecture with a Resnet18 backbone, evidential deep learning for uncertainty estimation, and VPL (vanishing point and line)-aware attention mechanism. The model is trained using Maximum Likelihood loss, KL divergence loss, and geometric loss incorporating vanishing point/line information. It operates without requiring prior camera calibration and achieves real-time performance (59.6ms on CPU, 7.4ms on RTX3070 GPU).

## Key Results
- Achieves over 90% F1-score across various datasets, including highway, urban, and rural environments
- Demonstrates strong generalization capability when trained on limited data
- Successfully operates on mobile phone images with varying camera poses (horizontal, vertical, front, pan, tilt)
- Enables reliable lane identification even when boundary lines are partially occluded or not fully visible

## Why This Works (Mechanism)

### Mechanism 1
The two-head structure improves robustness by providing complementary lane estimation perspectives (left and right boundary references). By splitting lane estimation into left and right heads, the model can handle situations where one boundary is occluded or not visible, allowing the other head to provide reliable inference. The model selects the more reliable output based on estimated uncertainty.

### Mechanism 2
VPL (vanishing point and line)-aware attention enables camera-agnostic adaptation by leveraging geometric relationships that remain consistent across camera configurations. The attention mechanism uses a context vector guided by vanishing point and line information, which maintains geometric relationships (vanishing line parallel to road plane, vanishing point ray parallel to lanes) regardless of camera mounting position or orientation.

### Mechanism 3
Evidential deep learning provides reliable uncertainty estimates that enable automatic selection between the two heads and rejection of unreliable outputs. The model estimates evidence values for each lane class rather than direct probabilities, converting these to Dirichlet distribution parameters. Lower uncertainty indicates higher reliability, allowing automatic selection of the better head or rejection of outputs when uncertainty exceeds thresholds.

## Foundational Learning

- Concept: Vanishing point and line geometry in perspective projection
  - Why needed here: Understanding how vanishing points and lines relate to road geometry is crucial for implementing the VPL-aware attention mechanism
  - Quick check question: In a standard camera perspective, what geometric relationship exists between the vanishing line and the road plane?

- Concept: Dirichlet distribution and evidential deep learning
  - Why needed here: The uncertainty estimation relies on converting evidence values to Dirichlet distribution parameters
  - Quick check question: How does evidential deep learning differ from traditional softmax-based classification in terms of uncertainty quantification?

- Concept: Attention mechanisms in convolutional neural networks
  - Why needed here: The model uses attention to focus on relevant road features while considering geometric context
  - Quick check question: What is the primary advantage of using attention mechanisms over pure convolutional feature extraction for this task?

## Architecture Onboarding

- Component map: Input image → Backbone (ResNet18) → Feature map → VPL-aware attention → Two heads (left/right) → Uncertainty estimation → Output selection
- Critical path: Image → Backbone → Attention → Heads → Uncertainty → Final lane prediction
- Design tradeoffs: Two-head structure adds complexity but improves robustness; VPL guidance adds geometric constraints but requires reasonable planar road assumptions
- Failure signatures: High uncertainty outputs, inconsistent predictions between heads, poor performance on non-planar roads
- First 3 experiments:
  1. Test baseline performance with single head vs two-head structure on datasets with varying boundary visibility
  2. Evaluate VPL guidance effectiveness by comparing with and without vanishing point/line loss
  3. Measure uncertainty calibration by testing precision-recall curves at different uncertainty thresholds

## Open Questions the Paper Calls Out
None

## Limitations
- The approach assumes roads are approximately planar, which may limit performance on roads with significant elevation changes or sharp curves
- The two-head architecture adds complexity compared to simpler single-head approaches with uncertainty estimation
- Validation is primarily limited to controlled datasets, and effectiveness on highly non-planar roads remains uncertain

## Confidence

- **High confidence**: The two-head structure with evidential uncertainty estimation improves robustness when boundary lines are partially occluded
- **Medium confidence**: VPL-aware attention enables true camera-agnostic performance across all configurations
- **Medium confidence**: The approach generalizes well to mobile phone images and non-calibrated cameras

## Next Checks

1. Test the model on roads with significant elevation changes and curves to evaluate VPL geometry assumptions under non-planar conditions
2. Compare the two-head architecture against a single-head baseline with uncertainty estimation to isolate the contribution of the dual-head design
3. Evaluate model performance under extreme domain shifts, including different countries' road markings and lighting conditions, to assess uncertainty estimation reliability