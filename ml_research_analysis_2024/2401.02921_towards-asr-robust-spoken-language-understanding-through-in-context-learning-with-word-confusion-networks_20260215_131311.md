---
ver: rpa2
title: Towards ASR Robust Spoken Language Understanding Through In-Context Learning
  With Word Confusion Networks
arxiv_id: '2401.02921'
source_url: https://arxiv.org/abs/2401.02921
tags:
- best
- language
- in-context
- performance
- spoken
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using word confusion networks (WCNs) derived
  from ASR lattices as input to large language models (LLMs) for spoken language understanding
  tasks. WCNs represent ASR ambiguities by listing multiple possible word options
  with associated confidence scores at each time step.
---

# Towards ASR Robust Spoken Language Understanding Through In-Context Learning With Word Confusion Networks

## Quick Facts
- arXiv ID: 2401.02921
- Source URL: https://arxiv.org/abs/2401.02921
- Reference count: 0
- Primary result: Word confusion networks (WCNs) derived from ASR lattices improve LLM performance on spoken language understanding tasks when ASR errors are present.

## Executive Summary
This paper proposes using word confusion networks (WCNs) derived from ASR lattices as input to large language models (LLMs) for spoken language understanding tasks. WCNs represent ASR ambiguities by listing multiple possible word options with associated confidence scores at each time step. The authors investigate whether this representation helps LLMs better handle noisy ASR transcripts compared to using just the top hypothesis. Experiments on spoken question answering and intent classification show that larger models like GPT-3.5 can achieve improved performance using WCN inputs, with gains over 1-best transcripts particularly notable when ASR errors are present.

## Method Summary
The proposed approach leverages word confusion networks (WCNs) - a compact representation of ASR lattices that lists multiple possible word hypotheses at each time step along with confidence scores. These WCNs are provided as input to LLMs, with the hypothesis that representing ASR uncertainty explicitly helps the models better handle transcription errors. The authors experiment with filtering WCNs by confidence score and providing instructions to the LLM about the WCN format. They evaluate this approach on spoken question answering and intent classification tasks using both GPT-3.5 and BLOOMZ models, comparing performance against using only the top ASR hypothesis.

## Key Results
- Larger models (GPT-3.5) show improved performance using WCN inputs compared to 1-best transcripts, especially when ASR errors are present
- Filtering WCNs by confidence score and providing format instructions enhances results
- Smaller models (BLOOMZ) show mixed results, indicating potential limitations
- Gains are particularly notable in spoken question answering tasks

## Why This Works (Mechanism)
The approach works because WCNs explicitly represent the uncertainty inherent in ASR output by providing multiple word hypotheses with confidence scores. When LLMs receive this richer representation of possible transcripts rather than just the single most likely hypothesis, they can better reason about the intended meaning despite transcription errors. This allows the models to leverage their strong language understanding capabilities to resolve ambiguities that arise from ASR errors.

## Foundational Learning
- Word Confusion Networks (WCNs): A compact representation of ASR lattices that lists possible word hypotheses at each time step with confidence scores. Needed to understand the input representation being used. Quick check: Can you explain how WCNs differ from simple n-best lists?
- Spoken Language Understanding (SLU): Tasks involving extracting meaning from spoken input, such as intent classification and question answering. Needed to contextualize the evaluation tasks. Quick check: What are the key challenges in SLU compared to text-only understanding?
- In-Context Learning: The ability of LLMs to perform tasks based on instructions and examples provided in the prompt without parameter updates. Needed to understand how LLMs are being used. Quick check: How does in-context learning differ from fine-tuning in LLMs?
- ASR Confidence Scores: Probability estimates associated with ASR hypotheses that indicate transcription reliability. Needed to understand how uncertainty is quantified. Quick check: What factors affect the reliability of ASR confidence scores?
- Compact Lattice Representations: Methods for efficiently encoding multiple ASR hypotheses. Needed to understand WCN efficiency. Quick check: Why are compact representations important for LLM input?

## Architecture Onboarding
- Component Map: ASR System -> WCN Generation -> LLM Input Processing -> SLU Task Output
- Critical Path: ASR transcription → WCN construction → confidence-based filtering → LLM prompt construction → task completion
- Design Tradeoffs: WCNs provide richer uncertainty information but increase input length and complexity versus single-best transcripts
- Failure Signatures: Mixed results on smaller models suggest effectiveness depends on model scale; computational overhead not evaluated
- First Experiments: 1) Compare WCN vs 1-best performance across varying ASR error rates 2) Ablate confidence score thresholds for WCN filtering 3) Measure computational cost differences between approaches

## Open Questions the Paper Calls Out
None

## Limitations
- Mixed performance on smaller models (BLOOMZ) suggests effectiveness may depend heavily on model scale
- Experiments focus primarily on spoken question answering and intent classification, limiting generalizability
- Computational overhead and cost-benefit trade-offs are not evaluated
- Limited analysis of optimal confidence score thresholds and alternative uncertainty representations

## Confidence
- High confidence: WCN representation benefits larger LLMs on SLU tasks when ASR errors are present
- Medium confidence: Method's general applicability across model sizes and task types
- Low confidence: Practical deployment benefits and real-world effectiveness

## Next Checks
1. Conduct systematic experiments varying ASR error rates and patterns to determine the method's robustness boundaries and identify failure modes
2. Perform ablation studies on confidence score thresholds and alternative uncertainty representations (e.g., n-best lists, entropy-based uncertainty) to optimize the WCN preprocessing pipeline
3. Measure and compare computational costs (inference time, memory usage) between WCN-based and single-best transcript approaches across different model sizes to assess practical feasibility