---
ver: rpa2
title: 'Dealing with Missing Modalities in Multimodal Recommendation: a Feature Propagation-based
  Approach'
arxiv_id: '2403.19841'
source_url: https://arxiv.org/abs/2403.19841
tags:
- multimodal
- missing
- recommendation
- features
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of missing modalities in multimodal
  recommender systems, where some items in the catalogue lack complete multimodal
  content (e.g., missing product images or descriptions). The authors propose FeatProp,
  a feature propagation-based approach that treats the missing modalities problem
  as a missing node features problem in graph learning.
---

# Dealing with Missing Modalities in Multimodal Recommendation: a Feature Propagation-based Approach

## Quick Facts
- arXiv ID: 2403.19841
- Source URL: https://arxiv.org/abs/2403.19841
- Reference count: 40
- Primary result: FeatProp outperforms baselines for imputing missing modalities in multimodal recommendation, particularly at high missing rates

## Executive Summary
This paper addresses the challenge of missing modalities in multimodal recommender systems, where some items lack complete multimodal content. The authors propose FeatProp, a feature propagation-based approach that treats missing modalities as a graph node feature imputation problem. By projecting the user-item graph into an item-item co-interaction graph and applying a modified feature propagation algorithm, FeatProp can impute missing multimodal features before feeding them to any downstream multimodal recommender system. Experimental results on three Amazon datasets show consistent performance improvements over baseline methods across various missing rates.

## Method Summary
FeatProp addresses missing modalities by first constructing an item-item co-interaction graph from the user-item interaction matrix, then applying sparsification and normalization before using a modified feature propagation algorithm to impute missing features. The method is model-agnostic and serves as a pre-processing step that can be applied to any multimodal recommender system. The approach leverages graph representation learning techniques, treating the missing modalities problem as a missing node features problem in graph learning, and iteratively propagates available multimodal features from co-interacted items to impute missing ones.

## Key Results
- FeatProp outperforms baseline methods (Zeros, Mean, Random) across all tested missing rates (10%-90%)
- Performance remains relatively stable even at high missing rates, with Recall@20 degrading gracefully
- FeatProp shows particular effectiveness on the Amazon Sports dataset when combined with the MMSSL multimodal recommender system
- The approach demonstrates robustness across different percentages of missing items, with stable performance trends

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Missing modalities are imputed by propagating multimodal features from co-interacted items through an item-item graph.
- Mechanism: The algorithm constructs an item-item co-interaction graph from the user-item interaction matrix, then iteratively propagates available multimodal features along this graph to impute missing features.
- Core assumption: Items that share users (co-interacted items) have similar multimodal content, allowing feature propagation to be meaningful.
- Evidence anchors:
  - [abstract] "projecting the user-item graph into an item-item co-interaction graph, applying sparsification and normalization, and then using a modified version of the feature propagation algorithm to impute missing multimodal features"
  - [section] "Inspired by the recent advances in graph representation learning, we propose to re-sketch the missing modalities problem as a problem of missing graph node features to apply the state-of-the-art feature propagation algorithm eventually"
  - [corpus] Weak: corpus lacks direct evidence for this specific mechanism, though related papers mention similar graph-based approaches
- Break condition: If co-interacted items don't share multimodal similarity (e.g., very diverse catalog), propagation will produce noisy imputations.

### Mechanism 2
- Claim: Feature propagation minimizes Dirichlet energy, ensuring smooth feature distributions across the graph.
- Mechanism: The iterative propagation process converges to a state that minimizes graph Dirichlet energy, creating smooth transitions between feature values of connected nodes.
- Core assumption: Minimizing Dirichlet energy produces reasonable imputations for missing features.
- Evidence anchors:
  - [abstract] "Running this iterative process to convergence minimizes the Dirichlet Energy of the graph [41], a quantity measuring the smoothness of the graph features"
  - [section] "FeatProp is a fixed, non-learnable, pre-processing step after which a standard graph neural network can be run on the graph with the reconstructed features"
  - [corpus] Explicit: "FeaProp" is explicitly mentioned as a baseline in corpus papers, supporting its relevance
- Break condition: If the graph topology is very sparse or disconnected, Dirichlet energy minimization may not produce meaningful imputations.

### Mechanism 3
- Claim: The approach is model-agnostic and can be applied as a pre-processing step to any multimodal recommender system.
- Mechanism: By treating missing modalities as a separate pre-processing problem, the core recommendation model remains unchanged while receiving complete feature inputs.
- Core assumption: The imputation quality is sufficient for downstream recommendation models to benefit without architectural changes.
- Evidence anchors:
  - [abstract] "Our method involves projecting the user-item graph into an item-item co-interaction graph, applying sparsification and normalization, and then using a modified version of the feature propagation algorithm to impute missing multimodal features"
  - [section] "Technically, we first project the user-item graph into an item-item one based on co-interactions. Then, leveraging the multimodal similarities among co-interacted items, we apply a modified version of the feature propagation technique to impute the missing multimodal features"
  - [corpus] Weak: corpus lacks direct evidence for model-agnostic claims, though related papers mention similar pre-processing approaches
- Break condition: If the imputation introduces significant bias or noise that the downstream model cannot handle.

## Foundational Learning

- Concept: Graph representation learning and feature propagation
  - Why needed here: The core mechanism relies on propagating features across a graph structure to impute missing values
  - Quick check question: What is the difference between message passing and feature propagation in graph neural networks?

- Concept: Multimodal feature extraction and representation
  - Why needed here: Understanding how multimodal features (visual, textual) are extracted and represented is crucial for the imputation process
  - Quick check question: How do pre-trained models like BERT and ResNet contribute to multimodal feature extraction?

- Concept: Collaborative filtering and user-item interaction graphs
  - Why needed here: The approach builds on collaborative filtering principles by assuming co-interacted items share similarities
  - Quick check question: What is the relationship between item similarity and user interaction patterns in collaborative filtering?

## Architecture Onboarding

- Component map:
  - Data ingestion: User-item interaction matrix, multimodal features
  - Graph construction: Item-item co-interaction graph creation
  - Sparsification: Top-k sparsification of item-item graph
  - Normalization: Symmetric Laplacian normalization
  - Feature propagation: Iterative imputation of missing features
  - Integration: Feeding imputed features to downstream recommender system

- Critical path: Data ingestion → Graph construction → Sparsification → Normalization → Feature propagation → Integration

- Design tradeoffs:
  - Sparsification rate (k): Higher k captures more connections but risks noise; lower k is cleaner but may miss important relationships
  - Number of propagation layers: More layers allow broader feature diffusion but risk oversmoothing
  - Convergence criteria: Early stopping saves computation but may leave imputation incomplete

- Failure signatures:
  - Poor performance on high-missing-rate scenarios: Indicates propagation cannot recover from severe data loss
  - Degradation with very high sparsification: Suggests important connections are being removed
  - Instability across random samplings: Points to sensitivity to initial missing item selection

- First 3 experiments:
  1. Compare imputation quality (e.g., reconstruction error) against baseline methods (Zeros, Mean, Random) on a small dataset
  2. Test sensitivity to sparsification rate by varying k and measuring recommendation performance
  3. Evaluate convergence behavior by testing different numbers of propagation layers on a held-out validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal percentage of missing modalities that maximizes the performance of FeatProp while maintaining computational efficiency?
- Basis in paper: [explicit] The paper states that FeatProp performs better than other baselines across various missing percentages (10% to 90%) and suggests that it becomes a winning solution at higher missing rates, particularly on Amazon Sports.
- Why unresolved: The paper does not specify an optimal percentage for missing modalities, and the performance trends vary across different datasets and models.
- What evidence would resolve it: Conducting experiments to systematically evaluate FeatProp's performance across a wider range of missing percentages and comparing it with computational costs could identify an optimal balance.

### Open Question 2
- Question: How does FeatProp's performance vary when applied to datasets with more than two modalities?
- Basis in paper: [inferred] The paper mentions visual, textual, and audio modalities but primarily tests FeatProp on datasets with visual and textual features. The impact of additional modalities is not explored.
- Why unresolved: The paper focuses on visual and textual modalities, leaving the performance on datasets with additional modalities unexplored.
- What evidence would resolve it: Testing FeatProp on datasets with three or more modalities and comparing its performance to baseline methods would provide insights into its effectiveness with diverse multimodal data.

### Open Question 3
- Question: What are the long-term effects of using FeatProp on the stability and adaptability of multimodal recommender systems?
- Basis in paper: [inferred] The paper discusses FeatProp as a pre-processing step but does not address its impact on the long-term performance or adaptability of recommender systems.
- Why unresolved: The focus is on immediate performance improvements, with no exploration of how FeatProp affects system stability or adaptability over time.
- What evidence would resolve it: Longitudinal studies tracking the performance of recommender systems using FeatProp over extended periods could reveal insights into its long-term effects on system stability and adaptability.

## Limitations
- The approach assumes co-interacted items share multimodal similarities, which may not hold for diverse product catalogs
- Performance degrades at very high missing rates (>70%), though remains more stable than baselines
- The method is tested primarily on Amazon product datasets with text and visual features, limiting generalizability to other domains

## Confidence
- High: Feature propagation effectively imputes missing multimodal features when co-interacted items share similarities
- Medium: Model-agnostic nature allows seamless integration with any multimodal recommender system
- Medium: FeatProp consistently outperforms baselines across different missing rates and datasets

## Next Checks
1. Test FeatProp on a dataset with high product diversity (e.g., fashion or electronics) to validate co-interaction similarity assumptions
2. Implement ablation studies varying sparsification rate (k) and propagation layers (L) to find optimal hyperparameters
3. Compare FeatProp against recent multimodal imputation methods like those using contrastive learning or generative models