---
ver: rpa2
title: Is Open-Source There Yet? A Comparative Study on Commercial and Open-Source
  LLMs in Their Ability to Label Chest X-Ray Reports
arxiv_id: '2402.12298'
source_url: https://arxiv.org/abs/2402.12298
tags:
- gpt-4
- dataset
- reports
- were
- radiology
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compares the performance of commercial (GPT-3.5 Turbo,
  GPT-4) and open-source large language models (Llama2, Mistral, QWEN) in labeling
  chest X-ray reports. Using two independent datasets, the models were evaluated on
  their ability to accurately classify 13 radiological findings using zero-shot and
  few-shot prompting techniques.
---

# Is Open-Source There Yet? A Comparative Study on Commercial and Open-Source LLMs in Their Ability to Label Chest X-Ray Reports

## Quick Facts
- arXiv ID: 2402.12298
- Source URL: https://arxiv.org/abs/2402.12298
- Reference count: 37
- Primary result: GPT-4 outperforms open-source LLMs in zero-shot prompting for radiology report classification, but few-shot prompting enables open-source models to match GPT-4 performance while preserving privacy.

## Executive Summary
This study compares commercial LLMs (GPT-3.5 Turbo, GPT-4) with open-source models (Llama2, Mistral, QWEN) on classifying chest X-ray reports for 13 radiological findings. Using two independent datasets, the models were evaluated with zero-shot and few-shot prompting techniques. GPT-4 consistently achieved the highest performance in zero-shot prompting, but with few-shot examples, top open-source models (QWEN1.5-72B, Llama2-70B) reached comparable accuracy. The findings suggest open-source models can serve as privacy-preserving alternatives to commercial APIs for medical report classification.

## Method Summary
The study evaluated LLMs on classifying chest X-ray reports using zero-shot and few-shot prompting on two datasets: an institutional dataset of 540 MGH reports and the ImaGenome dataset of 500 annotated reports. Models were tested for 13 radiological findings using micro and macro F1-scores. Few-shot examples were selected to include at least one positive sample for each finding. CheXbert and CheXpert-labeler served as baselines. Model outputs were post-processed to conform to CheXbert standards.

## Key Results
- GPT-4 achieved micro F1-scores of 0.975 (institutional) and 0.984 (ImaGenome) in zero-shot prompting, outperforming all open-source models
- With few-shot prompting, QWEN1.5-72B and Llama2-70B matched GPT-4's performance on the institutional dataset
- An ensemble of three open-source models (Mixtral-8x7B, Llama2-70B, QWEN1.5-72B) achieved micro F1-score of 0.960 on the institutional dataset

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Few-shot prompting bridges the performance gap between open-source LLMs and GPT-4 in radiology report classification
- Mechanism: Providing example reports with desired labels conditions open-source models to align their output patterns with expert annotations, compensating for their weaker zero-shot generalization
- Core assumption: The few-shot examples are representative and capture the label assignment patterns needed for accurate classification
- Evidence anchors:
  - [abstract] "However, with few-shot prompting, the best open-source models (QWEN1.5-72B, Llama2-70B) achieved performance on par with GPT-4"
  - [section] "Table 3 shows the results for few-shot prompting on the ImaGenome dataset... GPT-4 was the best performing model on this task with a micro F1-Score of 0.984, which constitutes a 0.9 percentage point improvement from its zero-shot result. Llama2-70B was still the second best performing model with a micro F1-Score of 0.970, but its performance did not improve through the use of few-shot prompting."
  - [corpus] Weak evidence; no corpus neighbors directly discuss few-shot vs zero-shot prompting effects
- Break condition: If few-shot examples are not representative or the task distribution shifts significantly, open-source models may fail to generalize

### Mechanism 2
- Claim: Open-source LLMs can be deployed locally, preserving data privacy and ensuring reproducibility
- Mechanism: By running models on-premises, sensitive patient data never leaves the hospital network, avoiding HIPAA compliance issues while enabling consistent performance over time
- Core assumption: The institution has sufficient GPU resources or quantized models can run on available hardware
- Evidence anchors:
  - [abstract] "the implementation of few-shot prompting can bring open-source models on par with GPT-4. This shows that open-source models could be a performant and privacy preserving alternative to GPT-4"
  - [section] "By using open source LLMs that run locally, privacy can be ensured because the data does not have to leave the hospital network to be processed on a remote server"
  - [corpus] Weak evidence; corpus neighbors focus on general NLP evaluation rather than deployment considerations
- Break condition: If local compute resources are insufficient, or if model updates are required for performance, reproducibility benefits diminish

### Mechanism 3
- Claim: Ensemble of diverse open-source models can match or exceed GPT-4 performance
- Mechanism: Majority voting among models with different strengths (e.g., Llama2-70B, QWEN1.5-72B, Mixtral-8x7B) leverages complementary capabilities and reduces individual model biases
- Core assumption: The ensemble models have uncorrelated errors and collectively cover the label space well
- Evidence anchors:
  - [abstract] "the ensemble consisting of Mixtral-8x7B, Llama2-70B and QWEN1.5-72B achieved a micro F1-score of 0.960" and "The ensemble achieved higher micro and macro F1-Scores than GPT-3.5 Turbo"
  - [section] "we were able to improve the overall performance of the open-source models on the institutional dataset by combining the three models with the best individual performance... This ensemble was particularly capable because its individual models had different labels on which they performed well."
  - [corpus] No direct corpus evidence supporting ensemble effectiveness for this specific task
- Break condition: If models have highly correlated errors or if the ensemble voting fails to resolve ambiguous cases, performance gains may be limited

## Foundational Learning

- Concept: Zero-shot vs few-shot prompting in LLMs
  - Why needed here: Understanding the performance difference between zero-shot and few-shot prompting is critical for selecting the right approach and interpreting results
  - Quick check question: Why did GPT-4 improve by 0.9 percentage points from zero-shot to few-shot on the ImaGenome dataset, while Llama2-70B did not?

- Concept: Model quantization and hardware constraints
  - Why needed here: Quantized models (e.g., Int4) enable deployment on limited hardware, but may impact accuracy; engineers must balance speed, cost, and performance
  - Quick check question: What is the trade-off between model size (parameters) and the need for quantization in this study?

- Concept: Multi-label classification and label hierarchy
  - Why needed here: Radiology reports involve hierarchical labels (e.g., Cardiomegaly implies Enlarged Cardiomediastinum); understanding this is key for correct evaluation
  - Quick check question: How does the hierarchical structure of labels affect the calculation of micro and macro F1-scores in this study?

## Architecture Onboarding

- Component map: Data ingestion -> Prompt template creation -> Model inference (quantized if needed) -> Output parsing -> Metric calculation
- Critical path: Data ingestion -> Prompt template creation -> Model inference (quantized if needed) -> Output parsing -> Metric calculation
- Design tradeoffs: Local deployment (privacy, reproducibility) vs. cloud APIs (convenience, updates); model size vs. hardware constraints; ensemble complexity vs. marginal gains
- Failure signatures: Inconsistent JSON output from models; mismatched label sets; class imbalance causing metric distortion; hardware OOM errors with large models
- First 3 experiments:
  1. Run a single report through GPT-4 zero-shot, inspect JSON output, ensure label collapsing matches CheXbert rules
  2. Deploy a quantized Llama2-70B model locally, run same report, compare output and F1-score
  3. Create a minimal ensemble (Llama2-70B + QWEN1.5-72B), run majority vote, evaluate improvement over individual models

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different prompt engineering strategies affect the performance of open-source LLMs in radiology report classification?
- Basis in paper: [inferred] The paper mentions that "Experiments were run on a development set to find the ideal strategies for choosing the examples" but does not provide detailed analysis of different prompt strategies
- Why unresolved: The paper only explores zero-shot and few-shot prompting with limited experimentation on prompt optimization, leaving the impact of various prompt engineering techniques unexplored
- What evidence would resolve it: Systematic testing of different prompt engineering approaches (chain-of-thought, tree-of-thought, different example selection methods) with comprehensive performance comparisons across various open-source models

### Open Question 2
- Question: Can ensemble models of open-source LLMs consistently outperform GPT-4 across different medical domains and report types?
- Basis in paper: [explicit] The paper shows that an ensemble of three open-source models (Mixtral-8x7B, Llama2-70B, QWEN1.5-72B) achieved performance close to GPT-4 on the institutional dataset
- Why unresolved: The study only tested one ensemble configuration on two specific datasets, leaving questions about generalizability and optimal ensemble composition unanswered
- What evidence would resolve it: Extensive testing of various ensemble configurations across multiple medical domains and report types, including different model combinations and voting mechanisms

### Open Question 3
- Question: What are the long-term cost implications and performance stability of using open-source LLMs versus commercial models for large-scale medical report processing?
- Basis in paper: [inferred] The paper discusses privacy advantages and initial cost benefits of open-source models but does not address long-term maintenance and performance stability
- Why unresolved: The study focuses on initial performance comparisons without considering ongoing operational costs, model updates, or performance degradation over time
- What evidence would resolve it: Long-term studies tracking performance, maintenance costs, and adaptation requirements of open-source models compared to commercial APIs across various medical institutions and report volumes

## Limitations
- Inconsistent effectiveness of few-shot prompting across datasets suggests dataset-dependent rather than generalizable improvements
- Large open-source models (70B parameters) may be impractical to deploy in resource-constrained settings even with quantization
- Study did not evaluate model performance over time or with different prompt templates, limiting assessment of real-world reliability

## Confidence
- High confidence: GPT-4's superior zero-shot performance across both datasets; the feasibility of local deployment for privacy preservation
- Medium confidence: The effectiveness of few-shot prompting for bridging performance gaps between commercial and open-source models; ensemble performance benefits
- Low confidence: Generalizability of few-shot prompting improvements across different datasets and medical domains

## Next Checks
1. Test the same few-shot prompting strategy on a third, independently sourced radiology dataset to verify if the performance improvements are reproducible beyond the institutional and ImaGenome datasets
2. Conduct a head-to-head comparison of quantized (Int4) versus full-precision open-source models to quantify the accuracy-cost tradeoff for practical deployment
3. Implement a longitudinal evaluation where models are tested monthly on new radiology reports to assess performance stability and identify potential drift over time