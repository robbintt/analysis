---
ver: rpa2
title: Decoupling Feature Extraction and Classification Layers for Calibrated Neural
  Networks
arxiv_id: '2405.01196'
source_url: https://arxiv.org/abs/2405.01196
tags: []
core_contribution: Decoupling the training of feature extraction and classification
  layers significantly improves the calibration of deep neural networks while maintaining
  accuracy. The proposed Two-Stage Training (TST) method trains feature extraction
  layers first, then retrains only the classification layers.
---

# Decoupling Feature Extraction and Classification Layers for Calibrated Neural Networks

## Quick Facts
- arXiv ID: 2405.01196
- Source URL: https://arxiv.org/abs/2405.01196
- Reference count: 35
- Primary result: Decoupling feature extraction and classification layer training significantly improves calibration while maintaining accuracy

## Executive Summary
This paper introduces a Two-Stage Training (TST) method that decouples the training of feature extraction layers from classification layers in neural networks, resulting in significantly improved calibration without sacrificing accuracy. The approach first trains the entire network, then freezes the feature extraction layers and retrains only the classification layers. A variational extension (V-TST) further improves calibration by adding a Gaussian prior to the final hidden layer and training variationally. Experiments demonstrate substantial reductions in Expected Calibration Error (ECE) - up to 87.64% improvement - across CIFAR10, CIFAR100, and SVHN datasets using WideResNet and Vision Transformer architectures.

## Method Summary
The proposed method involves two distinct training stages. First, the entire network is trained normally on the target dataset. Then, the feature extraction layers are frozen, and only the classification layers are retrained using the same dataset. The variational extension (V-TST) adds a Gaussian prior on the weights of the final hidden layer and trains using variational inference, encouraging the network to maintain information in the final hidden layer rather than collapsing it to a deterministic value. This approach addresses the calibration problem by preventing the feature extraction layers from adapting to the specific characteristics of the classification head during the second training stage.

## Key Results
- Substantial reduction in Expected Calibration Error (ECE) across all tested datasets and architectures
- Up to 87.64% improvement in calibration on CIFAR100 with ViT
- Minimal accuracy degradation (typically <1%) compared to baseline models
- V-TST variant provides additional structure in the feature space and improves out-of-distribution detection

## Why This Works (Mechanism)
The method works by decoupling the feature extraction process from the classification task. During standard training, feature extraction layers can overfit to the specific characteristics of the classification head, leading to overconfident predictions. By freezing these layers during the second training stage, the method forces the classification layers to work with the existing feature representation rather than allowing the features to adapt to the classifier. The variational extension further encourages information preservation in the final hidden layer by regularizing the weights with a Gaussian prior, preventing the network from collapsing this information into a deterministic mapping.

## Foundational Learning

1. **Calibration in deep learning**: Measuring whether predicted probabilities match empirical accuracy
   - Why needed: The paper's primary goal is improving model calibration
   - Quick check: Expected Calibration Error (ECE) should decrease with the proposed method

2. **Temperature scaling**: A post-hoc method for calibrating neural networks by scaling logits
   - Why needed: The paper uses temperature scaling as a baseline and compares against it
   - Quick check: Temperature scaling should provide baseline calibration improvements

3. **Variational inference in neural networks**: Training with probabilistic weights using Gaussian priors
   - Why needed: V-TST uses variational training with Gaussian priors on the final layer
   - Quick check: KL divergence between variational posterior and prior should be monitored during training

## Architecture Onboarding

Component map: Input -> Feature extraction layers -> Classification layers -> Output

Critical path: The feature extraction layers (first layers) must learn useful representations before the classification layers are trained in isolation.

Design tradeoffs: Freezing feature layers preserves learned representations but may limit adaptation to the specific classification task during stage two.

Failure signatures: Over-regularization in V-TST can lead to underfitting, while insufficient regularization may not improve calibration.

First experiments:
1. Apply TST to a pre-trained WideResNet on CIFAR10 and measure ECE improvement
2. Compare standard temperature scaling vs TST on the same architecture
3. Implement V-TST on CIFAR100 and evaluate both calibration and feature space structure

## Open Questions the Paper Calls Out

None specified in the provided content.

## Limitations

- Primary evaluation on CIFAR10, CIFAR100, and SVHN datasets with WideResNet and Vision Transformer architectures
- Theoretical explanation for calibration improvements is primarily empirical rather than analytical
- Limited systematic exploration of the trade-off between calibration and accuracy at scale

## Confidence

High confidence in calibration improvement claims on tested datasets, as results show consistent and substantial ECE reductions across multiple architectures and datasets.

Medium confidence in accuracy maintenance claims, as minimal accuracy drops are well-documented but trade-off exploration is limited.

Low confidence in out-of-distribution generalization claims, as these are tested on only a few shifted datasets and OOD benchmarks without systematic exploration.

## Next Checks

1. Test the method on diverse architectures including ResNet, EfficientNet, and language models to verify architecture-agnostic calibration improvements

2. Evaluate performance on domain shift scenarios beyond CIFAR-based shifts, including natural adversarial examples and real-world distribution shifts

3. Conduct ablation studies isolating the contributions of feature layer freezing versus classification layer retraining to quantify each component's impact on calibration improvement