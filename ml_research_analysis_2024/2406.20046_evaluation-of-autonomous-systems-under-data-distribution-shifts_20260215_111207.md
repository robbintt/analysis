---
ver: rpa2
title: Evaluation of autonomous systems under data distribution shifts
arxiv_id: '2406.20046'
source_url: https://arxiv.org/abs/2406.20046
tags:
- data
- shift
- image
- distance
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of evaluating autonomous systems
  under data distribution shifts, particularly in the context of self-driving cars.
  The authors propose using distance metrics between training and testing data to
  define safe operation limits within these shifts.
---

# Evaluation of autonomous systems under data distribution shifts

## Quick Facts
- arXiv ID: 2406.20046
- Source URL: https://arxiv.org/abs/2406.20046
- Authors: Daniel Sikar; Artur Garcez
- Reference count: 40
- Primary result: Histogram Intersection in RGB space is the most computationally efficient and provides strong linearity for detecting unsafe data distribution shifts in autonomous driving systems

## Executive Summary
This paper addresses the critical challenge of evaluating autonomous systems under data distribution shifts, with a focus on self-driving cars. The authors propose using distance metrics between training and testing data distributions to define safe operation limits when shifts occur. Through systematic experiments using a Unity-based game engine to generate labeled datasets and training models based on state-of-the-art self-driving architectures, they demonstrate that network predictive accuracy degrades beyond empirically determined thresholds of data distribution shift. The study identifies Histogram Intersection in RGB color space as the preferred metric for its computational efficiency and strong linearity in detecting when shifts become unsafe for reliable predictions.

## Method Summary
The authors generated labeled datasets using the Unity-based SDSandbox simulator, creating Generated Track and Generated Road circuits with steering angle labels. They trained neural network models based on Dave and PilotNet architectures on preprocessed RGB datasets (cropped, resized to 66x200, and converted to YUV). To evaluate distribution shifts, they systematically applied pixel intensity shifts ranging from -120 to +120 to test images and computed three distance metrics—Histogram Intersection, Relative Entropy, and Bhattacharyya Distance—in both RGB and YUV color spaces. The performance degradation was measured using error metrics including MAE, MAPE, MSE, and RMSE, allowing the authors to establish empirical thresholds beyond which predictions were deemed unreliable.

## Key Results
- Histogram Intersection in RGB space provides the most computationally efficient and linearly responsive metric for detecting unsafe distribution shifts
- The study establishes an empirical threshold of approximately 0.40 histogram overlap below which network predictive accuracy is expected to degrade
- Converting images to YUV color space reduces mean delta variability compared to RGB, creating a more stable baseline for detecting distribution shifts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Histogram Intersection in RGB space provides a computationally efficient and linearly responsive metric for detecting unsafe distribution shifts in autonomous driving perception systems.
- Mechanism: The metric measures overlap between training and testing image histograms; when overlap falls below an empirically determined threshold, it signals that the input data has drifted too far from the training distribution for reliable predictions.
- Core assumption: The histogram-based representation captures sufficient distributional information about pixel intensity shifts to correlate with model performance degradation.
- Evidence anchors:
  - [abstract] The study concludes that Histogram Intersection in RGB space is the most computationally efficient and provides strong linearity.
  - [section] "We concluded that in the RGB space, any of the three distance metrics would be adequate, and the least computationally intensive would be preferred, which is the Histogram Intersection."
  - [corpus] Weak - no direct mentions of histogram-based methods in related works; corpus focuses on conformal prediction and tree-based adaptations.
- Break condition: If the relationship between histogram overlap and model accuracy becomes non-linear due to complex lighting conditions or if the image preprocessing pipeline significantly alters the pixel distribution characteristics.

### Mechanism 2
- Claim: Converting images from RGB to YUV color space reduces variability in mean pixel intensity, making it easier to detect shifts relative to training data.
- Mechanism: YUV separates luminance (Y) from chrominance (U,V), creating a more perceptually uniform space where brightness changes affect primarily the Y channel, reducing noise in the distributional comparison.
- Core assumption: The mean delta reduction in YUV space provides a more stable baseline for detecting distribution shifts compared to RGB space.
- Evidence anchors:
  - [section] "We observed that when no datashift exists, the YUV mean is lower than the RGB mean... the mean delta is lower in YUV space, creating lesser variability in the data."
  - [corpus] Weak - corpus does not discuss color space transformations or their impact on distribution shift detection.
- Break condition: If the autonomous system relies on color information for decision-making (e.g., traffic light detection), converting to YUV could remove critical information and make shift detection less reliable.

### Mechanism 3
- Claim: Empirical threshold determination using controlled pixel intensity shifts provides a practical safety boundary for autonomous system operation.
- Mechanism: By systematically shifting pixel values and measuring the resulting performance degradation, the study establishes quantitative boundaries (e.g., ±40 intensity shift) beyond which predictions are deemed unreliable.
- Core assumption: The controlled shift experiments in a simulated environment accurately model real-world distribution shifts that could occur in deployment.
- Evidence anchors:
  - [section] "We concluded that beyond an empirically obtained threshold of the data distribution shift, it is unreasonable to expect network predictive accuracy not to degrade."
  - [section] "We could then claim that for any such pairing, we would accept the prediction of the network controlling the autonomous system as long as the Histogram overlap is greater than 0.40."
  - [corpus] Weak - corpus focuses on adaptive algorithms and conformal prediction but does not discuss empirical threshold determination for distribution shifts.
- Break condition: If real-world distribution shifts are more complex than uniform pixel intensity shifts (e.g., sudden appearance of novel objects, weather conditions), the empirical thresholds may not generalize.

## Foundational Learning

- Concept: Data distribution shift and its impact on machine learning model performance
  - Why needed here: The entire paper addresses how shifts between training and testing data distributions affect autonomous system reliability, making this fundamental concept essential for understanding the problem space.
  - Quick check question: What is the difference between covariate shift and concept drift, and how might each affect an autonomous driving system?

- Concept: Color space transformations and their perceptual implications
  - Why needed here: The paper uses both RGB and YUV spaces, requiring understanding of how these representations differ and why YUV might be advantageous for certain vision tasks.
  - Quick check question: How does the YUV color space separate luminance from chrominance, and what advantage does this provide for computer vision applications?

- Concept: Histogram-based image comparison metrics
  - Why needed here: The proposed safety mechanism relies on histogram intersection and other histogram-based distance metrics to quantify distribution shifts.
  - Quick check question: What properties make histogram intersection a computationally efficient metric, and how does it compare to KL divergence in terms of sensitivity to distribution differences?

## Architecture Onboarding

- Component map: Unity-based SDSandbox simulator → Image preprocessing pipeline (cropping, resizing, RGB→YUV conversion) → Trained CNN model (NVIDIA PilotNet architecture) → Histogram distance calculation module → Safety decision engine → Control handover mechanism
- Critical path: Image acquisition → Preprocessing → Prediction → Distribution shift detection → Safety decision → Control action
- Design tradeoffs: RGB provides more information but YUV offers better stability; more sophisticated distance metrics may be more accurate but computationally expensive; empirical thresholds are easy to implement but may not generalize
- Failure signatures: High MSE/MAPE values with small histogram distances may indicate model degradation not captured by distribution shift metrics; false positives in safety detection could cause unnecessary control handovers
- First 3 experiments:
  1. Replicate the histogram intersection experiments with the provided SDSandbox datasets to verify the linear relationship between pixel shifts and metric values
  2. Test the safety decision engine with images at various distances from the training distribution to validate the empirically determined thresholds
  3. Compare RGB and YUV performance on the same distribution shift detection task to verify the claimed advantages of YUV space

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the safe operation limits be determined for different autonomous systems beyond self-driving cars?
- Basis in paper: [explicit] The paper discusses using distance metrics between training and testing data to define safe operation limits for autonomous systems under data distribution shifts.
- Why unresolved: The paper focuses on self-driving cars as a specific example, but the methodology could potentially be applied to other autonomous systems. However, the authors do not explore this extension.
- What evidence would resolve it: Empirical studies applying the proposed distance metrics to other autonomous systems (e.g., drones, industrial robots) and validating the safe operation limits in real-world scenarios.

### Open Question 2
- Question: How do different types of data distribution shifts (e.g., rotation, translation, scaling) affect the performance of distance metrics in defining safe operation limits?
- Basis in paper: [explicit] The paper mentions that accuracy and confidence degrade with dataset shifts (rotated or horizontally translated images) and discusses the impact of pixel intensity value shifts on RGB images.
- Why unresolved: The paper focuses on pixel intensity value shifts and does not explore other types of data distribution shifts or their effects on the proposed distance metrics.
- What evidence would resolve it: Comparative studies analyzing the performance of distance metrics under various types of data distribution shifts and identifying the most robust metrics for different shift types.

### Open Question 3
- Question: How can the proposed distance metrics be integrated into existing autonomous systems to enable real-time detection of unsafe data distribution shifts?
- Basis in paper: [explicit] The paper proposes using distance metrics to define safe operation limits, but does not discuss how these metrics can be integrated into the decision-making process of autonomous systems.
- Why unresolved: The paper presents a theoretical framework for defining safe operation limits but does not provide a practical implementation strategy for real-time detection and response to unsafe data distribution shifts.
- What evidence would resolve it: Development and testing of a system that incorporates the proposed distance metrics into the decision-making process of an autonomous system, demonstrating its ability to detect and respond to unsafe data distribution shifts in real-time.

## Limitations
- The empirical thresholds established in a controlled simulation environment may not generalize to real-world autonomous driving scenarios with more complex distribution shifts
- The paper does not address potential concept drift scenarios where the relationship between input features and labels changes, only covariate shifts
- The computational efficiency gains of Histogram Intersection in RGB space have not been validated against alternative methods in real-time deployment contexts

## Confidence
- **High confidence** in the observation that data distribution shifts impact network predictive accuracy - supported by systematic experimental evidence
- **Medium confidence** in the proposed safety mechanism using histogram-based distance metrics - the methodology is sound but limited by simulation conditions
- **Low confidence** in the generalizability of empirically determined thresholds to real-world autonomous driving - requires validation in field testing

## Next Checks
1. Validate the empirically determined safety thresholds using real-world driving data with varying weather and lighting conditions to test robustness beyond the controlled simulation environment
2. Compare the proposed histogram-based approach against alternative distribution shift detection methods (such as conformal prediction or domain adaptation techniques) to assess relative performance and computational efficiency
3. Conduct ablation studies removing color space transformations to quantify the actual contribution of YUV conversion to improved distribution shift detection performance