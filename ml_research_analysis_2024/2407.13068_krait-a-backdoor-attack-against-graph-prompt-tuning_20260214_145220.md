---
ver: rpa2
title: 'Krait: A Backdoor Attack Against Graph Prompt Tuning'
arxiv_id: '2407.13068'
source_url: https://arxiv.org/abs/2407.13068
tags:
- graph
- prompt
- attack
- attacks
- tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Krait introduces a novel graph prompt backdoor attack that exploits
  the inherent vulnerability of graph prompt tuning models by crafting graph prompts
  as triggers. It uses a model-agnostic metric called label non-uniformity homophily
  to identify vulnerable poisoned candidates and proposes three customizable trigger
  generation methods to accommodate diverse attack scenarios.
---

# Krait: A Backdoor Attack Against Graph Prompt Tuning

## Quick Facts
- arXiv ID: 2407.13068
- Source URL: https://arxiv.org/abs/2407.13068
- Authors: Ying Song; Rita Singh; Balaji Palanisamy
- Reference count: 40
- Key outcome: Krait achieves 100% attack success rates by poisoning 0.15%-2% of nodes without sacrificing clean accuracy

## Executive Summary
Krait introduces a novel backdoor attack targeting graph prompt tuning models by crafting graph prompts as triggers. The attack exploits the similarity between graph prompt tuning and graph backdoor attacks, where both append small-scale subgraphs to input graphs. By generating universal triggers and embedding them during the graph prompt tuning process, Krait can achieve high attack success rates while maintaining stealthiness. The attack uses a model-agnostic metric called label non-uniformity homophily to identify vulnerable poisoned candidates and proposes three customizable trigger generation methods to accommodate diverse attack scenarios.

## Method Summary
Krait operates by first selecting poisoned candidates using the label non-uniformity homophily (LNH) metric, which identifies nodes near decision boundaries based on their homophily and label distribution. Three trigger generation methods are then employed: Invoke (creating new nodes), Interact (adding edges between existing nodes), and Modify (changing edge directions). A novel centroid similarity-based loss function is incorporated to optimize attack effectiveness by pushing poisoned samples closer to target centroids while maintaining distance from victim centroids. The attack is trained through graph prompt tuning, allowing triggers to be adaptively tuned along with benign prompts.

## Key Results
- Achieves 100% attack success rates by poisoning as few as 2-22 nodes (0.15%-2% of training nodes)
- Maintains clean accuracy comparable to benign models
- Remains effective across different GNN backbones (GCN, GAT, GT)
- Successfully transfers attacks across different homophily levels

## Why This Works (Mechanism)

### Mechanism 1
Graph prompt tuning's similarity to graph backdoor attacks allows triggers to be disguised as benign graph prompts. Both approaches append small-scale subgraphs to input graphs, enabling Krait to generate graph prompts as triggers that are adaptively tuned during the prompt tuning process.

### Mechanism 2
The label non-uniformity homophily (LNH) metric effectively identifies vulnerable poisoned candidates by combining homophily measurements with label distribution non-uniformity. Nodes with low homophily and high label distribution non-uniformity are near decision boundaries and more susceptible to misclassification.

### Mechanism 3
The centroid similarity-based loss function improves attack effectiveness by incorporating constraints on centroid alignment between poisoned samples and target/victim label centroids. This pushes poisoned samples closer to target centroids while maintaining distance from victim centroids, improving misclassification likelihood while preserving clean accuracy.

## Foundational Learning

- **Graph Neural Networks (GNNs) and message-passing mechanisms**: Understanding how GNNs aggregate information from local neighborhoods is crucial for comprehending how backdoor attacks can manipulate node representations. Quick check: What is the primary mechanism by which GNNs update node embeddings during message passing?

- **Graph prompt tuning and its relationship to pre-training/fine-tuning paradigms**: Krait exploits specific characteristics of graph prompt tuning, so understanding this paradigm is essential for grasping the attack's mechanism. Quick check: How does graph prompt tuning differ from traditional fine-tuning of pre-trained GNNs?

- **Homophily in graph data and its implications for GNN performance**: The LNH metric and defense analysis both rely on understanding homophily properties in graphs. Quick check: What is homophily in the context of graph data, and why is it important for GNN performance?

## Architecture Onboarding

- **Component map**: Poisoned candidate selection (LNH metric) -> Trigger generation (Invoke/Interact/Modify) -> Loss function optimization (centroid similarity-based) -> Model training and evaluation pipeline -> Defense analysis framework

- **Critical path**: 1. Compute LNH scores for candidate nodes, 2. Select poisoned candidates based on LNH and degree filtering, 3. Generate triggers using chosen method, 4. Train model with custom loss incorporating centroid constraints, 5. Evaluate attack effectiveness and stealthiness

- **Design tradeoffs**: Poisoning rate vs. attack effectiveness (higher rates increase ASR but reduce stealthiness), trigger size vs. computational overhead (larger triggers may improve effectiveness but increase training time), constraint coefficient vs. clean accuracy (stronger constraints may improve stealthiness but potentially reduce clean accuracy)

- **Failure signatures**: Low ASR despite high poisoning rate, significant drop in clean accuracy compared to benign model, high homophily differences between clean and poisoned samples, poor performance across multiple GNN backbones

- **First 3 experiments**: 1. Compare Krait's performance with random poisoned candidate selection using the same trigger generation method, 2. Evaluate the impact of different trigger generation methods (Invoke vs. Interact vs. Modify) on attack effectiveness, 3. Test Krait's performance across different GNN backbones (GCN, GAT, GT) to assess flexibility

## Open Questions the Paper Calls Out

### Open Question 1
How effective is Krait in defending against black-box graph prompt backdoor attacks in real-world applications? The paper extends Krait to the black-box setting and evaluates its performance using different GNN backbones, showing comparable effectiveness to the white-box setting. However, real-world applications may have more complex and diverse data distributions, attack vectors, and system configurations.

### Open Question 2
What are the long-term impacts of graph prompt backdoor attacks on the performance and reliability of graph neural networks? While the paper demonstrates that Krait can achieve high attack success rates without sacrificing clean accuracy, it does not explore the potential long-term consequences of backdoor injections on the model's performance, generalization, and adaptability to new data.

### Open Question 3
How can graph prompt backdoor attacks be effectively detected and mitigated in real-time applications? The paper analyzes the limitations of existing defense mechanisms and suggests monitoring nodes with high confidence scores and proximity to decision boundaries as a potential detection strategy, but does not provide a comprehensive solution for real-time detection and mitigation.

## Limitations
- Generalizability concerns across graphs with different homophily levels or structures remain unexplored
- Computational overhead of the centroid similarity-based loss function is not thoroughly analyzed
- Defense robustness against sophisticated mechanisms like certified defenses is not extensively evaluated
- Modified triggers involving edge additions/modifications could potentially be detected through graph structure analysis

## Confidence

**High Confidence Claims:**
- LNH metric effectively identifies vulnerable poisoned candidates
- Three trigger generation methods produce functional backdoor triggers
- Krait maintains clean accuracy while achieving high attack success rates

**Medium Confidence Claims:**
- Centroid similarity-based loss function significantly improves attack effectiveness and stealthiness
- Krait's effectiveness across different GNN backbones
- Transferability of attacks across different homophily levels

**Low Confidence Claims:**
- Claim that Krait is "undetectable by homophily and node-similarity-based defenders" without extensive testing
- Assertion that Krait is superior to all existing graph backdoor attacks without direct comparative experiments

## Next Checks

1. **Cross-domain transfer validation**: Test Krait's effectiveness when transferring triggers from one domain (e.g., Cora citation graph) to structurally different domains (e.g., Computers co-purchase graph) to validate the robustness of the trigger generation methods across heterogeneous graph structures.

2. **Defense ablation study**: Systematically evaluate Krait against a comprehensive suite of defense mechanisms including homophily-based defenders, spectral graph analysis, trigger detection algorithms, and certified defenses to identify potential detection vectors.

3. **Trigger complexity analysis**: Conduct experiments varying trigger sizes and complexity (number of nodes, edge density) to determine the minimum effective trigger size and assess the relationship between trigger complexity, attack effectiveness, and detectability.