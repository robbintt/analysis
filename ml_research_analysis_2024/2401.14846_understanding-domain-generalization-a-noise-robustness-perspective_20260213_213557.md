---
ver: rpa2
title: 'Understanding Domain Generalization: A Noise Robustness Perspective'
arxiv_id: '2401.14846'
source_url: https://arxiv.org/abs/2401.14846
tags:
- noise
- spurious
- features
- data
- algorithms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the performance of domain generalization
  (DG) algorithms compared to empirical risk minimization (ERM) under label noise.
  The authors theoretically analyze how label noise exacerbates spurious correlations
  for ERM, causing it to converge to suboptimal solutions.
---

# Understanding Domain Generalization: A Noise Robustness Perspective

## Quick Facts
- arXiv ID: 2401.14846
- Source URL: https://arxiv.org/abs/2401.14846
- Reference count: 40
- Primary result: Label noise exacerbates spurious correlations for ERM, but certain DG algorithms exhibit implicit label-noise robustness

## Executive Summary
This paper investigates the performance of domain generalization (DG) algorithms compared to empirical risk minimization (ERM) under label noise. The authors theoretically analyze how label noise amplifies spurious correlations for ERM, causing it to converge to suboptimal solutions. They show that certain DG algorithms, such as IRM and V-REx, exhibit implicit label-noise robustness, which helps mitigate spurious correlations and improve generalization in synthetic experiments. However, comprehensive experiments on real-world benchmark datasets indicate that label-noise robustness does not necessarily translate to better performance compared to ERM. The authors conjecture that the failure mode of ERM arising from spurious correlations may be less pronounced in practice.

## Method Summary
The paper combines theoretical analysis with empirical validation. Theoretically, the authors analyze how label noise affects ERM's convergence to spurious solutions using finite-sample analysis and minimum-norm inductive bias arguments. Empirically, they conduct experiments on synthetic datasets (CMNIST) with controlled spurious correlations and label noise, as well as real-world benchmark datasets (Waterbirds, CelebA, PACS, VLCS, OfficeHome, TerraIncognita, CivilComments) with injected label noise. They compare ERM against DG algorithms including IRM, V-REx, and GroupDRO, evaluating OOD accuracy, worst-group accuracy, and noise memorization metrics.

## Key Results
- Label noise amplifies spurious correlations for ERM, causing convergence to suboptimal solutions in synthetic experiments
- IRM and V-REx exhibit implicit label-noise robustness through regularization that penalizes memorization of noisy samples
- Comprehensive experiments on real-world datasets show label-noise robustness does not necessarily translate to better performance compared to ERM

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Label noise amplifies the failure mode of ERM by increasing reliance on spurious correlations during finite-sample training.
- Mechanism: When label noise is present, the classifier must memorize noisy samples to minimize training loss. In overparameterized settings, this memorization cost is dominated by the norm of nuisance features. The spurious-correlated classifier can memorize noisy samples with a smaller norm increase than the invariant classifier, making it the preferred solution under the minimum-norm inductive bias of gradient descent.
- Core assumption: The spurious classifier has a smaller norm increase for memorization than the invariant classifier, formalized as ∥w(inv)∥ ≥ ∥w(spu)∥ when ∥w(inv)∥² − ∥w(spu)∥² ≥ n(1 − γ)(1 − 2η)C.
- Evidence anchors:
  - [abstract] "our finite-sample analysis reveals that label noise exacerbates the effect of spurious correlations for ERM, undermining generalization."
  - [section] Theorem 4.2 provides the mathematical condition for when spurious classifiers have smaller norms.
  - [corpus] Weak - no direct corpus citations about label noise and spurious correlations.

### Mechanism 2
- Claim: Certain DG algorithms (IRM, V-REx) exhibit implicit label-noise robustness through their optimization objectives.
- Mechanism: IRM and V-REx add regularization terms that penalize memorization of noisy samples. For IRM, the gradient coefficient function α(ϕ) becomes negative for high predictive probabilities, preventing overconfidence on noisy data. For V-REx, the variance penalty makes environments with below-average risk receive gradient ascent instead of descent, effectively "unlearning" memorized noisy patterns.
- Evidence anchors:
  - [abstract] "we illustrate that DG algorithms exhibit implicit label-noise robustness during finite-sample training even when spurious correlation is present."
  - [section] "IRM aims to learn representations that are local optima for all environments... each of such costly memorization is non-invariant across domains and induces extra penalties."
  - [corpus] Weak - no direct corpus citations about IRM/V-REx noise robustness.

### Mechanism 3
- Claim: The gap between theory and practice exists because real-world conditions don't satisfy the theoretical failure conditions for ERM.
- Mechanism: Real-world datasets often have: (1) pretraining on large datasets providing better representations, (2) spurious correlations that are harder to learn than invariant features (making the norm condition unfavorable for spurious solutions), (3) insufficient distributional differences between environments for invariance learning algorithms to work effectively.
- Evidence anchors:
  - [abstract] "comprehensive experiments on real-world benchmark datasets indicate that label-noise robustness does not necessarily translate to better performance compared to ERM."
  - [section] "we discuss the difficulties of satisfying the theoretical conditions and other potential mitigators in practice."
  - [corpus] Weak - no direct corpus citations about theory-practice gaps in DG.

## Foundational Learning

- Concept: Spurious correlations and subpopulation shifts
  - Why needed here: The paper's core analysis depends on understanding how models can learn features that correlate with labels in training but don't generalize to test data. This is fundamental to why ERM fails and DG algorithms might help.
  - Quick check question: In the waterbirds dataset, what spurious correlation exists between the label and a feature that doesn't generalize?

- Concept: Overparameterization and minimum-norm inductive bias
  - Why needed here: The analysis assumes overparameterized models and shows that gradient descent converges to minimum-norm solutions. This is crucial for understanding why spurious classifiers can be preferred over invariant ones.
  - Quick check question: What is the minimum-norm inductive bias, and why does it cause ERM to prefer spurious solutions when label noise is present?

- Concept: Domain generalization vs. empirical risk minimization
  - Why needed here: The paper compares DG algorithms (IRM, V-REx, GroupDRO) against standard ERM to understand when and why DG methods might outperform. Understanding the differences in their objectives is essential.
  - Quick check question: How does the objective of IRM differ from standard ERM, and how does this difference provide label-noise robustness?

## Architecture Onboarding

- Component map: Synthetic data generation with controlled spurious correlations and label noise -> ERM and DG algorithm implementations -> Evaluation metrics including worst-group accuracy and noise memorization -> Theoretical analysis framework
- Critical path: 1. Generate synthetic data with specified spurious correlation γ and label noise η, 2. Train ERM and DG algorithms, 3. Compare test performance on minority groups and noise memorization, 4. Verify theoretical conditions are satisfied or not in practice
- Design tradeoffs: Using synthetic data allows precise control over spurious correlation and noise levels but may not capture real-world complexity. Real-world datasets are more realistic but have less control over the factors being studied. The theoretical analysis provides guarantees but relies on assumptions that may not hold in practice.
- Failure signatures: ERM performs significantly worse on minority groups as label noise increases, while DG algorithms maintain performance. ERM shows high noise memorization (accuracy on noisy training samples) compared to DG algorithms. Theoretical conditions for ERM failure are satisfied in synthetic experiments but not in real-world datasets.
- First 3 experiments:
  1. Run synthetic CMNIST experiments with varying γ and η to verify Theorem 4.2 conditions and observe ERM failure mode.
  2. Apply 10% and 25% label noise to real-world datasets (Waterbirds, CelebA) and compare ERM vs DG algorithms.
  3. Track noise memorization during training for different algorithms to quantify their robustness to label noise.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the lack of availability of invariant and spurious features in real-world settings impact the effectiveness of DG algorithms compared to ERM?
- Basis in paper: [explicit] The paper discusses the limitations of the theoretical analysis due to the assumption of available invariant and spurious features, and how this assumption may not hold in practice.
- Why unresolved: The paper acknowledges the potential limitations but does not provide a definitive answer on how the unavailability of ideal features affects the performance gap between DG algorithms and ERM.
- What evidence would resolve it: Empirical studies comparing the performance of DG algorithms and ERM on real-world datasets with varying levels of feature availability, specifically focusing on the impact of unavailable invariant and spurious features.

### Open Question 2
- Question: What is the role of data augmentation in mitigating the effects of label noise and spurious correlations on ERM's performance?
- Basis in paper: [inferred] The paper mentions that data augmentation is effective for OOD generalization under label noise, as seen in the experiments with Mixup outperforming other algorithms on domain-shift datasets.
- Why unresolved: While the paper demonstrates the effectiveness of data augmentation, it does not provide a comprehensive analysis of its role in mitigating the effects of label noise and spurious correlations specifically on ERM's performance.
- What evidence would resolve it: Detailed experiments comparing the performance of ERM with and without data augmentation on datasets with varying levels of label noise and spurious correlations, along with an analysis of the mechanisms by which data augmentation mitigates these effects.

### Open Question 3
- Question: How does the complexity of learning invariant features compared to spurious features impact the performance of ERM and DG algorithms in real-world scenarios?
- Basis in paper: [inferred] The paper suggests that the complexity of learning invariant features compared to spurious features may be a factor in the observed performance differences between ERM and DG algorithms, as seen in the discussion of the Waterbirds and CelebA datasets.
- Why unresolved: The paper does not provide a definitive answer on how the relative complexity of learning invariant and spurious features impacts the performance of ERM and DG algorithms in real-world scenarios.
- What evidence would resolve it: Empirical studies comparing the performance of ERM and DG algorithms on datasets with varying levels of feature complexity, along with an analysis of the relationship between feature complexity and algorithm performance.

## Limitations

- The theoretical framework relies on assumptions about data structure and algorithm behavior that may not hold in practice, particularly regarding the availability of invariant and spurious features.
- The significant gap between synthetic and real-world experimental results suggests that theoretical conditions are rarely satisfied in practice or that important practical factors are missing from the analysis.
- The analysis focuses on linear models or last-layer logistic regression, which may not capture the behavior of deep networks used in real-world applications.

## Confidence

- High confidence in theoretical analysis of ERM's failure mode under label noise, as mathematical conditions and proofs are rigorous with synthetic experiment validation
- Medium confidence in implicit noise robustness mechanisms of IRM and V-REx, as theoretical arguments are sound but empirical evidence is limited
- Low confidence in practical implications and real-world applicability due to significant gap between synthetic and real-world experimental results

## Next Checks

1. **Empirical validation of theoretical conditions**: Systematically test the norm conditions (Equation 5) across different datasets and noise levels to verify when spurious classifiers actually have smaller norms than invariant classifiers in practice.

2. **Investigation of pretraining effects**: Compare the behavior of randomly initialized models versus pretrained models to quantify how pretraining influences the relative difficulty of learning spurious versus invariant features, potentially explaining the theory-practice gap.

3. **Extension to deeper architectures**: Test whether the theoretical predictions hold for deeper neural networks with non-linear representations, and investigate how the depth and architecture affect the minimum-norm bias and spurious correlation learning dynamics.