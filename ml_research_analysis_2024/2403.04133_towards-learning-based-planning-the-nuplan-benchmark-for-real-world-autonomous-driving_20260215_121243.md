---
ver: rpa2
title: Towards learning-based planning:The nuPlan benchmark for real-world autonomous
  driving
arxiv_id: '2403.04133'
source_url: https://arxiv.org/abs/2403.04133
tags:
- traffic
- driving
- planning
- nuplan
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces nuPlan, the first large-scale real-world autonomous
  driving dataset and benchmark designed to evaluate machine learning-based planning.
  nuPlan includes 1282 hours of diverse driving data from four cities and features
  high-quality auto-labeled object tracks, traffic light data, and a taxonomy of 73
  driving scenarios.
---

# Towards learning-based planning:The nuPlan benchmark for real-world autonomous driving

## Quick Facts
- arXiv ID: 2403.04133
- Source URL: https://arxiv.org/abs/2403.04133
- Reference count: 40
- Key outcome: nuPlan is the first large-scale real-world autonomous driving dataset and benchmark designed to evaluate machine learning-based planning.

## Executive Summary
The nuPlan benchmark introduces a comprehensive framework for evaluating machine learning-based planning in autonomous driving. It includes 1282 hours of diverse driving data from four cities, high-quality auto-labeled object tracks, traffic light data, and a taxonomy of 73 driving scenarios. The benchmark features both open-loop and closed-loop evaluation modes, accounting for interactions with other traffic participants. Through extensive evaluation of rule-based, raster-based, and learning-based planners, the study reveals that while ML planners excel in open-loop settings, they struggle in closed-loop due to distribution shift. Hybrid approaches combining rule-based and ML components show the most promise for real-world deployment.

## Method Summary
The nuPlan benchmark provides a simulation and evaluation framework for autonomous driving planning, featuring both open-loop and closed-loop testing modes. The dataset includes 1282 hours of driving data from four cities with high-quality auto-labeled object tracks and traffic light data. The evaluation pipeline supports three types of planners: Simple (straight-line at constant speed), IDM (rule-based ACC policy), and ML-based (raster and vector input variants). The closed-loop evaluation uses either reactive or non-reactive agents and includes perturbation analysis to simulate imperfect perception. Performance is measured through scenario-specific metrics that assess lawfulness, progress, comfort, collision avoidance, and drivable area compliance.

## Key Results
- ML planners excel in open-loop settings but struggle in closed-loop due to distribution shift
- Rule-based planners perform better in closed-loop scenarios than pure ML approaches
- Hybrid approaches combining rule-based and ML components show the most promise, with CS Tu and AutoHorizon topping the nuPlan challenge leaderboard

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ML planners perform well in open-loop but struggle in closed-loop due to distribution shift.
- Mechanism: Open-loop evaluation uses ground-truth trajectories, so the planner only needs to match observed behavior. In closed-loop, the planner's actions affect the future states, potentially moving into regions of the state space not seen during training, causing compounding errors.
- Core assumption: The training data represents a narrow slice of the possible interaction space, and closed-loop scenarios generate novel configurations.
- Evidence anchors:
  - [abstract]: "while ML planners excel in open-loop settings, they struggle in closed-loop due to distribution shift"
  - [section]: "A closed-loop scenario can develop into a new situation that was never present in the training dataset"
  - [corpus]: Weak evidence. No corpus papers directly test this mechanism, though the overall trend in nuPlan-R and PLUTO suggests distribution shift is a known issue.
- Break condition: If the planner is trained with extensive closed-loop rollouts or adversarial scenarios that cover rare interactions, the distribution shift may be reduced.

### Mechanism 2
- Claim: Rule-based planners outperform pure ML planners in closed-loop because they rely on fixed, interpretable policies.
- Mechanism: Rule-based planners use deterministic policies (e.g., IDM) that do not depend on learned distributions. They can handle unseen scenarios gracefully as long as the rules cover basic safety and comfort constraints.
- Core assumption: The environment model used by the planner (e.g., IDM for agents) matches the simulation environment, giving them an advantage.
- Evidence anchors:
  - [abstract]: "Rule-based planners perform better in closed-loop scenarios, but hybrid approaches combining rule-based and ML components show the most promise."
  - [section]: "Rule-based planners, on the other hand, face no such issues. Policies like IDM can produce decent driving behavior."
  - [corpus]: Weak evidence. No corpus papers directly compare rule-based vs ML in nuPlan, but CS Tu (leaderboard) is rule-based + ML refinement.
- Break condition: If the rule-based assumptions about agent behavior are violated (e.g., non-cooperative agents), the planner may fail.

### Mechanism 3
- Claim: Hybrid planners combining rule-based and ML components achieve the best performance because they leverage strengths of both.
- Mechanism: ML components can capture nuanced, data-driven behaviors (e.g., human-like comfort), while rule-based components enforce safety and legality. The hybrid design allows ML to propose candidate trajectories that are then filtered or refined by rules.
- Core assumption: There exists a decomposition of the planning problem where ML can handle high-level decisions and rules can handle low-level constraints.
- Evidence anchors:
  - [abstract]: "hybrid approaches combining rule-based and ML components show the most promise"
  - [section]: "hybrid methods with learned-based components show the most promise in handling difficult scenarios"
  - [corpus]: Strong evidence. CS Tu and AutoHorizon both use hybrid designs and top the nuPlan challenge leaderboard.
- Break condition: If the decomposition is poor (e.g., ML proposes unsafe trajectories that rules cannot correct), the hybrid approach may not help.

## Foundational Learning

- Concept: Distribution shift in sequential decision-making
  - Why needed here: Closed-loop evaluation creates new states not seen during training, causing planner errors.
  - Quick check question: If a planner is trained only on straight driving, what happens when it encounters a sudden lane change in closed-loop?

- Concept: Imitation learning vs. reinforcement learning tradeoffs
  - Why needed here: The baselines include IL-based planners; understanding their limitations is key to interpreting results.
  - Quick check question: Why might an IL planner fail to generalize to a scenario with a new traffic light pattern?

- Concept: Closed-loop vs. open-loop evaluation
  - Why needed here: The paper's main contribution is a closed-loop benchmark; understanding the difference is critical.
  - Quick check question: In open-loop, the planner's actions don't affect the environmentâ€”true or false?

## Architecture Onboarding

- Component map: nuPlan dataset -> offline perception -> auto-labeled tracks + traffic light statuses + scenario tags -> Simulation (Agents -> Controller) -> Evaluation metrics -> Baselines (Simple -> IDM -> Raster ML -> UrbanDriver ML)

- Critical path: 1. Load scenario from dataset (sensor data or tracks) 2. Initialize agents (reactive or log-replay) 3. Run planner to get trajectory 4. Controller tracks trajectory 5. Evaluate against metrics 6. Repeat for all scenarios

- Design tradeoffs:
  - Reactive vs. non-reactive agents: Reactive allows longer, more realistic simulations but may favor IDM-like planners.
  - Open vs. closed-loop: Open-loop is simpler but doesn't test interaction; closed-loop is harder but more realistic.
  - Raster vs. vector input: Raster is simpler to implement but less efficient; vector is more flexible but requires more preprocessing.

- Failure signatures:
  - High miss rate in open-loop: Planner fails to match human trajectory.
  - At-fault collisions in closed-loop: Planner makes unsafe decisions.
  - Drivable area violations: Planner generates physically impossible trajectories.
  - Low progress along route: Planner is too conservative.

- First 3 experiments:
  1. Run IDM planner on a simple straight-lane scenario in open-loop and closed-loop to verify basic functionality.
  2. Compare raster ML planner vs. UrbanDriver in open-loop to see impact of model complexity.
  3. Evaluate hybrid planner (e.g., ML trajectory + rule-based refinement) on a left-turn scenario to test safety filtering.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we overcome the domain shift between open-loop and closed-loop simulation settings?
- Basis in paper: [explicit] The paper highlights that ML planners struggle in closed-loop scenarios due to distribution shift, where new situations not present in the training data can arise.
- Why unresolved: The paper acknowledges this as a major challenge but does not propose a definitive solution to bridge the gap between open-loop and closed-loop performance.
- What evidence would resolve it: Experimental results demonstrating a planner that performs comparably in both open-loop and closed-loop settings, or a novel training technique that effectively addresses distribution shift.

### Open Question 2
- Question: What is the impact of using high-quality offline perception data on the performance of ML planners in closed-loop simulation?
- Basis in paper: [explicit] The paper mentions that nuPlan's offline perception system generates high-quality object tracks, which is crucial for evaluating planning performance under limited perception noise. It also shows that a planner trained on perturbed data (simulating lower quality perception) performs worse than one trained on the original data.
- Why unresolved: While the paper demonstrates the importance of high-quality perception data, it does not quantify the exact impact on planner performance or explore the trade-offs between data quality and other factors like model complexity.
- What evidence would resolve it: A comprehensive study comparing planner performance across different levels of perception noise, or an analysis of how data quality interacts with other factors like model architecture or training techniques.

### Open Question 3
- Question: How can we design scenario-based metrics that better distinguish between conservative driving and desirable human-like behaviors?
- Basis in paper: [explicit] The paper notes that current metrics tend to reward conservative driving, making it difficult to differentiate between simple rule-abiding driving and more nuanced human-like behaviors.
- Why unresolved: The paper acknowledges the need for better metrics but does not propose specific alternatives or evaluate their effectiveness.
- What evidence would resolve it: A set of new metrics that are specifically designed to capture human-like driving behaviors, along with experimental results demonstrating their ability to differentiate between conservative and desirable driving styles.

## Limitations
- The closed-loop evaluation may favor IDM-like planners due to shared assumptions with reactive agents
- The exact implementation details of the UrbanDriver ML Planner are not fully specified
- The weighting scheme for the hybrid scoring function is not fully detailed

## Confidence
- Distribution shift effect: Medium - supported by empirical evidence but may be influenced by reactive agent assumptions
- Hybrid planner performance: High - strongly supported by nuPlan challenge leaderboard results
- Rule-based vs ML comparison: Medium - results may be biased by shared assumptions between IDM and reactive agents

## Next Checks
1. Test ML planners with non-IDM reactive agents to isolate distribution shift effects
2. Implement alternative hybrid designs (e.g., ML proposal + rule-based refinement) to verify the mechanism
3. Analyze specific scenarios where pure ML planners fail to identify failure modes