---
ver: rpa2
title: 'Still "Talking About Large Language Models": Some Clarifications'
arxiv_id: '2412.10291'
source_url: https://arxiv.org/abs/2412.10291
tags:
- language
- shanahan
- word
- belief
- such
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper clarifies the philosophical intent of Shanahan's earlier
  work "Talking About Large Language Models" and addresses misunderstandings about
  its stance on LLM capabilities. The paper emphasizes that its goal is not to advocate
  reductionism but to explore appropriate language use when discussing LLMs, drawing
  inspiration from Wittgenstein's later philosophy.
---

# Still "Talking About Large Language Models": Some Clarifications

## Quick Facts
- arXiv ID: 2412.10291
- Source URL: https://arxiv.org/abs/2412.10291
- Authors: Murray Shanahan
- Reference count: 4
- Key outcome: Clarifies philosophical intent of earlier work on LLM discourse, emphasizing cautious use of anthropomorphic language while recognizing capability-based appropriateness

## Executive Summary
This paper serves as a philosophical clarification of Murray Shanahan's earlier work "Talking About Large Language Models," addressing misunderstandings about its stance on LLM capabilities. The author emphasizes that the work's goal is not to advocate reductionism but to explore appropriate language use when discussing LLMs, drawing inspiration from Wittgenstein's later philosophy. The paper argues that while anthropomorphic language can be useful for describing LLM behavior, it should be applied cautiously, recognizing the fundamental differences between LLMs and human cognition.

## Method Summary
The paper presents a conceptual framework for understanding LLM-based systems through a hierarchy ranging from bare-bones models to embodied systems. This framework is used to argue that as capabilities increase, it becomes more appropriate to use terms like "belief" without caveats. The approach is philosophical rather than empirical, focusing on conceptual analysis and logical argumentation rather than experimental validation.

## Key Results
- Clarifies that the original work's goal was exploring appropriate language use for LLMs, not advocating reductionism
- Proposes a hierarchy of LLM-based systems from bare-bones models to embodied systems
- Argues that anthropomorphic language becomes more appropriate as capabilities increase
- Emphasizes the fundamental differences between LLMs and human cognition despite surface similarities

## Why This Works (Mechanism)
The paper's argument works by providing a structured framework for thinking about language use in AI discourse. By drawing on Wittgenstein's later philosophy, it offers a philosophical foundation for understanding when and how anthropomorphic language can be appropriately applied to AI systems. The hierarchical approach helps categorize different types of AI systems and their corresponding language appropriateness.

## Foundational Learning
- Wittgenstein's later philosophy on language use: Needed to understand the philosophical grounding of the argument; quick check: familiarity with Wittgenstein's concept of language games
- Hierarchy of AI system capabilities: Essential for understanding when anthropomorphic language becomes appropriate; quick check: ability to classify AI systems along the proposed capability spectrum
- Distinction between mechanistic and intentional language: Critical for grasping the core argument; quick check: understanding of when each type of language is most appropriate

## Architecture Onboarding
- Component map: Bare-bones models -> augmented systems -> embodied systems -> human-like systems
- Critical path: Philosophical clarification → Capability hierarchy → Language appropriateness → Practical guidelines
- Design tradeoffs: Philosophical rigor vs. practical applicability; theoretical framework vs. empirical validation
- Failure signatures: Misinterpretation as reductionism; oversimplification of capability distinctions; inappropriate use of anthropomorphic language
- First experiments: 1) Test how different framings affect user understanding of AI capabilities; 2) Develop measurable benchmarks for capability hierarchy thresholds; 3) Compare communication effectiveness using different language styles

## Open Questions the Paper Calls Out
None

## Limitations
- Philosophical interpretation depends heavily on subjective judgments about appropriate language use
- Hierarchy of LLM-based systems remains largely theoretical without empirical validation
- Connection to Wittgenstein's philosophy may not translate into concrete guidelines for AI practitioners

## Confidence
- High confidence: Clarification of philosophical stance and distinction from reductionist positions
- Medium confidence: Proposed hierarchy of LLM-based systems and its implications for language use
- Medium confidence: Connection to Wittgenstein's philosophy and its application to AI discourse

## Next Checks
1. Conduct empirical studies measuring how different framings of LLM capabilities affect user understanding and decision-making
2. Develop concrete criteria for assessing when an AI system has crossed thresholds in the proposed capability hierarchy
3. Design controlled experiments comparing communication effectiveness between teams using anthropomorphic versus mechanistic language for AI systems