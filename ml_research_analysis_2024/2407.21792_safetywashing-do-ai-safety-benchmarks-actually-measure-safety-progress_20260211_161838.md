---
ver: rpa2
title: 'Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?'
arxiv_id: '2407.21792'
source_url: https://arxiv.org/abs/2407.21792
tags:
- capabilities
- safety
- arxiv
- benchmarks
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether AI safety benchmarks genuinely
  measure safety progress or simply track general capabilities and training compute.
  Using a meta-analysis of dozens of models across various safety benchmarks, the
  authors empirically measure correlations between safety metrics and upstream model
  capabilities.
---

# Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?

## Quick Facts
- arXiv ID: 2407.21792
- Source URL: https://arxiv.org/abs/2407.21792
- Reference count: 40
- Primary result: Many AI safety benchmarks correlate strongly with general capabilities and training compute, potentially enabling "safetywashing" where capability improvements are misrepresented as safety advancements

## Executive Summary
This paper investigates whether AI safety benchmarks genuinely measure safety progress or simply track general capabilities and training compute. The authors conduct a comprehensive meta-analysis of dozens of models across various safety benchmarks, empirically measuring correlations between safety metrics and upstream model capabilities. They find that many safety benchmarks—including alignment with human preferences, misconception avoidance, scalable oversight, and static adversarial robustness—show high correlations with capabilities and compute, enabling "safetywashing" where capability improvements are misrepresented as safety advancements. Conversely, benchmarks like bias, dynamic adversarial robustness, and some calibration metrics demonstrate lower correlations. The study concludes that safety benchmarks often fail to isolate distinct safety properties and recommends that future benchmarks report their capabilities correlations to prevent misleading claims about AI safety progress.

## Method Summary
The authors conducted a meta-analysis examining correlations between safety benchmark performance and both upstream model capabilities and training compute across dozens of models. They measured empirical correlations between safety metrics and capability metrics to identify patterns of safetywashing. The analysis focused on multiple safety domains including human preference alignment, misconception avoidance, scalable oversight, adversarial robustness, and calibration. The study examined both static and dynamic adversarial robustness benchmarks, as well as bias measurements, to understand which safety properties might be genuinely independent of general capabilities.

## Key Results
- Many safety benchmarks (alignment with human preferences, misconception avoidance, scalable oversight, static adversarial robustness) show high correlations with capabilities and compute
- Benchmarks measuring bias, dynamic adversarial robustness, and some calibration metrics show lower correlations with capabilities
- The strong correlations between safety metrics and capabilities enable "safetywashing" practices where capability improvements are misrepresented as safety advancements

## Why This Works (Mechanism)
The paper demonstrates that when safety benchmarks correlate strongly with general capabilities and compute, improvements in benchmark scores may reflect general model advancement rather than specific safety progress. This mechanism occurs because models with higher capabilities naturally perform better on certain safety tasks, making it difficult to distinguish between genuine safety improvements and capability scaling effects. The correlation analysis reveals that many safety benchmarks are inadvertently measuring the same underlying phenomenon as capability benchmarks, rather than capturing distinct safety properties.

## Foundational Learning

**Capability Correlation Analysis**: Understanding how to measure and interpret correlations between safety metrics and capabilities is essential for evaluating benchmark validity. Quick check: Calculate Pearson correlation coefficients between safety benchmark scores and established capability metrics across multiple model generations.

**Compute-Scaling Relationships**: Recognizing how training compute relates to both capability and safety performance helps identify potential confounding factors. Quick check: Plot benchmark performance against training compute across models to visualize scaling relationships.

**Safetywashing Identification**: The ability to distinguish between genuine safety improvements and capability-driven score increases is crucial for accurate safety assessment. Quick check: Compare performance gaps between capability-matched models on safety versus capability benchmarks to identify potential safetywashing.

## Architecture Onboarding

**Component Map**: Models -> Safety Benchmarks -> Performance Metrics -> Capability/Compute Correlations -> Safetywashing Analysis

**Critical Path**: The analysis flows from model evaluation data through correlation calculations to safetywashing conclusions, with the correlation measurements serving as the key intermediate step.

**Design Tradeoffs**: The study balances comprehensive coverage of safety domains against the practical limitations of available benchmark data and model evaluations. Including more benchmarks increases coverage but may introduce additional correlation noise.

**Failure Signatures**: High correlation coefficients (>0.8) between safety and capability metrics indicate potential safetywashing. Low variance in safety performance improvements across capability levels suggests the benchmark may not be measuring distinct safety properties.

**3 First Experiments**:
1. Calculate correlation matrices between all safety benchmarks to identify redundant measurements
2. Perform principal component analysis on safety benchmark scores to identify underlying factors
3. Test benchmark sensitivity by comparing performance on safety tasks versus capability-matched control tasks

## Open Questions the Paper Calls Out
The paper acknowledges that correlation does not imply causation, and that some safety properties might genuinely improve alongside capabilities. However, the degree to which this occurs across different safety domains remains uncertain. The analysis also doesn't account for potential future safety challenges that may emerge at higher capability levels.

## Limitations
- The empirical correlation analysis relies on existing public benchmarks and model evaluations, which may not capture all relevant safety dimensions
- The compute-based and capability-based correlation metrics cannot fully disentangle whether safety improvements are genuine or merely artifacts of general capability scaling
- The study's conclusions are based on current benchmark designs, which may evolve rapidly as the field advances

## Confidence
- **High confidence**: The empirical finding that many safety benchmarks correlate strongly with capabilities and compute
- **Medium confidence**: The conclusion that this correlation enables "safetywashing" practices
- **Medium confidence**: The recommendation to report capabilities correlations in future benchmarks

## Next Checks
1. Replicate the correlation analysis with newer models and benchmarks released after this study
2. Conduct ablation studies to determine which specific benchmark components drive capability correlations
3. Develop and test new benchmark designs specifically engineered to minimize capability correlations while maintaining safety measurement validity