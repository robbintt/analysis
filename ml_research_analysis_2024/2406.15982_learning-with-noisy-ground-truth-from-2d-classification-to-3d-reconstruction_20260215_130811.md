---
ver: rpa2
title: 'Learning with Noisy Ground Truth: From 2D Classification to 3D Reconstruction'
arxiv_id: '2406.15982'
source_url: https://arxiv.org/abs/2406.15982
tags: []
core_contribution: This paper presents a survey on learning with noisy ground truth
  (LNGT) in machine learning tasks, particularly focusing on 2D classification and
  3D reconstruction. It introduces a formal definition of LNGT, unifying the analysis
  of existing works in the context of different machine learning tasks.
---

# Learning with Noisy Ground Truth: From 2D Classification to 3D Reconstruction

## Quick Facts
- arXiv ID: 2406.15982
- Source URL: https://arxiv.org/abs/2406.15982
- Reference count: 40
- Primary result: Introduces formal definition of Learning with Noisy Ground Truth (LNGT) and unifies analysis across 2D classification and 3D reconstruction tasks

## Executive Summary
This paper presents a comprehensive survey of Learning with Noisy Ground Truth (LNGT) in machine learning, focusing on 2D classification and 3D reconstruction tasks. The authors introduce a formal definition of LNGT that unifies the analysis of existing works across different machine learning domains. They propose a novel taxonomy based on error decomposition to classify existing methods and analyze the memorization effect observed in neural networks trained on noisy data. The survey identifies the core issue of LNGT as the unreliable empirical risk minimizer that overfits to mislabeled samples, and suggests solutions from three perspectives: data, model, and algorithms.

## Method Summary
The authors develop a systematic framework for understanding LNGT by introducing a formal definition that encompasses various forms of label noise and data imperfection. They create a taxonomy of existing methods based on how different approaches decompose the total error into components related to data quality, model capacity, and algorithmic strategies. The survey analyzes the memorization effect where neural networks initially fit clean samples before overfitting to mislabeled ones, using loss distribution analysis over training epochs. The paper draws connections between 2D classification and 3D reconstruction tasks, demonstrating how techniques developed for one domain can be applied to the other.

## Key Results
- Proposes a unified definition of Learning with Noisy Ground Truth (LNGT) that encompasses various forms of label noise and data imperfection
- Introduces a taxonomy of LNGT methods based on error decomposition into data, model, and algorithmic components
- Demonstrates the memorization effect in neural networks, where clean samples are learned first before overfitting to mislabeled samples
- Shows applicability of LNGT techniques across 2D classification and 3D reconstruction domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: In noisy ground truth scenarios, models tend to initially fit clean samples before overfitting to mislabeled samples, which is referred to as the "memorization effect."
- Mechanism: The model learns to distinguish between clean and mislabeled samples based on their loss distributions. During early training, clean samples have lower loss values, while mislabeled samples have higher loss values. This separation allows the model to prioritize learning from clean samples.
- Core assumption: The loss distribution of clean samples is significantly different from that of mislabeled samples, and this difference is observable early in training.
- Evidence anchors:
  - [abstract]: "In classification task, when DNNs model is trained with a noisy training set consisting of clean and mislabeled samples, it has been widely observed that the model outputs tend to severe fluctuate [27] then the model memorizes the noise."
  - [section]: "We analyze the normalized loss distribution over different training epochs in Fig. 2 top row. Intriguingly, the two distributions are merged at the initialization, then start to separate, but resume merging after the certain point."
  - [corpus]: No direct evidence, but related to noise-robust learning techniques.
- Break condition: If the noise rate is too high or the data is too complex, the loss distributions may not separate clearly, making it difficult for the model to distinguish between clean and mislabeled samples.

### Mechanism 2
- Claim: The core issue in learning with noisy ground truth is the unreliable empirical risk minimizer, which overfits to mislabeled samples.
- Mechanism: The empirical risk minimizer finds the hypothesis that minimizes the average loss over the noisy training set, including mislabeled samples. This leads to overfitting and poor generalization performance.
- Core assumption: The noisy training set contains a significant number of mislabeled samples that negatively impact the learning process.
- Evidence anchors:
  - [abstract]: "In this survey, We show that it is similar to the learning with noisy labels in 2D classification and propose a simple idea to solve it."
  - [section]: "In LNGT, the model would easily fit all noisy samples. The empirical risk ð‘…ð‘ (â„Ž) may then be far from being a good approximation of the expected risk ð‘…(â„Ž), and the resultant empirical risk minimizer â„ŽN overfits. Indeed, this is the core issue of LNGT, i.e., the empirical risk minimizer â„ŽN is no longer reliable."
  - [corpus]: No direct evidence, but related to noise-robust learning techniques.
- Break condition: If the noise rate is low or the data is simple, the empirical risk minimizer may still provide reasonable results despite the presence of some mislabeled samples.

### Mechanism 3
- Claim: Dynamic weighting schemes can help mitigate the impact of mislabeled samples by assigning lower weights to samples with higher loss values.
- Mechanism: The model assigns weights to samples based on their loss values or predictions. Samples with higher loss values or incorrect predictions are assigned lower weights, reducing their impact on the learning process.
- Core assumption: The model can accurately estimate the reliability of each sample based on its loss value or prediction.
- Evidence anchors:
  - [abstract]: "Another work M-correction [3] makes ð›½ dynamic for different samples, i.e., using a noise model to individually weight each sample."
  - [section]: "ð‘¤ð‘– is dynamically set to posterior probability conditioned on loss value and the Gaussian Mixture Model (GMM) is estimated after each training epoch using the normalized cross entropy loss for each sample ð‘–."
  - [corpus]: No direct evidence, but related to noise-robust learning techniques.
- Break condition: If the model cannot accurately estimate the reliability of each sample, the dynamic weighting scheme may not effectively mitigate the impact of mislabeled samples.

## Foundational Learning

- Concept: Empirical Risk Minimization
  - Why needed here: LNGT is built upon the concept of empirical risk minimization, where the model tries to minimize the average loss over the training set. Understanding this concept is crucial for grasping the challenges and solutions in LNGT.
  - Quick check question: What is the difference between expected risk and empirical risk, and why is empirical risk used as a proxy for expected risk in practice?

- Concept: Overfitting
  - Why needed here: Overfitting is a common problem in machine learning, where the model performs well on the training data but poorly on unseen data. In LNGT, overfitting to mislabeled samples is a key challenge that needs to be addressed.
  - Quick check question: How does overfitting to mislabeled samples differ from regular overfitting, and what are the potential consequences of this type of overfitting?

- Concept: Loss Functions
  - Why needed here: Different loss functions have varying properties when dealing with noisy labels. Understanding the characteristics of different loss functions is important for selecting appropriate ones in LNGT.
  - Quick check question: What are some examples of loss functions that are robust to noisy labels, and how do they differ from standard loss functions like cross-entropy?

## Architecture Onboarding

- Component map: Data -> Model (Neural Network) -> Loss Function -> Dynamic Weighting Scheme -> Updated Model
- Critical path: Training loop: (1) Forward pass with current model, (2) Compute loss with noisy labels, (3) Apply dynamic weighting to samples, (4) Backward pass and update weights, (5) Update weighting scheme based on new loss distributions
- Design tradeoffs: One tradeoff in LNGT is between fitting the clean samples well and avoiding overfitting to mislabeled samples. Another tradeoff is between using simple dynamic weighting schemes and more complex ones that may provide better performance but are harder to implement and tune.
- Failure signatures: Failure in LNGT can manifest as poor generalization performance on clean test data, high variance in predictions, or the model converging to a suboptimal solution that overfits to mislabeled samples.
- First 3 experiments:
  1. Train a model on a noisy dataset using a standard loss function (e.g., cross-entropy) and observe the overfitting behavior.
  2. Implement a simple dynamic weighting scheme (e.g., based on loss values) and evaluate its impact on the model's performance.
  3. Compare the performance of different loss functions (e.g., cross-entropy, MAE, NCE) on a noisy dataset to identify the most suitable one for LNGT.

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis is primarily theoretical and relies heavily on observations from classification tasks, with limited direct experimental validation across multiple 3D tasks
- Effectiveness of dynamic weighting schemes may vary significantly depending on specific characteristics of noise distribution and task complexity
- Survey does not extensively cover recent advances in self-supervised and semi-supervised learning approaches that could complement LNGT methods

## Confidence
- Definition and taxonomy of LNGT methods: High - Well-supported by existing literature and theoretical foundations
- Memorization effect analysis: Medium - Based on established observations but requires more rigorous empirical validation
- Applicability to 3D reconstruction: Medium - Conceptually sound but needs more direct experimental evidence
- Dynamic weighting effectiveness: Medium - Theoretical justification exists but real-world performance may vary

## Next Checks
1. Conduct systematic experiments across multiple 3D reconstruction tasks with varying noise rates to validate the applicability of LNGT techniques beyond classification
2. Compare the performance of different dynamic weighting schemes under controlled noise conditions to identify optimal strategies
3. Test the robustness of proposed methods when noise rates exceed 40% to establish practical limits of LNGT approaches