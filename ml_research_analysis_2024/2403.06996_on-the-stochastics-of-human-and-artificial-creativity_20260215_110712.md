---
ver: rpa2
title: On the stochastics of human and artificial creativity
arxiv_id: '2403.06996'
source_url: https://arxiv.org/abs/2403.06996
tags:
- creativity
- creative
- human
- process
- biases
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper develops a statistical representation of human creativity,
  integrating insights from stochastic theory, psychology, philosophy, neuroscience,
  and chaos theory. It conceptualizes human creativity as a two-step stochastic process:
  a bias-guided random proposal step and an evaluation step dependent on a flexible
  bias structure.'
---

# On the stochastics of human and artificial creativity

## Quick Facts
- arXiv ID: 2403.06996
- Source URL: https://arxiv.org/abs/2403.06996
- Reference count: 0
- Current AI systems lack autonomous creativity at human level due to inability to dynamically transform bias structures

## Executive Summary
This paper develops a statistical representation of human creativity by integrating insights from stochastic theory, psychology, philosophy, neuroscience, and chaos theory. It conceptualizes creativity as a two-step stochastic process: a bias-guided random proposal step followed by an evaluation step dependent on a flexible bias structure. The framework is then used to assess whether current AI systems (LLMs, diffusion models, reinforcement learning) can achieve human-level autonomous creativity. The analysis concludes these systems currently lack the capability to dynamically transform their bias structures, limiting them to generating proposals within fixed learned manifolds without true autonomous evaluation of novel ideas' usefulness.

## Method Summary
The paper develops a human creativity model based on stochastic processes and biases, incorporating insights from multiple disciplines. It then analyzes modern AI systems using this model, focusing on their ability to generate and evaluate novel ideas. The assessment compares AI architectures to the human model, examining whether they can autonomously generate and evaluate novel, useful ideas without human intervention. The evaluation is theoretical rather than empirical, based on architectural analysis of existing AI systems.

## Key Results
- Human creativity is modeled as a two-step stochastic process: bias-guided random proposal and flexible bias-dependent evaluation
- Current AI systems (LLMs, diffusion models, reinforcement learning) cannot autonomously evaluate the usefulness of novel ideas
- AI lacks dynamic bias transformation capability, limiting creativity to proposals within fixed learned manifolds

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Human creativity operates as a two-stage stochastic process: an open, bias-guided random proposal step followed by an evaluation step dependent on flexible bias structures.
- Mechanism: The process begins with divergent thinking, modeled as a Markov Chain Monte Carlo (MCMC)-like random walk through a cognitive state space. Proposals are generated based on transition probabilities shaped by biases, then evaluated against those same biases for usefulness. Creativity emerges when biases are dynamically restructured—through bending, blending, or breaking—to allow novel yet meaningful ideas.
- Core assumption: The human brain performs unconscious associative processing (like unconscious Markov processes) that can be statistically modeled, and that biases act as both proposal guides and evaluation criteria.
- Evidence anchors: [abstract] states the two-step stochastic process: "bias guided, random proposal step, and an evaluation step depending on a flexible or transformable bias structure." [section 2.2.1] describes MCMC as a statistical analogy for divergent thinking, where a proposal distribution governs randomness and a target distribution (bias) evaluates usefulness.
- Break condition: If biases are fixed and cannot be restructured, the system cannot evaluate usefulness of radical ideas outside its historical observations—this is where current AI fails.

### Mechanism 2
- Claim: Current generative AI lacks autonomous creativity because it cannot transform its bias structure dynamically; it can only propose within a fixed learned manifold.
- Mechanism: Generative models (LLMs, diffusion models) encode training data into a latent space and generate proposals by sampling nearest neighbors or performing diffusion steps. Evaluation of usefulness is external (human feedback or static loss functions), not internal and adaptive. Without the ability to restructure its bias space, the model cannot judge the value of ideas outside its learned distribution.
- Core assumption: AI models operate within a static bias manifold defined during training, and usefulness evaluation is not part of the generation loop.
- Evidence anchors: [section 3.1.1] explains LLMs lack an internal evaluation mechanism: "there is no inbuilt mechanism for accepting or rejecting the proposal with regard to its likelihood of serving a useful purpose." [section 3.1.2] notes diffusion models generate based on "biases of the (human) creators of the input images" but have no internal evaluator for beauty or causal plausibility.
- Break condition: If a model could implement a dynamic bias transformation mechanism (like conformal invariance in human thought), it could autonomously evaluate and accept novel ideas beyond its training distribution.

### Mechanism 3
- Claim: Unconscious parallel processing in the cerebellum enables humans to explore high-dimensional idea spaces rapidly, generating insights through invariant pattern recognition and reshuffling.
- Mechanism: The cerebellum performs parallel, fast, unconscious recombination of memories and thoughts, guided by goal-oriented models. This allows invariant (scale/location/rotation) pattern matching, enabling humans to blend or break cognitive structures creatively. The "eureka" moment occurs when the unconscious finds a good fit between reshuffled experiences and high-level biases (wholeness, beauty).
- Core assumption: The cerebellum supports unconscious creativity through parallel processing, reshuffling, and invariant pattern recognition, and that this process is guided by high-level biases.
- Evidence anchors: [section 2.3] discusses cerebellar role: "the cerebellum unconsciously is generalizing thoughts... using so-called inverse dynamic models." [section 2.4] links unconscious creativity to fractal/invariant processing: "the brain enters an invariant and fractal mode where new order is more easily generated."
- Break condition: If AI systems cannot replicate parallel unconscious processing with invariant pattern recognition, they cannot match human-level insight generation.

## Foundational Learning

- Concept: Stochastic Processes and Markov Chains
  - Why needed here: Understanding how random walks and transition probabilities model divergent thinking and proposal generation.
  - Quick check question: Can you explain how a Markov Chain Monte Carlo algorithm alternates between proposal and evaluation steps?

- Concept: Cognitive Biases and Bayesian Inference
  - Why needed here: Biases act as priors that guide proposal generation and evaluate usefulness; transforming biases is key to creativity.
  - Quick check question: How does Bayesian updating differ from dynamic restructuring of priors in the context of creative insight?

- Concept: Fractal Geometry and Conformal Invariance
  - Why needed here: These concepts explain how invariant pattern recognition allows humans to bend, blend, or break cognitive structures creatively.
  - Quick check question: Why might a state of conformal invariance in the brain facilitate creative restructuring of biases?

## Architecture Onboarding

- Component map:
  - Proposal Generator -> Bias Structure -> Evaluator -> Unconscious Processor -> Conformal Invariance Module

- Critical path:
  1. Generate candidate ideas via stochastic proposal process.
  2. Evaluate candidates against current bias structure.
  3. If no satisfactory candidate, trigger bias transformation (bending/blending/breaking).
  4. Repeat until useful novel idea found.

- Design tradeoffs:
  - Proposal randomness vs. focus: Higher randomness increases novelty but may reduce relevance.
  - Bias rigidity vs. flexibility: Fixed biases ensure stability but prevent radical creativity; flexible biases enable transformation but risk instability.
  - Conscious vs. unconscious processing: Conscious processing allows control but is slower; unconscious processing is faster but less controllable.

- Failure signatures:
  - Stuck in local maxima: Proposals keep cycling within a narrow region of the state space.
  - Overfitting to training data: Generated ideas are mere blends of existing concepts without true novelty.
  - Lack of usefulness evaluation: Novel ideas are generated but consistently rejected as irrelevant or meaningless.

- First 3 experiments:
  1. Implement a simple MCMC-based proposal generator with fixed bias structure; measure novelty and usefulness of generated ideas.
  2. Add dynamic bias transformation (e.g., random restructuring of prior weights) and observe changes in creativity metrics.
  3. Introduce parallel unconscious processor module that performs invariant pattern matching and reshuffling; evaluate impact on insight generation speed and quality.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific mechanisms could enable AI systems to dynamically transform their bias structures in a manner similar to human creativity?
- Basis in paper: [explicit] The paper argues that current AI systems lack the capability to dynamically transform or restructure their bias structures to evaluate the usefulness of radical ideas outside their historical observations.
- Why unresolved: Current AI models, such as large language models and diffusion models, rely on static bias structures learned during training and lack the flexibility to adapt these structures in response to novel stimuli or ideas.
- What evidence would resolve it: Evidence of AI systems that can autonomously restructure their bias frameworks in response to new information or contexts, demonstrating an ability to evaluate the usefulness of ideas beyond their training data.

### Open Question 2
- Question: How can AI systems be designed to assess the usefulness of creative outputs without human intervention?
- Basis in paper: [explicit] The paper highlights that current AI systems, like LLMs and diffusion models, do not have inbuilt mechanisms to evaluate the usefulness of their generated outputs, relying instead on human feedback.
- Why unresolved: Existing AI models generate outputs based on learned correlations but lack the ability to judge their own creations' relevance or utility without external human input.
- What evidence would resolve it: Development of AI systems with autonomous evaluation functions that can assess the relevance and utility of their outputs in various contexts, reducing the need for human feedback.

### Open Question 3
- Question: What role does conformal invariance play in human creativity, and can it be replicated in AI systems?
- Basis in paper: [explicit] The paper suggests that conformal invariance, a state where patterns are self-similar across scales, may facilitate creativity by allowing flexible cognitive control and restructuring of biases.
- Why unresolved: The paper hypothesizes that conformal invariance aids human creativity but does not explore how this concept could be implemented in AI systems to enhance their creative capabilities.
- What evidence would resolve it: Experimental evidence showing that AI systems incorporating conformal invariance-like properties can achieve creative outputs comparable to human creativity, particularly in tasks requiring novel pattern recognition and restructuring.

## Limitations
- The stochastic model of creativity relies heavily on conceptual analogies rather than empirically validated mechanisms
- The analysis of AI systems is based on theoretical architectural analysis rather than empirical testing
- The claim about AI's fundamental inability to achieve human-level creativity is a strong theoretical assertion requiring empirical validation

## Confidence
- High Confidence: The general framework of creativity as a two-step stochastic process (proposal + evaluation) is well-grounded in existing creativity research and statistical theory.
- Medium Confidence: The extension of this framework to include dynamic bias transformation is logically consistent but lacks direct empirical support.
- Low Confidence: The claim that current AI systems fundamentally cannot achieve human-level creativity due to static bias structures is a strong theoretical assertion that requires empirical validation.

## Next Checks
1. Conduct neuroimaging studies to identify neural correlates of bias transformation during creative insight, specifically looking for evidence of unconscious parallel processing and invariant pattern recognition as described in the stochastic creativity model.
2. Implement a prototype AI system with explicit bias transformation capabilities (e.g., meta-learning of prior distributions or conformal invariance modules) and empirically test whether it can generate and evaluate novel ideas beyond its training distribution.
3. Design and validate a benchmark task that specifically tests the ability to generate ideas that are both novel and useful according to dynamically changing criteria, distinguishing between proposal generation and autonomous evaluation capabilities.