---
ver: rpa2
title: Interpretable Company Similarity with Sparse Autoencoders
arxiv_id: '2412.02605'
source_url: https://arxiv.org/abs/2412.02605
tags:
- features
- sparse
- similarity
- pairs
- company
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper applies Sparse Autoencoders (SAEs) to enhance interpretability
  of company embeddings derived from SEC filings, enabling meaningful company similarity
  clusters. SAEs decompose large language model activations into interpretable sparse
  features, outperforming traditional SIC codes and embeddings in predicting return
  correlations (0.081 vs.
---

# Interpretable Company Similarity with Sparse Autoencoders

## Quick Facts
- arXiv ID: 2412.02605
- Source URL: https://arxiv.org/abs/2412.02605
- Reference count: 15
- Primary result: SAEs outperform SIC codes and embeddings in predicting return correlations (0.081 vs. -0.006)

## Executive Summary
This paper applies Sparse Autoencoders (SAEs) to enhance interpretability of company embeddings derived from SEC filings, enabling meaningful company similarity clusters. SAEs decompose large language model activations into interpretable sparse features, outperforming traditional SIC codes and embeddings in predicting return correlations (0.081 vs. -0.006 for SIC). The SAE-derived clusters achieve higher intra-cluster correlation (0.33 vs. 0.23 for SIC) and superior performance in pairs trading strategies, yielding higher Sharpe ratios and cumulative returns. By combining SAE features with SIC codes, the method captures both traditional and fundamental company characteristics, demonstrating practical value for risk management, hedging, and portfolio diversification.

## Method Summary
The method applies Sparse Autoencoders to embeddings generated from SEC 10-K filings to create interpretable company similarity measures. The approach decomposes language model activations into sparse features that can be labeled and interpreted by researchers. These SAE features are combined with traditional SIC codes to form hybrid similarity measures that outperform either method alone. The paper validates the approach through return correlation analysis and pairs trading strategy performance, demonstrating that SAE-derived clusters maintain higher correlations within clusters and generate superior risk-adjusted returns compared to SIC-based methods.

## Key Results
- SAEs predict return correlations at 0.081 vs. -0.006 for SIC codes
- Intra-cluster correlations reach 0.33 vs. 0.23 for SIC-based clusters
- Pairs trading strategies using SAE features achieve higher Sharpe ratios and cumulative returns

## Why This Works (Mechanism)
Sparse Autoencoders decompose complex embeddings into interpretable, sparse features that capture meaningful aspects of company fundamentals and business models. By learning to activate only a subset of features for each company, SAEs create more granular and meaningful representations than traditional classification systems like SIC codes. The combination of SAE features with SIC codes leverages both fundamental characteristics captured from textual analysis and established industry classifications, providing complementary information that improves similarity measurement and prediction accuracy.

## Foundational Learning
- **Sparse Autoencoders**: Neural networks that learn to compress and reconstruct input while enforcing sparsity constraints, producing interpretable features
  - Why needed: Standard embeddings lack interpretability; SAEs create human-understandable representations
  - Quick check: Verify that learned features can be meaningfully labeled by domain experts
- **SEC 10-K Filings**: Annual comprehensive business and financial reports filed with the SEC
  - Why needed: Provide rich textual data about company operations, risks, and strategies
  - Quick check: Ensure filings are properly parsed and cleaned before embedding generation
- **Company Embeddings**: Vector representations of companies derived from textual data
  - Why needed: Enable quantitative analysis of textual information and similarity measurement
  - Quick check: Validate that embeddings capture meaningful business characteristics
- **SIC Codes**: Standard Industrial Classification system for categorizing industries
  - Why needed: Provide traditional industry classification for comparison and combination
  - Quick check: Verify SIC code accuracy and consistency across companies
- **Pairs Trading**: Market-neutral strategy that takes long and short positions in correlated assets
  - Why needed: Practical application that tests similarity measures in real trading contexts
  - Quick check: Confirm statistical significance of trading results across different market regimes
- **Return Correlation**: Statistical measure of how asset returns move together
  - Why needed: Quantifies effectiveness of similarity measures in predicting actual market behavior
  - Quick check: Validate correlation calculations and test for statistical significance

## Architecture Onboarding

Component map: SEC Filings -> Language Model -> Embeddings -> Sparse Autoencoder -> Interpretable Features -> Similarity Measures -> Trading Strategy

Critical path: The essential flow is from SEC filings through language model to embeddings, then through SAE to interpretable features, which are used to create similarity measures for trading. The SAE layer is critical as it transforms uninterpretable embeddings into actionable features.

Design tradeoffs: The paper chooses interpretability over raw predictive power by using sparse features rather than dense embeddings. This sacrifices some information density but enables human understanding and trust. The combination with SIC codes represents another tradeoff between novel textual analysis and established industry classifications.

Failure signatures: Poor SAE performance would manifest as low correlation between derived clusters and actual returns, uninterpretable features, or no improvement over baseline methods. Data quality issues in SEC filings could propagate through the entire pipeline, resulting in meaningless embeddings and features.

First experiments:
1. Compare SAE-derived features against random features to establish baseline significance
2. Test individual SAE features vs combined feature sets for pairs trading performance
3. Validate interpretability by having independent researchers label the same features

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Small dataset with only 105 unique companies raises concerns about statistical significance and generalizability
- Exclusive focus on US-listed Russell 3000 companies limits international market applicability
- Sole reliance on SEC 10-K filings may miss valuable information from other sources

## Confidence
- SAE interpretability claim: Medium confidence (assessed by two researchers without systematic validation)
- Pairs trading results: Medium confidence (short backtest period, no out-of-sample validation)
- Combined SAE+SIC improvement: High confidence (supported by statistical comparisons)
- Practical adoption impact: Low confidence (speculative without implementation evidence)

## Next Checks
1. Test SAE-based clustering and pairs trading strategies on larger, more diverse datasets spanning multiple market cycles and international markets to assess robustness and generalizability
2. Conduct blind tests with domain experts to validate interpretability of SAE features and their practical utility for financial decision-making
3. Perform ablation studies to quantify incremental value of combining SAE features with SIC codes versus using either method independently, controlling for market factors and other variables