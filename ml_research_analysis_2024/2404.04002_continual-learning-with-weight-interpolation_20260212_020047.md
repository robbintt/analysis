---
ver: rpa2
title: Continual Learning with Weight Interpolation
arxiv_id: '2404.04002'
source_url: https://arxiv.org/abs/2404.04002
tags:
- learning
- interpolation
- continual
- tasks
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Continual Learning with Weight Interpolation
  (CLeWI), a method that improves rehearsal-based continual learning by interpolating
  between old and new model weights after each task. The approach leverages recent
  findings in weight interpolation to better consolidate knowledge and mitigate catastrophic
  forgetting.
---

# Continual Learning with Weight Interpolation

## Quick Facts
- arXiv ID: 2404.04002
- Source URL: https://arxiv.org/abs/2404.04002
- Authors: Jędrzej Kozal; Jan Wasilewski; Bartosz Krawczyk; Michał Woźniak
- Reference count: 40
- One-line primary result: CLeWI improves rehearsal-based continual learning by interpolating between old and new model weights after each task

## Executive Summary
This paper introduces Continual Learning with Weight Interpolation (CLeWI), a method that improves rehearsal-based continual learning by interpolating between old and new model weights after each task. The approach leverages recent findings in weight interpolation to better consolidate knowledge and mitigate catastrophic forgetting. By finding optimal weight permutations and applying linear interpolation, CLeWI enhances existing experience replay algorithms. The method includes an intuitive hyperparameter for controlling the stability-plasticity trade-off.

## Method Summary
CLeWI works by storing the previous model weights after each task, finding an optimal permutation to align neurons between the old and new models using activations from the rehearsal buffer, then linearly interpolating between the models using coefficient α. The process involves training on the current task with rehearsal, computing activations for both models using stored buffer samples, finding the optimal permutation to align these activations, applying the permutation to the old model, and interpolating between the models. Batch normalization statistics are updated after interpolation, and the new model is stored for the next task. The method is designed to work as a plugin for existing rehearsal-based continual learning algorithms.

## Key Results
- CLeWI significantly improves average accuracy across tasks when combined with rehearsal methods like ER, aGEM, MIR, BIC, and DER++
- The method provides explicit control over the stability-plasticity trade-off through the interpolation coefficient α
- CLeWI shows minimal benefit when combined with plasticity-constraining methods like EWC, as these methods already limit weight updates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Weight interpolation after each task improves continual learning by exploring local minima connected by low-loss paths.
- Mechanism: After training on a new task, the method interpolates between the old model weights and the new model weights using a learned permutation to align neurons, allowing the model to settle into a better local minimum that retains performance on previous tasks.
- Core assumption: Local minima in the loss landscape for different tasks are connected by low-loss paths when permutation symmetries are considered.
- Evidence anchors:
  - [abstract] "Our method, a simple yet powerful technique, enhances robustness against catastrophic forgetting by interpolating between old and new model weights after each novel task, effectively merging two models to facilitate exploration of local minima emerging after arrival of new concepts."
  - [section] "This property is known as mode connectivity... In the case of continual learning, this assumption cannot be met, as models are subject to forgetting [14] of previously seen data."
  - [corpus] Weak corpus coverage for mode connectivity in continual learning specifically; most related works focus on elastic weight consolidation.

### Mechanism 2
- Claim: The interpolation hyperparameter α provides explicit control over the stability-plasticity trade-off.
- Mechanism: By adjusting α, the interpolation can be biased toward either the new model (higher plasticity, better performance on current task but more forgetting) or the old model (higher stability, better retention but potentially worse current task performance).
- Core assumption: The loss landscape has regions where interpolating between two models with different task specializations yields intermediate models with balanced performance.
- Evidence anchors:
  - [abstract] "Additionally, our method provides an intuitive mechanism for controlling the stability-plasticity trade-off."
  - [section] "With higher α (interpolation closer to the old model), the model is prone to remembering the older tasks... With smaller α (interpolation closer to a newer model), the network archives better accuracy on the last task at the price of higher forgetting."
  - [corpus] Limited corpus evidence for α as a direct stability-plasticity control; most related works use regularization strength instead.

### Mechanism 3
- Claim: CLeWI works best when combined with rehearsal methods that do not overly constrain plasticity.
- Mechanism: Rehearsal methods provide the plasticity needed to learn new tasks, while interpolation provides the stability to retain old tasks. If the base method already constrains plasticity heavily, interpolation has less room to improve.
- Core assumption: The base rehearsal method must allow sufficient weight updates to create a new local minimum for the current task before interpolation can find a better consolidated solution.
- Evidence anchors:
  - [section] "In the interpolation process, we are losing some of the performance for the newest task at the cost of forgetting mitigation... These methods limit the plasticity of the networks."
  - [section] "Low plasticity can contribute to high overall loss and, in consequence, make interpolation harder."
  - [corpus] Weak corpus evidence for this specific interaction; most related works evaluate EWC or other regularization methods separately.

## Foundational Learning

- Concept: Mode connectivity and weight permutation invariance
  - Why needed here: The method relies on the assumption that neural networks with permuted weights can be linearly interpolated with low loss, which is fundamental to finding good weight alignments between tasks.
  - Quick check question: If two networks have the same architecture but different random initializations, can they be linearly interpolated with near-zero loss after finding the right permutation?

- Concept: Catastrophic forgetting and rehearsal-based continual learning
  - Why needed here: CLeWI is designed to work with rehearsal methods, so understanding how rehearsal prevents forgetting is essential to grasp why interpolation can further improve performance.
  - Quick check question: How does storing and replaying samples from previous tasks during training help mitigate forgetting?

- Concept: Stability-plasticity trade-off in continual learning
  - Why needed here: The interpolation hyperparameter α directly controls this trade-off, so understanding what stability and plasticity mean in this context is crucial.
  - Quick check question: What happens to a model's performance on old tasks if it has too much plasticity versus too much stability when learning new tasks?

## Architecture Onboarding

- Component map:
  Main model (θ) -> Previous model (θP) -> Memory buffer (M) -> Permutation finder -> Interpolation step -> Updated model (θ)

- Critical path:
  1. Train model on current task with rehearsal
  2. Compute activations for θ and θP using buffer M
  3. Find optimal permutation π to align activations
  4. Apply permutation to θP
  5. Interpolate: θ = (1-α)θ + απ(θP)
  6. Update batch norm statistics
  7. Store new θ as θP for next task

- Design tradeoffs:
  - Larger α improves stability but may hurt current task performance
  - More buffer samples improve permutation quality but increase memory cost
  - Wider networks improve interpolation effectiveness but increase computation

- Failure signatures:
  - If interpolation plot shows no local maxima, permutation alignment failed
  - If accuracy drops after interpolation, α may be too high or base method constrains plasticity too much
  - If permutation takes too long, buffer size or network width may be too large

- First 3 experiments:
  1. Run CLeWI with ER on split-CIFAR10 with α=0.3 and verify accuracy improvement over ER alone
  2. Plot interpolation curves for different α values to find optimal setting for current task
  3. Test CLeWI with a highly plasticity-constraining method (like EWC) to confirm it provides minimal benefit

## Open Questions the Paper Calls Out

- What is the optimal strategy for selecting the interpolation coefficient α across different tasks in a continual learning stream?
- How does CLeWI perform when applied to other computer vision tasks beyond image classification, such as object detection or semantic segmentation?
- Is it more effective to perform weight interpolation after every task or to use a selective mechanism that decides when to perform interpolation?
- How does CLeWI scale to very large models like transformers with billions of parameters, considering the memory requirements for storing previous model weights?

## Limitations

- The method assumes local minima for different tasks are connected by low-loss paths when permutation symmetries are considered, which may not hold for highly dissimilar tasks.
- CLeWI provides minimal benefit when combined with methods that already heavily constrain plasticity (like EWC), limiting its applicability to a subset of continual learning approaches.
- Storing previous model weights alongside current model weights can be prohibitive for large models like transformers with billions of parameters.

## Confidence

- Mechanism 1 (mode connectivity): Low confidence - while mode connectivity is well-established in standard settings, its application to continual learning with catastrophic forgetting is less explored in the corpus.
- Mechanism 2 (α as stability-plasticity control): Medium confidence - the interpolation behavior described is intuitive and supported by experimental results, though direct corpus evidence is limited.
- Mechanism 3 (plasticity constraint dependency): Medium confidence - the experimental results clearly show this pattern, but the corpus lacks strong supporting evidence for this specific interaction.

## Next Checks

1. Test CLeWI with a simple synthetic dataset where ground truth weight alignments are known to verify the permutation finder correctly identifies meaningful correspondences.
2. Create interpolation curves between models trained on different tasks to empirically verify that low-loss paths exist before applying CLeWI.
3. Systematically measure the plasticity of each base method (e.g., through Fisher information or weight change magnitude) to confirm the correlation between plasticity levels and CLeWI effectiveness.