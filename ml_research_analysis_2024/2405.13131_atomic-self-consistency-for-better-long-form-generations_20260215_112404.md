---
ver: rpa2
title: Atomic Self-Consistency for Better Long Form Generations
arxiv_id: '2405.13131'
source_url: https://arxiv.org/abs/2405.13131
tags:
- answer
- atomic
- clusters
- arxiv
- facts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Atomic Self-Consistency (ASC), a method to
  improve long-form LLM responses by combining relevant subparts from multiple stochastic
  samples. Unlike prior work that picks a single best response, ASC clusters atomic
  facts from all samples, selects consistent clusters, and merges them into a superior
  composite answer.
---

# Atomic Self-Consistency for Better Long Form Generations

## Quick Facts
- arXiv ID: 2405.13131
- Source URL: https://arxiv.org/abs/2405.13131
- Authors: Raghuveer Thirukovalluru; Yukun Huang; Bhuwan Dhingra
- Reference count: 8
- Key outcome: Merging atomic facts from multiple stochastic samples outperforms single-sample selection for long-form LLM responses

## Executive Summary
This paper introduces Atomic Self-Consistency (ASC), a method to improve long-form LLM responses by combining relevant subparts from multiple stochastic samples. Unlike prior work that picks a single best response, ASC clusters atomic facts from all samples, selects consistent clusters, and merges them into a superior composite answer. Experiments on ASQA, QAMPARI, QUEST, and ELI5 show significant gains over Universal Self-Consistency (USC) and Direct baselines, with ChatGPT and Llama2 models. ASC achieves 44.1 QA-F1 on ASQA and 20.50 recall on QAMPARI, demonstrating that merging multiple samples outperforms single-sample selection.

## Method Summary
ASC generates multiple stochastic samples per question using an LLM, then splits each sample into atomic facts (sentences). These atomic facts are clustered using sentence embeddings, with clusters filtered by consistency strength. Selected cluster representatives are merged using an LLM to produce the final answer. The method controls the precision-recall tradeoff via a threshold parameter Θ that determines which clusters to include based on their strength (number of samples containing the fact).

## Key Results
- ASC achieves 44.1 QA-F1 on ASQA dataset, significantly outperforming USC and Direct baselines
- On QAMPARI, ASC reaches 20.50 recall compared to 16.50 for USC and 10.50 for Direct
- ASC shows consistent improvements across multiple datasets (ASQA, QAMPARI, QUEST, ELI5) with both ChatGPT and Llama2 models
- Performance plateaus after ~20 samples, with diminishing returns beyond this point

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Merging atomic facts from multiple stochastic samples improves recall of relevant information compared to selecting a single best sample.
- **Mechanism**: The method clusters atomic facts (sentences) from multiple LLM samples, filters clusters by consistency strength, and merges selected cluster representatives into a final answer.
- **Core assumption**: Different LLM samples will contain complementary atomic facts relevant to the question, and clustering will group similar facts together for efficient selection.
- **Evidence anchors**:
  - [abstract]: "Unlike USC which only focuses on selecting the best single generation, ASC picks authentic subparts from the samples and merges them into a superior composite answer."
  - [section]: "Our research on the other hand, focuses on combining subparts of multiple stochastic samples to produce higher quality generations."
  - [corpus]: Weak - corpus lacks direct evaluation of merging strategy versus single-sample selection.
- **Break condition**: If samples are highly redundant or clustering fails to group semantically similar facts, merging provides little benefit over single-sample selection.

### Mechanism 2
- **Claim**: Consistency-based filtering using cluster strength effectively identifies and removes hallucinated atomic facts.
- **Mechanism**: Clusters with low membership (strength) are filtered out as likely hallucinatory, while high-strength clusters are retained as consistent across samples.
- **Core assumption**: True facts will appear consistently across multiple stochastic samples, while hallucinated facts will appear inconsistently.
- **Evidence anchors**:
  - [abstract]: "ASC picks authentic subparts from the samples and merges them into a superior composite answer."
  - [section]: "Consistency between model responses when used as a metric resulted in significant gains in reasoning."
  - [corpus]: Weak - corpus lacks detailed analysis of how cluster strength correlates with factual accuracy.
- **Break condition**: If the model generates consistently wrong information across samples, consistency-based filtering will retain hallucinations rather than remove them.

### Mechanism 3
- **Claim**: Controlling the cluster threshold parameter (Θ) allows balancing between precision and recall in the final answer.
- **Mechanism**: Higher Θ values select fewer, more consistent clusters (higher precision), while lower Θ values include more clusters (higher recall).
- **Core assumption**: There exists a tunable threshold that can adjust the precision-recall tradeoff without sacrificing overall quality.
- **Evidence anchors**:
  - [section]: "A lower Θ resulted in selecting a large number of clusters and resulted in improving QA-F1. This also increased the length of the final response."
  - [section]: "Reducing Θ on the other hand improved the Mauve fluency score as the shorter final answer matched more with the reference answer."
  - [corpus]: Weak - corpus lacks systematic evaluation of threshold effects across different datasets.
- **Break condition**: If the threshold is set too low, the final answer becomes too long and loses coherence; if too high, it misses relevant information.

## Foundational Learning

- **Concept**: Atomic fact extraction and verification
  - **Why needed here**: The method relies on breaking down long-form responses into atomic facts that can be individually verified and merged.
  - **Quick check question**: How does sentence-level atomic fact extraction compare to using neural models for identifying atomic facts in terms of accuracy and computational cost?

- **Concept**: Clustering algorithms and similarity measures
  - **Why needed here**: The method uses agglomerative clustering of sentence embeddings to group similar atomic facts across multiple samples.
  - **Quick check question**: What embedding model and distance threshold work best for clustering atomic facts from LLM responses?

- **Concept**: Consistency metrics and their relationship to factual accuracy
  - **Why needed here**: The method uses cluster strength as a proxy for consistency to filter out hallucinated facts.
  - **Quick check question**: How well does cluster strength correlate with actual factual accuracy compared to other verification methods like retrieval-based fact-checking?

## Architecture Onboarding

- **Component map**: Question -> LLM (generate m samples) -> Sentence tokenization -> Agglomerative clustering (SimCSE embeddings) -> Filter by Θ threshold -> LLM summarization -> Final composite answer
- **Critical path**: Generation -> Splitting -> Clustering -> Filtering -> Summarization
- **Design tradeoffs**: 
  - Using sentence-level atomic facts (fast, approximate) vs neural atomic fact extraction (accurate, expensive)
  - Consistency-based filtering (cheap, approximate) vs retrieval-based verification (expensive, accurate)
  - Number of samples (more samples = better coverage but higher cost)
- **Failure signatures**:
  - Low cluster strength threshold leads to long, incoherent answers
  - High cluster strength threshold leads to missing relevant information
  - Poor clustering causes unrelated facts to merge
  - Summarization LLM fails to properly merge cluster representatives
- **First 3 experiments**:
  1. Compare ASC performance with different numbers of samples (m=5, 10, 20, 50) to find the sweet spot where performance plateaus
  2. Test different clustering distance thresholds (d=0.10, 0.15, 0.20) to optimize cluster quality
  3. Compare ASC with random cluster selection to isolate the benefit of consistency-based filtering

## Open Questions the Paper Calls Out

- **Open Question 1**: What is the precise relationship between cluster entropy and performance gains when using fewer samples in ASC?
  - Basis in paper: Explicit - The paper mentions that "entropy starts to stagnate" when more samples are added and that "performance follows a similar trend increasing quickly at the beginning while slowly stagnating."
  - Why unresolved: The paper shows entropy-performance curves for QAMPARI but doesn't provide a precise mathematical relationship or threshold values for determining optimal sample count.
  - What evidence would resolve it: Detailed entropy-performance curves across all datasets with quantitative analysis of the inflection points where gains diminish.

- **Open Question 2**: How does ASC's performance compare to finetuned models specifically trained for long-form question answering?
  - Basis in paper: Inferred - The paper focuses on zero-shot performance with ChatGPT and Llama2 but doesn't compare against models finetuned on the specific QA datasets.
  - Why unresolved: The paper establishes ASC's effectiveness over baselines but doesn't benchmark against specialized finetuned models which might be the current state-of-the-art.
  - What evidence would resolve it: Head-to-head comparisons between ASC and finetuned models on all four datasets with standard metrics.

- **Open Question 3**: What is the impact of different sentence embedding models on ASC's clustering performance and final answer quality?
  - Basis in paper: Explicit - The paper uses "robert-large SimCSE" for sentence embeddings but doesn't explore alternatives.
  - Why unresolved: While the paper mentions using SimCSE, it doesn't investigate how different embedding models (e.g., BERT, RoBERTa, other SimCSE variants) affect ASC's effectiveness.
  - What evidence would resolve it: Systematic comparison of ASC using different embedding models with quantitative analysis of clustering quality and downstream QA performance.

## Limitations

- The assumption that cluster strength correlates with factual accuracy lacks strong empirical support in the corpus
- Sentence-level atomic fact extraction may not accurately capture atomic facts, leading to incorrect clustering
- Performance depends heavily on threshold parameter Θ, with limited evidence about robustness across different question types

## Confidence

- **High confidence**: The basic mechanism of clustering and merging atomic facts is technically sound and the experimental methodology (using established metrics on multiple datasets) is rigorous
- **Medium confidence**: The improvements over USC and Direct baselines are significant, but the extent to which these gains come from consistency-based filtering versus simply having more information from multiple samples is unclear
- **Low confidence**: The assumption that cluster strength reliably indicates factual accuracy lacks strong empirical support in the corpus

## Next Checks

1. **Hallucination Retention Test**: Design an experiment where the LLM consistently generates the same hallucination across samples. Measure whether ASC retains these hallucinations (indicating a critical flaw) or filters them out (supporting the consistency assumption).

2. **Threshold Robustness Analysis**: Systematically test ASC across a wider range of threshold values (Θ) on held-out data to determine the stability of optimal thresholds and identify potential overfitting to the tested datasets.

3. **Atomic Fact Extraction Accuracy**: Compare sentence-level atomic fact extraction against a neural model for identifying atomic facts on a sample of responses. Measure the accuracy of each method in correctly identifying and separating atomic facts, and assess how extraction errors impact ASC performance.