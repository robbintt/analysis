---
ver: rpa2
title: Deep Nets with Subsampling Layers Unwittingly Discard Useful Activations at
  Test-Time
arxiv_id: '2410.01083'
source_url: https://arxiv.org/abs/2410.01083
tags:
- image
- subsampling
- layers
- activations
- proc
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies that subsampling layers in deep networks
  discard potentially useful activations, which are instead leveraged at test time
  to improve performance. The authors propose a search and aggregation framework that
  identifies beneficial activation maps from discarded states and combines them via
  an attention-based module.
---

# Deep Nets with Subsampling Layers Unwittingly Discard Useful Activations at Test-Time

## Quick Facts
- arXiv ID: 2410.01083
- Source URL: https://arxiv.org/abs/2410.01083
- Authors: Chiao-An Yang; Ziwei Liu; Raymond A. Yeh
- Reference count: 40
- Key outcome: Search and aggregation framework improves image classification and semantic segmentation by leveraging discarded activations

## Executive Summary
This paper identifies that subsampling layers in deep networks discard potentially useful activations that could improve predictions at test time. The authors propose a framework that searches through discarded activation maps and aggregates them using an attention-based module. Experiments across nine architectures and four datasets show consistent accuracy improvements, with +0.87% top-1 accuracy on ImageNet and +0.51 mIoU on Cityscapes, while maintaining reasonable computational overhead.

## Method Summary
The approach modifies subsampling layers to extract multiple selection indices of activation maps rather than discarding all but one. A search procedure explores the space of discarded activations using a learned attention criterion or entropy-based confidence measure. The most promising activation maps are aggregated through a multi-head attention module that learns relative importance weights. The framework can be applied to pre-trained models without retraining, with optional fine-tuning of the attention module for improved performance.

## Key Results
- +0.87% top-1 accuracy improvement on ImageNet across nine architectures
- +0.51 mIoU improvement on Cityscapes semantic segmentation
- Consistent gains across Flowers102 and ADE20K datasets
- Complements existing test-time augmentation methods
- Performance scales with search budget while maintaining reasonable computational overhead

## Why This Works (Mechanism)

### Mechanism 1
Subsampling layers discard spatial information that can still be useful for prediction. When a subsampling layer with rate R discards activations, it removes R^2 times as many spatial activations as it keeps. These discarded activations encode complementary information about the input image that, if aggregated properly, can improve prediction accuracy. The core assumption is that discarded activations contain information complementary to retained activations.

### Mechanism 2
An attention-based aggregation module can effectively combine multiple discarded activation maps into a single prediction. The attention module learns relative importance weights between different activation maps through query-key-value transformations, allowing adaptive emphasis on more informative maps. The core assumption is that the relative importance of different activation maps varies across input samples and spatial regions.

### Mechanism 3
A search procedure can identify which discarded activation maps provide the most performance improvement. The search uses a greedy algorithm that expands promising states based on learned attention scores or entropy-based confidence, focusing computation on the most beneficial activation maps rather than evaluating all possible discarded states. The core assumption is that not all discarded activation maps are equally useful.

## Foundational Learning

- Concept: Subsampling and pooling operations in convolutional networks
  - Why needed here: The entire approach depends on understanding how subsampling layers discard spatial information and how different selection indices extract different activation maps
  - Quick check question: What is the relationship between subsampling rate R and the number of discarded vs retained activations?

- Concept: Attention mechanisms and multi-head attention
  - Why needed here: The aggregation module uses learned attention to combine multiple activation maps, requiring understanding of query-key-value operations and weighted averaging
  - Quick check question: How does the attention weight between two features depend on their query and key vectors?

- Concept: Greedy search algorithms and priority queues
  - Why needed here: The search procedure uses a priority queue to expand promising states based on a criterion, requiring understanding of state space exploration and heuristic evaluation
  - Quick check question: What determines the order in which states are expanded in the greedy search?

## Architecture Onboarding

- Component map: Input image → Backbone with modified subsampling layers → Multiple forward passes with different selection indices → Attention aggregation module → Classifier → Final prediction
- Critical path: Modified subsampling layers → Search procedure → Aggregation module → Classifier prediction
- Design tradeoffs: Larger search space provides more potential improvement but increases computation; learned aggregation provides better performance but requires training vs. entropy-based aggregation
- Failure signatures: Degraded performance with higher budgets (overfitting or poor aggregation); search procedure not finding useful states; attention weights becoming uniform
- First 3 experiments:
  1. Implement modified subsampling layers that allow extraction of different selection indices
  2. Test aggregation of two or three discarded activation maps using entropy-based weighting
  3. Implement and validate the greedy search procedure on a simple architecture

## Open Questions the Paper Calls Out

### Open Question 1
How do discarded activations vary across different architectures (CNN vs. Transformer) in terms of informativeness and utility? The paper notes that their approach excels in ViT-like architectures where subsampling layers with large subsampling rates R are used, but does not provide a systematic comparison of discarded activation utility across architectures.

### Open Question 2
What is the optimal search strategy for identifying useful discarded activations in deeper networks? While the paper presents a working search strategy, it doesn't compare it against other possible search strategies or analyze its efficiency in very deep networks.

### Open Question 3
How does the performance gain from using discarded activations scale with input resolution and model size? The paper experiments with different model sizes and resolutions but doesn't provide a systematic analysis of how performance gains scale with these factors.

### Open Question 4
Can the approach be extended to other types of neural network layers beyond subsampling layers? The paper focuses specifically on subsampling layers and mentions that the approach could potentially be applied to other layers, but doesn't explore this possibility.

## Limitations
- Computational overhead increases with search space size, though the framework maintains reasonable efficiency
- Learned attention module requires additional training, which may limit practical applicability
- Performance gains vary significantly across architectures and datasets

## Confidence

### Mechanism 1: Medium confidence
- Theoretical motivation is sound
- Limited direct evidence in corpus

### Mechanism 2: Medium confidence
- Technically feasible approach
- Effectiveness depends heavily on learning quality

### Mechanism 3: Medium confidence
- Greedy search is a reasonable heuristic
- Optimality is not guaranteed

## Next Checks

1. **Ablation study**: Compare learned vs. entropy-based aggregation across architectures to quantify the performance tradeoff
2. **Scalability analysis**: Measure computational overhead and accuracy gains across different search space sizes
3. **Robustness test**: Evaluate performance on out-of-distribution data to assess generalization of the aggregation framework