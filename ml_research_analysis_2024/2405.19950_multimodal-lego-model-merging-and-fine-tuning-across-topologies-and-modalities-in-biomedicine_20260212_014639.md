---
ver: rpa2
title: 'Multimodal Lego: Model Merging and Fine-Tuning Across Topologies and Modalities
  in Biomedicine'
arxiv_id: '2405.19950'
source_url: https://arxiv.org/abs/2405.19950
tags:
- multimodal
- modalities
- fusion
- data
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Multimodal Lego (MM-Lego) is a general-purpose framework for combining
  unimodal encoders into a performant multimodal model without requiring paired training
  data or extensive fine-tuning. It introduces LegoBlock wrappers that enforce shape
  consistency and harmonize latent representations in the frequency domain, enabling
  model merging with minimal signal interference.
---

# Multimodal Lego: Model Merging and Fine-Tuning Across Topologies and Modalities in Biomedicine

## Quick Facts
- arXiv ID: 2405.19950
- Source URL: https://arxiv.org/abs/2405.19950
- Reference count: 28
- Top-2 performance across all seven biomedical datasets with state-of-the-art results in five

## Executive Summary
Multimodal Lego (MM-Lego) is a general-purpose framework for combining unimodal encoders into a performant multimodal model without requiring paired training data or extensive fine-tuning. It introduces LegoBlock wrappers that enforce shape consistency and harmonize latent representations in the frequency domain, enabling model merging with minimal signal interference. The framework includes two variants: LegoMerge, which achieves competitive performance without fine-tuning, and LegoFuse, which surpasses benchmarks with minimal fine-tuning. Tested across seven medical datasets spanning imaging, tabular, and time-series modalities, MM-Lego demonstrated superior scalability, robustness to modality imbalance, and architecture-agnostic design.

## Method Summary
MM-Lego wraps unimodal encoders in LegoBlocks that enforce shape consistency and transform latents to the frequency domain. LegoMerge combines these frequency-domain latents using harmonic mean aggregation and task head weights via SLERP interpolation, achieving competitive performance without fine-tuning. LegoFuse extends this by stacking or weaving LegoBlocks and fine-tuning sequentially for a few epochs, surpassing benchmarks. The framework is tested on seven multimodal biomedical datasets including TCGA (histopathology, gene expression, mutations), MIMIC-III (clinical, time series), and ISIC (imaging, tabular) with Concordance Index and AUC as primary metrics.

## Key Results
- Achieved top-2 performance across all seven biomedical datasets
- State-of-the-art results in five out of seven datasets
- Demonstrated zero or minimal training requirements (2 epochs for LegoFuse)
- Superior scalability and robustness to modality imbalance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Frequency-domain latent representations reduce signal interference during model merging.
- **Mechanism**: Fourier transform yields orthogonal frequency components; harmonic mean of magnitudes and phase averaging combine representations without destructive interference.
- **Core assumption**: Orthogonal frequency components remain independent after transform and can be safely combined via harmonic mean.
- **Evidence anchors**:
  - [abstract]: "It harmonises these representations by learning features in the frequency domain to enable model merging with little signal interference."
  - [section]: "frequency-domain representations are: 1) signal-preserving as frequency features are less prone to signal interference upon aggregation"
  - [corpus]: weak; corpus does not directly address signal interference in frequency domain.
- **Break condition**: If frequency components are not truly orthogonal (e.g., due to sampling or windowing effects), destructive interference may occur.

### Mechanism 2
- **Claim**: LegoBlock wrappers enforce shape consistency and enable topology-agnostic model merging.
- **Mechanism**: All modality-specific encoders are wrapped to produce latent tensors of identical dimensions; cross-attention layers iteratively update these latents; SLERP interpolates task head weights across different architectures.
- **Core assumption**: Uniform latent shape is sufficient to allow merging despite differing underlying encoder architectures.
- **Evidence anchors**:
  - [abstract]: "We achieve this by introducing a wrapper for any unimodal encoder that enforces shape consistency between modality representations."
  - [section]: "With L ⊆ Rc×d and each element in L being in the frequency domain, we can use aggregation functions ψ(·), which are less prone to cancelling out signal."
  - [corpus]: weak; no corpus evidence directly on topology-agnostic merging via wrapper enforcement.
- **Break condition**: If latent dimensionality is insufficient to capture modality-specific information, performance degrades.

### Mechanism 3
- **Claim**: Iterative cross-attention within LegoBlock allows fine-tuning with minimal paired data.
- **Mechanism**: Latent state is passed sequentially through modality-specific blocks; during LegoFuse, each block conditions on all modalities' updates, enabling mutual context learning.
- **Core assumption**: Sequential conditioning approximates joint training while requiring fewer paired samples.
- **Evidence anchors**:
  - [abstract]: "LegoFuse, which surpasses benchmarks with minimal fine-tuning."
  - [section]: "LegoFuse operates at the layer level by sequentially passing through all layers in B... fine-tune the stacked or the weaved model for a few epochs with all (paired) modalities."
  - [corpus]: weak; no direct corpus evidence on minimal paired data fine-tuning via sequential conditioning.
- **Break condition**: If modality dependencies are too complex for sequential approximation, joint fine-tuning may be necessary.

## Foundational Learning

- **Concept**: Fourier transform and its properties (orthogonality, invertibility, distance preservation)
  - **Why needed here**: Enables frequency-domain latent representations that avoid signal interference and preserve distances for loss functions.
  - **Quick check question**: Why does Parseval's theorem matter for multimodal loss design?
- **Concept**: Cross-attention mechanisms and iterative state passing
  - **Why needed here**: LegoBlock uses cross-attention to update latents iteratively; LegoFuse stacks blocks for mutual conditioning.
  - **Quick check question**: How does sequential conditioning in LegoFuse differ from joint fine-tuning?
- **Concept**: Model merging techniques (SLERP, harmonic mean) and their assumptions
  - **Why needed here**: LegoMerge combines frequency-domain latents and task heads without paired data.
  - **Quick check question**: What architectural assumption does SLERP require that LegoMerge relaxes?

## Architecture Onboarding

- **Component map**: Unimodal encoder → LegoBlock wrapper → frequency-domain latent → aggregation (LegoMerge) or stacking (LegoFuse) → task prediction
- **Critical path**: Unimodal encoder → LegoBlock wrapper → frequency-domain latent → aggregation (LegoMerge) or stacking (LegoFuse) → task prediction
- **Design tradeoffs**:
  - Frequency domain adds computational overhead (FFT) but reduces interference.
  - Sequential conditioning in LegoFuse trades convergence speed for data efficiency.
  - Shape consistency requirement limits use with encoders producing incompatible latent shapes.
- **Failure signatures**:
  - Performance collapse if FFT introduces aliasing or if latent dimensions are too small.
  - LegoMerge failure if modality latents have highly skewed magnitude distributions.
  - LegoFuse instability if modality dependencies are too complex for sequential conditioning.
- **First 3 experiments**:
  1. Wrap a simple CNN encoder in LegoBlock; verify shape consistency and FFT inversion.
  2. Merge two LegoBlocks via harmonic mean; measure interference reduction vs. naive averaging.
  3. Stack two LegoBlocks and fine-tune on a small paired dataset; compare to joint training baseline.

## Open Questions the Paper Calls Out
The paper explicitly identifies the need for further research on self-supervised fitting of LegoBlock adapters, as current implementations require supervised samples for adapter training.

## Limitations
- Limited ablation studies on whether frequency-domain harmonization outperforms time-domain approaches
- Cross-attention mechanism's effectiveness lacks direct comparison to joint fine-tuning
- Fixed latent dimension configuration without exploration of scalability limits

## Confidence
- **High confidence**: Wrapper-enforced shape consistency and topology-agnostic design demonstrated through consistent top-2 performance
- **Medium confidence**: Frequency-domain harmonization mechanism's benefits need empirical isolation from other factors
- **Medium confidence**: Minimal fine-tuning success demonstrated but specific contribution of cross-attention requires further study

## Next Checks
1. **Frequency vs. Time Domain Ablation**: Implement a time-domain version of LegoMerge using the same wrapper and aggregation (harmonic mean) but without FFT/IFFT. Compare interference reduction and final performance to isolate the frequency mechanism's contribution.

2. **Wrapper-Only Control**: Create a baseline that only enforces shape consistency through the wrapper but uses naive averaging for merging. This tests whether shape consistency alone explains performance gains.

3. **Sequential Conditioning Stress Test**: Apply LegoFuse to a dataset where modality dependencies are known to be highly complex (e.g., modalities with strong temporal correlations). Compare performance and convergence speed to full joint fine-tuning to quantify the sequential approximation's limitations.