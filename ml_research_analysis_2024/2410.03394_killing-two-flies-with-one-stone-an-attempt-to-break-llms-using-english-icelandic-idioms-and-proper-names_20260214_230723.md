---
ver: rpa2
title: 'Killing Two Flies with One Stone: An Attempt to Break LLMs Using English->Icelandic
  Idioms and Proper Names'
arxiv_id: '2410.03394'
source_url: https://arxiv.org/abs/2410.03394
tags: []
core_contribution: 'This study presents a test suite to evaluate English-to-Icelandic
  translation models on idiomatic expressions and proper names. Two datasets were
  created: one testing idioms and their literal counterparts, and another testing
  Icelandic exonyms and gendered name inflections.'
---

# Killing Two Flies with One Stone: An Attempt to Break LLMs Using English->Icelandic Idioms and Proper Names

## Quick Facts
- arXiv ID: 2410.03394
- Source URL: https://arxiv.org/abs/2410.03394
- Reference count: 5
- One-line primary result: LLMs show relatively low performance on English-to-Icelandic translations of idiomatic expressions (max ~79% accuracy) and proper names (max ~54% accuracy)

## Executive Summary
This study presents a novel test suite to evaluate English-to-Icelandic translation models on two challenging linguistic phenomena: idiomatic expressions and proper names. The researchers created two datasets - one testing idioms and their literal counterparts, and another testing Icelandic exonyms and gendered name inflections. Results show that even state-of-the-art translation models struggle with these tasks, with maximum accuracy scores around 79% for idioms and 54% for place names. The study highlights significant room for improvement in handling these linguistic phenomena that are crucial for natural, readable translations.

## Method Summary
The researchers developed a custom test suite with two main components: an idiom evaluation module testing both metaphorical and literal uses of expressions, and a proper names evaluation module testing exonym translation and morphological inflection. The evaluation combines automatic scoring using keyword-based matching for idioms and lemmatized form matching for proper names, with manual review of translation outputs. The test suite was used to evaluate multiple translation models, including commercial systems and a custom submission, with results analyzed for performance patterns and error types.

## Key Results
- Idiomatic expressions pose significant challenges, with maximum accuracy around 79% achieved by Claude 3.5
- Place name translations show particularly low performance, with maximum accuracy around 54% achieved by the team's own AMI submission
- Models struggle to contextually disambiguate between literal and metaphorical meanings of identical phrases
- Proper name translations are error-prone, especially when Icelandic names have ambiguous surface forms (male vs female variants)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Idiomatic expressions are challenging for LLMs because they require metaphorical understanding beyond literal word meanings.
- Mechanism: The test suite evaluates models on both idiomatic and literal uses of the same expressions, forcing models to contextually disambiguate between metaphorical and literal meanings.
- Core assumption: LLMs struggle to switch between literal and metaphorical interpretations of identical phrases based on context.
- Evidence anchors:
  - [abstract]: "idiomatic expressions are known to be a significant challenge for modern translation models"
  - [section]: "We also try and test the models on their ability to translate the words in these expressions literally when appropriate"
  - [corpus]: Weak - corpus neighbors show related work on idiom translation but no direct evidence about literal/metaphorical switching mechanisms
- Break condition: Models develop explicit mechanisms for contextual disambiguation between literal and metaphorical meanings, or training data includes sufficient balanced examples of both usage types.

### Mechanism 2
- Claim: Proper names require morphological adaptation to target language inflection systems, which LLMs handle inconsistently.
- Mechanism: The test suite includes Icelandic names with ambiguous surface forms (e.g., male vs female variants sharing the same form) and requires correct inflection based on grammatical case.
- Core assumption: LLMs have difficulty mapping the same lexical form in source language to different inflected forms in target language depending on grammatical context.
- Evidence anchors:
  - [abstract]: "incorrect translations impact meaning as well as readability"
  - [section]: "we observe whether they are correctly inflected in the Icelandic text (which impacts not only the text's readability, but also its meaning)"
  - [corpus]: Weak - corpus shows related work on proper names but no direct evidence about inflection system challenges
- Break condition: Models develop robust morphological generation capabilities that can handle ambiguous surface forms and case-dependent inflections.

### Mechanism 3
- Claim: Exonym translation requires cultural-linguistic knowledge that LLMs may lack or apply inconsistently.
- Mechanism: The test suite includes place names that should be translated to Icelandic exonyms, testing whether models apply culturally appropriate translations rather than literal transliteration.
- Core assumption: LLMs either lack sufficient training data on exonym mappings or apply inconsistent translation strategies for place names.
- Evidence anchors:
  - [abstract]: "place names that should be translated into their Icelandic exonyms"
  - [section]: "we construct our own list of 52 names of cities and areas that we argue would be highly unusual not to translate into their Icelandic names"
  - [corpus]: Weak - corpus neighbors show related work on place names but no direct evidence about exonym translation challenges
- Break condition: Models develop explicit knowledge of exonym mappings or training data includes sufficient examples of culturally appropriate place name translations.

## Foundational Learning

- Concept: Idiomatic expressions and their literal counterparts
  - Why needed here: Understanding the difference between metaphorical and literal meanings is crucial for evaluating model performance on the idiom test suite
  - Quick check question: What is the difference between "kick the bucket" used idiomatically versus literally, and how would a model know which meaning to apply?

- Concept: Grammatical case systems and inflection
  - Why needed here: Icelandic has four grammatical cases that affect how names and nouns are inflected, which is central to evaluating proper name translations
  - Quick check question: How does the meaning of a sentence change when an Icelandic name is incorrectly inflected in the wrong grammatical case?

- Concept: Exonyms and culturally appropriate translation
  - Why needed here: Understanding when place names should be translated to culturally appropriate equivalents rather than transliterated is key to the proper names test suite
  - Quick check question: When should "Copenhagen" be translated to "Kaupmannahöfn" versus kept as "Copenhagen" in Icelandic text?

## Architecture Onboarding

- Component map: Test suite -> Automatic scoring -> Manual review -> Results analysis
- Critical path: Data preparation → Test suite construction → Model submission → Automatic scoring → Manual review → Results analysis → Documentation
- Design tradeoffs: The automatic scoring system prioritizes precision over recall, marking translations as incorrect if they contain any negative keywords. This conservative approach may undercount correct translations but ensures high confidence in reported errors.
- Failure signatures: Low scores on idiom translations indicate difficulty with metaphorical understanding. Poor performance on place names suggests inadequate exonym knowledge. Errors on Icelandic names reveal morphological inflection problems.
- First 3 experiments:
  1. Test a simple baseline model on the idiom suite to establish minimum performance expectations
  2. Run the proper names suite on a morphologically-aware model to compare performance
  3. Create synthetic examples mixing literal and idiomatic usage to test contextual disambiguation capabilities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific architectural modifications or fine-tuning strategies would be most effective for improving LLM performance on idiomatic expressions and proper names in English-to-Icelandic translation?
- Basis in paper: [explicit] The authors note "considerable room for improvement" and that these categories "continue to pose some problems for even state-of-the-art translation models"
- Why unresolved: The study only evaluates existing models without exploring architectural changes or fine-tuning approaches that could specifically target these linguistic phenomena
- What evidence would resolve it: Comparative experiments testing various fine-tuning approaches (domain adaptation, idiom-specific training data, morphological inflection techniques) against baseline models on the same test suite

### Open Question 2
- Question: How do human translators handle the same idiomatic expressions and proper names, and what strategies do they use that current LLMs are missing?
- Basis in paper: [inferred] The manual evaluation revealed "significant room for improvement" and the authors suggest future work could involve "more manual evaluation, ideally using more evaluators"
- Why unresolved: The paper only provides automatic and limited manual evaluation of LLM outputs without comparing to human translation strategies or performance benchmarks
- What evidence would resolve it: Controlled experiments comparing human translator outputs to LLM outputs on the same test suite, with detailed analysis of translation strategies and error patterns

### Open Question 3
- Question: What is the relationship between a model's ability to handle literal versus idiomatic translations, and why do some models show inverse performance on these tasks?
- Basis in paper: [explicit] The authors observe that "for some models, proficiency in effectively translating text in a literal sense comes at a cost to their ability to handle more metaphorical text"
- Why unresolved: The study identifies this inverse relationship but doesn't investigate the underlying mechanisms or determine whether this is a fundamental limitation or can be overcome
- What evidence would resolve it: Correlation studies across multiple models testing literal and idiomatic translation performance, combined with analysis of attention patterns and internal representations during translation tasks

## Limitations
- The keyword-based evaluation methodology may not capture all valid translations and could lead to false negatives
- The test suite size (397 idiom examples and 52 place names) may not provide comprehensive coverage of all linguistic variations
- Manual evaluation was limited to 50 samples, which may not capture systematic error patterns

## Confidence

- **High confidence**: Claims about overall low performance on both idiom and proper name translations are well-supported by the quantitative results presented.
- **Medium confidence**: Conclusions about specific model rankings (Claude 3.5 for idioms, AMI for place names) are supported but could vary with different test samples.
- **Low confidence**: Generalizations about model capabilities across all LLMs based on this limited test suite should be treated cautiously.

## Next Checks
1. Expand manual evaluation coverage: Manually review an additional 200+ random samples across both test suites to validate automatic scoring patterns and identify systematic error types.

2. Cross-linguistic validation: Apply the same evaluation methodology to English-to-other-language translation pairs to determine if the observed difficulties are specific to Icelandic or represent broader challenges for LLMs.

3. Semantic equivalence testing: Create a subset of test cases specifically designed to test whether models using semantically equivalent but lexically different expressions are being unfairly penalized by the current keyword-based evaluation system.