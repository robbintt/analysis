---
ver: rpa2
title: 'AS-ES Learning: Towards Efficient CoT Learning in Small Models'
arxiv_id: '2403.01969'
source_url: https://arxiv.org/abs/2403.01969
tags:
- learning
- as-es
- segmentation
- training
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new training paradigm AS-ES (Abstractive
  Segments - Extractive Segments) learning, which exploits the inherent information
  in CoT for iterative generation. Experiments show that our methods surpass the direct
  seq2seq training on CoT-extensive tasks like MWP and PET summarization, without
  data augmentation or altering the model itself.
---

# AS-ES Learning: Towards Efficient CoT Learning in Small Models

## Quick Facts
- arXiv ID: 2403.01969
- Source URL: https://arxiv.org/abs/2403.01969
- Authors: Nuwa Xi; Yuhan Chen; Sendong Zhao; Haochun Wang; Bing Qin; Ting Liu
- Reference count: 13
- Key outcome: AS-ES learning surpasses direct seq2seq training on CoT-intensive tasks without data augmentation or model alteration

## Executive Summary
This paper introduces AS-ES (Abstractive Segments - Extractive Segments) learning, a novel training paradigm that exploits inherent information in Chain-of-Thought reasoning for more efficient learning in small language models. The approach separates CoT into extractive and abstractive segments, allowing for more efficient optimization through dual-path or unified single-model training strategies. Experiments demonstrate superior performance on Math Word Problem solving and PET report summarization tasks compared to traditional direct seq2seq training methods.

## Method Summary
AS-ES learning works by segmenting Chain-of-Thought data into Abstractive Segments (AS) and Extractive Segments (ES), then training models using either dual-path (two separate models) or uni-path (single unified model) strategies. The method uses iterative generation with stop signs to control output length and employs various segmentation strategies including entropy-oriented and interleaving approaches. The paradigm achieves lower loss boundaries by optimizing extraction and abstractive reasoning separately, making it particularly effective for small models on CoT-intensive tasks.

## Key Results
- AS-ES learning outperforms direct seq2seq training on Math Word Problem and PET summarization tasks
- Unified single-model approach (USM) achieves better results than dual-path training with two models
- Different segmentation strategies (entropy-oriented vs interleaving) work best for different model sizes and tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AS-ES learning works by achieving a generally lower loss boundary compared to direct approach.
- Mechanism: The training strategy separates extraction and abstractive reasoning into distinct segments, allowing each to be optimized independently. This separation reduces the complexity of each optimization problem, leading to lower overall loss.
- Core assumption: Separating complex reasoning tasks into simpler subtasks allows for more efficient learning and optimization.
- Evidence anchors:
  - [abstract]: "Experiments show that our methods surpass the direct seq2seq training on CoT-extensive tasks"
  - [section]: "the lowest loss boundary for the direct approach is significantly larger than AS-ES learning, which partly explains why AS-ES learning works"
  - [corpus]: Weak - no direct evidence from corpus neighbors
- Break condition: If the segmentation fails to properly identify extractive vs abstractive segments, the loss reduction benefit disappears.

### Mechanism 2
- Claim: Small models can effectively handle both extraction and reasoning tasks within a single framework.
- Mechanism: The unified model approach (USM) allows the model to learn the interplay between different types of reasoning, leading to a more nuanced understanding of the data.
- Core assumption: A single model can learn the complex relationships between extraction and reasoning tasks without needing separate specialized models.
- Evidence anchors:
  - [abstract]: "using one unified model for generating AS/ES together"
  - [section]: "one model is enough and lead to even better results compared to using two models"
  - [corpus]: Weak - no direct evidence from corpus neighbors
- Break condition: If the model capacity is insufficient to capture the complexity of both tasks, performance will degrade.

### Mechanism 3
- Claim: The quality of AS-ES dataset construction significantly impacts model performance.
- Mechanism: By carefully structuring the training data with proper segmentation and organization, the model can focus on the most relevant information for each task.
- Core assumption: Proper data organization and segmentation are critical for effective learning, regardless of model size.
- Evidence anchors:
  - [section]: "Different segmentation strategies do play a key role in AS-ES learning"
  - [section]: "entropy-oriented segmentation works best for Flan-T5-large while interleaving segmentation works best for Flan-T5-small"
  - [corpus]: Weak - no direct evidence from corpus neighbors
- Break condition: If the segmentation method is poorly chosen for the specific task, performance will suffer.

## Foundational Learning

- Concept: Chain-of-Thought (CoT) reasoning
  - Why needed here: Understanding CoT is fundamental to grasping why AS-ES learning improves performance on reasoning tasks
  - Quick check question: Can you explain the difference between extractive and abstractive segments in the context of CoT?

- Concept: Data segmentation and organization
  - Why needed here: The effectiveness of AS-ES learning heavily depends on how the data is segmented and structured for training
  - Quick check question: How would you modify the AS-ES dataset construction if you wanted to include additional reasoning steps?

- Concept: Model capacity and task complexity
  - Why needed here: Understanding the relationship between model size and the complexity of tasks it can handle is crucial for interpreting the results
  - Quick check question: Why might a larger model benefit more from entropy-oriented segmentation compared to a smaller model?

## Architecture Onboarding

- Component map: Input -> AS-ES segmentation module -> Dataset construction -> Model training (DSM/USM) -> Generation with stop signs

- Critical path:
  1. Segment CoT data into AS and ES components
  2. Construct AS-ES dataset with proper organization
  3. Train model using either DSM or USM approach
  4. Generate output using iterative process with stop signs

- Design tradeoffs:
  - Dual-path vs uni-path: Two models provide specialized optimization but increase complexity; one model is simpler but may not capture task-specific nuances
  - Segmentation strategy: Different approaches work better for different tasks and model sizes
  - Stop sign implementation: Affects control over output length and quality

- Failure signatures:
  - High training loss despite low validation loss (overfitting)
  - Poor performance on validation set (underfitting or poor segmentation)
  - Inconsistent output length or quality (stop sign issues)

- First 3 experiments:
  1. Compare direct approach vs AS-ES learning with entropy segmentation on MWP dataset
  2. Test different segmentation strategies (entropy, interleaving, BLEU/ROUGE) on PET dataset
  3. Evaluate DSM vs USM performance on both datasets to determine optimal training strategy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of AS-ES learning scale with increasing model size beyond the tested Flan-T5 variants?
- Basis in paper: [explicit] The paper experiments with three sizes of Flan-T5 (small, base, large) and finds that the effectiveness of AS-ES learning varies with model size.
- Why unresolved: The paper does not explore model sizes larger than Flan-T5-large, leaving uncertainty about the scalability of AS-ES learning to even larger models or different architectures.
- What evidence would resolve it: Experiments comparing AS-ES learning across a wider range of model sizes, including those larger than Flan-T5-large and models from different architectures, would provide insights into the scalability and generalizability of the approach.

### Open Question 2
- Question: Can the AS-ES learning paradigm be effectively applied to tasks outside of logical reasoning, such as natural language understanding or generation tasks?
- Basis in paper: [inferred] The paper focuses on tasks like MWP and PET summarization, which heavily involve logical reasoning, but does not explore its applicability to other types of NLP tasks.
- Why unresolved: The specific characteristics of AS-ES learning that make it effective for logical reasoning tasks may not translate directly to other NLP domains, necessitating further investigation.
- What evidence would resolve it: Applying AS-ES learning to a diverse set of NLP tasks, including those focused on natural language understanding or generation, and comparing the results to traditional training methods would clarify its broader applicability.

### Open Question 3
- Question: What is the impact of different segmentation strategies on the performance of AS-ES learning in tasks with varying levels of complexity and domain specificity?
- Basis in paper: [explicit] The paper experiments with multiple segmentation strategies (entropy-oriented, location-oriented, loss-oriented, similarity-oriented) and finds that their effectiveness varies by task.
- Why unresolved: The paper does not provide a comprehensive analysis of how segmentation strategy impacts performance across a wide range of tasks with different characteristics.
- What evidence would resolve it: Conducting experiments with AS-ES learning on a broad spectrum of tasks, systematically varying the segmentation strategy, and analyzing the results would elucidate the relationship between segmentation strategy, task characteristics, and learning performance.

## Limitations
- Experimental results are based on two specific datasets (MWP and PET), limiting generalizability
- The optimal segmentation strategy appears task-dependent, suggesting no universal solution
- Model capacity assumptions need more extensive testing across different scales and architectures

## Confidence
- Mechanism 1 (Loss Boundary Reduction): Medium confidence
- Mechanism 2 (Unified Model Effectiveness): Medium confidence
- Mechanism 3 (Data Quality Impact): Medium confidence

## Next Checks
1. Test AS-ES learning on diverse reasoning tasks beyond MWP and PET to assess cross-domain generalization
2. Conduct experiments with wider range of model sizes (from 1-2B to 20-30B parameters) to understand scalability
3. Systematically test different segmentation strategies across all experimental setups with ablation studies to determine optimal approaches