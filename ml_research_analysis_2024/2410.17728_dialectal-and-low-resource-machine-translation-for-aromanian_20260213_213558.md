---
ver: rpa2
title: Dialectal and Low-Resource Machine Translation for Aromanian
arxiv_id: '2410.17728'
source_url: https://arxiv.org/abs/2410.17728
tags:
- aromanian
- translation
- romanian
- machine
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper builds the first Aromanian neural machine translation
  system using a 79k sentence parallel corpus. The authors fine-tune NLLB models and
  several instruction-tuned LLMs for translation between Aromanian, Romanian, and
  English.
---

# Dialectal and Low-Resource Machine Translation for Aromanian

## Quick Facts
- **arXiv ID**: 2410.17728
- **Source URL**: https://arxiv.org/abs/2410.17728
- **Reference count**: 20
- **Primary result**: First Aromanian neural machine translation system built using 79k sentence parallel corpus, with NLLB models outperforming LLMs on translation tasks.

## Executive Summary
This paper presents the first neural machine translation (NMT) system for Aromanian, an endangered Eastern Romance language spoken in the Balkans. The authors create a 79,000 sentence parallel corpus from diverse sources including religious texts, literature, lyrics, and news articles, then fine-tune both NLLB models and instruction-tuned large language models (LLMs) for translation between Aromanian, Romanian, and English. The NLLB-based approaches significantly outperform LLMs, particularly for Aromanian translation directions, achieving ChrF++ scores around 50 compared to below 40 for LLMs. A quantized 600M parameter NLLB model achieves ~65 tokens/second on CPU and is deployed in an online translation system with diacritic conversion capabilities.

## Method Summary
The authors first collect and align parallel texts from various sources (Bible, Divine Comedy, Lyrics Translate, etc.) to create a 79k sentence corpus, converting all texts to the Cunia orthography. They fine-tune a language-agnostic BERT Sentence Encoder (LaBSE) on Aromanian-Romanian and Aromanian-English pairs for sentence alignment and evaluation. Multiple models are then fine-tuned including NLLB-200 (1.3B and 600M parameters) and LLMs (LLaMA 3.1 8B, Qwen2 7B, RoLLaMA, TowerInstruct) using the Aromanian-Romanian-English corpus with special tokenization for Aromanian. The best-performing NLLB-600M model is quantized to 8-bit integers for CPU deployment, and the system is made available through an online interface with diacritic conversion.

## Key Results
- NLLB models outperform LLMs on Aromanian translation tasks, with ChrF++ scores around 50 for Aromanian-Romanian pairs versus below 40 for LLMs
- Fine-tuned NLLB models achieve better translation quality than zero-shot GPT-4o, which cannot produce translations into Aromanian
- A quantized NLLB-600M model achieves ~65 tokens/second on CPU with minimal performance loss compared to floating-point versions
- Human evaluation on 80 sentences shows machine translation quality is close to human translations, with most receiving perfect scores

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning pre-trained multilingual models on a 79k sentence parallel corpus significantly improves translation performance for Aromanian compared to zero-shot GPT-4o.
- Mechanism: Transfer learning from models pre-trained on related languages (Romanian, English) allows efficient adaptation to Aromanian with limited data, avoiding the need for massive monolingual corpora.
- Core assumption: The similarity between Aromanian and Romanian enables knowledge transfer, and the pre-trained models' tokenizers have seen similar byte-pair encodings in other Romance or Balkan languages.
- Evidence anchors:
  - [abstract]: "Automatic metrics show NLLB models outperform LLMs, especially for Aromanian translation, with ChrF++ scores around 50 for Aromanian-Romanian pairs versus below 40 for LLMs."
  - [section 5.1]: "we employ the GPT-4o model, in hopes of leveraging its extensive multilingual pre-training... However, GPT-4o is unable to produce translations into Aromanian."
  - [section 5.2]: "The NLLB tokenizer uses language tags... We expand the tokenizer vocabulary with the <rup_Latn> token for Aromanian."

### Mechanism 2
- Claim: Using a language-agnostic BERT Sentence Encoder (LaBSE) fine-tuned for Aromanian improves sentence alignment and evaluation accuracy.
- Mechanism: Fine-tuning LaBSE on Aromanian-Romanian and Aromanian-English pairs updates the embedding space to capture semantic similarities specific to Aromanian, enabling accurate alignment and evaluation.
- Core assumption: The contrastive loss during fine-tuning can effectively adjust the embedding space for Aromanian without overfitting.
- Evidence anchors:
  - [abstract]: "We introduce a suite of auxiliary tools, including a language-agnostic sentence embedding model for text mining and automated evaluation, complemented by a diacritics conversion system for different writing standards."
  - [section 4]: "The model is used in two ways: (1) to calculate the BERTScore (Zhang et al., 2020) and evaluate trained machine translation models... and (2) to mine and align sentences in parallel documents."

### Mechanism 3
- Claim: Quantizing the NLLB-600M model to 8-bit integers enables efficient CPU deployment with minimal performance loss.
- Mechanism: Integer quantization reduces memory usage and computational requirements while preserving model accuracy for inference tasks.
- Core assumption: The quantization process preserves the model's learned representations and does not introduce significant errors.
- Evidence anchors:
  - [section 7.1]: "We quantize the model using the ctranslate2 (Klein et al., 2020) engine to 8-bit integer weights... Regarding the performance loss typically associated with quantization, we observe minimal differences in the automatic metrics used."
  - [table 6]: "Differences between the quantized (INT8) and floating point 32 (FP32) versions of the fine-tuned NLLB 600M model, measured on the test split."

## Foundational Learning

- Concept: Transfer Learning
  - Why needed here: Aromanian is a low-resource language with limited parallel data, so leveraging knowledge from related languages (Romanian, English) is crucial for building effective translation models.
  - Quick check question: How does the similarity between Aromanian and Romanian facilitate knowledge transfer in pre-trained models?

- Concept: Contrastive Loss
  - Why needed here: Fine-tuning the LaBSE model requires a mechanism to learn embeddings that capture semantic similarities between Aromanian and other languages.
  - Quick check question: What role does the margin parameter play in the contrastive loss function during LaBSE fine-tuning?

- Concept: Quantization
  - Why needed here: Deploying the NLLB-600M model on CPU requires reducing its memory footprint and computational requirements without sacrificing translation quality.
  - Quick check question: How does 8-bit integer quantization affect the accuracy of machine translation models compared to floating-point operations?

## Architecture Onboarding

- Component map: Data Collection -> LaBSE Fine-tuning -> NLLB/LLM Fine-tuning -> Quantization -> Online System
- Critical path: Collect and align parallel corpus (79k sentence pairs) → Fine-tune LaBSE for Aromanian embeddings → Fine-tune NLLB-200 and LLMs for Aromanian translation → Quantize the best-performing model (NLLB-600M) → Deploy the online translation system
- Design tradeoffs:
  - Model size vs. translation quality: Smaller models (NLLB-600M) are faster and easier to deploy but may sacrifice some accuracy compared to larger models
  - Data quantity vs. quality: A larger corpus may improve translation quality but requires more resources to process and align
  - Orthography standardization: Converting to a single orthography (Cunia) simplifies training but may lose some linguistic nuances
- Failure signatures:
  - Poor translation quality: Indicates insufficient training data, inadequate model fine-tuning, or lack of similarity between Aromanian and the source languages
  - Slow inference: Suggests the need for model quantization or optimization
  - Diacritic conversion errors: Points to limitations in the n-gram-based conversion system
- First 3 experiments:
  1. Evaluate translation quality on a small held-out test set using automatic metrics (BLEU, ChrF++)
  2. Conduct human evaluation of machine-translated sentences for fluency, style, and meaning
  3. Measure inference speed and memory usage of the quantized NLLB-600M model on CPU

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of dialectal variation within Aromanian on machine translation quality, and how can models be adapted to handle multiple dialects effectively?
- Basis in paper: [explicit] The paper discusses the existence of multiple Aromanian varieties and dialects influenced by contact with Greek, Romanian, Turkish, Albanian, and South Slavic languages, and mentions that translation quality is biased towards certain varieties more than others.
- Why unresolved: The paper conducted human evaluation with only two native speakers from specific dialect backgrounds (Grǎmuştean and Cipan), and acknowledges that the model is biased to favor some Aromanian varieties more than others. A comprehensive evaluation across all major dialectal varieties was not possible due to limited access to speakers.
- What evidence would resolve it: A large-scale human evaluation involving native speakers from all major Aromanian dialectal varieties (Grǎmuştean, Cipan, Fãrşherot, Pindean, etc.) with systematic comparison of translation quality across dialects would provide conclusive evidence.

### Open Question 2
- Question: How does the inclusion of synthetic English data affect the quality of Aromanian translations, and what is the optimal strategy for incorporating synthetic data in low-resource language pairs?
- Basis in paper: [explicit] The paper notes that synthetic English translations were added to enable English-Aromanian translations, but acknowledges that the English sentences are machine-translated from Romanian and the results involving English should be taken with reservation.
- Why unresolved: The paper does not provide a systematic analysis of how translation errors in synthetic English data propagate through the training process and affect final translation quality, nor does it explore alternative strategies for incorporating English data.
- What evidence would resolve it: Controlled experiments comparing model performance with and without synthetic English data, and with different strategies for handling synthetic data (e.g., filtering low-quality translations, using synthetic data only for certain translation directions) would clarify the impact.

### Open Question 3
- Question: What is the long-term impact of machine translation systems on the preservation and evolution of endangered languages like Aromanian, particularly regarding the introduction of neologisms and dialectal homogenization?
- Basis in paper: [explicit] The paper mentions that machine translation systems generate neologisms derived from Romanian, even when established Aromanian terms exist, and raises concerns about representativeness and the introduction of bias through Romanian influence.
- Why unresolved: The paper does not address the broader sociolinguistic implications of introducing machine translation to an endangered language community, including potential effects on language use, dialectal diversity, and language preservation efforts.
- What evidence would resolve it: Longitudinal studies tracking language use patterns in the Aromanian community after introduction of machine translation tools, combined with sociolinguistic analysis of neologism adoption and dialectal variation in machine-generated texts versus human-written texts, would provide insights into the long-term impact.

## Limitations

- The parallel corpus comes primarily from literary and religious texts, raising questions about the model's performance on modern, colloquial, or domain-specific Aromanian content
- The decision to convert all texts to the Cunia orthography may not reflect how different Aromanian communities actually write, potentially limiting real-world usability
- Human evaluation was conducted on only 80 sentences across 3 language pairs, which may not be representative of the model's performance across diverse Aromanian content

## Confidence

- **High Confidence**: The finding that NLLB models outperform LLMs for Aromanian translation is well-supported by both automatic metrics and human evaluation. The performance gap (ChrF++ ~50 vs ~40) is substantial and consistent across evaluation methods.
- **Medium Confidence**: The claim that fine-tuning pre-trained multilingual models enables effective translation with limited data is plausible given the Romance language similarity, but the exact contribution of transfer learning versus the quality of the parallel corpus is difficult to disentangle.
- **Medium Confidence**: The assertion that quantized NLLB-600M achieves ~65 tokens/second on CPU is based on specific hardware and software configurations that may not generalize. The "minimal performance loss" claim relies on aggregate metrics that may mask quality degradation in specific linguistic phenomena.

## Next Checks

1. **Domain Expansion Test**: Evaluate the trained models on Aromanian texts from different domains (e.g., social media, news, technical documentation) to assess generalization beyond the literary corpus used in training.

2. **Orthography Robustness Test**: Evaluate translation quality when the model is presented with Aromanian text in different orthographies (not just Cunia) to determine if the single-orthography training limits real-world usability.

3. **Long-Form Translation Test**: Assess model performance on longer texts (paragraphs or documents) rather than sentence-level translation to identify any degradation in coherence, context preservation, or handling of complex discourse structures.