---
ver: rpa2
title: Diversity-Aware Agnostic Ensemble of Sharpness Minimizers
arxiv_id: '2403.13204'
source_url: https://arxiv.org/abs/2403.13204
tags:
- ensemble
- learning
- base
- deep
- learners
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes DASH Ensemble, a method for learning ensembles
  of diverse and sharpness-aware deep neural networks. The key idea is to encourage
  base learners to move divergently towards low-loss regions of minimal sharpness,
  thus improving ensemble generalization.
---

# Diversity-Aware Agnostic Ensemble of Sharpness Minimizers

## Quick Facts
- arXiv ID: 2403.13204
- Source URL: https://arxiv.org/abs/2403.13204
- Reference count: 40
- Primary result: Proposed DASH Ensemble achieves up to 6% improvement in ensemble accuracy over strong baselines on CIFAR-10/100 and Tiny-ImageNet

## Executive Summary
DASH Ensemble introduces a novel approach to ensemble learning that combines sharpness-aware minimization with an agnostic diversity-aware constraint. The method encourages base learners to explore diverse low-loss regions while maintaining minimal sharpness, resulting in improved generalization and robustness. By minimizing pairwise KL divergence among base learners, DASH promotes diversity while the sharpness-aware component ensures robust flat minima are found.

## Method Summary
DASH Ensemble trains multiple neural networks simultaneously using a combined objective that includes both sharpness-aware minimization (SAM) and an agnostic diversity-aware constraint based on KL divergence minimization. The diversity constraint encourages base learners to diverge while moving along low-loss directions, promoting exploration of different flat regions. The ensemble aggregates predictions through simple averaging, with the theoretical framework providing an upper bound on generalization loss that balances ensemble and individual learner sharpness.

## Key Results
- Achieves up to 6% improvement in ensemble accuracy over Deep Ensembles, SAM, and Fast Geometric Ensembles
- Improves uncertainty estimation with better Negative Log-Likelihood and Expected Calibration Error
- Enhances adversarial robustness compared to baseline ensemble methods
- Demonstrates effectiveness across CIFAR-10/100 and Tiny-ImageNet datasets with various architectures

## Why This Works (Mechanism)

### Mechanism 1
The ensemble generalization error can be bounded by the sharpness of both the ensemble model and its base learners. Theorem 1 provides an upper bound combining the sharpness of each base learner and the ensemble as a whole, with a trade-off coefficient γ controlling their relative contributions. This bound relies on convex loss functions and bounded perturbations.

### Mechanism 2
Promoting diversity among base learners prevents them from converging to the same flat region, improving ensemble performance. The agnostic diversity-aware constraint minimizes pairwise KL divergence among base learners, encouraging them to explore different low-loss regions. This diversity promotion is essential for the ensemble to capture multiple perspectives of the data distribution.

### Mechanism 3
The agnostic diversity-aware constraint interacts with the sharpness-aware minimization to guide base learners towards diverse low-loss regions. The constraint maximizes the alignment between the negative gradient of the loss and the gradient of the diversity term, encouraging base learners to diverge while moving along low-loss directions. This interaction is approximated through first-order Taylor expansion.

## Foundational Learning

- **Ensemble learning**: Combines multiple models to improve generalization, robustness, and uncertainty estimation. Why needed: To capture diverse perspectives and reduce individual model biases.
- **Sharpness-aware minimization**: Encourages models to find flat minima, which are more robust to shifts between training and testing sets. Why needed: To improve generalization by finding regions with uniformly low loss.
- **Kullback-Leibler divergence**: Measures the dissimilarity between probability distributions. Why needed: To quantify diversity between base learner predictions and promote exploration of different solutions.

## Architecture Onboarding

- **Component map**: Base learners -> Sharpness-aware minimization -> Diversity-aware constraint -> Ensemble aggregation
- **Critical path**: 1) Initialize base learners. 2) For each base learner, perform sharpness-aware minimization with diversity-aware constraint. 3) Aggregate predictions of base learners to form ensemble prediction.
- **Design tradeoffs**: Ensemble size vs. computational cost; Diversity vs. accuracy; Sharpness vs. diversity.
- **Failure signatures**: Low ensemble accuracy (poor collaboration), high uncertainty estimation error (poor calibration), low adversarial robustness (vulnerability to attacks).
- **First 3 experiments**: 1) Compare DASH with standard ensemble methods on CIFAR-10/100. 2) Evaluate the impact of the diversity-aware constraint on ensemble diversity and performance. 3) Analyze the effect of the trade-off coefficient γ on ensemble performance and uncertainty estimation.

## Open Questions the Paper Calls Out

### Open Question 1
How does the optimal value of γ in DASH vary across different architectures, datasets, and training conditions? The paper only tests γ values on one architecture and dataset combination, leaving open whether these findings generalize to other settings.

### Open Question 2
Can the DASH framework be extended to non-classification tasks such as regression or structured prediction? The paper focuses exclusively on classification tasks, but the theoretical framework could potentially apply to other tasks.

### Open Question 3
What is the computational trade-off between DASH and other ensemble methods, particularly regarding training time and memory usage? While DASH shows performance benefits, the additional diversity-aware constraint may introduce computational overhead that is not quantified.

## Limitations

- The theoretical generalization bound relies on strong convexity assumptions that may not hold for deep neural networks
- Empirical validation is limited to image classification tasks on CIFAR and Tiny-ImageNet
- The interaction between diversity and sharpness components relies on first-order Taylor expansion approximations
- Computational overhead relative to baseline methods is not explicitly quantified

## Confidence

- **High confidence**: Empirical results demonstrating DASH's superior performance over baseline ensemble methods on CIFAR-10/100 and Tiny-ImageNet datasets
- **Medium confidence**: Theoretical generalization bound provides valuable insight but depends on convexity assumptions
- **Medium confidence**: Mechanism by which diversity-aware constraint interacts with sharpness-aware minimization is conceptually sound but relies on approximations

## Next Checks

1. Test DASH on non-vision tasks (e.g., text classification, time series prediction) to assess generalizability beyond image data
2. Conduct ablation studies varying γ, ρ, and diversity temperature τ to identify optimal configurations and understand their impact
3. Evaluate DASH's performance and computational overhead on larger ensemble sizes and more complex architectures to determine practical limitations