---
ver: rpa2
title: Open-World Semi-Supervised Learning for Node Classification
arxiv_id: '2403.11483'
source_url: https://arxiv.org/abs/2403.11483
tags:
- classes
- novel
- seen
- learning
- open-world
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses open-world semi-supervised learning (Open-world
  SSL) for node classification, which aims to classify unlabeled nodes into seen classes
  or multiple novel classes. The authors propose an IMbalance-Aware method called
  OpenIMA to tackle the variance imbalance issue between seen and novel classes in
  the embedding space.
---

# Open-World Semi-Supervised Learning for Node Classification

## Quick Facts
- arXiv ID: 2403.11483
- Source URL: https://arxiv.org/abs/2403.11483
- Reference count: 40
- Primary result: Proposes OpenIMA method achieving 11.8% and 12.5% gains in overall accuracy on Coauthor Physics and ogbn-Products respectively

## Executive Summary
This paper addresses the challenge of open-world semi-supervised learning for node classification, where a model must classify unlabeled nodes into seen classes or multiple novel classes. The authors identify variance imbalance between seen and novel classes in the embedding space as a critical issue that degrades performance on novel classes. To tackle this, they propose OpenIMA, a method that trains from scratch using contrastive learning with bias-reduced pseudo labels generated through unsupervised clustering.

## Method Summary
OpenIMA employs a two-stage approach: first learning node representations using a Graph Attention Network (GAT) and then clustering all nodes (labeled and unlabeled) to generate pseudo labels. High-confidence pseudo labels are filtered and used in contrastive learning alongside manual labels. The method optimizes node representations using both InfoNCE loss (for unlabeled nodes) and cross-entropy loss (for labeled nodes), effectively reducing intra-class variance of novel classes while enhancing learning of seen classes. The number of clusters is set to the total number of classes (seen plus novel).

## Key Results
- OpenIMA achieves 11.8% and 12.5% gains in overall accuracy on Coauthor Physics and ogbn-Products respectively compared to best baseline
- The method effectively mitigates variance imbalance between seen and novel classes
- Extensive experiments on seven popular graph benchmarks demonstrate consistent improvements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contrastive learning with bias-reduced pseudo labels can effectively mitigate the variance imbalance between seen and novel classes without requiring pre-trained graph encoders.
- Mechanism: By clustering node representations and using high-confidence pseudo labels to define positive pairs in contrastive learning, the method reduces intra-class variance of novel classes and enhances learning of seen classes simultaneously.
- Core assumption: Unlabeled nodes of novel classes can be effectively grouped into meaningful clusters that capture semantic similarity, and these clusters can be leveraged to guide contrastive learning.
- Evidence anchors:
  - [abstract] "OpenIMA trains the node classification model from scratch via contrastive learning with bias-reduced pseudo labels."
  - [section] "We introduce pseudo labels to reduce the intra-class variances of novel classes and enhance the learning of seen classes."
- Break condition: If the clustering quality is poor (low silhouette coefficient) or the pseudo labels contain too much noise, contrastive learning will reinforce incorrect semantic groupings, leading to degraded performance.

### Mechanism 2
- Claim: The imbalance rate (ratio of intra-class variances between seen and novel classes) is a critical factor that negatively impacts classification accuracy on novel classes.
- Mechanism: When seen classes are better learned than novel classes, their representations have smaller intra-class variance. This creates a separation in the embedding space that makes it harder to correctly cluster novel class nodes.
- Core assumption: The quality of representation learning directly determines the separability and compactness of class clusters in the embedding space.
- Evidence anchors:
  - [section] "Based on empirical and theoretical analysis, we find the variance imbalance can negatively impact the model performance."
  - [section] "We find that the imbalance of intra-class variances between seen and novel classes is a critical factor that impacts open-world SSL on a graph."
- Break condition: If the representation learning becomes highly effective for both seen and novel classes (lowering the imbalance rate), the negative impact on novel class accuracy diminishes.

### Mechanism 3
- Claim: Two-stage training (representation learning followed by clustering-based classification) reduces bias compared to end-to-end methods when pre-trained encoders are unavailable.
- Mechanism: By decoupling representation learning from the classification task, the method avoids forcing the model to prematurely commit to seen class boundaries, allowing more flexible cluster formation for novel classes.
- Core assumption: Non-parametric clustering algorithms like K-Means can better adapt to the data distribution when applied to high-quality representations, compared to learned parametric classifiers.
- Evidence anchors:
  - [section] "Inspired by this, we will follow the two-stage design."
  - [section] "The two-stage methods have been demonstrated to reduce the bias."
- Break condition: If the learned representations are of insufficient quality (poor separation between classes), the clustering step will fail regardless of the two-stage approach.

## Foundational Learning

- Concept: Contrastive learning (CL)
  - Why needed here: To learn meaningful representations without relying on manual labels, especially for novel classes.
  - Quick check question: What distinguishes a positive pair from a negative pair in contrastive learning?

- Concept: Intra-class variance
  - Why needed here: The imbalance of intra-class variance between seen and novel classes is the core problem being addressed.
  - Quick check question: How does intra-class variance affect the compactness of clusters in the embedding space?

- Concept: K-Means clustering
  - Why needed here: To generate pseudo labels by grouping nodes based on their learned representations.
  - Quick check question: What is the effect of the number of clusters on the quality of pseudo labels?

## Architecture Onboarding

- Component map: Graph Encoder (GAT) -> Clustering Module -> Bias-Reduced Pseudo Label Generator -> Contrastive Learning Module -> Classification Head

- Critical path:
  1. Encode graph to obtain initial node representations
  2. Cluster all nodes (labeled + unlabeled) to generate pseudo labels
  3. Filter high-confidence pseudo labels for unlabeled nodes
  4. Train encoder using contrastive loss with both manual and pseudo labels
  5. Evaluate by clustering test representations and aligning with ground truth

- Design tradeoffs:
  - Using K-Means vs. parametric clustering: K-Means is unsupervised and avoids bias toward seen classes but requires specifying the number of clusters.
  - Including CE loss vs. only contrastive loss: CE helps learn seen classes faster but may increase bias; contrastive loss is more balanced but slower.
  - Filtering pseudo labels vs. using all: Filtering reduces noise but may discard useful information; using all risks reinforcing errors.

- Failure signatures:
  - Low silhouette coefficient on validation set: Clustering quality is poor, likely leading to noisy pseudo labels.
  - High accuracy on seen classes but low on novel classes: Model is overfitting to seen classes (variance imbalance not mitigated).
  - Accuracy drops when increasing pseudo label selection rate: Too much noise in pseudo labels is harming training.

- First 3 experiments:
  1. Train with only InfoNCE (no pseudo labels) to establish baseline performance.
  2. Train with InfoNCE + pseudo labels but without filtering to see effect of unfiltered pseudo labels.
  3. Train with InfoNCE + filtered pseudo labels to measure impact of bias reduction.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the variance imbalance between seen and novel classes specifically impact model performance in open-world SSL for node classification?
- Basis in paper: [explicit] The paper states that variance imbalance negatively impacts model performance and provides theoretical analysis on this relationship.
- Why unresolved: While the paper provides empirical and theoretical analysis, the exact mechanisms and extent of the impact are not fully explored.
- What evidence would resolve it: Detailed experimental results showing model performance under varying levels of variance imbalance, and theoretical models quantifying the relationship.

### Open Question 2
- Question: Can the proposed OpenIMA method be effectively extended to handle scenarios where the number of novel classes is unknown?
- Basis in paper: [explicit] The paper mentions that the number of novel classes is treated as a hyperparameter and provides initial exploration, but acknowledges this as an area for future work.
- Why unresolved: The current method requires an estimate of the number of novel classes, which may not always be available in real-world scenarios.
- What evidence would resolve it: Experiments demonstrating OpenIMA's performance on datasets with varying and unknown numbers of novel classes, and development of methods to automatically determine the number of novel classes.

### Open Question 3
- Question: How does the performance of OpenIMA compare to other open-world SSL methods when applied to different types of graph data with varying characteristics?
- Basis in paper: [inferred] The paper mentions that different types of graphs have distinct data distributions, implying potential challenges in applying open-world SSL methods across different graph types.
- Why unresolved: The experiments in the paper focus on specific graph datasets, and the generalizability of OpenIMA to diverse graph types is not fully explored.
- What evidence would resolve it: Extensive experiments on a wide range of graph datasets with different characteristics, comparing OpenIMA's performance to other open-world SSL methods.

## Limitations
- Scalability concerns with clustering step for large graphs with millions of nodes
- Hyperparameter sensitivity requiring careful tuning of cluster count, confidence thresholds, and loss weighting
- Assumption that novel classes are well-separated from seen classes in embedding space

## Confidence

- **High Confidence**: The claim that variance imbalance between seen and novel classes negatively impacts novel class accuracy is well-supported by empirical evidence and theoretical reasoning. The ablation studies showing performance degradation when this imbalance exists provide strong validation.

- **Medium Confidence**: The assertion that contrastive learning with bias-reduced pseudo labels effectively mitigates variance imbalance is supported by experimental results but could benefit from more rigorous theoretical justification. The mechanism by which clustering-generated pseudo labels specifically address the variance imbalance issue could be more thoroughly explained.

- **Medium Confidence**: The claim that two-stage training reduces bias compared to end-to-end methods is plausible given the evidence but lacks direct comparative experiments against end-to-end alternatives that might also address the variance imbalance problem.

## Next Checks

1. **Scalability Validation**: Evaluate OpenIMA on graphs with 100K+ nodes to quantify the computational overhead of the clustering step and assess whether the method remains practical for large-scale applications. Measure both runtime and memory consumption relative to single-stage alternatives.

2. **Overlap Robustness Test**: Construct synthetic datasets where novel classes partially overlap with seen classes or with each other. Measure how OpenIMA's performance degrades under these conditions compared to baselines, and whether the clustering quality (silhouette coefficient) correlates with final accuracy.

3. **End-to-End Comparison**: Implement an end-to-end alternative that addresses variance imbalance through architectural modifications (e.g., class-conditional batch normalization or adaptive margin losses) rather than two-stage clustering. Compare performance, training time, and sensitivity to hyperparameters against OpenIMA to determine whether the two-stage approach is truly necessary or optimal.