---
ver: rpa2
title: 'Conformalized-DeepONet: A Distribution-Free Framework for Uncertainty Quantification
  in Deep Operator Networks'
arxiv_id: '2402.15406'
source_url: https://arxiv.org/abs/2402.15406
tags:
- deeponet
- dence
- intervals
- conformal
- coverage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses uncertainty quantification (UQ) in Deep Operator
  Networks (DeepONet) by integrating conformal prediction to generate rigorous confidence
  intervals with coverage guarantees. The authors propose three main contributions:
  1) applying split conformal prediction to enhance existing UQ frameworks (B-DeepONet
  and Prob-DeepONet), 2) introducing a novel Quantile-DeepONet that naturally integrates
  with split conformal prediction, and 3) demonstrating effectiveness through multiple
  experiments.'
---

# Conformalized-DeepONet: A Distribution-Free Framework for Uncertainty Quantification in Deep Operator Networks

## Quick Facts
- arXiv ID: 2402.15406
- Source URL: https://arxiv.org/abs/2402.15406
- Authors: Christian Moya; Amirhossein Mollaali; Zecheng Zhang; Lu Lu; Guang Lin
- Reference count: 40
- Primary result: Achieves 94-97% coverage rates across multiple operator learning problems using conformal prediction

## Executive Summary
This paper addresses the challenge of uncertainty quantification in Deep Operator Networks (DeepONet) by integrating conformal prediction, a distribution-free framework that provides rigorous coverage guarantees. The authors propose three main contributions: applying split conformal prediction to enhance existing UQ frameworks (B-DeepONet and Prob-DeepONet), introducing a novel Quantile-DeepONet that naturally integrates with split conformal prediction, and demonstrating effectiveness through multiple experiments. The proposed methods successfully achieve average coverage rates of 94-97% (with α=0.05) across nonlinear pendulum, diffusion-reaction, and viscous Burgers' equation problems, while baseline methods without conformalization show significantly lower coverage (3-83%). The framework is also shown to extend to multi-fidelity settings and provides adaptive confidence intervals that reduce over-confidence issues.

## Method Summary
The method combines DeepONet architectures with split conformal prediction to generate confidence intervals with coverage guarantees. Three approaches are proposed: conformalized B-DeepONet, conformalized Prob-DeepONet, and Quantile-DeepONet with conformal prediction. The framework uses calibration data to compute empirical quantiles of a score function (absolute error normalized by predicted uncertainty), then applies this quantile as a correction factor to construct prediction intervals. Training uses Adam optimizer with learning rate 10^-3, and datasets consist of triplets (u_hat, x, G) where G(u)(x) is the target operator. The method is tested on nonlinear pendulum, diffusion-reaction, and viscous Burgers' equation problems with varying dataset sizes.

## Key Results
- Achieved average coverage rates of 94-97% across all tested operator learning problems with α=0.05
- Baseline methods without conformalization showed coverage rates of only 3-83%, demonstrating the effectiveness of the approach
- Quantile-DeepONet naturally integrates with split conformal prediction, providing more reliable intervals than B- and Prob-DeepONet variants
- The framework extends to multi-fidelity settings, reducing computational costs while maintaining coverage guarantees

## Why This Works (Mechanism)

### Mechanism 1
Split conformal prediction provides rigorous coverage guarantees for DeepONet outputs without distributional assumptions. The method uses a calibration set to compute empirical quantiles of a score function (absolute error normalized by predicted uncertainty), then applies this quantile as a correction factor to construct prediction intervals that satisfy coverage probability. Core assumption: The calibration data follows the same distribution as the test data (exchangeability). Break condition: If the calibration and test data distributions differ (violating exchangeability), coverage guarantees fail.

### Mechanism 2
Quantile-DeepONet naturally integrates with conformal prediction by directly modeling conditional quantiles rather than uncertainty. Quantile-DeepONet learns α/2 and 1−α/2 quantiles using pinball loss, providing interval bounds that are then corrected by split conformal prediction to ensure coverage. Core assumption: The quantile estimates from Quantile-DeepONet are consistent estimators of the true conditional quantiles. Break condition: If Quantile-DeepONet fails to learn accurate quantiles (e.g., due to insufficient training data or poor architecture), the resulting intervals will be invalid even after conformal correction.

### Mechanism 3
Combining conformal prediction with existing UQ frameworks (B-DeepONet, Prob-DeepONet) transforms heuristic uncertainty estimates into rigorous confidence intervals. The baseline methods provide initial uncertainty estimates (σ or ensemble-based), which serve as the denominator in the conformal score function. Split conformal prediction then corrects these estimates to achieve desired coverage. Core assumption: The baseline uncertainty estimates (σ or ensemble variance) are positively correlated with true prediction error. Break condition: If the baseline uncertainty estimates are uncorrelated with actual error (e.g., systematic bias), the conformal correction cannot achieve proper coverage.

## Foundational Learning

- **Concept**: Exchangeability and i.i.d. assumptions in conformal prediction
  - Why needed here: These assumptions justify using a calibration set to compute quantiles that will generalize to test data
  - Quick check question: What happens to coverage guarantees if the calibration data comes from a different distribution than the test data?

- **Concept**: Quantile regression and pinball loss
  - Why needed here: Quantile-DeepONet uses these to directly estimate conditional quantiles rather than uncertainty measures
  - Quick check question: How does the pinball loss function differ from standard MSE, and why is it appropriate for quantile estimation?

- **Concept**: Operator learning and function spaces
  - Why needed here: DeepONet maps between function spaces (U → V), and understanding this is crucial for interpreting coverage guarantees
  - Quick check question: In the context of DeepONet, what does it mean for a confidence interval to "cover" the operator target G?

## Architecture Onboarding

- **Component map**: Input functions → Branch network (coefficients b_k) → Trunk network (basis functions τ_k) → Output predictions → Conformal wrapper (calibration, score computation, quantile adjustment)

- **Critical path**: Training → Calibration → Coverage validation
  1. Train base DeepONet or Quantile-DeepONet
  2. Use calibration set to compute conformal quantile
  3. Apply quantile correction to generate prediction intervals
  4. Validate coverage on test set

- **Design tradeoffs**:
  - Using Prob-DeepONet vs Quantile-DeepONet: Prob-DeepONet may be more stable but less natural for conformal correction; Quantile-DeepONet directly estimates what conformal prediction needs
  - Calibration set size: Larger n provides better quantile estimates but increases computational cost
  - Architecture depth/width: Deeper networks may capture more complex operator behavior but risk overfitting

- **Failure signatures**:
  - Coverage consistently below 1−α: Indicates violation of exchangeability or poor base model uncertainty estimates
  - Extremely wide intervals: Suggests base model is underconfident or calibration set is too small
  - Coverage much higher than 1−α: Indicates base model is overconfident or calibration set is too large

- **First 3 experiments**:
  1. Implement conformalized Prob-DeepONet on a simple 1D operator (e.g., mapping u(t) to u'(t)) and verify coverage
  2. Compare Prob-DeepONet vs Quantile-DeepONet coverage on a nonlinear pendulum example
  3. Test sensitivity to calibration set size by varying n and measuring coverage distribution

## Open Questions the Paper Calls Out

### Open Question 1
How can conformalized-DeepONets be adapted for settings where exchangeability and i.i.d. assumptions do not hold, such as in DeepONet extrapolation or non-autonomous systems? The paper explicitly states this as a future research direction, noting that these settings violate the i.i.d. assumption required for standard conformal prediction, requiring new theoretical frameworks and methodologies.

### Open Question 2
What is the optimal balance between calibration dataset size and coverage performance for conformalized-DeepONets across different problem types? While the paper shows that n > 500 is generally sufficient for good coverage, the optimal size likely depends on problem complexity, noise levels, and DeepONet architecture, requiring systematic experiments across diverse PDE problems.

### Open Question 3
How does the combination of conformal prediction with Multi-Fidelity DeepONets perform in real-world applications beyond the 1D jump function example? The 1D jump function is a simplified test case; real-world multi-fidelity scenarios involve more complex dynamics and higher-dimensional inputs, requiring applications to problems like subsurface flow, weather prediction, or power grid modeling.

## Limitations
- The exchangeability assumption required for conformal coverage guarantees may not hold in practice, particularly when test data differs from calibration data in distribution
- The effectiveness of Quantile-DeepONet depends on the quality of quantile estimates, which may degrade with limited training data or complex operator behaviors
- Baseline uncertainty estimates must be positively correlated with true error for conformal correction to work effectively

## Confidence
- **High confidence** in the theoretical framework and Theorem 3.1 coverage guarantee (empirical validation across multiple experiments)
- **Medium confidence** in the practical implementation details and hyperparameter choices (some specifics not fully specified)
- **Low confidence** in generalizability beyond the specific operator learning problems tested (pendulum, diffusion-reaction, viscous Burgers' equation)

## Next Checks
1. Test coverage guarantees on operator learning problems with known distributional shifts between calibration and test sets to assess robustness to exchangeability violations
2. Perform ablation studies varying calibration set size n to determine the minimum sample size needed for reliable quantile estimation
3. Apply the framework to operator learning problems with discontinuous or multi-modal solutions to evaluate performance on challenging function spaces