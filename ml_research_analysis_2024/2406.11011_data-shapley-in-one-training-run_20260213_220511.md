---
ver: rpa2
title: Data Shapley in One Training Run
arxiv_id: '2406.11011'
source_url: https://arxiv.org/abs/2406.11011
tags:
- data
- shapley
- training
- in-run
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: In-Run Data Shapley enables efficient, targeted data attribution
  for specific trained models without costly retraining. By leveraging Taylor expansion
  and "ghost" techniques for gradient dot-products and gradient-Hessian-gradient products,
  it computes data contributions across training iterations with negligible overhead.
---

# Data Shapley in One Training Run

## Quick Facts
- arXiv ID: 2406.11011
- Source URL: https://arxiv.org/abs/2406.11011
- Authors: Jiachen T. Wang; Prateek Mittal; Dawn Song; Ruoxi Jia
- Reference count: 40
- One-line primary result: In-Run Data Shapley enables efficient, targeted data attribution for specific trained models without costly retraining.

## Executive Summary
In-Run Data Shapley introduces a method to compute data attribution scores during a single training run, avoiding the need for expensive retraining across multiple model variants. By leveraging Taylor expansion and "ghost" techniques for gradient computations, it efficiently estimates Shapley values that quantify each data source's contribution to a specific trained model. Experiments demonstrate that first-order In-Run Data Shapley matches Monte Carlo estimates with RMSE ≈ 0.0003 while running at near-regular training speed, enabling practical attribution for large-scale models.

## Method Summary
In-Run Data Shapley computes data attribution during training by approximating local utility functions using Taylor expansion of per-iteration validation loss changes. The method uses "ghost" techniques to efficiently compute gradient dot-products and gradient-Hessian-gradient products without instantiating per-sample gradients. First-order and second-order approximations provide different tradeoffs between accuracy and computational cost. The utility functions incorporate the specific random batch selection at each iteration, enabling attribution to the exact trained model rather than expected values across random seeds.

## Key Results
- First-order In-Run Data Shapley matches Monte Carlo estimates (RMSE ≈ 0.0003) and runs at near-regular training speed
- Second-order In-Run Data Shapley adds only ~2× overhead compared to first-order
- Applied to GPT2 and Pythia-410M on Pile, reveals 16% of well-curated data has negative impact
- Shows training data contributes even to paraphrased validation examples, challenging conventional copyright assumptions

## Why This Works (Mechanism)

### Mechanism 1
Taylor expansion approximates the utility function that measures validation loss change within a single iteration. First- and second-order expansions yield closed-form Shapley values computable from gradients and Hessians. Core assumption: Model performance change within a single iteration is small enough for Taylor expansion to be accurate. Evidence: Abstract states "model performance change in one iteration is sufficiently small to be accurately approximated by first- or second-order Taylor expansions." Break condition: If learning rate becomes too large, Taylor approximation errors would grow beyond acceptable bounds.

### Mechanism 2
Ghost dot-product and ghost gradient-Hessian-gradient product techniques enable efficient computation without instantiating per-sample gradients. By exploiting chain rule decompositions in backpropagation, gradient dot-products between any two samples can be computed from already-available quantities. Core assumption: Gradients and activations from a single backpropagation contain all necessary information for computing pairwise gradient interactions. Evidence: Section 4.2 demonstrates this technique using a simple linear layer, showing how to compute gradient dot-products efficiently. Break condition: If network architecture has complex operations not amenable to these decompositions, the technique would fail.

### Mechanism 3
Data Shapley values computed during training directly measure contribution to the specific trained model rather than expected contribution across random seeds. By defining utility functions that incorporate the specific random batch selection at each iteration, In-Run Data Shapley captures the exact training trajectory and randomness realization. Core assumption: Training process has sufficient deterministic structure within each iteration that local utility function captures meaningful contribution information. Evidence: Abstract states "In-Run Data Shapley quantifies the contribution of each data source to the specific target model of interest." Break condition: If model training is too stochastic or utility function is poorly defined, attribution may not capture meaningful contributions.

## Foundational Learning

- **Taylor series approximation**
  - Why needed here: Provides tractable approximation of local utility function U(t) that enables closed-form Shapley value computation
  - Quick check question: What is the error order of a second-order Taylor approximation when learning rate is η? (Answer: O(η³))

- **Shapley value axioms (null player, symmetry, linearity, efficiency)**
  - Why needed here: These properties ensure attribution scores are fair, additive, and interpretable as shares of total utility
  - Quick check question: Which Shapley value axiom guarantees that sum of individual contributions equals total loss reduction? (Answer: Efficiency)

- **Chain rule in backpropagation**
  - Why needed here: Enables "ghost" techniques by showing how individual gradients can be decomposed from aggregated gradients
  - Quick check question: In linear layer s = aW, how is individual gradient ∂ℓ(i)/∂W related to batch gradient ∂ℓ/∂s(i)? (Answer: ∂ℓ(i)/∂W = ∂ℓ/∂s(i) ⊗ a(i))

## Architecture Onboarding

- **Component map**: Training loop (PyTorch/NanoGPT adapted) -> Utility computation module (Taylor expansion + Shapley formula) -> Ghost computation module (dot-product and Hessian-vector products) -> Checkpoint/saving mechanism for intermediate values

- **Critical path**: 1) Forward pass with validation data included 2) Backward pass computing gradients and output gradients 3) Ghost dot-product computation for first-order values 4) Optional second backward pass for second-order interaction terms 5) Accumulate Shapley values across iterations

- **Design tradeoffs**: First-order vs second-order: accuracy vs computational cost (2× slower); Memory vs speed: storing intermediate gradients vs recomputing; Model compatibility: techniques work best with standard layers but may need adaptation for custom ops

- **Failure signatures**: Runtime becomes 2× slower than expected: second-order computation not properly optimized; NaN values in dot-products: gradient clipping or numerical instability in utility computation; Inconsistent values across runs: utility function not properly incorporating batch selection randomness

- **First 3 experiments**: 1) Verify ghost dot-product correctness: compare against naive per-sample gradient computation on simple linear model 2) Validate Taylor approximation: measure correlation between exact U(t) and approximations at different learning rates 3) Test efficiency: measure runtime overhead of first-order In-Run Data Shapley vs regular training on GPT2-small

## Open Questions the Paper Calls Out

### Open Question 1
How would In-Run Data Shapley perform on extremely large-scale foundation models (e.g., GPT-4, Gemini) with sufficient computational resources? The authors note their approach is applicable to larger-scale industrial models with adequate computing resources, but most experiments focus on GPT-2 and Pythia-410M due to resource limitations. The computational feasibility and accuracy on truly large-scale models remains untested.

### Open Question 2
Can the "ghost" techniques be extended to support adaptive optimizers like Adam beyond SGD? The authors acknowledge this as a limitation, stating that extending the "ghost" family techniques to support Adam and similar optimizers remains an exciting direction for future research. The normalization terms in adaptive optimizers create computational challenges that prevent straightforward extension of these techniques.

### Open Question 3
How sensitive is In-Run Data Shapley to the choice of validation data, and what constitutes a representative validation set for pretraining attribution? The method requires validation data to be available before training, but the paper acknowledges that choosing an appropriate validation set for pretraining (which typically lacks explicit labels) remains challenging.

## Limitations

- Method assumes Taylor expansions remain accurate throughout training, which may break down for large learning rates or later training stages where utility functions become non-linear
- "Ghost" techniques rely on specific layer structures and may not generalize to custom operations or highly non-linear architectures
- Memory overhead from storing intermediate gradients could be prohibitive for very large models

## Confidence

- **High Confidence**: First-order In-Run Data Shapley efficiency and correlation with Monte Carlo estimates (RMSE ≈ 0.0003), demonstrated across multiple model sizes and datasets
- **Medium Confidence**: Second-order approximation accuracy and its added value, based on controlled experiments with simplified models and synthetic data
- **Low Confidence**: Generalization to highly non-linear architectures, memory efficiency for massive models, and behavior under extreme learning rates or batch sizes

## Next Checks

1. **Scale Test**: Implement In-Run Data Shapley on a 7B parameter model with gradient checkpointing to measure actual memory overhead and verify scalability claims
2. **Robustness Test**: Systematically vary learning rates (0.0001 to 0.1) during training to identify at which point Taylor approximations break down and measure resulting attribution errors
3. **Architectural Generalization Test**: Apply the method to models with attention mechanisms, MLPs, and residual connections to verify that "ghost" techniques work across diverse layer types without modification