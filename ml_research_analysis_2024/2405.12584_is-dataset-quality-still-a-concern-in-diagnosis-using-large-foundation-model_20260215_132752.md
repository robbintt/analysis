---
ver: rpa2
title: Is Dataset Quality Still a Concern in Diagnosis Using Large Foundation Model?
arxiv_id: '2405.12584'
source_url: https://arxiv.org/abs/2405.12584
tags: []
core_contribution: This paper investigates whether large foundation models (LFMs)
  are robust to dataset quality issues such as image degradation and dataset bias
  in fundus disease diagnosis tasks. The authors evaluate RETFound, a pretrained LFM
  for retinal images, on two datasets (EyeQ and iSee) with varying image qualities
  and disease class distributions.
---

# Is Dataset Quality Still a Concern in Diagnosis Using Large Foundation Model?

## Quick Facts
- arXiv ID: 2405.12584
- Source URL: https://arxiv.org/abs/2405.12584
- Reference count: 17
- Key outcome: LFMs show greater robustness to dataset quality issues compared to smaller models, but fine-tuning strategies are crucial for optimal performance.

## Executive Summary
This paper investigates whether large foundation models (LFMs) are robust to dataset quality issues such as image degradation and dataset bias in fundus disease diagnosis tasks. The authors evaluate RETFound, a pretrained LFM for retinal images, on two datasets (EyeQ and iSee) with varying image qualities and disease class distributions. Key findings include: (1) RETFound is more resilient to image quality degradation compared to ResNet, with performance declining less as image quality decreases. (2) Dataset bias impacts RETFound's performance, with classes having lower proportions in the training data showing poorer performance, especially under image degradation. (3) Overall fine-tuning of RETFound is effective in mitigating the impact of dataset quality issues, outperforming linear probing and Tip-Adapter-based fine-tuning techniques. The study concludes that LFMs exhibit greater robustness to dataset quality challenges compared to smaller models, but fine-tuning strategies are crucial to further improve their performance.

## Method Summary
The authors evaluate RETFound, a pretrained LFM for retinal images, on two datasets (EyeQ and iSee) with varying image qualities and disease class distributions. They compare RETFound's performance to ResNet, a smaller model, across different quality subsets and tasks. The study also investigates the impact of three fine-tuning techniques (linear probe, overall fine-tuning, and Tip-Adapter) on mitigating the effects of dataset quality issues. Performance is assessed using metrics such as AUC, sensitivity, and specificity.

## Key Results
- RETFound is more resilient to image quality degradation compared to ResNet, with performance declining less as image quality decreases.
- Dataset bias impacts RETFound's performance, with classes having lower proportions in the training data showing poorer performance, especially under image degradation.
- Overall fine-tuning of RETFound is effective in mitigating the impact of dataset quality issues, outperforming linear probing and Tip-Adapter-based fine-tuning techniques.

## Why This Works (Mechanism)
None provided in the input.

## Foundational Learning
- Large foundation models (LFMs): Pretrained models with a large number of parameters that can be fine-tuned for specific tasks.
  - Why needed: LFMs have shown promising results in various domains, including medical imaging, due to their ability to capture rich semantic information.
  - Quick check: Evaluate the performance of other state-of-the-art LFMs (e.g., CLIP, Florence) on fundus disease diagnosis tasks.

- Dataset quality issues: Problems in the training data that can affect model performance, such as image degradation and dataset bias.
  - Why needed: Real-world medical datasets often suffer from quality issues, which can impact the reliability and generalizability of deep learning models.
  - Quick check: Assess the impact of dataset quality issues on model interpretability and explainability using techniques like saliency maps or attention visualization.

- Fine-tuning techniques: Methods to adapt pretrained models to specific tasks by updating model parameters.
  - Why needed: Fine-tuning allows LFMs to leverage their pretrained knowledge while adapting to the target domain and task.
  - Quick check: Investigate the impact of different fine-tuning techniques (e.g., linear probing, overall fine-tuning, Tip-Adapter) on model performance under various dataset quality conditions.

## Architecture Onboarding
- Component map: Input image -> Feature extraction (LFM) -> Classification head -> Output predictions
- Critical path: Image preprocessing -> LFM feature extraction -> Fine-tuning -> Performance evaluation
- Design tradeoffs: Larger models (LFMs) offer better generalization but require more computational resources compared to smaller models (e.g., ResNet).
- Failure signatures: Poor performance on low-quality images or underrepresented classes may indicate sensitivity to dataset quality issues.
- Three first experiments:
  1. Evaluate the robustness of other state-of-the-art LFMs (e.g., CLIP, Florence) to dataset quality issues in fundus disease diagnosis tasks.
  2. Investigate the impact of dataset quality issues on model interpretability and explainability using techniques like saliency maps or attention visualization.
  3. Assess the potential for LFMs to amplify existing biases in the data by evaluating their performance across different demographic subgroups within the datasets.

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How do specific fine-tuning techniques like Tip-Adapter and Linear Probe compare to overall fine-tuning in mitigating the impact of dataset quality issues on LFMs?
- Basis in paper: [explicit] The paper evaluates three fine-tuning techniques (linear probe, overall fine-tuning, and Tip-Adapter) on RETFound and finds that overall fine-tuning performs better than the other two methods. However, it does not provide a detailed comparison of the performance of these techniques across different quality subsets and tasks.
- Why unresolved: The paper mentions the performance of different fine-tuning techniques but does not provide a comprehensive analysis of how each technique performs under various dataset quality conditions and tasks.
- What evidence would resolve it: A detailed comparative analysis of the performance of different fine-tuning techniques across various quality subsets and tasks would help resolve this question.

### Open Question 2
- Question: Can the impact of dataset bias on LFMs be mitigated by balancing the dataset proportions, and how does this affect the model's performance under image degradation?
- Basis in paper: [inferred] The paper suggests that dataset bias affects the performance of RETFound, with classes having lower proportions showing poorer performance, especially under image degradation. It implies that balancing dataset proportions could mitigate these impacts, but does not explicitly test this hypothesis.
- Why unresolved: The paper identifies the impact of dataset bias but does not explore whether balancing the dataset proportions can effectively mitigate this issue and improve model performance under image degradation.
- What evidence would resolve it: Experimental results showing the performance of LFMs on balanced datasets versus imbalanced datasets, particularly under conditions of image degradation, would provide evidence to resolve this question.

### Open Question 3
- Question: What specific architectural or algorithmic modifications to LFMs could enhance their robustness to dataset quality issues, such as image degradation and dataset bias?
- Basis in paper: [inferred] The paper discusses the resilience of LFMs to dataset quality issues compared to smaller models but does not explore potential architectural or algorithmic modifications that could further enhance this robustness.
- Why unresolved: While the paper demonstrates the relative robustness of LFMs, it does not investigate specific modifications that could improve their performance in handling dataset quality issues.
- What evidence would resolve it: Research and experimental results on architectural or algorithmic changes to LFMs, such as attention mechanisms or data augmentation techniques, that improve their performance on low-quality or biased datasets would help resolve this question.

## Limitations
- The study focuses on a single pretrained LFM (RETFound) and two specific fundus datasets (EyeQ and iSee), which may limit generalizability to other LFMs or imaging modalities.
- The evaluation metrics used (AUC, sensitivity, specificity) may not fully capture clinical utility or real-world performance.
- The paper does not explore the impact of dataset quality issues on model interpretability or explainability.

## Confidence
- High: LFMs are more resilient to image quality degradation compared to smaller models like ResNet.
- Medium: Dataset bias impacts LFMs' performance, with lower-performing classes being more affected by image degradation.
- Medium: Fine-tuning strategies, particularly full fine-tuning, are effective in mitigating the impact of dataset quality issues on LFMs.

## Next Checks
1. Evaluate the robustness of other state-of-the-art LFMs (e.g., CLIP, Florence) to dataset quality issues in fundus disease diagnosis tasks.
2. Investigate the impact of dataset quality issues on model interpretability and explainability using techniques like saliency maps or attention visualization.
3. Assess the potential for LFMs to amplify existing biases in the data by evaluating their performance across different demographic subgroups within the datasets.