---
ver: rpa2
title: HW-SW Optimization of DNNs for Privacy-preserving People Counting on Low-resolution
  Infrared Arrays
arxiv_id: '2402.01226'
source_url: https://arxiv.org/abs/2402.01226
tags:
- people
- memory
- counting
- energy
- dnns
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a full-stack optimization flow for DNNs applied
  to privacy-preserving people counting using low-resolution IR sensors. The approach
  combines neural architecture search, mixed-precision quantization, and post-processing
  to achieve highly efficient DNNs tailored for edge deployment.
---

# HW-SW Optimization of DNNs for Privacy-preserving People Counting on Low-resolution Infrared Arrays

## Quick Facts
- arXiv ID: 2402.01226
- Source URL: https://arxiv.org/abs/2402.01226
- Reference count: 27
- One-line primary result: DNNs optimized for privacy-preserving people counting on 8x8 IR sensors achieve up to 4.2× memory reduction, 23.8× code size reduction, and 15.38× energy reduction vs. state-of-the-art.

## Executive Summary
This paper presents a full-stack optimization flow for DNNs applied to privacy-preserving people counting using low-resolution infrared (IR) sensors. The approach combines neural architecture search, mixed-precision quantization, and post-processing to achieve highly efficient DNNs tailored for edge deployment. The method uses PIT mask-based DNAS to explore sub-architectures within a seed CNN, then applies layer-wise mixed-precision quantization (INT4/INT8), and finally employs majority voting over multiple frames to improve accuracy. A novel hardware platform, MAUPITI, extends the IBEX RISC-V core with custom SIMD instructions for efficient low-precision inference. Compared to the state-of-the-art, the optimized models achieve significant reductions in memory footprint, code size, and energy consumption while maintaining comparable or better accuracy.

## Method Summary
The paper introduces a full-stack optimization flow for DNNs applied to privacy-preserving people counting using low-resolution IR sensors. The approach combines neural architecture search, mixed-precision quantization, and post-processing to achieve highly efficient DNNs tailored for edge deployment. The method uses PIT mask-based DNAS to explore sub-architectures within a seed CNN, then applies layer-wise mixed-precision quantization (INT4/INT8), and finally employs majority voting over multiple frames to improve accuracy. A novel hardware platform, MAUPITI, extends the IBEX RISC-V core with custom SIMD instructions for efficient low-precision inference. The optimization flow is evaluated on the LINAIGE dataset containing 25,110 labeled samples from 8x8 IR sensors.

## Key Results
- Optimized models achieve up to 4.2× reduction in memory footprint compared to state-of-the-art
- Code size reduced by up to 23.8× through the proposed optimization flow
- Energy consumption decreased by up to 15.38× while maintaining comparable or better accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The PIT mask-based DNAS efficiently explores sub-architectures within a seed CNN by pruning channels during training, leading to a large reduction in memory and MAC operations while maintaining accuracy.
- Mechanism: PIT uses trainable masks to selectively prune portions of the seed network during training. By optimizing both the weights and masks to minimize task loss plus a hardware cost term, the method identifies Pareto-optimal sub-networks.
- Core assumption: The seed CNN contains good sub-architectures that can be found by pruning, and the differentiable training process can effectively discover them.
- Evidence anchors:
  - [abstract] "PIT mask-based DNAS to explore sub-architectures within a seed CNN"
  - [section] "PIT starts from a seed CNN and explores sub-architectures contained in it by structurally pruning the output channels/features"
  - [corpus] Weak evidence - no direct corpus support for PIT's effectiveness; the FMR scores are moderate and citations are zero.
- Break condition: If the seed network is too shallow or poorly designed, the mask-based approach may not find better sub-architectures, or the differentiable optimization could get stuck in local minima.

### Mechanism 2
- Claim: Mixed-precision quantization with INT4 and INT8 reduces memory footprint and energy consumption significantly without severely degrading accuracy.
- Mechanism: Weights and activations are quantized using layer-wise mixed precision, assigning INT4 or INT8 depending on the layer's tolerance. Batch normalization is folded to reduce operations, and quantization-aware training recovers accuracy.
- Core assumption: The underlying hardware supports efficient INT4/INT8 SIMD operations, and the accuracy drop from quantization is acceptable.
- Evidence anchors:
  - [abstract] "layer-wise mixed-precision quantization (INT4/INT8)"
  - [section] "our preliminary QAT experiments showed a too high accuracy drop for precisions lower than INT4"
  - [corpus] No corpus evidence directly supporting mixed-precision quantization benefits for IR sensor data.
- Break condition: If layers are too sensitive to low precision, or hardware lacks native INT4/INT8 support, accuracy may degrade beyond acceptable limits.

- Claim: Post-processing via majority voting over a sliding window of frames improves accuracy with negligible overhead by exploiting temporal correlation.
- Mechanism: The classifier is applied to each frame independently, and the final prediction is the mode over the last N frames. This filters out sporadic misclassifications.
- Core assumption: Consecutive frames are highly correlated and misclassifications are sporadic rather than systematic.
- Evidence anchors:
  - [abstract] "employs majority voting over multiple frames to improve accuracy"
  - [section] "we avoid any re-computation by simply storing previous predictions in a FIFO data structure"
  - [corpus] No corpus evidence directly supporting majority voting for IR-based people counting.
- Break condition: If the scene changes rapidly or misclassifications are systematic (e.g., a certain pose is always misclassified), majority voting will not help and may even delay correct detections.

## Foundational Learning

- Concept: Neural Architecture Search (NAS) and Differentiable NAS (DNAS)
  - Why needed here: Manual exploration of DNN architectures is time-consuming and often suboptimal; DNAS automates and fine-tunes the search process.
  - Quick check question: What is the main advantage of DNAS over traditional NAS methods like reinforcement learning or evolutionary algorithms?

- Concept: Mixed-precision quantization and quantization-aware training (QAT)
  - Why needed here: Reduces model size and computational cost while preserving accuracy; QAT simulates quantization effects during training to recover accuracy.
  - Quick check question: Why is QAT preferred over post-training quantization when targeting very low precisions like INT4?

- Concept: Temporal correlation in sequential sensor data
  - Why needed here: IR sensor frames are highly correlated over short time windows, enabling post-processing techniques like majority voting to improve accuracy.
  - Quick check question: How does the assumption of temporal correlation justify using a sliding window majority vote instead of just the latest prediction?

## Architecture Onboarding

- Component map:
  - Seed CNN → PIT DNAS (mask-based pruning) → Mixed-precision QAT (INT4/INT8) → Majority voting post-processing → Deployment on MAUPITI (RISC-V + SIMD)
  - MAUPITI hardware: IR sensor array → customized IBEX core with INT4/INT8 SIMD → memory and energy-optimized kernels → runtime inference

- Critical path:
  1. DNAS search and QAT fine-tuning (GPU/CPU)
  2. Model compilation and kernel generation (toolchain)
  3. Deployment and inference on MAUPITI (MCU)

- Design tradeoffs:
  - Precision vs accuracy: INT4 saves memory/energy but risks accuracy loss; layer-wise assignment balances this.
  - Hardware cost vs performance: Custom SIMD instructions add area but enable efficient low-precision ops.
  - Latency vs accuracy: Majority voting adds negligible latency but improves accuracy by filtering noise.

- Failure signatures:
  - Accuracy drop after quantization → likely due to layer sensitivity or insufficient QAT epochs.
  - No Pareto improvement after DNAS → seed too shallow or search space too constrained.
  - Majority voting not helping → temporal correlation assumption invalid or systematic misclassifications.

- First 3 experiments:
  1. Run PIT DNAS with λ=0.1, 1.0, 10.0 on the seed CNN and plot memory vs accuracy to identify the best λ.
  2. Apply INT4 quantization to all layers and measure accuracy drop; then selectively upgrade critical layers to INT8.
  3. Implement majority voting with window sizes 3, 5, 7 and compare accuracy vs latency to find optimal window length.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of using higher resolution IR sensor data (e.g., 16x16) on the accuracy and efficiency trade-offs achieved by the proposed optimization flow?
- Basis in paper: [inferred] The paper focuses on 8x8 IR array data and notes that collecting their own dataset with higher resolution sensors will be part of future work.
- Why unresolved: The paper only tests on 8x8 resolution data and does not explore the effects of higher resolution inputs on the model performance or hardware requirements.
- What evidence would resolve it: Experiments comparing the same optimization flow applied to higher resolution IR data, showing changes in accuracy, memory footprint, and energy consumption.

### Open Question 2
- Question: How would the proposed optimization flow perform on other privacy-preserving sensor modalities beyond IR arrays, such as radar or ultrasonic sensors?
- Basis in paper: [inferred] The paper focuses specifically on IR arrays for privacy-preserving people counting, without exploring other sensor types.
- Why unresolved: The flow is tailored for IR array data and its effectiveness on different sensor modalities with different characteristics is unknown.
- What evidence would resolve it: Applying the same optimization flow to radar or ultrasonic sensor data and comparing the results to the IR-based approach in terms of accuracy and efficiency.

### Open Question 3
- Question: What are the performance trade-offs of implementing additional low-precision SIMD instructions (e.g., 2-bit, unsigned variants) in the MAUPITI core?
- Basis in paper: [explicit] The paper mentions that 2-bit SDOTP instructions were not implemented due to accuracy degradation, and unsigned variants were omitted to reduce area overhead.
- Why unresolved: The paper only evaluates the current set of custom instructions and does not explore the potential benefits or drawbacks of adding more instruction variants.
- What evidence would resolve it: Implementing and testing additional instruction variants on the MAUPITI core, measuring their impact on accuracy, energy efficiency, and area overhead for different DNN models.

## Limitations
- PIT DNAS effectiveness lacks direct corpus validation; moderate FMR scores and zero citations suggest limited external adoption.
- Mixed-precision quantization benefits for IR sensor data are not supported by external corpus evidence.
- Generalization to higher resolution IR data or other sensor modalities remains untested.

## Confidence
- **High**: Effectiveness of majority voting post-processing (temporal correlation assumption is well-justified for IR data)
- **Medium**: Memory/energy reductions from PIT DNAS and mixed-precision quantization (claims supported by internal results but lack external validation)
- **Low**: Generalization of PIT DNAS and quantization gains to other IR datasets or sensor types

## Next Checks
1. **PIT DNAS Robustness**: Run PIT with λ=0.1, 1.0, 10.0 on the seed CNN and plot memory vs accuracy to confirm Pareto optimality and identify sensitivity to λ.
2. **Quantization Sensitivity**: Systematically test INT4 quantization across all layers, then selectively upgrade critical layers to INT8 to quantify accuracy trade-offs and identify layer-wise precision limits.
3. **Temporal Correlation Validation**: Implement majority voting with window sizes 3, 5, 7 and measure accuracy vs latency to confirm optimal window length and validate temporal correlation assumption.