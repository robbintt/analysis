---
ver: rpa2
title: Mitigating Propensity Bias of Large Language Models for Recommender Systems
arxiv_id: '2409.20052'
source_url: https://arxiv.org/abs/2409.20052
tags:
- information
- user
- side
- bias
- recommender
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of propensity bias in Large Language
  Models (LLMs) when applied to recommender systems, which can lead to dimensional
  collapse and reduced recommendation accuracy. The authors propose a novel framework
  called Counterfactual LLM Recommendation (CLLMR) that mitigates these issues through
  two key components: a Spectrum-based Side information Encoder (SSE) that captures
  structural information from historical interactions while preventing dimensional
  collapse, and a causal inference approach that uses counterfactual reasoning to
  eliminate LLM-related biases during recommendation inference.'
---

# Mitigating Propensity Bias of Large Language Models for Recommender Systems

## Quick Facts
- arXiv ID: 2409.20052
- Source URL: https://arxiv.org/abs/2409.20052
- Reference count: 40
- Primary result: CLLMR improves Recall@10 by up to 6.26% and NDCG@10 by up to 12.80% over state-of-the-art methods

## Executive Summary
This paper addresses the problem of propensity bias in Large Language Models (LLMs) when applied to recommender systems, which can lead to dimensional collapse and reduced recommendation accuracy. The authors propose a novel framework called Counterfactual LLM Recommendation (CLLMR) that mitigates these issues through two key components: a Spectrum-based Side information Encoder (SSE) that captures structural information from historical interactions while preventing dimensional collapse, and a causal inference approach that uses counterfactual reasoning to eliminate LLM-related biases during recommendation inference. Extensive experiments on three real-world datasets (Amazon, Yelp, Steam) demonstrate that CLLMR consistently outperforms state-of-the-art methods.

## Method Summary
CLLMR is a framework that combines a Spectrum-based Side information Encoder (SSE) with counterfactual inference to mitigate propensity bias in LLM-based recommender systems. The SSE uses singular value decomposition (SVD) on historical interaction matrices to extract a spectrum that serves as a conditional prior in a variational autoencoder framework, learning low-dimensional side representations while preventing dimensional collapse. The causal inference component constructs a causal graph with exposure, mediator, and outcome nodes, then uses counterfactual reasoning to estimate and eliminate bias by computing pure natural direct effects and subtracting them from total effects.

## Key Results
- CLLMR achieves up to 6.26% improvement in Recall@10 compared to state-of-the-art methods
- CLLMR achieves up to 12.80% improvement in NDCG@10 metrics
- The framework effectively prevents dimensional collapse while maintaining alignment between LLM-generated side information and collaborative filtering representations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Spectrum-based Side information Encoder (SSE) prevents dimensional collapse by incorporating structural information from historical interactions into side information representations.
- Mechanism: SSE uses singular value decomposition (SVD) on the historical interaction matrix to extract a spectrum that captures the global structure. This spectrum is then used as a conditional prior in a variational autoencoder framework to learn low-dimensional side representations that maintain the global structure.
- Core assumption: The SVD spectrum of historical interactions contains sufficient structural information to guide the encoding of LLM-generated side information without causing dimensional collapse.
- Evidence anchors:
  - [abstract] "Specifically, we propose a spectrum-based side information encoder that implicitly embeds structural information from historical interactions into the side information representation, thereby circumventing the risk of dimension collapse."
  - [section 4.2] "SSE effectively learns the various factors within the data, preventing dimensional collapsing during the alignment process."
  - [corpus] Weak evidence - no direct corpus papers found that validate this specific mechanism of using SVD spectrum as conditional prior for preventing dimensional collapse in LLM-based recommender systems.
- Break condition: If the historical interaction data is too sparse or noisy, the SVD spectrum may not capture meaningful structure, causing the SSE to fail at preventing dimensional collapse.

### Mechanism 2
- Claim: Counterfactual inference eliminates LLM-related propensity bias by estimating and subtracting the indirect effects of bias through causal mediation analysis.
- Mechanism: The framework constructs a causal graph with exposure (side information), mediator (propensity bias), and outcome (recommendation performance). By setting the mediator to reference states, it computes the pure natural direct effect and subtracts it from the total effect to eliminate bias.
- Core assumption: The causal assumptions (no unmeasured confounding, no mediators affected by exposure) hold in the recommender system context, allowing valid causal effect estimation.
- Evidence anchors:
  - [abstract] "Furthermore, our CLLMR approach explores the causal relationships inherent in LLM-based recommender systems. By leveraging counterfactual inference, we counteract the biases introduced by LLMs."
  - [section 4.3] "We explore a causal perspective on propensity bias in LLM-based recommender systems and develop a counterfactual LLM framework (CLLMR) to train recommender systems, enabling counterfactual inference based on the designed causal graph to mitigate the propensity bias caused by LLMs during the recommendation inference stage."
  - [corpus] Moderate evidence - several papers on causal inference in recommender systems and counterfactual risk minimization exist in the corpus, but none specifically combine this with LLM propensity bias mitigation.
- Break condition: If the causal assumptions are violated (e.g., unmeasured confounders exist between side information and recommendation performance), the counterfactual inference will not correctly eliminate bias.

### Mechanism 3
- Claim: The noise injection in SSE enhances generalization by preventing overfitting to the historical interaction spectrum while maintaining the model's ability to capture user preferences.
- Mechanism: Random noise is added to the SVD spectrum before using it as a conditional prior, and a sign function ensures the noise maintains the same direction as the original spectrum, preventing orientation changes in the feature space.
- Core assumption: Small amounts of noise in the spectrum improve generalization without significantly degrading the structural information needed for encoding.
- Evidence anchors:
  - [section 4.2] "However, users may occasionally click by mistake when performing an action, and overfitting historical interaction data may result in overfitting, which may not accurately capture user preferences. To avoid overfitting and increase the generalization capabilities of the model, we add a small amount of noise to the spectrum."
  - [section 5.3.2] "By adding random noise to the spectrum when learning the side information representation, the model can better adapt to this uncertainty, thereby improving its performance in real-world environments."
  - [corpus] No direct evidence found in corpus for this specific noise injection mechanism in the context of SVD-based spectral conditioning.
- Break condition: If the noise magnitude is too large, it will corrupt the structural information in the spectrum, causing the SSE to lose its ability to prevent dimensional collapse.

## Foundational Learning

- Concept: Variational Autoencoders (VAEs) and reparameterization trick
  - Why needed here: SSE uses a conditional VAE framework with the SVD spectrum as a conditional prior to learn side representations
  - Quick check question: How does the reparameterization trick enable gradient-based optimization in VAEs when sampling from the latent distribution?

- Concept: Causal inference and mediation analysis
  - Why needed here: CLLMR uses counterfactual inference based on causal mediation analysis to estimate and eliminate propensity bias
  - Quick check question: What are the four key assumptions required for valid causal mediation analysis in the context of recommender systems?

- Concept: Graph neural networks and spectral graph theory
  - Why needed here: The SVD spectrum represents the global structure of the user-item interaction graph, which is crucial for the SSE
  - Quick check question: How does singular value decomposition relate to the spectral properties of graphs, and why is this useful for representation learning?

## Architecture Onboarding

- Component map: LLM Side Information Generator -> SSE -> Causal Inference Module -> Contrastive Learning Alignment -> Backbone Recommender -> Recommendations
- Critical path: LLM → SSE → Causal Inference → Contrastive Learning → Backbone Recommender → Recommendations
- Design tradeoffs:
  - SVD spectrum rank vs. hidden layer dimension: Must match to fully utilize the spectral information
  - Noise magnitude: Small noise improves generalization but too much corrupts structural information
  - Causal assumptions validity: Strong assumptions needed for counterfactual inference to work correctly
- Failure signatures:
  - Dimensional collapse: SSE fails to prevent representations from concentrating in low-dimensional subspace
  - Bias persistence: Causal inference doesn't eliminate propensity bias, recommendations remain skewed
  - Overfitting: Model performs well on training data but poorly on test data
- First 3 experiments:
  1. Compare singular values of representations with and without SSE on Amazon dataset to verify dimensional collapse prevention
  2. Run ablation study removing causal inference component to measure bias reduction effectiveness
  3. Vary spectrum rank (16, 32, 64) while keeping hidden layer at 32 to find optimal configuration

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the dimensionality of the spectrum-based side information encoder affect recommendation performance compared to other encoding methods?
- Basis in paper: [explicit] The paper states "The experimental results reveal that the performance of the model gradually improves when the noise size is increased from 0.001 to 0.01" and shows that SSE performs better than MLP in preventing dimensional collapse
- Why unresolved: While the paper demonstrates SSE's superiority over MLP, it doesn't directly compare different dimensionality settings of SSE against other state-of-the-art encoding methods
- What evidence would resolve it: Comparative experiments testing various dimensionality settings of SSE against other encoding approaches (MLP, attention mechanisms, etc.) on multiple datasets with statistical significance testing

### Open Question 2
- Question: What is the optimal trade-off between noise magnitude and spectrum rank for maximizing recommendation performance across different dataset characteristics?
- Basis in paper: [explicit] The paper conducts hyperparameter analysis showing that performance improves with noise size up to 0.01 but decreases beyond 0.1, and that rank 32 performs best
- Why unresolved: The paper provides optimal settings for one dataset but doesn't explore how these parameters interact or how they vary across datasets with different properties (sparsity, size, domain)
- What evidence would resolve it: Systematic experiments varying both noise magnitude and spectrum rank across datasets with different characteristics, including interaction effect analysis

### Open Question 3
- Question: How does the CLLMR framework perform in cold-start scenarios compared to existing approaches?
- Basis in paper: [inferred] The paper focuses on general recommendation performance but doesn't specifically address cold-start problems, which are critical in real-world recommender systems
- Why unresolved: Cold-start scenarios present unique challenges where historical interaction data is limited, and the LLM-based approach may have different strengths/weaknesses compared to traditional methods
- What evidence would resolve it: Experiments specifically designed to test CLLMR's performance on cold-start users/items, including comparison with cold-start specialized methods and analysis of which components contribute most to cold-start performance

## Limitations
- Implementation-specific limitations: The paper doesn't fully specify the text embedding model T used in the SSE component or the exact implementation details of the causal effect estimation models
- Theoretical assumptions: The causal mediation analysis approach relies on strong assumptions about no unmeasured confounding that may not hold in practice
- Dataset dependency: The effectiveness of the SVD spectrum approach depends on having sufficient interaction data density, limiting generalizability to sparse datasets

## Confidence
- **High confidence**: The mechanism of using SVD spectrum as a conditional prior in VAE framework for preventing dimensional collapse is well-grounded in established linear algebra and variational inference principles
- **Medium confidence**: The counterfactual inference approach for eliminating propensity bias is theoretically sound but relies on strong causal assumptions that may not always hold in practice
- **Low confidence**: The specific noise injection mechanism and its optimal magnitude for improving generalization are not well-supported by empirical evidence in the paper

## Next Checks
1. **Dimensional collapse verification**: Compare the singular value distribution of learned representations with and without SSE on the Amazon dataset to empirically verify that SSE prevents dimensional collapse
2. **Causal inference ablation study**: Remove the counterfactual inference component from the CLLMR framework and measure the remaining propensity bias to quantify how much bias reduction is actually achieved
3. **Robustness to spectrum rank**: Conduct experiments varying the spectrum rank (16, 32, 64) while keeping the hidden layer dimension fixed at 32 to determine the optimal configuration and test the robustness of the SSE approach