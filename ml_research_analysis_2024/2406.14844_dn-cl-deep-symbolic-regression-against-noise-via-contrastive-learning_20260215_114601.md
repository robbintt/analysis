---
ver: rpa2
title: 'DN-CL: Deep Symbolic Regression against Noise via Contrastive Learning'
arxiv_id: '2406.14844'
source_url: https://arxiv.org/abs/2406.14844
tags:
- data
- noise
- symbolic
- regression
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DN-CL, a deep symbolic regression model that
  incorporates contrastive learning to handle noisy data. The method treats noisy
  and clean data as different views of the same ground-truth expression and uses two
  parameter-sharing encoders to map data points into consistent features.
---

# DN-CL: Deep Symbolic Regression against Noise via Contrastive Learning

## Quick Facts
- arXiv ID: 2406.14844
- Source URL: https://arxiv.org/abs/2406.14844
- Reference count: 40
- DN-CL outperforms existing large-scale pre-trained models in both noisy and clean data scenarios, achieving higher R² scores and better recovery rates.

## Executive Summary
This paper introduces DN-CL, a deep symbolic regression model that incorporates contrastive learning to handle noisy data. The method treats noisy and clean data as different views of the same ground-truth expression and uses two parameter-sharing encoders to map data points into consistent features. By minimizing distances between positive pairs (same expression) and maximizing distances between negative pairs, DN-CL learns noise-resistant representations. Experiments on multiple public benchmarks show that DN-CL outperforms existing large-scale pre-trained models in both noisy and clean data scenarios, achieving higher R² scores and better recovery rates. The model also maintains competitive performance while reducing expression complexity and inference time compared to end-to-end methods.

## Method Summary
DN-CL uses a dual-encoder architecture with parameter-sharing to process clean and noisy data as different views of the same ground-truth expression. The model employs InfoNCE contrastive loss to align representations in feature space, pulling positive pairs (same expression) together while pushing negative pairs apart. Encoder outputs are concatenated and fed to a decoder that generates expression sequences. The combined loss function includes cross-entropy for expression prediction and λ-weighted InfoNCE for contrastive learning. Training uses balanced clean and noisy data, with Gaussian noise added at σ = η * RMS(y).

## Key Results
- DN-CL achieves higher R² scores than large-scale pre-trained models on both noisy and clean benchmarks
- The model maintains competitive performance while reducing expression complexity compared to end-to-end methods
- Recovery rate improves significantly on benchmarks with added Gaussian noise (η = 0.1)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contrastive learning aligns representations of clean and noisy data from the same expression, improving noise robustness.
- Mechanism: Two parameter-sharing encoders process clean and noisy data as "different views" of the same ground truth. InfoNCE loss pulls positive pairs (same expression) together while pushing negative pairs apart.
- Core assumption: Noisy and clean data from the same expression share the same underlying representation in feature space.
- Evidence anchors:
  - [abstract]: "treats noisy data and clean data as different views of the ground-truth mathematical expressions."
  - [section 3.1]: "The positive pairs should be similar to each other while the negative pair should be dissimilar to each other."
  - [corpus]: Weak; no direct mention of contrastive learning for symbolic regression, but related works in CL for SR exist (T-JST, SNIP, MMSR).
- Break condition: If noise patterns corrupt the feature space so that clean and noisy samples from the same expression are no longer distinguishable, the contrastive objective may fail.

### Mechanism 2
- Claim: Joint training of encoder and decoder end-to-end yields better distinct features than pretraining the encoder alone.
- Mechanism: Encoder learns representations conditioned on decoder's output needs; contrastive loss shapes the representation space before decoder consumes it.
- Core assumption: Decoder feedback during end-to-end training guides encoder to produce task-relevant features rather than generic ones.
- Evidence anchors:
  - [abstract]: "learn the data feature and the pre-order traversal of the expressions in an end-to-end strategy rather than train a encoder first, then fix the parameter of encoder and update the decoder."
  - [section 3.1]: "In practical, we replace half of the batch with the data after transformation t2 for coding simplicity."
- Break condition: If the decoder dominates training and forces the encoder to overfit to a narrow set of expression patterns, generalization may suffer.

### Mechanism 3
- Claim: Adding half noisy data and half clean data in training improves performance on both clean and noisy test sets.
- Mechanism: Balanced exposure to both domains prevents overfitting to clean data while still preserving clean-data accuracy.
- Core assumption: The encoder can learn a representation that generalizes across noise levels when trained on a balanced mix.
- Evidence anchors:
  - [section 4.3]: "we also expect the model still maintain superior results on clean data, thus the h1 are feed to the decoder too."
  - [section 4.3]: "Furthermore, our model utilize the contrastive learning as a constraint to reduce the distance between the features of data with different noise level."
- Break condition: If noise distribution in training is too different from test distribution, performance on both domains could degrade.

## Foundational Learning

- Concept: Contrastive learning (InfoNCE loss) for representation alignment
  - Why needed here: To enforce that clean and noisy views of the same expression map to nearby points in feature space, enabling noise-robust prediction.
  - Quick check question: In InfoNCE, what is the role of negative samples, and why are they necessary?

- Concept: Symbolic regression as sequence generation
  - Why needed here: The decoder outputs expressions as pre-order traversals; understanding sequence models and tokenization is key to modifying the architecture.
  - Quick check question: How does the model represent constants in the expression tree, and why is this representation important?

- Concept: Set Transformers for permutation-invariant encoding
  - Why needed here: The input is a set of (x, y) points; the encoder must be invariant to their order to ensure consistent representation.
  - Quick check question: What property must an encoder have to be permutation-invariant, and how does a Set Transformer achieve it?

## Architecture Onboarding

- Component map:
  Data transformation layer (identity + Gaussian noise) -> Dual encoders (parameter-sharing) -> Projection head (L2-normalized) -> Concatenated features -> Decoder (SymFormer-style) -> Expression sequence output

- Critical path:
  1. Sample clean batch → apply noise to half → feed to dual encoders
  2. Compute InfoNCE loss between encoder outputs
  3. Concatenate encoder features → feed to decoder → compute cross-entropy loss
  4. Backpropagate combined loss

- Design tradeoffs:
  - Dual encoders vs single encoder + noise injection: Dual encoders enforce symmetry but double memory; single encoder simpler but may learn asymmetric features.
  - λ tuning: Too high → contrastive dominates and hurts expression accuracy; too low → noise robustness gain minimal.
  - Feature concatenation vs concatenation in latent space: Concatenation preserves both views; projection could compress but may lose discriminative power.

- Failure signatures:
  - Training loss diverges: λ too high or learning rate mismatch between contrastive and generative objectives.
  - R² drops on clean data: Encoder overfits to noisy features; try increasing clean data ratio or reducing λ.
  - Decoder generates invalid syntax: Check tokenization consistency and maximum length setting.

- First 3 experiments:
  1. Run with λ = 0 (no contrastive loss) to confirm baseline degradation on noisy data.
  2. Sweep λ ∈ {0.01, 0.1, 1.0} on a small benchmark; plot R² vs λ to find sweet spot.
  3. Replace dual encoders with a single encoder + noise injection in training; compare R² on noisy vs clean test sets.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of DN-CL compare to hybrid methods that combine pre-trained models with reinforcement learning or Monte Carlo Tree Search?
- Basis in paper: [explicit] The paper mentions hybrid models like SNR, GDSR, and TPSR that combine pre-trained models with other techniques, but does not directly compare DN-CL to these methods.
- Why unresolved: The authors chose to compare DN-CL primarily with large-scale pre-trained models and end-to-end methods, leaving a gap in understanding how it performs relative to hybrid approaches.
- What evidence would resolve it: Conducting experiments to compare DN-CL's performance against hybrid methods on the same benchmarks used in the paper would provide a clear answer.

### Open Question 2
- Question: What is the impact of using different noise distributions (e.g., uniform noise, Laplace noise) in the training process of DN-CL?
- Basis in paper: [inferred] The paper only considers Gaussian noise for data augmentation, but other noise distributions could potentially affect the model's robustness and generalization.
- Why unresolved: The authors did not explore the effects of varying noise distributions, focusing solely on Gaussian noise as a proof of concept.
- What evidence would resolve it: Training DN-CL with different noise distributions and comparing its performance on noisy data benchmarks would reveal the impact of noise type on model robustness.

### Open Question 3
- Question: How does the choice of encoder architecture (e.g., SetTransformer vs. other architectures) influence the performance of DN-CL on symbolic regression tasks?
- Basis in paper: [explicit] The authors mention that any encoder-decoder architecture could be used with DN-CL, but they specifically chose SetTransformer for its permutation invariance.
- Why unresolved: The paper does not explore the effects of using different encoder architectures, leaving uncertainty about whether SetTransformer is the optimal choice.
- What evidence would resolve it: Experimenting with different encoder architectures while keeping the rest of the DN-CL framework constant would provide insights into the impact of encoder choice on performance.

## Limitations

- Exact implementation details of the dual SetTransformer encoders and their projection layers remain unclear, which are critical for the contrastive learning mechanism
- Training hyperparameters including learning rate schedule, optimizer type, and gradient clipping values are not specified
- The paper does not explore the effects of different noise distributions or encoder architectures on performance

## Confidence

- Contrastive learning mechanism effectiveness: High
- Exact hyperparameter choices: Medium
- Architectural implementation details: Medium
- Comparative results against baselines: Medium-High (assuming proper experimental setup)

## Next Checks

1. Implement ablation study with λ = 0 to verify contrastive learning contribution to noise robustness
2. Test dual encoder vs single encoder + noise injection design choice on a small benchmark
3. Verify balanced training data ratio (50% clean, 50% noisy) effect on both clean and noisy test performance