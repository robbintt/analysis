---
ver: rpa2
title: 'Advancing Real-time Pandemic Forecasting Using Large Language Models: A COVID-19
  Case Study'
arxiv_id: '2404.06962'
source_url: https://arxiv.org/abs/2404.06962
tags:
- data
- information
- forecasting
- week
- pandemic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PandemicLLM is the first LLM-based pandemic forecasting framework
  that reformulates disease spread prediction as a text reasoning task. It integrates
  multi-modal data including epidemiological time series, public health policies,
  genomic surveillance, and spatial demographics into structured prompts using an
  AI-human cooperative design, with a GRU encoder to handle temporal dynamics.
---

# Advancing Real-time Pandemic Forecasting Using Large Language Models: A COVID-19 Case Study

## Quick Facts
- arXiv ID: 2404.06962
- Source URL: https://arxiv.org/abs/2404.06962
- Reference count: 40
- Key outcome: LLM-based pandemic forecasting framework achieves 55.4%-60% accuracy on U.S. COVID-19 hospitalization forecasts

## Executive Summary
PandemicLLM is the first LLM-based framework that reformulates pandemic forecasting as a text reasoning task, enabling integration of previously inaccessible data streams like textual policies and genomic surveillance. The model combines a GRU encoder for temporal dynamics with structured prompts incorporating multi-modal data, achieving significant improvements over traditional forecasting models. Tested on U.S. state-level COVID-19 hospitalization forecasts, it demonstrates robust performance with clear interpretability for public health decision-making.

## Method Summary
The framework fine-tunes LLaMA2 models (7B, 13B, 70B parameters) using an AI-human cooperative prompt design that converts multi-modal pandemic data into structured textual format. A GRU encoder processes hospitalization time series while the LLM handles text-based reasoning about policies, genomic variants, and demographic factors. The model predicts ordinal categories of hospitalization trends rather than continuous values, providing interpretable forecasts with confidence levels. Data spans 50 U.S. states over 104 weeks, with evaluation on 1-week and 3-week ahead forecasts.

## Key Results
- Achieves 55.4%-60% accuracy and 0.59-0.63 MSE on U.S. state-level COVID-19 hospitalization forecasts
- Outperforms traditional models by at least 20% in accuracy
- Demonstrates 17-24% improvement from GRU encoder integration for temporal representation
- Provides robust predictions during variant emergence with clear confidence levels

## Why This Works (Mechanism)

### Mechanism 1
Reformulating pandemic forecasting as text reasoning enables incorporation of previously inaccessible data streams. The model converts multi-modal data (textual policies, genomic surveillance reports, demographic rankings) into structured prompts that LLMs can process through natural language reasoning rather than numerical pattern matching. Core assumption: Textual representations of policy stringency, variant characteristics, and demographic rankings contain sufficient information for accurate forecasting when properly structured.

### Mechanism 2
RNN encoder for time series data significantly improves forecasting accuracy by preserving temporal information. A GRU encoder transforms continuous hospitalization time series into fixed-dimensional embeddings that maintain temporal dynamics, which are then integrated with textual prompts. Core assumption: Temporal dependencies in hospitalization data are crucial for accurate forecasting and cannot be adequately captured through pure text summarization.

### Mechanism 3
Ordinal classification formulation improves interpretability and trustworthiness compared to continuous prediction targets. By categorizing hospitalization trends into discrete levels (Substantial Decrease, Moderate Decrease, Stable, Moderate Increase, Substantial Increase), the model provides clear, actionable predictions with confidence levels that decision-makers can use. Core assumption: Public health decision-makers prefer categorical predictions with uncertainty estimates over continuous numerical forecasts.

## Foundational Learning

- Concept: Multi-modal data integration and representation learning
  - Why needed here: The model must process heterogeneous data types (textual, numerical, sequential) that traditional models cannot handle simultaneously
  - Quick check question: How would you represent a policy stringency level change from "recommended closures" to "required closures" in a textual prompt that preserves temporal context?

- Concept: Transformer-based language models and autoregressive generation
  - Why needed here: LLMs form the core reasoning engine that processes the structured prompts and generates probabilistic forecasts
  - Quick check question: What is the key difference between how LLMs process tokens versus how traditional time series models process numerical sequences?

- Concept: Ordinal classification and confidence calibration
  - Why needed here: The model must provide interpretable predictions with uncertainty estimates that decision-makers can trust
  - Quick check question: How does the Brier Score differ from simple accuracy when evaluating ordinal classification performance?

## Architecture Onboarding

- Component map:
  Data preprocessing pipeline → Text conversion module (AI-human cooperative design) → RNN encoder for time series → LLM fine-tuning layer → Prediction output layer
  Each state-week combination generates one structured prompt with embedded sequential representations

- Critical path:
  Prompt construction (spatial + temporal + policy + genomic) → GRU encoding of hospitalization time series → LLM inference for category probability distribution → Confidence threshold evaluation for decision-making

- Design tradeoffs:
  Fixed prompt structure vs. adaptive prompt generation
  GRU encoder complexity vs. computational efficiency
  Model size (7B vs 13B vs 70B) vs. deployment feasibility
  Categorical prediction granularity vs. interpretability

- Failure signatures:
  Low confidence predictions across all states → potential data quality issues or model uncertainty
  Systematic bias in specific regions → regional trend patterns not captured by current prompt design
  Performance degradation during variant emergence → genomic surveillance data integration issues

- First 3 experiments:
  1. Ablation study: Remove GRU encoder and measure accuracy/MSE degradation (expected: 17-24% accuracy drop)
  2. Confidence threshold analysis: Plot accuracy vs confidence threshold to identify optimal decision-making cutoffs
  3. Variant emergence test: Remove genomic surveillance information and measure performance during BQ.1 variant surge period

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of PandemicLLM vary when incorporating additional data streams such as wastewater-based epidemiology or human behavior data? The authors state that the model "aims to expand its capabilities by including an even broader spectrum of disease-relevant data, such as wastewater-based epidemiology and human behavior data." Experimental results comparing the model's performance with and without these additional data sources would resolve this question.

### Open Question 2
What is the impact of different RNN architectures (e.g., LSTMs, attention mechanisms) on the model's performance compared to the GRU encoder used in PandemicLLM? The authors mention that "the design of PandemicLLM allows for easy future extensions to accommodate other time series encoder architectures (such as LSTMs or attention mechanisms), potentially providing better suitability for different disease types and propagation patterns." Experimental results comparing different RNN architectures against the current GRU-based model would resolve this question.

### Open Question 3
How does the model's performance change when scaling up the parameter size beyond the 70B model tested in the study? The authors note that "scaling the parameter size of the PandemicLLM could lead to performance improvements" and provide results for the 70B model, but do not explore larger models. Experimental results comparing performance with parameter sizes larger than 70B (e.g., 100B, 175B) against the current 70B model would resolve this question.

## Limitations

- Evaluation period of only 16 weeks may not capture full range of pandemic dynamics or seasonal variations
- 20% improvement claim relative to traditional models requires careful interpretation due to unspecified comparison baselines
- AI-human cooperative prompt design process lacks detailed procedural documentation for exact replication

## Confidence

- High Confidence: The fundamental premise that LLMs can process structured textual prompts incorporating multi-modal pandemic data
- Medium Confidence: The 55.4%-60% accuracy and 0.59-0.63 MSE performance metrics
- Low Confidence: The 17-24% improvement from GRU encoder integration

## Next Checks

1. **Extended temporal validation**: Replicate the forecasting performance across multiple seasonal cycles (spring, summer, fall, winter) to assess model robustness to temporal variations in disease transmission patterns.

2. **Baseline specification audit**: Obtain and implement the exact traditional forecasting models used for comparison to verify the claimed 20% improvement margin and ensure fair methodological comparison.

3. **Prompt engineering reproducibility test**: Implement the AI-human cooperative prompt design process with different human annotators to assess the consistency and generalizability of the prompt construction methodology across different implementation teams.