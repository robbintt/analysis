---
ver: rpa2
title: Exploring Continual Fine-Tuning for Enhancing Language Ability in Large Language
  Model
arxiv_id: '2410.16006'
source_url: https://arxiv.org/abs/2410.16006
tags:
- ability
- phase
- language
- task
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates continual fine-tuning (CFT) for enhancing
  multilingual language ability in large language models (LLMs) without sacrificing
  task ability in English. It introduces a two-phase CFT process where an English-only
  model is sequentially fine-tuned on multilingual data.
---

# Exploring Continual Fine-Tuning for Enhancing Language Ability in Large Language Model

## Quick Facts
- arXiv ID: 2410.16006
- Source URL: https://arxiv.org/abs/2410.16006
- Reference count: 29
- Key outcome: Continual fine-tuning with generative replay and layer freezing strategies successfully enhances multilingual language ability while preserving task performance in English

## Executive Summary
This paper investigates continual fine-tuning (CFT) as a method to enhance multilingual language ability in large language models (LLMs) without sacrificing task performance in English. The authors propose a two-phase CFT process where an English-only model is sequentially fine-tuned on multilingual data. They introduce two novel strategies—generative replay (GR) and heuristic-based layer freezing (LF)—to mitigate catastrophic forgetting and preserve task ability. The study demonstrates that these strategies outperform baseline approaches like LoRA and English replay, showing significant improvements in both task and language ability metrics.

## Method Summary
The study employs a two-phase continual fine-tuning process using base LLMs (MISTRAL-7B or LLAMA-3-8B). In Phase 1, models are fine-tuned on English datasets (ALPACA or OPEN ORCA) to establish task ability. In Phase 2, these models are fine-tuned on multilingual datasets (MULTIALPACA or MOPEN ORCA) to enhance language ability. The key innovation lies in two mitigation strategies: generative replay generates English data from the Phase 1 model to bridge distribution gaps during Phase 2 fine-tuning, while heuristic-based layer freezing identifies and freezes layers that changed most during Phase 1. Both strategies aim to preserve task ability while enabling multilingual adaptation.

## Key Results
- Task ability preservation in Phase 2 depends on similarity between Phase 1 and Phase 2 datasets, quantified using Dataset Embedding Similarity (DES) and Model Parameter Difference (MPD)
- Generative replay (GR) and heuristic-based layer freezing (LF) successfully mitigate catastrophic forgetting while improving language ability
- These strategies outperform baselines like LoRA and English replay (ER) in balancing multilingual adaptation and task retention

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Task ability preservation depends on similarity between Phase 1 and Phase 2 datasets
- Mechanism: Similar datasets maintain aligned model representations across phases, minimizing interference and preserving task ability
- Core assumption: Task similarity can be quantified using DES and MPD metrics
- Evidence anchors:
  - [abstract] "We observe that the 'similarity' of Phase 2 tasks with Phase 1 determines the LLM's adaptability"
  - [section 4.2] "For phase-wise datasets like Instruct and MULTIALPACA, the performance of the Phase 2 models trained on them declines for English"
  - [corpus] Weak - no direct corpus evidence for this specific mechanism
- Break condition: If similarity metrics fail to accurately capture task similarity, preservation cannot be reliably predicted

### Mechanism 2
- Claim: Generative replay mitigates catastrophic forgetting by generating English data that bridges distribution gaps
- Mechanism: Phase 1 model generates responses to English counterparts of Phase 2's multilingual dataset, creating replay data that acts as a bridge between distributions
- Core assumption: Generated replay data accurately represents Phase 1 distribution and effectively bridges gap with Phase 2
- Evidence anchors:
  - [section 5.1] "During Phase 2 fine-tuning, we include varying quantities of this generated data: specifically, 5% (GR_5) and 10% (GR_10), of the Phase 2 dataset"
  - [section 5.3] "GR and LF successfully mitigate the decline in task ability and also show gains in language ability"
  - [corpus] Weak - no direct corpus evidence for this specific mechanism
- Break condition: If generated replay data does not accurately represent Phase 1's distribution or fails to bridge gap with Phase 2

### Mechanism 3
- Claim: Heuristic-based layer freezing preserves task ability by freezing layers that changed most during Phase 1
- Mechanism: Layers that changed significantly during Phase 1 fine-tuning are identified and frozen during Phase 2 fine-tuning to prevent overwriting
- Core assumption: Most changed layers during Phase 1 are most critical for task ability
- Evidence anchors:
  - [section 5.2] "LF_H2: freezing the top-10 layers that have changed the most during Phase 1 fine-tuning"
  - [section 5.3] "GR and LF successfully mitigate the decline in task ability and also show gains in language ability"
  - [corpus] Weak - no direct corpus evidence for this specific mechanism
- Break condition: If identified layers are not most critical for task ability, freezing will not effectively mitigate catastrophic forgetting

## Foundational Learning

- Concept: Catastrophic forgetting
  - Why needed here: Understanding catastrophic forgetting is crucial for grasping the challenge of preserving task ability while enhancing language ability in continual fine-tuning
  - Quick check question: What is catastrophic forgetting, and why is it a concern in continual fine-tuning of LLMs?

- Concept: Dataset embedding similarity (DES)
  - Why needed here: DES is a key metric used to quantify similarity between Phase 1 and Phase 2 datasets
  - Quick check question: How does DES quantify the similarity between two datasets, and what does a high DES score indicate?

- Concept: Model parameter difference (MPD)
  - Why needed here: MPD provides a complementary measure to DES for quantifying dataset similarity
  - Quick check question: How does MPD quantify the similarity between two datasets, and what does a low MPD score indicate?

## Architecture Onboarding

- Component map: Base LLM (MISTRAL-7B or LLAMA-3-8B) -> Phase 1 fine-tuned model (English data) -> Phase 2 fine-tuned model (multilingual data with mitigating strategies)
- Critical path: Phase 1 fine-tuning on English data → Phase 2 fine-tuning on multilingual data with mitigating strategies → Evaluation of task and language ability
- Design tradeoffs: Balance between preserving task ability (through mitigation) and enhancing language ability (through multilingual fine-tuning)
- Failure signatures: Catastrophic forgetting of task ability, ineffective mitigation strategies, inaccurate similarity metrics
- First 3 experiments:
  1. Fine-tune MISTRAL-7B on ALPACA (Phase 1) and then on MULTIALPACA (Phase 2) without mitigating strategies to observe baseline performance
  2. Apply generative replay (GR_5) during Phase 2 fine-tuning on MULTIALPACA and compare performance to baseline
  3. Apply heuristic-based layer freezing (LF_H2) during Phase 2 fine-tuning on MULTIALPACA and compare performance to baseline and GR_5

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do DES and MPD metrics compare in their ability to predict task ability preservation across different language model architectures and dataset types?
- Basis in paper: [explicit] The paper introduces DES and MPD as metrics to quantify task similarity between phase-wise datasets
- Why unresolved: The study only tested these metrics on MISTRAL-7B and LLAMA-3-8B models with specific dataset pairs
- What evidence would resolve it: Systematic experiments applying DES and MPD to a broader range of models and dataset pairs

### Open Question 2
- Question: What are the underlying mechanisms that cause some models (like LLAMA-3-8B) to exhibit less cross-lingual transfer, and how can these be addressed?
- Basis in paper: [inferred] The paper observes that LLAMA-3-8B shows less cross-lingual transfer compared to MISTRAL-7B
- Why unresolved: The paper identifies this difference but does not investigate root causes or propose solutions
- What evidence would resolve it: Comparative analyses of model architectures, training procedures, and tokenization strategies

### Open Question 3
- Question: How can parameter-efficient regularization methods be developed to balance task ability preservation and multilingual adaptation?
- Basis in paper: [explicit] The paper acknowledges that existing methods like EWC are computationally expensive and LoRA suffers from forgetting
- Why unresolved: While proposing heuristic-based layer freezing and generative replay, the paper does not explore other parameter-efficient regularization techniques
- What evidence would resolve it: Empirical comparisons of novel parameter-efficient regularization methods on task and language ability retention

## Limitations

- Similarity metrics (DES and MPD) may oversimplify the multidimensional nature of task similarity
- Generative replay mechanism assumes generated English data effectively bridges distribution gaps, which may not hold for all dataset pairs
- Layer freezing strategy assumes most changed layers during Phase 1 are most critical for task preservation, which may not be universally true

## Confidence

- **High Confidence**: Task ability preservation depends on dataset similarity between phases is well-supported by empirical results across multiple dataset pairs
- **Medium Confidence**: Similarity metrics provide reasonable quantitative framework for predicting task preservation, though generalizability remains to be tested
- **Low Confidence**: Generative replay effectiveness heavily depends on quality of generated English data, which is not directly evaluated

## Next Checks

1. Apply DES and MPD metrics to a broader range of dataset pairs beyond the four studied to test their predictive power for task preservation

2. Evaluate quality and distribution alignment of generated English replay data with original Phase 1 data to ensure effective bridging

3. Conduct ablation studies to identify which layers are truly critical for task preservation by systematically unfreezing different layer groups during Phase 2