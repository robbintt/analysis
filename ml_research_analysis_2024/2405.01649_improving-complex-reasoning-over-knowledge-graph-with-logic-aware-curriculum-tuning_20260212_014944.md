---
ver: rpa2
title: Improving Complex Reasoning over Knowledge Graph with Logic-Aware Curriculum
  Tuning
arxiv_id: '2405.01649'
source_url: https://arxiv.org/abs/2405.01649
tags:
- query
- reasoning
- knowledge
- queries
- complex
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes LACT, a complex reasoning schema over knowledge
  graphs (KGs) using large language models (LLMs) with a logic-aware curriculum tuning
  framework. LACT augments first-order logical queries via binary tree decomposition
  to stimulate LLM reasoning capabilities and addresses difficulty gaps among query
  types using a logic-aware curriculum learning framework.
---

# Improving Complex Reasoning over Knowledge Graph with Logic-Aware Curriculum Tuning

## Quick Facts
- arXiv ID: 2405.01649
- Source URL: https://arxiv.org/abs/2405.01649
- Authors: Tianle Xia; Liang Ding; Guojia Wan; Yibing Zhan; Bo Du; Dacheng Tao
- Reference count: 27
- Key outcome: LACT achieves state-of-the-art performance, improving MRR scores by an average of +5.5% over advanced methods

## Executive Summary
This paper introduces LACT, a framework for complex reasoning over knowledge graphs using large language models. LACT combines binary tree decomposition to break down complex queries into simpler sub-queries and a logic-aware curriculum learning approach that trains on progressively harder samples. The method demonstrates significant improvements in MRR scores across multiple benchmark datasets, showing strong generalization capabilities and robustness across different model sizes.

## Method Summary
LACT addresses complex logical query answering over incomplete knowledge graphs by augmenting LLMs with three key components: binary tree decomposition (BTD) to convert complex queries into simpler sub-queries, curriculum learning to organize training data by difficulty, and knowledge graph neighborhood retrieval to provide relevant context. The framework fine-tunes LLaMA-2 models using instruction templates that incorporate query decomposition steps and retrieved KG information, with training progressing through easy to hard samples to optimize learning efficiency.

## Key Results
- Achieves state-of-the-art performance with average +5.5% MRR improvement over advanced methods
- Demonstrates strong generalization to out-of-distribution queries not seen during training
- Shows effective scaling across different model sizes and datasets while maintaining robustness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Binary Tree Decomposition reduces reasoning complexity by converting complex queries into simpler sub-queries
- Mechanism: Decomposes complex EF O1 queries into binary trees, then reverses level traversal to create chains of simple sub-queries
- Core assumption: Decomposing queries into simpler components makes them easier for LLMs to reason about
- Evidence anchors:
  - [abstract]: "we augment the arbitrary first-order logical queries via binary tree decomposition, to stimulate the reasoning capability of LLMs"
  - [section]: "We split each 1-to-n intersection/union node into n corresponding child nodes"
  - [corpus]: Weak - corpus shows related work on tree decomposition but no direct experimental evidence here

### Mechanism 2
- Claim: Curriculum Learning smooths difficulty gaps between different query types by training on progressively harder samples
- Mechanism: Divides training data into easy/medium/hard based on subquery count, then trains in stages with increasing difficulty
- Core assumption: LLMs learn better when exposed to simpler tasks first before harder ones
- Evidence anchors:
  - [abstract]: "we design a simple and flexible logic-aware curriculum learning framework"
  - [section]: "we divided samples into three parts: easy samples, medium samples and difficult samples"
  - [corpus]: Weak - corpus shows general CL literature but no specific KG reasoning studies

### Mechanism 3
- Claim: Knowledge graph information incorporated into prompts provides context that improves reasoning accuracy
- Mechanism: Uses neighborhood retrieval to gather relevant triplets and includes them in the prompt with the query
- Core assumption: LLMs perform better when given relevant KG context rather than reasoning from scratch
- Evidence anchors:
  - [abstract]: "We propose a strategy to incorporate the knowledge contained in the KGs into our training corpus"
  - [section]: "The input textual sequence S consists of the description of question D, knowledge graph neighbourhood information"
  - [corpus]: Weak - corpus mentions KG retrieval but no direct comparison to zero-shot reasoning

## Foundational Learning

- Concept: First-Order Logic (FOL) queries and their operators (projection, intersection, union, negation)
  - Why needed here: LACT specifically handles EF O1 queries, which are a subset of FOL
  - Quick check question: Can you explain the difference between conjunctive normal form (CNF) and disjunctive normal form (DNF) and how they relate to query structure?

- Concept: Knowledge Graph Embeddings and their limitations
  - Why needed here: LACT is positioned as an alternative to embedding-based methods, so understanding their weaknesses is crucial
  - Quick check question: What are the four main limitations of knowledge graph embedding methods mentioned in the paper?

- Concept: Large Language Model fine-tuning techniques
  - Why needed here: LACT uses instruction tuning with curriculum learning, requiring understanding of fine-tuning paradigms
  - Quick check question: What's the difference between instruction tuning and standard supervised fine-tuning?

## Architecture Onboarding

- Component map:
  - Base LLM (LLaMA-2)
  - Binary Tree Decomposition module
  - Curriculum Learning scheduler
  - Neighborhood Retrieval algorithm
  - Prompt template generator

- Critical path:
  1. Query arrives and gets decomposed via BTD
  2. Neighborhood retrieval gathers relevant triplets
  3. Prompt template combines query, context, and decomposition
  4. LLM generates answer following the decomposed chain
  5. Answer extraction via regex from generated text

- Design tradeoffs:
  - Token limit vs. completeness of retrieved context
  - Complexity of decomposition vs. LLM reasoning capacity
  - Number of curriculum stages vs. training efficiency

- Failure signatures:
  - High perplexity on decomposed vs. non-decomposed queries
  - Performance drop on OOD query types
  - Training instability when mixing difficulty levels

- First 3 experiments:
  1. Compare perplexity of queries with vs. without BTD on validation set
  2. Test MRR improvement when adding curriculum stages vs. random training
  3. Measure token usage and MRR trade-off with different neighborhood retrieval depths

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the binary tree decomposition (BTD) mechanism scale with increasingly complex query structures beyond the tested 14 query types?
- Basis in paper: [explicit] The paper mentions BTD decomposes complex EF O1 queries into subqueries, but only evaluates on 14 predefined query types
- Why unresolved: The scalability and performance of BTD for more complex or cyclic queries remains untested
- What evidence would resolve it: Empirical results showing BTD performance on a broader range of query types, including cyclic queries or queries with higher arity operators

### Open Question 2
- Question: What is the impact of varying the curriculum learning stages' sample ratios on model performance?
- Basis in paper: [explicit] The paper uses a 80:10:10 ratio for easy:medium:hard samples in the three training stages, but mentions this was decided after exploratory experiments
- Why unresolved: The optimal ratio for curriculum learning stages is not systematically studied, and the chosen ratio may not be universally optimal
- What evidence would resolve it: Ablation studies comparing different sample ratios across the curriculum stages and their effects on MRR scores

### Open Question 3
- Question: How does LACT's performance change with different knowledge graph incompleteness levels?
- Basis in paper: [inferred] The paper mentions LACT performs better with more complete information, but doesn't systematically vary the incompleteness level of the KG
- Why unresolved: The relationship between KG completeness and LACT's reasoning performance is not fully characterized
- What evidence would resolve it: Experiments varying the completeness of the KG and measuring corresponding changes in LACT's MRR scores

## Limitations
- Weak evidence anchors for critical mechanisms, particularly neighborhood retrieval and prompt templates
- Limited evaluation on more complex or cyclic query types beyond the 14 predefined structures
- No systematic study of optimal curriculum learning stage ratios or their impact on performance

## Confidence
- Mechanism 1 (BTD): Medium confidence - Decomposition approach is clear but lacks isolated ablation studies
- Mechanism 2 (Curriculum Learning): Medium confidence - Staging approach is detailed but not compared to alternatives
- Mechanism 3 (KG Context): Low confidence - Retrieval mechanism mentioned but not thoroughly validated

## Next Checks
1. Replicate the study with ablation testing on each mechanism independently (BTD only, curriculum only, KG context only) to isolate their individual contributions
2. Test the neighborhood retrieval algorithm's completeness by measuring recall of relevant triplets at different depth levels and comparing against oracle retrieval
3. Evaluate the model's robustness by measuring performance degradation when training data is limited or when queries are randomly ordered instead of curriculum-ordered