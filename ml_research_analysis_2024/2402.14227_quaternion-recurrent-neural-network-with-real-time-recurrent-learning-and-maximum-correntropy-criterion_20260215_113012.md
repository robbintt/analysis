---
ver: rpa2
title: Quaternion recurrent neural network with real-time recurrent learning and maximum
  correntropy criterion
arxiv_id: '2402.14227'
source_url: https://arxiv.org/abs/2402.14227
tags:
- quaternion
- rtrl
- function
- qrnn
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a quaternion recurrent neural network (QRNN)
  for real-time processing of 3D and 4D data with outliers. The approach combines
  the real-time recurrent learning (RTRL) algorithm and the maximum correntropy criterion
  (MCC) as a loss function, using the generalised HR (GHR) calculus for compact derivations.
---

# Quaternion recurrent neural network with real-time recurrent learning and maximum correntropy criterion

## Quick Facts
- arXiv ID: 2402.14227
- Source URL: https://arxiv.org/abs/2402.14227
- Reference count: 37
- Primary result: QRNN with RTRL and MCC loss achieves lowest MAE, RMSE, and nRMSE for motion prediction in lung cancer radiotherapy

## Executive Summary
This paper introduces a quaternion recurrent neural network (QRNN) designed for real-time processing of 3D and 4D data with outliers, specifically applied to motion prediction for lung cancer radiotherapy. The approach combines real-time recurrent learning (RTRL) with maximum correntropy criterion (MCC) as a loss function, using generalized HR (GHR) calculus for compact gradient derivations. The QRNN demonstrates superior performance compared to standard RNNs and quaternion least mean square algorithms, particularly in handling irregular breathing patterns during treatment.

## Method Summary
The proposed QRNN processes quaternion-valued 3D marker positions using RTRL for online adaptation and MCC as a robust loss function. The method employs GHR calculus to derive gradients efficiently for quaternion-valued functions. The QRNN was trained on chest marker position data from lung cancer radiotherapy patients, with regular and irregular breathing sequences, and evaluated using MAE, RMSE, and nRMSE metrics. The approach was compared against RNNs with MSE/MCC, QLMS, and LMS algorithms.

## Key Results
- QRNN with RTRL and MCC achieved lowest MAE, RMSE, and nRMSE compared to other methods
- Demonstrated robustness to irregular breathing patterns with smallest nRMSE increase between regular and irregular sequences
- QRNN+RTRL+MCC showed ~50% slower training than RNNs but superior performance on irregular patterns

## Why This Works (Mechanism)

### Mechanism 1
The non-quadratic MCC loss function is less sensitive to outliers than MSE because it uses a kernel-based similarity measure rather than a quadratic penalty. The MCC employs a Gaussian kernel that assigns higher weights to errors closer to the mean and rapidly down-weights larger errors, making the loss function robust to extreme values. This mechanism assumes the data contains outliers or heavy-tailed noise distributions.

### Mechanism 2
The GHR calculus enables compact derivations of quaternion gradients that would otherwise be extremely cumbersome. GHR calculus provides product and chain rules for quaternion functions, allowing gradient computations to be expressed in a more elegant and computationally efficient form. This mechanism assumes the learning algorithms require quaternion differentiation that cannot be handled by standard real-valued calculus.

### Mechanism 3
The combination of QRNN with RTRL and MCC provides robust motion prediction for irregular breathing patterns in lung cancer radiotherapy. The quaternion structure captures 3D spatial relationships, RTRL enables online adaptation to changing breathing patterns, and MCC provides robustness to irregular movements and noise. This mechanism assumes real-time adaptation is necessary for handling patient breathing variability during treatment.

## Foundational Learning

- **Quaternion algebra and operations**: Why needed - The data is naturally 3D/4D (marker positions), and quaternions provide compact representation with rotational properties. Quick check - What is the result of multiplying two quaternions q1 = a1 + ib1 + jc1 + kd1 and q2 = a2 + ib2 + jc2 + kd2?
- **Recurrent neural network dynamics and BPTT/RTRL algorithms**: Why needed - The problem involves time-series prediction of breathing patterns, requiring temporal modeling. Quick check - How does RTRL differ from backpropagation through time in terms of computational complexity and online learning capability?
- **Maximum correntropy criterion and kernel methods**: Why needed - The presence of outliers and irregular breathing patterns requires a robust loss function. Quick check - How does the Gaussian kernel in MCC down-weight large errors compared to the quadratic penalty in MSE?

## Architecture Onboarding

- **Component map**: Input layer (Quaternion-valued 3D marker positions) -> Hidden layers (QRNN layers with split hyperbolic tangent activation) -> Output layer (Predicted quaternion positions) -> Loss function (MCC with Gaussian kernel) -> Learning algorithm (RTRL with gradient clipping)
- **Critical path**: Forward pass → Error computation → Gradient calculation via GHR calculus → Weight updates → Prediction
- **Design tradeoffs**: QRNN vs RNN (QRNN captures multidimensional structure but is ~50% slower to train), MCC vs MSE (MCC is more robust to outliers but may be less precise for regular patterns), RTRL vs BPTT (RTRL enables online learning but has higher per-step complexity)
- **Failure signatures**: Vanishing/exploding gradients despite clipping (adjust learning rate or gradient norm threshold), poor performance on regular breathing patterns (consider switching to MSE), excessive jitter in predictions (adjust kernel size σ or learning rate)
- **First 3 experiments**: 1) Implement basic QRNN with MSE loss and RTRL to verify quaternion operations work correctly, 2) Add MCC loss function and compare performance on regular vs irregular breathing data, 3) Test online learning capability by evaluating performance on data not seen during initial training

## Open Questions the Paper Calls Out

### Open Question 1
How does the choice of kernel size (σ) in the maximum correntropy criterion affect the robustness and performance of the quaternion recurrent neural network (QRNN) in real-time applications with noisy or uncertain data? The paper mentions MCC is less sensitive to outliers but does not provide specific details on the impact of kernel size selection. Empirical studies comparing QRNN performance with different kernel sizes on diverse datasets with varying noise levels would provide insights into the optimal choice of σ for robust real-time processing.

### Open Question 2
Can the quaternion recurrent neural network (QRNN) with real-time recurrent learning (RTRL) and maximum correntropy criterion (MCC) be extended to handle higher-dimensional data beyond 3D and 4D, such as 5D or 6D data, and what are the computational implications? The paper focuses on 3D and 4D data applications, suggesting potential for extension to higher dimensions, but does not address the feasibility or computational challenges of such extensions. Testing the QRNN with RTRL and MCC on datasets with dimensions higher than 4D and analyzing the computational requirements would clarify its scalability and limitations.

### Open Question 3
How does the quaternion recurrent neural network (QRNN) with real-time recurrent learning (RTRL) and maximum correntropy criterion (MCC) compare to other state-of-the-art deep learning models, such as transformers or long short-term memory (LSTM) networks, in terms of accuracy and computational efficiency for real-time processing of 3D and 4D data? The paper compares the QRNN with RTRL and MCC to standard RNNs, quaternion least mean square algorithms, and least mean square algorithms, but does not include comparisons with more advanced models like transformers or LSTMs. Benchmarking the QRNN with RTRL and MCC against transformers and LSTMs on the same datasets would provide a clearer understanding of its strengths and weaknesses.

## Limitations

- Experimental validation relies on a single dataset (lung cancer radiotherapy breathing markers), limiting generalizability
- Hyperparameter sensitivity analysis is incomplete - specific values for learning rate, kernel size σ, and number of hidden units are not provided
- Computational complexity comparisons between the proposed method and alternatives are limited to training speed differences without considering real-time inference constraints

## Confidence

**High Confidence**: The mathematical foundations (GHR calculus, quaternion algebra, MCC properties) are well-established in the literature and the derivations appear correct.

**Medium Confidence**: The superiority of QRNN+RTRL+MCC for irregular breathing pattern prediction is demonstrated, but the single dataset and lack of ablation studies reduce confidence in the specific combination being optimal.

**Low Confidence**: Claims about computational efficiency and scalability to larger problems are not supported by systematic experiments.

## Next Checks

1. **Ablation Study**: Test QRNN with MSE loss, RNN with MCC loss, and QRNN with BPTT to isolate the contribution of each innovation to the overall performance improvement.

2. **Dataset Generalization**: Validate the approach on additional 3D/4D time-series datasets with outliers (e.g., motion capture data, sensor networks, financial time series) to assess broader applicability.

3. **Real-time Performance Analysis**: Measure inference latency and memory usage for the proposed QRNN+RTRL+MCC method compared to alternatives on the same hardware to quantify practical deployment constraints.