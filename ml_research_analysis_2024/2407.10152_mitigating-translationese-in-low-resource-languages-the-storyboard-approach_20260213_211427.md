---
ver: rpa2
title: 'Mitigating Translationese in Low-resource Languages: The Storyboard Approach'
arxiv_id: '2407.10152'
source_url: https://arxiv.org/abs/2407.10152
tags:
- translations
- text
- language
- sentences
- sentence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of translationese artifacts
  in low-resource language data collection by proposing a storyboard-based approach.
  Instead of directly translating English sentences, native speakers describe scenes
  from storyboards in their target languages, reducing direct exposure to source text.
---

# Mitigating Translationese in Low-resource Languages: The Storyboard Approach

## Quick Facts
- **arXiv ID**: 2407.10152
- **Source URL**: https://arxiv.org/abs/2407.10152
- **Reference count**: 0
- **Primary result**: Storyboard-based translations achieve better fluency and lexical diversity than direct text translations for low-resource African languages, though with lower accuracy.

## Executive Summary
This paper addresses the challenge of translationese artifacts in low-resource language data collection by proposing a storyboard-based approach. Instead of directly translating English sentences, native speakers describe scenes from storyboards in their target languages, reducing direct exposure to source text. Human evaluation and automated metrics show that while text translations are more accurate, storyboard translations achieve better fluency and lexical diversity across four African languages (Hausa, Ibibio, Swahili, and Yoruba). Specifically, human annotators preferred storyboard translations for fluency (e.g., 60% for Hausa), and storyboard translations demonstrated higher MTLD scores and lower POS perplexity in most languages, indicating more natural and diverse sentence structures.

## Method Summary
The study compares two approaches to translation: direct text translation (control group) and storyboard-based translation (treatment group). Native speakers in Hausa, Ibibio, Swahili, and Yoruba were tasked with either translating English sentences directly or describing images from storyboards without seeing the English text. The researchers used 26 storyboards from the Totem Field Storyboards dataset, with a 1-hour gap between viewing English sentences and translating images in the treatment group. Translations were evaluated through human assessment (accuracy and fluency) by native speakers proficient in both source and target languages, as well as automated metrics including LASER embeddings cosine similarity, MTLD for lexical diversity, and POS perplexity for syntactic complexity.

## Key Results
- Human annotators preferred storyboard translations for fluency over text translations in all four languages (Hausa: 60%, Ibibio: 66%, Swahili: 58%, Yoruba: 56%)
- Storyboard translations achieved higher MTLD scores in 3 out of 4 languages, indicating greater lexical diversity
- Text translations maintained superior accuracy compared to storyboard translations across all languages
- POS perplexity was lower for storyboard translations in 3 out of 4 languages, suggesting more natural syntactic structures

## Why This Works (Mechanism)
The storyboard approach reduces translationese artifacts by minimizing direct exposure to source text. When translators describe images without seeing the English sentences, they must rely on their understanding of the visual content rather than mimicking the source text structure. This encourages more natural expression in the target language and reduces the tendency to reproduce English syntactic patterns. The 1-hour gap between viewing English sentences and translating images further helps prevent translators from directly copying source text structures.

## Foundational Learning

**Translationese artifacts**: Systematic deviations from natural language that occur when translating from one language to another, often characterized by unnatural word choices and syntactic structures. Why needed: Understanding translationese is crucial for recognizing the problem this paper aims to solve. Quick check: Look for examples of unnatural phrasing that seems influenced by source language structure.

**MTLD (Measure of Textual Lexical Diversity)**: A metric that measures the diversity of vocabulary in a text by calculating the average length of sequential word strings that maintain a certain type-token ratio. Why needed: MTLD quantifies the lexical diversity claimed to be improved by the storyboard approach. Quick check: Higher MTLD values indicate greater lexical variety in translations.

**POS perplexity**: A measure of how predictable the sequence of part-of-speech tags is in a text, with lower values indicating more natural syntactic patterns. Why needed: POS perplexity helps evaluate whether translations follow natural grammatical patterns of the target language. Quick check: Compare POS perplexity values across different translation approaches to assess naturalness.

## Architecture Onboarding

**Component map**: Totem Field Storyboards dataset -> Translation tasks (control vs. treatment) -> Human evaluation (accuracy/fluency) -> Automated metrics (LASER, MTLD, POS perplexity) -> Analysis and comparison

**Critical path**: Storyboard selection -> Translation task assignment (control/treatment) -> Translation collection -> Human evaluation -> Automated metric computation -> Results analysis

**Design tradeoffs**: The approach trades accuracy for fluency and lexical diversity. Direct text translation yields more accurate translations but may produce translationese, while storyboard translation promotes natural language use at the cost of some accuracy.

**Failure signatures**: 
- If translators in the treatment group still produce translationese, it may indicate insufficient separation between source text viewing and image description
- Low LASER cosine similarity between control and treatment translations could indicate divergent content rather than reduced translationese
- If MTLD scores don't improve in storyboard translations, it may suggest translators are still influenced by source language patterns

**3 first experiments**:
1. Measure inter-annotator agreement for human evaluation to establish reliability of fluency and accuracy assessments
2. Compare LASER cosine similarity between control and treatment translations to quantify content preservation
3. Analyze specific linguistic features (e.g., word order, function words) to identify translationese patterns in text vs. storyboard translations

## Open Questions the Paper Calls Out

**Open Question 1**: How does the accuracy and fluency of storyboard-based translations compare to traditional text translations for more complex text types beyond simple sentences? The paper mentions that the feasibility of the method for translating intricate and detailed texts remains a point of contention, and storyboards might fall short in capturing the depth and nuances of elaborate narratives or technical documents. This remains unresolved as the study focused on simple sentences from storyboards and did not test more complex text types.

**Open Question 2**: How can generative AI models be effectively integrated into the storyboard creation process to improve efficiency and quality while addressing current limitations like character inconsistency and conveying complex messages? The paper discusses the potential of generative AI models like DALLE-3 for automating storyboard creation and highlights current challenges such as character inconsistency and conveying complex messages visually. This remains unresolved as the paper only provides a preliminary exploration without concrete solutions or effectiveness evaluations.

**Open Question 3**: How does the performance of storyboard-based translations compare to traditional text translations across a wider range of languages, including non-African languages and languages with different typological features? The study focused on four low-resource African languages and acknowledges that the results may not generalize to other languages or language families. This remains unresolved as the study only tested a limited set of languages, and the effectiveness may vary depending on linguistic characteristics.

## Limitations
- The study's focus on only four African languages limits generalizability to other language families
- The 1-hour gap between viewing English sentences and translating images may not be sufficient to prevent translationese influence
- The selection criteria for storyboards from the Totem Field dataset are not explicitly specified

## Confidence

**High confidence**: In the fluency and lexical diversity improvements demonstrated by storyboard translations
**Medium confidence**: In the trade-off between accuracy and fluency, as this requires careful interpretation of human evaluation results
**Low confidence**: In the generalizability of findings to other language families due to limited language coverage

## Next Checks

1. Conduct a controlled experiment to measure the effectiveness of the 1-hour gap in preventing translationese influence by comparing results with and without the delay
2. Expand the study to include additional languages from different families to assess the approach's generalizability
3. Perform a qualitative analysis of the storyboard translations to identify specific linguistic features that contribute to improved fluency and diversity