---
ver: rpa2
title: Language and Speech Technology for Central Kurdish Varieties
arxiv_id: '2403.01983'
source_url: https://arxiv.org/abs/2403.01983
tags:
- kurdish
- language
- central
- dialects
- corpus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents CORDI, the first corpus of colloquial speech
  for Central Kurdish varieties, created by transcribing over 300 movies and TV series.
  The corpus contains 186,038 utterances across six subdialects (Sulaymaniyah, Sanandaj,
  Erbil, Mahabad, Kalar, and Sardasht) with speaker metadata.
---

# Language and Speech Technology for Central Kurdish Varieties

## Quick Facts
- arXiv ID: 2403.01983
- Source URL: https://arxiv.org/abs/2403.01983
- Reference count: 16
- First corpus of colloquial speech for Central Kurdish varieties created from movies/TV series

## Executive Summary
This paper introduces CORDI, the first corpus of colloquial speech for Central Kurdish varieties, created by transcribing over 300 movies and TV series. The corpus contains 186,038 utterances across six subdialects (Sulaymaniyah, Sanandaj, Erbil, Mahabad, Kalar, and Sardasht) with speaker metadata. The authors conduct comparative linguistic analysis of these subdialects and evaluate downstream tasks including machine translation, automatic speech recognition, and language identification. Experimental results show that existing models perform suboptimally on dialectal data compared to standard varieties, highlighting the need for dialect-specific resources.

## Method Summary
The paper presents a three-part approach: corpus creation through transcription of movies and TV series dialogue, comparative linguistic analysis of six Central Kurdish subdialects, and evaluation of downstream NLP tasks. The CORDI corpus was created by transcribing 311 movies and series, resulting in 186,038 utterances. The linguistic analysis examines phonetic, phonological, morphological, syntactic, and lexical variations across subdialects. For downstream tasks, the authors evaluate machine translation using NLLB and Google Translate models, automatic speech recognition with Fairseq, and language identification using fastText and custom models.

## Key Results
- CORDI corpus contains 186,038 utterances across six Central Kurdish subdialects
- Existing NMT models show BLEU scores ranging from 19.9 to 43.6 on dialectal data
- ASR models achieve WER scores above 50-100 on subdialect test sets
- Language identification models achieve F1 scores between 0.76-0.986 depending on task complexity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The corpus of colloquial speech addresses the data paucity for Central Kurdish varieties by providing authentic dialectal data from multiple subdialects.
- Mechanism: Transcribing movies and TV series captures natural, colloquial speech that represents regional dialectal variations, which is typically missing from journalistic corpora.
- Core assumption: Movie and TV dialogue accurately represent natural speech patterns and dialectal variations of the targeted subdialects.
- Evidence anchors:
  - [abstract] "creating a corpus by transcribing movies and TV series as an alternative to fieldwork"
  - [section 3.1] "we create the corpus of dialogues in Central Kurdish – CORDI... based on the dialogues in over 300 movies and series"
  - [corpus] The corpus contains 186,038 utterances across six subdialects with speaker metadata
- Break condition: If the transcribed material doesn't represent authentic colloquial speech or if speakers in movies/series use standardized language rather than regional dialects.

### Mechanism 2
- Claim: The comparative linguistic analysis of Central Kurdish subdialects provides insights into phonetic, phonological, morphological, and lexical variations.
- Mechanism: Systematic comparison of linguistic features across six subdialects reveals patterns of variation and helps establish relationships between subdialects and the standard variety.
- Core assumption: The selected corpus material is representative enough to capture meaningful linguistic variation across the subdialects.
- Evidence anchors:
  - [abstract] "comparative linguistic analysis of these subdialects"
  - [section 4] "Comparative Dialectal Analysis" with subsections on phonetics, phonology, morphology, syntax, and lexicon
  - [corpus] The corpus contains sufficient data from each subdialect (ranging from 1,137 to 115,083 utterances)
- Break condition: If the corpus doesn't capture enough linguistic diversity or if the analysis is based on insufficient data from certain subdialects.

### Mechanism 3
- Claim: Downstream task evaluation demonstrates the limitations of existing models on dialectal data compared to standard varieties.
- Mechanism: Testing machine translation, automatic speech recognition, and language identification on dialectal data reveals performance gaps that highlight the need for dialect-specific resources.
- Core assumption: The evaluation tasks are appropriate benchmarks for measuring model performance on dialectal data.
- Evidence anchors:
  - [abstract] "evaluate downstream tasks including machine translation... automatic speech recognition... and language identification"
  - [section 5] "Experiments" section with results showing sub-optimal performance on dialectal data
  - [corpus] The corpus provides appropriate test data for each downstream task evaluation
- Break condition: If the downstream tasks don't adequately capture the challenges of dialectal variation or if the evaluation methodology is flawed.

## Foundational Learning

- Concept: Linguistic variation in dialect continua
  - Why needed here: Understanding how Central Kurdish varieties differ from each other and from the standard is crucial for interpreting the corpus and downstream task results
  - Quick check question: How would you differentiate between a dialect continuum and a set of discrete dialects?

- Concept: Speech corpus creation methodology
  - Why needed here: Knowing how to create and structure speech corpora is essential for understanding the CORDI corpus construction process
  - Quick check question: What are the key considerations when creating a speech corpus from movie/TV transcriptions versus fieldwork recordings?

- Concept: Evaluation metrics for language technology
  - Why needed here: Understanding metrics like BLEU, WER, and F1 scores is necessary for interpreting the experimental results
  - Quick check question: What does a BLEU score of 19.9 indicate about machine translation quality compared to a score of 43.6?

## Architecture Onboarding

- Component map: Video transcription pipeline → CORDI corpus → linguistic analysis module → downstream task evaluation framework
- Critical path: Corpus creation → downstream task evaluation, as the corpus is the foundational resource enabling all other work
- Design tradeoffs: Using movie/TV transcriptions provides rich colloquial data but may introduce bias toward certain dialects and register; fieldwork would provide more balanced representation but requires more resources
- Failure signatures: Poor performance in downstream tasks indicates either insufficient corpus quality/diversity or inadequate model adaptation for dialectal variation
- First 3 experiments:
  1. Test existing NMT models on CORDI test sets to establish baseline performance
  2. Train a dialect-aware language identification model on the corpus
  3. Evaluate the effect of dialectalization rules on machine translation quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the inclusion of colloquial speech data from movies and TV series affect the performance of language technology tools compared to standard journalistic corpora?
- Basis in paper: [explicit] The paper discusses the creation of CORDI, a corpus of colloquial speech from movies and TV series, and evaluates downstream tasks like machine translation, automatic speech recognition, and language identification on Central Kurdish varieties.
- Why unresolved: While the paper provides initial results showing suboptimal performance on dialectal data, it does not explore the long-term impact or specific improvements that could be made by incorporating more colloquial data.
- What evidence would resolve it: Comparative studies over time showing performance improvements with increased colloquial data, or specific case studies where colloquial data significantly enhances tool performance.

### Open Question 2
- Question: What are the specific linguistic features that contribute most to the challenges in automatic speech recognition for Central Kurdish subdialects?
- Basis in paper: [explicit] The paper reports high word error rates (WER) for automatic speech recognition on Central Kurdish subdialects, indicating significant challenges.
- Why unresolved: The paper identifies challenges but does not pinpoint specific linguistic features such as phonetic variations or morphological complexities that are most problematic.
- What evidence would resolve it: Detailed linguistic analysis of ASR errors, focusing on phonetic, morphological, and syntactic features that lead to recognition failures.

### Open Question 3
- Question: How effective are current rule-based approaches in handling the morphological and syntactic variations across Central Kurdish subdialects in machine translation tasks?
- Basis in paper: [explicit] The paper discusses the use of rule-based approaches for dialectalization and standardization in machine translation, noting modest improvements but also highlighting the complexities involved.
- Why unresolved: The paper provides initial insights into the effectiveness of these approaches but does not explore their limitations or potential improvements in depth.
- What evidence would resolve it: Comprehensive evaluation of rule-based approaches across different dialects, identifying specific areas where they succeed or fail, and proposing enhancements or alternative methods.

## Limitations

- The corpus relies on movie/TV transcriptions which may not fully represent all subdialects equally
- Downstream task performance remains suboptimal, with BLEU scores below 20 for most subdialects
- The effectiveness of rule-based dialectalization/standardization approaches has not been fully explored

## Confidence

- Corpus creation methodology: Medium confidence
- Comparative linguistic analysis: Medium confidence
- Downstream task evaluation results: Low confidence in current model performance on dialectal data

## Next Checks

1. Conduct speaker verification to ensure transcribed content accurately represents authentic colloquial speech from each targeted subdialect
2. Perform inter-annotator agreement assessment on a subset of transcriptions to establish reliability of the corpus creation process
3. Test dialectalization/standardization rules on held-out development data to verify their effectiveness before downstream task evaluation