---
ver: rpa2
title: Estimating the Probabilities of Rare Outputs in Language Models
arxiv_id: '2410.13211'
source_url: https://arxiv.org/abs/2410.13211
tags:
- sampling
- methods
- distribution
- probability
- token
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper studies estimating the probability of a rare event (e.g.,
  a specific token being output by a language model) when that probability is too
  small for random sampling to yield good estimates. It considers input distributions
  where each token is sampled independently, and evaluates methods for estimating
  the probability that a given target token is argmax sampled.
---

# Estimating the Probabilities of Rare Outputs in Language Models

## Quick Facts
- **arXiv ID**: 2410.13211
- **Source URL**: https://arxiv.org/abs/2410.13211
- **Authors**: Gabriel Wu; Jacob Hilton
- **Reference count**: 40
- **Primary result**: Importance sampling methods outperform activation extrapolation for estimating rare token probabilities in small transformer models.

## Executive Summary
This paper studies the challenge of estimating probabilities for rare outputs in language models, where the target probability is too small for random sampling to yield reliable estimates. The authors compare two classes of methods: importance sampling, which searches for inputs that produce rare outputs and reweights samples, and activation extrapolation, which fits distributions to model logits and extrapolates. Experiments on small transformer models (1-4 layers) with 216 model calls per method show that importance sampling consistently outperforms activation extrapolation, with Metropolis-Hastings Importance Sampling (MHIS) generally performing best on larger models and Independent Token Gradient Importance Sampling (ITGIS) on smaller models.

## Method Summary
The paper compares four estimation methods for rare event probabilities in transformer language models. Two importance sampling methods are tested: ITGIS, which treats token positions independently and uses gradients to obtain a new input distribution, and MHIS, which uses MCMC to sample from a non-independent distribution. Two activation extrapolation methods are also evaluated: QLD, which decomposes pre-unembed activations into independent subspaces and fits distributions to each, and GLD, which fits a Gaussian to the difference between maximum and target logits. Experiments use small transformer models (1, 2, and 4 layers) with a computational budget of 216 model calls per method, testing on 8 input distributions and 256 target tokens with ground truth probabilities between 10^-9 and 10^-5.

## Key Results
- Importance sampling methods consistently outperform activation extrapolation methods for rare event probability estimation
- MHIS performs best on larger models while ITGIS excels on smaller models
- QLD outperforms GLD among activation extrapolation methods
- Both method classes significantly outperform naive random sampling for low probability events

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Importance sampling methods can efficiently estimate rare event probabilities by biasing the sampling distribution toward inputs that produce the target behavior.
- **Mechanism**: The method constructs a new distribution q(x) that upweights inputs likely to produce the rare output, then reweights samples using importance sampling to obtain an unbiased estimate of the original probability.
- **Core assumption**: The importance sampling distribution q(x) can be designed to have a lower variance estimator than naive sampling.
- **Evidence anchors**:
  - [abstract] "importance sampling, which involves searching for inputs giving rise to the rare output, and activation extrapolation, which involves extrapolating a probability distribution fit to the model's logits. We find that importance sampling outperforms activation extrapolation, but both outperform naive sampling."
  - [section] "Naive sampling fails to produce good estimates for low probability events because it takes too many samples from D to observe a positive example. To address this, we can instead draw samples from a different distribution that up-weights regions of input space most likely to produce the behavior of interest."
- **Break condition**: If the target behavior is too rare or the model is too complex for importance sampling to efficiently find positive examples, the method will fail to produce good estimates.

### Mechanism 2
- **Claim**: Activation extrapolation methods can estimate rare event probabilities without explicitly finding inputs that produce the behavior.
- **Mechanism**: The method fits a probability distribution to the model's logits using random samples, then extrapolates into the tails of this distribution to estimate the probability of the rare event.
- **Core assumption**: The model's logits follow a distribution that can be reasonably fit using a small number of random samples, and this distribution can be extrapolated to estimate very low probabilities.
- **Evidence anchors**:
  - [abstract] "activation extrapolation, which involves extrapolating a probability distribution fit to the model's logits."
  - [section] "We use random samples to fit a probability distribution to the model's logits, and extrapolate into the tails of this distribution to produce a probability estimate."
- **Break condition**: If the model's logits don't follow a tractable distribution, or if the rare event lies in a part of the distribution that can't be accurately extrapolated from limited samples.

### Mechanism 3
- **Claim**: The Quadratic Logit Decomposition (QLD) method can estimate rare event probabilities by assuming independence between uncorrelated subspaces of the model's activations.
- **Mechanism**: The method decomposes the model's pre-unembed activations into two uncorrelated subspaces, fits distributions to each subspace independently, and combines them to estimate the probability of the rare event.
- **Core assumption**: The pre-unembed activations can be decomposed into two subspaces such that the contribution to the rare event is roughly equally split between them, and these subspaces are independent.
- **Evidence anchors**:
  - [section] "We first collect n samples of v (call them v(1), . . . ,v(n)). We then choose some unit direction d ∈ Rd (see below), then decompose each v(i) into a(i) + b(i), where a lies in the subspace spanned by d, and b lies in the complementary subspace that is orthogonal in a whitened basis."
  - [section] "by treating the random vectors a and b as independent, we can use our n samples of each to obtain n2 'synthetic' samples of u."
- **Break condition**: If the contribution to the rare event is not roughly equally split between the two subspaces, or if the subspaces are not independent, the QLD method will produce biased estimates.

## Foundational Learning

- **Concept**: Importance sampling
  - **Why needed here**: Importance sampling is the core mechanism used by two of the four estimation methods to efficiently estimate rare event probabilities by biasing the sampling distribution.
  - **Quick check question**: What is the key idea behind importance sampling, and how does it help in estimating rare event probabilities?

- **Concept**: Activation functions and logits in neural networks
  - **Why needed here**: The activation extrapolation methods rely on understanding how neural networks produce outputs through activations and logits, and how these can be modeled and extrapolated.
  - **Quick check question**: How do neural networks use activations and logits to produce outputs, and why is this relevant for estimating rare event probabilities?

- **Concept**: Markov Chain Monte Carlo (MCMC) methods
  - **Why needed here**: The Metropolis-Hastings Importance Sampling (MHIS) method uses MCMC to sample from a non-independent distribution, which is crucial for its operation.
  - **Quick check question**: What is the purpose of MCMC methods in the context of the MHIS method, and how do they help in sampling from complex distributions?

## Architecture Onboarding

- **Component map**: Input distributions -> Transformer models -> Estimation methods (ITGIS, MHIS, QLD, GLD) -> Probability estimates
- **Critical path**: Generate samples from input distributions → Run through transformer model → Apply estimation method → Produce probability estimate
- **Design tradeoffs**: Importance sampling vs activation extrapolation involves tradeoff between computational efficiency (importance sampling) and ability to estimate without finding explicit examples (activation extrapolation)
- **Failure signatures**: Importance sampling methods may fail if they can't find enough positive examples; activation extrapolation methods may fail if logits don't follow tractable distribution or extrapolation is inaccurate
- **First 3 experiments**:
  1. Implement basic ITGIS method and test on simple input distribution and model
  2. Implement QLD method and compare performance to ITGIS on same distribution and model
  3. Extend experiments to include MHIS method and test performance on larger models where inter-token interactions are more significant

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How do estimation methods perform on non-independent token distributions?
- **Basis in paper**: [explicit] The paper explicitly states that all input distributions used are independent, and this is necessary for the definition of ITGIS. It also notes that extending beyond independent token input distributions would require adapting the current estimation methods.
- **Why unresolved**: The paper's experimental setup is limited to independent token distributions, so there is no data on how the methods perform in more complex scenarios.
- **What evidence would resolve it**: Empirical results comparing the performance of the methods on non-independent token distributions, such as those generated by a separate generative model, would provide insight into their generalizability.

### Open Question 2
- **Question**: Can activation extrapolation methods be improved to match the performance of importance sampling methods?
- **Basis in paper**: [inferred] The paper finds that importance sampling methods outperform activation extrapolation methods in their experiments. However, it also suggests that new methods, particularly those leveraging internal model activations, may be needed for stronger guarantees about worst-case performance.
- **Why unresolved**: The paper does not explore potential improvements to activation extrapolation methods or alternative approaches that could achieve similar performance to importance sampling.
- **What evidence would resolve it**: Development and evaluation of new activation extrapolation methods that can match or exceed the performance of importance sampling methods on the same tasks would address this question.

### Open Question 3
- **Question**: How do the estimation methods perform on longer sequences of autoregressive generation?
- **Basis in paper**: [explicit] The paper explicitly states that the study is limited to single-token behaviors and notes that in practice, behaviors of concern likely involve long chains of autoregressive generation or interaction with the external world.
- **Why unresolved**: The experimental setup focuses on single-token outputs, so there is no data on how the methods perform in more realistic, multi-token scenarios.
- **What evidence would resolve it**: Empirical results evaluating the estimation methods on tasks involving longer sequences of autoregressive generation, such as language modeling or text completion, would provide insight into their practical applicability.

## Limitations

- Experiments are limited to small transformer models (1-4 layers) with relatively simple independent token distributions
- Computational budget of 216 model calls per method may disadvantage methods requiring more samples
- Temperature tuning procedure for importance sampling is only partially specified
- Study does not investigate performance on non-independent token distributions or longer autoregressive sequences

## Confidence

- **High confidence**: Comparative results between importance sampling and activation extrapolation methods are well-supported by experimental data across multiple model sizes
- **Medium confidence**: Relative performance differences between ITGIS and MHIS across model sizes are supported but may be sensitive to temperature tuning and budget constraints
- **Low confidence**: Claims about needing new methods for stronger worst-case guarantees are speculative and not directly tested

## Next Checks

1. **Temperature sensitivity analysis**: Systematically vary the temperature parameter across a wider range and quantify how sensitive each method's performance is to this hyperparameter choice, particularly comparing ITGIS and MHIS under identical temperature search procedures.

2. **Independence assumption validation**: For the QLD method, empirically measure the correlation between the decomposed subspaces across multiple runs and input distributions to quantify how often the independence assumption holds, and correlate this with estimation accuracy.

3. **Scalability evaluation**: Test these methods on larger transformer models (8+ layers) with attention mechanisms and non-independent input distributions to determine if the relative performance ordering between methods remains consistent as model complexity increases.