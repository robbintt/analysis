---
ver: rpa2
title: Generative Design through Quality-Diversity Data Synthesis and Language Models
arxiv_id: '2405.09997'
source_url: https://arxiv.org/abs/2405.09997
tags:
- design
- designs
- language
- dataset
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces TileGPT, a novel approach to generative design
  that integrates Quality-Diversity optimization, language models, and constraint
  satisfaction to address challenges in data acquisition and constraint adherence
  in architectural design. The method generates a diverse dataset using MAP-Elites,
  fine-tunes a language model with this data, and employs the Wave Function Collapse
  algorithm to ensure constraint compliance in generated layouts.
---

# Generative Design through Quality-Diversity Data Synthesis and Language Models

## Quick Facts
- arXiv ID: 2405.09997
- Source URL: https://arxiv.org/abs/2405.09997
- Reference count: 40
- Primary result: TileGPT combines Quality-Diversity optimization, language models, and Wave Function Collapse to generate constraint-compliant architectural designs from text prompts.

## Executive Summary
This paper introduces TileGPT, a novel generative design system that integrates Quality-Diversity (QD) optimization, language models, and constraint satisfaction to create architectural layouts. The method addresses key challenges in generative design: acquiring high-quality training data and ensuring designs meet construction constraints. By using MAP-Elites to generate a diverse dataset of WFC-generated designs, fine-tuning a language model on this data, and applying WFC for constraint compliance, TileGPT produces valid designs that closely align with textual prompts. Experiments show significant improvements over models trained on randomly sampled datasets.

## Method Summary
TileGPT generates a dataset of 50,000 paired designs and attributes using MAP-Elites with WFC-based genomes. The adjacency rules from 5 base layouts define 216 tile states. A causal language model (DistilGPT2) is fine-tuned on tokenized designs with cross-attention conditioning from a BART text encoder. The trained model generates designs from text prompts, which are then refined using WFC to ensure constraint compliance. The system is evaluated on validity (WFC solver success rate) and fidelity (attribute alignment with prompts).

## Key Results
- TileGPT reliably produces valid designs with high fidelity to textual prompts
- Outperforms models trained on randomly sampled datasets
- Demonstrates the critical role of evolutionary computation in creating high-quality datasets for generative models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Quality-Diversity optimization generates high-performing, diverse datasets that improve language model fidelity
- Mechanism: MAP-Elites searches WFC-generated designs to include extreme and high-performing examples in the dataset, enabling the language model to learn from a broader range of design attributes
- Core assumption: Dataset diversity directly correlates with model's ability to generate varied, high-quality designs
- Evidence anchors:
  - Abstract: "Crucially, our results indicate that data synthesized through the evolutionary search of QD not only improves overall model performance but is essential for the model's ability to closely adhere to textual guidance."
  - Section: "The enriched dataset thus obtained is pivotal in training our model, enabling it to produce designs that are not only varied but also superior in quality."
  - Corpus: Weak evidence from related papers; lacks direct evidence of dataset impact on language model fidelity

### Mechanism 2
- Claim: Fine-tuning a language model with synthetic dataset allows it to interpret and implement design directives in natural language
- Mechanism: Language model learns to map textual prompts to design attributes using cross-attention mechanisms to incorporate attribute vectors
- Core assumption: Model can effectively learn mapping between textual descriptions and design attributes from synthetic dataset
- Evidence anchors:
  - Abstract: "We then fine-tune a language model with this dataset to generate high-level designs."
  - Section: "A causal language model is finetuned to learns 'next tile prediction', analogous to the 'next token prediction' objective which most causal language models are optimized for."
  - Corpus: No direct evidence; lacks specific examples of language models interpreting design directives

### Mechanism 3
- Claim: Wave Function Collapse ensures constraint compliance in generated designs, refining high-level designs into detailed, valid layouts
- Mechanism: Language model generates simplified design, then WFC uses constraint satisfaction to ensure final design adheres to construction constraints
- Core assumption: WFC can effectively refine and validate designs generated by language model
- Evidence anchors:
  - Abstract: "These designs are then refined into detailed, constraint-compliant layouts using the Wave Function Collapse algorithm."
  - Section: "The WFC methodology consists of a four-step process: Pattern extraction, Initialization and pre-constraint, Cell collapse, and Propagation."
  - Corpus: Weak evidence; mentions WFC but lacks specific examples of use in refining language model outputs

## Foundational Learning

- Concept: Quality-Diversity (QD) Optimization
  - Why needed here: QD generates diverse, high-performing datasets essential for training language model
  - Quick check question: How does QD differ from traditional optimization in terms of solution diversity?

- Concept: Language Model Fine-Tuning
  - Why needed here: Fine-tuning adapts pre-trained language model to generate design-specific outputs from textual prompts
  - Quick check question: What role does cross-attention play in incorporating attribute vectors into language model?

- Concept: Constraint Satisfaction
  - Why needed here: Ensures generated designs adhere to construction constraints for real-world viability
  - Quick check question: How does WFC handle conflicts between design elements to maintain constraint compliance?

## Architecture Onboarding

- Component map: MAP-Elites → Dataset → Language Model Fine-Tuning → Design Generation → WFC Refinement → Final Design
- Critical path: MAP-Elites generates diverse dataset → Language model fine-tuned on dataset → Model generates designs from prompts → WFC refines designs to meet constraints → Final constraint-compliant design
- Design tradeoffs: Balancing dataset diversity with computational cost, ensuring language model interpretability without sacrificing design complexity, maintaining constraint compliance without overly restricting creativity
- Failure signatures: Poor dataset diversity leading to biased model outputs, language model misinterpretation of prompts, WFC's inability to resolve design conflicts
- First 3 experiments:
  1. Generate small dataset with MAP-Elites and evaluate diversity and performance
  2. Fine-tune language model with dataset and test ability to generate designs from textual prompts
  3. Apply WFC to refine generated designs and assess constraint compliance and design validity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does complexity of tile encoding scheme affect quality and diversity of generated designs in TileGPT?
- Basis in paper: [explicit] Paper discusses simplifying full tile set into functional categories to reduce complexity for language model, but doesn't explore impact of different encoding schemes
- Why unresolved: Paper focuses on specific encoding scheme without comparing alternatives or analyzing impact on design quality and diversity
- What evidence would resolve it: Comparative studies using different tile encoding schemes (more granular vs. more abstract) and evaluating resulting design quality, diversity, and model performance

### Open Question 2
- Question: What is optimal balance between number of fixed tiles and diversity of designs in WFC optimization process?
- Basis in paper: [inferred] Paper mentions fixing more tiles narrows distribution of possible mappings from genotype to phenotype, but doesn't explore trade-off between design diversity and search efficiency
- Why unresolved: Paper doesn't provide systematic analysis of how number of fixed tiles affects exploration of design space and quality of resulting designs
- What evidence would resolve it: Experiments varying number of fixed tiles and measuring diversity of generated designs, convergence speed of optimization algorithm, and quality of final designs

### Open Question 3
- Question: How does choice of language model architecture (e.g., DistilGPT2 vs. other models) impact performance of TileGPT in generating designs that adhere to textual prompts?
- Basis in paper: [explicit] Paper uses DistilGPT2 as base language model, but doesn't compare it to other architectures or analyze impact of model size and complexity on performance
- Why unresolved: Paper doesn't provide comparative analysis of different language model architectures or explore relationship between model complexity and design generation quality
- What evidence would resolve it: Experiments using different language model architectures (larger or smaller models, different transformer-based models) and evaluating their performance in generating designs that adhere to textual prompts

## Limitations
- Limited evidence on direct correlation between dataset diversity and language model fidelity
- No concrete examples demonstrating how well language model translates textual prompts into specific design attributes
- Insufficient empirical data on WFC's conflict resolution effectiveness in this context

## Confidence
- High Confidence: Integration of MAP-Elites for dataset generation and WFC for constraint satisfaction is well-established in literature
- Medium Confidence: Fine-tuning language models with synthetic datasets is plausible but effectiveness in this application lacks direct evidence
- Low Confidence: Direct correlation between dataset diversity and language model fidelity is assumed but not empirically validated

## Next Checks
1. Conduct thorough analysis of MAP-Elites dataset to quantify diversity and assess impact on language model performance
2. Test language model's ability to accurately translate wide range of textual prompts into specific design attributes using benchmark prompts
3. Perform detailed study of WFC's conflict resolution process in context of language model-generated designs, identifying common conflict scenarios and evaluating effectiveness in resolving them without compromising design integrity