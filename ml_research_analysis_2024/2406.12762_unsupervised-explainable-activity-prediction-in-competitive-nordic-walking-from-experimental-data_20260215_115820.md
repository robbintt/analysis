---
ver: rpa2
title: Unsupervised explainable activity prediction in competitive Nordic Walking
  from experimental data
arxiv_id: '2406.12762'
source_url: https://arxiv.org/abs/2406.12762
tags:
- data
- sensors
- unsupervised
- features
- activity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of recognizing and explaining
  different activity patterns in competitive Nordic Walking using low-cost wearable
  sensors. The proposed method employs an online processing unsupervised clustering
  approach to automatically expand limited manual tagging from judges, enabling explainable
  classification.
---

# Unsupervised explainable activity prediction in competitive Nordic Walking from experimental data

## Quick Facts
- arXiv ID: 2406.12762
- Source URL: https://arxiv.org/abs/2406.12762
- Authors: Silvia García-Méndez; Francisco de Arriba-Pérez; Francisco J. González-Castaño; Javier Vales-Alonso
- Reference count: 40
- Primary result: Achieves ~100% classification accuracy for correct, incorrect, and cheating Nordic Walking practices using unsupervised clustering with limited manual tagging

## Executive Summary
This paper addresses the challenge of recognizing and explaining different activity patterns in competitive Nordic Walking using low-cost wearable sensors. The proposed method employs an online processing unsupervised clustering approach to automatically expand limited manual tagging from judges, enabling explainable classification. By combining feature engineering with variance-based feature selection, the system achieves classification accuracy close to 100% in distinguishing between correct, incorrect, and cheating practices. The method also provides visual and natural language explanations of the predictions, enhancing transparency and interpretability. This approach reduces the need for manual labeling while maintaining high performance, making it suitable for real-time deployment in competitive sports scenarios.

## Method Summary
The method uses unsupervised K-means clustering to group sensor data into clusters, then leverages minimal manual tags (e.g., from judges) within each cluster to propagate labels across all samples in that cluster. Feature engineering creates multiple engineered features (averages, standard deviations, quartiles, FFT magnitudes) across different window sizes to capture both short-term and long-term movement patterns. Variance-based feature selection reduces dimensionality while preserving classification-relevant information. A second ARFC classifier provides explainable predictions with visual and natural language descriptions. The system processes sensor data from tri-axial accelerometers, gyroscopes, and magnetometers on wrists, ankles, and poles in real-time.

## Key Results
- Achieves classification accuracy close to 100% in distinguishing correct, incorrect, and cheating Nordic Walking practices
- Successfully expands limited manual tagging from judges to label all samples through unsupervised clustering
- Provides visual and natural language explanations of predictions through the ARFC explainable classifier
- Processes data in real-time with sub-40ms latency per sample
- Reduces manual labeling requirements while maintaining high performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Unsupervised clustering enables automatic expansion of limited manual tagging without requiring labeled training data.
- Mechanism: The system uses K-means clustering to group sensor data into clusters, then leverages minimal manual tags (e.g., from judges) within each cluster to propagate labels across all samples in that cluster.
- Core assumption: Practitioners' activities produce distinct, repeatable signal patterns that naturally cluster in feature space.
- Evidence anchors:
  - [abstract]: "The proposed method employs an online processing unsupervised clustering approach to automatically expand limited manual tagging from judges"
  - [section]: "Unsupervised clustering is based on the K-means method... This would be a quite natural process in Nordic Walking competitions. Judges could easily tag these references during a race by clicking a button when a practitioner passes by their locations"
  - [corpus]: No direct corpus evidence for this specific unsupervised tagging expansion mechanism
- Break condition: If activity patterns overlap significantly in feature space, clustering will fail to produce distinct groups, preventing accurate label propagation.

### Mechanism 2
- Claim: Feature engineering with sliding windows captures temporal patterns in Nordic Walking movements effectively.
- Mechanism: The system creates multiple engineered features (averages, standard deviations, quartiles, FFT magnitudes) across different window sizes to capture both short-term and long-term movement patterns.
- Core assumption: Nordic Walking movements have characteristic temporal patterns that can be captured by analyzing data over multiple time scales.
- Evidence anchors:
  - [section]: "Data calibration . Noise is a major issue... Different window lengths are set at the calibration stage by inspecting the sample intervals between successive minima of the sensor signals"
  - [section]: "Feature engineering . Once the sliding windows are selected, online processed features can be calculated ∀n > max (wQ1, wQ2, wQ3, wavg)"
  - [corpus]: No direct corpus evidence for this specific sliding window approach
- Break condition: If movement patterns are too irregular or if the window sizes don't match the actual movement cadence, the engineered features will fail to capture meaningful distinctions.

### Mechanism 3
- Claim: Variance-based feature selection reduces dimensionality while preserving classification-relevant information.
- Mechanism: The system applies a variance threshold to select only features whose values vary sufficiently across samples, filtering out static or noisy features.
- Core assumption: Classification-relevant information is carried by features with sufficient variance across different activity types.
- Evidence anchors:
  - [section]: "Feature analysis & selection . Let tσ > 0 be a configurable threshold... the set of selected features Swp,a,s,l[n] for online processing prediction and training update at that slot is composed of Φ(σ({avg wp,a,s,l[k], . . . , avgwp,a,s,l[n]}))"
  - [section]: "The VarianceThreshold function from the River package was used to calculate online processed feature variances"
  - [corpus]: No direct corpus evidence for this specific variance-based selection approach
- Break condition: If important classification features happen to have low variance due to normalization or if noise has high variance, the selection will either remove useful features or retain irrelevant ones.

## Foundational Learning

- Concept: K-means clustering algorithm
  - Why needed here: Forms the core unsupervised classification that groups similar movement patterns together
  - Quick check question: What parameter must be specified before running K-means, and how is it determined in this application?

- Concept: Sliding window feature extraction
  - Why needed here: Captures temporal patterns in sequential sensor data that single-timepoint features would miss
  - Quick check question: Why does the system use multiple window sizes (wQ1, wQ2, wQ3, wavg) instead of just one?

- Concept: Variance-based feature selection
  - Why needed here: Reduces computational complexity while focusing on features that actually distinguish between activity types
  - Quick check question: What is the risk of setting the variance threshold too high or too low?

## Architecture Onboarding

- Component map: Sensor data → Data calibration → Feature engineering → Feature selection → Online K-means clustering → Label propagation → Explainable ARFC re-classification → Dashboard output
- Critical path: The path from raw sensor data through clustering to final explanation must process within real-time constraints (under 40ms per sample)
- Design tradeoffs: Unsupervised clustering sacrifices some accuracy compared to supervised methods but eliminates the need for large labeled datasets; explainability adds interpretability but requires a second classification stage
- Failure signatures: Poor clustering results (low accuracy despite clear activity distinctions) suggest sensor placement issues or insufficient feature differentiation; slow processing indicates window sizes or feature counts are too large
- First 3 experiments:
  1. Run K-means clustering with varying numbers of clusters (2, 3, 4) on the raw data to verify distinct activity patterns exist
  2. Test different window sizes during calibration to find optimal temporal resolution for capturing Nordic Walking patterns
  3. Evaluate variance threshold values to find the sweet spot between dimensionality reduction and information preservation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the unsupervised clustering approach compare to supervised learning methods when applied to sports with more complex, fluid patterns (e.g., soccer or basketball) rather than well-defined activities like Nordic Walking?
- Basis in paper: [explicit] The paper states that "Currently, use of our system is limited to sports or training practices with clearly defined patterns or stages" and mentions future work to extend to "more open, 'fluid', sports, such as soccer and basketball."
- Why unresolved: The paper focuses on Nordic Walking, which has well-defined patterns. No experiments were conducted on sports with more complex, fluid patterns.
- What evidence would resolve it: Comparative studies applying the same unsupervised clustering approach to sports like soccer or basketball, measuring classification accuracy and explainability against supervised learning methods.

### Open Question 2
- Question: What is the impact of sensor placement variability (linear and angular displacements) on the classification accuracy and explainability of the system over long-term use and across different users?
- Basis in paper: [explicit] The paper mentions that "precise placement relative to body parts is unnecessary" and that "significant linear and angular displacements of the sensors between and during sessions" were observed.
- Why unresolved: While the paper acknowledges sensor displacement, it does not quantify its impact on long-term performance or across different users.
- What evidence would resolve it: Longitudinal studies tracking sensor placement variability and its correlation with classification accuracy and explainability metrics across multiple users and extended periods.

### Open Question 3
- Question: How does the proposed method handle concept drift in sports activities, where the definition of "correct" and "incorrect" practices may evolve over time or differ across coaches/regions?
- Basis in paper: [inferred] The paper uses a K-means clustering approach that assumes relatively stable patterns. The concept of "correct" vs "incorrect" practices is mentioned but not explored in terms of potential drift.
- Why unresolved: The paper does not address how the system adapts to changes in the definition of correct/incorrect practices over time or across different contexts.
- What evidence would resolve it: Experiments introducing concept drift by gradually changing the criteria for correct/incorrect practices and measuring the system's ability to adapt and maintain performance.

## Limitations

- The reported "close to 100%" classification accuracy appears overly optimistic given the unsupervised nature of the core approach and limited dataset size
- The reliance on manual tagging for cluster labeling introduces a semi-supervised element that isn't fully acknowledged in the unsupervised premise
- The explainability claims depend on a second supervised classifier (ARFC) which somewhat contradicts the unsupervised framework
- The 5-athlete dataset may not capture sufficient variability for robust generalization across different practitioners

## Confidence

**High Confidence**: The general approach of using unsupervised clustering for activity pattern recognition is technically sound and well-established in the HAR literature.

**Medium Confidence**: The specific implementation details for feature engineering, variance-based selection, and the combination of K-means with ARFC for explainability are described but lack sufficient detail for full reproducibility.

**Low Confidence**: The reported classification performance metrics appear too optimistic without proper baseline comparisons or independent validation, particularly given the unsupervised approach and limited dataset size (5 athletes).

## Next Checks

1. **Baseline Comparison**: Implement and compare against standard supervised classifiers (Random Forest, SVM, Neural Networks) using the same engineered features to establish whether the unsupervised approach provides genuine advantages.

2. **Cross-Subject Validation**: Test the clustering and classification performance across different athletes rather than within-subject to verify generalization capabilities, as the current 5-athlete dataset may not capture sufficient variability.

3. **Manual Tag Coverage Analysis**: Systematically evaluate how sensitive the clustering results are to the density and distribution of manual tags across clusters, as this represents a critical weak point in the unsupervised framework.