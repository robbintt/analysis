---
ver: rpa2
title: Evaluating Large Language Models as Virtual Annotators for Time-series Physical
  Sensing Data
arxiv_id: '2403.01133'
source_url: https://arxiv.org/abs/2403.01133
tags: []
core_contribution: This paper explores whether state-of-the-art large language models
  (LLMs) can serve as virtual annotators for time-series physical sensing data, addressing
  challenges of traditional human-in-the-loop annotation. The authors investigate
  whether LLMs like GPT-4 can directly annotate raw sensor data without relying on
  alternate modalities like video or audio.
---

# Evaluating Large Language Models as Virtual Annotators for Time-series Physical Sensing Data

## Quick Facts
- arXiv ID: 2403.01133
- Source URL: https://arxiv.org/abs/2403.01133
- Reference count: 40
- Primary result: LLMs can serve as virtual annotators for time-series sensor data when raw data is encoded using contrastive learning approaches

## Executive Summary
This paper explores the potential of large language models (LLMs) like GPT-4 as virtual annotators for time-series physical sensing data, addressing the challenge of annotating sensor data that lacks inherent interpretability. The authors demonstrate that raw accelerometer data is difficult for LLMs to classify accurately, but encoding the data using self-supervised contrastive learning approaches (SimCLR and TFC) significantly improves annotation performance. The study evaluates four Human Activity Recognition (HAR) benchmark datasets and shows that this encoding-LLM approach achieves consistent accuracy improvements without requiring computationally expensive fine-tuning.

## Method Summary
The authors investigate LLMs as virtual annotators through a two-phase study. In Phase I, they directly provide raw accelerometer data to GPT-4 for classification, which shows poor performance even with example guidance. In Phase II, they encode the raw sensor data using self-supervised contrastive learning approaches (SimCLR and TFC) to create more interpretable representations. These encoded representations are then provided to GPT-4 along with example annotations and metric-based guidance. The study evaluates four benchmark HAR datasets and compares the performance of raw versus encoded data with varying numbers of examples.

## Key Results
- GPT-4 struggles to accurately classify raw accelerometer data even with example annotations
- Encoding raw sensor data using contrastive learning approaches (SimCLR and TFC) significantly improves LLM annotation accuracy
- The approach achieves consistent accuracy improvements with increasing examples, though token length and cost remain practical considerations
- No computationally expensive fine-tuning is required, making the approach more accessible

## Why This Works (Mechanism)
The mechanism works because contrastive learning creates semantically meaningful representations of raw sensor data that are more interpretable by LLMs. Raw time-series sensor data consists of numerical sequences that lack inherent semantic meaning, making it difficult for LLMs trained on natural language to understand the patterns. By encoding the data into a learned representation space where similar activities are closer together, the LLM can leverage its natural language understanding capabilities to map between these encoded representations and activity labels. The metric-based guidance provides additional context about the distance relationships in the encoded space, helping the LLM make more informed classification decisions.

## Foundational Learning
- Contrastive Learning (why needed: creates meaningful representations from unlabeled data; quick check: verify similar activities are closer in embedding space)
- Time-series Encoding (why needed: transforms raw sensor sequences into interpretable representations; quick check: ensure encoding preserves temporal patterns)
- Self-supervised Learning (why needed: enables representation learning without labeled data; quick check: confirm encoder generalizes across datasets)
- Large Language Models (why needed: provides natural language understanding for mapping representations to labels; quick check: verify model's few-shot learning capability)
- Metric-based Guidance (why needed: provides spatial context for encoded representations; quick check: validate guidance improves classification accuracy)
- Human Activity Recognition (why needed: benchmark task for sensor data annotation; quick check: ensure dataset diversity across activities)

## Architecture Onboarding

Component Map: Raw Sensor Data -> Contrastive Encoder -> Encoded Representations -> LLM with Examples -> Activity Labels

Critical Path: The most critical path is from the contrastive encoder through to the LLM's final classification decision. The quality of the encoded representations directly determines the LLM's ability to make accurate annotations, making the encoder-LLM interface the bottleneck.

Design Tradeoffs: The main tradeoff is between encoding quality and token length/cost. Higher-dimensional encodings provide better semantic separation but increase token consumption and processing costs. The authors balance this by using efficient contrastive encoders while maintaining representation quality.

Failure Signatures: Primary failure modes include poor contrastive learning (causing similar activities to be distant in embedding space), insufficient examples for the LLM to learn patterns, and token length constraints that force truncation of important data segments.

First Experiments:
1. Compare LLM performance on raw vs encoded data with identical example sets
2. Vary the number of examples provided to assess learning curve characteristics
3. Test different contrastive learning approaches (SimCLR vs TFC) for encoding quality

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several implications arise from the research. The generalizability to other sensor modalities beyond accelerometers remains unexplored. The cost-benefit trade-off between encoding approaches and traditional supervised learning is not addressed. The potential biases in LLM annotations and their impact on downstream applications require investigation. The scalability of this approach for real-time or large-scale deployment scenarios is uncertain.

## Limitations
- Primary evaluation limited to accelerometer data from four HAR benchmark datasets
- Computational costs and token length constraints may limit practical scalability
- Reliance on proprietary GPT-4 model raises reproducibility concerns
- No comparison with traditional supervised learning approaches or smaller models
- Absence of extensive error analysis to understand systematic failure modes

## Confidence
- **High Confidence**: The finding that encoded representations improve LLM annotation accuracy compared to raw data
- **Medium Confidence**: The scalability and cost-effectiveness of the approach for real-world deployment
- **Low Confidence**: Generalizability to sensor modalities beyond accelerometers and diverse application domains

## Next Checks
1. Test the encoding-LLM pipeline with multi-modal sensor data (e.g., gyroscope, magnetometer) to assess cross-modality performance and robustness
2. Conduct a cost-benefit analysis comparing the proposed method with traditional supervised learning approaches on the same datasets, including model size, annotation time, and accuracy trade-offs
3. Perform a bias and error analysis by manually reviewing LLM annotations to identify systematic failure modes and potential sources of bias in the model's decision-making process