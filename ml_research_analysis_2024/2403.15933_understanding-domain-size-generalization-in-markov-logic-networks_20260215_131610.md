---
ver: rpa2
title: Understanding Domain-Size Generalization in Markov Logic Networks
arxiv_id: '2403.15933'
source_url: https://arxiv.org/abs/2403.15933
tags:
- domain
- logic
- markov
- parameter
- weight
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the generalization behavior of Markov Logic
  Networks (MLNs) across relational structures of different sizes. The authors formalize
  the notion of domain-size generalization for MLNs and provide bounds on the difference
  between probability distributions induced by an MLN on subsampled and larger domains.
---

# Understanding Domain-Size Generalization in Markov Logic Networks

## Quick Facts
- arXiv ID: 2403.15933
- Source URL: https://arxiv.org/abs/2403.15933
- Authors: Florian Chen; Felix WeitkÃ¤mper; Sagar Malhotra
- Reference count: 37
- Primary result: Reducing parameter variance improves MLN generalization across varying domain sizes

## Executive Summary
This paper addresses the challenge of domain-size generalization in Markov Logic Networks (MLNs), where models must perform well on relational structures of varying sizes. The authors formalize domain-size generalization and establish theoretical bounds showing that parameter variance in MLNs directly relates to their ability to generalize across different domain sizes. They demonstrate that methods reducing parameter variance, such as regularization and Domain-Size Aware MLNs, improve internal consistency and generalization performance across subsampled domains.

## Method Summary
The authors develop a theoretical framework for analyzing domain-size generalization in MLNs by examining how probability distributions change when moving between subsampled and full domains. They introduce the concept of parameter variance as a key metric and show its relationship to KL divergence bounds. The paper proposes three practical methods to control parameter variance: regularization techniques, Domain-Size Aware MLNs, and subsampling-aware training. These methods are evaluated empirically on four datasets, demonstrating that controlling parameter variance leads to improved generalization across domain sizes.

## Key Results
- Parameter variance bounds the KL divergence between MLN marginal distributions on different domain sizes
- Maximizing data log-likelihood while minimizing parameter variance corresponds to natural notions of domain-size generalization
- Regularization and Domain-Size Aware MLNs decrease parameter variance and increase internal consistency
- Controlling parameter variance through various methods leads to better generalization on subsampled domains

## Why This Works (Mechanism)
The mechanism works by recognizing that MLNs with high parameter variance exhibit unstable behavior when applied to domains of different sizes. By reducing parameter variance, the model parameters become more consistent across different domain configurations, leading to more stable probability distributions and better generalization.

## Foundational Learning

**Markov Logic Networks**: A framework combining first-order logic with probabilistic graphical models, allowing uncertain relationships between logical formulas. Needed to understand the baseline model being analyzed.

**Subsampling**: The process of selecting subsets of entities from a domain to create smaller domains for analysis. Quick check: Can you explain why subsampling is used instead of truly different domain sizes?

**KL Divergence**: A measure of difference between probability distributions. Quick check: Can you calculate KL divergence between two simple distributions?

**Parameter Variance**: Measures the variability of learned parameters across different domain configurations. Quick check: How would you compute parameter variance in a simple linear model?

**Marginal Distributions**: Probability distributions over subsets of variables in a probabilistic model. Quick check: Can you derive marginal distributions from a joint distribution?

## Architecture Onboarding

**Component Map**: MLN formulas -> Grounding -> Weight Learning -> Parameter Variance Control -> Domain-Size Generalization

**Critical Path**: The essential components are weight learning and parameter variance control, as these directly impact the model's ability to generalize across domain sizes.

**Design Tradeoffs**: The main tradeoff is between model expressiveness (complex formulas) and generalization capability (lower parameter variance). More complex formulas typically increase parameter variance.

**Failure Signatures**: High parameter variance manifests as inconsistent predictions across different domain sizes, while poor log-likelihood indicates inadequate learning.

**First Experiments**:
1. Measure parameter variance on a simple MLN with varying regularization strengths
2. Compare KL divergence between subsampled and full domain distributions
3. Evaluate generalization performance across different domain sizes with and without parameter variance control

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Theoretical analysis assumes full domain structure availability during training, which is rarely practical
- Primary focus on binary predicates limits applicability to real-world domains with higher-arity relationships
- Empirical evaluation uses subsampling rather than truly out-of-distribution domain sizes
- Domain-Size Aware MLN method may compound existing challenges with large domains

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Theoretical framework and proofs | High |
| Empirical results using subsampling | Medium |
| Practical applicability of Domain-Size Aware MLN method | Low |

## Next Checks

1. Test proposed methods on truly out-of-distribution domain sizes where entity structure differs substantially from training data
2. Evaluate framework on MLNs with predicates of higher arity beyond binary relationships
3. Compare parameter variance-based regularization against recent neuro-symbolic methods with vector representations