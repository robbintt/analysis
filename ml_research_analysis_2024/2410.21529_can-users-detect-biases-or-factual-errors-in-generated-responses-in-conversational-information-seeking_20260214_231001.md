---
ver: rpa2
title: Can Users Detect Biases or Factual Errors in Generated Responses in Conversational
  Information-Seeking?
arxiv_id: '2410.21529'
source_url: https://arxiv.org/abs/2410.21529
tags:
- response
- query
- user
- contr
- responses
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how users perceive and detect biases or
  factual errors in conversational information-seeking (CIS) system responses. Through
  two crowdsourced user studies examining query answerability and response incompleteness,
  we find that users struggle to identify factual errors and hallucinations in CIS
  responses, even when sources are provided.
---

# Can Users Detect Biases or Factual Errors in Generated Responses in Conversational Information-Seeking?

## Quick Facts
- arXiv ID: 2410.21529
- Source URL: https://arxiv.org/abs/2410.21529
- Reference count: 40
- Users struggle to identify factual errors and hallucinations in CIS responses, even when sources are provided.

## Executive Summary
This study investigates how users perceive and detect biases or factual errors in conversational information-seeking (CIS) system responses. Through two crowdsourced user studies examining query answerability and response incompleteness, we find that users struggle to identify factual errors and hallucinations in CIS responses, even when sources are provided. In contrast, users are better at detecting viewpoint diversity and balance issues in responses. User satisfaction correlates more strongly with response diversity and balance than with factual correctness. The findings highlight the need for CIS systems to transparently indicate potential inaccuracies and provide users with tools to assess information objectively.

## Method Summary
The study employed two crowdsourced experiments with Amazon Mechanical Turk workers. Researchers selected 20 queries from TREC CAsT'20 and '22 datasets and manually crafted response variants with controlled dimensions (factual correctness/source validity for answerability study; diversity/balance for viewpoints study). Using a within-subject design with Graeco-Latin square rotation, each worker evaluated 10 query-response pairs on four-point Likert scales. Three-way ANOVA analyzed the effects of controlled dimensions on user ratings of response quality dimensions and satisfaction.

## Key Results
- Users struggle to identify factual errors and hallucinations in CIS responses, even when sources are provided
- Users are better at detecting viewpoint diversity and balance issues than factual errors
- User satisfaction correlates more strongly with response diversity and balance than with factual correctness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Users struggle to detect factual errors in conversational information-seeking (CIS) system responses, even when sources are provided.
- Mechanism: When responses are fluent and coherent, users' ability to identify inaccuracies is compromised. This is because the presentation style of the response overshadows the need to verify factual correctness.
- Core assumption: Fluency of responses reduces users' vigilance in checking factual accuracy.
- Evidence anchors:
  - [abstract]: "users struggle to identify factual errors and hallucinations in CIS responses, even when sources are provided."
  - [section 5.1]: "In the answerability study, crowd workers demonstrate a limited ability to detect pitfalls in responses compared to the viewpoints study."
  - [corpus]: The corpus contains papers like "Explainability for Transparent Conversational Information-Seeking" and "Towards Reliable and Factual Response Generation: Detecting Unanswerable Questions in Information-Seeking Conversations," which suggest a recognized challenge in ensuring factual correctness in CIS systems.
- Break condition: If the system explicitly flags potential inaccuracies or provides clear guidance on assessing information objectively, the mechanism may break as users become more vigilant.

### Mechanism 2
- Claim: Users are better at detecting viewpoint diversity and balance issues than factual errors in CIS responses.
- Mechanism: Detecting viewpoint diversity and balance requires recognizing the presence of multiple perspectives, which is more intuitive and less reliant on background knowledge than verifying factual correctness.
- Core assumption: Recognizing diversity and balance is inherently easier than fact-checking for users.
- Evidence anchors:
  - [abstract]: "users are better at detecting viewpoint diversity and balance issues in responses."
  - [section 5.1]: "results for the viewpoints study...show small or medium effect on self-reported worker ratings meaning that users can correctly identify the problems related to viewpoint diversity and balance."
  - [corpus]: The presence of papers like "Adaptive Multi-Agent Response Refinement in Conversational Systems" indicates ongoing research into improving response quality, which may include addressing viewpoint diversity.
- Break condition: If users are provided with training or tools to better understand and assess factual accuracy, their ability to detect factual errors may improve.

### Mechanism 3
- Claim: User satisfaction in CIS systems is more strongly associated with response diversity and balance than with factual correctness.
- Mechanism: Users prioritize the perceived diversity and balance of information in responses, which may lead them to overlook factual inaccuracies if the response appears comprehensive and balanced.
- Core assumption: Users equate diversity and balance with quality, potentially at the expense of accuracy.
- Evidence anchors:
  - [abstract]: "User satisfaction correlates more strongly with response diversity and balance than with factual correctness."
  - [section 5.2]: "In the viewpoints study, satisfaction is tied to perceived balance, with users preferring unbiased responses that equally cover all viewpoints."
  - [corpus]: Papers like "User Prompting Strategies and ChatGPT Contextual Adaptation Shape Conversational Information-Seeking Experiences" suggest that user experience is a key focus in CIS research, potentially influencing satisfaction metrics.
- Break condition: If users are made aware of the importance of factual correctness through education or system prompts, their satisfaction criteria may shift.

## Foundational Learning

- Concept: Conversational Information-Seeking (CIS)
  - Why needed here: Understanding CIS is crucial as it forms the basis of the study, focusing on how users interact with and perceive information in conversational systems.
  - Quick check question: What distinguishes conversational information-seeking from traditional search methods?

- Concept: Factual Correctness vs. Viewpoints
  - Why needed here: The study differentiates between factual correctness and viewpoint diversity, highlighting how users perceive these dimensions differently.
  - Quick check question: Why might users find it easier to detect viewpoint diversity than factual errors in CIS responses?

- Concept: User Satisfaction Metrics
  - Why needed here: The study uses user satisfaction as a proxy for user experience, which is central to understanding how users perceive response quality.
  - Quick check question: How does user satisfaction correlate with response diversity and balance in CIS systems?

## Architecture Onboarding

- Component map: Query processing -> Response generation -> User interaction -> Evaluation
- Critical path:
  1. User submits a query.
  2. System processes the query and retrieves relevant passages.
  3. Response generation synthesizes information into a coherent response.
  4. Response is presented to the user.
  5. User provides feedback on response quality.
  6. System evaluates feedback to improve future responses.
- Design tradeoffs:
  - Balancing response fluency with factual accuracy to ensure users can detect errors.
  - Ensuring response diversity and balance without overwhelming users with information.
  - Providing source attribution without making the response cumbersome.
- Failure signatures:
  - Users fail to detect factual errors despite source availability.
  - Users prioritize response diversity over factual correctness in satisfaction ratings.
  - Feedback indicates confusion between response fluency and accuracy.
- First 3 experiments:
  1. Test user ability to detect factual errors in responses with and without source attribution.
  2. Measure user satisfaction with responses varying in viewpoint diversity and balance.
  3. Evaluate the impact of explicit accuracy warnings on user perception and satisfaction.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do users perceive and respond to factually incorrect responses in CIS systems when the incorrect information is subtle or difficult to detect?
- Basis in paper: [explicit] The study found that users struggle to identify factual errors and hallucinations in CIS responses, even when sources are provided.
- Why unresolved: The study used controlled errors that were easily detectable, not reflecting the subtlety of real-world inaccuracies.
- What evidence would resolve it: Experiments with more nuanced factual errors and a larger, more diverse set of queries could reveal how users detect and respond to subtle inaccuracies.

### Open Question 2
- Question: To what extent do users rely on the fluency and coherence of CIS responses as indicators of accuracy and trustworthiness?
- Basis in paper: [inferred] User satisfaction correlates more strongly with response diversity and balance than with factual correctness, suggesting that fluency might be a key factor in user perception.
- Why unresolved: The study did not explicitly investigate the relationship between response fluency and user trust in accuracy.
- What evidence would resolve it: User studies comparing responses with varying levels of fluency but consistent factual accuracy could clarify the role of fluency in user trust.

### Open Question 3
- Question: How do different user backgrounds (e.g., expertise, prior knowledge) influence the ability to detect biases and factual errors in CIS responses?
- Basis in paper: [explicit] The study found no significant effect of topic familiarity on user ratings of response dimensions, but this may be due to the controlled nature of the errors.
- Why unresolved: The study did not explore the impact of varying levels of user expertise or background knowledge on error detection.
- What evidence would resolve it: Experiments with users of varying expertise levels assessing responses on topics within and outside their areas of expertise could reveal the influence of background knowledge.

## Limitations
- Study relies on controlled experiments with a limited set of 20 queries, which may not fully represent real-world scenarios
- Use of crowd workers introduces potential variability in expertise and attentiveness despite attentiveness checks
- Focuses on specific dimensions of response quality, potentially overlooking other important factors
- Controlled nature of response variants may not capture full complexity of actual CIS system responses

## Confidence
- **High Confidence**: Users' ability to detect viewpoint diversity and balance issues in CIS responses
- **Medium Confidence**: Users' struggle to detect factual errors, even with sources provided
- **Low Confidence**: User satisfaction correlates more strongly with response diversity and balance than factual correctness

## Next Checks
1. Conduct a study using actual CIS system responses in real-world settings to assess if the findings hold outside of controlled experimental conditions
2. Investigate whether providing users with training or tools to assess factual accuracy improves their ability to detect errors in CIS responses
3. Perform a longitudinal study to track changes in user perception and satisfaction over time as they become more familiar with CIS systems and their potential limitations