---
ver: rpa2
title: Differentially private and decentralized randomized power method
arxiv_id: '2411.01931'
source_url: https://arxiv.org/abs/2411.01931
tags:
- privacy
- power
- matrix
- algorithm
- bound
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents improved privacy-preserving variants of the
  randomized power method for large-scale spectral analysis. The authors introduce
  a tighter sensitivity bound that reduces the required noise variance compared to
  prior work, achieving the same differential privacy guarantees with less noise.
---

# Differentially private and decentralized randomized power method

## Quick Facts
- arXiv ID: 2411.01931
- Source URL: https://arxiv.org/abs/2411.01931
- Reference count: 31
- One-line primary result: Improved privacy-preserving randomized power method with tighter sensitivity bounds and decentralized Secure Aggregation extension

## Executive Summary
This paper presents privacy-preserving variants of the randomized power method for spectral analysis of large matrices. The authors develop improved sensitivity bounds that reduce Gaussian noise variance compared to prior work, achieving better accuracy under the same differential privacy guarantees. They extend the method to a decentralized setting using Secure Aggregation, enabling collaborative computation across multiple parties without a trusted curator. The theoretical analysis provides both runtime-dependent and independent convergence bounds, with empirical validation showing significant improvements over existing approaches on real recommendation datasets.

## Method Summary
The method builds on the randomized power method for computing orthonormal bases of large matrix ranges while preserving differential privacy. It introduces a tighter sensitivity bound by replacing the √p scaling with maximum row ℓ2 norms, reducing noise variance. The decentralized variant distributes the data matrix across clients who each add noise calibrated for local DP, then uses Secure Aggregation to combine contributions with noise cancellation properties. The algorithm employs zCDP composition and Gaussian mechanism for privacy accounting, with theoretical convergence guarantees depending on spectral gap and matrix coherence properties.

## Key Results
- Improved sensitivity bound reduces noise variance by replacing √p·||X_i:||_max with max_i ||X_i:||_2
- Secure Aggregation enables distributed DP with noise variance comparable to central DP
- Runtime-independent bound scales with min(1, μ₁(A)) instead of μ₀(A), yielding tighter bounds for low-coherence matrices

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The improved sensitivity bound reduces noise variance by replacing √p·||X_i:||_max with max_i ||X_i:||_2.
- **Mechanism**: Tighter sensitivity analysis in the power iteration step, showing that the Frobenius norm of the change in AX^{l-1} can be bounded by the maximum ℓ2 row norm instead of the maximum entrywise norm scaled by √p.
- **Core assumption**: The adjacency model allows symmetric updates C with bounded ℓ1 row sums, and the QR decomposition preserves orthonormality.
- **Evidence anchors**:
  - [abstract] "we refine the privacy analysis so that the Gaussian noise variance no longer grows linearly with the target rank"
  - [section] Theorem 3.1 proof shows max_i ||X_i:||_2 ≤ √p · max_{ij} ||X_ij||^2
  - [corpus] No direct evidence; this is novel contribution
- **Break condition**: If the QR step introduces large coherence in the rows of X, the bound degrades toward the original √p scaling.

### Mechanism 2
- **Claim**: Secure Aggregation enables distributed DP with noise variance comparable to central DP.
- **Mechanism**: Each client adds noise calibrated for local DP, but Secure Aggregation ensures the sum of noises has variance matching central DP, avoiding the √s factor degradation typical in federated learning.
- **Core assumption**: Honest-but-curious threat model with no client collusion or dropouts.
- **Evidence anchors**:
  - [abstract] "by employing Secure Aggregation, we are able to set the noise scale comparable to that of central DP"
  - [section] Algorithm 2 proof shows Y_ℓ = AX^{ℓ-1} + G_ℓ with G_ℓ ~ N(0, ∆²_l · (sν²)) and sν² = σ²
  - [corpus] Related works (Chen et al. 2021, Kairouz et al. 2021) validate this approach in practice
- **Break condition**: If clients collude or dropout rates are high, the noise cancellation property fails and utility degrades.

### Mechanism 3
- **Claim**: The runtime-independent bound scales with min(1, μ₁(A)) instead of μ₀(A), yielding tighter bounds for low-coherence matrices.
- **Mechanism**: By analyzing row norms of orthonormal X directly, the bound avoids dependence on eigenvector entry coherence (μ₀) and instead uses row sum coherence (μ₁), which is often smaller.
- **Core assumption**: The orthonormal basis X has bounded row norms determined by the data matrix's row coherence structure.
- **Evidence anchors**:
  - [abstract] "we provide new privacy proofs that correct errors in previous works"
  - [section] Theorem 4.1 proof shows ∥X_i:∥² ≤ min(1, μ₁(A)) via decomposition X = UB
  - [corpus] No direct evidence; this is a novel theoretical improvement
- **Break condition**: If μ₁(A) is large (high row coherence), the bound becomes loose and the runtime-dependent bound may be preferable.

## Foundational Learning

- **Concept**: Differential Privacy (DP) and its variants (central vs local vs distributed)
  - Why needed here: The entire paper builds privacy guarantees on different DP models; understanding the noise calibration and composition properties is essential.
  - Quick check question: What is the difference between (ε, δ)-DP and ρ-zCDP, and why does the paper switch between them?

- **Concept**: Randomized Power Method and its convergence analysis
  - Why needed here: The algorithm iteratively approximates eigenvectors; knowing how noise affects convergence is key to understanding the improved bounds.
  - Quick check question: How does adding Gaussian noise at each iteration affect the spectral gap condition for convergence?

- **Concept**: Secure Aggregation and Multi-Party Computation
  - Why needed here: The decentralized variant relies on these protocols to aggregate client contributions without revealing individual data.
  - Quick check question: How does Secure Aggregation achieve noise cancellation across clients while preserving privacy?

## Architecture Onboarding

- **Component map**: Central node orchestrates iterations; client nodes hold local matrix shards A^(i); Secure Aggregation protocol aggregates Y^(i)_ℓ; QR decomposition produces orthonormal X_ℓ.
- **Critical path**: Broadcast X^{ℓ-1} → Client computes Y^(i)_ℓ = A^(i)X^{ℓ-1} + noise → Secure Aggregation → QR → X_ℓ → repeat.
- **Design tradeoffs**: Central coordination simplifies Secure Aggregation but introduces single point of trust; fully decentralized GOPA avoids this but may increase communication overhead.
- **Failure signatures**: If Secure Aggregation fails (e.g., dropout), the sum of noises no longer cancels and accuracy drops; if adjacency model is violated, privacy guarantees break.
- **First 3 experiments**:
  1. Run centralized PPM on synthetic PSD matrix with known eigenvectors, verify convergence with and without noise.
  2. Implement Secure Aggregation on two clients, check that sum of noisy contributions equals central DP noise variance.
  3. Measure row coherence μ₁(A) on real recommendation datasets and compare theoretical vs empirical noise scaling.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the traditional sense. However, several limitations and areas for future work are mentioned:

1. The impact of data quantization and modular arithmetic errors on accuracy and privacy guarantees is not addressed.
2. The algorithm assumes an "honest-but-curious" threat model and does not consider malicious users or corrupted data.
3. The decentralized algorithm's performance under client dropouts is not analyzed.

## Limitations
- The sensitivity improvement assumes QR decomposition maintains bounded row norms, which may degrade for certain matrix structures
- Secure Aggregation requires perfect client participation; dropout scenarios are not analyzed
- The row coherence bound μ₁(A) is dataset-dependent and may not always be smaller than eigenvector coherence μ₀(A)

## Confidence
- **Confidence: High** in the central DP mechanism (Mechanism 1) due to clear mathematical proofs and explicit sensitivity bound improvements
- **Confidence: Medium** in the decentralized DP mechanism (Mechanism 2) because it relies on Secure Aggregation protocols that assume honest-but-curious clients without dropouts
- **Confidence: Medium** in the runtime-independent bounds (Mechanism 3) as they depend on row coherence assumptions that may not hold for all datasets

## Next Checks
1. Empirically measure row coherence μ₁(A) on multiple recommendation datasets and compare noise variance predictions vs actual results
2. Test Secure Aggregation under various dropout rates to quantify utility degradation
3. Benchmark the privacy-accuracy tradeoff against existing federated PCA methods on real-world decentralized datasets