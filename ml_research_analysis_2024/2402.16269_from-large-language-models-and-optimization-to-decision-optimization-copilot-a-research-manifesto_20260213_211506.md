---
ver: rpa2
title: 'From Large Language Models and Optimization to Decision Optimization CoPilot:
  A Research Manifesto'
arxiv_id: '2402.16269'
source_url: https://arxiv.org/abs/2402.16269
tags:
- optimization
- problem
- decision
- constraints
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes creating a Decision Optimization CoPilot (DOCP)
  that uses large language models (LLMs) to make mathematical optimization accessible
  to non-experts. The DOCP would interact in natural language to understand a business
  problem, formulate an optimization model, and solve it.
---

# From Large Language Models and Optimization to Decision Optimization CoPilot: A Research Manifesto

## Quick Facts
- arXiv ID: 2402.16269
- Source URL: https://arxiv.org/abs/2402.16269
- Reference count: 40
- Key outcome: LLMs can generate optimization models but often contain errors and struggle with efficiency; significant research gaps remain before realizing a DOCP that makes optimization accessible to non-experts.

## Executive Summary
This paper proposes creating a Decision Optimization CoPilot (DOCP) that uses large language models (LLMs) to make mathematical optimization accessible to non-experts. The DOCP would interact in natural language to understand business problems, formulate optimization models, and solve them. Experiments with ChatGPT showed LLMs can generate optimization models but often contain errors and struggle with efficiency. The paper identifies three key requirements for a DOCP: understanding high-level business descriptions, enabling business user validation, and generating efficient models. While LLMs show promise, significant gaps remain before realizing the DOCP vision.

## Method Summary
The authors experimented with using ChatGPT to generate optimization models from business descriptions through various prompting strategies. They tested the LLM's ability to understand high-level problem descriptions, generate correct mathematical formulations, and create efficient models through reformulation. The experiments focused on bike rental hub location problems and vaccination clinic optimization. The paper analyzed the strengths and weaknesses of LLMs in optimization modeling and identified research directions for adapting LLMs to meet the requirements of a DOCP.

## Key Results
- LLMs can translate business-level problem descriptions into mathematical optimization models through conversational interaction
- LLM-generated models often contain errors that require human intervention and specialized validation tools
- Current LLMs struggle to generate computationally efficient models without explicit efficiency instructions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can translate business-level problem descriptions into mathematical optimization models through conversational interaction.
- Mechanism: LLMs use natural language understanding to extract key entities, objectives, and constraints from high-level descriptions, then map these to formal optimization structures.
- Core assumption: The LLM has sufficient domain knowledge and reasoning capability to correctly interpret business terminology and translate it into mathematical constructs.
- Evidence anchors:
  - [abstract] "interacting in natural language to grasp the business problem, subsequently formulating and solving the corresponding optimization model"
  - [section 4.2.1] "they interacted with the user to understand the business problem and managed to get to the point of generating an optimization formulation"
- Break condition: The LLM produces incomplete or unsuitable formulations when the business description lacks sufficient detail or contains ambiguous terminology.

### Mechanism 2
- Claim: LLM-generated optimization models can be validated and corrected through business user feedback.
- Mechanism: The LLM can explain its generated model in natural language, allowing users to identify errors and request corrections through iterative dialogue.
- Core assumption: Business users can understand enough about the optimization model to validate its correctness and provide meaningful feedback.
- Evidence anchors:
  - [section 3.1, Requirement #2] "provide sufficient tools appropriate for the business decision-maker not only to validate the model but also provide feedback in a way that will enable correction"
  - [section 4.2.2] "For the vaccination clinic optimization problem, it missed the essential term ri in the objective function"
- Break condition: The validation tools are insufficient for non-experts to detect subtle errors, or the feedback loop fails to correct identified issues.

### Mechanism 3
- Claim: LLMs can generate efficient optimization models that are computationally tractable for real-world problems.
- Mechanism: The LLM can reformulate problems to reduce variables, convert nonlinear to linear constraints, and apply problem-specific decomposition techniques.
- Core assumption: The LLM possesses knowledge of optimization theory and practical modeling techniques that can be applied automatically.
- Evidence anchors:
  - [section 4.2.3] "ChatGPT could not produce satisfactory reformulations without explicit instructions to maintain an equivalent form while minimizing variables"
  - [section 4.2.3] "ChatGPT also finds this reformulation but again forgets to introduce binary variables for the ≥ constraint"
- Break condition: The LLM generates models that are correct but computationally intractable, or introduces errors when attempting efficiency improvements.

## Foundational Learning

- Concept: Mixed Integer Linear Optimization (MILO)
  - Why needed here: The paper identifies MILO as the appropriate model type for many real-world business problems, requiring understanding of linear constraints, integer variables, and optimization algorithms.
  - Quick check question: What distinguishes MILO from linear optimization, and why is it often computationally harder?

- Concept: Natural Language Processing (NLP) and Prompt Engineering
  - Why needed here: The system relies on LLMs to interpret business descriptions and generate models through conversational interaction, requiring knowledge of how to structure effective prompts.
  - Quick check question: How does chain-of-thought prompting differ from standard prompting, and when might it be useful for optimization modeling?

- Concept: Mathematical Modeling and Problem Formulation
  - Why needed here: Creating optimization models requires translating real-world constraints and objectives into mathematical expressions, understanding different formulation approaches.
  - Quick check question: How can the same business problem be formulated in multiple ways, and what makes one formulation more efficient than another?

## Architecture Onboarding

- Component map: LLM interface -> Model generation -> Solver interface -> Validation/communication module
- Critical path: User provides problem description → LLM understands and generates model → Model is solved by external solver → Results are validated and communicated back to user
- Design tradeoffs: Using an LLM for both understanding and model generation versus separating these functions; direct solution generation versus generating models for external solving; fully automated versus human-in-the-loop approaches
- Failure signatures: Incorrect model formulations, computational intractability, inability to handle complex constraints, communication failures between components
- First 3 experiments:
  1. Test LLM's ability to generate correct models from detailed problem descriptions (Requirement #2)
  2. Evaluate LLM's capacity to understand high-level business descriptions and ask clarifying questions (Requirement #1)
  3. Assess LLM's ability to reformulate models for efficiency (Requirement #3)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal combination of LLM adaptation techniques (prompting, fine-tuning, RLHF) for different requirements of the DOCP?
- Basis in paper: [explicit] The paper discusses the need for LLM adaptation to create a DOCP and asks how best to combine prompting, fine-tuning, and RLHF for each requirement.
- Why unresolved: The paper identifies this as an important research direction but does not provide specific answers or experiments on optimal combinations.
- What evidence would resolve it: Systematic experiments comparing different combinations of adaptation techniques for each DOCP requirement, showing which combinations perform best.

### Open Question 2
- Question: How can a DOCP enable business users to validate optimization models without requiring optimization expertise?
- Basis in paper: [explicit] The paper identifies this as Requirement #2 and notes that existing techniques like what-if analysis could be augmented by LLM capabilities.
- Why unresolved: The paper acknowledges the challenge but does not provide specific mechanisms or tools for business user validation.
- What evidence would resolve it: Development and testing of user-friendly validation interfaces that allow non-experts to effectively verify and provide feedback on DOCP-generated models.

### Open Question 3
- Question: Can LLMs be effectively adapted to generate efficient optimization models through variable reduction and reformulation?
- Basis in paper: [explicit] The paper's experiments showed ChatGPT struggled with creating efficient models, and this is identified as a key research gap.
- Why unresolved: Current LLMs produce inefficient models that are difficult to solve; the paper suggests this needs improvement but doesn't provide solutions.
- What evidence would resolve it: Demonstration that adapted LLMs can consistently generate optimization models that are both correct and computationally efficient compared to human experts.

## Limitations
- Model Quality and Correctness: LLMs frequently generate incorrect models requiring human intervention, with limited testing on complex real-world problems.
- Efficiency Claims: LLMs struggle to generate computationally efficient models without explicit efficiency instructions, with no evidence they can automatically apply optimization reformulation techniques.
- Business User Validation: The assumption that non-experts can effectively validate optimization models through natural language feedback remains unproven and potentially unrealistic.

## Confidence
- High Confidence: The paper correctly identifies that current LLMs can generate optimization models from business descriptions but struggle with accuracy and efficiency. The experimental evidence from ChatGPT interactions is concrete and reproducible.
- Medium Confidence: The proposed requirements for a Decision Optimization CoPilot (DOCP) are well-reasoned and address real gaps in the field. However, the feasibility of implementing all three requirements simultaneously remains unproven.
- Low Confidence: The timeline and roadmap for achieving the DOCP vision are speculative. The paper doesn't provide concrete estimates for when LLM capabilities will mature sufficiently to handle complex optimization problems autonomously.

## Next Checks
1. **Scale-Up Experiment**: Test the LLM's model generation capabilities on problems with 100+ variables and constraints, measuring both correctness rates and generation time. This would validate whether current LLM capabilities can handle real-world optimization scales.

2. **User Validation Study**: Conduct a controlled experiment where business users attempt to validate LLM-generated models with and without specialized tools. Measure their ability to detect errors and provide actionable feedback, testing the feasibility of the human-in-the-loop approach.

3. **Efficiency Benchmarking**: Compare LLM-generated model formulations against expert-designed models for the same problems, measuring solution times and resource usage. This would quantify whether LLMs can match human optimization expertise in model efficiency.