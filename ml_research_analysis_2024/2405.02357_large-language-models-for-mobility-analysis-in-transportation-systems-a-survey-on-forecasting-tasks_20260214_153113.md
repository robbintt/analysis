---
ver: rpa2
title: 'Large Language Models for Mobility Analysis in Transportation Systems: A Survey
  on Forecasting Tasks'
arxiv_id: '2405.02357'
source_url: https://arxiv.org/abs/2405.02357
tags:
- traffic
- llms
- data
- forecasting
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey reviews the emerging application of large language
  models (LLMs) to mobility forecasting tasks in transportation systems. The authors
  categorize approaches into data processing techniques (tokenization, prompt engineering,
  embedding) and model framework strategies (fine-tuning, zero/few-shot, integration).
---

# Large Language Models for Mobility Analysis in Transportation Systems: A Survey on Forecasting Tasks

## Quick Facts
- arXiv ID: 2405.02357
- Source URL: https://arxiv.org/abs/2405.02357
- Authors: Zijian Zhang; Yujie Sun; Zepu Wang; Yuqi Nie; Xiaobo Ma; Ruolin Li; Peng Sun; Xuegang Ban
- Reference count: 40
- Primary result: Reviews LLM applications to transportation forecasting, categorizing approaches and identifying key challenges

## Executive Summary
This survey examines the emerging application of large language models (LLMs) to mobility forecasting tasks in transportation systems. The authors systematically categorize existing approaches into data processing techniques (tokenization, prompt engineering, embedding) and model framework strategies (fine-tuning, zero/few-shot, integration). They present comprehensive applications spanning traffic forecasting, human mobility analysis, demand prediction, and missing data imputation, highlighting recent research including TrafficBERT, ST-LLM, and TrafficGPT. The work identifies critical challenges including data scarcity, privacy concerns, generalization across regions, uncertainty quantification, and real-time inference requirements. The survey serves as a guide for future research directions in leveraging LLMs for improved transportation system forecasting and planning.

## Method Summary
The survey employs a systematic literature review methodology, examining 40 references across English-language publications. The authors categorize LLM applications in transportation into two main dimensions: data processing approaches (tokenization, prompt engineering, embedding) and model framework strategies (fine-tuning, zero/few-shot, integration). Applications are organized by forecasting task type, including traffic flow prediction, human mobility patterns, transportation demand forecasting, and data imputation. The analysis identifies recent model developments and synthesizes challenges facing the field, providing a structured overview of current capabilities and limitations in LLM-based transportation forecasting.

## Key Results
- Categorizes LLM applications in transportation into data processing techniques and model framework strategies
- Documents applications across traffic forecasting, human mobility, demand prediction, and missing data imputation
- Highlights recent research including TrafficBERT, ST-LLM, and TrafficGPT models
- Identifies key challenges: data scarcity, privacy concerns, regional generalization, uncertainty quantification, and real-time inference requirements

## Why This Works (Mechanism)
The survey demonstrates how LLMs can leverage their sequence modeling capabilities to capture complex spatiotemporal patterns in transportation data. By treating mobility sequences as tokenizable data, LLMs can learn hierarchical representations that capture both local patterns and long-range dependencies. The survey shows how prompt engineering enables zero/few-shot learning for scenarios with limited training data, while fine-tuning allows domain adaptation to specific transportation contexts. The integration approaches combine LLMs with traditional forecasting methods to leverage complementary strengths. This multi-pronged approach addresses the fundamental challenge of modeling the complex, multimodal nature of transportation systems.

## Foundational Learning
- Tokenization methods - needed to convert continuous mobility data into discrete sequences that LLMs can process; quick check: verify token boundaries preserve meaningful temporal patterns
- Prompt engineering - needed to guide LLMs toward relevant outputs without extensive retraining; quick check: test prompt variations for consistent performance
- Spatiotemporal embeddings - needed to capture both spatial relationships and temporal dependencies in transportation networks; quick check: validate embedding quality on known patterns
- Cross-modal integration - needed to combine textual, numerical, and visual transportation data; quick check: test integration approaches on multimodal datasets
- Uncertainty quantification - needed for reliable decision-making in transportation planning; quick check: verify confidence intervals capture prediction errors
- Privacy-preserving techniques - needed to handle sensitive mobility data; quick check: validate differential privacy guarantees

## Architecture Onboarding
**Component Map:** Raw mobility data -> Tokenization -> LLM backbone -> Output layer -> Forecasting results

**Critical Path:** Data preprocessing (tokenization/embedding) -> Model selection (fine-tune/zero-shot/integration) -> Training/inference -> Post-processing -> Evaluation

**Design Tradeoffs:** Fine-tuning offers better performance but requires more data and computational resources; zero-shot approaches need minimal training but may underperform on domain-specific tasks; integration combines strengths but adds complexity

**Failure Signatures:** Poor tokenization leads to loss of temporal patterns; inadequate prompt engineering causes irrelevant outputs; overfitting during fine-tuning reduces generalization; privacy-preserving methods may degrade prediction accuracy

**First Experiments:**
1. Benchmark tokenization approaches on a standard traffic dataset to evaluate information preservation
2. Compare zero-shot vs. few-shot performance on human mobility prediction tasks
3. Test integration approaches combining LLMs with traditional time series methods on demand forecasting

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Rapid LLM evolution may leave recent developments underrepresented in the survey
- Categorization framework may not fully capture hybrid approaches combining multiple strategies
- Focus on English-language literature potentially misses relevant work in other languages
- Lack of standardized benchmarks makes cross-model performance comparison difficult

## Confidence
- High Confidence: Categorization of data processing techniques and model framework strategies is well-supported by literature
- Medium Confidence: Applications in traffic forecasting, human mobility, demand prediction, and missing data imputation are documented but vary in maturity
- Medium Confidence: Identified challenges (data scarcity, privacy, generalization, uncertainty, real-time inference) are well-documented but may not be exhaustive

## Next Checks
1. Conduct systematic review of non-English literature to assess potential coverage gaps
2. Perform empirical validation comparing LLM approaches (fine-tuning vs. zero-shot vs. integration) on standardized benchmarks
3. Investigate generalization capabilities of existing models across different geographic regions and transportation modes through cross-regional validation studies