---
ver: rpa2
title: 'Ukrainian-to-English folktale corpus: Parallel corpus creation and augmentation
  for machine translation in low-resource languages'
arxiv_id: '2410.10063'
source_url: https://arxiv.org/abs/2410.10063
tags:
- translation
- corpus
- ukrainian
- machine
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new Ukrainian-to-English parallel corpus
  focused on Ukrainian folktales to support machine translation for low-resource languages.
  The corpus includes 4 folktales with 400 aligned sentence pairs (6,800 English and
  4,157 Ukrainian words).
---

# Ukrainian-to-English folktale corpus: Parallel corpus creation and augmentation for machine translation in low-resource languages

## Quick Facts
- arXiv ID: 2410.10063
- Source URL: https://arxiv.org/abs/2410.10063
- Reference count: 6
- One-line primary result: Introduces a manually curated Ukrainian-to-English folktale parallel corpus for low-resource machine translation

## Executive Summary
This paper introduces a new Ukrainian-to-English parallel corpus focused on Ukrainian folktales to support machine translation for low-resource languages. The corpus includes 4 folktales with 400 aligned sentence pairs (6,800 English and 4,157 Ukrainian words). The authors curated sentence and word-level alignments to preserve cultural and linguistic nuances, focusing on domain-specific terms like mythological creatures and cultural references. They employed manual curation and proposed literal translations to enhance semantic accuracy for machine translation models, contrasting with poetic adaptations often used in human translation. The corpus is publicly available and aims to improve translation performance by providing high-quality, culturally rich training data. Future work includes expanding the corpus and evaluating its impact on machine translation models.

## Method Summary
The authors created a Ukrainian-to-English parallel corpus for folktale translation by manually selecting and aligning sentences and words from four Ukrainian folktales and their English translations. They focused on preserving semantic fidelity through literal, descriptive translations of culture-loaded terms rather than poetic adaptations. The corpus includes sentence-level and word-level alignments, with special attention to mythological creatures and cultural references. The manual curation process aimed to ensure accurate semantic translation for machine learning purposes, recognizing that machine translation requires different translation strategies than human translation.

## Key Results
- New corpus of 4 Ukrainian folktales with 400 aligned sentence pairs
- Word and sentence alignment preserves cultural and linguistic nuances
- Literal translations of culture-specific terms proposed for better MT semantic accuracy
- Corpus publicly available on GitHub for future MT model training and evaluation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Aligning sentence and word pairs preserves semantic fidelity for machine translation training.
- Mechanism: By matching source sentences to target sentences and explicitly aligning culture-loaded terms, the corpus ensures that translation models learn accurate mappings between semantically equivalent phrases rather than relying on poetic or adaptive human translations.
- Core assumption: Machine translation benefits more from literal, semantically accurate translations than from culturally adapted (transcreated) ones in the folktale domain.
- Evidence anchors:
  - [abstract] "Our corpus is word and sentence-aligned, allowing for the best curation of meaning, specifically tailored for use as training data for machine translation models."
  - [section] "We have aligned corpus by words to finetune the domain knowledge transfer... We have also aligned corpus by words to finetune the domain knowledge transfer."
- Break condition: If aligned pairs introduce more noise than benefit (e.g., if sentence-level alignment mismatches are frequent), semantic accuracy may degrade rather than improve.

### Mechanism 2
- Claim: Including literal, descriptive translations of culturally specific terms improves model coverage of rare vocabulary.
- Mechanism: The corpus replaces poetic or adapted translations (e.g., "Crunch-Munch the Mouse") with literal, descriptive equivalents ("Scratching Mouse") and expands mythological terms with explanatory context ("Mavka, the forest spirit"), thereby increasing the semantic precision of rare or domain-specific tokens.
- Core assumption: Rare or culture-loaded terms are the primary source of translation errors in low-resource settings, and explicit semantic expansion helps models learn these mappings.
- Evidence anchors:
  - [abstract] "We offer a combined domain-specific approach to building and augmenting this corpus, considering the nature of the domain and differences in the purpose of human versus machine translation."
  - [section] "Adding an extra layer of culturally significant information can only improve the outcome of the translation process."
- Break condition: If the added descriptive terms are too long or unnatural, they may confuse the model or diverge from the target language norms.

### Mechanism 3
- Claim: Curating training data manually for sentence and word alignment reduces domain mismatch and increases translation accuracy.
- Mechanism: Manual curation ensures that sentence pairs reflect the original meaning without reordering or lossy translation, and word alignment captures domain-specific terminology that automated methods might miss, especially for low-resource languages.
- Core assumption: Manual curation is more effective than automated alignment in capturing nuanced cultural and linguistic meaning in the folktale domain.
- Evidence anchors:
  - [abstract] "We have created a new Ukrainian-To-English parallel corpus of familiar Ukrainian folktales based on available English translations and suggested several new ones."
  - [section] "Due to the nature of this research, we needed to do a substantial amount of manual work related to curating training data."
- Break condition: If manual curation introduces subjective bias or is not scalable for larger corpora, the benefits may diminish.

## Foundational Learning

- Concept: Parallel corpus construction
  - Why needed here: The corpus is the foundational training resource for machine translation; understanding how to build and align sentence and word pairs is critical to improving model performance.
  - Quick check question: What is the difference between sentence alignment and word alignment in a parallel corpus, and why are both used here?

- Concept: Low-resource language challenges
  - Why needed here: Ukrainian is characterized as low-resource; recognizing the scarcity of parallel data and the importance of high-quality, domain-specific corpora is essential for effective translation model training.
  - Quick check question: Why does the size of a high-quality corpus sometimes matter more than the size of a large but noisy corpus in low-resource machine translation?

- Concept: Domain adaptation in machine translation
  - Why needed here: Folktales contain unique cultural and linguistic features; adapting translation models to this domain requires specialized training data and alignment strategies.
  - Quick check question: How does domain adaptation differ between human translation (which may adapt for style) and machine translation (which requires literal accuracy)?

## Architecture Onboarding

- Component map: Corpus creation pipeline: manual selection → sentence alignment → word alignment → domain-specific augmentation
- Critical path:
  1. Identify source folktales and available translations
  2. Manually align sentences and words
  3. Augment with literal, descriptive translations of culture-loaded terms
  4. Publish corpus and evaluate with MT models
- Design tradeoffs:
  - Manual curation ensures high quality but limits scalability
  - Literal translations preserve semantics but may reduce fluency in target language
  - Word alignment captures rare terms but increases annotation effort
- Failure signatures:
  - High mismatch rate between aligned sentences
  - MT models trained on corpus show no improvement or degrade in performance
  - Corpus becomes outdated or incomplete as more folktales are discovered
- First 3 experiments:
  1. Train a baseline NMT model on a general Ukrainian-English corpus, then fine-tune on the folktale corpus; compare BLEU scores.
  2. Evaluate the impact of word-level alignment by training models with and without aligned rare terms; measure improvement on culture-loaded vocabulary.
  3. Test the effect of literal vs. poetic translations by creating two versions of the corpus and comparing translation accuracy for domain-specific terms.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed corpus impact machine translation model performance compared to existing general-purpose Ukrainian-English corpora?
- Basis in paper: [explicit] The authors plan to research the performance of this corpus on several machine translation models in the future
- Why unresolved: No experimental results are provided yet to evaluate the impact of the folktale corpus on translation quality
- What evidence would resolve it: Empirical evaluation comparing BLEU or other metrics between models trained on the folktale corpus versus general-purpose corpora

### Open Question 2
- Question: What is the optimal ratio of culture-specific versus general vocabulary for effective low-resource machine translation?
- Basis in paper: [inferred] The paper focuses on culture-loaded terms but doesn't explore the balance needed for practical translation systems
- Why unresolved: The corpus is specialized for folklore but doesn't address how much general language coverage is needed
- What evidence would resolve it: Systematic experiments varying the proportion of domain-specific to general vocabulary in training data

### Open Question 3
- Question: How scalable is the manual curation approach for expanding the corpus to include more folktales and other Ukrainian literary domains?
- Basis in paper: [explicit] "We needed to do a substantial amount of manual work related to curating training data"
- Why unresolved: The paper doesn't address automation or semi-automation strategies for corpus expansion
- What evidence would resolve it: Development and evaluation of automated or semi-automated alignment tools for cultural and linguistic terms

### Open Question 4
- Question: How do different translation strategies (literal vs. adapted) affect machine translation quality for culture-specific terms?
- Basis in paper: [explicit] The authors contrast their literal translations with existing poetic adaptations
- Why unresolved: The paper doesn't empirically compare different translation approaches for cultural terms
- What evidence would resolve it: Comparative evaluation of translation quality using different strategies for cultural and mythological terms

## Limitations

- Extremely small corpus size (400 sentence pairs) may limit model generalization
- Manual curation approach is not scalable for corpus expansion
- No empirical evaluation results provided to demonstrate actual translation improvements
- Literal translations may reduce target language fluency despite preserving semantics

## Confidence

- Sentence/word alignment improving semantic fidelity: Medium
- Literal translations aiding rare vocabulary coverage: Medium
- Overall translation performance improvements: Low (no experimental validation provided)

## Next Checks

1. Train and evaluate MT models on this corpus versus baseline general-purpose corpora to measure actual performance gains.
2. Assess translation fluency and cultural appropriateness of literal translations through human evaluation.
3. Test corpus scalability by manually expanding to additional folktales and measuring alignment quality degradation or improvement.