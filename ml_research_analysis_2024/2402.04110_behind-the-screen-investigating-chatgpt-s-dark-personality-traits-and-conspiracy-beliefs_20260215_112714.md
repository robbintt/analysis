---
ver: rpa2
title: 'Behind the Screen: Investigating ChatGPT''s Dark Personality Traits and Conspiracy
  Beliefs'
arxiv_id: '2402.04110'
source_url: https://arxiv.org/abs/2402.04110
tags: []
core_contribution: "This study examines dark personality traits and conspiracy beliefs\
  \ in ChatGPT (GPT-3.5 and GPT-4) using psychological tests. Both models showed low\
  \ levels of dark traits, with GPT-4 displaying higher belief in information withholding\u2014\
  a surprising result given its larger training dataset."
---

# Behind the Screen: Investigating ChatGPT's Dark Personality Traits and Conspiracy Beliefs

## Quick Facts
- arXiv ID: 2402.04110
- Source URL: https://arxiv.org/abs/2402.04110
- Authors: Erik Weber; Jérôme Rutinowski; Markus Pauly
- Reference count: 0
- Primary result: ChatGPT models exhibit low dark personality traits but GPT-4 shows higher belief in information withholding; political role assignments increase conspiracy beliefs

## Executive Summary
This study investigates dark personality traits and conspiracy beliefs in ChatGPT models (GPT-3.5 and GPT-4) using psychological assessment tools adapted for AI systems. Both models displayed relatively low levels of dark personality traits, though GPT-4 showed a notable tendency toward believing in information withholding compared to its predecessor. The research found that assigning political roles to the models significantly increased their conspiracy belief scores, mirroring patterns observed in human studies. Additionally, the order of personality tests administered influenced the models' responses, suggesting contextual memory effects in their reasoning processes.

## Method Summary
The researchers adapted two psychological scales—the Dark Triad Short Scale (D-TS) and the Conspiracy Theory Scale (C-TS)—for use with ChatGPT models. They conducted 20 test runs for each model (GPT-3.5 and GPT-4), systematically varying the order of personality tests and including role-play scenarios where the models assumed political identities. The study employed prompt engineering techniques to elicit personality assessments and scored responses using modified human scoring methodologies, with careful attention to the models' language patterns and self-reported beliefs.

## Key Results
- Both GPT-3.5 and GPT-4 exhibited low overall dark personality trait scores
- GPT-4 demonstrated significantly higher belief in information withholding compared to GPT-3.5
- Political role assignments increased conspiracy belief scores, consistent with human psychological research
- Test sequencing affected model responses, indicating contextual memory influences

## Why This Works (Mechanism)
The study leverages the inherent language generation capabilities of large language models to produce personality assessments that can be scored using adapted human psychological frameworks. By prompting the models to self-report on personality traits and conspiracy beliefs, the researchers tapped into the models' training data patterns and internal representations of human psychology. The role-play component activates the models' ability to adopt different perspectives, which appears to influence their belief systems in predictable ways.

## Foundational Learning
- **Dark Triad Personality Assessment**: Understanding narcissistic, Machiavellian, and psychopathic traits in AI systems helps identify potential alignment risks
- **Conspiracy Theory Measurement**: Evaluating belief patterns in models reveals how they process and integrate misinformation
- **Prompt Engineering for Psychological Testing**: Adapting human assessment tools for AI requires careful linguistic framing and response interpretation
- **Contextual Memory in LLMs**: Test ordering effects demonstrate that models retain and integrate information across sequential prompts

## Architecture Onboarding
- **Component Map**: User Prompts -> GPT Model (3.5/4) -> Response Generation -> Scoring System -> Analysis
- **Critical Path**: Psychological Scale Prompts → Model Response → Scoring Algorithm → Statistical Analysis
- **Design Tradeoffs**: Using human psychological scales provides familiar frameworks but may not capture AI-specific personality dimensions
- **Failure Signatures**: Inconsistent scoring across different evaluators, model version variations affecting trait assessments
- **First Experiments**:
  1. Replicate with alternative scoring methodologies
  2. Test different political role scenarios
  3. Vary prompt phrasing to assess sensitivity

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Human-designed psychological scales may not fully capture AI personality dimensions
- Scoring methodology introduces potential subjectivity in interpretation
- Small sample size (n=20 per model) limits statistical power
- Results may be influenced by specific prompt engineering approaches

## Confidence
**High Confidence**: Observed differences between GPT-3.5 and GPT-4 in conspiracy belief scores are well-supported by empirical data.

**Medium Confidence**: Political role assignment effects on conspiracy beliefs require cautious interpretation due to limited sample size.

**Low Confidence**: GPT-4's higher information withholding beliefs may be influenced by scoring methodology and need further validation.

## Next Checks
1. Replicate the study with larger sample sizes (n≥50 per model) and multiple independent scorers to establish inter-rater reliability for personality trait assessments.

2. Conduct cross-validation using alternative personality assessment frameworks specifically designed for AI systems, such as the Big Five Inventory adapted for language models.

3. Test the temporal stability of personality trait scores by conducting the same assessments across multiple time points to evaluate consistency and potential model version effects.