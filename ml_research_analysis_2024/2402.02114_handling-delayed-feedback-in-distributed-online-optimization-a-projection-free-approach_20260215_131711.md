---
ver: rpa2
title: 'Handling Delayed Feedback in Distributed Online Optimization : A Projection-Free
  Approach'
arxiv_id: '2402.02114'
source_url: https://arxiv.org/abs/2402.02114
tags: []
core_contribution: "The paper addresses online convex optimization (OCO) with adversarial\
  \ delayed feedback in both centralized and distributed settings. The key contribution\
  \ is the development of projection-free algorithms, DeLMFW for centralized and De2MFW\
  \ for distributed settings, which achieve an optimal regret bound of O(\u221AB),\
  \ where B is the sum of delays."
---

# Handling Delayed Feedback in Distributed Online Optimization : A Projection-Free Approach

## Quick Facts
- arXiv ID: 2402.02114
- Source URL: https://arxiv.org/abs/2402.02114
- Reference count: 40
- One-line primary result: Projection-free algorithms DeLMFW and De2MFW achieve optimal O(√B) regret in centralized and distributed online optimization with adversarial delayed feedback.

## Executive Summary
This paper addresses online convex optimization with adversarial delayed feedback in both centralized and distributed settings. The authors develop projection-free algorithms (DeLMFW and De2MFW) that achieve optimal regret bounds of O(√B) where B is the sum of delays. The algorithms use Frank-Wolfe updates with multiple online linear optimization oracles (FTPL) to handle delayed feedback, maintaining the same regret bound as non-delayed settings up to an additive term depending on total delay. Experiments on MNIST and FashionMNIST datasets demonstrate that the proposed algorithms outperform existing solutions in both centralized and distributed settings.

## Method Summary
The paper presents DeLMFW for centralized settings and De2MFW for distributed settings, both using Frank-Wolfe updates with K sub-iterations per round. Each oracle receives accumulated delayed gradients as feedback, allowing progress even when some feedback is missing. The distributed version includes gradient tracking and weighted averaging to maintain consensus among agents with different delay patterns. Key hyperparameters include ζ = 1/(G√B), ηk = min(1, A/k), and K = √T. The algorithms are tested on MNIST and FashionMNIST datasets with 30 agents across various network topologies.

## Key Results
- DeLMFW and De2MFW achieve optimal regret bounds of O(√B) in centralized and distributed settings respectively
- Algorithms outperform existing solutions (DOFW, BOLD-MFW) in both centralized and distributed settings
- Regret bound degradation is additive rather than multiplicative, preserving the optimal √T rate up to delay penalty
- Performance validated on real-world datasets (MNIST, FashionMNIST) with 30 agents across different network topologies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DeLMFW and De2MFW achieve optimal regret bounds of O(√B) in centralized and distributed settings respectively by using multiple FTPL oracles to handle delayed feedback.
- Mechanism: The algorithms use Frank-Wolfe updates with K sub-iterations per round, where each oracle receives accumulated delayed gradients as feedback. This allows the algorithm to make progress even when some feedback is missing, with the regret degradation bounded by the total delay B.
- Core assumption: The constraint set K is bounded and convex, and the loss functions are smooth and Lipschitz continuous.
- Evidence anchors:
  - [abstract] states the algorithms achieve "regret bound of O(√B) where B is the sum of delay"
  - [section] shows "Lemma 2. Let ˆvt be the FTPL prediction... For all t ∈ [T ], we have: ∥vt − ˆvt∥ ≤ ζDG Σs<t I{s+ds>t}"
  - [corpus] evidence is limited - the neighbor papers discuss projection-free methods but don't directly address delayed feedback handling
- Break condition: If the delays become adversarial in a way that causes feedback to arrive out of order beyond what the algorithm can handle, or if the Lipschitz/smoothness assumptions are violated

### Mechanism 2
- Claim: In the distributed setting, De2MFW uses gradient tracking and weighted averaging to maintain consensus among agents while handling individual delay patterns.
- Mechanism: Each agent maintains local oracles and performs weighted aggregation of neighbors' decisions (yi,t,k) and gradients (di,t,k). The gradient tracking step ensures the local gradients converge to the global gradient as K increases.
- Core assumption: The communication graph is connected and the doubly stochastic mixing matrix W has a spectral gap ρ = 1 - λ(W).
- Evidence anchors:
  - [section] shows "Lemma 3. Define Cd = k0√nD... max i∈[1,n] ∥yi,t,k − xt,k∥ ≤ Cd k"
  - [section] shows "Lemma 4. For all t ∈ [T ], k ∈ [K] and i ∈ [n]... ∥vi,t,k − ˆvi,t,k∥ ≤ 2ζ√nDG(λ(W)/ρ + 1) * 1/n Σi=1,n Σs≤t I{s+dis>t}"
  - [corpus] evidence is limited - neighbor papers discuss decentralized optimization but not specifically with delayed feedback
- Break condition: If the communication graph becomes disconnected, or if the spectral gap becomes too small causing slow mixing

### Mechanism 3
- Claim: The regret bound degrades additively by a term proportional to √B rather than multiplicatively, preserving the optimal √T rate up to the delay penalty.
- Mechanism: The key insight is that the delayed feedback affects the oracle predictions by at most ζDG per missing feedback, and since we use ζ = 1/(G√B), the total degradation is bounded by ζDG√B = DG/√B.
- Evidence anchors:
  - [section] shows "Theorem 1. Given a constraint set K... the regret of Algorithm 1 is Σt=1,T [ft(xt) − ft(x*)] ≤ 2βAD²√T + 3(A+1)(DG√B + RT,O)"
  - [section] shows "If we assume that there exists a maximum value d such that dt ≤ d for all t ∈ [T ]. Our regret bound becomes O(√dT)"
  - [corpus] evidence is limited - neighbor papers discuss online optimization but don't provide the specific regret analysis for delayed feedback
- Break condition: If the total delay B becomes comparable to or larger than T, the √B term could dominate and the algorithm would no longer be optimal

## Foundational Learning

- Concept: Online Convex Optimization (OCO) with adversarial delays
  - Why needed here: The entire problem setting assumes an online environment where loss functions are revealed adversarially with delays, requiring algorithms that can handle this uncertainty
  - Quick check question: What is the difference between stochastic and adversarial delays in online optimization?

- Concept: Frank-Wolfe algorithm and projection-free methods
  - Why needed here: The algorithms use Frank-Wolfe updates to avoid expensive projection operations, which is crucial for edge devices with limited computational resources
  - Quick check question: Why is avoiding projections particularly important in distributed edge computing scenarios?

- Concept: Gradient tracking and consensus in distributed optimization
  - Why needed here: De2MFW uses gradient tracking to ensure all agents converge to the same solution despite having different local delay patterns
  - Quick check question: How does gradient tracking differ from simple averaging in distributed optimization?

## Architecture Onboarding

- Component map:
  Central coordinator (centralized) or communication graph (distributed) -> K Frank-Wolfe oracles per agent/round -> Delay mechanism tracking which feedback arrives when -> Gradient accumulation and tracking components -> Decision aggregation components

- Critical path:
  1. Receive available feedback at time t
  2. Update each oracle with accumulated gradients
  3. Get oracle predictions vt,k
  4. Perform K Frank-Wolfe updates to get xt
  5. In distributed setting, aggregate neighbors' decisions and gradients
  6. Play xt and observe loss ft(xt)

- Design tradeoffs:
  - K vs regret: Larger K reduces consensus error but increases computational cost
  - Oracle choice: FTPL provides good regret bounds but other oracles could be used
  - Communication frequency: More frequent communication reduces delay impact but increases overhead

- Failure signatures:
  - Regret growing faster than √T suggests delay handling is breaking down
  - Divergence between agents' decisions indicates consensus mechanism failure
  - Slow convergence suggests spectral gap of W is too small

- First 3 experiments:
  1. Test DeLMFW on synthetic data with varying delay patterns (constant, random, adversarial) to verify the √B regret bound
  2. Test De2MFW on a small network with 2-3 agents and different delay patterns per agent to verify consensus maintenance
  3. Scale De2MFW to larger networks with different topologies (grid, cycle, complete) to observe how network structure affects performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the algorithm's performance change when using stochastic gradients instead of exact gradients?
- Basis in paper: [inferred] The paper mentions that exact gradients are used, but suggests that using stochastic gradients with variance reduction techniques could be explored in future work.
- Why unresolved: The paper does not provide any experimental results or theoretical analysis of the algorithm's performance when using stochastic gradients.
- What evidence would resolve it: Experimental results comparing the performance of the algorithm with exact and stochastic gradients on various datasets, and theoretical analysis of the regret bounds when using stochastic gradients.

### Open Question 2
- Question: How does the algorithm's performance change in distributed settings with communication delays?
- Basis in paper: [inferred] The paper focuses on adversarial delays in feedback, but mentions that communication delays can be practically challenging in distributed settings and could be improved upon in future work.
- Why unresolved: The paper does not provide any experimental results or theoretical analysis of the algorithm's performance in distributed settings with communication delays.
- What evidence would resolve it: Experimental results comparing the performance of the algorithm in distributed settings with and without communication delays on various network topologies and datasets.

### Open Question 3
- Question: How does the algorithm's performance change when the delay values are not upper bounded by a constant?
- Basis in paper: [explicit] The paper assumes that there exists a maximum delay value d such that dt ≤ d for all t ∈ [T], and the regret bound becomes O(√dT) in this case.
- Why unresolved: The paper does not provide any experimental results or theoretical analysis of the algorithm's performance when the delay values are not upper bounded by a constant.
- What evidence would resolve it: Experimental results comparing the performance of the algorithm with different delay distributions (e.g., exponential, uniform) on various datasets, and theoretical analysis of the regret bounds for different delay distributions.

## Limitations

- The theoretical guarantees rely on Lipschitz and smoothness conditions that may not hold in all practical scenarios
- The algorithms assume doubly stochastic mixing matrices with known spectral gaps, which may not be realistic in all distributed settings
- The variance of regret across different delay patterns and network topologies is not fully characterized

## Confidence

- **High Confidence**: The core algorithmic framework and the general √B regret bound structure
- **Medium Confidence**: The specific constants in the regret bounds and their dependence on network parameters
- **Low Confidence**: The robustness of the algorithms to non-smooth or non-convex loss functions

## Next Checks

1. **Adversarial Delay Stress Test**: Implement the algorithms and test under worst-case delay patterns (e.g., coordinated adversarial delays across all agents) to verify if the O(√B) bound holds in the most challenging scenarios.

2. **Network Topology Sensitivity Analysis**: Systematically vary network connectivity and spectral gap while keeping other parameters fixed to quantify how network structure affects convergence rates and regret bounds.

3. **Real-World Deployment Scenario**: Implement the distributed algorithm on a real edge computing testbed with heterogeneous devices and varying communication delays to validate performance outside controlled experimental conditions.