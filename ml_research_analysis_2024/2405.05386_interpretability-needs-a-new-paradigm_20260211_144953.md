---
ver: rpa2
title: Interpretability Needs a New Paradigm
arxiv_id: '2405.05386'
source_url: https://arxiv.org/abs/2405.05386
tags:
- paradigm
- interpretability
- explanations
- arxiv
- paradigms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper argues that interpretability research needs new paradigms
  beyond the current intrinsic and post-hoc approaches. The authors claim that neither
  paradigm adequately ensures faithfulness of explanations - the intrinsic paradigm's
  architectural constraints don't guarantee faithful explanations, while the post-hoc
  paradigm struggles to provide faithful explanations for black-box models.
---

# Interpretability Needs a New Paradigm

## Quick Facts
- arXiv ID: 2405.05386
- Source URL: https://arxiv.org/abs/2405.05386
- Reference count: 40
- Primary result: Current interpretability paradigms are inadequate for ensuring faithful explanations

## Executive Summary
This paper presents a critical analysis of current interpretability research paradigms and argues that both intrinsic and post-hoc approaches have fundamental limitations in ensuring faithful explanations. The authors contend that architectural constraints in intrinsic methods don't guarantee faithful explanations, while post-hoc methods struggle to provide faithful explanations for black-box models. They propose three emerging paradigms - learn-to-faithfully-explain, faithfulness-measurable models, and self-explaining models - as potential solutions to better address the challenge of ensuring explanation faithfulness while maintaining model performance.

## Method Summary
The paper provides a conceptual analysis and critique of existing interpretability paradigms rather than presenting a specific methodology. It synthesizes literature on intrinsic and post-hoc interpretability approaches to demonstrate their limitations in ensuring faithful explanations. The authors then propose three new conceptual paradigms as alternatives, focusing on theoretical frameworks rather than empirical implementation. The work is primarily analytical, examining the theoretical foundations and practical limitations of current approaches while suggesting new directions for research.

## Key Results
- Current intrinsic and post-hoc interpretability paradigms are fundamentally inadequate for ensuring faithful explanations
- Three emerging paradigms are proposed: learn-to-faithfully-explain, faithfulness-measurable models, and self-explaining models
- New paradigms could potentially better balance faithfulness and model performance
- Vigilance regarding faithfulness remains crucial even with new approaches to avoid misleading explanations

## Why This Works (Mechanism)

## Foundational Learning
1. **Intrinsic vs. Post-hoc Interpretability** - Understanding the distinction between models designed to be interpretable (intrinsic) versus those explained after training (post-hoc)
   - Why needed: The paper's critique centers on limitations of both approaches
   - Quick check: Can identify whether a given interpretability method falls into intrinsic or post-hoc category

2. **Explanation Faithfulness** - The degree to which an explanation accurately represents the model's actual decision-making process
   - Why needed: Central concept the paper argues current paradigms fail to ensure
   - Quick check: Can distinguish between explanations that appear convincing versus those that are truly faithful

3. **Black-box Model Limitations** - Challenges in understanding and explaining models whose internal workings are opaque
   - Why needed: Explains why post-hoc methods struggle with faithfulness
   - Quick check: Can articulate specific challenges in explaining complex neural networks

## Architecture Onboarding

Component Map: Learn-to-faithfully-explain -> Faithfulness-measurable model -> Self-explaining model

Critical Path: The paper identifies the need to move beyond current paradigms, proposes three alternatives, and emphasizes vigilance in validation

Design Tradeoffs: The new paradigms must balance faithfulness with model performance, computational efficiency, and practical implementation feasibility

Failure Signatures: Explanations that appear convincing but fail to capture actual model behavior; architectural constraints that don't translate to faithful explanations; measurement methods that cannot reliably assess faithfulness

First Experiments:
1. Implement a learn-to-faithfully-explain approach on a benchmark task
2. Develop a faithfulness-measurable model and compare explanation quality metrics
3. Create a self-explaining model prototype and conduct ablation studies on performance impact

## Open Questions the Paper Calls Out
None

## Limitations
- Proposed new paradigms remain largely theoretical without empirical validation
- Practical implementation challenges and computational costs are not thoroughly explored
- Performance trade-offs of new approaches are not well-characterized
- The actual utility and effectiveness of proposed paradigms require concrete empirical evidence

## Confidence
- Claim that current paradigms are inadequate: High confidence
- Feasibility of proposed new paradigms: Medium confidence
- Effectiveness of new paradigms in balancing faithfulness and performance: Low confidence

## Next Checks
1. Implement and evaluate a learn-to-faithfully-explain approach on a benchmark task to measure both faithfulness scores and model performance impacts
2. Develop a faithfulness-measurable model and validate whether it enables more reliable measurement of explanation faithfulness compared to existing methods
3. Create a self-explaining model prototype and conduct ablation studies to determine the performance cost of including explanation capabilities directly in the model architecture