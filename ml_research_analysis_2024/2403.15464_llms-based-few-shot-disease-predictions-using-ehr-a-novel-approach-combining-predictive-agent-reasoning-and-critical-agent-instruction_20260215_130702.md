---
ver: rpa2
title: 'LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining
  Predictive Agent Reasoning and Critical Agent Instruction'
arxiv_id: '2403.15464'
source_url: https://arxiv.org/abs/2403.15464
tags:
- agent
- prediction
- disease
- llms
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates using Large Language Models (LLMs) for
  few-shot disease prediction from Electronic Health Records (EHRs). Traditional supervised
  learning methods require large labeled datasets, which are costly and challenging
  to obtain.
---

# LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction

## Quick Facts
- arXiv ID: 2403.15464
- Source URL: https://arxiv.org/abs/2403.15464
- Reference count: 40
- LLMs can effectively perform few-shot disease prediction from EHR narratives using collaborative predictor and critic agents

## Executive Summary
This study explores using Large Language Models (LLMs) for few-shot disease prediction from Electronic Health Records (EHRs). Traditional supervised learning requires large labeled datasets, which are costly and challenging to obtain. The authors propose converting structured EHR data into natural language narratives and evaluating zero-shot and few-shot LLM performance using various prompting strategies. They introduce EHR-CoAgent, a novel approach using two LLM agents: a predictor agent that makes predictions and generates reasoning, and a critic agent that analyzes incorrect predictions and provides guidance for improvement. The critic's feedback updates the predictor's prompts, enabling the system to learn from mistakes and adapt to EHR-based disease prediction challenges. Results show that EHR-CoAgent achieves decent few-shot performance compared to traditional supervised learning methods, with GPT-4 generally outperforming GPT-3.5.

## Method Summary
The approach converts structured EHR data (diagnoses, labs, prescriptions) into natural language narratives by mapping medical codes to their names. For few-shot learning, the method selects small numbers of positive and negative examples from training data as exemplars. The EHR-CoAgent framework employs two LLM agents: a predictor agent that makes disease predictions with reasoning, and a critic agent that analyzes incorrect predictions to identify biases and reasoning flaws. The critic generates feedback on the predictor's reasoning, which is consolidated and used to refine the predictor's prompts. This iterative process creates a feedback loop that improves performance over time. The study evaluates zero-shot and few-shot performance using various EHR-prediction-oriented prompting strategies, comparing GPT-3.5 and GPT-4 performance.

## Key Results
- EHR-CoAgent achieves decent few-shot performance compared to traditional supervised learning methods
- GPT-4 generally outperforms GPT-3.5 in few-shot disease prediction tasks
- The collaborative agent framework with predictor and critic roles shows promise for learning from mistakes and improving predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Converting structured EHR data to natural language narratives enables LLMs to leverage their pre-trained medical knowledge effectively
- Mechanism: LLMs are pre-trained on vast text corpora including medical literature, but cannot directly interpret structured medical codes. By mapping ICD codes to their natural language names and constructing coherent narratives, the EHR data becomes accessible to the LLM's existing knowledge representations
- Core assumption: LLMs encode sufficient medical knowledge during pre-training to understand clinical concepts when presented in natural language format
- Evidence anchors:
  - [abstract]: "convert structured patient visit data (e.g., diagnoses, labs, prescriptions) into natural language narratives"
  - [section]: "We convert the structured EHR records into unstructured language narratives, denoted as H, by mapping the medical codes to their names"
  - [corpus]: Weak - no direct comparison of performance with vs without narrative conversion
- Break condition: If the LLM's pre-training corpus lacks sufficient medical domain coverage, or if critical clinical relationships are lost during narrative conversion

### Mechanism 2
- Claim: Collaborative agent framework with predictor and critic agents enables iterative refinement of reasoning and predictions
- Mechanism: The predictor agent makes initial predictions with reasoning, while the critic agent analyzes incorrect predictions to identify biases and reasoning flaws. The critic's feedback is consolidated and used to refine the predictor's prompts, creating a feedback loop that improves performance over time
- Core assumption: The critic agent can accurately identify systematic errors in the predictor's reasoning and generate actionable feedback
- Evidence anchors:
  - [abstract]: "proposes a novel approach that utilizes LLM agents with different roles: a predictor agent that makes predictions and generates reasoning processes and a critic agent that analyzes incorrect predictions and provides guidance for improving the reasoning of the predictor agent"
  - [section]: "Our approach combines the strengths of predictive agent reasoning and critical agent instruction to create a more robust and accurate prediction system"
  - [corpus]: Weak - no comparison with single-agent approaches using the same LLMs
- Break condition: If the critic agent cannot generate meaningful feedback, or if the predictor cannot effectively incorporate the feedback into improved reasoning

### Mechanism 3
- Claim: Few-shot learning capability of LLMs allows effective disease prediction with minimal labeled examples
- Mechanism: By providing a small number of exemplar cases (3 positive, 3 negative) in the prompt, the LLM can adapt its pre-existing knowledge to the specific task without requiring extensive fine-tuning or large labeled datasets
- Core assumption: LLMs can effectively generalize from a small number of examples when combined with their pre-existing knowledge
- Evidence anchors:
  - [abstract]: "evaluate the zero-shot and few-shot performance of LLMs using various EHR-prediction-oriented prompting strategies"
  - [section]: "We randomly select a small number of positive and negative samples (e.g., 3 positive and 3 negative) from the training data to serve as exemplars for each prediction category"
  - [corpus]: Moderate - related work on "Time Associated Meta Learning for Clinical Prediction" and "Augmented Risk Prediction for the Onset of Alzheimer's Disease" also explores few-shot approaches
- Break condition: If the few examples provided are not representative of the task distribution, or if the LLM cannot effectively integrate few-shot examples with its existing knowledge

## Foundational Learning

- Concept: Prompt engineering and zero-shot/few-shot learning
  - Why needed here: The entire approach relies on effectively prompting LLMs without fine-tuning, making prompt design critical for performance
  - Quick check question: What are the key differences between zero-shot, one-shot, and few-shot prompting, and how might each affect performance on medical prediction tasks?

- Concept: Agent-based collaborative AI systems
  - Why needed here: Understanding how multiple specialized agents can work together to solve complex problems is central to the EHR-CoAgent approach
  - Quick check question: What are the key design considerations when creating a system with multiple LLM agents that have different roles and responsibilities?

- Concept: Electronic Health Record structure and clinical coding systems
  - Why needed here: The study converts structured EHR data to narratives, requiring understanding of what data is available and how it's encoded
  - Quick check question: What are the main types of clinical codes used in EHR systems, and how do ICD, CPT, and ATC codes differ in their purpose and structure?

## Architecture Onboarding

- Component map: EHR data → Narrative conversion → Predictor agent → Critic agent → Feedback consolidation → Prompt refinement → Improved predictions
- Critical path: EHR data → Narrative conversion → Predictor agent → Critic agent → Feedback consolidation → Prompt refinement → Improved predictions
- Design tradeoffs:
  - Cost vs performance: GPT-4 provides better performance but higher cost than GPT-3.5
  - Prompt complexity vs interpretability: More detailed prompts may improve performance but reduce transparency
  - Batch size for critic feedback: Larger batches provide more comprehensive feedback but increase latency
- Failure signatures:
  - High sensitivity but low specificity suggests the model is overly conservative in predictions
  - No improvement after feedback iterations indicates the critic agent may not be generating actionable guidance
  - Performance degradation with additional few-shot examples suggests poor example selection or model confusion
- First 3 experiments:
  1. Compare zero-shot performance with and without narrative conversion to validate the conversion mechanism
  2. Test single LLM agent (predictor only) vs collaborative approach to isolate the benefit of the critic feedback loop
  3. Vary the number of few-shot examples (1, 3, 5, 10) to determine optimal sample size for adaptation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of EHR-CoAgent scale with increasing complexity of EHR narratives (e.g., longer patient histories, more diverse medical conditions)?
- Basis in paper: [inferred] The paper evaluates performance on two datasets but does not systematically vary narrative complexity or length.
- Why unresolved: The study uses fixed datasets with predetermined narrative structures without exploring how performance changes with narrative complexity.
- What evidence would resolve it: Systematic experiments varying narrative length, diversity of medical conditions, and complexity of patient histories while measuring performance changes.

### Open Question 2
- Question: What is the optimal balance between predictor and critic agent iterations for maximizing prediction accuracy without overfitting to specific cases?
- Basis in paper: [explicit] The paper mentions repeating the critic agent process "m times" but doesn't specify or test optimal values for m.
- Why unresolved: The paper states the critic agent generates feedback multiple times but doesn't explore how many iterations yield optimal performance.
- What evidence would resolve it: Experiments testing different values of m (number of critic iterations) and analyzing the trade-off between performance gains and overfitting risk.

### Open Question 3
- Question: How transferable is the EHR-CoAgent approach across different medical specialties beyond the tested domains (lipid metabolism and CVD)?
- Basis in paper: [inferred] The study focuses on two specific medical domains but doesn't test generalizability to other specialties.
- Why unresolved: The paper demonstrates success in two specific medical domains but doesn't evaluate performance across diverse medical specialties.
- What evidence would resolve it: Testing EHR-CoAgent on multiple medical specialties (e.g., oncology, neurology, infectious diseases) and comparing performance across domains.

### Open Question 4
- Question: How does the quality and completeness of EHR data affect the performance of LLM-based predictions, particularly in cases with missing or incomplete information?
- Basis in paper: [explicit] The paper mentions "budget consideration" in sampling data but doesn't systematically study the impact of data quality or completeness.
- Why unresolved: The study uses relatively complete datasets but doesn't explore how missing data, incomplete records, or data quality issues affect performance.
- What evidence would resolve it: Experiments systematically introducing missing data, incomplete records, or noise into EHR narratives and measuring the impact on prediction accuracy.

## Limitations
- Evaluation is primarily conducted on a single disease prediction task (diabetes to CVD progression), limiting generalizability
- The study uses GPT-3.5 and GPT-4 but does not compare against other LLM architectures or open-source alternatives
- The narrative conversion process from structured EHR data to natural language is not validated for preserving critical clinical information

## Confidence
- **High confidence**: The basic premise that LLMs can perform few-shot learning for disease prediction from EHR narratives is well-supported by the results
- **Medium confidence**: The EHR-CoAgent framework's effectiveness is demonstrated but could benefit from more extensive ablation studies
- **Low confidence**: The generality of findings across different diseases, healthcare systems, and LLM architectures remains unproven

## Next Checks
1. Apply the same framework to predict different disease outcomes (e.g., CKD progression, heart failure) using the same dataset to assess generalizability beyond CVD prediction from diabetes
2. Conduct controlled experiments comparing model performance with and without the narrative conversion step, and with and without the critic agent feedback loop, to isolate the contribution of each component
3. Benchmark GPT-4 performance against smaller or open-source models (e.g., LLaMA, Mistral) using the same framework to determine if performance gains justify increased computational costs for real-world deployment