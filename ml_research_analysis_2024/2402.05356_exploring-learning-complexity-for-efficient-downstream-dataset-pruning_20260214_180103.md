---
ver: rpa2
title: Exploring Learning Complexity for Efficient Downstream Dataset Pruning
arxiv_id: '2402.05356'
source_url: https://arxiv.org/abs/2402.05356
tags:
- uni00000013
- learning
- pruning
- uni00000008
- uni00000014
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a training-free hardness score named Distorting-based
  Learning Complexity (DLC) for efficient downstream dataset pruning. DLC quantifies
  sample hardness as the average predicted confidence of model subnets with different
  capacities, using a lightweight weights masking process instead of costly SGD optimization.
---

# Exploring Learning Complexity for Efficient Downstream Dataset Pruning

## Quick Facts
- arXiv ID: 2402.05356
- Source URL: https://arxiv.org/abs/2402.05356
- Authors: Wenyu Jiang; Zhenlong Liu; Zejian Xie; Songxin Zhang; Bingyi Jing; Hongxin Wei
- Reference count: 29
- Primary result: 35x speedup in dataset pruning while achieving state-of-the-art performance

## Executive Summary
This paper introduces Distorting-based Learning Complexity (DLC), a training-free method for dataset pruning that quantifies sample hardness through subnet confidence scores. The approach uses lightweight weight masking instead of SGD optimization, enabling dramatic speed improvements while maintaining competitive accuracy. FlexRand, a flexible under-sampling method with randomness, replaces traditional top-K strategies to mitigate subset distribution shift. Experiments demonstrate the method's effectiveness across image and instruction datasets, particularly at extreme pruning rates where it outperforms random pruning by up to 5% in classification accuracy.

## Method Summary
DLC measures sample hardness by computing the average predicted confidence across multiple model subnets with varying capacities. The method employs weight masking to sample these subnets without costly optimization, using only a single forward pass through the model. FlexRand introduces controlled randomness to the pruning process, replacing deterministic top-K selection with probabilistic sampling that better preserves the overall data distribution. The approach is training-free and architecture-agnostic, requiring only access to a pre-trained model for evaluation.

## Key Results
- Achieves 35x reduction in pruning time compared to traditional methods
- Establishes state-of-the-art performance on image and instruction dataset pruning benchmarks
- Outperforms random pruning by up to 5% in classification accuracy at extreme pruning rates

## Why This Works (Mechanism)
The method leverages the observation that sample hardness correlates with the consistency of model predictions across different subnet configurations. By sampling subnets through weight masking rather than full training, DLC captures how reliably a sample can be classified regardless of model capacity. The randomness introduced by FlexRand helps maintain dataset diversity by avoiding the selection bias inherent in deterministic pruning, which often leads to overrepresentation of easy samples and underrepresentation of challenging ones.

## Foundational Learning
- **Dataset pruning fundamentals**: Understanding how removing samples affects model performance and training dynamics
- **Sample hardness estimation**: Methods for quantifying the difficulty of learning from individual data points
- **Neural network subnetworks**: The concept that smaller subnetworks within larger networks can approximate full model behavior
- **Weight masking techniques**: Methods for selectively disabling network parameters without retraining
- **Confidence scoring in classification**: How predicted probabilities relate to sample difficulty and model certainty
- **Distribution preservation in subset selection**: Ensuring pruned datasets maintain representative characteristics of the full dataset

## Architecture Onboarding
**Component Map**: Pre-trained model -> Weight masking module -> Subnet confidence scoring -> FlexRand sampling -> Pruned dataset
**Critical Path**: The core computation involves generating multiple subnet configurations through weight masking, computing confidence scores for each sample across these subnets, and applying FlexRand sampling to select the final pruned dataset.
**Design Tradeoffs**: Speed vs. accuracy optimization through training-free approach, randomness vs. determinism in subset selection, and computational efficiency vs. theoretical rigor in hardness estimation.
**Failure Signatures**: Performance degradation on datasets with highly imbalanced classes, poor results when pre-trained model is mismatched to target domain, and sensitivity to random seed choices in FlexRand.
**First Experiments**: 1) Compare DLC vs random pruning on CIFAR-10 at 90% pruning rate, 2) Measure runtime differences between DLC and SGD-based pruning methods, 3) Evaluate ensemble performance using multiple FlexRand runs with different seeds.

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Theoretical justification for using subnet confidence as hardness proxy remains empirical rather than rigorously proven
- Performance on non-classification tasks (detection, segmentation, generation) not evaluated
- Sensitivity to random seed choices and variability in pruning outcomes not fully characterized

## Confidence
- High confidence in runtime improvements and comparative benchmarks on tested datasets
- Medium confidence in the general applicability of DLC across different model architectures and task types
- Medium confidence in the theoretical justification for using subnet confidence as a hardness proxy

## Next Checks
1. Test DLC performance on non-classification tasks including object detection, semantic segmentation, and text generation to assess generalizability beyond standard benchmarks
2. Evaluate sensitivity to random seed choices by measuring variance in pruning performance across multiple runs with identical hyperparameters but different random initializations
3. Compare DLC against learnable pruning methods in few-shot and domain adaptation scenarios where training data availability is limited but adaptation capability is critical