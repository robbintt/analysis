---
ver: rpa2
title: Investigating Markers and Drivers of Gender Bias in Machine Translations
arxiv_id: '2403.11896'
source_url: https://arxiv.org/abs/2403.11896
tags:
- gender
- pronoun
- language
- bias
- sentences
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates gender bias in machine translation using
  back-translation of 56 Software Engineering tasks via DeepL API across five intermediate
  languages. The research proposes a novel metric, the adjusted unalikeability coefficient
  (UCA), to measure gender variation in pronoun selection, addressing limitations
  in prior approaches that over-interpreted individual pronouns.
---

# Investigating Markers and Drivers of Gender Bias in Machine Translations

## Quick Facts
- arXiv ID: 2403.11896
- Source URL: https://arxiv.org/abs/2403.11896
- Authors: Peter J Barclay; Ashkan Sami
- Reference count: 34
- Primary result: Introduces UCA metric and identifies main verbs as drivers of gender uncertainty in machine translation

## Executive Summary
This study investigates gender bias in machine translation using a novel approach of back-translation through multiple intermediate languages. The researchers propose the adjusted unalikeability coefficient (UCA) as a new metric to measure gender variation in pronoun selection, addressing limitations in previous approaches that focused on individual pronouns. The method demonstrates that main verbs in sentences are significant drivers of gender uncertainty in translations, with languages falling into three loose groups based on pronoun usage patterns.

## Method Summary
The study employs a back-translation approach using DeepL API to translate 56 Software Engineering tasks through five intermediate languages, then back to English. A novel metric called the adjusted unalikeability coefficient (UCA) is introduced to measure gender variation in pronoun selection. The method identifies the main verb in each sentence and analyzes how different translation paths affect gender pronoun selection, providing a scalable alternative to large-scale surveys for mapping bias in language models.

## Key Results
- Main verbs in sentences are identified as significant drivers of gender uncertainty in translations
- Languages fall into three loose groups with similar pronoun usage patterns
- The UCA metric demonstrates robustness despite changes in DeepL's behavior over time
- The approach provides a scalable alternative to large-scale surveys for mapping bias in language models

## Why This Works (Mechanism)
The back-translation method through multiple intermediate languages creates a "washout effect" that amplifies subtle biases in the translation process. By using multiple paths, the method captures systematic patterns in how gender is handled across different language pairs. The UCA metric addresses the limitation of previous approaches by considering the overall variation in pronoun selection rather than focusing on individual pronouns, providing a more comprehensive view of gender bias in translations.

## Foundational Learning
- Back-translation methodology: Needed to understand how translating through multiple languages can reveal systematic biases in translation systems. Quick check: Can you explain how back-translation differs from direct translation?
- Pronoun variation metrics: Essential for quantifying gender bias in translations. Quick check: How does UCA differ from traditional gender bias metrics?
- Main verb identification: Critical for understanding sentence structure's role in gender bias. Quick check: Why would main verbs be more influential than other sentence components in determining gender?

## Architecture Onboarding
- Component map: Software Engineering tasks -> DeepL API -> 5 intermediate languages -> back-translation -> UCA analysis
- Critical path: Task selection → Translation through intermediate languages → Pronoun extraction → UCA calculation → Analysis
- Design tradeoffs: Single API (DeepL) provides consistency but limits generalizability; 56 tasks provide focused analysis but may not represent all domains
- Failure signatures: Inconsistent pronoun selection across translation paths suggests bias; uniform selection suggests lack of bias
- First experiments: 1) Test different translation APIs with same tasks, 2) Vary the number of intermediate languages, 3) Apply method to non-technical domains

## Open Questions the Paper Calls Out
None

## Limitations
- Study focuses on a specific dataset of 56 Software Engineering tasks, potentially limiting generalizability
- Relies on a single translation API (DeepL) and five intermediate languages
- The UCA metric is new and requires further validation across diverse datasets and contexts

## Confidence
- Medium confidence in main claims due to focused dataset and single translation system
- Robustness over time demonstrated, but only within DeepL API constraints
- Loose grouping of languages is an interesting observation but limited by small sample size

## Next Checks
1. Replicate the study using multiple translation APIs (e.g., Google Translate, Microsoft Translator) to assess consistency of results across systems
2. Expand the dataset to include a wider range of sentence structures and domains beyond Software Engineering tasks to test the generalizability of the UCA metric
3. Conduct a large-scale survey comparing the UCA metric's results with human judgments on gender bias in machine translations to validate its effectiveness