---
ver: rpa2
title: Scalable Property Valuation Models via Graph-based Deep Learning
arxiv_id: '2405.06553'
source_url: https://arxiv.org/abs/2405.06553
tags:
- graph
- normal
- property
- house
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents two graph neural network (GNN) models for property
  valuation that capture spatial relationships between houses using peer dependencies.
  The PD-GCN model employs standard graph convolutions with mean aggregation, while
  the PD-TGCN model uses transformer graph convolutions with attention mechanisms
  to weigh neighboring properties differently.
---

# Scalable Property Valuation Models via Graph-based Deep Learning

## Quick Facts
- arXiv ID: 2405.06553
- Source URL: https://arxiv.org/abs/2405.06553
- Authors: Enrique Riveros; Carla Vairetti; Christian Wegmann; Santiago Truffa; Sebastián Maldonado
- Reference count: 40
- This paper presents two graph neural network (GNN) models for property valuation that capture spatial relationships between houses using peer dependencies

## Executive Summary
This paper introduces two graph neural network architectures for property valuation that leverage spatial relationships between houses through peer dependency graphs. The PD-GCN model uses standard graph convolutions with mean aggregation, while the PD-TGCN model employs transformer graph convolutions with attention mechanisms to weight neighboring properties differently. Both models utilize an adapted k-nearest similar house sampling (KNHS) algorithm to define neighborhood structures in the graph.

Experiments on a proprietary dataset of 200,000 houses in Santiago, Chile demonstrate significant improvements over traditional machine learning approaches and the state-of-the-art PDVM method. The PD-TGCN model achieves the best performance with a mean absolute percentage error (MAPE) of 20.4%, showcasing the effectiveness of transformer convolutions in capturing complex geospatial patterns for real estate appraisal.

## Method Summary
The paper presents two graph-based deep learning models for property valuation that construct peer dependency graphs using the k-nearest similar house sampling (KNHS) algorithm. The PD-GCN model applies standard graph convolution operations with mean aggregation to propagate information between neighboring properties, while the PD-TGCN model replaces these with transformer graph convolutions that use attention mechanisms to differentially weight neighboring houses. Both architectures learn spatial relationships and dependencies between properties to improve valuation accuracy beyond traditional feature-based approaches.

## Key Results
- PD-TGCN achieves MAPE of 20.4%, outperforming PD-GCN (20.6%) and PDVM (21.1%) on the Santiago dataset
- Both GNN models significantly improve upon traditional machine learning baselines for property valuation
- Transformer graph convolutions demonstrate superior ability to weight neighboring properties compared to standard mean aggregation

## Why This Works (Mechanism)
The models work by capturing spatial dependencies between properties through graph structures. Traditional valuation methods treat properties as independent entities with features, missing crucial spatial relationships. By constructing graphs where nodes represent houses and edges represent similarity or proximity, the models can propagate valuation information across neighborhoods. The transformer-based attention mechanism in PD-TGCN allows the model to learn which neighboring properties are most influential for valuation, rather than treating all neighbors equally as in standard graph convolutions.

## Foundational Learning

**Graph Neural Networks**: Neural networks designed to operate on graph-structured data, enabling information propagation along edges between nodes. Needed to capture spatial relationships between properties; quick check: verify graph construction correctly represents neighborhood structures.

**Attention Mechanisms**: Components that allow models to weigh different inputs differently based on learned importance scores. Needed to differentiate the influence of various neighboring properties; quick check: examine attention weight distributions across different property types.

**K-Nearest Neighbors Sampling**: Algorithm for selecting the most relevant neighboring data points based on similarity metrics. Needed to define meaningful neighborhood structures in the property graph; quick check: validate that sampled neighbors are truly similar properties.

## Architecture Onboarding

**Component Map**: Input features -> KNHS sampling -> Graph construction -> (PD-GCN/PD-TGCN) -> Property valuations

**Critical Path**: Property features → KNHS algorithm → Peer dependency graph → Graph convolution layers → Valuation output

**Design Tradeoffs**: Standard graph convolutions vs. transformer convolutions (simplicity vs. adaptive weighting); mean aggregation vs. attention-based neighbor weighting (computational efficiency vs. expressiveness)

**Failure Signatures**: Poor performance may indicate inadequate neighborhood definition from KNHS, insufficient graph depth, or improper feature representation of properties

**First Experiments**: 1) Ablation study removing attention mechanism to quantify its contribution; 2) Vary k parameter in KNHS to find optimal neighborhood size; 3) Test on properties with extreme feature values to assess robustness

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on proprietary dataset from Santiago, Chile, limiting generalizability to other markets
- Limited benchmarking against broader range of established property valuation methods
- Parameter sensitivity of KNHS algorithm and its impact on different neighborhoods remains unexplored

## Confidence

**High confidence**: Comparative performance metrics showing PD-TGCN outperforming PD-GCN and PDVM on the specific dataset

**Medium confidence**: Claim that transformer convolutions provide superior weighting of neighboring properties, dependent on implementation details

**Medium confidence**: Generalizability of results to other real estate markets beyond Santiago, Chile

## Next Checks
1. Test model performance on property datasets from multiple cities and countries to assess generalizability across different real estate markets
2. Conduct ablation studies to quantify the individual contributions of transformer convolutions versus standard graph convolutions in the valuation accuracy
3. Evaluate model fairness metrics across different demographic and socioeconomic neighborhoods to identify potential bias in property valuations