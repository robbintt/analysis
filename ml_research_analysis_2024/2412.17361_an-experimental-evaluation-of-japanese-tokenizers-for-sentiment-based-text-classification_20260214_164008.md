---
ver: rpa2
title: An Experimental Evaluation of Japanese Tokenizers for Sentiment-Based Text
  Classification
arxiv_id: '2412.17361'
source_url: https://arxiv.org/abs/2412.17361
tags:
- classification
- text
- sentencepiece
- japanese
- mecab
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study compares three Japanese tokenizers\u2014MeCab, Sudachi,\
  \ and SentencePiece\u2014as preprocessing steps for sentiment-based text classification.\
  \ Using TF-IDF vectorization and two traditional classifiers (Multinomial Naive\
  \ Bayes and Logistic Regression), it finds that SentencePiece achieves the best\
  \ performance (7.78% test error) despite producing non-dictionary tokens, while\
  \ Sudachi yields dictionary-aligned tokens but is slowest."
---

# An Experimental Evaluation of Japanese Tokenizers for Sentiment-Based Text Classification

## Quick Facts
- arXiv ID: 2412.17361
- Source URL: https://arxiv.org/abs/2412.17361
- Reference count: 0
- Primary result: SentencePiece tokenizer achieves best sentiment classification performance (7.78% test error) among three evaluated Japanese tokenizers

## Executive Summary
This study benchmarks three Japanese tokenizers—MeCab, Sudachi, and SentencePiece—for sentiment-based text classification using traditional machine learning methods. The researchers compare tokenizer performance through a pipeline combining TF-IDF vectorization with Multinomial Naive Bayes and Logistic Regression classifiers. Results show SentencePiece achieving the lowest classification error rate despite producing non-dictionary tokens, while Sudachi provides dictionary-aligned tokens but with the slowest processing speed.

## Method Summary
The researchers evaluated three Japanese tokenizers by integrating them into a sentiment classification pipeline using TF-IDF vectorization and two traditional classifiers (Multinomial Naive Bayes and Logistic Regression). They measured both classification accuracy and processing speed across multiple Japanese sentiment datasets. The study focused on comparing token quality, vocabulary size, and computational efficiency while maintaining consistent downstream modeling approaches.

## Key Results
- SentencePiece achieved the best classification performance with 7.78% test error
- Sudachi produces dictionary-aligned tokens but has the slowest processing speed
- SentencePiece's non-dictionary tokens outperformed dictionary-aligned tokens from other tokenizers in classification accuracy

## Why This Works (Mechanism)
The study demonstrates that tokenizer choice significantly impacts downstream classification performance in Japanese NLP pipelines. SentencePiece's subword tokenization approach appears to capture sentiment-relevant patterns more effectively than dictionary-based methods for this specific task. The combination of SentencePiece tokenization with TF-IDF vectorization and Logistic Regression creates an efficient pipeline that balances accuracy and speed.

## Foundational Learning

**Japanese morphological analysis**: Why needed - Japanese lacks explicit word boundaries requiring specialized tokenization; Quick check - Can you explain why Japanese text requires morphological analysis before processing?

**Subword tokenization vs dictionary-based methods**: Why needed - Different tokenization strategies affect feature representation; Quick check - Can you contrast SentencePiece's subword approach with dictionary-based tokenizers?

**TF-IDF vectorization**: Why needed - Converts tokenized text to numerical features for traditional ML; Quick check - Can you describe how TF-IDF transforms text into feature vectors?

## Architecture Onboarding

**Component map**: Raw Japanese text -> Tokenizer (MeCab/Sudachi/SentencePiece) -> Token sequence -> TF-IDF vectorizer -> Classifier (Naive Bayes/Logistic Regression) -> Sentiment prediction

**Critical path**: Tokenizer selection -> Token sequence generation -> TF-IDF feature extraction -> Classifier training/prediction

**Design tradeoffs**: Dictionary alignment vs performance (Sudachi aligns with Japanese dictionaries but slower) vs subword flexibility (SentencePiece faster and more accurate but produces non-dictionary tokens)

**Failure signatures**: Poor tokenizer performance manifests as increased classification error; slow processing indicates inefficient tokenization; vocabulary size mismatches suggest tokenization granularity issues

**First experiments**:
1. Run identical sentiment classification pipeline with all three tokenizers on sample dataset
2. Compare vocabulary sizes and token overlap between tokenizer outputs
3. Measure processing time for each tokenizer on identical text corpus

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Evaluation limited to traditional ML methods without testing neural approaches that may yield different performance rankings
- Results based on only two classifiers and single vectorization method, limiting generalizability
- Benchmark uses only three sentiment datasets from single Japanese review corpus, potentially introducing domain bias

## Confidence
High confidence in relative processing speed rankings (SentencePiece fastest, Sudachi slowest) due to direct measurement. Medium confidence in classification accuracy findings because results depend heavily on the specific TF-IDF + traditional ML pipeline used. Low confidence in claims about SentencePiece's superiority across different modeling approaches or Japanese NLP tasks beyond sentiment classification.

## Next Checks
1. Replicate the benchmark using neural architectures (BERT, RoBERTa) with the same tokenizers to verify if SentencePiece maintains its performance advantage
2. Test the tokenizers on diverse Japanese NLP tasks (named entity recognition, machine translation) to assess generalizability beyond sentiment classification
3. Conduct ablation studies varying preprocessing parameters (tokenization granularity, stopword removal) to isolate the impact of tokenizer choice on downstream performance