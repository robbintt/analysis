---
ver: rpa2
title: Contextualizing Generated Citation Texts
arxiv_id: '2402.18054'
source_url: https://arxiv.org/abs/2402.18054
tags:
- citation
- context
- generation
- reference
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors propose a context-focused modification to the citation
  text generation task, where the generation target is not only the citation itself,
  but the entire context window, including the target citation. This approach is evaluated
  on the CORWA dataset using the Longformer Encoder-Decoder model, and the results
  show that the contextualized generation model is preferred by human readers and
  produces more coherent citations that fit their contexts compared to the baseline
  infilling approach.
---

# Contextualizing Generated Citation Texts

## Quick Facts
- arXiv ID: 2402.18054
- Source URL: https://arxiv.org/abs/2402.18054
- Reference count: 0
- Primary result: Context-focused citation generation with full context window produces more coherent citations preferred by human readers

## Executive Summary
This paper proposes a context-focused modification to citation text generation where the model generates not just the target citation but the entire surrounding context window, including the citation itself. The approach uses the Longformer Encoder-Decoder (LED) model trained on the CORWA dataset, which contains NLP-domain citations. The key insight is that generating the full context allows the model to leverage contextual clues about what topic to discuss and what stance to take, resulting in citations that better fit their surrounding discourse.

The authors evaluate their approach through human evaluation by graduate students, comparing their contextualized generation model against a baseline infilling approach. The results show modest but consistent preference for the contextualized model across relevance, coherence, and overall quality metrics, suggesting that including the full context window improves citation generation quality.

## Method Summary
The method involves training an LED model to generate the entire context window (citing paper introduction + paragraph containing the masked citation + reference paper abstract) rather than just the masked citation. The input to the model is the concatenation of the citing paper's introduction section, the paragraph containing the (masked) target citation, and the citation mark, title, and abstract of the reference paper. The model is trained on the CORWA dataset, with training, distant, and test partitions. Human evaluation is conducted by graduate students on fluency, relevance to the reference paper, coherence in the citation context, and overall quality.

## Key Results
- Human readers slightly prefer contextualized generation model over baseline infilling approach
- Improvements observed in relevance, coherence, and overall quality scores
- Contextualized approach produces citations that better fit their surrounding discourse

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Generating the full context window provides richer situational awareness than only generating the masked citation
- Mechanism: The decoder conditions on the complete citation context during generation, allowing it to use topical and stylistic cues from surrounding sentences to determine what aspect of the reference paper to focus on
- Core assumption: The citing context contains explicit signals about the intended focus and stance toward the reference paper
- Evidence anchors: Experimental results show human preference and improved coherence; the contextualized approach is preferred with respect to relevance, coherence, and overall quality

### Mechanism 2
- Claim: Including citation mark and reference paper metadata ensures the model links citation content to the correct reference
- Mechanism: The model learns to condition the generated citation text on both the context window and the reference paper's abstract, enabling focused, context-aware summaries
- Core assumption: The model can learn cross-attention between context tokens and reference abstract tokens
- Evidence anchors: The input format includes citation mark, title, and abstract; experimental setup demonstrates this configuration

### Mechanism 3
- Claim: Human readers can detect when a citation fits its context better than a generic summary
- Mechanism: By evaluating coherence, relevance, and overall quality, human judges prefer citations that integrate smoothly with the surrounding discourse
- Core assumption: Coherence is perceptible to domain experts and can be reliably rated
- Evidence anchors: Human evaluation results show slight preference for contextualized model across multiple quality dimensions

## Foundational Learning

- Concept: Infilling-style generation
  - Why needed here: The baseline approach masks the target citation and generates only that span, requiring the model to infer context from limited surrounding text
  - Quick check question: What is the input format for an infilling citation generation task?

- Concept: Context-aware summarization
  - Why needed here: The proposed method expands the target to the entire context window, enabling the model to use explicit discourse cues (e.g., "similarly", "in contrast") to shape the citation
  - Quick check question: How does including the full context window change the decoder's conditioning?

- Concept: Sequence-to-sequence modeling with attention
  - Why needed here: The LED model must attend over both the context window and reference abstract to produce coherent, focused citations
  - Quick check question: What type of attention mechanism is required to link context and reference abstract tokens?

## Architecture Onboarding

- Component map: Input sequence (citing intro + context paragraph + citation mark + reference title + reference abstract) -> LongformerEncoder -> LongformerDecoder -> Reconstructed context window with filled-in citation

- Critical path: Load and tokenize input sequence -> Encode with LED encoder -> Decode to reconstruct context + citation -> Post-process to extract citation text

- Design tradeoffs: Longer context window improves coherence but increases computational cost; using LED allows long inputs but requires careful batching; training with full context as target ensures coherence but makes evaluation more complex

- Failure signatures: Citation repeats information already in context; citation is too generic or misses topical cues; model generates unrelated content for the citation

- First 3 experiments: Compare ROUGE scores for baseline vs contextualized model on CORWA test set; run human evaluation with domain experts on 50 random samples; ablate context length: test with 1, 2, and 3 sentences before/after the citation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we automatically evaluate the coherence of generated citations with their context beyond ROUGE metrics?
- Basis in paper: The paper acknowledges that ROUGE does not capture coherence well and presents human evaluation and qualitative analysis instead
- Why unresolved: ROUGE is the standard metric for text generation, but it fails to capture aspects like coherence, informativeness, and factuality
- What evidence would resolve it: Development and validation of new automatic metrics that correlate well with human judgments of citation coherence

### Open Question 2
- Question: How well does the contextualized approach generalize to citation generation in other domains (e.g., biology, physics) or languages?
- Basis in paper: The paper focuses on NLP papers in English and acknowledges limitations in generalizing to other fields
- Why unresolved: The paper only tests on NLP papers and does not explore cross-domain or multilingual generalization
- What evidence would resolve it: Experimental results showing the effectiveness of the approach on diverse domains and languages

### Open Question 3
- Question: Can we develop methods to control the level of extractiveness or paraphrasing in generated citations to avoid plagiarism?
- Basis in paper: The ethics statement mentions that generated citations may copy extensively from reference abstracts, raising plagiarism concerns
- Why unresolved: The paper does not attempt to control the level of extractiveness in generated citations
- What evidence would resolve it: Implementation and evaluation of techniques to encourage more paraphrasing while maintaining citation quality

### Open Question 4
- Question: How can we mitigate the risk of generated citations containing false or unfair criticisms due to model errors or hallucinations?
- Basis in paper: The ethics statement warns that errors could result in false or unfair criticisms, negatively impacting perceptions of cited papers
- Why unresolved: The paper does not address methods to ensure factual correctness and fairness in generated citations
- What evidence would resolve it: Development and evaluation of fact-checking or bias-detection mechanisms for citation generation

## Limitations

- Human evaluation shows only modest preference for contextualized model with small effect sizes (0.03-0.06 improvements)
- Study does not report baseline infilling model performance metrics for absolute quality comparison
- Inter-annotator agreement is described as "moderate" without specific values reported, raising questions about evaluation reliability

## Confidence

**High Confidence**: The architectural modification (generating context window instead of isolated citation) is technically sound and well-implemented using LED. The mechanism of conditioning on surrounding discourse for context-aware generation is theoretically valid.

**Medium Confidence**: The claim that human readers prefer contextualized citations is supported by evaluation data, but the effect size is small and the inter-annotator agreement is not fully characterized.

**Low Confidence**: The assertion that this approach "allows the generation model to make use of contextual clues about what topic to discuss and what stance to take" lacks quantitative evidence showing actual improvement in topical focus or stance accuracy.

## Next Checks

1. **Ablation Study on Context Window Size**: Systematically test different context window sizes (1, 2, and 3 sentences before/after the citation) to determine if the observed improvements scale with context length or if diminishing returns occur.

2. **Automated Coherence Metrics**: Implement and report automated coherence metrics (such as entity grid coherence scores or discourse relation detection) to complement human evaluation and provide more granular analysis of coherence improvements.

3. **Reference Disambiguation Test**: Design an experiment where the same context window could logically cite different reference papers, then test whether the contextualized model correctly selects the appropriate citation focus based on the provided reference abstract versus the baseline approach.