---
ver: rpa2
title: Decoupling the Class Label and the Target Concept in Machine Unlearning
arxiv_id: '2406.08288'
source_url: https://arxiv.org/abs/2406.08288
tags:
- forgetting
- data
- unlearning
- label
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of machine unlearning when
  the class label and target concept are decoupled. The authors investigate three
  new problems beyond conventional all-matched forgetting: target mismatch, model
  mismatch, and data mismatch forgetting.'
---

# Decoupling the Class Label and the Target Concept in Machine Unlearning

## Quick Facts
- arXiv ID: 2406.08288
- Source URL: https://arxiv.org/abs/2406.08288
- Reference count: 40
- Authors: Jianing Zhu; Bo Han; Jiangchao Yao; Jianliang Xu; Gang Niu; Masashi Sugiyama
- Primary result: Proposed TARF framework achieves effective unlearning when class labels and target concepts are decoupled, outperforming existing methods

## Executive Summary
This paper addresses the challenge of machine unlearning when the class label and target concept are decoupled. The authors investigate three new problems beyond conventional all-matched forgetting: target mismatch, model mismatch, and data mismatch forgetting. They reveal crucial forgetting dynamics in the representation level and propose a general framework called TARget-aware Forgetting (TARF). TARF enables additional tasks to actively forget the target concept while maintaining the rest by simultaneously conducting annealed gradient ascent on forgetting data and selected gradient descent on hard-to-affect remaining data. The method is validated through various experiments under newly introduced settings, demonstrating its effectiveness. The paper also explores the performance of TARF on different model structures and provides ablation studies to characterize algorithm properties.

## Method Summary
The TARget-aware Forgetting (TARF) framework consists of three phases: target identification through representation gravity, target separation using dual optimization, and retraining approximation. The method identifies concept-aligned forgetting data in the remaining set by finding samples with similar representation distances to initially provided forgetting data. It then applies annealed gradient ascent on forgetting data (with decreasing learning rate k(t)) while simultaneously applying conditional gradient descent on selected retaining data using threshold τ(x,y,t). This dual optimization approach approximates the behavior of a fully retrained model while maintaining computational efficiency.

## Key Results
- TARF outperforms existing unlearning methods (FT, GA, RL, IU, BS, L1-sparse, SalUn, SCRUB) on CIFAR-10 and CIFAR-100 datasets
- The framework successfully handles model mismatch forgetting, where the forgetting target was trained by a different model
- TARF demonstrates effective unlearning on stable diffusion for image generation tasks
- Ablation studies show the importance of both annealed forgetting and target-aware retaining phases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The algorithm effectively identifies and separates the target concept from the retaining data by exploiting representation gravity in the feature space.
- Mechanism: By simultaneously conducting annealed gradient ascent on forgetting data and selected gradient descent on hard-to-affect remaining data, the method leverages the observed difference in representation distances (gravity) between forgetting and retaining data to achieve target separation.
- Core assumption: The representation gravity (measured as the difference in loss values between the original and unlearned models) is a reliable indicator of semantic similarity between data points and the forgetting target.
- Evidence anchors:
  - [abstract] "reveal crucial forgetting dynamics in the representation level"
  - [section 3.2] "We can utilize the representation gravity to identify the other unidentified forgetting data in the remaining set, and reveal the needs of deconstructing the pre-entangled representation"
  - [corpus] Weak evidence - corpus papers focus on general unlearning but don't specifically address representation gravity as a mechanism.

### Mechanism 2
- Claim: Annealed gradient ascent on forgetting data, combined with targeted gradient descent on retaining data, approximates the behavior of a fully retrained model.
- Mechanism: The learning rate reduction (k(t)) on forgetting data prevents excessive feature destruction while still achieving sufficient unlearning, and the selective gradient descent on retaining data reconstructs the feature representation to match retraining.
- Core assumption: The model can be guided toward retraining-like behavior through carefully controlled simultaneous optimization on two distinct data subsets.
- Evidence anchors:
  - [abstract] "by simultaneously conducting annealed gradient ascent on the forgetting data and selected gradient descent on the hard-to-affect remaining data"
  - [section 3.3] "LTARF = k(t) · (− 1|Df| P(x,y)∼Df ℓ(f (x), y)) + 1|Dun| P(x,y)∼Dun ℓ(f (x), y) · τ (x, y, t)"
  - [corpus] Weak evidence - corpus papers mention annealing and dual objectives but not in the specific context of approximating retraining.

### Mechanism 3
- Claim: Target identification through representation gravity enables effective unlearning even when forgetting data is insufficient to represent the full target concept.
- Mechanism: The algorithm identifies additional forgetting data in the remaining set by finding samples with similar representation distances to the initially provided forgetting data, then includes them in the unlearning process.
- Core assumption: Concept-aligned forgetting data share similar feature representations with the initially provided forgetting data, making them identifiable through representation distance metrics.
- Evidence anchors:
  - [abstract] "enables additional tasks to actively forget the target concept while maintaining the rest"
  - [section 3.2] "there exist a constant value ζ1 and sample (xu, yu) ∼ (Dt\Df) that exhibits weak gravity following the sample (x, y) ∼ Df"
  - [corpus] Weak evidence - corpus papers discuss concept unlearning but not through representation gravity-based identification.

## Foundational Learning

- Concept: Multi-class classification and feature representation learning
  - Why needed here: The method relies on understanding how neural networks learn class-specific feature representations and how these can be manipulated through gradient-based optimization.
  - Quick check question: Can you explain why a neural network trained on CIFAR-100 classes would have different feature representations for "boy" versus "people" (the superclass)?

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: The algorithm exploits the phenomenon where neural networks lose previously learned information when trained on new data, using it constructively for unlearning.
  - Quick check question: What happens to the weights of a neural network when you fine-tune it on a subset of the original training data?

- Concept: Gradient ascent vs. gradient descent optimization
  - Why needed here: The method uses gradient ascent to increase loss on forgetting data while using gradient descent to decrease loss on retaining data, requiring understanding of both optimization directions.
  - Quick check question: How would the update rule differ between maximizing loss on forgetting data versus minimizing loss on retaining data?

## Architecture Onboarding

- Component map: Input Data -> Representation Gravity Computation -> Target Identification -> Annealed Forgetting Module -> Target-Aware Retaining Module -> Output Model
- Critical path: 1) Compute representation distances for all data points, 2) Identify concept-aligned forgetting data in remaining set, 3) Apply annealed gradient ascent on forgetting data, 4) Apply conditional gradient descent on selected retaining data, 5) Monitor convergence toward retraining behavior.
- Design tradeoffs: The method trades computational efficiency for accuracy - it requires additional computation to identify concept-aligned data and apply dual optimization, but achieves better approximation of retraining than single-objective methods.
- Failure signatures: 1) High accuracy gap between forgetting and retaining data indicates insufficient separation, 2) Low UA but high RA indicates over-forgetting, 3) High accuracy on both indicates under-forgetting.
- First 3 experiments: 1) Test on CIFAR-100 with model mismatch forgetting to verify target separation, 2) Test on CIFAR-10 with target mismatch forgetting to verify target identification, 3) Test with different k values on all matched forgetting to find optimal annealing schedule.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can machine unlearning frameworks be made more efficient in terms of computational cost, especially for large-scale models?
- Basis in paper: [inferred] The paper discusses computational time cost (RTE) as an evaluation metric and mentions that current unlearning methods require extra computational cost.
- Why unresolved: While the paper evaluates computational efficiency, it doesn't propose specific methods to reduce the computational burden of unlearning, especially for large models like foundation models.
- What evidence would resolve it: Research demonstrating novel algorithmic approaches or architectural modifications that significantly reduce the computational cost of unlearning while maintaining effectiveness.

### Open Question 2
- Question: Can machine unlearning be effectively extended to generative models beyond stable diffusion, such as large language models or multimodal models?
- Basis in paper: [explicit] The paper extends TARF to stable diffusion for image generation, showing compatibility, and discusses potential extension to foundation models.
- Why unresolved: The paper only demonstrates unlearning on stable diffusion, a specific type of generative model. The effectiveness and challenges of unlearning on other generative model architectures remain unexplored.
- What evidence would resolve it: Empirical studies applying TARF or similar frameworks to diverse generative models (LLMs, GANs, multimodal models) and analyzing performance across different architectures and tasks.

### Open Question 3
- Question: How can machine unlearning handle spurious correlations in datasets where the identified forgetting data is insufficient to represent the target concept?
- Basis in paper: [explicit] The paper mentions in Appendix F.2 that some superclasses in CIFAR-100 are not semantically separable, making it difficult to identify concept-aligned forgetting data.
- Why unresolved: The paper identifies the issue of insufficient representation due to spurious correlations but doesn't propose solutions for handling such cases in unlearning.
- What evidence would resolve it: Research developing methods to detect and mitigate spurious correlations in unlearning tasks, potentially through advanced data augmentation, semi-supervised learning, or causal inference techniques.

### Open Question 4
- Question: What are the theoretical guarantees for machine unlearning under label domain mismatch scenarios, and how can they be formalized?
- Basis in paper: [inferred] The paper introduces new unlearning scenarios with label domain mismatch and discusses challenges, but doesn't provide theoretical analysis or guarantees.
- Why unresolved: While the paper empirically demonstrates the challenges of label domain mismatch, it lacks theoretical framework or bounds for unlearning performance in these scenarios.
- What evidence would resolve it: Mathematical proofs establishing conditions for successful unlearning under different label domain mismatch scenarios, including bounds on approximation error and privacy guarantees.

## Limitations

- The framework's effectiveness depends heavily on the reliability of representation gravity as an indicator of semantic similarity, which may break down with highly entangled feature representations.
- Performance is sensitive to the annealing schedule k(t) and threshold β, requiring careful hyperparameter tuning.
- The method may struggle with broad or diverse target concepts where initial forgetting data poorly represents the full concept space.

## Confidence

- Mechanism 1 (Representation Gravity Separation): Medium confidence
- Mechanism 2 (Annealed Gradient Ascent + Targeted Descent): Medium confidence
- Mechanism 3 (Concept-Aligned Data Identification): Low-Medium confidence

## Next Checks

- Validation Check 1: Test TARF on increasingly entangled feature representations to quantify how representation gravity reliability degrades and identify failure thresholds.
- Validation Check 2: Evaluate TARF's performance when the unlearning target concept has been learned by fundamentally different model architectures to test the limits of the annealing schedule's ability to bridge architectural gaps.
- Validation Check 3: Systematically vary the semantic diversity within target concepts to identify the boundary where representation gravity-based identification becomes unreliable.