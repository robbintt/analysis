---
ver: rpa2
title: 'MICA: Towards Explainable Skin Lesion Diagnosis via Multi-Level Image-Concept
  Alignment'
arxiv_id: '2401.08527'
source_url: https://arxiv.org/abs/2401.08527
tags: []
core_contribution: The paper proposes MICA, a multi-modal explainable disease diagnosis
  framework that aligns medical images and clinical-related concepts at multiple levels
  (global image, regional token, and concept subspace). MICA leverages a CNN-based
  image encoder and an LLM-based concept encoder to learn semantic correspondences
  between images and concepts, and uses contrastive learning and concept activation
  vectors to refine the alignments.
---

# MICA: Towards Explainable Skin Lesion Diagnosis via Multi-Level Image-Concept Alignment

## Quick Facts
- arXiv ID: 2401.08527
- Source URL: https://arxiv.org/abs/2401.08527
- Reference count: 14
- One-line primary result: MICA achieves superior performance on disease diagnosis and concept detection compared to state-of-the-art concept-based methods while preserving model interpretability.

## Executive Summary
MICA introduces a multi-modal explainable disease diagnosis framework that aligns medical images and clinical-related concepts at multiple levels: global image, regional token, and concept subspace. The framework leverages a CNN-based image encoder and an LLM-based concept encoder to learn semantic correspondences between images and concepts, using contrastive learning and concept activation vectors to refine these alignments. MICA demonstrates high performance and label efficiency for both concept detection and disease diagnosis while maintaining model interpretability through visual and textual explanations.

## Method Summary
MICA employs a multi-level image-concept alignment approach where a CNN-based image encoder processes medical images while an LLM-based concept encoder handles clinical-related concepts. The framework operates at three distinct levels: global image-level alignment using contrastive learning, regional token-level alignment through attention mechanisms, and concept subspace alignment using concept activation vectors. This multi-pronged approach enables the model to capture both holistic image patterns and localized semantic features while maintaining strong semantic correspondences between visual and textual representations.

## Key Results
- MICA achieves superior performance on disease diagnosis compared to state-of-the-art concept-based methods
- The framework demonstrates high label efficiency for concept detection tasks
- MICA preserves model interpretability while maintaining competitive diagnostic accuracy

## Why This Works (Mechanism)
The multi-level alignment approach works by capturing semantic correspondences at different granularities, allowing the model to understand both global image context and local feature relationships. By leveraging both CNN and LLM components, MICA can effectively bridge the modality gap between visual and textual representations, while the contrastive learning framework ensures that aligned representations are semantically meaningful. The concept activation vectors provide additional refinement by explicitly modeling the relationship between image features and clinical concepts.

## Foundational Learning

**Contrastive Learning**: A training approach that learns representations by pulling together similar samples and pushing apart dissimilar ones. Needed to establish strong semantic correspondences between image and concept representations. Quick check: Verify that positive pairs (image-concept pairs) are properly constructed and negative sampling is effective.

**Concept Activation Vectors (CAVs)**: Direction vectors in feature space that represent specific concepts. Used to quantify the relationship between image features and clinical concepts. Quick check: Validate that CAVs are stable across different runs and effectively capture the intended concepts.

**Multi-modal Alignment**: The process of mapping representations from different modalities (images and text) into a shared semantic space. Essential for enabling cross-modal reasoning and explanations. Quick check: Confirm that the alignment maintains semantic consistency across both modalities.

## Architecture Onboarding

**Component Map**: Image Encoder (CNN) -> Concept Encoder (LLM) -> Multi-level Alignment Module -> Disease Classifier

**Critical Path**: The most critical pathway is from image encoding through multi-level alignment to final diagnosis, as this determines both performance and interpretability.

**Design Tradeoffs**: The choice between using a CNN versus a vision transformer for image encoding affects both performance and computational efficiency. The decision to use an LLM for concept encoding trades model complexity for richer semantic understanding.

**Failure Signatures**: Poor alignment quality may manifest as inconsistent explanations between visual and textual outputs, while inadequate concept representation could lead to missed diagnostic features.

**First Experiments**: 1) Verify baseline performance without multi-level alignment, 2) Test individual alignment levels in isolation, 3) Evaluate concept detection accuracy with varying levels of concept annotation.

## Open Questions the Paper Calls Out

None specified in the provided content.

## Limitations

- Limited evaluation primarily on a single dermatology dataset (Derm7pt), raising concerns about generalizability
- High computational complexity due to integration of CNN and LLM components may limit practical deployment
- The depth and clinical relevance of the explanations require further validation for end-user utility

## Confidence

- **High Confidence**: Superior performance claims on disease diagnosis and concept detection are supported by presented results
- **Medium Confidence**: Interpretability preservation through multi-level alignment is plausible but requires further validation
- **Low Confidence**: Generalizability across different medical imaging domains remains uncertain without additional experiments

## Next Checks

1. Evaluate MICA on multiple dermatology datasets or other medical imaging domains to assess generalizability
2. Conduct thorough analysis of concept annotation quality and its impact on model performance
3. Measure computational requirements including memory, processing time, and energy consumption for practical deployment assessment