---
ver: rpa2
title: 'DP-Dueling: Learning from Preference Feedback without Compromising User Privacy'
arxiv_id: '2403.15045'
source_url: https://arxiv.org/abs/2403.15045
tags:
- algorithm
- learning
- privacy
- regret
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DP-Dueling, the first algorithm for differentially
  private dueling bandits. It addresses the problem of learning optimal actions from
  pairwise comparisons while preserving user privacy.
---

# DP-Dueling: Learning from Preference Feedback without Compromising User Privacy

## Quick Facts
- arXiv ID: 2403.15045
- Source URL: https://arxiv.org/abs/2403.15045
- Authors: Aadirupa Saha; Hilal Asi
- Reference count: 40
- Primary result: First differentially private algorithm for dueling bandits, achieving optimal regret bounds.

## Executive Summary
This paper introduces DP-Dueling, the first algorithm for differentially private dueling bandits. It addresses the problem of learning optimal actions from pairwise comparisons while preserving user privacy. The core idea is to use a round-robin elimination strategy combined with binary tree mechanisms for private estimation. For finite action spaces of size K, the algorithm achieves a regret bound of O(∑i=2K log(KT)/Δi + K/ε) under ε-DP. For general d-dimensional spaces, it attains a regret bound of Õ(d^6/(κε) + d√T/κ). The algorithm is optimal for finite spaces, matching both non-private and privacy lower bounds. The approach provides privacy "for free" when T ≫ d in the infinite-dimensional setting.

## Method Summary
DP-Dueling operates by maintaining an active set of items and using round-robin sampling to play the first arm from the active set and the second arm randomly from the same set. It employs binary tree mechanisms to privately estimate the Effective Borda Score (EBS) of each arm, adding calibrated noise to preserve ε-DP. Arms are eliminated when their upper confidence bounds fall below the lower confidence bounds of other arms. For infinite action spaces, the algorithm uses G-optimal design and core-sets to approximate rewards and eliminate arms efficiently.

## Key Results
- Achieves optimal regret bound of O(∑i=2K log(KT)/Δi + K/ε) for finite action spaces under ε-DP.
- For general d-dimensional spaces, attains regret bound of Õ(d^6/(κε) + d√T/κ).
- Matches non-private lower bound when T ≫ d, providing privacy "for free" in the infinite-dimensional setting.
- First algorithm to provide differential privacy guarantees for dueling bandit problems.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The algorithm achieves private regret bounds by combining round-robin elimination with binary tree mechanisms for private estimation.
- Mechanism: The algorithm runs in phases, maintaining an active set of items. At each round, it plays the first arm in a round-robin fashion from the active set and the second arm randomly from the same set. The binary tree mechanism is used to privately estimate the Effective Borda Score (EBS) of each arm, adding calibrated noise to preserve ε-DP.
- Core assumption: The binary tree mechanism can provide accurate private estimates of the win counts while adding only poly(log(TK))/ε noise with high probability.
- Evidence anchors:
  - [abstract]: "The core idea is to use a round-robin elimination strategy combined with binary tree mechanisms for private estimation."
  - [section]: "We use the binary tree mechanism to privately estimate the reward of each arm... we use the binary tree mechanism to provide private estimates for wt(i) for each arm i∈[K] using a different binary tree counter for each arm."
  - [corpus]: Weak evidence; related papers focus on general DP online learning but not dueling bandits specifically.
- Break condition: If the noise added by the binary tree mechanism exceeds the signal (e.g., when T is small or ε is very large), the EBS estimates become unreliable and the elimination criterion fails.

### Mechanism 2
- Claim: The algorithm eliminates suboptimal arms by comparing upper and lower confidence bounds on EBS scores.
- Mechanism: For each surviving arm i in the active set, the algorithm maintains UCB and LCB estimates of its EBS score. If UCBt(i) < LCBt(j) for some j, arm i is eliminated. This ensures that suboptimal arms are removed once their confidence intervals separate from better arms.
- Core assumption: The EBS scores concentrate around their true values with high probability, and the confidence intervals account for both statistical uncertainty and privacy noise.
- Evidence anchors:
  - [abstract]: "The algorithm plays the arms in a round-robin fashion, and uses the binary tree mechanism to privately estimate the reward of each arm."
  - [section]: "At each round t in phase τ, the algorithm performs a screening over all surviving arms i∈Sτ(t)... and prunes the arms with 'sufficiently low' EBS scores: precisely if there exists arms i, j ∈Sτ(t) such that UCBt(i) < LCBt(j), then arm i is eliminated."
  - [corpus]: Weak evidence; no direct mention of EBS or confidence bound elimination in related papers.
- Break condition: If the confidence intervals are too wide (due to high privacy noise or insufficient pulls), the elimination criterion may never be triggered, leading to linear regret.

### Mechanism 3
- Claim: For general d-dimensional spaces, the algorithm uses G-optimal design and core-sets to approximate rewards and eliminate arms efficiently.
- Mechanism: The algorithm identifies a G-optimal design (a representative set of dueling pairs) in each phase, plays each pair enough times to estimate the unknown utility vector w via maximum likelihood, and eliminates arms whose optimistic score estimates fall below a threshold relative to others.
- Core assumption: The Kiefer-Wolfowitz theorem guarantees a small core-set size (≤ d(d+1)/2) that allows efficient estimation, and the MLE estimator concentrates around the true w with high probability.
- Evidence anchors:
  - [abstract]: "For general d-dimensional spaces, it attains a regret bound of Õ(d^6/(κε) + d√T/κ)."
  - [section]: "The main idea lies in deriving an estimate of w∈Rd and maintaining confidence ellipsoids on the pairwise score-differences... At the beginning of any phase ℓ, we first identify the G-Optimal design... Upon identifying the G-Optimal design in phase ℓ, we play each dueling pair (x, y) in the support of the G-Optimal design 'enough times'..."
  - [corpus]: Weak evidence; related papers discuss DP bandits and core-sets but not in the dueling context.
- Break condition: If the core-set does not adequately represent the decision space or the MLE estimation fails to concentrate, the algorithm may eliminate good arms or retain bad ones.

## Foundational Learning

- Concept: Differential Privacy (DP) and its variants (pure ε-DP, (ε,δ)-DP).
  - Why needed here: The algorithm must ensure that changing any single user's preference does not significantly affect the output, preserving user privacy while learning from preferences.
  - Quick check question: What is the difference between pure ε-DP and (ε,δ)-DP, and why does the paper focus on pure ε-DP?

- Concept: Dueling Bandits and Preference Feedback Models.
  - Why needed here: The algorithm learns from pairwise comparisons rather than absolute ratings, modeling user preferences as Bernoulli random variables with probabilities determined by a logistic link function.
  - Quick check question: How does the logistic link function σ(r(at)−r(bt)) model the probability of one arm winning over another?

- Concept: Effective Borda Score (EBS) and its Properties.
  - Why needed here: EBS provides a total ordering of arms based on their average win probability against random opponents, enabling the elimination of suboptimal arms.
  - Quick check question: Why does the EBS of the best arm minus the EBS of the worst arm in a set S lower bound the preference gap ∆(i⋆S,i′S)?

## Architecture Onboarding

- Component map:
  - Round-robin arm selection -> Binary tree mechanism -> Private EBS estimation -> Confidence bounds (UCB/LCB) -> Elimination criterion -> Active set update

- Critical path:
  1. Initialize active set S1 = [K] and K binary tree counters.
  2. For each round t:
     a. Select at in round-robin from Sτ(t), bt randomly from Sτ(t).
     b. Observe preference ot and update win count wt(at) if at wins.
     c. Use binary tree counter to get private estimate ˜wt(at).
     d. Update UCBt(i) and LCBt(i) for all i∈Sτ(t).
     e. If UCBt(i) < LCBt(j) for some j, eliminate i and adjust counts.
  3. Repeat until one arm remains, then commit to it.

- Design tradeoffs:
  - Privacy vs. utility: Higher privacy (smaller ε) increases noise, widening confidence bounds and slowing elimination.
  - Exploration vs. exploitation: Round-robin ensures exploration but may be inefficient if the active set is large.
  - Finite vs. infinite arms: Finite case uses direct pairwise estimation; infinite case requires core-sets and G-optimal design, increasing complexity.

- Failure signatures:
  - High regret despite many rounds: Confidence intervals too wide due to excessive privacy noise or insufficient pulls.
  - Algorithm gets stuck with multiple arms: Elimination criterion never triggered because UCB/LCB overlap persists.
  - Wrong arm selected: Best arm eliminated due to under-estimation of its EBS score (rare if confidence bounds are valid).

- First 3 experiments:
  1. **Sanity check with K=3, ε=1, T=1000**: Verify that the algorithm correctly identifies the best arm with high probability and achieves sublinear regret.
  2. **Privacy-utility tradeoff**: Fix K=10, vary ε from 0.1 to 10, measure regret and verify ε-DP using the group privacy argument.
  3. **Scalability test for infinite arms**: Set d=5, generate a synthetic decision space, run the G-optimal design algorithm, and check that the core-set size and elimination efficiency scale as predicted.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the algorithm's performance scale when the preference feedback follows a non-logistic link function (e.g., probit or Gumbel)?
- Basis in paper: [explicit] The paper assumes a logistic link function σ(x) = (1 + e^(-x))^(-1) for modeling preference feedback, but acknowledges that this could be generalized to other link functions.
- Why unresolved: The paper focuses specifically on the logistic case and does not explore alternative link functions or their impact on privacy guarantees and regret bounds.
- What evidence would resolve it: Theoretical analysis showing how different link functions affect the algorithm's privacy-utility tradeoff, and empirical comparison of algorithms under different link functions.

### Open Question 2
- Question: Can the DP-GOptimal algorithm be extended to handle non-stationary preference matrices where the underlying utility vector w* changes over time?
- Basis in paper: [inferred] The paper focuses on stationary environments with a fixed w*, but many real-world applications involve changing user preferences over time.
- Why unresolved: The current algorithm design assumes a static w* and doesn't incorporate mechanisms for tracking changing preferences while maintaining privacy.
- What evidence would resolve it: Modified algorithm with tracking capabilities, theoretical analysis of regret under non-stationarity, and empirical validation on datasets with evolving preferences.

### Open Question 3
- Question: What is the impact of user-level privacy (local DP) versus central DP on the algorithm's regret bounds and practical performance?
- Basis in paper: [explicit] The paper mentions in Remark 3 that the algorithm could be extended to local DP, but notes that this would result in "larger noise and therefore the confidence intervals have to be changed accordingly."
- Why unresolved: The paper only provides regret bounds for central DP and doesn't explore the trade-offs between different DP models in terms of utility.
- What evidence would resolve it: Complete regret analysis for local DP variant, empirical comparison of central vs local DP implementations, and characterization of the utility gap between different DP models.

## Limitations

- The algorithm's performance degrades when privacy noise overwhelms the signal, particularly for small ε or insufficient T.
- Confidence intervals must be carefully calibrated to balance privacy noise and elimination efficiency, which may not always be optimal in practice.
- The analysis assumes accurate concentration of estimates and valid confidence bounds, but does not provide extensive empirical validation across diverse problem settings.

## Confidence

- Regret bounds for finite action spaces: **High** - The analysis is rigorous and matches known lower bounds.
- Regret bounds for general d-dimensional spaces: **Medium** - The proof relies on Kiefer-Wolfowitz and core-set properties, which are well-established, but the coupling with privacy noise adds complexity.
- Privacy guarantees: **High** - The use of binary tree mechanisms is standard for pure ε-DP, and the analysis follows known techniques.

## Next Checks

1. **Empirical robustness test**: Run the algorithm with varying ε and T to empirically measure how regret scales and whether the theoretical bounds are tight in practice.
2. **Confidence interval width analysis**: Track the empirical width of UCB/LCB intervals over time to verify that they shrink appropriately and do not prevent elimination.
3. **Best arm retention check**: Monitor the probability that the optimal arm is eliminated in finite simulations, especially under high privacy noise, to validate the soundness of the confidence bound construction.