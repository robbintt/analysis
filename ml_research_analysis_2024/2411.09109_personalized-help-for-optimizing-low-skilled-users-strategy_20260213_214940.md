---
ver: rpa2
title: Personalized Help for Optimizing Low-Skilled Users' Strategy
arxiv_id: '2411.09109'
source_url: https://arxiv.org/abs/2411.09109
tags:
- advice
- players
- pholus
- message
- game
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents PHOLUS, an AI advisor that provides move and
  message advice to Diplomacy players based on their intentions and game state. Unlike
  CICERO, which plays the game directly, PHOLUS acts as a passive advisor.
---

# Personalized Help for Optimizing Low-Skilled Users' Strategy

## Quick Facts
- arXiv ID: 2411.09109
- Source URL: https://arxiv.org/abs/2411.09109
- Reference count: 19
- One-line primary result: PHOLUS helps novice Diplomacy players compete with and sometimes surpass experienced players through AI-generated move and message advice

## Executive Summary
PHOLUS is an AI advisor that provides move and message advice to Diplomacy players based on their intentions and game state. Unlike playing agents, PHOLUS acts as a passive advisor that observes games and suggests optimal strategies. The system was tested across 12 games with 41 players, collecting over 7,900 advice instances. Results demonstrate that advice helps novices compete with experienced players and sometimes surpass them, even when not strictly followed. The mere presence of advice proved advantageous, with players receiving both move and message advice gaining more points than those receiving no advice.

## Method Summary
PHOLUS augments CICERO, a natural language agent with superhuman performance in Diplomacy, to generate move and message advice. The system passively observes games and provides advice based on game state and player's past messages. The study involved 12 games with novice and experienced players, collecting over 3,600 move advice instances and 4,300 message advice instances. Players received varying advice settings (no advice, message advice, move advice, both) and data was collected on advice acceptance rates, point gains/losses, and player feedback.

## Key Results
- Novice players accepted move advice 32.6% of the time and message advice 6.3% of the time
- Experienced players accepted move advice 6.4% of the time and message advice 3.4% of the time
- Players receiving both move and message advice gained more points than those receiving no advice
- Advice helped novices compete with and sometimes surpass experienced players even when not strictly followed

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PHOLUS improves novice performance even when advice is not fully followed.
- Mechanism: Advice provides strategic insights that inform decision-making and communication, shifting novice play style toward expert-level strategy.
- Core assumption: Players absorb strategic intent from advice even if moves differ; learning occurs through exposure to expert-level patterns.
- Evidence anchors:
  - [abstract] "The mere presence of advice can be advantageous, even if players do not follow it."
  - [section] "PHOLUS helps novices compete with experienced players and in some instances even surpass them. But this does not just mean the novices blindly follow the advice."
- Break condition: If novices fail to internalize strategic intent from advice (e.g., advice too complex or misaligned), the learning signal weakens and performance gains disappear.

### Mechanism 2
- Claim: Novice players accept move advice more frequently than message advice.
- Mechanism: Moves are concrete, low-risk, and directly tied to game state, making them easier to adopt. Messages require nuanced alignment with social strategy, increasing rejection risk.
- Core assumption: Players find move recommendations easier to evaluate and implement than communication strategies.
- Evidence anchors:
  - [section] "Novice players accepted move advice 32.6% of the time and message advice 6.3% of the time, compared to 6.4% and 3.4% for veterans."
  - [section] "Novices are more willing to accept move and message advice than veterans."
- Break condition: If message advice becomes more actionable (e.g., templates tied to explicit player intentions), the adoption gap could narrow or reverse.

### Mechanism 3
- Claim: Experienced players benefit less from advice because they are less willing to accept it.
- Mechanism: Experienced players have internalized strategies and distrust external advice; they selectively adopt advice only when it aligns with their goals.
- Core assumption: Expert players trust their own judgment more than AI-generated suggestions.
- Evidence anchors:
  - [section] "Experienced players tend to disregard advice. They accept only 3.4% of message advice and 6.4% of move advice from PHOLUS."
  - [section] "Although novice players are also hesitant to accept message advice, doing so 6.3% of the time, this rate is nearly double that of experienced players."
- Break condition: If PHOLUS can generate advice that explicitly addresses expert-level meta-goals (e.g., alliance dynamics), acceptance rates could improve.

## Foundational Learning

- Concept: Strategic abstraction in board games.
  - Why needed here: PHOLUS generates advice based on optimal utility; understanding how to map abstract strategy to concrete moves is critical for interpreting its recommendations.
  - Quick check question: Given a defensive position with two adjacent threats, what type of move advice would maximize survival without exposing a flank?
- Concept: Player intention modeling.
  - Why needed here: PHOLUS generates advice by inferring intentions from player messages; engineers must understand how to extract and represent intentions from natural language.
- Concept: Move agreement and equivalence metrics.
  - Why needed here: These metrics quantify how closely player moves align with advice; understanding their computation is essential for evaluating PHOLUS effectiveness.

## Architecture Onboarding

- Component map: Input layer (player move history, message history, game state) -> Intention inference module (NLP parser) -> Strategy generation module (CICERO-based advisor) -> Advice delivery interface -> Feedback collection
- Critical path: 1. Player submits move/message 2. PHOLUS recomputes advice based on updated context 3. Advice is presented to player 4. Player accepts or rejects advice 5. Acceptance data is logged for analysis
- Design tradeoffs:
  - Accuracy vs. latency: More complex intention modeling increases advice quality but risks slow delivery
  - Generality vs. specificity: Broad advice applies to many scenarios but may feel less tailored; specific advice is more actionable but risks misalignment
- Failure signatures:
  - Low acceptance rates across both player types
  - Sharp drop in move agreement between initial suggestion and final decision
  - High SMATCH scores but low actual adoption of message advice
- First 3 experiments:
  1. A/B test: Compare novice performance with move advice only vs. no advice
  2. Ablation test: Remove intention inference step and measure impact on move acceptance
  3. Longitudinal study: Track novice improvement over multiple games with consistent advice exposure

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does PHOLUS generate advice that is optimized for CICERO's intentions rather than player intentions, and what are the specific mechanisms that cause this misalignment?
- Basis in paper: [explicit] The paper states "Potential improvements include 1) explaining meta-level intentions (e.g., ally with Germany and prioritize defeating Austria) from player input, and 2) generating targeted move and message advice based on meta-level intentions." and "We suspect that the advice may be optimized more for CICERO's intentions, which come from optimal moves in the supervised training data."
- Why unresolved: The paper identifies this as a limitation but does not provide detailed analysis of the specific mechanisms causing the misalignment between PHOLUS's advice and player intentions.
- What evidence would resolve it: Detailed analysis comparing the decision-making processes of CICERO and PHOLUS, with specific examples showing where advice optimization diverges from player intentions.

### Open Question 2
- Question: What is the optimal frequency and timing for presenting advice to maximize player performance without causing over-reliance?
- Basis in paper: [inferred] The paper discusses that "the mere presence of advice can be advantageous, even if players do not follow it" and that "novices are more likely to follow PHOLUS's advice" but "do not fully trust move advice from PHOLUS." This suggests there may be an optimal balance between advice presentation and player autonomy.
- Why unresolved: The paper does not systematically vary the frequency or timing of advice presentation to determine what maximizes performance without creating over-reliance.
- What evidence would resolve it: Controlled experiments varying the frequency and timing of advice presentation across multiple games, measuring both performance outcomes and metrics of player autonomy.

### Open Question 3
- Question: How does the acceptance rate of message advice (6.3% for novices, 3.4% for veterans) compare to the actual utility of the advice when it is accepted?
- Basis in paper: [explicit] The paper provides acceptance rates but does not correlate these with outcomes when advice is actually followed.
- Why unresolved: The paper focuses on overall acceptance rates and general outcomes but does not examine the specific impact of message advice when players choose to follow it.
- What evidence would resolve it: Analysis tracking game outcomes specifically when message advice is accepted versus rejected, controlling for player skill level and game state.

## Limitations
- The paper lacks details on how PHOLUS augments CICERO's strategy generation to produce actionable move and message advice
- No information is provided about the linear regression model used to evaluate advice effectiveness
- The study's small sample size (12 games with 41 players) limits generalizability of the findings

## Confidence

- **High Confidence**: Novice players accepted move advice more frequently than message advice (32.6% vs 6.3%)
- **High Confidence**: Experienced players showed significantly lower advice acceptance rates (6.4% for moves, 3.4% for messages)
- **Medium Confidence**: The mere presence of advice improved novice performance even when not strictly followed
- **Low Confidence**: PHOLUS can help novices "surpass" experienced players based on the small sample size

## Next Checks

1. **Mechanism Validation**: Conduct a controlled experiment where novices receive move advice but are explicitly instructed to modify it. Measure if performance gains persist when advice is adapted rather than followed verbatim.
2. **Expert Acceptance Investigation**: Implement an A/B test where PHOLUS generates advice tailored to expert-level meta-strategies (alliance dynamics, long-term positioning) versus standard advice. Compare acceptance rates.
3. **Reproducibility Test**: Reimplement PHOLUS's intention inference and strategy generation components using publicly available Diplomacy datasets. Validate if the acceptance rate patterns (32.6% vs 6.3% for novices, 6.4% vs 3.4% for experts) replicate.