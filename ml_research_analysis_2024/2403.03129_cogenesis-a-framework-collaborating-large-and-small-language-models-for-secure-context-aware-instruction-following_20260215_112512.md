---
ver: rpa2
title: 'CoGenesis: A Framework Collaborating Large and Small Language Models for Secure
  Context-Aware Instruction Following'
arxiv_id: '2403.03129'
source_url: https://arxiv.org/abs/2403.03129
tags: []
core_contribution: This paper addresses the privacy concerns that arise when large
  language models (LLMs) require access to user context for generating personalized
  content. To mitigate these risks, the authors propose CoGenesis, a collaborative
  framework that leverages both large-scale cloud-based models and smaller, locally
  deployed models to jointly produce context-aware responses without exposing sensitive
  data.
---

# CoGenesis: A Framework Collaborating Large and Small Language Models for Secure Context-Aware Instruction Following

## Quick Facts
- arXiv ID: 2403.03129
- Source URL: https://arxiv.org/abs/2403.03129
- Reference count: 32
- Primary result: CoGenesis achieves competitive performance to full-context LLMs while preserving user privacy through collaboration between cloud and local models

## Executive Summary
CoGenesis addresses privacy concerns in context-aware language models by introducing a collaborative framework that separates sensitive user context from general knowledge processing. The framework combines large-scale cloud-based models with smaller locally deployed models to generate personalized responses without exposing private data. Through a novel data construction pipeline and two collaboration variants (sketch-based and logit-based), CoGenesis demonstrates that it can achieve comparable performance to full-context models while maintaining privacy guarantees.

## Method Summary
CoGenesis implements a two-tier architecture where a local small language model handles sensitive context information while a cloud-based large language model provides general knowledge and response generation capabilities. The framework uses a data construction pipeline to synthesize personalized instruction datasets for training. Two collaboration mechanisms are proposed: sketch-based, where the local model generates a response outline that the cloud model fills in, and logit-based, where the local model's probability distributions guide the cloud model's output generation. This separation ensures sensitive context never leaves the user's device while still enabling personalized responses.

## Key Results
- CoGenesis achieves competitive performance metrics compared to full-context LLMs across synthetic and public datasets
- The logit-based variant shows stronger gains than sketch-based methods in personalization metrics
- Privacy preservation is demonstrated through the framework's ability to maintain personalization without exposing sensitive user context

## Why This Works (Mechanism)
CoGenesis works by decomposing the instruction-following task into context-sensitive and context-agnostic components, allowing each to be handled by the most appropriate model. The local model processes and retains sensitive context information, generating either response sketches or probability distributions that guide the cloud model. This architectural separation prevents raw personal data from being transmitted to external servers while still leveraging the superior general knowledge and language understanding capabilities of large cloud models. The collaboration mechanism ensures that personalization is preserved through the guidance signals (sketches or logits) rather than through direct context exposure.

## Foundational Learning

**Context-aware instruction following**: Understanding how to generate responses that incorporate user-specific context while maintaining relevance - needed to frame the personalization challenge and evaluate CoGenesis's effectiveness against baseline approaches.

**Privacy-preserving machine learning**: Techniques for processing sensitive data without exposing it to external systems - essential for understanding the security guarantees CoGenesis claims to provide through its collaborative architecture.

**Knowledge distillation and model collaboration**: Methods for transferring information between models of different scales and capabilities - critical for understanding how the local and cloud models exchange information without compromising privacy.

**Synthetic dataset generation for personalization**: Creating artificial but realistic instruction-context pairs that capture personalization patterns - necessary to evaluate the framework when real sensitive data cannot be used for testing.

## Architecture Onboarding

**Component map**: User context -> Local small model -> (sketch/logits) -> Cloud large model -> Response generation

**Critical path**: The flow from local model processing through to cloud model completion represents the core execution sequence where privacy preservation and personalization must be balanced simultaneously.

**Design tradeoffs**: The framework trades computational efficiency and potential latency for privacy preservation, requiring careful optimization of the collaboration mechanism to maintain responsiveness while ensuring sensitive data remains local.

**Failure signatures**: Poor personalization quality indicates inadequate context transfer between models; security breaches would manifest as sensitive context appearing in cloud model outputs or logs; performance degradation suggests inefficient collaboration protocols.

**First 3 experiments**: 
1. Baseline comparison of local-only vs cloud-only models on privacy-sensitive tasks
2. Ablation study comparing sketch-based and logit-based collaboration variants
3. Stress testing with adversarial context inputs to verify privacy boundaries

## Open Questions the Paper Calls Out
None

## Limitations
- Privacy claims rely on synthetic datasets that may not capture real-world complexity and diversity of user contexts
- Performance comparisons are limited to narrow alternatives without extensive ablation studies across different model architectures
- No analysis of computational overhead or latency introduced by the collaboration mechanism

## Confidence
- Framework design and methodology: Medium - Well-defined but limited empirical validation
- Privacy preservation claims: Low-Medium - Based on synthetic rather than real-world data
- Performance improvements: Medium - Statistically significant but narrow comparison scope

## Next Checks
1. Evaluate CoGenesis on real user conversation logs with actual PII to validate privacy preservation claims under realistic conditions
2. Conduct extensive ablation studies testing different sketch generation strategies and collaboration hyperparameters
3. Measure end-to-end system latency and computational costs to assess practical deployment viability