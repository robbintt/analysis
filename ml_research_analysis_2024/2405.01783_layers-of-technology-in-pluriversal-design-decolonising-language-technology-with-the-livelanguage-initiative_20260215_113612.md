---
ver: rpa2
title: Layers of technology in pluriversal design. Decolonising language technology
  with the LiveLanguage initiative
arxiv_id: '2405.01783'
source_url: https://arxiv.org/abs/2405.01783
tags:
- language
- technology
- design
- knowledge
- technological
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper identifies how language technology is entangled with
  colonial knowledge through path dependencies and global governance structures. It
  proposes a five-layer model of technological activity to diversify co-design interventions:
  (1) data models and algorithms, (2) language resources and datasets, (3) normative
  frameworks, (4) political economies and business models, and (5) socio-cultural
  contexts of use.'
---

# Layers of technology in pluriversal design. Decolonising language technology with the LiveLanguage initiative

## Quick Facts
- arXiv ID: 2405.01783
- Source URL: https://arxiv.org/abs/2405.01783
- Authors: Gertraud Koch; Gábor Bella; Paula Helm; Fausto Giunchiglia
- Reference count: 16
- One-line primary result: A five-layer model of technological activity that identifies entry points for decolonizing language technology through value-oriented design

## Executive Summary
This paper presents a five-layer model for decolonizing language technology by analyzing how colonial knowledge is embedded across different technological layers. Using the LiveLanguage initiative as a case study, the authors demonstrate that language technology is entangled with colonial trajectories through path dependencies and global governance structures. The model identifies specific intervention points across technical layers (data models, algorithms, language datasets), normative frameworks, political economies, and socio-cultural contexts. While technical layers allow for more straightforward decoupling through engineering expertise, normative and contextual layers require broader co-design approaches to address neo-colonial governance issues and local community engagement.

## Method Summary
The paper analyzes the LiveLanguage initiative to develop a five-layer model of technological activity in language technology. The approach involves examining how LiveLanguage's technical improvements in data models, algorithms, and language resources address colonial path dependencies, while proposing interventions across normative frameworks, political economies, and socio-cultural contexts. The methodology draws on chaînes opératoires and assemblage theory to understand language technology as distributed across global scales, diverse sites, and practices. The authors use this framework to identify specific entry points for co-design interventions that can decouple language technology from colonial trajectories.

## Key Results
- Language technology is embedded with colonial knowledge through path dependencies in data models, algorithms, and governance structures
- Technical layers (1-2) can be decoupled from colonial trajectories through engineering interventions like direct language-to-language translation without English hub
- Normative and contextual layers (3-5) require broader co-design approaches to address neo-colonial governance and local community engagement

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Technical layers allow for direct decoupling from colonial trajectories through engineering expertise
- Mechanism: Engineering interventions can systematically address structural biases by redesigning data models and algorithms to avoid English-as-hub dependency and by expanding language datasets to include small languages directly
- Core assumption: Technical problems have technical solutions that can be implemented without broader social restructuring
- Evidence anchors: LiveLanguage's work on lexical gaps, diversity-oriented design in technical layers, five-layer model entry points

### Mechanism 2
- Claim: Pluriversal design theory provides heuristics for reframing colonial trajectories through value-oriented design in normative and contextual layers
- Mechanism: Normative frameworks and socio-cultural contexts can be restructured through participatory design approaches that incorporate diverse knowledge ecologies and local community engagement
- Core assumption: Co-design approaches can effectively transform normative and contextual layers without requiring fundamental changes to technical infrastructure
- Evidence anchors: Limits of technical diversity-oriented design, need for broader co-design approaches, stakeholder coordination requirements

### Mechanism 3
- Claim: Global governance structures in political economies create path dependencies that require macro-level intervention beyond technical co-design
- Mechanism: Political economies and business models must be addressed through coordinated efforts with language communities and alternative ownership models to circumvent neo-colonial exploitation
- Core assumption: Macro-level political economy issues can be bypassed through community coordination rather than requiring systemic economic reform
- Evidence anchors: LiveLanguage's community coordination efforts, internet companies and states negotiating interests, need to circumvent neo-colonial problems

## Foundational Learning

- Concept: Chaînes opératoires
  - Why needed here: This methodological approach helps deconstruct technological activities into individual practices that contribute to emergence of language technology, enabling targeted interventions at specific layers
  - Quick check question: How does scaling chaînes opératoires from micro to meso level help identify intervention points in language technology assemblages?

- Concept: Assemblage theory
  - Why needed here: Understanding language technology as assemblages of distributed agency across global scales, diverse sites, and practices explains why co-design interventions must target multiple interconnected layers rather than single points
  - Quick check question: Why can't language technology decolonization be achieved by intervening in just one layer of technological activity?

- Concept: Epistemic justice
  - Why needed here: Recognition of epistemic injustice explains why language technology must address not just technical representation but also the power dynamics that determine whose knowledge counts and how it's validated
  - Quick check question: How does the concept of epistemic justice relate to the problem of minority languages being excluded from large language models?

## Architecture Onboarding

- Component map: Layer 1: Data models and algorithms → Layer 2: Language resources and datasets → Layer 3: Normative frameworks → Layer 4: Political economies and business models → Layer 5: Socio-cultural contexts of use

- Critical path: Technical decoupling (Layers 1-2) → Normative reframing (Layer 3) → Community coordination (Layer 5) → Governance navigation (Layer 4)

- Design tradeoffs: Technical solutions offer immediate implementability but may miss deeper structural issues; normative interventions address root causes but require longer timeframes and broader stakeholder buy-in

- Failure signatures: Technical fixes that ignore cultural context produce culturally inappropriate translations; normative interventions without technical support fail to address algorithmic bias; community coordination without governance reform gets co-opted by corporate interests

- First 3 experiments:
  1. Implement direct language-to-language translation system without English hub and measure reduction in lexical gaps for minority languages
  2. Conduct participatory workshops with language communities to identify normative framework requirements for ethical language technology development
  3. Map current political economy relationships in language technology governance to identify leverage points for community-based alternatives

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can participatory design methods effectively address the epistemic injustice and cultural appropriation risks inherent in collecting language data from minority communities?
- Basis in paper: The paper identifies these risks but doesn't provide concrete solutions for avoiding them through participatory design
- Why unresolved: While the paper acknowledges these problems exist, it doesn't detail specific participatory design protocols or safeguards that would protect minority communities from exploitation
- What evidence would resolve it: Case studies showing successful participatory design frameworks that prevent epistemic injustice, along with documented community consent processes and benefit-sharing agreements

### Open Question 2
- Question: What specific governance mechanisms could replace corporate control of language resources while ensuring sustainable maintenance and development of minority language technologies?
- Basis in paper: The paper critiques corporate control but doesn't propose concrete alternative governance models
- Why unresolved: The paper identifies the problem of corporate exploitation but only vaguely mentions stewardship concepts without detailing how they would work in practice
- What evidence would resolve it: Concrete examples of community-owned language technology governance structures, including funding models and decision-making processes

### Open Question 3
- Question: How can the five-layer model be empirically tested to validate its effectiveness in guiding decolonizing interventions in language technology development?
- Basis in paper: The paper presents the five-layer model as a theoretical framework but doesn't provide empirical validation of its utility
- Why unresolved: While the model is theoretically sound, there's no evidence of its practical application or measurement of outcomes when used as a design guide
- What evidence would resolve it: Longitudinal studies comparing language technology projects using the five-layer model versus traditional approaches, with metrics on decolonization outcomes and community impact

## Limitations
- The technical decoupling mechanisms appear more theoretically sound than practically validated at scale
- The paper lacks concrete metrics for measuring success in decolonizing language technology
- Coordination requirements for addressing normative and contextual layers may be underestimated given complex power dynamics

## Confidence
- High confidence: The identification of colonial path dependencies in language technology and the basic premise that technical solutions can address some layers more directly than others
- Medium confidence: The effectiveness of community coordination as a substitute for macro-level political economy reform, and the assumption that co-design approaches can meaningfully transform normative frameworks without fundamental structural changes
- Low confidence: The scalability of direct translation systems without English hubs for the 2,000+ languages mentioned, and the feasibility of bypassing entrenched neo-colonial governance structures through the proposed multi-stakeholder coordination

## Next Checks
1. **Technical feasibility assessment**: Implement a pilot direct translation system between two minority languages (e.g., Quechua-Spanish or Hausa-Yoruba) and measure the reduction in lexical gaps compared to English-hub systems, documenting resource requirements and accuracy metrics

2. **Governance mapping exercise**: Conduct a systematic analysis of current ownership patterns and power dynamics in language technology governance, identifying specific leverage points where community coordination has successfully influenced corporate or state policies

3. **Community impact study**: Design and execute a longitudinal study tracking how interventions in different layers (technical, normative, contextual) affect actual language community outcomes over 12-24 months, including metrics for language preservation, economic benefit, and cultural representation