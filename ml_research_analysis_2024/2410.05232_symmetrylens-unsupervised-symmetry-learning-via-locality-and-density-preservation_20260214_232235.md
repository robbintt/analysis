---
ver: rpa2
title: 'SymmetryLens: Unsupervised Symmetry Learning via Locality and Density Preservation'
arxiv_id: '2410.05232'
source_url: https://arxiv.org/abs/2410.05232
tags:
- symmetry
- group
- data
- will
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an unsupervised symmetry learning method
  that discovers minimal generators of underlying Lie groups from raw data, producing
  symmetry-equivariant representations. The approach formulates an information-theoretic
  loss function measuring both symmetry preservation and locality coupling between
  data samples and candidate symmetry transformations.
---

# SymmetryLens: Unsupervised Symmetry Learning via Locality and Density Preservation

## Quick Facts
- arXiv ID: 2410.05232
- Source URL: https://arxiv.org/abs/2410.05232
- Authors: Onur Efe; Arkadas Ozakin
- Reference count: 33
- Primary result: Unsupervised discovery of minimal Lie group generators from raw data with cosine similarity > 0.99 and RMSE < 0.03 on synthetic datasets

## Executive Summary
This paper presents SymmetryLens, an unsupervised method for discovering minimal generators of underlying Lie groups from raw data. The approach formulates an information-theoretic loss function that measures both symmetry preservation and locality coupling between data samples and candidate symmetry transformations. By jointly learning symmetry generators alongside local resolving filters through joint optimization, the method successfully recovers pixel translations from image-like data and identifies non-obvious symmetries like frequency shifts with high accuracy. The approach is robust to noise and demonstrates stable training dynamics across diverse symmetry types.

## Method Summary
SymmetryLens discovers symmetry generators by optimizing a loss function that enforces both locality and stationarity properties in transformed representations. The method learns an orthogonal matrix G (the symmetry generator) and a resolving filter ψ(0) through joint optimization, forming a group convolution matrix L that transforms raw data into equivariant representations. A dynamic low-rank entropy estimation technique prevents local minima by first optimizing dominant principal components before refining with higher-rank components. The approach scales to 33-dimensional datasets without hyperparameter tuning and produces representations suitable for standard CNN architectures.

## Key Results
- Recovers pixel translation generators from image-like data with cosine similarity > 0.99
- Identifies non-obvious symmetries (frequency shifts, permuted translations) with RMSE < 0.03
- Successfully scales to 33-dimensional datasets without hyperparameter tuning
- Produces symmetry-equivariant representations directly usable by standard CNN architectures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Coupling locality and stationarity through correlation and resolution losses drives discovery of minimal symmetry generator
- Mechanism: The model learns symmetry generator G and resolving filter ψ(0) by optimizing loss function that simultaneously enforces stationarity (via uniformity loss) and locality (via alignment and resolution losses). Locality loss requires neighboring components of transformed representation be highly correlated while non-neighboring components be approximately independent.
- Core assumption: Data exhibits both locality and symmetry properties that are intrinsically linked and can be captured by loss function
- Evidence anchors: [abstract], [section] on simultaneous learning, weak evidence from related papers on symmetry learning in VAEs

### Mechanism 2
- Claim: Dynamic low-rank entropy estimation prevents local minima
- Mechanism: Uses rank-k approximation starting with low rank and gradually increasing over training epochs, allowing model to first optimize dominant principal components before refining with higher-rank components
- Core assumption: Data has hierarchical structure where most informative components can be learned first
- Evidence anchors: [section] on dynamic weighting of entropies, weak evidence from related papers on entropy estimation techniques

### Mechanism 3
- Claim: Learns equivariant representation directly usable by standard CNNs
- Mechanism: Group convolution operator L formed by combining learned symmetry generator G with resolving filter ψ(0) transforms data into representation equivariant under pixel translations
- Core assumption: Learned symmetry generator and resolving filter are accurate enough to produce truly equivariant representation
- Evidence anchors: [abstract] on CNN suitability, [section] on application to supervised learning, weak evidence from related papers on symmetry representations

## Foundational Learning

- Concept: Lie groups and group representations
  - Why needed here: Method discovers minimal generator of underlying Lie group of symmetries
  - Quick check question: What is relationship between Lie group and Lie algebra? How are group representations used to describe action of group on vector space?

- Concept: Information theory and entropy estimation
  - Why needed here: Loss function uses information-theoretic measures like entropy and mutual information to enforce locality and stationarity
  - Quick check question: What is difference between differential entropy and discrete entropy? How is entropy estimated from data in high-dimensional settings?

- Concept: Neural network architectures and optimization
  - Why needed here: Model uses neural networks for probability density estimation and gradient-based optimization
  - Quick check question: What are advantages/disadvantages of gradient-based optimization for learning symmetry generators? How do different neural network architectures affect probability density estimators?

## Architecture Onboarding

- Component map: Symmetry generator G -> Resolving filter ψ(0) -> Group convolution matrix L -> Transformed representation y -> Loss computation -> Gradients -> Update G and ψ(0)

- Critical path: Data → Group convolution matrix L → Transformed representation y → Loss computation (alignment, resolution, uniformity, preservation) → Gradients → Update G and ψ(0)

- Design tradeoffs:
  - Dimensionality vs. accuracy: Higher dimensions provide more information but increase computational complexity
  - Rank of entropy estimation: Lower rank provides more stable optimization but may miss important details
  - Strength of regularization terms: Stronger regularization enforces locality more strictly but may limit capturing complex symmetries

- Failure signatures:
  - Identity collapse: Generator converges to identity matrix, indicating failed symmetry discovery
  - Overfitting: Learns generator fitting training data perfectly but doesn't generalize
  - Underfitting: Fails to capture full complexity of underlying symmetry

- First 3 experiments:
  1. Train on simple dataset with known pixel translation symmetry and verify correct generator learning
  2. Train on dataset with complex symmetry (frequency shifts) and verify correct generator learning
  3. Train on dataset with added noise and verify robustness while learning correct generator

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can SymmetryLens be extended to learn non-linear group actions instead of just linear representations?
- Basis in paper: [explicit] "more generally, symmetry actions can be nonlinear. The philosophy of this paper can be applied to the nonlinear case as well, but of course the practical problems with optimization and the architectural choices for representing a nonlinear map will require work and experimentation."
- Why unresolved: Current implementation learns linear generators through exponential mapping of antisymmetric matrices
- What evidence would resolve it: Successful extension demonstrating nonlinear symmetry learning with concrete architecture and optimization strategy

### Open Question 2
- Question: What is theoretical relationship between learned resolving filter and "delta function along ρ" concept?
- Basis in paper: [explicit] "While we have not explicitly forced the model for this, in each case, the learned resolving filter was an approximate 'delta function along the symmetry direction' as described in Section 3.1."
- Why unresolved: Paper observes this behavior empirically but lacks formal proof
- What evidence would resolve it: Mathematical proof showing optimal resolving filter must approximate delta function under given loss function constraints

### Open Question 3
- Question: What is maximum dimensionality at which SymmetryLens can reliably learn symmetries?
- Basis in paper: [explicit] "At 33 dimensions... Our initial experiments indicate that method works on datasets with twice the dimensionality... For dimensions that are orders of magnitude higher, one will likely need further computational, and possibly algorithmic optimizations."
- Why unresolved: Only demonstrates up to 33 dimensions with speculative guidance on scalability
- What evidence would resolve it: Systematic experiments showing performance degradation curves as dimensionality increases

## Limitations

- Assumes data exhibits both locality and stationarity properties, which may not hold for many real-world datasets
- Success depends heavily on coupling between locality and symmetry properties, which may not be universal
- Currently limited to discrete symmetry groups and may not generalize to continuous or more complex symmetry structures

## Confidence

- Symmetry Discovery Claims: High (accurate identification of known symmetries with strong metrics)
- Scalability Claims: Medium (validated to 33 dimensions, untested for much higher dimensions)
- Real-World Applicability: Low (synthetic datasets, specific assumptions about data structure)

## Next Checks

1. Apply method to real-world dataset with known symmetries (e.g., molecular structures or time-series data) to validate generalizability beyond synthetic data

2. Systematically vary strength of locality and stationarity properties in synthetic data to determine performance boundaries and identify failure conditions

3. Compare unsupervised symmetry discovery performance against supervised symmetry learning approaches on datasets where ground truth symmetries are known