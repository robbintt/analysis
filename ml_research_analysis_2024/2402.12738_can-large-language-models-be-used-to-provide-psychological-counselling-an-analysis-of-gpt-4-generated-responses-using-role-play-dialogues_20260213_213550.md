---
ver: rpa2
title: Can Large Language Models be Used to Provide Psychological Counselling? An
  Analysis of GPT-4-Generated Responses Using Role-play Dialogues
arxiv_id: '2402.12738'
source_url: https://arxiv.org/abs/2402.12738
tags:
- utterances
- were
- client
- dialogue
- gpt-4
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated GPT-4's ability to generate responses for
  psychological counseling by comparing its outputs to those of human counselors in
  identical contexts from role-play dialogues. The evaluation was conducted by professional
  counselors who rated the appropriateness of both human and GPT-4 responses on a
  3-point scale.
---

# Can Large Language Models be Used to Provide Psychological Counselling? An Analysis of GPT-4-Generated Responses Using Role-play Dialogues

## Quick Facts
- arXiv ID: 2402.12738
- Source URL: https://arxiv.org/abs/2402.12738
- Reference count: 16
- Primary result: GPT-4-generated counseling responses rated as equivalent in quality to human counselors

## Executive Summary
This study evaluates GPT-4's capability to generate psychologically appropriate counseling responses by comparing its outputs to those of human counselors in identical role-play scenarios. Using professional counselor evaluations on a 3-point scale, the research found no statistically significant difference in response quality between human and AI-generated responses. While GPT-4 demonstrated competitive performance, some generated responses exhibited inappropriate phrasing that could convey problematic values. No offensive or discriminatory content was identified in the evaluated responses.

## Method Summary
The study collected Japanese counseling dialogues through role-playing scenarios with trained counselors across six themes. Counselor utterances were annotated with key points and intentions, then used to construct prompts for GPT-4-0613 with temperature 0.0. Professional counselors evaluated both human and GPT-4-generated responses for identical contexts using a 3-point Likert scale. Statistical analysis compared mean scores, and Krippendorff's alpha measured inter-rater agreement. The approach used chain-of-thought prompting with intention annotations to guide response generation.

## Key Results
- No significant difference in response quality between human counselors (mean 0.99) and GPT-4 (mean 0.94), p > 0.05
- Krippendorff's alpha of 0.24 indicated weak inter-rater agreement among evaluators
- No offensive or discriminatory content was identified in GPT-4-generated responses
- Some generated responses exhibited inappropriate phrasing or risk of conveying problematic values

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4 can generate psychologically appropriate counseling responses that are rated as equivalent to human counselors.
- Mechanism: GPT-4 was prompted using annotated role-play dialogue data that included key points and intentions from human counselors, enabling the model to simulate appropriate counseling behavior.
- Core assumption: The annotated key points and intentions capture the essential therapeutic strategies needed for effective counseling responses.
- Evidence anchors:
  - Analysis revealed no significant difference in quality between the two groups, with mean scores of 0.99 for human counselors and 0.94 for GPT-4 (p > 0.05).
  - The mean rating scores for the counsellors' utterances and GPT-4-generated utterances were 0.99 (variance: 0.49) and 0.94 (variance: 0.61), respectively. We also conducted a Mann-Whitney U-test at a significance level of 0.05 and found no significant differences.
- Break condition: If the key points and intentions don't accurately represent effective counseling strategies, or if GPT-4 fails to properly interpret the annotated guidance.

### Mechanism 2
- Claim: The chain-of-thought prompting with annotated intentions improves the quality of generated counseling responses.
- Mechanism: By providing GPT-4 with the counselor's key points and intentions before their actual utterances, the model can generate more contextually appropriate and therapeutically aligned responses.
- Core assumption: Explicit intention annotation helps the model understand the reasoning behind counselor responses and replicate that reasoning process.
- Evidence anchors:
  - To perform CoT prompting and generate higher-quality responses, we annotated the collected counselor utterances with the response key points and the intent of the response.
  - The evaluation results confirm that there were individual differences in the scoring tendencies of the evaluators, suggesting the generated responses were nuanced enough to be perceived differently by different counselors.
- Break condition: If the intention annotations are too complex or if GPT-4 cannot effectively process the multi-step reasoning required for therapeutic responses.

### Mechanism 3
- Claim: GPT-4 can avoid generating offensive or discriminatory content in counseling scenarios when properly prompted.
- Mechanism: The controlled generation process using specific counseling guidelines and role-play data limits the model's exposure to problematic content, resulting in safer outputs.
- Core assumption: The absence of offensive content in the training/guidance data prevents the model from generating such content in responses.
- Evidence anchors:
  - No offensive or discriminatory content was identified in the evaluated responses.
  - The evaluators and the authors confirmed that no offensive or discriminatory statements were found among the GPT-4-generated utterances.
- Break condition: If the model encounters adversarial prompts or real-world scenarios with problematic content not present in the training data.

## Foundational Learning

- Concept: Psychological counseling principles and therapeutic communication techniques
  - Why needed here: Understanding the therapeutic intent behind counselor responses is crucial for both annotating the role-play data and evaluating GPT-4's outputs.
  - Quick check question: What are the key differences between open-ended questions and closed-ended questions in counseling, and when should each be used?

- Concept: Chain-of-thought prompting and intention annotation in language models
  - Why needed here: The study's success depends on effectively using CoT prompting with intention annotations to guide GPT-4's response generation.
  - Quick check question: How does adding reasoning steps before generating a response improve the quality of LLM outputs compared to direct prompting?

- Concept: Evaluation methodology for subjective quality assessments
  - Why needed here: The study relies on professional counselor evaluations using a 3-point Likert scale, requiring understanding of inter-rater reliability and appropriate statistical tests.
  - Quick check question: What does a Krippendorff's alpha of 0.24 indicate about the agreement between evaluators, and is this acceptable for this type of study?

## Architecture Onboarding

- Component map: Data Collection -> Annotation Pipeline -> Prompt Construction -> GPT-4 Generation -> Evaluation Framework -> Analysis Layer
- Critical path:
  1. Collect and annotate role-play dialogues
  2. Construct prompts with guidelines and annotations
  3. Generate responses using GPT-4
  4. Have professional counselors evaluate both human and AI responses
  5. Analyze results for statistical significance and qualitative patterns
- Design tradeoffs:
  - Deterministic generation (temperature=0.0) vs. more diverse but potentially inconsistent responses
  - Detailed intention annotations vs. simpler prompts requiring less manual effort
  - Professional counselor evaluation vs. automated evaluation methods
  - Japanese language focus vs. multilingual generalization
- Failure signatures:
  - Low Krippendorff's alpha indicating poor inter-rater agreement
  - Statistically significant differences between human and AI response quality
  - Identification of offensive or discriminatory content in generated responses
  - GPT-4 generating responses that don't follow counseling guidelines
- First 3 experiments:
  1. Generate responses with and without intention annotations to measure the impact on quality scores
  2. Test different temperature settings to find the optimal balance between consistency and diversity
  3. Conduct A/B testing with different counselor evaluation groups to assess the robustness of the evaluation methodology

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LLMs consistently avoid generating responses that convey problematic values or unintended implications in sensitive counseling contexts?
- Basis in paper: The paper identifies a risky response where GPT-4 suggested that "kindness causes one to suffer oneself," which could inadvertently promote the idea that kindness should be avoided. The authors note this as a potential risk despite the small number of such cases.
- Why unresolved: The study only analyzed a limited set of role-play dialogues with predefined themes. Real-world counseling involves diverse, unpredictable client inputs, including potentially offensive or aggressive content, which could trigger more problematic responses.
- What evidence would resolve it: A systematic evaluation of GPT-4 responses across a broader range of counseling scenarios, including adversarial inputs and diverse cultural contexts, would reveal whether such problematic responses are isolated incidents or systematic issues requiring mitigation strategies.

### Open Question 2
- Question: Can LLM-based counseling systems maintain appropriate quality and safety when engaging in fully automated, multi-turn dialogues from start to finish?
- Basis in paper: The authors explicitly state that no experiments demonstrated a dialogue system with fully automatic counseling dialogue from start to finish, and they plan to evaluate this in future work.
- Why unresolved: The current study only evaluated individual responses in the context of role-play dialogues. The ability to maintain coherence, empathy, and appropriate boundaries across extended, multi-turn conversations remains untested.
- What evidence would resolve it: A deployed system that handles complete counseling sessions autonomously, with professional counselors evaluating the overall quality, safety, and effectiveness of the full dialogue rather than isolated responses.

### Open Question 3
- Question: How do cultural and linguistic differences impact the effectiveness and appropriateness of LLM-generated counseling responses?
- Basis in paper: The study was conducted using Japanese role-play dialogues and Japanese-speaking counselors, but the authors do not discuss whether their findings would generalize to other languages or cultural contexts.
- Why unresolved: The study's limited cultural and linguistic scope leaves open questions about whether the same prompts, guidelines, and evaluation criteria would yield similar results in different cultural settings where counseling norms and communication styles vary.
- What evidence would resolve it: Replicating the study with role-play dialogues in multiple languages and cultural contexts, with counselors from those cultures evaluating both the linguistic appropriateness and cultural sensitivity of the generated responses.

## Limitations
- Weak inter-rater agreement (Krippendorff's alpha of 0.24) suggests potential subjectivity in evaluation
- Role-play scenarios may not fully capture the complexity of real counseling sessions
- Evaluation conducted solely by professional counselors may introduce bias

## Confidence
- High confidence: GPT-4-generated responses are competitive with human counselors on average (p > 0.05)
- Medium confidence: Quality of individual responses given weak inter-rater agreement and identified issues with inappropriate phrasing
- Medium confidence: Absence of offensive content given limited evaluation scope

## Next Checks
1. Conduct a cross-validation study with a different set of professional counselors to assess the robustness of the evaluation methodology and improve inter-rater reliability.
2. Test GPT-4's responses in actual counseling sessions with informed clients to validate the findings from role-play scenarios and assess real-world applicability.
3. Implement an adversarial testing protocol to systematically evaluate the model's response to potentially problematic prompts and scenarios not covered in the original dataset.