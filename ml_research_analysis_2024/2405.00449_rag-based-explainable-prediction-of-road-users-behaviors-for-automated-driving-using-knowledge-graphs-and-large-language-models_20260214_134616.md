---
ver: rpa2
title: RAG-based Explainable Prediction of Road Users Behaviors for Automated Driving
  using Knowledge Graphs and Large Language Models
arxiv_id: '2405.00449'
source_url: https://arxiv.org/abs/2405.00449
tags:
- pedestrian
- vehicle
- road
- prediction
- lane
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents a neuro-symbolic system for predicting road\
  \ users\u2019 behaviors in autonomous driving scenarios, integrating Knowledge Graphs\
  \ (KGs) and Large Language Models (LLMs) using Retrieval Augmented Generation (RAG).\
  \ The approach combines Knowledge Graph Embeddings (KGE) with Bayesian inference\
  \ to enable inductive reasoning using both legacy graph data and real-time sensor\
  \ inputs."
---

# RAG-based Explainable Prediction of Road Users Behaviors for Automated Driving using Knowledge Graphs and Large Language Models

## Quick Facts
- arXiv ID: 2405.00449
- Source URL: https://arxiv.org/abs/2405.00449
- Authors: Mohamed Manzour Hussien; Angie Nataly Melo; Augusto Luis Ballardini; Carlota Salinas Maldonado; Rubén Izquierdo; Miguel Ángel Sotelo
- Reference count: 40
- Key outcome: RAG-based neuro-symbolic system predicts pedestrian crossing and lane change behaviors with F1-scores above 90%, providing explainable predictions through Knowledge Graphs, KGE, Bayesian inference, and fuzzy logic rules.

## Executive Summary
This paper presents a neuro-symbolic system for predicting road users' behaviors in autonomous driving scenarios, integrating Knowledge Graphs (KGs) and Large Language Models (LLMs) using Retrieval Augmented Generation (RAG). The approach combines Knowledge Graph Embeddings (KGE) with Bayesian inference to enable inductive reasoning using both legacy graph data and real-time sensor inputs. Two use cases—pedestrian crossing prediction and lane change prediction—are implemented. Results show superior performance compared to state-of-the-art methods, with F1-scores above 90% for both scenarios. The system also provides explainable predictions through fuzzy rules and RAG, offering insights into why certain behaviors are predicted.

## Method Summary
The proposed method extracts features from autonomous driving datasets (JAAD, PSI, HighD), converts them into linguistic categories, and constructs KGs using predefined ontologies. KGE models (ComplEx, TransE) learn continuous representations of KG triples, which are then used in Bayesian inference to predict road user behaviors. Fuzzy logic rules mined from training data enhance explainability by encoding domain expertise. RAG retrieves relevant KG triples and augments them with LLM-generated explanations. The system predicts pedestrian crossing actions and vehicle lane change maneuvers, evaluating performance using F1-score, precision, and recall metrics.

## Key Results
- Pedestrian crossing prediction achieves F1-score of 93.2% using PedFeatRulesKG (with fuzzy rules) vs. 90.1% for PedFeatKG (without fuzzy rules).
- Vehicle lane change prediction achieves F1-score of 92.5% on HighD dataset.
- RAG-generated explanations provide coherent and relevant insights into prediction decisions, enhancing system interpretability.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The system achieves explainable behavior predictions by integrating Knowledge Graph Embeddings (KGE) with Bayesian inference and RAG-based reasoning.
- **Mechanism:** KGE transforms structured road scene knowledge into continuous vector representations. Bayesian inference then calculates the probability of predicted behaviors (e.g., pedestrian crossing, lane change) conditioned on current sensor evidence. RAG augments these predictions with human-readable explanations by retrieving relevant contextual rules or linguistic descriptions.
- **Core assumption:** The Knowledge Graph ontology correctly encodes all relevant entities, relations, and reified triples for the targeted use cases.
- **Evidence anchors:**
  - [abstract] "Knowledge Graph Embeddings (KGE) and Bayesian inference are combined to allow the deployment of a fully inductive reasoning system"
  - [section III-C] Details on computing P(h|e) using reified triples from the graph
  - [corpus] Limited evidence for KGE+Bayesian systems in autonomous driving; most related work focuses on black-box DL models
- **Break condition:** If the KG ontology is incomplete or incorrectly defined, the Bayesian inference will propagate errors, leading to unreliable predictions.

### Mechanism 2
- **Claim:** Fuzzy logic rules enhance the robustness and explainability of predictions by encoding domain expertise.
- **Mechanism:** Fuzzy rule mining extracts human-like IF-THEN rules from training data (e.g., "IF pedestrian is near to curb AND looking forward THEN cross"). These rules are transformed into KG entities and linked to corresponding pedestrian instances. During inference, activated rules provide supporting evidence for predictions.
- **Core assumption:** Fuzzy rules mined from historical data accurately represent real-world pedestrian/driver behavior patterns.
- **Evidence anchors:**
  - [section IV-A] "fuzzy logic approach, characterized by its multi-valued nature that mirrors human thought and interpretation"
  - [section V-C] Results show PedFeatRulesKG (with fuzzy rules) outperforms PedFeatKG
  - [corpus] Fuzzy logic has been used in traffic modeling but integration with KG+Bayesian inference is novel
- **Break condition:** If the rule base is too sparse or overfitted to training data, predictions may lack generalizability or introduce bias.

### Mechanism 3
- **Claim:** RAG provides dynamic, context-aware explanations by combining KG embeddings with LLM-generated narratives.
- **Mechanism:** The RAG system retrieves relevant KG triples or rule descriptions based on current input features. These retrieved chunks are augmented with the query and fed to an LLM, which generates a concise explanation for the prediction.
- **Core assumption:** The retrieved KG triples are sufficiently relevant and the LLM prompt is well-structured to produce coherent explanations.
- **Evidence anchors:**
  - [section IV-B] Description of RAG workflow: retrieval → augmentation → generation
  - [section V-E] Example outputs show RAG explanations for pedestrian crossing decisions
  - [corpus] RAG is widely used for explainable NLP but application to autonomous driving predictions is emerging
- **Break condition:** If the retrieval module fails to find relevant triples, or the LLM generates inconsistent explanations, user trust may erode.

## Foundational Learning

- **Concept: Knowledge Graphs (KGs)**
  - Why needed here: KGs provide a structured, symbolic representation of road scenes, enabling reasoning over entities and relations (pedestrians, vehicles, roads, actions).
  - Quick check question: What are the three components of a KG triple? (Answer: subject, predicate, object)

- **Concept: Knowledge Graph Embeddings (KGE)**
  - Why needed here: KGE maps KG triples into low-dimensional vectors, allowing machine learning models to perform reasoning on continuous representations.
  - Quick check question: Which KGE model was used in the paper? (Answer: ComplEx and TransE)

- **Concept: Bayesian Inference**
  - Why needed here: Bayesian inference quantifies uncertainty in predictions by computing conditional probabilities given observed evidence, making the system more interpretable than pure ML classifiers.
  - Quick check question: What does P(h|e) represent in this context? (Answer: probability of hypothesis h given evidence e)

## Architecture Onboarding

- **Component map:**
  - Data Ingestion → Feature Extraction (DL models) → Linguistic Transformation → KG Construction → KGE Training → Bayesian Inference → RAG Explanation
  - KG Ontologies: PedFeatKG, PedFeatRulesKG, DriverKG
  - Libraries: AmpliGraph 2.0.0 (KGE), LangChain (RAG), PyTorch (feature extraction)

- **Critical path:** Feature extraction → KG construction → KGE training → Bayesian inference → prediction

- **Design tradeoffs:**
  - **Expressiveness vs. Efficiency:** Rich ontologies improve explainability but increase computational load for KGE training.
  - **Determinism vs. Generalization:** Fuzzy rules encode domain knowledge but may overfit to training scenarios.
  - **Static vs. Dynamic Knowledge:** KG stores historical knowledge, while RAG allows dynamic updates with new scenarios.

- **Failure signatures:**
  - Low F1-score with high precision → Overly conservative predictions, possibly due to sparse rule base
  - Inconsistent RAG explanations → Retrieval module failing to match relevant triples
  - Slow inference time → Overly large KG or inefficient KGE model

- **First 3 experiments:**
  1. **Sanity check:** Verify KG construction by manually inspecting a few triples and their embeddings.
  2. **Ablation study:** Compare PedFeatKG vs. PedFeatRulesKG to quantify the impact of fuzzy rules on prediction accuracy.
  3. **RAG quality test:** Generate predictions for a small test set and evaluate RAG explanations for coherence and correctness.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the RAG-based explainable prediction system vary across different cultural contexts and regions, and what specific factors contribute to these variations?
- Basis in paper: [explicit] The paper mentions that the proposed system will be tested in regions with different social rules, such as the MENA region, South-East Asia, and Latin America, to understand road users' behaviors in a more holistic manner.
- Why unresolved: The paper does not provide experimental results or analysis of the system's performance in different cultural contexts.
- What evidence would resolve it: Comparative experimental results showing the system's performance across different regions and cultural contexts, along with an analysis of the factors contributing to any variations in performance.

### Open Question 2
- Question: What are the limitations of the current knowledge graph embedding models (TransE and ComplEx) used in the proposed system, and how could alternative embedding models improve the accuracy and robustness of behavior predictions?
- Basis in paper: [explicit] The paper uses TransE and ComplEx models for knowledge graph embeddings but does not discuss their limitations or explore alternative models.
- Why unresolved: The paper does not provide a comparative analysis of different embedding models or discuss their potential impact on the system's performance.
- What evidence would resolve it: A comparative study of various knowledge graph embedding models, including their strengths and weaknesses, and an analysis of how alternative models could enhance the system's predictive capabilities.

### Open Question 3
- Question: How does the integration of the proposed predictive system with the behavior planner of an autonomous vehicle affect the overall safety and comfort of the driving experience, and what are the potential challenges in achieving seamless integration?
- Basis in paper: [explicit] The paper mentions that the proposed predictive system will be integrated with the behavior planner of an autonomous vehicle to make AVs behave in a more human-like fashion.
- Why unresolved: The paper does not provide details on the integration process, potential challenges, or the impact on safety and comfort.
- What evidence would resolve it: Experimental results and analysis of the integrated system's performance, including safety metrics, comfort assessments, and a discussion of the challenges faced during integration.

## Limitations

- The system's performance relies heavily on the completeness and correctness of the Knowledge Graph ontology.
- F1-scores above 90% are based on relatively small, domain-specific datasets (JAAD, PSI, HighD).
- The Bayesian inference framework assumes all relevant features are captured in KG triples, which may not hold for complex, real-world scenarios.

## Confidence

- **Mechanism Understanding:** Medium - The mechanism is well-articulated and the results are promising, but the evaluation lacks robustness testing on out-of-distribution data.
- **Reproducibility:** Low - Specific implementation details for feature extraction and ontology structure are not fully specified.
- **Generalizability:** Medium - The system shows strong performance on targeted datasets but has not been tested across diverse cultural contexts or novel scenarios.

## Next Checks

1. Test system performance on a held-out, out-of-distribution dataset to assess generalization.
2. Conduct ablation studies to quantify the individual contributions of KGE, Bayesian inference, fuzzy rules, and RAG to overall performance.
3. Perform human evaluation of RAG-generated explanations for coherence, relevance, and helpfulness.