---
ver: rpa2
title: The Parameters of Educability
arxiv_id: '2412.09480'
source_url: https://arxiv.org/abs/2412.09480
tags:
- parameters
- learning
- some
- educability
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper discusses the parameters of the educability model, a
  computational model proposed to describe the cognitive capability that makes humans
  unique in creating advanced civilizations. Educability is defined as the capability
  for acquiring and applying knowledge.
---

# The Parameters of Educability

## Quick Facts
- arXiv ID: 2412.09480
- Source URL: https://arxiv.org/abs/2412.09480
- Authors: Leslie G. Valiant
- Reference count: 6
- The paper identifies multiple parameters in the educability model that cannot be reduced to a single metric for evaluating cognitive performance.

## Executive Summary
The paper discusses the parameters of the educability model, a computational framework that describes human civilization-enabling cognition through three pillars: learning from experience, being teachable by instruction, and chaining theories. Educability is defined as the capability for acquiring and applying knowledge, and the paper argues that this system has many parameters that must be considered when implementing it in either biological or machine systems. Five key parameters are discussed in detail: Belief Choice, Belief Verification, Teaching to Reason, Management Rules for the Mind's Eye, and New Concept Formation.

## Method Summary
This theoretical paper builds on the original educability model [V24] to identify and analyze the key parameters of the educability system. The method involves conceptual analysis of how different parameters affect system behavior, with particular focus on how parameter choices impact the ability to learn, reason, and apply knowledge. The paper does not provide empirical implementation but rather establishes a framework for understanding the design space of educable systems.

## Key Results
- Educability systems have multiple parameters that prevent meaningful single-metric evaluation of cognitive performance
- Standalone educable systems require Belief Choice policies due to limited verification capabilities
- The multiplicity of parameters is a fundamental feature of human cognition rather than an incidental characteristic

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Educability is defined as a computational model that captures human civilization-enabling cognition through three pillars: learning from experience, being teachable by instruction, and chaining theories.
- Mechanism: The model uses scalable computational frameworks (PAC learning for experience, Turing computation for instruction, Robust Logic for chaining) that can be mathematically specified and efficiently realized, providing a behavioral definition analogous to learning from examples.
- Core assumption: That human cognitive capabilities can be decomposed into these three mathematically definable components that together capture civilization-building capacity.
- Evidence anchors:
  - [abstract] The educability model is a computational model that has been recently proposed to describe the cognitive capability that makes humans unique among existing biological species on Earth in being able to create advanced civilizations. Educability is defined as a capability for acquiring and applying knowledge.
  - [section] The notion of intelligence has never received a widely accepted behavioral definition. We believe that, for that reason, intelligence has not been a particularly useful notion for understanding either humans or machines. On the other hand, the notion of learning has been useful for understanding machines.
- Break condition: If any of the three pillars cannot be mathematically specified or efficiently realized, or if human cognition involves capabilities beyond these three that are essential for civilization-building.

### Mechanism 2
- Claim: The multiplicity of parameters in educability systems is a fundamental feature that prevents meaningful single-metric evaluation of cognitive performance.
- Mechanism: Because educability systems have numerous parameters (Belief Choice, Belief Verification, Teaching to Reason, Management Rules for the Mind's Eye, New Concept Formation, plus additional ones), each choice affects system behavior differently, making any single metric like IQ or AGI inadequate for evaluation.
- Core assumption: That the variety of educational choices and parameters available in human education mirrors the variety available in machine educability systems, and that this variety is not merely incidental but fundamental to the nature of cognition.
- Evidence anchors:
  - [section] The multiplicity of parameters is strongly hinted at by the broad variation found in human cognitive activity. Cognitive performance of an educated entity cannot be measured along a one-dimensional axis because of the innumerable parameters or choices made in the education process.
  - [section] If there is no universally optimal policy even in just this one parameter, then it already follows that there is no unique metric of a human being "intelligent" or "smart".
- Break condition: If a single parameter combination could be proven universally optimal across all environments and tasks, or if cognitive performance could be meaningfully reduced to a single dimension.

### Mechanism 3
- Claim: Standalone educable systems require Belief Choice policies because they cannot verify all external information directly, creating a fundamental vulnerability balanced against powerful information absorption capabilities.
- Mechanism: Since standalone systems can alter behavior based on external information but have limited resources for verification, they must implement policies for deciding which sources to trust, using either source-dependent strategies (authority figures, social groups) or content-dependent strategies (cognitive dissonance, cultural cognition).
- Core assumption: That standalone systems (both biological and machine) face the same fundamental problem of limited verification capability when absorbing information from their environment.
- Evidence anchors:
  - [section] Once a standalone system, whether a biological entity or a machine, can alter its behavior based on information it receives from its environment it needs a policy for determining which external information it should allow to change its behavior and which not.
  - [section] We believe that this gap for humans is not just an unfortunate omission of human evolution but something that is fundamentally difficult to overcome.
- Break condition: If standalone systems develop verification capabilities that make Belief Choice policies unnecessary, or if all external information becomes trivially verifiable.

## Foundational Learning

- Concept: PAC Learning (Probably Approximately Correct)
  - Why needed here: Forms the foundation for pillar (A) of educability - learning from experience through examples, providing a behavioral definition that can be mathematically specified and efficiently realized
  - Quick check question: What does PAC learning guarantee about the learned classifier's performance on new examples?

- Concept: Turing Computation
  - Why needed here: Underpins pillar (B) of educability - being teachable by instruction through explicit formulas, recipes, or programs that can be executed by a universal machine
  - Quick check question: How does Turing computation provide robustness through the fact that many variants have been shown to have the same power?

- Concept: Robust Logic and Mind's Eye
  - Why needed here: Enables pillar (C) of educability - chaining and applying theories through a flexible representation system where multiple objects and their relationships can be processed and updated
  - Quick check question: How does the Mind's Eye representation differ from traditional symbolic logic in handling complex situations with multiple objects and relationships?

## Architecture Onboarding

- Component map: PAC Learning -> Turing Computation -> Robust Logic with Mind's Eye, plus Belief Choice policies, Belief Verification methods, Teaching to Reason mechanisms, Management Rules for the Mind's Eye, and New Concept Formation mechanisms
- Critical path: 1) Define base attributes/concepts the system recognizes initially. 2) Implement PAC learning for experience-based knowledge acquisition. 3) Implement Turing computation for instruction-based knowledge absorption. 4) Implement Robust Logic with Mind's Eye for chaining and applying knowledge. 5) Define Belief Choice policies for handling external information. 6) Define Belief Verification methods for direct validation. 7) Define Teaching to Reason mechanisms. 8) Define Management Rules for the Mind's Eye. 9) Define New Concept Formation mechanisms.
- Design tradeoffs: Memory vs. processing speed (affecting how many tokens can be in the Mind's Eye simultaneously), computational efficiency vs. expressive power (affecting what can be represented and reasoned about), trust vs. verification (affecting how much external information is accepted without validation), and generality vs. specificity (affecting how broadly or narrowly the system can apply learned knowledge).
- Failure signatures: Inability to learn from new examples (PAC learning failure), failure to execute taught rules correctly (Turing computation failure), inability to chain knowledge or apply it to new situations (Robust Logic failure), poor decision-making about information sources (Belief Choice failure), failure to detect false beliefs (Belief Verification failure), inability to learn new reasoning methods (Teaching to Reason failure), inefficient or incorrect management of working memory (Mind's Eye failure), inability to form new concepts (New Concept Formation failure).
- First 3 experiments:
  1. Test PAC learning pillar with a simple concept learning task (e.g., learning to classify shapes) to verify that experience-based learning works as specified
  2. Test Turing computation pillar by teaching a simple rule (e.g., arithmetic operation) and verifying it can be executed correctly on new inputs
  3. Test Belief Choice policy by presenting conflicting information from different sources and verifying the system makes reasonable trust decisions based on source characteristics

## Open Questions the Paper Calls Out

- Question: What is the optimal policy for Belief Choice in different environments?
  - Basis in paper: [explicit] The paper states "The best policy appears to depend on the environment in which the individual operates."
  - Why unresolved: The paper identifies that different environments may require different Belief Choice policies, but does not specify what these optimal policies are for different scenarios.
  - What evidence would resolve it: Empirical studies comparing performance of different Belief Choice policies in various simulated or real-world environments.

- Question: Can human educability be improved through targeted interventions?
  - Basis in paper: [explicit] The paper lists this as one of the important questions it does not address: "Can human educability be improved by some intervention?"
  - Why unresolved: The paper acknowledges this as an open question but does not explore it, suggesting it remains an area for future research.
  - What evidence would resolve it: Longitudinal studies comparing educability metrics before and after various educational interventions or cognitive training programs.

- Question: How did the educability capability evolve in humans?
  - Basis in paper: [explicit] The paper lists this as one of the important questions it does not address: "How did this educability capability come together in the course of human evolution?"
  - Why unresolved: The paper identifies this as a key question about the origins of educability but does not provide an answer, indicating it is still unknown.
  - What evidence would resolve it: Comparative studies of cognitive capabilities across primate species, combined with archaeological evidence of tool use and cultural transmission in early humans.

## Limitations

- The theoretical nature of the paper means many parameters are described conceptually rather than with concrete implementations
- The relationship between the five detailed parameters and practical systems remains largely speculative with limited empirical validation
- Additional parameters beyond the five discussed likely exist but are not comprehensively enumerated

## Confidence

- **High Confidence**: The core argument that educability involves multiple parameters that prevent meaningful single-metric evaluation. This follows logically from the basic premise that human cognition involves diverse capabilities.
- **Medium Confidence**: The five specific parameters discussed (Belief Choice, Belief Verification, Teaching to Reason, Management Rules for the Mind's Eye, New Concept Formation) are presented as important but their relative importance and optimal configurations are not empirically established.
- **Low Confidence**: Claims about which parameter configurations are universally optimal or suboptimal across different domains and contexts.

## Next Checks

1. **Implement a simple educability system** with configurable parameters for Belief Choice and Belief Verification, then test how different parameter combinations affect performance on tasks requiring integration of external information.

2. **Conduct a literature review** to identify documented examples of how different human educational systems make different choices for the five parameters discussed, and analyze the outcomes in terms of cognitive performance metrics.

3. **Develop a formal framework** for mapping the conceptual parameters described in this paper to measurable quantities in existing machine learning systems, enabling empirical testing of parameter effects on system performance.