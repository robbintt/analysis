---
ver: rpa2
title: Adversarial-Robust Transfer Learning for Medical Imaging via Domain Assimilation
arxiv_id: '2402.16005'
source_url: https://arxiv.org/abs/2402.16005
tags:
- images
- medical
- learning
- texture
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the vulnerability of AI-based medical image
  diagnosis models to adversarial attacks, which exploit domain discrepancies between
  natural and medical images in transfer learning. The authors propose a domain assimilation
  approach that introduces texture and color adaptation into transfer learning, followed
  by a texture preservation component using Gray-Level Co-occurrence Matrix (GLCM)
  loss to suppress undesired distortion.
---

# Adversarial-Robust Transfer Learning for Medical Imaging via Domain Assimilation

## Quick Facts
- arXiv ID: 2402.16005
- Source URL: https://arxiv.org/abs/2402.16005
- Reference count: 32
- Primary result: Domain assimilation approach enhances adversarial robustness of transfer learning models for medical imaging while maintaining accuracy

## Executive Summary
This paper addresses the vulnerability of AI-based medical image diagnosis models to adversarial attacks, which exploit domain discrepancies between natural and medical images in transfer learning. The authors propose a domain assimilation approach that introduces texture and color adaptation into transfer learning, followed by a texture preservation component using Gray-Level Co-occurrence Matrix (GLCM) loss to suppress undesired distortion. Experiments across multiple modalities (MRI, CT, X-ray, Ultrasound) show that the proposed method effectively enhances model robustness against various adversarial attacks (FGSM, BIM, PGD, MIFGSM) while maintaining competitive accuracy.

## Method Summary
The approach combines a texture-color adaptation module that dynamically learns parameters to transform grayscale medical images into RGB format, making them compatible with pretrained models. A GLCM loss component preserves essential texture information during this transformation by minimizing the distance between second-order texture features (ASM, Contrast, Homogeneity, Correlation, Dissimilarity) of original and colorized images. The model is fine-tuned on medical datasets with this loss weighted at α=0.98, balancing cross-entropy and texture preservation objectives.

## Key Results
- Models maintain ~90% accuracy under most attacks with small perturbations (epsilon=1/255), compared to <20% for baseline models
- Texture-color adaptation increases difficulty of generating successful attacks across all tested modalities
- Ultrasound images show highest sensitivity to adaptation due to complex texture patterns
- The approach demonstrates consistent robustness improvements across multiple backbone architectures (ResNet18, ResNet50, DenseNet121)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain discrepancy between natural and medical images makes transfer learning vulnerable to adversarial attacks
- Mechanism: Natural images have more color variation and complex textures, while medical images are grayscale with monotonic biological textures. This mismatch causes models to learn irrelevant attention regions and sharp loss landscapes that are easier to exploit
- Core assumption: The domain gap between natural and medical images is significant enough to impact adversarial robustness
- Evidence anchors:
  - [abstract] "However, a significant domain discrepancy exists between natural and medical images, which causes AI models resulting from transfer learning to exhibit heightened vulnerability to adversarial attacks"
  - [section] "natural and medical images have inherent differences from each other, forming a gap that is largely overlooked when applying transfer learning"
  - [corpus] Weak evidence - no direct corpus mentions of domain discrepancy impact on robustness
- Break condition: If medical images have sufficient color and texture variation similar to natural images, the domain gap would be minimal

### Mechanism 2
- Claim: Texture-color adaptation module reduces domain discrepancy by transforming medical images to resemble natural images
- Mechanism: The module learns to generate RGB images from grayscale medical images while preserving texture information through GLCM loss, making them more compatible with pretrained models
- Core assumption: Transforming medical images to look more like natural images will improve robustness without sacrificing accuracy
- Evidence anchors:
  - [abstract] "This paper proposes a domain assimilation approach that introduces texture and color adaptation into transfer learning"
  - [section] "Our proposed approach consists of a texture-color adaptation module that dynamically learns parameters in conjunction with pretrained models"
  - [corpus] Weak evidence - no corpus mentions of texture-color adaptation specifically
- Break condition: If the adaptation process introduces too much distortion or loses critical diagnostic information

### Mechanism 3
- Claim: GLCM loss preserves essential texture information during colorization to prevent misdiagnosis
- Mechanism: The loss function measures the distance between second-order texture features (ASM, Contrast, Homogeneity, Correlation, Dissimilarity) of original and colorized images, minimizing distortion
- Core assumption: Second-order texture statistics are sufficient to capture essential diagnostic features
- Evidence anchors:
  - [abstract] "To prevent over-adaptation, which can lead to the loss of essential information in medical images and result in misdiagnoses, we introduce a novel Gray-Level Co-occurrence Matrix (GLCM) loss"
  - [section] "GLCM loss is propagated backward through the entire network for updating parameters"
  - [corpus] Weak evidence - no corpus mentions of GLCM loss for medical imaging robustness
- Break condition: If texture information is not critical for the specific medical diagnosis task

## Foundational Learning

- Concept: Gray-Level Co-occurrence Matrix (GLCM) texture analysis
  - Why needed here: Provides quantitative measures of texture preservation during colorization to ensure diagnostic features aren't lost
  - Quick check question: What are the five second-order texture features calculated from GLCM matrices?

- Concept: Adversarial attack types (FGSM, BIM, PGD, MIFGSM)
  - Why needed here: Understanding attack mechanisms helps evaluate robustness improvements and identify vulnerabilities
  - Quick check question: How does iterative gradient ascent in PGD differ from single-step FGSM?

- Concept: Transfer learning domain adaptation
  - Why needed here: Explains why models trained on natural images need modification for medical imaging tasks
  - Quick check question: What is the primary challenge when applying ImageNet-pretrained models to medical images?

## Architecture Onboarding

- Component map: Input → Texture Module → Color Module → Pretrained Backbone → Classifier, with GLCM loss branch from Color Module to original image
- Critical path: Color Module output → Pretrained Backbone → Classification, with texture preservation through GLCM loss
- Design tradeoffs: More aggressive colorization improves naturalness but risks losing texture; GLCM loss preserves texture but limits color variation
- Failure signatures: Model accuracy drops significantly on ultrasound images; adversarial attacks succeed at lower perturbation levels; texture-color adaptation introduces artifacts
- First 3 experiments:
  1. Train with only texture module, evaluate accuracy and texture preservation on a small medical dataset
  2. Add color module without GLCM loss, compare natural appearance vs. diagnostic accuracy
  3. Implement full pipeline with GLCM loss, test against FGSM attacks with epsilon=1/255

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different GLCM distance and orientation parameters affect the effectiveness of texture preservation across different medical imaging modalities?
- Basis in paper: [explicit] The paper mentions using distance=3 for 8 orientations but notes ultrasound images contain more complex textures that were too sensitive to adaptation
- Why unresolved: The paper only tested one specific GLCM configuration (distance=3, 8 orientations) without exploring parameter sensitivity or modality-specific optimization
- What evidence would resolve it: Systematic experiments varying GLCM distance parameters and orientations across all four modalities, comparing attack robustness and accuracy

### Open Question 2
- Question: Can the domain assimilation approach be extended to other medical imaging tasks beyond classification, such as segmentation or object detection?
- Basis in paper: [inferred] The paper focuses exclusively on classification tasks but mentions that texture analysis is important for "classification and segmentation" in the preliminaries
- Why unresolved: The methodology was only evaluated on binary classification tasks, leaving open whether the texture-color adaptation approach generalizes to other medical imaging problems
- What evidence would resolve it: Application and evaluation of the same approach on segmentation or detection tasks with similar adversarial robustness metrics

### Open Question 3
- Question: What is the computational overhead of the domain assimilation approach during inference compared to standard transfer learning?
- Basis in paper: [inferred] The paper mentions the architecture includes additional texture and color modules but doesn't report inference time or computational cost
- Why unresolved: While training was performed on GPU, the paper doesn't address whether the additional modules create significant latency in clinical deployment scenarios
- What evidence would resolve it: Benchmark comparisons of inference time and computational requirements between baseline models and adapted models on representative hardware

## Limitations
- Limited dataset diversity (only 4 medical imaging modalities)
- No comparison with other domain adaptation techniques for robustness
- Unclear generalization to multi-class or more complex diagnostic tasks
- No real-world adversarial attack validation on deployed systems

## Confidence
**High confidence** in the core observation that transfer learning from natural to medical images creates robustness vulnerabilities to adversarial attacks. The empirical results showing accuracy degradation under attacks (from ~90% clean accuracy to <20% under attacks for baseline models) are well-supported and reproducible.

**Medium confidence** in the proposed domain assimilation mechanism. While the general approach of texture-color adaptation is sound, the specific implementation details of the texture and color modules are underspecified in the paper. The GLCM loss formulation is clearly defined, but its effectiveness depends heavily on proper implementation of the texture adaptation module.

**Medium confidence** in the GLCM-based texture preservation approach. The use of second-order texture features is methodologically sound, but the paper lacks ablation studies showing whether other texture preservation methods would work equally well. The assumption that second-order statistics are sufficient for medical diagnosis may not hold for all modalities.

## Next Checks
1. Implement ablation study removing GLCM loss to quantify its contribution to robustness vs. accuracy trade-off
2. Test the approach on additional medical imaging datasets (e.g., dermatology, pathology) to assess generalization
3. Compare against alternative domain adaptation methods (e.g., adversarial domain adaptation, style transfer) for adversarial robustness