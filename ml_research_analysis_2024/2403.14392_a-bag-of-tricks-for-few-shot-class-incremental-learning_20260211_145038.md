---
ver: rpa2
title: A Bag of Tricks for Few-Shot Class-Incremental Learning
arxiv_id: '2403.14392'
source_url: https://arxiv.org/abs/2403.14392
tags:
- classes
- learning
- tricks
- incremental
- stability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a framework for few-shot class-incremental
  learning (FSCIL) that improves both stability and adaptability. The method combines
  six key techniques grouped into stability tricks (supervised contrastive loss, pre-assigning
  prototypes, pseudo-classes), adaptability tricks (incremental fine-tuning with subnet
  tuning), and training tricks (pre-training, additional learning signals).
---

# A Bag of Tricks for Few-Shot Class-Incremental Learning

## Quick Facts
- arXiv ID: 2403.14392
- Source URL: https://arxiv.org/abs/2403.14392
- Authors: Shuvendu Roy; Chunjong Park; Aldi Fahrezi; Ali Etemad
- Reference count: 32
- Key outcome: Achieves state-of-the-art results on CIFAR-100, CUB-200, and miniImageNet with 3.22%, 1.1%, and 2.0% improvements respectively

## Executive Summary
This paper presents a comprehensive framework for few-shot class-incremental learning (FSCIL) that addresses the stability-adaptability dilemma. The approach combines six key techniques grouped into stability tricks (supervised contrastive loss, pre-assigning prototypes, pseudo-classes), adaptability tricks (incremental fine-tuning with subnet tuning), and training tricks (pre-training, additional learning signals). The unified framework significantly outperforms prior works across multiple benchmark datasets, achieving 3.22%, 1.1%, and 2.0% improvements on CIFAR-100, CUB-200, and miniImageNet respectively.

## Method Summary
The framework integrates six techniques to balance stability and adaptability in FSCIL. Stability tricks include supervised contrastive loss for better feature discrimination, pre-assigning prototypes to maintain class representations, and pseudo-classes to preserve old knowledge. Adaptability tricks involve incremental fine-tuning with selective subnet tuning to adapt to new classes. Training tricks encompass pre-training on base classes and additional learning signals to improve feature quality. These components are combined into a unified training pipeline that processes base classes first, then incrementally learns new classes while preserving old knowledge through the proposed tricks.

## Key Results
- Achieves 3.22%, 1.1%, and 2.0% improvements over state-of-the-art on CIFAR-100, CUB-200, and miniImageNet respectively
- Demonstrates effectiveness across different model sizes and shot settings
- Shows robust performance through extensive ablation studies of individual components

## Why This Works (Mechanism)
The framework addresses the fundamental challenge in FSCIL where models must balance learning new classes without forgetting old ones. The stability tricks prevent catastrophic forgetting by maintaining discriminative features and preserving old knowledge representations. The adaptability tricks enable effective learning of new classes through selective fine-tuning mechanisms. The training tricks improve overall feature quality and learning efficiency. Together, these components create a synergistic effect that outperforms individual techniques.

## Foundational Learning
- Few-shot learning: Why needed - enables learning from limited examples; Quick check - measure performance with varying shot numbers
- Class-incremental learning: Why needed - simulates real-world scenarios where data arrives sequentially; Quick check - evaluate forgetting of old classes
- Contrastive learning: Why needed - improves feature discrimination between classes; Quick check - measure feature separability
- Catastrophic forgetting: Why needed - understanding forgetting mechanisms guides stability techniques; Quick check - track performance degradation on old classes
- Prototype-based classification: Why needed - provides stable class representations; Quick check - measure prototype drift over time
- Knowledge distillation: Why needed - transfers knowledge from old to new models; Quick check - evaluate knowledge preservation metrics

## Architecture Onboarding

Component Map:
Base Classes -> Pre-training -> Incremental Steps -> Stability Tricks -> Adaptability Tricks -> Final Model

Critical Path:
The critical path follows the training sequence: pre-train on base classes, then process each incremental step with stability and adaptability tricks applied in parallel to maintain both old and new class knowledge.

Design Tradeoffs:
The framework trades computational complexity for performance gains. Multiple techniques are applied sequentially and in parallel, increasing training time but significantly improving accuracy. The choice of when to apply each trick balances stability and adaptability requirements.

Failure Signatures:
Performance degradation on old classes indicates insufficient stability tricks. Poor performance on new classes suggests inadequate adaptability mechanisms. High computational overhead may indicate inefficient implementation of multiple tricks.

First Experiments:
1. Baseline comparison without any tricks to establish performance floor
2. Individual trick ablation to measure contribution of each component
3. Incremental step size sensitivity analysis to determine optimal learning pace

## Open Questions the Paper Calls Out
None

## Limitations
- Performance improvements evaluated primarily on benchmark datasets, limiting generalization to real-world scenarios
- Assumes fixed number of shots per class and incremental steps, which may not reflect practical deployment conditions
- Computational overhead and memory requirements of proposed techniques not extensively discussed

## Confidence
- High confidence in technical implementation and experimental methodology
- Medium confidence in generalization across diverse datasets beyond standard benchmarks
- Medium confidence in stability-adaptability claims without testing on edge cases

## Next Checks
1. Evaluate framework on more diverse and challenging datasets to test robustness beyond standard benchmarks
2. Analyze computational and memory overhead of proposed techniques when scaling to larger models or datasets
3. Test framework under varying incremental step sizes and shot numbers to assess adaptability to non-standard scenarios