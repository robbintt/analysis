---
ver: rpa2
title: When and how can inexact generative models still sample from the data manifold?
arxiv_id: '2508.07581'
source_url: https://arxiv.org/abs/2508.07581
tags:
- generative
- score
- support
- vector
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates why some generative models can still sample
  from the data manifold even when the learned vector field has errors. The authors
  take a dynamical systems approach to analyze the robustness of the support under
  perturbations to the generating process.
---

# When and how can inexact generative models still sample from the data manifold?

## Quick Facts
- arXiv ID: 2508.07581
- Source URL: https://arxiv.org/abs/2508.07581
- Reference count: 18
- Key outcome: The paper proves that infinitesimal errors in generative models cause density shifts only along the data manifold, and that Lyapunov vector alignment with tangent spaces enables this robustness.

## Executive Summary
This paper investigates why some generative models can still sample from the data manifold even when the learned vector field has errors. The authors take a dynamical systems approach to analyze the robustness of the support under perturbations to the generating process. They show that infinitesimal learning errors cause the predicted density to differ from the target density only on the data manifold for a wide class of generative models. Further, they prove that the alignment of the top Lyapunov vectors with the tangent spaces along the boundary of the data manifold leads to this robustness.

## Method Summary
The authors analyze generative models as dynamical systems, focusing on how infinitesimal errors in the learned vector field affect the support of the generated distribution. They use statistical response theory to show that density perturbations remain on-support for infinitesimal errors, and Lyapunov analysis to identify when models exhibit this robustness. The method involves computing finite-time Lyapunov vectors via QR decomposition of the Jacobian along trajectories, then verifying alignment with the data manifold's tangent space. Experimental validation uses synthetic 2D data (two moons) and real datasets (MNIST, CIFAR-10).

## Key Results
- Infinitesimal learning errors cause predicted density to differ from target density only on the data manifold
- Alignment of top Lyapunov vectors with tangent spaces along the boundary enables robustness
- Compression toward the data manifold automatically produces Lyapunov alignment under certain conditions
- Flow matching models show less robustness than score-based models due to weaker attraction conditions

## Why This Works (Mechanism)

### Mechanism 1: Statistical Response Confinement
- Claim: Infinitesimal errors in the learned vector field produce density perturbations supported only where the target density is non-zero.
- Mechanism: The statistical response operator propagates perturbations through the transfer operator. Integration by parts reveals that response field u(ρ_τ) is proportional to ρ_τ itself, so mass only shifts where ρ_τ ≠ 0.
- Core assumption: The target density is absolutely continuous and Ft ∈ C¹(R^D).
- Evidence anchors: [abstract] "infinitesimal learning errors cause the predicted density to be different from the target density only on the data manifold for a wide class of generative models"; [section 3] Equation 2 shows u(ρ_τ)(x) = -ρ_τ(x) × [sum over time of divergence terms].
- Break condition: Large (non-infinitesimal) perturbations; non-compact support; discontinuous dynamics.

### Mechanism 2: Lyapunov Vector Alignment with Data Manifold
- Claim: When the top d-dimensional Lyapunov subspace spans the tangent space Tx∂M at the support boundary, the model exhibits robustness of support.
- Mechanism: Finite-time Lyapunov vectors represent most sensitive perturbation directions. Alignment means these sensitive directions lie tangent to the manifold, so errors cannot push samples off-support.
- Core assumption: The target score is orthogonal to the tangent space of the boundary manifold.
- Evidence anchors: [abstract] "alignment of the top Lyapunov vectors (most sensitive infinitesimal perturbation directions) with the tangent spaces along the boundary of the data manifold leads to robustness"; [section 4] Definition 4.2 formalizes alignment; Proposition 4.1 proves it enables support prediction.
- Break condition: Non-attractive dynamics; degenerate Lyapunov spectrum (non-unique leading eigenvectors).

### Mechanism 3: Compression-Induced Alignment
- Claim: Sufficient attraction toward the data manifold automatically produces Lyapunov alignment.
- Mechanism: When the vector field has large compression normal to the manifold and small cross-derivatives near the end of generation, the tangent dynamics decompose into fast (normal) and slow (tangential) modes. The slow modes dominate the top Lyapunov subspace.
- Core assumption: Conditions (i)-(iii) in Theorem 4.3—expansion phase followed by uniform attraction with bounded second derivatives and negligible cross-derivatives.
- Evidence anchors: [section 4] Theorem 4.3 provides sufficient conditions; proof shows how score components along Ed_t become negligible; [Figure 1, columns 1-2] Score field visibly orthogonal to support; [Figure 2, bottom] Lyapunov spectrum shows gap at index ≈ intrinsic dimension.
- Break condition: Non-compressive dynamics; large cross-derivatives ∇_{t,d⊥} v_{t,d} or ∇_{t,d} v_{t,d⊥}; early stopping before attraction phase completes.

## Foundational Learning

- Concept: **Lyapunov Exponents and Vectors**
  - Why needed here: The paper's core mechanism relies on finite-time Lyapunov vectors as the principal deformation directions. Without understanding how dF^τ characterizes stability, the alignment criterion is opaque.
  - Quick check question: Given a time-varying Jacobian dF_t along a trajectory, can you compute the QR decomposition iteratively to extract stretching factors and principal directions?

- Concept: **Transfer (Frobenius-Perron) Operator**
  - Why needed here: The statistical response analysis uses the pushforward operator L_t to propagate density perturbations. Understanding L_t ρ = ρ ∘ F^{-1}_t / |det dF_t| ∘ F^{-1}_t is essential.
  - Quick check question: If F maps x → 2x, what is L acting on a density ρ(x)?

- Concept: **Score-Based Generative Models as Dynamical Systems**
  - Why needed here: The paper treats SGMs, flow matching, and related models uniformly as non-autonomous dynamical systems Ft(x) = x + δ_t v_t(x). The reverse process and its discretization are the objects of analysis.
  - Quick check question: In a diffusion model, what is the relationship between the forward noising process and the reverse denoising process's drift term?

## Architecture Onboarding

- Component map:
  Score/drift network v_t(x) -> Time integration (Euler-Maruyama/ODE solver) -> Lyapunov computation (QR decomposition) -> Perturbation injection

- Critical path:
  1. Train score network on target samples
  2. Generate samples via reverse process F^τ
  3. Compute finite-time Lyapunov vectors by QR decomposition of accumulated dF_t
  4. Verify alignment: compute |score · LV_top| at generated samples
  5. Inject perturbations χ_t and observe whether density shifts tangent to support

- Design tradeoffs:
  - Diffusion vs. Flow Matching: Flow matching variants are less robust than SGMs for the same target
  - Noise schedule: Cosine schedule used empirically; different schedules affect discretization error but not fundamental robustness
  - Early stopping: Δ parameter avoids score singularity near t=0 but truncates attraction phase

- Failure signatures:
  - Non-robust models: Lyapunov vectors not aligned with support; perturbations push density into low-probability regions
  - Positive leading LEs: In non-robust models, some sample paths show expansion in sensitive directions
  - No spectral gap: If Lyapunov spectrum is continuous without gap at intrinsic dimension, superstability off-manifold is absent

- First 3 experiments:
  1. 2D two-moons with analytical scores: Compute exact score via quadrature, generate samples, compute LVs, verify alignment visually and via dot product histogram. Perturb score and confirm density shifts along moons.
  2. MNIST Lyapunov spectrum: Train DDPM on MNIST, compute LEs along trajectories, identify gap at index ≈20 (intrinsic dimension). Perturb along LV_1 vs. LV_100 and observe image quality degradation pattern.
  3. Alignment comparison across models: Train diffusion, OT-CFM, and stochastic interpolant on same 2D target. Compare robustness and alignment. Correlate alignment quality with Theorem 4.3 conditions.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Are the sufficient conditions for alignment (specifically regarding the anisotropy of vector field derivatives and contraction factors) also necessary for the robustness of support?
- Basis in paper: [explicit] The authors state in the "Conclusion and limitations" section: "We only provide a sufficient condition and not a necessary condition for alignment and hence robustness."
- Why unresolved: The current proof relies on a specific set of bounds for the derivatives of the drift vector field, but it is possible that robustness could emerge from other dynamical structures not captured by these assumptions.
- What evidence would resolve it: A theoretical derivation showing that violation of these conditions invariably leads to non-robustness, or a counter-example of a robust generative model that violates the conditions.

### Open Question 2
- Question: Can the degree of alignment between Lyapunov vectors and the data manifold distinguish between models that generalize versus those that memorize the training data?
- Basis in paper: [explicit] The authors note in the limitations that "our results do not explicitly reveal insight into memorization."
- Why unresolved: Memorization involves fitting to specific sample points rather than the underlying geometry; it is unknown if the tangent space geometry extracted via Lyapunov vectors remains consistent or degrades in memorization regimes.
- What evidence would resolve it: Empirical analysis comparing the Lyapunov spectra and alignment metrics of models trained with varying capacities or regularization strengths known to induce memorization.

### Open Question 3
- Question: Is the alignment of Lyapunov vectors with the data manifold a universal phenomenon, or is it specific to score-based generative models (SGMs) and certain flow-matching variants?
- Basis in paper: [explicit] The authors call for "More extensive experimentation with various different generative models... to determine the most common scenario where alignment occurs."
- Why unresolved: While the theory is general, empirical validation was primarily restricted to SGMs and flow matching, with some flow matching models showing less robustness.
- What evidence would resolve it: A systematic study calculating finite-time Lyapunov exponents for a diverse range of generative architectures (e.g., GANs, VAEs, transformers) on standard benchmarks.

### Open Question 4
- Question: Can the sufficient conditions for alignment be formalized into a regularization objective to enforce robustness in models that naturally lack it, such as specific conditional flow matching variants?
- Basis in paper: [inferred] Appendix G.5 identifies that conditional flow matching models can be "less robust... than score-based diffusions," and the authors suggest their work provides "principled algorithmic improvements."
- Why unresolved: The paper establishes a diagnostic for robustness (alignment) but does not demonstrate how to modify the loss function of a non-robust model to enforce this alignment.
- What evidence would resolve it: Designing a regularization term based on the cross-derivative constraints in Theorem 4.3 and showing it increases robustness in flow matching models.

## Limitations
- The theoretical framework relies on infinitesimal perturbation analysis, but experimental validation uses finite perturbations (0.5-1.0 L∞)
- The extension to singular target distributions is mentioned but not thoroughly validated experimentally
- The sufficient conditions for alignment are not proven necessary, leaving open the possibility of alternative robustness mechanisms

## Confidence
- **High Confidence**: The statistical response mechanism (Mechanism 1) showing density perturbations remain on-support for infinitesimal errors
- **Medium Confidence**: The Lyapunov alignment mechanism (Mechanism 2) connecting top Lyapunov vectors to tangent spaces
- **Low Confidence**: The compression-induced alignment conditions (Mechanism 3) as sufficient but not necessary conditions

## Next Checks
1. Systematically vary perturbation magnitude from infinitesimal to large values and measure the transition point where samples leave the support to test the gap between theoretical robustness and practical perturbation tolerance

2. Quantify Lyapunov alignment using statistical measures (mean dot product, variance) across multiple runs and datasets, rather than relying on visual inspection, to test whether alignment quality predicts robustness across different generative model architectures

3. Implement and validate the singular target extension (Appendix B) on a concrete example with non-absolutely continuous support (e.g., a distribution supported on a lower-dimensional fractal) to verify that the statistical response mechanism still holds