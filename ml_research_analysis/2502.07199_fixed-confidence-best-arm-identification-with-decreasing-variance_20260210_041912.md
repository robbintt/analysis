---
ver: rpa2
title: Fixed-Confidence Best Arm Identification with Decreasing Variance
arxiv_id: '2502.07199'
source_url: https://arxiv.org/abs/2502.07199
tags:
- best
- arms
- cost
- sampling
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles the fixed-confidence best arm identification
  problem in a multi-armed bandit setting where rewards are Gaussian with fixed means
  but time-varying variances that decrease as $1/t$. This setup models situations
  where feedback becomes more accurate over time, such as multiple reviewers improving
  their product evaluations with repeated use.
---

# Fixed-Confidence Best Arm Identification with Decreasing Variance

## Quick Facts
- arXiv ID: 2502.07199
- Source URL: https://arxiv.org/abs/2502.07199
- Authors: Tamojeet Roychowdhury; Kota Srinivas Reddy; Krishna P Jagannathan; Sharayu Moharir
- Reference count: 17
- One-line primary result: Proposed algorithms achieve significant cost savings in best arm identification when reward variance decreases over time

## Executive Summary
This paper addresses the fixed-confidence best arm identification problem in multi-armed bandits where rewards are Gaussian with decreasing variance over time. The authors propose two policies - WTCS for known sub-optimality gaps and PS-WSE for the general case - that leverage the decreasing variance structure to achieve significant cost savings compared to classical algorithms. The key insight is that as variance decreases over time, more weight should be given to recent observations when estimating arm quality.

## Method Summary
The paper introduces two algorithms: Wait-Then-Continuously-Sample (WTCS) and Periodic Sampling with Weighted Successive Elimination (PS-WSE). WTCS operates by waiting initially before sampling all arms continuously, while PS-WSE samples periodically with decreasing frequency and uses weighted averages of rewards. Both algorithms incorporate the variance structure (decreasing as 1/t) into their decision-making process, allowing them to strategically allocate sampling effort over time. The PS-WSE algorithm specifically weights recent samples more heavily in its estimates, recognizing that these have lower variance.

## Key Results
- WTCS and PS-WSE achieve desired confidence levels while minimizing cumulative sampling cost
- Simulation results show significant performance improvements over classical algorithms like Successive Elimination and LUCB
- PS-WSE demonstrates particularly strong cost savings despite potentially longer identification times
- The algorithms effectively leverage the decreasing variance structure to optimize sampling strategies

## Why This Works (Mechanism)
The algorithms work by exploiting the time-varying variance structure where uncertainty decreases over time. As variance decreases (proportional to 1/t), later samples become more informative and should be weighted more heavily in arm quality estimates. The PS-WSE algorithm implements this by sampling periodically with decreasing frequency, allowing variance to decrease between samples, then using weighted averages that give more importance to recent observations. This strategic sampling approach balances the trade-off between identification time and cumulative sampling cost.

## Foundational Learning

1. **Fixed-confidence best arm identification**: Required for understanding the problem setup where we need to identify the best arm with probability at least 1-Î´ while minimizing sampling cost
   - Why needed: Forms the fundamental problem being solved
   - Quick check: Can you explain the difference between fixed-confidence and fixed-budget settings?

2. **Time-varying variance structure**: Essential for modeling scenarios where feedback becomes more accurate over time
   - Why needed: Enables the core algorithmic innovation of weighting recent samples more heavily
   - Quick check: What happens to the optimal sampling strategy if variance increases instead of decreases?

3. **Successive elimination framework**: Provides the baseline approach that the new algorithms improve upon
   - Why needed: Serves as the comparison point and underlying structure for PS-WSE
   - Quick check: How does successive elimination differ from top-two arm selection algorithms?

## Architecture Onboarding

Component Map: Problem Formulation -> Algorithm Design -> Theoretical Analysis -> Simulation Validation

Critical Path:
1. Problem formulation with decreasing variance model
2. Algorithm design incorporating variance structure
3. Theoretical analysis proving confidence guarantees
4. Simulation experiments validating performance gains

Design Tradeoffs:
- WTCS requires known sub-optimality gap but achieves simpler implementation
- PS-WSE works without prior knowledge but requires more complex periodic sampling
- Both algorithms trade potentially longer identification times for reduced cumulative cost
- Weighted averaging increases computational complexity but improves statistical efficiency

Failure Signatures:
- Poor performance if variance does not actually decrease as assumed
- Suboptimal results if the variance structure is misspecified
- Computational bottlenecks if the number of arms is very large

First Experiments:
1. Implement PS-WSE and compare against Successive Elimination on synthetic data with known variance structure
2. Test sensitivity of algorithms to misspecification of the variance decay rate
3. Evaluate performance on non-Gaussian reward distributions to test robustness

## Open Questions the Paper Calls Out
None

## Limitations
- Assumes Gaussian rewards with known variance structure (decreasing as 1/t)
- Theoretical analysis limited to specific time-varying variance model
- WTCS requires known sub-optimality gap, limiting practical applicability
- Does not address computational complexity or scalability to large numbers of arms

## Confidence

High: The theoretical guarantees for achieving desired confidence levels with both proposed policies
Medium: The simulation results showing performance improvements over classical algorithms
Low: The practical applicability of the assumptions (known variance structure, known sub-optimality gap) to real-world scenarios

## Next Checks
1. Test the algorithms with non-Gaussian reward distributions and unknown variance structures
2. Implement the policies in a real-world application (e.g., recommendation system) to validate practical performance
3. Analyze the computational complexity and scalability of the algorithms for large-scale problems