---
ver: rpa2
title: Do LLMs Truly Understand When a Precedent Is Overruled?
arxiv_id: '2510.20941'
source_url: https://arxiv.org/abs/2510.20941
tags:
- legal
- case
- task
- reasoning
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a benchmark evaluation of long-context language
  models on identifying overruling relationships in U.S. Supreme Court cases.
---

# Do LLMs Truly Understand When a Precedent Is Overruled?

## Quick Facts
- arXiv ID: 2510.20941
- Source URL: https://arxiv.org/abs/2510.20941
- Authors: Li Zhang; Jaromir Savelka; Kevin Ashley
- Reference count: 36
- Models struggle with historical cases and complex legal reasoning despite basic temporal awareness

## Executive Summary
This paper evaluates long-context language models on identifying overruling relationships in U.S. Supreme Court cases using a benchmark of 236 case pairs. The study tests models' ability to navigate lengthy judicial opinions and identify when one case overrules another through three tasks: open-ended identification, closed-ended verification, and reversed verification to test temporal reasoning. Results show that while models can perform simple temporal logic tasks with high accuracy, they struggle with complex legal reasoning and produce temporally impossible outputs in open-ended generation tasks. The best-performing model achieved 73.31% accuracy on open-ended identification, with performance degrading significantly for historical cases from before 1953.

## Method Summary
The study uses 236 U.S. Supreme Court case pairs (1789–2025) from Constitution Annotated with full opinion texts from CourtListener, ranging from 705 to 116,455 words. Three tasks are designed: open-ended identification of overruled cases, closed-ended verification (true/false/unknown), and reversed verification to test temporal reasoning. GPT-4o serves as automated judge with few-shot prompting, achieving 98% human agreement. Models tested include Qwen3-235B-A22B, Gemini-2.5-flash-lite, Gemini-2.5-flash, Gemini-2.5-pro, and GPT-5, with inference parameters set to temperature=0.1 and top_p=0.5.

## Key Results
- Best model achieved 73.31% accuracy on open-ended identification of overruled cases
- Era sensitivity: 0% accuracy on 1810-1881 cases for some models vs 82.47% on modern cases
- Temporal logic: 100% accuracy on reversed verification (Task 3) vs 75.42% on forward verification (Task 2)
- Models produce temporally impossible relationships in complex open-ended tasks despite maintaining basic temporal awareness in simple contexts

## Why This Works (Mechanism)

### Mechanism 1: Temporal Bias in Training Data Distribution
Models exhibit degraded performance on historical legal cases due to training data imbalance favoring modern texts. They lack linguistic and conceptual frameworks to parse archaic legal terminology, different citation conventions, and distinct argumentative structures from earlier eras. Core assumption: Training corpora contain proportionally fewer pre-1950s legal documents with specialized vocabulary.

### Mechanism 2: Shallow Logical Heuristics Substitute for Deep Legal Comprehension
Models achieve high accuracy on simple temporal logic tasks without understanding underlying legal reasoning. They apply surface-level pattern matching (e.g., "earlier year cannot overrule later year") rather than integrating distributed legal arguments across document sections. Core assumption: High performance on simple verification tasks indicates heuristic application rather than genuine comprehension.

### Mechanism 3: Context-Dependent Temporal Reasoning Under Cognitive Load
Models maintain basic temporal awareness in constrained tasks but produce temporally impossible outputs in open-ended generation. Open-ended tasks require simultaneous information extraction, relationship identification, and temporal constraint satisfaction; models fail to coordinate these processes under complexity. Core assumption: Cognitive load from multi-step reasoning causes temporal logic breakdown.

## Foundational Learning

- **Concept: Precedent hierarchy and stare decisis**
  - Why needed here: Overruling relationships are foundational to common law; understanding that precedents remain binding until explicitly overruled by higher/same court is essential for task comprehension
  - Quick check question: Can you explain why an 1880 Supreme Court decision cannot overrule a 1920 Supreme Court decision?

- **Concept: Temporal consistency in causal reasoning**
  - Why needed here: Models must recognize that causal relationships (overruling) require temporal ordering (cause precedes effect)
  - Quick check question: If Case A (1990) mentions Case B (2000), what temporal constraints apply to any causal claim about their relationship?

- **Concept: Distributed reasoning in long-form documents**
  - Why needed here: Legal arguments span multiple sections; overruling reasoning is rarely localized to single paragraphs
  - Quick check question: Why might extracting an overruling relationship require reading sections I, III, and V of a 20,000-word opinion?

## Architecture Onboarding

- **Component map:** Document ingestion → Information extraction across sections → Relationship identification → Temporal constraint validation → Response generation
- **Critical path:** 1. Document ingestion → 2. Information extraction across sections → 3. Relationship identification → 4. Temporal constraint validation → 5. Response generation
- **Design tradeoffs:** Open-ended (Task 1) tests realistic retrieval but requires automated evaluation; closed-ended (Task 2) simplifies evaluation but tests recognition rather than generation; reversed verification (Task 3) isolates temporal reasoning from legal comprehension
- **Failure signatures:** Partial extraction, confusion, hallucination, temporal impossibility
- **First 3 experiments:** 1. Baseline era sensitivity on stratified historical intervals (1810-1881, 1882-1953, 1954-2025); 2. Ablation on prompt constraint with explicit temporal reminder; 3. Verification confidence calibration comparing abstention rates between Task 2 and Task 3

## Open Questions the Paper Calls Out

- **Open Question 1:** Would retrieval-augmented generation (RAG) architectures improve LLM performance on identifying overruling relationships compared to pure long-context approaches? (basis: authors suggest exploring RAG systems)
- **Open Question 2:** Can legal domain-specific pre-training or fine-tuning mitigate the era sensitivity observed in historical case analysis? (basis: authors note future work should explore legal domain-specific pre-training)
- **Open Question 3:** Do the observed failures generalize to other legal systems and jurisdictions with different precedent structures? (basis: authors state dataset focuses exclusively on U.S. Supreme Court cases)
- **Open Question 4:** What mechanisms underlie the discrepancy between models' high confidence in rejecting temporally impossible propositions versus their hesitation in verifying correct relationships? (basis: authors observe this pattern but don't explain underlying mechanism)

## Limitations

- Training data composition claims lack direct empirical evidence about actual corpus distributions
- Automated evaluation using GPT-4o judge may not capture nuanced legal reasoning requiring domain expertise
- Temporal stratification boundaries may mask more granular patterns in performance degradation

## Confidence

- **Medium confidence:** Temporal bias in training data - supported by performance patterns but lacking direct corpus analysis
- **High confidence:** Shallow heuristics vs deep comprehension - consistent evidence across multiple tasks showing divergent performance patterns
- **Medium confidence:** Context-dependent temporal reasoning - strong Task 1 failures but requires further validation that cognitive load is causal mechanism

## Next Checks

1. **Training corpus composition analysis:** Obtain and analyze actual training data distributions for tested models to empirically verify whether pre-1950s legal texts are underrepresented relative to modern cases.

2. **Temporal constraint ablation study:** Systematically test whether adding explicit temporal reminders ("only later cases can overrule earlier cases") to prompts reduces impossible-relationship errors in Task 1, isolating whether cognitive load or temporal awareness is the limiting factor.

3. **Expert legal evaluation sample:** Manually evaluate a stratified random sample of model outputs (10 cases from each era) using legal experts to validate that GPT-4o judge accuracy holds for complex legal reasoning beyond temporal consistency.