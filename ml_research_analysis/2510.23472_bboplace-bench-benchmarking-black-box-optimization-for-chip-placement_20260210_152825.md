---
ver: rpa2
title: 'BBOPlace-Bench: Benchmarking Black-Box Optimization for Chip Placement'
arxiv_id: '2510.23472'
source_url: https://arxiv.org/abs/2510.23472
tags:
- placement
- chip
- optimization
- algorithms
- design
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces BBOPlace-Bench, the first benchmark for
  black-box optimization (BBO) algorithms applied to chip placement. The framework
  provides a modular platform integrating three problem formulations: sequence pair,
  mask-guided optimization, and hyperparameter optimization of the DREAMPlace analytical
  placer.'
---

# BBOPlace-Bench: Benchmarking Black-Box Optimization for Chip Placement

## Quick Facts
- arXiv ID: 2510.23472
- Source URL: https://arxiv.org/abs/2510.23472
- Reference count: 40
- Introduces first benchmark for black-box optimization in chip placement

## Executive Summary
BBOPlace-Bench introduces the first comprehensive benchmark for evaluating black-box optimization (BBO) algorithms in chip placement, a critical step in VLSI design automation. The framework provides three problem formulations (sequence pair, mask-guided optimization, and DREAMPlace hyperparameter optimization) and evaluates five representative BBO algorithms across standardized industrial chip cases. Results demonstrate that evolutionary algorithms and mask-guided optimization formulations significantly outperform traditional sequence pair approaches and achieve state-of-the-art results compared to mainstream analytical and reinforcement learning methods.

## Method Summary
The benchmark integrates three formulations: Sequence Pair (SP) for permutation-based search, Mask-Guided Optimization (MGO) for continuous coordinate optimization with greedy legality enforcement, and Hyperparameter Optimization (HPO) for tuning DREAMPlace parameters. Five BBO algorithms are evaluated: Simulated Annealing, vanilla-EA, Evolution Strategies/CMA-ES, Particle Swarm Optimization, and Bayesian Optimization. The framework processes industrial chip cases from ISPD 2005 and ICCAD 2015 benchmarks, supporting Bookshelf and LEF-DEF formats. Evaluations use 10,000 iterations for macro placement and 200 for global placement across five random seeds per experiment.

## Key Results
- Mask-guided optimization and hyperparameter optimization formulations outperform sequence pair formulation
- Evolutionary algorithms (vanilla-EA, PSO) demonstrate superior performance over simulated annealing and Bayesian optimization in high-dimensional search spaces
- BBO approaches achieve state-of-the-art performance compared to mainstream analytical and reinforcement learning methods for both macro placement and global placement tasks

## Why This Works (Mechanism)

### Mechanism 1: Greedy Mapping from Genotype to Phenotype
The Mask-Guided Optimization formulation outperforms Sequence Pair through a decoding heuristic that enforces legality and greedy local improvement. Instead of searching vast permutation spaces, MGO searches continuous coordinates and uses a "Wire-Mask" decoder that snaps raw coordinates to the nearest valid grid cell minimizing incremental wirelength while enforcing non-overlap constraints. This narrows the search space from "how to fit" to "where to improve."

### Mechanism 2: Surrogate Modeling for Mixed-Space Configuration
Global Placement effectiveness is achieved by tuning DREAMPlace hyperparameters rather than moving geometric objects. The HPO formulation treats placement as optimizing solver configurations (learning rate, density weights), shifting complexity from combinatorial geometry to continuous/mixed-variable optimization. This assumes DREAMPlace's robustness allows significant performance improvements through parameter tuning.

### Mechanism 3: Dimensionality-Driven Algorithm Selection
Evolutionary Algorithms outperform Bayesian Optimization in high-dimensional search spaces due to population-based exploration capabilities. BO suffers from cubic Gaussian Process complexity and struggles to build accurate surrogate models in dimensions exceeding 1000, while EAs maintain parallel exploration efficiency.

## Foundational Learning

- **Concept: Half-Perimeter Wirelength (HPWL)**
  - Why needed: Primary fitness function the benchmark optimizes, acting as PPA proxy
  - Quick check: For three pins at (0,0), (0,10), (10,0), is HPWL the triangle perimeter or bounding box?

- **Concept: Genotype-Phenotype Mapping**
  - Why needed: BBO algorithms manipulate vectors that must be decoded into physical layouts
  - Quick check: In MGO, does the optimizer place macros directly at coordinates or suggest positions adjusted by Wire-Mask decoder?

- **Concept: Global vs. Macro Placement**
  - Why needed: Benchmark distinguishes between optimizing large blocks only vs. entire chip including standard cells
  - Quick check: Which metric (MP-HPWL or GP-HPWL) is computationally cheaper but less correlated with final chip performance?

## Architecture Onboarding

- **Component map:** Preprocessor -> Interface -> Problem Formulation -> Optimizer -> Evaluator
- **Critical path:** evaluator.evaluate() call triggers either full DREAMPlace run (HPO) or wiremask check (MGO)
- **Design tradeoffs:**
  - MGO: Fast evaluation, legal solutions, but limited by greedy decoding
  - HPO: Slow evaluation, but optimizes global solution including standard cells
  - SP: Theoretical completeness, but poor scalability/performance
- **Failure signatures:**
  - Stagnation in BO: Optimizer stops improving due to high-dimensional surrogate model failure
  - Over-constraint in MGO: Coarse grid prevents finding valid non-overlapping spots
- **First 3 experiments:**
  1. Sanity Check: Run adaptec1 with CMA-ES on MGO to reproduce baseline HPWL (~56.13)
  2. Dimensionality Stress Test: Run MGO with 128→512→1024 macros using Vanilla-EA to observe scaling trends
  3. Algorithm Swap: On superblue1 HPO, swap Vanilla-EA for BO to verify performance recovery in lower dimensions

## Open Questions the Paper Calls Out

- How can multi-objective BBO algorithms balance conflicting PPA objectives like congestion, power, and timing?
- Can accurate surrogate models be constructed for GP-HPWL and PPA metrics to reduce computational cost?
- How can chip placement fitness landscape properties be analyzed to guide targeted BBO algorithm design?
- Can targeted Bayesian Optimization techniques outperform EAs in high-dimensional chip placement search spaces?

## Limitations

- Computational resource requirements for global placement evaluations (requires full DREAMPlace solver runs)
- Quality of greedy Wire-Mask decoder may struggle with extremely tight packing scenarios
- Focus on specific industrial chip cases may limit generalizability to newer design technologies

## Confidence

- **High Confidence:** Relative performance ranking of BBO algorithms (EA > PSO > SA > BO in high dimensions)
- **Medium Confidence:** Superiority of mask-guided optimization over sequence pair formulations
- **Medium Confidence:** HPO formulation achieves state-of-the-art performance for global placement

## Next Checks

1. **Scalability Test:** Systematically evaluate BBO algorithms on progressively larger chip instances (128→512→1024 macros) to verify documented scaling trends
2. **Decoder Robustness Analysis:** Test Wire-Mask decoder on extremely congested layouts to determine failure modes where sequence pair might theoretically succeed
3. **HPO Sensitivity Study:** Conduct ablation experiments on DREAMPlace hyperparameters to quantify parameter impact on global placement quality