---
ver: rpa2
title: Layer-Aware Influence for Online Data Valuation Estimation
arxiv_id: '2510.16007'
source_url: https://arxiv.org/abs/2510.16007
tags:
- influence
- training
- learning
- data
- sample
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a layer-aware online data valuation estimator
  that approximates sample influence during training using only loss-to-output gradients,
  avoiding full-network gradients. The method improves upon prior Hessian-free influence
  approaches by replacing per-layer feedback with a single output-layer signal, reducing
  noise and computational overhead while maintaining high fidelity to a Shapley-value
  baseline.
---

# Layer-Aware Influence for Online Data Valuation Estimation

## Quick Facts
- **arXiv ID:** 2510.16007
- **Source URL:** https://arxiv.org/abs/2510.16007
- **Reference count:** 40
- **Primary result:** Layer-aware online data valuation estimator using only loss-to-output gradients improves accuracy and reduces training costs on LLM and image/text classification tasks.

## Executive Summary
This paper introduces a layer-aware online data valuation estimator that approximates sample influence during training using only loss-to-output gradients, avoiding full-network gradients. The method improves upon prior Hessian-free influence approaches by replacing per-layer feedback with a single output-layer signal, reducing noise and computational overhead while maintaining high fidelity to a Shapley-value baseline. Extensive experiments on LLM pre-training/fine-tuning and image/text classification show the estimator improves accuracy and reduces training costs, making dynamic data curation scalable and efficient. The approach enables single-run training with minimal overhead and is compatible with SGD-style updates.

## Method Summary
The Layer-Aware Influence (LAI) estimator approximates sample influence by aggregating multi-layer embedding similarities and output-layer gradients, requiring only backpropagation to the output layer. The influence score for a training sample is computed as the sum of layer-wise embedding similarities multiplied by output-layer gradient similarity against a cached validation set. Samples with negative influence scores are excluded from the current batch update, enabling dynamic curation during training. The method is designed to be computationally efficient, requiring only forward passes to cache embeddings and backward passes to the output layer for scoring.

## Key Results
- LAI improves ranking fidelity to Shapley-value baseline by reducing noise through single-output-layer gradient approximation
- Online curation using LAI scores improves final accuracy and reduces training cost by dynamically excluding detrimental samples
- Method achieves substantial accuracy gains with lower time and memory costs compared to full gradient-based influence methods

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Replacing per-layer gradient feedback with a single output-layer gradient reduces variance in influence estimation, improving ranking fidelity to a Shapley-value baseline.
- **Mechanism:** Standard backpropagation through depth accumulates noise from stochastic mini-batch statistics and nonlinearities; using only the output-layer gradient avoids this aggregation while preserving signal.
- **Core assumption:** Gradient-norm decay and bounded activations hold; cross-layer covariances are nonnegative.
- **Evidence anchors:** Abstract and Section 4.2 explicitly state noise reduction benefits of output-layer gradient usage.
- **Break condition:** If gradient norms do not decay with depth or activations are unbounded, variance reduction may not hold.

### Mechanism 2
- **Claim:** Multi-layer embedding similarities aggregated with a single output-layer gradient retain ranking fidelity while enabling efficient online estimation.
- **Mechanism:** The influence score is approximated as sum of layer-wise embedding similarities multiplied by output-layer gradient similarity, avoiding full-network parameter gradients.
- **Core assumption:** Output-layer gradient is a stable proxy for layerwise gradient alignments.
- **Evidence anchors:** Abstract and Section 4.1 provide the explicit LAI formulation.
- **Break condition:** If alignment decreases substantially in earlier layers relative to output layer, ranking fidelity may degrade.

### Mechanism 3
- **Claim:** Online curation using LAI scores can improve final accuracy and reduce training cost by dynamically excluding samples with negative estimated influence.
- **Mechanism:** Samples with influence < 0 are skipped in current batch, reducing wasted updates; this adapts to evolving sample importance.
- **Core assumption:** Influence estimates sufficiently correlate with true sample utility; validation set is representative.
- **Evidence anchors:** Abstract and Section 5.3 show reduced validation loss and improved accuracy with fewer samples.
- **Break condition:** If validation set is biased or non-representative, curation may systematically exclude important subgroups.

## Foundational Learning

- **Concept: Influence Functions (gradient-based data attribution)**
  - **Why needed here:** LAI is a Hessian-free, layer-aware variant of influence functions; understanding the original formulation clarifies what is being approximated.
  - **Quick check question:** Can you explain why the Hessian inverse is a computational bottleneck in classical influence functions?

- **Concept: Backpropagation and Gradient Flow**
  - **Why needed here:** The noise-reduction argument relies on how gradients propagate through layers and where noise accumulates.
  - **Quick check question:** What are two sources of stochasticity in backpropagation through normalization layers?

- **Concept: Shapley Values as a Data Valuation Baseline**
  - **Why needed here:** The paper uses Monte Carlo Shapley estimates as a fidelity reference; understanding this grounds the evaluation.
  - **Quick check question:** Why is exact Shapley computation intractable for large datasets, and what is a common approximation strategy?

## Architecture Onboarding

- **Component map:** Validation cache -> Scoring module -> Curation policy -> Training loop
- **Critical path:**
  1. Forward pass to cache multi-layer embeddings for validation set
  2. For each training batch: forward pass, backprop to output layer only, compute LAI scores, apply curation policy, proceed with optimizer step
  3. Integrate scoring and curation into each mini-batch update

- **Design tradeoffs:**
  - Validation cache size vs. fidelity: Larger cache improves coverage but increases memory/compute
  - Update frequency of cache: Static cache is cheaper; dynamic cache tracks drift but adds overhead
  - Choice of threshold: Zero-threshold is simple but may be too aggressive; percentile-based thresholds trade data efficiency for robustness
  - Assumption: Adam preconditioning may introduce direction mismatch; diagonal preconditioning is a low-cost mitigation

- **Failure signatures:**
  - Ranking collapse: LAI scores concentrate near zero, providing no discriminative signal
  - Over-aggressive pruning: Training loss plateaus early with too few samples
  - Bias amplification: Performance drops on minority subgroups
  - Memory blowup: If full per-sample gradients are accidentally materialized, memory cost spikes

- **First 3 experiments:**
  1. Fidelity test on small dataset: Compute LAI and Ghost scores for subset; measure correlation with Monte Carlo Shapley values
  2. Ablation on cache size: Sweep validation cache size and measure ranking stability and final accuracy
  3. Curation policy comparison: Compare zero-threshold filtering vs. percentile-based vs. reweighting on noisy-label dataset

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the Layer-Aware Influence (LAI) estimator be modified to achieve exact alignment with adaptive optimizers like Adam without incurring the high computational cost of per-sample moment statistics?
- **Basis in paper:** The authors state in Appendix E that achieving exact Adam-consistent scoring requires per-sample moment statistics and is typically too costly.
- **Why unresolved:** The paper offers a lightweight proxy but leaves a gap between this approximation and a theoretically exact, efficient solution for adaptive methods.
- **What evidence would resolve it:** A derivation of an efficient influence estimator that is provably consistent with Adam's update rule, or empirical results showing parity with per-sample moment methods on large-scale benchmarks.

### Open Question 2
- **Question:** Does the reliance on a validation set for online data valuation systematically exclude beneficial "long-tail" examples or amplify dataset biases?
- **Basis in paper:** The Ethics Statement explicitly lists amplification of validation-set bias and possible exclusion of long-tail groups as potential risks.
- **Why unresolved:** While identified as a risk, the paper does not quantify the extent of this bias on imbalanced datasets or propose a concrete algorithmic correction.
- **What evidence would resolve it:** Experiments on class-imbalanced benchmarks measuring the performance drop on minority classes when using LAI versus standard training.

### Open Question 3
- **Question:** How should the validation set be optimally constructed for unsupervised or self-supervised pre-training to maximize the efficacy of the LAI estimator?
- **Basis in paper:** Section 5.2 notes that LLM pre-training lacks a dedicated validation set, forcing use of self-influence which yielded only marginal gains.
- **Why unresolved:** The paper demonstrates LAI works with self-influence but implies the gains are limited compared to fine-tuning.
- **What evidence would resolve it:** A comparative study of pre-training runs using various validation set constructions showing significant perplexity reductions over the self-influence baseline.

## Limitations
- Noise-reduction mechanism relies on unproven assumptions about gradient-norm decay and cross-layer covariance positivity
- Interaction with adaptive optimizers (Adam) remains unclear regarding diagonal preconditioning usage
- Validation cache staleness and its impact on ranking fidelity over long training runs is not systematically studied

## Confidence
- **High confidence:** Online curation improves accuracy and reduces training cost when validation set is representative
- **Medium confidence:** Single-output-layer gradient approximation improves ranking fidelity over per-layer feedback
- **Low confidence:** LAI scores remain stable and discriminative across training epochs without cache updates

## Next Checks
1. **Gradient-norm decay validation:** Measure gradient norms across layers during training to verify decay as assumed in Appendix B
2. **Optimizer consistency test:** Run CIFAR-10N experiments with SGD and Adam (with/without diagonal preconditioning) to isolate optimizer effects
3. **Cache dynamics study:** Compare static vs. periodically-updated validation caches on CIFAR-10N to quantify staleness impact on accuracy and ranking fidelity