---
ver: rpa2
title: Multi-Agent Reinforcement Learning for Sample-Efficient Deep Neural Network
  Mapping
arxiv_id: '2507.16249'
source_url: https://arxiv.org/abs/2507.16249
tags:
- marl
- agent
- mapping
- parameters
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of efficiently mapping deep
  neural networks (DNNs) to hardware accelerators, which is critical for optimizing
  latency, energy consumption, and resource utilization. The authors propose a decentralized
  multi-agent reinforcement learning (MARL) framework that significantly improves
  sample efficiency over traditional single-agent approaches.
---

# Multi-Agent Reinforcement Learning for Sample-Efficient Deep Neural Network Mapping

## Quick Facts
- arXiv ID: 2507.16249
- Source URL: https://arxiv.org/abs/2507.16249
- Authors: Srivatsan Krishnan; Jason Jabbour; Dan Zhang; Natasha Jaques; Aleksandra Faust; Shayegan Omidshafiei; Vijay Janapa Reddi
- Reference count: 31
- One-line primary result: MARL achieves 30-300× faster convergence than single-agent RL for DNN mapping optimization

## Executive Summary
This paper addresses the challenge of efficiently mapping deep neural networks (DNNs) to hardware accelerators, which is critical for optimizing latency, energy consumption, and resource utilization. The authors propose a decentralized multi-agent reinforcement learning (MARL) framework that significantly improves sample efficiency over traditional single-agent approaches. The core innovation is a clustering-based agent assignment algorithm that groups correlated mapping parameters under shared agents while distributing independent parameters across different agents, enabling parallelized exploration of the vast mapping space while reducing computational overhead.

## Method Summary
The authors propose a decentralized multi-agent reinforcement learning (MARL) framework for DNN mapping optimization. The method uses a clustering-based agent assignment algorithm that groups correlated mapping parameters under shared agents while distributing independent parameters across different agents. This enables parallelized exploration of the mapping space. The framework employs a shared global reward signaling mechanism where agents receive a common reward based on final hardware performance (latency, energy) without explicit communication. The approach uses agglomerative clustering to analyze parameter correlations from an initial exploration dataset, then assigns parameters to agents based on this clustering structure.

## Key Results
- MARL achieves 30-300× faster convergence than single-agent RL under equal sample budgets
- Up to 32.61× latency reduction and 16.45× energy-delay product (EDP) reduction achieved
- MARL consistently outperforms state-of-the-art baselines including random search, Bayesian optimization, genetic algorithms, and GAMMA across multiple DNN architectures

## Why This Works (Mechanism)

### Mechanism 1: Parallelized Search Space Factorization
Distributing mapping parameters across multiple agents reduces the effective search space per agent, accelerating convergence. Instead of a single agent searching a combinatorial space of 10^10, the mapping problem is factorized. Independent parameters are assigned to separate agents who explore their local parameter spaces in parallel, significantly reducing steps required compared to sequential or joint search.

### Mechanism 2: Correlation-Guided Agent Clustering
Grouping highly correlated parameters under shared agents prevents coordination errors and stabilizes learning. The algorithm computes a correlation matrix of parameters relative to the optimization objective and uses agglomerative clustering to group parameters that move together. This ensures strongly interdependent decisions are made by a single agent, preserving necessary coordination while allowing independent parameters to be decentralized.

### Mechanism 3: Shared Global Reward Signaling
A shared global reward allows decentralized agents to converge without explicit communication overhead. Agents do not exchange messages directly but receive a common reward signal based on final hardware performance. Each agent learns to adjust its specific parameters to maximize this shared return, effectively learning to cooperate implicitly through the environment's feedback loop.

## Foundational Learning

- **Design Space Exploration (DSE)**: Understanding what "mapping" implies (tiling, loop ordering, parallelization) is essential to grasp search space complexity (10^4 to 10^39). Quick check: Can you explain why loop ordering affects data locality and energy consumption in an accelerator?

- **Sample Efficiency**: The paper's primary metric distinguishes between "wall-clock time" and "sample efficiency" (steps to converge). Quick check: Why is sample efficiency critical when evaluating a DNN mapping simulator that might be slow to run?

- **Agglomerative Clustering**: This is the core structural innovation. Understanding how dendrograms work is necessary to interpret the agent assignment strategy. Quick check: In hierarchical clustering, what determines the "threshold" for grouping parameters into a single agent?

## Architecture Onboarding

- **Component map**: Dataset Generator -> Clustering Module -> MARL Controller -> MaestroEnv (Gym wrapper)

- **Critical path**: 1) Correlation Analysis (Offline): Run initial simulations to populate dataset 2) Clustering: Execute clustering algorithm to determine agent-parameter assignment 3) Training: Initialize MARL framework with clustered assignment; train agents to maximize reward

- **Design tradeoffs**: Agent Count (B=1 stable but slow; B=10 fast but resource-heavy; clustering finds sweet spot); Initial Data Cost (20,000 samples required upfront, amortized over multiple optimizations)

- **Failure signatures**: Sparse Reward (agents never converge if random search yields no positive rewards); Correlation Drift (clustering based on initial samples doesn't reflect optimal region correlations)

- **First 3 experiments**: 1) Baseline Verification: Implement single-agent RL vs. MARL (10 agents) on MobileNet-v2 Layer 2 to reproduce "100x faster convergence" curve 2) Clustering Ablation: Compare fixed agent counts vs. correlation-guided clustering 3) Overhead Analysis: Measure wall-clock time for 20,000-sample correlation phase vs. time saved during MARL training

## Open Questions the Paper Calls Out

### Open Question 1
Can the decentralized MARL framework maintain its sample efficiency and convergence speed when applied to the mapping spaces of Transformers and MLPs? The authors state the approach is broadly applicable to any DNN mapping problem, but experimental evaluation exclusively benchmarks CNN architectures.

### Open Question 2
To what degree can the correlation-based agent assignments learned from one DNN architecture be transferred to a significantly different architecture without re-running the clustering overhead? The paper claims the initial dataset cost can be amortized but provides no analysis on what defines "similar" architectures or how much transfer is possible.

### Open Question 3
How sensitive is the quality of the final mapping to the choice of the initial exploration policy (π) used to generate the correlation dataset? The paper notes different policies can be used but doesn't analyze how the distribution of initial data impacts the accuracy of the subsequent correlation matrix.

## Limitations
- Reliance on initial correlation analysis from limited sample pool (20,000 samples) - if this dataset fails to capture true parameter relationships, clustering will be suboptimal
- Assumes parameter independence within clusters, but real hardware mappings may exhibit complex, non-linear interactions that correlation metrics cannot capture
- Scalability analysis limited to ResNet-50, MobileNet-v2, and DenseNet-121 - broader architecture coverage would strengthen generalizability claims

## Confidence
- **High Confidence**: The 30-300× sample efficiency improvement is well-supported by convergence curves comparing MARL to single-agent RL under equal sample budgets
- **Medium Confidence**: The clustering-based agent assignment shows promising results but relies on assumptions about correlation stability that require further validation across diverse hardware platforms
- **Medium Confidence**: The claim of state-of-the-art performance against GAMMA, Bayesian optimization, and genetic algorithms is substantiated through comprehensive comparisons

## Next Checks
1. **Correlation Stability Test**: Run clustering algorithm on multiple independent initial datasets (varying random seeds) to measure variance in agent assignments and resulting performance
2. **Architecture Generalization**: Apply MARL to three additional DNN architectures (e.g., EfficientNet, ShuffleNet, Inception) to validate cross-architecture effectiveness
3. **Hardware Platform Transfer**: Test the same DNN-to-mapping pipeline across different hardware accelerators (e.g., NVIDIA GPU, Intel CPU, custom ASIC simulator) to assess platform dependence of correlation analysis