---
ver: rpa2
title: 'Garment Inertial Denoiser (GID): Endowing Accurate Motion Capture via Loose
  IMU Denoiser'
arxiv_id: '2601.01360'
source_url: https://arxiv.org/abs/2601.01360
tags:
- garment
- motion
- pose
- data
- inertial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of accurate motion capture
  using wearable inertial measurement units (IMUs) embedded in loose-fitting garments,
  where sensor-body displacement introduces severe, structured noise that corrupts
  inertial signals and breaks standard inertial motion capture pipelines. The authors
  propose Garment Inertial Denoiser (GID), a lightweight, plug-and-play Transformer-based
  denoising module that factorizes the problem into three stages: location-specific
  denoising, adaptive cross-wear fusion, and pose prediction.'
---

# Garment Inertial Denoiser (GID): Endowing Accurate Motion Capture via Loose IMU Denoiser

## Quick Facts
- **arXiv ID:** 2601.01360
- **Source URL:** https://arxiv.org/abs/2601.01360
- **Reference count:** 40
- **Primary result:** GID is a Transformer-based denoising module that factorizes loose-IMU denoising into location-specific denoising, adaptive fusion, and pose prediction, enabling accurate motion capture from loose garments with limited training data.

## Executive Summary
This paper addresses the challenge of accurate motion capture using wearable inertial measurement units (IMUs) embedded in loose-fitting garments, where sensor-body displacement introduces severe, structured noise that corrupts inertial signals and breaks standard inertial motion capture pipelines. The authors propose Garment Inertial Denoiser (GID), a lightweight, plug-and-play Transformer-based denoising module that factorizes the problem into three stages: location-specific denoising, adaptive cross-wear fusion, and pose prediction. GID uses a location-aware expert architecture where a shared spatio-temporal backbone captures global motion while per-IMU expert heads specialize in local garment dynamics, with a lightweight fusion module ensuring cross-part consistency. This design enables stable training and effective learning from limited paired loose-tight IMU data. The authors also introduce GarMoCap, a comprehensive dataset featuring diverse users, motions, and garment types. Experimental results demonstrate that GID enables accurate, real-time denoising from single-user training and generalizes across unseen users, motions, and garment types. When used as a drop-in module, GID consistently improves the accuracy and robustness of state-of-the-art inertial motion capture methods, reducing angular and positional errors while enhancing motion smoothness.

## Method Summary
GID addresses loose-IMU denoising by factorizing the mapping into location-specific denoising, adaptive cross-wear fusion, and pose prediction. The architecture uses a shared spatio-temporal Transformer backbone with per-IMU expert heads that specialize in local garment dynamics. A lightweight fusion module adaptively combines denoised and raw signals, while a consistency transformer refines cross-part relationships. The method trains on paired loose-tight IMU data from the GarMoCap dataset and operates as a plug-in module for existing pose estimators like PIP and ASIP. The approach leverages location-aware experts to handle heterogeneous sensor dynamics and uses learnable convex combination weights to balance stability and realism in the fused signals.

## Key Results
- GID reduces angular error from 24.53° to 22.24° and positional error from 2.32 cm to 2.11 cm compared to baseline methods on loose IMU data.
- The method generalizes across unseen users, motions, and garment types when trained on single-user, single-garment paired data.
- GID improves downstream pose estimator accuracy (PIP, ASIP) while maintaining real-time performance on consumer hardware.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Decomposing the loose-IMU-to-pose mapping into separate denoising and pose estimation stages reduces effective learning complexity.
- **Mechanism:** The mapping f_IMUloose→θ is factorized into f_IMUloose→IMUtight ∘ f_IMUtight→θ. Since loose-wear and tight-wear signals share similar spatio-temporal structure, learning to invert structured garment disturbances is a lower-complexity problem than learning pose from corrupted signals directly.
- **Core assumption:** Garment-induced noise is structured and invertible rather than random; paired loose-tight data is sufficient to learn this inverse mapping.
- **Evidence anchors:**
  - [abstract] "factorizes loose-wear MoCap into three stages: (i) location-specific denoising, (ii) adaptive cross-wear fusion, and (iii) general pose prediction"
  - [section 3.2] "This decomposition strategy is advantageous. It constrains the hypothesis space and enables more efficient learning from limited paired data."
  - [corpus] FIP and LIP papers attempt similar domain translation but rely on large-scale synthetic data; GID achieves comparable results with ~11 min vs. ~1967 min of training data.
- **Break condition:** If garment-body dynamics are highly nonlinear or chaotic (e.g., very loose fabrics with unpredictable deformation), the denoising inverse may become ill-posed.

### Mechanism 2
- **Claim:** Assigning separate denoisers to each IMU location mitigates conflicting optimization gradients from heterogeneous sensor dynamics.
- **Mechanism:** Sensors at different body sites (wrist vs. torso vs. waist) experience distinct garment-body coupling (sliding, slack, contact patterns). Location-specific expert heads specialize in these local physics, while a shared backbone captures global motion regularities.
- **Core assumption:** Location-dependent noise patterns are learnable and consistent enough across users/garments to permit specialization without overfitting.
- **Evidence anchors:**
  - [abstract] "GID uses a location-aware expert architecture, where a shared spatio-temporal backbone models global motion while per-IMU expert heads specialize in local garment dynamics"
  - [section 3.2] "Using a single shared model to represent such heterogeneous distributions introduces conflicting optimization gradients, making it difficult to learn an effective and generalizable mapping."
  - [corpus] No direct corpus comparison for expert architectures in this domain; evidence is primarily internal (ablation shows performance drop when LSD removed).
- **Break condition:** If training data is too sparse per-location, expert heads may overfit to specific users or garment configurations.

### Mechanism 3
- **Claim:** Adaptive fusion of denoised and raw signals balances stability and realism, improving motion smoothness.
- **Mechanism:** After location-specific denoising, a learnable convex combination α·ÎMU_tight + (1−α)·IMU_loose adaptively weighs denoised signals (stable, artifact-reduced) against original signals (preserves high-frequency motion realism). A final transformer enforces cross-part consistency.
- **Core assumption:** Neither pure denoised nor pure raw signals are optimal; the optimal balance varies across motions and contexts.
- **Evidence anchors:**
  - [section 3.2] "This formulation allows the model to adaptively balance the stability of tight-wear signals and the realism of loose-wear dynamics"
  - [table 5] Ablation shows removing ACF increases angle error (22.24→24.53°) and IMU MAE (0.130→0.145).
  - [corpus] No direct external validation of this specific fusion strategy in related work.
- **Break condition:** If α is poorly calibrated or overfits to training motions, fusion may reintroduce noise or over-smooth critical motion details.

## Foundational Learning

- **Concept: Sparse IMU Pose Estimation**
  - Why needed here: GID is a plug-in module for existing sparse IMU pose estimators (PIP, PNP, ASIP). Understanding how these systems map IMU signals to joint rotations is essential.
  - Quick check question: Can you explain why sparse IMU systems (3-6 sensors) require learned priors to resolve kinematic ambiguity?

- **Concept: Transformer Spatio-Temporal Modeling**
  - Why needed here: GID uses temporal-spatial transformers as backbones; understanding attention over time and across body parts is critical for debugging and extension.
  - Quick check question: How does a transformer jointly model temporal dependencies in a sensor sequence and spatial relationships across multiple sensors?

- **Concept: Domain Adaptation vs. Factorized Learning**
  - Why needed here: The paper explicitly contrasts its factorized approach with domain randomization. Understanding this distinction helps evaluate when each is appropriate.
  - Quick check question: Why does domain randomization fail for structured, physics-based noise like garment dynamics?

## Architecture Onboarding

- **Component map:** Loose IMU → location-specific denoisers → ÎMU_tight per sensor → fusion (α·ÎMU_tight + (1-α)·IMU_loose) → consistency transformer → refined signals → pose predictor → joint rotations

- **Critical path:**
  1. Loose IMU → location-specific denoisers → ÎMU_tight per sensor
  2. Fusion: α·ÎMU_tight + (1−α)·IMU_loose
  3. Consistency transformer → refined signals
  4. Pose predictor → joint rotations

- **Design tradeoffs:**
  - Expert heads vs. shared denoiser: Experts improve accuracy but increase parameters and require sufficient per-location data.
  - Fusion vs. direct denoised output: Fusion adds robustness but introduces an additional learnable component that may mis-calibrate.
  - Root-relative vs. world-frame: GID operates root-relative; this limits compatibility with physics-based methods like PNP that use world-frame cues.

- **Failure signatures:**
  - No improvement with PNP: Likely due to root-relative/world-frame mismatch (noted in paper).
  - High jitter despite denoising: ACF may be over-weighting raw signals; check α distribution.
  - Poor cross-garment generalization: Location-specific experts may have overfit to training garment geometry.

- **First 3 experiments:**
  1. **Ablation per component:** Train GID with FPS only, FPS+LSD, and full GID; measure IMU MAE and pose error to validate each mechanism's contribution.
  2. **Cross-garment transfer:** Train on D^full_GID (single user), test on D^upper_FIP and D^upper_LIP; report angular/positional errors to assess generalization.
  3. **Fusion weight analysis:** Visualize learned α across different motion types (running vs. boxing vs. walking) to understand when fusion favors denoised vs. raw signals.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can integrating differentiable physics or garment simulation priors close the remaining performance gap between denoised loose-wear signals and ideal tight-wear ground truth?
- Basis in paper: [explicit] Authors state: "current models do not yet fully capture the complex non-linear dynamics of cloth–body interactions" and suggest "Integrating differentiable physics or garment simulation priors... could further reduce this gap."
- Why unresolved: Current purely data-driven denoising leaves a measurable accuracy gap; the structured physical nature of garment-body dynamics is not explicitly modeled.
- What evidence would resolve it: Demonstrated reduction in MAE and pose errors when physics-informed constraints are incorporated, compared to the current GID baseline.

### Open Question 2
- Question: How does GID generalize across more diverse clothing configurations with different sensor placements, fabric materials, and garment cuts?
- Basis in paper: [explicit] Authors note: "our current garment designs still share a certain degree of similarity—for instance, comparable sensor placements and fabric layouts—which may limit the model's ability to generalize across diverse clothing configurations."
- Why unresolved: Evaluation used only 4 garment types with similar designs; real-world deployment would encounter far more varied clothing.
- What evidence would resolve it: Systematic evaluation across a wider corpus of garments varying fabric stiffness, fit, and sensor mounting locations.

### Open Question 3
- Question: How can the coordinate space mismatch between root-relative denoising and world-frame physics-based estimators be resolved?
- Basis in paper: [explicit] Authors observe that GID does not improve PNP performance due to "a representational mismatch: our denoiser operates in a root-relative IMU space, whereas PNP relies on world-frame, physically structured inertial cues."
- Why unresolved: Training in world coordinates introduces alignment and subject-specific motion complications that destabilize optimization.
- What evidence would resolve it: An architecture variant that maintains physical consistency while supporting both coordinate frames, showing improved compatibility with physics-based downstream methods.

### Open Question 4
- Question: Can scaling paired loose–tight training data yield a generalizable foundation model for garment-based IMU denoising?
- Basis in paper: [explicit] Future work states the goal of "a generalizable, physically grounded foundation model for garment-based IMU denoising that fully closes the loose–tight sensing gap" via expanded data collection.
- Why unresolved: Current experiments use single-user, single-garment training; scaling behavior across diverse users, motions, and fabrics remains untested.
- What evidence would resolve it: Scaling curves showing denoising and pose accuracy improvements as training data diversity increases, with zero-shot generalization benchmarks.

## Limitations

- The method operates in root-relative coordinates, limiting compatibility with world-frame physics-based estimators like PNP.
- Current experiments use only 4 garment types with similar designs, potentially limiting generalization to more diverse clothing configurations.
- The exact Transformer architecture specifications (layer depth, attention head count, hidden dimensions) are not disclosed, making precise reproduction challenging.

## Confidence

- **High Confidence:** The core mechanism of location-specific denoising followed by fusion is well-supported by ablation results (Table 5) showing clear error reductions when both components are present.
- **Medium Confidence:** Claims of real-time performance and generalization across users/motions are supported by experimental results but rely on limited test scenarios and specific hardware configurations.
- **Low Confidence:** The assertion that GID can serve as a "plug-and-play" module for arbitrary pose estimators is qualified by the noted incompatibility with PNP, suggesting broader compatibility testing is needed.

## Next Checks

1. **Component Ablation:** Systematically disable FPS, LSD, and ACF modules individually to quantify each component's contribution to final accuracy, measuring both IMU reconstruction error and downstream pose accuracy.
2. **Cross-Garment Stress Test:** Train GID on upper-body garments only, then evaluate on lower-body garments (pants) from GarMoCap to test the limits of location-specific generalization.
3. **Fusion Sensitivity Analysis:** Conduct a grid search over α initialization and learning rate schedules to identify optimal settings and assess whether fusion weights converge to sensible values across different motion types.