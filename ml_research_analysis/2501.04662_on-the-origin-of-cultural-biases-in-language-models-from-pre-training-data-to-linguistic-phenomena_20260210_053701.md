---
ver: rpa2
title: 'On The Origin of Cultural Biases in Language Models: From Pre-training Data
  to Linguistic Phenomena'
arxiv_id: '2501.04662'
source_url: https://arxiv.org/abs/2501.04662
tags:
- entities
- arabic
- arab
- english
- western
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the origins of cultural biases in language
  models (LMs) towards Western entities when operating in non-Western languages, specifically
  Arabic. The authors introduce CAMeL-2, a parallel Arabic-English benchmark of 58,086
  entities across seven types, and 367 natural contexts.
---

# On The Origin of Cultural Biases in Language Models: From Pre-training Data to Linguistic Phenomena

## Quick Facts
- arXiv ID: 2501.04662
- Source URL: https://arxiv.org/abs/2501.04662
- Reference count: 40
- Primary result: Language models show reduced performance gaps between Arab and Western entities when tested in English versus Arabic, with polysemy and tokenization choices contributing to cultural bias

## Executive Summary
This paper investigates why language models exhibit cultural biases favoring Western entities when operating in non-Western languages, using Arabic as a case study. The authors introduce CAMeL-2, a parallel Arabic-English benchmark of 58,086 entities across seven types and 367 natural contexts, to systematically evaluate model performance. Their experiments reveal that linguistic phenomena like word polysemy and tokenization choices significantly contribute to perceived Western bias, beyond simple training data imbalances. The study demonstrates that when models are tested in English rather than Arabic, performance gaps between Arab and Western entities decrease substantially, suggesting that language-specific processing challenges compound cultural knowledge gaps.

## Method Summary
The authors created CAMeL-2, a parallel Arabic-English benchmark containing 58,086 entities across seven entity types (persons, locations, organizations, etc.) with 367 natural contexts. They evaluated multiple language models on this benchmark in both Arabic and English, measuring performance differences between Arab and Western entities. The study employed controlled experiments varying tokenization strategies and vocabulary sizes to isolate the effects of linguistic processing on cultural bias. Statistical analysis was used to correlate entity frequency, polysemy levels, and lexical overlap with performance metrics across different model configurations.

## Key Results
- Performance gaps between Arab and Western entities decrease when models are tested in English versus Arabic
- High-frequency Arab entities with polysemy (multiple word senses) show particularly poor performance in Arabic
- Larger Arabic vocabularies and frequency-based tokenization exacerbate performance issues for polysemous entities
- Entities with high lexical overlap with other Arabic script languages cause additional performance drops

## Why This Works (Mechanism)
The study identifies how linguistic phenomena in Arabic interact with language model processing to create or amplify cultural biases. Word polysemy in Arabic creates ambiguity that models struggle to resolve, particularly for high-frequency terms that have multiple meanings depending on context. Tokenization choices that prioritize frequent terms can fragment culturally-specific entities or create ambiguous subword units, further degrading performance. When these linguistic challenges are combined with training data imbalances favoring Western entities, the resulting bias appears more severe than either factor alone would produce.

## Foundational Learning

**Polysemy** - Multiple word senses for a single lexical item (why needed: explains why common Arab words confuse models; quick check: count distinct meanings in dictionary)

**Frequency-based tokenization** - Splitting text based on word occurrence patterns (why needed: shows how tokenization choices affect entity representation; quick check: compare subword units across different vocabulary sizes)

**Lexical overlap** - Shared character sequences across languages using same script (why needed: explains cross-language interference effects; quick check: measure character n-gram overlap between language pairs)

**Script-based ambiguity** - Multiple languages sharing writing systems (why needed: reveals how script similarity creates processing challenges; quick check: test models on transliterated text)

## Architecture Onboarding

**Component map:** Data collection -> Benchmark creation -> Model evaluation -> Error analysis -> Mechanism isolation

**Critical path:** Benchmark entities -> Context generation -> Model inference -> Performance measurement -> Linguistic feature correlation

**Design tradeoffs:** Parallel vs. monolingual benchmarks (parallel enables direct comparison but may introduce translation artifacts); controlled tokenization vs. standard settings (controlled reveals mechanisms but may not reflect real-world deployment)

**Failure signatures:** Performance drops specifically for high-frequency polysemous Arab entities; inconsistent tokenization of culturally-specific terms; confusion between Arab entities and similar-sounding Western names

**First experiments:** 1) Evaluate models on monolingual Arab and Western entity sets separately; 2) Test with fixed vs. adaptive tokenization strategies; 3) Measure correlation between polysemy levels and performance degradation

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Findings are limited to Arabic-English comparisons and may not generalize to other language pairs or script systems
- Benchmark construction process may contain subtle biases in entity selection or context creation
- Analysis focuses on specific tokenization strategies without exploring the full parameter space of possible approaches

## Confidence

**High confidence:** Performance gaps decrease in English vs. Arabic testing; correlation between frequency and polysemy effects

**Medium confidence:** Tokenization exacerbating polysemy issues; lexical overlap causing performance drops

**Low confidence:** Broader implications for other non-Western languages; proposed solutions for addressing biases

## Next Checks

1. Replicate benchmark methodology with non-Western languages using different script systems (Hindi, Thai, Russian) to test generalizability

2. Systematically vary tokenization strategies across different vocabulary sizes to quantify relationships with entity performance

3. Conduct detailed error analysis to distinguish between cultural knowledge gaps and linguistic processing issues in model predictions