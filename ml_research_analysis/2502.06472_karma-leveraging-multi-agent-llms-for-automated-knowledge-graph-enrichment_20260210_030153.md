---
ver: rpa2
title: 'KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment'
arxiv_id: '2502.06472'
source_url: https://arxiv.org/abs/2502.06472
tags:
- knowledge
- agents
- conf
- each
- relevance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KARMA addresses the challenge of scalable knowledge graph enrichment
  from scientific literature by employing a multi-agent LLM framework. The system
  decomposes extraction into specialized agents for entity discovery, relationship
  validation, and conflict resolution, ensuring accurate and adaptive knowledge integration.
---

# KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment

## Quick Facts
- arXiv ID: 2502.06472
- Source URL: https://arxiv.org/abs/2502.06472
- Authors: Yuxing Lu; Jinzhuo Wang
- Reference count: 40
- Achieves 83.1% LLM-verified correctness while identifying up to 38,230 new entities from 1,200 PubMed articles

## Executive Summary
KARMA addresses the challenge of scalable knowledge graph enrichment from scientific literature by employing a multi-agent LLM framework. The system decomposes extraction into specialized agents for entity discovery, relationship validation, and conflict resolution, ensuring accurate and adaptive knowledge integration. Experiments on 1,200 PubMed articles across genomics, proteomics, and metabolomics demonstrate that KARMA identifies up to 38,230 new entities while achieving 83.1% LLM-verified correctness and reducing conflict edges by 18.6% through multi-layer assessments. The framework outperforms single-agent approaches and shows domain-specific strengths, with DeepSeek-v3 driving the highest coverage gains.

## Method Summary
KARMA implements a nine-agent sequential pipeline that processes scientific literature into structured knowledge graph triplets. The workflow begins with Ingestion (PDF to text), Reader (segmentation and scoring), and Summarizer (document condensation), followed by Entity Extraction Agent (EEA) that uses domain ontologies (UMLS, MeSH, SNOMED CT) for entity discovery. The Relationship Extraction Agent (REA) validates semantic connections between entities, while the Schema Alignment Agent (SAA) ensures type consistency. Conflict Resolution Agent (CRA) resolves contradictory triplets through multi-layer assessment, and the Evaluator Agent (EA) computes confidence, clarity, and relevance scores for final integration. The system employs three LLM backbones (GLM-4, GPT-4o, DeepSeek-v3) with entity normalization via embedding distance and triplet integration using thresholded mean scores.

## Key Results
- Identifies up to 38,230 new entities across genomics, proteomics, and metabolomics domains
- Achieves 83.1% LLM-verified correctness in extracted knowledge triplets
- Reduces conflict edges by 18.6% through multi-layer conflict assessment mechanisms

## Why This Works (Mechanism)
KARMA's effectiveness stems from its specialized multi-agent architecture that decomposes complex knowledge extraction into focused subtasks. Each agent performs domain-specific processing with clear input-output contracts, allowing for targeted optimization and error isolation. The sequential pipeline ensures semantic consistency as information flows from raw text through entity extraction to relationship validation and conflict resolution. Domain ontology integration provides semantic grounding for entity normalization, while the multi-layer conflict assessment mechanism systematically evaluates contradictory evidence to maintain KG quality. The threshold-based integration approach filters low-confidence extractions, ensuring only high-quality triplets enter the knowledge graph.

## Foundational Learning
- Multi-agent LLM architecture: Why needed - decomposes complex extraction tasks into specialized components for accuracy and scalability; Quick check - verify each agent's output format matches next agent's input requirements
- Domain ontology integration: Why needed - ensures semantic consistency and entity normalization across scientific literature; Quick check - validate extracted entities map correctly to UMLS/MeSH identifiers
- Conflict resolution through multi-layer assessment: Why needed - scientific literature often contains contradictory findings requiring systematic reconciliation; Quick check - examine CRA's resolution of conflicting triplets from different articles
- Threshold-based triplet integration: Why needed - filters low-confidence extractions to maintain KG quality; Quick check - analyze score distributions to calibrate Θ threshold

## Architecture Onboarding
- Component map: Ingestion -> Reader -> Summarizer -> EEA -> REA -> SAA -> CRA -> EA
- Critical path: EEA → REA → CRA (entity extraction, relationship validation, and conflict resolution form the core quality assurance pipeline)
- Design tradeoffs: Sequential agent pipeline maximizes accuracy through specialized processing but increases latency; parallel processing could improve speed but risks semantic inconsistencies
- Failure signatures: High entity noise indicates EEA ontology filtering issues; schema drift suggests SAA classification failures; low QA coherence despite high correctness reveals Reader Agent filtering problems
- Three first experiments: 1) Run single document through all agents with DeepSeek-v3 to verify workflow; 2) Compare entity extraction accuracy across three LLM backbones; 3) Test conflict resolution on known contradictory triplets from literature

## Open Questions the Paper Calls Out
None

## Limitations
- Missing specific threshold values (δ, θ_r, ρ, Θ) and weight parameters (α_i, β_j, γ_k) require manual tuning for reproducibility
- Entity normalization depends on unspecified BERT-based embedding model, creating potential inconsistencies
- LLM-verified correctness metric lacks human validation, raising questions about reliability for critical applications

## Confidence
- High confidence: Multi-agent architecture design and sequential workflow with complete agent prompts provided
- Medium confidence: Coverage and conflict ratio improvements (38,230 entities, 18.6% reduction) are well-documented
- Low confidence: Correctness metric (83.1%) interpretation given lack of human validation and unspecified aggregation weights

## Next Checks
1. Implement parameter sweep for four critical thresholds (δ, θ_r, ρ, Θ) on small validation set to identify stable operating points
2. Compare entity normalization results using multiple BERT-based models (SciBERT vs BioBERT) to verify robustness
3. Conduct human annotation validation on 100 randomly sampled triplets to benchmark LLM-verified correctness against ground truth