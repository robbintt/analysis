---
ver: rpa2
title: Towards Provably Unlearnable Examples via Bayes Error Optimisation
arxiv_id: '2511.08191'
source_url: https://arxiv.org/abs/2511.08191
tags:
- data
- error
- bayes
- unlearnable
- examples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the problem of protecting user data from\
  \ being exploited in machine learning training, particularly when data is collected\
  \ without explicit consent. The authors propose a method for constructing unlearnable\
  \ examples that are provably harder for models to learn from by systematically maximizing\
  \ the Bayes error\u2014a measure of inherent classification difficulty."
---

# Towards Provably Unlearnable Examples via Bayes Error Optimisation

## Quick Facts
- arXiv ID: 2511.08191
- Source URL: https://arxiv.org/abs/2511.08191
- Reference count: 15
- Primary result: Achieves 28.12% accuracy when training on fully unlearnable CIFAR-10 data

## Executive Summary
This paper addresses the critical problem of protecting user data from unauthorized machine learning training by proposing a method to create provably unlearnable examples. The authors develop an approach that systematically maximizes the Bayes error—a fundamental measure of classification difficulty—to make data inherently harder to learn from. By using projected gradient ascent to optimize Bayes error under perceptual constraints, they create examples that remain effective even when mixed with clean data and resist standard adversarial defenses.

## Method Summary
The authors propose a novel method for generating unlearnable examples by maximizing the Bayes error through projected gradient ascent optimization. The approach involves estimating the Bayes error and then iteratively perturbing input data to systematically increase this error bound while maintaining perceptual similarity through norm-constrained optimization. The method guarantees an increase in Bayes error through theoretical analysis and demonstrates effectiveness across multiple image classification benchmarks. The optimization process ensures that perturbations remain imperceptible while making the examples fundamentally harder for learning algorithms to extract useful patterns.

## Key Results
- Test accuracy drops from 95.12% to 28.12% when training on fully unlearnable CIFAR-10 data
- Maintains effectiveness with 50% clean data mixing, dropping accuracy from 91.16% to 69.68%
- Outperforms existing approaches and achieves only 74.5% accuracy under adversarial training defenses
- Shows consistent performance across CIFAR-10, CIFAR-100, and Tiny ImageNet datasets

## Why This Works (Mechanism)
The method works by directly targeting the Bayes error—the theoretical minimum error rate achievable by any classifier. By systematically maximizing this fundamental limit through carefully crafted perturbations, the approach creates data that is inherently unlearnable regardless of the learning algorithm used. The projected gradient ascent optimization ensures that perturbations increase classification difficulty while remaining imperceptible to humans, making the unlearnable examples effective even when mixed with clean training data.

## Foundational Learning
- Bayes Error: The theoretical minimum classification error achievable by any classifier - needed to understand the fundamental limit being maximized
- Projected Gradient Ascent: Optimization technique for constrained maximization - needed to understand how perturbations are computed while maintaining perceptual bounds
- Norm-Bounded Constraints: Mathematical limits on perturbation magnitude - needed to ensure generated examples remain imperceptible
- Adversarial Training: Defense mechanism against adversarial examples - needed to understand the robustness of the approach
- Image Classification Benchmarks: Standard datasets like CIFAR-10/100 - needed to contextualize experimental results

## Architecture Onboarding

**Component Map**
Data Preparation -> Bayes Error Estimation -> Projected Gradient Ascent -> Unlearnable Example Generation -> Model Training

**Critical Path**
The core pipeline follows: Bayes error estimation → gradient ascent optimization → perturbation application → training evaluation. The critical component is the Bayes error estimation function, as it determines the optimization direction.

**Design Tradeoffs**
The method trades computational efficiency for theoretical guarantees - each unlearnable example requires multiple optimization iterations. The norm constraints balance between effectiveness and imperceptibility, where tighter bounds reduce effectiveness but maintain better visual quality.

**Failure Signatures**
- Insufficient Bayes error increase indicates poor initialization or optimization
- High perceptual similarity to clean data suggests norm constraints are too tight
- Complete model failure suggests perturbations are too aggressive

**First Experiments**
1. Verify Bayes error estimation accuracy on clean CIFAR-10 images
2. Test single-image unlearnable example generation and validation
3. Evaluate mixed dataset performance with 10% unlearnable examples

## Open Questions the Paper Calls Out
None

## Limitations
- Computational overhead from multiple optimization steps per image limits scalability
- Reliance on specific assumptions about loss function and optimization landscape
- Focus on image classification tasks with unclear generalizability to other data types

## Confidence
- High confidence: Empirical effectiveness on standard benchmarks (CIFAR-10/100, Tiny ImageNet)
- Medium confidence: Theoretical guarantees about Bayes error maximization
- Medium confidence: Generalizability across different model architectures

## Next Checks
1. Test effectiveness against state-of-the-art adversarial training defenses with adaptive loss functions
2. Evaluate computational efficiency and scalability on datasets 10x larger than CIFAR-10
3. Assess transferability of unlearnable examples across different model architectures beyond tested ones