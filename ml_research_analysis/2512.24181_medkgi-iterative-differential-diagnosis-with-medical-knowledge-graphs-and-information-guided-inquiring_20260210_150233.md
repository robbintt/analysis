---
ver: rpa2
title: 'MedKGI: Iterative Differential Diagnosis with Medical Knowledge Graphs and
  Information-Guided Inquiring'
arxiv_id: '2512.24181'
source_url: https://arxiv.org/abs/2512.24181
tags:
- diagnostic
- diagnosis
- medical
- clinical
- medkgi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MedKGI addresses limitations in LLM-based clinical diagnosis by
  integrating a medical knowledge graph to ground hypotheses, an information gain-based
  strategy to prioritize discriminative questions, and a structured OSCE-format diagnostic
  record for consistent evidence tracking. This framework models iterative differential
  diagnosis by constraining reasoning to validated ontologies, dynamically selecting
  symptoms that maximize diagnostic uncertainty reduction, and maintaining coherent
  dialogue states.
---

# MedKGI: Iterative Differential Diagnosis with Medical Knowledge Graphs and Information-Guided Inquiring

## Quick Facts
- **arXiv ID:** 2512.24181
- **Source URL:** https://arxiv.org/abs/2512.24181
- **Reference count:** 33
- **Key outcome:** State-of-the-art diagnostic accuracy (69.81%) with 30% fewer dialogue turns than baselines.

## Executive Summary
MedKGI is a framework for iterative differential diagnosis that combines medical knowledge graphs, information gain-based questioning, and structured state tracking. The system constrains LLM reasoning to validated ontologies, dynamically selects symptoms that maximize diagnostic uncertainty reduction, and maintains coherent dialogue states through an OSCE-format record. Experiments demonstrate superior performance in both accuracy and efficiency compared to existing methods.

## Method Summary
MedKGI uses a multi-stage process where the Doctor Agent generates differential diagnoses, which are then grounded in PrimeKG through entity alignment. The system calculates information gain for candidate symptoms based on current disease probabilities, selects the most informative question, and updates a structured OSCE JSON record. The framework uses a patient simulation environment with three agents (Doctor, Patient, Measurement) and terminates when diagnostic accuracy is achieved or maximum rounds are reached.

## Key Results
- Achieves state-of-the-art diagnostic accuracy of 69.81% on clinical benchmarks
- Reduces dialogue turns by 30% compared to baseline methods
- Demonstrates significant performance gains through ablation studies (IG vs. random selection shows 38.68% accuracy difference)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Constraining LLM reasoning to a medical Knowledge Graph (KG) appears to reduce hallucinations and ground hypotheses in validated clinical relationships.
- **Mechanism:** The framework maps patient symptoms and LLM-proposed diseases to entities within a structured KG (PrimeKG). Instead of free-form generation, the LLM generates a differential set, which is then filtered or expanded based on the graph's disease-symptom edges, ensuring the reasoning space is medically valid.
- **Core assumption:** The underlying Knowledge Graph (PrimeKG) is comprehensive and accurate enough to capture the relevant disease-symptom relationships for the target cases.
- **Evidence anchors:** [abstract]: "...integrates a medical knowledge graph (KG) to constrain reasoning to validated medical ontologies..."; [section 4.2]: Describes the multi-stage alignment pipeline (Exact, Edit-Distance, Semantic) to map text to KG nodes.

### Mechanism 2
- **Claim:** Using Information Gain (IG) to select questions seems to drive diagnostic efficiency by maximizing the expected reduction in uncertainty (entropy).
- **Mechanism:** The system maintains a probability distribution over candidate diseases. It simulates asking about potential symptoms and calculates the expected entropy reduction ($H(D) - H(D|s)$) for each. The symptom that maximizes this gain is selected for the next turn, theoretically pruning the hypothesis space faster than random selection.
- **Core assumption:** Symptoms are conditionally independent given a disease (Naive Bayes assumption), and uniform likelihoods are sufficient approximations for complex medical interactions.
- **Evidence anchors:** [abstract]: "...selects questions based on information gain to maximize diagnostic efficiency..."; [section 4.3]: Explicitly defines $IG(s) = H(D) - H(D|s)$ as the selection criteria.

### Mechanism 3
- **Claim:** Maintaining an explicit, structured state (OSCE record) likely mitigates context overloading and inconsistency in multi-turn dialogues.
- **Mechanism:** Rather than relying on the LLM's implicit attention over a growing history, the system updates a structured JSON "Diagnostic Record" (symptoms, history, exams) at every turn. This acts as a "working memory" or state machine, ensuring the LLM sees a consistent summary rather than raw dialogue history.
- **Core assumption:** The LLM is capable of reliably extracting structured data from unstructured text to update the JSON state without introducing errors.
- **Evidence anchors:** [abstract]: "...adopts an OSCE-format structured state to maintain consistent evidence tracking across turns."; [section 4.4]: Describes the JSON schema management to prevent context overloading.

## Foundational Learning

- **Concept: Differential Diagnosis (DDx)**
  - **Why needed here:** The core task is not single-shot classification but an iterative narrowing of a hypothesis set.
  - **Quick check question:** How does Bayes' theorem allow us to update the probability of a disease $D$ given a new positive or negative symptom $s$?

- **Concept: Shannon Entropy**
  - **Why needed here:** Used as the metric for "diagnostic uncertainty." The system seeks to minimize this value.
  - **Quick check question:** If you have two candidate diseases with probabilities 0.5 and 0.5, versus 0.9 and 0.1, which state has higher entropy (uncertainty)?

- **Concept: Conditional Independence**
  - **Why needed here:** The paper's math for calculating $P(S_{pos}, S_{neg} | D_i)$ relies on assuming symptoms are independent once the disease is known.
  - **Quick check question:** Why might "cough" and "sore throat" *not* be conditionally independent in a patient with a cold, and how does violating this assumption affect Information Gain?

## Architecture Onboarding

- **Component map:** Doctor Agent -> KG Module (PrimeKG + Entity Alignment) -> IG Selector -> State Manager -> Patient/Measurement Agents
- **Critical path:** Input (Patient Profile & OSCE State) -> Hypothesize (LLM proposes differential) -> Ground (Map to KG) -> Plan (Calculate IG for symptoms) -> Act (Select symptom) -> Update (Receive answer & update state)
- **Design tradeoffs:** KG Constraint vs. Breadth (prevents hallucinations but limits to known entities); Naive Bayes vs. Accuracy (simplifies calculation but may reduce accuracy in complex syndromes)
- **Failure signatures:** Stagnation (differential set unchanged for $n$ turns); Entity Misalignment (high threshold causes valid terms to be rejected)
- **First 3 experiments:**
  1. KG Ablation: Run system with KG module disabled to verify hallucination reduction claim on MedQA subset
  2. Hyperparameter Tuning: Test candidate disease count and $k$ ratio for optimal balance
  3. State Consistency Check: Inject contradiction into Patient Agent responses to test OSCE State Manager handling

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does MedKGI's performance change when deployed in real-world clinical settings with ambiguous patient narratives, compared to current LLM-generated simulations?
- Basis in paper: [explicit] The authors state their "patient simulation relies on LLM-generated case descriptions that may not fully capture the ambiguity of real patient narratives."
- Why unresolved: Current evaluation relies entirely on simulated agents that don't replicate linguistic imprecision or non-cooperation of human patients.
- What evidence would resolve it: User study or live clinical deployment comparing MedKGI's interaction logs against simulated benchmarks.

### Open Question 2
- Question: Would replacing the uniform conditional probability model with data-driven likelihoods improve diagnostic discrimination for diseases with complex symptom correlations?
- Basis in paper: [explicit] The authors note their method assumes "conditional independence among symptoms given a disease and employ[s] uniform likelihood... [which] may lead to suboptimal question selection."
- Why unresolved: Current method uses simplified probability model rather than weighted probabilities from epidemiological data.
- What evidence would resolve it: Ablation study integrating learned conditional probabilities into information gain calculation.

### Open Question 3
- Question: Can the information gain-based strategy remain effective when patients underreport stigmatized symptoms or provide anxiety-driven responses?
- Basis in paper: [explicit] The authors acknowledge their "patient agent assumes cooperative and coherent symptom reporting," whereas real patients exhibit "cognitive or linguistic biases: underreporting stigmatized symptoms... or anxiety-driven concerns."
- Why unresolved: Framework optimizes for information gain assuming truthful/cooperative inputs, lacking mechanism to detect or adapt to deceptive/biased inputs.
- What evidence would resolve it: Stress-testing with adversarial patient agents programmed to withhold symptoms or simulate high-anxiety verbosity.

## Limitations
- Framework's reliance on PrimeKG's coverage creates critical dependencyâ€”cannot diagnose diseases outside the graph
- Naive Bayes assumption for symptom independence may break down in complex clinical presentations with correlated symptoms
- Paper does not specify stagnation threshold $n$ or provide complete Measurement Agent prompts for exact reproduction

## Confidence
- **High Confidence:** Information Gain calculation methodology and structured OSCE state management approach
- **Medium Confidence:** Entity alignment pipeline using PubMedBERT with threshold 0.85, Bayesian update mechanism for negative symptoms
- **Low Confidence:** Termination conditions (particularly stagnation threshold $n$), complete Measurement Agent functionality

## Next Checks
1. **Entity Alignment Robustness Test:** Measure how often valid medical terms fail the 0.85 threshold across diverse symptom set, evaluate performance with stricter (0.90) and looser (0.80) thresholds
2. **Independence Assumption Validation:** Design controlled experiment with correlated symptom pairs (e.g., cough/sore throat) to measure whether IG-based selection produces redundant questions compared to correlation-aware baseline
3. **Stagnation Threshold Sensitivity:** Run system with different values of $n$ (e.g., 2, 3, 5 consecutive turns) to determine impact on diagnostic accuracy and dialogue efficiency in ambiguous cases