---
ver: rpa2
title: Controllable Pareto Trade-off between Fairness and Accuracy
arxiv_id: '2509.13651'
source_url: https://arxiv.org/abs/2509.13651
tags:
- fairness
- loss
- reference
- vector
- pareto
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of balancing fairness and accuracy
  in NLP tasks by proposing a controllable Pareto trade-off method (CPT) that allows
  users to specify their preference for fairness and accuracy through reference vectors.
  The core idea involves using multi-objective optimization with moving average gradients
  to stabilize updates and gradient pruning to reduce dimensionality, enabling more
  precise control over the trade-off between fairness and accuracy.
---

# Controllable Pareto Trade-off between Fairness and Accuracy

## Quick Facts
- **arXiv ID**: 2509.13651
- **Source URL**: https://arxiv.org/abs/2509.13651
- **Reference count**: 40
- **Primary result**: CPT achieves controllable fairness-accuracy trade-offs via moving average gradients, gradient pruning, and reference vector guidance

## Executive Summary
This paper addresses the challenge of balancing fairness and accuracy in NLP tasks by proposing a controllable Pareto trade-off method (CPT) that allows users to specify their preference for fairness and accuracy through reference vectors. The core idea involves using multi-objective optimization with moving average gradients to stabilize updates and gradient pruning to reduce dimensionality, enabling more precise control over the trade-off between fairness and accuracy. Experiments on hate speech detection and occupation classification tasks demonstrate that CPT outperforms baseline methods in terms of hypervolume on the Pareto front and achieves better controllability, precisely following human-defined reference vectors while maintaining good generalization to unseen data.

## Method Summary
CPT employs a two-stage optimization process: a correction stage that optimizes a single objective until the KL divergence constraint is met, followed by a multi-objective optimization (MOO) stage that jointly optimizes fairness loss, accuracy loss, and a KL constraint to follow reference vectors. The method stabilizes fairness updates using moving average gradients across mini-batches and reduces gradient dimensionality through pruning of low-magnitude parameters. The common descent direction is computed using the Multiple Gradient Descent Algorithm (MGDA) with Frank-Wolfe solver, allowing the model to navigate the Pareto front according to user-specified preferences.

## Key Results
- CPT achieves higher hypervolume on Pareto front compared to MGDA and scalarization baselines
- The method demonstrates superior controllability, precisely following specified reference vectors
- CPT maintains good generalization to unseen data while achieving the desired fairness-accuracy trade-off
- Moving average gradients and gradient pruning contribute to stable optimization and improved solution quality

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Moving average gradients mitigate fairness loss drift caused by mini-batch stochasticity.
- **Mechanism**: The fairness gradient $\bar{G}_k = \beta \bar{G}_{k-1} + (1-\beta) \nabla_\theta L(\theta)$ accumulates gradients across steps, ensuring subgroups missing from the current mini-batch are still represented in the update direction. This stabilizes the common descent vector computation in MGDA.
- **Core assumption**: The moving average weight $\beta$ is tuned such that the averaged gradient approximates the full gradient without introducing excessive lag.
- **Evidence anchors**: [abstract] "CPT 1) stabilizes the fairness update with a moving average of stochastic gradients to determine the update direction"; [Section 3.2] "by accumulating the previous fairness gradients, CPT takes into account those subgroups that might be missing in the current mini-batch"
- **Break condition**: If $\beta$ is too high, gradients become stale; if too low, drift persists.

### Mechanism 2
- **Claim**: Gradient pruning reduces noise in the common descent direction by retaining only high-magnitude parameters.
- **Mechanism**: A pruning mask $M$ zeroes out gradients of parameters below threshold $\gamma \|\theta\|_1$. The pruned gradient $\tilde{G}_i = M \odot \bar{G}_i$ is used to compute MGDA weights $\alpha$, yielding a less noisy common descent vector $g = \sum_i \alpha_i \tilde{G}_i$.
- **Core assumption**: Parameters with larger magnitudes are more influential for optimization; low-magnitude parameters contribute noise to inner products.
- **Evidence anchors**: [abstract] "prunes the gradients by only keeping the gradients of the critical parameters"; [Section 3.3] "high-dimension gradients could be dominated by noise, making the common descent vector calculated by MGDA imprecise"
- **Break condition**: Over-aggressive pruning ($\gamma$ too large) removes informative gradients; under-pruning fails to denoise.

### Mechanism 3
- **Claim**: Reference vectors guide optimization to user-specified regions of the Pareto front via a two-stage process.
- **Mechanism**: A reference vector $\vec{v} = (v_{fair}, v_{acc})$ encodes preference ratios. The constraint loss $\Psi(\vec{l}, \vec{v}) = D_{KL}(\vec{l}/\|\vec{l}\|_1 \| \vec{v}/\|\vec{v}\|_1)$ penalizes deviation. Stage 1 (correction) optimizes a single objective until $\Psi < \psi$; Stage 2 (MOO) jointly optimizes $L_{fair}$, $L_{acc}$, and $\Psi$.
- **Core assumption**: The KL constraint is sufficient to keep the solution near the reference vector direction throughout training.
- **Evidence anchors**: [abstract] "allows users to specify their preference for fairness and accuracy through reference vectors"; [Section 3.4] "CPT applies two stages for the optimization: correction stage and MOO stage"
- **Break condition**: If the threshold $\psi$ is too loose, solutions drift; if too tight, optimization may fail to satisfy the constraint.

## Foundational Learning

- **Concept: Pareto stationarity in multi-objective optimization**
  - **Why needed here**: CPT aims to produce Pareto-optimal trade-offs; understanding that no single direction improves all objectives simultaneously is essential.
  - **Quick check question**: Can you explain why a Pareto-stationary solution cannot be improved on one objective without degrading another?

- **Concept: Equalized Odds (EODD) fairness metric**
  - **Why needed here**: The fairness loss $L_{fair}$ is defined via DiffEodd, which enforces equal TPR and FPR across groups conditioned on labels.
  - **Quick check question**: Given a classifier's confusion matrices for two groups, how would you compute the EODD gap?

- **Concept: Exponential moving average for gradient stabilization**
  - **Why needed here**: Mechanism 1 relies on EMA to approximate full gradients; understanding momentum-like smoothing is critical.
  - **Quick check question**: What happens to the effective gradient if $\beta = 0.9$ versus $\beta = 0.5$ over 10 steps?

## Architecture Onboarding

- **Component map**: Input (X, Y, A) → Sentence Transformer encoder → 2 FC layers (classifier) → Compute L_acc and L_fair → Gradient EMA → Gradient pruning → MGDA (Frank-Wolfe) → α weights → Common descent vector g → Parameter update: θ ← θ - ηg
- **Critical path**: Initialize moving averages; per batch compute losses; correction stage until KL<ψ; MOO stage with pruned gradients; update parameters.
- **Design tradeoffs**:
  - **Pruning ratio γ**: Higher γ removes more noise but risks losing signal. Paper does not report systematic ablation.
  - **Moving average weight β**: Controls stability vs. responsiveness. Figure 2 shows sensitivity; β_fair ∈ [0.80, 0.88] shifts dominance.
  - **Reference vectors**: Choice of v determines trade-off region. Paper uses 6 vectors; coverage of full Pareto front is not guaranteed.
- **Failure signatures**:
  - Solutions clustering despite different v → KL constraint too loose or MOO not activated
  - Fairness loss remains high → β_fair too low or mini-batches miss subgroups
  - Gradient instability → pruning too aggressive or β near 1 with high learning rate
- **First 3 experiments**:
  1. Reproduce main results on Jigsaw with default hyperparameters (β=0.8, γ unspecified, ψ=0.002). Verify hypervolume improvement over baselines.
  2. Ablate pruning: Compare CPT vs. CPT(w/o Prune) on hypervolume and trajectory stability. Check if pruning primarily affects fairness or accuracy gradients.
  3. Vary β_fair while fixing β_acc on held-out reference vector to assess controllability sensitivity. Measure KL divergence between final l and v.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can the method be extended to generate a set of Pareto stationary solutions near a reference vector rather than converging to a single solution?
  - **Basis in paper**: [explicit] The conclusion states, "In the future work, we would like to explore how to get a set of Pareto stationary solutions near the reference vector instead of a single solution for each vector."
  - **Why unresolved**: The current implementation targets a specific point on the Pareto front for a given reference vector, limiting the user's ability to choose from multiple diverse solutions within the same preferred region.
  - **What evidence would resolve it**: A modification of the CPT algorithm that outputs a local subset of the Pareto front for a single reference vector, validated by diversity metrics.

- **Open Question 2**: How can the sensitivity to moving average weights (β) be reduced to ensure robustness across datasets with different distributions?
  - **Basis in paper**: [explicit] The "Limitations" section notes that "it could be tedious to tune the moving average weights" and "weights may not always generalize well... due to the difference in data distribution."
  - **Why unresolved**: The method currently depends on manual hyperparameter tuning for the gradient moving average, which threatens its practicality as a general-purpose fairness tool.
  - **What evidence would resolve it**: An adaptive weighting scheme or a theoretical analysis establishing safe default values that perform consistently across the Jigsaw and BiasBios datasets without retuning.

- **Open Question 3**: Can the optimization constraints be modified to ensure the fairness-accuracy trade-off holds at the class level rather than just the aggregate dataset level?
  - **Basis in paper**: [explicit] The "Limitations" section states, "the performance in each class may not follow the preference," and suggests the "community may need to consider a fine-grained fairness loss function."
  - **Why unresolved**: A globally controllable trade-off does not guarantee that specific subgroups (e.g., specific occupations in BiasBios) are treated fairly, as evidenced by the inconsistent TPR gaps in the case study.
  - **What evidence would resolve it**: A study applying CPT with a fine-grained loss function, demonstrating that the trade-off preference is statistically consistent across individual classes.

## Limitations

- **Hyperparameter sensitivity**: The method is sensitive to moving average weights (β) and pruning ratio (γ), requiring careful tuning that may not generalize across datasets.
- **Limited scope**: Experiments focus on two NLP tasks with binary sensitive attributes, leaving multi-group and non-NLP applications untested.
- **Computational efficiency claims**: Runtime and memory benefits of gradient pruning are not empirically quantified or compared to alternatives.

## Confidence

**High confidence**: The core methodology (moving average gradients for stability, gradient pruning for dimensionality reduction, two-stage MOO with reference vectors) is internally consistent and mathematically sound.

**Medium confidence**: The reported improvements in hypervolume and controllability are likely reproducible given the detailed algorithm description, but exact performance depends on sensitive hyperparameter choices that are underspecified.

**Low confidence**: Claims about practical applicability to real-world fairness scenarios are overstated given the limited experimental scope and lack of robustness testing.

## Next Checks

1. **Hyperparameter sensitivity analysis**: Systematically vary β_fair ∈ {0.70, 0.75, 0.80, 0.85, 0.90} and γ ∈ {0.1, 0.2, 0.3, 0.4, 0.5} on Jigsaw dataset, measuring hypervolume, KL divergence from reference vectors, and training stability. Report variance across seeds.

2. **Multi-group extension test**: Apply CPT to a dataset with intersectional subgroups (e.g., gender×age combinations) and evaluate whether the moving average gradient mechanism maintains fairness across all subgroups, not just binary splits.

3. **Cross-dataset generalization**: Train CPT on Jigsaw, then evaluate performance on an unseen toxicity dataset (e.g., Civil Comments) using the same reference vectors. Measure degradation in accuracy, fairness, and ability to follow reference vectors compared to in-distribution performance.