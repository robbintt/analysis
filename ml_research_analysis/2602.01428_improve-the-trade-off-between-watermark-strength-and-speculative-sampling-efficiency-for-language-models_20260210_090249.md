---
ver: rpa2
title: Improve the Trade-off Between Watermark Strength and Speculative Sampling Efficiency
  for Language Models
arxiv_id: '2602.01428'
source_url: https://arxiv.org/abs/2602.01428
tags:
- watermark
- sampling
- strength
- token
- speculative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the trade-off between watermark strength and
  sampling efficiency in speculative decoding for large language models (LLMs). The
  key insight is that maximal watermark strength is achieved when token generation
  is a deterministic function of pseudorandom numbers, but prior approaches weakened
  this by introducing randomness in token acceptance.
---

# Improve the Trade-off Between Watermark Strength and Speculative Sampling Efficiency for Language Models

## Quick Facts
- arXiv ID: 2602.01428
- Source URL: https://arxiv.org/abs/2602.01428
- Reference count: 40
- Key outcome: Introduces pseudorandom draft-token acceptance to break the trade-off between watermark strength and speculative sampling efficiency, achieving maximum watermark strength (entropy of target distribution) while maintaining optimal sampling efficiency (1-TV(Q,P)).

## Executive Summary
This work addresses the fundamental trade-off between watermark strength and sampling efficiency in speculative decoding for large language models. The key insight is that maximal watermark strength is achieved when token generation is a deterministic function of pseudorandom numbers, but prior approaches weakened this by introducing randomness in token acceptance. To overcome this, the authors propose a principled method that injects pseudorandomness into the draft-token acceptance decision itself, making the entire generation process a deterministic function of pseudorandom variables. This approach preserves unbiasedness, attains maximal speculative sampling efficiency (1−TV(Q,P)), and achieves maximum watermark strength (entropy of the target distribution). Experiments on ELI5 and C4 datasets with Llama and Gemma model pairs demonstrate that this method improves watermark detectability (e.g., TPR@FPR=1% up to 0.8 vs 0.6 for baselines) while maintaining sampling efficiency (AATPS ≈ 1.8-3.3 across settings), breaking the previously assumed trade-off.

## Method Summary
The method introduces pseudorandom draft-token acceptance to speculative sampling, where token generation becomes a deterministic function of pseudorandom variables. For each proposed draft token, acceptance/rejection is determined by a pseudorandom variable u=G(ζR) rather than a random coin flip. This preserves unbiasedness while achieving maximum watermark strength (Ent(P)) and sampling efficiency (1-TV(Q,P)). The approach works with both Gumbel-max and SynthID watermarking schemes, with experiments using tournament rounds m=30 for SynthID as a practical approximation to the theoretical m→∞.

## Key Results
- Achieves TPR@FPR=1% up to 0.8 on held-out test sets, improving over prior methods (0.6)
- Maintains sampling efficiency with AATPS ≈ 1.8-3.3 across settings, matching standard speculative sampling
- Preserves unbiasedness with LOGPPL matching baseline values within error bars
- Works across multiple model pairs (Llama-68M/7B, Gemma-2B/7B) and datasets (ELI5, C4)

## Why This Works (Mechanism)

### Mechanism 1: Watermark Strength via KL Divergence
- **Claim**: Watermark strength, quantified as expected KL divergence between watermarked and original token distributions, governs the exponential decay rate of p-values in statistical detection.
- **Mechanism**: The paper defines watermark strength as WS(Pζ) = Eζ[DKL(Pζ || P)], which under the unbiasedness condition (Eζ[Pζ] = P) is equivalent to mutual information I(w; ζ). Theorem 3.1 establishes that the p-value under the likelihood ratio test decays as exp(-nD) where D is the average KL divergence, directly linking this measure to detection sample complexity.
- **Core assumption**: The log-likelihood ratios are independent, uniformly bounded, and admit a common neighborhood around zero where their moment generating functions are finite. The watermarking scheme must be unbiased (Eζ[Pζ] = P).
- **Evidence anchors**:
  - [abstract]: "We introduce a quantitative measure of watermark strength that governs statistical detectability"
  - [Section 3.1, Definition 3.1]: Formal definition of watermark strength via expected KL divergence
  - [Section 3.1, Theorem 3.1]: Proves p-value decay rate equals average KL divergence
  - [corpus]: Weak direct evidence; related work "Watermarking Degrades Alignment" examines watermark quality trade-offs but not this specific KL-based strength measure

### Mechanism 2: Maximum Strength via Degeneracy
- **Claim**: Maximum watermark strength is attained if and only if each token is a deterministic function of the pseudorandom number ζ (i.e., Pζ is degenerate, placing all mass on a single token).
- **Mechanism**: Theorem 3.2 proves that WS(Pζ) = Ent(P) - Eζ[Ent(Pζ)] ≤ Ent(P), with equality holding iff Ent(Pζ) = 0 almost surely. Intuitively, when the watermarked distribution is degenerate for each ζ, the token is fully determined by the pseudorandom seed, maximizing the mutual information between token and seed. Both Gumbel-max and SynthID (as tournament rounds m → ∞) achieve this maximum.
- **Core assumption**: The watermark must be unbiased. For SynthID, the tournament rounds m must approach infinity for the degeneracy guarantee.
- **Evidence anchors**:
  - [abstract]: "maximized when tokens are deterministic functions of pseudorandom numbers"
  - [Section 3.1, Theorem 3.2]: Proves the upper bound and degeneracy condition
  - [Section 3.1, Theorem 3.3]: Confirms Gumbel-max and SynthID (m → ∞) achieve maximum strength
  - [corpus]: No direct corpus evidence on degeneracy achieving maximum strength

### Mechanism 3: Breaking the Trade-off via Pseudorandom Acceptance
- **Claim**: Pseudorandom draft-token acceptance enables simultaneous achievement of maximal watermark strength and maximal speculative sampling efficiency, breaking the previously believed unavoidable trade-off.
- **Mechanism**: Standard speculative sampling uses truly random acceptance decisions, which introduce residual randomness that weakens watermark coupling. By making acceptance variable u = G(ζR) pseudorandom (deterministic given seed ζR), the entire token generation process becomes a deterministic function of (ζD, ζT, ζR). Algorithm 1 implements this: draft tokens from QζD, accept/reject via pseudorandom u, and sample from residual distribution (P-Q)+,ζT on rejection. Theorem 4.1 proves this preserves unbiasedness, achieves sampling efficiency SE = 1 - TV(Q, P), and maintains maximum watermark strength WS = Ent(P).
- **Core assumption**: ζD, ζT, ζR are independent pseudorandom variables. The watermark decoder S is unbiased and degenerate (achieves maximum strength). Repeated context masking is applied to maintain unbiasedness for repeated contexts.
- **Evidence anchors**:
  - [abstract]: "introduce a principled mechanism that injects pseudorandomness into draft-token acceptance, ensuring maximal watermark strength while maintaining speculative sampling efficiency"
  - [Section 4.1, Theorem 4.1]: Proves unbiasedness, maximum sampling efficiency (SE = 1 - TV(Q, P)), and maximum watermark strength (WS = Ent(P))
  - [Section 5, Figure 2]: Experiments show AATPS matches standard speculative sampling while TPR improves
  - [corpus]: No corpus papers address this pseudorandom acceptance mechanism

## Foundational Learning

- **Concept: Speculative Sampling (Draft-Then-Verify)**
  - **Why needed here**: The paper's entire contribution centers on reconciling watermarking with speculative sampling efficiency. Without understanding that speculative sampling uses a lightweight draft model to propose tokens and a target model to verify them in parallel, the trade-off problem and solution are incomprehensible.
  - **Quick check question**: Given draft distribution Q and target distribution P, what is the acceptance probability for a proposed token w'? Answer: min{1, P(w')/Q(w')}.

- **Concept: KL Divergence and Mutual Information**
  - **Why needed here**: The paper's quantitative watermark strength measure is defined via expected KL divergence, shown equivalent to mutual information under unbiasedness. Understanding that KL divergence measures distributional "distance" and mutual information quantifies dependence between variables is essential.
  - **Quick check question**: For unbiased watermark Pζ (Eζ[Pζ] = P), what is WS(Pζ) = Eζ[DKL(Pζ || P)] equivalent to? Answer: Mutual information I(w; ζ).

- **Concept: Unbiased Watermarking**
  - **Why needed here**: The paper's theory and mechanism explicitly require unbiased watermarks (Eζ[Pζ] = P). Understanding that unbiased watermarks preserve the original token distribution when averaged over pseudorandomness is critical for interpreting Theorem 3.2 and 4.1.
  - **Quick check question**: What property must a watermarking decoder S satisfy for unbiasedness? Answer: Eζ[S(P, ζ)] = P for all token distributions P.

## Architecture Onboarding

- **Component map**:
  - Watermark decoder S: Maps (P, ζ) → Pζ. Examples: Gumbel-max (argmax over log(Uw)/Pw), SynthID tournament sampling (Tgm ◦ ... ◦ Tg1(P))
  - Draft model QζD = S(Q, ζD): Watermarked lightweight model proposing K tokens
  - Target model PζT = S(P, ζT): Watermarked large model verifying proposals
  - Pseudorandom acceptance variable u = G(ζR): Replaces random acceptance coin flip, enables deterministic generation
  - Residual sampler (P-Q)+,ζT = S((P-Q)+, ζT): Samples replacement token when draft rejected
  - Detection module: Uses (yD, yT, u) for Gumbel-max (Ars-τ) or (yD, yT, u) with MLP for SynthID (Bayes-MLP)

- **Critical path**:
  1. Generate K draft tokens from QζD sequentially
  2. Compute target logits for all K+1 positions in parallel
  3. For each draft token: compute u = G(ζR), accept if u < min{1, P(w)/Q(w)}, else sample from residual and break
  4. If all K accepted: sample bonus token from PζT
  5. Detection: select correct test statistic using (u, threshold τ) for Gumbel-max or trained MLP for SynthID

- **Design tradeoffs**:
  - **Lookahead K**: Larger K increases potential speedup but requires more parallel target forward passes; experiments use K ∈ {2, 3, 4}
  - **Tournament rounds m (SynthID)**: Higher m increases watermark strength (approaching degeneracy) but increases sampling complexity; experiments use m = 30 as practical approximation
  - **Detection threshold τ**: Tuned on validation set; lower τ trusts draft statistics more, higher τ trusts target/residual statistics more
  - **Temperature**: Lower temperatures (0.5 for Gumbel-max, 0.7 for SynthID in experiments) make detection more pronounced

- **Failure signatures**:
  - **AATPS significantly below standard speculative sampling**: Check if pseudorandom acceptance variable u is correctly generated from G(ζR) rather than truly random
  - **Detection TPR not improving vs. prior-based methods**: Verify that u is accessible during detection and MLP is properly trained (for SynthID) or τ is correctly calibrated (for Gumbel-max)
  - **Output quality degradation (LOGPPL increase)**: Check that unbiasedness conditions hold; verify repeated context masking is implemented
  - **Watermark strength below Ent(P)**: For SynthID, ensure m is sufficiently large; check that all three pseudorandom components (ζD, ζT, ζR) are independent

- **First 3 experiments**:
  1. **Validate efficiency preservation**: Run Algorithm 1 on ELI5 with Llama-68M/7B, measure AATPS for K ∈ {2, 3, 4}, compare against standard speculative sampling baseline; expect AATPS to match within confidence intervals (Table 1)
  2. **Validate detectability improvement**: Train Ars-τ (Gumbel-max) or Bayes-MLP (SynthID) on 1000 watermarked texts, evaluate TPR@FPR=1% on held-out 1000 texts; expect TPR to exceed prior-based baseline by 10-20% at 200 tokens (Figure 2)
  3. **Validate unbiasedness**: Compute log perplexity (LOGPPL) on generated texts; expect values to match standard speculative sampling within error bars, confirming Eζ[P'ζ] = P (Table 1, 2)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the pseudorandom acceptance mechanism be extended to tree-based speculative sampling methods?
- Basis in paper: [explicit] The Conclusion states that while the paper focuses on standard speculative sampling, the framework points toward "potential extensions to variants such as tree-based methods... which could further accelerate generation."
- Why unresolved: The current theoretical analysis and Algorithm 1 are formulated for the standard draft-then-verify loop, whereas tree-based methods require verification of multiple candidate branches simultaneously.
- Evidence: A theoretical extension of Theorem 4.1 or empirical experiments showing preserved watermark strength in tree-based decoders like SpecInfer or Medusa.

### Open Question 2
- Question: How can the framework be generalized to non-degenerate or biased watermarking schemes?
- Basis in paper: [explicit] The Conclusion notes that the current work applies to unbiased degenerate watermarks, but it is an "open and interesting direction to investigate how to extend our framework... to non-degenerate watermarks and even biased ones."
- Why unresolved: The proof of maximum watermark strength (Theorem 4.1) relies on the condition that the watermarked distribution is degenerate (point mass); this condition is violated by soft (non-degenerate) or biased watermarks.
- Evidence: Deriving new Pareto curves or a modified acceptance kernel that maintains efficiency when the entropy of the watermarked distribution is non-zero.

### Open Question 3
- Question: Does the pseudorandom acceptance mechanism influence the robustness of the watermark to human edits?
- Basis in paper: [explicit] The Conclusion identifies "investigating the impact of pseudorandom acceptance on robustness to editing" as an open direction, noting that human edits can weaken watermark signals.
- Why unresolved: While the paper demonstrates improved detectability (True Positive Rate), it does not test the persistence of the watermark signal under adversarial or benign text modifications.
- Evidence: Experiments measuring detection scores on watermarked text after subjecting it to standard robustness attacks, such as paraphrasing, insertion, or deletion.

## Limitations

- **Finite tournament rounds**: SynthID uses m=30 rounds as a practical approximation to the theoretical m→∞ required for true degeneracy, resulting in slightly suboptimal watermark strength.
- **Computational overhead**: The approach requires parallel target model forward passes for K+1 positions, maintaining the fundamental computational cost of speculative decoding.
- **Model dependency**: Experimental results are based on limited model pairs (Llama and Gemma), raising questions about generalizability to other model architectures.

## Confidence

**High Confidence (4/5)**: Claims about theoretical properties (Theorems 3.1, 3.2, 4.1) and their proofs are mathematically rigorous and internally consistent. The relationship between KL divergence, mutual information, and watermark strength is well-established.

**Medium Confidence (3/5)**: Experimental results showing improved TPR@FPR=1% while maintaining AATPS are credible given the controlled setup, but the limited model diversity (only Llama and Gemma pairs) and specific temperature settings (0.5, 0.7) reduce generalizability.

**Low Confidence (2/5)**: The practical impact of pseudorandom acceptance on real-world deployment scenarios remains uncertain, particularly regarding seed/key management, resistance to watermark removal attacks, and behavior under distribution shifts.

## Next Checks

1. **Efficiency-Preserving Validation**: Implement Algorithm 1 with K=3 on a held-out ELI5 test set using the same Llama-68M/7B pair. Measure AATPS over 1000 generated texts and verify it matches standard speculative sampling within 5% (expected: ~2.5 tokens per step). Document any computational overhead from parallel target passes.

2. **Watermark Strength Benchmarking**: Using the same 1000-text test set, compare TPR@FPR=1% at 200 tokens between: (a) proposed method with pseudorandom acceptance, (b) prior-based watermarking with standard speculative sampling, and (c) standard speculative sampling without watermarking. Expect proposed method to achieve ~0.8 TPR vs ~0.6 for prior methods.

3. **Unbiasedness Stress Test**: Generate 500 texts using the proposed method and compute LOGPPL. Compare against baseline (standard speculative sampling without watermarking) and verify the difference is <0.1 nats per token, confirming Eζ[P'ζ] = P holds empirically.