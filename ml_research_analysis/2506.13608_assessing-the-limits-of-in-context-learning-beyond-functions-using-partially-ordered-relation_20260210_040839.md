---
ver: rpa2
title: Assessing the Limits of In-Context Learning beyond Functions using Partially
  Ordered Relation
arxiv_id: '2506.13608'
source_url: https://arxiv.org/abs/2506.13608
tags:
- lobin
- task
- complexity
- performance
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how well Large Language Models (LLMs) can
  learn partial order relations using In-Context Learning (ICL). The authors propose
  a novel evaluation framework using k-shot c-complex prompts to test models' ability
  to infer transitive and anti-symmetric relations in posets, such as the "less than"
  and "divides" relations.
---

# Assessing the Limits of In-Context Learning beyond Functions using Partially Ordered Relation

## Quick Facts
- **arXiv ID**: 2506.13608
- **Source URL**: https://arxiv.org/abs/2506.13608
- **Reference count**: 40
- **Primary result**: ICL performance saturates with increasing task complexity due to fundamental rank limitations in meta-gradient updates

## Executive Summary
This paper investigates the limits of Large Language Models' ability to learn partial order relations through In-Context Learning (ICL). The authors propose a novel evaluation framework using k-shot c-complex prompts to test models' ability to infer transitive and anti-symmetric relations in posets, such as the "less than" and "divides" relations. Through theoretical analysis and empirical experiments across multiple open-source LLMs and GPT models, the paper demonstrates that while ICL can partially encode simple linear orders, performance degrades significantly as task complexity increases. The findings reveal that ICL's representational capacity is fundamentally constrained by the rank of meta-gradient updates, which cannot exceed the embedding dimension.

## Method Summary
The authors developed a comprehensive evaluation framework using k-shot c-complex prompts to assess ICL performance on partial order relations. They tested multiple open-source LLMs and GPT models on tasks involving "less than" and "divides" relations, systematically varying the complexity parameter c. The theoretical analysis examined the relationship between meta-gradient rank and embedding dimension, while task vector geometry analysis revealed collapsed latent representations for high-complexity prompts. The methodology combined empirical experimentation with mathematical analysis to establish fundamental limitations of ICL for relational reasoning beyond simple functions.

## Key Results
- ICL performance degrades significantly as task complexity increases, with models failing to generalize beyond simple linear orders
- Theoretical analysis shows ICL's representational capacity is fundamentally limited by the rank of meta-gradient updates, constrained by embedding dimension
- Task vector geometry analysis reveals collapsed latent representations for high-complexity prompts, confirming the saturation phenomenon

## Why This Works (Mechanism)
The mechanism underlying ICL's limitations stems from the fundamental constraint that meta-gradient updates cannot exceed the rank of the embedding dimension. When models attempt to learn partial order relations through ICL, they rely on updating internal representations based on in-context examples. However, the number of independent directions in which these representations can be updated is bounded by the embedding dimension. As task complexity increases (more complex partial orders), the number of independent relational constraints exceeds this bound, causing performance saturation. This creates a bottleneck where the model cannot adequately represent the full complexity of the target relation within the constraints of its embedding space.

## Foundational Learning
- **Partial order relations**: Transitive and anti-symmetric relations like "less than" and "divides" that form posets. Needed to understand the relational reasoning tasks being tested.
- **In-Context Learning (ICL)**: The ability of LLMs to learn from examples provided in the prompt without parameter updates. Quick check: Can the model correctly predict outputs for unseen inputs after seeing k examples?
- **Meta-gradient updates**: The mechanism by which ICL updates internal representations based on in-context examples. Quick check: Are the updates bounded by the embedding dimension?
- **Task vector geometry**: Analysis of how task representations behave in latent space as complexity increases. Quick check: Do representations collapse for high-complexity tasks?

## Architecture Onboarding
**Component map**: Embedding layer -> Attention mechanism -> Feed-forward network -> Task representation space -> Output layer
**Critical path**: Input examples → embedding → attention → meta-gradient computation → latent representation update → prediction
**Design tradeoffs**: Fixed embedding dimension vs. task complexity capacity; computational efficiency vs. representational power
**Failure signatures**: Performance saturation with increasing c-complexity; collapsed latent representations; inability to generalize beyond simple linear orders
**First experiments**: 1) Vary k-shot examples while holding complexity constant; 2) Test different partial order relations beyond less-than and divides; 3) Systematically vary embedding dimensions to test rank-limitation hypothesis

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical analysis relies heavily on a limited set of relations (less-than and divides) and specific model families
- Definition of "complexity" through c-complex prompts could benefit from more rigorous formal grounding
- Alternative learning mechanisms in LLMs cannot be entirely ruled out despite the presented evidence

## Confidence
- **High Confidence**: ICL performance degradation with increasing task complexity; empirical evidence of saturation
- **Medium Confidence**: Theoretical rank limitation claims; the mathematical framework is sound but empirical validation is limited
- **Medium Confidence**: Task vector geometry analysis; while methodologically sound, the interpretation of collapsed representations requires further validation

## Next Checks
1. Test additional partial order relations (e.g., subset inclusion, dependency graphs) to verify whether the observed limitations generalize beyond the two studied relations
2. Conduct ablation studies varying embedding dimensions systematically to test the rank-limitation hypothesis across different model families
3. Explore whether fine-tuning on partial order examples can overcome the identified ICL limitations, distinguishing between representational capacity and optimization constraints