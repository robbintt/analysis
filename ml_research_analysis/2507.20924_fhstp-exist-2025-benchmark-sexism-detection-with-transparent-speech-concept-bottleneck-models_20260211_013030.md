---
ver: rpa2
title: 'FHSTP@EXIST 2025 Benchmark: Sexism Detection with Transparent Speech Concept
  Bottleneck Models'
arxiv_id: '2507.20924'
source_url: https://arxiv.org/abs/2507.20924
tags:
- scbm
- scbmt
- task
- sexism
- xlm-roberta
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper describes a system for detecting and classifying sexism
  in social media posts. The authors developed two interpretable models based on a
  speech concept bottleneck approach: SCBM, which uses a list of 132 descriptive adjectives
  as human-interpretable bottleneck concepts, and SCBMT, which extends SCBM by fusing
  these adjective-based representations with transformer-generated embeddings.'
---

# FHSTP@EXIST 2025 Benchmark: Sexism Detection with Transparent Speech Concept Bottleneck Models

## Quick Facts
- **arXiv ID**: 2507.20924
- **Source URL**: https://arxiv.org/abs/2507.20924
- **Reference count**: 13
- **Primary result**: SCBMT outperforms fine-tuned transformers on fine-grained sexism categorization tasks while providing interpretable explanations

## Executive Summary
This paper presents a transparent approach to sexism detection using Speech Concept Bottleneck Models (SCBM) and their fusion variant (SCBMT). The system encodes tweets into human-interpretable adjective representations using a frozen LLM, then classifies them as sexist or non-sexist while providing explanations in terms of the most relevant descriptive adjectives. The SCBMT model fuses these adjective-based representations with transformer embeddings, achieving superior performance on fine-grained categorization tasks while maintaining interpretability. The approach ranked 6th for English and Spanish content and 4th for English-only in the binary sexism identification task at the EXIST 2025 benchmark.

## Method Summary
The authors developed three models for sexism detection: SCBM, which uses a frozen LLM to encode texts into 132 human-interpretable adjectives before classification; SCBMT, which fuses these adjective vectors with frozen XLM-RoBERTa embeddings; and a fine-tuned XLM-RoBERTa baseline. The LLM scores each adjective's relevance via marginalized probability of affirmative tokens, creating sparse, interpretable vectors. SCBMT projects these vectors and concatenates them with transformer embeddings for richer representation. Models were trained on EXIST2025 (6,920 train / 1,038 dev / 2,076 test) with additional augmentation from EXIST2024/2022 datasets, optimizing for macro-F1 during training and ICM-Soft metrics for evaluation.

## Key Results
- SCBMT outperformed fine-tuned transformers on fine-grained sexism categorization tasks
- SCBMT achieved 6th place for English and Spanish content, 4th place for English-only in binary sexism identification
- SCBM provided human-interpretable explanations through adjective vectors
- XLM-RoBERTa achieved best results for binary sexism identification

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Constraining the intermediate representation to human-readable adjectives forces the model to learn disentangled features, enabling inherent interpretability without post-hoc explanation tools.
- **Mechanism:** The architecture inserts a bottleneck layer where each neuron corresponds to a specific descriptive adjective. An LLM evaluates text against these adjectives, creating a sparse, human-readable vector. A lightweight classifier then maps this vector to the final sexism label.
- **Core assumption:** The LLM can accurately and consistently map nuances of sexism onto the predefined static list of 132 adjectives.
- **Evidence anchors:**
  - [abstract] "SCBM leverages large language models (LLMs) to encode input texts into a human-interpretable representation of adjectives, then used to train a lightweight classifier."
  - [section 2.3.1] "SCBM... provides human-interpretable explanations for the predictions in terms of the most related descriptive adjectives."
- **Break condition:** If the LLM's probability marginalization fails to capture context (e.g., sarcasm), the adjective vector will be garbage-in/garbage-out, and the lightweight classifier will fail.

### Mechanism 2
- **Claim:** Fusing "intention-oriented" concept vectors with "semantic" transformer embeddings compensates for the information loss typical in pure bottleneck models.
- **Mechanism:** SCBMT concatenates two vectors: (1) the high-level, explicit intention vector from the adjective bottleneck and (2) the rich, implicit contextual embedding from a frozen XLM-RoBERTa. The classifier learns to weigh explicit semantic cues against implicit contextual patterns.
- **Core assumption:** The adjective representation captures features orthogonal to the transformer's embeddings, specifically regarding intent and emotion.
- **Evidence anchors:**
  - [section 2.3.2] "This fusion enables the model to capture a more comprehensive range of textual features by integrating interpretable and contextual information."
  - [section 4] "SCBMT... outperforms fine-tuned transformers. This outcome can be directly attributed to the complementary semantic information captured by our adjective-based representation."
- **Break condition:** If the adjectives are redundant with the transformer's latent space, the fusion adds no value, only computational cost.

### Mechanism 3
- **Claim:** Using frozen LLMs for concept extraction preserves language robustness better than fine-tuning, as the frozen LLM retains its pre-trained multilingual reasoning capabilities.
- **Mechanism:** Rather than updating model weights (which can overfit to specific language patterns in the training set), the system uses a frozen LLM to project text into a concept space. This acts as a language-agnostic semantic anchor.
- **Core assumption:** The prompt and adjective lexicon are of sufficient quality that the LLM does not require fine-tuning to understand the domain context.
- **Evidence anchors:**
  - [section 4] "Although our adjectives and prompts were only designed for English, SCBMT still performed comparably well on Spanish data... suggesting a high degree of language robustness."
  - [corpus] Neighbor paper "Demographic Biases and Gaps in the Perception of Sexism in Large Language Models" suggests LLMs have existing, albeit biased, perceptions of sexism that can be leveraged.
- **Break condition:** Complex prompt dependencies or low-resource languages not well-represented in the LLM's pre-training data will likely cause performance degradation.

## Foundational Learning

- **Concept: Concept Bottleneck Models (CBM)**
  - **Why needed here:** This is the core architecture replacing standard black-box embeddings. You must understand that the "bottleneck" is a forced intermediate prediction layer, not just a compressed vector.
  - **Quick check question:** Can you explain why predicting intermediate concepts (adjectives) helps debug a false positive better than a standard classification score?

- **Concept: Probability Marginalization in LLMs**
  - **Why needed here:** The paper doesn't ask the LLM for text output, but rather the probability of "Yes/Si" tokens to generate continuous scores.
  - **Quick check question:** How does summing the probabilities of affirmative tokens (like "Yes") result in a continuous relevance score between 0 and 1?

- **Concept: Multilingual Transformers (XLM-RoBERTa)**
  - **Why needed here:** This serves as both the baseline and the semantic backbone for the SCBMT fusion model.
  - **Quick check question:** Why is a "frozen" transformer used in the SCBMT fusion, but a "fine-tuned" one used in the baseline run?

## Architecture Onboarding

- **Component map:** Raw Tweet (EN/ES) → Frozen LLM (Llama 3.1 8B) → 132-dim Adjective Vector → Frozen XLM-RoBERTa-large → Contextual Embedding → Fusion Layer (Linear projection + Concatenation) → MLP Classifier (ReLU/Softmax)
- **Critical path:** The **Concept Encoder** prompt engineering. If the prompt "Tell me if the adjective [X] describes the content..." fails to elicit a robust probability distribution, the entire interpretability chain collapses.
- **Design tradeoffs:**
  - **SCBM vs. SCBMT:** SCBM is fully interpretable and lightweight but less accurate. SCBMT trades some interpretability (due to the transformer fusion) for higher accuracy on complex tasks.
  - **Frozen vs. Fine-tuned:** SCBMT keeps the transformer frozen (faster, less overfitting) vs. the Baseline which fine-tunes (slower, better for simple binary tasks).
- **Failure signatures:**
  - **Concept Saturation:** The LLM assigns high scores to almost all adjectives, making the interpretation vector dense and noisy.
  - **Language Drift:** The frozen LLM performs poorly on Spanish slang not present in its pre-training, despite the paper's claims of robustness.
- **First 3 experiments:**
  1. **Reproduce Adjective Vector:** Run 10 sample tweets through the Llama-3.1 prompt to verify the marginalization logic yields meaningful variance (not just 0s and 1s).
  2. **Baseline vs. Frozen:** Compare the binary classification performance of Fine-tuned XLM-RoBERTa (Run 3) vs. Frozen XLM-RoBERTa to isolate the value of fine-tuning.
  3. **Ablation on Fusion:** Train SCBMT with *only* the adjective vector (SCBM) vs. the fused vector to measure the specific lift provided by the transformer embeddings for the "Source Intention" task (Subtask 1.2).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can more sophisticated prompting strategies improve the derivation of adjective-based representations in the Speech Concept Bottleneck Model?
- **Basis in paper:** [explicit] The conclusion explicitly identifies the use of "more sophisticated prompting techniques to derive the adjective-based representation" as a promising direction for future work.
- **Why unresolved:** The current implementation relies on calculating the marginalized probability of simple affirmative tokens (e.g., "Yes"), which may fail to capture complex semantic nuances compared to techniques like Chain-of-Thought prompting.
- **Evidence:** A comparative study evaluating SCBM performance when using advanced prompting methods (e.g., Few-Shot or CoT) versus the current probability-based method.

### Open Question 2
- **Question:** Does the involvement of domain experts in expanding the adjective lexicon improve the model's interpretability and coverage?
- **Basis in paper:** [explicit] The authors state that "collaboration with domain experts could support the expansion of the automatically generated adjective lexicon" to enhance coverage and interpretability.
- **Why unresolved:** The current lexicon of 132 adjectives was generated automatically by an LLM (GPT-o3-mini) and may contain gaps or biases that limit its ability to describe all facets of sexism effectively.
- **Evidence:** Results from a user study measuring the perceived quality of explanations and an analysis of classification performance on edge cases using an expert-curated lexicon.

### Open Question 3
- **Question:** What architectural changes are required to effectively leverage annotator demographic data to model subjectivity in sexism detection?
- **Basis in paper:** [inferred] The paper notes that incorporating demographic information via persona-based prompting did not consistently improve results ("settings with more information incorporated do not always lead to better results"), suggesting the method of integration was insufficient.
- **Why unresolved:** While the dataset provides rich demographic data, the failure of the persona-prompting approach leaves the potential utility of this metadata for modeling annotator disagreement unexplored.
- **Evidence:** Experiments comparing the current persona-prompting approach against architectures that fuse demographic embeddings directly into the classifier or use attention mechanisms over annotator features.

## Limitations

- The LLM's ability to consistently map nuanced sexism onto a static list of 132 adjectives is an unverified assumption that could fail silently
- Language robustness claims for Spanish are insufficiently validated given that the adjective lexicon and prompts were only designed for English
- The MLP architecture details remain underspecified, making exact reproduction difficult
- Evaluation only compares against XLM-RoBERTa as a baseline, lacking comparisons to other strong multilingual models

## Confidence

- **High Confidence:** SCBM provides inherently interpretable explanations through adjective vectors; XLM-RoBERTa baseline performance on binary classification tasks is verifiable through benchmark submission records
- **Medium Confidence:** SCBMT's superior performance on fine-grained tasks is well-supported by quantitative results, but the exact contribution of the fusion mechanism remains unclear
- **Low Confidence:** The claim that adjective representations capture orthogonal information to transformer embeddings lacks empirical ablation studies; interpretability quality evaluation is subjective without empirical measurement

## Next Checks

1. **LLM Scoring Consistency Validation:** Run the Llama-3.1 prompt on 20 diverse tweets (10 English, 10 Spanish) and verify that adjective probability scores span the full 0-1 range meaningfully rather than clustering at extremes or producing uniform distributions. Compare distributions across languages to empirically test the language robustness claim.

2. **Ablation Study on Fusion Contribution:** Train three variants on the Source Intention task (Subtask 1.2): (a) SCBM only (adjectives → MLP), (b) SCBMT (adjectives + frozen transformer), and (c) Transformer-only (frozen XLM-RoBERTa → MLP). Measure F1 differences to isolate the specific value added by the adjective representation beyond the transformer's capabilities.

3. **Cross-Lingual Robustness Test:** Take the Spanish subset of EXIST2025 and apply the English-designed adjective lexicon with zero-shot transfer. Compare SCBMT performance on Spanish versus English samples, controlling for class balance. Supplement with error analysis on Spanish-specific slang or cultural references that may fail the English-trained adjective mapping.