---
ver: rpa2
title: Local Entropy Search over Descent Sequences for Bayesian Optimization
arxiv_id: '2511.19241'
source_url: https://arxiv.org/abs/2511.19241
tags:
- function
- local
- objective
- evaluation
- descent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Local Entropy Search (LES) targets the solution reachable by an
  iterative optimizer starting from an initial design, rather than the global optimum.
  It propagates the posterior belief over the objective through the optimizer, yielding
  a distribution over descent sequences.
---

# Local Entropy Search over Descent Sequences for Bayesian Optimization

## Quick Facts
- **arXiv ID:** 2511.19241
- **Source URL:** https://arxiv.org/abs/2511.19241
- **Reference count:** 40
- **Primary result:** LES achieves strong sample efficiency on high-complexity synthetic objectives and benchmark problems, outperforming existing local and global Bayesian optimization methods.

## Executive Summary
Local Entropy Search (LES) is a novel Bayesian optimization approach that targets solutions reachable by iterative optimizers starting from initial designs, rather than pursuing the global optimum. The method propagates posterior beliefs over the objective function through the optimizer, yielding a distribution over descent sequences. By selecting the next evaluation point through maximizing mutual information with this distribution, LES achieves strong sample efficiency, particularly in higher-dimensional problems with complex objectives.

The approach uses analytic entropy calculations combined with Monte-Carlo sampling of descent sequences to efficiently explore the search space. Empirical results demonstrate that LES consistently outperforms existing Bayesian optimization methods on synthetic GP samples with high complexity, achieving lower cumulative regret and better final objective values with fewer evaluations.

## Method Summary
LES operates by modeling the propagation of posterior beliefs through iterative optimization trajectories. At each iteration, the method maintains a distribution over possible descent sequences that could be followed from the current point. Rather than selecting the next evaluation based on maximizing the expected improvement at the global optimum, LES chooses points that maximize mutual information with the distribution of reachable optima. This is achieved through analytic entropy calculations and Monte-Carlo sampling of descent sequences, allowing the algorithm to focus computational resources on regions of the search space that are both promising and reachable by the optimizer.

## Key Results
- LES consistently outperformed other methods on GP samples with high complexity in higher dimensions
- Achieved lower cumulative regret and better final objective values with fewer evaluations
- Demonstrated strong sample efficiency compared to existing local and global Bayesian optimization methods

## Why This Works (Mechanism)
LES works by shifting the optimization target from the global optimum to the set of solutions reachable by iterative optimizers. This approach acknowledges that in many practical scenarios, the global optimum may be unreachable due to constraints or computational limitations, and instead focuses on finding the best solution that can be reached from a given starting point. By propagating posterior beliefs through the optimizer and maintaining a distribution over descent sequences, LES can make more informed decisions about where to sample next, focusing on regions that are both promising and accessible.

## Foundational Learning
- **Bayesian Optimization**: Sequential optimization method using probabilistic surrogate models to guide search - needed to understand the broader context and why LES differs from standard approaches; quick check: can you explain the difference between acquisition functions in standard BO vs LES?
- **Mutual Information Maximization**: Information-theoretic approach to selecting informative samples - needed to understand how LES chooses evaluation points; quick check: can you derive the mutual information formula used in LES?
- **Descent Sequences**: Trajectories followed by iterative optimizers - needed to understand how LES models reachable solutions; quick check: can you describe how descent sequences are sampled in LES?
- **Analytic Entropy Calculations**: Mathematical techniques for computing entropy without numerical integration - needed to understand computational efficiency; quick check: can you explain why analytic entropy is preferable to numerical methods in this context?

## Architecture Onboarding

**Component Map:** Prior over objective -> GP surrogate model -> Descent sequence sampler -> Entropy calculator -> Mutual information optimizer -> Next evaluation point

**Critical Path:** The core execution path follows: GP update → descent sequence simulation → entropy calculation → mutual information maximization → evaluation point selection. Each component must complete before the next can begin, creating a sequential dependency chain.

**Design Tradeoffs:** The method trades computational complexity (simulating multiple descent sequences) for improved sample efficiency and more realistic optimization targets. The analytic entropy approach reduces computational burden but requires specific mathematical properties in the surrogate model.

**Failure Signatures:** Poor performance on non-smooth or discontinuous functions, computational bottlenecks when simulating many descent sequences in high dimensions, and degraded performance when the optimizer cannot effectively explore the search space.

**3 First Experiments:**
1. Run LES on a simple 1D synthetic function with known optima to verify basic functionality
2. Compare LES against standard Bayesian optimization on a benchmark problem to establish baseline performance
3. Test LES on a high-complexity GP sample to verify the claimed advantages in challenging scenarios

## Open Questions the Paper Calls Out
None

## Limitations
- Computational complexity of simulating multiple descent sequences may limit scalability to very high-dimensional problems
- Performance on non-smooth or discontinuous objective functions is not thoroughly explored
- Reliance on differentiable optimization trajectories may be problematic for non-differentiable objectives

## Confidence

**Methodology and theoretical framework:** High
- The approach is mathematically well-founded with clear connections to Bayesian optimization theory

**Empirical performance claims:** Medium
- Results show strong performance on tested problems, but comparison is primarily against other Bayesian optimization methods

**Scalability assertions:** Low
- Computational complexity claims need verification on very high-dimensional problems

## Next Checks
1. Test LES on high-dimensional problems with >20 dimensions to assess computational scalability limits
2. Evaluate performance on non-differentiable objective functions to understand limitations of the descent sequence approach
3. Compare against gradient-free optimization methods to establish the relative advantages of the Bayesian approach