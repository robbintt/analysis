---
ver: rpa2
title: 'Theoretical Foundations of Prompt Engineering: From Heuristics to Expressivity'
arxiv_id: '2512.12688'
source_url: https://arxiv.org/abs/2512.12688
tags:
- prompt
- fixed
- routing
- executor
- error
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper studies how a fixed Transformer backbone can switch
  behaviors via prompts alone, reframing prompt engineering as a theoretical object
  rather than a heuristic. The key idea is to treat prompts as externally injected
  programs and construct a simplified Transformer that interprets them via three core
  mechanisms: attention for selective routing from prompt memory, a token-wise FFN
  for local arithmetic conditioned on retrieved fragments, and depth-wise stacking
  for composing these into multi-step computation.'
---

# Theoretical Foundations of Prompt Engineering: From Heuristics to Expressivity

## Quick Facts
- arXiv ID: 2512.12688
- Source URL: https://arxiv.org/abs/2512.12688
- Reference count: 40
- Primary result: Proves Prompt-UAT - a fixed Transformer can approximate any continuous function by varying only the prompt

## Executive Summary
This paper establishes a theoretical foundation for prompt engineering by reframing prompts as externally injected programs for a fixed Transformer backbone. The authors construct a simplified Transformer architecture that interprets prompts via three core mechanisms: attention for selective routing from prompt memory, a token-wise FFN for local arithmetic conditioned on retrieved fragments, and depth-wise stacking for composing these into multi-step computation. Under this decomposition, they prove that for any continuous target function on a compact domain, there exists a single fixed Transformer that can approximate it arbitrarily well by changing only the prompt. This establishes Prompt-UAT (Prompt Universal Approximation Theorem) and provides a unified framework for analyzing trade-offs under length, precision, and norm constraints, while remaining distinct from empirical claims about pretrained LLMs.

## Method Summary
The paper introduces a simplified Transformer that interprets prompts as externally injected programs through three mechanisms: attention for routing from prompt memory, token-wise FFN for local arithmetic, and depth-wise stacking for multi-step composition. The constructive proof proceeds in two stages: first using classical UAT to get a ReLU MLP N_g approximating the target function g, then encoding N_g's parameters into prompt key-value slots using a addressing scheme κ with margin γ. The fixed executor program emulates N_g's forward pass by routing queries to retrieve parameters, assembling them, performing arithmetic updates via token-wise 2-layer ReLU FFNs, and composing results across depth. The construction requires "sufficiently large" hyperparameters but provides no quantitative guidance for specific tasks.

## Key Results
- Establishes Prompt-UAT: any continuous function g∈C(X) on compact domain X can be approximated arbitrarily well by a fixed Transformer varying only the prompt
- Provides constructive proof decomposing prompt execution into routing, arithmetic, and composition mechanisms
- Analyzes error composition across macro-steps and derives bounds on routing impurity and temperature scaling
- Explicitly distinguishes theoretical existence result from empirical claims about pretrained LLMs

## Why This Works (Mechanism)
The paper works by treating prompts as externally injected programs and constructing a simplified Transformer that can interpret them. The key insight is decomposing the computation into three orthogonal mechanisms: attention for selective routing from prompt memory (retrieving parameters), token-wise FFN for local arithmetic conditioned on retrieved fragments (performing computations), and depth-wise stacking for composing these into multi-step computation (building complex functions). By encoding MLP parameters into prompt slots with addressing schemes that enable clean routing, and by carefully composing error budgets across execution steps, the framework establishes that a fixed architecture can approximate any continuous function through prompt variation alone.

## Foundational Learning
- **Prompt-UAT (Prompt Universal Approximation Theorem)**: A fixed Transformer backbone can approximate any continuous function g∈C(X) on compact domain X by varying only the soft prompt p. **Why needed**: Provides theoretical foundation for prompt engineering beyond heuristics. **Quick check**: Verify the approximation error ∥F_θ*(p,·)−g∥_∞ < ε for target ε.
- **Simplified Transformer Architecture**: Single-head self-attention with token-wise 2-layer ReLU FFN, residual connections, no LayerNorm/Dropout. **Why needed**: Enables clean theoretical analysis while preserving core computational mechanisms. **Quick check**: Confirm attention and FFN operations match Appendix B specifications.
- **Prompt Encoding Scheme**: Partition L slots into parameter (I_par) and work (I_wrk) memory; store MLP weight/bias fragments as key-value pairs using addressing scheme κ: [L_max]→ℝ^{d_k} with margin γ. **Why needed**: Enables the executor to retrieve and assemble MLP parameters from prompt. **Quick check**: Verify key orthogonality and margin condition for routing.
- **Executor Program**: Macro-steps for query formation → routing read → assembly → arithmetic update → optional write-back with invariants Inv-1 (boundedness), Inv-2 (slot partition), Inv-3 (margin condition). **Why needed**: Provides algorithmic framework for prompt interpretation. **Quick check**: Confirm each macro-step preserves the stated invariants.
- **Error Composition Analysis**: Decomposes total approximation error into routing error, arithmetic error, and composition error across depth, with explicit bounds. **Why needed**: Enables quantitative understanding of error sources and trade-offs. **Quick check**: Verify δ^arith_t, δ^route_t satisfy composition bound (Lemma E.2).

## Architecture Onboarding

**Component Map**: Prompt Memory (key-value slots) -> Attention Routing -> Token-wise FFN Arithmetic -> Depth-wise Composition -> Output

**Critical Path**: Prompt encoding → Attention routing read → Parameter assembly → Arithmetic update → Composition across depth → Final output

**Design Tradeoffs**: Single-head vs multi-head attention (simplicity vs expressive power), continuous soft prompts vs discrete hard prompts (approximation power vs practical constraints), fixed vs adaptive temperature τ (theoretical guarantees vs empirical performance), depth T vs per-step error budgets (composition vs local precision).

**Failure Signatures**: Routing impurity too high (soft prompts blend multiple slots), error accumulates beyond ε across macro-steps, boundedness invariant (Inv-1) breaks - token states explode.

**First Experiments**:
1. Implement simplified Transformer with single-head attention and 2-layer ReLU FFN; verify basic attention routing and arithmetic operations work as specified.
2. Encode a simple MLP (e.g., approximating a quadratic function) into prompt slots using the addressing scheme; test whether the executor can correctly retrieve and execute the parameters.
3. Vary temperature τ and prompt length L systematically; measure their impact on routing impurity and approximation quality for a fixed target function.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do prompt length, precision, and norm constraints quantitatively trade off against approximation error ε in the Prompt-UAT framework?
- Basis in paper: The authors state this is "a direct next step," having "deferred" these trade-offs and explicitly noted they "do not quantify the costs induced by realistic constraints—such as prompt length, finite precision, norm bounds, or the margins/temperature scaling required for reliable routing."
- Why unresolved: The main theorem uses unconstrained soft prompts in R^L×D with no norm bounds, establishing only an existential result. Real systems have finite context length L, finite numerical precision, and bounded prompt norms—all of which restrict the achievable hypothesis class.
- What evidence would resolve it: Explicit bounds relating (L, bit-precision, ||p||_bound) to the best achievable ε for target function classes with specified regularity (e.g., Lipschitz constants, smoothness).

### Open Question 2
- Question: What are the fundamental limits of prompt-based switching for hard prompts (finite vocabulary, finite length)?
- Basis in paper: The authors identify as a key direction: "derive lower bounds and impossibility results for hard prompts (finite vocabularies and finite lengths), including information-theoretic limits on how much task specification can be conveyed."
- Why unresolved: The constructive proof relies on continuous soft prompts that can encode real-valued parameters (MLP weights) with arbitrary precision. Discrete tokenization and finite vocabulary constrain the information capacity of prompts in ways the current theory does not address.
- What evidence would resolve it: Lower bounds showing, for specific finite vocabularies V and lengths L, which function classes cannot be approximated below some error threshold regardless of the executor architecture.

### Open Question 3
- Question: Can the existential prompts guaranteed by Prompt-UAT be found through practical optimization procedures?
- Basis in paper: The authors explicitly disclaim: "it does not provide an algorithm to find such prompts" and list as future work "whether the existential prompts can be recovered by practical optimization."
- Why unresolved: The construction is fully explicit but non-algorithmic—it shows existence by designing prompts that store MLP parameters with specific key-value encodings. The optimization landscape for finding such prompts via gradient descent or search is uncharacterized.
- What evidence would resolve it: Either (1) algorithms that provably converge to near-optimal prompts under stated assumptions, or (2) hardness results showing optimization barriers for certain target functions or architectures.

### Open Question 4
- Question: How do pretraining-induced constraints (architecture, training dynamics, learned representations) restrict the prompt-switchable function class in real LLMs?
- Basis in paper: The authors repeatedly emphasize their result "should not be read as an empirical claim that pretrained LLMs satisfy Prompt-UAT as stated" and ask how "pretrained constraints (architecture, training-induced biases, and optimization dynamics) alter the boundary between possible and impossible switching."
- Why unresolved: The fixed executor θ* is constructed for the proof, not derived from any pretraining procedure. Real LLMs have structure imposed by gradient descent on large corpora, which may make certain regions of H_θ* unreachable or poorly conditioned.
- What evidence would resolve it: Characterizations of which functions in H_θ* are empirically reachable via prompt optimization for specific pretrained models, compared against the theoretical H_θ* from the construction.

## Limitations
- The theoretical framework assumes a simplified Transformer with single-head attention and ReLU-based token-wise FFNs, diverging from practical multi-head architectures
- The construction relies on "sufficiently large" hyperparameters without providing quantitative guidance for specific approximation tasks
- The key addressing scheme κ exists by assumption rather than explicit construction, making practical implementation unclear
- The separation between theoretical construction and practical prompt engineering remains significant - the paper does not claim that existing LLMs implement the executor program

## Confidence
**High Confidence**: The mathematical proofs for the simplified architecture are rigorous and internally consistent. The decomposition into routing, arithmetic, and composition mechanisms is logically sound and the error composition bounds are properly derived.

**Medium Confidence**: The constructive existence argument for approximating arbitrary continuous functions is valid within the simplified model. However, the gap between theoretical construction and practical implementation remains significant, particularly regarding hyperparameter selection and key encoding.

**Low Confidence**: Claims about implications for empirical prompt engineering or practical LLM applications should be treated cautiously. The paper explicitly distinguishes its theoretical contribution from empirical observations, but the connection between theory and practice is not established.

## Next Checks
1. **Quantitative Gap Analysis**: Implement the simplified Transformer with concrete hyperparameters for a specific approximation task (e.g., approximating a simple polynomial) and measure the actual vs. theoretical error rates. Compare how the routing impurity and error composition behave in practice versus the theoretical bounds.

2. **Key Encoding Feasibility**: Develop an explicit algorithm for constructing the key addressing scheme κ that achieves the required margin γ for a non-trivial label set. Test whether the proposed single-head attention can effectively route to the correct slots under realistic conditions.

3. **Hyperparameter Sensitivity**: Systematically vary the key parameters (temperature τ, depth T, prompt length L, FFN width) and measure their impact on approximation quality. Identify the quantitative relationships between these parameters and the achievable precision ε, moving beyond the existential "sufficiently large" characterization.