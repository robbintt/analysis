---
ver: rpa2
title: 'Factuality on Demand: Controlling the Factuality-Informativeness Trade-off
  in Text Generation'
arxiv_id: '2602.00848'
source_url: https://arxiv.org/abs/2602.00848
tags:
- factuality
- facts
- response
- informativeness
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Factuality-Controlled Generation (FCG), a
  framework for controlling the factuality-informativeness trade-off in language model
  outputs. FCG allows users to specify factuality constraints (e.g., 80% of information
  must be correct) and trains models to respect these constraints while remaining
  informative.
---

# Factuality on Demand: Controlling the Factuality-Informativeness Trade-off in Text Generation

## Quick Facts
- **arXiv ID:** 2602.00848
- **Source URL:** https://arxiv.org/abs/2602.00848
- **Reference count:** 9
- **Primary result:** FCG fine-tuning improves factuality adherence from 0% to 23.6% for 100% factuality requirement and from 5.5% to 12.6% for 90% factuality level

## Executive Summary
This paper introduces Factuality-Controlled Generation (FCG), a framework for controlling the factuality-informativeness trade-off in language model outputs. FCG allows users to specify factuality constraints (e.g., 80% of information must be correct) and trains models to respect these constraints while remaining informative. The authors propose a synthetic training approach that generates initial responses, evaluates confidence of individual facts, and removes minimal low-confidence content to meet target factuality levels.

When evaluated on biography generation tasks, FCG fine-tuning significantly improves factuality adherence: from 0% to 23.6% for strict 100% factuality requirement, and from 5.5% to 12.6% for 90% factuality level. The method also improves the factuality-informativeness trade-off curve, achieving higher informativeness at equivalent factuality levels compared to baseline approaches. The results demonstrate that supervised training on synthetic data can effectively teach language models to respect factuality constraints while maintaining content quality.

## Method Summary
The Factuality-Controlled Generation framework introduces a synthetic training approach where initial model responses are generated and then analyzed for factuality confidence. Individual facts are evaluated, and low-confidence content is systematically removed to create training examples that meet specific factuality thresholds. This process teaches models to dynamically adjust their outputs based on specified factuality requirements. The approach involves fine-tuning language models on this synthetic dataset, enabling them to generate text that adheres to user-specified factuality constraints while optimizing for informativeness.

## Key Results
- FCG fine-tuning improved strict 100% factuality adherence from 0% to 23.6%
- FCG improved 90% factuality adherence from 5.5% to 12.6%
- FCG achieved higher informativeness at equivalent factuality levels compared to baseline approaches
- The method successfully created a controllable trade-off between factuality and informativeness

## Why This Works (Mechanism)
The framework works by training models on synthetic examples where low-confidence facts have been removed to meet target factuality levels. During inference, the model learns to self-assess factuality confidence and adjust content accordingly, effectively balancing the trade-off between accuracy and informativeness based on user requirements.

## Foundational Learning
- **Factuality confidence estimation**: Needed to identify which facts may be unreliable; quick check: validate confidence scores against human judgments
- **Synthetic data generation**: Required to create training examples with controlled factuality levels; quick check: ensure removed content doesn't bias remaining information
- **Factuality-informativeness trade-off**: Core concept for balancing accuracy with content quality; quick check: measure both metrics across the spectrum
- **Fine-tuning methodology**: Essential for adapting pre-trained models to factuality constraints; quick check: monitor training stability and convergence
- **Automated evaluation metrics**: Needed for scalable assessment; quick check: correlate automated metrics with human evaluations

## Architecture Onboarding

**Component Map:** User input -> Factuality constraint -> FCG model -> Text generation -> Factuality confidence assessment -> Output

**Critical Path:** User specifies factuality requirement → FCG model generates text → Model assesses factuality confidence → Outputs adjusted text meeting requirements

**Design Tradeoffs:** 
- Synthetic training vs. real annotated data (synthetic is scalable but may have biases)
- Automated vs. human evaluation (automated is efficient but may miss nuances)
- Factuality precision vs. content informativeness (fundamental trade-off being controlled)

**Failure Signatures:**
- Over-aggressive fact removal leading to uninformative outputs
- Under-estimation of factuality confidence causing inaccurate content
- Poor generalization to domains beyond training data

**First 3 Experiments:**
1. Test FCG on biography generation tasks with varying factuality constraints (100%, 90%, 80%)
2. Compare FCG performance against baseline models without factuality control
3. Evaluate the factuality-informativeness trade-off curve across different constraint levels

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several emerge from the work including generalization to other domains, handling of complex factuality assessments, and the scalability of confidence estimation methods.

## Limitations
- Synthetic training relies heavily on accuracy of confidence estimation for individual facts
- Evaluation limited to biography generation tasks, unclear generalization to other domains
- Does not address potential biases introduced by synthetic data generation process

## Confidence
- **Factuality improvement claims:** Medium - measurable improvements but limited to biography domain
- **Generalizability claims:** Low - only tested on biographies, unclear if method transfers to other domains
- **Automated evaluation validity:** Medium - relies on automated metrics without extensive human validation

## Next Checks
1. Test FCG on diverse text generation tasks beyond biographies (e.g., technical documentation, news summaries) to assess domain generalization
2. Conduct human evaluation studies to validate automated factuality and informativeness metrics
3. Compare FCG performance against alternative approaches like uncertainty-aware fine-tuning or retrieval-augmented generation methods on the same benchmarks