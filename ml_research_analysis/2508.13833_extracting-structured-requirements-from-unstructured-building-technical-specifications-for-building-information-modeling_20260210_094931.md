---
ver: rpa2
title: Extracting Structured Requirements from Unstructured Building Technical Specifications
  for Building Information Modeling
arxiv_id: '2508.13833'
source_url: https://arxiv.org/abs/2508.13833
tags:
- extraction
- entities
- learning
- page
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study integrates Building Information Modeling (BIM) with
  Natural Language Processing (NLP) to automate the extraction of structured requirements
  from unstructured French Building Technical Specification (BTS) documents. The approach
  employs Named Entity Recognition (NER) and Relation Extraction (RE) techniques using
  transformer-based models like CamemBERT and transfer learning with the French language
  model Frcorenewslg, both pre-trained on a large French corpus.
---

# Extracting Structured Requirements from Unstructured Building Technical Specifications for Building Information Modeling

## Quick Facts
- **arXiv ID:** 2508.13833
- **Source URL:** https://arxiv.org/abs/2508.13833
- **Reference count:** 40
- **Primary result:** CamemBERT and Fr_core_news_lg achieved NER F1-scores over 90%, while Random Forest with syntactic features achieved RE F1 above 80%.

## Executive Summary
This study addresses the challenge of automating requirement extraction from unstructured French Building Technical Specification (BTS) documents to support Building Information Modeling (BIM). The authors develop a pipeline that combines hierarchical document segmentation, Named Entity Recognition (NER), and Relation Extraction (RE) using transformer-based models and traditional machine learning. By fine-tuning French language models (CamemBERT, Fr_core_news_lg) and leveraging syntactic features for RE, the approach achieves high accuracy in identifying construction concepts and properties and their relationships. The work demonstrates the potential for automating BIM product verification and recommendation systems.

## Method Summary
The method involves preprocessing French BTS PDFs to remove headers/footers and segment text into hierarchical chunks using regex-based numbering. Two NER approaches are employed: fine-tuning the CamemBERT transformer and transfer learning with the Fr_core_news_lg spaCy model, both trained on a hand-crafted annotated dataset. For RE, a Random Forest classifier is trained using a custom feature vector emphasizing syntactic features like entity distance, position, and orientation. The pipeline outputs structured JSON triples representing concepts, properties, and their relations, which can be mapped to knowledge graphs for BIM applications.

## Key Results
- CamemBERT and Fr_core_news_lg achieved NER F1-scores over 90% on the French BTS dataset.
- Random Forest with syntactic features achieved RE F1 above 80%, outperforming semantic-heavy models.
- The segmentation algorithm failed on approximately 28% of documents due to inconsistent numbering systems.

## Why This Works (Mechanism)

### Mechanism 1: Transfer Learning for Domain-Specific NER
Pre-trained French language models (CamemBERT, Fr_core_news_lg) are adapted to the construction domain with high accuracy by fine-tuning on a small hand-crafted dataset. This leverages pre-learned contextual embeddings from large French corpora, adjusting weights to recognize domain-specific entities without massive annotated data. The core assumption is that syntactic and semantic structures in general French corpora transfer effectively to technical construction language.

### Mechanism 2: Syntactic Feature Dominance in Relation Extraction
Random Forest classifiers using strictly syntactic features (distance, position, orientation) outperform semantic-heavy models for RE in BTS documents. Structural proximity (e.g., word count between entities, punctuation delimiters) acts as a stronger signal for relationships than the semantic content of intervening words. The core assumption is that document layout (headers, lists) correlates more reliably with entity relationships than semantic context.

### Mechanism 3: Hierarchical Segmentation for Context Preservation
Segmenting documents based on numbering hierarchies (regex matching) is necessary because single-sentence analysis loses context. The system uses regular expressions to detect section levels (1.1, 1.1.1), merging parent sections with sub-sections to ensure general properties are linked to specific concepts during RE. The core assumption is that BTS documents possess a consistent, machine-readable numbering system mirroring the logical hierarchy of requirements.

## Foundational Learning

- **Concept:** Transfer Learning (Fine-tuning)
  - **Why needed here:** Essential to understand why the paper chooses CamemBERT over training from scratch, addressing the "scarcity of domain-specific annotated data."
  - **Quick check question:** How does freezing base layers of CamemBERT vs. fine-tuning the whole model affect the risk of "catastrophic forgetting" in this context?

- **Concept:** Conditional Random Fields (CRF) vs. Token Classification
  - **Why needed here:** The paper compares BiLSTM-CRF against Transformers; understanding CRF explains why the paper notes specific difficulties with "generalization" in the BiLSTM-CRF model compared to the transformer.
  - **Quick check question:** Why might a CRF layer struggle with "rare entities" like "Bay" compared to the attention mechanisms in CamemBERT?

- **Concept:** Feature Engineering for Relation Extraction
  - **Why needed here:** The success of the Random Forest model depends entirely on the "custom feature vector"; you cannot debug RE performance without understanding features like "Orientation" and "Count of Words."
  - **Quick check question:** If you removed the "Title of Raw Requirement" feature, how would it likely impact the extraction of relations for items listed in sub-sections?

## Architecture Onboarding

- **Component map:** PDF -> Text (MuPDF) -> Header/Footer Removal (Levenshtein distance) -> Regex Numbering Parser -> Hierarchy Tree -> Raw Requirement Chunks -> NER (CamemBERT/Fr_core_news_lg) -> Entity Spans (Concepts & Properties) -> Feature Extraction (Syntactic) -> Random Forest Classifier -> Relation Triples

- **Critical path:** Segmentation -> NER. If the segmentation regex fails to group parent/child sections, the NER model sees incomplete text. Even with perfect NER, subsequent RE will fail because relevant "Concept" and "Property" will be in different processing chunks.

- **Design tradeoffs:**
  - **Regex vs. Layout Analysis for Segmentation:** The paper uses regex for speed and simplicity but admits it fails on 28% of documents due to formatting inconsistencies. An alternative (layout analysis models) would be more robust but slower.
  - **Syntactic vs. Semantic Features:** The paper explicitly rejects semantic features (Word2Vec) for RE because they introduced noise. This favors precision over potential semantic generalization.

- **Failure signatures:**
  - **"False Negatives" in NER:** Likely caused by rare entities (e.g., "Flame Arrester") having few training examples.
  - **"Recall Drop" in RE:** Likely caused by long distances between entities breaking the syntactic feature patterns of the Random Forest model.
  - **Segmentation Crash:** Occurs when page numbers or headers are inconsistent, breaking the Levenshtein distance threshold.

- **First 3 experiments:**
  1. **Sanity Check (NER):** Run the pre-trained CamemBERT model on a raw BTS page without fine-tuning to establish a baseline for domain drift.
  2. **Feature Ablation (RE):** Retrain the Random Forest model removing the "Orientation" and "Word Count" features to verify the paper's claim that syntactic features are the primary drivers of performance.
  3. **Segmentation Stress Test:** Feed the segmentation algorithm a BTS document with inconsistent numbering (e.g., "1, 1.1, 3") to identify if the system crashes or merely degrades gracefully.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can prompt engineering with Causal Language Models (CLMs) like GPT or Mistral achieve superior performance in Named Entity Recognition and Relation Extraction for French BTS documents compared to the current fine-tuned CamemBERT and feature-based Random Forest models?
- **Basis in paper:** [explicit] The authors state in Section 5.2 that future research will explore CLMs and prompt engineering to determine if they offer the best solution without relying on large annotated datasets or manually crafted features.
- **Why unresolved:** The current study focused on transformer-based Masked Language Models (CamemBERT) and feature-based supervised models, which required annotated data and custom feature engineering; CLMs have not yet been tested on this specific French construction dataset.
- **What evidence would resolve it:** Comparative benchmarks of zero-shot and few-shot CLM performance against the established F1-scores (CamemBERT >90% NER, Random Forest >80% RE) on the same test dataset.

### Open Question 2
- **Question:** Can Large Language Models (LLMs) effectively automate the extraction of hierarchical document structures from BTS files that lack consistent numbering systems, overcoming the limitations of the current rule-based segmentation algorithm?
- **Basis in paper:** [explicit] Section 5.2 outlines a plan to leverage LLMs for segmentation using instructional prompts, while Section 5.1 notes the current algorithm struggles with inconsistent or absent numbering (impacting ~28% of documents).
- **Why unresolved:** The current methodology relies on regular expressions based on incremental numbering, which failed for documents with encoding issues, inconsistent numbering, or no numbering.
- **What evidence would resolve it:** Successful extraction of hierarchical sections from the 27.78% of documents that previously failed the regex-based segmentation, evaluated against manual ground truth.

### Open Question 3
- **Question:** How can the extracted structured requirements be mapped to a knowledge graph to facilitate automated BIM product recommendations and verification?
- **Basis in paper:** [explicit] The abstract and Section 5.2 mention representing outcomes as a knowledge graph to enhance automatic verification and "create a model that can automatically propose BIM products."
- **Why unresolved:** The paper successfully extracts the entities and relations (outputting JSON) but stops short of formalizing them into a graph structure or developing the downstream product recommendation system.
- **What evidence would resolve it:** A functional prototype that queries product catalogues based on the extracted JSON/Graph requirements and returns compliant BIM components.

## Limitations
- The study relies on a hand-crafted dataset of 233 annotated raw requirements, which may not capture the full variability of French BTS documents, particularly rare entities.
- The superiority of CamemBERT and Fr_core_news_lg is demonstrated specifically for French; performance claims may not translate to other languages without retraining.
- The segmentation approach depends heavily on consistent hierarchical numbering, with a 28% failure rate on documents with inconsistent numbering.

## Confidence

- **High Confidence:** The effectiveness of transfer learning for domain-specific NER in French BTS documents (F1 > 90%). The experimental design and results are clear and well-documented.
- **Medium Confidence:** The superiority of Random Forest with syntactic features for RE (F1 > 80%). While results are strong, the specific feature engineering choices may be dataset-dependent.
- **Low Confidence:** The generalizability of the approach to other construction document formats or languages without significant modification.

## Next Checks

1. **Dataset Diversity Test:** Apply the trained models to a separate set of BTS documents from different sources or time periods to assess performance degradation on unseen document styles.
2. **Cross-Lingual Transfer:** Fine-tune the French models on English or Spanish BTS documents to test if the syntactic feature dominance in RE generalizes across languages.
3. **Formatting Robustness:** Intentionally corrupt the numbering system in test documents (e.g., inconsistent levels, missing numbers) to quantify the segmentation failure rate and its impact on downstream NER/RE performance.