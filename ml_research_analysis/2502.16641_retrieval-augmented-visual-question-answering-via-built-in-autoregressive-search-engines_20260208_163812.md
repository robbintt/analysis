---
ver: rpa2
title: Retrieval-Augmented Visual Question Answering via Built-in Autoregressive Search
  Engines
arxiv_id: '2502.16641'
source_url: https://arxiv.org/abs/2502.16641
tags:
- knowledge
- retrieval
- answer
- visual
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces ReAuSE, a Retrieval-Augmented Visual Question
  Answering framework that integrates a built-in autoregressive search engine into
  a generative multi-modal large language model. This design enables the model to
  function both as a generative retriever, producing document identifiers from knowledge
  bases, and as an accurate answer generator, utilizing the retrieved knowledge to
  respond to questions.
---

# Retrieval-Augmented Visual Question Answering via Built-in Autoregressive Search Engines

## Quick Facts
- arXiv ID: 2502.16641
- Source URL: https://arxiv.org/abs/2502.16641
- Reference count: 18
- Introduces ReAuSE, a generative retriever-generator framework that achieves 2.9%-9.6% VQA accuracy improvements over strong baselines

## Executive Summary
ReAuSE introduces a novel approach to knowledge-based visual question answering by integrating a built-in autoregressive search engine into a multimodal large language model. Unlike traditional discriminative retrieval methods, ReAuSE generates document identifiers directly from queries using constrained beam decoding, enabling unified retrieval-generation within a single model. The framework incorporates reinforced retrieval calibration via direct preference optimization to align retrieval performance with answer generation quality, achieving state-of-the-art results on OKVQA and A-OKVQA benchmarks while maintaining computational efficiency.

## Method Summary
ReAuSE uses a MiniGPT4-v2-7B base model (ViT-L/14 + LLaMA-2-7B) with separate LoRA adapters for retrieval and generation. The retrieval adapter employs constrained beam decoding via FM-Index to generate document identifiers from knowledge bases. A reinforced calibration module uses a reward model to score documents and applies DPO to optimize retrieval preferences. The generation adapter produces answers conditioned on retrieved documents. Training occurs in three stages: retrieval SFT, reinforced calibration, and answer generation, with less than 3 hours of training on 4×NVIDIA A6000 GPUs.

## Key Results
- VQA accuracy improvements of 2.9% to 9.6% across all metrics compared to strong baselines
- PRRecall@5 scores of 92.6% on GS112K and 88.0% on Wiki21M knowledge bases
- Comparable efficiency to traditional retrieval methods while requiring fewer computational resources
- Significant performance gains over baseline models including mKG-RAG, OMGM, and GPV-2

## Why This Works (Mechanism)

### Mechanism 1: Autoregressive Document Identifier Generation
ReAuSE replaces traditional similarity scoring with autoregressive identifier generation, allowing the MLLM to function as both retriever and generator. Constrained beam decoding via FM-Index ensures generated identifiers map deterministically to real documents. The approach assumes the base MLLM has sufficient pre-existing knowledge to recognize document-content associations from multi-modal queries.

### Mechanism 2: Reinforced Retrieval Calibration via DPO
The framework uses a reward model to score documents on VQA answer correctness, keyword overlap, and semantic similarity. DPO then optimizes the retrieval LoRA to prefer high-reward identifiers, aligning retriever preferences with answer generator needs. This calibration improves both retrieval quality and downstream VQA accuracy.

### Mechanism 3: Joint Probability Inference for Answer Selection
Answers are selected using joint probability P(Ri|X) × P(Y|X, Di) across top-K retrieved documents. This approach marginalizes over retrieval uncertainty and properly weights uncertain retrievals against answer confidence, yielding more robust answers than single-document prompting.

## Foundational Learning

- **Concept: Generative Retrieval (Differentiable Search Index / SEALS / Autoregressive Search Engines)**
  - Why needed: ReAuSE treats retrieval as seq2seq generation rather than dense vector matching, leveraging LLMs' ability to "memorize" document-content mappings
  - Quick check: Given query "palm tree species," explain why generating "ficus carica" as identifier differs from cosine similarity retrieval

- **Concept: Direct Preference Optimization (DPO)**
  - Why needed: The reinforced calibration uses DPO instead of PPO-based RLHF, avoiding reward model training while optimizing retrieval preferences
  - Quick check: In DPO, why are both π_Θ and π_sft needed in the loss? What happens if π_sft is too close to π_Θ?

- **Concept: Constrained Decoding with Trie/FM-Index**
  - Why needed: Valid identifiers must exist in the KB; FM-Index enables O(V) prefix-constrained next-token search regardless of KB size
  - Quick check: How does FM-Index differ from a simple trie for substring search? What's the tradeoff in construction time vs. query time?

## Architecture Onboarding

- **Component map:**
  Input (Image + Question) -> [Shared MLLM Backbone] -> [LoRA Adapter 1: Retrieval] -> FM-Index -> Top-K Documents -> [LoRA Adapter 2: Generation] -> [Joint Probability Aggregator] -> Final Answer

- **Critical path:**
  1. FM-Index construction from KB (one-time, handles 21M docs for Wiki21M)
  2. Identifier extraction via LLM summarizer (assumes unique subsequences exist)
  3. Reward model inference for triplet generation (3 forward passes per sample)
  4. DPO training loop on LoRA parameters only (0.49% of model)

- **Design tradeoffs:**
  - Identifier length vs. uniqueness: Longer identifiers = fewer collisions but harder to generate (paper uses ~10 tokens)
  - Beam width K vs. latency: K=5 adds ~751ms; K=10 adds ~1.02s (paper shows K=5 sufficient for 92.6% recall)
  - Shared vs. separate LoRA adapters: Single backbone enables knowledge transfer but requires careful isolation

- **Failure signatures:**
  - Hallucinated identifiers: If constrained decoding disabled, model generates plausible but non-existent doc IDs (2.5% VQA drop)
  - Reward hacking: If VQA reward dominates, model may retrieve answer-containing docs lacking supporting context
  - KB scale collapse: If Wiki21M causes >20% recall drop, check FM-Index memory allocation

- **First 3 experiments:**
  1. Sanity check: Run retrieval-only on OKVQA-GS112K. Verify PRRecall@5 >85% before training generation adapter
  2. Ablation on reward components: Train three variants (VQA-only, EM-only, Sim-only rewards). Compare to full model
  3. Scale test: Evaluate on Wiki21M. If PRRecall@5 drops below 80%, investigate FM-Index build completeness

## Open Questions the Paper Calls Out
- How effectively does ReAuSE generalize to highly specialized domains such as biomedicine or education?
- Does the reliance on a frozen MLLM backbone limit the model's ability to retrieve information absent from its pre-training data?
- Can the framework handle dynamic, real-time updates to the knowledge base without requiring resource-intensive retraining?

## Limitations
- Identifier extraction quality and uniqueness guarantees are not empirically validated for heterogeneous knowledge bases
- FM-Index implementation challenges for 21M documents lack memory and latency specifications
- Reward model homogeneity assumptions lack ablation studies with different reward model architectures

## Confidence
- High Confidence: PRRecall@5 scores (92.6% on GS112K, 88.0% on Wiki21M) are directly measurable
- Medium Confidence: VQA accuracy improvements (2.9%-9.6%) depend on retrieval-generation interaction
- Low Confidence: Efficiency claims relative to traditional methods lack direct computational benchmarks

## Next Checks
1. Verify identifier uniqueness across GS112K and Wiki21M by measuring collision rates when extracting 10-token subsequences
2. Benchmark FM-Index construction and query latency for 21M documents on comparable hardware
3. Perform ablation study removing the reinforced calibration module to quantify its specific contribution