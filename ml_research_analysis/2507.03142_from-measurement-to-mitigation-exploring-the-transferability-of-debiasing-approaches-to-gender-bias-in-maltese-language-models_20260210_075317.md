---
ver: rpa2
title: 'From Measurement to Mitigation: Exploring the Transferability of Debiasing
  Approaches to Gender Bias in Maltese Language Models'
arxiv_id: '2507.03142'
source_url: https://arxiv.org/abs/2507.03142
tags:
- bias
- maltese
- language
- gender
- bertu
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates gender bias in Maltese language models
  (BERTu and mBERTu) and evaluates the transferability of English debiasing techniques
  to this low-resource, morphologically rich language. Bias was measured using CrowS-Pairs,
  SEAT, and sentence template analysis, revealing that both models exhibit gender
  bias, with monolingual BERTu showing stronger biases.
---

# From Measurement to Mitigation: Exploring the Transferability of Debiasing Approaches to Gender Bias in Maltese Language Models

## Quick Facts
- arXiv ID: 2507.03142
- Source URL: https://arxiv.org/abs/2507.03142
- Authors: Melanie Galea; Claudia Borg
- Reference count: 11
- Primary result: CDA most effective debiasing method for Maltese LMs, reducing CrowS scores by up to 13.1%

## Executive Summary
This study investigates gender bias in Maltese language models (BERTu and mBERTu) and evaluates the transferability of English debiasing techniques to this low-resource, morphologically rich language. Bias was measured using CrowS-Pairs, SEAT, and sentence template analysis, revealing that both models exhibit gender bias, with monolingual BERTu showing stronger biases. Among the debiasing methods tested—Counterfactual Data Augmentation (CDA), Dropout Regularization, Auto-Debias, and GuiDebias—CDA was most effective, reducing CrowS scores by up to 13.1% and SEAT scores by up to 14.1%. Dropout Regularization showed moderate success, particularly for multilingual models, while GuiDebias increased bias in Maltese models. Auto-Debias reduced bias in monolingual models but increased it in multilingual ones. t-SNE visualizations confirmed persistent gender associations in BERTu, though multilingual mBERTu exhibited more balanced representations. The findings highlight the need for tailored debiasing approaches and multiple evaluation metrics for low-resource languages.

## Method Summary
The research employed multiple bias measurement techniques including CrowS-Pairs, Sentence Encoder Association Test (SEAT), and template-based sentence analysis to evaluate gender bias in Maltese language models. The study tested four debiasing approaches: Counterfactual Data Augmentation (CDA), Dropout Regularization, Auto-Debias, and GuiDebias. Each method was systematically applied to both monolingual (BERTu) and multilingual (mBERTu) Maltese models. The effectiveness of debiasing was measured using the same metrics used for initial bias assessment, allowing for direct comparison of bias levels before and after intervention. t-SNE visualizations were used to examine gender representation spaces in the models.

## Key Results
- CDA most effective debiasing method, reducing CrowS scores by up to 13.1% and SEAT scores by up to 14.1%
- BERTu exhibited stronger gender bias than mBERTu across all evaluation metrics
- Auto-Debias reduced bias in monolingual models but increased it in multilingual models
- t-SNE visualizations showed persistent gender associations in BERTu, more balanced representations in mBERTu

## Why This Works (Mechanism)
The debiasing methods work by modifying the training process or data distribution to reduce gender associations in the learned representations. CDA achieves this by balancing the training corpus with counterfactual examples, Dropout Regularization introduces noise to prevent over-reliance on gender cues, Auto-Debias directly penalizes gender-related dimensions in the loss function, and GuiDebias uses geometric approaches to separate gender information from task-relevant features. The varying effectiveness across monolingual and multilingual models suggests that these mechanisms interact differently with language-specific morphological structures and cross-lingual transfer patterns.

## Foundational Learning
- Maltese language morphology: Why needed - to understand how gender manifests in this morphologically rich language; Quick check - identify gender-marking suffixes and their distribution across word classes
- Cross-lingual transfer effects: Why needed - to explain why debiasing methods work differently in monolingual vs multilingual models; Quick check - compare gender associations in shared vs language-specific layers
- Counterfactual data augmentation: Why needed - to understand the mechanism behind CDA's effectiveness; Quick check - measure gender distribution before/after CDA application
- Bias measurement metrics: Why needed - to evaluate debiasing effectiveness; Quick check - verify metric sensitivity to known gender associations

## Architecture Onboarding

**Component Map:**
Data -> Model Training -> Bias Measurement -> Debiasing Method -> Re-measurement -> Analysis

**Critical Path:**
Training data preparation -> Model training -> Initial bias measurement -> Debiasing intervention -> Post-debiasing evaluation -> Visualization analysis

**Design Tradeoffs:**
- Computational cost vs debiasing effectiveness (CDA requires more data but shows better results)
- Language-specific vs cross-lingual approaches (monolingual models show stronger bias but may be easier to debias)
- Multiple metrics vs single metric evaluation (comprehensive assessment but increased complexity)

**Failure Signatures:**
- Debiasing methods that increase bias (GuiDebias in Maltese models)
- Inconsistent results across different evaluation metrics
- Methods that work for monolingual but not multilingual models (Auto-Debias)

**3 First Experiments:**
1. Compare gender associations in shared vs language-specific layers of mBERTu
2. Test CDA with varying ratios of counterfactual examples
3. Evaluate debiasing effectiveness on out-of-distribution gender contexts

## Open Questions the Paper Calls Out
None

## Limitations
- Limited Maltese corpus size (3.5 billion tokens) may constrain model performance and debiasing effectiveness
- Evaluation metrics may not fully capture gender bias manifestations in morphologically rich languages
- Findings may not generalize to other low-resource morphologically rich languages with different linguistic properties

## Confidence
- High confidence: Both BERTu and mBERTu exhibit gender bias (consistent across multiple metrics)
- Medium confidence: Effectiveness rankings of debiasing methods (vary between monolingual and multilingual models)
- Medium confidence: Transferability of English debiasing techniques to Maltese (mixed success observed)
- Low confidence: Generalizability to other low-resource morphologically rich languages (Maltese has unique properties)

## Next Checks
1. Conduct systematic evaluation of debiasing methods across multiple low-resource morphologically rich languages
2. Develop and validate additional evaluation metrics specifically designed for morphologically rich languages
3. Investigate long-term stability of debiasing effects through extended model use and exposure to new data