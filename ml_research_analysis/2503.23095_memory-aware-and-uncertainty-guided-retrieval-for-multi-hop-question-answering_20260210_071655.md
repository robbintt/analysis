---
ver: rpa2
title: Memory-Aware and Uncertainty-Guided Retrieval for Multi-Hop Question Answering
arxiv_id: '2503.23095'
source_url: https://arxiv.org/abs/2503.23095
tags:
- retrieval
- multi-hop
- arxiv
- reasoning
- filtering
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces MIND, a Memory-Informed and Interactive
  Dynamic RAG framework for multi-hop question answering. MIND addresses two key limitations
  in existing RAG methods: fixed retrieval schedules and ineffective use of previously
  retrieved knowledge.'
---

# Memory-Aware and Uncertainty-Guided Retrieval for Multi-Hop Question Answering

## Quick Facts
- **arXiv ID:** 2503.23095
- **Source URL:** https://arxiv.org/abs/2503.23095
- **Authors:** Yuelyu Ji; Rui Meng; Zhuochun Li; Daqing He
- **Reference count:** 36
- **Primary result:** MIND framework achieves up to 3.5% improvement in F1 score on multi-hop QA datasets

## Executive Summary
This paper introduces MIND, a Memory-Informed and Interactive Dynamic RAG framework for multi-hop question answering. MIND addresses two key limitations in existing RAG methods: fixed retrieval schedules and ineffective use of previously retrieved knowledge. The framework employs dynamic retrieval triggering based on token-level entropy and attention signals, prompt-based entity extraction, and memory-aware filtering that stores high-confidence facts across reasoning steps. MIND significantly outperforms baseline methods on four multi-hop QA datasets (HotpotQA, 2WikiMultihopQA, StrategyQA, IIRC), achieving up to 3.5% improvement in F1 score and reducing unnecessary retrieval calls by 10-15%. The memory-aware design ensures cross-hop consistency while the dynamic thresholding adapts retrieval to varying question complexity, demonstrating superior performance in complex reasoning tasks compared to static retrieval approaches.

## Method Summary
MIND is a Memory-Informed and Interactive Dynamic RAG framework that enhances multi-hop question answering through uncertainty-guided retrieval triggering and memory-aware filtering. The framework operates through iterative sub-query formulation, where the LLM monitors token-level entropy and attention signals to dynamically decide when to retrieve external knowledge. Extracted entities are scored using confidence functions and validated through Chain-of-Thought reasoning before being stored in memory. The system forms refined sub-queries based on memory content, enabling step-by-step reasoning across multiple documents while maintaining cross-hop consistency.

## Key Results
- MIND achieves up to 3.5% improvement in F1 score compared to baseline methods on multi-hop QA datasets
- Dynamic retrieval triggering reduces unnecessary retrieval calls by 10-15% while maintaining accuracy
- Memory-aware filtering ensures cross-hop consistency and prevents noise accumulation in reasoning chains
- Outperforms static retrieval approaches on HotpotQA, 2WikiMultihopQA, StrategyQA, and IIRC datasets

## Why This Works (Mechanism)

### Mechanism 1: Uncertainty-Guided Retrieval Triggering (RIND)
- **Claim:** Dynamically triggering retrieval based on real-time model uncertainty appears to reduce unnecessary calls while maintaining accuracy.
- **Mechanism:** The RIND module monitors token-level entropy and attention influence during generation. If the maximum uncertainty signal exceeds a dynamic threshold θ (defined by α and β hyperparameters), generation is paused to retrieve external knowledge.
- **Core assumption:** High entropy and specific attention patterns correlate directly with a lack of parametric knowledge (hallucination risk) rather than general linguistic ambiguity.
- **Evidence anchors:**
  - [abstract] "...dynamic retrieval triggering based on token-level entropy and attention signals..."
  - [section 3.2] Defines the threshold θ and the condition for triggering retrieval.
  - [corpus] Related work (DRAGIN, SEAKER) validates that real-time uncertainty signals are effective for retrieval decisions.
- **Break condition:** If a query is ambiguous but the model is confident (low entropy), or if the model is confused by noise (high entropy) but the query is simple, this mechanism may fail to trigger or trigger excessively.

### Mechanism 2: Memory-Aware Entity Filtering
- **Claim:** Filtering extracted entities via confidence scores and Chain-of-Thought (CoT) reasoning likely improves multi-hop consistency by preventing noise accumulation.
- **Mechanism:** Extracted entities are scored using a confidence function (Eq. 4) involving entropy and max attention. A hybrid mode validates logical consistency via CoT before ranking by confidence to decide what enters the memory store M.
- **Core assumption:** Discarding low-confidence or logically inconsistent entities removes "hallucinated" or irrelevant context without losing critical "bridging" entities.
- **Evidence anchors:**
  - [abstract] "...memory-aware filtering, which stores high-confidence facts..."
  - [section 3.3] Details the filtering strategies (No Filter, CoT, Conf, Hybrid).
  - [section 4.2.4] Notes that CoT+Conf can occasionally remove necessary low-certainty bridging entities.
- **Break condition:** Over-filtering (e.g., aggressive CoT+Conf) on tasks with implicit or weakly supported bridging entities may degrade performance compared to simpler baselines.

### Mechanism 3: Iterative Sub-Query Formulation
- **Claim:** Reformulating the original query into specific sub-queries based on memory content enables step-by-step reasoning across multiple documents.
- **Mechanism:** When RIND triggers retrieval, the system forms a sub-query (e.g., identifying a missing relation like "father of") to fetch the specific missing link. This retrieved fact is added to memory, and the process iterates.
- **Core assumption:** The LLM can correctly decompose a complex query into a sequential dependency graph where one sub-query resolves the prerequisites for the next.
- **Evidence anchors:**
  - [section 3.4] "Once new entities are identified, a refined sub-query is formed..."
  - [figure 1] Visualizes the transition from the main query to "Who is the father of..."
  - [corpus] Neighbor papers (e.g., RISE) support iterative exploration for multi-hop QA.
- **Break condition:** If entity extraction (Step 1) fails to identify the correct pivot entity, the subsequent sub-query will be irrelevant, leading to cascading retrieval errors.

## Foundational Learning

- **Concept: Entropy in Language Models**
  - **Why needed here:** Used as the primary signal for "ignorance" or "hallucination risk" in the RIND module.
  - **Quick check question:** If a model generates a token with probability 0.9 vs 0.3, how does the entropy differ, and what does that imply for retrieval need?

- **Concept: Multi-hop "Bridging" Entities**
  - **Why needed here:** Understanding that the answer depends on an intermediate entity (e.g., finding the father before finding the grandfather) is crucial for designing the sub-query mechanism.
  - **Quick check question:** In the query "Who is X's grandfather?", which entity is the "bridge" that must be retrieved first?

- **Concept: Precision vs. Recall in Filtering**
  - **Why needed here:** Essential for tuning the memory filter (CoT vs. Confidence vs. No Filter) to balance answer correctness (Precision) with evidence coverage (Recall).
  - **Quick check question:** Does a "No Filter" strategy prioritize precision or recall, and what is the associated risk in a multi-hop context?

## Architecture Onboarding

- **Component map:** Input Query -> Prompt Extraction -> Generator + RIND -> Decision Gate -> Retrieval -> Memory -> Context Update
- **Critical path:** The interaction between the RIND module (deciding when) and the Memory Filter (deciding what). If RIND is insensitive, retrieval never happens; if the Memory Filter is too loose, context window overflows or confuses the model.
- **Design tradeoffs:**
  - **Fixed vs. Dynamic Thresholds:** Dynamic (Eq. 3) adapts to question complexity but adds computational overhead vs. a simple fixed threshold (Table 4).
  - **Filtering Strategies:** "No Filter" is computationally cheapest but noisiest; "CoT+Conf" is most robust against noise but risks dropping critical low-confidence bridges (Table 1 results on StrategyQA vs 2Wiki).
- **Failure signatures:**
  - **Stuck in loop:** RIND repeatedly triggers retrieval on the same token (threshold too low).
  - **Silent failure:** Model generates plausible but wrong answer without triggering retrieval (threshold too high or confidence artificially high).
  - **Context drift:** Memory accumulates irrelevant entities (filter settings too permissive), causing the final answer to synthesize unrelated facts.
- **First 3 experiments:**
  1. **Threshold Validation:** Replicate Table 4 on a dev set to verify if dynamic thresholding (α, β tuning) actually outperforms a fixed threshold (e.g., 0.6) for your specific LLM backbone.
  2. **Filter Ablation:** Run the 4 filter modes (None, CoT, Conf, CoT+Conf) on a sample of HotpotQA "bridge" questions to observe the trade-off between retrieval count (#Ret) and F1 score.
  3. **Entity Extraction sanity check:** Manually inspect Step 1 outputs to ensure the prompt-based extraction is identifying the correct bridge entities; if this fails, the subsequent RIND/Memory loop cannot recover.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the MIND framework be effectively extended to conversational AI systems where multi-turn interactions require persistent context and robust retrieval strategies?
- Basis in paper: [explicit] The conclusion states, "Future work will focus on extending this framework to conversational AI systems, where multi-turn interactions require robust retrieval strategies."
- Why unresolved: The current framework is evaluated on single-turn multi-hop QA datasets; it lacks mechanisms for handling dialogue history or context drift over extended interactions.
- What evidence would resolve it: Evaluation results of MIND on multi-turn conversational QA datasets (e.g., QReCC or CoQA) showing maintenance of retrieval efficiency and accuracy across dialogue turns.

### Open Question 2
- Question: Can an adaptive meta-controller be developed to dynamically select filtering strategies (e.g., switching between CoT and No Filter) based on query complexity to prevent performance degradation on simple questions?
- Basis in paper: [inferred] Section 4.2.4 notes that the "CoT + Conf" hybrid filter "can trail simpler approaches in more direct scenarios" because excessive filtering removes necessary entities on straightforward tasks.
- Why unresolved: The current implementation relies on a single, fixed filtering mode per run, which forces a trade-off between precision on complex queries and recall on simple ones.
- What evidence would resolve it: A mechanism that automatically detects query complexity and switches strategies, resulting in higher average F1 scores across a dataset containing a mix of simple and complex questions compared to any static filtering configuration.

### Open Question 3
- Question: What specific memory update mechanisms are required to handle long-term dependencies and entity retention more effectively without losing cross-hop consistency?
- Basis in paper: [explicit] The conclusion identifies "improving memory update mechanisms to handle long-term dependencies" as an important future direction, noting that entity retention is crucial for consistency.
- Why unresolved: The current memory module caches entities across steps, but the paper suggests further optimization is needed for scaling to applications with longer reasoning chains or larger knowledge scopes.
- What evidence would resolve it: Ablation studies comparing different memory decay or update rates on datasets requiring significantly more reasoning hops (e.g., >4 hops), demonstrating superior entity consistency and reduced hallucination rates.

## Limitations

- **Dataset Generalization Gap:** Performance may not translate to domains with implicit relationships or different entity structures beyond Wikipedia and structured data
- **Computational Overhead Trade-offs:** Dynamic retrieval triggering adds real-time monitoring overhead not fully quantified against retrieval call reduction benefits
- **Threshold Sensitivity and Hyperparameter Dependence:** Heavy reliance on α, β hyperparameter tuning may indicate brittleness across varying question distributions

## Confidence

**High Confidence (8/10):** The core architectural design combining memory-aware filtering with uncertainty-guided retrieval triggering is technically sound. The modular approach (RIND for timing, memory for storage, entity extraction for pivoting) follows established patterns in retrieval-augmented generation literature.

**Medium Confidence (6/10):** The reported performance improvements (up to 3.5% F1 gain) are based on controlled experiments across four datasets. However, the ablation studies showing "10-15% reduction in retrieval calls" may not fully account for the computational overhead of the monitoring mechanism itself.

**Low Confidence (4/10):** Claims about cross-hop consistency maintenance and prevention of "hallucination" are largely inferred from performance metrics rather than directly measured. The memory-aware design's effectiveness in preventing knowledge drift across reasoning steps is not explicitly validated through targeted experiments.

## Next Checks

1. **Cross-Domain Transfer Validation:** Evaluate MIND on datasets from significantly different domains (e.g., scientific literature, news articles, or conversational data) to test the generalizability of entity extraction and sub-query formulation mechanisms. Compare performance degradation against domain-specific fine-tuning of baseline models.

2. **Computational Overhead Measurement:** Implement profiling to measure the actual wall-clock time and GPU memory usage of the RIND monitoring mechanism across varying context lengths. Compare the end-to-end latency of MIND against static retrieval baselines under identical hardware conditions.

3. **Failure Mode Analysis:** Conduct systematic testing where the entity extraction module is deliberately given malformed or ambiguous input to observe how the framework recovers (or fails to recover). Track whether the memory-aware filtering prevents or exacerbates error propagation across reasoning steps in these failure scenarios.