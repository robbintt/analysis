---
ver: rpa2
title: 'I2MoE: Interpretable Multimodal Interaction-aware Mixture-of-Experts'
arxiv_id: '2505.19190'
source_url: https://arxiv.org/abs/2505.19190
tags:
- multimodal
- modality
- interaction
- i2moe
- experts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces I2MoE, a mixture-of-experts framework that
  explicitly models heterogeneous modality interactions to improve both performance
  and interpretability in multimodal learning. It uses specialized interaction experts
  to capture unique, synergistic, and redundant information across modalities, along
  with a reweighting model that assigns importance scores for local and global interpretability.
---

# I2MoE: Interpretable Multimodal Interaction-aware Mixture-of-Experts

## Quick Facts
- arXiv ID: 2505.19190
- Source URL: https://arxiv.org/abs/2505.19190
- Authors: Jiayi Xin; Sukwon Yun; Jie Peng; Inyoung Choi; Jenna L. Ballard; Tianlong Chen; Qi Long
- Reference count: 32
- Primary result: I2MoE achieves up to 5.5% accuracy gains over vanilla fusion by explicitly modeling heterogeneous modality interactions through specialized experts

## Executive Summary
I2MoE introduces a mixture-of-experts framework that explicitly models heterogeneous modality interactions to improve both performance and interpretability in multimodal learning. It uses specialized interaction experts to capture unique, synergistic, and redundant information across modalities, along with a reweighting model that assigns importance scores for local and global interpretability. Experiments on five real-world datasets (including ADNI, MIMIC-IV, IMDB, MOSI, and ENRICO) show consistent improvements over vanilla fusion methods, with up to 5.5% accuracy gains. The approach is flexible, integrating seamlessly with existing fusion methods, and provides meaningful insights into modality contributions through both sample-level and dataset-level analysis.

## Method Summary
I2MoE uses n+2 experts (n uniqueness experts for each modality, one synergy expert, and one redundancy expert) to capture different interaction types between modalities. A reweighting MLP assigns sample-specific weights to each expert's output, combining them into a final prediction. During training, random vector masking creates synthetic positive/negative examples for weakly supervised interaction losses, forcing experts to specialize in their designated interaction types. The framework integrates with existing fusion backbones like MulT, SwitchGate, and InterpretCC, and provides both sample-level and dataset-level interpretability through the expert weight distributions.

## Key Results
- Achieves up to 5.5% accuracy improvements over vanilla fusion methods across five real-world datasets
- Ensemble of specialized experts consistently outperforms individual interaction experts by 0.6-7.1% accuracy
- High expert disagreement rates (81-99% across datasets) demonstrate heterogeneous interaction patterns while maintaining strong overall performance
- Interpretable weight distributions reveal meaningful modality contributions, such as image uniqueness experts dominating Animation genre prediction on IMDB

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Weakly supervised interaction losses with random vector masking induce expert specialization for distinct modality interaction types.
- Mechanism: During training, additional forward passes replace one modality embedding with a random vector. For each expert, these perturbed outputs serve as positive/negative examples. Uniqueness expert F_uni1 receives y_12≈y_-2 as positive (modality 2 masked) and y_-1 as negative. Synergy expert treats all masked outputs as negative. Redundancy expert treats all as positive. This contrastive pressure forces structural differentiation without explicit interaction labels.
- Core assumption: Random vectors fully suppress task-relevant information from the masked modality; mean/zero vectors would leak residual signal.
- Evidence anchors: [abstract] and [Section 3.3.2] describe the loss formulations; [Appendix B] shows random masking outperforms alternatives across five datasets.

### Mechanism 2
- Claim: The reweighting MLP provides sample-adaptive expert combination while exposing interaction contributions for interpretation.
- Mechanism: An MLP takes all modality embeddings and outputs soft weights [w_uni1, w_uni2, w_syn, w_red]. The final prediction is a weighted sum of expert outputs. Weights are trained end-to-end via task loss. Sample-level weights reveal which interaction type dominates each prediction; dataset-level weight distributions characterize overall modality dynamics.
- Core assumption: The reweighting MLP can learn meaningful mapping from embeddings to interaction importance without direct supervision on weights.
- Evidence anchors: [abstract] describes the reweighting model; [Section 5.3] shows how image uniqueness experts receive higher weights for Animation genre prediction; [Section 6.3, ablation (3)] shows performance drops when using global learnable weights instead of adaptive reweighting.

### Mechanism 3
- Claim: The ensemble of specialized experts captures complementary information that no single fusion model can access.
- Mechanism: Vanilla fusion uses shared parameters for all interaction types. I2MoE dedicates separate parameters to each interaction, allowing experts to learn specialized representations. The reweighting combines them adaptively. Even when experts disagree (85% of IMDB samples, 81% of ADNI), the ensemble can achieve correct predictions by weighting appropriately.
- Core assumption: Modality interactions are heterogeneous within and across samples; specialization yields better representation than monolithic fusion.
- Evidence anchors: [Section 5.4] shows I2MoE-MulT performance consistently surpasses individual experts; [Section 6.2, Table 3] reveals high expert disagreement yet maintained accuracy; [Section 6.3, ablation (5)] shows significant performance drops when removing uniqueness experts.

## Foundational Learning

- Concept: Partial Information Decomposition (PID)
  - Why needed here: I2MoE's four expert types directly map to PID components (uniqueness, synergy, redundancy). Understanding PID clarifies why heterogeneous interactions require specialized modeling.
  - Quick check question: Given two modalities, can you identify a prediction that requires both simultaneously (synergy) versus one where either modality suffices (redundancy)?

- Concept: Mixture-of-Experts routing
  - Why needed here: I2MoE extends MoE by replacing token-level routing with interaction-type routing via the reweighting MLP. Standard MoE intuition about load balancing and expert capacity applies.
  - Quick check question: How does I2MoE's reweighting differ from sparse MoE routing (e.g., top-k gating)?

- Concept: Weak supervision via input perturbation
  - Why needed here: I2MoE has no ground-truth labels for which interaction type applies to each sample. Random vector masking creates synthetic positive/negative pairs to induce specialization.
  - Quick check question: Why might random vectors outperform zero vectors for masking, and when might this assumption fail?

## Architecture Onboarding

- Component map:
  - Modality encoders E_i (backbone-specific, frozen or fine-tuned) → embeddings e_i
  - Interaction experts F_uni1, F_uni2, ..., F_syn, F_red (each wraps a fusion backbone like MulT)
  - Reweighting MLP W: takes [e_1, ..., e_n], outputs weights summing to 1
  - Prediction heads H_i within each expert
  - Interaction loss module: generates masked forward passes and computes triplet/cosine losses

- Critical path:
  1. Forward pass with full inputs → expert outputs ŷ_i^(0) and main prediction ŷ = Σ w_i · ŷ_i^(0)
  2. For each modality j: forward pass with modality j replaced by random vector → ŷ_i^(j) for all experts
  3. Compute task loss on ŷ; compute interaction losses per expert using masked outputs as pos/neg
  4. Backprop through all components jointly
  5. Inference: single forward pass, no masking needed

- Design tradeoffs:
  - Computational overhead: Training requires (n+1) forward passes per batch (Table 6 shows 1.8-19.8x slower training). Inference is single-pass.
  - Expert count: Scales as n+2 (one uniqueness per modality plus synergy/redundancy), avoiding combinatorial explosion.
  - Backbone flexibility: Any fusion method with modality embeddings can be wrapped. Tested with MulT, SwitchGate, InterpretCC, MoE++.

- Failure signatures:
  - Uniform weight distribution → reweighting MLP not learning; check embedding quality or increase hidden dimension.
  - Experts collapsing to similar predictions → interaction loss weight λ_int too low; increase or verify masking is effective.
  - Performance worse than vanilla fusion → overfitting to interaction loss; reduce λ_int or add regularization.
  - High disagreement but low accuracy on disagreement cases (Table 3, IMDB) → reweighting not resolving conflict effectively.

- First 3 experiments:
  1. Replicate I2MoE-MulT on a 2-modality dataset (e.g., IMDB) with default hyperparameters. Verify that each expert shows distinct behavior by computing pairwise agreement rates.
  2. Ablate the interaction loss (No-Interaction variant). Confirm performance drops on ADNI/MOSI as reported in Table 4.
  3. Visualize weight distributions across test set (Figure 4 style). Check that your domain shows meaningful variation; uniform weights suggest upstream issues.

## Open Questions the Paper Calls Out

- Question: Can alternative formulations for the interaction loss improve expert specialization and performance beyond the current triplet margin and cosine similarity approach?
  - Basis in paper: The Conclusion states that "alternative forms of interaction loss could be explored to further improve performance."
  - Why unresolved: The current implementation relies on specific contrastive losses to approximate PID interactions, but the optimality of these specific loss functions is not guaranteed.
  - What evidence would resolve it: Comparative studies showing higher expert orthogonality or task accuracy using different loss functions (e.g., mutual information estimators) on the same benchmarks.

- Question: How can feature attribution methods be integrated to analyze the contributions of individual features within specific interaction experts?
  - Basis in paper: The Conclusion suggests "integrating feature attribution methods to analyze the contributions of individual features within interaction experts can offer deeper interpretable insights."
  - Why unresolved: Current interpretability is limited to sample-level and dataset-level expert weights, lacking granular visibility into which specific input features drive an expert's decision.
  - What evidence would resolve it: A new module that generates feature importance maps (e.g., saliency maps) for each expert that align semantically with the expert's designated interaction type (e.g., unique visual features for the Uniqueness expert).

- Question: How can the framework be improved to handle cases where interaction experts strongly disagree, particularly on complex multi-label datasets?
  - Basis in paper: Section 6.2 reveals that on the IMDB dataset, experts disagree 99.99% of the time, and I2MoE yields incorrect predictions 84.14% of the time during these disagreements.
  - Why unresolved: The current reweighting model struggles to arbitrate between experts when they provide highly divergent outputs, leading to performance degradation in complex scenarios.
  - What evidence would resolve it: A modified reweighting mechanism or arbitration strategy that increases prediction accuracy specifically in the "Disagree" subset of test samples.

## Limitations
- Random vector masking effectiveness depends on the assumption that random vectors contain no task-relevant information, which may fail when random vectors accidentally correlate with semantic content.
- Expert specialization relies on properly tuned interaction loss weights (λ_int), with different values used across datasets without clear theoretical justification.
- Interpretation methodology assumes sample-level weight distributions reflect meaningful interaction patterns but lacks validation against human expert judgment or alternative interpretability frameworks.

## Confidence
- **High**: Claims about performance improvements (5.5% accuracy gains) and ensemble benefits over individual experts are directly supported by experimental results across five datasets.
- **Medium**: Claims about interpretability utility (local/global insights) are supported by case studies but lack systematic validation or comparison to established interpretability frameworks.
- **Low**: Claims about random vector masking being optimal (vs mean/zero masking) are based on single empirical comparison without ablation studies or theoretical grounding.

## Next Checks
1. Verify that random vector masking is necessary: Compare I2MoE performance using random vectors vs mean vectors vs zero vectors across all five datasets, replicating Table 5 analysis.
2. Test robustness to interaction loss weight: Systematically vary λ_int from 0.0001 to 1.0 and measure performance/interpretability trade-offs on ADNI and IMDB.
3. Validate interpretability claims: Compare I2MoE weight-based interpretation against SHAP values or attention visualizations on IMDB to assess whether weight distributions provide unique insights.