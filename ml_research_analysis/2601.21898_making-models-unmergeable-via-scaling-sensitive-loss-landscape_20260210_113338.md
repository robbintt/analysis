---
ver: rpa2
title: Making Models Unmergeable via Scaling-Sensitive Loss Landscape
arxiv_id: '2601.21898'
source_url: https://arxiv.org/abs/2601.21898
tags:
- unprotected
- trap
- merging
- accuracy
- params
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces TRAP 2, a training-time method to make fine-tuned\
  \ model updates unmergeable while preserving their standalone performance. Unlike\
  \ post-hoc defenses limited to Transformers and full-weight access, TRAP 2 embeds\
  \ protection directly into the update by inducing loss degradation under scaling\u2014\
  a common effect in merging."
---

# Making Models Unmergeable via Scaling-Sensitive Loss Landscape

## Quick Facts
- **arXiv ID**: 2601.21898
- **Source URL**: https://arxiv.org/abs/2601.21898
- **Reference count**: 40
- **Primary result**: TRAP 2 makes fine-tuned model updates unmergeable while preserving standalone performance through loss landscape perturbation

## Executive Summary
This paper introduces TRAP 2, a training-time method that makes fine-tuned model updates unmergeable by embedding protection directly into the update process. Unlike post-hoc defenses limited to Transformers and full-weight access, TRAP 2 induces loss degradation under scaling operations commonly used in merging. The method works across different architectures (ViT, ConvNeXt) and release formats (LoRA adapters, full models), consistently degrading performance under merging while maintaining standalone utility. Theoretical analysis supports these findings with convergence guarantees under scaling and merging operations.

## Method Summary
TRAP 2 operates by perturbing the loss landscape during training to create scaling-sensitive regions that degrade when merging operations are applied. The method modifies the training objective to induce specific curvature properties in the loss surface that amplify under linear combinations typical of model merging. During fine-tuning, TRAP 2 adds a regularization term that creates sharp loss valleys along directions relevant to merging, causing performance collapse when updates are scaled and combined. The approach is architecture-agnostic and works with both full-parameter fine-tuning and parameter-efficient methods like LoRA adapters.

## Key Results
- TRAP 2 consistently degrades merging performance while preserving standalone utility across ViT and ConvNeXt architectures
- Outperforms prior post-hoc defenses, particularly in adapter-only settings where previous methods fail
- Theoretical analysis proves convergence and controlled degradation under scaling and merging operations
- Effective across multiple release formats including LoRA adapters and full model weights

## Why This Works (Mechanism)
TRAP 2 exploits the mathematical properties of loss landscape geometry under linear transformations. When models are merged, their parameters are typically combined through weighted averaging or linear interpolation. TRAP 2 creates loss surfaces with specific curvature characteristics that are highly sensitive to these linear operations. The regularization term during training ensures that directions along which merging occurs correspond to steep gradients or pathological curvature, causing merged models to converge to poor local minima. This scaling-sensitivity is embedded during the fine-tuning phase, making it intrinsic to the update rather than an external wrapper.

## Foundational Learning
- **Loss landscape geometry**: Understanding how parameter space curvature affects optimization and generalization is crucial for designing perturbation strategies that specifically target merging operations
- **Model merging mathematics**: Knowledge of linear combinations, weighted averaging, and interpolation in parameter space is needed to predict how perturbations will amplify under merging
- **Adversarial training concepts**: Techniques for embedding robustness or fragility into models during training provide the conceptual framework for TRAP 2's approach
- **Parameter-efficient fine-tuning**: Familiarity with LoRA and other adapter methods is necessary to understand the full scope of TRAP 2's applicability
- **Gradient-based optimization**: Understanding how optimization trajectories interact with loss surface geometry explains why merged models fail
- **Regularization techniques**: Knowledge of how different regularization terms shape loss landscapes informs the design of TRAP 2's objective function

## Architecture Onboarding
**Component map**: Training pipeline -> TRAP 2 regularization -> Modified loss function -> Parameter updates -> Protected fine-tuned model
**Critical path**: Fine-tuning process incorporating TRAP 2 objective → Model update generation → Standalone evaluation → Merging operation → Degraded performance validation
**Design tradeoffs**: Protection strength vs. standalone performance degradation, computational overhead vs. security level, architecture compatibility vs. effectiveness
**Failure signatures**: Insufficient perturbation amplitude leading to successful merging, over-regularization causing standalone performance collapse, architecture-specific optimization issues
**First experiments**: 1) Validate standalone performance preservation on base architecture without TRAP 2, 2) Test merging degradation on simple linear interpolation baseline, 3) Measure computational overhead during training phase

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Computational overhead during training not quantified, creating uncertainty about scalability
- Effectiveness on very large models with complex merging operations remains unproven
- Potential for adaptive attackers to develop countermeasures against loss landscape perturbation
- Limited evaluation to vision models and adapter-based deployments, with unclear effectiveness for LLMs and full-parameter releases

## Confidence
- **High confidence** in standalone performance preservation claims (extensively validated across architectures)
- **Medium confidence** in merging degradation effectiveness (strong empirical support but limited adversarial testing)
- **Medium confidence** in theoretical convergence guarantees (formal analysis provided but simplified assumptions)
- **Low confidence** in computational overhead characterization (not systematically measured)

## Next Checks
1. Measure and report wall-clock training time overhead and memory requirements for TRAP 2 compared to standard fine-tuning across different model scales
2. Evaluate TRAP 2's effectiveness against adaptive merging strategies that attempt to compensate for loss landscape perturbations
3. Test the method on large language models (LLMs) and full-parameter model releases to assess generalizability beyond vision tasks and adapter-based deployments