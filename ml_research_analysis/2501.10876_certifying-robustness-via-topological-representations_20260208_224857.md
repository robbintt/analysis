---
ver: rpa2
title: Certifying Robustness via Topological Representations
arxiv_id: '2501.10876'
source_url: https://arxiv.org/abs/2501.10876
tags:
- persistence
- robustness
- diagrams
- neural
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces the Stable Rank Network (SRN), a neural network
  architecture that learns Lipschitz-stable geometric representations from persistence
  diagrams, common descriptors in topological data analysis. SRN combines learnable
  vectorizations using stable ranks with Lipschitz neural networks, enabling certified
  robustness under adversarial perturbations.
---

# Certifying Robustness via Topological Representations

## Quick Facts
- arXiv ID: 2501.10876
- Source URL: https://arxiv.org/abs/2501.10876
- Reference count: 34
- Key outcome: SRN achieves 79.6% accuracy on ORBIT5K with certified robustness under adversarial perturbations

## Executive Summary
This paper introduces the Stable Rank Network (SRN), a neural network architecture that learns Lipschitz-stable geometric representations from persistence diagrams for certified adversarial robustness. SRN combines learnable vectorizations using stable ranks with Lipschitz neural networks, enabling provable guarantees on robustness under input perturbations. The approach maintains high certified accuracy on the ORBIT5K dataset while avoiding the accuracy degradation seen in standard robust training methods. The method provides theoretical guarantees by leveraging the Lipschitz stability of persistent homology and controllable Lipschitz constants in the network architecture.

## Method Summary
The Stable Rank Network (SRN) processes topological data by first computing persistence diagrams from input metric spaces (like point clouds), then applying a learnable stable rank vectorization to obtain a fixed-dimensional representation. This vectorization is combined with a Lipschitz neural network where each layer uses 1-Lipschitz neurons of the form $u(x, w, b) = \|x - w\|_\infty + b$. The composition yields a globally Lipschitz function with a known constant K, enabling certified robustness through margin-based certification. The architecture achieves this by avoiding unbounded Lipschitz constants that arise in standard neural networks, providing provable guarantees that classification will remain stable within certified radii.

## Key Results
- SRN achieves 79.6% test accuracy on ORBIT5K dataset
- Certified robust accuracy at $\epsilon = 10^{-3}$: 71.3% (significantly higher than non-robust baselines)
- Outperforms Perslay architecture, which shows significant accuracy degradation under small perturbations
- Maintains high certified robustness with controllable Lipschitz constants throughout the network

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The Stable Rank Network (SRN) maintains a known, controllable global Lipschitz constant by composing two guaranteed Lipschitz components.
- **Mechanism:** The architecture first applies a learnable stable rank vectorization, which is a proven K-Lipschitz function from the space of persistence diagrams (with p-Wasserstein metric) to $\mathbb{R}^N$ (with $L_\infty$ metric). This is followed by a Lipschitz Neural Network where each layer uses neurons of the form $u(x, w, b) = \|x - w\|_\infty + b$, which are 1-Lipschitz by design. The composition of K-Lipschitz and 1-Lipschitz functions yields a controllable global Lipschitz constant, avoiding the problem of unbounded or uncomputable constants in standard networks.
- **Core assumption:** The learnable reparameterization function F must have a computable Lipschitz constant K (e.g., for differentiable F, K = sup F').
- **Evidence anchors:**
  - [abstract]: "SRN combines learnable vectorizations using stable ranks with Lipschitz neural networks... controllable Lipschitz constants in the network."
  - [section 3.1]: "Since rp,F is K-Lipschitz and all layers of the Lipschitz neural network are 1-Lipschitz functions, their composition f is a K-Lipschitz function."
  - [corpus]: ECLipsE-Gen-Local paper confirms that computing exact Lipschitz constants for standard networks is NP-hard, motivating architectures with provable bounds.
- **Break condition:** If the learnable F function is not constrained to be K-Lipschitz, or if standard neural network layers are substituted, the certifiable bound is lost.

### Mechanism 2
- **Claim:** Certified robustness is computed analytically from the prediction margin and known Lipschitz constant, requiring only a single forward pass.
- **Mechanism:** For a classifier $g = \text{argmax} \circ f$, the method leverages the margin certification framework. The certified robustness radius at sample x is $\epsilon \geq M_x / (2K)$, where $M_x$ is the prediction margin (difference between the correct class logit and the second-highest logit) and K is the known Lipschitz constant. This provides a lower bound on the perturbation radius within which the classification is guaranteed to remain unchanged.
- **Core assumption:** The Lipschitz constant K accurately bounds the network's sensitivity; an overestimated K yields conservative but valid certificates.
- **Evidence anchors:**
  - [abstract]: "This stability can be used to certify ε-robustness for samples in a dataset."
  - [section 3.1]: "g is ϵ-robust at x for all ϵ ≥ M_x / 2K, where K is the Lipschitz constant of f and M_x is the prediction margin."
  - [section 4]: "For SRN... computing a lower bound for the robustness radius at a sample x only requires a forward pass of x in the neural network to get M_x."
  - [corpus]: LDLT L-Lipschitz Network paper confirms that end-to-end Lipschitz control enables robustness certification.
- **Break condition:** If the Lipschitz constant K is unknown or the margin M_x is miscomputed, the certified radius cannot be determined.

### Mechanism 3
- **Claim:** The pipeline leverages the inherent Lipschitz stability of persistent homology (PH) to create certifiable robustness from raw input data to final prediction.
- **Mechanism:** PH transforms input metric spaces (e.g., point clouds) into persistence diagrams. The p-Wasserstein distance between diagrams is Lipschitz-stable with respect to appropriate input metrics (e.g., Gromov-Hausdorff distance for point clouds). SRN preserves this stability through its architecture, creating a composition of Lipschitz functions from input to output. This enables certifying robustness with respect to perturbations in the original input space.
- **Core assumption:** Input data can be meaningfully represented as metric spaces and the chosen PH construction preserves the stability properties.
- **Evidence anchors:**
  - [abstract]: "SRN... learns Lipschitz-stable geometric representations from persistence diagrams... enabling certified robustness under adversarial perturbations."
  - [section 1]: "PH is a Lipschitz function, with known Lipschitz constants, with respect to appropriate metrics on data and representation space."
  - [section A.2]: "Stability results also exist for other types of data... e.g. Gromov-Hausdorff distance between point clouds."
  - [corpus]: Lipschitz Bounds for Persistent Laplacian Eigenvalues paper confirms related stability properties in topological descriptors.
- **Break condition:** If the input representation does not form a metric space or the PH computation introduces numerical instabilities, the certification chain from input to output is broken.

## Foundational Learning

### Concept 1: Lipschitz Continuity
- **Why needed:** Ensures bounded output change for bounded input perturbations, enabling certified robustness
- **Quick check:** Verify that network layers use 1-Lipschitz neurons and the global constant K is computed correctly

### Concept 2: Persistent Homology (PH)
- **Why needed:** Transforms input metric spaces into stable topological representations (persistence diagrams)
- **Quick check:** Confirm PH computation preserves stability properties and diagrams are correctly computed from point clouds

### Concept 3: Wasserstein Distance
- **Why needed:** Metric on persistence diagrams that enables stability guarantees and Lipschitz analysis
- **Quick check:** Verify Wasserstein distance computation between diagrams and its use in vectorization stability proof

### Concept 4: Certified Robustness via Margin Certification
- **Why needed:** Provides analytical bounds on adversarial perturbation radii using prediction margins
- **Quick check:** Confirm margin calculation and radius formula $\epsilon \geq M_x / (2K)$ are correctly implemented

### Concept 5: Stable Rank Vectorization
- **Why needed:** Converts variable-size persistence diagrams to fixed-dimensional vectors while preserving Lipschitz properties
- **Quick check:** Verify vectorization output dimension matches network input and maintains K-Lipschitz property

## Architecture Onboarding

### Component Map
Input Point Clouds -> Persistence Diagram Computation (H1) -> Stable Rank Vectorization -> 5-Layer Lipschitz MLP -> Classification Output

### Critical Path
The critical path for certified robustness is: Point Clouds → PH Computation → Stable Rank Vectorization (K-Lipschitz) → Lipschitz Neural Network (1-Lipschitz per layer) → Output. The composition ensures the entire pipeline is K-Lipschitz, enabling the margin-based certification formula.

### Design Tradeoffs
- **Robustness vs Accuracy:** SRN achieves certified robustness but with lower accuracy (79.6%) compared to non-robust methods (87.7%)
- **Single vs Multi-Homology:** Current implementation uses only H1 for simplicity, potentially missing information from other homology dimensions
- **Fixed vs Variable Input Size:** Stable rank vectorization handles variable PD sizes but requires padding/truncation to match network input dimensions

### Failure Signatures
- **Dimension Mismatch Errors:** Variable-length stable rank vectors don't align with fixed network input size
- **Invalid Certified Radii:** Incorrect Lipschitz constant computation or margin calculation leads to invalid or overly conservative bounds
- **Numerical Instability:** PH computation or Wasserstein distance calculations introduce errors that break stability guarantees

### First Experiments
1. Verify Lipschitz properties by computing numerical gradients and confirming output changes are bounded by K times input perturbations
2. Test certified radius computation by comparing analytical bounds against empirical adversarial attacks on a small test set
3. Validate vectorization alignment by checking that all stable rank outputs have consistent dimensions matching the first network layer

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the Stable Rank Network perform when integrating multiple homology dimensions simultaneously?
- **Basis in paper:** [explicit] The authors state in Appendix C.4: "To simplify the analysis in terms of Wasserstein distance we choose to work with only one persistence diagram per sample... We choose H1 as it is more distinctive."
- **Why unresolved:** The current implementation restricts inputs to a single degree (H1) to simplify the analysis. It is unclear if the Lipschitz stability guarantees and the vectorization method scale effectively when concatenating or processing representations from multiple homology degrees ($H_0, H_1, H_2$, etc.).
- **What evidence would resolve it:** Experimental results on a dataset requiring multi-dimensional topology (e.g., 3D shape segmentation) where the SRN processes concatenated stable ranks from multiple degrees, reporting both accuracy and certified robustness radii.

### Open Question 2
- **Question:** Can certified robustness be effectively extended to the original input space (e.g., point clouds) rather than just the space of persistence diagrams?
- **Basis in paper:** [explicit] The Conclusion suggests: "Leveraging existing stability results of PH, a ML pipeline with interesting robustness properties w.r.t. appropriate distances in the input space (e.g. point clouds, function spaces) can thus be designed."
- **Why unresolved:** The current work certifies robustness with respect to the Wasserstein distance between persistence diagrams, not the distance in the input space (e.g., Gromov-Hausdorff distance for point clouds). Composing the Lipschitz constant of the SRN with the stability constants of the persistence diagram construction for end-to-end certification is theoretically proposed but not demonstrated.
- **What evidence would resolve it:** A theoretical derivation or empirical measurement of the robustness radius in the input metric space, verifying that small perturbations to the point cloud do not flip the classifier prediction.

### Open Question 3
- **Question:** Can the architecture be modified to close the performance gap with non-robust methods while maintaining certification?
- **Basis in paper:** [inferred] Comparison in Table 2 shows SRN achieves 79.6% accuracy whereas the non-robust Perslay architecture achieves 87.7%.
- **Why unresolved:** The paper demonstrates a trade-off between robustness and standard accuracy, which is common in certified defenses. It is unstated whether this ~8% drop is an inherent limitation of the stable rank vectorization or a result of the specific Lipschitz neural network architecture used ($\|x-w\|_\infty + b$ units).
- **What evidence would resolve it:** An ablation study testing different Lipschitz-constrained layers or stable rank parameterizations that achieve comparable accuracy to Perslay (e.g., >85%) on the ORBIT5K dataset.

## Limitations

- **Missing Implementation Details:** Vectorization step's handling of variable-length outputs and training hyperparameters are unspecified, creating uncertainty in exact reproduction
- **Performance Gap:** SRN shows ~8% accuracy drop compared to non-robust methods, indicating a trade-off between certification and standard accuracy
- **Single Homology Dimension:** Current implementation uses only H1, potentially missing valuable topological information from other dimensions

## Confidence

- **High Confidence:** The theoretical framework for SRN (Mechanism 1 and 2) is well-specified and follows from established Lipschitz theory. The certified robustness computation method is clearly defined and verifiable.
- **Medium Confidence:** The overall approach combining topological representations with Lipschitz networks is sound, but the empirical performance claims (accuracy, certified radius values) depend on the missing implementation details.
- **Low Confidence:** The exact numerical results on ORBIT5K cannot be independently verified without resolving the implementation ambiguities in vectorization alignment and training configuration.

## Next Checks

1. Verify the dimension handling in the stable rank vectorization by testing with point clouds of varying sizes and confirming consistent input dimensions to the first network layer.
2. Implement the Lipschitz MLP with the specified $L_\infty$ neurons and verify the global Lipschitz constant K=1 through numerical gradient estimation on validation samples.
3. Compare certified robustness radii computed from the analytical formula against empirical adversarial attack results (e.g., PGD) on a small subset of test samples to validate the theoretical bounds.