---
ver: rpa2
title: 'MedSentry: Understanding and Mitigating Safety Risks in Medical LLM Multi-Agent
  Systems'
arxiv_id: '2505.20824'
source_url: https://arxiv.org/abs/2505.20824
tags:
- medical
- agent
- arxiv
- safety
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents MedSentry, a comprehensive benchmark and evaluation
  pipeline for assessing and defending against insider threats in medical LLM multi-agent
  systems. The authors construct a dataset of 5,000 adversarial medical prompts across
  25 threat categories and 100 subthemes, then systematically evaluate four representative
  multi-agent architectures (Layers, SharedPool, Centralized, Decentralized) under
  attack by a single "dark-personality" agent.
---

# MedSentry: Understanding and Mitigating Safety Risks in Medical LLM Multi-Agent Systems

## Quick Facts
- arXiv ID: 2505.20824
- Source URL: https://arxiv.org/abs/2505.20824
- Reference count: 40
- A benchmark and defense system for insider threats in medical LLM multi-agent systems

## Executive Summary
MedSentry addresses critical safety risks in medical LLM multi-agent systems by identifying and mitigating insider threats. The framework constructs a comprehensive adversarial prompt dataset across 25 threat categories and evaluates four multi-agent architectures under attack. Through systematic analysis, the research demonstrates that decentralized architectures show superior resilience to malicious agents, while centralized and shared-pool designs are more vulnerable. The work introduces a personality-scale detection and correction mechanism that effectively restores system safety by identifying and isolating malicious agents based on psychometric profiling.

## Method Summary
The authors developed a benchmark dataset of 5,000 adversarial medical prompts spanning 25 threat categories and 100 subthemes. They evaluated four representative multi-agent architectures - Layers, SharedPool, Centralized, and Decentralized - by introducing a single malicious agent with dark personality traits. System performance was measured using the Medical Logical Consistency Score (LCS) and harm rate metrics. To defend against threats, they proposed a Personality-Scale Detection and Correction (PCDC) mechanism combining psychometric screening with behavior verification and topology-aware isolation. The PCDC system uses statistical personality inference from LLM responses to identify and neutralize malicious agents while maintaining system functionality.

## Key Results
- Decentralized architectures showed highest resilience with only 2.6% LCS drop under attack
- SharedPool architecture was most vulnerable with 8.7% LCS reduction when attacked
- PCDC defense restored safety metrics to near-baseline levels across all architectures
- Personality-scale detection achieved effective identification of malicious agents in medical contexts

## Why This Works (Mechanism)
The PCDC mechanism works by combining psychometric profiling with behavior verification to identify malicious agents within multi-agent systems. It analyzes communication patterns and response characteristics to detect dark personality traits, then applies topology-aware isolation to neutralize threats while preserving system functionality. The lightweight design enables real-time monitoring without significant computational overhead, making it practical for clinical deployment.

## Foundational Learning
- Multi-agent architecture vulnerabilities: Understanding how different coordination patterns affect system resilience to insider threats
  - Why needed: Different architectures have varying susceptibility to coordinated attacks
  - Quick check: Compare LCS drops across architecture types under identical threat conditions

- Personality-scale detection in LLMs: Methods for inferring psychological traits from model responses
  - Why needed: Enables identification of malicious agents based on behavioral patterns
  - Quick check: Validate detection accuracy against known personality trait benchmarks

- Medical domain adversarial prompts: Specialized threat categories relevant to healthcare applications
  - Why needed: Medical systems face unique safety and ethical risks requiring domain-specific protections
  - Quick check: Ensure adversarial prompts cover realistic clinical scenarios and potential harm vectors

## Architecture Onboarding

**Component map:**
User Input -> Multi-Agent System -> PCDC Monitor -> Output Generation

**Critical path:**
User request flows through the multi-agent architecture, while PCDC continuously monitors agent communications for personality anomalies and intervenes when threats are detected.

**Design tradeoffs:**
- Lightweight personality detection vs. comprehensive behavioral analysis
- Real-time monitoring overhead vs. safety assurance
- Architecture-specific isolation strategies vs. universal protection mechanisms

**Failure signatures:**
- Rapid LCS degradation indicating coordinated malicious activity
- Anomalous communication patterns between normally independent agents
- Deviation from established personality baselines in agent responses

**3 first experiments:**
1. Baseline LCS measurement across all four architectures without adversarial agents
2. Attack scenario testing with single malicious agent in each architecture type
3. PCDC defense validation showing safety metric restoration post-attack

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset generalizability to real-world clinical settings remains uncertain
- PCDC reliability in high-stakes medical contexts not yet proven
- Synthetic multi-agent architectures may not reflect operational system behaviors
- Dark triad framework may not capture all medical-specific insider threat patterns

## Confidence

| Claim | Confidence |
|-------|------------|
| Architectural vulnerability findings | High |
| PCDC defense efficacy | Medium |
| Dataset threat coverage | Low-Medium |

## Next Checks
1. Test PCDC against adaptive adversaries who modify communication patterns to evade personality-scale detection
2. Evaluate benchmark with actual clinical multi-agent deployments in hospital information systems to assess ecological validity
3. Expand adversarial dataset to include domain-specific insider threats from real medical error reports and cybersecurity incident databases