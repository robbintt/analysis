---
ver: rpa2
title: 'Towards geological inference with process-based and deep generative modeling,
  part 2: inversion of fluvial deposits and latent-space disentanglement'
arxiv_id: '2510.17478'
source_url: https://arxiv.org/abs/2510.17478
tags:
- wells
- data
- sample
- test
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the use of generative adversarial networks
  (GANs) for geological inference, specifically focusing on inverting fluvial deposits
  to match well and seismic data. Four inversion approaches (latent optimization,
  inference network, variational inference, and MCMC) were tested on three synthetic
  fluvial deposits with varying numbers of wells (4, 8, and 20).
---

# Towards geological inference with process-based and deep generative modeling, part 2: inversion of fluvial deposits and latent-space disentanglement

## Quick Facts
- arXiv ID: 2510.17478
- Source URL: https://arxiv.org/abs/2510.17478
- Authors: Guillaume Rongier; Luk Peeters
- Reference count: 40
- Primary result: GAN inversion for fluvial deposits fails due to entangled latent spaces, but pivotal tuning can restructure locally to achieve acceptable matches

## Executive Summary
This study investigates the use of generative adversarial networks (GANs) for geological inference, specifically focusing on inverting fluvial deposits to match well and seismic data. Four inversion approaches (latent optimization, inference network, variational inference, and MCMC) were tested on three synthetic fluvial deposits with varying numbers of wells (4, 8, and 20). Results showed that these approaches struggled to match well data, especially as the number of wells increased or the test sample diverged from the training data. The key bottleneck was identified as the GAN's entangled latent representation, where samples with similar sedimentological features were not necessarily close in the latent space. While label conditioning and latent overparameterization partially disentangled the latent space, they were insufficient for successful inversion. Fine-tuning the GAN locally to restructure the latent space (pivotal tuning) significantly improved results, reducing mismatches to acceptable levels for all test cases, with and without seismic data. However, this approach depended on an initial, partially successful inversion step. The study concludes that GANs can handle the tasks required for their integration into geomodeling workflows, but further research is needed to assess their robustness and optimize their use in geological interpretation.

## Method Summary
The study trained a 3D DCGAN on 20,000 synthetic fluvial deposit realizations from the CHILD model, then tested four inversion methods (latent optimization, inference network, variational inference, and MCMC) to match well and seismic data from three test samples. The key innovation was applying pivotal tuning—fine-tuning generator weights using discriminator perceptual loss—to restructure the entangled latent space locally. This was compared against other restructuring approaches including bigger architectures, latent overparameterization, and conditioning. All methods were evaluated using mean absolute error against well data and full ground truth, with a 1% error threshold for inversion quality.

## Key Results
- All four standard inversion approaches failed to achieve the 1% error threshold, with performance degrading as well count increased
- The fundamental bottleneck was identified as the entangled latent representation, not the inversion algorithm itself
- Pivotal tuning achieved acceptable error levels (<1%) for all test cases when applied after partial initial inversion success
- Seismic data dramatically improved generalization error by constraining global channel geometry
- Conditioning and latent overparameterization provided modest improvements but were insufficient alone

## Why This Works (Mechanism)

### Mechanism 1: Latent Space Entanglement as Inversion Bottleneck
- Claim: GAN inversion fails primarily because the learned latent representation is entangled—samples with similar geological features are not spatially proximate in latent space.
- Mechanism: Gradient-based optimization traverses a rugged error landscape with many local minima because semantically similar outputs map to disconnected latent regions. This makes finding data-matching samples inefficient or impossible.
- Core assumption: The bottleneck lies in latent structure rather than the inversion algorithm itself.
- Evidence anchors:
  - [abstract] "The key bottleneck lies in the GAN's latent representation: it is entangled, so samples with similar sedimentological features are not necessarily close in the latent space."
  - [section 3.1] "The error landscape becomes more rugged as the number of wells increases, with what appears like more local minima."
  - [corpus] Diffusion models for subsurface inversion (arXiv:2507.15809) show improved inversion, suggesting generative architecture choice affects latent structure.
- Break condition: If the target sample lies entirely outside the training distribution, no latent restructuring will succeed.

### Mechanism 2: Pivotal Tuning for Local Latent Restructuring
- Claim: Fine-tuning generator weights after partial inversion restructures the latent space locally, reducing data mismatch to acceptable levels.
- Mechanism: Unlike latent optimization (which keeps weights fixed), pivotal tuning updates generator parameters using perceptual loss from the discriminator. This creates new latent regions that better align with data constraints.
- Core assumption: Initial latent optimization must achieve partial success—pivotal tuning cannot recover from completely failed inversion.
- Evidence anchors:
  - [abstract] "Fine-tuning the GAN to restructure the latent space locally reduces mismatches to acceptable levels for all test cases."
  - [section 3.2] "Pivotal tuning is the only technique that passed the 1% threshold on the vast majority of its 300 samples for all cases."
  - [section 3.4] "Pivotal tuning offers more a local correction than a complete reorganization of the latent space."
- Break condition: Using random latent vectors (vs. pre-inverted) yields poor results—confirmed by Roich et al. (2022).

### Mechanism 3: Multi-Modal Data Integration via Seismic Constraints
- Claim: Combining seismic data (broad spatial coverage, low resolution) with well data (local, high resolution) dramatically improves generalization.
- Mechanism: Well data constrain local sediment fraction; seismic data constrain global channel belt geometry through the forward seismic model, reducing uncertainty between wells.
- Core assumption: The forward model relating geology to seismic amplitudes is reasonably characterized.
- Evidence anchors:
  - [section 3.3] "Adding the seismic data has a huge impact on the generalization error... It systematically decreases after latent optimization."
  - [section 3.3] "The seismic data plays a key role in this, which is in line with its large spatial coverage."
  - [corpus] GANs with spatially adaptive denormalization (arXiv:2512.02863) similarly show improved inversion with seismic integration.
- Break condition: Poor seismic quality or misspecified forward model limits benefit.

## Foundational Learning

- **Concept: Latent Space and Entanglement**
  - Why needed here: Understanding that GANs map random vectors to outputs, and entangled spaces scatter similar features across disconnected regions.
  - Quick check question: Why does a disentangled latent space make gradient-based inversion easier?

- **Concept: Inversion vs. Conditioning**
  - Why needed here: Inversion separates data matching from training (flexible but harder); conditioning integrates data during training (easier but rigid).
  - Quick check question: What is the practical trade-off between these approaches for geological workflows?

- **Concept: Perceptual Loss with Discriminators**
  - Why needed here: Pivotal tuning uses discriminator features rather than pixel-wise error to preserve geological plausibility during fine-tuning.
  - Quick check question: Why might perceptual loss outperform MSE for geological realism?

## Architecture Onboarding

- **Component map:**
  Generator: 3D DCGAN with residual blocks, spectral normalization, Leaky ReLU, latent size 128. Discriminator: Mirror architecture with R1 regularization. Inversion: Four methods (latent optimization, inference network, variational flows, MCMC). Restructuring: Bigger GAN, latent overparameterization, conditioning, pivotal tuning.

- **Critical path:**
  1. Train unconditional GAN on 20K process-based realizations.
  2. Extract well/seismic data from test samples.
  3. Run latent optimization (500–1000 iterations).
  4. If partial success, apply pivotal tuning (250–1000 iterations).
  5. Evaluate inversion error (wells) and generalization error (full ground truth).

- **Design tradeoffs:**
  Larger latent (512) may help inversion but hurts pivotal tuning and memory. Bigger architecture (closer to BigGAN) improves consistency modestly. Conditioning requires retraining; pivotal tuning works post-hoc but depends on initial inversion.

- **Failure signatures:**
  Inference network/variational inference collapse with 8+ wells (identical samples). Latent optimization never passes 1% threshold. Pivotal tuning produces checkerboard artifacts if initial samples are too far from data. Off-center channel belts (rare in training) show much higher errors.

- **First 3 experiments:**
  1. Reproduce latent optimization failure on test sample 1 with 4 wells to validate entanglement hypothesis.
  2. Vary initial inversion quality before pivotal tuning to find the "partial success" threshold.
  3. Compare generalization error with vs. without seismic data to quantify multi-modal integration value.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What constitutes an optimal latent space structure for geological subsurface modeling—local disentanglement versus global descriptive feature control?
- Basis in paper: [explicit] "But what would be a proper structure for subsurface modeling remains to be seen. Is being disentangled good enough, even if it means that each latent parameter only updates samples locally? Would controlling more global, descriptive features like the width of the channel belt or the overall fraction of coarse sediments help?"
- Why unresolved: Label conditioning showed inconsistent behavior across latent space locations, and conditioning quality varied between parameters without systematic analysis of optimal structure for inversion.
- What evidence would resolve it: Comparative study of different latent architectures with quantitative metrics linking latent organization to inversion success rates and uncertainty quantification quality.

### Open Question 2
- Question: Can StyleGAN's intermediate W space architecture improve inversion performance for 3D geological models compared to BigGAN-style architectures?
- Basis in paper: [explicit] "Expending StyleGAN or one of its variants... to 3D and perform an ablation study to explore its impact on inversion would be valuable."
- Why unresolved: StyleGAN's less-entangled W space has shown promise for natural images, but 3D adaptation for continuous geological properties remains untested against current approaches.
- What evidence would resolve it: Direct comparison of inversion errors, convergence rates, and sample diversity between StyleGAN-3D and BigGAN architectures on identical test cases.

### Open Question 3
- Question: Can inversion approaches, particularly pivotal tuning, maintain acceptable error thresholds when applied to real geological data with uncertain data-generating processes?
- Basis in paper: [inferred] "Like most studies applying GANs to subsurface modeling, our case studies are entirely synthetic... testing GANs on real data should be the next target... It is then unclear whether a technique like pivotal tuning can still reach the 1% threshold in those conditions."
- Why unresolved: Synthetic experiments used perfectly known data-generating processes; real seismic data introduces processing artifacts, velocity model uncertainties, and petrophysical interpretation biases.
- What evidence would resolve it: Application of the same inversion workflow to field datasets with independent validation through outcrop analogs or additional borehole control.

### Open Question 4
- Question: What is the optimal strategy for designing training datasets from process-based models to maximize latent space coverage for inversion tasks?
- Basis in paper: [explicit] "We then need a clearer perspective on to properly and efficiently design training datasets from process-based models for such tasks."
- Why unresolved: Test sample 3 was poorly represented in training data, causing inversion failure; current training data generation followed no principled sampling strategy targeting inversion needs.
- What evidence would resolve it: Systematic experiments varying training set composition (parameter ranges, sample density in parameter space) with quantification of resulting latent space coverage and inversion success rates for edge-case geological scenarios.

## Limitations
- All experiments use synthetic data with known ground truth; real-world validation remains untested
- Pivotal tuning requires initial partial inversion success, creating a chicken-and-egg dependency
- The study focuses on DCGAN architecture; results may not generalize to other generative models
- Training data generation followed no principled sampling strategy for inversion needs

## Confidence
- **High Confidence:** Pivotal tuning significantly improves inversion performance when initial latent optimization achieves partial success. This is consistently demonstrated across all test cases.
- **Medium Confidence:** The claim that latent entanglement is the fundamental bottleneck. While supported by error landscape analysis, alternative explanations (e.g., insufficient optimization iterations, suboptimal hyperparameters) cannot be fully ruled out.
- **Medium Confidence:** Multi-modal data integration (wells + seismic) dramatically improves generalization. The effect is clear in synthetic experiments, but the magnitude may differ with real seismic data quality variations.

## Next Checks
1. **Architecture Transferability Test:** Apply the same inversion pipeline to a diffusion model trained on the same fluvial deposits. Compare inversion performance and latent structure characteristics to test whether entanglement is architecture-specific.
2. **Distribution Boundary Characterization:** Systematically vary test samples' distance from the training distribution (e.g., channel width, sinuosity) and measure the point at which pivotal tuning fails to achieve acceptable inversion error.
3. **Real Data Pilot Study:** Apply the methodology to a small real-world dataset with both well logs and seismic data. Quantify the gap between synthetic and real performance, particularly focusing on forward model uncertainty and data quality impacts.