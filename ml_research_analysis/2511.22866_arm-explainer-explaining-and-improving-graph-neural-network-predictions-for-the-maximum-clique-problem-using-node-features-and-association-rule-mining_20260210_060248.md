---
ver: rpa2
title: ARM-Explainer -- Explaining and improving graph neural network predictions
  for the maximum clique problem using node features and association rule mining
arxiv_id: '2511.22866'
source_url: https://arxiv.org/abs/2511.22866
tags:
- graph
- neural
- node
- clique
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ARM-Explainer, a post-hoc, model-level explainer
  based on association rule mining to explain and improve graph neural network (GNN)
  predictions for the maximum clique problem (MCP). ARM-Explainer discovers association
  rules from node features and GNN predictions, identifying the most important features
  and their value ranges that influence predictions.
---

# ARM-Explainer -- Explaining and improving graph neural network predictions for the maximum clique problem using node features and association rule mining

## Quick Facts
- arXiv ID: 2511.22866
- Source URL: https://arxiv.org/abs/2511.22866
- Reference count: 40
- Key outcome: ARM-Explainer achieves high median lift (2.42) and confidence (0.49) for explaining GNN predictions; 22% improvement in clique size on large graphs when adding informative node features

## Executive Summary
This paper introduces ARM-Explainer, a post-hoc explainer that uses association rule mining to discover interpretable patterns between node features and GNN predictions for the maximum clique problem. Applied to the HGS GNN on TWITTER and BHOSLIB-DIMACS datasets, ARM-Explainer achieves strong rule quality metrics. The method also demonstrates that adding uncorrelated, informative node features (like neighbor degree statistics and centrality measures) significantly improves GNN performance on large dense graphs, increasing the median largest-found clique size by 22%.

## Method Summary
ARM-Explainer works by training a Hybrid Geometric Scattering (HGS) GNN to predict node probabilities of clique membership, then applying FP-Growth association rule mining to binned node features and predictions. Node features are binned into 5 percentile ranges per graph instance, and only top/bottom 20% prediction nodes are retained. The method uses greedy non-overlapping rule selection to identify the most explanatory association rules. The approach is demonstrated on TWITTER and BHOSLIB-DIMACS datasets, comparing 3-feature and 10-feature HGS models.

## Key Results
- ARM-Explainer discovers association rules with median lift 2.42 and confidence 0.49
- Adding informative node features increases median largest-found clique size by 22% (from 29.5 to 36) on BHOSLIB-DIMACS large graphs
- 28 out of 34 test instances showed positive improvement when using 10 features vs 3 features
- Feature importance shifts from log degree (small graphs) to log std neighbor degree (large dense graphs)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Association rule mining can extract human-interpretable patterns explaining why GNNs assign high/low clique-membership probabilities to specific nodes.
- **Mechanism:** ARM-Explainer applies FP-Growth to binned node features and GNN output probabilities across all graph instances. Rules of the form `{feature range} → {prediction range}` are ranked by support, confidence, and lift metrics, then filtered via greedy non-overlapping selection.
- **Core assumption:** The GNN's prediction logic can be approximated by co-occurrence patterns between discretized input features and output probability bins, without needing access to internal model parameters.
- **Evidence anchors:**
  - [abstract] "The eight most explanatory association rules discovered by ARM-Explainer achieve high median lift and confidence values of 2.42 and 0.49."
  - [section 4.3] "FP-Growth's two-scan construction, absence of candidate generation, and focused conditional mining make it well-suited for large graph datasets."
  - [corpus] Related work on GCO-HPIF (arxiv 2512.20915) also uses association rule mining for explaining combinatorial optimization hardness, suggesting the approach generalizes—but corpus evidence on validation across broader COP domains is limited.
- **Break condition:** If node features are highly correlated (e.g., log degree and log triangles in TWITTER with r=0.98), discovered rules may be redundant and not reflect genuinely distinct learned patterns.

### Mechanism 2
- **Claim:** Adding uncorrelated, informative node features improves GNN performance on large, dense graphs for the maximum clique problem.
- **Mechanism:** Centrality-based features (betweenness, eigenvector, closeness) and neighbor-degree statistics capture structural signals that basic features (degree, clustering coefficient) miss. The HGS GNN learns to weight these via attention mechanisms across diffusion layers.
- **Core assumption:** Nodes in large cliques have distinctive values on certain structural features that differ from non-clique nodes, and the GNN can learn these distinctions when provided relevant features.
- **Evidence anchors:**
  - [abstract] "Augmenting the GNN with informative node features substantially improves its performance on the MCP, increasing the median largest-found clique size by 22% (from 29.5 to 36) on large graphs."
  - [section 6, Table 3] Instance-wise improvements: p_hat1000-3 improved 123%, p_hat1500-2 improved 130%; 28/34 test instances showed positive change.
  - [section 6] "Logarithm of node degree and logarithm of standard deviation of neighboring nodes are uncorrelated, with correlation coefficient of 0.04"—enabling new learning.
- **Break condition:** If added features are highly correlated with existing ones, performance gains will be marginal (observed in TWITTER: only 3.7% average improvement where features were correlated).

### Mechanism 3
- **Claim:** Percentile-based binning at the instance level enables cross-graph pattern extraction while controlling for graph-specific feature distributions.
- **Mechanism:** For each graph, node features and predictions are binned into 0-20, 20-40, 40-60, 60-80, 80-100 percentile ranges. Only top/bottom 20% of predictions are retained, focusing analysis on nodes the GNN is most confident about.
- **Core assumption:** The relative ranking of features within a graph—not absolute values—drives GNN predictions; extreme predictions reveal clearer explanatory patterns.
- **Evidence anchors:**
  - [section 4.4] "Binning by 20 percentile increments yielded results with good support and confidence measures while avoiding overfitting."
  - [section 4.4] Only 40% of nodes (top and bottom 20%) selected to identify features important for confident predictions.
  - [corpus] No direct corpus validation of this specific binning strategy; this is a design choice requiring empirical tuning.
- **Break condition:** If graph topologies vary extremely (constant features across instances like eccentricity=2 in BHOSLIB), binning may collapse to trivial patterns for those features.

## Foundational Learning

- **Association Rule Mining (Support, Confidence, Lift)**
  - Why needed here: ARM-Explainer outputs rules quantified by these metrics; interpreting results requires understanding what lift=2.42 means (2.42× more likely than random).
  - Quick check question: If support=0.085 and confidence=0.499 for a rule, what fraction of all transactions contain the antecedent?

- **Message-Passing GNNs**
  - Why needed here: HGS uses multi-layer message passing with low-pass (neighborhood averaging) and band-pass (wavelet) filters; understanding how information propagates clarifies what features the GNN can access.
  - Quick check question: After 2 message-passing layers, what is the maximum hop distance from which a node can receive information?

- **Maximum Clique Problem (NP-hardness, constraints)**
  - Why needed here: The custom loss function (Equation 8) encodes clique constraints via adjacency matrix penalties; understanding MCP clarifies why this loss structure makes sense.
  - Quick check question: Why does the loss function penalize edges in the complement graph?

## Architecture Onboarding

- **Component map:**
  Input Graph → Node Feature Extraction (10 features) → HGS GNN (Embedding MLP → K Diffusion Layers with attention → Output MLP → Min-max scaling → Node probabilities) → Rule-based Decoder (greedy clique construction) → ARM-Explainer (Percentile binning → FP-Growth → Greedy rule selection)

- **Critical path:**
  1. Feature computation must complete before GNN training (some features like betweenness centrality are O(n·(n+m))—bottleneck for large graphs).
  2. GNN training uses unsupervised loss; no ground-truth labels required.
  3. ARM-Explainer runs post-hoc on trained model outputs; does not affect training.

- **Design tradeoffs:**
  - **3 features vs. 10 features:** Original HGS used 3 (fast but lower accuracy on large dense graphs). 10 features improve accuracy but increase preprocessing time significantly.
  - **Minimum support/confidence thresholds:** 0.05 support and 0.1 confidence chosen to avoid trivial rules and combinatorial explosion; lower values increase rule count exponentially.
  - **Instance-level vs. global binning:** Instance-level handles graph heterogeneity but may obscure absolute feature importance.

- **Failure signatures:**
  - Rules with low lift (<1.5) indicate weak explanatory power—likely trivial correlations.
  - No improvement when adding features → check feature correlation matrix; new features may be redundant.
  - Constant features across dataset (e.g., eccentricity=2) → exclude from analysis; they provide no discriminative signal.

- **First 3 experiments:**
  1. Reproduce TWITTER results with 3 features; verify median clique size ~13 and identify top rule (should be high degree → high probability).
  2. Run on BHOSLIB-DIMACS with 2 vs. 9 features; confirm ~22% median improvement and observe antecedent shift from log degree to log std neighbor degree.
  3. Vary minimum support threshold (0.03, 0.05, 0.10) and measure rule count vs. lift distribution to validate robustness of rule selection.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can ARM-Explainer generalize effectively to other graph-based COPs (e.g., MIS, MaxCut, TSP) and different GNN architectures beyond HGS?
  - **Basis in paper:** [explicit] "ARM-Explainer can be applied to a wide variety of learning algorithms and graph-based COPs to investigate its performance in different problem-algorithm combinations."
  - **Why unresolved:** ARM-Explainer was only demonstrated on HGS for the maximum clique problem; no experiments on other COPs or GNN architectures were conducted.
  - **What evidence would resolve it:** Experiments applying ARM-Explainer to other COPs (TSP, MaxCut, MIS) with various GNN architectures, reporting rule quality metrics (lift, confidence, support).

- **Open Question 2:** Do alternative ARM algorithms (e.g., newer FP-Growth variants, Apriori, ECLAT) yield higher-quality or more concise association rules than the FP-Growth implementation used?
  - **Basis in paper:** [explicit] "There are newer versions of FP-Growth proposed in the literature, as well as other ARM approaches... that can be applied to investigate whether they yield better association rules than FP-Growth."
  - **Why unresolved:** Only one ARM algorithm was tested; no comparative analysis of ARM methods was performed.
  - **What evidence would resolve it:** Systematic comparison of multiple ARM algorithms on the same GNN prediction datasets, evaluating rule quality metrics and computational efficiency.

- **Open Question 3:** How can self-interpretable GNN architectures be designed for COP contexts where generating a subgraph (e.g., a clique) solves the problem rather than explains it?
  - **Basis in paper:** [explicit] "Self-interpretable approaches can be developed. However, it is not yet clear how such an architecture would look in a COP context."
  - **Why unresolved:** Existing self-interpretable GNNs for classification tasks do not directly transfer to COPs; the fundamental tension between solving and explaining in COPs remains unaddressed.
  - **What evidence would resolve it:** Novel architecture designs that simultaneously optimize for solution quality and explanation fidelity, with empirical validation on benchmark COPs.

- **Open Question 4:** Can feature importance methods (e.g., SHAP values) systematically identify the most informative node features for different graph datasets, potentially improving GNN performance beyond the 10 features tested?
  - **Basis in paper:** [explicit] "There is scope to identify the most informative node features for different graph datasets through approaches such as SHAP values."
  - **Why unresolved:** Node feature selection was based on domain intuition; no automated or data-driven feature importance analysis was conducted.
  - **What evidence would resolve it:** SHAP-based feature importance analysis across multiple graph datasets, followed by experiments comparing GNN performance with SHAP-selected versus intuitively-selected features.

## Limitations

- The specific HGS GNN architecture parameters (embedding dimension, number of diffusion layers, attention mechanism details) are not fully specified, potentially affecting reproducibility of exact performance metrics
- The selection criterion for "best model" on validation (how ties are broken, exact threshold used) is unspecified
- While rule quality metrics are strong, the practical interpretability of discovered rules across diverse graph types remains to be validated

## Confidence

- **High confidence:** The core mechanism of using association rule mining for post-hoc explanation works as described; the general approach of adding informative node features to improve GNN performance is well-supported by the 22% median improvement on BHOSLIB-DIMACS
- **Medium confidence:** The specific binning strategy (instance-level percentile binning, 20% selection) is reasonable but not extensively validated against alternatives; the observed performance improvements are substantial but depend on feature correlation patterns
- **Low confidence:** The absolute values of lift/confidence may vary significantly with different binning thresholds or minimum support settings; the method's generalizability to other combinatorial optimization problems beyond MCP has not been demonstrated

## Next Checks

1. Verify the HGS GNN architecture details (embedding dimension d_h, diffusion layers K, attention mechanism) and reproduce the exact 3-feature baseline results on TWITTER before adding features
2. Test alternative binning strategies (global vs. instance-level, different percentile cutoffs) to assess robustness of discovered rules
3. Apply ARM-Explainer to a different combinatorial optimization problem (e.g., maximum independent set or graph coloring) to validate generalizability of the approach