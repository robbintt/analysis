---
ver: rpa2
title: Feature Impact Analysis on Top Long-Jump Performances with Quantile Random
  Forest and Explainable AI Techniques
arxiv_id: '2508.09810'
source_url: https://arxiv.org/abs/2508.09810
tags:
- features
- feature
- jump
- athletes
- step
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of analyzing biomechanical features
  in elite long jump performance by proposing a machine learning framework combining
  quantile random forests with explainable AI techniques. Using data from World Championship
  finals, the authors impute missing values, select key features via Lasso-regularized
  quantile regression, and train quantile random forests to predict effective jump
  distance with a focus on top 10% performances.
---

# Feature Impact Analysis on Top Long-Jump Performances with Quantile Random Forest and Explainable AI Techniques

## Quick Facts
- **arXiv ID:** 2508.09810
- **Source URL:** https://arxiv.org/abs/2508.09810
- **Reference count:** 40
- **Key outcome:** Machine learning framework combining quantile random forests with explainable AI identifies performance-critical biomechanical features for elite long jumpers, with gender-specific differences in key factors

## Executive Summary
This study addresses the challenge of analyzing biomechanical features in elite long jump performance by proposing a machine learning framework combining quantile random forests with explainable AI techniques. Using data from World Championship finals, the authors impute missing values, select key features via Lasso-regularized quantile regression, and train quantile random forests to predict effective jump distance with a focus on top 10% performances. SHAP analysis and ICE plots reveal that for male athletes, take-off knee angle (>169°) is critical, while for female athletes, landing technique and approach adjustments are most influential. The method achieves low pinball loss (0.0287 for men, 0.0333 for women), demonstrating its effectiveness in identifying performance-critical features and interactions, with implications for targeted athletic training.

## Method Summary
The authors developed a machine learning pipeline that first addresses missing biomechanical data through multiple imputation by chained equations (MICE), then performs feature selection using Lasso-regularized quantile regression to identify the most relevant predictors of jump distance. They trained quantile random forests to predict the conditional quantiles of effective jump distance, with particular focus on the top 10% performances. The model's predictions were evaluated using pinball loss, and feature importance was assessed through SHAP (SHapley Additive exPlanations) values and interaction effects were visualized using Individual Conditional Expectation (ICE) plots. The analysis was stratified by gender to account for physiological differences.

## Key Results
- Quantile random forest achieves pinball loss of 0.0287 for male athletes and 0.0333 for female athletes
- For male athletes, take-off knee angle (>169°) emerges as the most critical feature for top performances
- For female athletes, landing technique and approach adjustments show strongest influence on top 10% performances
- SHAP analysis reveals non-linear feature interactions that traditional statistical methods might miss

## Why This Works (Mechanism)
The approach works by combining robust statistical imputation with advanced machine learning that can capture non-linear relationships and interactions between biomechanical features. Quantile regression focuses on the conditional distribution tails, making it particularly suited for identifying what distinguishes elite performances from average ones. The explainable AI techniques (SHAP and ICE) provide interpretability to the black-box model, allowing coaches and biomechanists to understand which specific features and their interactions drive performance differences.

## Foundational Learning
- **Quantile regression**: Estimates conditional quantiles of the response variable; needed because performance analysis requires understanding what drives extreme (top) performances rather than just average outcomes; quick check: verify model can accurately predict different quantiles (not just median)
- **Quantile random forests**: Ensemble method combining random forests with quantile regression; needed to handle non-linear relationships and interactions between biomechanical features; quick check: compare pinball loss against baseline linear quantile regression
- **SHAP values**: Game-theoretic approach for explaining individual predictions; needed to attribute feature importance in complex models; quick check: ensure SHAP values sum to model output difference from baseline
- **Multiple imputation by chained equations (MICE)**: Statistical technique for handling missing data; needed because biomechanical datasets often have incomplete measurements; quick check: assess imputation quality through posterior predictive checks
- **Pinball loss**: Evaluation metric for quantile predictions; needed because standard MSE doesn't capture quantile-specific accuracy; quick check: confirm lower values indicate better quantile estimation
- **Individual Conditional Expectation (ICE) plots**: Visualization tool showing how predictions change as feature values vary; needed to reveal feature interactions and non-linear effects; quick check: verify ICE plots show reasonable behavior across feature ranges

## Architecture Onboarding
**Component Map:** Data preprocessing (MICE) -> Feature selection (Lasso quantile regression) -> Model training (Quantile random forest) -> Evaluation (Pinball loss) -> Interpretation (SHAP + ICE)

**Critical Path:** MICE imputation → Lasso feature selection → Quantile RF training → SHAP interpretation

**Design Tradeoffs:** The authors prioritized interpretability through explainable AI techniques over potentially higher accuracy from more complex black-box models. They chose quantile regression over standard regression to focus on top performers rather than average performance, accepting the computational cost of quantile-specific training.

**Failure Signatures:** Poor imputation quality would manifest as unstable feature importance rankings across different imputation runs. Overfitting might appear as excellent training pinball loss but poor validation performance. SHAP values that don't sum to prediction differences indicate implementation errors in the explanation method.

**First Experiments:**
1. Run ablation study removing SHAP interpretation to assess impact on practical utility
2. Test model sensitivity by varying the quantile threshold (top 5% vs top 10%)
3. Compare performance when using only complete cases versus imputed data

## Open Questions the Paper Calls Out
None

## Limitations
- Small sample size (n=72 athletes) and focus on World Championship finals may limit generalizability to broader populations
- Missing data imputation introduces uncertainty that wasn't fully quantified
- Findings based on elite athletes may not translate to developmental or recreational levels

## Confidence
- Feature importance rankings: Medium confidence - results are sensitive to feature selection methods and imputation choices
- Performance prediction accuracy: High confidence - pinball loss metrics are robust and well-validated
- Gender-specific findings: Medium confidence - based on small subgroup sizes and may reflect sample-specific patterns

## Next Checks
1. Replicate analysis with larger datasets spanning multiple competition levels to test generalizability
2. Conduct ablation studies testing model sensitivity to different imputation methods and feature selection approaches
3. Validate feature importance findings through controlled biomechanical experiments measuring actual performance changes