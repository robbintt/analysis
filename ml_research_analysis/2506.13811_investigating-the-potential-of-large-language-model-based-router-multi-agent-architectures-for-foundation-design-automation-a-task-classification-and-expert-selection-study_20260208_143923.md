---
ver: rpa2
title: 'Investigating the Potential of Large Language Model-Based Router Multi-Agent
  Architectures for Foundation Design Automation: A Task Classification and Expert
  Selection Study'
arxiv_id: '2506.13811'
source_url: https://arxiv.org/abs/2506.13811
tags:
- engineering
- design
- performance
- foundation
- geotechnical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that router-based multi-agent AI systems
  can significantly enhance foundation design automation in geotechnical engineering.
  By employing intelligent task classification and expert selection, the proposed
  system achieved performance scores of 95.00% for shallow foundation design and 90.63%
  for pile design, outperforming standalone models and conventional agentic workflows
  by 8.75-43.75 percentage points.
---

# Investigating the Potential of Large Language Model-Based Router Multi-Agent Architectures for Foundation Design Automation: A Task Classification and Expert Selection Study

## Quick Facts
- arXiv ID: 2506.13811
- Source URL: https://arxiv.org/abs/2506.13811
- Reference count: 0
- This study demonstrates router-based multi-agent AI systems can significantly enhance foundation design automation in geotechnical engineering.

## Executive Summary
This research explores the application of large language model-based router multi-agent architectures for automating foundation design in geotechnical engineering. The system employs intelligent task classification and expert selection to route queries to specialized agents for shallow and pile foundation design. Through a dual-tier classification framework and structured prompt engineering, the proposed architecture achieved performance scores of 95.00% for shallow foundation design and 90.63% for pile design, significantly outperforming standalone models and conventional agentic workflows. The study marks a breakthrough in AI capabilities for safety-critical engineering applications by demonstrating LLMs can perform complex engineering calculations autonomously without external computational tools.

## Method Summary
The method employs a LangChain framework with n8n workflow orchestration to create a multi-agent system consisting of a Classifier, Designer (shallow/pile specialists), Reviewer, and Senior Engineer agents. The system uses Grok 3 or Gemini 2.5 Pro as the backbone LLM, with SerpAPI integration for code lookups. Task classification is performed through a dual-tier framework using LLM embeddings and softmax (Equation 4) to route queries between shallow and pile foundation streams. Expert agents are equipped with domain-specific system prompts containing formulas and one-shot examples. A Reviewer agent applies weighted scoring (Equation 5) to evaluate outputs against a 4-criteria rubric (accuracy, chain-of-thought reasoning, complex scenario handling, structured output consistency) before final formatting by the Senior Engineer.

## Key Results
- Achieved 95.00% performance score for shallow foundation design and 90.63% for pile design
- Outperformed standalone models and conventional agentic workflows by 8.75-43.75 percentage points
- Demonstrated LLMs can perform complex engineering calculations autonomously without external computational tools
- Established intelligent task classification and expert routing as critical factors for AI performance in geotechnical engineering

## Why This Works (Mechanism)

### Mechanism 1
The system achieves higher accuracy than standalone models primarily through task decomposition and expert routing, which isolates the reasoning context for the LLM. A dual-tier classification framework first categorizes the problem and routes it to a specialized agent. This specialized agent operates with a system prompt containing domain-specific formulas and one-shot examples. By constraining the problem space, the LLM is less likely to hallucinate irrelevant formulas compared to a generalist model. The routing classifier must accurately identify the problem type; if misclassified, the specialized agent will likely fail.

### Mechanism 2
Performance gains are contingent on structured prompt engineering that embeds Chain-of-Thought (CoT) reasoning directly into the agent's instructions. The prompts enforce step-by-step derivation, forcing the LLM to generate intermediate reasoning steps, which has been shown to improve mathematical logic reliability. The LLM must have sufficient inherent mathematical capability to follow the provided derivation steps without external calculation tools. Complex scenarios requiring multi-step logic branches not covered in the one-shot examples may lead to logical flaws despite the prompt structure.

### Mechanism 3
The multi-agent critic loop (Reviewer Agent) acts as an error-correction mechanism, filtering outputs that pass initial calculation checks but fail professional standards. A dedicated Technical Reviewer Agent evaluates the output against a weighted scoring function before final release, checking for calculation errors and code compliance. This mimics a human QA process. The Reviewer Agent must be capable of detecting subtle mathematical errors that the Designer Agent produced. If the Reviewer and Designer share the same logical blind spots (model homogeneity), systematic errors may pass unchecked.

## Foundational Learning

- **Concept: Geotechnical Bearing Capacity Theory**
  - Why needed here: To interpret the AI's output. You must know the difference between ultimate and allowable bearing capacity to validate if the AI applied the correct Factor of Safety (FS).
  - Quick check question: Can you identify the variables $N_c, N_q, N_\gamma$ in Terzaghi's equation and explain how soil friction angle ($\phi$) affects them?

- **Concept: System Prompts & One-Shot Learning**
  - Why needed here: The system's Expert Selection is defined entirely by the system prompt. Understanding how to structure these prompts (Context + Instruction + Example) is required to maintain or debug agents.
  - Quick check question: How does providing a single worked example (one-shot) in the prompt change the LLM's output format compared to zero-shot instructions?

- **Concept: Workflow Orchestration (LangChain/n8n)**
  - Why needed here: The architecture relies on passing JSON outputs between agents (Router -> Expert -> Reviewer). Understanding data transformation between nodes is essential.
  - Quick check question: If the Classifier outputs a class label "Pile," how does the Router use that string to select the specific "Pile Expert" agent node?

## Architecture Onboarding

- **Component map:** Input (Natural language query) -> Router/Classifier (LLM-based text classifier) -> Expert Agents (Specialized nodes with distinct System Prompts) -> Reviewer Agent (Technical evaluation) -> Senior Engineer (Final formatting) -> Final Report

- **Critical path:** The Classification Node. If this node misinterprets "raft foundation" as a "shallow footing," the downstream expert agent will apply the wrong analytical method (e.g., using Terzaghi instead of plate load theory), rendering the final output technically invalid regardless of calculation accuracy.

- **Design tradeoffs:**
  - Latency vs. Robustness: Adding the "Senior Engineer" and "Reviewer" agents increases the workflow time (and token cost) significantly compared to a single-agent call.
  - Specificity vs. Generality: System prompts are hard-coded for specific codes (e.g., Vesic). They may fail on obscure or non-standard geotechnical methods not included in the prompt instructions.

- **Failure signatures:**
  - Drift: The agent cites outdated codes if the SerpAPI tool is not triggered or returns poor results.
  - Calculation Collapse: The output contains text reasoning but the final numerical answer is missing or formatted incorrectly (Score 0.0 on "Structured Output").

- **First 3 experiments:**
  1. Ablation Test: Run the same 10 queries through the "Router + Expert" pipeline without the "Reviewer" agent to isolate the performance contribution of the QA layer.
  2. Classification Stress Test: Input ambiguous queries (e.g., "design a foundation for a bridge pier") to measure the Router's accuracy in distinguishing between Pile and Shallow categories.
  3. Model Substitution: Swap the underlying LLM (e.g., switch Grok 3 to DeepSeek R1) in the Expert Agent while keeping prompts constant to measure model dependency.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can uncertainty quantification frameworks be effectively integrated into router-based multi-agent systems to satisfy safety-critical requirements in geotechnical engineering?
- Basis in paper: [explicit] The authors identify "uncertainty quantification frameworks for safety-critical applications" as a critical priority for future research in the Conclusion and Section 5.4.
- Why unresolved: The current study focuses on accuracy and performance scores but lacks probabilistic methods to quantify confidence levels in the AI's autonomous mathematical reasoning.
- What evidence would resolve it: The development and validation of a framework that provides statistical confidence intervals or reliability metrics for design outputs.

### Open Question 2
- Question: How does the router-based architecture perform when expanded to the full spectrum of geotechnical scenarios, such as slope stability and retaining walls, beyond the initial 27 foundation design test cases?
- Basis in paper: [explicit] The paper acknowledges the "relatively constrained scope" of the 27 test cases and suggests future work must cover the "full spectrum of geotechnical... scenarios."
- Why unresolved: The current dataset is limited to shallow and pile foundation designs, leaving other complex scenarios untested.
- What evidence would resolve it: Benchmarking results from a comprehensive dataset including diverse geotechnical challenges like slope stability or ground improvement.

### Open Question 3
- Question: Do hybrid architectures combining the strengths of different foundational models (e.g., Grok 3 and Gemini 2.5 Pro) yield higher accuracy than single-model router configurations?
- Basis in paper: [explicit] Section 5.4 and the Conclusion list "investigating hybrid architectures combining strengths of different AI models" as a specific future direction.
- Why unresolved: The experiments primarily evaluated router systems using a single backbone model (Grok 3 or Gemini) rather than mixing them.
- What evidence would resolve it: A comparative study measuring the performance of a heterogeneous multi-model router against the homogeneous baselines established in this paper.

## Limitations
- Performance claims rely on a closed-set of 27 test cases, limiting generalizability to real-world geotechnical design scenarios
- Does not address safety-critical failure modes such as systematic hallucination when encountering unfamiliar soil conditions
- Absence of peer review and independent validation raises questions about reproducibility in diverse engineering contexts

## Confidence
- **High Confidence:** Task classification accuracy and expert routing mechanisms are well-documented and supported by the 8.75-43.75 percentage point performance gains over conventional agentic workflows
- **Medium Confidence:** The claim of LLM autonomy in complex engineering calculations is plausible but requires validation on broader, more complex scenarios beyond the test set
- **Low Confidence:** The assertion that human oversight is "essential" lacks quantitative evidence of failure rates or error detection capabilities in real-world practice

## Next Checks
1. **Ablation Test on Safety-Critical Scenarios:** Systematically remove the Reviewer agent and run test cases with high safety factors to quantify the risk of unchecked calculation errors
2. **Cross-Model Consistency Test:** Substitute the LLM backbone (e.g., Grok 3 â†’ DeepSeek R1) and rerun all 27 test cases to measure model dependency and robustness
3. **Real-World Stress Test:** Deploy the system on 10+ complex, ambiguous foundation design problems from actual engineering projects to assess performance degradation and classification accuracy in realistic settings