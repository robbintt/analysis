---
ver: rpa2
title: 'GALA: A GlobAl-LocAl Approach for Multi-Source Active Domain Adaptation'
arxiv_id: '2510.22214'
source_url: https://arxiv.org/abs/2510.22214
tags:
- domain
- gala
- target
- source
- adaptation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of multi-source active domain
  adaptation (MS-ADA), where a model trained on multiple source domains needs to be
  adapted to a target domain with minimal labeled data. The key difficulty lies in
  designing selection criteria that handle both inter-class diversity and multi-source
  domain variation.
---

# GALA: A GlobAl-LocAl Approach for Multi-Source Active Domain Adaptation

## Quick Facts
- **arXiv ID:** 2510.22214
- **Source URL:** https://arxiv.org/abs/2510.22214
- **Reference count:** 40
- **Primary result:** Achieves 51.0% accuracy on DomainNet with only 1% of target annotations vs. 32.9% for baseline ResNet-101.

## Executive Summary
This paper tackles multi-source active domain adaptation (MS-ADA), where models trained on multiple source domains must be adapted to a target domain with minimal labeled data. The key challenge is designing selection criteria that handle both inter-class diversity and multi-source domain variation. The proposed GALA strategy addresses this by combining a global k-means clustering step with a cluster-wise local selection criterion, ensuring both diversity and transferability. GALA is plug-and-play and can be seamlessly integrated into existing DA frameworks without adding trainable parameters.

## Method Summary
GALA operates in two steps: a global k-means clustering of gradient embeddings for diversity, followed by cluster-wise local selection based on uncertainty and domain gap. It uses gradient embeddings for the global step to partition target samples into clusters, then selects the most informative samples within each cluster using a metric combining uncertainty and normalized distance to source domain centroids. The method is training-free, adds no parameters, and can be integrated into existing DA frameworks. Experiments on Digit-Five, Office-Home, and DomainNet show consistent improvement over prior methods.

## Key Results
- Achieves 51.0% accuracy on DomainNet with 1% labeled target data
- Outperforms baseline ResNet-101 (32.9%) and prior active learning methods
- Demonstrates consistent improvement across three standard DA benchmarks
- Maintains plug-and-play integration with existing DA frameworks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Partitioning the unlabeled target domain via gradient-based k-means ensures that the selected samples cover diverse regions of the feature space.
- **Mechanism:** The algorithm computes a gradient embedding for each target sample, $g_c(x_j^t)$, which scales with predictive uncertainty (Eq. 1). It then performs k-means clustering on these embeddings, creating $B$ clusters. By selecting a fixed budget of samples from each cluster, the method ensures the final annotated set is not overly concentrated in one area of the feature space.
- **Core assumption:** The gradient embedding, derived from pseudo-labels, is a sufficiently reliable proxy for both uncertainty and feature-space location to create meaningful clusters.
- **Evidence anchors:** [abstract] "Global k-means clustering step for target-domain samples... ensures diversity." [section III-B] "After that, we divide the target samples into B clusters according to their diversity and uncertainty."
- **Break condition:** If the initial model's pseudo-labels are highly inaccurate, the gradient embeddings will be misleading, causing the k-means clustering to group samples incorrectly.

### Mechanism 2
- **Claim:** Within each global cluster, selecting samples with a combined high-uncertainty and large domain-gap metric prioritizes the most informative and hard-to-transfer examples.
- **Mechanism:** For each cluster $C_b^s$, source samples are assigned to $K$ sub-clusters based on their source domain. A distance metric $d_{k,j}$ is computed between each target sample and the source domain centroids. The final selection metric $v(x_j^t)$ is the product of this normalized domain gap and the L2-normalized gradient embedding.
- **Core assumption:** The distance metric $d_{k,j}$ based on normalized mean and variance differences of feature embeddings is a good proxy for transferability or "domain gap."
- **Evidence anchors:** [abstract] "Local step enhances transferability by selecting samples with high uncertainty and large domain gaps." [section III-C] "Therefore we select the target sample with the highest value of v(xj^t) for each cluster."
- **Break condition:** If the feature embeddings from the backbone model are not discriminative enough, the distance metric $d_{k,j}$ will be noisy.

### Mechanism 3
- **Claim:** The GALA strategy is training-free and can be applied as a sample selection pre-processing step, improving the base DA method's efficiency by focusing it on the most valuable labeled data.
- **Mechanism:** GALA operates using the features and gradients from the current model at each active learning round. It outputs a small set of target samples to be annotated and added to the training set. The base DA method then continues its training, now including these target samples in its supervised loss term.
- **Core assumption:** The base DA method is capable of effectively using a small amount of target-domain supervised data to improve its alignment and generalization.
- **Evidence anchors:** [abstract] "GALA is plug-and-play and can be integrated into existing DA frameworks without adding trainable parameters." [section III-D] "We further introduce a supervised loss term on the selected target samples (L st)."
- **Break condition:** If the base DA method's loss functions are overwhelmed by the large amount of source data, the small signal from the actively selected target samples may be ignored.

## Foundational Learning

- **Concept:** Domain Adaptation (DA)
  - **Why needed here:** GALA is a strategy for a specific DA setting (MS-ADA). You must understand that DA aims to transfer models from a source domain to a different target domain.
  - **Quick check question:** Can you explain why a model trained on MNIST might fail on SVHN?

- **Concept:** Active Learning (AL)
  - **Why needed here:** GALA uses AL principles to select which target samples to annotate. You must understand the goal of AL: to maximize model performance with a minimal annotation budget.
  - **Quick check question:** What is the core trade-off an active learning strategy tries to balance (e.g., uncertainty vs. diversity)?

- **Concept:** k-means Clustering
  - **Why needed here:** This is the central algorithm in GALA's "Global Step." You must understand how it partitions data into groups based on feature similarity.
  - **Quick check question:** If you run k-means on a dataset, what property do the samples within a single cluster share?

## Architecture Onboarding

- **Component map:**
  1. Backbone Model (e.g., ResNet-50) -> Feature Embeddings $M$
  2. Classifier Head (final linear layer $W$) -> Logits and Pseudo-labels
  3. Global k-Means Module -> Gradient embeddings $g_c$ and B clusters
  4. Local Selection Module -> Domain gap distances $d_{k,j}$ and selection metric $v(x_j^t)$
  5. Base DA Trainer -> Domain adaptation training with selected target samples

- **Critical path:**
  1. Train initial model on source domains
  2. At each active learning round: compute embeddings, perform Global Clustering -> perform Local Selection -> human annotates selected samples -> add to labeled set
  3. Retrain/update the DA model with the expanded labeled set

- **Design tradeoffs:**
  - The hybrid metric combines uncertainty and domain gap with a simple product, assuming they are of comparable scale and importance
  - The method relies on pseudo-labels for the global step, which could create feedback loops if the initial model is poor
  - The distance metric uses $\mu/\sqrt{\sigma^2 + \epsilon}$ for domain distance, which normalizes by variance but is a heuristic choice

- **Failure signatures:**
  - Cluster Collapse: If the model is highly confident, gradient embeddings become small, making clustering meaningless
  - Poor Transferability: If the domain shift is too extreme, even the "best" selected samples might not help the base DA method align

- **First 3 experiments:**
  1. Baseline vs. GALA: Run a base DA method (e.g., DANN) on an MSDA task with random target sample selection vs. GALA selection. Plot accuracy vs. annotation budget.
  2. Ablation on Selection Metric: Run the full GALA pipeline with modified local selection metric (only uncertainty, only domain gap, vs. combined product).
  3. Ablation on Hyperparameter $\alpha$: Vary the $\alpha$ value as shown in Figure 5 and test on a different dataset to check sensitivity.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can GALA be adapted for Source-Free Domain Adaptation where the local step cannot access source domain statistics?
  - **Basis in paper:** Section III-C calculates the domain gap distance $d_{k,j}$ using source domain centroids, implying continuous access to source data is required.
  - **Why unresolved:** The paper assumes source data availability during the active selection phase, a condition often violated in privacy-preserving real-world scenarios.
  - **What evidence would resolve it:** A modified GALA variant using cached or generated source statistics tested on standard MS-ADA benchmarks without raw source data access.

- **Open Question 2:** How does the noise in pseudo-labels during early training rounds impact the convergence of the global clustering step?
  - **Basis in paper:** Section III-B relies on pseudo-labels to generate gradient embeddings for the global k-means step.
  - **Why unresolved:** In early active learning rounds, the model is poorly calibrated; incorrect pseudo-labels may misguide the diversity selection.
  - **What evidence would resolve it:** Comparative analysis of clustering quality and final accuracy using ground-truth labels versus pseudo-labels for the global step in Round 1.

- **Open Question 3:** Why does the specific combination of gradient embedding (Global) and feature map (Local) outperform other configuration combinations?
  - **Basis in paper:** Section V-B empirically observes that using gradient embedding for the global step and feature map for the local step performs best, but offers no theoretical justification.
  - **Why unresolved:** The distinct properties of these embeddings that make them suitable for diversity versus transferability remain an empirical finding without formal explanation.
  - **What evidence would resolve it:** A theoretical analysis or t-SNE visualization of the embedding spaces to explain the synergy between gradient-based uncertainty and feature-based domain distance.

## Limitations
- The method relies on source domain data being available during the active selection phase, which may not be feasible in privacy-preserving scenarios
- The global step's clustering quality depends heavily on the accuracy of pseudo-labels from the initial model
- The combined metric assumes uncertainty and domain gap are of comparable scale and importance, which may not hold for all datasets

## Confidence
- **Method Implementation:** High - The method is clearly specified with equations and step-by-step procedure
- **Experimental Results:** Medium - Results are reported on standard benchmarks but some hyperparameter details are missing
- **Theoretical Claims:** Low - The paper provides empirical results but limited theoretical justification for why the hybrid approach works

## Next Checks
1. Verify that the gradient embedding computation uses only the pseudo-label gradient and scales correctly with predictive uncertainty
2. Confirm that the domain gap distance uses minimum (not average) distance across source domains
3. Test the sensitivity of the $\alpha$ hyperparameter on a different dataset than those reported in the paper