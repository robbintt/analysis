---
ver: rpa2
title: Towards Contamination Resistant Benchmarks
arxiv_id: '2505.08389'
source_url: https://arxiv.org/abs/2505.08389
tags:
- text
- cipher
- shift
- table
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces the concept of contamination resistance to
  address the challenge of data leakage in LLM evaluation. The authors propose a benchmark
  based on Caesar ciphers that dynamically generates infinite unique instances, ensuring
  models cannot memorize all possible queries.
---

# Towards Contamination Resistant Benchmarks

## Quick Facts
- arXiv ID: 2505.08389
- Source URL: https://arxiv.org/abs/2505.08389
- Reference count: 40
- Primary result: Dynamic Caesar cipher benchmark reveals contamination effects in widely-used LLMs

## Executive Summary
This paper introduces contamination resistance as a critical criterion for LLM evaluation benchmarks, addressing the widespread problem of data leakage where models memorize test instances during pre-training. The authors propose a Caesar cipher benchmark that dynamically generates infinite unique instances, making memorization infeasible and ensuring performance reflects genuine reasoning capabilities. Experiments across multiple leading models (GPT-4o, LLaMA3.1, Qwen2.5, QwQ-32B) reveal inconsistent performance patterns, particularly between shift=3 (showing inflated accuracy due to contamination) and other shifts, exposing the limitations of current evaluation practices.

## Method Summary
The paper proposes a contamination-resistant benchmark based on Caesar ciphers that dynamically generates plaintext-ciphertext pairs across 25 possible shifts. The benchmark tests encoding and decoding tasks using both natural English words and random nonsense words, with four prompt formats (open, base, dict, code) and both zero-shot and few-shot settings. Models are evaluated on exact match accuracy and character error rate across shifts [3, 6, 9, 12], with temperature=0 for reproducibility. The infinite instance space ensures no model can memorize all possible queries, while performance variance across shift values serves as a diagnostic for contamination effects.

## Key Results
- GPT-4o achieves 82% accuracy on shift=3 natural decoding but 0% on shift=9 encoding with random plaintext
- Models show 40-60 percentage point performance gaps between shift=3 and other shifts, indicating contamination
- GPT-4o fails to benefit from few-shot demonstrations and struggles with random nonsense words
- Position-indexed accuracy reveals autoregressive generation biases that override logical deduction

## Why This Works (Mechanism)

### Mechanism 1
- Dynamically generated benchmarks with infinite instance spaces resist contamination by making memorization infeasible
- Core assumption: Models exposed to contaminated data will show performance patterns correlating with training data prevalence
- Evidence: Models perform well on shift=3 (prevalent in training) but fail on shift=6, 9, 12

### Mechanism 2
- Inconsistent performance across functionally equivalent task variants reveals memorization-based competence
- Core assumption: Tasks requiring identical cognitive operations should yield consistent performance if capability is genuinely learned
- Evidence: GPT-4o achieves 82% on shift=3 natural decoding but 0% on shift=9 encoding with random plaintext

### Mechanism 3
- Position-indexed accuracy degradation reveals autoregressive generation biases that override logical deduction
- Core assumption: Genuine algorithmic reasoning would produce position-independent accuracy for deterministic tasks
- Evidence: Accuracy declines from first to third output character even in deterministic tasks where all positions should be equally tractable

## Foundational Learning

- **Data Contamination (Test Set Contamination)**
  - Why needed: The entire paper diagnoses contamination effects; understanding models can memorize test instances during pre-training is essential
  - Quick check: If a model achieves 95% accuracy on a benchmark released before its training cutoff but 40% on equivalent new instances, what hypothesis explains this gap?

- **Autoregressive Language Modeling**
  - Why needed: Position-degradation finding depends on understanding how next-token prediction creates statistical rather than logical output generation
  - Quick check: Why would an autoregressive model generate different outputs for the same deterministic task when early tokens differ?

- **Generalization vs. Memorization in Neural Networks**
  - Why needed: The paper's core thesis distinguishes genuine reasoning capabilities from retrieval of memorized patterns
  - Quick check: What experimental manipulation would distinguish whether a model has learned an algorithm versus memorized input-output pairs?

## Architecture Onboarding

- **Component map**: Benchmark Generator -> Prompt Templates -> Evaluation Pipeline -> Contamination Diagnostic
- **Critical path**: 1) Define plaintext corpus, 2) Generate cipher instances across target shifts, 3) Format prompts, 4) Run inference, 5) Compute metrics, 6) Analyze performance variance
- **Design tradeoffs**: Shift selection balances contamination gradient and task tractability; plaintext type distinguishes word-level memorization from character-level reasoning; prompt format affects automated evaluation capability
- **Failure signatures**: High shift=3 accuracy with near-zero performance on other shifts; correct reasoning chains with incorrect final answers; correct code generation with incorrect direct answers; first-character accuracy >> third-character accuracy
- **First 3 experiments**: 1) Baseline contamination check: shift=3 vs. shift=9 decoding with natural plaintext, 2) Generalization stress test: natural vs. random plaintext at shift=3, 3) Reasoning format comparison: dict vs. code prompts on harder shifts

## Open Questions the Paper Calls Out

- **Open Question 1**: How do reasoning-optimized models like OpenAI o1 perform on contamination-resistant benchmarks compared to GPT-4o? (basis: explicit statement about cost constraints)
- **Open Question 2**: Does fine-tuning LLMs on random nonsense words to solve ciphers degrade their performance on general natural language tasks? (basis: explicit statement about unclear effects)
- **Open Question 3**: Can DeepSeek R1 consistently solve encoding tasks, or is its failure rate an artifact of server instability and temperature settings? (basis: explicit statement about inability to control parameters)
- **Open Question 4**: Can the criteria for contamination resistance be successfully applied to complex, non-algorithmic tasks beyond simple linear mappings like the Caesar cipher? (basis: inferred from paper's broader implications)

## Limitations

- Contamination resistance mechanism relies on assumption about shift=3 prevalence in training data without direct evidence
- Position-degradation analysis may conflate contamination effects with inherent autoregressive generation limitations
- Generalization diagnostic between natural and random plaintext could reflect tokenization differences rather than memorization patterns

## Confidence

- **High Confidence**: Benchmark successfully exposes contamination in current evaluation practices through consistent performance gaps between shift=3 and other shifts
- **Medium Confidence**: Position-degradation analysis revealing autoregressive biases, though distinguishing contamination from architectural limitations requires further investigation
- **Low Confidence**: Generalization diagnostic between natural and random plaintext, as attribution to word-level memorization may overlook other explanatory factors

## Next Checks

1. **Cross-model contamination gradient**: Evaluate same benchmark across models with known training cutoffs to verify contamination effects correlate with exposure dates
2. **Algorithmic reasoning intervention**: Implement pre-processing step teaching models Caesar cipher algorithm before evaluation to confirm bottleneck is algorithmic reasoning
3. **Controlled training experiment**: Fine-tune base model on Caesar ciphers with shifts 6, 9, 12 but exclude shift=3 entirely to validate training data prevalence drives contamination patterns