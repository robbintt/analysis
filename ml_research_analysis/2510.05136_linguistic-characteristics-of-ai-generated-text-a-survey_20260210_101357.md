---
ver: rpa2
title: 'Linguistic Characteristics of AI-Generated Text: A Survey'
arxiv_id: '2510.05136'
source_url: https://arxiv.org/abs/2510.05136
tags:
- aigt
- text
- more
- other
- linguistic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey synthesizes findings from 44 studies on the linguistic
  characteristics of AI-generated text (AIGT) compared to human-written text (HWT).
  Research shows AIGT tends to be more formal and impersonal, with higher use of nouns,
  determiners, and adpositions, and lower use of adjectives and adverbs.
---

# Linguistic Characteristics of AI-Generated Text: A Survey

## Quick Facts
- **arXiv ID**: 2510.05136
- **Source URL**: https://arxiv.org/abs/2510.05136
- **Reference count**: 40
- **Key outcome**: Survey of 44 studies reveals AIGT is more formal, impersonal, and repetitive than HWT, with distinctive part-of-speech patterns

## Executive Summary
This survey synthesizes findings from 44 studies examining linguistic differences between AI-generated text (AIGT) and human-written text (HWT). The research reveals consistent patterns showing AIGT tends to be more formal and impersonal, with higher usage of nouns, determiners, and adpositions, but lower usage of adjectives and adverbs. AIGT also exhibits lower lexical diversity, smaller vocabulary, and more repetitive patterns. The findings are predominantly based on English texts and GPT-family models, particularly GPT-3.5, with limited investigation into other languages and model architectures.

## Method Summary
The survey systematically reviewed 44 peer-reviewed studies published between 2019 and 2024, examining linguistic characteristics of AIGT compared to HWT. Studies were identified through systematic database searches and evaluated for methodological rigor, including prompt design, text genre, and analytical approaches. The review categorized findings across multiple linguistic dimensions including lexical features (vocabulary richness, word frequency), syntactic complexity, part-of-speech distribution, and text coherence metrics.

## Key Results
- AIGT shows higher formality and impersonality compared to HWT, with increased noun and determiner usage but decreased adjective and adverb usage
- AIGT exhibits lower lexical diversity and more repetitive patterns, particularly in formal text genres
- Most research focuses on English and GPT models, with only 9 studies using multiple prompts, highlighting need for more robust experimental designs

## Why This Works (Mechanism)
Unknown: The survey does not explicitly explain the mechanisms behind why AIGT exhibits these linguistic patterns. This likely relates to training data composition and optimization objectives, but specific causal explanations are not provided in the reviewed studies.

## Foundational Learning
- **Part-of-speech distribution**: Understanding grammatical categories and their frequency patterns helps identify systematic differences between AIGT and HWT
- **Lexical diversity metrics**: Measures like type-token ratio and entropy reveal vocabulary richness differences
- **Syntactic complexity analysis**: Sentence length, clause complexity, and dependency structures distinguish text generation approaches
- **Text repetition detection**: Algorithms for identifying repeated n-grams and semantic redundancy
- **Formality and tone assessment**: Linguistic markers that signal formality, objectivity, and impersonality in text

## Architecture Onboarding
- **Component map**: Text corpus → Preprocessing → Feature extraction (POS, lexical, syntactic) → Statistical analysis → Pattern identification
- **Critical path**: Corpus collection → Prompt engineering → Text generation → Feature extraction → Statistical comparison
- **Design tradeoffs**: Controlled experimental conditions vs. naturalistic text generation; model-specific vs. generalizable findings
- **Failure signatures**: Over-reliance on single prompts; English-only focus; GPT-centric analysis; limited cross-linguistic validation
- **First experiments**: 1) Compare POS distributions across multiple GPT versions using identical prompts; 2) Analyze lexical diversity in formal vs. informal genres; 3) Test repetition patterns in multilingual AIGT outputs

## Open Questions the Paper Calls Out
Unknown: The survey does not explicitly list open questions in a dedicated section. Based on the limitations and confidence assessments, potential open questions would likely include: How do AIGT characteristics vary across non-English languages? How robust are current findings across different prompting strategies? How do linguistic patterns evolve with newer model versions? What are the underlying mechanisms driving observed differences?

## Limitations
- Heavy skew toward English-language texts and GPT-family models limits generalizability
- Most studies use single prompts or limited variations, with only 9 employing multiple prompts
- Reliance on controlled experimental conditions rather than naturalistic settings constrains external validity

## Confidence
- High confidence in observable patterns like formal/informal tone differences and part-of-speech distributions
- Medium confidence in lexical diversity metrics and repetition patterns
- Low confidence in cross-linguistic generalizability and robustness across diverse prompting strategies

## Next Checks
1. Systematic comparison of AIGT from multiple model families (e.g., Claude, LLaMA, Gemini) using identical prompts and evaluation metrics
2. Cross-linguistic analysis of AIGT characteristics across at least 5 non-English languages with varying typological features
3. Longitudinal study tracking how AIGT linguistic patterns evolve as newer model versions are released and training data composition changes