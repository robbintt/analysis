---
ver: rpa2
title: 'Less is More: Learning Graph Tasks with Just LLMs'
arxiv_id: '2508.10115'
source_url: https://arxiv.org/abs/2508.10115
tags:
- graph
- training
- tasks
- tokens
- graphs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work investigates whether large language models can learn\
  \ to solve fundamental graph tasks without specialized graph encoders, and whether\
  \ such learning generalizes to unseen graph structures and tasks. The authors train\
  \ small LLMs using instructive chain-of-thought solutions for four core tasks\u2014\
  node count, node degree, and reachability using BFS or DFS\u2014and evaluate performance\
  \ across multiple approaches including LoRA, P-Tuning, Graph Tokens, and Graph Tokens\
  \ + Text."
---

# Less is More: Learning Graph Tasks with Just LLMs

## Quick Facts
- arXiv ID: 2508.10115
- Source URL: https://arxiv.org/abs/2508.10115
- Reference count: 40
- Small LLMs can learn graph tasks through instruction tuning without specialized graph encoders

## Executive Summary
This work investigates whether large language models can learn to solve fundamental graph tasks without specialized graph encoders, and whether such learning generalizes to unseen graph structures and tasks. The authors train small LLMs using instructive chain-of-thought solutions for four core tasks—node count, node degree, and reachability using BFS or DFS—and evaluate performance across multiple approaches including LoRA, P-Tuning, Graph Tokens, and Graph Tokens + Text. Results show that even small LLMs can effectively learn graph tasks with instruction tuning, achieving near-perfect accuracy on in-distribution graphs.

The LoRA approach demonstrates strong generalization to larger graphs and out-of-distribution structures, maintaining high accuracy even on graphs twice the training size, while Graph Tokens alone shows brittleness in such settings. The models also show transferability to new tasks with minimal additional training, and can improve question-answering performance when generating graphs from textual problems.

## Method Summary
The authors train small LLMs using instructive chain-of-thought solutions for four fundamental graph tasks: node count, node degree, and reachability using BFS or DFS. They evaluate four approaches: LoRA, P-Tuning, Graph Tokens, and Graph Tokens + Text. The models are trained on synthetic graph data and tested on both in-distribution and out-of-distribution graphs. The instruction tuning approach uses carefully crafted chain-of-thought solutions to teach the models how to reason about graph structures.

## Key Results
- Small LLMs achieve near-perfect accuracy on in-distribution graph tasks with instruction tuning
- LoRA approach generalizes well to larger graphs and out-of-distribution structures, maintaining high accuracy on graphs twice the training size
- Graph Tokens approach shows brittleness when applied to larger or out-of-distribution graphs
- Models demonstrate transferability to new graph tasks with minimal additional training

## Why This Works (Mechanism)
The instruction tuning approach with instructive chain-of-thought solutions enables LLMs to learn the reasoning patterns needed for graph tasks. By providing step-by-step reasoning examples, the models learn to decompose graph problems into manageable steps. The LoRA approach, which adds low-rank adaptation layers, appears particularly effective at capturing the generalizable patterns needed for handling different graph sizes and structures. The chain-of-thought format helps the models understand the logical flow required for graph algorithms like BFS and DFS.

## Foundational Learning
- Graph representation basics (why needed: models must understand how graphs are structured; quick check: can the model identify nodes and edges from input)
- BFS and DFS algorithms (why needed: core reachability tasks require understanding these traversal methods; quick check: can the model correctly trace traversal paths)
- Node degree calculation (why needed: fundamental graph property that tests basic understanding; quick check: can the model count edges for any given node)
- Chain-of-thought reasoning (why needed: provides step-by-step problem-solving framework; quick check: can the model follow and reproduce reasoning steps)

## Architecture Onboarding

**Component Map:**
LLMs (Llama 3B/8B) -> Instruction Tuning -> Graph Tasks (Node Count, Node Degree, BFS, DFS)

**Critical Path:**
Input graph text -> Chain-of-thought reasoning template -> Model processing -> Task-specific output

**Design Tradeoffs:**
- Model size vs. performance (smaller models work but with varying generalization)
- Synthetic vs. real-world data (synthetic used for controlled evaluation)
- Instruction complexity (more detailed instructions improve learning but may reduce generalization)

**Failure Signatures:**
- Graph Tokens approach failing on larger graphs indicates brittleness in learned representations
- Inconsistent performance across different graph sizes suggests limited scaling capabilities
- Difficulty with complex or combined tasks reveals limitations in reasoning depth

**3 First Experiments:**
1. Test LoRA and Graph Tokens approaches on graphs 4x larger than training data
2. Evaluate zero-shot performance on new graph tasks not seen during training
3. Compare performance between synthetic and real-world graph datasets

## Open Questions the Paper Calls Out
None

## Limitations
- Generalization varies significantly across approaches, with Graph Tokens showing brittleness on larger and out-of-distribution graphs
- Evaluation primarily uses synthetic graph data, leaving real-world performance untested
- Instruction tuning requires carefully crafted chain-of-thought solutions, which may not scale to more complex graph tasks
- Focus on four specific graph tasks may not capture full complexity of graph reasoning problems

## Confidence
- **High confidence** in the core finding that LLMs can learn basic graph tasks through instruction tuning on in-distribution data
- **Medium confidence** in generalization claims, particularly for the LoRA approach, due to varying performance across different graph sizes and structures
- **Medium confidence** in the transferability results, as these were demonstrated on a limited set of additional tasks

## Next Checks
1. Test the trained models on real-world graph datasets from diverse domains (e.g., social networks, molecular structures) to validate generalization beyond synthetic data
2. Evaluate the instruction tuning approach on more complex graph tasks that combine multiple operations or require higher-order reasoning
3. Investigate the robustness of the models to noisy or incomplete graph representations to assess practical applicability