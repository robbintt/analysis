---
ver: rpa2
title: Aligning Learning and Endogenous Decision-Making
arxiv_id: '2507.00851'
source_url: https://arxiv.org/abs/2507.00851
tags:
- learning
- decision
- problem
- endogenous
- demand
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an end-to-end learning framework for decision-making
  under endogenous uncertainty, where the random variable depends on the decision
  itself. The authors propose training a model to predict uncertainty in a way that
  aligns with the downstream optimization task, using a task-based loss function.
---

# Aligning Learning and Endogenous Decision-Making

## Quick Facts
- arXiv ID: 2507.00851
- Source URL: https://arxiv.org/abs/2507.00851
- Reference count: 3
- This paper introduces an end-to-end learning framework for decision-making under endogenous uncertainty, where the random variable depends on the decision itself.

## Executive Summary
This paper presents a framework for training machine learning models that are aware of their downstream decision-making impact under endogenous uncertainty, where decisions affect the random variables they predict. The authors propose minimizing a task-based loss function that aligns the predictor with the downstream optimization objective, rather than traditional prediction accuracy metrics. They extend this to a robust optimization framework that constructs uncertainty sets over models and optimizes decisions to protect against worst-case predictions. The framework also handles two-stage information-gathering problems where initial decisions reveal information about future uncertainties.

## Method Summary
The method trains models to minimize a task-based loss function that measures the difference between the realized cost and the predicted cost for historical decisions, rather than minimizing prediction error on random variables. For robust optimization, the framework constructs an uncertainty set of models consistent with the data and optimizes decisions against the worst-case model in this set. The uncertainty set size is determined by data complexity and theoretical bounds. The framework uses sampling-based methods or mixed-integer programming for training, and cutting-plane algorithms for solving the robust optimization problems.

## Key Results
- Task-based learning consistently outperforms traditional two-stage methods on pricing, assortment optimization, and electricity scheduling problems
- The robust optimization variant can capture near-optimal decisions with high probability as a function of data size
- The information-gathering extension successfully learns when to poll for information in electricity scheduling problems

## Why This Works (Mechanism)

### Mechanism 1
Minimizing task-based loss theoretically aligns the predictor with the downstream decision objective better than minimizing mean-squared error (MSE) on the random variable. Standard two-stage methods predict the mean E[z], but for non-linear cost functions c(v, z), c(v, E[z]) ≠ E[c(v, z)] (Jensen's inequality). This method trains a predictor f̂ such that the cost of the decision implied by f̂ matches the observed realized cost on historical data, effectively learning a point forecast that acts as a "decision-aware" surrogate for the distribution.

### Mechanism 2
Constructing uncertainty sets over the space of models (rather than the data) and optimizing for the worst-case model can protect against overfitting and limited data. Instead of picking one "best" model, the method defines an uncertainty set U_ε containing all models with task-loss error below a threshold ε. The decision is chosen to maximize the objective against the worst-case predictor in that set (min-max optimization). The paper proves this set contains the true optimal predictor with high probability.

### Mechanism 3
Treating "information gathering" (polling) as a first-stage endogenous decision allows the framework to learn the value of information. The decision to poll variable w affects the conditional distribution of the remaining variables. The framework unifies endogenous (first stage) and exogenous (second stage) learning to train a model that predicts the outcome of polling w without needing to actually observe the counterfactual polls during training.

## Foundational Learning

- **Concept: Endogenous vs. Exogenous Uncertainty**
  - **Why needed here:** This is the central distinction of the paper. Exogenous uncertainty allows counterfactual evaluation on historical data, while endogenous uncertainty prevents this because you never observed the outcome for the decision you didn't set.
  - **Quick check question:** Does my decision v change the distribution of the random variable z? If yes, standard "predict-then-optimize" may fail.

- **Concept: Smart Predict-then-Optimize (SPO)**
  - **Why needed here:** Understanding that the goal is not "accurate prediction" but "decision quality." A model with higher MSE might yield better decisions if its errors are aligned with the cost function's gradients.
  - **Quick check question:** Am I optimizing my model's weights to minimize prediction error, or to minimize the regret of the resulting decision?

- **Concept: Cutting-Plane Methods (Optimization)**
  - **Why needed here:** The robust formulation requires solving a min-max problem. The paper utilizes cutting-plane algorithms to solve the outer maximization efficiently.
  - **Quick check question:** Can I formulate my inner problem such that I can generate constraints (cuts) to guide the outer search?

## Architecture Onboarding

- **Component map:**
  1. History Buffer: Stores (x_n, v_n, z_n, c(v_n, z_n))
  2. Task-Based Learner: Neural network trained to minimize |c(v, f(x,v)) - c(v, z)|
  3. Uncertainty Set Generator: Calculates ε and defines set U_ε of compatible models
  4. Robust Solver: Min-max optimizer using cutting-planes or alternating descent

- **Critical path:**
  1. Define the cost function c(v, z)
  2. Implement the "Task Loss" (Eq. 3) - primary deviation from standard ML
  3. Implement the "Inner Problem" to find worst-case prediction for fixed action
  4. Wrap Inner Problem in "Outer Problem" to find best action

- **Design tradeoffs:**
  - Exact MIP vs. Sampling: Exact is accurate but slow; sampling is faster but may get stuck in local minima
  - Robustness ε: Choosing ε involves tradeoff between conservativeness and optimality

- **Failure signatures:**
  - Revenue Collapse: Model extrapolates wildly to out-of-sample decisions
  - Over-conservatism: If ε is too high, robust optimizer will assume worst possible demand for every price

- **First 3 experiments:**
  1. Pricing Validation: Compare proposed method against "Predict-then-Optimize" baseline on synthetic data
  2. Robustness Check: Vary robustness parameter ε and verify initial improvement before over-conservatism
  3. Information Gathering: Implement "Electricity Scheduling" use case, testing if model learns non-trivial polling time

## Open Questions the Paper Calls Out

### Open Question 1
How can the non-convex task-based learning objective be solved efficiently with global optimality guarantees for non-linear models? The paper provides a trade-off between an exact but slow method and a fast but heuristic method, leaving a gap for scalable, provably optimal algorithms for general function classes.

### Open Question 2
Can the robust optimization approach adaptively tune the uncertainty set size (ε) to balance robustness against the underlying complexity of the noise and data distribution? The optimal ε is context-dependent and theoretical bounds rely on often unknown constants.

### Open Question 3
How can the decision-making pipeline ensure global optimality in the outer problem when the predicted objective function is non-convex with respect to the decision variables? The paper suggests sampling initial points as a heuristic but does not provide a method to guarantee global convergence for non-convex decision spaces.

## Limitations
- The framework requires differentiable or piecewise-linear cost functions, limiting applicability to complex objectives
- Computational burden of solving min-max problems may be prohibitive for high-dimensional action spaces
- Theoretical guarantees assume finite hypothesis class, but practical demonstrations use neural networks where covering numbers are difficult to compute

## Confidence
- **High Confidence:** Core mechanism of task-based loss alignment and basic robust optimization formulation
- **Medium Confidence:** Theoretical guarantees for robust uncertainty sets rely on covering number assumptions
- **Low Confidence:** Extension to information-gathering problems lacks rigorous validation beyond electricity scheduling case study

## Next Checks
1. **Computational Scaling Test:** Evaluate running time of robust optimization algorithm as number of actions and features increases
2. **Hypothesis Class Sensitivity:** Compare performance across different model architectures to understand how complexity affects theoretical bounds
3. **Robustness Parameter Calibration:** Conduct systematic study on synthetic data where true model is known to determine optimal ε selection strategies