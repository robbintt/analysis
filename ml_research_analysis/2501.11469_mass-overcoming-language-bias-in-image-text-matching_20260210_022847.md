---
ver: rpa2
title: 'MASS: Overcoming Language Bias in Image-Text Matching'
arxiv_id: '2501.11469'
source_url: https://arxiv.org/abs/2501.11469
tags:
- bias
- mass
- language
- image
- image-text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses language bias in image-text matching, where
  visual-language models rely too heavily on textual priors rather than visual content.
  The proposed Multimodal ASsociation Score (MASS) framework reduces this bias by
  computing pointwise mutual information between image and text tokens, aggregating
  them to form a debiased similarity score.
---

# MASS: Overcoming Language Bias in Image-Text Matching
arXiv ID: 2501.11469
Source URL: https://arxiv.org/abs/2501.11469
Authors: Jiwan Chung; Seungwon Lim; Sangkyu Lee; Youngjae Yu
Reference count: 25
Primary result: Multimodal ASsociation Score (MASS) reduces language bias in image-text matching by computing pointwise mutual information, achieving up to 93% improvement on color debiasing and 19.3% reduction in gender bias while maintaining high recall.

## Executive Summary
MASS addresses language bias in image-text matching where visual-language models rely too heavily on textual priors rather than visual content. The proposed framework computes pointwise mutual information between image and text tokens, aggregating them to form a debiased similarity score. MASS works with existing models without retraining and shows strong performance across three bias domains: color (93% improvement over baselines), counting (4.7% gain in adversarial set), and gender bias (up to 19.3% reduction while maintaining high recall). It also improves linguistic understanding in compositionality benchmarks (Winoground, SVO-Probes), outperforming baselines like CLIP and token likelihood methods.

## Method Summary
MASS is an inference-time method that computes debiased image-text similarity by estimating pointwise mutual information (PMI) between image and text tokens. The method requires two forward passes through an autoregressive visual-language model: one with the actual image and one with a null (black-filled) image to estimate marginal text likelihood. The per-token PMI is computed as the difference between conditional log-likelihoods, then averaged across all tokens to produce the final MASS score. This approach isolates genuine image-text association while removing linguistic priors learned during training.

## Key Results
- Color debiasing: 93% improvement over baselines, successfully matching grayscale images with correct color descriptions
- Counting bias: 4.7% gain in adversarial set accuracy while maintaining performance on balanced set
- Gender bias: Up to 19.3% reduction in Bias@K while maintaining Recall@K above 90%
- Compositionality: Groupscore improved from 9.5 (baseline ITM) to 20.3 (OFA-large) on Winoground

## Why This Works (Mechanism)

### Mechanism 1: Pointwise Mutual Information Decomposition
Claim: Subtracting the text-only marginal likelihood from image-conditioned likelihood isolates genuine image-text association while removing linguistic priors. The decomposition log p(x|c) = log p(x) + log[p(c|x)/p(c)] separates linguistic plausibility from true association. MASS retains only the association term by computing PMI.

### Mechanism 2: Null Image Marginal Approximation
Claim: A black-filled image provides a computationally efficient approximation of the marginal text likelihood without requiring Monte Carlo sampling. Instead of sampling N random images, MASS uses p(xt|x<t, c∅) where c∅ is a null image, requiring only one additional forward pass.

### Mechanism 3: Token-Level Aggregation for Compositional Sensitivity
Claim: Averaging PMI across all tokens preserves sensitivity to word order and compositionality that sequence-level scores lose. MASS computes (1/l) Σ log[p(xt|x<t,c) / p(xt|x<t,c∅)] per token, enabling discrimination between "dog chases cat" and "cat chases dog."

## Foundational Learning

- **Concept: Pointwise Mutual Information (PMI)**
  - Why needed here: MASS is fundamentally PMI applied to image-text pairs. Understanding PMI as measuring "how much more likely x and c co-occur than by chance" is essential.
  - Quick check question: If p(x|c) = p(x), what is PMI(x; c)? (Answer: 0, indicating no association)

- **Concept: Autoregressive Language Modeling**
  - Why needed here: MASS relies on autoregressive models that factor text likelihood as p(x) = Π p(xt|x<t). The token-by-token conditioning is what enables per-token PMI computation.
  - Quick check question: Why can't contrastive models like CLIP directly compute MASS? (Answer: They produce sequence-level embeddings, not per-token likelihoods)

- **Concept: Language Bias in Vision-Language Models**
  - Why needed here: The problem MASS solves is that VL models learn dataset priors (e.g., "fireman" is more likely than "firewoman") that override visual evidence.
  - Quick check question: On the color debiasing task, why does raw token likelihood prefer "The tomato is red" over "The tomato is gray" for a grayscale image? (Answer: Training data bias makes "red" a priori more likely regardless of the image)

## Architecture Onboarding

- **Component map:**
Input: Image c, Text x = {x1, ..., xl}
     ↓
[Backbone VL Model - autoregressive, e.g., OFA, BLIP-2]
     ↓ outputs token logits
┌────────────────────────────────────────┐
│  Forward Pass 1: Image c + Text x      │ → p(xt|x<t, c) per token
└────────────────────────────────────────┘
┌────────────────────────────────────────┐
│  Forward Pass 2: Null image c∅ + Text x│ → p(xt|x<t, c∅) per token
└────────────────────────────────────────┘
     ↓
[Per-token PMI: log p(xt|x<t,c) - log p(xt|x<t,c∅)]
     ↓
[Aggregation: mean over all tokens]
     ↓
Output: MASS score (scalar)

- **Critical path:** The backbone model must output per-token logits (not just sequence embeddings). OFA, BLIP-2, and LLaVA work; CLIP does not.

- **Design tradeoffs:**
  - Null image vs. Monte Carlo sampling: Null image is 10-100× faster but may be less accurate for models with strong black-image biases.
  - Mean vs. sum aggregation: Mean normalizes for sequence length (implemented); sum would favor longer texts.
  - Backbone choice: OFA-large provides best results (20.3 Groupscore on Winoground) but requires 930M parameters; tiny (33M) still improves over baselines.

- **Failure signatures:**
  - MASS ≈ 0 for all pairs: Check that null image is correctly formatted (black RGB image matching backbone's expected resolution).
  - Negative MASS for correct pairs: May indicate null image triggers fallback behavior that doesn't isolate priors; try Monte Carlo with 10-20 random images.
  - No improvement over TL: Verify backbone is autoregressive (not contrastive-only like base CLIP).

- **First 3 experiments:**
  1. **Sanity check on color bias:** Use the Natural Colors Dataset. For grayscale tomato images, verify MASS(gray image, "The tomato is gray") > MASS(gray image, "The tomato is red"). Expected: TL fails ~33% of categories; MASS should succeed on all but one.
  2. **Winoground compositionality test:** Run OFA-large with MASS on Winoground. Target Groupscore >15 (baseline ITM: 9.5, TL: 15.8, MASS: 20.3 per paper).
  3. **Ablation on null image:** Compare null-image MASS vs. Monte Carlo MASS (N=10 random images) on a small subset of Winoground. If results diverge >5%, the null image approximation may be unreliable for your backbone.

## Open Questions the Paper Calls Out

### Open Question 1
Question: How can MASS be adapted to mitigate social biases that manifest visually or as cross-modal combinations, rather than solely through language priors?
Basis in paper: [Explicit] The authors state in the Broader Impact section that "Social bias could be manifested as visual bias or even in the form of bias that is identified only as combinations of image and text," which MASS does not currently address.
Why unresolved: The current framework only subtracts the text-only marginal likelihood (p(x)) and does not account for biases inherent in the visual encoder or the interaction between visual and textual features.
What evidence would resolve it: Demonstrating MASS's efficacy on bias benchmarks that rely on visual stereotypes (e.g., racial or occupational visual biases) rather than textual gender/color correlations.

### Open Question 2
Question: To what extent does MASS's debiasing performance depend on the specific architecture and pre-training data of the underlying visual-language model?
Basis in paper: [Explicit] The authors acknowledge that because MASS is an inference-time method, it "cannot audit the information stored in the models' parameters," meaning "the range and intensity of its effect may vary with respect to the base VL model used."
Why unresolved: While results are shown for OFA, BLIP-2, and LLaVA, the paper does not analyze if certain model structures or training corpora render the pointwise mutual information approximation ineffective or unstable.
What evidence would resolve it: A comparative analysis of MASS scores across a diverse set of backbone models (e.g., diffusion-based vs. autoregressive) to identify architectural features that predict the success of the debiasing intervention.

### Open Question 3
Question: Is the use of a "null image" (black-filled image) a universally robust approximation for the text-only marginal likelihood across different domains?
Basis in paper: [Inferred] Section 3.2 notes that while Monte Carlo estimation is accurate but expensive, the authors "discovered that using image input as a null image... is a good alternative" empirically, leaving the theoretical robustness of this heuristic undefined.
Why unresolved: Visual-language models may interpret a black image as a specific visual signal (e.g., "night" or "darkness") rather than an absence of information, potentially skewing the calculated association score for certain semantic classes.
What evidence would resolve it: Ablation studies comparing the black-image approximation against Monte Carlo sampling and other null-image variants (e.g., noise, mean-image) on diverse datasets to measure approximation error.

## Limitations
- Null image approximation reliability: The black-filled image assumption may fail for models with strong visual priors for specific pixel values or contexts where black images have semantic meaning
- Token-level calibration dependence: MASS performance critically depends on backbone model's token-level likelihood estimates being well-calibrated
- Limited bias domain validation: Only three specific bias types (color, counting, gender) have been tested, with unknown generalizability to other domains

## Confidence
- High confidence: The core PMI-based debiasing mechanism and its theoretical decomposition into linguistic vs. association components
- Medium confidence: The null image approximation's effectiveness across diverse models and datasets
- Low confidence: The method's performance on bias types not explicitly tested in the paper

## Next Checks
1. **Null image calibration test**: Compare MASS scores using null image vs. Monte Carlo sampling (N=10 random images) on 100 Winoground samples. If correlation <0.95 or performance difference >5%, the null image approximation is unreliable for your backbone model.

2. **Cross-bias domain evaluation**: Apply MASS to a spatial reasoning task (e.g., "The vase is behind the chair" vs. "The vase is in front of the chair" for a clear spatial configuration). Measure whether MASS maintains compositionality while reducing spatial language priors.

3. **Model-agnostic stress test**: Implement MASS on a contrastive-only model (e.g., CLIP) by extracting sequence embeddings and approximating token likelihoods through gradient-based saliency. If MASS fails to improve over baseline, this confirms the method's dependence on autoregressive architectures.