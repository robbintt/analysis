---
ver: rpa2
title: 'When the LM misunderstood the human chuckled: Analyzing garden path effects
  in humans and language models'
arxiv_id: '2502.09307'
source_url: https://arxiv.org/abs/2502.09307
tags:
- while
- sentence
- sentences
- llms
- humans
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study investigates whether Large Language Models (LLMs) and
  humans experience similar comprehension difficulties with garden-path sentences,
  a well-known challenge in human psycholinguistics. The authors propose three non-mutually
  exclusive hypotheses: (1) garden-path syntax is inherently harder due to reanalysis
  demands; (2) misinterpretation is driven by semantic plausibility of the noun as
  a verb object; (3) transitive verbs lead to more misinterpretation than reflexive
  or unaccusative verbs.'
---

# When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models

## Quick Facts
- arXiv ID: 2502.09307
- Source URL: https://arxiv.org/abs/2502.09307
- Reference count: 18
- Primary result: LLMs exhibit comprehension patterns similar to humans when processing garden-path sentences

## Executive Summary
This study investigates whether Large Language Models (LLMs) and humans experience similar comprehension difficulties with garden-path sentences, a well-known challenge in human psycholinguistics. The authors propose three non-mutually exclusive hypotheses about why garden-path structures cause processing difficulties: inherent syntactic complexity due to reanalysis demands, semantic plausibility of nouns as verb objects, and differences between transitive and intransitive verb types. They test these hypotheses using comprehension questions, with humans performing word-by-word reading tasks and LLMs answering via few-shot prompting. Results show humans and LLMs both struggle with garden-path structures, and LLMs exhibit similar effects across syntactic complexity, plausibility, and verb type. Stronger LLMs show higher correlation with human behavior. Additional tasks (paraphrasing and image generation) confirm that LLMs often misinterpret garden-path sentences in ways similar to humans. Overall, the study reveals that LLMs approximate human comprehension patterns in these challenging syntactic contexts, supporting their potential as models for human-like language processing.

## Method Summary
The study employs a multi-pronged experimental approach to compare human and LLM garden-path sentence processing. For human participants, the researchers use a word-by-word self-paced reading paradigm where participants read sentences incrementally and answer comprehension questions about the final interpretation. For LLMs, the researchers use few-shot prompting to elicit interpretations of garden-path sentences and answer similar comprehension questions. The study tests three hypotheses: (1) garden-path syntax is inherently harder due to reanalysis demands; (2) misinterpretation is driven by semantic plausibility of the noun as a verb object; (3) transitive verbs lead to more misinterpretation than reflexive or unaccusative verbs. To validate findings beyond comprehension questions, the authors conduct supplementary experiments including paraphrasing tasks and image generation prompts. The image generation task is particularly creative, as it requires the LLM to produce visual representations that should only be coherent if the model correctly parsed the garden-path structure.

## Key Results
- Humans and LLMs both struggle with garden-path structures, showing similar difficulty patterns across syntactic complexity
- LLMs exhibit effects similar to humans across syntactic complexity, semantic plausibility, and verb type
- Stronger LLMs show higher correlation with human behavior in garden-path processing
- Supplementary tasks (paraphrasing and image generation) confirm LLMs often misinterpret garden-path sentences in ways similar to humans

## Why This Works (Mechanism)
The study demonstrates that LLMs capture meaningful aspects of human-like language processing through their ability to replicate garden-path effects. The mechanism appears to involve similar sensitivity to syntactic complexity, semantic plausibility, and verb type properties. The alignment across multiple experimental paradigms suggests LLMs are not merely pattern-matching but approximating the underlying cognitive processes involved in incremental sentence comprehension. The image generation task provides particularly compelling evidence, as it requires the model to commit to an interpretation in a way that reveals genuine parsing decisions rather than surface-level responses.

## Foundational Learning
- Garden-path sentences: Sentences that lead readers to initially misinterpret the syntactic structure, requiring reanalysis. Why needed: These are well-studied phenomena in human psycholinguistics that create measurable comprehension difficulties. Quick check: Can you identify the two possible interpretations in "The horse raced past the barn fell"?
- Self-paced reading: A psycholinguistic method where participants control the presentation rate of words to measure processing difficulty. Why needed: Allows researchers to measure incremental comprehension and identify where garden-path effects occur. Quick check: What would a processing slowdown at "fell" in the example sentence indicate?
- Few-shot prompting: A technique where LLMs are given several examples before being asked to perform a task. Why needed: Helps guide LLMs to produce more consistent and interpretable responses for comprehension questions. Quick check: How might different numbers of examples affect LLM performance on garden-path sentences?

## Architecture Onboarding
Component map: Sentence input -> Incremental processing -> Semantic plausibility evaluation -> Syntactic reanalysis -> Final interpretation output
Critical path: The incremental processing stage where initial parse commitment occurs is crucial, as this determines whether garden-path effects will manifest
Design tradeoffs: The study trades off precise measurement of real-time processing dynamics (available in human experiments) for the ability to test multiple models and conditions efficiently
Failure signatures: Both humans and LLMs show processing slowdowns and comprehension errors when encountering garden-path structures, with severity correlating with syntactic complexity
3 first experiments:
1. Test whether providing explicit syntactic cues before garden-path sentences reduces LLM misinterpretation rates
2. Compare performance across different prompting strategies (zero-shot, few-shot, chain-of-thought) on garden-path comprehension
3. Evaluate whether fine-tuning on garden-path sentences eliminates the observed effects

## Open Questions the Paper Calls Out
None

## Limitations
- The reliance on comprehension questions as the primary measure may not fully capture the dynamic, incremental nature of human sentence comprehension
- The non-mutually-exclusive framing of hypotheses makes it difficult to determine which factors are most causally important
- The image generation task introduces additional variables beyond syntactic processing that could influence results

## Confidence
- High confidence: LLMs and humans show similar difficulty patterns with garden-path sentences across syntactic complexity
- Medium confidence: Semantic plausibility significantly influences garden-path misinterpretation for both humans and LLMs
- Medium confidence: LLMs approximate human behavior in garden-path processing, though exact mechanisms may differ

## Next Checks
1. Implement self-paced reading or eye-tracking paradigms to measure processing difficulty incrementally rather than through comprehension questions alone
2. Conduct controlled interventions to manipulate semantic plausibility independently from syntactic structure to better isolate causal factors
3. Test whether fine-tuning LLMs on garden-path sentences reduces the observed effects, which would help determine if these patterns reflect architectural limitations or training data characteristics