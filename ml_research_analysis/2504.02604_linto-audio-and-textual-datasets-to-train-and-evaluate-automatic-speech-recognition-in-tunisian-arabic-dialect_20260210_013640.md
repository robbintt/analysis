---
ver: rpa2
title: LinTO Audio and Textual Datasets to Train and Evaluate Automatic Speech Recognition
  in Tunisian Arabic Dialect
arxiv_id: '2504.02604'
source_url: https://arxiv.org/abs/2504.02604
tags:
- tunisian
- arabic
- audio
- datasets
- speech
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces the LinTO audio and textual datasets for Tunisian
  Arabic Dialect, addressing the challenge of limited annotated speech data for this
  low-resource language. The datasets include diverse text sources and real-world
  audio recordings with transcriptions, featuring code-switching between Tunisian
  Arabic, English, and French.
---

# LinTO Audio and Textual Datasets to Train and Evaluate Automatic Speech Recognition in Tunisian Arabic Dialect

## Quick Facts
- arXiv ID: 2504.02604
- Source URL: https://arxiv.org/abs/2504.02604
- Reference count: 5
- The LinTO dataset introduces 93 hours of raw audio and 4.5M lines of text for Tunisian Arabic Dialect, with baseline Kaldi TDNN models achieving 36.6% WER on YouTube test sets using voice conversion augmentation.

## Executive Summary
This paper introduces the LinTO audio and textual datasets for Tunisian Arabic Dialect, addressing the challenge of limited annotated speech data for this low-resource language. The datasets include diverse text sources and real-world audio recordings with transcriptions, featuring code-switching between Tunisian Arabic, English, and French. Data augmentation techniques, including Voice Conversion Augmentation, were applied to enhance speaker diversity and improve model robustness. Preliminary experiments with Kaldi-based ASR models show significant improvements in performance, particularly for code-switching scenarios, when using augmented data. The LinTO datasets provide a valuable resource for training and evaluating ASR systems for Tunisian Arabic Dialect, with the release of a baseline model demonstrating feasibility and effectiveness.

## Method Summary
The LinTO dataset combines multiple sources: TunSwitch corpus, MASC Tunisian subset, YouTube crawls, and Hugging Face datasets. Audio is collected at 16kHz, segmented to ≤30s chunks, and cleaned using Spleeter source separation. Text normalization uses a 12,500-word dictionary to standardize variant spellings. Three training conditions are evaluated: No-Aug (93H raw, 20 epochs), No-VCA (5×93H classical augmentation, 4 epochs), and VCA (5×466H with voice conversion, 4 epochs). Kaldi TDNN models with triphone GMM-HMM alignment and 4-gram LMs are trained using extended Buckwalter transliteration for Arabic+Latin text.

## Key Results
- Baseline Kaldi TDNN model with VCA augmentation achieves 36.6% WER on YouTube test sets
- VCA significantly improves Latin word recall in code-switching scenarios (F1/recall/precision scores with 95% confidence intervals provided)
- Scratch training outperforms zero-shot Whisper large-v3 (82.0% WER) on the same test sets
- The LinTO textual corpus contains 4.5M lines with ~288K unique words

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Voice Conversion Augmentation