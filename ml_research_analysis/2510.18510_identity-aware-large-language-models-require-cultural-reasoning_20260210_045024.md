---
ver: rpa2
title: Identity-Aware Large Language Models require Cultural Reasoning
arxiv_id: '2510.18510'
source_url: https://arxiv.org/abs/2510.18510
tags:
- cultural
- language
- llms
- norms
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper defines cultural reasoning as the capacity of large
  language models to recognise culture-specific knowledge, norms, and social practices
  and to adapt outputs accordingly. It argues that current evaluation methods are
  insufficient because they focus on static accuracy and fail to capture dynamic,
  context-dependent cultural adaptation.
---

# Identity-Aware Large Language Models require Cultural Reasoning

## Quick Facts
- arXiv ID: 2510.18510
- Source URL: https://arxiv.org/abs/2510.18510
- Reference count: 40
- Current LLMs default to Western norms in cultural reasoning, failing to adapt outputs to specific cultural contexts

## Executive Summary
This paper defines cultural reasoning as the capacity of large language models to recognize and apply culture-specific knowledge, norms, and social practices. Current evaluation methods focus on static factual recall rather than dynamic, context-dependent cultural adaptation, leading models to default to Western norms even when prompted with non-Western contexts. The authors propose a structured evaluation pipeline involving domain identification, multilingual data elicitation, human validation, and fine-tuning to improve cultural competence. Using the multilingual Greater Region of SaarLorLux as an example, they highlight the need for AI to handle mixed cultural identities and sociolinguistic complexity.

## Method Summary
The paper proposes a four-stage pipeline for evaluating and improving cultural reasoning in LLMs: (1) elicit socio-pragmatic descriptions from native speakers across specific country-language pairs, (2) derive testable value statements through human validation, (3) assemble tasks including QA, preference with rationales, and ranking, and (4) evaluate models pre/post fine-tuning on validated statements. The approach targets six domains (family, education, work, public services, media, politeness) across multilingual contexts like Luxembourgish, French, and German in the SaarLorLux region.

## Key Results
- Current LLMs default to Western norms in moral reasoning, idioms, and advice regardless of cultural context
- Multilingual capability does not guarantee multicultural reasoning; language-culture non-equivalence is a significant challenge
- Fine-tuning on survey data only partially reduces Western bias; the proposed value statement distillation method aims to improve this

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Current evaluation methods fail to measure cultural reasoning because they optimize for static factual recall rather than adaptive application.
- **Mechanism**: Benchmarks testing for "knowledge about" cultures allow models to rely on surface-level associations. True cultural reasoning requires "context-appropriate application" where a model must select procedures that vary by locale.
- **Core assumption**: High accuracy on static cultural knowledge bases does not imply the model can navigate novel or ambiguous cultural situations.
- **Evidence anchors**: Abstract states methods "fail to capture adaptive reasoning in context," citing Kharchenko et al. on knowledge-application gaps.

### Mechanism 2
- **Claim**: Skewed training data distributions create a "default Western norm" bias that overrides specific cultural prompting in under-represented contexts.
- **Mechanism**: Dominance of Western perspectives in pre-training leads to stronger embedding associations for Western concepts, causing models to default to Western priors when encountering ambiguous prompts from under-represented cultures.
- **Core assumption**: Volume of Western data creates gravitational pull that simple prompting cannot fully counteract.
- **Evidence anchors**: Abstract notes models "default to Western norms," citing Naous et al. on disproportionate favoring of Western entities.

### Mechanism 3
- **Claim**: Cultural reasoning requires a structured pipeline that forces derivation of "value statements" from raw descriptions to enable consistent evaluation.
- **Mechanism**: Unstructured cultural text is too noisy for reliable benchmarking. The pipeline forces distillation: Elicit descriptions → Human Validation → Distill into "Value Statements" to create contrast sets that test if a model can apply a norm rather than just retrieve a fact.
- **Core assumption**: Annotators can reliably reduce complex cultural practices into concise, testable value statements that retain sufficient nuance.
- **Evidence anchors**: Abstract proposes four-stage pipeline to assess models' ability to reason within culturally specific frameworks.

## Foundational Learning

- **Concept**: Cultural Reasoning vs. Cultural Knowledge
  - **Why needed here**: The paper argues that knowing a fact (e.g., "Japanese people bow") is distinct from reasoning (e.g., knowing when to bow vs. shake hands in a mixed setting).
  - **Quick check question**: If a model correctly identifies a cultural holiday, does that prove it can advise a user on how to behave during that holiday?

- **Concept**: Bias vs. Perspective Taking
  - **Why needed here**: The paper reframes "bias" not just as harm, but as a necessary mechanism for perspective-taking. A model must "bias" its output toward a specific cultural frame to be identity-aware.
  - **Quick check question**: Is the model's tendency to prioritize Western norms a failure of safety or a failure of context detection?

- **Concept**: Language-Culture Non-Equivalence
  - **Why needed here**: Section 4.2 highlights that language choice indexes specific cultural identities. Multilingual capability does not guarantee multicultural reasoning.
  - **Quick check question**: Can a model be fluent in a language but fail to understand the cultural norms associated with its speakers?

## Architecture Onboarding

- **Component map**: Domain Selector → Elicitation Engine → Validator → Statement Distiller → Evaluator
- **Critical path**: The transition from Elicitation to Statement Distillation (Section 4.3). If prompt design fails to elicit nuanced descriptions, resulting value statements will be generic and useless for testing reasoning.
- **Design tradeoffs**: Heavy reliance on human validation creates high-precision but high-cost/low-scalability dataset compared to synthetic generation methods.
- **Failure signatures**:
  - Hallucinated Norms: Model generates plausible but non-existent cultural rules
  - Agreeableness Bias: Model judges all stories as "normative" regardless of cultural conflict
  - Monolingual Cultural Collapse: Model ignores specific Country-Language matrix and defaults to dominant language's culture
- **First 3 experiments**:
  1. Consistency Check: Prompt with same cultural scenario paraphrased in different languages to see if reasoning changes
  2. Contrast Set Evaluation: Judge stories that adhere to vs. violate norms for under-represented regions
  3. Value Statement Validation: Have model generate "value statements" for known culture and compare against human-validated set

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can LLMs reliably emulate users with hybrid or mixed cultural identities without defaulting to a single dominant cultural frame?
- **Basis in paper**: Authors explicitly ask "whether an LLM could emulate a user shaped equally by Luxembourgish and French norms" (Page 11)
- **Why unresolved**: Current benchmarks assess static, single-culture contexts, failing to capture complexity of cross-border or diasporic settings where norms conflict or merge
- **What evidence would resolve it**: Successful evaluation results on pipeline's "Conflict reconciliation" criteria in multilingual regions like SaarLorLux

### Open Question 2
- **Question**: Does improved multilingual capability inherently lead to better cultural reasoning, or are these distinct capabilities?
- **Basis in paper**: Authors state: "Cross-lingual transfer should be distinguished from cross-cultural transfer" and note that "Identity-aware AI therefore cannot rely on multilingual capacity alone" (Page 11)
- **Why unresolved**: Models often transfer linguistic form effectively but fail to transfer nuanced cultural priors like politeness strategies or norm salience
- **What evidence would resolve it**: Decoupling of language fluency scores from cultural adaptation scores in benchmarks

### Open Question 3
- **Question**: Is fine-tuning on validated value statements sufficient to bridge the gap between possessing cultural knowledge and applying it contextually?
- **Basis in paper**: Paper notes that "fine-tuning on survey data only partly reduces this tendency" to default to Western norms (Abstract) and proposes new fine-tuning method using value statements (Section 4.4)
- **Why unresolved**: Unclear if proposed method overcomes "adaptability gap" where models know a norm but fail to use it during reasoning
- **What evidence would resolve it**: Improved performance on "Justified adaptation" operational criteria compared to standard survey-based fine-tuning

## Limitations

- Human validation scalability: Pipeline's dependence on human validation for each country-language pair creates high-cost, low-scalability constraints
- SaarLorLux case study lacks quantitative evidence: Illustrative but doesn't provide empirical demonstration of model failures in this multilingual region
- Intra-cultural variation mechanism underspecified: Handling of intra-cultural variation (claim f) is conceptually important but not well-defined in evaluation design

## Confidence

- **High Confidence**: Claim that current evaluation methods focus on static accuracy rather than adaptive cultural reasoning is well-supported by multiple citations
- **Medium Confidence**: Assertion that Western training data skew creates persistent "default norm" bias is plausible but exact magnitude across architectures unclear
- **Low Confidence**: Specific four-stage pipeline's effectiveness in improving cultural reasoning has not been empirically validated; proposed as solution but lacks demonstrated outcomes

## Next Checks

1. **Human Validation Reproducibility**: Implement Stage 1–2 pipeline for small set of domains and 2–3 country-language pairs. Measure inter-annotator agreement and test if distilled value statements are consistent and non-generic.

2. **Model Consistency under Cultural Swap**: Using pre-trained model, evaluate responses to identical scenarios with only cultural context swapped (e.g., US vs. Japan norms). Check if outputs change appropriately based on specified culture.

3. **Contrast Set Effectiveness**: Construct minimal contrast set where one item follows cultural norm and another violates it. Test if models can distinguish between them with justifications, validating pipeline's ability to create meaningful reasoning tasks.