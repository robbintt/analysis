---
ver: rpa2
title: Mamba-Based Ensemble learning for White Blood Cell Classification
arxiv_id: '2504.11438'
source_url: https://arxiv.org/abs/2504.11438
tags:
- mamba
- classification
- arxiv
- learning
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of white blood cell (WBC) classification,\
  \ a task that is critical for diagnosing immune disorders but is traditionally labor-intensive\
  \ and prone to inconsistencies. The authors propose a novel framework leveraging\
  \ Mamba models\u2014known for their linear complexity and scalability\u2014integrated\
  \ with ensemble learning to improve classification accuracy and efficiency."
---

# Mamba-Based Ensemble learning for White Blood Cell Classification

## Quick Facts
- arXiv ID: 2504.11438
- Source URL: https://arxiv.org/abs/2504.11438
- Reference count: 33
- Primary result: Mamba-based ensemble achieves 93.94% accuracy on Chula-WBC-8 and 99.24% on BloodMNIST

## Executive Summary
This paper addresses the challenge of white blood cell (WBC) classification, a task that is critical for diagnosing immune disorders but is traditionally labor-intensive and prone to inconsistencies. The authors propose a novel framework leveraging Mamba models—known for their linear complexity and scalability—integrated with ensemble learning to improve classification accuracy and efficiency. They also introduce a new dataset, Chula-WBC-8, which contains images of eight WBC types from patients with disorders, addressing the issue of data imbalance. Experiments show that the Mamba-based ensemble approach outperforms existing methods, including the Sysmex DI-60 automated system, achieving a 93.94% accuracy on Chula-WBC-8 and 99.24% on the BloodMNIST benchmark. The results validate Mamba's effectiveness in this domain and demonstrate its potential for practical deployment in resource-constrained clinical settings.

## Method Summary
The method combines five Mamba-based architectures (ViM, VMamba, MambaVision, MedMamba, LocalMamba) into an ensemble, with an MLP meta-learner integrating their predictions. Input images are resized to 224×224 and processed through patch embeddings specific to each variant. Base models are trained on an 80% partition of the data, while a 20% holdout set trains the meta-learner. The approach employs weighted cross-entropy loss and data augmentation (rotation, translation, scaling, shearing, flips, color jitter, Gaussian blur) to address class imbalance. Models are optimized using AdamW, with MedMamba trained from scratch and others using ImageNet pretraining.

## Key Results
- Mamba-based ensemble achieves 93.94% accuracy on Chula-WBC-8 (newly introduced dataset) versus Sysmex DI-60's 77.33%
- Ensemble outperforms best individual model on BloodMNIST (99.24% vs 99.04%) and Chula-WBC-8 (93.94% vs 92.69%)
- Performance gap between datasets reflects greater morphological similarity among WBC subtypes in Chula-WBC-8 compared to BloodMNIST's inclusion of RBCs and platelets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Mamba's selective state space modeling enables linear-complexity feature extraction from image patches, making it computationally tractable for resource-constrained clinical deployment compared to quadratic-attention Transformers.
- **Mechanism:** Input images are divided into spatially encoded patches and processed through stacked Mamba blocks with selective scan mechanisms that determine which features propagate forward. Causal convolution blocks reduce spatial dimensions while limiting operations to previous states, progressively capturing longer sequential dependencies in deeper blocks.
- **Core assumption:** The linear complexity of Mamba transfers effectively to 2D vision tasks through patch-based scanning strategies, and this computational efficiency does not critically degrade feature representation quality for WBC morphology.
- **Evidence anchors:**
  - [abstract] "Mamba models, known for their linear complexity, provide a scalable alternative to Transformer-based approaches, making them suitable for deployment in resource-constrained environments."
  - [section II.B] "State Space Models (SSMs) map input sequences to output sequences through a latent state calculated from the previous state and current input, offering an efficient alternative to Transformers by scaling linearly with sequence length and enabling parallel computation."
  - [corpus] Weak direct validation; corpus papers (CellMamba, ms-Mamba) apply Mamba to related domains but do not independently verify the complexity-accuracy tradeoff claim.
- **Break condition:** If input resolution requirements grow such that memory bottlenecks shift from attention computation to patch storage/processing, linear complexity advantages may diminish. If WBC classification relies heavily on long-range spatial dependencies that bidirectional scans cannot approximate efficiently, accuracy may degrade unacceptably.

### Mechanism 2
- **Claim:** Ensemble combination of diverse Mamba architectures reduces variance and improves robustness by leveraging different scanning strategies and feature extraction pathways.
- **Mechanism:** Five Mamba variants with distinct scanning approaches (bidirectional Vim, 2D selective scan in VMamba, standard convolution in MambaVision, local scans in LocalMamba, grouped convolution in MedMamba) generate predictions on holdout data. A meta-learner (MLP) combines these predictions, optimizing integration without inheriting individual model biases.
- **Core assumption:** The selected Mamba variants provide sufficiently diverse predictions that their combination yields non-redundant information, and the meta-learner can effectively learn to weight their contributions without overfitting to the holdout set.
- **Evidence anchors:**
  - [section IV.B] "Ensembles benefit from leveraging diverse base models to maximize variance, combining the predictions of several trained models through a 'meta-learner' to enhance performance."
  - [Table II-III] Ensemble achieves 99.24% on BloodMNIST (vs. 99.04% best individual) and 93.94% on Chula-WBC-8 (vs. 92.69% best individual), though Chula improvement is more modest.
  - [corpus] DCENWCNet validates CNN ensembles for WBC classification with LIME explainability, supporting ensemble efficacy in this domain but not specifically for Mamba architectures.
- **Break condition:** If base models converge to highly correlated predictions (low diversity), ensemble gains will plateau. If the meta-learner overfits despite 5-epoch training limit, holdout-based training may leak information.

### Mechanism 3
- **Claim:** Combining targeted data augmentation with class-weighted loss functions mitigates bias toward majority WBC classes caused by natural subtype prevalence imbalance.
- **Mechanism:** Minority classes (basophil: 93, metamyelocyte: 83) are augmented to reach 500 samples each via rotation, translation, scaling, shearing, color jitter, and Gaussian blur. Weighted cross-entropy assigns loss weights inversely proportional to class frequencies, emphasizing minority class errors during optimization.
- **Core assumption:** The augmentation strategy preserves morphological validity (augmented cells remain diagnostically meaningful), and the weighted loss does not cause the model to overfit to noisy minority class samples.
- **Evidence anchors:**
  - [Table III] On Chula-WBC-8, models with imbalance strategies generally improve (MambaVision: 90.80% → 92.00%; LocalMamba: 90.80% → 92.79%), but ensemble slightly decreases (93.94% → 92.37%), suggesting ensembling may naturally address imbalance.
  - [section IV.C] "To further address class imbalance, we employ a weighted cross-entropy loss, assigning weights inversely proportional to the class frequencies, thus emphasizing minority classes."
  - [corpus] AttriGen addresses annotation challenges in blood cell datasets but does not directly validate augmentation strategies for WBC imbalance.
- **Break condition:** If augmentation introduces artifacts that the model learns instead of genuine morphological features, generalization will suffer. If minority class samples contain labeling noise (expert disagreement), weighted loss may amplify incorrect signals.

## Foundational Learning

- **Concept: State Space Models (SSMs) and Selective Scan**
  - **Why needed here:** Mamba's core innovation is replacing attention with SSMs that compress sequence history into a latent state, updated via selective gating. Understanding this is essential to diagnose why the model may fail on long-range dependencies or why certain patches contribute more to predictions.
  - **Quick check question:** Given a sequence of image patch embeddings, can you explain how the selective scan mechanism decides which information to retain vs. discard, and how this differs fundamentally from Transformer attention?

- **Concept: Ensemble Diversity and Meta-Learning**
  - **Why needed here:** The framework's performance gains depend on combining models that make different errors. Without understanding diversity sources (architecture differences vs. training variance), you cannot debug an underperforming ensemble.
  - **Quick check question:** If all five Mamba variants achieve 95% accuracy but make identical errors on the same 5% of samples, what will the ensemble accuracy be, and why?

- **Concept: Class Imbalance in Medical Imaging**
  - **Why needed here:** WBC datasets naturally reflect physiological prevalence (neutrophils >> basophils). Understanding how imbalance skews loss gradients and evaluation metrics is critical to interpreting reported improvements and avoiding false progress.
  - **Quick check question:** A model achieves 90% accuracy on an imbalanced dataset where one class comprises 90% of samples. What additional metrics should you examine before concluding the model performs well?

## Architecture Onboarding

- **Component map:**
  ```
  Input Image (224×224)
       ↓
  Patch Embedding (varies by variant)
       ↓
  Parallel Mamba Backbone Ensemble (n=5)
       ├── Vim: Bidirectional scan + reverse conv
       ├── VMamba: 2D selective scan (SS2D)
       ├── MambaVision: Standard conv (bidirectional)
       ├── LocalMamba: Local scans + dual-branch attn
       └── MedMamba: Grouped conv + channel shuffle
       ↓ (5 prediction vectors concatenated)
  Meta-Learner (MLP, 5 epochs max)
       ↓
  Final Classification (8 classes)
  ```

- **Critical path:** Input preprocessing (resize to 224×224, normalize) → individual Mamba feature extraction → classification head per model → prediction concatenation → MLP meta-learner → final prediction. The training split partitions into base-model training set and meta-learner holdout set to prevent data leakage.

- **Design tradeoffs:**
  - **Computational cost vs. robustness:** Five models increase training and inference time ~5× but provide ensemble gains; ablation studies should quantify marginal benefit per added model.
  - **Imbalance strategy vs. ensemble:** Results suggest ensembling alone may address imbalance (ensemble performed better without imbalance strategies on Chula-WBC-8), indicating potential redundancy.
  - **Pretrained vs. scratch training:** MedMamba trained from scratch performed poorly (65.83% → 87.04% with imbalance handling), highlighting dependency on pretrained weights where available.

- **Failure signatures:**
  - **SNE/BNE confusion:** Both methods misclassify between segmented and band neutrophils due to transitional cell stages; this is an inherent label ambiguity problem, not a model failure (Figure 3).
  - **Low inter-class variance:** Chula-WBC-8 performance (93.94%) lags BloodMNIST (99.24%) because Chula contains only WBCs with subtle distinctions, while BloodMNIST includes RBCs and platelets with greater morphological variation.
  - **Heatmap focus divergence:** Figure 4 shows LocalMamba focuses more on cell regions than Swin Transformer, but both can fail on the same samples, suggesting certain morphological features are genuinely ambiguous.

- **First 3 experiments:**
  1. **Single-model baseline:** Train each Mamba variant individually on Chula-WBC-8 without ensemble or imbalance strategies. This establishes component contribution and identifies which architecture best captures WBC morphology.
  2. **Ablation on ensemble size:** Compare ensemble performance with n=2, 3, 5 models to quantify marginal accuracy gains vs. computational cost. Determine if a smaller, cheaper ensemble achieves comparable results.
  3. **Imbalance strategy interaction:** Run 2×2 factorial design (ensemble: yes/no × imbalance strategies: yes/no) to clarify whether the observed ensemble performance without imbalance handling is robust or a statistical artifact of the train/test split.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can Mamba-based models effectively support downstream clinical tasks such as automated leukemia detection from WBC classification outputs?
- **Basis in paper:** [explicit] The authors state in the conclusion: "Future research could consider these downstream tasks... potentially enabling an alternate approach to WBC-based diagnostics, such as automated Leukaemia detection."
- **Why unresolved:** This study only evaluated WBC classification in isolation; no downstream diagnostic tasks were tested.
- **What evidence would resolve it:** Experiments applying Mamba-based WBC classifiers as feature extractors or inputs to leukemia detection systems, with evaluation on patient outcome datasets.

### Open Question 2
- **Question:** Why does the ensemble model's accuracy decrease (93.94% → 92.37%) when applying the imbalanced data strategy on Chula-WBC-8, while individual models benefit from it?
- **Basis in paper:** [inferred] Table III shows the ensemble is the only model that performs worse with the imbalanced data strategy, which the authors suggest may be because "ensembling could naturally overcome the imbalance issue," but this hypothesis is untested.
- **Why unresolved:** The mechanism remains unclear—whether ensemble diversity already mitigates imbalance, or whether weighting/augmentation interferes with meta-learner optimization.
- **What evidence would resolve it:** Ablation studies isolating augmentation vs. weighted loss effects on ensemble components and meta-learner training dynamics.

### Open Question 3
- **Question:** Can the model better distinguish transitional WBC stages (e.g., BNE to SNE) that currently cause the most misclassifications?
- **Basis in paper:** [inferred] The confusion matrix analysis notes that "both methods predominantly misclassify between SNE and BNE, often due to some cells being in a transitional stage," yet no targeted solution is proposed.
- **Why unresolved:** The paper treats this as an inherent ambiguity without exploring whether specialized architectures or ordinal regression could capture continuous morphological transitions.
- **What evidence would resolve it:** Experiments with ordinal classification losses, intermediate class labels, or attention mechanisms focused on nuclear morphology features specific to transitional stages.

## Limitations
- Chula-WBC-8 dataset is newly introduced and not clearly available for download, preventing independent validation
- Base model hyperparameters are not specified, relying on "following original papers" which may not be precisely reproducible
- MLP meta-learner architecture (layers, dimensions, activations) is unspecified

## Confidence
- **High confidence:** Mamba's linear complexity advantage over Transformers for WBC classification (supported by theoretical efficiency claims and resource-constrained deployment rationale)
- **Medium confidence:** Ensemble approach improves accuracy on both datasets (observed improvements are statistically present but modest on Chula-WBC-8)
- **Medium confidence:** Imbalance handling strategies are effective (supported by ablation results, though ensemble alone appears sufficient)

## Next Checks
1. Train each Mamba variant individually on Chula-WBC-8 without ensemble or imbalance strategies to establish baseline performance and identify architectural strengths
2. Conduct ablation studies varying ensemble size (n=2, 3, 5) to quantify marginal accuracy gains versus computational overhead
3. Perform 2×2 factorial analysis of ensemble presence versus imbalance strategy presence to clarify whether ensemble naturally handles class imbalance or strategies remain necessary