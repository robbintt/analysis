---
ver: rpa2
title: 'PARSE: LLM Driven Schema Optimization for Reliable Entity Extraction'
arxiv_id: '2510.08623'
source_url: https://arxiv.org/abs/2510.08623
tags:
- schema
- extraction
- schemas
- type
- json
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PARSE addresses the challenge of reliable structured information
  extraction from unstructured text for LLM agent systems by optimizing JSON schemas
  for LLM consumption and implementing reflection-based guardrails. The system features
  ARCHITECT, which iteratively refines schemas through synthetic test data generation
  and automated code generation for backward compatibility, and SCOPE, which performs
  systematic validation with missing attribute checks, grounding verification, and
  rule compliance.
---

# PARSE: LLM Driven Schema Optimization for Reliable Entity Extraction

## Quick Facts
- arXiv ID: 2510.08623
- Source URL: https://arxiv.org/abs/2510.08623
- Reference count: 40
- Key outcome: Up to 64.7% accuracy improvement on SWDE and 92% reduction in extraction errors within first retry

## Executive Summary
PARSE addresses the challenge of reliable structured information extraction from unstructured text for LLM agent systems by optimizing JSON schemas for LLM consumption and implementing reflection-based guardrails. The system features ARCHITECT, which iteratively refines schemas through synthetic test data generation and automated code generation for backward compatibility, and SCOPE, which performs systematic validation with missing attribute checks, grounding verification, and rule compliance. Evaluation on three datasets (Retail-Conv, SGD, SWDE) demonstrates significant improvements in extraction accuracy while maintaining practical latency.

## Method Summary
PARSE implements a two-component framework for reliable entity extraction from unstructured text. The ARCHITECT module iteratively refines JSON schemas by generating synthetic test data, extracting entities using these schemas, and updating them based on extraction performance. The SCOPE module performs systematic validation through missing attribute checks, grounding verification to ensure extracted entities match source text, and rule compliance validation. The framework employs reflection-based guardrails that allow multiple extraction attempts with schema refinements, achieving up to 10% improvement across models while maintaining practical deployment latency.

## Key Results
- Up to 64.7% accuracy improvement on SWDE dataset
- 92% reduction in extraction errors within first retry attempt
- 10% average improvement across models with combined framework

## Why This Works (Mechanism)
The framework succeeds by addressing the fundamental challenge that JSON schemas, while structured for LLM consumption, often fail to capture the nuances of real-world unstructured text. ARCHITECT's iterative refinement process bridges this gap by continuously improving schema definitions based on actual extraction performance, while SCOPE's multi-layered validation ensures extracted entities meet rigorous quality standards before being accepted.

## Foundational Learning
- JSON Schema Optimization: Why needed - LLMs struggle with rigid schema definitions; Quick check - Schema flexibility vs extraction accuracy correlation
- Synthetic Test Data Generation: Why needed - Limited real-world edge cases for training; Quick check - Synthetic data diversity coverage metrics
- Reflection-Based Guardrails: Why needed - Single-pass extraction insufficient for complex texts; Quick check - Retry success rate vs initial pass failure rate
- Grounding Verification: Why needed - Prevent hallucination of extracted entities; Quick check - Text-entity match confidence scores
- Backward Compatibility: Why needed - Schema changes shouldn't break existing systems; Quick check - Automated code generation correctness metrics
- Multi-Attempt Extraction: Why needed - Complex texts require iterative refinement; Quick check - Performance improvement per retry attempt

## Architecture Onboarding

**Component Map:** User Input -> ARCHITECT -> SCOPE -> Output

**Critical Path:** Schema Optimization (ARCHITECT) -> Validation (SCOPE) -> Output Generation

**Design Tradeoffs:** The framework trades computational overhead for accuracy improvements through multiple extraction attempts and schema refinements. While this introduces latency, the practical deployment threshold remains acceptable for most use cases.

**Failure Signatures:** Schema optimization may fail when synthetic test data doesn't represent real-world edge cases; validation may miss subtle grounding errors; reflection guardrails may enter infinite loops with poorly defined schemas.

**First Experiments:**
1. Run baseline extraction on SWDE dataset without any schema optimization to establish performance floor
2. Apply single iteration of ARCHITECT optimization and measure accuracy improvement
3. Enable SCOPE validation and quantify error reduction from guardrail implementation

## Open Questions the Paper Calls Out
None

## Limitations
- Performance improvements based on limited dataset scope and controlled conditions
- Guardrail effectiveness lacks real-world failure mode analysis
- Insufficient characterization of latency and computational costs for practical deployment

## Confidence
- Performance Improvements: Medium - based on limited dataset scope and controlled conditions
- Guardrail Effectiveness: Medium - lacks real-world failure mode analysis
- Practical Deployment Viability: Low - insufficient characterization of latency and computational costs

## Next Checks
1. Conduct field deployment studies across diverse industries with varying schema complexity to validate generalization claims beyond the three evaluated datasets
2. Perform comprehensive latency and resource utilization benchmarking under realistic load conditions to quantify practical deployment overhead
3. Design stress tests with adversarial and out-of-distribution data to evaluate guardrail robustness and schema optimization stability under extreme conditions