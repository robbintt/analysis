---
ver: rpa2
title: Data Augmentation Supporting a Conversational Agent Designed for Smoking Cessation
  Support Groups
arxiv_id: '2512.17092'
source_url: https://arxiv.org/abs/2512.17092
tags:
- posts
- data
- support
- conversational
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of improving intent detection
  for a conversational agent supporting smoking cessation support groups, where low
  engagement and stigma hinder user participation. To overcome insufficient high-quality
  data for training intent classifiers, the authors employ a two-level data augmentation
  strategy: (1) synthetic data generation using GPT-4 for intents with low F1 scores,
  and (2) real data scraping from a related online support community.'
---

# Data Augmentation Supporting a Conversational Agent Designed for Smoking Cessation Support Groups

## Quick Facts
- arXiv ID: 2512.17092
- Source URL: https://arxiv.org/abs/2512.17092
- Authors: Salar Hashemitaheri; Ian Harris
- Reference count: 21
- Primary result: 32% F1 score improvement in intent classification for smoking cessation support group conversational agent through targeted data augmentation

## Executive Summary
This paper addresses the challenge of improving intent detection for a conversational agent supporting smoking cessation support groups, where low engagement and stigma hinder user participation. To overcome insufficient high-quality data for training intent classifiers, the authors employ a two-level data augmentation strategy: (1) synthetic data generation using GPT-4 for intents with low F1 scores, and (2) real data scraping from a related online support community. Human annotators validate the quality of both synthetic and real posts, ensuring relevance and fluency. The augmented dataset is used to retrain the intent classifier, resulting in a 32% improvement in F1 score. Both synthetic and real data augmentation contributed similarly to performance gains. The study demonstrates a replicable framework for enhancing conversational agent performance in data-scarce domains.

## Method Summary
The authors implement a two-level data augmentation approach to improve intent classification for a smoking cessation support group conversational agent. First, they identify underperforming intent classes (F1 < 80%) and generate synthetic posts using GPT-4 based on quality-screened original posts. Second, they scrape real posts from a related online community (Ex-Community) and manually annotate them. Both synthetic and real posts undergo human validation for intent fit, fluency, and non-redundancy. The augmented dataset (original + validated synthetic + validated real) is used to retrain the intent classifier, achieving a 32% F1 improvement.

## Key Results
- 32% overall F1 score improvement in intent classification after targeted data augmentation
- Synthetic and real post augmentation led to similar performance improvements
- 87% of generated synthetic posts deemed high quality by human annotators
- 73% of scraped real posts validated as good quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Targeting data augmentation at underperforming intent classes yields greater performance gains than uniform augmentation.
- Mechanism: The authors identify intents with F1 scores below 80%, then selectively generate synthetic posts only for those classes. This concentrates labeling effort where the model is most confused, addressing class-specific data sparsity rather than wasting resources on already-well-performing intents.
- Core assumption: Low F1 scores are primarily caused by insufficient training examples for that intent, not by inherent ambiguity or overlap with other intents.
- Evidence anchors:
  - [abstract] "we fine-tuned an open source LLM to classify posts...and identify intents with low F1 (precision+recall) scores. Then, for these intents, we generate additional synthetic data"
  - [section 3.1] "we set a cutoff performance threshold of 80 percent...if the F1 score for any intent is below 80 percent, we view that as too low, necessitating data augmentation"
  - [corpus] Related work (Giyahchi 2023) also fine-tuned BERT for intent detection in health support groups, supporting the class-imbalance hypothesis.
- Break condition: If low F1 persists after 2-3 augmentation rounds, the cause is likely intent overlap or poor definition, not data scarcity.

### Mechanism 2
- Claim: Human-in-the-loop validation prevents synthetic noise from degrading model performance.
- Mechanism: Each synthetic and scraped post is reviewed by two trained annotators for intent fit, fluency, and non-redundancy. Disagreements are escalated to an expert. This filters out GPT hallucinations and off-topic content before they enter training data.
- Core assumption: Human annotators can reliably judge intent fit and quality; annotation errors are rare enough not to introduce systematic bias.
- Evidence anchors:
  - [abstract] "average of 87% of the generated synthetic posts deemed high quality by human annotators"
  - [section 3.1.4] "Each synthetic post is independently evaluated by two human annotators...If annotators disagree, they discuss and attempt to reach agreement"
  - [corpus] SynBullying paper similarly uses LLM-generated synthetic conversations but does not report human validation rates, limiting direct comparison.
- Break condition: If inter-annotator agreement drops below ~70%, intent definitions may be too ambiguous for reliable labeling.

### Mechanism 3
- Claim: Combining synthetic and real augmentation sources provides complementary coverage improvements.
- Mechanism: Synthetic posts (from GPT-4) expand existing intent classes with controlled variation. Real scraped posts (from Ex-Community) introduce authentic language patterns and edge cases the generator might miss. Together they address different gaps in the original dataset.
- Core assumption: The scraped community shares sufficiently similar intent distributions and language patterns; domain shift is minimal enough that real posts transfer without extensive relabeling.
- Evidence anchors:
  - [abstract] "Synthetic and real post augmentation led to similar performance improvements"
  - [section 3.2] "we scrape over 10,000 posts from the Ex-Community...73% were validated as good quality"
  - [corpus] Corpus lacks direct evidence on synthetic vs. real augmentation comparisons in health domains; this finding would benefit from replication.
- Break condition: If real posts require >40% rejection rate or significant relabeling effort, the source domain may be too dissimilar.

## Foundational Learning

- Concept: **Intent Classification for Conversational Agents**
  - Why needed here: The entire augmentation pipeline targets intent detection; without understanding what intents are and how they map to responses, the augmentation strategy makes little sense.
  - Quick check question: Can you explain why a post like "I keep dreaming about smoking" might be classified differently from "I had a dream last night"?

- Concept: **F1 Score and Class-Imbalanced Evaluation**
  - Why needed here: The paper uses F1 < 80% as the trigger for augmentation; understanding why F1 matters more than accuracy for imbalanced multi-class problems is essential.
  - Quick check question: If a model achieves 95% accuracy but F1 of 60% on a specific intent, what does that suggest about the class distribution?

- Concept: **Prompt Engineering for Synthetic Data Generation**
  - Why needed here: The quality of synthetic posts depends directly on how prompts are crafted from original posts; poor prompts yield generic or off-target outputs.
  - Quick check question: What prompt would you write to generate varied posts about "nicotine replacement therapy side effects" while avoiding repetitive outputs?

## Architecture Onboarding

-