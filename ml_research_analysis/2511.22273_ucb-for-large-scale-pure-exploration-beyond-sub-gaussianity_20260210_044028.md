---
ver: rpa2
title: 'UCB for Large-Scale Pure Exploration: Beyond Sub-Gaussianity'
arxiv_id: '2511.22273'
source_url: https://arxiv.org/abs/2511.22273
tags:
- uni00000013
- uni00000008
- sample
- uni00000048
- uni00000036
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies pure exploration in large-scale problems with
  non-sub-Gaussian (including heavy-tailed) distributions. Traditional approaches
  rely on Gaussian or sub-Gaussian assumptions, which limit applicability in settings
  where such assumptions fail.
---

# UCB for Large-Scale Pure Exploration: Beyond Sub-Gaussianity

## Quick Facts
- arXiv ID: 2511.22273
- Source URL: https://arxiv.org/abs/2511.22273
- Reference count: 40
- This paper studies pure exploration in large-scale problems with non-sub-Gaussian distributions using UCB algorithms and proves sample optimality.

## Executive Summary
This paper addresses pure exploration in large-scale multi-armed bandit problems when the reward distributions are non-sub-Gaussian, including heavy-tailed settings. Traditional UCB algorithms rely on sub-Gaussian assumptions, which limit their applicability in general settings. The authors introduce a meta-UCB algorithm that works under more general distributional assumptions by requiring only that the bonus function vanishes asymptotically and the selection rule chooses the alternative with the largest sample size upon stopping.

The key contribution is establishing that this meta-UCB approach achieves sample optimality - maintaining non-zero probability of correct selection while keeping total sampling budget linear in the number of alternatives - under two non-sub-Gaussian settings: (1) location-scale structure with bounded variance, and (2) general distributions with bounded absolute moment of order q>3. The authors derive distribution-free lower bounds on correct selection probability using a boundary-crossing perspective and extend their analysis beyond the traditional indifference-zone formulation to cases where mean gaps shrink at controlled rates.

## Method Summary
The authors propose a meta-UCB algorithm that decouples the UCB definition from specific distributional assumptions. The algorithm defines UCB values as sample means plus bonus terms that depend only on the sample size of each alternative, not on other alternatives' statistics. A key requirement is that the bonus function must vanish asymptotically. The selection rule chooses the alternative with the largest sample size upon stopping, which differs from traditional UCB approaches that select based on maximum UCB value.

The analysis framework treats the best alternative's UCB process as a boundary and derives distribution-free lower bounds on correct selection probability. For the location-scale setting with bounded variance, the authors leverage concentration inequalities that don't require sub-Gaussianity. For the general bounded absolute moment case with q>3, they use moment-based concentration results. The framework extends beyond indifference-zone formulation by showing that sample optimality can be achieved when mean gaps shrink at controlled rates, provided the bonus function satisfies a confidence sequence condition.

## Key Results
- The meta-UCB algorithm achieves sample optimality (non-zero PCS with linear total budget) under location-scale structure with bounded variance
- Sample optimality is also achieved for general distributions with bounded absolute moment of order q>3
- Traditional UCB1 fails to achieve sample optimality due to uniform budget allocation across alternatives
- The analysis extends beyond indifference-zone formulation to cases with shrinking mean gaps at controlled rates

## Why This Works (Mechanism)
The success of the meta-UCB approach stems from its decoupling of the bonus function from distributional assumptions and its adaptive sampling strategy. By requiring only that the bonus function vanishes asymptotically rather than imposing specific concentration properties, the algorithm can work with a broader class of distributions. The selection rule that chooses the alternative with the largest sample size ensures efficient allocation of sampling budget to promising alternatives, avoiding the uniform allocation that causes UCB1 to fail. The boundary-crossing analysis provides a unified framework for deriving lower bounds on correct selection probability that applies across different distributional settings.

## Foundational Learning
- **Upper Confidence Bound (UCB) algorithms**: These define upper confidence values as sample means plus bonus terms. Why needed: They provide a principled way to balance exploration and exploitation in bandit problems. Quick check: Verify that UCB values properly shrink as sample sizes increase.
- **Pure exploration vs. regret minimization**: Pure exploration focuses on identifying the best alternative with high probability rather than minimizing cumulative regret. Why needed: This setting has different optimality criteria and algorithm design considerations. Quick check: Confirm the algorithm's stopping criterion ensures correct selection with high probability.
- **Non-sub-Gaussian concentration inequalities**: These provide probabilistic bounds without assuming light-tailed distributions. Why needed: Heavy-tailed distributions violate standard sub-Gaussian assumptions. Quick check: Verify concentration bounds hold for the specific non-sub-Gaussian settings considered.
- **Boundary-crossing perspective**: This treats the best alternative's UCB process as a boundary for analyzing correct selection probability. Why needed: It provides a unified framework for deriving distribution-free lower bounds. Quick check: Confirm the boundary-crossing analysis correctly captures the probability of correct selection.
- **Confidence sequences**: These are sequences of confidence intervals that hold uniformly over time. Why needed: They ensure the bonus function provides valid uncertainty quantification throughout the algorithm's execution. Quick check: Verify the bonus function satisfies the required confidence sequence condition.
- **Sample optimality**: This refers to achieving non-zero correct selection probability with total sampling budget linear in the number of alternatives. Why needed: It characterizes the fundamental trade-off between accuracy and efficiency in large-scale problems. Quick check: Confirm the total sampling budget scales linearly with the number of alternatives.

## Architecture Onboarding

Component map: Meta-UCB algorithm -> Bonus function computation -> Sample mean calculation -> Stopping rule -> Selection rule

Critical path: The algorithm iteratively collects samples, computes UCB values using the bonus function, checks stopping conditions, and upon stopping, selects the alternative with the largest sample size. The bonus function computation and stopping rule evaluation are the most computationally intensive components.

Design tradeoffs: The decoupling of bonus function from distributional assumptions provides generality but requires careful design of the bonus function to ensure confidence sequence properties. The selection rule prioritizes sample size over UCB value, which differs from traditional approaches and may seem counterintuitive but is necessary for sample optimality under non-sub-Gaussian settings.

Failure signatures: Algorithm failure manifests as either (1) incorrect selection with high probability, or (2) excessive sampling budget that grows super-linearly with the number of alternatives. The numerical experiments show that UCB1 fails due to uniform budget allocation, suggesting that poor bonus function design or inappropriate selection rules can lead to sample inefficiency.

First experiments:
1. Implement the meta-UCB algorithm with different bonus functions (e.g., empirical Bernstein, Maurer-Pontil) to test their impact on sample optimality
2. Test the algorithm on synthetic data with known heavy-tailed distributions to verify theoretical guarantees
3. Compare the meta-UCB approach against Track-and-Stop and other non-UCB pure exploration algorithms in non-sub-Gaussian settings

## Open Questions the Paper Calls Out
None

## Limitations
- The tightness of the derived lower bounds on correct selection probability is uncertain and may not be achievable by the meta-UCB algorithm
- The extension beyond indifference-zone formulation assumes specific mean gap decay rates without characterizing their optimality
- The analysis does not fully explore alternative selection rules and their impact on sample efficiency

## Confidence
High: Location-scale setting with bounded variance
Medium: General bounded absolute moment case with q>3
Medium: Sample optimality claims across all non-sub-Gaussian settings

## Next Checks
1. Test the meta-UCB algorithm with alternative bonus functions that do not satisfy the confidence sequence condition to quantify the impact on sample optimality
2. Conduct experiments varying the mean gap decay rates beyond the specified bounds to identify sharp thresholds for maintaining sample optimality
3. Compare the meta-UCB approach against non-UCB pure exploration algorithms (e.g., Track-and-Stop) in non-sub-Gaussian settings to assess relative efficiency