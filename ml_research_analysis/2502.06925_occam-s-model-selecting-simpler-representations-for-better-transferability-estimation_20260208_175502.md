---
ver: rpa2
title: 'Occam''s model: Selecting simpler representations for better transferability
  estimation'
arxiv_id: '2502.06925'
source_url: https://arxiv.org/abs/2502.06925
tags:
- transferability
- dataset
- concept
- metrics
- estimation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces two novel transferability estimation metrics,
  INT and Concept Variance, based on the idea that simpler representations with clearer
  class separations lead to better fine-tuning performance. INT measures pairwise
  normalized interclass distances in embedding space, while Concept Variance assesses
  the irregularity of class label distributions across feature space.
---

# Occam's model: Selecting simpler representations for better transferability estimation

## Quick Facts
- arXiv ID: 2502.06925
- Source URL: https://arxiv.org/abs/2502.06925
- Authors: Prabhant Singh; Sibylle Hess; Joaquin Vanschoren
- Reference count: 40
- Primary result: Introduces INT and Concept Variance metrics for transferability estimation, achieving up to 32% improvement in Kendall's tau over state-of-the-art methods

## Executive Summary
This paper addresses the problem of source-independent transferability estimation (SITE) - predicting which pre-trained model will perform best on a target dataset without access to source training data. The authors propose two novel metrics, INT (measuring normalized interclass distances) and Concept Variance (measuring label distribution irregularity), based on the hypothesis that simpler, more linearly separable representations transfer better. Both metrics are computationally efficient and demonstrate superior ranking accuracy compared to existing methods across diverse image classification tasks, with INT showing particular strength in overall performance and Concept Variance excelling in limited-data scenarios.

## Method Summary
The authors introduce two transferability estimation metrics that operate on pre-trained model embeddings of target data. INT computes normalized pairwise distances between samples from different classes in embedding space, measuring how well-separated classes are. Concept Variance measures the standard deviation of local concept variation, quantifying how consistently class labels change across embedding space. Both metrics assume that representations closer to a simple, class-separable structure require fewer gradient steps during fine-tuning. The methods run in seconds, requiring only a forward pass through each pre-trained model and simple distance computations, making them practical for model zoo selection.

## Key Results
- INT achieves up to 32% improvement in weighted Kendall's tau (τω) compared to state-of-the-art transferability metrics
- Concept Variance shows strongest performance in limited-data scenarios, particularly on DIBaS (τω=0.87) and Flowers (τω=0.73)
- Both metrics are computationally efficient, running significantly faster than competing approaches while maintaining or improving ranking accuracy
- INT shows consistent performance across diverse datasets and model architectures, with average τω=0.70 across all evaluations

## Why This Works (Mechanism)

### Mechanism 1: Normalized Interclass Distance
- **Claim:** Embeddings with larger normalized interclass distances are easier to fine-tune.
- **Core assumption:** Euclidean distance in pre-trained embedding space correlates with fine-tuning difficulty.
- **Evidence:** Abstract states "simpler representations with clearer class separations lead to better fine-tuning performance"; Section 3.2 shows loss minimization requires embedded points far from other class centers.
- **Break condition:** Overestimates transferability when classes require non-linear boundaries or in very high dimensions (Table 5 shows degradation with larger networks).

### Mechanism 2: Concept Variance
- **Claim:** Standard deviation of local concept variation predicts transferability, especially in limited-data regimes.
- **Core assumption:** Label smoothness in local neighborhoods correlates with fine-tuning efficiency; variance in this smoothness matters more than average smoothness.
- **Evidence:** Abstract mentions "irregularity of class label distributions"; Section 3.3 explains higher standard deviation indicates structured representations; Table 2 shows strong limited-data performance.
- **Break condition:** Sensitive to class imbalance and requires α hyperparameter tuning (optimal range 2-5).

### Mechanism 3: Representational Simplicity
- **Claim:** Representational simplicity reduces gradient descent steps needed during fine-tuning.
- **Core assumption:** Fine-tuning trajectory length correlates with initial embedding's departure from neural collapse structure.
- **Evidence:** Section 3.2 argues neural collapse is a byproduct of loss function properties; Section 3.1 hypothesizes embeddings with simple structure fine-tune more easily.
- **Break condition:** Assumes cross-entropy fine-tuning; may not generalize to other transfer methods.

## Foundational Learning

- **Concept: Kendall's tau (τ) and weighted Kendall's tau (τω)**
  - Why needed: Primary evaluation metric measuring ranking correlation between predicted transferability scores and actual fine-tuned performance.
  - Quick check: If metric A ranks models [3,1,2,4] and true performance is [3,2,1,4], would τ be positive or negative? (Yes, τ would be positive as the relative order of the top model is correct)

- **Concept: Source-Independent Transferability Estimation (SITE)**
  - Why needed: The problem setting where you have pre-trained model and target data but NOT original source training data.
  - Quick check: Why would source-dependent metrics (SDTE) be impractical for selecting from HuggingFace models? (Because source training data is rarely available for models in public model zoos)

- **Concept: Neural Collapse**
  - Why needed: Theoretical motivation for INT; describes phenomenon where within-class embeddings collapse toward class mean and class means become equiangular.
  - Quick check: If embeddings from a pre-trained model already exhibit neural collapse on your target classes, would you expect high or low INT scores? (High INT scores, as classes would be well-separated)

## Architecture Onboarding

- **Component map:**
  ```
  Target Dataset (images + labels)
        ↓
  [Forward Pass] Pre-trained Model Zoo → Embeddings (N × d)
        ↓
  [INT Branch]                    [Concept Variance Branch]
  Pairwise interclass distances    Distance matrix D → weights w
  Normalize by class sizes         Compute per-sample v(xi)
  Sum across class pairs           Return std(v)
        ↓                                    ↓
  INT score                         CV score
        ↓                                    ↓
        [Rank models by score(s)]
  ```

- **Critical path:**
  1. Extract embeddings: Single forward pass per model (no gradients needed)
  2. Compute INT: O(k² × N² × d) where k=classes, N=samples, d=embedding dim
  3. Compute Concept Variance: O(N² × d)
  4. Rank models by INT (or combined INT+CV for limited-data scenarios)

- **Design tradeoffs:**
  - INT vs. Concept Variance: INT more robust overall (avg τω=0.70 vs 0.42), but CV stronger in limited-data regimes
  - Distance metric: Euclidean outperforms cosine, Manhattan, squared Euclidean (Table 6)
  - α for CV: Default 2.0 works reasonably; optimal range 2-5 (Figure 3)
  - Combination strategy: Simple sum INT+CV works; paper doesn't explore learned combinations

- **Failure signatures:**
  - Large embedding dimensions: All metrics degrade (Table 5 shows negative τ on some datasets with larger models)
  - Very imbalanced classes: INT normalization may not compensate
  - Out-of-distribution target domains: If pre-trained features are irrelevant, neither metric predicts well
  - Negative τ values on DIBaS and Cars with larger networks indicate poorly-performing models (10-35% accuracy) destabilizing rankings

- **First 3 experiments:**
  1. Reproduce INT on a single domain: Take 3-5 pre-trained Vision Transformers from timm, extract embeddings on Flowers, compute INT, fine-tune all models, verify ranking correlation. Expected: ~1-2 seconds for INT computation.
  2. Ablate distance metric: Compare Euclidean vs. Cosine vs. Manhattan for INT on same setup. Paper shows Euclidean optimal; verify this holds for your model zoo.
  3. Limited-data stress test: Subset target data to 40 samples per class, compare INT vs. CV vs. INT+CV. Paper suggests CV becomes more competitive; verify the combination strategy.

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical grounding relies on neural collapse behavior that may not uniformly exist across all pre-trained models and target domains
- Euclidean distance assumption may break down for datasets requiring non-linear decision boundaries
- Concept Variance is sensitive to the α hyperparameter (optimal range 2-5) without systematic hyperparameter search

## Confidence
- **High confidence:** INT metric computational efficiency and ranking accuracy improvements (extensive Table 2 results showing consistent τω gains)
- **Medium confidence:** Concept Variance performance claims (stronger in limited-data regimes but with more variable results across datasets)
- **Low confidence:** Theoretical connection between neural collapse and transferability prediction (largely conceptual with limited empirical validation)

## Next Checks
1. **Domain shift robustness test:** Apply INT and Concept Variance to target datasets intentionally out-of-distribution from pre-trained model domains (e.g., medical imaging with general vision models) to assess breakdown conditions.
2. **Fine-tuning method generalization:** Validate whether INT rankings transfer to non-cross-entropy fine-tuning scenarios (adapter-based methods, contrastive learning objectives) to test mechanism generality.
3. **Dimensionality sensitivity analysis:** Systematically vary embedding dimensions (via feature selection or dimensionality reduction) on INT and Concept Variance scores to quantify performance degradation observed in Table 5.