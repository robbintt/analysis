---
ver: rpa2
title: Learning to Detect Multi-class Anomalies with Just One Normal Image Prompt
arxiv_id: '2505.09264'
source_url: https://arxiv.org/abs/2505.09264
tags:
- anomaly
- normal
- detection
- prompt
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes OneNIP, a unified anomaly detection method
  that uses a normal image as a global visual prompt to guide feature reconstruction.
  The approach leverages bidirectional cross-attention between target features and
  the normal image prompt, along with pseudo-anomalous samples for feature restoration
  and a supervised refiner for accurate pixel-level segmentation.
---

# Learning to Detect Multi-class Anomalies with Just One Normal Image Prompt

## Quick Facts
- arXiv ID: 2505.09264
- Source URL: https://arxiv.org/abs/2505.09264
- Reference count: 40
- OneNIP achieves 97.9% I-ROC and 63.7% P-PR on MVTec, and 92.6% I-ROC and 56.8% P-PR on BTAD

## Executive Summary
This paper proposes OneNIP, a unified anomaly detection method that leverages a single normal image as a global visual prompt to guide feature reconstruction. The approach uses bidirectional cross-attention between target features and the normal image prompt, along with pseudo-anomalous samples for feature restoration and a supervised refiner for accurate pixel-level segmentation. OneNIP significantly outperforms state-of-the-art methods on MVTec, BTAD, and VisA benchmarks, demonstrating superior performance in both image-level classification and pixel-level anomaly segmentation under unified settings.

## Method Summary
OneNIP is a reconstruction-based anomaly detection framework that uses a single normal image as a prompt to guide the reconstruction of target images. The architecture consists of a feature extractor, a self-attention encoder, a bidirectional cross-attention decoder, a restoration stream for training, and a supervised refiner for pixel-level segmentation. During training, pseudo-anomalous samples are generated to restore features and train the refiner. At inference, the model calculates reconstruction error maps and refines them into final anomaly segmentation maps.

## Key Results
- Achieves 97.9% I-ROC and 63.7% P-PR on MVTec AD benchmark
- Achieves 92.6% I-ROC and 56.8% P-PR on BTAD benchmark
- Outperforms state-of-the-art methods including UniAD, PaDiM, and DRAEM across multiple datasets

## Why This Works (Mechanism)
The bidirectional cross-attention decoder allows the target image features to query information from the normal image prompt and vice versa, dynamically fusing them. This prevents the model from simply reconstructing target features using their own context (identity shortcut problem). The restoration stream forces the model to learn feature restoration from pseudo-anomalous samples, while the supervised refiner converts low-resolution error maps into high-resolution segmentation maps. The normal image prompt provides a global reference that helps the model distinguish anomalies from normal variations.

## Foundational Learning
- **Self-Attention & Cross-Attention in Transformers**
  - Why needed here: The entire architecture is built on transformers. The encoder uses self-attention to model context, and the decoder uses cross-attention to allow the "target image features" to query information from the "normal image prompt."
  - Quick check question: Can you explain how cross-attention allows the model to query the prompt features using the target features?

- **Reconstruction-Based Anomaly Detection**
  - Why needed here: The core premise is that the model should be good at reconstructing normal features and bad at reconstructing anomalies.
  - Quick check question: What is the "identity shortcut" problem in reconstruction models, and how does this paper's prompt approach aim to solve it?

- **Pseudo-Anomaly Generation (e.g., CutPaste, DRAEM)**
  - Why needed here: The paper uses these techniques to create synthetic training data for both the "restoration" stream and the "supervised refiner."
  - Quick check question: What is a CutPaste augmentation, and how does it provide a pixel-level mask for training the refiner?

## Architecture Onboarding
- Component map:
    1. Feature Extractor (Backbone): Extracts feature maps from target and prompt images
    2. Self-Attention Encoder: Models contextual relationships within features
    3. Bidirectional Cross-Attention Decoder: Performs cross-attention in both directions to fuse features
    4. Restoration Stream: Training-only pathway for feature restoration from pseudo-anomalies
    5. Supervised Refiner: Lightweight decoder that upsamples error maps to final segmentation

- Critical path:
    Inference: Target Image & Prompt Image -> Backbone -> Encoder -> Bidirectional Decoder -> Calculate Error Map -> Refiner
    Training: Adds Pseudo-Anomaly Image -> Backbone -> Encoder -> Decoder (Restoration) -> Calculate Restoration Loss

- Design tradeoffs:
    - Single Prompt vs. Memory Bank: Simpler and more memory-efficient but potentially less robust
    - Supervised Refiner: Adds complexity and depends on synthetic anomaly quality
    - Bidirectional vs. Unidirectional Attention: Bidirectional decoder outperforms simpler alternatives

- Failure signatures:
    - Wrong Prompt: Using incorrect class prompts causes dramatic performance drops
    - Camouflaged Anomalies: Subtle anomalies may still be difficult to detect
    - Low-Resolution Errors: Refiner is critical for good pixel-level performance

- First 3 experiments:
    1. Ablation on Prompt Strategy: Compare no prompt, static prompt, and full bidirectional dynamic prompt
    2. Refiner Ablation: Evaluate performance with and without the supervised refiner module
    3. Pseudo-Anomaly Sensitivity: Test performance variation with different pseudo-anomaly generation methods

## Open Questions the Paper Calls Out
### Open Question 1
- **Question:** How can the architecture of the bidirectional decoder and supervised refiner be optimized beyond their current "simple" designs to maximize pixel-level segmentation accuracy?
- **Basis in paper:** [explicit] The authors state in the Conclusion that the "bidirectional decoder and supervised refiner are only simply designed, leaving ample room for improvement."
- **Why unresolved:** The current study prioritized validating the core concept of using a normal image prompt over engineering complex architectural components.
- **What evidence would resolve it:** Comparative studies integrating advanced attention mechanisms or multi-scale refinement blocks into the decoder and refiner, demonstrating improved P-PR scores.

### Open Question 2
- **Question:** Can the additional training overhead introduced by the unsupervised restoration stream be reduced or eliminated while maintaining its effectiveness in guiding the normal image prompt?
- **Basis in paper:** [explicit] The paper lists as a limitation that the "restoration stream introduces additional training costs."
- **Why unresolved:** The restoration stream is currently necessary to force the model to rely on the prompt rather than just contextual information.
- **What evidence would resolve it:** A modified training objective that achieves feature restoration without a separate auxiliary network.

### Open Question 3
- **Question:** How can the framework be made robust to prompt retrieval failures or high intra-class variance where a single random normal prompt is insufficient?
- **Basis in paper:** [inferred] The ablation study shows drastic performance drops when using incorrect class prompts.
- **Why unresolved:** The method assumes a correct class prompt is available or retrievable via feature similarity.
- **What evidence would resolve it:** Analysis of performance using "worst-case" prompts within the same class, or introduction of a prompt attention/selection mechanism.

## Limitations
- The bidirectional cross-attention decoder introduces significant computational overhead
- Performance is sensitive to the quality and representativeness of the single prompt image
- Supervised refiner's effectiveness depends on the quality of synthetic pseudo-anomalies
- Computational complexity and scalability to high-resolution imagery are not explicitly addressed

## Confidence
**High Confidence:** Architectural contributions and benchmark results are clearly described and supported by ablation studies.

**Medium Confidence:** Claims of "unified" settings require further validation across all tested datasets without class-specific fine-tuning.

**Low Confidence:** Performance on BTAD lacks qualitative analysis of specific defect types; camouflaged anomaly handling is mentioned but not empirically validated.

## Next Checks
1. **Prompt Robustness Test:** Systematically evaluate performance degradation when using prompts from different classes or when the prompt image is corrupted/noisy.

2. **Real Defect Generalization:** Validate the model on industrial datasets with confirmed real defect annotations beyond the synthetic pseudo-anomalies used in training.

3. **Computational Profiling:** Measure inference time and memory consumption across different input resolutions and batch sizes, comparing against simpler reconstruction baselines.