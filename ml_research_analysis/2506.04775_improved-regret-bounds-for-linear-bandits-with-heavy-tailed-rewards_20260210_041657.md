---
ver: rpa2
title: Improved Regret Bounds for Linear Bandits with Heavy-Tailed Rewards
arxiv_id: '2506.04775'
source_url: https://arxiv.org/abs/2506.04775
tags:
- bound
- regret
- lower
- bounds
- heavy-tailed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work addresses stochastic linear bandits with heavy-tailed\
  \ rewards, where the rewards have finite (1+\u03B5)-absolute central moments. The\
  \ authors improve both upper and lower regret bounds compared to prior work."
---

# Improved Regret Bounds for Linear Bandits with Heavy-Tailed Rewards

## Quick Facts
- arXiv ID: 2506.04775
- Source URL: https://arxiv.org/abs/2506.04775
- Reference count: 40
- One-line primary result: Improved regret bounds for stochastic linear bandits with heavy-tailed rewards using geometry-aware experimental design and truncation

## Executive Summary
This work addresses stochastic linear bandits where rewards have finite (1+ε)-absolute central moments, extending beyond the typical finite-variance setting. The authors introduce a new elimination-based algorithm guided by experimental design that achieves improved regret bounds compared to prior work. Their approach combines robust mean estimation via truncation with geometry-aware sampling to handle the heavy-tailed noise effectively.

## Method Summary
The authors propose the MED-PE algorithm, which operates in phases with geometrically increasing budgets. In each phase, it solves for an optimal sampling distribution that minimizes the (1+ε)-moment of the estimation error, then samples actions according to this distribution. The algorithm uses truncated empirical means to robustly estimate rewards while eliminating suboptimal arms based on confidence intervals. The method handles infinite-dimensional settings via the kernel trick and provides dimension-dependent bounds that improve upon existing results for specific geometries.

## Key Results
- Achieves regret of O(d^(1+3ε)/(2(1+ε)) T^(1/(1+ε))), improving dependence on dimension d for all ε∈(0,1)
- Proves lower bound of Ω(d^(2ε)/(1+ε) T^(1/(1+ε))), strictly improving upon multi-armed bandit rates
- Shows action set dependent bounds, with further dimension reduction possible for l_p-norm balls where p≤1+ε
- Extends to kernelized settings, establishing first sublinear bounds for Matérn kernel across all ε∈(0,1]

## Why This Works (Mechanism)

### Mechanism 1: Geometry-Aware Experimental Design
- Claim: Optimizing the sampling distribution minimizes the $(1+\epsilon)$-moment of the estimation error
- Mechanism: The algorithm solves for a distribution $\lambda$ that minimizes $M_{1+\epsilon}$, a functional representing the maximum $(1+\epsilon)$-absolute moment of the error vector
- Core assumption: The action set geometry allows for a design where the worst-case directional moment can be constrained
- Evidence anchors:
  - [abstract] "...elimination-based algorithm guided by experimental design..."
  - [section 3] "Design a sampling distribution... that minimizes the (1+epsilon)-absolute moment... in the worst-case direction..."
  - [corpus] Related work [2508.13679] confirms the significance of geometry in heavy-tailed linear bandits

### Mechanism 2: Robust Mean Estimation via Truncation
- Claim: Truncating extreme reward values allows the estimator to concentrate around the true mean even when variance is infinite
- Mechanism: The algorithm uses a "truncated empirical mean" which discards samples exceeding a threshold based on the moment bound $\upsilon$
- Core assumption: Rewards have a finite $(1+\epsilon)$-absolute central moment bounded by $\upsilon$
- Evidence anchors:
  - [section 3] "We adopt the truncated mean for concreteness..."
  - [appendix a.1] "Lemma 3... satisfies... |bµ - µ| <= ... using the truncated empirical mean."
  - [corpus] [2503.00419] discusses Huber regression as an alternative

### Mechanism 3: Phased Elimination
- Claim: Allocating samples in phases with geometrically increasing budgets ensures that suboptimal arms are eliminated before cumulative regret becomes linear
- Mechanism: In phase $\ell$, the algorithm samples active arms based on the design $\lambda^*$. It computes a robust confidence interval and eliminates arms with rewards significantly below the estimated optimum
- Core assumption: The underlying parameter $\theta^*$ and optimal reward are bounded
- Evidence anchors:
  - [algorithm 1] "Eliminate suboptimal arms from the active set."
  - [section 3] "This process is repeated... until... a single arm remains."

## Foundational Learning

### Concept: Stochastic Linear Bandits
- Why needed here: The core framework; you must understand how $y_t = \langle x_t, \theta^* \rangle + \eta_t$ relates actions (vectors) to rewards (scalars)
- Quick check question: If I choose action $x$, what is the expected reward and how does the noise term affect it?

### Concept: Moments of Distributions (Heavy-Tailed)
- Why needed here: The paper distinguishes between finite variance ($\epsilon=1$) and finite $(1+\epsilon)$-moments
- Quick check question: Does a distribution with $\epsilon=0.5$ have a finite standard deviation? (Answer: No)

### Concept: Experimental Design (G-optimality)
- Why needed here: The algorithm builds on optimal design theory to choose where to sample
- Quick check question: Why distribute samples across directions rather than just pulling the best-looking arm?

## Architecture Onboarding

### Component map:
Design Optimizer -> Sampler -> Robust Estimator -> Eliminator

### Critical path:
The calculation of the design $\lambda^*$ is the most computationally distinct step. You must ensure the solver handles the specific objective `M_{1+\epsilon}` correctly.

### Design tradeoffs:
- **Truncation Threshold:** Too low $\rightarrow$ high bias (discard valid data). Too high $\rightarrow$ high variance (outliers leak in)
- **Design Granularity:** Updating the design every phase is costly but precise; infrequent updates save compute but may sample suboptimal regions longer

### Failure signatures:
- **Linear Regret:** If `tau_\ell` is too small or the truncation threshold is wrong, the algorithm fails to eliminate bad arms
- **Numerical Instability:** `A(gamma)(lambda)` inversion can be unstable if the design places zero probability on some dimensions

### First 3 experiments:
1. **Sanity Check (Synthetic):** Implement on a 2D unit ball with $\epsilon=1$ (Gaussian noise) to verify recovery of known optimal bounds ($\sqrt{T}$)
2. **Heavy-Tail Stress Test:** Run on synthetic data with Pareto-distributed noise ($\epsilon=0.5$). Compare "Truncated Mean" vs "Standard Mean" to validate the robustness claim
3. **Dimension Scaling:** Fix $T$ and vary $d$. Plot Regret vs $d$ to verify the claimed $d^{\frac{1+3\epsilon}{2(1+\epsilon)}}$ scaling (Corollary 1)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the minimax regret gap between the upper bound $\tilde{O}(d^{\frac{1+3\varepsilon}{2(1+\varepsilon)}} T^{\frac{1}{1+\varepsilon}})$ and the lower bound $\Omega(d^{\frac{2\varepsilon}{1+\varepsilon}} T^{\frac{1}{1+\varepsilon}})$ be closed for general action sets?
- Basis in paper: [explicit] The conclusion states the authors "conjecture that this [the lower bound rate] is the correct minimax rate"
- Why unresolved: While the geometry-dependent bounds recover the lower bound dimension dependence in specific cases, the upper bound for general action sets remains strictly looser in its dependence on dimension $d$
- What evidence would resolve it: An algorithm achieving $\tilde{O}(d^{\frac{2\varepsilon}{1+\varepsilon}} T^{\frac{1}{1+\varepsilon}})$ regret or a revised lower bound matching the current upper bound's dimension exponent

### Open Question 2
- Question: Is there a tight regret bound for heavy-tailed kernel bandits using the Matérn kernel that bridges the gap shown in Figure 2?
- Basis in paper: [explicit] Appendix C.3 notes that "gaps still remain between the upper and lower bounds" for the kernelized setting
- Why unresolved: The paper's upper bound for the Matérn kernel (Corollary 4) improves on prior work but does not match the existing lower bound from [RCG19]
- What evidence would resolve it: Deriving an upper bound that aligns with the $\Omega(T^{\frac{\nu+d\epsilon}{\nu(1+\epsilon)+d\epsilon}})$ scaling or proving a new lower bound consistent with the paper's $\tilde{O}(T^{\frac{1-\epsilon}{1+\epsilon}\frac{2\nu}{2\nu+d}})$ result

### Open Question 3
- Question: What is the optimal dimension dependence for finite action sets of size $n$?
- Basis in paper: [inferred] Table 1 and Theorem 2 show a gap between the upper bound $\tilde{O}(\sqrt{d} (\log n)^{\dots})$ and lower bound $\tilde{\Omega}(d^{\dots} (\log n)^{\dots})$
- Why unresolved: The lower bound construction involves partitioning dimensions into groups, potentially leaving a gap regarding the true information-theoretic difficulty
- What evidence would resolve it: An algorithm with regret scaling as $\tilde{O}(d^{\frac{\epsilon}{1+\epsilon}} \dots)$ for finite action sets, or a lower bound construction that forces the $\sqrt{d}$ dependence

## Limitations

- The algorithm relies heavily on the action set having "nice" geometry that allows the experimental design to keep the moment bound υ constant (independent of dimension)
- The dependence on correctly specifying the moment bound υ is critical - mis-specification could lead to poor performance
- The extension to kernelized settings, while theoretically interesting, introduces additional complexities not fully addressed in the main text

## Confidence

- **Upper Regret Bound (O(d^(1+3ε)/(2(1+ε)) T^(1/(1+ε))))**: Medium-High confidence - The bound is derived through a novel combination of techniques and mathematical derivation appears sound, though relies on specific geometric properties
- **Lower Bound (Ω(d^(2ε)/(1+ε) T^(1/(1+ε))))**: Medium confidence - While derived from established information-theoretic arguments, the claim of "strictly improving" upon multi-armed bandit rates needs empirical validation
- **Kernel Trick Extension**: Low-Medium confidence - Theoretically interesting but the claim of being "first sublinear bounds for all ε ∈ (0,1]" requires careful verification due to additional complexities

## Next Checks

1. **Robustness to Moment Bound Misspecification**: Implement the algorithm with incorrect (overly conservative or aggressive) values of υ and measure the degradation in performance across different ε values

2. **Action Set Geometry Stress Test**: Test the algorithm on action sets with less "nice" geometry (e.g., irregular polytopes, high-dimensional spheres) to verify the assumption that υ remains constant

3. **Kernel Extension Verification**: Implement the Matérn kernel extension on a concrete problem (e.g., kernelized contextual bandits with heavy-tailed noise) and verify the sublinear regret claim empirically across the full range of ε values