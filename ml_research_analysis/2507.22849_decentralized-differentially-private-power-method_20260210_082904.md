---
ver: rpa2
title: Decentralized Differentially Private Power Method
arxiv_id: '2507.22849'
source_url: https://arxiv.org/abs/2507.22849
tags:
- privacy
- data
- agent
- algorithm
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a novel Decentralized Differentially Private\
  \ Power Method (D-DP-PM) for Principal Component Analysis (PCA) in networked multi-agent\
  \ settings. The key innovation is enabling collaborative estimation of global eigenvectors\
  \ when each agent only observes a subset of dimensions through row-wise data partitioning,\
  \ while ensuring (\u03B5, \u03B4)-Differential Privacy without requiring a central\
  \ aggregator."
---

# Decentralized Differentially Private Power Method

## Quick Facts
- arXiv ID: 2507.22849
- Source URL: https://arxiv.org/abs/2507.22849
- Reference count: 32
- Primary result: Novel D-DP-PM algorithm for PCA in networked multi-agent settings with (ε, δ)-DP guarantees

## Executive Summary
This paper introduces a Decentralized Differentially Private Power Method (D-DP-PM) for Principal Component Analysis in networked multi-agent systems where each agent observes only a subset of data dimensions. The key innovation is enabling collaborative estimation of global eigenvectors without a central aggregator while providing (ε, δ)-differential privacy guarantees. The method uses random initialization privacy and calibrated Gaussian noise additions, with agents sharing only local embeddings of current eigenvector iterates.

The authors prove that D-DP-PM satisfies the prescribed privacy guarantees and establish convergence rates that explicitly characterize network topology impacts. Experiments on real-world datasets demonstrate superior privacy-utility tradeoffs compared to naive local DP approaches, particularly in moderate privacy regimes (ε ∈ [2, 5]). The algorithm converges rapidly, allowing practitioners to trade iterations for enhanced privacy while maintaining competitive utility.

## Method Summary
D-DP-PM operates in a decentralized setting where agents collaboratively estimate the principal eigenvector of a global covariance matrix. Each agent holds only a subset of rows of the global data matrix, enabling privacy through data partitioning. The algorithm alternates between local power method updates on each agent's local data and consensus aggregation steps to synchronize eigenvector estimates across the network. Gaussian noise calibrated to the sensitivity of local updates is added to ensure differential privacy. The method leverages the inherent privacy of random initialization and requires agents to share only low-dimensional local embeddings rather than raw data.

## Key Results
- D-DP-PM achieves (ε, δ)-differential privacy for PCA in decentralized settings without central aggregator
- Convergence rates explicitly characterize network topology impact with additive error from consensus and DP noise
- Superior privacy-utility tradeoffs compared to local DP approaches in moderate privacy regimes (ε ∈ [2, 5])
- Rapid convergence allowing iteration-privacy tradeoffs while maintaining competitive utility

## Why This Works (Mechanism)
The method works by exploiting three key mechanisms: inherent privacy from random initialization eliminates the need for additional noise in early iterations, calibrated Gaussian noise additions provide formal (ε, δ)-DP guarantees while being small enough to maintain utility, and consensus aggregation ensures convergence to the global principal eigenvector despite only local data access. The row-wise data partitioning naturally limits information leakage while the power method iterations progressively refine the eigenvector estimate through local computations and network-wide synchronization.

## Foundational Learning
- Differential Privacy fundamentals: why needed - provides formal privacy guarantees; quick check - understand (ε, δ) definition and sensitivity concepts
- Power Method for PCA: why needed - iterative approach suitable for decentralized computation; quick check - verify convergence conditions and rate
- Consensus protocols in networks: why needed - enables agents to agree on global eigenvector; quick check - understand convergence conditions based on network topology
- Sensitivity analysis for partitioned data: why needed - determines noise scale for DP; quick check - verify sensitivity calculations for row-wise partitions

## Architecture Onboarding

Component map: Data Partitioning -> Local Power Updates -> Gaussian Noise Addition -> Consensus Aggregation -> Embedding Sharing

Critical path: Data partitioning at initialization → Iterative local power method updates with noise → Consensus aggregation across network → Local embedding computation and sharing → Repeat until convergence

Design tradeoffs: The algorithm balances privacy (noise magnitude), utility (convergence speed), and communication overhead (embedding size). Higher privacy requires more noise, slowing convergence. Larger embeddings improve accuracy but increase communication costs. Network topology affects convergence rate and consensus quality.

Failure signatures: Slow convergence indicates poor network connectivity or excessive noise. High variance in local estimates suggests insufficient consensus or inadequate noise calibration. Complete divergence typically indicates network partitioning or initialization issues.

First experiments: 1) Verify basic convergence on synthetic data without privacy noise; 2) Test privacy-utility tradeoff on standard datasets with varying ε values; 3) Evaluate sensitivity to network topology changes using ring vs. random geometric graphs.

## Open Questions the Paper Calls Out
None

## Limitations
- Convergence analysis assumes idealized network topologies and synchronized updates
- Impact of network delays, packet losses, and asynchronous communication unexplored
- Sensitivity analysis for row-wise partitioned data in non-i.i.d. settings requires further validation
- Gaussian noise parameters may be overly conservative, limiting utility in high-privacy regimes

## Confidence

- Privacy guarantee claims: High - follows established DP frameworks with rigorous mechanism design
- Convergence rate claims: Medium - theoretical analysis sound but relies on strong assumptions about connectivity and data distribution
- Experimental results: Medium - demonstrated on standard datasets but limited in scale and real-world network conditions

## Next Checks

1. Empirical evaluation under realistic network conditions including communication delays, packet losses, and heterogeneous update rates across agents
2. Sensitivity analysis of privacy-utility tradeoff across different data partition schemes (row-wise vs column-wise vs random partitions)
3. Scalability testing on larger networked systems with 100+ agents to verify theoretical convergence bounds hold in practice