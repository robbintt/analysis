---
ver: rpa2
title: 'iServe: An Intent-based Serving System for LLMs'
arxiv_id: '2501.13111'
source_url: https://arxiv.org/abs/2501.13111
tags:
- iserve
- latency
- memory
- llms
- gpus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: iServe is an intent-based LLM serving system that automates the
  deployment configuration selection process for LLM inference. It introduces lightweight
  LLM fingerprints to efficiently profile and estimate latency and memory requirements
  across hundreds of deployment configurations, eliminating the need for expensive
  manual profiling.
---

# iServe: An Intent-based Serving System for LLMs

## Quick Facts
- arXiv ID: 2501.13111
- Source URL: https://arxiv.org/abs/2501.13111
- Reference count: 40
- Primary result: Reduces latency by 77.62%, cost by 86.70%, and SLO violations by 7.09×

## Executive Summary
iServe is an intent-based LLM serving system that automates deployment configuration selection for LLM inference. By introducing lightweight LLM fingerprints (1-2 hidden layers), iServe efficiently profiles and estimates latency and memory requirements across hundreds of deployment configurations without expensive full-model profiling. The system selects optimal configurations based on user intent (minimize latency, cost, memory, or meet SLOs) and applies a load-aware GPU placement policy. Evaluation shows significant performance improvements over state-of-the-art systems while reducing profiling costs by 6.05× (GPU-hours).

## Method Summary
iServe builds on TensorRT-LLM to implement fingerprint-based profiling and intent-driven deployment. The system generates 1-2 layer fingerprints from LLMs, profiles these under a subset of configurations, and extrapolates full-LLM metrics using linear scaling relationships. At deployment time, configurations are ranked by user intent and mapped to available GPUs using a hybrid placement policy that balances packing efficiency against latency. The system operates with FCFS scheduling and continuous monitoring of GPU load and memory usage.

## Key Results
- Reduces latency by 77.62% and cost by 86.70% compared to state-of-the-art systems
- Achieves 7.09× reduction in SLO violations and 4.72× improvement in GPU throughput
- Cuts profiling costs by 6.05× (GPU-hours) through fingerprint-based estimation
- Uses 37.5% fewer GPUs than least-loaded placement while maintaining latency within 0.05-0.76× median increase

## Why This Works (Mechanism)

### Mechanism 1: Fingerprint-based Estimation Reduces Profiling Cost
Profiling LLM "fingerprints" (1-2 hidden layers) instead of full models enables efficient estimation of memory and latency across all deployment configurations. Decoder-only LLMs consist of repeated identical hidden layers, allowing linear relationships between layer count and both memory footprint and inference latency (TTFT, TPOT). By profiling fingerprints under a subset of configurations and solving systems of equations, iServe extrapolates full-LLM metrics for all ~180 possible configurations.

### Mechanism 2: Intent-to-Configuration Mapping via Estimated Metrics
User intents (minimize latency, cost, memory, or meet SLOs) translate to optimal configurations through ranked configuration maps. The Fingerprint Controller generates a configuration map with estimated memory and latency per deployment option. At deployment time, the Deployment Controller ranks configurations by intent, traverses the list, and selects the first feasible one given available GPU memory and cluster state.

### Mechanism 3: Hybrid Load-Aware GPU Placement
A threshold-based hybrid policy balances packing efficiency (fewer GPUs) against latency (reduced contention). GPUs are categorized as packable (load < θ) or non-packable (load ≥ θ). The system first attempts packing on packable GPUs; if insufficient memory, it falls back to least-loaded placement on non-packable GPUs. Load is measured as busy-seconds over a 120-second window.

## Foundational Learning

- **Tensor Parallelism (TP) vs. Pipeline Parallelism (PP)**: Understanding that TP splits operations (reduces latency but increases memory via activation replication) while PP distributes layers (reduces per-GPU memory but increases total footprint) is essential for interpreting configuration trade-offs. Quick check: Given an 8-GPU cluster, which parallelism strategy minimizes latency for a 70B model, and which minimizes per-GPU memory?

- **LLM Inference Latency Decomposition (TTFT + TPOT × output_length)**: Profiling strategy L2 relies on decomposing latency into time-to-first-token and per-output-token components, then extrapolating via layer counts. Quick check: If TTFT for a 2-layer fingerprint is 50ms and TPOT is 10ms, what is the estimated latency for a 40-layer LLM generating 100 tokens?

- **Quantization Effects on Latency vs. Memory**: Memory reduction from quantization is predictable (INT4 → ~75% reduction), but latency impact is LLM-specific due to weight reconversion overheads. Quick check: Why might INT4 quantization reduce latency for a 70B model but increase it for a 7B model?

## Architecture Onboarding

- **Component map**: Fingerprint Controller (CPU process) -> Generator creates 1-2 layer fingerprints -> Profiler deploys fingerprints on harvested GPUs -> Estimator solves systems of equations to produce configuration maps -> Deployment Controller ranks configurations by intent -> Hybrid placement policy assigns memory blocks to K GPUs -> TensorRT-LLM process launched

- **Critical path**: 1) LLM registration → fingerprint generation → profile under (TP=1/PP=1, TP=1/PP=2, TP=2/PP=1) per quantization → estimate all configurations → store in configuration map. 2) Deployment request → rank by intent → iterate until feasible → assign memory blocks to K GPUs → launch TensorRT-LLM process. 3) Inference request → Scheduler dispatches to worker IP/port from in-memory map.

- **Design tradeoffs**: (L2, M2) profiling chosen over (L2, M3) for 60% lower profiling time despite slightly higher estimation error. Hybrid placement trades 0.05-0.76× median latency increase for 37.5% fewer GPUs compared to least-loaded. Batching disabled for profiling simplicity; assumed batch-size-1 behavior generalizes.

- **Failure signatures**: Estimation error spikes: Likely non-linear layer interactions (check pruning/quantization combinations). SLO violations under profiling: GPU load >30% during harvested profiling (Section 8.6). Placement failures: Fragmented GPU memory preventing even block distribution; fallback to next-ranked configuration.

- **First 3 experiments**: 1) Validate fingerprint accuracy: For a target LLM (e.g., Falcon-40B), compare estimated vs. actual latency/memory across all configurations; compute APE distribution. 2) Intent switching stress test: Deploy with minimize-latency intent, then switch to minimize-cost mid-workload; measure adaptation latency and configuration change overhead. 3) Load threshold sensitivity: Sweep θ (load threshold for hybrid policy) from 0.1 to 0.9 under bursty trace; plot GPU count vs. p95 latency tradeoff curve.

## Open Questions the Paper Calls Out

### Open Question 1
How can iServe incorporate accuracy as a user intent given the lack of standardized accuracy metrics for LLM serving? [explicit] "In this paper, we omit accuracy as a user intent, as the LLM community has yet to define a suitable metric for it. We consider developing an LLM serving system that adapts to accuracy requirements as future work." Why unresolved: No consensus exists on accuracy metrics suitable for intent-based serving; trade-offs between accuracy and other intents remain unexplored. What evidence would resolve it: Integration of task-specific benchmarks or perplexity measures into iServe's intent framework, with experiments showing configuration selection under accuracy constraints.

### Open Question 2
Can fingerprint-based profiles be extrapolated across different GPU architectures (e.g., A6000 to A100/H100) without re-profiling? [explicit] "To reduce cost, we could extrapolate profiles across GPU types by adjusting for architectural differences; we leave this for future work." Why unresolved: Current iServe requires per-GPU-type profiling in heterogeneous clusters, increasing costs. What evidence would resolve it: Experiments demonstrating bounded estimation error when applying architectural adjustment factors to extrapolate fingerprints across GPU generations.

### Open Question 3
How can iServe efficiently profile multi-modal LLMs with non-textual components (e.g., vision encoders in LLaVA)? [explicit] "To accommodate models that deviate from this structure (e.g., LLaVA, which includes image layers), the Fingerprint Controller can be extended to profile unique layers for those models." Why unresolved: Current fingerprints assume decoder-only architectures with repetitive, structurally identical hidden layers. What evidence would resolve it: A modified fingerprinting approach handling heterogeneous layer types, validated on vision-language models with latency/memory estimation accuracy comparable to text-only models.

## Limitations
- Architecture-dependent profiling approach assumes decoder-only LLMs with repeated identical layers, limiting applicability to encoder-decoder models
- Accuracy requirements cannot be specified as user intent, restricting use cases where quality metrics matter
- Runtime intent switching requires full profiling recomputation, creating deployment rigidity

## Confidence

- **High Confidence**: Fingerprint-based profiling reduces profiling cost (6.05× reduction verified through GPU-hour measurements); Intent-to-configuration mapping correctly ranks and selects feasible configurations; Hybrid placement policy achieves stated GPU count reductions (5 GPUs vs 8 for least-loaded).

- **Medium Confidence**: Latency and cost reduction claims (77.62% and 86.70%) are supported by trace-based evaluation but depend on specific workload patterns and may not generalize to all production scenarios.

- **Low Confidence**: SLO violation reduction (7.09×) claim is based on a single experiment configuration and may be sensitive to trace characteristics and load patterns.

## Next Checks

1. **Architecture Transferability Test**: Validate the fingerprinting approach on encoder-decoder architectures (T5, BART) and models with heterogeneous layer structures. Measure estimation error distribution and identify architectural patterns where linear extrapolation fails.

2. **Intent Switching Performance**: Implement runtime intent switching in a test deployment and measure: (a) time to adapt to new intent, (b) profiling overhead for intent change, and (c) configuration stability during workload transitions.

3. **Load Sensitivity Analysis**: Systematically vary the 120-second load measurement window and θ threshold under bursty synthetic workloads. Characterize the tradeoff curve between GPU utilization efficiency and p95 latency to identify optimal parameter ranges for different workload profiles.