---
ver: rpa2
title: 'LAVA: Language Model Assisted Verbal Autopsy for Cause-of-Death Determination'
arxiv_id: '2509.09602'
source_url: https://arxiv.org/abs/2509.09602
tags:
- verbal
- autopsy
- accuracy
- cause
- causes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LA-VA combines LLM-based predictions with embedding-based classifiers
  and probabilistic models for cause-of-death determination from verbal autopsies.
  Using GPT-5 with structured prompts and post-hoc calibration, the method achieved
  top-1 accuracies of 48.6% (adults), 50.5% (children), and 53.5% (neonates) across
  11,978 cases from the PHMRC dataset, outperforming traditional baselines by 5-10%.
---

# LAVA: Language Model Assisted Verbal Autopsy for Cause-of-Death Determination

## Quick Facts
- **arXiv ID**: 2509.09602
- **Source URL**: https://arxiv.org/abs/2509.09602
- **Reference count**: 25
- **Primary result**: LA-VA achieves 48.6-53.5% top-1 accuracy for cause-of-death determination across different age groups using GPT-5

## Executive Summary
LAVA (Language Model Assisted Verbal Autopsy) combines large language model predictions with embedding-based classifiers and probabilistic models to determine causes of death from verbal autopsy narratives. The method uses GPT-5 with structured prompts and post-hoc calibration to achieve improved accuracy over traditional machine learning baselines, particularly for distinctive causes like maternal mortality and injuries. While showing promise for improving mortality surveillance in resource-limited settings, the approach requires further validation on real-world datasets beyond the PHMRC research study.

## Method Summary
LAVA integrates multiple computational approaches for cause-of-death classification from verbal autopsy narratives. The system uses GPT-5 to generate structured predictions from narrative text, with post-hoc calibration to improve accuracy. These LLM predictions are combined with embedding-based classifiers that extract features from the text, and integrated through probabilistic models to produce final cause-of-death determinations. The framework is evaluated on the PHMRC dataset across adult, child, and neonatal populations, achieving improved performance particularly for causes with distinctive clinical presentations.

## Key Results
- Achieved top-1 accuracies of 48.6% (adults), 50.5% (children), and 53.5% (neonates) across 11,978 cases
- Outperformed traditional baselines by 5-10% in overall accuracy
- Highest performance for distinctive conditions like maternal mortality and injuries
- Accuracy improved with narrative length
- Calibration improved population-level CSMF accuracy without affecting individual predictions

## Why This Works (Mechanism)
LAVA leverages the pattern recognition capabilities of large language models trained on diverse text data to identify cause-of-death patterns from narrative descriptions. The combination of LLM-based predictions with embedding-based classifiers and probabilistic integration allows the system to capture both semantic understanding and statistical relationships in the data. Post-hoc calibration addresses potential biases in LLM predictions, while the multi-component architecture provides robustness across different cause categories and narrative qualities.

## Foundational Learning
- **Verbal Autopsy Methodology**: Systematic collection of information about deaths from family members or caregivers - needed for understanding the data source and limitations
- **Large Language Models in Medical Contexts**: Application of LLMs to clinical text analysis - needed for understanding the core technology
- **Calibration of Probabilistic Models**: Techniques to adjust model predictions to match observed frequencies - needed for improving population-level accuracy
- **Multiple Cause-of-Death Classification**: Handling the complexity of assigning single or multiple causes from narrative descriptions - needed for understanding the task complexity

## Architecture Onboarding

**Component Map**: Verbal Autopsy Narrative -> LLM Processing -> Embedding Extraction -> Probabilistic Integration -> Cause-of-Death Classification

**Critical Path**: Narrative text enters the system, undergoes LLM-based prediction generation, is simultaneously processed by embedding classifiers, and these outputs are integrated through probabilistic models to produce final cause assignments.

**Design Tradeoffs**: The use of GPT-5 provides strong semantic understanding but introduces potential biases and requires careful calibration. The multi-component approach adds complexity but improves robustness across different cause categories and narrative qualities.

**Failure Signatures**: Performance degrades for causes with overlapping symptoms, shorter narratives, and conditions that are less distinctive in verbal descriptions. Potential biases may emerge from LLM training data influencing cause classifications across different cultural contexts.

**First Experiments**:
1. Validate individual component performance (LLM, embedding classifier, probabilistic model) on held-out test sets
2. Compare calibrated vs uncalibrated LLM predictions across different cause categories
3. Test sensitivity to narrative length by evaluating performance on truncated versions of the same narratives

## Open Questions the Paper Calls Out
The paper identifies several key uncertainties: generalizability beyond the PHMRC dataset to real-world verbal autopsy data, the clinical and public health impact of the reported accuracy improvements, and potential biases in LLM predictions across different cultural and linguistic contexts. The authors note that their evaluation was limited to a research dataset and did not include testing on routine health information systems or physician-certified determinations.

## Limitations
- Evaluation limited to PHMRC research dataset, not real-world routine health information systems
- Unclear clinical and public health impact of 5-10% accuracy improvements over baselines
- Potential biases in LLM predictions not fully explored across different cultural contexts
- Performance may degrade for causes with overlapping symptoms and less distinctive presentations

## Confidence
- **High confidence** in technical implementation and performance metrics for the LAVA framework
- **Medium confidence** in scalability and real-world applicability given controlled evaluation setting
- **Low confidence** in clinical utility without field validation against physician-certified determinations

## Next Checks
1. External validation on verbal autopsy datasets from multiple countries and languages, particularly from routine health information systems rather than research studies
2. Head-to-head comparison with physician-certified verbal autopsies in the same population to assess clinical concordance and identify systematic biases
3. Evaluation of LAVA's performance across different narrative lengths and quality levels found in real-world verbal autopsy interviews