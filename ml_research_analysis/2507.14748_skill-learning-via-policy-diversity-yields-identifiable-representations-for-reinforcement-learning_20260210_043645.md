---
ver: rpa2
title: Skill Learning via Policy Diversity Yields Identifiable Representations for
  Reinforcement Learning
arxiv_id: '2507.14748'
source_url: https://arxiv.org/abs/2507.14748
tags:
- learning
- arxiv
- identifiability
- skill
- skills
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors investigate why mutual information skill learning (MISL)
  methods in reinforcement learning (RL) succeed at learning useful state representations.
  They focus on Contrastive Successor Features (CSF) and prove that its success can
  be explained by identifiable representation learning theory from nonlinear ICA.
---

# Skill Learning via Policy Diversity Yields Identifiable Representations for Reinforcement Learning

## Quick Facts
- arXiv ID: 2507.14748
- Source URL: https://arxiv.org/abs/2507.14748
- Reference count: 40
- Primary result: CSF learns identifiable features up to linear transformation when using diverse skill policies

## Executive Summary
This paper investigates why mutual information skill learning (MISL) methods succeed at learning useful state representations in reinforcement learning. The authors focus on Contrastive Successor Features (CSF) and prove that its success can be explained by identifiable representation learning theory from nonlinear ICA. They demonstrate that CSF learns features up to a linear transformation of the ground-truth states when using an inner product parametrization and diverse skill-conditioned policies. The work provides theoretical insights into what constitutes a diverse policy, why maximum entropy policies fail, and how different MI objectives affect feature space geometry.

## Method Summary
The authors analyze Contrastive Successor Features (CSF), a mutual information skill learning method that learns state representations by maximizing the mutual information between skills and their induced state distributions. CSF uses an inner product parametrization to learn a representation function φ and a skill embedding function ψ. The method learns diverse skill-conditioned policies that induce different state visitation distributions. The authors prove that under certain conditions (diverse policies, inner product parametrization), CSF recovers the ground-truth state representation up to a linear transformation. They validate their theoretical claims empirically in MuJoCo and DeepMind Control environments, showing CSF can recover ground-truth features both from states and pixels.

## Key Results
- CSF achieves R2 scores up to 1.0 when recovering ground-truth features from states
- Oracle returns reach up to 200 for zero-shot task transfer using recovered representations
- Maximum entropy policies fail to produce identifiable representations, while diverse skill policies succeed

## Why This Works (Mechanism)
CSF works because diverse skill policies induce sufficiently different state visitation distributions, creating the necessary constraints for identifiable representation learning. The inner product parametrization allows the method to learn features that are maximally informative about the skills while maintaining the geometric properties needed for identifiability. The mutual information objective ensures that the learned representations preserve the essential structure of the state space while being invariant to irrelevant variations.

## Foundational Learning
- Mutual Information Skill Learning (MISL): A framework where skills are learned to maximize mutual information with state distributions
  - Why needed: Provides the theoretical foundation for understanding how skill diversity leads to identifiable representations
  - Quick check: Verify that MI between skills and states is positive and bounded

- Identifiable Representation Learning: The property that a representation can be uniquely determined up to certain transformations
  - Why needed: Explains why CSF succeeds where other methods fail in learning meaningful representations
  - Quick check: Confirm that the learned representation can be mapped back to ground-truth states via linear transformation

- Diverse Policy Characterization: Quantification of policy diversity through eigenvalue analysis of occupancy measure's second moment matrix
  - Why needed: Provides a concrete metric for what constitutes "diverse" policies in the context of identifiability
  - Quick check: Calculate the eigenvalue spectrum of the second moment matrix for different policy sets

## Architecture Onboarding
- Component Map: States -> φ (representation) -> Features -> ψ (skill embedding) -> Skills -> Policies -> State distributions
- Critical Path: φ learns from state distributions induced by diverse skill policies, ψ learns skill embeddings, combined via inner product for contrastive learning
- Design Tradeoffs: Inner product parametrization enables identifiability but may limit expressiveness compared to other architectures
- Failure Signatures: Low R2 scores, poor oracle returns, or inability to recover ground-truth features indicate insufficient policy diversity or incorrect parametrization
- First Experiments: 1) Test CSF on simple MDP with known ground-truth states, 2) Vary policy diversity levels and measure impact on identifiability, 3) Compare inner product vs. other parametrizations

## Open Questions the Paper Calls Out
The paper identifies several open questions regarding the practical application of their theoretical insights. How can the framework be extended to handle more complex, high-dimensional environments with partial observability? What are the implications for transfer learning when representations are only identifiable up to linear transformations? How does the theory apply to continuous skill spaces rather than discrete skill sets?

## Limitations
- Theoretical claims assume ground-truth states are available, which rarely holds in practice
- Empirical validation limited to specific benchmark environments with relatively low-dimensional state spaces
- The linear transformation ambiguity in recovered representations may limit practical utility for some downstream tasks

## Confidence
- High: CSF's identifiability under theoretical assumptions (ground-truth states, inner product parametrization)
- Medium: Empirical demonstration of feature recovery in benchmark environments
- Medium: Claims about policy diversity requirements and maximum entropy failure

## Next Checks
1. Test CSF's identifiability on more complex, high-dimensional environments with partial observability and non-smooth dynamics
2. Evaluate downstream task performance using the recovered representations, not just their proximity to ground-truth features
3. Compare CSF's identifiability against other mutual information skill learning methods under varying levels of policy diversity and environmental stochasticity