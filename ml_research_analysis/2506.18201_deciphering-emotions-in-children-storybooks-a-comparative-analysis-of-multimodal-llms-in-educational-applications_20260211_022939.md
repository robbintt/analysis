---
ver: rpa2
title: 'Deciphering Emotions in Children Storybooks: A Comparative Analysis of Multimodal
  LLMs in Educational Applications'
arxiv_id: '2506.18201'
source_url: https://arxiv.org/abs/2506.18201
tags:
- emotion
- emotional
- arabic
- recognition
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated multimodal large language models (MLLMs) for
  emotion recognition in Arabic children's storybooks, comparing GPT-4o and Gemini
  1.5 Pro across zero-shot, few-shot, and chain-of-thought prompting strategies. Using
  75 illustrations from seven Arabic storybooks, the models were tested against human-annotated
  emotions based on Plutchik's framework.
---

# Deciphering Emotions in Children Storybooks: A Comparative Analysis of Multimodal LLMs in Educational Applications

## Quick Facts
- arXiv ID: 2506.18201
- Source URL: https://arxiv.org/abs/2506.18201
- Reference count: 40
- Key outcome: GPT-4o outperformed Gemini 1.5 Pro in Arabic emotion recognition from children's book illustrations, achieving 59% macro F1-score with chain-of-thought prompting versus Gemini's 43% best performance.

## Executive Summary
This study evaluates multimodal large language models for emotion recognition in Arabic children's storybooks, comparing GPT-4o and Gemini 1.5 Pro across three prompting strategies. Using 75 illustrations from seven Arabic storybooks, the models were tested against human-annotated emotions based on Plutchik's framework. GPT-4o consistently outperformed Gemini, with chain-of-thought prompting yielding the highest accuracy for GPT-4o but degrading Gemini's performance. Error analysis revealed that valence inversions (60.7% of errors) dominated misclassification patterns, highlighting challenges in cross-cultural emotion recognition and the need for culturally sensitive training approaches.

## Method Summary
The study evaluated two multimodal LLMs (GPT-4o and Gemini 1.5 Pro) using 75 illustrations from Arabic children's storybooks, annotated by four native Arabic speakers using Plutchik's nine-emotion framework. Three prompting strategies were tested: zero-shot classification, few-shot learning with exemplars, and chain-of-thought reasoning. Models received Arabic prompts instructing them to classify emotions from illustrations. Performance was measured using macro F1-score (to account for class imbalance) and Cohen's Kappa for human-AI agreement. Error analysis categorized misclassifications into valence inversions, arousal mismatches, and contextual/cultural misinterpretations.

## Key Results
- GPT-4o achieved 59% macro F1-score with chain-of-thought prompting, outperforming Gemini's best of 43% (zero-shot)
- Valence inversions accounted for 60.7% of all misclassifications across both models
- Both models struggled with culturally nuanced emotions, particularly "trust" (ثقة) which diverged from Western definitions
- Arabic textual content frequently overrode visual emotional cues in multimodal processing

## Why This Works (Mechanism)

### Mechanism 1
- Chain-of-thought prompting improves GPT-4o emotion recognition by eliciting sequential reasoning that stabilizes internal emotional representations in architectures with robust multimodal fusion.
- Core assumption: Emotion recognition benefits from deliberative reasoning rather than purely intuitive processing.
- Evidence: GPT-4o achieved 59% F1 with CoT prompting; Gemini degraded to 37% under same conditions.
- Break condition: CoT degraded Gemini performance and caused over-interpretation in ambiguous cases.

### Mechanism 2
- Valence inversions dominate misclassification because models process emotions as discrete categories rather than understanding dimensional affect structure.
- Core assumption: Valence processing requires semantic and cultural knowledge beyond surface visual features.
- Evidence: 60.7% of errors were valence inversions; error analysis showed systematic positive-negative confusion.
- Break condition: Performance improves when visual cues are unambiguous (prominent smiles, clear fear expressions).

### Mechanism 3
- Arabic text overrides visual emotional cues due to imbalanced multimodal fusion weighting.
- Core assumption: Current architectures prioritize textual input over visual signals when both modalities are present.
- Evidence: Case analysis showed conflict-related text influenced predictions despite neutral visual appearances.
- Break condition: Not tested in text-free conditions; mechanism inferred from qualitative analysis.

## Foundational Learning

- **Plutchik's Wheel of Emotions**: The study uses this 8-emotion framework (joy, trust, fear, surprise, sadness, disgust, anger, anticipation + neutral) as the classification taxonomy. Quick check: Can you name the four positive-valence emotions in Plutchik's framework?

- **Macro F1-Score**: The dataset is imbalanced (happiness = 40%, disgust = 1.3%); macro F1 averages per-class performance equally rather than weighting by frequency. Quick check: Why would accuracy be misleading if happiness comprised 40% of labels and a model always predicted "happiness"?

- **Cohen's Kappa (κ)**: Measures human-AI agreement while accounting for chance; κ = 0.56 (GPT-4o) vs. κ = 0.37 (Gemini) indicates moderate vs. fair agreement levels. Quick check: What κ value range indicates "moderate" vs. "fair" agreement?

## Architecture Onboarding

- Component map: Image input -> Visual encoder -> Multimodal fusion -> Language model -> Prompt interface -> Emotion classification
- Critical path: 1) Image ingested through vision encoder 2) Visual features aligned with text embeddings in shared multimodal space 3) Prompt instructs model to classify into 9 emotion categories 4) CoT variant adds sequential reasoning step before classification 5) Output mapped to predefined Arabic emotion taxonomy
- Design tradeoffs:
  - Holistic vs. segmented input: GPT-4o dropped 25 points when characters isolated; Gemini improved 12.5 points
  - Taxonomic scaffolding: Providing Plutchik's wheel helped Gemini CoT (+12.5 points) but hurt GPT-4o (-12.5 points)
  - Prompting language: English prompts may outperform Arabic prompts for some Arabic NLP tasks
- Failure signatures:
  - Valence inversions: 60.7% of errors—systematic positive/negative confusion
  - Neutral state collapse: Multiple zero F1-scores; models over-interpret ambiguous images
  - Cultural misalignment: Arabic-specific emotional expressions interpreted through Western-centric definitions
  - Text dominance: Conflict-related text overrides neutral visual expressions
- First 3 experiments:
  1. Baseline calibration: Run zero-shot classification on 10 images with clear emotional markers
  2. Text-visual conflict test: Present images where Arabic text contradicts visual emotion cues
  3. Culture-specific probe: Test "trust" (ثقة) classification specifically against human rationales

## Open Questions the Paper Calls Out

- **Educational impact**: Do emotion-aware MLLM interfaces significantly improve Arabic literacy outcomes compared to non-adaptive educational tools? (Section 5.8 calls for intervention studies measuring actual learning outcomes)
- **Specialized vs. general models**: Can specialized Arabic NLP models outperform general-purpose MLLMs on emotion recognition in children's literature? (Section 5.7 notes lack of comparison with MARBERT, QARiB)
- **Explainable AI insights**: Can XAI techniques identify specific features causing systematic valence inversions? (Section 5.8 suggests attention visualization could reveal reasoning patterns)

## Limitations

- Dataset size limited to 75 illustrations from seven Arabic storybooks, constraining generalizability
- Exact Arabic prompt templates not provided, requiring reconstruction that may introduce variability
- Claims about text dominance and cultural misalignment based on qualitative case analysis rather than systematic experimentation
- Mechanism underlying valence inversion dominance remains speculative without controlled ablation studies

## Confidence

- **High Confidence**: GPT-4o outperforms Gemini across all prompting strategies (macro F1-scores: 59% vs. 43% for CoT prompting)
- **Medium Confidence**: Chain-of-thought prompting improves GPT-4o performance but not uniformly across architectures
- **Medium Confidence**: Valence inversions account for 60.7% of misclassifications

## Next Checks

1. **Controlled Valence Conflict Test**: Create systematic test set with opposing visual/textual valence to quantify text dominance effect
2. **Culture-Specific Emotion Probe**: Conduct focused experiments on "trust" (ثقة) classification comparing model predictions against human annotator rationales
3. **Prompt Template Replication**: Reconstruct and test exact Arabic prompt templates across multiple model versions to isolate performance differences from prompt design vs. architecture variations