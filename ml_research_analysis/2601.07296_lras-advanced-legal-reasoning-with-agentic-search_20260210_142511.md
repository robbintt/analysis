---
ver: rpa2
title: 'LRAS: Advanced Legal Reasoning with Agentic Search'
arxiv_id: '2601.07296'
source_url: https://arxiv.org/abs/2601.07296
tags:
- legal
- search
- reasoning
- answer
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LRAS, the first framework that shifts legal
  LLMs from static "closed-loop thinking" to dynamic "Active Inquiry." The framework
  integrates introspective imitation learning and difficulty-aware reinforcement learning
  to enable models to identify knowledge boundaries and handle legal reasoning complexity.
  LRAS significantly outperforms state-of-the-art baselines by 8.2-32% across multiple
  legal benchmarks, with the most substantial gains observed in deep reasoning tasks
  requiring reliable knowledge.
---

# LRAS: Advanced Legal Reasoning with Agentic Search

## Quick Facts
- arXiv ID: 2601.07296
- Source URL: https://arxiv.org/abs/2601.07296
- Reference count: 40
- Outperforms state-of-the-art by 8.2-32% on legal benchmarks

## Executive Summary
LRAS introduces a novel framework that transforms legal language models from static "closed-loop thinking" to dynamic "Active Inquiry" through introspective imitation learning and difficulty-aware reinforcement learning. The approach enables models to identify knowledge boundaries and autonomously plan multi-step exploratory searches, significantly improving legal reasoning performance. LRAS achieves 8.2-32% gains across multiple legal benchmarks, with the most substantial improvements in deep reasoning tasks requiring reliable knowledge synthesis.

## Method Summary
LRAS trains legal models through a two-stage pipeline: (1) SFT on curated trajectories that teach search triggers, filtering out trivial queries and pruning incorrect searches; (2) GRPO RL on "hard" samples (pass rate <50%) to optimize multi-step search strategies. The framework uses Qwen3 backbone (4B/8B/14B variants) with SerpAPI + Jina Reader for retrieval, enabling agentic search that outperforms static RAG by 26% on difficult legal queries.

## Key Results
- 8.2-32% improvement over state-of-the-art baselines across multiple legal benchmarks
- 26% relative gain (49.2% vs 39.0%) for agentic search vs static RAG on hard reasoning tasks
- 49.7% of RL model queries trigger multi-search behavior (vs ~3% in SFT)
- Identifies 71.3% of failures stem from lack of search trigger (introspection deficit)

## Why This Works (Mechanism)

### Mechanism 1
Imitation learning on uncertainty-filtered data teaches models to recognize knowledge boundaries and trigger search appropriately. By discarding trivial queries and retaining ambiguous cases, the model learns "insufficient confidence → search" patterns rather than defaulting to confident hallucination.

### Mechanism 2
Difficulty-aware RL transforms passive retrieval into autonomous multi-step exploratory search. By focusing on hard samples (pass rate <50%) and optimizing trajectory-level rewards, GRPO encourages chaining searches rather than settling on first retrieval.

### Mechanism 3
Agentic search outperforms static RAG on deep reasoning tasks requiring knowledge synthesis. The model can query adaptively based on intermediate reasoning gaps, enabling targeted retrieval rather than one-shot context injection.

## Foundational Learning

**Introspection Deficit**
- Why needed: Models don't know when they don't know (71.3% of errors occur without search trigger)
- Quick check: Can your model output "I need to search" before attempting an answer?

**Group Relative Policy Optimization (GRPO)**
- Why needed: Optimizes multi-step search trajectories with group-normalized advantages in RL stage
- Quick check: How does GRPO differ from standard PPO in handling trajectory-level rewards?

**Closed-loop vs. Active Inquiry Reasoning**
- Why needed: The paradigm shift from parametric-only reasoning to interactive retrieval
- Quick check: Does your system's reasoning trace include queries generated during reasoning?

## Architecture Onboarding

**Component map:**
Input query → Internal reasoning (՜ tag) → Confidence assessment → Search trigger decision → External search (SerpAPI + Jina Reader → Qwen3-32B summarizer) → Answer generation

**Critical path:**
1. Query → internal reasoning → confidence assessment
2. If insufficient: generate search query → retrieve top-5 → summarize
3. Loop until confident → generate answer

**Design tradeoffs:**
- SFT teaches when to search; RL teaches how to search multi-step
- Summarizer reduces noise but may filter relevant details
- Max 6 assistant turns limits search depth (mean 1.27 searches, max 5)

**Failure signatures:**
- Over-searching on simple queries
- Hallucinated legal articles despite search
- Retrieval returns irrelevant statutes → reasoning derails

**First 3 experiments:**
1. Replicate Table 1: sample failures from base model, measure search trigger rate
2. Ablate introspection levels: compare Level-1 vs Level-3 prompts on held-out legal queries
3. Compare static RAG vs agentic search on curated "hard subset" matching Figure 2 methodology

## Open Questions the Paper Calls Out

**Extended interaction horizons:** How does LRAS perform when scaled to extremely complex scenarios requiring deep, multi-layered inquiry chains beyond 6 turns? The current max 6 assistant turns may not fully explore complex scenarios.

**Retrieval error recovery:** What mechanisms can detect and recover from retrieval errors when external search returns incomplete or irrelevant statutes? No error-detection module was implemented.

**Cross-jurisdictional generalization:** Does the agentic search paradigm transfer to other legal systems and languages beyond Chinese law? All benchmarks are Chinese-specific with no cross-jurisdictional experiments.

**Specialized database integration:** How does performance scale when integrating multiple specialized legal databases versus general web search? Only general web search configuration was tested.

## Limitations

**Data accessibility:** Exact SFT trajectories, RL hard sample sets, and trained weights are not publicly released, limiting reproducibility.

**Search quality dependency:** Performance assumes high-quality, relevant retrieval. No retrieval precision metrics reported, and max 6 turns suggests limited search depth.

**Evaluation scope:** All datasets are Chinese legal corpora. Effectiveness on other legal systems or general knowledge domains remains untested.

## Confidence

**High confidence:** Introspection deficit identification and SFT mechanism (71.3% failure rate is concrete empirical finding)

**Medium confidence:** RL mechanism and difficulty-aware optimization (depends on RL training data quality)

**Low confidence:** Agentic search superiority claim without controlled retrieval quality experiments (26% relative gain not fully isolated)

## Next Checks

1. **Controlled retrieval experiment:** Create difficulty-stratified subset and compare LRAS agentic search against static RAG using identical retrieval quality to isolate reasoning mechanism from retrieval advantages.

2. **Search trigger reliability test:** Sample 100 held-out legal queries that base model answers incorrectly, then measure search trigger rate and accuracy improvement when search is forced.

3. **Cross-domain generalization study:** Apply LRAS methodology to non-legal reasoning benchmarks (e.g., GSM8K, MMLU) with appropriate knowledge domains to test generalization beyond legal corpora.