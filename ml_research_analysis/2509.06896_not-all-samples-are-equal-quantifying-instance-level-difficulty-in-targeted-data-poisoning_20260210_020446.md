---
ver: rpa2
title: 'Not All Samples Are Equal: Quantifying Instance-level Difficulty in Targeted
  Data Poisoning'
arxiv_id: '2509.06896'
source_url: https://arxiv.org/abs/2509.06896
tags:
- poisoning
- attacks
- difficulty
- attack
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of quantifying instance-level
  difficulty in targeted data poisoning attacks, where attackers aim to manipulate
  the prediction of specific test samples while maintaining normal performance on
  others. The authors identify three key factors that influence poisoning difficulty:
  classification difficulty during clean training, parameter-space poisoning distance,
  and poison budget.'
---

# Not All Samples Are Equal: Quantifying Instance-level Difficulty in Targeted Data Poisoning

## Quick Facts
- **arXiv ID:** 2509.06896
- **Source URL:** https://arxiv.org/abs/2509.06896
- **Reference count:** 25
- **Primary result:** EPA effectively separates easy-to-poison from hard-to-poison samples across CIFAR-10 and TinyImageNet datasets

## Executive Summary
This paper addresses the problem of quantifying instance-level difficulty in targeted data poisoning attacks, where attackers aim to manipulate the prediction of specific test samples while maintaining normal performance on others. The authors identify three key factors that influence poisoning difficulty: classification difficulty during clean training, parameter-space poisoning distance, and poison budget. They introduce three metrics to quantify these factors: ergodic prediction accuracy (EPA), poisoning distance (δ), and budget lower bound (τ). All metrics can be computed using only clean training data and processes without requiring actual poisoning attacks.

The proposed metrics successfully predict poisoning difficulty across diverse scenarios and attack methods on CIFAR-10 and TinyImageNet datasets. EPA shows strong correlation with attack success rates, while δ and τ provide fine-grained predictions for specific poison classes. The work provides a practical framework for assessing vulnerability to targeted data poisoning attacks without expensive attack evaluations.

## Method Summary
The authors develop three metrics to quantify instance-level poisoning difficulty using only clean training data. Ergodic Prediction Accuracy (EPA) measures classification difficulty by computing the average predicted probability of the correct class over training trajectories. Poisoning distance (δ) measures the minimal parameter perturbation needed to misclassify a target sample. Budget lower bound (τ) estimates the minimal poison sample count required for successful attack. These metrics leverage ergodic theory to approximate training dynamics without actual poisoning, making them computationally efficient and broadly applicable. The approach provides a framework for predicting which samples are most vulnerable to targeted poisoning attacks before deployment.

## Key Results
- EPA effectively separates easy-to-poison from hard-to-poison samples with strong correlation to actual attack success rates
- δ and τ metrics provide fine-grained predictions for specific poison classes and complement EPA insights
- All three metrics successfully predict poisoning difficulty across diverse attack methods on CIFAR-10 and TinyImageNet
- Metrics can be computed using only clean training data without expensive poisoning attack evaluations

## Why This Works (Mechanism)
The metrics work by capturing three fundamental aspects of poisoning difficulty: how hard a sample is to classify during normal training (EPA), how much parameter space needs to shift to cause misclassification (δ), and what budget is required to achieve that shift (τ). By analyzing clean training dynamics through ergodic methods, the approach approximates how samples behave under adversarial manipulation without actually performing attacks.

## Foundational Learning
- **Ergodic Theory:** Used to approximate training dynamics over time - needed for EPA computation without actual poisoning
- **Parameter-space analysis:** Measures distance in weight space to cause misclassification - needed for δ metric
- **Budget estimation:** Calculates minimal poison samples required - needed for τ metric
- **Classification difficulty:** Measures inherent hardness of samples during clean training - needed for EPA baseline
- **Training trajectory approximation:** Simulates how models evolve during training - needed for all three metrics
- **Adversarial perturbation analysis:** Studies minimal changes needed to cause misclassification - needed for δ computation

## Architecture Onboarding

**Component Map:** Clean training data → EPA/δ/τ computation → Difficulty prediction → Attack vulnerability assessment

**Critical Path:** Clean training → Trajectory sampling → Metric computation → Difficulty classification

**Design Tradeoffs:** Computational efficiency vs. accuracy tradeoff in ergodic approximation; broad applicability vs. dataset-specific calibration

**Failure Signatures:** Poor correlation between metrics and actual attack success suggests distributional mismatch or inadequate trajectory sampling

**First Experiments:** 1) Compute EPA on CIFAR-10 test samples and compare to clean accuracy; 2) Measure δ for samples with varying EPA values; 3) Validate τ predictions against known poisoning budgets

## Open Questions the Paper Calls Out
None

## Limitations
- Metrics validated primarily on CIFAR-10 and TinyImageNet, limiting generalizability to other datasets
- Reliance on ergodic methods introduces computational overhead that may constrain practical deployment
- Assumption that clean training data captures poisoning difficulty may fail under distribution shifts
- Performance on architectures beyond standard CNNs remains unexplored

## Confidence
- EPA effectively separates easy-to-poison from hard-to-poison samples: **High**
- δ and τ provide fine-grained predictions for specific poison classes: **Medium**
- Metrics can be computed without actual poisoning attacks: **High**

## Next Checks
1. Test EPA, δ, and τ metrics on diverse model architectures beyond standard CNNs, including transformers and vision-language models
2. Evaluate metric performance under distribution shift conditions where test samples differ from training distribution
3. Benchmark computational efficiency of ergodic-based EPA computation against practical deployment constraints in real-world systems