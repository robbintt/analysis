---
ver: rpa2
title: 'ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling'
arxiv_id: '2510.27610'
source_url: https://arxiv.org/abs/2510.27610
tags:
- modeling
- problem
- equivalence
- optimization
- instance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of evaluating Large Language
  Models (LLMs) on optimization modeling tasks. The key difficulty is that equivalent
  optimization models can have different structures, making it hard to assess correctness.
---

# ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling

## Quick Facts
- arXiv ID: 2510.27610
- Source URL: https://arxiv.org/abs/2510.27610
- Authors: Zhuohan Wang, Ziwei Zhu, Ziniu Li, Congliang Chen, Yizhou Han, Yufeng Lin, Zhihang Lin, Angyang Gu, Xinglin Hu, Ruoyu Sun, Tian Ding
- Reference count: 40
- Primary result: ORGEval achieves 100% consistency in evaluating LLM-generated optimization models while running in seconds, outperforming solver-based methods that suffer from inconsistency and infeasibility issues.

## Executive Summary
This paper addresses the challenge of evaluating Large Language Models (LLMs) on optimization modeling tasks, where equivalent optimization models can have different structures making correctness assessment difficult. Traditional solver-based evaluation methods are inconsistent, computationally expensive, and fail when problems are infeasible. ORGEval introduces a graph-theoretic framework that reduces model equivalence detection to graph isomorphism testing using the Weisfeiler-Lehman (WL) test, with guaranteed correctness when graphs satisfy the symmetric decomposable (SD) property. The framework demonstrates significant improvements in evaluation speed and consistency while creating Bench4Opt, a dataset for optimization modeling that enables systematic benchmarking of LLMs.

## Method Summary
ORGEval converts Linear/Mixed-Integer Programming instances to weighted bipartite graphs where nodes represent variables and constraints, and edges encode coefficient matrices. The Weisfeiler-Lehman test iteratively refines node colors based on neighborhood structure, while the symmetric decomposable property provides a sufficient condition for guaranteed isomorphism detection. The framework uses random parameter sampling to generate instances that satisfy SD conditions with high probability, enabling efficient evaluation without manual instance curation. ORGEval compares color distributions between ground-truth and test instances, declaring equivalence only when both graphs are SD and have identical colorings.

## Key Results
- ORGEval achieves 100% consistency across 5 random parameter configurations, significantly outperforming solver-based methods
- Evaluation completes in seconds even for large instances, compared to minutes or failure for solver-based approaches
- Bench4Opt dataset enables systematic benchmarking, with DeepSeek-V3 and Claude-Opus-4 achieving highest accuracy among tested LLMs
- Zero inconsistency rate compared to solver-based methods that show significant variability across parameter samples

## Why This Works (Mechanism)

### Mechanism 1
Optimization model equivalence can be detected by testing graph isomorphism on bipartite graph representations. A MILP/LP instance with m constraints and n variables converts to a weighted bipartite graph G = (V ∪ W, E), where V represents constraints and W represents variables. Edge weights encode coefficient matrix A, while node features capture objective coefficients, variable types, constraint bounds, and operators. Permutation of variables/constraints in the original model corresponds exactly to graph isomorphism in this representation.

### Mechanism 2
The Weisfeiler-Lehman (WL) test provides polynomial-time isomorphism detection with guaranteed correctness when graphs satisfy the "symmetric decomposable" (SD) property. WL-test iteratively refines node "colors" by aggregating neighbor color multisets. Converged color distributions form a graph signature. For SD graphs, the paper proves that identical color distributions ⇔ isomorphism. The SD condition requires that after WL coloring, non-uniquely-colored nodes partition into k equal-sized disjoint groups where each group has all distinct colors, groups share the same color sets, and groups are mutually disconnected.

### Mechanism 3
Random parameter sampling from model parameter supports yields symmetric decomposable instances with high probability, enabling reliable SD-based evaluation without manual instance curation. The paper shows that if each decision variable's parameter vector has at least one coordinate drawn independently from a continuous distribution, parameter collisions across variables/constraints become probability-zero events. This structural diversity prevents the symmetries that break WL-test, making random instances SD almost surely.

## Foundational Learning

- **MILP/LP Standard Form and Model-Data Separation**: Why needed here - The paper assumes optimization models map parameter configurations θ to instances P with shared structure but varying numerical data. Understanding min c^T x s.t. Ax ∘ b, with variable types τ, is essential to grasp how "equivalence" differs from "same optimal value." Quick check question: Given two LP models with identical variables/constraints but different coefficient matrices A, are they guaranteed to have different optimal values under all parameter configurations?

- **Graph Isomorphism vs. WL-Test**: Why needed here - WL-test is a fast approximation for graph isomorphism but can fail on certain graph families. The paper's contribution is identifying SD graphs as a tractable subset where WL-test is provably correct. Quick check question: If WL-test outputs identical color distributions for two graphs, are they guaranteed to be isomorphic? (Answer: No, unless additional conditions like SD are satisfied.)

- **Bipartite Graph Construction for Constraint Systems**: Why needed here - The encoding of optimization instances as bipartite graphs (variable nodes, constraint nodes, weighted edges) is the representational foundation. Missing this makes the entire isomorphism-reduction opaque. Quick check question: In the bipartite graph representation, what information is stored in node features vs. edge weights?

## Architecture Onboarding

- **Component map**: Instance Generator -> Graph Encoder -> WL-Coloring Engine -> SD-Detector -> Equivalence Decider
- **Critical path**: 1) LLM generates test code → execute with parameters → extract test instance; 2) Load ground-truth instance from Bench4Opt; 3) Encode both as bipartite graphs; 4) Run WL-test on both graphs; 5) SD-check on test graph (ground-truth guaranteed SD by dataset construction); 6) Compare color distributions → equivalence verdict
- **Design tradeoffs**: Stricter equivalence definition permits only variable renaming and constraint reordering, excluding mathematically valid reformulations (slack variables, equivalent constraint combinations). SD requirement means all ground-truth instances must be SD, limiting applicability to problem classes that naturally satisfy this condition. Parameter sampling trades theoretical completeness for computational feasibility.
- **Failure signatures**: False positive (rare under SD) - Non-isomorphic graphs produce identical WL colors → incorrect "equivalent" verdict. False negative - SD-check fails on test instance → returns "not equivalent" even if structurally correct but non-SD. Compilation error - LLM code doesn't run → no instance to evaluate. Infeasible instance - ORGEval still works for structural comparison unlike solver-based methods.
- **First 3 experiments**: 1) Validate WL-test on known SD/non-SD pairs by constructing small MILP instances by hand and manually verifying SD detection matches Algorithm 3 output. 2) Reproduce consistency comparison by sampling 5 random parameter configurations for 20 Bench4Opt problems and verifying 100% consistency claim. 3) Runtime scaling analysis by measuring ORGEval evaluation time on MIPLIB instances across problem sizes (100, 1000, 10000 variables+constraints).

## Open Questions the Paper Calls Out

- **Can ORGEval evaluate non-linear optimization problems?**: The paper explicitly limits scope to linear and mixed-integer linear programs. Non-linear constraints involve products or functions of variables, requiring different graph topology that is not addressed. Evidence would require modified graph construction capable of representing non-linear terms combined with proof of whether SD condition holds or can be adapted.

- **How to accommodate valid but structurally non-isomorphic formulations?**: ORGEval's definition of model equivalence is stricter than conventionally adopted in OR, failing to recognize valid reformulations that alter graph structure such as adding slack variables or using strong formulations. Evidence would require extension to verify "model-lossless-reduction" rather than strict isomorphism.

- **Why do reasoning models underperform in this domain?**: The authors observe that reasoning models like o1 and DeepSeek-R1 consistently exhibit lower accuracy and appear susceptible to hallucination propagation, with cascading effects contributing to progressive accuracy degradation. Evidence would require ablation study analyzing intermediate reasoning traces to identify where mathematical formulation diverges.

## Limitations

- **SD property dependency**: ORGEval's correctness guarantee depends entirely on the symmetric decomposable property, which may not hold for all problem classes including highly symmetric formulations or manually crafted instances.
- **Strict equivalence definition**: The framework's equivalence definition permits only variable renaming and constraint reordering, potentially rejecting structurally equivalent models that differ by slack variables or constraint reformulations.
- **Ground-truth requirements**: All ground-truth instances must satisfy SD conditions, limiting applicability to problem classes that naturally satisfy this requirement under random parameter sampling.

## Confidence

- **High Confidence**: ORGEval's runtime efficiency and consistency claims (sub-minute evaluation, 100% consistency) are directly supported by experimental results in Table 1 and Section 4.2.
- **Medium Confidence**: Theoretical guarantees for WL-test on SD graphs are mathematically rigorous, but practical applicability depends on whether real optimization problems satisfy SD conditions under random sampling.
- **Medium Confidence**: Benchmark results comparing LLMs are internally consistent but limited to a single dataset (Bench4Opt) with specific problem characteristics.

## Next Checks

1. **SD Property Validation**: Systematically test ORGEval on optimization problems known to have high symmetry (e.g., traveling salesman, bin packing) to identify when SD detection fails and quantify the conservative false-negative rate.

2. **Equivalence Definition Stress Test**: Compare ORGEval's structural equivalence judgments against solver-based solution-equivalence on instances where models differ by slack variables or constraint reformulations to quantify the strictness tradeoff.

3. **Cross-Dataset Generalization**: Apply ORGEval to optimization problems from other sources (e.g., OR-Library, COPs) with varying symmetry characteristics to assess whether SD detection generalizes beyond Bench4Opt's construction.