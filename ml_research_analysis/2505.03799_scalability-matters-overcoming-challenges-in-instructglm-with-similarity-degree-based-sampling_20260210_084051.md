---
ver: rpa2
title: 'Scalability Matters: Overcoming Challenges in InstructGLM with Similarity-Degree-Based
  Sampling'
arxiv_id: '2505.03799'
source_url: https://arxiv.org/abs/2505.03799
tags:
- graph
- node
- sdm-instructglm
- available
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SDM-InstructGLM, a method to enhance Large
  Language Models (LLMs) for graph-based tasks without relying on Graph Neural Networks
  (GNNs). The core challenge addressed is the limited ability of LLMs to process large-scale
  graph structures due to token constraints and lack of dedicated graph mechanisms.
---

# Scalability Matters: Overcoming Challenges in InstructGLM with Similarity-Degree-Based Sampling

## Quick Facts
- arXiv ID: 2505.03799
- Source URL: https://arxiv.org/abs/2505.03799
- Authors: Hyun Lee; Chris Yi; Maminur Islam; B. D. S. Aritra
- Reference count: 40
- One-line primary result: SDM-InstructGLM improves node classification accuracy by 19.2% on Cora and 0.67% on PubMed through similarity-degree-based biased sampling.

## Executive Summary
This paper introduces SDM-InstructGLM, a method to enhance Large Language Models (LLMs) for graph-based tasks without relying on Graph Neural Networks (GNNs). The core challenge addressed is the limited ability of LLMs to process large-scale graph structures due to token constraints and lack of dedicated graph mechanisms. SDM-InstructGLM introduces a similarity-degree-based biased random walk that selectively samples nodes using cosine similarity of node features and degree centrality, enabling efficient and structured graph encoding. This approach improves token utilization and mitigates information loss from random sampling.

## Method Summary
SDM-InstructGLM replaces random neighbor sampling in LLM-based graph learning with a structured, biased sampling approach. The method calculates transition probabilities using the product of cosine similarity between node embeddings and degree centrality, then sorts selected nodes by this combined score. This creates an efficient token budget allocation that prioritizes semantically and structurally important nodes. The approach is tested on Cora and PubMed datasets using Llama-7B fine-tuned with LoRA, achieving significant accuracy improvements over baseline InstructGLM implementations.

## Key Results
- On Cora dataset: 1-hop accuracy improves by 19.2% (to 81.74%) and 2-hop by 16.3% (to 84.92%)
- On PubMed dataset: 1-hop accuracy improves by 0.15% (to 91.70%) and 2-hop by 0.67% (to 91.48%)
- Ablation studies confirm both similarity and degree-based weighting are critical, especially for sparse graphs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Biased random walks based on feature similarity and degree centrality serve as a proxy for attention mechanisms, improving the signal-to-noise ratio in subgraph sampling.
- Mechanism: The method calculates a transition probability $p(v|u)$ using the product of cosine similarity between node embeddings and the degree of the target node (Eq. 10-13). This prioritizes traversing to neighbors that are both semantically related and structurally prominent, filtering out less relevant nodes before they consume the LLM's context window.
- Core assumption: The paper assumes that nodes critical for classification tasks exhibit either high feature similarity (homophily) or high structural connectivity (centrality).
- Evidence anchors:
  - [abstract] "...selectly samples and encodes graph information based on node-feature similarity and degree centrality..."
  - [section IV.A] "...probability of transitioning to a neighboring node is influenced by both the cosine similarity... and the degree centrality..."
  - [corpus] Related work in the corpus (e.g., SSTAG, ATLAS) discusses structure-aware learning, but does not explicitly validate this specific similarity-degree heuristic for LLMs.
- Break condition: Performance may degrade on heterophilic graphs where connected nodes belong to different classes (low feature similarity), as the bias would filter out dissimilar but structurally necessary neighbors.

### Mechanism 2
- Claim: Structured node ordering enhances the LLM's ability to process graph topology by priming the model with the most relevant context early in the sequence.
- Mechanism: Instead of random permutation, sampled nodes are sorted by a cumulative score $s(v) = \text{cosSim} \cdot \text{deg}(v)$. This places semantically and structurally heavy nodes at the start of the prompt, potentially leveraging the LLM's causal attention mechanism more effectively.
- Core assumption: LLMs process sequential graph descriptions more effectively when high-priority tokens appear earlier, mimicking "prefix-tuning" effects or primacy bias.
- Evidence anchors:
  - [section IV.B] "Nodes in $V'$ are then sorted in descending order of $s(v)$, ensuring that structurally and semantically significant nodes appear earlier..."
  - [section V.B] "...allows the LLM to capture meaningful topological dependencies more effectively..."
  - [corpus] The corpus does not provide comparative evidence on node ordering strategies within prompts for graph tasks.
- Break condition: If the LLM uses bidirectional attention (e.g., BERT-based encoders rather than causal decoders), the specific ordering of tokens may have reduced impact on performance.

### Mechanism 3
- Claim: Dynamic hop-aware token budgeting prevents context overflow while preserving multi-hop structural integrity better than fixed truncation.
- Mechanism: The system calculates a sampling cap $N_{sample}(h)$ per hop level based on the dataset's empirical average neighbor counts and a maximum token budget $T_{max}$.
- Core assumption: The optimal token allocation for a node's neighborhood follows the empirical distribution of the training graph structure.
- Evidence anchors:
  - [section IV.C] "...dynamically adjusts the allocation based on the empirical average node count per hop observed in the dataset."
  - [section V.C] Ablation studies show consistent improvements (+2.18% 1-hop) even with limited prompt nodes, suggesting efficient budget use.
  - [corpus] "Graph Learning at Scale" and "RapidGNN" in the corpus address neighbor explosion, supporting the necessity of sampling, but do not validate this specific dynamic allocation formula.
- Break condition: On graphs with highly irregular power-law distributions, average-based budgeting might starve high-degree nodes of necessary context or waste tokens on sparse regions.

## Foundational Learning

- Concept: **GraphSAGE / Neighbor Sampling**
  - Why needed here: This paper modifies the standard random walk sampling used in GraphSAGE-like architectures. Understanding that LLMs cannot ingest full neighborhoods (the "neighbor explosion" problem) is the baseline constraint this paper addresses.
  - Quick check question: Can you explain why uniform random sampling loses structural information compared to the biased approach proposed here?

- Concept: **Instruction Tuning (InstructGLM)**
  - Why needed here: The paper builds upon InstructGLM, which translates graph topology into natural language prompts. The mechanism relies on the model's ability to parse these textual graph descriptions as valid instructions.
  - Quick check question: How does the model handle the input "v connects with {v2} in 2 hops" differently from a standard GNN adjacency matrix multiplication?

- Concept: **Homophily vs. Heterophily**
  - Why needed here: The mechanism biases walks toward "similar" nodes. This relies heavily on the assumption of homophily (birds of a feather flock together). Understanding this distinction is critical for diagnosing failure cases.
  - Quick check question: If a graph is heterophilic (e.g., a fraud detection network where fraudsters connect to honest users), would a similarity-based bias still work?

## Architecture Onboarding

- Component map: Feature Encoder -> SDM Sampler -> Prompt Generator -> LLM Backbone
- Critical path: The **SDM Sampler** is the novel contribution. If the `cosSim` or `deg` weights are miscalculated, the "Attention Proxy" effect fails, and performance reverts to random sampling.
- Design tradeoffs:
  - **Semantic vs. Structural**: The $\alpha$ (implied as equal weighting in Eq. 10) trades off between feature similarity (semantic) and degree centrality (structural).
  - **Token Efficiency vs. Completeness**: Aggressive capping via $T_{max}$ prevents OOM errors but may sever critical 3-hop paths.
- Failure signatures:
  - **CORA vs. PubMed Gap**: If you see massive gains on sparse graphs (CORA) but minimal gains on dense graphs (PubMed), verify if the degree centrality weighting is drowning out neighbors in high-degree nodes (over-smoothing the context).
  - **Loss Spikes**: If loss diverges, check the prompt generator; invalid textual graph syntax can corrupt the instruction tuning process.
- First 3 experiments:
  1. **Sanity Check (Ablation)**: Run the pipeline on CORA with "w/o Cos Similarity" (Table III). Confirm the accuracy drop to ~63% to verify the similarity mechanism is active.
  2. **Token Sensitivity**: Vary the $T_{max}$ budget on the PubMed dataset to replicate the "Limited Prompt Node" results (Table IV) and find the breaking point where accuracy drops.
  3. **Heterophily Stress Test**: (Assumption-based) Test on a synthetic heterophilic graph (e.g., different colors connected) to see if the similarity bias causes accuracy to plummet below the random baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SDM-InstructGLM perform on large-scale industrial graphs (e.g., OGB) where context windows are insufficient to cover even 1-hop neighborhoods?
- Basis in paper: [explicit] Section V.A explicitly states resource limitations prevented testing on the larger ArXiv dataset used in the baseline.
- Why unresolved: The study is restricted to small/medium citation networks (Cora and PubMed), leaving scalability to massive graphs unverified.
- What evidence would resolve it: Evaluation on Open Graph Benchmark (OGB) datasets like Products or Papers100M containing millions of nodes.

### Open Question 2
- Question: Is the multiplicative combination of cosine similarity and degree centrality optimal, or should the weighting be topology-adaptive?
- Basis in paper: [inferred] Section IV.A uses a fixed product $z_{uv}$ without learnable weights, yet ablation studies (V.C) show differing sensitivities on Cora vs. PubMed.
- Why unresolved: The fixed heuristic may not generalize to graphs where semantic and structural importance are uncorrelated or inversely related.
- What evidence would resolve it: A comparative analysis using learnable attention weights versus the fixed product on diverse graph structures.

### Open Question 3
- Question: Which specific topological characteristics render structured node ordering superior to standard random sampling?
- Basis in paper: [explicit] The Conclusion states future work will "identify the specific characteristics within the dataset that brings advantage to our node-ordering method..."
- Why unresolved: The paper demonstrates *that* the method works but lacks a theoretical explanation for why it benefits specific datasets more than others.
- What evidence would resolve it: Controlled experiments on synthetic graphs varying diameter and density while holding semantic similarity constant.

## Limitations

- Heterophily Blindness: The mechanism fundamentally assumes homophily and may actively harm performance on heterophilic graphs where dissimilar nodes are structurally connected.
- Limited Dataset Scope: All experiments use Cora and PubMed, which are relatively small, dense, and homophilic text-attributed graphs.
- Unverified Prompt Templates: Critical implementation details—the exact instruction prefixes and classification query formats—are unspecified, creating a significant reproducibility barrier.

## Confidence

**High Confidence**: The core mechanism of biased random walks (Mechanism 1) and the ablation study results demonstrating the importance of both similarity and degree weighting are well-supported by the experimental evidence.

**Medium Confidence**: The claim that structured node ordering (Mechanism 2) meaningfully enhances LLM processing is supported by results but lacks direct comparative evidence within the paper or corpus. The token budgeting mechanism (Mechanism 3) shows empirical success but relies on dataset-specific assumptions.

**Low Confidence**: Claims about performance on heterophilic graphs or graphs substantially different from Cora/PubMed are speculative without experimental validation.

## Next Checks

1. **Heterophily Stress Test**: Implement a synthetic heterophilic graph (e.g., bipartite structure where connected nodes have different labels/classes) and compare SDM-InstructGLM performance against both the random baseline and traditional GNNs. Measure whether the similarity bias causes accuracy to fall below the random baseline.

2. **Prompt Template Verification**: Reconstruct the exact prompt templates by systematically varying the instruction prefix and classification query formats on Cora. Measure the performance sensitivity to these variations to identify the minimum viable template specification.

3. **Token Budget Sensitivity Analysis**: Conduct a systematic ablation study varying the $T_{max}$ parameter across multiple orders of magnitude on both Cora and PubMed. Identify the breaking point where accuracy degradation begins and characterize the relationship between token budget and performance gains.