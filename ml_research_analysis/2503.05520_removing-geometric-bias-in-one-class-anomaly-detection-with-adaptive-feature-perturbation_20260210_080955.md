---
ver: rpa2
title: Removing Geometric Bias in One-Class Anomaly Detection with Adaptive Feature
  Perturbation
arxiv_id: '2503.05520'
source_url: https://arxiv.org/abs/2503.05520
tags:
- plume
- normal
- class
- data
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of unsupervised one-class anomaly
  detection in images without relying on geometric biases present in standard datasets.
  The authors propose PLUME, a method that operates in frozen feature spaces from
  pretrained models and generates pseudo-anomalous features using an adaptive linear
  feature perturbation technique.
---

# Removing Geometric Bias in One-Class Anomaly Detection with Adaptive Feature Perturbation

## Quick Facts
- **arXiv ID**: 2503.05520
- **Source URL**: https://arxiv.org/abs/2503.05520
- **Reference count**: 40
- **Primary result**: PLUME achieves state-of-the-art performance on CIFAR-10 (84.5% AUC) and demonstrates robustness on geometric bias-free SPARK dataset (77% AUC)

## Executive Summary
This paper addresses the fundamental problem of geometric bias in one-class anomaly detection by proposing PLUME, a method that operates in frozen feature spaces from pretrained models. The authors identify that standard anomaly detection datasets contain geometric biases that make the task artificially easy, and introduce the SPARK dataset specifically designed to be free from such biases. PLUME uses adaptive linear feature perturbation to generate pseudo-anomalous samples by applying decaying linear perturbations to feature vectors, with noise distributions adapted to each sample. The method incorporates a contrastive learning objective to guide the classification process, achieving superior performance on both standard datasets (CIFAR-10 and CIFAR-100) and the bias-free SPARK dataset.

## Method Summary
PLUME operates by first extracting frozen features from pretrained models, then generating pseudo-anomalous samples through an adaptive linear feature perturbation technique. The perturbation mechanism applies decaying linear transformations to feature vectors, with noise distributions that adapt to each individual sample's characteristics. A contrastive learning objective is incorporated to guide the classification process, helping the model distinguish between normal and pseudo-anomalous samples. The method is trained end-to-end and demonstrates strong performance across multiple datasets while being specifically designed to avoid reliance on geometric biases present in standard datasets.

## Key Results
- Achieves state-of-the-art performance on CIFAR-10 with 84.5% average AUC across all classes
- Outperforms existing methods on CIFAR-100, reaching 80.3% average AUC
- Demonstrates robust performance on geometric bias-free SPARK dataset with 77% AUC using ResNet50 features
- Shows consistent improvement over baselines including OC-SVM, SVDD, and deep anomaly detection methods

## Why This Works (Mechanism)
The method's effectiveness stems from its ability to generate realistic pseudo-anomalous samples that capture the underlying data distribution without relying on geometric shortcuts. By adapting the noise distribution to each sample and applying decaying linear perturbations, PLUME creates perturbations that are both meaningful and challenging for the model to distinguish from true anomalies. The contrastive learning objective ensures that the model learns to separate normal and pseudo-anomalous samples in a way that generalizes beyond simple geometric differences, addressing the core limitation of existing approaches that exploit dataset biases.

## Foundational Learning
- **One-class anomaly detection**: Identifying samples that deviate from a learned normal class distribution; needed to frame the problem correctly and understand evaluation metrics
- **Geometric bias in datasets**: Systematic patterns in training data that make anomaly detection artificially easy; quick check: examine if anomalies can be detected by simple shape or color heuristics
- **Frozen feature spaces**: Using pretrained model embeddings without fine-tuning; needed to leverage transfer learning while maintaining computational efficiency
- **Adaptive perturbation**: Noise generation that varies based on input characteristics; quick check: verify perturbation magnitude scales with feature vector norms
- **Contrastive learning**: Training objective that pulls similar samples together while pushing dissimilar ones apart; needed to create meaningful separation between normal and pseudo-anomalous samples
- **Linear decay mechanisms**: Perturbations that reduce in magnitude over time or iterations; quick check: confirm decay rate prevents vanishing or exploding perturbations

## Architecture Onboarding
**Component map**: Input images -> Frozen feature extractor -> Adaptive perturbation module -> Contrastive loss -> Anomaly score
**Critical path**: Feature extraction → Perturbation generation → Contrastive training → Inference scoring
**Design tradeoffs**: Uses frozen features for efficiency but may miss domain-specific representations; adaptive perturbation adds complexity but improves sample quality; contrastive loss requires careful hyperparameter tuning
**Failure signatures**: Poor performance on datasets with strong geometric biases suggests insufficient perturbation strength; collapse to trivial solutions indicates contrastive loss imbalance; sensitivity to initialization may reveal optimization challenges
**First experiments**: 1) Ablation study removing contrastive loss component, 2) Evaluation on synthetic geometric bias datasets, 3) Sensitivity analysis of perturbation decay parameters

## Open Questions the Paper Calls Out
The paper acknowledges that while it demonstrates strong performance on image-based anomaly detection, the applicability of the adaptive feature perturbation approach to other data modalities such as time series or tabular data remains unexplored. Additionally, the reliance on pretrained frozen features may limit the method's effectiveness when such features are unavailable or poorly aligned with the target domain.

## Limitations
- Evaluation focuses primarily on image datasets, leaving cross-modal generalization unclear
- Reliance on pretrained frozen features may limit applicability in domains lacking suitable pretrained models
- While SPARK addresses geometric bias, broader domain robustness across diverse real-world scenarios remains underexplored

## Confidence
- Claims of outperforming state-of-the-art methods on CIFAR datasets: **High**
- Assertion of being "truly bias-free": **Medium** (geometric bias evaluation is rigorous but may not capture all practical biases)
- Performance claims on geometric bias-free data: **Medium** (limited dataset diversity)

## Next Checks
1. Test PLUME on non-image datasets (time series, tabular data) to verify cross-modal applicability
2. Conduct ablation studies to isolate contributions of contrastive loss, adaptive perturbation, and linear decay components
3. Evaluate performance under distribution shift scenarios with varying degrees of domain mismatch from pretraining data