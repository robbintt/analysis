---
ver: rpa2
title: Multi-granular Training Strategies for Robust Multi-hop Reasoning Over Noisy
  and Heterogeneous Knowledge Sources
arxiv_id: '2502.05944'
source_url: https://arxiv.org/abs/2502.05944
tags:
- reasoning
- knowledge
- amkor
- multi-hop
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AMKOR, a generative framework for multi-hop
  question answering that dynamically integrates parametric and retrieved knowledge
  while exploring reasoning trajectories using probabilistic beam reasoning. AMKOR
  employs a multi-granular learning strategy optimizing both local reasoning steps
  and global answer accuracy.
---

# Multi-granular Training Strategies for Robust Multi-hop Reasoning Over Noisy and Heterogeneous Knowledge Sources

## Quick Facts
- arXiv ID: 2502.05944
- Source URL: https://arxiv.org/abs/2502.05944
- Reference count: 36
- Key outcome: AMKOR achieves state-of-the-art performance, improving average F1 scores by 2.5% over baseline methods on multi-hop QA tasks.

## Executive Summary
This paper introduces AMKOR, a generative framework for multi-hop question answering that dynamically integrates parametric and retrieved knowledge while exploring reasoning trajectories using probabilistic beam reasoning. AMKOR employs a multi-granular learning strategy optimizing both local reasoning steps and global answer accuracy. Evaluated on four multi-hop QA datasets including HotpotQA and MuSiQue, AMKOR achieves state-of-the-art performance, improving average F1 scores by 2.5% over baseline methods. It demonstrates superior robustness to noisy knowledge, scalability, and effectiveness on complex multi-hop reasoning tasks. The framework effectively balances reasoning quality and computational efficiency through dynamic knowledge fusion and probabilistic trajectory exploration.

## Method Summary
AMKOR is a generative framework that combines parametric knowledge from large language models with retrieved external knowledge for multi-hop question answering. The system uses scaled dot-product attention for knowledge fusion, probabilistic beam reasoning to explore multiple reasoning trajectories, and a multi-granular loss function that jointly optimizes local reasoning steps and global answer accuracy. The framework is trained via stochastic gradient descent and evaluated on four benchmark datasets including HotpotQA and MuSiQue. The probabilistic beam reasoning mechanism generates multiple candidate reasoning paths, while the multi-granular loss ensures both intermediate reasoning quality and final answer correctness are optimized during training.

## Key Results
- Achieves state-of-the-art performance with 2.5% average F1 score improvement over baseline methods
- Demonstrates superior robustness to noisy knowledge, maintaining performance with up to 40% irrelevant context
- Effectively handles complex multi-hop reasoning tasks with 3-hop and 4-hop questions showing significant improvements

## Why This Works (Mechanism)
AMKOR works by dynamically fusing parametric and retrieved knowledge through scaled dot-product attention, allowing the model to leverage both memorized information and up-to-date external sources. The probabilistic beam reasoning explores multiple reasoning trajectories simultaneously, reducing the risk of cascading errors that often plague sequential reasoning approaches. The multi-granular loss function optimizes both local reasoning steps (ensuring intermediate reasoning quality) and global answer accuracy (ensuring final answer correctness), creating a balanced training objective that improves overall performance.

## Foundational Learning
- **Multi-hop reasoning**: Understanding how to decompose complex questions into intermediate reasoning steps - needed because multi-hop questions require connecting multiple pieces of information across different sources - quick check: verify the model can correctly identify and chain together intermediate reasoning steps
- **Knowledge fusion techniques**: Scaled dot-product attention for combining parametric and retrieved knowledge - needed to dynamically weigh different knowledge sources based on their relevance and reliability - quick check: measure attention weight distributions across different knowledge sources
- **Probabilistic beam search**: Exploring multiple reasoning trajectories rather than greedy decoding - needed to reduce error propagation and find optimal reasoning paths through noisy knowledge - quick check: compare performance with different beam sizes to find optimal trade-off
- **Multi-granular optimization**: Jointly optimizing local and global objectives - needed to balance intermediate reasoning quality with final answer accuracy - quick check: ablate local vs global loss components to verify their complementary effects
- **Retrieval-augmented generation**: Combining external knowledge retrieval with generative models - needed to overcome the knowledge limitations of parametric models while maintaining reasoning capabilities - quick check: measure performance degradation when retrieval is disabled
- **Noisy knowledge handling**: Robustness to irrelevant or incorrect retrieved information - needed because real-world knowledge sources often contain noise and contradictions - quick check: systematically add noise to retrieved passages and measure performance degradation

## Architecture Onboarding

Component map: Question -> Retrieval Engine -> Fusion Module -> Probabilistic Beam Reasoning -> Answer Generator -> Output

Critical path: Question → Retrieval → Fusion → Beam Reasoning → Answer Generation

Design tradeoffs:
- Beam size vs. computational efficiency: Larger beams explore more reasoning paths but increase latency
- Local vs. global loss weights: Balancing intermediate reasoning quality against final answer accuracy
- Number of retrieved snippets: More snippets provide better coverage but increase noise and computation
- Knowledge source selection: Balancing parametric knowledge reliability against retrieved knowledge freshness

Failure signatures:
- Knowledge omission errors (41.2% of failures): Missing critical information in retrieved passages
- Cascading errors: Poor intermediate reasoning leading to incorrect final answers
- Fusion conflicts: Inability to resolve contradictory information from different sources
- Over-reliance on parametric knowledge: Failure to leverage retrieved information effectively

First experiments:
1. Ablation study: Compare AMKOR performance with only global loss (λ_local=0) versus only local loss (λ_global=0) to verify multi-granular training benefits
2. Retrieval impact analysis: Disable retrieval and measure performance drop to quantify the value of external knowledge
3. Beam size sensitivity: Test performance across beam sizes 1, 3, 5, and 10 to find optimal trade-off between accuracy and efficiency

## Open Questions the Paper Calls Out
- How to maintain robustness in "extremely noisy environments" beyond the 40% noise level evaluated, as the current analysis is limited to maximum 40% irrelevant context
- How to enhance retrieval mechanisms to mitigate "knowledge omission," which accounts for 41.2% of errors, by integrating wider-ranging or iterative retrieval strategies
- How to reduce inference latency to match single-pass baselines (0.8s) without sacrificing accuracy gains, as current 1.2s latency is 50% higher

## Limitations
- Lack of specific hyperparameter values (λ_local, λ_global, beam size, learning rate) makes reproduction challenging
- No specification of base LLM architecture and size creates uncertainty about implementation details
- Computational overhead from multi-granular training approach and beam reasoning not fully characterized

## Confidence
- **High confidence**: Core methodology (scaled dot-product attention, beam search) follows established patterns
- **Medium confidence**: Multi-granular loss formulation is mathematically coherent and performance improvements are likely real
- **Low confidence**: Robustness claims lack specific validation metrics beyond F1 scores

## Next Checks
1. **Ablation study verification**: Test AMKOR performance with only global loss versus only local loss to confirm synergistic benefit of multi-granular training
2. **Knowledge omission error analysis**: Manually examine 50 failed cases from MuSiQue to verify ~41% are knowledge omission errors, then test whether expanding retrieval snippets improves these failures
3. **Cascading error measurement**: For 3-hop and 4-hop questions, measure whether probabilistic beam reasoning reduces error propagation compared to greedy decoding by comparing per-hop reasoning accuracy