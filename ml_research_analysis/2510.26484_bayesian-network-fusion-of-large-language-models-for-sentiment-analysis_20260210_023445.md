---
ver: rpa2
title: Bayesian Network Fusion of Large Language Models for Sentiment Analysis
arxiv_id: '2510.26484'
source_url: https://arxiv.org/abs/2510.26484
tags:
- sentiment
- bnlf
- llms
- financial
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces BNLF, a Bayesian network-based framework for
  sentiment analysis that fuses predictions from multiple large language models (LLMs)
  including FinBERT, RoBERTa, and BERTweet. BNLF addresses challenges of inconsistency,
  interpretability, and computational cost in using domain-specific LLMs for financial
  sentiment analysis by modeling LLM predictions as probabilistic nodes within a Bayesian
  network, enabling principled late fusion and transparent reasoning.
---

# Bayesian Network Fusion of Large Language Models for Sentiment Analysis

## Quick Facts
- arXiv ID: 2510.26484
- Source URL: https://arxiv.org/abs/2510.26484
- Authors: Rasoul Amirzadeh; Dhananjay Thiruvady; Fatemeh Shiri
- Reference count: 12
- Primary result: BNLF achieves 78.6% accuracy on combined test set, improving over baseline LLMs by approximately six percentage points

## Executive Summary
This paper introduces BNLF, a Bayesian network-based framework for sentiment analysis that fuses predictions from multiple large language models (LLMs) including FinBERT, RoBERTa, and BERTweet. The framework addresses challenges of inconsistency, interpretability, and computational cost in using domain-specific LLMs for financial sentiment analysis by modeling LLM predictions as probabilistic nodes within a Bayesian network, enabling principled late fusion and transparent reasoning. Evaluated on three diverse financial datasets, BNLF consistently improves accuracy by approximately six percentage points over baseline LLMs, achieving 78.6% accuracy on the combined test set, with balanced performance across sentiment classes.

## Method Summary
BNLF constructs a Bayesian network where LLM sentiment predictions form probabilistic nodes connected to an input text node (representing corpus type) and a sentiment prediction node. The network structure enforces conditional independence between LLM predictions given the input text, with conditional probability tables (CPTs) learned from training data. During inference, LLM predictions are fed as evidence, and the network computes posterior sentiment probabilities through probabilistic inference. The framework requires no additional fine-tuning and operates at decision level, making it lightweight and interpretable.

## Key Results
- BNLF improves sentiment classification accuracy by approximately six percentage points over baseline LLMs
- Achieves 78.6% accuracy on combined test set (Financial PhraseBank, FIQA, and Twitter Financial News Sentiment)
- Maintains balanced performance across sentiment classes (NEG, NEU, POS) with no class domination
- Demonstrates corpus-specific performance variation: 66.5% negative sentiment accuracy on TFNS vs. 95%+ on Financial PhraseBank and FIQA

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Late fusion via Bayesian networks outperforms simple ensemble aggregation by modeling conditional dependencies rather than combining predictions linearly.
- Mechanism: BNLF constructs a DAG where LLM prediction nodes are conditionally independent given the input text, then learns CPTs from training data that capture how each model's predictions relate to ground-truth sentiment. The joint probability distribution enables principled fusion that accounts for model-specific reliability patterns.
- Core assumption: The conditional independence assumption between LLM prediction nodes holds—that model outputs don't directly influence each other beyond their shared dependence on input text characteristics.
- Evidence anchors:
  - [abstract] "BNLF performs late fusion by modelling the sentiment predictions from multiple LLMs as probabilistic nodes within a Bayesian network"
  - [section 4, p.7-8] "No arcs are allowed between the LLM prediction nodes, enforcing conditional independence... This structure ensures interpretability, reflects domain-specific relationships, and provides a principled basis for probabilistic fusion"
  - [corpus] Weak direct evidence; related work on Bayesian teaching for LLMs (FMR=0.598) suggests probabilistic frameworks improve reasoning but doesn't validate this specific fusion approach
- Break condition: If constituent models develop correlated errors (e.g., all trained on similar financial corpora), the independence assumption fails and BN may overweight their consensus.

### Mechanism 2
- Claim: Explicitly modeling corpus type as a conditioning node enables dataset-aware inference that adjusts sentiment predictions based on source characteristics.
- Mechanism: The Input Text node functions as a deterministic parent to each LLM prediction node, allowing the BN to learn corpus-specific prediction patterns. During inference, setting the corpus type propagates through the network to influence the posterior sentiment distribution.
- Core assumption: Corpus characteristics are stable and predictive of model behavior across the test distribution.
- Evidence anchors:
  - [section 6.2.1, p.15-17] Scenario analyses show "even with identical negative predictions from all LLMs, BNLF's outputs vary considerably by corpus"—TFNS yields 66.5% negative vs. 95%+ for Financial PhraseBank and FIQA
  - [section 6.2.2, p.18] Influence strength analysis shows corpus type directly affects BNLF output (influence=0.327)
  - [corpus] No direct corroboration; corpus signals show related work on probabilistic integration with textual evidence but not corpus-conditioning specifically
- Break condition: If deployment involves corpus types not represented in training data, the Input Text node conditioning may produce unreliable posteriors.

### Mechanism 3
- Claim: Complementary model specializations (domain-specific vs. general vs. social-media-trained) provide diverse signals that the BN can weight according to learned influence strengths.
- Mechanism: FinBERT (financial domain), RoBERTa (general-purpose), and BERTweet (Twitter-specific) capture different linguistic patterns. The BN's learned CPTs encode how reliably each model's predictions correlate with ground truth under different conditions.
- Core assumption: Model diversity translates to prediction diversity that BN can exploit—models must disagree in informative ways rather than making identical errors.
- Evidence anchors:
  - [section 4, p.7] "Together, these models capture complementary aspects of sentiment across financial and social media corpora"
  - [section 6.2.2, p.18] Influence analysis shows FinBERT has strongest direct influence (0.364), followed by RoBERTa (0.320) and BERTweet (0.309), with different corpus effects on each
  - [section 6.1, p.13-14] Pairwise agreement analysis shows RoBERTa-BERTweet have highest agreement (82.4%) while FinBERT-RoBERTa agree less (65.9%), confirming meaningful diversity
  - [corpus] Multi-agent probabilistic inference frameworks (FMR=0.513) support diversity-based debiasing but don't validate this specific combination
- Break condition: If all models share systematic biases (e.g., positivity bias in financial text), the BN will amplify rather than correct these biases.

## Foundational Learning

- Concept: Bayesian Network structure (DAG + CPTs)
  - Why needed here: BNLF's entire fusion mechanism depends on understanding how directed edges encode conditional dependencies and how CPTs parameterize those relationships.
  - Quick check question: Given a BN with nodes A→B→C, is A conditionally independent of C given B?

- Concept: Late fusion vs. early fusion
  - Why needed here: BNLF specifically uses decision-level (late) fusion rather than feature-level combination; understanding this distinction clarifies why no fine-tuning is required.
  - Quick check question: Why might late fusion be preferred when integrating models with different architectures?

- Concept: Conditional probability and posterior inference
  - Why needed here: BNLF outputs posterior sentiment distributions given evidence (LLM predictions + corpus type); interpreting results requires understanding how evidence updates beliefs.
  - Quick check question: In BNLF, what happens to the posterior sentiment distribution if all three LLMs predict "negative" for a TFNS input?

## Architecture Onboarding

- Component map:
  1. Input Text node (deterministic) → identifies corpus source
  2. LLM Module (FinBERT, RoBERTa, BERTweet) → generates discrete sentiment predictions
  3. Bayesian Network → DAG with CPTs learned from training data
  4. Probabilistic Sentiment Prediction node → posterior distribution over {NEG, NEU, POS}
  5. Label mapping → argmax of posterior to discrete output

- Critical path: Input text → three parallel LLM inference calls → prediction tuple (e.g., NEG, NEU, POS) → BN inference with corpus type evidence → posterior distribution → final label

- Design tradeoffs:
  - Efficiency vs. expressiveness: Using discrete predictions (not confidence scores) simplifies CPT learning but discards uncertainty information from individual models
  - Interpretability vs. performance: Constraining BN structure via domain knowledge ensures explainability but may miss data-driven dependencies
  - Model size vs. deployability: Medium-sized LLMs (~110-135M params) enable CPU/single-GPU deployment but may lack capacity of larger models

- Failure signatures:
  - All models predict same class but BN output differs significantly → check corpus-type conditioning effects
  - Low agreement between BNLF and constituent models on new corpus → CPTs may not generalize; consider retraining
  - Neutral class dominance regardless of inputs → class imbalance in training data may bias CPTs

- First 3 experiments:
  1. Reproduce baseline comparison: Run FinBERT, RoBERTa, BERTweet, and BNLF on the combined test set; verify ~6% accuracy improvement holds
  2. Ablate corpus conditioning: Set Input Text node to uniform distribution and measure performance drop to quantify corpus-conditioning contribution
  3. Test out-of-distribution corpus: Apply BNLF to a fourth financial dataset (e.g., different time period or platform) without retraining to assess generalization bounds

## Open Questions the Paper Calls Out
None

## Limitations
- Conditional independence assumption between LLM prediction nodes lacks empirical validation and may fail if models develop correlated errors
- Framework's performance on out-of-distribution corpora or unseen financial domains has not been tested
- BN structure relies on domain knowledge rather than data-driven structure learning, potentially missing complex dependencies

## Confidence
- High Confidence: The mechanism of using Bayesian networks for late fusion is well-established theoretically. The framework's architecture and inference process are clearly described and reproducible.
- Medium Confidence: The claimed ~6 percentage point improvement over baselines is supported by experimental results on three datasets, but lacks absolute performance metrics and out-of-distribution testing.
- Low Confidence: The conditional independence assumption between LLM predictions and the generalization to unseen financial corpora remain largely unverified assumptions.

## Next Checks
1. Out-of-distribution corpus testing: Apply BNLF to a fourth financial sentiment dataset from a different time period or source platform without retraining to quantify performance degradation and identify generalization limits.
2. Conditional independence validation: Systematically test the independence assumption by measuring pairwise correlations between LLM prediction errors and analyzing whether correlated errors degrade BNLF performance compared to ensemble methods.
3. Ablation of corpus conditioning: Run BNLF with the Input Text node set to uniform distribution across all test sets to quantify the exact contribution of corpus-type conditioning to the overall performance improvement.