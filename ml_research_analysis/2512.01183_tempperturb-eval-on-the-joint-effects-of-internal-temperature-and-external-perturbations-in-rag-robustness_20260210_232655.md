---
ver: rpa2
title: 'TempPerturb-Eval: On the Joint Effects of Internal Temperature and External
  Perturbations in RAG Robustness'
arxiv_id: '2512.01183'
source_url: https://arxiv.org/abs/2512.01183
tags:
- temperature
- perturbations
- across
- perturbation
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study systematically investigates how temperature settings
  in Retrieval-Augmented Generation (RAG) systems interact with external text perturbations
  simulating noisy retrieval. The research reveals that high temperature settings
  amplify vulnerability to perturbations, while different perturbation types exhibit
  non-linear sensitivity across the temperature range.
---

# TempPerturb-Eval: On the Joint Effects of Internal Temperature and External Perturbations in RAG Robustness

## Quick Facts
- arXiv ID: 2512.01183
- Source URL: https://arxiv.org/abs/2512.01183
- Reference count: 0
- This study systematically investigates how temperature settings in RAG systems interact with external text perturbations simulating noisy retrieval.

## Executive Summary
This research examines how temperature settings in Retrieval-Augmented Generation (RAG) systems interact with external text perturbations to affect robustness under noisy retrieval conditions. Through controlled experiments with five LLMs (GPT-3.5, GPT-4o, Llama-3.1, Llama-3.2, and DeepSeek-Reasoner) on HotpotQA, the study reveals that high temperature settings amplify vulnerability to perturbations while different perturbation types exhibit non-linear sensitivity across the temperature range. The findings demonstrate that temperature proves to be a more pronounced influence on model correctness than specific perturbation types, with temperature and perturbations jointly creating fragility landscapes where systems fail dramatically when facing real-world noise combined with typical sampling strategies.

## Method Summary
The study systematically evaluates five LLMs (GPT-3.5, GPT-4o, Llama-3.1-8B, Llama-3.2-1B, DeepSeek-Reasoner) on 600 HotpotQA samples (100 per fact-count × question-type combination) across temperature settings from 0.0 to 2.0 in 0.2 increments. Three perturbation types are applied to supporting sentences: Sentence Replacement (swapping latter portion with irrelevant sentences), Sentence Removal (deleting latter half), and NER Replacement (masking named entities with [MASK] tokens). Each condition runs three inference passes, with BERTScore F1 (RoBERTa-large) as the primary metric against reference answers expanded via GPT-4o.

## Key Results
- High temperature settings consistently amplify vulnerability to perturbations across all perturbation types
- DeepSeek-Reasoner maintains consistent performance across temperatures while GPT models degrade significantly above T=1.4 and Llama models show earlier deterioration around T=0.6
- Temperature proves to be a more pronounced influence on model correctness than specific perturbation types
- Temperature and perturbations jointly create fragility landscapes where systems fail dramatically when facing real-world noise combined with typical sampling strategies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: High temperature settings amplify model vulnerability to input perturbations through sampling stochasticity
- Mechanism: Temperature controls the softmax sharpness over token logits. Higher T flattens the distribution, increasing the probability of sampling lower-likelihood tokens. When input context is perturbed, the already-shifted logit distribution becomes more unstable, making incorrect tokens competitive with correct ones.
- Core assumption: The flattening effect on logit distributions compounds with semantic noise from perturbations rather than averaging out
- Evidence anchors:
  - [abstract]: "high-temperature settings consistently amplify vulnerability to perturbations"
  - [Section 5.1]: "all perturbation types demonstrate amplified sensitivity compared to baseline conditions as temperature rises, suggesting that temperature acts as a performance degradation amplifier"
  - [corpus]: Weak direct evidence; RARE (arXiv:2506.00789) evaluates RAG robustness to noise but does not isolate temperature effects

### Mechanism 2
- Claim: Model architecture and training objective determine temperature sensitivity thresholds
- Mechanism: Reasoning-focused models (DeepSeek-Reasoner) generate Chain-of-Thought before final answers, which may constrain the output space and provide implicit regularization against sampling variance
- Core assumption: CoT generation creates a buffer that absorbs sampling variance before the final answer is produced
- Evidence anchors:
  - [Section 5.1]: "deepseek-reasoner maintains nearly invariant performance across the temperature range, GPT models exhibit degradation beginning at T = 1.4, Llama models demonstrate earlier performance deterioration at T = 0.6"
  - [Section 6.2]: "gpt-4o typically produces fluent but incorrect responses under perturbation... deepseek-reasoner often fails more gracefully with concise but incomplete answers"
  - [corpus]: No direct corpus evidence on CoT as temperature buffer; this is an inferential hypothesis

### Mechanism 3
- Claim: Sentence-level perturbations cause more degradation than entity-level perturbations due to information density disruption
- Mechanism: Sentence Replacement and Removal eliminate reasoning pathways required for multi-hop QA. NER Replacement preserves sentence structure and reasoning scaffolding, only corrupting specific entity tokens—which models may sometimes bypass using internal parametric knowledge
- Core assumption: Models can partially compensate for entity corruption using internal knowledge but cannot reconstruct missing reasoning chains
- Evidence anchors:
  - [Section 5.1]: "NER Replacement induces minimal degradation at T = 2.0, whereas Sentence Replacement and Sentence Removal lead to more substantial performance loss"
  - [Section 7]: "we observed instances where models maintained correctness despite substantial perturbations, suggesting utilization of internal knowledge"
  - [corpus]: RAG Safety (arXiv:2507.08862) documents knowledge conflicts but does not isolate perturbation granularity

## Foundational Learning

- Concept: **Softmax Temperature Scaling**
  - Why needed here: The entire paper hinges on understanding how T modifies token probability distributions
  - Quick check question: At T=2.0, does a token with logit 4.0 have higher or lower probability than at T=0.5?

- Concept: **Multi-hop Reasoning in QA**
  - Why needed here: HotpotQA bridge questions require connecting facts across documents; perturbation effects depend on where the break occurs in reasoning chains
  - Quick check question: If a bridge question asks "Which university has the larger campus?" and entity A's campus size is removed from context, can the question still be answered?

- Concept: **Coefficient of Variation (CV) for Output Stability**
  - Why needed here: The paper uses CV to distinguish temperature-induced variability from perturbation-induced variability
  - Quick check question: If mean BERTScore is 0.90 with std=0.05, what is the CV?

## Architecture Onboarding

- Component map:
  Input Layer -> LLM Generator (5 model options) -> Evaluation Layer
  HotpotQA query + retrieved supporting sentences (baseline) OR perturbed sentences (3 types) -> Five model options (GPT-3.5, GPT-4o, Llama-3.1-8B, Llama-3.2-1B, DeepSeek-Reasoner) with temperature parameter (0.0-2.0 in 0.2 increments) -> Reference answer expansion via GPT-4o → BERTScore/ROUGE computation against RoBERTa-large

- Critical path:
  1. Sample selection (100 per fact-count category × 2 question types = 600 samples)
  2. Apply perturbation to supporting sentences (baseline, sentence replacement, removal, NER replacement)
  3. Run 3 inference passes per (model, temperature, perturbation) condition
  4. Compute mean/std BERTScore; aggregate across samples

- Design tradeoffs:
  - BERTScore vs. Exact Match: Trade recall of semantic equivalence for sensitivity to perturbation-induced drift
  - 3 runs per condition: Balances computational cost against variance estimation (may be insufficient for high-T conditions where variance increases substantially)
  - Gold-context perturbation only: Isolates generator sensitivity but does not capture retrieval-generation compounding

- Failure signatures:
  - T≥1.4 with GPT models: Sharp BERTScore drop, high CV, refusal responses ("The retrieved document does not provide...")
  - T≥0.6 with Llama models: Gradual degradation with increased variability
  - T=2.0 across models: Garbled output, code snippets, mixed languages, complete query failure

- First 3 experiments:
  1. Baseline establishment: Run all 5 models at T=0.2 on unperturbed HotpotQA samples to confirm expected performance hierarchy
  2. Single perturbation stress test: Apply Sentence Removal to 50 bridge questions, run GPT-4o at T=0.2, 1.0, 1.6; verify non-linear degradation curve
  3. Cross-model threshold mapping: For a single question type (bridge), sweep temperature in 0.1 increments from 0.0-1.0 for Llama-3.1 to identify precise inflection point (paper reports ~0.6)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do retrieval inaccuracies and generation sensitivity compound in end-to-end RAG pipelines when using actual retrieval systems rather than perturbed gold contexts?
- Basis in paper: [explicit] The authors state: "The present study isolates the LLM generator's sensitivity by perturbing gold contexts, thereby controlling for retrieval noise. A future direction is to incorporate actual retrieval systems to examine how retrieval inaccuracies and generation sensitivity compound in end-to-end pipelines."
- Why unresolved: This study deliberately controlled for retrieval noise by using gold contexts; real retrieval systems introduce additional error modes not captured here
- What evidence would resolve it: Experiments combining actual retrieval systems (e.g., BM25, dense retrievers) with temperature and perturbation analysis on the same benchmark

### Open Question 2
- Question: What mechanisms determine when and how internal knowledge activates versus reliance on retrieved context in RAG systems under perturbation?
- Basis in paper: [explicit] The authors observe "instances where models maintained correctness despite substantial perturbations" but note "the unpredictable nature of this phenomenon, where models sometimes bypass corrupted context entirely but other times produce confidently wrong responses, highlights the challenge of determining when and how internal knowledge mechanisms activate in RAG settings."
- Why unresolved: The conditions triggering internal knowledge utilization versus context dependency remain uncharacterized
- What evidence would resolve it: Controlled experiments systematically varying knowledge freshness in training data and context reliability to identify activation thresholds

### Open Question 3
- Question: Do reasoning-focused models like DeepSeek-Reasoner maintain temperature robustness due to prioritizing logical coherence over discursive fluency?
- Basis in paper: [explicit] The authors hypothesize that "as a reasoning model, deepseek-reasoner may prioritize logical coherence and conciseness over the discursive fluency characteristic of a general-purpose model like gpt-4o, a hypothesis that merits further investigation."
- Why unresolved: The architectural and training differences underlying DeepSeek-Reasoner's unique temperature stability (nearly invariant performance across T=0–2.0) remain unexplained
- What evidence would resolve it: Ablation studies comparing reasoning-specialized models with their base versions, and analysis of attention patterns across temperature settings

### Open Question 4
- Question: Which question structures or knowledge domains exhibit greater fragility to the combined effects of temperature and perturbations?
- Basis in paper: [inferred] The authors note that "significant performance variability across samples suggests that certain question structures or knowledge domains are inherently more fragile than others," but only compared bridge versus comparison question types, finding minimal difference in temperature sensitivity patterns
- Why unresolved: The sample-level analysis was qualitative and limited to selected failure cases; systematic characterization of fragility factors was not conducted
- What evidence would resolve it: Regression analysis correlating performance degradation with linguistic features, entity types, reasoning complexity, and domain categories across the full sample set

## Limitations
- Controlled experimental setup may not fully capture real-world RAG complexity by perturbing only gold-context sentences rather than simulating the entire retrieval-generation pipeline
- Temperature sweep represents a narrow slice of possible sampling strategies; real RAG systems often employ adaptive or context-aware temperature schedules
- 3-run averaging per condition may be insufficient for high-temperature regimes where output variance increases substantially
- BERTScore metric introduces biases toward certain linguistic patterns and may not capture all forms of correctness degradation

## Confidence
- High Confidence: Temperature acts as a performance degradation amplifier across all perturbation types (well-supported by systematic experimental design)
- Medium Confidence: DeepSeek-Reasoner maintains consistent performance across temperatures due to its Chain-of-Thought architecture (empirical observation is robust but causal mechanism requires additional validation)
- Low Confidence: Sentence-level perturbations cause more degradation than entity-level perturbations due to information density disruption (assumes models cannot reconstruct missing reasoning chains from parametric knowledge)

## Next Checks
1. **End-to-end pipeline validation**: Extend the perturbation framework to include retrieval-stage noise (e.g., corrupted document titles, misranked passages) and measure whether temperature sensitivity patterns persist when perturbations occur before the generator receives context

2. **Adaptive temperature scheduling test**: Implement a context-aware temperature controller that adjusts T based on perturbation severity detection, then compare robustness against the fixed-temperature baseline

3. **Multi-model ensemble analysis**: Create ensembles combining high-temperature (T>1.0) and low-temperature (T<0.5) outputs from different models, then measure whether averaging across temperature-sensitive models reduces overall perturbation vulnerability