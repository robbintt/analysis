---
ver: rpa2
title: Value-Guided KV Compression for LLMs via Approximated CUR Decomposition
arxiv_id: '2509.15038'
source_url: https://arxiv.org/abs/2509.15038
tags:
- compression
- curdkv
- tokens
- attention
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CurDKV, a value-centric KV cache compression
  method for LLMs that uses leverage scores derived from CUR matrix decomposition
  to select tokens. Unlike existing methods that rely on attention scores, CurDKV
  computes importance based on the combined key and value matrices, with scalable
  approximations via random projections.
---

# Value-Guided KV Compression for LLMs via Approximated CUR Decomposition

## Quick Facts
- arXiv ID: 2509.15038
- Source URL: https://arxiv.org/abs/2509.15038
- Reference count: 40
- Primary result: Achieves up to 9.6% higher accuracy than baselines at 90% KV cache compression

## Executive Summary
This paper introduces CurDKV, a value-centric KV cache compression method for LLMs that uses leverage scores derived from CUR matrix decomposition to select tokens. Unlike existing methods that rely on attention scores, CurDKV computes importance based on the combined key and value matrices, with scalable approximations via random projections. Evaluated on LongBench and Ruler benchmarks across LLaMA and Mistral models, CurDKV outperforms state-of-the-art methods such as SnapKV and ChunkKV, achieving up to 9.6% higher accuracy at aggressive compression ratios (90% cache reduction) and reducing generation latency by up to 40%. It is compatible with FlashAttention and Grouped Query Attention, making it practical for efficient long-context inference.

## Method Summary
CurDKV compresses the KV cache by computing leverage scores through random Gaussian projections of key and value matrices. The method projects K and V matrices using a random matrix G∈R^(d×r) (r=20), computes row norms to approximate leverage scores, and combines key/value scores via element-wise multiplication. It preserves the first 4 tokens as sinks and selects the top-(k−s) tokens by score. AdaCurDKV extends this with per-head adaptive budget allocation. The approach operates during prefill phase, is compatible with FlashAttention (avoiding QK^T materialization), and reduces generation-time memory and latency.

## Key Results
- Outperforms SnapKV and ChunkKV baselines by up to 9.6% accuracy at 90% compression
- Achieves up to 40% reduction in generation latency while maintaining task performance
- Works effectively on LLaMA-3.1-8B-Instruct across 16 LongBench tasks and 8 Ruler needle-in-a-haystack tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Value vectors serve as a more reliable proxy for semantic importance than attention scores because attention intensity does not strictly correlate with the model's output reconstruction error.
- **Mechanism:** The method computes "leverage scores" (squared norms of left-singular vectors) for the Key and Value matrices. By selecting tokens with high scores in the Value matrix specifically, the method minimizes $\|V - V'\|_F$. Lemma 3.1 proves that minimizing this Value reconstruction error bounds the final attention output error $\|softmax(QK^T)V - softmax(QK'^T)V'\|_F$.
- **Core assumption:** The attention output fidelity (reconstruction loss) is the correct proxy for downstream task performance, rather than query-key alignment.
- **Evidence anchors:**
  - [Abstract]: "this heuristic overlooks the contribution of value vectors, which directly influence the attention output."
  - [Page 4]: Lemma 3.1 establishes the theoretical bound linking $V$ reconstruction to attention output reconstruction.
  - [Page 2, Figure 1]: Demonstrates visually that high average attention scores do not imply high eviction loss.
- **Break condition:** If a task relies heavily on positional retrieval where the "value" content is generic but the "key" position is unique, value-centric scoring might undervalue positional anchors.

### Mechanism 2
- **Claim:** Random Gaussian projections provide a scalable approximation of exact SVD-based leverage scores without materializing the full covariance matrix.
- **Mechanism:** Instead of calculating full SVD for $K$ and $V$, the algorithm projects these matrices into a lower-dimensional space $r$ (using a random matrix $G \sim \mathcal{N}(0, 1/r)$). The row norms of these projected matrices act as approximations of the true leverage scores, reducing complexity from $O(nd^2)$ to $O(ndr)$.
- **Core assumption:** The random projection preserves the relative ranking of row norms sufficiently to identify the top-$k$ tokens (Johnson-Lindenstrauss lemma implication).
- **Evidence anchors:**
  - [Page 5, Algorithm 1]: Lines 2-3 explicitly define the sampling and projection steps.
  - [Page 5]: "This maintains relative importance across tokens while significantly reducing computational cost."
  - [Corpus]: *CURing Large Models* applies similar CUR concepts to static weight compression; this paper adapts the approximation specifically for the dynamic KV cache.
- **Break condition:** If the projection dimension $r$ is too small relative to the sequence length $n$, the variance of the estimate may cause ranking errors, leading to the eviction of high-leverage tokens.

### Mechanism 3
- **Claim:** Combining Key and Value scores via element-wise multiplication ($\ell^K_j \cdot \ell^V_j$) balances input-sensitive (Key) and output-sensitive (Value) retention.
- **Mechanism:** Keys determine *where* to attend, while Values determine *what* is returned. Multiplying the scores ensures a token is retained only if it is significant in both the attention routing (Key) and the semantic output (Value), preventing the retention of tokens that are "attention sinks" with no semantic value, or semantically rich tokens that are never attended to.
- **Core assumption:** Importance is the intersection of routing relevance and semantic density.
- **Evidence anchors:**
  - [Page 5, Algorithm 1]: Line 5 defines the combined score.
  - [Page 7, Figure 3]: Ablation shows "Key-Value Product" and "Value" methods outperform "Key-only" at 90% compression.
  - [Corpus]: *WeightedKV* merges cache based on attention; this method explicitly distinguishes Key vs. Value utility.
- **Break condition:** In architectures with significant "attention sink" behavior (e.g., early layers), purely multiplicative scoring might suppress essential stability tokens if not for the explicit "attention sink" preservation step (Line 8).

## Foundational Learning

- **Concept:** **Leverage Scores (CUR Decomposition)**
  - **Why needed here:** This is the mathematical engine replacing attention heuristics. You must understand that a leverage score quantifies how much a specific row (token) contributes to the span (information content) of the entire matrix.
  - **Quick check question:** If a token has a high attention score but a low leverage score in $V$, what does CurDKV assume about its importance? (Answer: It assumes the token is less critical for the final output reconstruction).

- **Concept:** **KV Cache Prefill vs. Generation**
  - **Why needed here:** CurDKV operates primarily during the prefill phase (processing the prompt) to compress the cache before generation begins. You need to distinguish the compute-bound nature of prefill (where scoring happens) from the memory-bound nature of generation (where savings occur).
  - **Quick check question:** Does CurDKV reduce peak memory during the prefill phase or the generation phase? (Answer: Primarily generation, as scoring requires computing the cache first, though it reduces the *stored* cache immediately post-prefill).

- **Concept:** **FlashAttention Compatibility**
  - **Why needed here:** Many prior KV compression methods (like H2O) require accessing the $QK^T$ matrix, which FlashAttention fuses and hides. CurDKV is compatible because it computes scores from $K$ and $V$ directly, independent of the attention matrix calculation.
  - **Quick check question:** Why does relying on $QK^T$ scores break FlashAttention compatibility? (Answer: FlashAttention does not materialize the $N \times N$ attention matrix in HBM to save memory).

## Architecture Onboarding

- **Component map:** Key ($K$) and Value ($V$) matrices per layer/head group -> Projector: Random matrix $G$ generator -> Scorer: Computes row norms $\|K_i G\|$ and $\|V_i G\|$ -> Selector: Top-$k$ masker (preserves $k$ tokens + $s$ sinks) -> Outputs: Compressed $K', V'$

- **Critical path:**
  1.  **Projection:** Matrix multiplication ($K \cdot G$). This is the primary computational overhead added to the prefill step.
  2.  **Normalization:** Element-wise multiplication of Key and Value norms.
  3.  **Slicing:** Indexing the original tensors to extract the compressed cache.

- **Design tradeoffs:**
  - **Projection Dimension ($r$):** Paper defaults to $r=20$. Lower $r$ is faster but noisier scores; higher $r$ is more accurate but slower prefill.
  - **Static vs. Adaptive:** *AdaCurDKV* distributes the budget across heads based on score mass, while standard *CurDKV* uses a fixed budget per head.
  - **Latency vs. Accuracy:** The method trades increased prefill time (scoring overhead) for reduced generation time (smaller cache reads).

- **Failure signatures:**
  - **Mistral / Sliding Window:** The paper notes performance drops on Mistral at 90% compression (Page 9). This suggests the method struggles with architectures that use sliding windows or lack strong head specialization.
  - **Aggressive Compression:** Below 10% retention, key-value disentanglement may fail, causing "eviction loss" to spike unpredictably (Figure 2 curves).

- **First 3 experiments:**
  1.  **Reproduce Lemma 3.1 Proxy:** Plot "Average Attention Score" vs. "Value Leverage Score" for a random batch. Verify that high attention does not always overlap with high leverage (validating Figure 1).
  2.  **Prefill Overhead Profiling:** Measure the wall-clock time of the `Project -> Score -> Select` block independently of the model forward pass. Verify the claim of "scalable approximations" on sequence lengths $> 100k$.
  3.  **Ablation on Projection $r$:** Run the "Needle in a Haystack" (Ruler) task with $r \in \{5, 20, 128\}$ to observe the noise floor in retrieval accuracy vs. the compute cost.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can CurDKV be extended to support dynamic compression during the generation phase to adapt to emerging information needs?
- **Basis in paper:** [explicit] The authors state in "Limitations and future work" that CurDKV relies on "static token selection during the prefill phase," which limits responsiveness to dynamic queries during generation.
- **Why unresolved:** The current method computes leverage scores once; modifying this for online updating without introducing significant latency overhead is a non-trivial engineering challenge.
- **What evidence would resolve it:** A variant of CurDKV that updates KV retention dynamically during decoding steps while maintaining the reported latency reductions.

### Open Question 2
- **Question:** Can incorporating lightweight learned components improve performance in semantically sparse settings compared to the current static leverage score calculation?
- **Basis in paper:** [explicit] The authors suggest exploring "lightweight learned components" to improve performance specifically in semantically sparse settings.
- **Why unresolved:** The current method relies on unsupervised leverage scores derived from CUR decomposition; determining if a learned function can better approximate semantic importance remains untested.
- **What evidence would resolve it:** A comparative analysis on sparse datasets showing a learned variant outperforming the static leverage score baseline.

### Open Question 3
- **Question:** How does varying the dimension of the random Gaussian projection ($r$) affect the trade-off between computational overhead and reconstruction fidelity across different model sizes?
- **Basis in paper:** [inferred] The paper fixes the projection dimension to $r=20$ in the methodology but does not provide an ablation study on how this specific hyperparameter impacts performance on larger models or longer sequences.
- **Why unresolved:** It is unclear if $r=20$ is universally optimal or if it should scale with model dimension ($d$) or sequence length ($n$).
- **What evidence would resolve it:** An ablation study plotting accuracy and latency metrics against varying $r$ values (e.g., 10, 20, 50, 100) for different model configurations.

## Limitations
- Performance degradation on Mistral architecture at 90% compression suggests architecture-specific limitations
- Limited characterization of behavior at extreme compression ratios below 10% retention
- Static token selection during prefill phase cannot adapt to dynamic generation needs

## Confidence
- **High Confidence:** The core mechanism of using value vectors instead of attention scores for importance is well-supported by both theory and empirical results. The compatibility claims with FlashAttention and GQA are technically sound given the method's independence from QK^T materialization.
- **Medium Confidence:** The scalability claims for random projections are reasonable but lack ablation studies showing the trade-off between projection dimension r and approximation quality. The average performance improvements are robust, but the variance across tasks and architectures needs more examination.
- **Low Confidence:** The adaptive budget allocation in AdaCurDKV relies on an external kvpress implementation with unspecified entropy statistics. The method's behavior at extreme compression ratios (<10% retention) where key-value disentanglement may fail is mentioned but not thoroughly characterized.

## Next Checks
1. **Projection Dimension Sensitivity:** Run the Needle-in-a-Haystack tasks (Ruler benchmark) with varying projection dimensions r ∈ {5, 20, 128} to quantify the noise floor in retrieval accuracy versus prefill computational overhead. This would validate whether r=20 represents an optimal trade-off or if higher dimensions are needed for critical retrieval tasks.

2. **Architecture-Specific Analysis:** Conduct head-wise ablation studies on LLaMA versus Mistral to identify which attention heads contribute most to the performance gap at 90% compression. This would clarify whether the degradation stems from sliding-window attention mechanics or other architectural differences.

3. **Extreme Compression Behavior:** Systematically evaluate CurDKV at retention ratios below 10% to characterize the point where eviction loss spikes unpredictably. This would establish the practical limits of the method and identify scenarios where alternative compression strategies might be necessary.