---
ver: rpa2
title: A First Context-Free Grammar Applied to Nawatl Corpora Augmentation
arxiv_id: '2510.04945'
source_url: https://arxiv.org/abs/2510.04945
tags:
- nawatl
- language
- sentences
- corpus
- grammar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces a context-free grammar (CFG) to generate\
  \ artificial sentences in Nawatl, a low-resource indigenous language, to augment\
  \ limited corpora for language model training. A micro-grammar \xB5GNAW\u22950 was\
  \ constructed to produce syntactically valid sentences, which were then filtered\
  \ for semantic plausibility using rules on animate/inanimate noun-verb associations."
---

# A First Context-Free Grammar Applied to Nawatl Corpora Augmentation

## Quick Facts
- arXiv ID: 2510.04945
- Source URL: https://arxiv.org/abs/2510.04945
- Reference count: 6
- Primary result: CFG-generated Nawatl sentences improved FastText semantic similarity to τ=0.527, ranking third behind LLMs

## Executive Summary
This paper presents a novel approach to augmenting low-resource indigenous language corpora using context-free grammar (CFG) generation. The authors developed µGNAW⊕0, a micro-grammar for Nawatl that generates syntactically valid sentences which are then filtered for semantic plausibility through animate/inanimate noun-verb association rules. The resulting artificial corpus (≈807K sentences) was merged with existing π-YALLI data to create π-yall-IA⊕0 (≈11M tokens). FastText models trained on this enriched corpus achieved competitive performance on semantic similarity tasks, demonstrating that CFG-based augmentation can meaningfully improve static model performance in low-resource scenarios.

## Method Summary
The authors constructed a context-free grammar (CFG) called µGNAW⊕0 specifically for Nawatl language sentence generation. This grammar produces syntactically valid sentences that are then filtered using semantic rules about animate/inanimate noun-verb associations to ensure plausibility. The filtered artificial sentences (≈807K) were merged with the existing π-YALLI corpus to create an enriched dataset π-yall-IA⊕0 (≈11M tokens). FastText models were trained on this augmented corpus and evaluated on sentence-level semantic similarity tasks, achieving a Kendall's τ of 0.527, ranking third behind larger LLMs like Gemini 2.5 and Claude 3.7.

## Key Results
- FastText models trained on CFG-augmented Nawatl corpus achieved Kendall's τ=0.527 on semantic similarity tasks
- The enriched corpus (π-yall-IA⊕0) reached approximately 11M tokens
- Performance ranked third behind LLMs (Gemini 2.5: 0.693, Claude 3.7: 0.607) but surpassed other static models
- Demonstrated CFG-generated data can meaningfully improve static model performance in low-resource scenarios

## Why This Works (Mechanism)
The approach works by systematically generating syntactically valid sentences that respect Nawatl grammar rules, then filtering them for semantic plausibility using linguistic constraints about animate/inanimate associations. This ensures the artificial data maintains both grammatical correctness and semantic coherence, addressing the core challenge of low-resource language modeling where limited training data constrains model performance. The CFG provides controlled variation while the semantic filtering preserves linguistic authenticity.

## Foundational Learning
- **Context-Free Grammars (CFGs)**: Why needed - to systematically generate syntactically valid sentences; Quick check - verify grammar productions cover essential Nawatl syntactic structures
- **Semantic Filtering**: Why needed - to ensure artificial sentences maintain linguistic plausibility; Quick check - validate animate/inanimate association rules against native speaker judgments
- **Corpus Augmentation**: Why needed - to address data scarcity in low-resource languages; Quick check - measure diversity and coverage of generated vs. natural sentences
- **Static vs. Contextual Embeddings**: Why needed - to establish baseline performance before moving to contextual models; Quick check - compare FastText vs. contextual embeddings on same task
- **Kendall's Tau**: Why needed - to measure ranking correlation for semantic similarity evaluation; Quick check - verify statistical significance of performance differences

## Architecture Onboarding

### Component Map
µGNAW⊕0 (CFG generator) -> Semantic Filter (animate/inanimate rules) -> Corpus Merger (π-YALLI + synthetic) -> FastText Training -> Semantic Similarity Evaluation

### Critical Path
CFG generation → Semantic filtering → Corpus merging → Model training → Evaluation

### Design Tradeoffs
The authors chose rule-based semantic filtering over statistical approaches to ensure linguistic validity, accepting potential limitations in coverage for guaranteed plausibility. Static embeddings were used instead of contextual models to establish baseline performance, though this may underestimate the gap between traditional and modern approaches.

### Failure Signatures
- Syntactically valid but semantically nonsensical sentences slipping through filtering
- Over-generation of certain sentence patterns due to CFG limitations
- Semantic filtering rules too restrictive, reducing corpus diversity
- Evaluation benchmark not capturing practical utility of augmented corpus

### First Experiments
1. Generate 1,000 sentences with CFG and manually verify syntactic validity
2. Apply semantic filtering and measure retention rate of generated sentences
3. Train FastText on small augmented subset and evaluate on semantic similarity task

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies heavily on a single semantic similarity benchmark
- Static embeddings (FastText) used may underestimate performance gap with contextual models
- Semantic filtering rules may introduce bias or miss valid constructions

## Confidence
- High confidence in technical implementation of CFG and corpus merging methodology
- Medium confidence in evaluation results due to limited benchmark diversity
- Medium confidence in semantic filtering approach's effectiveness

## Next Checks
1. Evaluate the enriched corpus on additional downstream tasks specific to Nawatl language applications (morphological analysis, named entity recognition, or dialect classification)
2. Conduct human evaluation of synthetic sentences to assess naturalness and semantic plausibility beyond automated filtering
3. Test alternative filtering approaches (statistical co-occurrence patterns or transformer-based plausibility scoring) to compare against rule-based semantic filtering method