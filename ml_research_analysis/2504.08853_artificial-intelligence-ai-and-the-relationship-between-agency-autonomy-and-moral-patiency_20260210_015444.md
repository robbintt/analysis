---
ver: rpa2
title: Artificial Intelligence (AI) and the Relationship between Agency, Autonomy,
  and Moral Patiency
arxiv_id: '2504.08853'
source_url: https://arxiv.org/abs/2504.08853
tags:
- moral
- agency
- systems
- agents
- autonomy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper critically examines the nature of agency in AI systems,
  arguing that while current AI exhibits sophisticated behaviors, it lacks genuine
  agency and autonomy. Through a systematic analysis of basic, autonomous, and moral
  agency, the authors demonstrate that AI systems operate within rigid pre-programmed
  boundaries rather than demonstrating true goal-directed behavior and environmental
  responsiveness.
---

# Artificial Intelligence (AI) and the Relationship between Agency, Autonomy, and Moral Patiency

## Quick Facts
- arXiv ID: 2504.08853
- Source URL: https://arxiv.org/abs/2504.08853
- Reference count: 16
- Primary result: Current AI lacks genuine agency and autonomy despite sophisticated behaviors

## Executive Summary
This paper critically examines the nature of agency in AI systems, arguing that while current AI exhibits sophisticated behaviors, it lacks genuine agency and autonomy. The authors systematically analyze basic, autonomous, and moral agency to demonstrate that AI systems operate within rigid pre-programmed boundaries rather than demonstrating true goal-directed behavior and environmental responsiveness. The paper challenges traditional assumptions about the relationship between moral agency and moral patiency, suggesting that future AI systems could potentially achieve limited moral agency without consciousness, creating a theoretical case where these concepts become decoupled.

## Method Summary
The paper employs a philosophical analysis approach, examining the nature of agency through systematic comparison of basic, autonomous, and moral agency frameworks. The authors use logical argumentation to distinguish between different types of agency and explore their implications for AI systems. The methodology involves critical examination of existing philosophical concepts of agency and their application to artificial intelligence, while considering the relationship between agency, autonomy, and moral patiency.

## Key Results
- Current AI systems lack genuine agency due to rigid pre-programmed boundaries
- Moral agency and moral patiency can theoretically be decoupled in future AI systems
- AI systems require more nuanced frameworks for evaluating artificial agency

## Why This Works (Mechanism)
The paper's framework works by establishing clear distinctions between different types of agency (basic, autonomous, and moral) and examining how these relate to AI systems. The mechanism relies on philosophical analysis to identify key characteristics that define genuine agency, such as goal-directed behavior, environmental responsiveness, and consciousness. By systematically comparing these characteristics against AI capabilities, the authors demonstrate why current systems fall short of genuine agency.

## Foundational Learning
1. **Agency Types** - Why needed: To distinguish between different levels of decision-making capability; Quick check: Can identify which type applies to a given system
2. **Moral Patiency** - Why needed: To understand how responsibility and moral consideration are distributed; Quick check: Can determine who/what deserves moral consideration
3. **Autonomy Levels** - Why needed: To measure the degree of self-determination in systems; Quick check: Can assess the independence of decision-making processes

## Architecture Onboarding

Component Map:
Basic Agency -> Autonomous Agency -> Moral Agency

Critical Path:
The progression from basic to moral agency follows increasing complexity in goal-directed behavior, environmental responsiveness, and consciousness.

Design Tradeoffs:
- Simplicity vs. capability in agency frameworks
- Philosophical rigor vs. practical applicability
- Individual vs. collective agency considerations

Failure Signatures:
- Misclassification of agency types
- Over-attribution of agency to non-conscious systems
- Underestimation of emergent behaviors in complex systems

First 3 Experiments:
1. Test agency framework against case studies of advanced AI systems exhibiting emergent behaviors
2. Develop concrete scenarios demonstrating decoupled moral agency/patiency
3. Evaluate framework's applicability to collective or distributed AI systems

## Open Questions the Paper Calls Out
None explicitly stated in the source material.

## Limitations
- Central claim about AI lacking genuine agency rests on current technological limitations rather than fundamental impossibility
- Framework relies heavily on philosophical definitions that may not capture emergent AI behaviors
- Lacks empirical grounding for the decoupling of moral agency from moral patiency

## Confidence

- AI lacking genuine agency: Medium
- Framework for agency types: Medium  
- Decoupling moral agency and patiency: Low

## Next Checks

1. Test the agency framework against case studies of advanced AI systems exhibiting emergent behaviors
2. Develop concrete scenarios demonstrating how decoupled moral agency/patiency might manifest in practice
3. Evaluate the framework's applicability to collective or distributed AI systems