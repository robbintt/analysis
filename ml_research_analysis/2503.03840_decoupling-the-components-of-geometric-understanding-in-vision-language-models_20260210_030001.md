---
ver: rpa2
title: Decoupling the components of geometric understanding in Vision Language Models
arxiv_id: '2503.03840'
source_url: https://arxiv.org/abs/2503.03840
tags:
- geometric
- rotation
- stimuli
- understanding
- geometry
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates the geometric understanding of vision-language
  models (VLMs) using a cognitive science paradigm that isolates visual comprehension
  from reasoning and world knowledge. The authors adapted stimuli from Dehaene et
  al.
---

# Decoupling the components of geometric understanding in Vision Language Models

## Quick Facts
- arXiv ID: 2503.03840
- Source URL: https://arxiv.org/abs/2503.03840
- Reference count: 9
- Primary result: VLMs consistently underperform humans on geometric understanding tasks, showing brittle comprehension especially for mental rotation tasks

## Executive Summary
This study evaluates vision-language models' geometric understanding by adapting a cognitive science paradigm from Dehaene et al. (2006). The researchers tested VLMs on 6 geometric concepts using "odd one out" tasks with 6 images each, comparing performance against US adults and Munduruku adults without formal education. The results reveal that VLMs struggle with geometric concepts that humans find intuitive, particularly tasks requiring mental rotation, suggesting fundamental differences in how machines and humans learn geometric understanding.

## Method Summary
The researchers adapted stimuli from Dehaene et al.'s (2006) study on geometric intuitions, creating tasks that isolate visual comprehension from reasoning and world knowledge. They used "odd one out" tasks with 6 images per concept across 6 geometric categories. Three VLMs were tested: Gemini Pro 1.0, Gemini Pro 1.5, and GPT-4V. Performance was compared against prior research data from US adults (70-80% accuracy) and Munduruku adults without formal education (60-70% accuracy). Mental rotation was tested by presenting rotated stimuli and observing performance changes.

## Key Results
- VLMs achieved only 30-40% accuracy across most geometric categories, compared to 70-80% for US adults and 60-70% for Munduruku adults
- VLMs showed brittle understanding, particularly struggling with mental rotation tasks where performance varied dramatically based on rotation angle
- Human performance remained stable across rotation angles while VLM performance was poorest when mental rotation was required

## Why This Works (Mechanism)
The study's methodology reveals that VLMs learn geometric concepts differently from humans by decoupling visual comprehension from reasoning and world knowledge. This approach isolates the visual processing component, showing that VLMs' geometric understanding is more superficial and dependent on learned patterns rather than conceptual comprehension. The mental rotation findings demonstrate that VLMs lack the physical world experience that humans integrate with formal education, leading to brittle performance when faced with rotated stimuli.

## Foundational Learning
- Visual comprehension isolation - Separating visual processing from reasoning allows assessment of pure visual understanding
  - Why needed: To determine if VLMs truly understand geometric concepts or are relying on other cognitive processes
  - Quick check: Compare performance across tasks with varying reasoning demands

- Odd one out paradigm - Using comparative visual tasks to test concept discrimination
  - Why needed: Provides clear ground truth for concept understanding without requiring explicit explanations
  - Quick check: Verify task difficulty matches human performance baselines

- Mental rotation assessment - Testing geometric understanding under rotated conditions
  - Why needed: Reveals whether models understand concepts invariantly or are memorizing specific configurations
  - Quick check: Compare performance across multiple rotation angles

## Architecture Onboarding
- Component map: Visual input -> Feature extraction -> Concept matching -> Response generation
- Critical path: Image processing pipeline → geometric feature recognition → comparison logic → output selection
- Design tradeoffs: Accuracy vs. computational efficiency, generalization vs. memorization, invariance vs. specificity
- Failure signatures: Inconsistent performance across rotations, low accuracy on basic geometric concepts, brittleness to stimulus variations
- First experiments: 1) Test additional VLMs to assess generalizability, 2) Conduct ablation studies varying stimulus properties, 3) Design tasks explicitly testing physical vs. formal knowledge

## Open Questions the Paper Calls Out
None

## Limitations
- Methodology assumptions about VLM processing may not align with actual model mechanisms
- Limited to three VLMs, restricting generalizability to broader VLM landscape
- Fixed set of 6 geometric concepts may not capture full spectrum of geometric understanding

## Confidence
- VLM performance relative to humans: High
- Mental rotation findings: Medium
- Interpretation of learning sources: Medium

## Next Checks
1. Test additional VLMs beyond the three models examined to establish generalizability
2. Conduct ablation studies varying specific stimulus properties to isolate influential visual features
3. Design complementary tasks explicitly testing physical world experience versus formal geometric knowledge