---
ver: rpa2
title: Are All Spanish Doctors Male? Evaluating Gender Bias in German Machine Translation
arxiv_id: '2502.19104'
source_url: https://arxiv.org/abs/2502.19104
tags:
- gender
- bias
- german
- language
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces WinoMTDE, a new gender bias evaluation test
  set for German machine translation, extending the automatic evaluation method from
  Stanovsky et al. (2019) to German.
---

# Are All Spanish Doctors Male? Evaluating Gender Bias in German Machine Translation

## Quick Facts
- arXiv ID: 2502.19104
- Source URL: https://arxiv.org/abs/2502.19104
- Reference count: 40
- Key outcome: Introduces WinoMTDE test set for German MT gender bias evaluation; GPT-4o-mini outperforms traditional MT systems with accuracy ranging from 37.0% to 95.8%

## Executive Summary
This study addresses gender bias in German machine translation by introducing WinoMTDE, a new evaluation test set extending the automatic evaluation method from Stanovsky et al. (2019) to German. The dataset contains 288 balanced sentences with occupational stereotypes annotated using German labor statistics. The research evaluates five commercial MT systems (Google Translate, Microsoft Translator, Amazon Translate, DeepL, SYSTRAN) and GPT-4o-mini for their ability to correctly translate gendered German sentences into seven target languages. Results reveal persistent gender bias across most models, with GPT-4o-mini consistently outperforming traditional MT systems in both accuracy and lower gender-based F1-score gaps.

## Method Summary
The study creates WinoMTDE by adapting the WinoMT framework for German language evaluation. Researchers constructed 288 balanced sentences incorporating occupational stereotypes, annotated using German labor statistics to ensure representativeness. The evaluation framework automatically measures gender bias by comparing translation accuracy across gendered sentence variations. Five commercial machine translation systems plus GPT-4o-mini were tested on their ability to handle gender-specific translations from German into seven target languages. The methodology employs automatic metrics including accuracy and gender-based F1-score gaps to quantify bias, though human evaluation was not conducted.

## Key Results
- GPT-4o-mini consistently outperforms traditional MT systems with accuracy ranging from 37.0% to 95.8%
- Persistent gender bias observed across most commercial MT systems evaluated
- Lower gender-based F1-score gaps achieved by GPT-4o-mini compared to traditional MT systems

## Why This Works (Mechanism)
The evaluation framework works by leveraging occupational stereotype sentences that are balanced and annotated with real-world labor statistics. By testing gender-specific variations of these sentences across multiple translation directions, the system can automatically detect when MT models systematically prefer one gender over another for specific occupations. The use of German labor statistics provides empirical grounding for what constitutes "correct" gender associations, while the automatic evaluation metrics enable scalable assessment across multiple systems and languages.

## Foundational Learning

**Occupational stereotype bias**: Understanding how certain professions become associated with specific genders in language models - needed to design appropriate test sentences that reveal systematic biases

**German grammatical gender**: Knowledge of how gender works in German (masculine, feminine, neuter) - needed because German's gender system differs significantly from English and affects translation accuracy

**Automatic evaluation metrics**: Familiarity with F1-score, accuracy, and other quantitative measures for bias assessment - needed to interpret the numerical results and compare system performance objectively

**Labor statistics as ground truth**: Using real-world demographic data to establish expected gender distributions - needed to create empirically-based evaluation criteria rather than subjective judgments

**Cross-linguistic translation dynamics**: Understanding how gender information transfers between languages with different grammatical structures - needed to interpret results across the seven target languages tested

## Architecture Onboarding

**Component map**: Test sentence generation -> Labor statistics annotation -> Translation generation -> Automatic evaluation -> Bias quantification

**Critical path**: The core evaluation flow where occupational stereotype sentences are translated by MT systems, then automatically assessed for gender accuracy using predefined metrics

**Design tradeoffs**: The study prioritizes automatic evaluation scalability over human judgment depth, sacrificing nuanced semantic assessment for broader system coverage

**Failure signatures**: Systematic gender preference patterns, large F1-score gaps between masculine and feminine translations, accuracy below 50% indicating worse-than-random performance

**Three first experiments**:
1. Test a single MT system on a subset of 50 sentences to validate the evaluation framework
2. Compare automatic metrics against human judgments on 20 sample translations
3. Evaluate reverse translation direction (target language to German) to assess bidirectional bias

## Open Questions the Paper Calls Out
None

## Limitations
- Test set comprises only 288 sentences, representing a relatively small sample size for definitive conclusions
- Evaluation focuses exclusively on German-to-seven-language translations without examining reverse direction
- Automatic metrics may not fully capture semantic correctness and contextual appropriateness of gender translations

## Confidence

**High confidence**: GPT-4o-mini's superior performance metrics compared to traditional MT systems, given clear numerical superiority across accuracy and F1-score gap measures

**Medium confidence**: Persistence of gender bias across commercial MT systems, as results show variation in performance and may be influenced by specific sentence constructions

**Medium confidence**: Relationship between occupational stereotypes and translation outcomes, as annotation relies on German labor statistics which may not fully capture cultural nuances

## Next Checks

1. Expand the test set to include at least 1000 balanced sentences covering a broader range of occupations and contexts to improve statistical power

2. Conduct human evaluation studies alongside automatic metrics to assess semantic correctness and contextual appropriateness of gender translations

3. Test the same MT systems on other language pairs, particularly German-to-non-European languages, to evaluate bias consistency across different linguistic structures