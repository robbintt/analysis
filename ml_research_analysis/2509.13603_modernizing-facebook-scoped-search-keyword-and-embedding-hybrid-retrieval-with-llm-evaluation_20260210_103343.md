---
ver: rpa2
title: 'Modernizing Facebook Scoped Search: Keyword and Embedding Hybrid Retrieval
  with LLM Evaluation'
arxiv_id: '2509.13603'
source_url: https://arxiv.org/abs/2509.13603
tags:
- search
- retrieval
- query
- system
- meta
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a modernized Facebook Group Scoped Search
  system that integrates traditional keyword-based retrieval with embedding-based
  retrieval (EBR) to enhance search relevance and diversity. The approach combines
  semantic understanding from EBR with the precision of keyword matching, addressing
  the limitations of keyword-only search in capturing natural language queries and
  reducing sparse result sets in group contexts.
---

# Modernizing Facebook Scoped Search: Keyword and Embedding Hybrid Retrieval with LLM Evaluation

## Quick Facts
- arXiv ID: 2509.13603
- Source URL: https://arxiv.org/abs/2509.13603
- Reference count: 15
- Hybrid retrieval approach combining keyword and embedding-based methods achieves 85.2% top-5 relevance rate

## Executive Summary
This paper presents a modernized Facebook Group Scoped Search system that integrates traditional keyword-based retrieval with embedding-based retrieval (EBR) to enhance search relevance and diversity. The approach combines semantic understanding from EBR with the precision of keyword matching, addressing the limitations of keyword-only search in capturing natural language queries and reducing sparse result sets in group contexts. To support rapid iteration and quality measurement, the authors developed an LLM-based evaluation framework using Llama 3 as an automated judge, enabling scalable offline relevance assessment.

The hybrid retrieval system was tested with real-world query sets, and results showed consistent improvements: the blended approach achieved a top-5 relevance rate of 85.2% (up from 84.7%) and a top-5 somewhat relevant rate of 94.7% (up from 94.1%). Error and skip rates remained low, indicating reliable evaluation performance. The study demonstrates practical benefits for large-scale social platform search systems and offers insights into deploying advanced retrieval architectures with automated evaluation pipelines.

## Method Summary
The authors developed a hybrid retrieval system that combines traditional keyword-based retrieval with embedding-based retrieval (EBR) to improve Facebook Group Scoped Search. The approach integrates semantic understanding from EBR with the precision of keyword matching, addressing the limitations of keyword-only search in capturing natural language queries and reducing sparse result sets in group contexts. To enable rapid iteration and quality measurement, they implemented an LLM-based evaluation framework using Llama 3 as an automated judge for scalable offline relevance assessment. The system was tested on real-world query sets, demonstrating consistent improvements in relevance metrics while maintaining low error and skip rates.

## Key Results
- Hybrid retrieval achieved top-5 relevance rate of 85.2% (up from 84.7%)
- Top-5 somewhat relevant rate improved to 94.7% (up from 94.1%)
- Error and skip rates remained low, indicating reliable evaluation performance

## Why This Works (Mechanism)
The hybrid approach works by combining the semantic understanding capabilities of embedding-based retrieval with the precision and interpretability of keyword-based retrieval. EBR captures the meaning behind natural language queries, enabling better handling of synonyms and related concepts, while keyword retrieval provides exact matching for specific terms. The LLM-based evaluation framework enables rapid iteration by providing consistent, scalable relevance judgments without the need for extensive human annotation. This combination addresses the core limitation of keyword-only search systems, which struggle with natural language queries and often return sparse results in group contexts where content may be semantically related but not keyword-identical.

## Foundational Learning
**Embedding-based retrieval (EBR):** Vector representations of queries and documents that capture semantic meaning, enabling similarity-based search. Why needed: Traditional keyword matching fails with natural language queries and synonyms. Quick check: Compare similarity scores between semantically related but lexically different query-document pairs.

**LLM-based evaluation:** Using language models like Llama 3 to automatically judge search result relevance. Why needed: Traditional evaluation requires expensive human annotation and doesn't scale for rapid iteration. Quick check: Compare LLM judgments against human annotations on a validation set.

**Hybrid retrieval blending:** Combining multiple retrieval approaches (keyword + EBR) through learned or heuristic weighting. Why needed: No single retrieval method dominates across all query types and user intents. Quick check: A/B test different blending ratios on representative query sets.

**Group search optimization:** Tailoring search systems for community-based content where user intent often involves finding related discussions or resources. Why needed: Standard web search approaches don't capture the social context and information needs in group settings. Quick check: Analyze query reformulation patterns in group vs general search contexts.

## Architecture Onboarding

**Component Map:** Query Processing -> Hybrid Retrieval Engine -> Result Ranking -> LLM Evaluation Judge -> Metrics Dashboard

**Critical Path:** User Query → Query Parsing → Parallel Keyword Retrieval + EBR → Score Blending → Final Ranking → LLM Evaluation

**Design Tradeoffs:** The system trades some precision from keyword-only retrieval for improved recall and semantic coverage through EBR integration. The LLM evaluation provides faster iteration cycles but may introduce evaluation bias compared to human judgments. The hybrid approach requires maintaining two retrieval systems and a blending mechanism, increasing infrastructure complexity.

**Failure Signatures:** Keyword retrieval dominance may indicate insufficient semantic coverage or poor EBR quality. High skip rates in LLM evaluation suggest ambiguous queries or evaluation framework limitations. Performance degradation on specific query types may reveal model biases or inadequate training data coverage.

**First 3 Experiments:**
1. Compare top-5 relevance rates of pure keyword vs pure EBR vs hybrid approaches on a fixed query set
2. Measure correlation between LLM evaluation scores and human judgments across different query categories
3. Test the impact of different blending ratios (e.g., 70/30 keyword/EBR vs 50/50 vs 30/70) on overall relevance metrics

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- No online A/B testing results or user engagement metrics presented
- LLM-based evaluation framework may introduce evaluation bias and doesn't fully capture user satisfaction nuances
- Lacks detailed information about query distribution, group characteristics, and specific nature of "sparse result sets"

## Confidence
- High confidence in technical implementation of hybrid retrieval system
- Medium confidence in claimed improvements due to absence of online validation
- Low confidence in generalizability beyond Facebook Group context

## Next Checks
1. Conduct online A/B testing to measure actual user engagement metrics (click-through rates, session duration, query reformulation rates) rather than relying solely on offline relevance judgments
2. Perform ablation studies to isolate the contribution of each component (keyword vs EBR) and test different blending strategies with statistical significance testing
3. Validate the LLM evaluation framework against human judgments across diverse query types and user intent categories to assess evaluation reliability and potential biases