---
ver: rpa2
title: Probing the Trajectories of Reasoning Traces in Large Language Models
arxiv_id: '2601.23163'
source_url: https://arxiv.org/abs/2601.23163
tags:
- reasoning
- density
- earth
- same
- decile
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper systematically probes reasoning trace trajectories in
  large language models by truncating reasoning traces at fixed token-percentiles
  and re-injecting partial traces to measure induced answer distributions. Applied
  to Qwen3 and gpt-oss models on GPQA Diamond and MMLU-Pro benchmarks, the method
  reveals that accuracy and decision commitment consistently increase with reasoning
  depth, driven primarily by instance-specific semantic content rather than context
  length or generic reasoning style.
---

# Probing the Trajectories of Reasoning Traces in Large Language Models

## Quick Facts
- **arXiv ID:** 2601.23163
- **Source URL:** https://arxiv.org/abs/2601.23163
- **Reference count:** 40
- **Primary result:** Accuracy and decision commitment consistently increase with reasoning depth, driven primarily by instance-specific semantic content rather than context length or generic reasoning style.

## Executive Summary
This paper systematically probes reasoning trace trajectories in large language models by truncating reasoning traces at fixed token-percentiles and re-injecting partial traces to measure induced answer distributions. Applied to Qwen3 and gpt-oss models on GPQA Diamond and MMLU-Pro benchmarks, the method reveals that accuracy and decision commitment consistently increase with reasoning depth, driven primarily by instance-specific semantic content rather than context length or generic reasoning style. Cross-model transfer experiments show that stronger models can successfully rescue incorrect partial traces from weaker models, particularly when allowed free continuation, though anchoring effects remain substantial. The findings demonstrate that reasoning traces are trajectory-dependent interventions whose value comes from semantic coherence with the question, enabling diagnostics for compute-efficient and safer deployment without assuming intermediate tokens are faithful explanations.

## Method Summary
The paper systematically probes reasoning trace trajectories by generating full reasoning traces with thinking mode enabled, slicing them into deciles by token count, and re-injecting partial traces to measure induced answer distributions. For each question, models generate complete reasoning traces, which are tokenized and segmented at 0%, 10%, 20%, ... 100% percentiles. Probe prompts combine system instructions, questions, and partial traces with early-stopping suffixes, then extract next-token probabilities over answer choices. The method evaluates accuracy, decision commitment, flip rates, and non-choice probability across deciles, comparing original traces against random, swap, and shuffle controls. Cross-model transfer experiments inject source-model traces into target models at various deciles with immediate answering or free continuation conditions.

## Key Results
- Accuracy and decision commitment consistently increase as reasoning depth grows from 0% to 100% of trace tokens.
- Gains are primarily driven by instance-specific semantic content in reasoning traces, not context length or generic reasoning style (shuffle control yields only 0.3-10.8% gain vs 18.1-33.1% for original traces).
- Stronger models can rescue incorrect partial traces from weaker models, with free continuation improving rescue rates by 17-43% over immediate answering.

## Why This Works (Mechanism)

### Mechanism 1: Instance-Specific Semantic Coherence Drives Accuracy Gains
- **Claim:** Reasoning traces improve accuracy primarily through question-specific semantic content, not context length or generic reasoning style.
- **Mechanism:** When partial traces containing instance-relevant reasoning are injected, they carry signal that shifts probability mass toward the correct answer. The sequential coherence of tokens matters because it preserves logical relationships.
- **Core assumption:** Models encode task-relevant information in the semantic relationships between tokens, not just in token identities or structural patterns.
- **Evidence anchors:**
  - [abstract] "These gains are primarily driven by relevant content in the model generation rather than context length or generic 'reasoning style' effects."
  - [Section 3.2] Original traces yield +18.1–33.1% accuracy gain; shuffle control (same tokens, randomized order) yields only +0.3–10.8%; swap control (another question's reasoning) can actively hurt accuracy (−18.4% to +3.0%).
  - [corpus] Related work "Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens" questions whether semantic coherence is necessary, suggesting partial signal may persist even without coherent structure—weak corpus support for this mechanism's universality.
- **Break condition:** If shuffle controls matched original trace performance, or if swap controls improved accuracy, the semantic-coherence mechanism would be falsified.

### Mechanism 2: Progressive Probability Concentration Along Trajectory
- **Claim:** As reasoning depth increases, models concentrate probability mass on a single answer choice, reducing flip rates and non-choice probability.
- **Mechanism:** The model sequentially integrates information from earlier tokens, progressively ruling out alternatives. By late deciles, the induced distribution has collapsed toward a committed prediction.
- **Core assumption:** Intermediate tokens causally influence final predictions through sequential conditioning, not merely as a byproduct of model architecture.
- **Evidence anchors:**
  - [abstract] "Accuracy and decision commitment consistently increase as the percentage of provided reasoning tokens grows."
  - [Section 3.1] Probability assigned to eventual final response rises with decile; non-choice probability declines; flip rate decreases with reasoning depth on MMLU-Pro.
  - [corpus] "Hidden States as Early Signals" (arXiv:2601.09093) shows step-level evaluation can detect low-value reasoning segments early—consistent with non-uniform information density along trajectories.
- **Break condition:** If flip rates increased or probability mass remained dispersed at late deciles, progressive concentration would not hold.

### Mechanism 3: Cross-Model Rescue with Anchoring Asymmetry
- **Claim:** Stronger models can recover from weaker models' incorrect partial traces, but anchoring to the wrong answer persists, especially when forced to answer immediately.
- **Mechanism:** Free continuation allows the target model to generate corrective reasoning that overrides the injected prefix. Immediate probing locks in the anchor because the model conditions on the flawed prefix without opportunity to backtrack.
- **Core assumption:** Stronger models encode more robust priors that can overcome misleading context when given additional compute.
- **Evidence anchors:**
  - [abstract] "Stronger models can successfully rescue incorrect partial traces from weaker models, particularly when allowed free continuation, though anchoring effects remain substantial."
  - [Section 3.3] Free continuation improves rescue rates by +17–43% over base mode across model pairs; anchoring drops 11–32% with free continuation but remains 15–60%.
  - [corpus] "Thought Manipulation" (arXiv:2504.13626) and related work on thought reuse examine similar transfer dynamics—corpus provides directional support but limited direct replication.
- **Break condition:** If rescue rates were uniform across deciles, or if anchoring disappeared entirely with free continuation, the asymmetry mechanism would need revision.

## Foundational Learning

- **Concept: Next-token probability probing via softmax**
  - **Why needed here:** The entire protocol depends on extracting raw softmax probabilities at a specific generation position to measure induced answer distributions.
  - **Quick check question:** Given logits [2.0, 1.0, 0.5] for answers A, B, C, what is P(A)?

- **Concept: Tokenization and decile slicing**
  - **Why needed here:** Deciles are defined by token count, not character count; cross-model transfer requires re-tokenization with the target model's vocabulary.
  - **Quick check question:** If a trace has 500 tokens, how many tokens are in the 40th decile prefix?

- **Concept: Chain-of-Thought as test-time compute scaling**
  - **Why needed here:** The paper frames reasoning traces within the broader literature on scaling inference computation to improve accuracy.
  - **Quick check question:** Why would longer reasoning not always improve accuracy (hint: "overthinking")?

## Architecture Onboarding

- **Component map:**
  1. Trace generator -> Decile slicer -> Probe constructor -> Probability extractor -> Control generator -> Transfer handler
- **Critical path:**
  1. Generate full traces for all (model, benchmark) pairs
  2. Slice into deciles and construct probe prompts
  3. Extract answer probabilities at each decile
  4. Run controls (random, swap, shuffle) in parallel
  5. For transfer experiments, inject source-model deciles into target model with/without free continuation
- **Design tradeoffs:**
  - **Decile granularity:** 10% intervals capture coarse dynamics but may miss high-information local regions
  - **Early-stopping suffix choice:** The paper shows robustness to suffix phrasing (Figure A1), but different models may require family-specific formatting
  - **Answer token definition:** Bare uppercase letters vs. space-prefixed; paper uses bare letters to avoid multi-token issues
- **Failure signatures:**
  - **Qwen3-8B \boxed{} anomaly:** Frequent LaTeX boxing biases predictions toward "A" and causes accuracy drop from decile 90→100 (Table A3)—visible only via per-decile analysis
  - **High non-choice probability:** Indicates model not committing to valid answer choices; check early-stopping suffix compatibility
  - **Flat accuracy across deciles in controls:** Expected for random/swap; if original traces also flat, trace generation may be failing
- **First 3 experiments:**
  1. **Baseline reproducibility:** Run the full protocol on Qwen3-4B with GPQA Diamond; verify accuracy rises from ~31% (decile 0) to ~54% (decile 100) per Table A2
  2. **Control validation:** Implement shuffle control; confirm gain is <50% of original trace gain (should be +0–11% vs +18–33%)
  3. **Single transfer pair:** Inject Qwen3-4B decile-40 traces into Qwen3-14B; measure rescue rate and anchoring rate in base vs. free modes; expect ~15–25% rescue in base, ~40–50% in free per Table A4

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can trajectory probing be extended to open-ended generation tasks where answer distributions cannot be directly probed via single-token next-token probabilities?
- **Basis in paper:** [explicit] "We evaluate only multiple-choice benchmarks (GPQA Diamond and MMLU-Pro), where answer distributions can be directly probed via next-token probabilities on single-letter responses. While extending the protocol to open-ended generation is possible, it would require different evaluation metrics."
- **Why unresolved:** The current protocol relies on direct probability extraction over a fixed answer vocabulary, which is inapplicable to free-form outputs.
- **What evidence would resolve it:** Development of evaluation metrics (e.g., semantic similarity scoring, latent answer extraction) that enable comparable trajectory probing for open-ended tasks.

### Open Question 2
- **Question:** What is the actual non-uniform information density distribution along reasoning traces, and which specific reasoning segments contribute most to accuracy gains?
- **Basis in paper:** [explicit] "The decile-based slicing treats all reasoning positions equivalently within each percentile, potentially masking non-uniform information density along the trace."
- **Why unresolved:** Decile aggregation averages over potentially heterogeneous segments; critical reasoning steps may be concentrated at specific positions.
- **What evidence would resolve it:** Fine-grained segment-level importance analysis (e.g., leave-one-out or step-wise interventions) identifying which trace portions drive accuracy improvements.

### Open Question 3
- **Question:** To what extent do reasoning traces faithfully reflect the model's internal decision process versus serving as post-hoc rationalizations?
- **Basis in paper:** [explicit] "We do not address the faithfulness of reasoning traces to the model's internal computations. Our results characterize the functional effects of trace injection on output distributions, not whether intermediate tokens causally reflect the model's decision process."
- **Why unresolved:** Functional probing measures output effects but cannot distinguish causal reasoning from confabulation.
- **What evidence would resolve it:** Causal intervention studies manipulating internal representations combined with trace analysis to assess whether trace content tracks internal computation.

### Open Question 4
- **Question:** How much of the observed negative correlation between reasoning trace length and accuracy is attributable to question difficulty versus inefficient or derailing reasoning?
- **Basis in paper:** [inferred] "Interestingly, shorter reasoning traces are associated with higher accuracy [...] However, note that we are not able to control for question difficulty here."
- **Why unresolved:** Difficulty is a confound—models may produce longer traces when struggling on hard questions, making causal direction unclear.
- **What evidence would resolve it:** Controlled experiments with difficulty-matched question sets, or difficulty estimation methods that enable stratified analysis.

## Limitations
- The paper does not address whether reasoning traces faithfully reflect the model's internal decision process versus serving as post-hoc rationalizations.
- The current protocol cannot be directly extended to open-ended generation tasks without different evaluation metrics.
- Decile-based slicing may mask non-uniform information density along reasoning traces by treating all positions equivalently within each percentile.

## Confidence
- **High confidence:** The semantic-coherence mechanism driving accuracy gains is well-supported by control experiments (shuffle vs original trace performance).
- **Medium confidence:** The cross-model rescue mechanism is supported but limited by the availability of the gpt-oss models referenced.
- **Medium confidence:** The progressive probability concentration mechanism is observed but requires careful interpretation of flip rate and non-choice probability dynamics.

## Next Checks
1. **Baseline reproducibility check:** Run the full protocol on Qwen3-4B with GPQA Diamond; verify accuracy rises from ~31% (decile 0) to ~54% (decile 100) per Table A2.
2. **Control validation check:** Implement shuffle control; confirm gain is <50% of original trace gain (should be +0–11% vs +18–33%).
3. **Transfer experiment check:** Inject Qwen3-4B decile-40 traces into Qwen3-14B; measure rescue rate and anchoring rate in base vs. free modes; expect ~15–25% rescue in base, ~40–50% in free per Table A4.