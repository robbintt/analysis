---
ver: rpa2
title: 'AGENT: An Aerial Vehicle Generation and Design Tool Using Large Language Models'
arxiv_id: '2504.08981'
source_url: https://arxiv.org/abs/2504.08981
tags:
- design
- designs
- agent
- which
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AGENT, a large language model-based tool
  for generating and evaluating unmanned aerial vehicle (UAV) designs. AGENT is built
  on the CodeT5+ LLM and fine-tuned on the AircraftVerse dataset, which contains UAV
  designs and physics simulation results.
---

# AGENT: An Aerial Vehicle Generation and Design Tool Using Large Language Models

## Quick Facts
- **arXiv ID:** 2504.08981
- **Source URL:** https://arxiv.org/abs/2504.08981
- **Reference count:** 8
- **Primary result:** LLM-based UAV design tool achieving R² scores of 0.161-0.944 for flight dynamics prediction and order-of-magnitude faster than physics simulation

## Executive Summary
AGENT is a large language model-based tool for generating and evaluating unmanned aerial vehicle designs. Built on CodeT5+, it's fine-tuned on AircraftVerse dataset containing 27,714 UAV designs with physics simulation results. The model learns to generate UAV designs conditioned on desired flight properties and can act as a surrogate for the physics simulator. Experiments show high accuracy in predicting design success and flight dynamics metrics, with R² scores ranging from 0.161 to 0.944 for various properties.

## Method Summary
AGENT uses CodeT5+ 220M parameters, fine-tuned on AircraftVerse dataset containing UAV designs and physics simulation results. The training employs a curriculum of four tasks: component generation/reverse/masking, conditional design generation, design tree masking, and surrogate modeling. The model is trained for 50K steps with AdamW optimizer, weight decay 0.1, batch size 50, and exponential learning rate decay. Inference uses beam search decoding with beam size 10, supporting both greedy and sampling modes.

## Key Results
- R² scores for surrogate predictions: 0.161-0.944 across mass, hover time, max speed, and max distance metrics
- Achieves ~11 seconds runtime on A100 vs ~120 seconds for physics simulator (order of magnitude faster)
- Conditional generation produces designs meeting specified constraints within same order of magnitude as prompts
- Successfully generates valid JSON design trees conditioned on desired flight properties

## Why This Works (Mechanism)

### Mechanism 1: Multi-task Curriculum Learning
A diverse training curriculum enables a single model to perform multiple design behaviors. The encoder-decoder architecture maps task-specific commands (e.g., `<|generate design|>`, `<|evaluate design|>`) to appropriate outputs, with shared token embeddings creating latent connections between component properties and full designs. Curriculum ablations show optimal performance when combining component database with masking tasks (R² = 0.418 for hover time vs 0.356 baseline).

### Mechanism 2: Code Pre-training Transfer
CodeT5+'s pre-training on programming languages enables rapid acquisition of JSON-structured design trees. JSON syntax similarity to Java/C allows the model to parse hierarchical design trees without extensive domain-specific pre-training. Minimal preprocessing (json.dumps + tokenization) preserves structural relationships.

### Mechanism 3: LLM-based Surrogate Modeling
The encoder-decoder architecture learns an implicit mapping from design structure to simulation outputs via supervised training on paired (design, output.json) examples. The model functions as an orders-of-magnitude faster surrogate while maintaining useful prediction accuracy (R² scores 0.161-0.944).

## Foundational Learning

- **Encoder-Decoder Transformer Architecture**
  - *Why needed here:* AGENT relies on encoder-decoder cross-attention where encoder provides commands/context and decoder generates sequences
  - *Quick check:* Can you explain how cross-attention allows the decoder to incorporate encoder information at each generation step?

- **Causal Language Modeling Loss**
  - *Why needed here:* Decoder is trained to predict next token given all previous tokens, governing how model learns to generate valid JSON sequences autoregressively
  - *Quick check:* In causal LM, why is training target shifted by one position relative to decoder input?

- **Beam Search Decoding**
  - *Why needed here:* AGENT uses both greedy and sampling-based beam search during inference; understanding trade-offs between deterministic vs diverse generation is critical for deployment
  - *Quick check:* What is the difference between selecting highest-probability beam path vs sampling from categorical distribution at each step?

## Architecture Onboarding

- **Component map:**
  CodeT5+ (220M) -> Tokenizer -> Curriculum Scheduler -> Fine-tuning pipeline -> Inference Module -> Simulator Interface

- **Critical path:**
  1. Load pre-trained CodeT5+ (220M) weights
  2. Preprocess AircraftVerse JSON files (filter >512 tokens, split successful/failed designs)
  3. Construct (encS, decS) pairs for each curriculum task
  4. Fine-tune all parameters (50K steps, AdamW, weight decay 0.1, batch size 50)
  5. Evaluate surrogate metrics (R² on test set) and generation quality (simulator validation)

- **Design tradeoffs:**
  - 220M parameter model fits on single GPU with 2.5GB VRAM; larger variants would improve capacity but reduce accessibility
  - Adding component tasks alone degraded hover time predictions (R²: 0.356 → 0.289), but adding masking tasks recovered performance (R²: 0.418)
  - Filtering >512 tokens removes complex designs (often less likely to fly), potentially limiting model's ability to handle advanced configurations

- **Failure signatures:**
  - Out-of-distribution conditioning may produce implausible designs
  - Designs approaching 512 tokens may be truncated, producing invalid JSON
  - Masking patterns not seen during training may produce incoherent completions

- **First 3 experiments:**
  1. Baseline surrogate validation: Run `<|evaluate design|>` on held-out test set; compute R² for hover time, max speed, max distance
  2. Conditional generation fidelity: Generate 5 designs per prompt; run through physics simulator; verify outputs within same order of magnitude
  3. Curriculum ablation: Train three model variants (no components, no masking, full curriculum); compare R² on flight dynamics predictions

## Open Questions the Paper Calls Out
- Can natural language prompts effectively replace structured JSON commands for design generation without degrading output quality?
- How would integrating the physics simulator for autonomous surrogate model updates affect design generation quality and convergence?
- Would scaling to larger CodeT5+ variants improve conditional generation precision to better match target flight dynamics?

## Limitations
- Distribution shift risk: Performance on out-of-distribution design prompts remains untested
- Curriculum task interaction: Optimal balance between training tasks was determined empirically without systematic sensitivity analysis
- Simulator dependency: Model fundamentally depends on quality and coverage of AircraftVerse training data

## Confidence
- **High Confidence**: Model architecture and training procedure claims (CodeT5+ 220M parameters, 50K steps, curriculum design)
- **Medium Confidence**: Surrogate prediction accuracy claims (R² scores 0.161-0.944) supported by test set evaluations
- **Low Confidence**: Claims about rapid learning of JSON structure due to code pre-training supported only by this paper's success

## Next Checks
1. Generate 50 designs conditioned on hover times uniformly sampled from [0, 1000] seconds; run through physics simulator and analyze correlation between prompt values and simulator outputs
2. Systematically vary component generation weight (0%, 5%, 10%, 20%, 50%) while holding other parameters constant; measure impact on surrogate R² scores across 5 random seeds
3. Apply AGENT's curriculum framework to electric motor design domain; train for 25K steps and compare surrogate accuracy to domain-specific model trained from scratch