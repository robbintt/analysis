---
ver: rpa2
title: 'No One Left Behind: How to Exploit the Incomplete and Skewed Multi-Label Data
  for Conversion Rate Prediction'
arxiv_id: '2512.13300'
source_url: https://arxiv.org/abs/2512.13300
tags:
- conversion
- action
- data
- samples
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of training multi-task CVR models
  with incomplete and skewed multi-label data in online advertising. Many advertisers
  submit only a subset of user conversion actions due to privacy constraints, leading
  to asymmetric multi-label data.
---

# No One Left Behind: How to Exploit the Incomplete and Skewed Multi-Label Data for Conversion Rate Prediction

## Quick Facts
- arXiv ID: 2512.13300
- Source URL: https://arxiv.org/abs/2512.13300
- Authors: Qinglin Jia; Zhaocheng Du; Chuhan Wu; Huifeng Guo; Ruiming Tang; Shuting Shi; Muyu Zhang
- Reference count: 40
- Primary result: KAML framework achieves 12.11% RPM and 0.92% CVR improvement in online A/B tests for multi-task CVR prediction with incomplete and skewed multi-label data

## Executive Summary
This paper addresses the critical challenge of training multi-task conversion rate prediction models when advertisers submit only partial conversion labels due to privacy constraints. The proposed KAML framework tackles the problem of asymmetric multi-label data through three innovative strategies: attribution-driven masking to identify reliable conversion signals, hierarchical knowledge extraction to handle advertiser-specific data distribution discrepancies, and ranking-based label utilization to maximize utility from unlabeled samples. The framework demonstrates significant improvements over existing multi-task learning baselines, both in offline experiments and online A/B testing, with particular effectiveness in handling the real-world complexities of advertising platform data.

## Method Summary
The KAML framework introduces a comprehensive approach to handle incomplete and skewed multi-label data in conversion rate prediction. The attribution-driven masking strategy analyzes advertisers' historical submission patterns to identify reliable conversion signals while filtering out unreliable ones. The hierarchical knowledge extraction mechanism addresses the challenge of varying data distributions across different advertisers by creating advertiser-specific knowledge representations. The ranking-based label utilization strategy enables the model to leverage unlabeled samples by treating them as partial supervision through ranking constraints. These components work together to create a robust multi-task learning system that can effectively predict conversion rates even when data is incomplete and skewed across multiple advertisers.

## Key Results
- Achieves 12.11% improvement in Revenue Per Mille (RPM) in online A/B tests
- Delivers 0.92% improvement in Conversion Rate (CVR) in online A/B tests
- Significantly outperforms existing multi-task learning baselines on both industrial and public datasets

## Why This Works (Mechanism)
The framework succeeds by addressing the fundamental challenge of learning from incomplete and skewed multi-label data through three complementary strategies. The attribution-driven masking strategy identifies reliable conversion signals by analyzing historical submission patterns, ensuring the model learns from trustworthy data. The hierarchical knowledge extraction mechanism creates advertiser-specific representations that account for varying data distributions and submission patterns across different advertisers. The ranking-based label utilization strategy maximizes the utility of unlabeled samples by treating them as partial supervision, allowing the model to learn from the broader population of samples that lack complete label information. Together, these components create a robust learning system that can effectively handle the complexities of real-world advertising data.

## Foundational Learning
- Attribution-driven masking: Identifies reliable conversion signals from historical data; quick check: analyze historical submission patterns for consistency
- Hierarchical knowledge extraction: Creates advertiser-specific representations to handle data distribution discrepancies; quick check: compare representations across advertisers
- Ranking-based label utilization: Leverages unlabeled samples as partial supervision; quick check: validate ranking constraints on unlabeled data
- Multi-task learning architecture: Simultaneously predicts multiple conversion types; quick check: ensure balanced gradient flow across tasks
- Advertiser-specific modeling: Accounts for varying submission patterns and data distributions; quick check: measure performance across different advertiser segments

## Architecture Onboarding

Component Map: Input Data -> ADM Preprocessing -> HKE Knowledge Extraction -> RLU Label Utilization -> Multi-Task Prediction

Critical Path: Raw input features → Attribution-driven masking → Hierarchical knowledge representation → Ranking-based label assignment → Final conversion rate predictions

Design Tradeoffs: The framework balances between utilizing available labeled data and leveraging unlabeled samples, between advertiser-specific modeling and shared knowledge, and between computational efficiency and modeling complexity. The masking strategy introduces additional computation but improves reliability, while the hierarchical approach increases model complexity but captures advertiser-specific patterns more effectively.

Failure Signatures: Poor performance may occur when historical submission data is extremely sparse or inconsistent, when advertiser-specific patterns are too diverse to capture with hierarchical modeling, or when the ranking-based approach fails to properly utilize unlabeled samples. The model may also struggle when conversion patterns change rapidly over time.

First Experiments:
1. Test attribution-driven masking on synthetic data with known reliable/unreliable signals
2. Evaluate hierarchical knowledge extraction with varying numbers of advertisers
3. Assess ranking-based label utilization with different levels of label completeness

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several areas warrant further investigation: the generalizability of the framework across different advertising platforms, the impact of temporal dynamics on the attribution-driven masking strategy, and the scalability of the hierarchical knowledge extraction mechanism as the number of advertisers grows significantly.

## Limitations
- Performance validation was conducted primarily within Alibaba's ecosystem, raising questions about generalizability
- The hierarchical knowledge extraction mechanism's effectiveness may depend on the quality and completeness of historical submission data
- The ranking-based label utilization strategy assumes unlabeled samples follow similar patterns to labeled ones, which may not always hold
- The framework does not address potential biases introduced by the masking strategy

## Confidence

- KAML framework design and implementation: High
- Offline experimental results: Medium
- Online A/B test results: Medium
- Cross-platform generalizability: Low
- Long-term performance stability: Low

## Next Checks

1. Test KAML's performance on multiple advertising platforms with varying data completeness levels and different advertiser demographics
2. Conduct ablation studies to quantify the individual contributions of ADM, HKE, and RLU components under different data skew scenarios
3. Evaluate model performance over extended time periods to assess stability and identify potential temporal drift in conversion patterns