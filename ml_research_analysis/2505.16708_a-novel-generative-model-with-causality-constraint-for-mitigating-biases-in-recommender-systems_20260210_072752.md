---
ver: rpa2
title: A Novel Generative Model with Causality Constraint for Mitigating Biases in
  Recommender Systems
arxiv_id: '2505.16708'
source_url: https://arxiv.org/abs/2505.16708
tags:
- latent
- lcdr
- recommendation
- causal
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses latent confounding bias in recommender systems,
  which can obscure true causal relationships between user feedback and item exposure,
  degrading recommendation performance. The proposed LCDR framework uses an identifiable
  Variational Autoencoder (iVAE) to learn latent causal representations, which then
  constrain the latent representations learned by a standard VAE through a unified
  loss function.
---

# A Novel Generative Model with Causality Constraint for Mitigating Biases in Recommender Systems

## Quick Facts
- arXiv ID: 2505.16708
- Source URL: https://arxiv.org/abs/2505.16708
- Reference count: 40
- Primary result: LCDR achieves 19.4% higher NDCG@5 and 8.6% higher RECALL@5 compared to best baseline

## Executive Summary
This paper addresses latent confounding bias in recommender systems, where unobserved variables influence both user feedback and item exposure, obscuring true causal relationships. The proposed LCDR framework uses an identifiable Variational Autoencoder (iVAE) to learn latent causal representations from exposure and proxy variables, then constrains a standard VAE's latent space through an alignment loss. This allows the model to recover meaningful confounders even from weak proxy signals. Extensive experiments on three real-world datasets (Coat, Yahoo!R3, KuaiRand) demonstrate consistent improvements over state-of-the-art methods, with LCDR achieving 19.4% higher NDCG@5 and 8.6% higher RECALL@5 on average.

## Method Summary
LCDR employs a two-phase approach to mitigate latent confounding bias. First, it jointly trains an iVAE (taking exposure A and proxy variables W) and a constrained VAE (taking only exposure A). The iVAE learns identifiable latent representations Z by conditioning its prior on proxies, while the LCVAE learns Z_lc constrained to align with Z through an L2 distance term in the unified loss. After representation learning, a Matrix Factorization model uses Z_lc as additional input for final recommendations. The constraint term λ controls the strength of alignment, allowing LCDR to leverage even weak proxy variables while avoiding the need for proxies during inference.

## Key Results
- LCDR achieves 19.4% higher NDCG@5 and 8.6% higher RECALL@5 on average compared to the best baseline method
- Consistent performance improvements across all three datasets (Coat, Yahoo!R3, KuaiRand) and all metric variants (Recall@5, NDCG@5, NDCG@10)
- Ablation studies confirm the importance of both the iVAE component and the constraint term, with performance degrading when either is removed

## Why This Works (Mechanism)

### Mechanism 1: Identifiable Latent Confounder Recovery via iVAE
LCDR recovers latent confounders that are causally meaningful rather than arbitrary statistical representations. The iVAE component conditions its prior p(Z|W) on proxy variables W (e.g., user demographics, item features). By using auxiliary variables that vary independently of exposure A, iVAE achieves identifiability up to a linear transformation, per Theorem 1 in Section 4.7. This distinguishes it from standard VAEs where latent representations are unidentifiable. Core assumption: Proxy variables W must have sufficient variability and satisfy invertibility conditions (L matrix full rank). Break condition: If proxy variables W are constant or near-deterministic functions of exposure A, identifiability fails.

### Mechanism 2: Indirect Causal Constraint via L2 Alignment
Constraining VAE representations toward iVAE representations transfers causal structure without requiring proxies at inference time. The unified loss (Eq. 6) adds λ * ||Z_lc - Z||² to the standard VAE ELBO. This forces Z_lc (learned by LCVAE from A alone) to align with Z (learned by iVAE from A and W). At inference, only Z_lc is needed—no proxy variables required. The constraint acts as a regularizer preventing Z_lc from overfitting to spurious correlations in exposure data. Core assumption: The iVAE representations Z capture meaningful confounder structure even when proxies are noisy/weak. Break condition: If λ is set too high, Z_lc collapses to Z and loses information; if too low, no causal benefit transfers.

### Mechanism 3: Backdoor-Style Adjustment Using Learned Confounders
Marginalizing over Z_lc in the outcome model removes confounding bias from exposure-outcome estimation. Following Eq. 13, the potential outcome distribution is computed as E_{Z_lc}[p(r_ui|A, Z_lc)]. This is a standard backdoor adjustment where Z_lc serves as the adjustment set. The additive model f(u, i, Z_lc; η) = L_LCVAE + L_MF (Eq. 18) incorporates confounder information into predictions. Core assumption: Z_lc must satisfy the backdoor criterion (block all confounding paths). Break condition: If Z_lc does not capture all confounders, residual bias remains.

## Foundational Learning

- Concept: Variational Autoencoders and the Evidence Lower Bound (ELBO)
  - Why needed here: Understanding how LCDR modifies the standard VAE objective (adding causal constraint) requires fluency with ELBO decomposition (reconstruction + KL terms)
  - Quick check question: Can you explain why maximizing ELBO is equivalent to maximizing log-likelihood with a regularization term?

- Concept: Confounding and Backdoor Adjustment in Causal Inference
  - Why needed here: The core motivation is latent confounding bias; Section 4.4 uses backdoor-style formulas to define debiasing
  - Quick check question: In a DAG where Z affects both A (treatment) and R (outcome), why does conditioning on Z remove confounding bias?

- Concept: Identifiability in Latent Variable Models
  - Why needed here: iVAE's claim rests on identifiability (Theorem 1). Without this, Z could be any rotation of true confounders
  - Quick check question: Why does conditioning the prior on auxiliary variables (W) help achieve identifiability compared to a standard VAE?

## Architecture Onboarding

- Component map:
  - iVAE encoder: (A, W) → (μ_w, σ_w) → Z via reparameterization
  - LCVAE encoder: A → (μ_φ, σ_φ) → Z_lc via reparameterization
  - LCVAE decoder: Z_lc → reconstruction of A
  - Constraint: L2 distance ||Z_lc - Z||² computed per batch
  - Recommendation head: f(u, i, Z_lc) combines LCVAE loss + MF prediction (Eq. 18)

- Critical path:
  1. Batch of (A, W) enters both iVAE and LCVAE in parallel
  2. iVAE produces Z; LCVAE produces Z_lc
  3. Loss = -ELBO + λ||Z_lc - Z||²
  4. After representation learning converges, freeze encoders
  5. Train MF model with Z_lc as additional input

- Design tradeoffs:
  - λ tuning: High λ (e.g., 0.9 on Coat/KuaiRand) enforces strong constraint but risks information loss; low λ (0.1 on Yahoo!R3) preserves flexibility but weaker debiasing
  - Proxy selection: Paper uses available features (demographics, categories); Assumption: better proxies → stronger identifiability but no formal proxy quality metric provided
  - Latent dimension: Not explicitly tuned in paper; should match confounder complexity

- Failure signatures:
  - NDCG/Recall similar to MF baseline: Constraint may be too weak (λ≈0) or proxies uninformative
  - Performance worse than VAE-iVAE naive combination: Constraint too strong (λ→1), Z_lc collapsed
  - High variance across runs: Check reparameterization stability; ensure KL annealing if needed

- First 3 experiments:
  1. Reproduce Coat dataset results (Table 3) with λ=0.9; verify NDCG@5 ≈ 0.597
  2. Ablation: Train LCDR without constraint term (λ=0) and compare to Table 4 "LCDR w/o LC"
  3. Proxy quality test: Replace W with random noise; expect performance drop toward MF baseline, confirming proxy necessity for identifiability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the LCDR framework be effectively extended to mitigate other types of biases in recommender systems, such as selection bias?
- Basis in paper: [explicit] "In the future, we plan to explore the potential of utilizing the LCDR model to address other challenges in recommender systems, such as selection bias."
- Why unresolved: The current work focuses solely on latent confounding bias; selection bias involves different causal mechanisms and may require modifications to the constraint framework
- What evidence would resolve it: Experiments applying LCDR to datasets with known selection bias, comparing against methods like IPS and DR-JL specifically on selection bias metrics

### Open Question 2
- Question: How does LCDR perform when integrated with more complex recommendation backbones beyond Matrix Factorization, such as DeepFM, DCN, or graph-based models?
- Basis in paper: [inferred] The paper only evaluates LCDR with MF as the backbone, stating "we adopt the Matrix Factorisation (MF) model... given its simplicity and widespread use." Performance with richer architectures remains untested
- Why unresolved: More complex backbones have different inductive biases and may interact differently with the latent causal constraints
- What evidence would resolve it: Comparative experiments integrating LCDR constraints into neural recommendation models (e.g., DeepFM, LightGCN) on the same benchmark datasets

### Open Question 3
- Question: How sensitive is LCDR's performance to systematic degradation in proxy variable quality, and what is the minimum proxy information required for effective debiasing?
- Basis in paper: [inferred] The paper claims LCDR works with "weak or noisy proxy variables" but does not conduct controlled experiments varying proxy quality or systematically removing proxy features
- Why unresolved: Real-world proxy variables vary in relevance and noise levels; understanding failure modes is critical for practical deployment
- What evidence would resolve it: Ablation studies with synthetic noise injection into proxy variables and experiments progressively removing proxy features to identify critical information thresholds

### Open Question 4
- Question: How should the constraint weight λ be automatically tuned for new datasets, given its high sensitivity and dataset-specific optimal values (0.1 vs. 0.9)?
- Basis in paper: [inferred] The paper uses λ=0.9 for Coat, λ=0.1 for Yahoo!R3, and λ=0.9 for KuaiRand without providing a principled selection method, and hyperparameter analysis shows performance degrades with suboptimal λ
- Why unresolved: Grid search is impractical for production systems; no guidance exists for predicting optimal λ from dataset properties
- What evidence would resolve it: Analysis correlating dataset characteristics (e.g., sparsity, proxy correlation strength) with optimal λ, or development of an adaptive λ adjustment mechanism

## Limitations
- The identifiability mechanism relies on strong assumptions about proxy variable quality and variability that may not hold in real-world settings
- The exact interpretation of the recommendation loss function (Eq. 18) remains ambiguous, potentially affecting reproducibility
- The paper does not provide sensitivity analysis for critical hyperparameters (λ, latent dimension) that significantly impact performance

## Confidence
- High Confidence: Empirical performance gains (19.4% NDCG@5, 8.6% RECALL@5) are well-supported by experimental results across three datasets
- Medium Confidence: The iVAE identifiability mechanism is theoretically sound but relies on assumptions that require empirical validation
- Medium Confidence: The backdoor adjustment interpretation is reasonable but not formally proven to eliminate all confounding bias

## Next Checks
1. **Proxy Sensitivity Test:** Systematically vary proxy quality (e.g., add noise, reduce features) to empirically validate whether identifiability claims hold in practice
2. **Hyperparameter Stability:** Conduct grid search over λ and latent dimensions to establish robustness and identify optimal settings across datasets
3. **Causal Graph Verification:** Perform counterfactual analysis to verify that Z_lc blocks all backdoor paths, confirming the backdoor adjustment interpretation