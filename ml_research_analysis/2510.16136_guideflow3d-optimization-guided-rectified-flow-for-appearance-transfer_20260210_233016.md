---
ver: rpa2
title: 'GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer'
arxiv_id: '2510.16136'
source_url: https://arxiv.org/abs/2510.16136
tags:
- appearance
- transfer
- image
- mesh
- object
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GuideFlow3D introduces a training-free framework for transferring
  texture and fine geometric details from an appearance object to a 3D asset, even
  when the geometries of the input and appearance objects differ significantly. The
  method extends rectified flow sampling with differentiable guidance functions, enabling
  inference-time conditioning without retraining.
---

# GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer

## Quick Facts
- arXiv ID: 2510.16136
- Source URL: https://arxiv.org/abs/2510.16136
- Authors: Sayan Deb Sarkar; Sinisa Stekovic; Vincent Lepetit; Iro Armeni
- Reference count: 40
- Primary result: Introduces a training-free framework for transferring texture and fine geometric details from an appearance object to a 3D asset using optimization-guided rectified flow sampling.

## Executive Summary
GuideFlow3D presents a novel training-free approach for 3D appearance transfer that enables the transfer of texture and fine geometric details from an appearance object (image-mesh pair or text) to an input 3D mesh, even when geometries differ significantly. The method extends rectified flow sampling with differentiable guidance functions, allowing inference-time conditioning without retraining. By interleaving latent-space optimization with sampling steps, the framework preserves global 3D structure while enabling fine-grained style control through two novel guidance objectives: part-aware appearance loss and self-similarity loss.

## Method Summary
GuideFlow3D operates on Structured Latents (SLAT) from Trellis, where fixed voxel positions anchor learnable latent codes. The method implements two guidance objectives: L_appearance for image-mesh pairs using PartField co-segmentation to establish semantic correspondences, and L_structure for text/image-only conditioning using contrastive self-similarity loss. During sampling, the standard rectified flow update is interleaved with gradient steps from the guidance loss, creating a tug-of-war between the pretrained velocity field (preserving realistic geometry) and the guidance gradient (steering toward the appearance target). The approach uses pretrained trellis-image-large and trellis-text-large checkpoints, runs for 300 steps with AdamW (lr=5×10^-4), and achieves transfer in 96 seconds on RTX 4090.

## Key Results
- Outperforms baselines across both image and text-conditioned settings in GPT-based ranking evaluations
- Successfully transfers appearance to meshes with significantly different geometries through part-aware semantic correspondence
- Maintains structural consistency through self-similarity loss when 3D appearance geometry is unavailable
- Demonstrates flexibility by handling diverse 3D shapes and styles from multiple datasets

## Why This Works (Mechanism)

### Mechanism 1: Interleaved Optimization-Flow Sampling
The method replaces standard reverse-time ODE updates with guidance-injected updates: $\hat{z}_t = z_t + \Delta t \cdot v_\theta(zt, t|c) + \nabla_{z_t} L(z|c)$. This creates a "tug-of-war" where the pretrained velocity field $v_\theta$ maintains realistic 3D structure while the gradient $\nabla L$ steers the latent toward the specific appearance target. The core assumption is that the velocity field is robust enough to project off-manifold perturbations back onto the manifold of valid 3D assets during subsequent steps.

### Mechanism 2: Part-Aware Semantic Correspondence
Using geometric co-segmentation features from PartField, the method clusters voxels into semantic parts (e.g., "legs," "seat") and enforces appearance consistency only within corresponding clusters via the $L_{appearance}$ loss. This prevents texture misalignment when global geometries differ by matching functional parts across different object categories. The approach relies on approximate matching rather than one-to-one correspondences, making it robust to geometric variations.

### Mechanism 3: Structural Contrastive Consistency
When no 3D appearance mesh is available, the method applies $L_{structure}$, a contrastive loss that maximizes similarity between voxels in the same geometric cluster while pushing apart those in different clusters. This self-similarity loss acts as a regularizer to prevent the "style" from overwhelming the "structure," preserving the intrinsic geometry of the input mesh even with text or image conditioning.

## Foundational Learning

- **Rectified Flow**: Straight trajectory sampling from noise to data using ODE formulation $z_t = (1-t)z_0 + t\epsilon$. Needed to understand the ODE sampling loop and why this differs from stochastic diffusion. Quick check: Does the sampler predict noise ($\epsilon$) or velocity ($v = \epsilon - z_0$)? (Answer: velocity $v_\theta$).

- **Structured Latents (SLAT)**: Sparse voxel grid of latent codes anchored to mesh surface where position $p_i$ is fixed while latent $z_i$ is updated. Critical to understand that we optimize feature vectors at fixed coordinates. Quick check: In the update equation, are we optimizing voxel coordinates or feature vectors? (Answer: feature vectors).

- **Universal Guidance**: Replacing "training a ControlNet" with "inference-time optimization" by backpropagating arbitrary losses through latents. Needed to understand how to apply custom losses during sampling. Quick check: If $z_t$ requires gradients, how does the computational graph interact with the frozen velocity model $v_\theta$? (Answer: gradients flow through the update equation).

## Architecture Onboarding

- **Component map**: Input Mesh + Appearance Object -> Trellis Encoder + PartField Encoder -> GuideFlow3D Sampler (Rectified Flow + Gradient Descent) -> D3D Decoder -> Output Mesh

- **Critical path**: 1) Voxelization of Input Mesh & random latent initialization; 2) PartField feature extraction for co-segmentation; 3) The Loop: For $t$ in $[T, 0]$: a) Flow Step: $z_{flow} \leftarrow z_t - \Delta t \cdot v_\theta(z_t)$; b) Guidance: Compute $L_{appearance}$ or $L_{structure}$ and gradients; c) Update: $z_{t-1} \leftarrow z_{flow} + \alpha \cdot \nabla L$; 4) Decode final latent to Mesh.

- **Design tradeoffs**: Inference speed overhead (96s vs 78s baseline) due to optimization loop; heavy reliance on PartField segmentation quality; high guidance weight improves style fidelity but risks breaking geometry.

- **Failure signatures**: Janus Problem/Multi-face artifacts (base Rectified Flow failure); Texture Bleeding (coarse PartField clustering); Gray/Washed out results (weak guidance signal or low learning rate).

- **First 3 experiments**: 1) Sanity Check: Run "w/o Rectified Flow" (pure optimization) to confirm artifacts, then "w/o Guidance" to confirm lack of style transfer; 2) Correspondence Ablation: Replace PartField with Euclidean Nearest Neighbors in latent space to visualize semantic alignment drop; 3) Text vs. Image Guidance: Run same mesh with image reference vs. text prompt to compare texture fidelity vs. structural preservation.

## Open Questions the Paper Calls Out

- Can the optimization-guided sampling be replaced with a self-supervised feed-forward network for real-time inference while maintaining transfer quality? The current method requires 96 seconds on RTX 4090, and the paper suggests this as future work.

- How can guidance objectives be designed to handle noisy or incomplete input meshes, which the current method explicitly assumes are noiseless? The paper notes this as a limiting factor for some future applications.

- Does the co-segmentation-based correspondence mechanism fail systematically for certain geometric configurations like highly asymmetric objects or thin structures? The paper lacks systematic analysis of failure modes despite noting some limitations.

## Limitations

- Inference speed is significantly slower than baseline methods due to the optimization loop, making real-time applications impractical.
- The method relies heavily on external models (PartField for segmentation, Trellis for generation) whose quality directly impacts performance.
- Assumes noiseless input meshes, limiting applicability to real-world scanned data with artifacts or missing geometry.

## Confidence

- **High confidence**: Core framework (interleaved rectified flow + gradient guidance) and experimental evaluation design
- **Medium confidence**: Novel guidance losses (part-aware appearance, self-similarity) due to limited direct evidence in corpus
- **Low confidence**: Exact implementation details of guidance schedule and weighting

## Next Checks

1. **Schedule ablation**: Run with guidance at every step vs. every N steps to measure impact on realism and style transfer
2. **Gradient weighting sweep**: Test λ ∈ {0.1, 1, 10} to find the balance between preserving geometry and enhancing style fidelity
3. **Part segmentation baseline**: Replace PartField with simple geometric clustering to isolate the benefit of semantic correspondence