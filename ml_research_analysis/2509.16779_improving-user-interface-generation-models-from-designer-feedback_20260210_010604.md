---
ver: rpa2
title: Improving User Interface Generation Models from Designer Feedback
arxiv_id: '2509.16779'
source_url: https://arxiv.org/abs/2509.16779
tags:
- feedback
- designers
- data
- design
- designer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a method for improving UI generation models
  using designer feedback. The authors collected feedback from 21 designers on synthetically
  generated UIs using four interfaces: ranking, commenting, sketching, and revising.'
---

# Improving User Interface Generation Models from Designer Feedback

## Quick Facts
- **arXiv ID**: 2509.16779
- **Source URL**: https://arxiv.org/abs/2509.16779
- **Reference count**: 40
- **Key outcome**: Sketching and revising feedback interfaces produce higher quality training data for UI generation models than conventional ranking methods

## Executive Summary
This paper addresses the challenge of generating user interfaces that meet designer expectations by introducing a novel approach that incorporates designer feedback into model training. The authors developed four different feedback interfaces (ranking, commenting, sketching, and revising) and collected preference pairs from 21 designers evaluating synthetically generated UIs. They converted this feedback into training data to fine-tune code generation models, demonstrating that designer-aligned interfaces like sketching and revising produce superior results compared to conventional ranking methods. Their approach achieved state-of-the-art performance, with the sketching-trained model outperforming established baselines including GPT-5.

## Method Summary
The authors collected feedback from 21 designers on synthetically generated UIs using four distinct interfaces: ranking, commenting, sketching, and revising. Designers evaluated the generated UIs and provided their feedback through these interfaces. The collected feedback was then converted into preference pairs, which served as training data for fine-tuning code generation models. The researchers experimented with different base models and measured performance improvements after incorporating the designer feedback. They conducted both quantitative evaluations of model performance and qualitative analysis of the feedback quality to determine which interfaces produced the most useful training data.

## Key Results
- Sketching and revising feedback interfaces produced the highest quality training data and best model performance
- The sketching-trained model outperformed all tested baselines, including GPT-5
- Designer-aligned feedback interfaces generated more effective training data than conventional ranking methods
- The approach demonstrated generalizability across different base models

## Why This Works (Mechanism)
The mechanism works by directly incorporating human design preferences into the model training process. When designers provide feedback through sketching and revising interfaces, they communicate their intent and design preferences more precisely than through ranking alone. This richer feedback creates more informative preference pairs that capture the nuances of good UI design. The fine-tuning process then aligns the model's generation capabilities with these learned preferences, resulting in outputs that better match designer expectations. The iterative nature of sketching and revising allows designers to articulate specific improvements, creating more targeted training signals than binary comparisons.

## Foundational Learning

**UI Generation Models**
- *Why needed*: Foundation for understanding how AI creates interface designs
- *Quick check*: Can identify common UI components and layout patterns

**Fine-tuning Code Generation Models**
- *Why needed*: Core technique for adapting models to designer preferences
- *Quick check*: Understands how preference pairs update model weights

**Preference Learning from Human Feedback**
- *Why needed*: Key mechanism for incorporating designer input
- *Quick check*: Can explain how feedback translates to training signals

**Interface Design Feedback Methods**
- *Why needed*: Different ways designers communicate preferences
- *Quick check*: Understands strengths/weaknesses of ranking vs sketching

## Architecture Onboarding

**Component Map**
Designer Feedback Collection -> Preference Pair Generation -> Model Fine-tuning -> UI Generation

**Critical Path**
The most critical path is: Designer provides sketching/revising feedback → Preference pairs created → Model fine-tuning → Improved UI generation. This path directly connects human input to model output quality.

**Design Tradeoffs**
- Ranking interfaces: Easy to implement but limited feedback depth
- Commenting interfaces: Rich qualitative data but harder to convert to preference pairs
- Sketching interfaces: Most precise feedback but requires more designer effort
- Model complexity vs. training data quality tradeoff

**Failure Signatures**
- Poor model performance indicates insufficient or misaligned feedback
- Inconsistent preference pairs suggest unclear designer instructions
- Overfitting to specific designers' preferences rather than general design principles

**First Experiments**
1. Compare model performance using feedback from each interface type
2. Test generalizability by fine-tuning different base models with same feedback
3. Validate preference pair quality through inter-designer agreement analysis

## Open Questions the Paper Calls Out
None

## Limitations
- Small sample size of 21 designers may not represent broader design community
- Synthetic UI generation evaluation may not capture real-world design complexity
- Limited number of preference pairs (n=141) for some interface comparisons

## Confidence

**High confidence**: Sketching and revising feedback interfaces effectively produce higher quality training data, well-supported by experimental results and qualitative analysis.

**Medium confidence**: Generalizability across different base models is demonstrated but limited to specific models tested; GPT-5 comparison claims require caution due to potential evaluation differences.

**Medium confidence**: Designer-aligned interfaces produce better data than ranking methods, supported by results but based on relatively small sample size.

## Next Checks
1. **Scale validation**: Replicate study with larger, more diverse designer group (minimum 50 participants) to confirm interface effectiveness and validate preference data quality.

2. **Real-world application testing**: Implement fine-tuned models in actual design workflows to assess practical utility, user satisfaction, and impact on design efficiency compared to baseline approaches.

3. **Long-term stability assessment**: Evaluate model performance and feedback quality over extended periods and multiple fine-tuning iterations to understand potential degradation or improvement patterns in the feedback-to-performance pipeline.