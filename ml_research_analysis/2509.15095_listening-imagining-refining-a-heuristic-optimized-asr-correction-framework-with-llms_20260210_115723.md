---
ver: rpa2
title: 'Listening, Imagining & Refining: A Heuristic Optimized ASR Correction Framework
  with LLMs'
arxiv_id: '2509.15095'
source_url: https://arxiv.org/abs/2509.15095
tags:
- correction
- lir-asr
- heuristic
- search
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LIR-ASR introduces a novel heuristic-optimized iterative framework
  for ASR error correction, inspired by human auditory perception. It employs a "Listening-Imagining-Refining"
  strategy where LLM-generated phonetic variants are contextually evaluated and refined.
---

# Listening, Imagining & Refining: A Heuristic Optimized ASR Correction Framework with LLMs

## Quick Facts
- arXiv ID: 2509.15095
- Source URL: https://arxiv.org/abs/2509.15095
- Reference count: 0
- Primary result: LIR-ASR achieves up to 1.5 percentage point reduction in CER/WER over baselines across English and Chinese ASR outputs

## Executive Summary
LIR-ASR introduces a novel heuristic-optimized iterative framework for ASR error correction, inspired by human auditory perception. It employs a "Listening-Imagining-Refining" strategy where LLM-generated phonetic variants are contextually evaluated and refined. A finite state machine guides controlled exploration of candidate corrections, while rule-based constraints maintain semantic fidelity. Experiments demonstrate average CER/WER reductions of up to 1.5 percentage points over baselines, with the proposed method outperforming direct and evolutionary prompts, as well as n-best approaches, across both English and Chinese ASR outputs. The method shows reliable convergence and effectively handles interdependent recognition errors.

## Method Summary
The LIR-ASR framework operates through iterative cycles of error detection (Listening), phonetic variant generation (Imagining), and context-aware correction (Refining). A finite state machine controls the search process, alternating between exploration and exploitation states to avoid local optima. Phonetic neighbors are generated via G2P conversion, then evaluated by LLMs with rule-based constraints filtering semantically inconsistent candidates. The process terminates when no improvement occurs for k≥2 consecutive iterations or i≥8 total iterations. The framework was evaluated on FLEURS dataset subsets using Whisper-medium and Whisper-large-v3 recognizers, with Qwen3-235B and DeepSeek-V3.1 as LLM correctors.

## Key Results
- Average CER/WER reductions of up to 1.5 percentage points over baselines
- Outperforms direct and evolutionary prompts, as well as n-best approaches
- Effective handling of interdependent recognition errors through iterative refinement
- Reliable convergence behavior with FSM-controlled search termination

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The finite state machine (FSM) enables controlled alternation between exploration and exploitation, preventing stagnation in local optima.
- **Mechanism:** Three states—No Search, Search, Search++—govern when phonetic variants are generated. The FSM transitions based on whether transcript improvements occur, with termination triggered after k≥2 consecutive no-change iterations or i≥8 total iterations. This prevents premature convergence while limiting computational cost.
- **Core assumption:** Recognition errors are interdependent, requiring progressive resolution rather than one-step correction (Section 1).
- **Evidence anchors:**
  - [abstract] "A heuristic optimization with finite state machine (FSM) is introduced to prevent the correction process from being trapped in local optima"
  - [Section 2.1] Full FSM transition logic with termination criteria
  - [corpus] Weak direct corpus support; neighbor papers focus on GER paradigms without explicit FSM control
- **Break condition:** If errors are isolated rather than interdependent, FSM overhead provides diminishing returns.

### Mechanism 2
- **Claim:** Phonetic neighbor generation via G2P creates semantically plausible correction candidates that LLMs can evaluate contextually.
- **Mechanism:** Grapheme-to-Phoneme conversion produces similar-sounding character substitutions. Each candidate si ∈ N(s) is corrected in parallel by the LLM (Eq. 1), then fused via F(·) to preserve semantic meaning. The scoring function f(s) evaluates candidates, with greedy acceptance ensuring monotonic improvement.
- **Core assumption:** ASR errors preserve phonetic similarity to ground truth (homophones, near-homophones dominate error types).
- **Evidence anchors:**
  - [Section 2.2] "Neighbor generation is performed via Grapheme-to-Phoneme (G2P) conversion and similar-sounding character substitutions"
  - [Section 3.3] Ablation shows removing neighbor search increases CER/WER to 3.25/5.98
  - [corpus] Confidence-Guided Error Correction (arxiv 2509.25048) similarly uses word-level uncertainty for LLM-based correction
- **Break condition:** If ASR errors are largely non-phonetic (semantic hallucinations, word order issues), neighbor generation will miss correct candidates.

### Mechanism 3
- **Claim:** Rule-based constraints filter linguistically plausible but semantically inconsistent substitutions, maintaining fidelity to original speech content.
- **Mechanism:** Two constraint types: (1) Phonetic consistency—replacements must meet similarity thresholds via Pinyin/G2P metrics; (2) Length/structure consistency—excessive insertions or deletions are filtered. Candidates failing constraints are excluded from S′ before scoring.
- **Core assumption:** LLMs may generate corrections that improve surface fluency but deviate from speaker intent.
- **Evidence anchors:**
  - [Section 2.2] "Candidate replacements must be sufficiently similar in pronunciation... Candidates with excessive insertion or deletion are filtered out"
  - [Section 3.3] Removing rules causes largest performance drop: CER/WER degrades from 2.89/5.23 to 6.62/9.27 on Whisper-large-v3 Chinese
  - [corpus] Fewer Hallinations paper (cited in Section 1) addresses similar LLM hallucination risks in ASR correction
- **Break condition:** If original ASR output has severe structural errors requiring significant rewrites, rigid constraints may block valid corrections.

## Foundational Learning

- **Concept: Finite State Machines for Search Control**
  - Why needed here: Understanding state transitions (No Search → Search → Search++) explains why the system alternates between refining current candidates and exploring new phonetic variants.
  - Quick check question: Given a transcript that improves on iteration 3 but not iteration 4, which state would the FSM be in for iteration 5?

- **Concept: Grapheme-to-Phoneme (G2P) Conversion**
  - Why needed here: Neighbor generation depends on G2P to produce phonetically similar alternatives. Without this, you cannot trace how candidate corrections are generated.
  - Quick check question: For the Chinese character sequence "支付" (zhīfù), what phonetic neighbors might G2P generate?

- **Concept: Monotone Convergence in Iterative Optimization**
  - Why needed here: The paper claims guaranteed convergence (Eq. 5-7) based on non-decreasing scores and bounded f max. Understanding this helps diagnose when iterations fail to improve.
  - Quick check question: If f(st) plateaus for 3 consecutive iterations but k has not reached threshold, what does this imply about the candidate neighborhood?

## Architecture Onboarding

- **Component map:**
  ASR Output → [FSM Controller] ←→ [Neighbor Generator (G2P)] → [LLM Corrector] → Corrected Candidates → [Candidate Fusion] → Fused Transcript → [Rule Constraints] → Filtered Candidate Set S′ → [LLM Scorer] → Score f(s) → [Greedy Selector] → Updated Transcript or Terminate

- **Critical path:** The FSM state determines whether neighbor search occurs. If in No Search and no improvement for k≥2 iterations, the process terminates before exploring phonetic variants—this is the most common early-exit point.

- **Design tradeoffs:**
  - Max iterations (i≥8) vs. convergence quality: Lower values reduce latency but may leave interdependent errors unresolved.
  - Candidate pool size (fixed at 3): Larger pools increase coverage but multiply LLM calls.
  - Rule constraint strictness: Tighter phonetic thresholds prevent drift but may reject valid corrections in accented speech.

- **Failure signatures:**
  - Rapid termination with k=2: Indicates either high-quality ASR input or overly aggressive neighbor generation producing no viable candidates.
  - Score oscillation (not shown in paper but implied): Would suggest LLM scoring inconsistency—paper assumes monotonic improvement.
  - Performance collapse without rules (CER 6.62): Signals LLM is rewriting rather than correcting.

- **First 3 experiments:**
  1. **Reproduce ablation on single language:** Run LIR-ASR with DeepSeek-V3.1 on FLEURS Chinese subset, systematically disabling rule constraints. Expect CER increase of ~3-4 points if implementation is correct.
  2. **FSM state transition logging:** Instrument the FSM to log state sequences across 100 samples. Verify that "stuck" transcripts (no improvement) terminate at k=2, not max iterations.
  3. **Phonetic neighbor inspection:** For 20 corrected samples, manually inspect N(s) candidates before and after rule filtering. Confirm filtered candidates are semantic drifts, not phonetic near-misses.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LIR-ASR maintain performance gains when applied to low-resource languages like Tibetan, given challenges in phonetic variability and data scarcity?
- Basis: [explicit] The authors state future work involves extending the framework to Tibetan to validate cross-lingual adaptability.
- Why unresolved: Current experiments are restricted to English and Chinese subsets of the FLEURS dataset.
- What evidence would resolve it: Evaluation results on Tibetan datasets showing CER/WER improvements comparable to those in high-resource languages.

### Open Question 2
- Question: What is the computational latency and resource cost trade-off of the iterative LIR-ASR framework compared to single-pass correction methods?
- Basis: [inferred] The methodology involves up to 8 iterations, requiring multiple LLM calls (scoring, fusion) and G2P neighbor generation per sample.
- Why unresolved: The paper focuses on accuracy (CER/WER) but does not report inference time or computational overhead.
- What evidence would resolve it: Latency benchmarks (e.g., RTF or ms/audio sec) and token consumption metrics compared to baselines.

### Open Question 3
- Question: How robust is the convergence behavior when the LLM's scoring function diverges from ground truth accuracy?
- Basis: [inferred] The theoretical convergence relies on the LLM assigning accurate scores, but LLMs may score "fluently hallucinated" text higher than the ground truth.
- Why unresolved: While rule constraints mitigate this, the system could theoretically converge to a "locally optimal" error if the LLM persists in favoring it.
- What evidence would resolve it: Analysis of failure cases where the iteration count increases but WER degrades or stabilizes on semantically incorrect text.

## Limitations
- Prompt engineering opacity: No examples of Listening, Imagining, or Refining prompts provided, making exact reproduction speculative
- Phonetic similarity metric ambiguity: Specific similarity algorithm and thresholds unspecified, affecting constraint filtering reproducibility
- Interdependent error assumption fragility: FSM overhead may provide minimal benefit if real ASR errors are largely isolated

## Confidence
- **High confidence** in FSM mechanism and termination logic—fully specified with clear state transitions and convergence proofs
- **Medium confidence** in neighbor generation effectiveness—G2P is standard but specific substitution rules and candidate selection criteria are underspecified
- **Low confidence** in absolute performance claims—without prompt templates or scoring function details, the 1.5-point CER/WER reduction cannot be independently verified

## Next Checks
1. **Prompt template isolation test:** Implement the three LLM prompts (Listening, Imagining, Refining) with placeholder instructions, run on 10 samples, and measure baseline LLM correction performance without FSM or constraints. This isolates LLM capability from framework contribution.

2. **Phonetic similarity metric validation:** For 20 corrected samples, manually inspect which phonetic neighbors pass/failure rule constraints. Verify that filtered candidates are semantic drifts rather than valid corrections, confirming constraint thresholds are appropriate.

3. **FSM state transition analysis:** Instrument the FSM to log state sequences across 100 samples. Verify that transcripts failing to improve terminate at k=2 iterations (not max 8), and that Search++ state is only entered when prior improvements are detected, confirming FSM logic matches paper claims.