---
ver: rpa2
title: 'AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda'
arxiv_id: '2511.02374'
source_url: https://arxiv.org/abs/2511.02374
tags:
- clinical
- ayurvedic
- language
- ayurveda
- ayurparam
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AyurParam-2.9B is a bilingual (English-Hindi) language model fine-tuned
  from Param-1-2.9B-Instruct on a domain-specific Ayurveda corpus. The model was trained
  using 4.75 million Q&A pairs derived from classical Ayurvedic texts and clinical
  literature.
---

# AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda

## Quick Facts
- arXiv ID: 2511.02374
- Source URL: https://arxiv.org/abs/2511.02374
- Reference count: 40
- Primary result: AyurParam-2.9B achieves 39.97% overall accuracy on BhashaBench-Ayur, outperforming 1.5-3B instruction-tuned models

## Executive Summary
AyurParam-2.9B is a bilingual (English-Hindi) language model fine-tuned from Param-1-2.9B-Instruct on a domain-specific Ayurveda corpus. The model was trained using 4.75 million Q&A pairs derived from classical Ayurvedic texts and clinical literature. On the BhashaBench-Ayur benchmark, AyurParam-2.9B achieved 39.97% overall accuracy, outperforming other 1.5-3B parameter instruction-tuned models (e.g., Llama-3.2-3B: 33.20%, Qwen2.5-3B: 32.68%) and matching larger models. The model demonstrated particularly strong performance on multiple-choice questions (40.12% accuracy) and maintained consistent results across easy, medium, and hard difficulty levels. This work demonstrates that targeted domain adaptation with high-quality supervision enables small-scale models to achieve outsized gains in specialized benchmarks.

## Method Summary
AyurParam was developed through supervised fine-tuning of Param-1-2.9B-Instruct using 4.75 million instruction pairs in English and Hindi. The training data was generated by synthesizing classical Ayurvedic texts and clinical literature using Qwen-3 235B, followed by rigorous human-in-the-loop validation with domain experts. The model was trained for 3 epochs with a learning rate of 5×10⁻⁶ on a multi-node NVIDIA H100 cluster, using a batch size of 1024. Evaluation was conducted on BhashaBench-Ayur, a benchmark consisting of 14,963 questions across 15+ domains, including multiple-choice, fill-in-the-blank, assertion-reason, and match-column formats.

## Key Results
- AyurParam-2.9B achieved 39.97% overall accuracy on BhashaBench-Ayur
- Outperformed other 1.5-3B parameter instruction-tuned models (Llama-3.2-3B: 33.20%, Qwen2.5-3B: 32.68%)
- Strong performance on multiple-choice questions (40.12% accuracy)
- Consistent results across difficulty levels (easy: 43.93%, medium: 38.86%, hard: 31.21%)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Targeted domain fine-tuning on curated Ayurvedic corpus enables smaller models to outperform larger general-purpose models on specialized benchmarks.
- Mechanism: Exposure to 4.75M domain-specific examples spanning classical texts, clinical guidelines, and Q&A pairs allows the model to internalize Ayurvedic terminology, reasoning frameworks (dosha imbalances, samprapti), and bilingual conventions that general LLMs lack.
- Core assumption: General-purpose pre-training corpora contain insufficient coverage of specialized medical traditions, and this gap can be bridged through supervised fine-tuning rather than continued pre-training.
- Evidence anchors:
  - [abstract]: "AyurParam not only surpasses all open-source instruction-tuned models in its size class (1.5–3B parameters), but also demonstrates competitive or superior performance compared to much larger models"
  - [section 3]: "The resulting corpus contained approximately 4.75M grounded Q&A pairs, distributed as: Q&A pair (EN + HI): ~1.27M pairs; Objective/MCQ: ~0.9M pairs; Multi-turn reasoning: ~1.51M pairs"
  - [corpus]: Related work (Ling et al. 2023, CardioEmbed) supports domain adaptation strategies for specialized medical fields, showing similar patterns in cardiology

### Mechanism 2
- Claim: Human-in-the-loop validation with domain experts reduces hallucination and improves factual grounding.
- Mechanism: Practitioners manually reviewed sampled pages from 10 representative books, identifying over-generalization, implicit assumptions, and unsupported reasoning; this feedback iteratively refined the synthesis policy used by Qwen-3 235B for Q&A generation.
- Core assumption: Expert-identified error patterns can be codified into synthesis constraints, and these constraints generalize across the full dataset.
- Evidence anchors:
  - [abstract]: "rigorous annotation protocols for factual precision and instructional clarity"
  - [section 3.4]: "Experts identified over-generalization, implicit assumptions, and unsupported reasoning, which informed iterative refinements to the synthesis policy. This loop significantly reduced hallucination and improved epistemic fidelity"
  - [corpus]: MedKGEval and related medical LLM work emphasizes clinical validation necessity, though direct evidence for this specific HITL approach in Ayurveda is limited

### Mechanism 3
- Claim: Structured bilingual templates with explicit response markers improve instruction-following across English and Hindi.
- Mechanism: Custom templates using `<user>`, `<assistant>`, and `<actual response>` tags provide clear supervision signals for turn-taking and response boundaries in both languages, reducing ambiguity in multi-turn dialogues.
- Core assumption: Explicit structural markers help the model learn when to respond and what constitutes ground-truth output, particularly important for code-switched or multilingual contexts.
- Evidence anchors:
  - [abstract]: "context-aware, reasoning, and objective-style Q&A in both English and Hindi"
  - [section 4.2]: "we employed custom bilingual templates (English and Hindi)... responses were further enclosed within <actual response> and </actual response>, clearly indicating the ground-truth output"
  - [corpus]: Limited direct corpus evidence for this specific template mechanism in Indic medical domains; related multilingual NLP work (IndicCorp, mC4) supports language-aware training but not this exact format

## Foundational Learning

- Concept: **Supervised Fine-Tuning (SFT) vs. Continued Pre-Training**
  - Why needed here: AyurParam adapts Param-1-2.9B through SFT on labeled Q&A pairs rather than continued pre-training on raw text; understanding this distinction is critical for replication.
  - Quick check question: Why would SFT on 4.75M instruction pairs be preferred over continued pre-training on the 54.5M-word raw corpus for this use case?

- Concept: **Instruction Tuning Alignment**
  - Why needed here: The model uses dialogue-style `<user>`/`<assistant>` markers to learn instruction-following behavior; this differs from standard language modeling objectives.
  - Quick check question: What failure modes might occur if you trained on the same data without explicit instruction-response formatting?

- Concept: **Multilingual Tokenization for Indic Scripts**
  - Why needed here: The vocabulary includes 256k tokens handling Devanagari (Sanskrit, Hindi, Marathi); Hindi performance lag (38.04% vs 41.12%) suggests tokenization or data coverage issues.
  - Quick check question: How might tokenization quality affect performance gaps between English and Hindi in a domain-specialized model?

## Architecture Onboarding

- Component map:
  Base Model (Param-1-2.9B-Instruct) -> Training Framework (Hugging Face TRL) -> Data Pipeline (Taxonomy -> Corpus Collection -> OCR -> Normalization -> Q&A Generation -> Validation) -> Evaluation (BhashaBench-Ayur)

- Critical path:
  1. Taxonomy establishment (Section 3.1) -> ensures balanced domain coverage, prevents over-representation of easily available material
  2. License governance (Section 3.2) -> filters to CC0/CC-BY/public domain only; critical for legal redistribution
  3. OCR quality assurance (Section 3.3) -> confidence scores, Indic-specific heuristics; low-confidence pages flagged for exclusion
  4. Knowledge-grounded synthesis (Section 3.4) -> responses must cite support spans from source passage
  5. SFT training (Section 4.2) -> 3 epochs, lr=5×10⁻⁶, global batch size 1024

- Design tradeoffs:
  - **Size vs. specialization**: 2.9B with domain data competes with 7B-27B general models, but may lack reasoning depth on hard questions (31.21% vs 43.93% on easy)
  - **Automation vs. validation**: LLM-generated Q&A at scale (4.75M) with selective human review (10 books sampled) balances cost vs. quality
  - **Language coverage vs. balance**: English-dominated corpus (50.6%) may explain Hindi performance gap

- Failure signatures:
  - Hindi accuracy (38.04%) trails English (41.12%) -> likely data imbalance or tokenization issues
  - Match-column questions: 24.39% (worst format) vs MCQ: 40.12% (best format) -> structured comparison tasks are weak
  - Hard questions: 31.21% vs Easy: 43.93% -> reasoning-intensive prompts remain challenging
  - Panchakarma & Rasayana and Ayurvedic Literature domains underperform (noted in Section 5)

- First 3 experiments:
  1. **Baseline isolation**: Evaluate Param-1-2.9B-Instruct (base, no Ayurveda fine-tuning) on BhashaBench-Ayur to quantify domain adaptation gains
  2. **Language ablation**: Train English-only and Hindi-only variants on respective subsets to diagnose whether language gap stems from data volume, quality, or tokenization
  3. **Data scaling curve**: Train with 25%, 50%, 75% of the 4.75M dataset (stratified by domain) to identify diminishing returns and optimal data efficiency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does high performance on structured exam-style benchmarks (BhashaBench-Ayur) translate to clinical utility in realistic consultation scenarios?
- Basis in paper: [explicit] The authors acknowledge that their evaluation "relies exclusively on structured exam-style questions" and does not capture "clinical reasoning in realistic consultation scenarios" or "safety and appropriateness of generated advice."
- Why unresolved: No human evaluation by Ayurvedic practitioners was conducted, and no open-ended generation or consultation-style assessment was performed.
- What evidence would resolve it: Systematic human evaluation by Ayurvedic practitioners assessing response quality in simulated clinical consultations, comparing benchmark scores to practitioner ratings.

### Open Question 2
- Question: What data augmentation or architecture interventions can close the Hindi-English performance gap (38.04% vs 41.12%) without sacrificing domain accuracy?
- Basis in paper: [explicit] The paper explicitly notes that "performance in Hindi lagged behind English" and identifies "improved multilingual coverage" as essential for the next phase of research, proposing "targeted data augmentation, improved tokenization strategies, and possibly language-specific fine-tuning."
- Why unresolved: The current training corpus has insufficient Hindi representation, and the paper does not test specific interventions.
- What evidence would resolve it: Ablation studies comparing different multilingual balancing strategies (data augmentation, tokenization changes, language-specific adapters) measuring both accuracy and language parity.

### Open Question 3
- Question: What safety mechanisms and guardrails are necessary and sufficient for deploying domain-specialized medical LLMs like AyurParam in educational or clinical settings?
- Basis in paper: [explicit] The authors state AyurParam "lacks explicit safety mechanisms to prevent generation of inappropriate, unsafe, or potentially harmful medical advice" and call for "disclaimer generation, uncertainty quantification, and refusal mechanisms for out-of-scope queries."
- Why unresolved: No safety layer was implemented or tested; the paper only notes that instruction-tuning reduced prescriptive phrasing but did not eliminate risk.
- What evidence would resolve it: Implementation and red-team evaluation of safety interventions, measuring false refusal rates and harmful advice generation across adversarial and benign queries.

## Limitations

- Evaluation benchmark may be contaminated by training data overlap, potentially inflating performance metrics
- Hindi performance gap (38.04% vs 41.12%) suggests language imbalance or tokenization issues that weren't systematically addressed
- Weak performance on structured comparison tasks (match-column: 24.39%) and specialized domains indicates limitations in certain reasoning patterns

## Confidence

**High Confidence**: Technical implementation details are well-documented and reproducible; observed superiority over comparable-sized models on BhashaBench-Ayur is credible given systematic domain adaptation approach.

**Medium Confidence**: Claims of outperforming much larger models require qualification as performance lags on harder questions and structured reasoning tasks; comparison may not reflect equivalent difficulty levels.

**Low Confidence**: Assertions about practical utility for clinical reference and educational support extend beyond empirical evidence as evaluation focuses on isolated question-answering without assessing real-world usability factors.

## Next Checks

1. **Independent Benchmark Evaluation**: Deploy AyurParam on an external, independently curated Ayurveda benchmark that was not constructed from the training corpus to assess generalization capability.

2. **Ablation Study on Language Components**: Conduct controlled experiments training English-only and Hindi-only variants on respective language subsets, then evaluate both on balanced bilingual test sets to isolate language gap sources.

3. **Clinical Safety and Grounding Analysis**: Implement systematic audit of model outputs on clinical reasoning questions, comparing responses against original source passages to quantify hallucination rates and unsupported inferences.