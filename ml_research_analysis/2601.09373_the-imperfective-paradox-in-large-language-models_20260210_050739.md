---
ver: rpa2
title: The Imperfective Paradox in Large Language Models
arxiv_id: '2601.09373'
source_url: https://arxiv.org/abs/2601.09373
tags:
- group
- bias
- verbs
- aspectual
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "We investigate whether large language models can logically reason\
  \ about the Imperfective Paradox, a linguistic phenomenon where past progressive\
  \ aspect entails event realization for activities (e.g., running \u2192 ran) but\
  \ not for goal-oriented accomplishments (e.g., building \u219B built). To probe\
  \ this, we introduce IMPERFECTIVENLI, a diagnostic NLI dataset constructed using\
  \ a minimal-pair design across four logical conditions (Interrupted/Ambiguous \xD7\
  \ Telic/Atelic), featuring 100 telic and 100 atelic verbs with fine-grained semantic\
  \ annotations (Creation, Consumption, Change of State, Motion to Goal)."
---

# The Imperfective Paradox in Large Language Models

## Quick Facts
- **arXiv ID**: 2601.09373
- **Source URL**: https://arxiv.org/abs/2601.09373
- **Reference count**: 40
- **Primary result**: LLMs exhibit systematic teleological bias in aspectual reasoning, hallucinating completion for telic verbs even when negated

## Executive Summary
This paper investigates whether large language models can logically reason about the Imperfective Paradox, a linguistic phenomenon where past progressive aspect entails event realization for activities but not for goal-oriented accomplishments. The authors introduce IMPERFECTIVENLI, a diagnostic NLI dataset with minimal-pair design across four logical conditions, featuring 100 telic and 100 atelic verbs with fine-grained semantic annotations. Evaluating seven 7-9B open-weight models in zero-shot settings, they uncover a pervasive Teleological Bias: models systematically hallucinate completion for telic verbs, often overriding explicit textual negation.

The study reveals that while model embeddings can distinguish process from result representations, inference is dominated by priors about goal attainment rather than faithful logical reasoning. Prompting interventions like Chain-of-Thought and Counterfactual reduce hallucinated completions but over-correct, causing incorrect rejections of valid entailments for atelic verbs. The research demonstrates that current LLMs lack structural aspectual awareness, operating as probabilistic narrative predictors rather than reliable logical reasoners, with reasoning improving with scale but exhibiting non-linear emergence patterns.

## Method Summary
The authors construct IMPERFECTIVENLI, a diagnostic NLI dataset using minimal-pair design across four logical conditions (Interrupted/Ambiguous Ã— Telic/Atelic). The dataset contains 100 telic and 100 atelic verbs with fine-grained semantic annotations (Creation, Consumption, Change of State, Motion to Goal). Seven 7-9B open-weight models are evaluated in zero-shot settings on this dataset. The study employs representational analyses to examine whether embeddings distinguish process from result, and tests prompting interventions including Chain-of-Thought and Counterfactual approaches to assess their impact on reducing teleological bias.

## Key Results
- Models exhibit systematic teleological bias, hallucinating completion for telic verbs even when textual negation is present
- Embedding analyses show distinct process/result representations, but inference is dominated by goal-attainment priors
- Prompting interventions reduce hallucinated completions but over-correct, incorrectly rejecting valid entailments for atelic verbs
- Aspectual reasoning improves with model scale and exhibits non-linear emergence patterns
- Motion verbs are reasoned about more accurately than creation verbs

## Why This Works (Mechanism)
LLMs exhibit teleological bias in aspectual reasoning because they operate as probabilistic narrative predictors rather than faithful logical reasoners. The models' representations can distinguish process from result states, but inference is dominated by learned priors about goal attainment rather than the actual logical entailment patterns. This suggests that the models have learned strong narrative completions for telic verbs from training data, which override explicit textual information when making inferences.

## Foundational Learning

**Imperfective Paradox**: The linguistic phenomenon where past progressive aspect entails event realization for activities but not for goal-oriented accomplishments. Understanding this is crucial for evaluating aspectual reasoning in LLMs.

**Telic vs Atelic Verbs**: Telic verbs describe goal-oriented actions (e.g., building, creating) while atelic verbs describe ongoing activities without inherent endpoints (e.g., running, walking). This distinction is fundamental to the study's experimental design.

**Minimal-Pair Design**: A methodological approach where items are constructed to differ in only one feature, allowing isolation of specific effects. Used here to create controlled comparisons across logical conditions.

**Chain-of-Thought Prompting**: A technique where models are prompted to explain their reasoning step-by-step before producing an answer. The quick check is whether this intervention reduces hallucinated completions without over-correction.

## Architecture Onboarding

**Component Map**: Input Text -> Embedding Layer -> Transformer Blocks -> Attention Mechanism -> Output Layer -> Prediction

**Critical Path**: The core inference process involves token embeddings flowing through transformer layers, where attention mechanisms combine contextual information to produce the final prediction about entailment.

**Design Tradeoffs**: The study uses zero-shot evaluation to test general reasoning capabilities rather than fine-tuned performance, sacrificing potential accuracy gains for broader generalizability.

**Failure Signatures**: Models consistently hallucinate completion for telic verbs despite explicit negation, and prompting interventions over-correct by rejecting valid atelic entailments.

**First Experiments**:
1. Test negated telic verbs with varied syntactic structures to determine if bias persists across linguistic contexts
2. Evaluate fine-tuned models on IMPERFECTIVENLI to assess whether training reduces teleological bias
3. Extend experiments to multilingual settings to verify whether observed biases are language-specific

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions beyond those addressed through its experimental design and analysis.

## Limitations

- The dataset focuses on English and may not generalize to other languages with different aspectual systems
- Zero-shot evaluation limits understanding of how fine-tuning might alter observed patterns
- The causal mechanism linking distinct process/result embeddings to biased inference remains unclear

## Confidence

**High**: Existence of teleological bias across models for telic verbs
**Medium**: Claim that prompt interventions reduce hallucinated completions
**Low**: Conclusions from scaling analysis given limited model size testing

## Next Checks

1. Test model behavior on negated telic verbs with varied syntactic structures to determine if bias persists across linguistic contexts
2. Evaluate fine-tuned models on IMPERFECTIVENLI to assess whether training reduces teleological bias without introducing over-correction
3. Extend experiments to multilingual settings to verify whether the observed biases are language-specific or reflect general architectural tendencies