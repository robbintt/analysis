---
ver: rpa2
title: 'DarkEQA: Benchmarking Vision-Language Models for Embodied Question Answering
  in Low-Light Indoor Environments'
arxiv_id: '2512.24985'
source_url: https://arxiv.org/abs/2512.24985
tags:
- low-light
- image
- noise
- question
- llie
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DarkEQA addresses the critical need for benchmarking vision-language
  models (VLMs) in low-light conditions, a real-world necessity often overlooked by
  existing EQA benchmarks. The core method involves creating a physics-based low-light
  image synthesis pipeline that models illumination degradation and sensor noise at
  the RAW sensor level, enabling controlled multi-level low-light conditions.
---

# DarkEQA: Benchmarking Vision-Language Models for Embodied Question Answering in Low-Light Indoor Environments

## Quick Facts
- arXiv ID: 2512.24985
- Source URL: https://arxiv.org/abs/2512.24985
- Reference count: 40
- Primary result: VLMs experience significant performance degradation under low-light conditions, with sensor noise further compounding this decline.

## Executive Summary
DarkEQA addresses the critical need for benchmarking vision-language models (VLMs) in low-light conditions, a real-world necessity often overlooked by existing EQA benchmarks. The core method involves creating a physics-based low-light image synthesis pipeline that models illumination degradation and sensor noise at the RAW sensor level, enabling controlled multi-level low-light conditions. This is paired with a deterministic rule-based QA generation process to ensure reproducibility and avoid data contamination. The benchmark evaluates VLMs under these degraded conditions, both with and without low-light image enhancement (LLIE) preprocessing. Primary results show that VLMs experience significant performance degradation under low-light conditions, with sensor noise further compounding this decline.

## Method Summary
DarkEQA creates a physics-based low-light synthesis pipeline that models illumination degradation and sensor noise at the RAW sensor level, paired with deterministic rule-based QA generation. The synthesis pipeline inverts standard ISP operations to recover camera-linear RAW data, then applies EV drop and injects four physically-grounded noise components before re-rendering to sRGB. QA pairs are generated from pre-computed frame statistics using explicit rules that validate conditions before creating questions. The benchmark evaluates VLMs under these degraded conditions, both with and without low-light image enhancement preprocessing, across five question families covering room recognition, object detection, and spatial reasoning.

## Key Results
- VLMs experience significant performance degradation under low-light conditions, with sensor noise further compounding this decline.
- While LLIE preprocessing can improve performance at severe degradation levels (L4-L5), it yields mixed or even negative results at moderate levels.
- The deterministic, rule-based QA generation successfully prevents data contamination and ensures reproducible evaluation.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Physics-based synthesis in RAW space produces realistic low-light degradations that isolate illumination loss from sensor noise effects.
- Mechanism: The pipeline inverts standard ISP operations to recover camera-linear RAW data, then applies EV drop and injects four physically-grounded noise components before re-rendering to sRGB. This preserves noise statistics relative to photon counts rather than post-ISP perceptual curves.
- Core assumption: Real camera sensors follow the described noise formation model with Tukey-λ distributed read noise and row-wise banding artifacts.
- Evidence anchors:
  - [abstract] "visual degradations are modeled in linear RAW space, simulating physics-based illumination drop and sensor noise followed by an ISP-inspired rendering pipeline"
  - [section III-A] "This design enables disentangling the respective impacts of illumination degradation and sensor noise on perceptual performance of VLMs"
- Break condition: If target cameras use significantly different sensor architectures or non-standard ISP pipelines, noise statistics may diverge from modeled distributions.

### Mechanism 2
- Claim: Paired noise-free and noise-injected variants enable attribution of VLM failures to specific degradation sources.
- Mechanism: For each image, the benchmark generates two branches: (1) pure EV drop without noise, and (2) EV drop with physics-motivated noise injection. Comparing VLM performance across these branches at matching illumination levels isolates whether performance loss stems from insufficient signal or noise corruption.
- Core assumption: VLMs process these synthetic degradations similarly to real low-light captures.
- Evidence anchors:
  - [abstract] "DarkEQA isolates the perception bottleneck by evaluating question answering from egocentric observations under controlled degradations, enabling attributable robustness analysis"
  - [section III-A] "This design enables disentangling the respective impacts of illumination degradation and sensor noise on perceptual performance of VLMs"
- Break condition: If VLMs develop different internal representations for synthetic vs real noise patterns, attribution conclusions may not transfer.

### Mechanism 3
- Claim: Deterministic, rule-based QA generation prevents data contamination and ensures reproducible evaluation.
- Mechanism: QA pairs are generated from pre-computed frame statistics using explicit rules that validate conditions before creating questions. No VLM services are used in generation, avoiding circular evaluation where models judge themselves.
- Core assumption: Rule-generated questions adequately cover the perceptual primitives needed for embodied operation.
- Evidence anchors:
  - [section III-B] "all Question Answering (QA) pairs are deterministically generated via rule-based procedure, rather than depending on commodity VLM services"
  - [section III-B] "This approach ensures each question has a single, verifiable answer by filtering ambiguities"
- Break condition: If embodied tasks require perceptual primitives beyond the five defined question families, benchmark coverage will be incomplete.

## Foundational Learning

- Concept: **Image Signal Processing (ISP) Pipeline**
  - Why needed here: The synthesis pipeline requires understanding how cameras transform RAW sensor data to sRGB (demosaicing, white balance, color correction, tone mapping, gamma) to properly invert these operations.
  - Quick check question: Can you explain why noise must be injected in RAW space rather than after gamma correction?

- Concept: **Sensor Noise Physics**
  - Why needed here: The benchmark models four distinct noise types with different statistical properties (Poisson shot noise, Tukey-λ read noise, row-correlated pattern noise, uniform quantization noise).
  - Quick check question: Why does shot noise follow a Poisson distribution while read noise is better modeled with a heavy-tailed distribution?

- Concept: **Multiple-Choice Evaluation Protocol**
  - Why needed here: Constrained answer spaces enable exact-match scoring and avoid free-form generation ambiguities when measuring degradation effects.
  - Quick check question: What are the tradeoffs between multiple-choice and open-ended evaluation for diagnosing VLM perception failures?

## Architecture Onboarding

- Component map: Unprocessing Module (sRGB → Bayer RAW) -> Noise Injection Module (shot → read → row → quantization) -> EV Drop Module (2^(-ΔEV) scaling) -> QA Generation Engine (rule-based extraction) -> Evaluation Harness (multiple-choice scoring)
- Critical path: Unprocessing quality determines noise realism → noise statistics control degradation severity → EV drop + noise combination defines L1-L5 levels → VLM processes degraded image → accuracy drop relative to L0 measures robustness
- Design tradeoffs: Synthetic vs real low-light enables paired analysis but risks sim-to-real gap; rule-based vs VLM-generated QA avoids contamination but may miss edge cases; multiple-choice vs open-ended provides clean metrics but constrains failure mode visibility
- Failure signatures: Accuracy below blind-LLM baseline indicates VLM extracts negative value from degraded visual input; LLIE preprocessing reducing accuracy at moderate levels suggests enhancement introduces artifacts; sharp accuracy cliff between adjacent levels indicates hard threshold in VLM perception
- First 3 experiments:
  1. Baseline characterization: Run all VLMs on L0 (clean) images to establish upper bounds; verify blind-LLM baseline is consistently below VLM performance.
  2. Degradation sweep: Evaluate one mid-scale VLM across all L1-L5 levels with noise-free vs noise-injected variants to isolate noise contribution.
  3. LLIE diagnostic: Apply DarkIR preprocessing to L4-L5 images, compare VLM accuracy with/without enhancement; inspect enhanced images for artifacts at levels where performance decreases.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific mechanisms cause Low-Light Image Enhancement (LLIE) preprocessing to degrade VLM performance at moderate degradation levels (L1-L3) while improving it at severe levels (L4-L5)?
- Basis in paper: [explicit] The authors state that "a detailed causal analysis of these failures remains a valuable direction for future research," specifically regarding the observation that LLIE yields "unstable behavior" and performance decreases at moderate levels.
- Why unresolved: The paper quantifies the performance drop but does not isolate whether the failure is due to the introduction of enhancement artifacts, loss of semantic edges, or shifts in data distribution that conflict with VLM pre-training.
- What evidence would resolve it: A component-wise analysis of LLIE outputs (e.g., frequency domain analysis) correlated with VLM attention maps, or the development of an enhancement model optimized for VLM feature preservation rather than human perception.

### Open Question 2
- Question: To what extent does performance on the synthetic DarkEQA benchmark predict success in physical real-world low-light environments?
- Basis in paper: [explicit] The conclusion acknowledges that "mitigating a potential real-to-sim gap presents another important avenue for subsequent work," noting that the synthetic approach is a practical choice driven by limitations.
- Why unresolved: While the synthesis is physics-based, the pipeline operates on rendered images (HM3D-Sem) which may lack the complex light scattering, lens flares, or diverse sensor responses found in physical cameras during actual robotic deployment.
- What evidence would resolve it: A comparative study evaluating the same VLM agents on DarkEQA versus a newly collected dataset of real-world robot navigation sequences captured under equivalent low-light conditions.

### Open Question 3
- Question: How can VLMs be modified to prioritize semantic features that are robust to color distortion in near-dark conditions, similar to the luminance-dependence of human night vision?
- Basis in paper: [inferred] The paper notes that VLMs perform worse than blind LLMs on "Object Attribute - Color" at severe levels (L5) and draws an analogy to human rod cells functioning better than cone cells in the dark.
- Why unresolved: It is unclear if current VLMs fail because they attempt to interpret color noise as signal, or if the loss of color information fundamentally breaks their internal reasoning processes.
- What evidence would resolve it: Ablation studies on VLM inputs using grayscale-only or luminance-channel-only versions of the L4/L5 datasets to determine if removing color noise improves reasoning accuracy.

## Limitations

- Performance attribution claims lack direct validation that synthetic degradations match real low-light sensor behavior.
- The five question families may not comprehensively cover all perceptual primitives needed for embodied tasks.
- LLIE preprocessing shows unstable behavior at moderate degradation levels, potentially introducing enhancement artifacts not accounted for in the analysis.

## Confidence

- **High** confidence in deterministic QA generation mechanism for avoiding data contamination.
- **Medium** confidence in attribution claims linking performance drops to specific degradation sources.
- **Low** confidence that current benchmark comprehensively covers embodied task requirements.

## Next Checks

1. **Noise Model Validation**: Generate side-by-side comparisons of synthetic low-light images versus real camera captures under identical EV conditions. Measure perceptual similarity and noise distribution statistics to confirm the physics-based model accurately reproduces real sensor behavior.

2. **Sim-to-Real Transfer Test**: Evaluate VLMs on real low-light images from HM3D-Sem validation scenes and compare performance degradation patterns against synthetic results. This would validate whether attribution conclusions hold beyond the synthetic domain.

3. **QA Coverage Analysis**: Conduct an ablation study where each question family is removed individually, then measure impact on overall accuracy across degradation levels. This would reveal whether any critical perceptual capabilities are inadequately represented in the current benchmark design.