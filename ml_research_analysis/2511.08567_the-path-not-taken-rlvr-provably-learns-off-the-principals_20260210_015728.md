---
ver: rpa2
title: 'The Path Not Taken: RLVR Provably Learns Off the Principals'
arxiv_id: '2511.08567'
source_url: https://arxiv.org/abs/2511.08567
tags:
- arxiv
- rlvr
- optimization
- update
- principal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work investigates why Reinforcement Learning with Verifiable
  Rewards (RLVR) produces sparse parameter updates despite substantial performance
  gains. The authors reveal that sparsity is a superficial artifact of a deeper, model-conditioned
  optimization bias: RLVR consistently updates a narrow, stable subset of parameters
  across runs, datasets, and algorithms.'
---

# The Path Not Taken: RLVR Provably Learns Off the Principals

## Quick Facts
- arXiv ID: 2511.08567
- Source URL: https://arxiv.org/abs/2511.08567
- Reference count: 40
- Primary result: RLVR exhibits sparse, model-conditioned updates that preserve spectral structure by learning off principal parameter directions, unlike SFT

## Executive Summary
This work reveals that Reinforcement Learning with Verifiable Rewards (RLVR) produces sparse parameter updates not merely as a computational artifact but as a manifestation of deeper geometric bias. Through the Three-Gate Theory, the authors show RLVR consistently updates a narrow, stable subset of parameters across runs, datasets, and algorithms. This bias stems from the interplay of KL constraints, pretrained model geometry, and precision, steering updates away from principal directions into low-curvature subspaces. Empirically, RLVR preserves spectral structure while SFT distorts it, challenging the transfer of SFT-era parameter-efficient methods to RLVR contexts.

## Method Summary
The authors validate their Three-Gate Theory through controlled experiments comparing RLVR and SFT on pretrained models (DeepSeek-R1-Distill-Qwen-1.5B, Qwen2.5-Math-7B, Llama-3.2-3B) across math and code domains. Using VeRL with DAPO and bf16 precision, they measure bf16-aware sparsity, compute Jaccard overlap and consensus ratios across runs, analyze spectral preservation via SVD, and quantify update-principal overlap. The study contrasts RLVR's off-principal optimization with SFT's principal-targeting behavior, revealing distinct optimization regimes.

## Key Results
- RLVR updates a sparse, model-conditioned subset of parameters consistently across runs, datasets, and algorithms
- RLVR preserves spectral structure and learns off principal directions, while SFT distorts spectra and targets principal weights
- The Three-Gate Theory explains how KL constraints, pretrained geometry, and precision interact to bias updates into low-curvature subspaces

## Why This Works (Mechanism)
The Three-Gate Theory posits that KL constraints, pretrained model geometry, and precision interact to create an optimization bias in RLVR. KL clipping prevents large deviations from pretrained distributions, pushing updates toward low-curvature, spectrum-preserving directions. Pretrained geometry provides stable parameter subspaces that RLVR exploits, while bf16 precision limits update magnitudes, further constraining the optimization path. This combination steers RLVR away from principal directions (where curvature is high) and toward stable, sparse update patterns that preserve overall spectral structure.

## Foundational Learning
- **bf16-aware sparsity**: Critical for correctly quantifying parameter updates in low-precision training; check by comparing absolute vs relative tolerance methods
- **Spectral preservation**: Understanding how SVD-based analysis captures parameter update geometry; verify by comparing pre/post-spectrum drift
- **Principal angle analysis**: Measures subspace rotation between update directions and principal components; validate by computing top-k angles
- **Consensus ratio**: Quantifies agreement in update patterns across runs; test by computing heatmap row/column stripes in Q/K/V/O and MLP layers
- **KL clipping impact**: Controls optimization path by limiting distribution shift; assess by comparing token-wise KL curves with/without clipping
- **Model-conditioned locality**: Update patterns depend on pretrained architecture; verify by testing across different model families

## Architecture Onboarding
**Component Map**: VeRL (v4.0) -> DAPO -> bf16 parameters -> AdamW optimizer -> Spectral analysis pipeline

**Critical Path**: DAPO with KL clipping → bf16-aware update detection → Spectral preservation analysis → Update-principal overlap quantification

**Design Tradeoffs**: bf16 precision enables computational efficiency but may mask subtle update patterns; KL clipping stabilizes training but biases optimization; spectral analysis provides geometric insight but may miss non-linear deformations

**Failure Signatures**: Unbounded KL growth indicates misconfigured clipping; PiSSA collapse at high LR shows instability along principal directions; wrong sparsity quantification yields false positives/negatives

**First Experiments**:
1. Implement bf16-aware unchanged-weight probe (η=1e-3 relative) to compute sparsity_bf16 and extract per-layer update masks
2. Compute pairwise Jaccard of update masks and consensus-ratio heatmaps to verify model-conditioned locality
3. Run spectral analysis—layerwise SVD pre/post—to measure principal angles and normalized spectrum drift

## Open Questions the Paper Calls Out
None

## Limitations
- Results primarily validated on math/code domains with verifiable rewards; generalizability to open-ended tasks remains unproven
- Spectral preservation claims rely on SVD analysis that may not capture full non-linear geometric deformations
- bf16-only analysis excludes float32 pretraining regimes where numerical behavior may differ

## Confidence
**High Confidence**: Empirical observation of sparse, model-conditioned update patterns across multiple runs and architectures; robust spectral preservation results distinguishable from SFT behavior

**Medium Confidence**: Theoretical mechanism linking KL constraints, pretrained geometry, and precision to off-principal optimization bias; requires further validation for exact causal pathway

**Low Confidence**: Claims about RLVR's optimization landscape being fundamentally different from SFT; comparison limited to observable metrics without direct landscape characterization

## Next Checks
1. Apply analysis framework to open-ended RLVR tasks (chat, creative writing) where rewards are not easily verifiable
2. Systematically test proposed interventions (orthogonal V/O rotations, head permutations) to measure quantitative impact on sparsity and performance
3. Compute and compare Hessian spectra and mode connectivity between RLVR and SFT fine-tuned models to directly assess optimization landscape differences