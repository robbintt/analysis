---
ver: rpa2
title: 'GRACE: Discriminator-Guided Chain-of-Thought Reasoning'
arxiv_id: '2305.14934'
source_url: https://arxiv.org/abs/2305.14934
tags:
- coin
- ball
- claire
- alice
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GRACE, a discriminator-guided chain-of-thought
  reasoning approach that addresses the problem of language models assigning high
  likelihood to incorrect reasoning steps in multi-step problems. GRACE employs a
  step-level discriminator trained via contrastive learning on automatically aligned
  correct and incorrect steps, which is then used during decoding to score candidate
  next steps for correctness.
---

# GRACE: Discriminator-Guided Chain-of-Thought Reasoning

## Quick Facts
- arXiv ID: 2305.14934
- Source URL: https://arxiv.org/abs/2305.14934
- Authors: Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, Lu Wang
- Reference count: 40
- Introduces discriminator-guided CoT reasoning that improves accuracy across 6 benchmarks by 3.3-30.9% absolute

## Executive Summary
GRACE addresses a fundamental limitation of chain-of-thought reasoning where language models can assign high likelihood to incorrect reasoning steps. The approach introduces a discriminator-guided decoding mechanism that uses contrastive learning to train a step-level discriminator capable of distinguishing correct from incorrect reasoning steps. This discriminator is then used during decoding to score candidate next steps, guiding the model toward more accurate reasoning paths. The method achieves significant improvements in final answer accuracy across multiple reasoning benchmarks while being sample-efficient compared to baseline approaches.

## Method Summary
GRACE trains a discriminator via contrastive learning using automatically aligned correct and incorrect reasoning steps. The discriminator learns to distinguish between valid and invalid intermediate reasoning steps. During decoding, GRACE scores candidate next steps using the discriminator's confidence rather than relying solely on likelihood. This allows the model to select reasoning steps that are both likely and correct. The approach can be combined with self-consistency and works with both fine-tuned FLAN-T5 and few-shot prompted LLaMA models. Human and LLM evaluations demonstrate that GRACE not only improves final answer accuracy but also reduces solution error rates by 44% on GSM8K.

## Key Results
- Achieves 3.3-30.9% absolute accuracy improvements across six reasoning benchmarks (GSM8K, MathQA-Gain, SVAMP, MultiArith, Coin Flip, Tracking Shuffled Objects)
- When combined with self-consistency, reaches up to 15.7% absolute improvements over vanilla self-consistency
- Reduces solution error rates from 9.0% to 5.0% (44% reduction) on GSM8K based on human and LLM evaluation
- Demonstrates sample efficiency, requiring fewer samples than vanilla self-consistency to achieve better performance

## Why This Works (Mechanism)
The discriminator-guided approach works by addressing the core problem that language models can generate high-likelihood but incorrect reasoning steps. By training a discriminator to recognize correct versus incorrect steps through contrastive learning on automatically generated data, GRACE provides a separate signal during decoding that evaluates the correctness of reasoning steps rather than just their likelihood. This dual-signal approach (likelihood + correctness) guides the model toward reasoning paths that are both probable and valid, effectively filtering out plausible but erroneous intermediate steps that would lead to incorrect final answers.

## Foundational Learning
- **Contrastive learning**: Needed to train the discriminator to distinguish correct from incorrect reasoning steps; quick check: verify the discriminator achieves high accuracy on the contrastive training task
- **Chain-of-thought reasoning**: Required as the baseline approach that GRACE improves upon; quick check: ensure baseline CoT achieves reasonable performance on target benchmarks
- **Discriminator-guided decoding**: Essential for incorporating correctness signals during generation; quick check: validate that discriminator scores correlate with actual step correctness
- **Self-consistency ensemble**: Important baseline for comparison and potential combination; quick check: confirm self-consistency provides consistent accuracy improvements
- **Automatic data alignment**: Critical for creating training data without manual annotation; quick check: verify that automatically generated incorrect steps are indeed incorrect and diverse

## Architecture Onboarding

**Component Map**: Input -> Base Model (FLAN-T5/LLaMA) -> Discriminator -> Scoring Function -> Output

**Critical Path**: Input → Base Model → Discriminator → Scoring → Output

**Design Tradeoffs**: 
- Uses likelihood-based scoring versus correctness-based scoring
- Balances between exploration (sampling diverse paths) and exploitation (following discriminator guidance)
- Requires training an additional discriminator versus using only the base model

**Failure Signatures**: 
- Discriminator may fail to detect certain types of reasoning errors
- Incorrectly generated reasoning steps may still receive high discriminator scores
- The approach may not generalize well to reasoning tasks outside the mathematical domain

**First 3 Experiments**:
1. Evaluate discriminator accuracy on distinguishing correct vs incorrect reasoning steps on held-out data
2. Compare GRACE's performance against vanilla CoT and self-consistency on a single benchmark
3. Analyze sample efficiency by measuring accuracy improvements as a function of the number of samples generated

## Open Questions the Paper Calls Out
None

## Limitations
- The approach relies on automatically generated incorrect steps for training, which may not capture the full diversity of human reasoning errors
- Performance gains vary significantly across benchmarks (3.3% to 30.9% absolute improvement), suggesting effectiveness may depend on problem type or difficulty
- The method's generalizability to non-mathematical reasoning tasks remains untested

## Confidence
- **High confidence**: The discriminator architecture and contrastive training methodology are sound and well-implemented
- **Medium confidence**: The relative improvements over baseline methods are reliable, though absolute gains vary by benchmark
- **Medium confidence**: The sample efficiency claims are supported by the experiments, but real-world efficiency gains may be more modest

## Next Checks
1. Conduct ablation studies removing the discriminator guidance to quantify the exact contribution of this component versus other factors like increased sampling
2. Test the approach on reasoning tasks outside the mathematical domain to assess generalizability to different reasoning types
3. Perform error analysis on discriminator failures to understand which types of reasoning errors the model struggles to detect