---
ver: rpa2
title: 'Rethinking deep learning: linear regression remains a key benchmark in predicting
  terrestrial water storage'
arxiv_id: '2510.10799'
source_url: https://arxiv.org/abs/2510.10799
tags:
- linear
- data
- single
- lstm
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compares deep learning models (LSTM and Temporal Fusion
  Transformer) with traditional statistical models for predicting terrestrial water
  storage (TWS) at basin scale. Using the HydroGlobe dataset, which includes both
  baseline model simulations and data-assimilated versions incorporating satellite
  observations, the research demonstrates that a simple linear regression model outperforms
  more complex deep learning approaches.
---

# Rethinking deep learning: linear regression remains a key benchmark in predicting terrestrial water storage

## Quick Facts
- arXiv ID: 2510.10799
- Source URL: https://arxiv.org/abs/2510.10799
- Reference count: 0
- Linear regression outperforms LSTM and TFT for basin-scale TWS prediction

## Executive Summary
This study compares deep learning models (LSTM and Temporal Fusion Transformer) with traditional statistical models for predicting terrestrial water storage (TWS) at basin scale. Using the HydroGlobe dataset, which includes both baseline model simulations and data-assimilated versions incorporating satellite observations, the research demonstrates that a simple linear regression model outperforms more complex deep learning approaches. The linear model, particularly when trained separately for each basin, achieved the best performance across multiple evaluation metrics including Nash-Sutcliffe efficiency and Kling-Gupta efficiency. The study reveals that the effectiveness of deep learning models is limited by dataset heterogeneity and nonstationary patterns in TWS, which are better captured by simpler models incorporating explicit trend features.

## Method Summary
The study evaluates linear regression, LSTM, and Temporal Fusion Transformer models for predicting basin-averaged TWS using HydroGlobe dataset. Linear_single trains separate models per basin with 60 features including lagged inputs, monthly dummies, and trend index. DL models are trained globally with standardized inputs. Models are evaluated on 2016-2020 test period using NSE, KGE, correlation, RMSE, and bias metrics. Hyperparameters are optimized via Optuna with early stopping.

## Key Results
- Linear_single achieved highest average NSE (0.63) and KGE (0.79) across all basins
- Linear_glob underperformed due to coefficient heterogeneity across basins
- Removing time_idx from TFT caused substantial performance degradation in trend-heavy basins
- Longer sequence lengths did not improve LSTM or TFT performance due to concentration of temporal importance on recent timesteps

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Basin-specific linear models outperform globally-trained deep learning models for TWS prediction when feature-target relationships exhibit high spatial heterogeneity.
- Mechanism: Linear_single explicitly models basin-specific coefficients, allowing each basin's unique hydrological characteristics to be captured independently. When coefficients vary substantially across basins (as shown in the coefficient distribution analysis), pooling data globally forces a single set of parameters to fit heterogeneous distributions, introducing systematic bias that outweighs variance reduction from larger training sets.
- Core assumption: The feature-target relationship at basin scale is predominantly linear or can be adequately approximated by linear combinations with seasonal and trend components.
- Evidence anchors:
  - [abstract] "a simple linear regression model outperforms more complex deep learning approaches... particularly when trained separately for each basin"
  - [section 3.2] "the learned coefficients from Linear_single exhibit a widespread distribution across basins, suggesting that feature-target relationships vary significantly... a single set of coefficients learned by Linear_glob introduces the presence of a large bias for individual basins"
- Break condition: If basin characteristics were more homogeneous, or if nonlinear interactions dominated TWS dynamics, global models with shared representations would gain advantage.

### Mechanism 2
- Claim: TFT's ability to capture nonstationarity in TWS depends primarily on explicit global time index embeddings rather than the self-attention mechanism alone.
- Mechanism: The self-attention mechanism is permutation-invariant and does not inherently encode temporal ordering. TFT compensates through learned time embeddings that provide absolute temporal context. Removing this embedding causes substantial performance degradation in basins with strong depletion trends, as the model loses its primary mechanism for tracking long-term distributional shifts.
- Core assumption: Nonstationarity in TWS manifests predominantly as monotonic or smooth trend-like shifts that can be encoded through positional embeddings.
- Evidence anchors:
  - [abstract] "nonstationary patterns in TWS, [are] better captured by simpler models incorporating explicit trend features"
  - [section 3.5] "removing the time_idx feature... leads to a substantial degradation in TFT's performance, particularly in bias, RMSE, and KGE... the primary mechanism allowing TFT to capture nonstationarity is not its self-attention mechanism but rather the explicit encoding of time via global embeddings"
- Break condition: If nonstationarity involved abrupt regime shifts or complex nonlinear dynamics rather than smooth trends, both time embeddings and linear trend terms would be insufficient.

### Mechanism 3
- Claim: Increasing input sequence length does not systematically improve LSTM or TFT performance when recent timesteps dominate predictive contributions.
- Mechanism: SHAP analysis reveals that LSTM assigns highest importance to the most recent time steps regardless of sequence length, with distant past contributing minimally. TFT's attention patterns shift inconsistently across sequence lengths, failing to establish stable temporal dependency structures. Without autoregressive target information, extended histories provide diminishing returns.
- Core assumption: Hydrological memory effects in TWS are adequately captured by the most recent 6-12 months of meteorological and land surface inputs.
- Evidence anchors:
  - [section 3.3] "more recent time steps contribute the most to predictions, particularly the closest time step... the contribution from these distant steps remains considerably lower"
  - [section 3.3] "TFT's attention patterns vary substantially with sequence length... This observed inconsistency in attention distribution... likely explains why TFT does not show improved performance with longer sequence input"
- Break condition: If critical hydrological memory extended beyond 12-18 months with structured dependencies (e.g., multi-year drought legacies), longer sequences would become advantageous.

## Foundational Learning

- Concept: **Bias-variance tradeoff with heterogeneous data**
  - Why needed here: Understanding why global models fail despite more data requires recognizing that pooled heterogeneous data increases bias faster than it reduces variance.
  - Quick check question: If you trained a model on data from 100 basins with coefficient distributions spanning Â±2 standard deviations, would you expect a single global model to outperform basin-specific models?

- Concept: **Nonstationarity and distribution shift**
  - Why needed here: TWS prediction faces temporal distribution shifts where training and test periods have different statistical properties, affecting model generalization.
  - Quick check question: A model trained on 2003-2015 TWS data is tested on 2016-2020 data in a basin showing accelerating depletion. What type of failure mode should you anticipate?

- Concept: **Permutation invariance in Transformers**
  - Why needed here: Standard self-attention treats input positions symmetrically, requiring explicit positional or temporal encoding to capture sequence order.
  - Quick check question: If you shuffle the order of timesteps in an input sequence to a vanilla Transformer without positional encoding, should the output change?

## Architecture Onboarding

- Component map:
  Linear_single: Per-basin linear regression with lagged features (48), monthly dummies (11), and trend index (1) = 60 total features
  LSTM: Single-layer with hidden size optimized per dataset (64-512), processes time-varying + static inputs globally
  TFT: Hybrid architecture combining LSTM blocks with multi-head attention (4-5 heads), accepts static and time-varying covariates
  Target: Monthly basin-averaged TWS from HydroGlobe (OL or DA versions)

- Critical path:
  1. Data preparation: Standardize each basin's features using training period statistics only
  2. For Linear_single: Fit separate regression per basin with explicit trend and seasonal features
  3. For DL models: Pool globally standardized data, train with early stopping on validation loss (patience=10 epochs)
  4. Evaluate on 2016-2020 test period using NSE, KGE, correlation, RMSE, bias

- Design tradeoffs:
  - Basin-specific vs global training: Basin-specific handles heterogeneity but forfeits data synergy; global enables transfer learning but introduces bias
  - Explicit trend features vs learned temporal embeddings: Linear trend is interpretable and robust to smooth shifts; learned embeddings may capture complex patterns but lack guarantees
  - Sequence length selection: Longer sequences theoretically capture extended memory but risk overfitting and show empirically diminishing returns

- Failure signatures:
  - Strong negative NSE values in basins with significant trends: Model failing to capture nonstationarity
  - Large performance gap between OL and DA datasets: Model struggles with human-intervention dynamics
  - Attention/feature importance concentrated only on recent steps: Model not leveraging extended temporal context

- First 3 experiments:
  1. Replicate Linear_single vs Linear_glob comparison on a subset of basins to confirm coefficient heterogeneity; plot coefficient distributions across basins for key features (precipitation, temperature).
  2. Ablate the global time index embedding in TFT and evaluate on basins with significant depletion trends (DA dataset); quantify bias and KGE degradation.
  3. Test Linear_single on a basin with known nonlinear human intervention (e.g., irrigation-driven depletion with threshold effects) to probe where linear assumptions break down; compare against tree-based models.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can specific deep learning architectures or adaptive learning frameworks be developed to outperform linear models in nonstationary hydrological environments without relying on explicit trend features?
- Basis in paper: [Explicit] Section 3.5 and the Conclusion state that future work should explore how architecture choices and adaptive frameworks can enhance robustness in dynamically evolving systems, noting that linear trend assumptions may fail under complex shifts.
- Why unresolved: The study found that TFT relies on time embeddings rather than internal mechanisms to handle nonstationarity, and it still underperformed compared to the explicit linear trend in the benchmark.
- What evidence would resolve it: A DL architecture designed for distributional shifts that outperforms Linear_single on the nonstationary Data Assimilation (DA) dataset without manual trend inputs.

### Open Question 2
- Question: To what degree is the performance gap between linear and deep learning models attributable to the absence of explicit features regarding human interventions, such as irrigation withdrawal?
- Basis in paper: [Explicit] The Discussion notes that model performance may be constrained by available input features, specifically citing the lack of time-varying data on human activity like groundwater pumping.
- Why unresolved: The current feature set (climate, soil moisture) captures human impacts only indirectly, potentially limiting the DL models' ability to utilize their nonlinear modeling capacity.
- What evidence would resolve it: Re-running the experiments with datasets that include explicit anthropogenic features (e.g., reservoir operations, irrigation) to see if DL models gain a performance advantage.

### Open Question 3
- Question: Can a globally pre-trained Temporal Fusion Transformer (TFT) serve as a foundation model that, when fine-tuned, outperforms linear benchmarks in data-scarce basins?
- Basis in paper: [Explicit] Section 3.1 identifies TFT as a potential candidate for a foundation model, suggesting it could be fine-tuned for specific basins or data-scarce regions to reduce data requirements.
- Why unresolved: While TFT showed competitive global performance, the study did not explicitly test the transfer learning capabilities of a pre-trained model against the basin-specific linear benchmark.
- What evidence would resolve it: A transfer learning experiment where a globally trained TFT is fine-tuned on small subsets of basin data and achieves higher NSE/KGE than the Linear_single benchmark.

## Limitations
- Conclusions depend heavily on HydroGlobe dataset structure and basin-level aggregation
- Limited exploration of hyperparameter tuning for DL models may leave performance gains unrealized
- Absence of comparisons to more advanced nonlinear statistical methods leaves open questions about linear model's success

## Confidence

- **High confidence**: Linear models outperform global DL models when feature-target relationships exhibit high spatial heterogeneity; explicit temporal trend features are critical for capturing nonstationarity in TWS.
- **Medium confidence**: Basin-specific linear regression with explicit trend features is generally preferable to complex DL for TWS prediction at basin scale; longer sequence lengths do not improve DL performance due to concentration of temporal importance on recent timesteps.
- **Low confidence**: The specific architecture and hyperparameters of LSTM/TFT are optimal for this task; similar results would hold for all hydrological prediction problems or different basin scales.

## Next Checks

1. Test Linear_single against GAM or gradient-boosted trees on basins with known nonlinear human intervention (e.g., irrigation thresholds) to identify where linear assumptions break down.
2. Evaluate model performance when aggregating from basin to larger hydrologic units (e.g., major river basins) to assess sensitivity to spatial scale.
3. Implement an ablation study removing explicit trend features from Linear_single and time_idx from TFT on the DA dataset to quantify the specific contribution of nonstationarity handling.