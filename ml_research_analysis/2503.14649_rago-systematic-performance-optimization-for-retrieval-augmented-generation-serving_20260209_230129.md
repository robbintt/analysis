---
ver: rpa2
title: 'RAGO: Systematic Performance Optimization for Retrieval-Augmented Generation
  Serving'
arxiv_id: '2503.14649'
source_url: https://arxiv.org/abs/2503.14649
tags:
- retrieval
- arxiv
- performance
- batch
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "RAGO introduces RAGSchema, a structured abstraction that captures\
  \ performance-relevant attributes of RAG workloads, and proposes a systematic optimization\
  \ framework to address the challenges of RAG serving. By analyzing representative\
  \ RAG paradigms, RAGO identifies key system design decisions and explores scheduling\
  \ policies\u2014including task placement, resource allocation, and batching\u2014\
  to optimize performance."
---

# RAGO: Systematic Performance Optimization for Retrieval-Augmented Generation Serving

## Quick Facts
- arXiv ID: 2503.14649
- Source URL: https://arxiv.org/abs/2503.14649
- Reference count: 40
- Primary result: RAGO achieves up to 2x QPS/chip and 55% TTFT reduction through systematic RAG serving optimization

## Executive Summary
RAGO introduces RAGSchema, a structured abstraction for representing diverse RAG workloads, and develops a systematic optimization framework to enhance RAG serving performance. The framework addresses key challenges in RAG serving by analyzing representative RAG paradigms and exploring scheduling policies including task placement, resource allocation, and batching strategies. Through analytical modeling and exhaustive search, RAGO identifies optimal configurations that significantly outperform systems built by extending LLM-only serving infrastructure.

## Method Summary
RAGO's methodology centers on three core components: RAGSchema abstraction for representing RAG pipelines, analytical cost modeling using roofline analysis to predict component performance, and an exhaustive scheduler that explores placement, allocation, and batching configurations. The framework profiles each RAG component independently under varying resources and batch sizes, then uses this data to identify bottlenecks and generate Pareto-optimal scheduling decisions. The optimization process balances tradeoffs between latency (TTFT, TPOT) and throughput (QPS/chip) while accounting for the unique characteristics of RAG workloads including iterative retrieval and heterogeneous component requirements.

## Key Results
- Achieves up to 2x increase in QPS/chip compared to LLM-only system extensions
- Reduces time-to-first-token latency by up to 55% through optimized scheduling
- Hybrid collocation strategy outperforms both fully collocated and fully disaggregated approaches by up to 1.5x in QPS/chip

## Why This Works (Mechanism)

### Mechanism 1: RAGSchema Abstraction
RAGSchema enables systematic performance optimization by abstracting heterogeneous RAG workloads into a structured representation that captures pipeline specification and configuration parameters. This abstraction allows consistent evaluation of scheduling policies across diverse RAG algorithms. The core assumption is that performance-relevant attributes can be captured without modeling quality differences between same-sized models or databases. This approach is validated by its ability to represent a wide range of RAG paradigms and enable systematic optimization, though it may require extension for non-pipeline parallelism.

### Mechanism 2: Bottleneck Identification via Cost Modeling
RAGO uses analytical cost modeling with roofline analysis to identify bottlenecks and enable targeted scheduling decisions. By profiling each RAG component independently and using operator latency = max(compute_time, memory_time), the framework identifies which stage limits throughput. This mechanism assumes calibrated simulators accurately reflect production hardware behavior. Evidence shows retrieval often dominates in hyperscale scenarios, and encoding/prefix stages can become bottlenecks for long-context workloads. The approach aligns with related work addressing prefill bottlenecks through caching.

### Mechanism 3: Hybrid Placement Strategy
Hybrid collocation-disaggregation task placement outperforms fully disaggregated or fully collocated designs by allowing time-multiplexing of similar computational components while keeping memory-bound operations disaggregated. This mechanism assumes time-multiplexing overhead is negligible compared to stage execution time. The framework searches placement combinations to find Pareto-optimal configurations, with evidence showing hybrid approaches achieve up to 1.5× improvement in QPS/chip. However, components with highly variable latencies may introduce unmodeled delays.

## Foundational Learning

- **LLM Serving Stages (Prefix vs. Decode)**: RAGO's scheduling depends on understanding that prefix is compute-bound (processes entire input) while decode is memory-bound (auto-regressive, KV cache access). Quick check: Given a 70B model with 512-token prefix and 256-token generation, which stage dominates total FLOPs?

- **Approximate Nearest Neighbor (ANN) Search**: Retrieval bottleneck analysis requires understanding IVF-PQ algorithm behavior and scan percentage tradeoffs. Quick check: Why does scanning 0.1% vs 1% of database vectors affect retrieval time but not proportionally (due to memory bandwidth saturation)?

- **Roofline Model**: RAGO's cost model uses roofline analysis (latency = max(compute, memory)) to predict component performance. Quick check: For an operator with 10 GFLOPs and 20 GB data transfer on hardware with 100 GFLOPS compute and 50 GB/s bandwidth, is it compute-bound or memory-bound?

## Architecture Onboarding

- **Component map**: RAGSchema Parser -> Performance Profiler -> Schedule Generator -> Pareto Analyzer -> Cost Model Engine
- **Critical path**: RAGSchema → Performance profiling per stage → Schedule generation → End-to-end evaluation → Pareto frontier selection
- **Design tradeoffs**: Latency vs throughput (small batches minimize TTFT, large batches maximize QPS); collocation vs disaggregation (reduces fragmentation but complicates scheduling); retrieval quality vs performance (higher scan percentage improves recall but increases retrieval time)
- **Failure signatures**: QPS plateaus despite adding XPUs (bottleneck shifted to retrieval); TTFT spikes with burst requests (batch size misconfiguration causing pipeline stalls); decode idleness during iterative retrieval (iterative batch size too large relative to decode batch)
- **First 3 experiments**: 1) Baseline characterization on Case I (hyperscale) to verify retrieval dominance; 2) Placement sensitivity comparison on Case IV (rewriter+reranker) to reproduce 1.5× QPS/Chip improvement; 3) Batch size tuning on Case II (long-context 1M tokens) to find optimal encode batch size

## Open Questions the Paper Calls Out
None

## Limitations
- Analytical modeling may not capture all real-world effects across different hardware platforms
- RAGSchema abstraction may not fully represent emerging RAG paradigms with non-standard pipeline structures
- Exhaustive search approach becomes computationally expensive for larger configuration spaces

## Confidence

- **High confidence**: RAGSchema provides useful abstraction for representing RAG workloads; analytical cost modeling effectively identifies bottlenecks; hybrid collocation strategies outperform extremes in tested scenarios
- **Medium confidence**: Specific numerical improvements depend on particular hardware configurations and workload mix; generalizability to different RAG architectures and hardware platforms requires validation
- **Low confidence**: Exhaustive search methodology scales efficiently to larger configuration spaces; cost model calibration methodology is robust across different hardware generations

## Next Checks

1. **Hardware generalization test**: Validate RAGO's performance predictions and scheduling recommendations on a different hardware platform (e.g., NVIDIA GPUs instead of XPUs) using the same RAG workloads and configurations.

2. **Architecture extension validation**: Apply RAGSchema and the optimization framework to a non-standard RAG paradigm (e.g., RAG with agent-based retrieval or tree-based search) to verify the abstraction's flexibility and the framework's applicability.

3. **Scalability stress test**: Evaluate RAGO's scheduling performance as the configuration space grows (e.g., more components, finer-grained resource allocation options) to identify computational bottlenecks in the exhaustive search approach and assess potential need for heuristic optimization.