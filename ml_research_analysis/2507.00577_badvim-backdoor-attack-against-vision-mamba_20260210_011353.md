---
ver: rpa2
title: 'BadViM: Backdoor Attack against Vision Mamba'
arxiv_id: '2507.00577'
source_url: https://arxiv.org/abs/2507.00577
tags:
- state
- backdoor
- vision
- attack
- badvim
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: BadViM is the first backdoor attack framework designed specifically
  for Vision Mamba architectures. It exploits the centralized hidden state vulnerability
  through Resonant Frequency Triggers (RFT) and Hidden State Alignment.
---

# BadViM: Backdoor Attack against Vision Mamba

## Quick Facts
- arXiv ID: 2507.00577
- Source URL: https://arxiv.org/abs/2507.00577
- Authors: Yinghao Wu; Liyan Zhang
- Reference count: 21
- BadViM achieves >99.8% attack success rates against Vision Mamba with minimal clean data accuracy loss

## Executive Summary
BadViM introduces the first backdoor attack framework specifically targeting Vision Mamba architectures. The attack exploits the centralized hidden state vulnerability through Resonant Frequency Triggers (RFT) and Hidden State Alignment, achieving near-perfect attack success rates while maintaining minimal impact on clean data accuracy. BadViM demonstrates exceptional robustness against common defense mechanisms including PatchDrop, PatchShuffle, and JPEG compression, maintaining ASR above 99% in most cases.

## Method Summary
BadViM exploits the centralized hidden state vulnerability in Vision Mamba architectures through a two-phase approach. First, it identifies model-specific resonant frequencies to create distributed, stealthy triggers that are difficult to detect. Second, it aligns the model's internal representations with target class manifolds using a composite loss function. The attack leverages Vision Mamba's selective state spaces to manipulate hidden states, allowing precise control over the model's behavior while maintaining clean data performance.

## Key Results
- Achieves attack success rates above 99.8% across CIFAR-10 and ImageNet-1K
- Maintains minimal clean data accuracy degradation (CDA loss negligible)
- Demonstrates robustness against common defenses: ASR above 99% against PatchDrop and PatchShuffle, 98.5% against JPEG compression

## Why This Works (Mechanism)
BadViM exploits the centralized hidden state structure of Vision Mamba, where the hidden state serves as a bottleneck for information flow. By identifying resonant frequencies that amplify specific hidden state components, the attack can create triggers that are both effective and stealthy. The Hidden State Alignment phase ensures that when the trigger is present, the model's internal representations align with the target class manifold, forcing misclassification while maintaining normal behavior on clean data.

## Foundational Learning
- **Vision Mamba Architecture**: Selective State Space Models (SSMs) used for vision tasks; needed to understand attack surface, quick check: verify hidden state centralization
- **Centralized Hidden State Vulnerability**: Bottleneck in information flow that can be exploited; needed to identify attack vector, quick check: confirm hidden state dependency on input
- **Resonant Frequency Triggers**: Frequency-based manipulation of hidden states; needed for stealthy trigger generation, quick check: validate frequency sweep effectiveness
- **Hidden State Alignment**: Aligning internal representations with target manifolds; needed for effective misclassification, quick check: measure manifold distance before/after alignment
- **Composite Loss Function**: Multi-objective optimization for trigger generation; needed to balance attack effectiveness and stealth, quick check: verify loss component contributions
- **Defense Mechanisms**: Common backdoor defenses like PatchDrop, PatchShuffle; needed to evaluate attack robustness, quick check: test against each defense individually

## Architecture Onboarding
- **Component Map**: Input -> Vision Mamba Blocks -> Centralized Hidden State -> Output
- **Critical Path**: Trigger generation → Hidden state manipulation → Class alignment → Misclassification
- **Design Tradeoffs**: Resonant frequencies vs. trigger visibility, attack strength vs. clean accuracy preservation
- **Failure Signatures**: Failed alignment (model ignores trigger), frequency mismatch (trigger ineffective), defense detection (trigger identified)
- **First Experiments**: 1) Baseline Vision Mamba performance on clean data, 2) Frequency sweep to identify resonant frequencies, 3) Hidden state visualization before and after alignment

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on centralized hidden state structure that may not generalize to all Mamba variants
- Computationally expensive frequency sweep phase for trigger generation
- Limited exploration of tasks beyond image classification

## Confidence
- **High Confidence**: Experimental results showing >99.8% ASR and robustness against common defenses are well-supported
- **Medium Confidence**: Claim of being "first" framework needs verification in rapidly evolving field
- **Low Confidence**: Generalizability to real-world adaptive defense scenarios remains uncertain

## Next Checks
1. Test BadViM's effectiveness against adaptive defense mechanisms targeting hidden state manipulation in selective state space models
2. Evaluate computational overhead of RFT generation across different scale Vision Mamba models (1B to 10B parameters)
3. Investigate whether resonant frequency triggers remain effective during continual learning or fine-tuning on new datasets