---
ver: rpa2
title: 'A Multimodal Approach to Alzheimer''s Diagnosis: Geometric Insights from Cube
  Copying and Cognitive Assessments'
arxiv_id: '2512.16184'
source_url: https://arxiv.org/abs/2512.16184
tags:
- cube
- graph
- features
- alzheimer
- cognitive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study introduces a graph-based deep learning framework for\
  \ Alzheimer\u2019s disease detection using hand-drawn cube copying tasks. Cube sketches\
  \ are converted into graph representations encoding spatial geometry, local topology\
  \ via graphlet degrees, and angular relationships, then processed by graph neural\
  \ networks and fused with demographic and neuropsychological features in a multimodal\
  \ late-fusion model."
---

# A Multimodal Approach to Alzheimer's Diagnosis: Geometric Insights from Cube Copying and Cognitive Assessments

## Quick Facts
- arXiv ID: 2512.16184
- Source URL: https://arxiv.org/abs/2512.16184
- Authors: Jaeho Yang; Kijung Yoon
- Reference count: 21
- Key outcome: Graph-based deep learning framework for AD detection using hand-drawn cube copying tasks, achieving accuracy: 0.913, F1: 0.808, AUC: 0.950, AUPRC: 0.924

## Executive Summary
This study introduces a graph-based deep learning framework for Alzheimer's disease detection using hand-drawn cube copying tasks. Cube sketches are converted into graph representations encoding spatial geometry, local topology via graphlet degrees, and angular relationships, then processed by graph neural networks and fused with demographic and neuropsychological features in a multimodal late-fusion model. The approach significantly outperforms pixel-based CNN baselines and achieves strong diagnostic accuracy when integrating cube graphs with age, education, and NPT scores. SHAP analysis identifies specific graphlet motifs and geometric distortions as key predictors, closely aligning with clinical observations of visuospatial impairments in AD. The method provides an interpretable, non-invasive, and scalable approach for early AD screening.

## Method Summary
The framework converts hand-drawn cube sketches into graph representations through a pipeline of adaptive thresholding, skeletonization, Douglas-Peucker simplification, and node merging. Node features include spatial coordinates, graphlet degree vectors (up to 4-node graphlets), and inner angles. These graph features are processed by a Graph Attention Network (GAT) and fused with demographic variables (age, education) and neuropsychological test scores through separate MLPs in a late-fusion architecture. The model is trained on a dataset of 124 participants (96 cognitively normal, 28 AD) using stratified 80-10-10 splits, with Macro-F1 as the primary selection metric.

## Key Results
- Graph-based GAT model achieves AUC=0.950, significantly outperforming pixel-based CNN baseline (AUC=0.688)
- Multimodal fusion of cube graphs with demographics and NPT scores improves F1 from 0.330 to 0.808
- Graphlet 6 emerges as the most influential predictor, with reduced motif counts in AD drawings
- Age+Education+NPT unimodal achieves AUC=0.827, demonstrating cube graphs add discriminative value

## Why This Works (Mechanism)

### Mechanism 1
Graph representations of cube drawings capture AD-related visuospatial impairments more effectively than pixel-based approaches. Vectorization converts raster drawings into node-edge structures where nodes represent corner points and edges represent drawn lines, preserving geometric relationships that CNNs must infer implicitly. GNN message-passing aggregates local structural information into graph-level representations. Core assumption: Visuospatial deficits manifest as quantifiable disruptions in cube geometry rather than purely texture patterns. Evidence: GAT AUC=0.950 vs CNN AUC=0.688; related work confirms visuospatial impairment sensitivity. Break condition: Severely degraded drawing quality may prevent meaningful node/edge extraction.

### Mechanism 2
Graphlet degree vectors encode local topological motifs as interpretable biomarkers. Each node's GDV counts participation in small induced subgraphs (2-4 node graphlets). Specific motifs occur predictably in well-formed cubes (graphlet 6 appears 3 times for 3-edge corners). AD drawings show reduced counts due to structural errors, providing discriminative features for SHAP analysis. Core assumption: Diagnostic signal lies in motif frequency disruptions, not coordinate positions. Evidence: Graphlet 6 identified as most influential predictor; AD drawings frequently lack sufficient graphlet 6 motifs. Break condition: Variable node counts across samples make GDV distributions incomparable.

### Mechanism 3
Late fusion of graph features with demographic variables improves robustness to class imbalance. Cube graphs alone achieve high AUC (0.895) but low F1 (0.330) on imbalanced data. Demographics processed through separate MLPs provide class-balancing contextual signals. Concatenating embeddings allows model to adjust decision boundaries based on risk factors independent of drawing quality. Core assumption: Age and education provide complementary diagnostic signal not fully captured in drawing behavior. Evidence: F1 increases to 0.752 with demographic addition; non-graph modalities alone achieve weaker performance. Break condition: Demographic distribution shifts between training and deployment populations may miscalibrate predictions.

## Foundational Learning

- Concept: **Graph Neural Networks (GNNs) and Message Passing**
  - Why needed here: Core architecture processes cube drawings as graphs rather than images. Understanding GNN message-passing explains why structural motifs become discriminative features.
  - Quick check question: Given a 4-node path graph, what representation does each node have after one message-passing layer if initial features are one-hot position encodings?

- Concept: **Graphlet Degree Vectors (GDV)**
  - Why needed here: Paper uses 15-dimensional GDVs as node features. Understanding graphlet orbits explains why specific motifs carry different diagnostic information.
  - Quick check question: In a 4-cycle (square), which nodes share the same graphlet orbit, and how many distinct orbits exist?

- Concept: **Late Fusion vs Early Fusion**
  - Why needed here: Multimodal design concatenates embeddings from separately processed modalities. Understanding tradeoffs explains why this approach preserves modality-specific representations.
  - Quick check question: If you fused raw features before any neural processing (early fusion), what normalization challenge would arise when combining graph embeddings with demographic one-hots?

## Architecture Onboarding

- Component map:
  Raw Image → Binarization → Vectorization → Douglas-Peucker Simplification → Node Merging → Graph G=(V,E) → Node Features: [x,y coords] ⊕ [GDV-15] ⊕ [angles up to 3] → GAT layers → Graph-level pooling → Demographics: Age(one-hot-9) ⊕ Education(one-hot-7) → MLP-3 → Demographic embedding → NPT scores (normalized) → MLP-3 → NPT embedding → [Graph embedding] ⊕ [Demo embedding] ⊕ [NPT embedding] → MLP-2 classifier → AD/Control

- Critical path:
  1. Vectorization quality determines graph fidelity—errors cascade through all downstream components
  2. Node merge threshold (δ) controls graph sparsity; too aggressive merges distinct corners, too conservative creates fragmented graphs
  3. GAT attention weights enable interpretability via SHAP—architectures without attention may sacrifice this

- Design tradeoffs:
  - GAT vs EGNN/Polynormer: Simpler GAT trades theoretical expressiveness for interpretability (EGNN F1=0.484 vs GAT F1=0.808)
  - Graph-only vs multimodal: Unimodal graphs give AUC=0.895 but F1=0.330; multimodal required for balanced performance
  - GDV size: 4-node graphlets (15 dimensions) chosen; larger graphlets increase feature dimension but may overfit on n=124 dataset

- Failure signatures:
  - Extremely sparse graphs (≤3 nodes): Likely vectorization failure, should flag for manual review
  - F1 << AUC gap: Class imbalance not adequately addressed; check demographic feature encoding
  - SHAP shows no graph features in top-10: Graph branch may not be learning; verify GNN gradient flow

- First 3 experiments:
  1. **Vectorization sanity check**: Manually inspect 10 random samples at each pipeline stage (binarized → vectorized → simplified → final graph) to validate node extraction quality and tune δ threshold.
  2. **Graph-only baseline ablation**: Train GAT on cube graphs alone with 5-fold cross-validation to establish unimodal performance bounds before multimodal integration.
  3. **Node feature contribution**: Train three variants removing each feature type (no coords / no GDV / no angles) to quantify contribution of spatial, topological, and geometric information.

## Open Questions the Paper Calls Out

### Open Question 1
Can the graph-based multimodal framework effectively differentiate between cognitively normal individuals, those with mild cognitive impairment (MCI), and Alzheimer's disease in a multi-class setting? Current study only evaluates binary classification (CN vs. AD), lacking validation on the prodromal MCI stage where early intervention is most critical. Experimental results showing discrimination between CN, MCI, and AD classes would resolve this.

### Open Question 2
Does the incorporation of temporal drawing dynamics, such as stroke order, speed, and hesitation, improve diagnostic sensitivity compared to static graph structures alone? Current methodology relies solely on final geometric structure, ignoring process-level motor and cognitive data captured during drawing. A comparative study where temporal features are fused with graph features, demonstrating improved AUC or F1 scores over static unimodal baseline, would resolve this.

### Open Question 3
Do the identified graphlet biomarkers and model performance generalize to larger, multi-center cohorts with diverse demographic and cultural backgrounds? Study relies on specific cohort of 124 participants from single region, raising concerns about overfitting to specific demographic or artistic conventions. Successful external validation on independent, larger dataset from different clinical sites would resolve this.

## Limitations
- Small sample size (n=124) with severe class imbalance (28 AD vs 96 CN) raises concerns about model robustness and F1 score volatility
- Critical hyperparameters for graph construction (adaptive threshold parameters, Douglas-Peucker tolerance, node merge distance) are unspecified
- Single-site, cross-sectional design limits clinical generalizability across populations and disease stages

## Confidence

- **High Confidence**: Graph-based representations outperform pixel-based CNNs (AUC: 0.950 vs 0.688); multimodal fusion improves balanced accuracy; SHAP-identified graphlet 6 as key predictor
- **Medium Confidence**: Clinical interpretability of graphlet disruptions aligns with visuospatial impairment literature; demographic fusion addresses class imbalance
- **Low Confidence**: Optimal hyperparameter settings remain unknown; single dataset limits validation; scalability to other visuospatial tasks untested

## Next Checks

1. **Ablation on graphlet sizes**: Systematically test 2-node, 3-node, and 4-node graphlets to identify minimal sufficient topology for AD discrimination
2. **Cross-validation robustness**: Implement 5-fold stratified cross-validation across multiple random seeds to quantify F1 score variance and assess stability
3. **External validation**: Test the complete pipeline on an independent dataset (different site or time period) to evaluate clinical generalizability beyond single-source data used here