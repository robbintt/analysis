---
ver: rpa2
title: Evaluating LLMs on Generating Age-Appropriate Child-Like Conversations
arxiv_id: '2510.24250'
source_url: https://arxiv.org/abs/2510.24250
tags:
- liker
- barn
- language
- leke
- children
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study evaluated five LLMs' ability to generate age-appropriate
  Norwegian child-like conversations for ages 5 and 9. Expert education professionals
  assessed text samples, achieving good inter-rater reliability (ICC=0.75).
---

# Evaluating LLMs on Generating Age-Appropriate Child-Like Conversations

## Quick Facts
- **arXiv ID**: 2510.24250
- **Source URL**: https://arxiv.org/abs/2510.24250
- **Reference count**: 40
- **Primary result**: Expert education professionals assessed Norwegian child-like text samples, finding most LLMs generated language perceived as more advanced than target ages 5 and 9, with GPT-4 and NorBloom-7b performing relatively well.

## Executive Summary
This study evaluated five LLMs' ability to generate age-appropriate Norwegian child-like conversations for ages 5 and 9. Expert education professionals (teachers, counselors) assessed text samples, achieving good inter-rater reliability (ICC=0.75). Evaluators were more accurate predicting 5-year-olds (MAE=1.20) than 9-year-olds (MAE=2.69), and most LLMs generated language perceived as more advanced than target ages. The study found that purely computational metrics proved inadequate for evaluating developmental appropriateness in this low-resource language context. GPT-4 and NorBloom-7b performed relatively well compared to other models tested.

## Method Summary
The study generated 20 text samples per model per age group (5 and 9 years) using five different LLMs and a standardized 10-question interview script in Norwegian. Each model generated texts for both male and female personas. Education professionals then blindly evaluated 12 text samples (2 real child interviews plus 10 LLM-generated texts), predicting the age of each speaker and providing written justifications. The researchers also conducted computational analysis using compiled Norwegian linguistic resources, including age-of-acquisition (AoA) scores and word frequency data from 10 datasets covering 1,813 words post-processing. Statistical analysis included paired t-tests and correlation between human and computational assessments.

## Key Results
- Expert evaluators achieved good inter-rater reliability (ICC=0.75) when assessing developmental appropriateness
- Evaluators were significantly more accurate predicting 5-year-olds (MAE=1.20) than 9-year-olds (MAE=2.69)
- Most LLMs generated language perceived as more advanced than target ages
- GPT-4 achieved lowest overall MAE (1.40) while RUTER-LLAMA-2-13b had highest MAE (2.98)
- Purely computational metrics proved inadequate for evaluating developmental appropriateness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Expert human evaluators can reliably assess developmental appropriateness of child-like text, achieving higher accuracy for younger children than older children.
- Mechanism: Education professionals apply domain expertise from systematic classroom observation to recognize age-related linguistic markers such as vocabulary complexity, syntactic structures, and pragmatic maturity. Inter-rater reliability (ICC=0.75) indicates shared professional frameworks for developmental assessment.
- Core assumption: Professional experience with children translates to consistent judgment about written language samples without audio or contextual cues.
- Evidence anchors:
  - [abstract] "Evaluators were more accurate predicting 5-year-olds (MAE=1.20) than 9-year-olds (MAE=2.69)"
  - [section 4.3.1] "Texts from 5-year-olds (M = 1.20, SD = 0.79) were predicted significantly more accurately than those from 9-year-olds (M = 2.69, SD = 0.73), t(9) = -5.352, p < 0.001"
  - [corpus] Limited direct corpus support; related work (LLM Safety for Children) addresses safety but not age prediction accuracy.
- Break condition: If evaluator expertise is domain-specific (e.g., only early childhood), accuracy patterns may reverse; fixed text order in the study (noted as limitation) may have introduced practice/fatigue confounds.

### Mechanism 2
- Claim: LLMs systematically generate language perceived as more linguistically advanced than target child ages due to adult-centric training corpora.
- Mechanism: Training data predominantly contains adult-authored content (web crawls, books, articles), causing models to default to sophisticated vocabulary and complex syntax even when prompted for child-like output. This bias appears across model architectures.
- Core assumption: The observed overestimation reflects training data composition rather than prompt design failures alone.
- Evidence anchors:
  - [abstract] "Most LLMs generated language perceived as more advanced than target ages"
  - [section 1] "Most LLMs training datasets predominantly consist of adult-authored content from web crawls, books, and articles"
  - [corpus] Related work (Valentini et al.) confirms LLMs "frequently fail to adjust vocabulary to meet comprehension levels appropriate for younger children."
- Break condition: If prompt engineering explicitly incorporates authentic child language examples (few-shot), this bias may reduce—though not tested in this study.

### Mechanism 3
- Claim: Purely computational metrics (AoA scores, word frequency, structural characteristics) are inadequate for evaluating developmental appropriateness in low-resource languages.
- Mechanism: Norwegian linguistic databases lack comprehensive age-stratified lexical resources; 83% of compiled AoA data covers children under age 5, providing insufficient discriminative power for older age groups. Computational metrics failed to capture qualitative differences experts detected.
- Core assumption: The inadequacy stems from resource scarcity rather than fundamental limitations of computational approaches.
- Evidence anchors:
  - [abstract] "purely computational metrics proved inadequate for evaluating developmental appropriateness"
  - [section 4.4] "83% (1,580 words including inflections) of the words with AoA scores in our compiled dataset are associated with children under age 5"
  - [corpus] Limited corpus evidence on Norwegian specifically; related work focuses on English child language corpora.
- Break condition: If comprehensive age-annotated corpora become available, computational metrics may become viable complements to human evaluation.

## Foundational Learning

- Concept: Age-of-Acquisition (AoA)
  - Why needed here: AoA ratings indicate when words are typically learned; critical for assessing whether LLM output matches developmental stages.
  - Quick check question: Can you explain why a word with AoA of 3 might appear inappropriately advanced in text targeting 5-year-olds? (Answer: No—it's age-appropriate; AoA 3 means acquired by age 3.)

- Concept: Inter-rater Reliability (ICC)
  - Why needed here: Establishes whether expert judgments are consistent enough to trust as ground truth for model evaluation.
  - Quick check question: An ICC of 0.75 indicates what proportion of variance is due to true differences versus measurement error? (Answer: ~75% true differences, ~25% error.)

- Concept: Low-Resource Language Constraints
  - Why needed here: Norwegian lacks comprehensive child language corpora, limiting both training data and evaluation benchmarks.
  - Quick check question: Why might a model perform well on English child-like generation but fail in Norwegian? (Answer: English has extensive age-stratified corpora; Norwegian does not.)

## Architecture Onboarding

- Component map:
  - Model layer: Norwegian-specific models (NorBloom-7b, NorMistral-7b) vs. multilingual (GPT-4, GPTSW) vs. fine-tuned adaptations (RUTER-LLAMA-2-13b)
  - Prompt layer: Standardized interview script (10 questions) with age-targeted instructions
  - Evaluation layer: Expert human assessors (blind) + computational analysis (AoA, frequency, structure)
  - Data layer: Compiled Norwegian linguistic resources (10 datasets, 1,813 words post-processing)

- Critical path: Define target age → Design age-appropriate prompt → Generate text → Strip identifying markers → Expert blind evaluation → Correlate with computational metrics

- Design tradeoffs:
  - Specialized Norwegian models (NorBloom, NorMistral) showed competitive accuracy with smaller size (7B) vs. larger fine-tuned multilingual (RUTER-LLAMA-2-13B had MAE=2.98)
  - GPT-4 achieved lowest overall MAE (1.40) but requires API dependency and higher cost
  - NorMistral-7b consistently underestimated ages (perceived as less mature), which may be preferable for safety-critical applications

- Failure signatures:
  - Generated text overestimated by 4-5 years (e.g., RUTER-LLAMA-2-13b for 9-year-olds → predicted 13.90)
  - Vocabulary sophistication markers: complex subordinate clauses, abstract reasoning, meta-linguistic comments
  - Underestimation (NorMistral pattern): very short responses (8-15 words), simple sentence structures

- First 3 experiments:
  1. Baseline replication: Generate 20 samples per model per age (5, 9) with current prompts; measure MAE and prediction variance
  2. Prompt engineering intervention: Add few-shot examples from authentic child interviews; compare overestimation rates
  3. Resource augmentation: Expand Norwegian AoA database for ages 6-12; re-run computational analysis to test correlation with expert judgments

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can computational metrics be developed that reliably predict human expert judgments of developmental appropriateness in child-like language generation?
- Basis in paper: [explicit] "purely computational metrics proved inadequate for evaluating developmental appropriateness" and authors call for "developing of age-annotated child language corpora and automated metrics specifically designed for assessing developmental appropriateness."
- Why unresolved: Current metrics (AoA scores, word frequency, structural characteristics) showed minimal differences between age groups and failed to capture qualitative differences experts detected.
- What evidence would resolve it: Novel metrics showing strong correlation (e.g., r > 0.8) with expert age predictions across multiple age groups and languages.

### Open Question 2
- Question: Do findings regarding LLM limitations in generating age-appropriate Norwegian child language generalize to other low- and medium-resource languages?
- Basis in paper: [explicit] Authors call for "cross-linguistic studies comparing Norwegian findings with other low or medium resource languages to identify universal versus language-specific patterns."
- Why unresolved: The study only examined Norwegian, and it remains unknown whether challenges stem from universal training data biases or language-specific resource limitations.
- What evidence would resolve it: Replication studies across diverse low-resource languages (e.g., Finnish, Vietnamese, Swahili) showing consistent or divergent error patterns.

### Open Question 3
- Question: Can advanced prompt engineering techniques incorporating authentic child language examples improve LLM age-appropriateness to within ±0.5 years of target ages?
- Basis in paper: [explicit] Authors suggest "explore advanced prompt engineering techniques that explicitly incorporate developmental linguistic knowledge, potentially using few-shot learning with authentic child language examples."
- Why unresolved: Most LLMs generated language perceived as more advanced than target ages (7/10 texts overestimated), with MAE ranging from 1.40–2.98 years.
- What evidence would resolve it: Controlled experiments comparing baseline prompts against few-shot prompts with age-annotated child corpora, showing significantly reduced MAE.

### Open Question 4
- Question: Does LLM-generated age-appropriate language improve learning outcomes and engagement in educational applications compared to standard LLM outputs?
- Basis in paper: [explicit] "Longitudinal studies tracking LLM-generated age-appropriate language effectiveness in actual educational applications, measuring learning outcomes and engagement."
- Why unresolved: The study only evaluated perceived authenticity, not actual educational effectiveness with children.
- What evidence would resolve it: Randomized controlled trials in educational settings measuring comprehension, engagement time, and learning gains with developmentally appropriate vs. standard LLM-generated content.

## Limitations

- Small sample size (10 LLM-generated texts evaluated by 10 professionals) limits generalizability
- Fixed text presentation order rather than randomization may have introduced order effects
- Norwegian language context presents unique challenges with limited age-stratified linguistic resources
- Text-only evaluation without audio or visual context may affect ecological validity

## Confidence

**High Confidence**: Expert human evaluators can reliably assess developmental appropriateness of child-like text (ICC=0.75 demonstrates acceptable inter-rater reliability). The finding that evaluators were more accurate predicting 5-year-olds (MAE=1.20) than 9-year-olds (MAE=2.69) is well-supported by paired t-test results (t(9) = -5.352, p < 0.001).

**Medium Confidence**: LLMs systematically generate language perceived as more advanced than target child ages. While the pattern is clear across multiple models, the mechanism attribution to adult-centric training corpora remains inferential rather than directly tested. The comparative performance of Norwegian-specific models (NorBloom-7b) versus larger multilingual models (RUTER-LLAMA-2-13b) shows promise but requires replication with larger sample sizes.

**Low Confidence**: Purely computational metrics are inadequate for evaluating developmental appropriateness in low-resource languages. This conclusion rests heavily on the specific Norwegian context and the limited availability of comprehensive age-stratified resources. The inadequacy may reflect resource scarcity rather than fundamental limitations of computational approaches.

## Next Checks

1. **Order Effects Validation**: Re-run the expert evaluation with randomized text presentation order and control for potential practice or fatigue effects. Compare ICC values and MAE scores between ordered vs. randomized conditions to isolate systematic bias from order effects.

2. **Resource Augmentation Impact**: Expand the Norwegian AoA database by integrating additional child language corpora and lexical resources beyond the current 10 datasets. Re-run computational analysis on the same LLM-generated texts and measure correlation improvement with expert judgments.

3. **Prompt Engineering Intervention**: Design and test prompt variants that explicitly incorporate authentic child language examples (few-shot learning) versus baseline prompts. Generate new samples and compare overestimation rates across conditions to validate whether prompt design can mitigate adult-centric bias.