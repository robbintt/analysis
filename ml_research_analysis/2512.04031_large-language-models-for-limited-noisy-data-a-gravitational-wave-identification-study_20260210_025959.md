---
ver: rpa2
title: 'Large Language Models for Limited Noisy Data: A Gravitational Wave Identification
  Study'
arxiv_id: '2512.04031'
source_url: https://arxiv.org/abs/2512.04031
tags:
- data
- noise
- wave
- llms
- gravitational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether large language models (LLMs) can
  effectively identify gravitational wave signals using only limited observational
  data and non-Gaussian, non-stationary detector noise. Unlike traditional neural
  networks that rely on extensive simulated datasets, LLMs process data through tokenization
  and global self-attention, which naturally emphasize coherent patterns and suppress
  localized noise artifacts.
---

# Large Language Models for Limited Noisy Data: A Gravitational Wave Identification Study

## Quick Facts
- arXiv ID: 2512.04031
- Source URL: https://arxiv.org/abs/2512.04031
- Reference count: 17
- Primary result: 97.4% accuracy on binary gravitational wave classification using only 90 observed LIGO events, without simulated data

## Executive Summary
This study investigates whether large language models can effectively identify gravitational wave signals using only limited observational data and non-Gaussian, non-stationary detector noise. Unlike traditional neural networks that rely on extensive simulated datasets, LLMs process data through tokenization and global self-attention, which naturally emphasize coherent patterns and suppress localized noise artifacts. The authors finetune the Meta-Llama-3-8B-Instruct model on 90 real LIGO gravitational wave events, without using any simulated signals, and achieve 97.4% accuracy on the test set.

## Method Summary
The authors use 90 GWTC-3 events from LIGO O1-O3 runs, extracting 2-second sliding windows with 1-second stride from H1 and L1 strain data. Data undergoes bandpass filtering (20-500 Hz), Tukey windowing, and Constant-Q Transform (CQT) processing. The CQT frames are quantized using KMeans clustering into discrete tokens, which are then concatenated and fed to a finetuned Meta-Llama-3-8B-Instruct model with LoRA. The model uses binary cross-entropy loss and achieves 97.4% accuracy on held-out test data without any simulated signals.

## Key Results
- 97.4% accuracy and 97.4% recall on binary classification of gravitational wave signals vs. noise using only 90 observed LIGO events
- Adding large-scale simulated datasets does not improve performance, indicating LLMs can extract discriminative features directly from observational data
- Scaling experiments show predictable accuracy gains with increasing model size and dataset size

## Why This Works (Mechanism)
LLMs process data through tokenization and global self-attention, which naturally emphasize coherent patterns and suppress localized noise artifacts. The self-attention mechanism allows the model to capture long-range dependencies in the gravitational wave signal while ignoring transient noise events that characterize detector noise.

## Foundational Learning
- **KMeans clustering**: Used to quantize CQT frames into discrete tokens for LLM input. Why needed: Transforms continuous spectral features into discrete vocabulary for tokenization. Quick check: Verify cluster centers capture meaningful spectral patterns.
- **Constant-Q Transform**: Computes time-frequency representation of gravitational wave strain data. Why needed: Provides log-frequency resolution suitable for transient signal detection. Quick check: Confirm CQT preserves signal morphology while suppressing noise.
- **LoRA fine-tuning**: Low-rank adaptation technique for efficient LLM adaptation. Why needed: Enables parameter-efficient fine-tuning on small datasets. Quick check: Monitor training loss convergence within 2 epochs.

## Architecture Onboarding

**Component Map**
Raw strain data -> Bandpass filter -> Tukey window -> CQT -> KMeans quantization -> Token sequences -> Llama-3-8B-Instruct + LoRA -> Binary classification

**Critical Path**
CQT + KMeans quantization -> Token sequence generation -> Llama-3-8B-Instruct fine-tuning -> Binary classification head

**Design Tradeoffs**
- Tokenization via KMeans vs. direct spectral input: Enables use of pre-trained LLM but may lose fine-grained spectral information
- LoRA vs. full fine-tuning: Parameter-efficient but may limit adaptation capacity
- No simulated data vs. simulation-assisted training: Reduces domain shift but limits training sample diversity

**Failure Signatures**
- Class imbalance causing biased predictions (check per-class recall)
- Tokenization mismatch degrading performance (verify CQT dimensions and cluster assignments)
- Overfitting on small dataset (monitor training vs. validation loss)

**First Experiments**
1. Reconstruct the KMeans quantization step with standard vocabulary size and verify token sequences preserve CQT structure
2. Train Llama-3-8B-Instruct with LoRA configuration on 90-event dataset and measure accuracy/reliability
3. Compare performance with and without simulated signals to test simulation benefit

## Open Questions the Paper Calls Out
- Will LLMs trained on current LIGO data generalize to future observing runs (O4, O5) with different detector noise characteristics?
- Can LLMs perform parameter estimation (mass, spin, distance) rather than just binary signal detection?
- Why does simulation-based pre-finetuning fail to improve LLM performance on real gravitational wave data?
- How effectively do these methods transfer to other astronomical domains with non-Gaussian noise, such as radio pulsar searches or fast radio burst detection?

## Limitations
- Exact KMeans vocabulary size and clustering configuration are unspecified
- Multi-detector sequence concatenation details and effective sequence length are unclear
- Post-oversampling dataset sizes and absolute training duration are not provided

## Confidence
- **High confidence**: LLMs can identify gravitational waves using only observational data without simulated signals, achieving high accuracy (97.4%)
- **Medium confidence**: Simulated data does not improve performance and LLM scaling follows predictable patterns
- **Medium confidence**: Broader applicability to other astronomical domains with non-Gaussian noise

## Next Checks
1. Reconstruct the KMeans quantization step with a standard vocabulary size (e.g., 1000 clusters) and verify that the resulting token sequences preserve CQT frame structure before model input
2. Train the Llama-3-8B-Instruct with LoRA configuration on the 90-event observational dataset and measure both accuracy and per-class recall to confirm the reported 97.4% metrics
3. Conduct a controlled experiment comparing finetuning with and without simulated signals to directly test whether simulation data provides any performance benefit on observational test sets