---
ver: rpa2
title: Probing Geometry of Next Token Prediction Using Cumulant Expansion of the Softmax
  Entropy
arxiv_id: '2510.04285'
source_url: https://arxiv.org/abs/2510.04285
tags:
- cumulants
- prompts
- entropy
- cumulant
- softmax
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a cumulant-expansion framework to probe how
  large language models (LLMs) internalize higher-order statistical structures during
  next-token prediction. By treating the softmax entropy of each layer's logit distribution
  as a perturbation around its center distribution, the authors derive closed-form
  cumulant observables that isolate successively higher-order correlations.
---

# Probing Geometry of Next Token Prediction Using Cumulant Expansion of the Softmax Entropy

## Quick Facts
- arXiv ID: 2510.04285
- Source URL: https://arxiv.org/abs/2510.04285
- Authors: Karthik Viswanathan; Sang Eon Park
- Reference count: 40
- This paper introduces a cumulant-expansion framework to probe how large language models (LLMs) internalize higher-order statistical structures during next-token prediction.

## Executive Summary
This paper introduces a cumulant-expansion framework to probe how large language models (LLMs) internalize higher-order statistical structures during next-token prediction. By treating the softmax entropy of each layer's logit distribution as a perturbation around its center distribution, the authors derive closed-form cumulant observables that isolate successively higher-order correlations. Empirically, they track these cumulants in GPT-2 and Pythia models on Pile-10K prompts. Key findings include: (i) structured prompts exhibit a characteristic rise-and-plateau profile across layers, whereas token-shuffled prompts remain flat, revealing the dependence of cumulant profiles on meaningful context; (ii) during training, all cumulants increase monotonically before saturating, visualizing the model's progression from capturing variance to learning skew, kurtosis, and higher-order statistical structures; and (iii) mathematical prompts show distinct cumulant signatures compared to general text, quantifying fundamentally different processing mechanisms. These results establish cumulant analysis as a lightweight, mathematically grounded probe of feature-learning dynamics in high-dimensional neural networks.

## Method Summary
The authors develop a cumulant expansion framework that treats the softmax entropy of LLM logits as a perturbation around a "center" distribution (the arithmetic mean of per-token softmax distributions). They derive closed-form expressions for cumulants up to order 7 using incomplete Bell polynomials, which capture successively higher-order statistical moments (variance, skew, kurtosis, etc.) of how token logit distributions deviate from the center. The method extracts intermediate-layer logits using TunedLens, computes per-token softmax distributions, derives the center distribution, calculates deviation vectors, and converts moments to cumulants. Experiments track these observables across layers for structured versus shuffled prompts, throughout training, and across different prompt types (mathematical vs general text).

## Key Results
- Structured prompts exhibit characteristic rise-and-plateau cumulant profiles across layers; shuffled prompts remain flat
- During training, all cumulants increase monotonically before saturating, showing progression from variance to higher-order statistics
- Mathematical prompts show distinct cumulant signatures compared to general text, indicating fundamentally different processing mechanisms

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cumulant expansion of softmax entropy isolates successively higher-order correlations in logit distributions.
- Mechanism: By treating mean softmax entropy as a perturbation around a "center" distribution (the average of per-token predictions), the KL-divergence term decomposes into cumulants via the cumulant generating function. Each cumulant (κ₂, κ₃, ...) captures variance, skew, kurtosis, and higher moments of how token logits deviate from the center.
- Core assumption: The distribution of logit deviations from the center characterizes the geometric structure of the model's latent predictions on the probability simplex.
- Evidence anchors:
  - [abstract] "By treating the softmax entropy... as a perturbation around its 'center' distribution, we derive closed-form cumulant observables that isolate successively higher-order correlations."
  - [Section 3, Eq. 4] Shows the entropy decomposition: ⟨S(X)⟩ = S(μ) − (1/N)Σ βⁿ/n! κₙ(−ΣδXᵢ)
  - [corpus] Related work "The Geometry of Tokens in Internal Representations of Large Language Models" (Viswanathan et al., 2025) establishes intrinsic dimension–softmax entropy relationships, supporting geometric interpretation.
- Break condition: If logits across tokens collapse to identical distributions (no variation), cumulants beyond κ₁ vanish and the probe provides no discrimination.

### Mechanism 2
- Claim: Structured prompts produce characteristic rise-and-plateau cumulant profiles across layers; shuffled prompts remain flat.
- Mechanism: Meaningful token order allows the model to build higher-order dependencies layer-by-layer. The deviation distribution δX becomes increasingly structured (non-Gaussian) as layers refine predictions. Shuffling destroys sequential dependencies, leaving δX distribution approximately constant.
- Core assumption: Token shuffling sufficiently disrupts learned sequential patterns without changing marginal token statistics.
- Evidence anchors:
  - [abstract] "Structured prompts exhibit a characteristic rise-and-plateau profile across layers, whereas token-shuffled prompts remain flat."
  - [Section 4.1, Fig. 2] Shows structured prompt cumulants rising through intermediate layers and plateauing; shuffled prompts flat near zero for κ₃+.
  - [corpus] Limited direct corpus validation; this is a novel observable introduced by this work.
- Break condition: If models develop position-invariant representations (e.g., via certain pretraining objectives), shuffling may not flatten cumulant profiles.

### Mechanism 3
- Claim: During training, models progressively learn higher-order statistics: variance → skew → kurtosis → beyond.
- Mechanism: Early training captures low-order moments (κ₂ rises first); as optimization continues, the model fits increasingly fine-grained statistical structure, visible as monotonic increase in all cumulants before saturation.
- Core assumption: Cumulant growth reflects genuine feature learning rather than memorization or noise amplification.
- Evidence anchors:
  - [abstract] "During training, all cumulants increase monotonically before saturating, directly visualizing the model's progression from capturing variance to learning skew, kurtosis..."
  - [Section 4.2, Fig. 3] Shows all cumulants increasing and plateauing with training steps.
  - [corpus] Distributional simplicity bias (Refinetti et al., ICML'23; Rende et al., NeurIPS'24) provides prior evidence that neural networks learn lower-order statistics first.
- Break condition: If training is too short or dataset lacks higher-order structure, higher cumulants may not develop meaningfully.

## Foundational Learning

- Concept: Cumulants and moment-generating functions
  - Why needed here: The core contribution reformulates softmax entropy via cumulant expansion; understanding how κ₂, κ₃, κ₄... relate to variance, skew, kurtosis is essential.
  - Quick check question: Given a distribution, can you explain why κ₂ = σ² (variance) but κ₄ ≠ E[X⁴]?

- Concept: KL-divergence as a statistical distance
  - Why needed here: The entropy perturbation uses KL-divergence from center distribution; Eq. 3 expands this into cumulants.
  - Quick check question: Why is D_KL(p||q) asymmetric, and what does this imply for choosing the "center"?

- Concept: Probability simplex geometry
  - Why needed here: Logits map to probability distributions on the simplex; cumulants probe how these distributions are positioned relative to the center.
  - Quick check question: If two logit vectors differ by a constant offset, do their softmax probabilities differ?

## Architecture Onboarding

- Component map:
  - Tokenize prompt -> TunedLens -> Extract layer-wise logits -> Compute softmax per token -> Compute center distribution p_μ -> Compute deviations δX_t -> Calculate moments -> Convert to cumulants -> Average across tokens

- Critical path: Tokenize prompt → forward pass with TunedLens → extract layer-wise logits → compute softmax per token → compute center distribution p_μ → compute δX → compute moments → convert to cumulants → average across tokens.

- Design tradeoffs:
  - **Higher cumulant order**: More information but noisier estimates; paper uses up to κ₇.
  - **Token-wise vs aggregate**: Paper aggregates δX across tokens (additive cumulant property); could analyze per-position cumulants for finer granularity.
  - **Temperature β**: Set to 1/T; changing β rescales cumulant contributions (Eq. 3).

- Failure signatures:
  - **All cumulants near zero**: Model not learning higher-order structure (undertrained, shuffled data, or architectural issue).
  - **No differentiation between structured/shuffled**: Model may not use sequential information (position embeddings disabled?).
  - **Unstable high-order cumulants**: Numerical precision issues with Bell polynomial computation for κ₆+.

- First 3 experiments:
  1. **Reproduce structured vs shuffled comparison**: Take 5 prompts from Pile-10K, compute cumulant profiles for original and shuffled versions using GPT-2; verify rise-and-plateau vs flat patterns.
  2. **Layer-wise entropy gap**: Plot mean softmax entropy vs S(μ) across layers for both conditions; confirm widening gap for structured prompts.
  3. **Cross-model scaling**: Run the same analysis on GPT-2 small, medium, large to check if cumulant profiles scale predictably with model size (use Fig. 6 as reference).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can actively manipulating cumulant magnitudes during inference steer the model toward specific outputs or reasoning styles?
- Basis in paper: [explicit] The authors state, "Future research could explore... the causal effects of directly manipulating cumulants."
- Why unresolved: The current work establishes cumulants as *observables* (probes) but does not test their sufficiency or necessity as control knobs for generation.
- What evidence would resolve it: Interventions that clamp or scale specific cumulants (e.g., κ3 or κ4) in intermediate layers, resulting in predictable changes to output accuracy or stylistic traits.

### Open Question 2
- Question: Is there a predictable, quantitative relationship between the saturation of higher-order cumulants and the minimization of validation loss during training?
- Basis in paper: [explicit] The conclusion suggests exploring "the correlation between loss and cumulants."
- Why unresolved: While Figure 3 shows both loss decreases and cumulants increase, the precise functional relationship (e.g., linear, power-law) remains uncharacterized.
- What evidence would resolve it: Scatter plots and regression analysis correlating specific cumulant growth rates against perplexity drops across multiple checkpoints and model scales.

### Open Question 3
- Question: Do non-transformer architectures (e.g., Mamba, RWKV) exhibit the same "rise-and-plateau" cumulant profile for structured context?
- Basis in paper: [inferred] The methodology is applied exclusively to "GPT-2 and Pythia models" (transformers), leaving the universality of the finding unknown.
- Why unresolved: The geometric evolution might be an artifact of the specific residual stream and attention mechanisms in transformers rather than a universal feature of deep learning.
- What evidence would resolve it: Applying the TunedLens cumulant framework to state-space or recurrent models to compare logit geometry evolution.

## Limitations
- Dimensionality assumptions: The theoretical framework assumes cumulants capture meaningful geometric structure in high-dimensional probability simplices, but the effective dimensionality of LLM logits may be much lower than vocabulary size.
- Temperature sensitivity: While β = 1/T is used throughout, the temperature scaling of cumulants is not systematically explored.
- Center distribution validity: The arithmetic mean p_μ assumes token distributions are approximately exchangeable around a common center, but language tokens exhibit strong position-dependent effects.

## Confidence
**High confidence** (experimental validation + theoretical grounding):
- Cumulant expansion mathematically decomposes softmax entropy into higher-order statistical moments
- Structured prompts produce distinct cumulant profiles compared to shuffled prompts in GPT-2
- Training progression shows monotonic increase in all cumulants before saturation

**Medium confidence** (empirical support but theoretical gaps):
- Cumulants quantify "fundamentally different processing mechanisms" between mathematical and general text
- Rise-and-plateau profile reflects meaningful layer-wise feature learning
- Cumulant analysis provides "lightweight, mathematically grounded probe" of learning dynamics

**Low confidence** (novelty limits validation):
- Geometric interpretation of cumulants as probing "feature-learning dynamics" in high-dimensional networks
- Claims about isolating "successively higher-order correlations" without rigorous statistical testing
- Generalization of findings to other model architectures or pretraining objectives

## Next Checks
1. **Cross-dataset validation**: Repeat the structured vs shuffled prompt analysis on multiple datasets (C4, WikiText, Common Crawl) and verify that rise-and-plateau cumulant profiles persist across domains. This tests whether the geometric patterns are fundamental to LLM processing or dataset artifacts.

2. **Temperature sensitivity analysis**: Systematically vary temperature (T = 0.5, 1, 2, 4) and measure how cumulant profiles scale with βⁿ. Plot κₙ/βⁿ to test if the normalized cumulants remain consistent, establishing whether temperature is merely a scaling factor or fundamentally alters the geometric structure being measured.

3. **Position-specific cumulant decomposition**: Instead of averaging δX across tokens, compute cumulants separately for each position (first token, middle tokens, last token). Compare position-specific profiles to the aggregated version to test whether the center distribution assumption obscures position-dependent geometric features that may be crucial for next-token prediction.