---
ver: rpa2
title: Diffusion Classifier Guidance for Non-robust Classifiers
arxiv_id: '2507.00687'
source_url: https://arxiv.org/abs/2507.00687
tags:
- classifier
- guidance
- non-robust
- diffusion
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work extends classifier guidance to non-robust classifiers,
  enabling their use in conditional sampling without retraining on diffusion noise.
  It addresses the challenge of unstable guidance gradients from classifiers not trained
  on diffusion noise.
---

# Diffusion Classifier Guidance for Non-robust Classifiers

## Quick Facts
- arXiv ID: 2507.00687
- Source URL: https://arxiv.org/abs/2507.00687
- Authors: Philipp Vaeth; Dibyanshu Kumar; Benjamin Paassen; Magda Gregorová
- Reference count: 23
- Primary result: Enables non-robust classifiers to guide conditional sampling via EMA-stabilized gradients, achieving >99% accuracy and cFID=13.9 on CelebA

## Executive Summary
This work addresses the challenge of using non-robust classifiers (trained only on clean images) for classifier guidance in diffusion models. Standard classifier guidance fails with non-robust classifiers because their decision boundaries become meaningless under diffusion noise. The authors propose a stabilization method combining one-step denoised image predictions (ˆx(xt)₀) with exponential moving average (EMA) of classifier gradients during the reverse diffusion process. This approach recovers meaningful gradients from non-robust classifiers and maintains stable guidance throughout sampling, achieving performance close to robust classifiers while avoiding the need for noise-augmented training.

## Method Summary
The method extends classifier guidance to non-robust classifiers by computing gradients on one-step denoised predictions rather than noisy intermediates, then stabilizing these gradients using EMA. During the reverse diffusion process, the classifier is applied to ˆx(xt)₀ (the estimated clean image from the diffusion model) to recover meaningful decision boundaries. The gradients are then smoothed across time steps using EMA without de-biasing terms, which biases early guidance toward zero to avoid unreliable high-noise gradients. The stabilized gradients shift the diffusion model's mean prediction according to the guidance scale, enabling effective conditional sampling without retraining classifiers on diffusion noise.

## Key Results
- Non-robust classifiers without stabilization produce no valid samples (FID >100k)
- EMA stabilization with ˆx(xt)₀-prediction achieves >99% target class accuracy on CelebA
- Best setup achieves cFID=13.9 on CelebA, comparable to robust classifier performance
- Method works across multiple datasets: CelebA (64×64, 256×256), SportBalls (64×64)
- Optimal guidance scale exists; too high scales (>150) degrade sample quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Applying classifiers to one-step denoised predictions (ˆx(xt)₀) rather than noisy intermediates recovers meaningful gradients from non-robust classifiers.
- Mechanism: The diffusion model estimates the clean image via ˆx(xt)₀ = (xt/√(ᾱt)) - (√(1-ᾱt)/√(ᾱt))εθ(xt, t). This shifts the classifier's input distribution toward its training domain, restoring accuracy (Figure 1: non-robust + prediction matches robust classifier accuracy).
- Core assumption: The one-step denoised prediction is sufficiently accurate that the classifier's decision boundary remains meaningful.
- Evidence anchors:
  - [abstract] "combined with the one-step denoised image prediction (ˆx(xt)₀) to improve gradient quality"
  - [section 2.4] Figure 1 shows accuracy recovery; Figure 3 shows reduced but not eliminated gradient sensitivity
  - [corpus] "Provably Reliable Classifier Guidance through Cross-entropy Error Control" addresses classifier reliability under guidance

### Mechanism 2
- Claim: Exponential moving average (EMA) of classifier gradients stabilizes guidance by enforcing temporal consistency across diffusion steps.
- Mechanism: Equation 7 (νᵗᵉᵐᵃₜ = βνᵗᵉᵐᵃₜ₋₁ + (1-β)g) accumulates gradients, damping sudden direction changes. Higher β (0.99 vs 0.9) provides stronger smoothing.
- Core assumption: Adjacent diffusion steps should produce similar guidance directions; large fluctuations indicate noise rather than signal.
- Evidence anchors:
  - [abstract] "stabilization techniques inspired by stochastic optimization, particularly exponential moving averages"
  - [section 2.5] Figure 4: EMA (β=0.99) achieves gradient stability (Sg) comparable to robust classifiers for t < 200
  - [corpus] Weak direct precedent; "Enhancing Diffusion Model Guidance through Calibration and Regularization" addresses early-step overconfidence but via different mechanisms

### Mechanism 3
- Claim: Deliberately omitting de-biasing terms in EMA suppresses unreliable early-time gradients.
- Mechanism: Without de-biasing, the initial EMA state biases guidance toward zero during high-noise steps (xT, xT-1, ...), preventing corruption from uninformative gradients.
- Core assumption: Early denoising steps contain insufficient signal for reliable classifier guidance.
- Evidence anchors:
  - [abstract] Not explicitly stated
  - [section 2.5] "We do not include any de-biasing terms... to bias the guidance terms toward zero... avoiding unreliable conditioning information early"
  - [corpus] "Mitigating the Noise Shift" addresses noise-level misalignment during sampling, supporting noise-awareness concerns

## Foundational Learning

- Concept: **DDPM forward/reverse process and noise schedules**
  - Why needed here: Understanding how ᾱt controls noise levels is essential for interpreting ˆx(xt)₀ predictions and when gradients become unreliable.
  - Quick check question: At what fraction of total diffusion steps T does the non-robust classifier accuracy drop to random guessing? (Answer: ~25%, per Figure 1)

- Concept: **Classifier guidance (Equation 1) and the guidance scale trade-off**
  - Why needed here: The mean shift μ'θ(xt) = μθ(xt) + sΣt(xt)∇xt log pcl(y|xt) is the core intervention point; scale s trades off conditioning strength vs. sample quality.
  - Quick check question: What happens when guidance scale exceeds optimal range on CelebA? (Answer: FID increases, cFID eventually increases after turning point)

- Concept: **EMA from stochastic optimization (momentum)**
  - Why needed here: The stabilization mechanism directly borrows from SGD with momentum; understanding β as a smoothing window is critical for hyperparameter selection.
  - Quick check question: Why does β=0.99 outperform β=0.9 for gradient stability? (Answer: Larger window smooths more aggressively across time steps)

## Architecture Onboarding

- Component map:
  DDPM backbone -> Classifier -> Guidance module -> EMA state

- Critical path:
  1. Sample xT ~ N(0, I)
  2. For each t: compute ˆx(xt)₀ via Equation 5 → classifier forward → gradient w.r.t. xt → EMA update → shift mean via Equation 1 → sample xt-1
  3. Return x'₀

- Design tradeoffs:
  - **Guidance scale s**: Higher s improves accuracy but degrades FID; optimal range exists (e.g., s ≈ 150 for CelebA)
  - **EMA β**: 0.99 more stable but may delay conditioning; 0.9 faster response but noisier
  - **Memory**: ˆx(xt)₀ requires backprop through diffusion model at each step (increased memory vs. direct noisy classification)

- Failure signatures:
  - **No stabilization + non-robust classifier**: Process fails completely; diffusion mean offset breaks sampling
  - **ADAM stabilization**: cFID deteriorates at higher t due to variance-based rescaling amplifying differences
  - **Guidance scale too high**: FID and cFID both increase; conditioning overpowers diffusion

- First 3 experiments:
  1. **Reproduce gradient stability curves (Figures 2-4)**: Compute Sl and Sg metrics on validation data to confirm non-robust classifier instability and stabilization effectiveness.
  2. **Ablate stabilization methods**: Compare ˆx(xt)₀ only vs. ˆx(xt)₀ + EMA (β=0.9, 0.99) vs. ADAM on CelebA with fixed guidance scale.
  3. **Guidance scale sweep**: On target dataset, sweep s and plot accuracy, FID, cFID to identify optimal range; compare to robust classifier baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed EMA-based stabilization method be effectively translated to faster, non-Markovian diffusion samplers like DDIM or SDE solvers?
- Basis in paper: [explicit] "Translating our findings to other diffusion reverse samplers is subject to future work."
- Why unresolved: The authors restricted their experimental validation to the standard DDPM reverse process (Markov chain) and did not test if the gradient stabilization holds when the sampling trajectory or step size changes significantly.
- What evidence would resolve it: Experimental results applying the nrCG method to alternative samplers (e.g., DDIM) showing that stabilized gradients remain effective and prevent divergence under different sampling dynamics.

### Open Question 2
- Question: Does the implementation of dynamic guidance schedules (varying the scale or EMA factor over time) outperform the fixed-parameter setups tested in this study?
- Basis in paper: [explicit] "Especially other techniques from stochastic optimization and dynamic guidance schedules will be explored."
- Why unresolved: The current study utilizes fixed guidance scales and stabilization hyperparameters (β) throughout the entire reverse process, potentially leaving performance gains on the table during specific diffusion phases.
- What evidence would resolve it: A comparative study showing that a time-dependent schedule (e.g., increasing/decreasing guidance strength s or β as t → 0) yields better FID or accuracy scores than the static baselines.

### Open Question 3
- Question: Can other stochastic optimization techniques beyond Momentum and ADAM provide
  - Basis in paper: [explicit] "Especially other techniques from stochastic optimization... will be explored."
  - Why unresolved: The study only tests Momentum (EMA) and ADAM as stabilization techniques, leaving other optimization methods unexplored.
  - What evidence would resolve it: Comparative results showing that alternative techniques (e.g., Nesterov momentum, RMSProp) achieve better stability or sample quality than the tested methods.

## Limitations

- **Architecture specificity**: Exact U-Net and MobileNetV3 configurations are not fully specified, requiring access to code repository for faithful reproduction
- **Hyperparameter sensitivity**: Guidance scale values appear empirically tuned without systematic sensitivity analysis across datasets
- **Gradient quality metrics**: Sl and Sg metrics measure mathematical stability but lack validation against human perceptual quality or downstream task performance

## Confidence

- **High confidence**: The core stabilization mechanism (EMA applied to classifier gradients) is technically sound and well-supported by experimental evidence
- **Medium confidence**: The claim that EMA stabilization achieves "close to robust classifier performance" is supported but relies on specific hyperparameter choices
- **Low confidence**: The assertion that ˆx(xt)₀-prediction "recovers meaningful gradients" lacks direct quantitative validation

## Next Checks

1. **Ablation study on EMA window size**: Systematically vary β from 0.9 to 0.999 and measure the trade-off between gradient stability (Sg metric) and sample quality (FID/cFID) to identify optimal smoothing levels.

2. **Cross-dataset generalization test**: Apply the method to a held-out dataset (e.g., LSUN bedroom) with different image statistics and noise schedules to verify the claimed robustness beyond the three tested datasets.

3. **Gradient quality correlation analysis**: Correlate the Sg/Sₗ metrics with human perceptual quality scores and downstream task performance to validate whether these mathematical stability measures predict actual guidance effectiveness.