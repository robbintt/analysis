---
ver: rpa2
title: Mi:dm 2.0 Korea-centric Bilingual Language Models
arxiv_id: '2601.09066'
source_url: https://arxiv.org/abs/2601.09066
tags:
- data
- korean
- training
- language
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Mi:dm 2.0 is a Korea-centric bilingual LLM developed to address
  limitations of existing models in Korean language and cultural understanding. It
  introduces a robust data pipeline with quality filtering, synthetic data generation,
  and curriculum learning, along with a Korean-optimized tokenizer.
---

# Mi:dm 2.0 Korea-centric Bilingual Language Models

## Quick Facts
- arXiv ID: 2601.09066
- Source URL: https://arxiv.org/abs/2601.09066
- Reference count: 40
- Primary result: Korea-centric bilingual LLM with state-of-the-art Korean performance and strong English results

## Executive Summary
Mi:dm 2.0 is a Korea-centric bilingual language model developed to address limitations of existing models in Korean language and cultural understanding. The model features a robust data pipeline with quality filtering, synthetic data generation, and curriculum learning, optimized for Korean language processing. Available in two sizes (11.5B and 2.3B parameters), Mi:dm 2.0 demonstrates state-of-the-art performance on Korean-specific benchmarks and strong results on English benchmarks, while maintaining high safety standards through comprehensive RAI evaluations.

## Method Summary
Mi:dm 2.0 employs a sophisticated data pipeline featuring quality filtering, synthetic data generation, and curriculum learning to optimize Korean language understanding. The model uses a Korean-optimized tokenizer and is available in two configurations: Mi:dm 2.0 Base (11.5B parameters) trained via depth-up scaling, and Mi:dm 2.0 Mini (2.3B parameters) trained through knowledge distillation. The training methodology emphasizes cultural and linguistic specificity for Korean language processing while maintaining bilingual capabilities for English tasks.

## Key Results
- State-of-the-art performance on Korean-specific benchmarks including KMMLU
- Strong results on English language benchmarks
- Top-tier zero-shot performance across tasks
- High Not Unsafe Rates and low Attack Success Rates in safety evaluations

## Why This Works (Mechanism)
The model's effectiveness stems from its Korea-centric design approach, incorporating cultural and linguistic specificity through specialized data curation and training techniques. The bilingual architecture enables seamless language switching while maintaining task performance across both Korean and English. The curriculum learning approach ensures progressive skill development, while the optimized tokenizer improves tokenization efficiency for Korean language patterns.

## Foundational Learning
1. **Curriculum Learning** - Gradually increasing task complexity during training; needed for effective knowledge transfer and prevents catastrophic forgetting; quick check: monitor validation loss curve for expected learning progression
2. **Knowledge Distillation** - Transferring knowledge from larger to smaller models; needed for efficient model scaling; quick check: compare student-teacher performance on representative tasks
3. **Tokenizer Optimization** - Custom tokenization for Korean language patterns; needed for improved language understanding; quick check: measure token efficiency metrics (tokens per character)

## Architecture Onboarding

**Component Map**
Data Pipeline -> Tokenizer -> Training Framework -> Model Architecture (Base/Mini) -> Evaluation Framework -> Safety Testing

**Critical Path**
Data Quality Filtering -> Synthetic Data Generation -> Curriculum Learning -> Model Training -> Safety Validation

**Design Tradeoffs**
- Base model prioritizes performance (11.5B) vs Mini model prioritizes efficiency (2.3B)
- Korean cultural specificity vs bilingual generalization
- Safety robustness vs performance optimization

**Failure Signatures**
- Performance degradation on Korean cultural reasoning tasks
- Safety evaluation failures on RAI benchmarks
- Tokenization inefficiencies for Korean compound words

**First Experiments**
1. Evaluate Korean cultural reasoning task performance vs baseline models
2. Test zero-shot performance on English benchmarks
3. Validate safety evaluation results on Not Unsafe Rate metrics

## Open Questions the Paper Calls Out
None

## Limitations
- Lack of detailed quantitative results in abstract for independent verification
- Absence of statistical significance testing for performance improvements
- Limited comparative baseline data for safety evaluation metrics

## Confidence

| Claim Type | Confidence |
|------------|------------|
| Technical implementation (data pipeline, tokenizer, training) | Medium |
| Performance claims (benchmark scores, KMMLU) | Medium-Low |
| Safety evaluation claims (RAI results) | Medium |

## Next Checks
1. Obtain and verify specific benchmark scores for KMMLU and other Korean/English evaluations with statistical significance testing
2. Request detailed RAI evaluation metrics including Not Unsafe Rate percentages and Attack Success Rate baselines for comparison
3. Validate actual performance of released models through independent testing on Korean cultural reasoning tasks and cross-lingual benchmarks