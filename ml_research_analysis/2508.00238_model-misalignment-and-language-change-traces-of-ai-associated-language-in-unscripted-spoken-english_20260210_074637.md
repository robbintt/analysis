---
ver: rpa2
title: 'Model Misalignment and Language Change: Traces of AI-Associated Language in
  Unscripted Spoken English'
arxiv_id: '2508.00238'
source_url: https://arxiv.org/abs/2508.00238
tags:
- language
- 'false'
- words
- human
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates whether AI language models are influencing
  human language use by analyzing lexical trends in unscripted spoken English from
  science and technology podcasts before and after ChatGPT's 2022 release. Focusing
  on 20 words identified as AI-overused, the researchers found a moderate but significant
  increase in their usage post-2022, while baseline synonyms showed no directional
  shift.
---

# Model Misalignment and Language Change: Traces of AI-Associated Language in Unscripted Spoken English

## Quick Facts
- arXiv ID: 2508.00238
- Source URL: https://arxiv.org/abs/2508.00238
- Reference count: 13
- Primary result: Unscripted spoken English shows significant increase in AI-associated word usage post-2022, suggesting early language change driven by AI exposure

## Executive Summary
This study investigates whether AI language models are influencing human language use by analyzing lexical trends in unscripted spoken English from science and technology podcasts before and after ChatGPT's 2022 release. Focusing on 20 words identified as AI-overused, researchers found a moderate but significant increase in their usage post-2022, while baseline synonyms showed no directional shift. This suggests that human lexical choices are beginning to converge with AI-associated patterns, potentially reflecting early language change driven by AI exposure rather than just tool usage. However, causation remains unclear, as some trends may align with natural language evolution. The findings raise concerns about AI's role in shaping human communication and highlight challenges in linguistic research due to the growing uncertainty of human authorship in written texts.

## Method Summary
The study analyzed 22.1 million words from 17 conversational science and technology podcasts, comparing lexical frequency changes between pre-2022 and post-2022 periods (excluding 2022). Researchers focused on 20 AI-associated words identified in prior literature and 87 baseline synonyms. Transcripts were obtained directly or generated using OpenAI Whisper, then processed with spaCy for lemmatization and POS-tagging. Frequency counts per lemma/POS were converted to occurrences per million (OPM), and log-ratios with Laplace smoothing were computed. Weighted mean log-ratios (inverse variance weighting) were tested against zero using z-tests, with chi-square tests for individual words. The approach aimed to detect convergence between human speech and LLM-associated lexical patterns.

## Key Results
- AI-associated words showed significant frequency increase post-2022 (weighted mean log-ratio = 0.210, z = 3.725, p < 0.001)
- Baseline synonyms showed no significant directional shift (weighted mean log-ratio = 0.033, non-significant)
- Individual word analyses revealed 11 of 20 target words significantly increased, while only 1 of 87 baselines showed significant change
- Words like "delve," "surpass," "boast," and "align" showed the strongest increases

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Repeated exposure to LLM-generated language may cause AI-associated lexical patterns to "seep into" human language production through usage-based entrenchment.
- **Mechanism:** When humans repeatedly encounter specific word choices (e.g., "delve," "surpass") in AI-generated content, these patterns may be subconsciously adopted into their own mental lexicon, even if the words do not reflect their original linguistic preferences. This aligns with usage-based theories where repetition strengthens linguistic representations.
- **Core assumption:** Humans exposed to LLM outputs incorporate observed patterns into their own language production, even in unscripted contexts.
- **Evidence anchors:**
  - [abstract] "suggests a convergence between human word choices and LLM-associated patterns"
  - [Page 7, Broader societal implications] "a word or expression that may not have reflected a speaker's own linguistic preference may nonetheless become part of their language system, simply through repeated exposure"
  - [corpus] Related paper "Exploring the Structure of AI-Induced Language Change in Scientific English" corroborates AI-associated lexical spikes, though in written academic contexts
- **Break condition:** If the target demographic (tech-affine podcast speakers) systematically reduces LLM exposure, the trend should plateau or reverse. The paper notes early 2025 "delve-pushback" in PubMed as potential early signal.

### Mechanism 2
- **Claim:** The observed lexical overrepresentation in LLMs originates from Learning from Human Feedback (LfHF) amplifying stylistic features that do not generalize to all user populations.
- **Mechanism:** During preference learning, human annotators may systematically favor polished, formal-sounding outputs, causing models to overproduce words like "meticulous" or "intricate." These amplified preferences then propagate to users whose own linguistic norms differ.
- **Core assumption:** Assumption: The lexical biases stem from the LfHF training phase specifically, not pretraining corpora alone.
- **Evidence anchors:**
  - [Page 2] "Juzek and Ward (2025) suggest that lexical overuse may similarly arise during this phase"
  - [Page 8, Conclusion] "the overuse of certain words by LLMs is widely believed to stem from the training procedure known as Learning from Human Feedback"
  - [corpus] No direct corpus evidence on LfHF lexical effects; this mechanism remains inferential based on cited literature
- **Break condition:** If models trained without LfHF show similar lexical overuse patterns, the mechanism would shift toward pretraining data artifacts.

### Mechanism 3
- **Claim:** A self-reinforcing feedback loop may form where AI-influenced human language becomes training data for future models, amplifying initial misalignments.
- **Mechanism:** Human language production increasingly incorporates AI patterns; this modified output is scraped as training data; subsequent models further amplify these patterns; humans are exposed to more amplified outputs. This creates a semi-self-contained training loop.
- **Core assumption:** Sufficient AI-generated or AI-influenced text enters future training corpora to shift model distributions.
- **Evidence anchors:**
  - [Page 5-6, Discussion] "today's language production becomes tomorrow's LLM training data, the day after tomorrow's LLM output, and eventually part of the linguistic input humans encounter"
  - [Page 6] cites Hataya, Bao, and Arai (2023); Briesch, Sobania, and Rothlauf (2023); Alemohammad et al. (2023) on self-consuming generative models
  - [corpus] Weak direct evidence; corpus neighbors do not address feedback loop dynamics in language specifically
- **Break condition:** If human language change outpaces model retraining cycles, or if deliberate filtering removes AI-influenced text from training corpora, loop strength diminishes.

## Foundational Learning

- **Concept: Weighted log-ratio analysis for corpus comparison**
  - **Why needed here:** The paper's primary finding relies on comparing word frequency changes across time periods using log ratios weighted by inverse variance. Understanding this statistical approach is necessary to interpret the reported effect size (0.210) and significance.
  - **Quick check question:** Why would a simple mean of percentage changes be inadequate for aggregating frequency shifts across words with vastly different base rates?

- **Concept: Lemmatization and POS-tagging in corpus linguistics**
  - **Why needed here:** The analysis operates on lemmata (base forms) rather than surface tokens, and distinguishes part-of-speech categories to avoid conflating distinct word senses (e.g., "lead" the noun vs. verb).
  - **Quick check question:** Why might analyzing raw word forms instead of lemmata produce misleading frequency estimates for verbs like "delve"?

- **Concept: Human-authorship indeterminacy**
  - **Why needed here:** The paper's central methodological challenge is that written texts can no longer be assumed human-authored. This motivated the focus on unscripted spoken language as a proxy for "genuine" human production.
  - **Quick check question:** Why are unscripted podcasts a better proxy for human language production than academic presentations, even though both are spoken?

## Architecture Onboarding

- **Component map:** Podcast selection -> Audio download/Whisper transcription -> spaCy lemmatization + POS-tagging -> Temporal segmentation (pre/post-2022) -> Frequency counting -> Log-ratio computation -> Weighted aggregation -> z-test + chi-square tests -> Baseline comparison
- **Critical path:** The validity of the entire analysis hinges on the assumption that unscripted podcasts represent genuine human language production. Any undetected scripted segments (promotional interstitials, pre-written questions) contaminate this proxy.
- **Design tradeoffs:**
  - **Dataset scope vs. generalizability:** Focusing on tech/science podcasts increases likelihood of detecting LLM exposure effects but limits claims to that demographic. Rural sermons or non-technical genres likely show different patterns.
  - **Statistical power vs. multiple testing:** 22.1M words provides power for group-level tests, but individual word analyses (20 targets, 87 baselines) require cautious interpretation without strict alpha correction.
- **Failure signatures:**
  - Baseline words showing similar directional shift would suggest broader lexical drift unrelated to AI
  - High variance across podcasts within each time period would indicate insufficient sample consistency
  - Individual word increases concentrated in low-frequency items may reflect noise rather than genuine shift
- **First 3 experiments:**
  1. **Replication with expanded corpus:** Double dataset size (targeting ~44M words) to reduce baseline variance; include non-tech podcasts to test demographic boundary conditions.
  2. **Speaker-level longitudinal tracking:** Where possible, identify individual speakers appearing in both pre- and post-2022 episodes; analyze within-speaker lexical change to control for population shifts.
  3. **Qualitative context analysis:** Manually code usage contexts for significantly increased words (e.g., "surpass," "boast," "align") to determine whether meanings/discourse frames shift alongside frequency, or if AI exposure correlates with semantic narrowing.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Do the observed lexical shifts reflect AI-induced language change or natural linguistic evolution?
- **Basis in paper:** [explicit] The authors state in the abstract and conclusion, "Whether this represents natural language change or a novel shift driven by AI exposure remains an open question."
- **Why unresolved:** Correlation does not imply causation; some words were already trending upward before ChatGPT, and there is no counterfactual scenario where AI did not exist.
- **What evidence would resolve it:** Longitudinal studies tracking specific speakers over time to correlate their degree of LLM exposure with changes in their lexical choices.

### Open Question 2
- **Question:** Do AI-associated lexical shifts in spoken language extend beyond tech-affine demographics to the general population?
- **Basis in paper:** [explicit] The authors acknowledge that their focus on science and technology podcasts means results "likely do not reflect general population trends" and explicitly call for "further research... to explore regional and varietal differences."
- **Why unresolved:** The current dataset is skewed towards speakers in globally oriented, tech-focused discourse who are more likely to be early adopters of AI tools.
- **What evidence would resolve it:** Replication of this frequency analysis on spoken corpora from diverse, non-technological contexts, such as rural sermons or general casual conversation.

### Open Question 3
- **Question:** What micro-level discourse mechanisms explain unexpected word trends, such as the decline of "realm"?
- **Basis in paper:** [explicit] The authors note that "realm" decreased despite being cited as an LLM-associated word and suggest that "extensive qualitative analyses" of contexts and speaker roles are needed to understand such anomalies.
- **Why unresolved:** The current study relies on macro-level frequency analysis (occurrences per million) rather than semantic or contextual inspection of specific instances.
- **What evidence would resolve it:** Qualitative case studies analyzing the specific discourse frames, speaker types, and contextual meanings of outliers like "realm" and "groundbreaking."

## Limitations

- Causation cannot be definitively established; observed patterns may reflect natural language evolution or demographic-specific trends rather than AI influence
- The tech-savvy podcast demographic limits generalizability to broader populations
- Whisper transcription process could introduce systematic biases, though this would affect both periods equally

## Confidence

- **High Confidence:** The statistical finding that AI-associated words show significant frequency increase (0.210, z=3.725, p<0.001) while baseline synonyms do not (0.033, non-significant) is methodologically robust
- **Medium Confidence:** The interpretation that this pattern reflects AI influence rather than natural language change is reasonable but not definitively proven
- **Low Confidence:** The hypothesized mechanisms (usage-based entrenchment, LfHF amplification, feedback loops) remain largely theoretical with limited direct corpus evidence

## Next Checks

1. **Speaker-Level Analysis:** Where individual speaker identities can be tracked across pre- and post-2022 episodes, analyze within-speaker lexical changes to control for population shifts and strengthen causal inference.

2. **Demographic Boundary Testing:** Replicate the analysis on non-technical spoken corpora (e.g., general interest podcasts, religious broadcasts) to determine whether observed patterns are specific to tech-savvy speakers or represent broader language change.

3. **Contextual Usage Analysis:** Manually code usage contexts for significantly increased words to determine whether meanings or discourse frames shift alongside frequency, or if AI exposure correlates with semantic narrowing or register changes.