---
ver: rpa2
title: Dual-Encoder Transformer-Based Multimodal Learning for Ischemic Stroke Lesion
  Segmentation Using Diffusion MRI
arxiv_id: '2512.20436'
source_url: https://arxiv.org/abs/2512.20436
tags:
- segmentation
- lesion
- transunet
- ischemic
- stroke
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of automated segmentation of
  ischemic stroke lesions from multimodal diffusion MRI data, specifically Diffusion-Weighted
  Imaging (DWI) and Apparent Diffusion Coefficient (ADC) scans. The authors propose
  a dual-encoder TransUNet architecture to explicitly model modality-specific representations
  from these inputs, enhanced with adjacent slice information using a three-slice
  input configuration.
---

# Dual-Encoder Transformer-Based Multimodal Learning for Ischemic Stroke Lesion Segmentation Using Diffusion MRI

## Quick Facts
- arXiv ID: 2512.20436
- Source URL: https://arxiv.org/abs/2512.20436
- Authors: Muhammad Usman; Azka Rehman; Muhammad Mutti Ur Rehman; Abd Ur Rehman; Muhammad Umar Farooq
- Reference count: 27
- Primary result: Proposed dual-encoder TransUNet achieves 85.4% Dice Similarity Coefficient on ISLES 2022 test set for ischemic stroke lesion segmentation

## Executive Summary
This paper addresses the challenge of automated segmentation of ischemic stroke lesions from multimodal diffusion MRI data, specifically Diffusion-Weighted Imaging (DWI) and Apparent Diffusion Coefficient (ADC) scans. The authors propose a dual-encoder TransUNet architecture to explicitly model modality-specific representations from these inputs, enhanced with adjacent slice information using a three-slice input configuration. This approach was evaluated on the ISLES 2022 dataset, where the proposed model achieved the highest segmentation accuracy with a Dice Similarity Coefficient of 85.4% on the test set.

## Method Summary
The method involves a dual-encoder TransUNet architecture that processes DWI and ADC modalities through separate CNN encoders, fuses representations at the bottleneck, and applies a transformer module for global context modeling. The model uses three consecutive axial slices per modality (128×128×3×2 input) to incorporate inter-slice continuity. Training employs a two-stage approach with initial encoder freezing for 5 epochs followed by full fine-tuning. The framework is built on PyTorch with FastAI, using the official TransUNet codebase extended for multimodal inputs. Preprocessing includes min-max normalization, spatial cropping using DWI non-zero bounding box, and slice-wise processing with augmentation including flips, rotations, and resizing.

## Key Results
- Dual-encoder TransUNet achieved 85.4% Dice Similarity Coefficient on ISLES 2022 test set
- Three-slice input configuration improved performance to 85.4% compared to 83.1% with single-slice dual-encoder
- Transformer-based models outperformed convolutional baselines in multimodal stroke lesion segmentation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Separating DWI and ADC encoding pathways improves multimodal fusion for stroke lesion segmentation.
- Mechanism: Dual-encoder architecture processes each modality through independent encoders with separate parameters, then fuses representations at the bottleneck. This preserves modality-specific characteristics (DWI captures hyperintense acute ischemia; ADC shows hypointense diffusion restriction) that early channel concatenation may conflate.
- Core assumption: DWI and ADC encode complementary but distinct pathological information that benefits from separate feature extraction before fusion.
- Evidence anchors:
  - [abstract] "a dual-encoder TransUNet architecture is proposed to learn modality-specific representations from DWI and ADC inputs"
  - [section 3.3] "dual-encoder TransUNet...achieved a Dice score of 83.1%, representing a noticeable improvement over the single-encoder baseline"
  - [corpus] Weak direct comparison—neighbor papers emphasize attention and domain adaptation but not dual-encoder fusion specifically.
- Break condition: If DWI and ADC are highly correlated or one modality is noisy/corrupted, separate encoders may overfit to modality-specific artifacts without gaining complementary signal.

### Mechanism 2
- Claim: Hybrid CNN-Transformer architectures capture both local texture and long-range spatial dependencies better than pure CNNs for lesion segmentation.
- Mechanism: TransUNet uses a CNN encoder for local feature extraction, followed by a transformer module that applies self-attention across tokenized feature patches. This enables modeling of global relationships between distant image regions—relevant for irregular, fragmented lesions.
- Core assumption: Stroke lesions exhibit spatially distributed patterns that require non-local context beyond receptive fields of convolutional kernels.
- Evidence anchors:
  - [abstract] "transformer-based models outperform convolutional baselines"
  - [section 3.2] "TransUNet achieved the highest Dice score...improved performance...effectively captures both local texture information and long-range contextual dependencies"
  - [corpus] "Generalizable automated ischaemic stroke lesion segmentation with vision transformers" corroborates transformer advantages for this task.
- Break condition: If lesions are uniformly small and localized, transformer overhead may not justify marginal gains; CNNs with sufficient depth could suffice.

### Mechanism 3
- Claim: Incorporating adjacent slice context improves boundary delineation for fragmented or small infarcts.
- Mechanism: Three consecutive axial slices per modality are stacked as input (128×128×3×2), providing limited inter-slice continuity without full 3D volume processing. The encoder implicitly learns z-direction coherence, aiding segmentation of lesions spanning multiple slices.
- Core assumption: Ischemic lesions exhibit anatomical continuity across adjacent slices that informs boundary estimation.
- Evidence anchors:
  - [abstract] "adjacent slice information is integrated using a three-slice input configuration"
  - [section 3.4] "three-slice dual-encoder TransUNet achieved...Dice score of 85.4%...underscoring the importance of inter-slice continuity for accurate lesion boundary delineation"
  - [corpus] No direct neighbor comparison on multi-slice strategies; evidence is paper-internal.
- Break condition: If slice thickness is large or inter-slice gaps exist, adjacent slices may not provide meaningful context; could introduce noise.

## Foundational Learning

- **TransUNet architecture**
  - Why needed here: The paper extends TransUNet; understanding its CNN encoder → transformer → CNN decoder flow is prerequisite to modifying encoder structure.
  - Quick check question: Can you explain how TransUNet tokenizes CNN feature maps for transformer input and reconstructs spatial resolution in the decoder?

- **Multimodal medical imaging fusion strategies**
  - Why needed here: The paper compares early fusion (channel concatenation) vs. late fusion (bottleck fusion); distinguishing these is essential for architectural decisions.
  - Quick check question: What is the difference between early fusion and late fusion in multimodal networks, and what are their tradeoffs?

- **Dice Similarity Coefficient**
  - Why needed here: Primary evaluation metric; interpreting DSC values is necessary to assess model performance and compare variants.
  - Quick check question: How does DSC penalize false positives vs. false negatives, and why is it preferred over pixel accuracy for imbalanced segmentation?

## Architecture Onboarding

- **Component map**: Input layer (128×128×3×2 tensor) -> Dual encoders (two parallel CNN backbones for DWI and ADC) -> Fusion point (bottleneck concatenation) -> Transformer module (self-attention over tokenized features) -> Decoder (upsampling CNN with skip connections) -> Output (binary segmentation mask)

- **Critical path**: 
  1. Preprocess DWI/ADC volumes → min-max normalize, crop to non-zero regions, extract three-slice stacks
  2. Feed each modality through its dedicated encoder
  3. Fuse encoder outputs at bottleneck
  4. Pass fused features through transformer for global context
  5. Decode to segmentation mask with skip connections

- **Design tradeoffs**:
  - Dual-encoder vs. single-encoder: +1.8% DSC gain but 2× encoder parameters
  - Three-slice vs. single-slice: +2.3% DSC gain but 3× input channels and memory
  - TransUNet vs. Swin-UNet: +4.9% DSC gain; TransUNet selected despite Swin efficiency claims

- **Failure signatures**:
  - Dice stuck at ~70–75%: Check modality alignment, ensure DWI/ADC spatial registration
  - Over-segmentation of background: May indicate insufficient modality separation—try dual-encoder
  - Poor boundary delineation: Consider adding adjacent slice context or increasing input resolution
  - Training instability with frozen encoder: Reduce initial learning rate or extend warmup phase

- **First 3 experiments**:
  1. Replicate single-encoder TransUNet baseline with early fusion (target: ~81% DSC) to validate preprocessing pipeline.
  2. Ablate dual-encoder vs. single-encoder with identical training settings to isolate architectural contribution.
  3. Sweep slice context (1 vs. 3 vs. 5 slices) to identify optimal z-axis context window before diminishing returns.

## Open Questions the Paper Calls Out

- Does the proposed dual-encoder architecture maintain high segmentation performance when applied to external clinical cohorts with different scanner protocols?
  - Basis in paper: [explicit] The conclusion states future work will focus on "evaluating model generalizability across external cohorts."
  - Why unresolved: The current study evaluated the model exclusively on the ISLES 2022 dataset, which may not fully represent the heterogeneity of scanner parameters and acquisition settings found in broader clinical practice.
  - Evidence: Quantitative performance metrics (Dice Similarity Coefficient) reported on independent, multi-center datasets distinct from the ISLES 2022 training data.

- To what extent does migrating from the 2.5D slice-wise framework to a full volumetric 3D architecture impact segmentation accuracy?
  - Basis in paper: [explicit] The authors list "extending the proposed approach to full volumetric segmentation" as a direction for future work.
  - Why unresolved: This study utilized a three-slice input configuration (2.5D) to balance computational efficiency with spatial context; the potential performance gains or trade-offs of using complete 3D volumes remain unquantified.
  - Evidence: A comparative study benchmarking the proposed 2.5D model against a 3D volumetric implementation on the same dataset.

- Does the inclusion of FLAIR or perfusion MRI modalities yield significant improvements over the current DWI-ADC combination?
  - Basis in paper: [explicit] The paper suggests "incorporating additional imaging modalities such as FLAIR or perfusion MRI" in future research.
  - Why unresolved: The current framework is optimized for the specific complementary relationship between DWI and ADC; the marginal benefit of integrating additional tissue contrast mechanisms has not been tested.
  - Evidence: Experimental results comparing the current model's performance against a modified version trained with FLAIR or perfusion inputs.

## Limitations
- Three-slice input strategy assumes anatomical continuity across slices, which may not hold for very thin or thick slice acquisitions
- Fixed 200/50 train/test split without reporting variance across multiple runs limits statistical confidence
- Specific contribution of each modality to performance gains is not isolated through ablation studies

## Confidence
- **High confidence**: TransUNet architecture outperforms CNN baselines; three-slice context improves segmentation accuracy; dual-encoder design yields measurable DSC improvement over single-encoder
- **Medium confidence**: Modality-specific encoding provides meaningful information gain (limited ablation evidence); adjacent slice integration benefits boundary delineation (no cross-study validation)
- **Low confidence**: Relative performance claims against Swin-UNet (single comparison); generalizability to other stroke imaging protocols or datasets (no external validation)

## Next Checks
1. **Ablation study**: Train single-encoder variants with early vs. late fusion on identical data splits to quantify dual-encoder contribution independent of other architectural changes

2. **Cross-dataset validation**: Evaluate the trained model on an independent acute/sub-acute stroke dataset (e.g., ISLES 2015) to assess generalizability beyond the ISLES 2022 cohort

3. **Parameter sensitivity analysis**: Systematically vary the number of adjacent slices (1, 3, 5, 7) and quantify DSC improvements to determine optimal z-axis context window before diminishing returns