---
ver: rpa2
title: A Comprehensive Evaluation Framework for Synthetic Trip Data Generation in
  Public Transport
arxiv_id: '2510.24375'
source_url: https://arxiv.org/abs/2510.24375
tags:
- data
- synthetic
- privacy
- real
- utility
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study introduces a comprehensive Representativeness-Privacy-Utility\
  \ (RPU) framework to evaluate synthetic public transport trip data generation. The\
  \ framework assesses data quality across three dimensions\u2014representativeness,\
  \ privacy, and utility\u2014and three hierarchical levels: record, group, and population."
---

# A Comprehensive Evaluation Framework for Synthetic Trip Data Generation in Public Transport

## Quick Facts
- **arXiv ID:** 2510.24375
- **Source URL:** https://arxiv.org/abs/2510.24375
- **Reference count:** 17
- **Primary Result:** CTGAN emerges as the most balanced model for synthetic public transport trip data, offering strong performance across representativeness, privacy, and downstream utility metrics.

## Executive Summary
This paper introduces the Representativeness-Privacy-Utility (RPU) framework to evaluate synthetic public transport trip data generation. The framework assesses data quality across three dimensions—representativeness, privacy, and utility—and three hierarchical levels: record, group, and population. Twelve generative models, including statistical, deep generative, and privacy-enhanced approaches, were benchmarked using real-world smart card data. Results revealed no single model excels across all dimensions, highlighting inherent trade-offs between privacy and utility. CTGAN emerged as the most balanced model, offering strong performance across representativeness, privacy, and downstream task utility.

## Method Summary
The study benchmarks 12 generative models (Bayesian Networks, Gaussian Mixture Models, CTGAN, TVAE, diffusion models, privacy-enhanced variants, and LLMs) using real-world Hong Kong MTR Octopus card data. The RPU framework evaluates synthetic data at record, group, and population levels across three dimensions: representativeness (distributional similarity), privacy (protection against inference attacks), and utility (downstream task performance). Data is preprocessed with one-hot encoding for categoricals and min-max normalization for continuous features. Each model generates synthetic data of equal size to the training set, which is then evaluated using metrics including Kullback-Leibler divergence, JSD, EMD, MIA scores, k-NN distances, and TSTR evaluation with Gradient Boosting Regressor. Results are normalized to enable cross-model comparison.

## Key Results
- No single model achieves optimal performance across all RPU dimensions, confirming inherent trade-offs
- CTGAN demonstrates the most balanced performance across representativeness, privacy, and utility metrics
- Privacy-enhanced models (Priv-BN, PATE-GAN) significantly improve privacy protection but sacrifice representativeness and utility
- Diffusion models struggle with one-hot encoded categorical features, ranking lowest overall
- LLMs achieve high representativeness but exhibit relatively low downstream utility

## Why This Works (Mechanism)

### Mechanism 1: The Privacy-Utility Trade-off via Noise Injection
Formal Differential Privacy mechanisms function by injecting calibrated noise into the learning process, obscuring individual contributions to prevent memorization. This noise simultaneously perturbs the fine-grained joint distributions and correlations required for high-fidelity modeling and accurate downstream prediction. The noise scale required to satisfy meaningful privacy budgets is significant enough to disrupt complex, non-linear dependencies present in public transport trip data.

### Mechanism 2: Hierarchical Decomposition of Evaluation
Aggregate metrics can mask local failures. A synthetic dataset might match global trip histograms perfectly while failing to reproduce specific travel patterns of minority groups or inadvertently reproducing unique individual trajectories. The RPU framework forces evaluation at Record, Group, and Population levels to expose these blind spots, as statistical similarity at one level does not correlate perfectly with similarity at other levels.

### Mechanism 3: Conditional Generation for Tabular Complexity
Deep generative models designed specifically for tabular data (like CTGAN) outperform general-purpose models because they condition on data modes to handle mixed data types and non-Gaussian distributions. Standard GANs struggle with the non-continuous, multi-modal nature of tabular trip data (e.g., distinct station IDs combined with continuous timestamps). CTGAN uses conditional generation and mode-specific training logic to navigate discrete and complex distributions, reducing mode collapse where other models fail.

## Foundational Learning

- **Concept: Generative Adversarial Networks (GANs) vs. Variational Autoencoders (VAEs)**
  - Why needed here: The paper benchmarks these two dominant deep learning architectures. Understanding the difference between learning via an adversarial game (GAN/CTGAN) versus variational inference/reconstruction (VAE/TVAE) is necessary to interpret benchmark results.
  - Quick check question: Does a GAN optimize a minimax game between a generator and discriminator, or does it maximize a variational lower bound on the data log-likelihood?

- **Concept: Differential Privacy (DP) and the Privacy Budget (ε)**
  - Why needed here: To understand the mechanics of the "Privacy-Enhanced" models (Priv-BN, PATE-GAN) and why they inevitably trade off utility.
  - Quick check question: If ε → 0, does the privacy protection increase or decrease, and what typically happens to data accuracy?

- **Concept: Membership Inference Attacks (MIA)**
  - Why needed here: This is the primary metric for Record-Level Privacy in the paper. You must understand that MIA tests if an attacker can distinguish if a specific record was used in training.
  - Quick check question: In the paper's MIA setup, is the attacker trying to predict if a record belongs to the "training" class or the "holdout" class?

## Architecture Onboarding

- **Component map:** Preprocessing -> Generators (12 models) -> RPU Evaluator (3x3 metrics)
- **Critical path:**
  1. Split Data: Strictly separate Training, Holdout (for MIA), and Test sets
  2. Generate: Train a candidate model (e.g., CTGAN) and generate synthetic dataset equal to real set size
  3. Evaluate: Run RPU pipeline computing validity, distributional metrics, MIA scores, and TSTR utility
- **Design tradeoffs:**
  - Encoding vs. Architecture: One-hot encoding hampers Diffusion models (expect continuous spaces)
  - BN vs. CTGAN: Bayesian Networks are interpretable and safe but may miss complex non-linear correlations; CTGAN captures complexity but is a black box with higher computational cost
  - Privacy vs. Utility: You cannot maximize both simultaneously; must select operating point on trade-off curve
- **Failure signatures:**
  - Low Record-Level Representativeness: Synthetic trips violate logical constraints (e.g., negative trip duration)
  - High MIA Score: Synthetic data distribution overlaps almost perfectly with training data (memorization)
  - Diffusion Model Collapse: Generated categorical variables are invalid or "blurry" due to one-hot encoding mismatch
- **First 3 experiments:**
  1. Baseline Validation: Replicate BN vs. CTGAN comparison to verify setup reproduces CTGAN's better balance
  2. Privacy Stress Test: Implement MIA targeting rare subgroups to see if group-level privacy degrades faster than population-level
  3. Utility Task Specifics: Run TSTR using specific downstream task (e.g., trip duration prediction) to quantify utility loss

## Open Questions the Paper Calls Out

- **Hybrid Architectures**: Can integrating statistical constraints into deep generative models achieve superior RPU trade-offs compared to CTGAN?
- **Sensitive Attributes**: Do model rankings remain consistent when applied to transport datasets containing highly sensitive socioeconomic attributes?
- **LLM Utility Gap**: Why do LLMs achieve high representativeness but low downstream utility despite accurate distributional matching?
- **Diffusion Model Encoding**: Does adoption of embedding layers over one-hot encoding improve diffusion model performance in this framework?

## Limitations
- Evaluation relies on specific hyperparameter settings for generative models that are not fully disclosed
- Choice of downstream task (trip duration prediction) may not generalize to all public transport applications
- Privacy assessment using MIA and k-NN distance assumes these methods capture all realistic attack scenarios
- Validation limited to one dataset and transportation domain

## Confidence
- **High Confidence**: The existence of privacy-utility trade-offs in synthetic data generation
- **Medium Confidence**: CTGAN's superior balance of RPU metrics (results may depend on specific task and hyperparameters)
- **Medium Confidence**: The RPU framework's comprehensiveness (validation limited to one dataset and domain)

## Next Checks
1. **Hyperparameter Sensitivity Analysis**: Systematically vary key parameters (e.g., learning rate, network depth, privacy budget) for CTGAN and Priv-BN to assess robustness of RPU rankings
2. **Cross-Domain Applicability**: Apply the RPU framework to synthetic generation for a different transportation mode (e.g., bus networks) to test generalizability
3. **Advanced Privacy Attack Testing**: Implement membership inference attacks beyond k-NN distance and Random Forest classification to stress-test privacy claims, particularly for group-level protection