---
ver: rpa2
title: 'When Sharpening Becomes Collapse: Sampling Bias and Semantic Coupling in RL
  with Verifiable Rewards'
arxiv_id: '2601.15609'
source_url: https://arxiv.org/abs/2601.15609
tags:
- collapse
- sampling
- sharpening
- policy
- modes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# When Sharpening Becomes Collapse: Sampling Bias and Semantic Coupling in RL with Verifiable Rewards

## Quick Facts
- arXiv ID: 2601.15609
- Source URL: https://arxiv.org/abs/2601.15609
- Reference count: 40
- Key outcome: RLVR suffers from over-sharpening (premature collapse onto limited reasoning modes), mitigated by Inverse-success Advantage Calibration (IAC) and Distribution-Level Calibration (DLC)

## Executive Summary
This paper identifies "over-sharpening" as a critical failure mode in Reinforcement Learning with Verifiable Rewards (RLVR), where policies prematurely collapse onto limited reasoning modes, suppressing valid alternatives. The authors demonstrate that finite-batch sampling bias and semantic coupling between related queries propagate this collapse globally across datasets. They propose two calibration techniques—Inverse-success Advantage Calibration (IAC) and Distribution-Level Calibration (DLC)—that re-weight advantages and reshape rollout distributions to preserve entropy and improve generalization on complex reasoning tasks.

## Method Summary
The paper addresses over-sharpening in RLVR by introducing two calibration methods: IAC re-weights positive advantages inversely to query success rates, while DLC uses a memory network to track and reshape rollout distributions. Both techniques aim to stabilize the partition function Z'(q) that normalizes probabilities during finite-batch updates. The methods are evaluated on DeepScaleR with Qwen3 models, showing improved PASS@8 and AVG@8 scores on mathematical reasoning benchmarks compared to standard GRPO and entropy-based baselines.

## Key Results
- IAC achieves +6.2% PASS@8 on DeepScaleR and +9.5% on MATH500 compared to DAPO baseline
- IAC improves generalization, reaching +11.5% on O-Bench (out-of-distribution)
- DLC shows marginal gains over IAC but introduces ~5× higher rollout latency due to memory network overhead
- IAC effectively delays entropy collapse, maintaining ~0.20-0.24 nats vs. baseline collapse to ~0.08 nats

## Why This Works (Mechanism)

### Mechanism 1: Finite-Batch Sampling Bias
Finite-batch updates bias learning toward sampled modes, suppressing correct but unsampled reasoning paths. When the model is confident (Δπ > 0), the batch partition function Z'(q) exceeds 1, scaling down probabilities of unsampled modes. This "forgetting" of valid alternatives is theoretically proven in Theorem 3.3 and empirically validated in toy softmax experiments.

### Mechanism 2: Semantic Coupling
Collapse propagates globally because gradient updates for one query disproportionately affect semantically related queries via shared model parameters. Using NTK approximation, updates intended for query q induce logit shifts in related query q'. When gradients for correct modes are aligned (Assumption 3.1), over-sharpening at q' is promoted when seen modes receive significantly larger logit increases than unseen modes.

### Mechanism 3: Inverse-Success Advantage Calibration (IAC)
IAC re-weights the advantage function inversely to query success rate, stabilizing Z'(q) and mitigating over-sharpening. It scales positive advantages by (G - |S₊|)ᵅ, down-weighting "easy" queries that contribute most to partition function inflation. This preserves signal from difficult queries while preventing uniform suppression of unsampled modes.

## Foundational Learning

- **Concept: KL-regularized Optimization & Partition Functions**
  - Why needed here: Core theoretical contribution relies on deriving optimal policy π* and batch approximation π̂ using Lagrange multipliers and partition functions Z(q). Understanding how Z(q) normalizes probabilities is essential for grasping "suppression via scaling" mechanism.
  - Quick check question: In the standard RLVR objective E[A] - βD_KL, does the partition function Z(q) increase or decrease the probability of modes not explicitly weighted by the advantage?

- **Concept: Neural Tangent Kernel (NTK) Regime**
  - Why needed here: Section 3.3 uses NTK approximation to prove how gradients align and propagate collapse, requiring viewing LLM as kernel machine in infinite-width limit rather than just function approximator.
  - Quick check question: How does the assumption ∇θf(q)ᵀ∇θf(q') ≈ ηK(q,q') imply that training on query q affects logits of query q'?

- **Concept: Mode Collapse vs. Entropy Collapse**
  - Why needed here: Paper redefines entropy collapse as asymptotic limit of "over-sharpening," distinguishing between low entropy (confidence) and loss of diverse valid reasoning paths (over-sharpening).
  - Quick check question: Is it possible to have high entropy while still experiencing over-sharpening? (Hint: Yes, if probability mass concentrates on incorrect modes or single correct mode while noise exists elsewhere).

## Architecture Onboarding

- **Component map:**
  Policy πθ (LLM) -> Reference πref (frozen checkpoint) -> Advantage Calculator -> IAC Scaler -> Update mechanism
  Optional: Memory Network mφ -> DLC Logit Calibration -> Policy πθ

- **Critical path:**
  1. Rollout: Sample G responses per query
  2. Verify: Calculate raw rewards (e.g., binary reward 0/1 centered by mean)
  3. Count: Determine success count |S₊| per query group
  4. Calibrate (IAC): Scale advantages: Ã = A · (G - |S₊|)ᵅ
  5. Update: Apply GRPO/Reinforce++ update with calibrated advantages
  *(DLC adds pre-rollout step where memory logits are subtracted from policy logits)*

- **Design tradeoffs:**
  - IAC vs. Filtering: IAC re-weights all data, preserving signal from easy queries; hard filtering reduces training distribution size and can destabilize convergence on easy tasks
  - DLC Overhead: Introduces ~5× higher rollout latency due to lack of kernel-level support for synchronized multi-model sampling

- **Failure signatures:**
  - Excessive Collapse: Accuracy saturates early; entropy drops to near zero (e.g., < 0.1 nats)
  - IAC Over-correction (α too high): Performance on easy benchmarks (GSM8K) degrades while hard benchmarks improve
  - DLC Memory Drift: If memory network mφ trains too fast, it might suppress correct modes aggressively

- **First 3 experiments:**
  1. Implement 2-superclass classifier (Section 3.4/Figure 1) to confirm raw advantages collapse rapidly while IAC delays or prevents collapse
  2. Train on DeepScaleR subset, sweep α ∈ [0, 2] to find optimal calibration (α ≈ 1.0 suggested), plot entropy vs. accuracy
  3. Integrate IAC into DAPO baseline to verify "inverse-success" weighting is additive to existing entropy clipping mechanisms

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Is over-sharpening an inevitable byproduct of advancing model performance, or merely a structural artifact of algorithmic bias?
- Basis in paper: [explicit] Introduction states "it remains unclear whether over-sharpening is an inevitable byproduct of advancing model performance or a structural artifact of algorithmic bias"
- Why unresolved: While calibrations mitigate collapse caused by sampling bias, paper doesn't prove suppression of unsampled modes (Δπ > 0 in Theorem 3.3) is entirely separable from maximizing confidence on solved queries
- What evidence would resolve it: Theoretical bounds or empirical scaling laws demonstrating entropy preservation via calibration doesn't impose penalty on upper bound of final performance on complex reasoning tasks

### Open Question 2
- Question: Do gradient alignment and diagonal dominance assumptions used to model semantic coupling hold across diverse model architectures and non-reasoning domains?
- Basis in paper: [inferred] Analysis relies on Assumption 3.1 (gradient alignment) and Assumption 3.3 (diagonal dominance), empirically validated only on small dense model (Qwen3-0.6B) using GSM8K in Appendix F
- Why unresolved: Relies on specific NTK properties to derive collapse propagation; if properties are weaker or inverted in other architectures or domains, semantic coupling mechanism may differ significantly
- What evidence would resolve it: Empirical measurement of kernel properties K_qq and gradient correlations across diverse architectures (e.g., MoE) and tasks (e.g., coding/creative writing)

### Open Question 3
- Question: Can negative samples containing partially correct reasoning be effectively calibrated for learning, rather than being excluded to maintain stability?
- Basis in paper: [inferred] Section 4.1 states IAC leaves negative advantages untouched, noting "Negative samples often contain partially correct reasoning segments... Over-amplifying their (negative) advantages can therefore destroy useful intermediate structure"
- Why unresolved: Decision to exclude negative samples from calibration is heuristic to avoid instability; leaves open whether "partially correct" information could improve reasoning robustness if weighted correctly
- What evidence would resolve it: Development of robust negative-advantage calibration mechanism that statistically improves performance over "leave untouched" baseline without increasing gradient variance

## Limitations
- Theoretical framework relies heavily on idealized assumptions (infinite-width NTK regime, perfect logit separation, exact batch partition function knowledge)
- Empirical validation limited to DeepScaleR and six benchmarks with Qwen3 models only, leaving generalization to other RLVR tasks and model families uncertain
- Memory network implementation in DLC minimally specified, raising reproducibility and practical overhead concerns

## Confidence
- **High Confidence:** Existence of over-sharpening in RLVR and its mitigation by IAC (supported by multiple ablation studies showing consistent entropy preservation and accuracy gains)
- **Medium Confidence:** Theoretical mechanism of finite-batch sampling bias causing mode suppression via partition function inflation (Theorem 3.3 provides mathematical proof, but practical magnitude depends on unverifiable assumptions)
- **Low Confidence:** Semantic coupling mechanism via NTK bounds (relies on specific alignment assumptions and simplified network dynamics that may not hold in practical LLMs)

## Next Checks
1. **Ablation on Sampling Frequency:** Run IAC with varying G (4, 8, 16 responses per query) to empirically test predicted relationship between batch size and collapse severity. Plot entropy/accuracy curves across different G values.

2. **Semantic Coupling Isolation:** Design controlled experiment where semantically related queries are deliberately clustered or separated in batch. Measure whether IAC's effectiveness correlates with semantic proximity, directly testing coupling hypothesis.

3. **Cross-Task Transferability:** Apply IAC to non-mathematical RLVR task (e.g., code generation with execution rewards, or fact verification). Compare performance against baselines to assess whether mechanism is task-specific or general to verifiable rewards.