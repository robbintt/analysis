---
ver: rpa2
title: Aggregating Low Rank Adapters in Federated Fine-tuning
arxiv_id: '2501.06332'
source_url: https://arxiv.org/abs/2501.06332
tags:
- federated
- learning
- lora
- training
- fine-tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces FRA-LoRA, a novel aggregation method for federated
  fine-tuning of large language models using Low-Rank Adaptation (LoRA). Traditional
  Federated Averaging (FedAvg) introduces errors when averaging LoRA adapters due
  to the non-linear nature of the product of adapter matrices.
---

# Aggregating Low Rank Adapters in Federated Fine-tuning

## Quick Facts
- arXiv ID: 2501.06332
- Source URL: https://arxiv.org/abs/2501.06332
- Authors: Evelyn Trautmann; Ian Hales; Martin F. Volk
- Reference count: 34
- Primary result: FRA-LoRA achieves 94.95% accuracy on SST2 vs 94.84% for FedAvg and 94.72% for FFA-LoRA

## Executive Summary
This paper addresses a fundamental problem in federated learning of large language models: the incompatibility between traditional Federated Averaging (FedAvg) and Low-Rank Adaptation (LoRA) adapters. When averaging LoRA adapters using FedAvg, errors are introduced due to the non-linear nature of the product of adapter matrices. The proposed FRA-LoRA method directly averages the full weight increments and then performs low-rank decomposition using Singular Value Decomposition (SVD) to obtain the aggregated adapters. This approach shows improved accuracy in early training stages, particularly with small numbers of clients and balanced datasets.

## Method Summary
FRA-LoRA introduces a novel aggregation method that resolves the mathematical incompatibility between FedAvg and LoRA. Traditional FedAvg averages LoRA adapter matrices (A and B) directly, but this introduces errors because the final adapted weights depend on the non-linear product AB. FRA-LoRA instead computes the full weight increments from each client, averages these increments, and then applies SVD to decompose the averaged increment back into low-rank adapters. This preserves the mathematical properties of LoRA while maintaining the benefits of federated aggregation. The method is evaluated on GLUE benchmark tasks using RoBERTa-large as the base model.

## Key Results
- On SST2 dataset: FRA-LoRA achieves 94.95% accuracy vs 94.84% (FedAvg) and 94.72% (FFA-LoRA)
- On MNLI dataset: FRA-LoRA shows 85.37% accuracy vs 85.30% (FedAvg) and 85.24% (FFA-LoRA)
- FRA-LoRA demonstrates faster convergence in early training stages, particularly with small client counts (2-4 clients)
- The method maintains compatibility with Differential Privacy mechanisms

## Why This Works (Mechanism)
The mathematical foundation of FRA-LoRA addresses a fundamental issue in federated LoRA training. In standard LoRA, the adapted weights are computed as W' = W + AB, where A and B are low-rank matrices. When using FedAvg, averaging A and B separately breaks this relationship because (A₁ + A₂)(B₁ + B₂) ≠ A₁B₁ + A₂B₂. FRA-LoRA circumvents this by computing the full weight increments (AB) from each client, averaging these increments directly, and then applying SVD to find the optimal low-rank decomposition of the averaged increment. This preserves the mathematical structure while enabling proper federated aggregation.

## Foundational Learning
**Federated Learning**: Distributed training where multiple clients collaborate without sharing raw data. Why needed: Enables privacy-preserving model training across decentralized data sources. Quick check: Verify understanding of client-server architecture and aggregation mechanisms.

**Low-Rank Adaptation (LoRA)**: Parameter-efficient fine-tuning method using low-rank matrix decomposition. Why needed: Reduces computational cost when adapting large models to new tasks. Quick check: Understand how LoRA matrices A and B approximate weight updates.

**Singular Value Decomposition (SVD)**: Matrix factorization technique decomposing a matrix into three components. Why needed: Enables reconstruction of low-rank structure from averaged weight increments. Quick check: Verify ability to interpret SVD outputs and rank selection.

**GLUE Benchmark**: Collection of natural language understanding tasks for evaluating models. Why needed: Standard evaluation framework for NLP models. Quick check: Review task definitions and evaluation metrics for MNLI and SST2.

**Differential Privacy**: Framework for quantifying and limiting information leakage in data analysis. Why needed: Ensures individual data privacy in federated learning systems. Quick check: Understand basic concepts of privacy budgets and noise addition.

## Architecture Onboarding

**Component Map**: Clients (with local LoRA adapters) -> Server (aggregates increments via SVD) -> Global model (with aggregated adapters)

**Critical Path**: Local training -> Weight increment computation -> Server aggregation via SVD -> Adapter reconstruction -> Global model update

**Design Tradeoffs**: FRA-LoRA trades additional computation (SVD) at the server for improved mathematical correctness and accuracy. This contrasts with simpler FedAvg averaging that is computationally cheaper but mathematically incorrect for LoRA. The method also enables DP integration but requires careful rank selection to balance approximation error and computational cost.

**Failure Signatures**: Poor performance may indicate insufficient rank in SVD decomposition, numerical instability in averaging large weight increments, or suboptimal learning rates during local training. Accuracy degradation compared to FedAvg could suggest the SVD approximation is too lossy for the given task.

**First 3 Experiments**:
1. Replicate the SST2 results comparing FRA-LoRA against FedAvg and FFA-LoRA with identical hyperparameters
2. Test rank sensitivity by varying SVD rank and measuring accuracy trade-offs
3. Evaluate convergence speed differences across the three methods in early training stages

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Evaluation limited to only two GLUE benchmark tasks (MNLI and SST2), restricting generalizability
- Performance improvements are modest (less than 0.2% accuracy gain on SST2), suggesting incremental rather than transformative benefits
- Computational overhead from SVD decomposition during aggregation is not quantified or compared to baseline methods
- Behavior under highly non-IID data distributions and heterogeneous client scenarios is not thoroughly explored

## Confidence
- **High confidence**: The mathematical formulation of FRA-LoRA and its distinction from traditional FedAvg aggregation is sound and well-explained
- **Medium confidence**: The empirical results showing modest accuracy improvements are reproducible given the described methodology, but generalizability remains uncertain
- **Low confidence**: Claims about Differential Privacy compatibility are asserted but not empirically validated in the paper

## Next Checks
1. Test FRA-LoRA across diverse NLP tasks beyond GLUE, including question answering and summarization, to assess generalizability
2. Evaluate computational overhead of SVD decomposition during aggregation and compare total training time against baseline methods
3. Conduct experiments under highly non-IID data distributions to assess robustness in realistic federated learning scenarios