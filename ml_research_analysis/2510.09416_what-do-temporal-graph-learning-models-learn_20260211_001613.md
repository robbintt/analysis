---
ver: rpa2
title: What Do Temporal Graph Learning Models Learn?
arxiv_id: '2510.09416'
source_url: https://arxiv.org/abs/2510.09416
tags:
- edges
- graph
- learning
- temporal
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper systematically evaluates how well seven state-of-the-art
  temporal graph learning models learn eight fundamental graph properties, including
  temporal granularity, direction, density, persistence, periodicity, recency, homophily,
  and preferential attachment. The authors use both synthetic and real-world datasets
  to test models like DyGFormer, DyRep, GraphMixer, JODIE, TCL, TGAT, and TGN.
---

# What Do Temporal Graph Learning Models Learn?

## Quick Facts
- **arXiv ID**: 2510.09416
- **Source URL**: https://arxiv.org/abs/2510.09416
- **Reference count**: 40
- **Primary result**: Seven temporal graph learning models fail to capture fundamental properties like edge direction and recency while succeeding at preferential attachment learning

## Executive Summary
This paper systematically evaluates seven state-of-the-art temporal graph learning models on their ability to learn fundamental graph properties beyond standard link prediction accuracy. The authors test models including DyGFormer, DyRep, GraphMixer, JODIE, TCL, TGAT, and TGN on eight properties: temporal granularity, direction, density, persistence, periodicity, recency, homophily, and preferential attachment. Using both synthetic and real-world datasets, the study reveals critical limitations in current temporal graph models, particularly their inability to distinguish edge direction, calibrate predicted graph density, or capture recent interactions effectively. The findings highlight the need for more interpretable evaluation frameworks and point to specific architectural improvements needed in future temporal graph learning research.

## Method Summary
The study evaluates seven temporal graph learning models on their ability to capture fundamental graph properties rather than just link prediction accuracy. Models are tested on both empirical datasets (Enron, UCI, Wikipedia) discretized into various time granularities and synthetic datasets (Stochastic Block Models for homophily, Barabási-Albert graphs for preferential attachment). The evaluation framework uses ROC-AUC for standard tests and custom metrics like balanced accuracy and average predicted probability scores for property-specific tests. Models are implemented using DyGLib with explicit hyperparameters listed in Appendix A. Key property tests include analyzing probability differences between directed edges and their reverses, varying negative sampling ratios to test density calibration, and creating disjoint edge sets to test recency and persistence learning.

## Key Results
- Models fail to capture edge direction, showing symmetric probability distributions for (u,v) and (v,u) edges
- Models cannot calibrate predicted graph density, producing predictions orders of magnitude different from training density
- Models fail to capture recency of interactions, showing flat probability distributions across edges from different training timesteps
- Most models successfully learn preferential attachment, with predicted probabilities increasing exponentially with node degree
- Only a few models effectively learn persistence and periodicity properties

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Temporal graph models successfully capture preferential attachment by learning degree-correlated edge formation patterns.
- Mechanism: Models encode node degree information through repeated exposure during training; nodes with more historical edges accumulate stronger representation signals, which translate to higher predicted probabilities for future adjacent edges. The paper demonstrates this via Barabási-Albert graphs where all seven models show monotonically increasing average edge probabilities with logarithmic node degree (Figure 6, from ~0.1 for low-degree nodes to 0.6–0.7 for high-degree nodes).
- Core assumption: The training distribution's degree-correlated sampling is sufficient for models to infer preferential attachment without explicit degree features.
- Evidence anchors:
  - [abstract] "most succeed at learning preferential attachment"
  - [Section 4.3.2] "all models assign on average very low probabilities, around 0.1, to edges relating to low-degree nodes, and, with exponential increase of node degree, the average probability rises continuously up to 0.6–0.7"
  - [corpus] Weak relevance; corpus focuses on text-attributed dynamic graphs and LLM integration, not structural mechanism analysis.
- Break condition: If node degree information is masked or training graphs have uniform degree distributions, the preferential attachment signal should disappear.

### Mechanism 2
- Claim: Models fail to distinguish edge direction because they treat (u,v) and (v,u) as nearly equivalent during inference.
- Mechanism: Direction is implicitly encoded via node order in edge tuples, but training with symmetric negative sampling and lack of explicit directional inductive biases leads models to learn near-symmetric representations. Figure 1 shows ~50% of edges have prediction differences <0.02 between (u,v) and (v,u); Table 5 shows reverse edges receive average probabilities of 0.70–0.81, comparable to or exceeding positive edge scores.
- Core assumption: The direction signal, if captured, would manifest as asymmetric probability scores for reversed edges.
- Evidence anchors:
  - [abstract] "models fail to capture edge direction"
  - [Section 4.1.2] "for most models, on roughly 50% of all edges the probability of edges being predicted is nearly symmetric with a difference smaller than 0.02"
  - [corpus] No directly relevant corpus evidence for directional encoding failures.
- Break condition: If models were trained with explicit direction-aware objectives (e.g., contrastive loss between (u,v) and (v,u)), asymmetric predictions should emerge.

### Mechanism 3
- Claim: Temporal granularity improves performance only when models incorporate fine-grained time encodings; simpler models achieve similar results with discretized timestamps.
- Mechanism: Continuous-time models with learned time encodings (e.g., DyRep, GraphMixer, JODIE, TGN) leverage granular timestamps to distinguish temporally proximate events; however, TGAT, DyGFormer, and TCL show limited improvement from continuous timestamps (Table 3), suggesting their temporal modules may underutilize fine-grained information or that discretization captures sufficient signal for these architectures.
- Core assumption: If granular timestamps contain predictive information, models leveraging them should outperform discretized variants.
- Evidence anchors:
  - [abstract] "models fail to capture...recency of interactions"
  - [Section 4.1.1] "flattening timestamps consistently harms performance to a severe degree" but "TGAT appears to even perform better with discrete timesteps"
  - [corpus] Weak relevance; corpus does not address temporal granularity effects.
- Break condition: If time encodings are ablated or replaced with random noise, performance should collapse for granularity-sensitive models but remain stable for others.

## Foundational Learning

- Concept: Temporal Graph Formalism (Continuous vs. Discrete)
  - Why needed here: The paper operates on continuous-time edge streams G=(V,E) where E={(ui,vi,ti)} and also uses discretized snapshots; understanding both representations is essential for interpreting granularity experiments.
  - Quick check question: Given edges (A,B,t=1.5) and (A,B,t=1.8), would a discrete-time model with timestep size 1.0 treat them as co-occurring or separate?

- Concept: Negative Sampling in Dynamic Link Prediction
  - Why needed here: Models require negative edges during training; sampling strategy (random, historical, temporal) affects what patterns models learn, as demonstrated in the density experiments where varying negative ratios directly impacted predicted graph density.
  - Quick check question: Why might sampling negative edges from historical positive edges lead to different model behavior than uniform random sampling?

- Concept: Preferential Attachment and Power-Law Degree Distributions
  - Why needed here: All models successfully learn this property; understanding that high-degree nodes attract proportionally more edges explains why models assign higher probabilities to edges adjacent to popular nodes.
  - Quick check question: In a Barabási-Albert graph with 1000 nodes, would a node with 100 historical edges receive higher, lower, or equal predicted edge probability compared to a node with 10 historical edges?

## Architecture Onboarding

- **Component map**: Edge (ui,vi,ti) -> Time Encoder -> Node Memory/Neighbor Retrieval -> Representation Update -> Link Decoder -> Probability Score
- **Critical path**: The full pipeline from temporal edge input through time encoding, node state updates, and final probability prediction determines whether models capture temporal properties correctly.
- **Design tradeoffs**:
  - Memory-based (TGN, JODIE, DyRep) vs. attention-based (DyGFormer, TGAT, TCL, GraphMixer): Memory models theoretically capture recency via decay but fail in practice; attention models handle long-range dependencies but may over-smooth temporal signals.
  - Fine-grained time encodings vs. discrete timesteps: Adds computational cost; benefits vary by architecture (essential for DyRep/GraphMixer, marginal for TGAT/TCL).
- **Failure signatures**:
  - Direction failure: Predictions for (u,v) and (v,u) differ by <0.02 for 50%+ of edges; reverse edges scored 0.7–0.8.
  - Recency failure: Flat probability distribution across edges from different training timesteps (Figure 5); no monotonic trend with recency.
  - Density failure: Predicted density orders of magnitude below training density; models predict near-zero edges when negative sampling ratio increases.
- **First 3 experiments**:
  1. **Direction probing**: Train on directed synthetic graph with asymmetric patterns; measure |P(u,v) - P(v,u)| distribution to confirm directional blindness.
  2. **Recency ablation**: Construct dataset with explicit recency signal (recent edges 10× more likely to reappear); check if any model shows monotonic probability increase with recency.
  3. **Density calibration**: Vary negative sampling ratio 1:1 to 1:100; plot predicted vs. true density to confirm models cannot calibrate edge quantity regardless of training signal.

## Open Questions the Paper Calls Out
None

## Limitations
- The evaluation framework uses binary property tests rather than continuous spectrum assessment, potentially oversimplifying model capabilities
- Synthetic datasets may not fully capture real-world complexity despite controlled experimental conditions
- The study focuses on fundamental graph properties but does not examine higher-order patterns or multi-relational dynamics

## Confidence

- **High confidence**: Models fail to capture edge direction (supported by symmetric probability distributions)
- **Medium confidence**: Models fail to capture graph density and recency (supported by calibration tests but with potential sampling artifacts)
- **Medium-Low confidence**: Models successfully learn preferential attachment and periodicity (based on binary tests rather than continuous measurement)

## Next Checks

1. **Direction Sensitivity**: Implement explicit directional contrastive loss and measure changes in (u,v) vs (v,u) probability asymmetry across all models
2. **Recency Signal Strength**: Create datasets with varying recency signal magnitudes (1× to 100× probability differences) to test model sensitivity thresholds
3. **Negative Sampling Robustness**: Vary negative sampling ratios beyond the tested range (1:1 to 1:17) to identify breaking points in density calibration ability