---
ver: rpa2
title: Optimizing Recall or Relevance? A Multi-Task Multi-Head Approach for Item-to-Item
  Retrieval in Recommendation
arxiv_id: '2506.06239'
source_url: https://arxiv.org/abs/2506.06239
tags:
- relevance
- semantic
- recall
- mtmh
- items
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the fundamental trade-off between recall and
  semantic relevance in item-to-item (I2I) retrieval for recommendation systems. Existing
  I2I models optimized for recall using co-engagement data often fail to capture semantic
  relevance, leading to overfitting short-term patterns and missing opportunities
  for novel interest discovery and content diversity.
---

# Optimizing Recall or Relevance? A Multi-Task Multi-Head Approach for Item-to-Item Retrieval in Recommendation

## Quick Facts
- arXiv ID: 2506.06239
- Source URL: https://arxiv.org/abs/2506.06239
- Reference count: 40
- Key result: Multi-head I2I model improves recall by 14.4% and semantic relevance by 56.6% over state-of-the-art baselines.

## Executive Summary
Item-to-item (I2I) retrieval models face a fundamental trade-off between recall (retrieving frequently co-engaged items) and semantic relevance (capturing meaningful content relationships). Traditional models optimized for recall using co-engagement data often miss opportunities for novel interest discovery and content diversity. This paper proposes MTMH (Multi-Task Multi-Head), a model that jointly optimizes both objectives through knowledge distillation from a pre-trained content encoder and a multi-head architecture that separately captures engagement and relevance signals.

## Method Summary
MTMH uses a two-tower architecture with shared SparseNN and DenseNN backbones, splitting into two separate MLP heads: an engagement head trained only on co-engagement loss (InfoNCE), and a relevance head trained on both co-engagement loss and KL divergence from a pre-trained content encoder. The model serves merged candidates from both heads using a quota-based approach (α=50 by default), balancing high-recall co-engaged items with semantically relevant discoveries. Training uses Adagrad optimizer with learning rate 0.01, batch size 2048, for 1 epoch with wr=0.5.

## Key Results
- MTMH improves recall by up to 14.4% and semantic relevance by up to 56.6% compared to state-of-the-art baselines.
- Online A/B testing shows 0.05% increase in daily active users, 0.22% in daily time spent, 0.31% in distinct item views, 0.25% in fresh content delivery, 0.33% in novel interest discovery rate, and 0.14% in user interest recall.
- MTMH achieves faster embedding convergence for fresh items with limited co-engagement data, improving cold-start performance.

## Why This Works (Mechanism)

### Mechanism 1: Knowledge Distillation Preserves Semantic Structure in Learned Embeddings
- Claim: Distilling knowledge from a pre-trained content encoder into retrieval embeddings transfers semantic understanding that co-engagement data alone cannot capture.
- Mechanism: The relevance loss minimizes KL divergence between the similarity distribution from content encoder embeddings (teacher) and the I2I model's embeddings (student). This aligns relative semantic similarities without requiring explicit relevance labels.
- Core assumption: The pre-trained content encoder has already learned meaningful semantic relationships from multi-modal content that transfer to the recommendation domain.
- Evidence anchors:
  - [abstract] "The model distills knowledge from a pre-trained content encoder to preserve semantic relevance."
  - [Section 2, Figure 1] Content-encoder based model achieves 37.5% semantic relevance vs 22.4% for co-engagement model, though with <1% recall.
  - [corpus] LLM-I2I paper corroborates LLM-based semantic understanding boosting I2I models, but corpus lacks direct evidence for this specific distillation approach.
- Break condition: If the content encoder's semantic space poorly aligns with user-perceived relevance (e.g., encoder focuses on visual similarity but users care about topical similarity), distillation may transfer misaligned signals.

### Mechanism 2: Multi-Head Architecture Decomposes the Fundamental Recall-Relevance Trade-off
- Claim: A single multi-task model cannot simultaneously maximize recall and semantic relevance because the objectives conflict beyond a certain point; separate heads preserve different item populations.
- Mechanism: The engagement head (trained on co-engagement loss only) retrieves highly co-engaged but potentially less semantically relevant items (e.g., popular items). The relevance head (trained on multi-task loss) retrieves items with both high semantic relevance and engagement. Merging candidates from both heads at serving time covers both populations.
- Core assumption: The sets of "highly co-engaged but less relevant" and "highly relevant with moderate engagement" items have limited overlap, justifying separate retrieval paths.
- Evidence anchors:
  - [Section 2, Q2 results] Multi-task single-head model achieves >50% relevance increase but recall plateaus earlier as K increases, indicating saturation in the high-relevance item pool.
  - [Section 3.3] "The engagement head is trained to minimize co-engagement loss only... while the relevance head is trained to minimize the multi-task learning loss."
  - [corpus] No direct corpus evidence for multi-head decomposition specifically; related work (PI2I) focuses on personalization rather than multi-objective decomposition.
- Break condition: If both heads converge to similar embedding spaces (e.g., relevance head overpowers engagement signals), the multi-head benefit collapses to a single-head model.

### Mechanism 3: Faster Fresh Content Embedding Convergence via Semantic Priors
- Claim: Multi-task learning with semantic distillation accelerates embedding convergence for fresh items with limited co-engagement data.
- Mechanism: Fresh items inherit meaningful embeddings from content features via the relevance loss, providing a semantic prior before co-engagement signals accumulate. This reduces cold-start latency.
- Core assumption: Fresh items have accessible content features that the content encoder can process, even without engagement history.
- Evidence anchors:
  - [Section 4.5, Figure 7] MTMH shows faster embedding delta convergence (distance to final embedding) compared to production model over training steps.
  - [Section 4.6, Table 5] Online A/B testing shows +0.25% in "percentage of fresh content" metric.
  - [corpus] Weak direct evidence; DAS paper mentions semantic IDs for cold-start but uses different mechanisms.
- Break condition: If fresh items lack extractable content features (e.g., placeholder metadata), the semantic prior cannot be established.

## Foundational Learning

- **Contrastive Learning (InfoNCE Loss)**:
  - Why needed here: The co-engagement loss (Eq. 1) uses InfoNCE to pull positive pairs closer and push negative pairs apart in embedding space. Understanding temperature scaling, negative sampling strategies, and batch construction is essential for debugging recall.
  - Quick check question: Can you explain why increasing the number of negative samples generally improves embedding quality but increases training cost?

- **Knowledge Distillation via KL Divergence**:
  - Why needed here: The relevance loss (Eq. 2) distills semantic knowledge from a frozen teacher (content encoder) to the student (I2I embeddings). You need to understand soft labels, temperature in softmax, and why DKL(Q||P) is used rather than MSE.
  - Quick check question: Why does distillation use soft labels (probability distributions) rather than hard labels derived from content embeddings?

- **Multi-Objective Optimization Trade-offs**:
  - Why needed here: The paper explicitly shows that recall and relevance cannot both be maximized in a single-head model. Understanding Pareto frontiers, loss weighting (wr hyperparameter), and gradient conflicts helps explain why multi-head is necessary.
  - Quick check question: If you observe that increasing wr improves relevance but recall drops sharply, what does this suggest about the gradient alignment between the two losses?

## Architecture Onboarding

- **Component map**:
  SparseNN + DenseNN backbone -> Shared embedding -> Engagement Head MLP -> ANN search -> Preranker -> Candidates
                                                                  -> Relevance Head MLP -> ANN search -> Preranker -> Candidates
                                                                                                                 -> Quota-based merger -> Final candidate set

- **Critical path**:
  1. Item features → SparseNN/DenseNN → shared embedding
  2. Shared embedding → Head 1 MLP → engagement embeddings → ANN cluster search → prerank → candidates
  3. Shared embedding → Head 2 MLP → relevance embeddings → ANN cluster search → prerank → candidates
  4. Merge candidates by quota α → final candidate set → downstream ranker
  5. Training: Head 1 gets Le only; Head 2 gets Le + wr * Lr

- **Design tradeoffs**:
  - **α (serving quota)**: Higher α = more recall, less relevance. Can tune at serving time without retraining. Paper finds α=50 optimal.
  - **wr (training weight)**: Higher wr = more relevance, potential recall drop. Requires retraining to change. Paper uses 0.5 default.
  - **Head architecture sharing**: Sharing SparseNN/DenseNN reduces parameters but creates gradient coupling. Paper claims minimal overhead from separate head MLPs.

- **Failure signatures**:
  - **Recall drops after adding relevance loss**: wr may be too high; gradient from relevance loss overwhelms engagement signals. Reduce wr or check content encoder alignment.
  - **Both heads retrieve similar items**: Heads may not be diverging; verify that Head 1 is trained on Le only (no relevance loss) and check learning rates.
  - **Fresh content still has poor recall**: Content encoder may not cover fresh item semantics; check if fresh items have valid content features and encoder coverage.
  - **Preranker biases toward engagement head candidates**: If preranker is trained purely on engagement, it may downrank relevance head candidates. Paper preranks per-head separately to mitigate this.

- **First 3 experiments**:
  1. **Ablate heads individually**: Serve only Head 1 (MTMH-H1) and only Head 2 (MTMH-H2) to measure recall vs relevance trade-off. Compare to merged MTMH. Should replicate Table 2 patterns.
  2. **Sweep α at serving time**: With fixed wr=0.5, vary α ∈ {0, 30, 50, 70, 100} and plot recall@500 vs L2 topic relevance. Should replicate Figure 6b Pareto curve.
  3. **Sweep wr at training time**: Retrain models with wr ∈ {0, 0.25, 0.5, 1.0, 5.0} and measure offline metrics. Confirm Table 4 trade-offs before online deployment.

## Open Questions the Paper Calls Out
- **Open Question 1**: How does the optimal trade-off quota (α) between the engagement and relevance heads shift across domains with different user interaction densities or content lifecycles?
- **Open Question 2**: Can the multi-head architecture scale efficiently to incorporate more than two heads (e.g., adding a dedicated diversity or fairness head) without complicating the merging strategy?
- **Open Question 3**: To what extent does the quality of the I2I retrieval depend on the specific pre-trained content encoder, and does distillation propagate the encoder's biases?

## Limitations
- The paper relies heavily on proprietary data from a commercial platform, limiting external validation of the reported improvements.
- The specific platform context (billions of users) may influence generalizability to smaller-scale systems.
- The multi-head architecture adds serving complexity that may not be justified for all recommendation scenarios.

## Confidence
- **High Confidence**: The fundamental trade-off between recall and semantic relevance in I2I models, and the multi-head architecture as a solution to this trade-off. The mechanism of knowledge distillation preserving semantic structure is well-established in the literature.
- **Medium Confidence**: The specific performance improvements (14.4% recall, 56.6% relevance gains) due to potential data-specific effects and the proprietary nature of evaluation datasets.
- **Low Confidence**: The generalizability of the α=50 serving quota and wr=0.5 training weight across different recommendation domains and user behaviors.

## Next Checks
1. **Cross-domain validation**: Test MTMH on public recommendation datasets (e.g., Amazon, MovieLens) to verify whether the recall-relevance trade-off decomposition generalizes beyond the proprietary platform.
2. **Head convergence analysis**: Monitor embedding similarity between engagement and relevance heads during training to quantify the degree of separation achieved and identify conditions where heads may collapse.
3. **Cold-start ablation**: Isolate fresh items with zero engagement history and measure whether semantic priors from content features alone provide meaningful retrieval quality before engagement signals accumulate.