---
ver: rpa2
title: 'TBDFiltering: Sample-Efficient Tree-Based Data Filtering'
arxiv_id: '2601.22016'
source_url: https://arxiv.org/abs/2601.22016
tags:
- quality
- data
- algorithm
- filtering
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TBDFILTERING, a sample-efficient, non-parametric
  approach for filtering large-scale datasets for large language model (LLM) training.
  The method leverages hierarchical clustering based on text embeddings to adaptively
  select documents for quality evaluation by an LLM, significantly reducing the number
  of expensive queries needed.
---

# TBDFiltering: Sample-Efficient Tree-Based Data Filtering

## Quick Facts
- **arXiv ID:** 2601.22016
- **Source URL:** https://arxiv.org/abs/2601.22016
- **Reference count:** 16
- **Primary result:** Introduces a sample-efficient, non-parametric data filtering method for LLM training that provably requires only a small number of document evaluations by adaptively selecting samples via hierarchical clustering of text embeddings.

## Executive Summary
TBDFILTERING presents a novel, theoretically grounded approach for filtering large-scale datasets for LLM training. By leveraging hierarchical clustering based on text embeddings, the method adaptively selects documents for quality evaluation by an LLM, significantly reducing the number of expensive queries needed. Under the assumption that the clustering contains a subtree with sufficiently pure leaves, TBDFILTERING provably requires only a small number of document evaluations proportional to the size of this subtree. Empirically, the approach consistently improves the performance of Gemma 3 models (270M, 1B, 4B parameters) trained on filtered data compared to unfiltered baselines across eight benchmarks including HellaSwag, MMLU, and PIQA. It also outperforms or matches a state-of-the-art classifier-based filtering method while avoiding the need to train specialized scoring models.

## Method Summary
TBDFILTERING is a sample-efficient, non-parametric data filtering method for LLM training that leverages hierarchical clustering based on text embeddings. The approach adaptively selects documents for quality evaluation by an LLM, significantly reducing the number of expensive queries needed. Under the assumption that the clustering contains a subtree with sufficiently pure leaves, TBDFILTERING provably requires only a small number of document evaluations proportional to the size of this subtree. Empirically, TBDFILTERING consistently improves the performance of Gemma 3 models trained on filtered data compared to unfiltered baselines across eight benchmarks.

## Key Results
- TBDFILTERING consistently improves the performance of Gemma 3 models (270M, 1B, 4B parameters) trained on filtered data compared to unfiltered baselines across eight benchmarks.
- The method outperforms or matches a state-of-the-art classifier-based filtering method while avoiding the need to train specialized scoring models.
- Under the assumption of a pure subtree in the clustering, TBDFILTERING provably requires only a small number of document evaluations, proportional to the size of this subtree.

## Why This Works (Mechanism)
TBDFILTERING works by leveraging the hierarchical structure of clustered text embeddings to adaptively select high-quality documents for LLM evaluation. Instead of evaluating every document, the method explores the clustering tree, prioritizing subtrees with higher estimated purity. This allows it to focus computational resources on the most promising regions of the data, reducing the total number of expensive LLM queries required. The approach avoids the need for proxy models or pre-trained classifiers, relying instead on direct LLM-based evaluation, which is more flexible and avoids the brittleness of proxy scoring models.

## Foundational Learning

1. **Hierarchical Clustering of Text Embeddings**
   - *Why needed:* Groups similar documents together, enabling the method to exploit structure in the data and focus evaluation on representative subsets.
   - *Quick check:* Verify that clusters capture semantic similarity by inspecting cluster samples.

2. **Adaptive Document Selection via Tree Exploration**
   - *Why needed:* Allows the algorithm to prioritize subtrees with higher estimated purity, focusing computational resources where they are most likely to yield high-quality data.
   - *Quick check:* Confirm that the selection strategy reduces the number of LLM queries compared to random or exhaustive evaluation.

3. **Purity-based Quality Estimation**
   - *Why needed:* Provides a principled way to estimate the quality of documents within a subtree, guiding the adaptive selection process.
   - *Quick check:* Measure the correlation between estimated purity and actual document quality as judged by the LLM.

4. **Sample Complexity Guarantees**
   - *Why needed:* Ensures the method is theoretically efficient, requiring only a small number of evaluations proportional to the size of a pure subtree.
   - *Quick check:* Validate that the number of evaluations grows sublinearly with dataset size under the purity assumption.

## Architecture Onboarding

**Component Map:** Text Embeddings -> Hierarchical Clustering -> Tree Structure -> Adaptive Selection -> LLM Evaluation -> Filtered Dataset

**Critical Path:** Text Embeddings → Hierarchical Clustering → Tree Structure → Adaptive Selection → LLM Evaluation → Filtered Dataset

**Design Tradeoffs:** The method trades off the computational cost of hierarchical clustering and tree exploration against the savings from reduced LLM queries. It avoids training proxy models but requires a high-quality embedding model and clustering algorithm.

**Failure Signatures:** Poor clustering (e.g., due to noisy embeddings or inappropriate granularity) can lead to suboptimal document selection and reduced filtering quality. If the dataset lacks a sufficiently pure subtree, the sample complexity guarantees may not hold.

**First Experiments:**
1. Test the impact of different embedding models on clustering quality and filtering performance.
2. Evaluate the sensitivity of filtering results to clustering granularity and algorithm choice.
3. Measure the actual reduction in LLM queries compared to exhaustive evaluation across diverse datasets.

## Open Questions the Paper Calls Out
None

## Limitations
- The method's theoretical guarantees depend on the presence of a pure subtree in the clustering, which may not hold in practice, especially with noisy or highly diverse datasets.
- Empirical results do not fully explore the impact of embedding model choice or the robustness of filtering under different clustering granularities.
- The comparison with classifier-based methods is informative, but direct scalability and cost comparisons under realistic conditions are not provided.

## Confidence

- **Theoretical claims and sample complexity:** High
- **Empirical performance gains over baselines:** High
- **Practical efficiency vs. classifier-based filtering:** Medium
- **Robustness across diverse datasets and embedding models:** Low

## Next Checks

1. Test TBDFILTERING's filtering quality and efficiency with different embedding models and clustering algorithms to assess robustness.
2. Conduct a head-to-head scalability and cost analysis comparing TBDFILTERING to classifier-based methods under realistic data sizes and budgets.
3. Evaluate the impact of varying subtree purity assumptions on filtering performance and sample efficiency across diverse datasets.