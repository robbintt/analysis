---
ver: rpa2
title: Hierarchical Indexing with Knowledge Enrichment for Multilingual Video Corpus
  Retrieval
arxiv_id: '2510.09553'
source_url: https://arxiv.org/abs/2510.09553
tags:
- video
- retrieval
- multilingual
- hierarchical
- videos
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of retrieving relevant instructional
  videos from large, multilingual medical archives, particularly when queries and
  video subtitles are in different languages. The proposed method uses a multi-stage
  framework that segments video subtitles into semantic chunks, enriches them with
  domain-specific knowledge graph facts, and organizes them into a hierarchical tree
  structure.
---

# Hierarchical Indexing with Knowledge Enrichment for Multilingual Video Corpus Retrieval

## Quick Facts
- arXiv ID: 2510.09553
- Source URL: https://arxiv.org/abs/2510.09553
- Reference count: 40
- Key outcome: Achieved R@1=0.3264, R@10=0.4211, R@50=0.5177, MRR=0.3407, and Overall=1.6059 on NLPCC-2025 mVCR test set

## Executive Summary
This paper addresses the challenge of retrieving relevant instructional medical videos from large, multilingual archives when queries and subtitles are in different languages. The proposed method uses a multi-stage framework that segments video subtitles into semantic chunks, enriches them with domain-specific knowledge graph facts, and organizes them into a hierarchical tree structure. At retrieval time, a coarse-to-fine tree search prunes irrelevant branches, and top candidates are re-ranked by a multilingual large language model. This approach achieves state-of-the-art performance on the NLPCC-2025 mVCR test set.

## Method Summary
The system first segments video subtitles into semantic chunks using LaBSE embeddings with a cosine similarity threshold. Each chunk undergoes knowledge graph enrichment through entity recognition (XLM-RoBERTa NER) and concatenation of relevant medical facts. The enriched chunks are organized into a hierarchical tree using K-means for coarse clusters and hierarchical agglomerative clustering for finer levels. For retrieval, queries are encoded with LaBSE and traverse the tree with pruning based on similarity thresholds. The top candidates are re-ranked by a multilingual LLM, with final video scores determined by max pooling of chunk-level relevance scores.

## Key Results
- Achieved R@1=0.3264, R@10=0.4211, R@50=0.5177, MRR=0.3407, and Overall=1.6059 on NLPCC-2025 mVCR test set
- Ablation studies show KG enrichment contributes 6.6% improvement to Overall score
- LLM re-ranking is most critical component, with 12.9% decrease in Overall score when removed
- Each component (KG enrichment, hierarchical indexing, LLM re-ranking) contributes significantly to performance

## Why This Works (Mechanism)

### Mechanism 1
Hierarchical tree structuring with dynamic pruning reduces search space for long-video retrieval. The system groups subtitle chunks via K-means and HAC into a tree, calculating cosine similarity at the coarse cluster level and pruning branches below threshold θ. Core assumption: centroid embeddings sufficiently represent semantic content of children. Evidence: coarse-to-fine tree search avoids exhaustive cross-encoder scoring. Break condition: relevant content scattered across disjoint clusters may be excluded during early pruning.

### Mechanism 2
Knowledge Graph enrichment bridges terminology gaps between layperson queries and professional medical subtitles. Medical entities are identified and linked to KG triples, converted to natural language statements, and appended to chunk text. Core assumption: LaBSE encoder can integrate concatenated factual statements without semantic dilution. Evidence: removing KG enrichment decreases Overall score by 6.6%. Break condition: noisy KG retrieval or context window overflow may degrade embedding quality.

### Mechanism 3
Multilingual LLM re-ranking captures nuanced cross-language relevance that embedding similarity misses. Lightweight LLM scores top-M candidates on 1-3 scale using original query and enriched chunk text. Core assumption: LLM possesses sufficient multilingual medical knowledge without fine-tuning. Evidence: LLM re-ranking is most critical component with 12.9% Overall score decrease when removed. Break condition: if initial retrieval fails to surface correct video chunk into top-M, re-ranker cannot recover it.

## Foundational Learning

**LaBSE (Language-agnostic BERT Sentence Embedding)**
- Why needed: Universal translator mapping Chinese queries and English/Chinese subtitles into shared vector space
- Quick check: How does LaBSE handle alignment between Chinese medical query and English subtitle containing same medical concept?

**Hierarchical Agglomerative Clustering (HAC) vs. K-means**
- Why needed: K-means for broad topics, HAC for fine-grained subtopics in tree structure
- Quick check: Why would HAC be preferred for lower tree levels (subtopics) compared to K-means?

**Max Pooling in Aggregation**
- Why needed: Scores chunks but must return ranked video list; max pooling allows video ranking high if any segment is highly relevant
- Quick check: What is risk of using max pooling if video has one relevant short segment and large amount of irrelevant content?

## Architecture Onboarding

**Component map:** Pre-processor (NER + KG Lookup → Text Concatenation) → Indexer (LaBSE Embeddings → K-means → HAC → Tree Storage) → Retriever (Query LaBSE Embedding → Cosine Similarity Tree Traversal → Top-M Candidates) → Scorer (LLM Re-ranker → Max Pooling → Final Ranking)

**Critical path:** KG Enrichment and Chunking phase. Wrong semantic boundaries (τ) split mid-concept; failed KG enrichment leaves vocabulary gap. These offline steps determine system's "recall ceiling."

**Design tradeoffs:**
- Latency vs. Recall: pruning threshold θ determines candidates reaching LLM (high θ reduces latency but risks missing relevant chunks)
- Specificity vs. Generality: text concatenation simple but may clutter context compared to structured embedding methods

**Failure signatures:**
- High Latency: likely caused by low pruning threshold θ passing too many chunks to LLM
- Low R@1 but High R@50: initial embedding/tree search works but re-ranker/chunking fails to identify best segment precisely
- Language Mismatch: if LaBSE embeddings not normalized or medical terminology out-of-distribution, tree search fails before LLM sees candidates

**First 3 experiments:**
1. Threshold Sensitivity Analysis: vary chunking threshold τ and pruning threshold θ to plot latency vs. R@1 curve
2. Ablation Reproduction (NER component): replace XLM-RoBERTa NER with dictionary-based matcher to isolate knowledge vs. entity recognition accuracy impact
3. Zero-Shot Language Test: feed queries in language not explicitly focused on dataset to test LaBSE "language-agnostic" claim versus LLM's multilingual capabilities

## Open Questions the Paper Calls Out

**Open Question 1**
Can GNNs outperform text concatenation for KG enrichment? Paper explicitly states need to explore structured KG reasoning with GNNs to overcome text concatenation limitations. Unresolved because text concatenation may fail to capture complex relational structures or introduce noise. Evidence: comparative study measuring retrieval precision when swapping concatenation for GNN-based encoder.

**Open Question 2**
Can knowledge distillation compress LLM re-ranker into lightweight model suitable for real-time deployment without significant accuracy loss? Authors propose investigating knowledge distillation for more compact LLM re-ranker. Unresolved because current "lightweight" LLM still incurs high computational costs limiting scalability. Evidence: benchmarks comparing latency and performance retention of distilled student model against current teacher LLM.

**Open Question 3**
To what degree does integrating visual features enhance retrieval performance compared to subtitle-only hierarchical index? Paper lists incorporating visual features for true multi-modal retrieval as key future priority. Unresolved because current system relies entirely on textual subtitles and KG facts, ignoring visual modality. Evidence: ablation studies on mVCR dataset assessing performance gains when visual frame embeddings are fused with text-based chunk embeddings.

## Limitations
- Performance metrics based on single dataset (NLPCC-2025 mVCR), limiting generalizability
- Method assumes availability of high-quality multilingual KG and NER model, which may not be feasible for all domains
- Critical hyperparameters empirically tuned but not disclosed, creating reproduction barrier and raising stability questions

## Confidence
- High: overall effectiveness of hierarchical indexing approach and significant contribution of KG enrichment well-supported by ablation results
- Medium: claim that LLM re-ranking is most critical component supported but specific contribution of chosen prompt/template not fully detailed
- Low: robustness to different KG sources, NER accuracy variations, and extreme language pairs not empirically tested beyond provided dataset

## Next Checks
1. Reproduce the Ablation Study: re-run system with only indexing components (no KG enrichment, no LLM re-ranking) to confirm reported performance drops
2. Cross-Dataset Evaluation: apply trained model to different multilingual medical video dataset or synthetic dataset with controlled language variations
3. Hyperparameter Sensitivity Analysis: systematically vary τ, θ, K, and M within reasonable ranges and plot impact on latency and retrieval metrics