---
ver: rpa2
title: 'TCDE: Topic-Centric Dual Expansion of Queries and Documents with Large Language
  Models for Information Retrieval'
arxiv_id: '2512.17164'
source_url: https://arxiv.org/abs/2512.17164
tags:
- expansion
- query
- retrieval
- document
- topic-centric
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TCDE addresses the semantic misalignment problem that arises when
  query expansion (QE) and document expansion (DE) are applied separately in information
  retrieval. The core idea is to use large language models (LLMs) to perform topic-centric
  dual expansion of both queries and documents.
---

# TCDE: Topic-Centric Dual Expansion of Queries and Documents with Large Language Models for Information Retrieval

## Quick Facts
- arXiv ID: 2512.17164
- Source URL: https://arxiv.org/abs/2512.17164
- Reference count: 36
- Primary result: Achieves 2.8% relative improvement in NDCG@10 on SciFact dataset by using topic-centric dual expansion

## Executive Summary
TCDE addresses semantic misalignment in information retrieval by simultaneously expanding both queries and documents using large language models. The method generates topic-focused pseudo-documents for queries and distills documents into core topic sentences, creating semantic bridges that improve retrieval performance. Experiments on TREC Deep Learning and BEIR benchmarks show TCDE significantly outperforms strong state-of-the-art expansion baselines, with particular effectiveness in dense retrieval tasks.

## Method Summary
TCDE uses an LLM (qwen-turbo) to perform topic-centric dual expansion: queries are expanded by generating N diverse topic-focused pseudo-documents, then concatenated with the original query repeated 5×; documents are expanded by extracting N topic sentences that are appended to the original content. This symmetric approach creates semantic alignment between queries and documents, improving both sparse (BM25) and dense (E5) retrieval performance. The method addresses the vocabulary mismatch problem while avoiding topic drift through conservative distillation for document expansion.

## Key Results
- 2.8% relative improvement in NDCG@10 on SciFact dataset for dense retrieval
- Consistent improvements across 12 BEIR benchmark datasets
- Ablation studies show TCDE outperforms TQE-only and TDE-only variants
- Optimal topic count N=5, with diminishing returns beyond this point

## Why This Works (Mechanism)

### Mechanism 1: Topic-Centric Query Expansion Creates Multi-Perspective Semantic Anchors
Generating diverse topic-focused pseudo-documents for each query captures latent sub-topics that better span the user's information need. An LLM is prompted to generate N distinct topic-centric documents reflecting different perspectives, which are concatenated with the original query (repeated 5× for weight) to form q+. This increases lexical overlap with relevant documents while enriching semantic representation.

### Mechanism 2: Distillation-Based Document Expansion Prevents Topic Drift
Extracting concise topic sentences from documents (rather than generating synthetic queries) preserves document semantics while creating alignment points. An LLM identifies N abstract topics in each document and expresses each as a single sentence, which are appended to the original document as d+ = concat(d, S_Topic). This conservative approach avoids introducing external information that could mismatch queries.

### Mechanism 3: Dual Expansion Creates Synergistic Topic-Centric Alignment
Simultaneously applying topic-centric expansion to both queries and documents produces greater gains than either alone through semantic bridges. TQE generates topic pseudo-documents while TDE extracts topic sentences, both using the same topic-centric frame to create "semantic bridges" that increase keyword overlap and bring positive q-d pairs closer in embedding space.

## Foundational Learning

- **Vocabulary Mismatch Problem**: Queries and documents often use different terms to express the same concepts, causing retrieval failures. Quick check: If a user searches "mask COVID protection" but relevant documents use "N95 respirator filtration," will BM25 retrieve them? No, because BM25 relies on exact term matching.

- **Sparse vs. Dense Retrieval Paradigms**: TCDE works on both BM25 (sparse, lexical) and E5 (dense, semantic). Quick check: Why does TCDE improve both sparse retrieval (via keyword overlap) and dense retrieval (via embedding space geometry)? Because it increases both lexical overlap and semantic similarity.

- **Asymmetric vs. Symmetric Expansion**: Prior methods (QE-only or DE-only) are asymmetric, causing semantic misalignment. Quick check: If you expand queries but not documents, what happens when expanded queries introduce terms that don't exist in any document? The query becomes unmatchable, degrading retrieval performance.

## Architecture Onboarding

- **Component map**: TQE Module (Online) -> LLM + prompt template -> generates N topic pseudo-documents -> concatenates with repeated original query; TDE Module (Offline) -> LLM + prompt template -> extracts N topic sentences -> concatenates with original document -> indexes d+; Retrieval Module -> matches q+ against index of d+ using BM25 or E5

- **Critical path**: Offline: Run TDE on all corpus documents -> build expanded index (one-time cost, amortized); Online: For each incoming query -> run TQE -> retrieve against expanded index; Dual expansion happens at different stages but shares topic-centric design principle

- **Design tradeoffs**: N=5 topics (diminishing returns beyond 2-5); 5× query repetition (prioritizes original intent); qwen-turbo LLM choice (fast, cheap but may hallucinate); distillation vs generation for DE (safer but may miss query-relevant angles)

- **Failure signatures**: Topic drift in TQE (hallucinations produce off-topic expansions); over-expansion noise (N too high introduces off-topic sentences); misaligned topic granularity (TQE generates broad topics while TDE extracts narrow sentences); MS MARCO Dev degradation (highly-tuned datasets may not benefit)

- **First 3 experiments**: 1) Reproduce ablation (Table 6): Run TQE-only, TDE-only, and TCDE on TREC DL'19 with BM25; 2) Sensitivity to N (Figure 4): Vary N_q from 1-10 on held-out dataset; 3) Cross-dataset generalization: Train/expand on one domain, test on another

## Open Questions the Paper Calls Out

- **Hallucination and topic drift**: The authors acknowledge expansions "can still drift or under-represent minority viewpoints in specialized domains," but don't evaluate niche domains where LLMs may hallucinate or lack knowledge.

- **LLM model sensitivity**: The methodology relies exclusively on qwen-turbo without analyzing sensitivity to the LLM's size or architecture. It's unclear if high-quality "topic-centric" generation requires a specific model scale.

- **Computational efficiency**: Document expansion is computationally intensive, and the paper doesn't propose or test efficiency methods for the offline indexing stage that requires running an LLM on the entire corpus.

## Limitations

- **LLM generation variability**: Quality depends heavily on prompt engineering and generation parameters (temperature, max_tokens, top_p) that aren't specified in the paper.

- **Hallucination risk in TQE**: Generating synthetic pseudo-documents introduces potential factual inaccuracies that aren't validated against the corpus, while TDE's distillation approach is safer.

- **Scalability constraints**: Online TQE requires LLM API calls for every query, creating latency and cost concerns at production scale.

## Confidence

- **High confidence**: The synergistic benefit of dual expansion (TCDE > TQE-only or TDE-only) is well-supported by ablation studies showing consistent improvements across multiple datasets and metrics.

- **Medium confidence**: The topic-centric design principle is theoretically sound and partially validated, but specific implementation details and prompt engineering choices could be optimized further.

- **Low confidence**: Claims about semantic bridge formation and topic alignment mechanisms are largely theoretical, based on cosine similarity visualizations rather than rigorous quantitative analysis.

## Next Checks

1. **Reproduce ablation study with hyperparameter sensitivity**: Run TQE-only vs TDE-only vs TCDE comparison while varying LLM generation parameters (temperature 0.0-1.0, max_tokens 50-200) to establish robustness bounds.

2. **Hallucination audit**: Sample 50 expanded queries and 50 expanded documents, manually verify topic relevance and factual accuracy against the original corpus to quantify hallucination rates.

3. **Cross-dataset transfer validation**: Train expansions on scientific papers (SciFact) and evaluate retrieval performance on biomedical literature (NFCorpus) to test whether topic-centric alignment generalizes across domains.