---
ver: rpa2
title: Zeroth-Order Sharpness-Aware Learning with Exponential Tilting
arxiv_id: '2510.16157'
source_url: https://arxiv.org/abs/2510.16157
tags:
- zeroth-order
- zest
- have
- preprint
- objective
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work bridges zeroth-order optimization with sharpness-aware
  minimization by introducing a continuous spectrum of sharpness-aware objectives
  via exponential tilting. The core method, ZEST, leverages tilted SAM objectives
  parameterized by a tilting parameter t, smoothly interpolating between average-
  and max-loss formulations.
---

# Zeroth-Order Sharpness-Aware Learning with Exponential Tilting

## Quick Facts
- arXiv ID: 2510.16157
- Source URL: https://arxiv.org/abs/2510.16157
- Reference count: 40
- Primary result: Introduces ZEST, a zeroth-order optimizer that achieves sharpness-aware generalization by interpolating between average- and max-loss objectives via exponential tilting.

## Executive Summary
This work bridges zeroth-order optimization with sharpness-aware minimization by introducing a continuous spectrum of sharpness-aware objectives via exponential tilting. The core method, ZEST, leverages tilted SAM objectives parameterized by a tilting parameter t, smoothly interpolating between average- and max-loss formulations. New zeroth-order algorithms are developed to solve this family of objectives using finite function evaluations, with two practical ratio-of-expectation estimators (naive and bias-corrected). Theoretically, ZEST can identify and avoid minima with large curvatures that vanilla zeroth-order methods miss. Empirically, ZEST consistently outperforms vanilla zeroth-order baselines across classification, multiple-choice QA, and language generation tasks, while being computationally and memory-efficient.

## Method Summary
ZEST introduces a family of sharpness-aware objectives by applying exponential tilting to the SAM framework. The tilted objective $F_t(x) = \frac{1}{t}\log \mathbb{E}[e^{t \cdot f(x+\epsilon)}]$ smoothly interpolates between average loss ($t \to 0$) and max loss SAM ($t \to \infty$). The algorithm estimates gradients using k random perturbation directions, evaluating exponentially tilted losses in both positive and negative directions. Two ratio-of-expectation estimators are proposed: a naive weighted sum and a bias-corrected version. The method uses a memory-efficient perturbation generation scheme that regenerates random directions from seeds rather than storing them, making it scalable to large models. The tilting parameter t controls the sharpness-awareness, with t=1 identified as a safe default choice.

## Key Results
- ZEST consistently outperforms vanilla zeroth-order baselines across GLUE classification, multiple-choice QA, and language generation tasks
- On GLUE with RoBERTa-Base and OPT-1.3B, ZEST achieves accuracy gains up to 5.9% on noisy data
- ZEST solutions exhibit smaller eigenvalues and lower loss variability under perturbations, confirming flatter minima
- The method is computationally and memory-efficient, using seed-based perturbation regeneration to avoid storing all directions
- t=1 is identified as a safe default tilting parameter that nearly always outperforms zeroth-order baselines

## Why This Works (Mechanism)
ZEST works by introducing exponential tilting to the SAM objective, creating a continuous spectrum between average and max loss formulations. The tilted objective $\frac{1}{t}\log \mathbb{E}[e^{tX}]$ smoothly interpolates between an average and a maximum as t increases. This allows the optimizer to trade off between smoothness (low t) and sharpness-awareness (high t). The ratio-of-expectation estimator then approximates gradients of this tilted objective using only function evaluations, enabling curvature-sensitive optimization without explicit gradients. By adjusting t, practitioners can balance convergence stability with the desire for flat minima that generalize better.

## Foundational Learning

**Concept: Sharpness-Aware Minimization (SAM)**
- Why needed here: ZEST's core goal is to bring SAM's benefits—finding flatter minima for better generalization—to gradient-free settings
- Quick check question: Why does minimizing the maximum loss in a parameter neighborhood lead to flatter minima compared to minimizing the average loss?

**Concept: Zeroth-Order Optimization (Two-Point Estimator)**
- Why needed here: ZEST modifies the foundational two-point gradient estimator used in methods like MeZO
- Quick check question: With only black-box function access, how do you estimate the gradient direction along a random vector $u$ using two function evaluations?

**Concept: Exponential Tilting & Log-Sum-Exp**
- Why needed here: This is the mathematical bridge connecting the average-loss ($t \to 0$) and max-loss ($t \to \infty$) objectives
- Quick check question: How does the log-expectation-exponential function $\frac{1}{t}\log \mathbb{E}[e^{tX}]$ smoothly interpolate between an average and a maximum as the parameter $t$ increases?

## Architecture Onboarding

**Component map:** The ZEST algorithm consists of three main stages per iteration: (1) Sampling & Scoring: Sample k random directions and evaluate the exponentially tilted loss in both positive and negative directions for each. (2) Weight Calculation: Compute normalized scores and apply a ratio estimator to determine the update weight for each direction. (3) Parameter Update: Regenerate the same random directions using seeds and apply a weighted update to the parameters.

**Critical path:** The correct implementation of the ratio-of-expectations estimator is critical. The naive estimator uses a simple weighted sum, while the bias-corrected version adds a correction term based on the variance of the loss values. An error here will produce a biased gradient estimate that fails to minimize the intended t-SAM objective.

**Design tradeoffs:**
- **Perturbation Distribution:** Gaussian vs Uniform Ball perturbations impact theoretical bias and gradient estimator formulas
- **Number of Perturbations (k):** Larger k reduces variance but linearly increases forward passes per training step; k=5 is used as default
- **Estimator Choice:** Bias-corrected estimator offers better theoretical bias reduction (O(1/k²)) but adds computational overhead; naive estimator is simpler but may be more biased for small k

**Failure signatures:**
- Instability at high t: As t approaches infinity, the objective approaches max-loss SAM, which can be non-differentiable and unstable to optimize
- Memory blow-up: Failing to use seed-based regeneration for perturbations would negate ZEST's key memory-efficiency advantage
- Stagnant loss: Incorrect bias correction implementation may produce significantly biased gradient estimates that prevent effective optimization

**First 3 experiments:**
1. **Hyperparameter Scan for t:** On a small validation set, run ZEST with t values [0, 1, 5, 20] to confirm t=1 is a safe default and observe performance vs t trade-off curve
2. **Baseline Comparison vs MeZO:** Implement vanilla two-point zeroth-order estimator (MeZO, equivalent to ZEST with t→0) and compare test accuracy and loss sharpness against ZEST (t=1)
3. **Memory & Throughput Profiling:** Implement seed-based regeneration for perturbations and measure GPU memory usage and iterations-per-second for both ZEST and first-order SAM baseline to quantify efficiency gains

## Open Questions the Paper Calls Out
- Can more advanced ratio-of-expectation estimators significantly improve ZEST's convergence speed or bias reduction compared to the naive and bias-corrected plug-in methods?
- How does ZEST perform when applied to other sharpness-aware objectives or sharpness definitions beyond the tilted SAM formulation?
- Is there a principled, adaptive strategy for selecting the tilting parameter t during training based on local loss landscape geometry?

## Limitations
- Hyperparameter sensitivity to tilting parameter t, though t=1 is identified as a safe default
- Theoretical analysis assumes infinite sample sizes for perturbation directions; finite-sample behavior in high dimensions may deviate from theory
- Experiments rely on prompt-based fine-tuning for classification, but prompt templates are not fully specified

## Confidence

**High Confidence:** The theoretical formulation of the tilted SAM objective and its connection to flatness; the computational efficiency advantage over first-order SAM; the empirical superiority of ZEST over vanilla zeroth-order baselines in terms of accuracy and sharpness.

**Medium Confidence:** The claim that t=1 is universally safe; the exact impact of the bias-corrected estimator in very high dimensions; the robustness of ZEST under extreme noise levels.

**Low Confidence:** Performance on non-prompt-based architectures; generalization to non-language tasks; scalability to trillion-parameter models.

## Next Checks

1. **Hyperparameter Sweep for t:** Conduct systematic ablation study across t values [0, 0.1, 1, 5, 20, 100] on held-out GLUE validation set to map performance-vs-t trade-off and confirm t=1 is optimal or near-optimal.

2. **Robustness to Perturbation Count k:** Vary number of sampled directions (k from 1 to 20) to empirically assess variance-bias trade-off of gradient estimator and verify k=5 provides good balance between stability and computational cost.

3. **Sharpness Verification Under Different Noise Models:** Replicate sharpness analysis but introduce multiple types of noise (Gaussian input noise, label noise at varying corruption rates, adversarial perturbations) to test robustness of ZEST-found minima compared to MeZO and first-order SAM.