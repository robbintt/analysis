---
ver: rpa2
title: 'GRANITE: A Generalized Regional Framework for Identifying Agreement in Feature-Based
  Explanations'
arxiv_id: '2601.22771'
source_url: https://arxiv.org/abs/2601.22771
tags:
- feature
- explanations
- regional
- pure
- disagreement
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GRANITE is a generalized regional framework that addresses disagreement
  in feature-based explanations by partitioning the feature space into regions where
  interaction and distribution influences are minimized. The method unifies existing
  regional approaches and extends them to feature groups, providing consistent and
  interpretable explanations for black-box models.
---

# GRANITE: A Generalized Regional Framework for Identifying Agreement in Feature-Based Explanations

## Quick Facts
- arXiv ID: 2601.22771
- Source URL: https://arxiv.org/abs/2601.22771
- Reference count: 40
- One-line primary result: GRANITE reduces disagreement between feature-based explanations (e.g., ICE vs PDP, CFI vs PFI) by partitioning the feature space into interpretable regions.

## Executive Summary
GRANITE addresses a fundamental problem in explainable AI: different feature attribution methods often produce inconsistent explanations for the same black-box model. The framework identifies that these disagreements arise from two main sources—feature interactions and feature dependencies—and provides a unified solution through recursive partitioning. By creating regions where these influences are minimized, GRANITE produces aligned explanations that are both more interpretable and more reliable than global approaches.

The method extends existing regional explanation techniques to handle feature groups and provides theoretical guarantees for why partitioning reduces disagreement. Through experiments on real-world datasets including Bikesharing and Diabetes, GRANITE demonstrates substantial improvements in explanation consistency, reducing disagreement from 100% to as low as 3% in certain regions while maintaining interpretability through simple decision tree structures.

## Method Summary
GRANITE partitions the feature space using a decision tree approach to minimize disagreement between explanation methods. The algorithm pre-computes model evaluations on mixed feature sets (R-matrices) to efficiently estimate regional disagreement, then recursively splits regions based on which feature and threshold maximally reduces this disagreement. The framework handles both interaction disagreement (e.g., between pure and full effects) and distribution disagreement (e.g., between marginal and conditional masking) through the same partitioning mechanism, with regularization to prevent overfitting.

## Key Results
- On Bikesharing dataset, reduced interaction disagreement between ICE and PDP curves from 100% to 4% in certain regions
- Reduced distribution disagreement between CFI and PFI from 100% to 3% at maximum depth
- Provided interpretable regions revealing how feature importance varies across subpopulations
- Produced simpler explanations than global approaches while maintaining agreement

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Partitioning the feature space reduces disagreement caused by feature interactions by isolating regions where interaction effects are minimized.
- **Mechanism:** When the feature space is split, the variance of interaction terms within the resulting sub-region is reduced. The paper formalizes this using Theorem 1: if masking operators are fixed, the difference between explanation methods is proportional to the pure interaction effects. By restricting the region, these interaction terms shrink, causing "pure" methods (which ignore interactions) and "full" methods (which include them) to converge.
- **Core assumption:** The interaction effects vary across the feature space such that specific axis-aligned splits can effectively isolate or neutralize them.
- **Evidence anchors:**
  - [section 3.3] "Theorem 1... the disagreement is driven solely by higher-order terms."
  - [figure 1] Shows disagreement disappearing when splitting on $X_2$, the interacting feature.
- **Break condition:** If interactions are global and uniformly distributed, recursive partitioning may fail to find regions with low interaction variance.

### Mechanism 2
- **Claim:** Partitioning aligns marginal and conditional explanations by minimizing the discrepancy between marginal and conditional feature distributions within a region.
- **Mechanism:** Disagreement often stems from "masking"—whether unobserved features are sampled from the marginal or conditional distribution. Theorem 3 states that this disagreement is a function of the density ratio between these distributions. By partitioning the space to minimize this density ratio difference, marginal explanations and conditional explanations converge.
- **Core assumption:** Feature dependencies are localized enough that splitting on conditioning variables effectively decorrelates the features within the leaves.
- **Evidence anchors:**
  - [section 3.3] "Theorem 3... the disagreement is equal to the local explanation of $\delta_\Omega$, driven by the difference between conditional and marginal distribution."
  - [section 5] "Features become nearly uncorrelated within the learned regions, causing PFI and CFI to coincide."
- **Break condition:** If feature dependencies are complex and multi-modal, simple axis-aligned splits may fail to achieve conditional independence.

### Mechanism 3
- **Claim:** A greedy risk-minimization strategy efficiently approximates the optimal partition where explanations agree.
- **Mechanism:** The framework uses a recursive partitioning algorithm (similar to CART) to minimize a "disagreement risk" metric. It pre-computes model evaluations on mixed feature sets and greedily selects splits that maximize the reduction in disagreement between the target explanation pairs, subject to a regularization penalty to prevent overfitting.
- **Core assumption:** The optimal regions can be approximated by axis-aligned splits rather than requiring arbitrary polygonal shapes.
- **Evidence anchors:**
  - [section 3.5] "We adopt a recursive partitioning approach... to minimize disagreement risk."
  - [algorithm 1] Defines the greedy splitting and pruning logic.
- **Break condition:** If the computation of explanation disagreement is noisy or unstable, the greedy path may converge to a local minimum that offers little interpretability gain.

## Foundational Learning

- **Concept: Functional ANOVA (fANOVA) Decomposition**
  - **Why needed here:** GRANITE relies on the fANOVA identity to separate main effects from interaction effects. Understanding that a function can be written as a sum of components is essential to grasp why explanations disagree when they handle these components differently.
  - **Quick check question:** In a model $F(x_1, x_2) = x_1 + x_2 + x_1x_2$, which term represents the interaction effect that causes "pure" and "full" explanations to differ?

- **Concept: Masking Operators (Marginal vs. Conditional)**
  - **Why needed here:** This is the second root cause of disagreement identified in the paper. One must understand the difference between intervening on a feature (marginal distribution, breaking correlations) and observing a feature (conditional distribution, preserving correlations) to interpret the "Distribution Influence" mechanism.
  - **Quick check question:** If feature $A$ is highly correlated with feature $B$, would a "marginal" explanation for $A$ substitute $B$ with its mean, or keep the observed value of $B$?

- **Concept: Recursive Partitioning (Decision Trees)**
  - **Why needed here:** The practical implementation of GRANITE is a decision tree algorithm. Familiarity with how trees select split points to minimize variance is necessary to understand the estimation section.
  - **Quick check question:** Why does the algorithm include a regularization term $\alpha K$ (where $K$ is the number of leaves) in its objective function?

## Architecture Onboarding

- **Component map:** Pre-processor (computes R-matrices) -> Core Engine (recursive partitioning) -> Output (decision tree structure)
- **Critical path:** The computation of the R-matrices is the primary memory and time bottleneck. The algorithm requires evaluating the model on N² permutations if done naively; optimization or sub-sampling is critical here.
- **Design tradeoffs:**
  - **Interpretability vs. Agreement:** Increasing tree depth reduces disagreement but increases the number of regions, making the overall explanation harder to summarize.
  - **Computation vs. Precision:** Sub-sampling data to compute R-matrices reduces memory usage but may introduce noise into the estimated disagreement risk.
- **Failure signatures:**
  - **High Memory Usage:** Crashing during the pre-computation phase due to the O(dN²) space complexity on large datasets.
  - **Smooth Interactions:** The tree creating many tiny regions to capture smooth, non-abrupt interaction transitions, resulting in fragmented, uninterpretable outputs.
- **First 3 experiments:**
  1. **Synthetic Validation:** Replicate the "Toy Example" where interactions (X₁, X₂) and dependencies (X₃, X₄) are known. Verify that splits occur precisely at the boundaries defined by the interacting/dependent features.
  2. **Scalability Test:** Run the R-matrix computation on varying sample sizes (N=500, 1000, 2000) and measure runtime/memory to validate the quadratic complexity claim before running on full datasets.
  3. **Disagreement Quantification:** Apply GRANITE to the "Bikesharing" dataset. Plot the "Disagreement Risk" vs. "Tree Depth" to observe the saturation point where adding regions yields diminishing returns in agreement.

## Open Questions the Paper Calls Out

- **Open Question 1:** How can feature groups be selected in a principled manner for joint influence measures?
  - **Basis:** Section 6 states that while feature groups increase expressiveness, "selecting such feature groups in a principled manner remains an important direction for future work."
  - **Why unresolved:** The current framework relies on predefined groups rather than an automated or theoretically grounded selection mechanism.
  - **Evidence:** An algorithm that automatically identifies optimal feature subsets that maximize regional explanation agreement while minimizing the number of partitions.

- **Open Question 2:** What is the optimal strategy to minimize interaction and distributional influences simultaneously?
  - **Basis:** Section 6 notes that while minimizing both sources of disagreement is possible, it highlights a "trade-off between interpretability and alignment" that is not fully explored.
  - **Why unresolved:** The paper primarily optimizes for one disagreement source at a time; joint optimization may require an intractable number of regions, reducing interpretability.
  - **Evidence:** A comparative analysis showing the convergence properties of simultaneous minimization versus sequential approaches on datasets with mixed dependencies and interactions.

- **Open Question 3:** How can subsample sizes be determined dynamically based on uncertainty in regional explanations?
  - **Basis:** Section 6 suggests that "future work could choose subsample sizes based on uncertainty in the regional explanations" to manage O(dN²) memory constraints.
  - **Why unresolved:** The current method relies on fixed sub-sampling for computational feasibility, potentially compromising statistical robustness.
  - **Evidence:** A theoretical analysis providing bounds on the required sample size relative to the variance of the regional explanations and partition depth.

## Limitations
- Quadratic computational complexity of R-matrix computation may limit scalability to larger datasets
- Axis-aligned partitions may not capture complex, non-linear interaction patterns effectively
- Quality of conditional masking depends on binning strategy, which can introduce approximation errors

## Confidence
- **High confidence**: The core mechanism of reducing disagreement through partitioning is well-supported by theorems and empirical results across multiple datasets
- **Medium confidence**: The extension to feature groups shows promise but has limited experimental validation compared to single features
- **Medium confidence**: The interpretability claims rely on user study assumptions rather than direct validation of human comprehension

## Next Checks
1. **Scalability test**: Measure runtime and memory usage of R-matrix computation across varying sample sizes (N=500, 1000, 2000) to verify computational complexity claims
2. **Partition quality validation**: On synthetic data with known interaction boundaries, verify that GRANITE's splits align with the true interaction locations
3. **Conditional masking sensitivity**: Test how different binning strategies (quantiles vs. decision tree leaves) affect the reduction in distribution disagreement