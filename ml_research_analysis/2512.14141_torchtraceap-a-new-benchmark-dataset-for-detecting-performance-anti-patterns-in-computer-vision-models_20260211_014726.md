---
ver: rpa2
title: 'TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns
  in Computer Vision Models'
arxiv_id: '2512.14141'
source_url: https://arxiv.org/abs/2512.14141
tags:
- trace
- torch
- event
- detection
- window
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TorchTraceAP, the first benchmark dataset
  for detecting performance anti-patterns in computer vision models' PyTorch traces.
  The dataset contains over 600 traces from diverse CV applications (classification,
  detection, segmentation, generation) across multiple hardware platforms, with both
  trace-level and window-level annotations.
---

# TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns in Computer Vision Models

## Quick Facts
- arXiv ID: 2512.14141
- Source URL: https://arxiv.org/abs/2512.14141
- Reference count: 40
- Primary result: 78.41% AUC-ROC for seen tasks, 63.42% for unseen tasks

## Executive Summary
This paper introduces TorchTraceAP, the first benchmark dataset for detecting performance anti-patterns in computer vision models' PyTorch traces. The dataset contains over 600 traces from diverse CV applications (classification, detection, segmentation, generation) across multiple hardware platforms, with both trace-level and window-level annotations. To address the challenge of detecting anomalies in lengthy traces, the authors propose a two-stage approach: a lightweight ML model first identifies suspicious trace windows using a novel event and window encoder, followed by an LLM for fine-grained classification and feedback. Experimental results show that their method significantly outperforms unsupervised clustering and rule-based techniques, achieving up to 78.41% AUC-ROC for seen tasks and 63.42% for unseen tasks. The LLM-based classification achieves 75% accuracy in identifying specific anti-pattern types.

## Method Summary
The authors propose a two-stage approach for detecting performance anti-patterns in PyTorch traces. Stage 1 uses a lightweight ML model with a hierarchical event-to-window encoder that captures both temporal sequences and call stack hierarchies in traces. The encoder fuses GPU/CPU event names, launch delays, and durations into unified embeddings using RoBERTa with trainable adapters, then aggregates events using transformer attention with 2D positional encoding. This model identifies suspicious trace windows. Stage 2 employs an LLM (GPT-4.1) for fine-grained classification of anti-pattern types and iterative feedback, compensating for the ML model's lack of semantic reasoning. The system is trained using weakly supervised multiple-instance learning with a modified assumption that positive traces may contain limited anti-patterns, employing a multi-component loss function to learn discriminative boundaries without window-level labels.

## Key Results
- Two-stage approach achieves 78.41% AUC-ROC for seen tasks vs. ~50-54% for baselines
- LLM-based classification achieves 75% accuracy in identifying specific anti-pattern types
- Method shows 63.42% AUC-ROC for unseen tasks, demonstrating cross-task generalization
- Outperforms unsupervised clustering and rule-based techniques by significant margins

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Event-to-Window Encoding
The hierarchical encoder captures the 2D structure of torch traces (temporal sequence + call stack hierarchy) more effectively than flat representations. Event encoder fuses GPU/CPU event names (via RoBERTa + trainable adapters), launch delay, and duration into unified embeddings. Window encoder then aggregates events using transformer attention with 2D positional encoding (relative launch time + stream ID). Core assumption: Anti-patterns emerge from relationships between events across both temporal and hierarchical dimensions, not from isolated events.

### Mechanism 2: Weakly Supervised MIL with Modified Assumptions
Modified multiple-instance learning enables effective training from trace-level labels only. Uses average window score (not max) for trace-level prediction, acknowledging positive traces may contain limited anti-patterns. Multi-component loss (BCE + SVM-inspired embedding separation + clustering + smoothness) learns discriminative boundaries without window-level labels. Core assumption: Positive traces ("good traces") still contain some inefficiencies but fewer/less severe than negative traces.

### Mechanism 3: Two-Stage LLM-Augmented Pipeline
Lightweight ML detection + LLM classification compensates for individual method limitations. Stage 1 efficiently processes long traces to localize suspicious windows. Stage 2 LLM receives condensed window context for anti-pattern type classification and feedback, enabling iterative refinement. Core assumption: LLMs can accurately classify anti-patterns given localized context but fail on full traces; lightweight models can localize but lack semantic reasoning for classification.

## Foundational Learning

- **PyTorch Profiler and Trace Structure**: Traces are 2D structures (X-axis: chronological execution, Y-axis: call stack hierarchy). Understanding this representation is essential for encoding design and anti-pattern interpretation. *Quick check*: Can you describe what the X-axis (time) and Y-axis (call stack) represent in a torch trace, and why a Conv2d operation might span multiple hierarchy levels?

- **CUDA Streams and Asynchronous Execution**: 2D positional encoding uses stream ID; anti-patterns like "NCCL and Compute not Overlap" depend on stream behavior. Multiple streams enable parallel kernel execution. *Quick check*: Why might computation kernels (cuDNN) and communication kernels (NCCL) execute on different CUDA streams, and how does this relate to the "NCCL Block main Stream" anti-pattern?

- **Multiple-Instance Learning (MIL)**: The training framework adapts MIL for weakly supervised anti-pattern detection. *Quick check*: What is the standard MIL assumption about positive bags, and why does the paper argue this doesn't hold for torch traces?

## Architecture Onboarding

- **Component map**: Raw PyTorch Trace → Trace Preprocessing → Event Encoder (RoBERTa + adapters) → Window Encoder (transformer + 2D positional encoding) → Window-to-Window Model (dilated convs + MHSA) → Threshold Filter → LLM (GPT-4.1)

- **Critical path**: Event attribute extraction is essential; 2D positional encoding enables inter-event relationship modeling; multi-loss optimization requires balance; window selection threshold controls precision/recall tradeoff for LLM input quality.

- **Design tradeoffs**: Window count (N_w): 100 windows balanced across seen tasks; 200 better for complex models but may fragment anti-pattern regions. Training-free vs. trainable text encoder: RoBERTa frozen with trainable adapters balances domain adaptation vs. overfitting. Embedding dimensions: d=128 per attribute, D=256 window embedding - larger improves expressiveness but increases memory. Average vs. max pooling: Average tolerates limited anti-patterns in positive traces.

- **Failure signatures**: AUC near 50% indicates embeddings not discriminative; high seen/unseen gap (>15%) suggests overfitting; LLM classification accuracy drops below 70% indicate window extraction may fragment anti-patterns; uniform anomaly scores indicate relation modeling failure.

- **First 3 experiments**: 1) Baseline reproduction: Run Rule/Clustering/Pure LLM baselines to validate ~50-54% AUC baseline. 2) Ablation study: Remove Event Adapter, Transformer Encoder, and Relation Modeling components to verify improvement path. 3) Window sensitivity analysis: Test N_w ∈ {50, 100, 200} on both seen and unseen tasks to characterize localization vs. context tradeoff.

## Open Questions the Paper Calls Out

- **Can the anti-pattern detection framework generalize to non-vision ML domains such as NLP, speech, or reinforcement learning workloads?**: The authors state TorchTraceAP is "the first dataset specifically designed to evaluate and improve ML models' ability to detect anti patterns in traces" but focus exclusively on CV applications. Different ML domains have distinct computational patterns, kernel types, and anti-pattern manifestations that may not transfer directly.

- **How can the 15% performance gap between seen tasks (78.41% AUC) and unseen tasks (63.42% AUC) be reduced?**: Table 3 shows consistent degradation on unseen test tasks (pose estimation, depth estimation, image generation) compared to seen tasks, suggesting limited cross-task generalization. The model may overfit to task-specific event patterns rather than learning fundamental anti-pattern signatures.

- **Can the method be adapted to other deep learning frameworks beyond PyTorch, such as TensorFlow or JAX?**: The entire methodology is designed around PyTorch profiler trace format, PyTorch-specific operations, and CUDA event structures. No mention of framework-agnostic design. Different frameworks have different profiling formats, operation naming conventions, and execution abstractions that would require substantial modifications.

## Limitations

- Critical implementation details like loss weights, window segmentation strategy, and embedding initialization parameters are unspecified, preventing full reproducibility.
- The two-stage approach creates a complex dependency chain where errors in window extraction directly impact LLM classification accuracy.
- Dataset construction methodology lacks detail on how ground truth anti-pattern annotations were established across diverse hardware platforms, raising questions about annotation consistency.

## Confidence

- **High Confidence**: The hierarchical encoding mechanism and two-stage pipeline architecture are well-specified and demonstrate measurable improvements over baselines (78.41% vs. 54% AUC-ROC for seen tasks).
- **Medium Confidence**: The weakly supervised MIL formulation shows promise but lacks empirical validation of the modified assumptions about trace-level label quality.
- **Low Confidence**: Reproducibility is significantly hampered by missing implementation details in the event encoder, window segmentation, and LLM integration components.

## Next Checks

1. **Baseline Implementation Verification**: Reproduce Rule, Clustering, and Pure LLM baselines on the TorchTraceAP test split to validate the reported ~50-54% AUC baseline performance and establish implementation correctness before attempting the full pipeline.

2. **Window Sensitivity Analysis**: Systematically test window counts N_w ∈ {50, 100, 200} across both seen and unseen tasks to characterize the localization vs. context tradeoff and identify optimal windowing parameters for your target workload complexity.

3. **Ablation Study Validation**: Implement and evaluate each component removal (Event Adapter, Transformer Encoder, Relation Modeling) as specified in Table 5 to verify the claimed improvement trajectory from 58.26% to 78.41% AUC-ROC and understand component contributions.