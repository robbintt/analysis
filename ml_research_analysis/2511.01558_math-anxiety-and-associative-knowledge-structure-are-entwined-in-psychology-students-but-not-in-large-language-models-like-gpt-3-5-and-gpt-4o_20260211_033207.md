---
ver: rpa2
title: Math anxiety and associative knowledge structure are entwined in psychology
  students but not in Large Language Models like GPT-3.5 and GPT-4o
arxiv_id: '2511.01558'
source_url: https://arxiv.org/abs/2511.01558
tags:
- anxiety
- math
- students
- valence
- degree
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explored how math anxiety and associative knowledge
  structure are linked in psychology students but not in Large Language Models (GPT-3.5
  and GPT-4o). Researchers used behavioural forma mentis networks to model individual
  and group differences in the perception and association of concepts related to math
  and anxiety.
---

# Math anxiety and associative knowledge structure are entwined in psychology students but not in Large Language Models like GPT-3.5 and GPT-4o

## Quick Facts
- **arXiv ID:** 2511.01558
- **Source URL:** https://arxiv.org/abs/2511.01558
- **Reference count:** 10
- **Primary result:** Math anxiety correlates with structural prominence of "anxiety" in associative networks for psychology students, but not for LLMs.

## Executive Summary
This study investigates the relationship between math anxiety and associative knowledge structure using behavioral forma mentis networks (BFMNs). Psychology undergraduates showed that higher math anxiety was predicted by positive valence ratings and higher network degree centrality of the concept "anxiety," alongside negative valence for "math." In contrast, GPT-3.5 and GPT-4o simulations failed to replicate this pattern, likely due to the absence of affective grounding and embodied emotional experiences in these models. These findings highlight the importance of emotional perception and associations in managing student math anxiety.

## Method Summary
The study employed behavioral forma mentis networks to model individual and group differences in the perception and association of concepts related to math and anxiety. Two samples of psychology undergraduates (n₁=70, n₂=57) were compared against GPT-simulated students (GPT-3.5: n₃=300; GPT-4o: n₄=300). Participants completed the Math Anxiety Scale (MAS-IT), a free association task with 40 cues, and rated each word and association on a 1-5 valence scale. BFMNs were constructed, and network metrics (degree, closeness) and valence ratings were used in OLS regression models to predict math anxiety scores.

## Key Results
- Positive valence ratings and higher degree centrality of "anxiety" predicted higher total and evaluative math anxiety in psychology students.
- These predictive models failed for GPT-3.5 and GPT-4o due to differences in simulated networks and psychometric scores compared to humans.
- High math-anxiety students framed "anxiety" in an emotionally polarizing way, a pattern absent in low math-anxiety students and LLMs.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** In human students, math anxiety levels appear linked to the structural prominence and affective valence of the concept "anxiety" within their semantic memory.
- **Mechanism:** High math anxiety correlates with "rumination," where "anxiety" acts as a highly connected hub (high degree centrality) in the associative network. This structural prominence makes anxious thoughts more accessible during math tasks, depleting working memory.
- **Core assumption:** Network degree centrality in a free-association task validly proxies the cognitive accessibility or "salence" of a concept.
- **Evidence anchors:**
  - [abstract] "positive valence ratings and higher network degree for 'anxiety'... could predict higher total and evaluative math anxiety."
  - [section] Experiment 1 Results: "Total, Evaluation, and Everyday/Social MA were all significantly positively correlated to its [anxiety's] degree."
  - [corpus] Paper 43852 (SpreadPy) supports the theoretical basis for modeling cognitive spreading activation in these networks.
- **Break condition:** If "anxiety" degree centrality were unrelated to psychometric anxiety scores, or if the relationship were strictly limited to the "math" node alone (which the paper found insignificant in Exp 1).

### Mechanism 2
- **Claim:** Large Language Models (LLMs) fail to replicate the entwinement of math anxiety and semantic structure found in humans due to a lack of "affective grounding."
- **Mechanism:** LLMs generate associations based on linguistic co-occurrence patterns rather than embodied emotional experiences or autobiographical memory. Consequently, their "simulated" anxiety does not reorganize their semantic network structure as it does in humans.
- **Core assumption:** The disconnect between psychometric scores and network structure in GPT implies a fundamental difference in "cognition" rather than just a failure of the simulation prompt.
- **Evidence anchors:**
  - [abstract] "these models did not work on GPT-based data because of differences in simulated networks and psychometric scores."
  - [section] Experiment 3 Discussion: "LLMs can reproduce affective language but lack genuine emotional grounding or self-referential cognition."
  - [corpus] Corpus evidence is weak for this specific cognitive mechanism; Paper 3287 discusses general trust/anxiety in AI assistants but does not validate the structural network gap.
- **Break condition:** If GPT models showed similar R-squared values and regression coefficients to human students when predicting anxiety from network features.

### Mechanism 3
- **Claim:** Human students exhibit cognitive dissonance by framing "science" positively while framing "math" negatively, a specific emotional polarization not consistently replicated by AI.
- **Mechanism:** Negative emotional reasoning targets specific triggers (math/evaluation) while sparing broader abstract concepts (science). In contrast, GPT-3.5 often framed "math" positively (using advanced terminology), failing to mirror the human "math anxiety" stereotype.
- **Core assumption:** The contrast in valence between "science" and "math" is a hallmark of the specific "math anxiety" construct rather than general academic anxiety.
- **Evidence anchors:**
  - [abstract] "'Science' was rated positively, but contrasted against the negative perception of 'math'."
  - [section] Experiment 4 Results (Science/Math Semantic Frames): Human high-anxiety students perceived "math" negatively, whereas GPT-3.5 students perceived it positively.
  - [corpus] Paper 12558 discusses evaluating VLMs on student math drawings, providing context on how models perceive math artifacts, though not specifically the valence mechanism.
- **Break condition:** If GPT models spontaneously adopted the negative valence framing of "math" relative to "science" found in high-anxiety human populations without specific negative priming.

## Foundational Learning

- **Concept: Behavioral Forma Mentis Networks (BFMNs)**
  - **Why needed here:** This is the core analytical unit of the paper. You must understand that BFMNs map free associations (links) and emotional ratings (valence) to visualize a "mindset."
  - **Quick check question:** How does a BFMN differ from a standard semantic network? (Answer: It integrates affective valence data with associative links.)

- **Concept: Centrality Measures (Degree vs. Closeness)**
  - **Why needed here:** The paper relies on these metrics to quantify "structural prominence." "Degree" counts connections (richness), while "closeness" measures how easily one concept reaches others (accessibility).
  - **Quick check question:** In this study, which centrality measure of "anxiety" was a better predictor of total math anxiety?

- **Concept: Prompt Engineering / Personification**
  - **Why needed here:** To understand Experiment 3, you need to know how the authors attempted to force variance in GPT outputs by assigning profiles (age, gender, socio-economic status) to "simulate" students rather than asking the model directly.
  - **Quick check question:** Why did the authors use specific socio-demographic prompts for the GPT models? (Answer: To embed variety and ecological validity in the simulated responses.)

## Architecture Onboarding

- **Component map:** Data Collection -> Network Construction -> Analysis Engine
- **Critical path:**
  1. **Prompting:** Defining the 40 cue words and the "student persona" prompt.
  2. **Extraction:** Parsing free associations and valence ratings (1-5).
  3. **Aggregation:** converting individual ratings to categorical valence (positive/negative/neutral) via quartiles.
  4. **Modeling:** Running regressions to predict MAS-IT scores from network features.

- **Design tradeoffs:**
  - **Valence Encoding:** The authors used quartile-based thresholds to convert numeric ratings to categorical valence (positive/negative/neutral) to adapt to individual response biases, rather than fixed thresholds.
  - **Sample Size:** GPT sample sizes (n=300) were roughly 4x larger than human samples (n=70/57) to compensate for the "flat" or low-variance nature of AI responses.

- **Failure signatures:**
  - **Positive Math Framing in AI:** If GPT models produce "positive" associations for "math" (e.g., "differential equations") when humans produce negative ones (e.g., "exam"), the simulation has failed to capture the anxiety mindset.
  - **Low R-squared:** Regression models explaining <3% of variance (as seen in GPT-3.5) indicate the structural features do not map to the "psychological" state.

- **First 3 experiments:**
  1. **Baseline Human:** Test if network features (degree of "anxiety") predict math anxiety in psychology students (Exp 1).
  2. **Replication (Context):** Re-test the hypothesis with different cue words (educational/learning context) to ensure robustness (Exp 2).
  3. **Digital Twin:** Attempt to replicate the human findings in GPT-3.5 and GPT-4o using persona-based prompting to see if AI "minds" work the same way (Exp 3).

## Open Questions the Paper Calls Out

- **Question:** Does math anxiety cause the restructuring of associative knowledge, or do pre-existing network structures increase vulnerability to anxiety?
  - **Basis in paper:** [explicit] The Discussion states that "it remains unclear whether anxiety reorganises associative structure or whether pre-existing associative biases increase vulnerability to anxiety."
  - **Why unresolved:** The study utilizes a cross-sectional design, which identifies correlations between network features and anxiety levels but cannot establish the direction of causality.
  - **What evidence would resolve it:** Longitudinal studies tracking changes in network centrality and valence over time, or intervention studies that attempt to modify associative structures to reduce anxiety.

- **Question:** Does the predictive relationship between network structure and math anxiety found in psychology students generalize to other academic disciplines?
  - **Basis in paper:** [explicit] The Limitations section notes the human data "were collected from psychology undergraduates and may not reflect how math anxiety manifests in students from other STEM-oriented fields."
  - **Why unresolved:** The study relied on convenience sampling within a specific department, limiting the ability to generalize findings to students with different academic backgrounds or mathematical expertise.
  - **What evidence would resolve it:** Replicating the BFMN methodology with diverse student populations, such as engineering or mathematics majors, to determine if the same network features predict anxiety.

- **Question:** Can integrating affective grounding enable Large Language Models to simulate human-like cognitive-emotional structures related to math anxiety?
  - **Basis in paper:** [inferred] The Discussion concludes that LLMs fail to model anxiety because they lack "affective grounding" and "embodied experience," suggesting a need for "hybrid cognitive/affective models."
  - **Why unresolved:** Current LLMs operate on linguistic co-occurrence patterns and lack the physiological or emotional feedback loops hypothesized to drive the anxiety-structure link in humans.
  - **What evidence would resolve it:** Developing LLMs enhanced with knowledge graphs or affective tagging systems, then testing if their simulated BFMNs can predict psychometric scores with the accuracy found in human samples.

## Limitations

- The human data were collected from psychology undergraduates and may not reflect how math anxiety manifests in students from other STEM-oriented fields.
- The use of persona-based prompting for LLMs is an untested approach and results may reflect prompt sensitivity rather than genuine cognitive differences.
- The valence encoding scheme (quartile-based thresholds) is adaptive per participant, making cross-model comparisons potentially non-equivalent and limiting generalizability.

## Confidence

- **High confidence:** The finding that human students' math anxiety correlates with the structural prominence and affective valence of "anxiety" in their associative networks, as this is supported by robust regression results (R² up to 0.59) and aligns with cognitive theory.
- **Medium confidence:** The claim that LLMs fundamentally differ from humans in linking anxiety to network structure, due to uncertainty about prompt effects and the possibility that alternative simulation strategies might yield different results.
- **Low confidence:** The conclusion about specific emotional polarization (science vs. math valence) in high-anxiety students, as this relies on between-group comparisons with small sample sizes and lacks direct replication.

## Next Checks

1. **Prompt Robustness Test:** Re-run the GPT simulations with varied temperature and top_p settings to assess the stability of the "math positivity" effect.
2. **Cross-Cultural Replication:** Test the human BFMN-anxiety correlation in a non-Western undergraduate sample to evaluate cultural generalizability.
3. **Alternative LLM Architectures:** Compare results across different model families (e.g., Claude, LLaMA) to determine if the observed AI-human differences are model-specific or represent a broader class distinction.