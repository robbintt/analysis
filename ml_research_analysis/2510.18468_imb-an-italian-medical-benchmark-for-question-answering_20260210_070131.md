---
ver: rpa2
title: 'IMB: An Italian Medical Benchmark for Question Answering'
arxiv_id: '2510.18468'
source_url: https://arxiv.org/abs/2510.18468
tags:
- medical
- question
- questions
- https
- italian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces IMB, the first large-scale Italian medical
  benchmark for question answering, consisting of two datasets: IMB-QA with 782,644
  patient-doctor conversations across 77 medical categories, and IMB-MCQA with 25,862
  multiple-choice questions from medical specialty exams. The authors address the
  challenge of limited medical QA resources for non-English languages by leveraging
  Large Language Models to improve data quality and anonymization while preserving
  conversational authenticity.'
---

# IMB: An Italian Medical Benchmark for Question Answering

## Quick Facts
- arXiv ID: 2510.18468
- Source URL: https://arxiv.org/abs/2510.18468
- Reference count: 40
- Primary result: First large-scale Italian medical QA benchmark showing specialized adaptation outperforms larger general models

## Executive Summary
This paper introduces IMB, the first large-scale Italian medical benchmark for question answering, consisting of two datasets: IMB-QA with 782,644 patient-doctor conversations across 77 medical categories, and IMB-MCQA with 25,862 multiple-choice questions from medical specialty exams. The authors address the challenge of limited medical QA resources for non-English languages by leveraging Large Language Models to improve data quality and anonymization while preserving conversational authenticity. Through experiments with Retrieval-Augmented Generation (RAG) and domain-specific fine-tuning, they demonstrate that specialized adaptation strategies can outperform larger general-purpose models in medical QA tasks. Their results show BERTScore Precision improvements up to 0.638 and accuracy gains through RAG and fine-tuning, challenging the assumption that model scale is the primary factor for medical QA success.

## Method Summary
The methodology involves creating two Italian medical QA datasets through automated preprocessing of forum data. IMB-QA contains patient-doctor conversations from medical forums, processed through an LLM-assisted pipeline using Llama3-Med42-8B for text reformulation and Italian_NER_XXL for PII removal. IMB-MCQA consists of medical specialty exam questions. The paper evaluates Retrieval-Augmented Generation using FAISS with MiniLM embeddings and domain-specific fine-tuning of small language models (1B-3B parameters) on these datasets. Experiments compare standard LLMs against RAG-enhanced versions and fine-tuned models using BERTScore Precision for open-ended QA and accuracy for multiple-choice questions.

## Key Results
- Specialized adaptation strategies (RAG and fine-tuning) can outperform larger general-purpose models in medical QA tasks
- BERTScore Precision improvements up to 0.638 achieved through domain-specific fine-tuning
- RAG consistently improves semantic precision across medical categories when retrieving from 100k knowledge base passages
- Fine-tuned Small Language Models (1B-3B parameters) compete effectively with larger 70B parameter models

## Why This Works (Mechanism)

### Mechanism 1: Contextual Grounding via RAG
- **Claim:** Retrieval-Augmented Generation (RAG) improves semantic precision in medical open-ended QA by constraining the model with relevant prior knowledge.
- **Mechanism:** A dense vector index (FAISS with `all-MiniLM-L6-v2` embeddings) retrieves the top-5 relevant passages from a 100k knowledge base. These passages are prepended to the user query, providing factual context that grounds the generation process.
- **Core assumption:** The retriever successfully surfaces documents that contain the answer or relevant diagnostic logic for the specific query.
- **Evidence anchors:** Table 7 shows consistent BERTScore Precision improvements (e.g., Neurology improving from 0.653 to 0.706) when RAG is applied to `gemma-2-9b-it`.

### Mechanism 2: Domain Adaptation via Fine-Tuning SLMs
- **Claim:** Fine-tuning Small Language Models (SLMs) on a domain-specific corpus allows them to compete with larger general-purpose models on semantic alignment.
- **Mechanism:** By training smaller models (1B–3B parameters) on the IMB-QA dataset, the model's weights adapt to the specific distribution of Italian medical terminology and the conversational structure of patient-doctor interactions.
- **Core assumption:** The quality of the "reformulated" answers in the training set is high enough to guide the model without introducing noise.
- **Evidence anchors:** Table 8 demonstrates that fine-tuning `Llama-3.2-3B-Instruct` improves BERTScore Precision from 0.6332 to 0.7031.

### Mechanism 3: LLM-Assisted Data Refinement
- **Claim:** Automated preprocessing using specialized LLMs improves the signal-to-noise ratio of raw forum data, making it viable for benchmarking and training.
- **Mechanism:** A pipeline uses a medical LLM (`Llama3-Med42-8B`) to rewrite colloquial forum responses into coherent, standardized Italian, while a separate NER model (`Italian_NER_XXL`) identifies and removes Personally Identifiable Information (PII).
- **Core assumption:** The rewriting LLM preserves the medical semantics of the original doctor's advice while changing the stylistic presentation.
- **Evidence anchors:** Section 3.2.1 states that the reformulation and anonymization pipeline reduced PII presence from 27% to 1% while improving readability.

## Foundational Learning

- **Concept: BERTScore vs. Lexical Overlap**
  - **Why needed here:** In medical QA, a correct answer can be phrased in many ways. Traditional metrics like BLEU measure exact token overlap, which fails to capture semantic correctness. BERTScore measures embedding similarity.
  - **Quick check question:** If a model answers "Hypertension" instead of "High Blood Pressure," which metric would penalize it less?

- **Concept: Retrieval-Augmented Generation (RAG)**
  - **Why needed here:** The paper highlights that model scale is not the only driver of performance. Understanding how to bolt a retrieval system (FAISS) onto an LLM is essential to reproducing their results.
  - **Quick check question:** Why does prepending "top-5 relevant passages" to a query reduce hallucination?

- **Concept: Hallucination in Medical LLMs**
  - **Why needed here:** The paper explicitly targets the reduction of hallucinations through RAG and fine-tuning.
  - **Quick check question:** Why is "semantic grounding" (linking generated text to retrieved facts) critical in a clinical context compared to a creative writing context?

## Architecture Onboarding

- **Component map:** Raw sources (MedicItalia, Dica33) → Preprocessing Pipeline (NER for PII + Llama3-Med42 for rewriting) → IMB-QA / IMB-MCQA → Embeddings via `all-MiniLM-L6-v2` → FAISS Index (100k contexts) → Base LLM (e.g., Gemma-2-9b-it) + Adapter (Fine-tuning weights on IMB-QA) → BERTScore (semantic similarity) for QA; Accuracy for MCQA

- **Critical path:** The **Data Preprocessing (Anonymization & Reformulation)** is the most critical step. If the PII removal fails, the dataset cannot be used. If the reformulation is too aggressive, the "authentic" nature of the conversations is lost, reducing the dataset's value for training robust models.

- **Design tradeoffs:**
  - Scale vs. Specificity: The paper argues that a smaller model (8B-9B) with RAG or fine-tuning can outperform a 70B general model.
  - Privacy vs. Fidelity: Aggressive anonymization ensures safety but risks stripping context.
  - Multiple-Choice vs. Open-Ended: The architecture supports both, but Open-Ended requires significantly more complex evaluation (BERTScore vs. Accuracy).

- **Failure signatures:**
  - Category Overfitting: Model performs well on "Gastroenterology" (high volume) but fails on "Pediatric Surgery" (low volume).
  - Context Confusion: RAG retrieves irrelevant passages if the query is too short or ambiguous, leading to "distracted" generation.
  - Language Drift: Models trained predominantly on English medical data (e.g., BioBERT) struggle with Italian nuances without specific adaptation.

- **First 3 experiments:**
  1. **Baseline Benchmark:** Run `Llama-3.1-8B-Instruct` (no RAG, no fine-tuning) on IMB-MCQA to establish a baseline accuracy score.
  2. **RAG Implementation:** Build the FAISS index from a subset of IMB-QA answers and evaluate `gemma-2-9b-it` with and without retrieved context on the Neurology category (highest difficulty) to isolate the RAG contribution.
  3. **SLM Fine-Tuning:** Fine-tune `Llama-3.2-1B` on the IMB-QA dataset (80/20 split) and compare BERTScore Precision against the baseline to validate the "specialization over scale" hypothesis.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does expanding the benchmark to include English data and balancing under-represented medical categories impact cross-lingual transfer learning and model generalization?
- **Basis in paper:** [Explicit] The authors state in the Conclusion that future work will focus on "expanding the dataset by incorporating additional medical specialties and languages (such as English)" and "improving category balancing."
- **Why unresolved:** The current dataset is strictly Italian-only and suffers from severe class imbalances (e.g., Gastroenterology is over-represented while Sleep Medicine is scarce), making it impossible to assess cross-lingual capabilities or performance on niche specialties with the current release.
- **What evidence would resolve it:** Comparative performance metrics of models trained on the new multilingual/balanced version versus the current monolingual/imbalanced version, specifically testing performance on the previously under-represented categories.

### Open Question 2
- **Question:** To what extent can advanced semantic filtering and human verification reduce informational noise in the IMB-QA dataset without stripping away the conversational authenticity required for realistic patient-doctor modeling?
- **Basis in paper:** [Explicit] The authors identify informational noise as a key limitation and propose future work on "implementing advanced filtering techniques" combined with "semantic filtering and human verification methods."
- **Why unresolved:** While the current pipeline uses LLMs to reformulate text, the paper notes that forum data often contains "irrelevant or ambiguous details." It is unclear if automated filtering can remove this noise while preserving the "colloquial language" and "implicit medical knowledge" the authors aim to capture.
- **What evidence would resolve it:** A comparative study measuring signal-to-noise ratios and "authenticity" scores (via human expert review) between the current dataset and a version processed with the proposed advanced filtering techniques.

### Open Question 3
- **Question:** What specific validation metrics are required to ensure that LLM-based anonymization effectively mitigates indirect re-identification risks in medical forum data?
- **Basis in paper:** [Explicit] The paper acknowledges that "ensuring complete anonymization is inherently challenging" and states that "Future iterations of the dataset will incorporate additional validation steps to assess and improve the effectiveness of the anonymization process."
- **Why unresolved:** While NER reduced detectable PII to 1%, the authors admit that "indirect re-identification risks may persist" (e.g., via rare medical conditions combined with location). The current methodology does not quantify or validate protection against these indirect attacks.
- **What evidence would resolve it:** Results from red-teaming exercises or adversarial attacks attempting to re-identify individuals in the dataset using auxiliary information, thereby proving the robustness of the anonymization beyond simple PII detection.

### Open Question 4
- **Question:** Does the improvement in semantic similarity scores (BERTScore) for fine-tuned Small Language Models correlate with a reduction in factual hallucinations?
- **Basis in paper:** [Inferred] The paper highlights that medical QA requires models that do not hallucinate, but the authors explicitly note that "formal hallucination metrics are not reported" despite observing improved BERTScore Precision in fine-tuned models.
- **Why unresolved:** BERTScore measures semantic overlap, not factual accuracy. A model could theoretically achieve a high BERTScore by generating fluent, medically plausible but factually incorrect statements (hallucinations), misleading researchers about the model's true clinical safety.
- **What evidence would resolve it:** Evaluation of the fine-tuned SLMs using dedicated hallucination detection metrics (e.g., FACTSCORE or Med-HALT) or expert human annotation to verify that higher BERTScores align with increased factual accuracy.

## Limitations

- **Data Quality Uncertainty:** The LLM-assisted preprocessing pipeline may inadvertently remove medically relevant nuances or introduce subtle biases while attempting to improve data quality and anonymization.
- **Evaluation Metric Gaps:** While BERTScore and accuracy are appropriate metrics, they do not directly measure clinical accuracy or safety-critical aspects of medical responses, nor do they address potential hallucinations that might persist despite RAG and fine-tuning.
- **Class Imbalance Issues:** The dataset suffers from severe category imbalances, with some specialties like Gastroenterology being over-represented while others like Sleep Medicine are scarce, limiting the model's ability to generalize across all medical domains.

## Confidence

- **High Confidence:** The demonstration that specialized adaptation strategies (RAG and fine-tuning) can outperform larger general-purpose models is well-supported by experimental results showing consistent BERTScore Precision improvements and accuracy gains.
- **Medium Confidence:** The claim about this being the first large-scale Italian medical benchmark is plausible given the cited lack of resources for non-English languages, but would benefit from more thorough literature review to confirm absolute novelty.
- **Low Confidence:** The assertion that their results "challenge the assumption that model scale is the primary factor for medical QA success" is somewhat overstated, as they primarily demonstrate that 8B-9B models with appropriate adaptation can match or slightly exceed a 70B model, rather than definitively proving scale is unimportant.

## Next Checks

1. **Clinical Expert Review:** Have medical professionals evaluate a random sample of model-generated responses from the IMB-QA dataset to assess clinical accuracy and identify any persistent hallucinations or safety concerns that automated metrics might miss.

2. **Category Balance Analysis:** Analyze the performance distribution across all 77 medical categories to identify whether the model exhibits significant overfitting to high-frequency specialties and quantify performance degradation on rare categories.

3. **Generalization Test:** Evaluate the fine-tuned models on external Italian medical QA datasets (if available) or translate English medical QA datasets to Italian to test whether the adaptation truly captures Italian medical language nuances or simply overfits to the specific forum style in IMB-QA.