---
ver: rpa2
title: A Variational Approach for Mitigating Entity Bias in Relation Extraction
arxiv_id: '2506.11381'
source_url: https://arxiv.org/abs/2506.11381
tags:
- entity
- relation
- variance
- pers
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses entity bias in relation extraction, where models
  rely excessively on entities rather than contextual cues. It introduces a variational
  information bottleneck (VIB) framework that maps entities into probabilistic distributions,
  allowing the model to quantify and reduce reliance on entity-specific information
  while preserving task-relevant features.
---

# A Variational Approach for Mitigating Entity Bias in Relation Extraction

## Quick Facts
- **arXiv ID:** 2506.11381
- **Source URL:** https://arxiv.org/abs/2506.11381
- **Reference count:** 20
- **Primary result:** Variational Information Bottleneck (VIB) framework mitigates entity bias in RE, achieving SOTA on TACRED (70.4% ID, 66.5% OOD) and superior interpretability via learned variance.

## Executive Summary
This paper addresses entity bias in relation extraction, where models over-rely on entity identities rather than contextual cues, leading to poor out-of-domain generalization. The authors introduce a variational information bottleneck framework that maps entities into probabilistic distributions with learned variances, explicitly controlling the trade-off between entity-specific and contextual information. Experiments on TACRED, REFinD, and BioRED datasets show state-of-the-art performance, with LUKE-Large achieving 70.4% (ID) and 66.5% (OOD) on TACRED. The approach also provides intrinsic interpretability by quantifying per-instance entity versus context reliance through variance analysis.

## Method Summary
The VIB framework integrates into PLMs like RoBERTa-Large or LUKE-Large by mapping entity tokens to learnable Gaussian distributions using single-layer perceptrons that predict mean (μ) and standard deviation (σ). A binary entity mask ensures compression targets only entity tokens, preserving contextual representations. The original entity embeddings are blended with stochastic samples z ~ N(μ, σ) at ratio β=0.5, forcing the model to rely more on context when variance is high. Training minimizes a combined loss of cross-entropy and VIB objective (KL divergence to standard normal), with adaptive weighting α balancing the two terms. This approach explicitly compresses entity-specific information while retaining relation-predictive features.

## Key Results
- VIB achieves 70.4% ID and 66.5% OOD F1 on TACRED with LUKE-Large, outperforming SCM by 2.1% and 4.1% respectively
- On REFinD and BioRED datasets, VIB improves OOD performance by 3.7% and 2.9% over SCM baselines
- Variance analysis shows low variance indicates entity reliance while high variance reflects context usage, providing intrinsic interpretability
- LUKE backbone shows larger gains than RoBERTa, confirming entity-aware pretraining amplifies VIB effectiveness

## Why This Works (Mechanism)

### Mechanism 1
- Mapping entity tokens to learnable Gaussian distributions provides a differentiable mechanism to compress entity-specific information while preserving relation-predictive features. The VIB replaces deterministic entity embeddings with stochastic encodings z ~ N(μ, σ), where learned variance σ² controls information throughput—low variance yields tighter encodings (preserving entity identity), while high variance increases stochasticity, forcing greater reliance on contextual cues. The reparameterization trick enables gradient flow through sampling.

### Mechanism 2
- Selective blending via a binary entity mask ensures compression targets only entity tokens, preserving contextual representations essential for relation prediction. A binary mask M identifies entity positions, with non-entity tokens retaining original embeddings while entity tokens blend deterministic and stochastic representations at ratio β=0.5. This isolates perturbation to entities while leaving context untouched.

### Mechanism 3
- Learned variance provides intrinsic interpretability, quantifying per-instance entity vs. context reliance without external probing modules. During inference, the trained SLP outputs σ per entity token, where variance σ² inversely correlates with entity reliance—low variance indicates stronger entity dependence, while high variance reflects greater context reliance. This emerges from training dynamics rather than requiring separate interpretability infrastructure.

## Foundational Learning

- **Variational Information Bottleneck (VIB)**: Why needed: The entire framework builds on VIB theory—understanding how mutual information constraints create compression is essential to grasp why entity debiasing occurs. Quick check: Explain why minimizing I(X; Z|E) encourages the latent Z to retain semantic content while discarding entity-specific information.

- **Reparameterization Trick**: Why needed: Enables backpropagation through stochastic sampling z = μ + ε · σ; without this, gradient-based optimization of Gaussian parameters is impossible. Quick check: Why can't gradients flow directly through a sampled z ~ N(μ, σ), and how does reparameterization resolve this?

- **Entity Bias in Relation Extraction**: Why needed: Understanding the core problem—models overfit to entity identity/type rather than learning relational patterns from context, causing poor out-of-domain generalization. Quick check: Provide an example where entity bias would yield correct in-domain predictions but failures on entity-replaced OOD test sets.

## Architecture Onboarding

- **Component map**: Input tokens with [hs]/[ho] markers → Entity mask extraction → VIB encoding (μ, σ) → Reparameterized sampling → Blended embedding x' → PLM backbone → Entity marker extraction → Classification → Joint loss

- **Critical path**: Input → Entity mask extraction → VIB encoding (μ, σ) → Reparameterized sampling → Blended embedding x' → PLM forward pass → Entity marker extraction → Classification → Joint loss

- **Design tradeoffs**: β=0.5 is empirically optimal; higher values increase debiasing but risk losing entity type signals. LUKE shows larger gains than RoBERTa due to entity-aware pretraining. Per-token variance prediction may be restrictive for multi-token entities. Gaussian assumption is tractable but potentially limiting.

- **Failure signatures**: Variance collapse (all σ → 0 indicates bypassed bottleneck); OOD performance gap >15 F1 suggests insufficient context reliance; relation-specific degradation shows VIB excels on context-heavy relations but underperforms on entity-reliant ones.

- **First 3 experiments**: 1) β sweep validation on TACRED ID/OOD to confirm 0.5 generalizes. 2) Interpretability correlation by manually annotating entity vs. context reliance and correlating with predicted variance. 3) Backbone scaling to DistilBERT to test if entity-aware pretraining is necessary.

## Open Questions the Paper Calls Out

- Can the VIB framework be effectively adapted for generative Large Language Models (LLMs) and encoder-decoder architectures like T5?
- How does the VIB approach perform in multilingual settings where language-specific nuances might alter the balance between entity and context reliance?
- How can the model dynamically handle instances where high variance forces reliance on context, but the available context is uninformative or sparse?

## Limitations

- The interpretability claims rely on aggregate OOD statistics rather than instance-level human validation
- Hyperparameter sensitivity to β and adaptive α weighting lacks comprehensive analysis
- Gaussian assumption per entity token may be too restrictive for complex entity representations

## Confidence

- **High Confidence**: Core VIB mechanism and mathematical formulation are well-specified and theoretically grounded
- **Medium Confidence**: Selective blending mechanism is clearly defined but isolation effect on contextual tokens is inferred rather than directly tested
- **Low Confidence**: Claim of universal superiority is partially supported—VIB excels on context-heavy relations but underperforms on entity-reliant ones

## Next Checks

1. **Instance-Level Interpretability Test**: Manually annotate 100 OOD examples with entity vs. context reliance scores, then correlate these with model-predicted variances to validate interpretability mechanism beyond aggregate statistics

2. **VIB Architecture Ablation**: Test alternative variance prediction strategies including per-entity pooling, mixture models instead of single Gaussians, and different σ clipping thresholds to assess Gaussian assumption's impact

3. **Backbone Generalization Study**: Apply VIB to smaller PLMs (DistilBERT, BERT-base) and entity-oblivious models to determine whether gains depend on entity-aware pretraining or transfer to general architectures