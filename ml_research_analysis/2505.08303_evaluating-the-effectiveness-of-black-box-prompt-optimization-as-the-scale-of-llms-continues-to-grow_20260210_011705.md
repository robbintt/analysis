---
ver: rpa2
title: Evaluating the Effectiveness of Black-Box Prompt Optimization as the Scale
  of LLMs Continues to Grow
arxiv_id: '2505.08303'
source_url: https://arxiv.org/abs/2505.08303
tags:
- prompt
- optimization
- llms
- methods
- prompts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigates the effectiveness of black-box prompt\
  \ optimization methods as large language models (LLMs) continue to scale up. The\
  \ authors evaluate three popular black-box optimization techniques\u2014EvoPrompt,\
  \ ProTeGi, and BPO\u2014on large-scale models including DeepSeek V3 (671B) and Gemini\
  \ 2.0 Flash across four NLU and NLG datasets."
---

# Evaluating the Effectiveness of Black-Box Prompt Optimization as the Scale of LLMs Continues to Grow

## Quick Facts
- **arXiv ID**: 2505.08303
- **Source URL**: https://arxiv.org/abs/2505.08303
- **Reference count**: 9
- **Primary Result**: Black-box prompt optimization yields only marginal improvements (0.86-2.03%) on large-scale LLMs due to inverse scaling law

## Executive Summary
This study investigates how black-box prompt optimization effectiveness changes as large language models scale up. The authors evaluate three popular black-box optimization techniques—EvoPrompt, ProTeGi, and BPO—on large-scale models including DeepSeek V3 (671B) and Gemini 2.0 Flash across four NLU and NLG datasets. Results show only limited performance improvements: for NLU tasks, average accuracy gains were 0.86% and 1.16% for DeepSeek V3 and Gemini 2.0 Flash respectively, while NLG tasks saw improvements of 1.04% and 2.03%. To understand this phenomenon, experiments were conducted on Qwen 2.5 models ranging from 7B to 72B parameters, revealing an inverse scaling law where optimization effectiveness diminishes as model size increases. The study suggests that larger models' superior inherent alignment and semantic understanding make them less sensitive to subtle prompt variations, rendering black-box optimization less beneficial at scale.

## Method Summary
The authors evaluated three black-box prompt optimization methods (EvoPrompt, ProTeGi, and BPO) on large-scale language models including DeepSeek V3 (671B) and Gemini 2.0 Flash. They tested these methods across four datasets spanning both natural language understanding and generation tasks. To investigate the scaling relationship, they conducted controlled experiments on Qwen 2.5 models ranging from 7B to 72B parameters, systematically measuring optimization effectiveness as model size increased. The evaluation measured accuracy improvements for NLU tasks and performance gains for NLG tasks, providing quantitative evidence for the inverse scaling phenomenon.

## Key Results
- Black-box optimization achieved only 0.86% and 1.16% average accuracy improvements on DeepSeek V3 and Gemini 2.0 Flash for NLU tasks
- NLG tasks showed slightly better but still limited improvements of 1.04% and 2.03% for the respective models
- Inverse scaling law observed: optimization effectiveness decreased systematically as model size increased from 7B to 72B parameters

## Why This Works (Mechanism)
The effectiveness of black-box prompt optimization is inversely related to model scale because larger models possess superior inherent alignment and semantic understanding. These enhanced capabilities make them less sensitive to subtle prompt variations, reducing the marginal gains achievable through external optimization techniques. As models become more capable of understanding and responding to natural language instructions, the need for carefully engineered prompt variations diminishes.

## Foundational Learning
- **Inverse Scaling Law**: Why needed - To understand how optimization effectiveness changes with model size; Quick check - Verify diminishing returns across multiple model families
- **Black-Box Optimization**: Why needed - Core methodology being evaluated; Quick check - Compare performance against white-box approaches
- **Semantic Understanding**: Why needed - Key factor affecting prompt sensitivity; Quick check - Measure correlation between semantic capabilities and optimization gains
- **Prompt Sensitivity**: Why needed - Determines optimization potential; Quick check - Quantify how parameter count affects response to prompt variations
- **NLU vs NLG Task Differences**: Why needed - To understand task-specific optimization effects; Quick check - Compare scaling patterns across task types
- **Alignment Capabilities**: Why needed - Primary driver of reduced optimization effectiveness; Quick check - Correlate alignment metrics with optimization gains

## Architecture Onboarding

**Component Map**: Data → Model (various sizes) → Black-Box Optimizer (EvoPrompt/ProTeGi/BPO) → Prompt Variations → Performance Metrics

**Critical Path**: Task specification → Prompt optimization → Model inference → Performance evaluation → Scaling analysis

**Design Tradeoffs**: Computational cost of optimization vs. marginal performance gains; Generalizability across task types vs. task-specific optimization; Black-box vs. white-box approaches

**Failure Signatures**: Marginal gains (<2%) across large models; Systematic decrease in optimization effectiveness with increasing parameter count; Task-dependent variations in optimization returns

**First Experiments**:
1. Baseline evaluation of three black-box optimizers on 7B model
2. Scaling experiment measuring optimization effectiveness across 7B-72B parameter range
3. Task-type comparison between NLU and NLG optimization performance

## Open Questions the Paper Calls Out
The authors acknowledge that black-box optimization may still provide value in specialized or constrained scenarios not captured in their evaluation, though these scenarios remain underspecified. The study does not characterize what specific conditions or task types might benefit from optimization despite the inverse scaling trend.

## Limitations
- Evaluation limited to four datasets across only two model families (DeepSeek and Gemini)
- Unclear generalizability across different domains, languages, and task types
- Does not account for variations across different prompting paradigms (chain-of-thought, few-shot, etc.)
- Specialized scenarios where optimization might still be valuable remain underspecified

## Confidence
**High Confidence**: The empirical finding that black-box prompt optimization yields only marginal improvements (0.86-2.03%) on large-scale models is well-supported by the experimental results across multiple model sizes and tasks.

**Medium Confidence**: The proposed inverse scaling law explanation (that larger models' superior alignment reduces sensitivity to prompt variations) is plausible but requires additional validation across more diverse model architectures and task types.

**Medium Confidence**: The conclusion that black-box optimization is "less beneficial at scale" appropriately qualifies the finding by acknowledging potential utility in specialized scenarios, though these scenarios need clearer characterization.

## Next Checks
1. Replicate the inverse scaling experiments across additional model families (GPT, Claude, Llama) and task categories to verify whether the phenomenon generalizes beyond DeepSeek and Gemini.

2. Conduct ablation studies testing different prompting paradigms (chain-of-thought, role prompting, few-shot) to determine if optimization effectiveness varies by instruction format.

3. Evaluate optimization performance on domain-specific or low-resource language tasks where prompt engineering traditionally shows higher returns, to test whether the authors' caveat about specialized scenarios holds true.