---
ver: rpa2
title: 'Empirical Likelihood-Based Fairness Auditing: Distribution-Free Certification
  and Flagging'
arxiv_id: '2601.20269'
source_url: https://arxiv.org/abs/2601.20269
tags:
- hypothesis
- empirical
- disparity
- theorem
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an empirical likelihood-based fairness auditing
  (ELFA) framework for certifying and flagging algorithmic bias in black-box models
  without requiring distributional assumptions. The method constructs empirical likelihood
  ratio statistics for performance disparities across sensitive subgroups, leveraging
  their asymptotic chi-square distributions for valid inference.
---

# Empirical Likelihood-Based Fairness Auditing: Distribution-Free Certification and Flagging

## Quick Facts
- **arXiv ID**: 2601.20269
- **Source URL**: https://arxiv.org/abs/2601.20269
- **Reference count**: 40
- **Primary result**: Distribution-free framework for certifying and flagging algorithmic bias using empirical likelihood ratio statistics

## Executive Summary
This paper introduces an empirical likelihood-based fairness auditing (ELFA) framework for certifying and flagging algorithmic bias in black-box models without requiring distributional assumptions. The method constructs empirical likelihood ratio statistics for performance disparities across sensitive subgroups, leveraging their asymptotic chi-square distributions for valid inference. For certification, it tests whether zero falls within the confidence interval; for flagging, it uses the Benjamini-Hochberg procedure with EL-derived p-values to control false discovery rates. Simulation studies demonstrate that ELFA achieves coverage probabilities closer to nominal levels than bootstrap methods while being computationally efficient, with runtime reduced by several orders of magnitude. Applied to the COMPAS dataset, ELFA successfully identifies intersectional biases, revealing higher positive prediction rates for African-American males under 25 and lower rates for Caucasian females relative to population means.

## Method Summary
The ELFA framework constructs empirical likelihood ratio statistics to test for performance disparities across sensitive subgroups without requiring distributional assumptions. For certification, it evaluates whether observed disparities are statistically distinguishable from zero using confidence intervals derived from the asymptotic chi-square distribution of the likelihood ratio statistic. For flagging, it computes p-values from the same statistic and applies the Benjamini-Hochberg procedure to control the false discovery rate across multiple subgroup comparisons. The approach leverages the nonparametric nature of empirical likelihood to provide distribution-free inference while maintaining computational efficiency compared to bootstrap-based alternatives.

## Key Results
- ELFA achieves coverage probabilities closer to nominal levels than bootstrap methods across simulation studies
- Runtime efficiency improved by several orders of magnitude compared to bootstrap approaches
- Successfully identified intersectional biases in COMPAS dataset: higher positive prediction rates for African-American males under 25, lower rates for Caucasian females relative to population means

## Why This Works (Mechanism)
The method works by constructing empirical likelihood ratio statistics that capture the relative plausibility of observed performance disparities under the null hypothesis of no bias. These statistics follow an asymptotic chi-square distribution, enabling valid hypothesis testing without distributional assumptions. The Benjamini-Hochberg procedure then controls the false discovery rate when conducting multiple comparisons across subgroups, providing a principled way to flag potential biases while accounting for multiplicity.

## Foundational Learning
The framework builds upon the theoretical foundation of empirical likelihood, which provides a nonparametric approach to statistical inference by treating the empirical distribution as the reference. By leveraging the asymptotic chi-square distribution of empirical likelihood ratio statistics, ELFA enables distribution-free inference for fairness auditing. The method also incorporates established multiple testing correction procedures to handle the multiplicity inherent in subgroup comparisons.

## Architecture Onboarding
The ELFA framework can be integrated into existing fairness auditing pipelines as a drop-in replacement for bootstrap-based methods. It requires only the ability to compute performance metrics across sensitive subgroups and access to the empirical distribution of these metrics. The method's distribution-free nature means it can be applied regardless of the underlying data distribution, making it particularly suitable for black-box models where distributional assumptions cannot be verified.

## Open Questions the Paper Calls Out
The paper does not explicitly identify open questions, but implicit challenges include extending the framework to handle more complex fairness definitions, determining optimal subgroup definitions for intersectional analysis, and establishing theoretical guarantees for finite sample performance.

## Limitations
- Asymptotic chi-square approximations may not hold for small sample sizes or highly imbalanced subgroups
- Computational efficiency claims lack specific sample sizes and computational environment details
- COMPAS dataset analysis focuses on descriptive subgroup comparisons rather than framework effectiveness at scale
- The framework assumes independent observations, which may not hold in certain applications
- No theoretical analysis of power loss compared to parametric methods when distributional assumptions are actually met

## Confidence
- **Theoretical framework**: High
- **Simulation results**: Medium (limited methodological details)
- **COMPAS dataset application**: Low (focus on descriptive comparisons)

## Next Checks
1. Validate asymptotic approximation accuracy across varying sample sizes and subgroup sizes, particularly when n<100 or subgroup proportions fall below 5%
2. Compare ELFA's sensitivity to detect bias against established methods (e.g., permutation tests, bootstrap) on multiple fairness metrics beyond positive prediction rates
3. Test ELFA's performance when distributional assumptions are actually met to determine if distribution-free approach incurs any power loss compared to parametric methods
4. Evaluate the impact of correlation between observations on ELFA's validity and power
5. Assess the framework's performance on datasets with different characteristics (e.g., varying levels of imbalance, different bias patterns)