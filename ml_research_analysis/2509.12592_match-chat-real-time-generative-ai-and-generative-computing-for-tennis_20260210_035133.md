---
ver: rpa2
title: 'Match Chat: Real Time Generative AI and Generative Computing for Tennis'
arxiv_id: '2509.12592'
source_url: https://arxiv.org/abs/2509.12592
tags:
- match
- user
- chat
- generative
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Match Chat is a real-time generative AI assistant for tennis fans
  that delivers accurate, context-aware match insights via natural language queries.
  It integrates Generative AI with Generative Computing through an Agent-Oriented
  Architecture that combines rule engines, predictive models, and streaming data to
  route and process queries efficiently.
---

# Match Chat: Real Time Generative AI and Generative Computing for Tennis

## Quick Facts
- arXiv ID: 2509.12592
- Source URL: https://arxiv.org/abs/2509.12592
- Reference count: 0
- Primary result: Real-time generative AI assistant for tennis delivering 92.83% accuracy with 6.25s response time under 120 req/sec

## Executive Summary
Match Chat is a real-time generative AI assistant that provides tennis fans with context-aware match insights through natural language queries. The system integrates Generative AI with Generative Computing via an Agent-Oriented Architecture combining rule engines, predictive models, and streaming data to efficiently route and process queries. Deployed at Wimbledon and the US Open, it served nearly 1 million users with high accuracy and response times while maintaining 100% uptime across both tournaments.

## Method Summary
The system uses an Agent-Oriented Architecture that routes queries through a combination of rule engines, predictive models, and streaming data processing components. It leverages real-time data ingestion from tennis matches and employs generative models to create contextually relevant responses. The architecture is designed to mask complexity while maintaining scalability and reliability, with interactive query guidance handling 96% of user interactions.

## Key Results
- 92.83% answer accuracy across Wimbledon and US Open deployments
- 6.25-second average response time under peak load of 120 requests/second
- 100% uptime maintained across both major tennis tournaments
- 96% of queries were guided interactively, serving nearly 1 million users

## Why This Works (Mechanism)
The system's effectiveness stems from its Agent-Oriented Architecture that intelligently routes queries to appropriate processing components. Rule engines handle straightforward queries while predictive models manage complex, context-dependent questions. The integration of streaming data ensures real-time responsiveness, and the interactive guidance system helps users formulate effective queries. This combination allows the system to balance accuracy with performance under high load conditions.

## Foundational Learning
**Agent-Oriented Architecture**: Why needed - To manage complex query routing and processing; Quick check - Verify distinct agent roles and routing logic
**Real-time Streaming Integration**: Why needed - To provide current match data for accurate responses; Quick check - Confirm latency from data ingestion to response generation
**Interactive Query Guidance**: Why needed - To improve user experience and query success rates; Quick check - Measure guidance effectiveness through completion rates

## Architecture Onboarding
**Component Map**: User Query -> Query Router -> Rule Engine | Predictive Model | Streaming Processor -> Response Generator -> User Interface
**Critical Path**: Query reception through routing to final response generation, with fallback paths through multiple processing components
**Design Tradeoffs**: Complexity masking vs. transparency, real-time performance vs. computational cost, accuracy vs. response time
**Failure Signatures**: Query routing failures, streaming data delays, model prediction errors, response generation timeouts
**First Experiments**:
1. Test query routing accuracy with sample tennis match questions
2. Measure streaming data latency from match events to system availability
3. Evaluate response generation quality across different query types

## Open Questions the Paper Calls Out
None

## Limitations
- Accuracy measurement methodology lacks detail and validation against ground truth
- No technical substantiation for 100% uptime claims regarding failover mechanisms
- Interactive guidance definition and measurement criteria not clearly specified

## Confidence
- **High Confidence**: Architecture description, deployment at Wimbledon/US Open, user volume (~1M), query volume and response time metrics
- **Medium Confidence**: Accuracy rate (lacks validation methodology details), 96% interactive query guidance (no definition of what constitutes "guided")
- **Low Confidence**: System complexity masking claims, reliability assertions without technical substantiation

## Next Checks
1. Request detailed methodology for accuracy measurement, including ground truth data sources and annotation protocols
2. Obtain system architecture diagrams showing failover and load balancing mechanisms that enabled claimed 100% uptime
3. Analyze query distribution data to verify the 96% interactive guidance claim and understand the nature of unguided queries