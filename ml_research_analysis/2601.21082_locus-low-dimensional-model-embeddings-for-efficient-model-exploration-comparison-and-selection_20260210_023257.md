---
ver: rpa2
title: 'LOCUS: Low-Dimensional Model Embeddings for Efficient Model Exploration, Comparison,
  and Selection'
arxiv_id: '2601.21082'
source_url: https://arxiv.org/abs/2601.21082
tags:
- embeddings
- embedding
- correctness
- query
- queries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes LOCUS, a method to produce low-dimensional\
  \ vector embeddings that compactly represent a language model\u2019s capabilities\
  \ across queries. LOCUS is an attention-based approach that generates embeddings\
  \ by a deterministic forward pass over query encodings and evaluation scores via\
  \ an encoder model, enabling seamless incorporation of new models to the pool and\
  \ refinement of existing model embeddings without retraining."
---

# LOCUS: Low-Dimensional Model Embeddings for Efficient Model Exploration, Comparison, and Selection

## Quick Facts
- **arXiv ID:** 2601.21082
- **Source URL:** https://arxiv.org/abs/2601.21082
- **Reference count:** 40
- **Primary result:** Up to 4.8× fewer query evaluations needed than baselines for robust, informative model embeddings

## Executive Summary
LOCUS introduces a method to generate low-dimensional vector embeddings that compactly represent a language model's capabilities across queries. The approach uses an attention-based encoder that processes tokenized query-evaluation pairs through latent bottleneck blocks to produce deterministic, permutation-invariant embeddings. These embeddings capture behavioral similarity between models, enabling applications like model comparison, portfolio selection, and proxy routing without retraining when new models are added.

## Method Summary
LOCUS generates model embeddings by processing sets of query encodings and binary correctness scores through an encoder with MLP tokenizer, two latent bottleneck attention blocks (r=64 latents), and learned-query aggregation. The embeddings are trained jointly with a correctness predictor via binary cross-entropy loss. The architecture avoids positional encodings for permutation invariance and uses learned latents to reduce attention complexity from O(n²) to O(n×r). The system enables efficient routing and model exploration without retraining when incorporating new models.

## Key Results
- Sample efficiency: LOCUS needs 2.3-4.8× fewer query evaluations than baselines (EmbedLLM, IRT-Net) to achieve similar routing accuracy
- Geometric meaning: Pearson correlation of 0.845-0.887 between embedding distance and correctness disagreement between models
- Nearest-neighbor utility: Closest neighbor models agree on correctness 79% of the time, enabling proxy routing for unavailable models

## Why This Works (Mechanism)

### Mechanism 1
Bidirectional attention over tokenized evaluations produces permutation-invariant embeddings. The tokenizer maps query encodings and scores to a common token space, bidirectional attention processes them without positional encodings, and learned-query aggregation attends over all tokens to produce a single embedding. The absence of positional encodings ensures shuffling input evaluations only shuffles intermediate representations, yielding identical final embeddings.

### Mechanism 2
Latent bottleneck attention blocks enable linear-time embedding generation while preserving cross-evaluation information flow. Instead of O(n²) self-attention, compression blocks have latents attend to evaluation tokens (O(n×r)), then broadcast blocks have evaluation tokens attend to latent outputs. This creates an information bottleneck that still allows global communication through r learned vectors.

### Mechanism 3
Geometric proximity in embedding space correlates with behavioral similarity, enabling nearest-neighbor operations. The joint training objective implicitly structures embedding space so that models with similar correctness patterns across queries are mapped nearby. This emerges from the predictive task rather than explicit similarity losses.

## Foundational Learning

- **Permutation equivariance and invariance in set networks**: Essential for processing variable-sized evaluation sets without sensitivity to ordering. Quick check: If you shuffle the rows of X_m^(0) in Equation 1, what happens to z_m and why?

- **Latent bottleneck architectures (e.g., Perceiver, Set Transformer)**: Critical for understanding how learned latents mediate information flow between tokens to achieve O(n×r) complexity. Quick check: Why does the compression block use U^(ℓ) as queries rather than keys?

- **Binary cross-entropy with sigmoid for probability estimation**: Important for understanding calibration of routing decisions. Quick check: If routing accuracy is high but correctness prediction accuracy is low, what might this indicate about the predictor?

## Architecture Onboarding

- **Component map**: Evaluation data → MLP tokenizer → 2 latent bottleneck Set Transformer blocks → learned-query aggregation → model embedding → concatenate with query encoding → 2-layer MLP → sigmoid probability

- **Critical path**: Query encodings and correctness scores are tokenized, processed through latent bottleneck attention, aggregated to form model embedding, concatenated with new query encoding, and passed through predictor MLP to produce routing decision

- **Design tradeoffs**: Embedding dimension d=128 (larger improves capacity but increases complexity); number of latents r=64 (controls compression ratio); evaluation set size ~128-256 queries sufficient for stability

- **Failure signatures**: Embeddings drift across resampled evaluation sets (check training diversity); routing accuracy plateaus below baselines (increase r or evaluation diversity); regenerated embeddings diverge from originals (verify no positional encodings)

- **First 3 experiments**: 1) Sample efficiency test: Train on {256, 512, 1024} evaluations per model; verify LOCUS reaches baseline accuracy with 2.3-4.8× fewer samples. 2) Robustness to query overlap: Generate embeddings with varying overlap (0-100%); verify correctness prediction accuracy remains stable. 3) Nearest-neighbor proxy validation: For each model, compute embedding and find k-th nearest neighbor; measure correctness agreement rate and confirm ~79% for k=1.

## Open Questions the Paper Calls Out

- **Multimodal model embeddings**: How can LOCUS be adapted for vision-language models where queries include image or audio data? The current framework relies on fixed-dimensional text sentence encoders that cannot handle non-textual inputs natively.

- **Adaptive query evaluation**: Can adaptive query selection strategies be integrated to identify the most informative queries for embedding generation rather than relying on random sampling? This could potentially reduce sample requirements further.

- **Noisy evaluation scores**: Does the deterministic encoder effectively capture model capabilities when evaluation scores are continuous, noisy "LLM-as-a-judge" ratings rather than binary correctness labels? The paper focuses on ground truth benchmarks but lists LLM-as-a-judge as a practical source.

## Limitations

- **Missing hyperparameters**: Optimizer, learning rate, batch size, weight decay, and training epochs are not specified, making exact reproduction difficult.

- **Evaluation diversity uncertainty**: It's unclear whether the 4096 evaluations per model come from single or mixed benchmarks, which may affect embedding quality.

- **Domain generalization gap**: Experiments focus on academic benchmarks; performance on real-world production queries remains unvalidated.

- **Latent size justification**: The choice of r=64 latents lacks theoretical justification and sensitivity analysis across different model capacities.

## Confidence

- **High Confidence**: Sample efficiency claims, correctness prediction accuracy, permutation invariance due to lack of positional encodings, and linear-time complexity via latent bottleneck.

- **Medium Confidence**: Geometric meaning of embedding space, proxy model utility, and portfolio selection capabilities. These rely on evaluation set representativeness and the emergence of meaningful geometry.

- **Low Confidence**: Resilience to unavailable models, optimal portfolio selection, and overall robustness across diverse query distributions not tested in the paper.

## Next Checks

1. **Latent count ablation**: Systematically vary r ∈ {16, 32, 64, 128} and measure routing accuracy degradation to validate the 64-latent bottleneck choice.

2. **Cross-domain transfer**: Train LOCUS embeddings on academic benchmarks, then evaluate routing accuracy on a held-out dataset of production queries to measure performance drop.

3. **Dynamic portfolio selection validation**: Implement the two-stage selection (diversity-first, then proxy refinement) on synthetic models with known pairwise similarity to verify >95% coverage of capability space.