---
ver: rpa2
title: Dynamical model parameters from ultrasound tongue kinematics
arxiv_id: '2510.18629'
source_url: https://arxiv.org/abs/2510.18629
tags:
- ultrasound
- data
- parameters
- tongue
- dynamical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses whether dynamical model parameters can be reliably
  estimated from ultrasound tongue kinematics, and compares these with parameters
  estimated from simultaneously-recorded EMA data. A linear harmonic oscillator model
  was fitted to ultrasound and EMA data for tongue dorsum and jaw movements during
  vowel production, using a constrained least squares optimization approach.
---

# Dynamical model parameters from ultrasound tongue kinematics

## Quick Facts
- arXiv ID: 2510.18629
- Source URL: https://arxiv.org/abs/2510.18629
- Reference count: 0
- The study compares dynamical model parameters estimated from ultrasound and EMA data, finding comparable model fits and no systematic differences in stiffness and damping parameters between modalities.

## Executive Summary
This study investigates whether dynamical model parameters can be reliably estimated from ultrasound tongue kinematics by comparing these estimates with those derived from simultaneously-recorded EMA data. A linear harmonic oscillator model was fitted to tongue dorsum and jaw movements during vowel production using constrained least squares optimization. The results show that ultrasound-derived parameters are comparable to EMA-derived parameters, with no systematic differences in stiffness and damping parameters, though ultrasound-estimated target parameters showed some systematic differences consistent with known tracking characteristics.

## Method Summary
The researchers recorded ultrasound and EMA data simultaneously from speakers producing vowels, tracking tongue dorsum and jaw movements. A linear harmonic oscillator dynamical model was fitted to this kinematic data using constrained least squares optimization. Bayesian hierarchical regression was employed to compare the model parameters (stiffness k, damping b, and target T) between the two imaging modalities, examining both systematic differences and variability patterns.

## Key Results
- Model fits were comparable between ultrasound and EMA, with R² values ≥ 0.90 for all variables
- No systematic differences were found in stiffness (k) and damping (b) parameters between modalities
- Ultrasound-estimated target (T) parameters were systematically lower for TDx, JAWx, and JAWy, and more variable for JAW movements, consistent with ultrasound tracking characteristics

## Why This Works (Mechanism)
The linear harmonic oscillator model captures articulatory dynamics through three parameters: stiffness (k) representing elastic forces, damping (b) representing resistance to motion, and target (T) representing equilibrium positions. The constrained least squares optimization ensures physically plausible parameter estimates while fitting the model to kinematic trajectories from both ultrasound and EMA data streams.

## Foundational Learning
- Linear harmonic oscillator dynamics: why needed to model articulatory movements; quick check verify spring-mass-damper equations match observed kinematics
- Bayesian hierarchical regression: why needed to compare parameters across imaging modalities; quick check examine posterior distributions for systematic differences
- Constrained optimization: why needed to ensure physically meaningful parameters; quick check verify constraints prevent unrealistic values

## Architecture Onboarding
**Component map:** Ultrasound imaging -> Tongue tracking -> Kinematic trajectories -> Model fitting -> Parameter estimates; EMA imaging -> Articulator tracking -> Kinematic trajectories -> Model fitting -> Parameter estimates

**Critical path:** Data acquisition (ultrasound/EMA) -> Preprocessing and tracking -> Kinematic trajectory extraction -> Model fitting with constraints -> Parameter comparison via Bayesian regression

**Design tradeoffs:** Ultrasound offers richer lingual information and non-invasive collection but introduces tracking errors from probe stabilization; EMA provides direct articulator measurements but limited lingual coverage and requires invasive markers

**Failure signatures:** Poor model fits (R² < 0.90) indicate inadequate dynamical model or tracking errors; systematic parameter differences suggest modality-specific biases in tracking or stabilization

**3 first experiments:** 1) Verify tracking accuracy by comparing ultrasound-derived kinematics with ground truth movements; 2) Test model sensitivity by varying constraint parameters; 3) Cross-validate parameter estimates using held-out data subsets

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis focused on limited speakers and vowel productions, potentially missing articulatory variability
- Ultrasound tracking introduces potential errors from probe stabilization and tissue deformation
- Linear harmonic oscillator model may not capture all articulatory dynamics across speech sounds

## Confidence
- Comparable ultrasound and EMA model fits (R² ≥ 0.90): High
- No systematic differences in k and b parameters: High
- Systematic differences in ultrasound T parameters: Medium

## Next Checks
1. Replicate analysis with larger, more diverse speaker sample and broader phonetic inventory
2. Compare ultrasound and EMA parameter estimates using cross-validation with held-out data
3. Conduct sensitivity analysis varying ultrasound tracking algorithm and probe stabilization protocols