---
ver: rpa2
title: Calibration and Discrimination Optimization Using Clusters of Learned Representation
arxiv_id: '2510.19328'
source_url: https://arxiv.org/abs/2510.19328
tags:
- calibration
- cece
- methods
- clusters
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel calibration method, CCL (Clustered
  Calibration), which leverages clustering of learned representations to enhance both
  calibration and discrimination. Unlike traditional methods that apply uniform transformations,
  CCL trains separate calibration models on clusters of data identified through learned
  embeddings like SHAP values or leaf indices.
---

# Calibration and Discrimination Optimization Using Clusters of Learned Representation

## Quick Facts
- arXiv ID: 2510.19328
- Source URL: https://arxiv.org/abs/2510.19328
- Authors: Tomer Lavi; Bracha Shapira; Nadav Rappoport
- Reference count: 40
- Primary result: CCL (Clustered Calibration) leverages clustering of learned representations to enhance both calibration and discrimination, improving calibration scores from 82.28% to up to 100% across multiple datasets.

## Executive Summary
This paper introduces CCL (Clustered Calibration), a novel calibration method that leverages clustering of learned representations to enhance both calibration and discrimination. Unlike traditional methods that apply uniform transformations, CCL trains separate calibration models on clusters of data identified through learned embeddings like SHAP values or leaf indices. The authors also propose CECE (Clustered ECE), a new metric that evaluates calibration using cluster-based binning, which serves as an effective model selection tool optimizing both calibration and discrimination simultaneously.

## Method Summary
CCL works by first training a base predictor (XGBoost) and extracting learned representations from it, either through SHAP values or leaf indices. These representations are then clustered using K-means or Agglomerative clustering to identify subpopulations with distinct error distributions. Separate parametric calibration models (Platt, Temperature Scaling, Beta, or Dirichlet) are then trained on each cluster. During inference, samples are embedded, assigned to clusters, and calibrated using the corresponding cluster-specific model. The method consistently improves calibration scores across multiple datasets while maintaining or improving discrimination performance.

## Key Results
- CCL consistently improves calibration scores across multiple datasets, achieving up to 100% accuracy in calibration improvement
- CECE serves as an effective model selection tool, uniquely optimizing both calibration and discrimination simultaneously
- Experiments demonstrate CCL's superiority over unified calibration approaches and non-parametric methods like Isotonic Regression and Histogram Binning
- The method is particularly applicable to high-stakes domains like clinical decision support systems where precise calibration and uncertainty quantification are critical

## Why This Works (Mechanism)

### Mechanism 1
Partitioning the sample space into clusters of learned representations allows for specialized calibration functions that reduce local error better than a single global function. Traditional calibration applies a uniform transformation across all data, ignoring subpopulations with distinct error distributions. CCL identifies these subpopulations via clustering and trains independent calibration models for each, minimizing the specific bias of that subgroup. This works when the underlying classification model generates representations where proximity implies similar miscalibration patterns.

### Mechanism 2
Using cluster assignments as bins for evaluation (CECE) preserves discrimination ability (AUC) while optimizing calibration. Standard calibration metrics sort samples by predicted probability, meaning calibration can shift samples between bins, potentially harming ranking order. CECE sorts samples by cluster assignment, which is invariant to the calibration output. Therefore, minimizing CECE forces probabilities to align with observed frequencies within fixed groups without disrupting the global ranking of the groups.

### Mechanism 3
Learned representations (specifically SHAP values or Leaf Indices) are more effective features for identifying calibration-relevant subpopulations than raw input features. Raw features often fail to capture the complex interactions the model uses for prediction. Leaf indices or SHAP values explicitly encode the model's decision path. Clustering these representations groups samples that are "processed similarly" by the model, revealing subgroups with distinct error profiles (e.g., high confidence but low accuracy).

## Foundational Learning

- **Expected Calibration Error (ECE)**
  - Why needed here: ECE is the baseline error metric CCL seeks to minimize. You must understand binning strategies to grasp why the paper proposes Adaptive ECE and Clustered ECE (CECE) as alternatives.
  - Quick check question: Why might a model with high accuracy still have a high ECE score?

- **Post-hoc Calibration Functions (Platt, Isotonic, Temperature)**
  - Why needed here: CCL is a wrapper that applies these functions locally. You need to distinguish parametric methods (Platt, Temperature) from non-parametric methods (Isotonic), as CCL is designed primarily for parametric methods.
  - Quick check question: Why does the paper suggest avoiding non-parametric methods like Isotonic Regression inside the CCL wrapper?

- **Representation Learning (Leaf Indices & SHAP)**
  - Why needed here: The input to the clustering algorithm is not the raw data but a "learned representation." Understanding that Leaf Indices represent the path a sample takes through a decision tree is crucial for implementing the embedding step.
  - Quick check question: What information does a vector of Leaf Indices capture that a raw feature vector might miss regarding the model's internal state?

## Architecture Onboarding

- **Component map:**
  Base Predictor -> Embedding Extractor -> Cluster Router -> Calibration Ensemble -> Inference Logic

- **Critical path:**
  1. Generate embeddings for the calibration set using the frozen base predictor
  2. Fit the clustering model on these embeddings to determine k subgroups
  3. Fit k independent calibration models, one for each subgroup's data

- **Design tradeoffs:**
  - Interpretability vs. Performance: SHAP values provide interpretable clusters but are computationally expensive. Leaf indices are extremely fast but offer less immediate explainability.
  - Cluster Count (k): Low k approaches global calibration (underfitting); high k risks overfitting calibration models on small data slices.

- **Failure signatures:**
  - Cluster Collapse: Visualization shows clusters do not separate positive/negative labels
  - Performance Degradation: CECE improves, but ROC-AUC drops
  - Variance Explosion: Cluster sizes vary wildly, rendering local calibration useless

- **First 3 experiments:**
  1. Sanity Check (Toy Data): Train XGBoost. Apply standard Platt Scaling vs. CCL-Platt (using Leaf Indices). Verify Local ECE < Global ECE.
  2. Embedding Ablation: Run CCL three times using raw features, Leaf Indices, and SHAP values. Compare cluster homogeneity scores.
  3. Metric Validation: Train 5 different calibration configurations. Plot CECE vs. ROC-AUC. Verify the negative correlation claimed.

## Open Questions the Paper Calls Out

### Open Question 1
How does CCL performance compare to unified calibration when applied to deep neural networks in computer vision and natural language processing tasks? All reported experiments utilize XGBoost on tabular data; the efficacy of learned representations is unproven for continuous input spaces like images or text.

### Open Question 2
Can the Clustered Calibration framework be effectively integrated into Conformal Prediction and Domain Adaptation pipelines? The current paper focuses solely on calibration error and discrimination, without addressing distribution shifts or coverage guarantees required for these specific fields.

### Open Question 3
To what extent is the method's performance sensitive to the selection of the number of clusters (k), and does the optimal cluster count vary significantly across different datasets? While the authors use the "elbow method" to select k, they do not provide a theoretical justification or sensitivity analysis regarding how the choice of k impacts the trade-off between calibration error and cluster homogeneity.

## Limitations

- The method's dependence on learned representations means severely under-fitted or poorly regularized base models could produce uninformative clusters, negating potential benefits
- The universal applicability of the method across all tabular datasets and model types is not established; success on 10 datasets does not guarantee similar results on all possible tabular problems
- The exact mechanism by which learned representations consistently identify calibration-relevant subpopulations is not fully validated in the corpus

## Confidence

- **High Confidence:** The empirical results showing improved calibration scores (CECE) and maintained/increased discrimination (ROC-AUC) are reproducible if the described methodology is followed precisely.
- **Medium Confidence:** The theoretical justification for why cluster-based binning (CECE) preserves discrimination while improving calibration is logical but not fully validated by independent corpus evidence.
- **Low Confidence:** The method's universal applicability across all tabular datasets and model types is not established.

## Next Checks

1. **Cross-Validation Stability Test:** Run CCL on the same dataset multiple times with different random seeds. Verify that the improvement in CECE over standard calibration is statistically significant and consistent across runs.

2. **Base Model Ablation:** Apply CCL to models with varying levels of fit (e.g., under-fitted vs. well-tuned XGBoost). Confirm that the method provides the most benefit when the base model has learned meaningful, non-noisy representations.

3. **Cluster Interpretability Audit:** For a few key clusters, use SHAP summary plots or decision tree visualization to confirm that the clusters are indeed formed around meaningful features/interactions and not random noise.