---
ver: rpa2
title: 'Private-RAG: Answering Multiple Queries with LLMs while Keeping Your Data
  Private'
arxiv_id: '2511.07637'
source_url: https://arxiv.org/abs/2511.07637
tags:
- privacy
- questions
- budget
- documents
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces two new algorithms for private retrieval-augmented
  generation (RAG) that allow answering hundreds of queries while maintaining meaningful
  privacy and utility. The key insight is that most documents in the external corpus
  are rarely accessed, so instead of composing privacy loss across all queries, privacy
  should be tracked at the document level.
---

# Private-RAG: Answering Multiple Queries with LLMs while Keeping Your Data Private

## Quick Facts
- arXiv ID: 2511.07637
- Source URL: https://arxiv.org/abs/2511.07637
- Authors: Ruihan Wu, Erchi Wang, Zhiyuan Zhang, Yu-Xiang Wang
- Reference count: 40
- Key outcome: Introduces two private RAG algorithms achieving ε≈10 for 100 queries with strong utility

## Executive Summary
This paper addresses the privacy challenge in retrieval-augmented generation (RAG) systems by proposing a document-level privacy accounting framework. Traditional RAG systems apply privacy loss per query, making them impractical for answering multiple questions. The authors introduce MURAG and MURAG-ADA, which track privacy at the document level since most documents are rarely accessed. These methods achieve strong utility while maintaining meaningful privacy guarantees, effectively defending against membership inference attacks while outperforming non-RAG baselines.

## Method Summary
The paper proposes two algorithms for private RAG: MURAG and MURAG-ADA. MURAG uses fixed relevance thresholds with individual privacy filters, tracking privacy loss at the document level rather than query level. This approach recognizes that privacy should be composed based on document access frequency rather than total query count. MURAG-ADA improves upon this by privately releasing query-specific thresholds to better adapt to correlated queries, reducing unnecessary privacy budget consumption. Both methods are evaluated on three LLMs (OPT-1.3B, Pythia-1.4B, Mistral-7B) across multiple datasets, demonstrating strong utility preservation with ε≈10 for 100 queries.

## Key Results
- MURAG and MURAG-ADA achieve strong utility (outperforming non-RAG baselines) with ε≈10 for 100 queries
- MURAG-ADA excels on correlated multi-hop questions by adaptively adjusting relevance thresholds
- Both methods effectively mitigate state-of-the-art membership inference attacks
- Document-level privacy accounting significantly improves the privacy-utility tradeoff compared to query-level approaches

## Why This Works (Mechanism)
The key insight is that traditional RAG systems waste privacy budget by composing loss across all queries, even though most documents are rarely accessed. By shifting to document-level privacy accounting, the total privacy budget depends on how often each document is retrieved rather than the total number of queries. This makes private RAG practical for answering hundreds of questions. MURAG-ADA further improves efficiency by adaptively adjusting relevance thresholds for correlated queries, preventing unnecessary privacy budget consumption when queries share similar document retrieval patterns.

## Foundational Learning
- Document-level vs. Query-level privacy accounting: Why needed - Traditional methods compose privacy loss per query, making multi-query systems impractical. Quick check - Verify that document access frequency follows expected distribution patterns.
- Differential Privacy composition theorems: Why needed - To mathematically justify decomposing query privacy into document-level losses. Quick check - Ensure composition bounds remain tight under the assumed independence conditions.
- Membership inference attacks: Why needed - To evaluate the practical privacy guarantees of the proposed methods. Quick check - Test against adaptive attacks that probe based on observed outputs.

## Architecture Onboarding

Component map: Query Processor -> Document Retriever -> Relevance Filter -> LLM Generator -> Privacy Accountant

Critical path: Query → Retriever → Filter → LLM → Answer

Design tradeoffs: Fixed vs. adaptive relevance thresholds (MURAG vs MURAG-ADA), tight vs. loose composition bounds, privacy budget allocation between retrieval and generation.

Failure signatures: High false positive rate in relevance filtering wastes privacy budget; overly conservative thresholds reduce utility; poor composition bounds lead to overestimated privacy loss.

First experiments:
1. Test document access frequency distribution on sample datasets to validate document-level privacy assumptions
2. Compare privacy budget consumption between query-level and document-level accounting on synthetic query sets
3. Evaluate relevance threshold sensitivity by measuring utility degradation as threshold varies

## Open Questions the Paper Calls Out
None

## Limitations
- Real-world query distributions may violate independence assumptions required for tight composition bounds
- MURAG-ADA's performance gains on correlated queries lack deep analytical justification
- Membership inference attack evaluation uses specific methodology; robustness against stronger adaptive attacks unclear

## Confidence

- Document-level privacy accounting framework: High
- Utility preservation claims (ε≈10 for 100 queries): Medium
- Membership inference defense effectiveness: Medium
- MURAG-ADA adaptive threshold mechanism: Low

## Next Checks
1. Test algorithms on datasets with varying query correlation structures to validate MURAG-ADA's advantages
2. Evaluate robustness against stronger membership inference attacks, including adaptive probing attacks
3. Conduct ablation studies removing document-level privacy decomposition to quantify its contribution to privacy-utility tradeoff