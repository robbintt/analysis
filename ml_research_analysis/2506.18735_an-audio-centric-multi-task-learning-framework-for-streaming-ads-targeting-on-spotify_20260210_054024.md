---
ver: rpa2
title: An Audio-centric Multi-task Learning Framework for Streaming Ads Targeting
  on Spotify
arxiv_id: '2506.18735'
source_url: https://arxiv.org/abs/2506.18735
tags:
- video
- audio
- task
- stream
- slots
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces CAMoE, a multi-task learning framework for\
  \ optimizing click-through rate prediction on Spotify\u2019s audio-centric, multi-modal\
  \ ad platform. CAMoE uses modality-aware task grouping, adaptive loss masking, and\
  \ deep-cross network experts to handle data imbalance and capture complex feature\
  \ interactions."
---

# An Audio-centric Multi-task Learning Framework for Streaming Ads Targeting on Spotify

## Quick Facts
- arXiv ID: 2506.18735
- Source URL: https://arxiv.org/abs/2506.18735
- Reference count: 34
- Primary result: Multi-task learning framework improves click-through rate prediction for streaming ads by leveraging audio and video modalities.

## Executive Summary
This paper introduces CAMoE, a multi-task learning framework designed to optimize click-through rate (CTR) prediction for Spotify's audio-centric, multi-modal ad platform. By integrating modality-aware task grouping, adaptive loss masking, and deep-cross network experts, CAMoE addresses data imbalance and captures complex feature interactions across audio and video ads. Offline evaluations demonstrate significant improvements in AUC-PR over single-task and content-based baselines, while a large-scale A/B test shows a 14.5% increase in CTR for audio ads and a 1.3% increase for video ads, alongside a 4.8% reduction in eCPC for audio slots. The results highlight the effectiveness of modality-aware architectures in real-world, multi-modal advertising systems.

## Method Summary
CAMoE employs a multi-task learning architecture that groups related prediction tasks by modality (audio vs. video) and applies adaptive loss masking to handle data imbalance. The framework integrates deep-cross network experts to model complex feature interactions within each modality. This design allows the model to jointly optimize for multiple ad formats while accounting for the unique characteristics of each content type. The approach is evaluated both offline and through a large-scale A/B test on Spotify's platform.

## Key Results
- Offline AUC-PR improvements over single-task and content-based baselines.
- 14.5% increase in CTR for audio ads in A/B test.
- 1.3% increase in CTR for video ads and 4.8% reduction in eCPC for audio slots.

## Why This Works (Mechanism)
CAMoE's effectiveness stems from its ability to leverage modality-aware task grouping and adaptive loss masking to handle data imbalance and capture complex interactions across audio and video ads. By jointly optimizing for multiple tasks, the framework can share representations and improve generalization, while the deep-cross network experts allow for fine-grained modeling of modality-specific features.

## Foundational Learning
- Multi-task learning: Needed to jointly optimize for multiple ad formats; quick check: compare single-task vs. multi-task performance.
- Modality-aware task grouping: Needed to leverage shared and unique features across audio and video; quick check: evaluate grouping strategies.
- Adaptive loss masking: Needed to address data imbalance; quick check: assess impact of masking on minority classes.

## Architecture Onboarding
- **Component map**: Input features -> Modality-aware task grouping -> Adaptive loss masking -> Deep-cross network experts -> Output predictions
- **Critical path**: Feature extraction and grouping -> Expert modeling -> Loss computation and masking -> Final prediction
- **Design tradeoffs**: Balancing shared vs. modality-specific representations; complexity vs. interpretability
- **Failure signatures**: Poor performance on minority classes; overfitting to majority modality; degraded accuracy when grouping is suboptimal
- **First experiments**: 1) Ablation study removing modality grouping; 2) Test with fixed vs. adaptive loss weights; 3) Compare deep-cross vs. standard DNN experts

## Open Questions the Paper Calls Out
None provided.

## Limitations
- A/B test results limited to audio and video ads; no detailed breakdowns for other ad formats.
- Offline evaluation lacks statistical significance analysis and confidence intervals.
- Limited discussion of potential confounding factors (e.g., seasonality, concurrent product changes).
- Scalability and performance under extreme data imbalance not addressed.

## Confidence
- High confidence in technical novelty and methodological soundness of CAMoE's architecture.
- Medium confidence in offline evaluation results due to lack of statistical detail.
- Low confidence in generalization of A/B test results to other platforms or ad formats.

## Next Checks
1. Conduct statistical significance analysis for both offline and online results; extend A/B testing to additional ad formats and inventory segments.
2. Perform ablation studies to quantify the impact of modality-aware task grouping and adaptive loss masking; test under simulated extreme data imbalance.
3. Run multi-platform evaluation (e.g., on YouTube or Pandora) to assess generalization beyond Spotify.