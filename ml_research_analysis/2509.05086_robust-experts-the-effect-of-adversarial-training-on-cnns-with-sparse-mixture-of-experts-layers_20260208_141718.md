---
ver: rpa2
title: 'Robust Experts: the Effect of Adversarial Training on CNNs with Sparse Mixture-of-Experts
  Layers'
arxiv_id: '2509.05086'
source_url: https://arxiv.org/abs/2509.05086
tags:
- experts
- training
- accuracy
- adversarial
- gap-fc
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Sparse mixture-of-experts (MoE) layers were integrated into CNN
  architectures (ResNet-18 and ResNet-50) trained on CIFAR-100 to enhance adversarial
  robustness. MoE layers replaced either residual blocks (BlockMoE) or individual
  convolutional layers (ConvMoE) in deeper network stages, using top-k routing with
  four experts.
---

# Robust Experts: the Effect of Adversarial Training on CNNs with Sparse Mixture-of-Experts Layers

## Quick Facts
- **arXiv ID**: 2509.05086
- **Source URL**: https://arxiv.org/abs/2509.05086
- **Reference count**: 34
- **Primary result**: Sparse MoE layers in CNNs improve adversarial robustness under PGD training when using BlockMoE in deeper stages with entropy balancing loss.

## Executive Summary
This work investigates the integration of sparse mixture-of-experts (MoE) layers into convolutional neural networks (CNNs) for improved adversarial robustness. The authors replace residual blocks or convolutional layers in ResNet architectures with MoE layers containing multiple experts and a gating network. Through extensive experiments on CIFAR-100, they demonstrate that BlockMoE layers (replacing entire residual blocks) combined with entropy-based balancing loss and top-2 routing yield consistent improvements in both clean and adversarial accuracy compared to dense baselines. The study also reveals an unexpected finding: under switch loss, individual experts can sometimes outperform the full MoE model in adversarial accuracy, suggesting robust subpaths emerge through concentrated training.

## Method Summary
The method integrates sparse MoE layers into ResNet-18 and ResNet-50 architectures trained on CIFAR-100. MoE layers replace either residual blocks (BlockMoE) or individual convolutional layers (ConvMoE) in deeper network stages, using top-k routing with four experts. The models are trained with adversarial training using PGD-7 attacks, and compared against dense baselines using clean accuracy and adversarial accuracy under PGD-20 and AutoPGD attacks. Two auxiliary balancing losses are evaluated: entropy loss (maximizing expert utilization diversity) and switch loss (encouraging sharp routing decisions). Gate architectures include global average pooling with fully connected layers (GAP-FC) and convolutional gating with global average pooling (Conv-GAP).

## Key Results
- BlockMoE layers in conv5_x with top-2 routing and entropy loss show consistent robustness improvements over dense baselines
- Entropy loss outperforms switch loss for balanced expert utilization and overall robustness
- Individual experts trained with switch loss sometimes achieve higher adversarial accuracy than the full MoE model
- Deeper MoE placement (conv5_x) is more effective than shallower stages for robustness gains
- ConvMoE models show mixed results with less stable robustness improvements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Block-level MoE layers provide more consistent robustness improvements than convolution-level MoE under adversarial training.
- Mechanism: Replacing entire residual blocks (BlockMoE) rather than individual convolutional layers (ConvMoE) allows experts to learn more semantically meaningful and independent representations. Each expert contains two convolutional layers plus a skip connection, reducing interference between experts and improving gradient isolation during adversarial training.
- Core assumption: Coarser-grained structural units enable better expert specialization on semantically distinct features, which translates to more robust decision boundaries.
- Evidence anchors:
  - [abstract] "MoE layers replaced either residual blocks (BlockMoE) or individual convolutional layers (ConvMoE)... BlockMoE layers showed consistent improvements... ConvMoE models yielded mixed results"
  - [section] Section 3.2: "We choose to focus on larger structural units, such as layers and residual blocks, with a higher capacity and semantic meaning. Compared to fine-grained filter-level MoEs, block-level MoEs simplify routing decisions and encourage expert specialization and robustness."
  - [corpus] Limited direct comparison in related work; Zhang et al. [34] explored filter-level MoEs for CNNs but not block-level comparison.
- Break condition: If experts are too large (replacing multiple blocks), gradient isolation benefits may diminish as each expert becomes too complex to specialize effectively.

### Mechanism 2
- Claim: Entropy-based auxiliary loss promotes balanced expert utilization and better robustness than switch loss under adversarial training.
- Mechanism: Entropy loss directly maximizes the entropy of the average expert importance distribution (L_entropy = -H(P)), encouraging uniform utilization across all experts. Switch loss allows sharper routing decisions that can collapse onto a small subset of frequently-used experts.
- Core assumption: Balanced expert utilization leads to distributed adversarial training signal across all model capacity, improving overall robustness.
- Evidence anchors:
  - [abstract] "Entropy loss outperformed switch loss in promoting balanced expert utilization and overall robustness"
  - [section] Figure 7: Visualizes routing collapse under switch loss (extreme expert under-utilization) vs. balanced distribution under entropy loss during adversarial training
  - [corpus] Corpus evidence on load balancing is limited to general MoE literature; specific robustness comparison appears novel to this work.
- Break condition: If entropy loss weight is too high, it may force semantically suboptimal routing decisions, degrading clean accuracy.

### Mechanism 3
- Claim: Routing collapse under switch loss can inadvertently produce robust expert subpaths that outperform the full gated MoE model.
- Mechanism: When switch loss causes routing to concentrate on a small set of experts, those experts receive focused adversarial training signal. This concentrated training produces "robust experts" with stronger adversarial accuracy, even though overall model utilization is imbalanced.
- Core assumption: Assumption: Focused adversarial training on limited computation paths can produce more robust feature representations than distributed training.
- Evidence anchors:
  - [abstract] "individual experts trained with switch loss sometimes outperformed the full MoE model in adversarial accuracy, suggesting robust subpaths can emerge through concentrated training"
  - [section] Figure 8 and Section 4.3.2: "A group of significantly more robust experts emerges... These results indicate that sparse MoEs can be used as a proxy to train robust classification models by finding robust subpaths in networks with dynamic routing."
  - [corpus] Related corpus papers on MoE robustness (e.g., Puigcerver et al. [24], Zhang et al. [34]) do not report this phenomenon; it appears to be a novel finding in this work.
- Break condition: If routing collapses to a single expert, the model effectively loses MoE capacity benefits and may underfit the data distribution.

## Foundational Learning
- Concept: Top-k sparse routing
  - Why needed here: Core mechanism enabling conditional computation where only k experts are activated per input, balancing capacity with efficiency.
  - Quick check question: Why does k=2 provide better robustness-accuracy tradeoffs than k=1 or higher values?

- Concept: Routing collapse (dying experts)
  - Why needed here: Critical failure mode where the gating network consistently routes most inputs to a small subset of experts, wasting model capacity.
  - Quick check question: Which auxiliary loss does the paper recommend to prevent routing collapse under adversarial training?

- Concept: Adversarial training with PGD
  - Why needed here: Training paradigm where adversarial examples (PGD-7 attacks) are incorporated into training to improve model robustness at inference time.
  - Quick check question: Why does the paper observe that MoE robustness benefits are "largely confined to adversarially trained settings"?

## Architecture Onboarding
- Component map:
  Input → conv1 → conv2_x → conv3_x → conv4_x → conv5_x (with BlockMoE replacing 2nd BasicBlock) → Global Pool → FC → Output
- Critical path:
  Input → conv1 → conv2_x → conv3_x → conv4_x → conv5_x (with BlockMoE replacing 2nd BasicBlock) → Global Pool → FC → Output
  - Optimal placement: Single BlockMoE in conv5_x, replacing the 2nd BasicBlock
- Design tradeoffs:
  - k (activated experts): k=1 maximizes sparsity but reduces accuracy; k=2 provides best robustness-accuracy tradeoff; k>2 shows diminishing returns
  - Number of experts: 4–8 experts optimal; >8 experts degrades individual expert training quality due to sparse gradient signals
  - Loss function: Entropy loss for balanced utilization and best overall robustness; Switch loss for discovering robust expert subpaths
- Failure signatures:
  - Routing collapse: >80% of inputs assigned to single expert (check expert utilization distribution)
  - Over-capacity: Adversarial accuracy drops with >8 experts despite increased parameter count
  - Shallow placement: MoE in conv2_x–conv4_x shows minimal robustness gains compared to conv5_x
- First 3 experiments:
  1. Replicate BlockMoE baseline: ResNet-18, replace 2nd BasicBlock in conv5_x with 4-expert BlockMoE, top-2 routing, entropy loss, PGD-7 adversarial training—target ~2–3% PGD accuracy improvement over dense baseline
  2. Ablate MoE placement: Compare BlockMoE in conv4_x vs. conv5_x (1st vs. 2nd BasicBlock) to confirm deeper placement is critical for robustness gains
  3. Analyze routing collapse: Train identical models with switch loss vs. entropy loss, log expert utilization per epoch, and correlate collapse patterns with PGD-20 and AutoPGD robustness metrics

## Open Questions the Paper Calls Out
- Can robustness-aware gating strategies be developed to preferentially route inputs through the most robust experts during inference?
- Can insights from the lottery ticket hypothesis guide the identification and refinement of robust subnetworks within MoE architectures?
- Why does switch loss, despite causing routing collapse, produce individual experts that are more robust than the full MoE model?
- Do the robustness improvements from MoE layers generalize to larger-scale datasets (e.g., ImageNet) and more diverse architectures beyond ResNet?

## Limitations
- Robustness improvements are largely confined to adversarially trained settings, with limited evidence for clean accuracy gains from MoE alone.
- The routing collapse phenomenon under switch loss raises questions about whether the "robust experts" represent true model improvement or simply overfitted adversarial subpaths.
- The comparison between BlockMoE and ConvMoE architectures lacks comprehensive ablation studies across different routing strategies and loss functions.

## Confidence
- **High confidence**: Entropy loss provides better balanced utilization than switch loss under adversarial training
- **Medium confidence**: Block-level MoE placement in conv5_x yields consistent robustness gains
- **Medium confidence**: Top-2 routing provides optimal robustness-accuracy tradeoff
- **Low confidence**: Individual experts trained with switch loss can outperform full MoE models in adversarial accuracy

## Next Checks
1. Verify PGD-7 attack hyperparameters (epsilon bound, step size, number of iterations) and their impact on robustness metrics
2. Test whether robust expert subpaths persist under different adversarial training schedules or when combined with standard adversarial training methods
3. Evaluate whether entropy loss's balancing effect degrades under varying batch sizes or when training with different optimizer configurations