---
ver: rpa2
title: 'From Completion to Editing: Unlocking Context-Aware Code Infilling via Search-and-Replace
  Instruction Tuning'
arxiv_id: '2601.13384'
source_url: https://arxiv.org/abs/2601.13384
tags:
- code
- arxiv
- completion
- middle
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Search-and-Replace Infilling (SRI), a framework
  that replaces the traditional Fill-in-the-Middle (FIM) paradigm for code completion.
  FIM relies on unaligned base models and cannot correct contextual errors, leading
  to security vulnerabilities and poor performance with safety-aligned chat models.
---

# From Completion to Editing: Unlocking Context-Aware Code Infilling via Search-and-Replace Instruction Tuning

## Quick Facts
- arXiv ID: 2601.13384
- Source URL: https://arxiv.org/abs/2601.13384
- Authors: Jiajun Zhang; Zeyu Cui; Jiaxi Yang; Lei Zhang; Yuheng Jing; Zeyao Ma; Tianyi Bai; Zilei Wang; Qiang Liu; Liang Wang; Binyuan Hui; Junyang Lin
- Reference count: 40
- The paper introduces Search-and-Replace Infilling (SRI), a framework that replaces the traditional Fill-in-the-Middle (FIM) paradigm for code completion.

## Executive Summary
This paper introduces Search-and-Replace Infilling (SRI), a novel framework that reframes code completion as context-aware micro-editing through an explicit search-and-replace paradigm. Unlike traditional FIM, which relies on unaligned base models and struggles with contextual errors, SRI structurally grounds edits via an explicit search phase that aligns completion tasks with instruction-following priors of chat models. The approach enables chat models to surpass base model performance with minimal fine-tuning data while preserving general coding competencies and maintaining inference efficiency.

The authors demonstrate SRI's effectiveness across 20+ models on five mainstream benchmarks, showing significant improvements in completion accuracy and security resilience. By synthesizing a high-quality dataset (SRI-200K) and fine-tuning the SRI-Coder series, the framework achieves state-of-the-art results while addressing key limitations of FIM, including security vulnerabilities and poor performance with safety-aligned chat models. The method preserves inference latency comparable to standard FIM while enabling context-aware corrections that traditional approaches cannot achieve.

## Method Summary
The method involves fine-tuning decoder-only code models on a novel Search-and-Replace Infilling (SRI) format that replaces traditional FIM. SRI uses an explicit SEARCH block (replicating context) followed by a REPLACE block (completed code) in a diff-style format. The authors synthesized 200K high-quality training samples from The Stack v2 using tree-sitter AST extraction, creating an 80K mixed dataset (20K SRI + 60K filtered instructions + 100 safety samples). Fine-tuning was performed on Qwen2.5-Coder Base using Megatron-LM with specific hyperparameters (5e-5 LR, 32K context, BF16, etc.). The approach was validated across 20+ models on five benchmarks, demonstrating superior completion accuracy and security resilience compared to traditional FIM.

## Key Results
- SRI-Coder enables chat models to surpass base model completion performance with only 20K training samples
- SRI achieves perplexity of 3.89 vs. 4.98–6.15 for NL-FIM variants, indicating better pre-training distribution alignment
- Security-aligned chat models show 13.8–20.0% attack success rate with SRI vs. 97.5–100% with traditional FIM
- The approach preserves inference latency comparable to standard FIM while maintaining general coding competencies

## Why This Works (Mechanism)

### Mechanism 1: Grounding through SEARCH
The explicit SEARCH block functions as a grounding mechanism that improves completion accuracy by forcing context verification before generation. The model must replicate the editable region (marker + ~10 lines context) before generating the REPLACE block, acting as a visual chain-of-thought that compels context identification and validation.

### Mechanism 2: Pre-training Distribution Alignment
The diff-style format achieves lower perplexity by aligning with pre-training distribution of version control patterns. Code LLMs are pre-trained on repositories containing Git commits and diff files with `<<<<<<< SEARCH / ======= / >>>>>>> REPLACE` patterns, matching SRI's format more closely than conversational NL prompts.

### Mechanism 3: Security Inheritance
SRI enables security-aligned chat models to perform completion, inheriting their safety training against prompt injection attacks. Traditional FIM requires unaligned base models (near 100% attack success rate), while SRI reduces attack success to 5–20% by using instruction-tuned models with post-training safety features.

## Foundational Learning

- **Fill-in-the-Middle (FIM) Pre-training**: Understanding why FIM requires base models and why chat models degrade (up to 59%) when prompted with NL-FIM is essential context.
  - Quick check question: Can you explain why decoder-only models need the `prefix → suffix → middle` reordering during FIM training?

- **Unified Diff / Search-and-Replace Format**: SRI adopts this format; understanding how it avoids fragile line-number dependencies helps explain robustness.
  - Quick check question: How does the `<<<<<<< SEARCH / ======= / >>>>>>> REPLACE` structure differ from standard unified diff's line-number-based hunks?

- **Perplexity as Distributional Alignment Signal**: The paper uses perplexity analysis to argue SRI aligns better with pre-training distribution than NL prompts.
  - Quick check question: Given the same ground-truth code, why would a lower conditional perplexity indicate better format alignment?

## Architecture Onboarding

- **Component map**: Editable Region Definition (marker + 10-line context) -> Prompt Template (SRI format) -> Model Generation (SEARCH + REPLACE) -> Post-Processing (extract_replace_code)

- **Critical path**: Construct prompt with prefix/suffix/marker -> Model generates SEARCH (must include marker) + REPLACE -> Post-process to extract middle code -> Apply replacement for evaluation

- **Design tradeoffs**: Editable region size (5–20 lines stable; 30 lines shows degradation), training data volume (20K sufficient), model scale (larger models benefit more), mixed training (preserves competencies)

- **Failure signatures**: Missing marker in SEARCH block (Gemini models), format overfitting (chat models), small model struggle (<3B models show inconsistent gains)

- **First 3 experiments**:
  1. Zero-shot SRI evaluation: Apply SRI prompt to existing chat models on CrossCodeEval
  2. Fine-tuning ablation: Train on identical 20K dataset as SRI vs. NL-FIM to isolate format effects
  3. Security validation: Run SAL benchmark comparing base-FIM vs. SRI-enabled models

## Open Questions the Paper Calls Out

- How does SRI-Coder perform in real-world IDE deployment, and what qualitative feedback do developers provide on context-aware micro-editing versus standard FIM?
- Can knowledge distillation or other transfer techniques effectively equip smaller models (<1B parameters) with SRI capabilities comparable to larger models?
- To what extent does the performance gain of SRI depend on the prevalence of diff-format data in the pre-training corpus, and can it transfer to model families without such exposure?
- Does SRI's context-aware editing introduce new failure modes in complex, multi-file codebases, such as unintended modifications across dependent files?

## Limitations

- Dataset construction gaps: Exact criteria for selecting SRI training subset and filtering heuristics remain unspecified
- Model-specific format sensitivity: SRI format shows inconsistent performance across different model families
- Limited security validation scope: Testing covers only subset of attack vectors, leaving novel exploits unaddressed

## Confidence

- **High Confidence**: Grounding through SEARCH mechanism (well-supported by internal evidence and consistent performance improvements)
- **Medium Confidence**: Pre-training distribution alignment (compelling but indirect evidence via perplexity correlation)
- **Medium Confidence**: Security inheritance (demonstrated but attributed rather than explicitly validated)

## Next Checks

1. Cross-Model Format Robustness: Test SRI prompt format with diverse model families on CrossCodeEval to identify format-specific failure modes
2. Format Ablation Study: Conduct controlled experiments comparing identical models fine-tuned on equivalent data in SRI vs. NL-FIM formats
3. Extended Security Audit: Expand SAL benchmark testing to include attacks specifically targeting the search-block structure