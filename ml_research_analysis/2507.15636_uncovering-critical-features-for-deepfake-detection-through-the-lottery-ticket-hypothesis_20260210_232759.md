---
ver: rpa2
title: Uncovering Critical Features for Deepfake Detection through the Lottery Ticket
  Hypothesis
arxiv_id: '2507.15636'
source_url: https://arxiv.org/abs/2507.15636
tags:
- pruning
- detection
- deepfake
- network
- sparsity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper applies the Lottery Ticket Hypothesis to deepfake detection,
  examining whether sparse subnetworks can maintain detection accuracy. The authors
  test iterative magnitude pruning (IMP) with MesoNet, CNN-5, ResNet-18, and XceptionNet
  on OpenForensic and FaceForensics++ datasets.
---

# Uncovering Critical Features for Deepfake Detection through the Lottery Ticket Hypothesis

## Quick Facts
- arXiv ID: 2507.15636
- Source URL: https://arxiv.org/abs/2507.15636
- Authors: Lisan Al Amin; Md. Ismail Hossain; Thanh Thi Nguyen; Tasnim Jahan; Mahbubul Islam; Faisal Quader
- Reference count: 31
- Primary result: Iterative magnitude pruning (IMP) enables deepfake detection models to maintain accuracy at 80% sparsity, with ResNet-18 showing strongest lottery ticket behavior

## Executive Summary
This paper explores the application of the Lottery Ticket Hypothesis to deepfake detection, investigating whether sparse subnetworks can maintain detection accuracy after iterative magnitude pruning. The authors test four popular architectures (MesoNet, CNN-5, ResNet-18, and XceptionNet) on two benchmark datasets (OpenForensic and FaceForensics++). Their findings demonstrate that IMP consistently outperforms one-shot pruning approaches, with ResNet-18 maintaining near-original performance even at 80% sparsity. The study also reveals that winning tickets can transfer across datasets, suggesting practical applications for efficient deepfake detection systems.

## Method Summary
The authors employ iterative magnitude pruning (IMP) to identify sparse subnetworks that maintain detection accuracy. They start with four pre-trained deepfake detection architectures and systematically prune weights based on magnitude, retraining after each pruning iteration. The process is applied to both binary classification (real vs. fake) on OpenForensic and FaceForensics++ datasets. Performance is evaluated at various sparsity levels (20%, 40%, 60%, 80%) with comparisons between IMP and one-shot pruning methods. Grad-CAM visualization is used to analyze whether pruned models maintain focus on critical facial regions. The study also examines transferability of winning tickets by applying pruned architectures trained on one dataset to test data from another dataset.

## Key Results
- ResNet-18 demonstrates strongest lottery ticket behavior, maintaining near-original performance at 80% sparsity
- MesoNet retains 56.2% accuracy at 80% sparsity on OpenForensic (≈90% of baseline 62.6%)
- CNN-5 maintains 78.3% accuracy at 60% sparsity on FaceForensics++
- IMP consistently outperforms one-shot pruning across all tested architectures
- Winning tickets show transferability across datasets, maintaining reasonable performance

## Why This Works (Mechanism)
The Lottery Ticket Hypothesis suggests that dense neural networks contain sparse subnetworks (winning tickets) that can be trained in isolation to match or exceed the accuracy of the original network. In deepfake detection, this works because the critical features for identifying manipulated content—such as subtle facial artifacts, inconsistencies in eye movement, or unnatural skin texture—are concentrated in specific pathways within the network. IMP effectively identifies and preserves these crucial connections while removing redundant parameters. The iterative nature of IMP allows the network to adapt to sparsity gradually, redistributing learned features across the remaining parameters and maintaining the model's ability to focus on discriminative facial regions.

## Foundational Learning

**Lottery Ticket Hypothesis**
- Why needed: Provides theoretical foundation for identifying sparse, high-performing subnetworks
- Quick check: Verify that pruned networks can be retrained from original initialization to achieve baseline accuracy

**Iterative Magnitude Pruning (IMP)**
- Why needed: Enables gradual identification of critical network parameters through iterative pruning and retraining
- Quick check: Confirm that performance improves or stabilizes with iterative pruning compared to one-shot approaches

**Grad-CAM Visualization**
- Why needed: Allows qualitative assessment of whether pruned models maintain focus on critical detection regions
- Quick check: Compare activation maps between full and pruned models to verify preserved attention patterns

**Deepfake Detection Benchmarks**
- Why needed: Provides standardized evaluation framework using OpenForensic and FaceForensics++ datasets
- Quick check: Validate dataset splits and ensure consistent preprocessing across all experiments

## Architecture Onboarding

**Component Map**
MesoNet/CNN-5 -> Feature Extraction -> Classification -> Output
ResNet-18/XceptionNet -> Deep Feature Learning -> Classification -> Output

**Critical Path**
Input image → Convolutional layers → Feature maps → Classification head → Binary decision (real/fake)

**Design Tradeoffs**
- IMP vs One-shot pruning: Iterative approach maintains higher accuracy but requires more computational resources
- Sparsity level vs Performance: Higher sparsity reduces model size but may compromise detection accuracy
- Transferability: Winning tickets can cross datasets but may lose some specificity

**Failure Signatures**
- Sudden accuracy drops at specific sparsity thresholds
- Loss of focus on critical facial regions in Grad-CAM analysis
- Failure to converge during retraining phases

**First Experiments**
1. Compare baseline accuracy of all four architectures on both datasets
2. Run one-shot pruning at 50% sparsity for initial performance comparison
3. Execute IMP at 20% sparsity increments to identify optimal pruning strategy

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations

- Binary classification focus without addressing multi-class deepfake detection scenarios
- Limited cross-dataset transferability experiments requiring broader validation
- Grad-CAM analysis lacks quantitative metrics for feature preservation assessment
- Computational overhead of IMP may offset efficiency gains from sparse models

## Confidence

**High Confidence:** IMP consistently outperforms one-shot pruning across architectures and datasets; ResNet-18 shows robust lottery ticket behavior at 80% sparsity.

**Medium Confidence:** Transferability of winning tickets across datasets shows promise but needs validation with more diverse dataset combinations and manipulation types.

**Low Confidence:** Practical deployment claims require real-world testing with computational overhead and inference speed measurements.

## Next Checks

1. **Cross-Dataset Robustness Test**: Validate lottery ticket transferability using additional deepfake datasets with varying manipulation types and compression levels beyond current limited combinations.

2. **Multi-Class Detection Evaluation**: Extend pruning experiments to multi-class scenarios distinguishing between different deepfake generation methods rather than binary classification.

3. **Computational Efficiency Analysis**: Measure actual inference speed and memory usage of pruned models in deployment scenarios to quantify real-world efficiency gains against pruning overhead.