---
ver: rpa2
title: 'Engineering AI Agents for Clinical Workflows: A Case Study in Architecture,MLOps,
  and Governance'
arxiv_id: '2602.00751'
source_url: https://arxiv.org/abs/2602.00751
tags:
- clinical
- architecture
- agent
- mlops
- governance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a case study of the "Maria" platform, a production-grade
  clinical AI system that addresses the engineering challenges of building reliable,
  maintainable, and governable AI for primary healthcare. The central hypothesis is
  that trustworthy clinical AI is achieved through the holistic integration of four
  foundational engineering pillars: a synergistic architecture combining Clean Architecture
  and Event-Driven Architecture for resilience and auditability, an Agent-Based Design
  where AI components are autonomous agents with their own MLOps lifecycle, robust
  MLOps pipelines for versioning, monitoring, and governance, and a Human-in-the-Loop
  governance model integrated as an event-driven safety net.'
---

# Engineering AI Agents for Clinical Workflows: A Case Study in Architecture,MLOps, and Governance

## Quick Facts
- arXiv ID: 2602.00751
- Source URL: https://arxiv.org/abs/2602.00751
- Reference count: 37
- Primary result: Production-grade clinical AI system demonstrating that trustworthy AI requires integrated architecture, MLOps, and governance

## Executive Summary
This paper presents a case study of the "Maria" platform, a production-grade clinical AI system that addresses the engineering challenges of building reliable, maintainable, and governable AI for primary healthcare. The central hypothesis is that trustworthy clinical AI is achieved through the holistic integration of four foundational engineering pillars: a synergistic architecture combining Clean Architecture and Event-Driven Architecture for resilience and auditability, an Agent-Based Design where AI components are autonomous agents with their own MLOps lifecycle, robust MLOps pipelines for versioning, monitoring, and governance, and a Human-in-the-Loop governance model integrated as an event-driven safety net. The platform demonstrates practical lessons for building maintainable, scalable, and accountable AI-enabled systems in high-stakes domains.

## Method Summary
The Maria platform was developed as a production system for primary healthcare workflows, implementing a synergistic architecture that combines Clean Architecture principles with Event-Driven Architecture. The system treats AI components as autonomous agents, each with independent MLOps lifecycles including versioned prompts, schemas, and model IDs. A Human-in-the-Loop governance model is integrated as an event-driven workflow that not only serves as a safety check but also generates a "golden set" of corrected outputs for continuous model improvement. The implementation includes separate CI/CD pipelines per agent, an event bus for auditability, and a clinical review process that captures corrections for retraining.

## Key Results
- Agent-level MLOps lifecycles reduce deployment risk by isolating changes to individual components
- Event-driven architecture provides complete audit trails for regulatory compliance and decision reconstruction
- Human-in-the-Loop corrections form a "golden set" that drives continuous model improvement
- 19% of AI outputs required clinician corrections, creating high-quality training data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Treating AI components as autonomous agents with independent MLOps lifecycles improves system modularity and deployment safety.
- Mechanism: By encapsulating prompts, schemas, policies, and model IDs within each agent, and giving each its own CI/CD pipeline and versioned registry, a change to one agent cannot inadvertently break another. This decoupling localizes risk and enables independent testing and deployment.
- Core assumption: Teams have the resources to build and maintain multiple, independent pipelines and registries.
- Evidence anchors:
  - [abstract] "We introduce the Agent as the primary unit of modularity, each possessing its own autonomous MLOps lifecycle."
  - [section 4.3, Lesson 3] "The lesson for practitioners is that the high upfront engineering cost of building and maintaining separate, autonomous lifecycles pays for itself in reduced deployment risk..."
  - [corpus] Paper 'A Practical Guide for Designing, Developing, and Deploying Production-Grade Agentic AI Workflows' discusses agentic workflows, supporting the concept of agent-based design as a growing practice.
- Break condition: If your organization lacks the infrastructure or team capacity to maintain multiple pipelines, or if the agents are extremely simple and tightly coupled by nature.

### Mechanism 2
- Claim: An Event-Driven Architecture (EDA) serves as the technical backbone for auditability and governance.
- Mechanism: Every significant action (e.g., agent completion, human review, data persistence) publishes an immutable event to a central event bus. This log of domain events creates a complete, end-to-end audit trail, allowing any AI decision to be reconstructed and traced back to a specific model version and human reviewer.
- Core assumption: A reliable and scalable event bus and event storage mechanism are in place.
- Evidence anchors:
  - [abstract] "...synergistic architecture that combines Clean Architecture... with an Event-driven architecture for resilience and auditability."
  - [section 3.1] "...the event bus inherently acts as a governance mechanism; every state change is captured as an immutable domain event, providing the granular, end-to-end audit trail required..."
  - [corpus] Paper 'The Social Responsibility Stack: A Control-Theoretic Architecture for Governing Socio-Technical AI' discusses architectures for governing AI, aligning with the need for built-in governance mechanisms.
- Break condition: If events are not persisted immutably, if the event bus is unreliable and loses messages, or if critical system actions bypass the event bus.

### Mechanism 3
- Claim: A Human-in-the-Loop (HITL) workflow, when integrated as an event-driven MLOps data source, serves as a safety net and a primary engine for continuous improvement.
- Mechanism: The HITL process is not a simple approval gate but a structured workflow that produces high-quality, expert-curated data. Clinician corrections ("Corrected" cohort) feed directly into a "golden set" for offline model evaluation and retraining. This closes the feedback loop, integrating human expertise back into the automated pipeline.
- Core assumption: Sufficient clinical expert time is available to perform reviews, and a process exists to systematically curate feedback into training data.
- Evidence anchors:
  - [abstract] "...Human-in-the-Loop governance model is technically integrated not merely as a safety check, but as a critical, event-driven data source for continuous improvement."
  - [section 4.4, Lesson 4] "...the 19% 'Corrected' cohort is the most valuable output of our system... they are high-quality, expert-curated data points that form the core of our 'golden set' for the MLOps Offline Eval."
  - [corpus] Paper 'Towards Conversational AI for Human-Machine Collaborative MLOps' supports the concept of human-machine collaboration in MLOps.
- Break condition: If the volume of AI outputs overwhelms human review capacity, or if there is no systematic way to ingest corrections back into the training pipeline.

## Foundational Learning

- Concept: **Clean Architecture**
  - Why needed here: To protect core clinical business rules from volatility in outer infrastructure layers (e.g., swapping LLM providers, changing database schemas). It makes core logic testable and maintainable.
  - Quick check question: Can you run the unit tests for your core clinical decision logic without connecting to a real database or external LLM API?

- Concept: **Publish-Subscribe Model**
  - Why needed here: This is the core pattern of the Event-Driven Architecture. It allows components (publishers and subscribers) to communicate asynchronously without direct knowledge of each other, enabling decoupling, resilience, and scalability.
  - Quick check question: Does your `Pre-Medical Appointment Agent` need to know that the `HITL Workflow` exists in order to publish its `completed` event?

- Concept: **MLOps "Golden Set"**
  - Why needed here: It is the curated, validated dataset used for offline evaluation of agents. This set is not static; it is actively enriched by corrections from the HITL process, forming the basis for continuous improvement and preventing model drift.
  - Quick check question: When a clinician corrects an AI-generated summary in production, what is the automated path that gets this corrected example into your model's evaluation dataset?

## Architecture Onboarding

- Component map:
    - Ingestion API -> Intent Classifier -> Agent Layer -> LLM Providers/Storage -> Event Bus -> HITL Workflow -> Storage/Observability

- Critical path:
    1.  User input arrives at `Ingestion API`.
    2.  `Intent Classifier` routes to appropriate `Agent` in the Core.
    3.  `Agent` executes logic via abstract ports, calling `LLM Providers` and `Storage`.
    4.  Upon completion, `Agent` publishes a domain event (e.g., `ClinicalSummaryReadyForReview`) to the `Event Bus`.
    5.  `HITL Workflow` consumes the event, pausing the process and presenting the output to a clinician.
    6.  Clinician's decision (`Approve`/`Correct`/`Reject`) triggers an event, leading to persistence, a feedback loop, or an alert.
    7.  All events are logged to `Observability` for audit and monitoring.

- Design tradeoffs:
    - **Synergistic vs. Isolated Architectures:** Combining Clean and EDA requires careful interface design. The benefit (resilient, maintainable, auditable) outweighs the initial complexity.
    - **Agent-level vs. System-level MLOps:** Agent-level pipelines have higher overhead but isolate deployment risk. System-level is simpler but creates tight coupling.
    - **HITL as a Gate vs. Data Source:** A gate only blocks bad outputs. A data source uses corrections to improve the model, requiring investment in data curation pipelines.

- Failure signatures:
    - **High latency in synchronous API:** Indicates blocking calls in the Core that should be asynchronous. Check if agent logic is waiting on external calls directly.
    - **Cascade failure across agents:** Indicates shared, coupled MLOps pipelines or shared mutable state. Verify pipeline independence.
    - **Loss of audit trail for a decision:** Indicates an action bypassed the `Event Bus`. Check for direct database writes not triggered by an event.

- First 3 experiments:
    1.  **Isolate a Core Use Case:** Take one simple clinical rule (e.g., "a summary must include a diagnosis") and implement it in a Clean Architecture style, creating a use case, entity, and abstract interface. Verify it can be tested without any infrastructure dependencies.
    2.  **Implement a Single-Agent MLOps Lifecycle:** For one agent (e.g., `Pre-Medical Appointment Agent`), create a Git repository and a CI/CD pipeline that versions its prompts and schemas. Deploy a change and observe the independent rollout.
    3.  **Trace a "Golden Set" Example:** Intentionally generate a flawed AI output. Pass it through the HITL workflow, make a correction, and verify that the corrected output is automatically staged in the "golden set" storage location for the MLOps offline evaluation.

## Open Questions the Paper Calls Out
None

## Limitations
- The platform was built for a specific clinical context (primary healthcare in Australia), limiting generalizability to other domains or regulatory environments.
- Results focus on engineering architecture and MLOps processes rather than clinical outcomes or system performance metrics.
- Assumes clinician availability for ongoing HITL review, which may not scale to higher volumes or be sustainable long-term.

## Confidence
- **High**: The architectural patterns (Clean Architecture + EDA) and their implementation details are well-described and technically sound.
- **Medium**: The mechanism for integrating HITL as a continuous improvement data source is conceptually robust but lacks quantified evidence of its effectiveness.
- **Medium**: The claim about agent-level MLOps lifecycles reducing deployment risk is logical but based on internal observations rather than comparative studies.

## Next Checks
1. Measure the actual impact of the "Corrected" cohort on model performance by tracking F1 scores or similar metrics before and after retraining with HITL data.
2. Conduct a resource analysis of maintaining independent MLOps pipelines per agent, including build times, storage costs, and team overhead, to validate the claimed ROI.
3. Test the audit trail reconstruction capability by simulating a clinical decision review and verifying complete traceability from event logs back to model versions and human reviewers.