---
ver: rpa2
title: 'Chinchunmei at SemEval-2025 Task 11: Boosting the Large Language Model''s
  Capability of Emotion Perception using Contrastive Learning'
arxiv_id: '2507.15714'
source_url: https://arxiv.org/abs/2507.15714
tags:
- track
- emotion
- contrastive
- english
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work explores two contrastive learning approaches\u2014sample-based\
  \ (Contrastive Reasoning Calibration) and generation-based (DPO, SimPO)\u2014to\
  \ enhance emotion perception in multilingual text-based emotion detection. The sample-based\
  \ method trains the model by comparing pairs of samples to generate more reliable\
  \ predictions, while the generation-based approach refines predictions by differentiating\
  \ between correct and incorrect outputs."
---

# Chinchunmei at SemEval-2025 Task 11: Boosting the Large Language Model's Capability of Emotion Perception using Contrastive Learning

## Quick Facts
- arXiv ID: 2507.15714
- Source URL: https://arxiv.org/abs/2507.15714
- Reference count: 25
- Primary result: Achieved 9th place in Track A and 6th place in Track B for English, with generation-based contrastive learning (DPO) showing significant gains in intensity prediction

## Executive Summary
This work explores two contrastive learning approaches to enhance emotion perception in multilingual text-based emotion detection. The team fine-tuned LLaMA3-Instruct-8B using LoRA on the SemEval-2025 Task 11 dataset, comparing standard training with sample-based (CRC) and generation-based (DPO, SimPO) contrastive methods. The generation-based approach, particularly DPO, significantly improved intensity prediction performance while sample-based contrastive learning introduced additional uncertainty. Multilingual training degraded English performance, leading the team to use monolingual models for English submissions. The system achieved top rankings in both tracks for English and performed competitively across other languages.

## Method Summary
The method involves fine-tuning LLaMA3-Instruct-8B (8B parameters) using LoRA (rank=8, alpha=16) on SemEval-2025 Task 11 data. Three approaches were implemented: Standard Prediction (SFT) as baseline, Sample-based contrastive (CRC) using random sample pairs for comparison, and Generation-based (DPO/SimPO) using label mutation to create preference pairs. Training used 3 epochs, batch size 128, AdamW optimizer, and language-specific learning rates. CRC inference employed majority voting across multiple rounds (N=3 for Track A, N=7 for Track B). The generation-based methods showed superior performance, particularly for intensity prediction in Track B.

## Key Results
- Generation-based contrastive learning (DPO) significantly improved intensity prediction, achieving top rankings in Track B
- Sample-based contrastive learning (CRC) introduced additional uncertainty, with 70% of errors being neutral predictions
- Multilingual training degraded English performance compared to monolingual training
- Most intensity prediction errors were off-by-one (predicting 2 instead of 3), indicating coarse but not fine-grained understanding

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Generation-based contrastive learning (DPO) improves emotion intensity prediction by refining the model's sensitivity to scoring boundaries.
- **Mechanism:** The model maximizes likelihood of correct outputs while minimizing likelihood of "mutated" (incorrect) outputs, learning finer distinctions between intensity levels.
- **Core assumption:** Incorrect outputs generated via label mutation effectively represent the "negative" space of valid emotion expressions.
- **Evidence anchors:** Abstract shows DPO showing significant gains; Section 4.2 notes over 90% of errors differ from ground truth by only one intensity level.
- **Break condition:** If label mutation is too random or fails to approximate realistic errors, the contrastive signal becomes noise.

### Mechanism 2
- **Claim:** Sample-based contrastive learning (CRC) introduces uncertainty in emotion detection due to inherent ambiguity and subjectivity of emotional text.
- **Mechanism:** The model pairs test samples with reference samples for comparative judgment, but ambiguous reference samples cause prediction fluctuations.
- **Core assumption:** Comparing samples provides stable reference points that reduce prediction variance.
- **Evidence anchors:** Abstract states CRC introduces additional uncertainty; Section 4.2 shows 70% of errors are neutral predictions.
- **Break condition:** Mechanism fails when dataset contains high ambiguity, as comparison amplifies noise rather than canceling it out.

### Mechanism 3
- **Claim:** Joint multilingual training degrades performance in high-resource languages (e.g., English) due to interference in emotion perception across diverse cultural contexts.
- **Mechanism:** The model maps distinct cultural expressions of emotion into shared representation space, but optimization pressure from diverse patterns distorts specific decision boundaries.
- **Core assumption:** Emotion labels are not perfectly universal transferable concepts; cultural context shifts semantic mapping.
- **Evidence anchors:** Abstract shows multilingual training degrades English performance; Section 4.1 identifies conflicts in model's understanding across languages.
- **Break condition:** Mechanism holds under limited model capacity and unified fine-tuning; might break with modular architectures or larger models.

## Foundational Learning

- **Concept: Direct Preference Optimization (DPO)**
  - **Why needed here:** Core technique driving performance gains in Track B, optimizing policy directly using preference pairs without separate reward model.
  - **Quick check question:** How does DPO treat the reference model compared to SimPO, and why might retaining the reference model help preserve structured output formatting?

- **Concept: Label Mutation for Synthetic Preference Pairs**
  - **Why needed here:** DPO requires "chosen" and "rejected" pairs, generated artificially by mutating ground truth labels.
  - **Quick check question:** Why is probability of mutating 5 labels set to just 0.1%? What does this imply about difficulty of handling multi-label vs. single-label errors?

- **Concept: In-Context Contrastive Reasoning**
  - **Why needed here:** Sample-based approach; understanding why comparing "Sample A" vs. "Sample B" might fail helps design better few-shot strategies.
  - **Quick check question:** If model is easily influenced by random reference sample, what does that indicate about its confidence or calibration on primary input?

## Architecture Onboarding

- **Component map:** Base (LLaMA-3-Instruct-8B with LoRA) -> Input Processor (Prompt templates for Track A/B) -> Contrastive Data Engine (CRC pairs or DPO mutation pairs) -> Training Pipeline (SFT -> DPO/SimPO) -> Inference Aggregator (Voting for CRC)

- **Critical path:** Generation of high-quality negative samples (rejection pairs) for DPO is the critical lever for Track B performance.

- **Design tradeoffs:**
  - DPO vs. SimPO: DPO requires reference model (higher memory) but preserves formatting; SimPO is reference-free (efficient) but risks formatting collapse.
  - Multilingual vs. Monolingual: Unified training supports all languages but sacrifices English accuracy; team prioritized competition ranking.

- **Failure signatures:**
  - SimPO formatting collapse: Outputs correct sentiment but in unparseable format.
  - CRC uncertainty drift: Model defaults to "neutral" or oscillates between scores with ambiguous samples.
  - Intensity proximity error: Track B errors predominantly off-by-one, suggesting model understands zone but lacks precision.

- **First 3 experiments:**
  1. Sanity Check (SFT Baseline): Fine-tune LLaMA-3-8B on English-only data using Standard Prediction template.
  2. Mutation Sensitivity Test: Implement DPO pipeline with specified mutation probabilities; verify "rejected" outputs are parseable.
  3. Reference Model Ablation: Run DPO vs. SimPO side-by-side on validation slice to monitor formatting compliance vs. accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can Contrastive Reasoning Calibration (CRC) be adapted to handle borderline emotional expressions without introducing high uncertainty (70% neutral prediction errors)?
- Basis in paper: Page 4, Section 4.2 notes most misclassifications are due to neutral predictions because comparing ambiguous samples "can easily influence their predictions, causing uncertainty."
- Why unresolved: Authors conclude dataset may be ill-suited but don't determine if different sampling strategy could mitigate instability.
- What evidence would resolve it: Experiment with stratified or difficulty-based sampling for CRC pairs, demonstrating reduced neutral bias on ambiguous test cases.

### Open Question 2
- Question: How can reference-free preference optimization methods (like SimPO) be stabilized to prevent catastrophic loss of structured output formatting?
- Basis in paper: Page 5, Conclusion states SimPO's poor performance "primarily stemmed from the loss of output formatting" highlighting "critical role of reference model in stabilizing generation-based contrastive optimization."
- Why unresolved: Paper identifies problem as lack of reference model constraint but doesn't propose mechanism to maintain structure without one.
- What evidence would resolve it: Modified SimPO loss function or constrained decoding approach maintaining output template without reference model.

### Open Question 3
- Question: Does negative transfer from multilingual to English emotion detection stem from conflicting cultural definitions of emotions or linguistic interference in LLaMa-3 backbone?
- Basis in paper: Page 4, Section 4.1 states multilingual training underperforms English-only and suggests "differences in emotion perception across languages introduce conflicts."
- Why unresolved: Authors observe degradation but don't ablate whether issue arises from limited capacity to align cultural emotion norms or diluting English data distribution.
- What evidence would resolve it: Ablation study measuring performance degradation as function of training data diversity across culturally vs. linguistically distinct languages.

## Limitations

- Critical hyperparameters for DPO and SimPO (β and γ values) are not specified, making faithful reproduction challenging.
- CRC approach's tendency to produce neutral predictions (70% of errors) is identified but not adequately explained or investigated.
- Performance gains in Track B are qualified by the observation that most errors differ by only one intensity level, suggesting lack of fine-grained precision.

## Confidence

**High Confidence:** Generation-based contrastive learning (DPO) improves intensity prediction is well-supported by experimental results showing top rankings in Track B across all metrics.

**Medium Confidence:** Multilingual training degrades English performance is supported by experimental data but lacks detailed investigation into underlying causes.

**Low Confidence:** Sample-based contrastive learning introduces additional uncertainty is primarily a negative result without comprehensive analysis of why the approach fails.

## Next Checks

1. **Hyperparameter Sensitivity Analysis:** Systematically vary DPO β parameter (e.g., 0.01, 0.1, 1.0) and SimPO γ parameter to determine impact on performance and output formatting stability.

2. **Reference Sample Quality Assessment:** Analyze distribution of reference samples used in CRC inference to determine if certain types (ambiguous, neutral, or highly emotional) correlate with increased prediction uncertainty.

3. **Cross-Lingual Interference Quantification:** Design experiment measuring performance degradation as function of training data diversity by training models on English-only, English+one other language, and English+multiple languages.