---
ver: rpa2
title: 'PhaseNAS: Language-Model Driven Architecture Search with Dynamic Phase Adaptation'
arxiv_id: '2507.20592'
source_url: https://arxiv.org/abs/2507.20592
tags:
- search
- phasenas
- architecture
- detection
- phase
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PhaseNAS addresses the efficiency challenge in Neural Architecture
  Search (NAS) by introducing a dynamic, LLM-driven framework with phase-aware model
  switching. The method uses smaller LLMs for initial exploration and transitions
  to larger LLMs for refinement based on real-time score thresholds.
---

# PhaseNAS: Language-Model Driven Architecture Search with Dynamic Phase Adaptation

## Quick Facts
- arXiv ID: 2507.20592
- Source URL: https://arxiv.org/abs/2507.20592
- Reference count: 20
- Primary result: Dynamic LLM-driven NAS with phase transitions reduces search time by up to 86% while maintaining/improving accuracy across vision tasks

## Executive Summary
PhaseNAS introduces a dynamic, LLM-driven neural architecture search framework that uses smaller LLMs for initial exploration and larger LLMs for refinement based on real-time performance thresholds. The method employs a structured template language to reduce semantic ambiguity in architecture generation and uses zero-shot proxy scoring (Zen-Score extension) to accelerate evaluation. On NAS-Bench-Macro, PhaseNAS achieves 93.11% accuracy (rank 3), outperforming static LLM approaches. For CIFAR-10/100 classification, it reduces search time by up to 86% while maintaining or improving accuracy (up to 97.34%). In object detection (COCO), PhaseNAS produces YOLOv8 variants with higher mAP (up to 46.1) and lower computational cost than baselines.

## Method Summary
PhaseNAS implements a two-phase search using small LLMs for exploration (Qwen2.5-7B/14B/32B) and large LLMs for refinement (Qwen2.5-72B/Llama-3.3-70B/Claude-3.5-Sonnet). Architectures are encoded using structured template strings (e.g., `ConvK3BNRELU(3,8,1,1)`) and evaluated via zero-shot proxy scoring (Zen-NAS for classification, NAS_det for detection). The search transitions from exploration to refinement when architectures exceed performance thresholds (γ_trans, γ_stop). The framework maintains a priority pool of top-K candidates and validates architectures for dimension compatibility before final evaluation.

## Key Results
- NAS-Bench-Macro: 93.11% accuracy (rank 3), outperforming static LLM approaches
- CIFAR-10/100: Up to 97.34% accuracy with 86% search time reduction
- COCO object detection: YOLOv8 variants with mAP up to 46.1 and lower computational cost
- Phase transition mechanism demonstrates superior efficiency across diverse vision tasks

## Why This Works (Mechanism)

### Mechanism 1: Phase-Dependent Resource Scaling
Allocating smaller LLMs for broad exploration and larger LLMs for refinement optimizes the efficiency-quality trade-off in architecture search. The framework starts with cost-efficient smaller LLMs for sampling diverse architectures, then switches to larger, more capable LLMs when candidates hit performance thresholds, avoiding the cost of running large models on low-potential candidates.

### Mechanism 2: Structured Template Encoding
Translating architecture configurations into structured, string-based template language reduces syntax errors and improves LLM comprehension compared to free-form text. Architectures are described via parameterized templates (e.g., `ConvK3BNRELU(3,8,1,1)`) that enforce dimension compatibility and reduce semantic ambiguity.

### Mechanism 3: Zero-Shot Proxy Scoring (Zen-Score Extension)
Evaluating architectures without training by measuring sensitivity to input perturbations and BatchNorm stability accelerates the search loop. PhaseNAS calculates a NAS Score by perturbing inputs and measuring response in feature maps and normalization layers, serving as a proxy for trainability and generalization.

## Foundational Learning

- **Search Space vs. Evaluation Protocol**: PhaseNAS decouples architecture generation (LLM) from evaluation (Zero-Shot Score). This separation is crucial for search speed.
  - Quick check: Can you distinguish between the metric used to guide the LLM (Score) and the metric used for final result (Accuracy/mAP)?

- **Zero-Shot NAS Proxies**: The paper relies on "Zen-Score" to skip training. This is a heuristic based on signal propagation theory, not a trained metric.
  - Quick check: Does calculating the NAS Score require backpropagation/gradient updates, or just forward passes?

- **LLM Context Windows and Constraints**: The switch from small to large LLMs implies constraints on prompt complexity. The "Structured Template" is essentially a compression method to fit architecture definitions into context windows of smaller models.
  - Quick check: Why would a "rigid" template help a smaller (7B parameter) model succeed where free-form Python code might fail?

## Architecture Onboarding

- **Component map**: Controller -> LLM Interface -> Parser/Builder -> Scorer -> Pool
- **Critical path**: Prompt Construction (Task constraints → Natural Language) → Generation (LLM → Template String) → Validation & Scoring (Template → Model → Score) → Phase Transition Check (Score ≥ γ_trans?)
- **Design tradeoffs**:
  - Threshold Sensitivity: Setting γ_trans too low risks switching to expensive LLM too early; setting it too high risks never switching
  - Template Rigidity: Strict templates ensure valid code but may limit novel architectural discoveries
- **Failure signatures**:
  - Stuck in Exploration: Pool never produces score above γ_trans, causing small LLM to loop infinitely
  - Syntax Drift: LLM generates valid-looking strings that fail to parse into executable models
  - Proxy Mismatch: High NAS Score but low final accuracy (overfitting to proxy metric)
- **First 3 experiments**:
  1. Validation Run: Run PhaseNAS on NAS-Bench-Macro for 10 iterations to verify rank/accuracy reproduction
  2. Ablation on Phase Switch: Run search with γ_trans set very high (Exploration only) vs. very low (Refinement only) to measure cost/accuracy delta
  3. Template Stress Test: Generate YOLOv8* variant with SCDown block to ensure parser handles specific module definitions

## Open Questions the Paper Calls Out
- How sensitive is PhaseNAS performance to choice of transition threshold (γ_trans, γ_stop), and can these be automatically determined without manual tuning?
- Does the dynamic phase transition approach generalize to non-vision domains such as natural language processing and multi-modal tasks?
- How well does the proposed detection-specific NAS score (NAS_det) correlate with actual trained detection performance across diverse architectures?
- Can hardware-aware metrics such as latency and energy consumption be integrated into PhaseNAS without sacrificing search efficiency?

## Limitations
- Phase transition mechanism introduces sensitivity to threshold calibration which could significantly impact efficiency gains but lacks thorough analysis
- Zero-shot proxy scoring shows promising correlation but lacks ablation studies demonstrating robustness when proxy scores diverge from true performance
- Template rigidity, while solving syntax issues, may constrain architectural innovation in emerging design spaces

## Confidence
- High confidence: Efficiency improvements (86% search time reduction) and CIFAR-10/100 accuracy results (up to 97.34%)
- Medium confidence: Object detection performance (mAP up to 46.1) - depends on proper COCO validation setup
- Medium confidence: NAS-Bench-Macro ranking (93.11%, rank 3) - benchmark-specific results may not generalize
- Low confidence: Generalizability claims across "diverse vision tasks" - limited to classification and detection

## Next Checks
1. **Threshold Sensitivity Analysis**: Systematically vary γ_trans from 100-120 to quantify efficiency-accuracy trade-offs and identify optimal operating points
2. **Proxy Score Correlation Validation**: Generate architectures with high NAS Score but intentionally invalid structures to test if proxy truly filters poor designs
3. **Cross-Task Transfer Test**: Apply PhaseNAS template and scoring to a novel vision task (e.g., semantic segmentation) to validate framework adaptability beyond classification/detection