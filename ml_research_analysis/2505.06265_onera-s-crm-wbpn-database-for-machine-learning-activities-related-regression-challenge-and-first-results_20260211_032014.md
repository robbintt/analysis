---
ver: rpa2
title: ONERA's CRM WBPN database for machine learning activities, related regression
  challenge and first results
arxiv_id: '2505.06265'
source_url: https://arxiv.org/abs/2505.06265
tags:
- flow
- data
- conditions
- regressors
- been
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces ONERA's CRM WBPN database, comprising 468\
  \ Reynolds-Averaged Navier-Stokes simulations using the Spalart-Allmaras turbulence\
  \ model on the NASA/Boeing Common Research Model wing-body-pylon-nacelle configuration.\
  \ The database covers wide-ranging flow conditions including Mach numbers from 0.30\
  \ to 0.96, angles of attack from -15\xB0 to 15\xB0, and three Reynolds numbers based\
  \ on different stagnation pressures."
---

# ONERA's CRM WBPN database for machine learning activities, related regression challenge and first results

## Quick Facts
- **arXiv ID:** 2505.06265
- **Source URL:** https://arxiv.org/abs/2505.06265
- **Reference count:** 32
- **Key outcome:** ONERA's CRM WBPN database comprises 468 RANS-SA simulations covering wide flight envelope; regression challenge predicts wall distributions with R² scores 0.890-0.956 and wrMAE 0.228-0.346

## Executive Summary
This paper introduces ONERA's CRM WBPN database containing 468 Reynolds-Averaged Navier-Stokes simulations with Spalart-Allmaras turbulence model on the NASA/Boeing Common Research Model wing-body-pylon-nacelle configuration. The database covers Mach numbers from 0.30 to 0.96, angles of attack from -15° to 15°, and three Reynolds numbers. A regression challenge is defined to predict wall distributions of pressure and friction coefficients for unseen aerodynamic conditions, with two-thirds of the data allocated for training/validation and one-third for testing. Classical machine learning regressors are evaluated, showing intermediate difficulty with globally satisfactory accuracy but high errors for worst-case predictions.

## Method Summary
The database uses 468 RANS-SA simulations on CRM WBPN geometry with 260,774 wall points per simulation. Input features include coordinates (x,y,z), normal vectors (nx,ny,nz), and flow conditions (M∞, AoA, pi). Train/test split uses 312 simulations for training (further split 75%/25% for inner-training/validation) and 156 for testing, with final evaluation on 140 test cases excluding extreme AoA. Pointwise MLP with 5 hidden layers (166, 235, 248, 81, 72), λ-DNN dual-branch architecture, and Decision Tree (depth=108) are tested against global methods including MLP, kNN (k=6-9), POD+RBF (99% energy threshold), and IsoMap+RBF (r=3 latent dimensions). Weighted R² score and worst relative mean absolute error (wrMAE) serve as evaluation metrics.

## Key Results
- Global MLP achieves highest R² score of 0.956 across all four output variables
- IsoMap outperforms POD with R²=0.940 versus 0.890, showing better preservation of sharp flow features
- Worst-case relative mean absolute errors range from 0.228 to 0.346, indicating difficulty at extreme conditions
- Global methods consistently outperform pointwise methods due to better spatial correlation capture

## Why This Works (Mechanism)

### Mechanism 1: Constrained Physics Coverage via RANS-SA
By fixing the geometry and turbulence model, the solution space becomes a function of only three flow parameters, allowing regressors to interpolate between known states. The 468 simulations provide discrete mapping of 3D input space to high-dimensional output space. RANS-SA model must accurately capture physical trends across flight envelope for reliable regression targets.

### Mechanism 2: Spatial Context in Global Regressors
Global regressors outperform pointwise methods by implicitly capturing spatial correlations and shock structures. Pointwise methods treat each surface point as independent, while global methods force network to learn coherent spatial distribution, penalizing physically implausible discontinuities.

### Mechanism 3: Manifold Learning for Non-Linear Dynamics
IsoMap outperforms POD because it better preserves non-linear geometry of flow manifold. POD relies on linear superposition struggling with sharp structures like moving shocks, while IsoMap uses geodesic distances to respect non-linear curvature of parameter space.

## Foundational Learning

- **Concept:** Reynolds-Averaged Navier-Stokes (RANS) Limitations
  - **Why needed here:** Database uses RANS with Spalart-Allmaras providing steady average of turbulent flow, missing unsteady fluctuations
  - **Quick check question:** Does the database contain unsteady (time-resolved) data? (No, relies on steady-state assumptions degrading at high AoA)

- **Concept:** Pointwise vs. Global Regression
  - **Why needed here:** Defines architecture strategy - pointwise scales easily but ignores spatial neighbors; global captures topology but scales poorly with mesh size
  - **Quick check question:** If you add new point to mesh, does pointwise regressor require retraining? (No, usually, provided inputs are normalized)

- **Concept:** Overfitting in High-Dimensional Spaces
  - **Why needed here:** With 260k outputs and only 312 training flows, global methods risk memorization
  - **Quick check question:** Why did Decision Tree achieve high R² but terrible worst-case error? (Overfit training density, depth-108 tree failed to generalize on sparse test regions)

## Architecture Onboarding

- **Component map:** Flow Conditions (M∞, AoA, pi) + (optional: x,y,z,nx,ny,nz) -> Regressor (Global MLP or IsoMap recommended) -> Surface Fields (Cp, Cfx, Cfy, Cfz) at 260,774 nodes -> Integration for total forces

- **Critical path:** Load Scattered Data (X: inputs, Y: coefficients) -> Perform Train/Test Split (2/3 train, 1/3 test) -> Scale inputs/outputs (Critical for MLPs) -> Train Global MLP (5 layers, width up to 16k neurons)

- **Design tradeoffs:** Global MLP: Highest accuracy (R²=0.956) but massive parameter count; IsoMap: Better physics preservation than POD for shocks but requires expensive geodesic distance calculation; Pointwise MLP: Lower accuracy but independent of mesh topology

- **Failure signatures:** Shock Misplacement (Global MLP missing upper surface shock), Extreme AoA Divergence (High wrMAE >0.30 at low Mach/high incidence), Overfitting (Decision Trees memorizing training data)

- **First 3 experiments:** 1) Baseline Pointwise MLP: Implement simple MLP to predict Cp from (M, AoA, pi, x, y, z), measure test R² (~0.93 target); 2) Global MLP Benchmark: Implement paper's best architecture to verify R²=0.956, check missed shock reproduction; 3) IsoMap Embedding: Run IsoMap on training snapshots to visualize 3D latent space, verify test points inside training convex hull

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can novel regression architectures significantly reduce the worst relative mean absolute error (wrMAE) observed in baseline models without sacrificing global accuracy?
- **Basis in paper:** Authors note "intermediate difficulty" of challenge, highlighting satisfactory global R² scores (up to 0.956) but high relative errors (wrMAE 0.228-0.346) for worst-case predictions
- **Why unresolved:** Classical methods fail to robustly handle non-linearities of flight envelope, particularly at extreme angles of attack where convergence is poor
- **What evidence would resolve it:** Model submission achieving wrMAE below 0.2 while maintaining R² above 0.95 on test set

### Open Question 2
- **Question:** How can machine learning regressors be adapted to accurately predict sharp discontinuities, such as shock waves, which are currently smoothed out?
- **Basis in paper:** Analysis shows global MLP results state "detailed characteristics of flow are still poorly predicted," specifically noting shock visible in CFD data does not appear in model prediction
- **Why unresolved:** Standard fully-connected networks and POD-based methods tend to diffuse sharp gradients, failing to capture distinct transonic shock features
- **What evidence would resolve it:** Visual confirmation of predicted shock locations aligning with CFD isolines and improved local error metrics in transonic flow regions

### Open Question 3
- **Question:** Does leveraging structured surface mesh topology yield better performance for wall distribution regression compared to scattered pointwise approaches?
- **Basis in paper:** Paper notes data projected onto non-overlapping multi-patch structured wall-mesh and suggests "topological machine learning might be considered in the future"
- **Why unresolved:** Current study focuses on scattered pointwise and global mode-wise methods, leaving potential benefits of exploiting mesh connectivity unexplored
- **What evidence would resolve it:** Comparative benchmarks showing structured methods outperforming pointwise MLP baselines (R² ~0.935) on same test conditions

## Limitations
- RANS-SA simulations degrade at high angles of attack where flow separation and unsteadiness dominate, potentially limiting prediction accuracy
- Test set excludes extreme conditions, potentially masking worst-case model failures and creating overly optimistic performance estimates
- Quasi-random train/test split prevents direct replication without exact seed or ordering, limiting reproducibility

## Confidence

- **High Confidence:** Existence and basic properties of CRM WBPN database (468 simulations, 260k+ wall points, specified flow conditions) are well-documented and verifiable through Codabench platform
- **Medium Confidence:** Relative performance rankings of different ML methods (Global MLP > IsoMap > Pointwise MLP > POD) are supported by reported metrics, though exact score values depend on specific train/test split
- **Low Confidence:** Claim that global methods inherently capture spatial correlations better than pointwise methods assumes specific mesh topology and training density; may not generalize to unstructured meshes or sparse sampling

## Next Checks

1. **RANS Accuracy Verification:** Compare RANS-SA predictions against higher-fidelity simulations (LES/DNS if available) for select extreme AoA cases to quantify "ground truth" error floor that ML methods cannot surpass

2. **Extrapolation Stress Test:** Train on subset of data excluding specific Mach/AoA region, then test on that region to measure true extrapolation capability beyond interpolation

3. **Mesh Sensitivity Analysis:** Repeat regression challenge on coarser mesh version of database to determine if spatial correlation benefits of global methods persist when surface resolution decreases