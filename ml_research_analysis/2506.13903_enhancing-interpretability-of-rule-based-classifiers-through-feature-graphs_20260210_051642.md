---
ver: rpa2
title: Enhancing interpretability of rule-based classifiers through feature graphs
arxiv_id: '2506.13903'
source_url: https://arxiv.org/abs/2506.13903
tags:
- feature
- rule
- features
- importance
- rules
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of interpreting complex rule-based
  classifiers by proposing a comprehensive framework for estimating feature contributions.
  The core method involves a graph-based feature visualisation strategy that projects
  rule sets onto feature graphs, capturing feature interactions and importance.
---

# Enhancing interpretability of rule-based classifiers through feature graphs

## Quick Facts
- arXiv ID: 2506.13903
- Source URL: https://arxiv.org/abs/2506.13903
- Authors: Christel Sirocchi; Damiano Verda
- Reference count: 30
- The proposed feature importance metric achieves 8 top robustness scores across 15 datasets, outperforming Gini (4), SHAP (2), and permutation (1) while maintaining comparable accuracy.

## Executive Summary
This paper addresses the challenge of interpreting complex rule-based classifiers by proposing a comprehensive framework for estimating feature contributions. The core method involves a graph-based feature visualization strategy that projects rule sets onto feature graphs, capturing feature interactions and importance. A novel feature importance metric derived from this graph, along with a distance metric for comparing rule sets, are introduced. Experiments on synthetic and benchmark datasets, including two clinical datasets, demonstrate the method's ability to uncover relevant features and interactions. The proposed feature importance metric performs comparably to permutation importance in accuracy and excels in robustness, achieving 8 top scores for robustness across 15 datasets. This framework provides valuable insights for high-stakes domains like healthcare, aiding in identifying risk factors and prioritizing patient information.

## Method Summary
The framework projects rule-based classifiers onto feature graphs to capture feature interactions and importance. It computes feature relevance via error-based metrics, rule relevance via covering and error, then constructs a tripartite graph (features → rules → classes) that's projected onto a feature-only graph using multiplicative aggregation. Feature importance is computed as degree centrality in this graph, while rule set distance is measured via Frobenius norm of adjacency matrix differences. The method is evaluated on synthetic datasets and 15 public benchmarks, comparing feature selection accuracy and robustness against permutation importance, Gini importance, and SHAP.

## Key Results
- The feature importance metric achieves 8 top robustness scores vs. 4 for Gini, 2 for SHAP, and 1 for permutation across 15 datasets
- Feature selection accuracy is comparable to permutation importance while demonstrating superior stability across cross-validation folds
- The framework successfully identifies both independent and combined predictive features in synthetic datasets
- Distance metrics effectively differentiate between structurally similar and dissimilar rule-based models

## Why This Works (Mechanism)

### Mechanism 1: Tripartite-to-Bipartite Graph Projection
Projecting rule-based classifiers onto feature graphs preserves feature interaction information that scalar importance scores lose. A tripartite graph (features → rules → classes) with weighted edges is projected onto a feature-only graph where edge weights between features reflect their joint contribution to shared rules. The projection formula uses multiplicative aggregation: aij = 1 - ∏(1 - pki · pkj · qk) across all rules, where pki/pkj are feature relevances and qk is rule relevance. This makes the score sensitive to strong joint relevance in even a single rule, unlike additive aggregation which would dilute rare but important interactions. The core assumption is that strong feature interactions in rule sets are infrequent but significant; multiplicative aggregation preserves these better than summation. Evidence shows the method captures both diagonal dominance (independent features) and off-diagonal dominance (combined features) in synthetic datasets.

### Mechanism 2: Degree Centrality as Feature Importance
Degree centrality in the projected feature graph provides a feature importance metric that is both accurate for feature selection and more robust to data variability than permutation importance or Gini importance. Feature importance is computed as the sum of the i-th row of the normalized adjacency matrix: Importance(vi) = Σ A'ij. This aggregates both self-edges (individual contributions) and cross-edges (joint contributions), unlike Gini importance which only captures marginal impurity reduction. The core assumption is that features contributing to many high-quality rules deserve higher importance. Evidence shows the metric performs comparably to permutation importance in accuracy while achieving 8 top robustness scores across 15 datasets versus 4 for Gini, 2 for SHAP, and 1 for permutation.

### Mechanism 3: Frobenius Norm Distance for Rule Set Comparison
The Frobenius norm of adjacency matrix differences provides a size-agnostic distance metric for comparing rule sets across models, datasets, or time periods. Given two feature graphs with adjacency matrices A'₁ and A'₂, distance is d(A'₁, A'₂) = ||A'₁ - A'₂||F. Since graphs are normalized to sum to 100, the distance is independent of rule set size, enabling comparison between models with different numbers of rules. The core assumption is that feature contribution patterns are the meaningful basis for comparing rule sets. Evidence shows the metric correctly identifies DT and MLP as most similar models and DT and RIPPER as most different when comparing multiple classifiers.

## Foundational Learning

- **Rule-based classifiers and rule extraction**: The framework operates on rule sets from DT, LLM, RIPPER, or extracted from neural networks. Understanding how rules are generated and represented (antecedent → consequent) is prerequisite. Quick check: Given a decision tree path "if glucose > 140 AND age > 50 → diabetes", can you write it as a formal rule Rk = (Ck, Tk)?

- **Covering and error in rule quality metrics**: Feature relevance (I□) and rule relevance (I∇) are computed from covering (proportion of correct-class samples satisfying the rule) and error (proportion of wrong-class samples satisfying the rule). Quick check: A rule Rk has covering = 0.3 and error = 0.1. What is the rule relevance I∇?

- **Graph projection and centrality measures**: The core contribution is projecting a tripartite graph onto a feature graph and using degree centrality as importance. Understanding bipartite/graph projection is essential. Quick check: In a feature graph with 3 nodes and adjacency matrix A (normalized to sum 100), if row 1 sums to 45 and row 2 sums to 35, which feature has higher importance?

## Architecture Onboarding

- **Component map**: Input: Rule set R (n rules), feature set V (m features), dataset D (d samples) → Feature Relevance Matrix P (n × m) → Rule Relevance Vector q (n × 1) → Adjacency Matrix A (m × m) → Normalized A' (sum = 100) → Feature Importance (degree centrality) → Graph Distance (Frobenius norm)

- **Critical path**: Rule set → Relevance computation (P, q) → Graph projection (A → A') → Centrality/Distance. The relevance computation is the bottleneck for large rule sets (O(n × m × d) for error-based I□).

- **Design tradeoffs**: Multiplicative vs. additive projection: Multiplicative highlights rare strong interactions; additive smooths them out. Error-based vs. impurity-based relevance: Error-based requires dataset access; impurity-based (Gini) is dataset-free but less accurate for rule quality. Normalization: Sum-to-100 normalization enables cross-model comparison but loses absolute scale information.

- **Failure signatures**: Empty or sparse feature graph: Indicates rules use few/no shared features; check rule diversity or feature redundancy. Near-zero centrality for known-important features: Check if relevance metrics (covering/error) are computed correctly; rules may have high error. Distance metric returns very high values for similar rule sets: Check feature alignment—are feature sets identical?

- **First 3 experiments**:
  1. Generate synthetic datasets with known independent vs. combined predictive features; verify diagonal dominance for independent features and off-diagonal dominance for combined features.
  2. On Pima Diabetes, select top-k features using graph centrality vs. permutation importance; compare downstream DT accuracy and verify robustness across CV folds.
  3. Train DT and LLM on same dataset; compute graph distance; verify structurally different models (RIPPER vs. MLP+extraction) yield higher distances than similar models (DT vs. MLP).

## Open Questions the Paper Calls Out

- **Hypergraph modeling**: Can modeling rule-feature relationships as hypergraphs provide more accurate representations of higher-order feature interactions than the proposed pairwise projection strategy? The current framework projects tripartite relationships onto a pairwise feature graph, which may obscure the specific context of complex interactions involving three or more features simultaneously.

- **Alternative relevance metrics**: How does the choice of underlying relevance metrics (e.g., support, lift, impurity gain) impact the stability and accuracy of the proposed feature importance score? The experiments primarily utilized specific relevance functions based on covering and error; the sensitivity of the final graph centrality to these input parameters remains untested.

- **Hypercube-based methods**: Does the feature graph framework maintain its robustness when applied to rule sets generated by hypercube-based extraction methods (e.g., ITER, GridEx)? The evaluation was limited to decision trees, RIPPER, LLM, and neural networks with CART extraction. Hypercube methods produce grid-like rule structures that may yield different graph densities or interaction patterns.

## Limitations
- The multiplicative projection mechanism, though theoretically sound for capturing rare strong interactions, lacks direct empirical validation against additive alternatives
- The error-based relevance computation requires full dataset access, limiting applicability to cases where rules can be re-evaluated
- The normalization step for distance metrics, while enabling cross-model comparison, discards absolute scale information that may be diagnostically useful

## Confidence
- **High Confidence**: The framework's ability to compute feature importance rankings comparable to permutation importance, supported by consistent results across 15 datasets
- **Medium Confidence**: The robustness advantage over competing methods (8 top scores vs. 4 for Gini), though this depends on the specific cross-validation protocol
- **Low Confidence**: The specific advantages of multiplicative over additive graph projection, as this mechanism is theoretically justified but not empirically validated

## Next Checks
1. Generate synthetic datasets with known interaction patterns (independent vs. combined features) and verify that the graph projection correctly identifies diagonal dominance for independent features and off-diagonal dominance for combined features

2. Implement both multiplicative and additive graph projection variants on the same datasets; compare their ability to identify known important feature interactions in benchmark datasets

3. Test the framework on larger rule sets (100+ rules) to evaluate computational efficiency of the error-based relevance computation and identify performance bottlenecks