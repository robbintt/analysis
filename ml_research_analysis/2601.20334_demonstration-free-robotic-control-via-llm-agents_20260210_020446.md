---
ver: rpa2
title: Demonstration-Free Robotic Control via LLM Agents
arxiv_id: '2601.20334'
source_url: https://arxiv.org/abs/2601.20334
tags:
- agent
- tasks
- manipulation
- faea
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether general-purpose LLM agent frameworks
  can serve as an alternative control paradigm for embodied manipulation, without
  requiring task-specific demonstrations or fine-tuning. The authors introduce FAEA
  (Frontier Agent as Embodied Agent), which applies an unmodified LLM agent framework
  directly to manipulation tasks, using iterative reasoning to discover successful
  policies through trial and error.
---

# Demonstration-Free Robotic Control via LLM Agents

## Quick Facts
- arXiv ID: 2601.20334
- Source URL: https://arxiv.org/abs/2601.20334
- Reference count: 39
- Primary result: LLM agents achieve 84.9%-96% success on manipulation tasks without demonstrations or fine-tuning

## Executive Summary
This paper demonstrates that unmodified LLM agent frameworks can directly control robotic manipulation tasks without requiring task-specific demonstrations or fine-tuning. The authors introduce FAEA (Frontier Agent as Embodied Agent), which applies iterative reasoning through a ReAct loop to discover successful policies via trial and error. Evaluated on LIBERO, ManiSkill3, and MetaWorld benchmarks with privileged state access, FAEA achieves success rates approaching VLA models trained with up to 100 demonstrations per task, while requiring zero demonstrations or fine-tuning. The approach enables autonomous exploration of novel scenarios and opens a path for robotics systems to leverage actively maintained agent infrastructure and benefit from ongoing advances in frontier models.

## Method Summary
FAEA uses an unmodified LLM agent framework (Claude Opus 4.5 via Claude Agent SDK) to control robotic manipulation through iterative reasoning. The system operates via a ReAct loop: reasoning about the task, generating Python scripts for simulation execution, observing outcomes, and refining the approach. It uses privileged state access (exact object positions, gripper state via `get_obs()`) through a Gymnasium interface. No gradient updates or task-specific fine-tuning are performed. The method employs absolute end-effector position control and a standardized prompt template. Human coaching can be optionally added to improve performance. The approach is evaluated on three benchmarks: LIBERO (120 tasks), ManiSkill3 (14 tasks × 5 seeds), and MetaWorld (50 tasks).

## Key Results
- FAEA achieves 84.9% success on LIBERO, 85.7% on ManiSkill3, and 96% on MetaWorld benchmarks
- Performance approaches VLA models trained with ≤100 demonstrations per task despite requiring zero demonstrations or fine-tuning
- Human coaching increases LIBERO performance from 84.9% to 88.2%
- The method enables autonomous exploration of novel scenarios without demonstration data

## Why This Works (Mechanism)
FAEA works by leveraging the strong reasoning capabilities of frontier LLMs to decompose complex manipulation tasks into executable Python scripts. The iterative ReAct loop allows the agent to discover successful policies through trial and error, without requiring any pre-collected demonstration data. By using privileged state access, the agent can make precise geometric reasoning about object positions and gripper states. The demonstration-free approach enables autonomous exploration and benefits directly from ongoing advances in frontier models without requiring robotics-specific fine-tuning.

## Foundational Learning
- **ReAct loop reasoning**: Iterative cycle of reasoning → action generation → observation → refinement. Why needed: Enables discovery of successful policies without demonstrations. Quick check: Can the agent successfully complete tasks with increasing complexity?
- **Privileged state access**: Direct access to ground-truth object positions and gripper states via `get_obs()`. Why needed: Enables precise geometric reasoning for manipulation planning. Quick check: Does the agent correctly identify object positions and gripper state?
- **Script-based control**: Generation of executable Python scripts for simulation interaction. Why needed: Translates high-level reasoning into concrete simulation actions. Quick check: Are generated scripts syntactically valid and executable?
- **Trace validation**: Post-hoc verification of agent behavior to detect cheating or brute-force patterns. Why needed: Ensures genuine problem-solving rather than exploitation of simulator loopholes. Quick check: Does automated validation confirm legitimate problem-solving?

## Architecture Onboarding

**Component Map**: Task description -> LLM reasoning -> Python script generation -> Simulation execution -> Observation -> Trace validation -> Success check

**Critical Path**: The ReAct loop forms the critical path where each iteration involves LLM reasoning, script generation, simulation execution, and observation. Performance is bounded by LLM inference time and simulation execution speed.

**Design Tradeoffs**: The method trades computational efficiency for demonstration-free capability. Each decision cycle requires LLM reasoning and script generation, making real-time control impractical but eliminating the need for demonstration collection. Privileged state access enables precise control but limits real-world applicability.

**Failure Signatures**: Precision tasks consistently fail due to the mismatch between reasoning timescales and fine-grained control requirements. Tasks requiring sub-millimeter alignment (peg/plug insertion) are particularly problematic. The agent may also attempt to cheat by accessing internal simulator state or performing exhaustive searches.

**3 First Experiments**:
1. Run FAEA on a simple pick-and-place task to verify basic functionality
2. Test on a precision task (e.g., peg insertion) to observe failure modes
3. Evaluate with and without human coaching on the same task to measure coaching impact

## Open Questions the Paper Calls Out
- **Vision-only adaptation**: Can FAEA transfer to physical robots using standard perception pipelines? All experiments relied on privileged state access unavailable in physical settings.
- **Dynamic manipulation extension**: How far can agentic control extend toward dynamic or reactive manipulation? Current deliberative planning operates at seconds-scale latency.
- **Safety constraint development**: How can safety constraints prevent hazardous exploration without stifling problem-solving? Agents optimized for success may exploit unintended shortcuts.
- **Precision task capability**: Can the framework overcome precision limitations observed in assembly tasks? Discrete action commands cannot currently achieve sub-millimeter alignment.

## Limitations
- Relies on privileged state information (exact object positions, gripper state) rather than vision-only perception
- Struggles with precision-demanding tasks requiring sub-centimeter accuracy
- Computationally expensive per decision cycle, making real-time control impractical
- High success rates on MetaWorld may reflect task simplicity rather than method superiority

## Confidence
**High confidence** in the core finding that unmodified LLM agents can solve complex manipulation tasks without demonstrations or fine-tuning, given privileged state access.
**Medium confidence** in claims about practical utility for real-world robotics, given the privileged state assumption and computational requirements.
**Low confidence** in the assertion that FAEA enables autonomous exploration of "novel scenarios" beyond the tested benchmarks.

## Next Checks
1. **Vision-only adaptation**: Implement a vision encoder for state observation and evaluate FAEA performance on the same benchmarks to quantify the impact of removing privileged state access.
2. **Real-time feasibility analysis**: Measure end-to-end latency per decision cycle including LLM inference, script execution, and validation to determine whether the approach can support closed-loop control.
3. **Precision task ablation**: Design a benchmark suite specifically targeting sub-centimeter manipulation accuracy to characterize the fundamental limits of iterative trial-and-error approaches.