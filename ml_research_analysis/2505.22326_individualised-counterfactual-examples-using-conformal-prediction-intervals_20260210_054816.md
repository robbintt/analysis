---
ver: rpa2
title: Individualised Counterfactual Examples Using Conformal Prediction Intervals
arxiv_id: '2505.22326'
source_url: https://arxiv.org/abs/2505.22326
tags:
- prediction
- counterfactual
- data
- conformal
- individual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel method for generating individualised
  counterfactual examples using conformal prediction intervals. The core idea is to
  model an individual's limited knowledge of a black-box classifier and generate counterfactuals
  that maximally reduce their prediction uncertainty.
---

# Individualised Counterfactual Examples Using Conformal Prediction Intervals

## Quick Facts
- arXiv ID: 2505.22326
- Source URL: https://arxiv.org/abs/2505.22326
- Reference count: 11
- Generates individualised counterfactual examples using conformal prediction intervals to reduce prediction uncertainty

## Executive Summary
This paper introduces a novel method for generating individualised counterfactual examples using conformal prediction intervals. The approach models an individual's limited knowledge of a black-box classifier and generates counterfactuals that maximally reduce their prediction uncertainty. By combining a loss function that balances proximity to the original instance with the width of conformal prediction intervals, the method produces "conformal prediction interval counterfactuals" (CPICFs) that can improve classification performance when used for data augmentation. Experiments on synthetic and real-world datasets demonstrate that CPICFs can lead to better average precision and F1 scores compared to unconstrained counterfactuals, particularly when the training dataset is small.

## Method Summary
The method generates individualised counterfactual examples by modeling what an individual knows about a black-box classifier through a subset T(k) of training data. Using conformal prediction intervals on this subset, the approach quantifies the individual's uncertainty about the classifier's predictions. A counterfactual example is then generated to minimize the width of this prediction interval while remaining close to the original instance. The loss function balances proximity to the original instance with the width of the conformal prediction intervals. The method leverages conformalized quantile regression (CQR) to obtain prediction intervals, though this can lead to quantile crossing issues. The approach offers a principled way to tailor counterfactual explanations to individual users' knowledge levels, potentially enhancing trust and transparency in algorithmic decision-making.

## Key Results
- CPICFs generated with appropriate parameter tuning (λ) lead to better average precision and F1 scores compared to unconstrained counterfactuals
- Performance improvements are particularly pronounced when the training dataset is small
- The method demonstrates the potential for using individualised counterfactuals as a data augmentation technique to improve classifier performance
- Optimal trade-off parameter λ varies depending on the conformal prediction error rate α, requiring careful parameter tuning

## Why This Works (Mechanism)
The method works by explicitly modeling the uncertainty an individual has about a black-box classifier's predictions. By using conformal prediction intervals on a subset of data that represents the individual's knowledge, the approach quantifies this uncertainty in a statistically rigorous way. The counterfactual generation process then optimizes to reduce this uncertainty while maintaining proximity to the original instance, effectively providing explanations that are tailored to what the individual actually knows and doesn't know about the model.

## Foundational Learning
- **Conformal Prediction**: Provides distribution-free uncertainty quantification for predictions; needed to rigorously measure individual uncertainty without distributional assumptions
- **Counterfactual Explanations**: Generate "what-if" scenarios to explain model predictions; needed as the base technique being enhanced with uncertainty quantification
- **Quantile Regression**: Estimates conditional quantiles of a response variable; needed for conformalized quantile regression to obtain prediction intervals
- **Loss Function Balancing**: Combines multiple objectives (proximity and uncertainty reduction); needed to optimize for both closeness to original instance and maximum uncertainty reduction
- **Data Augmentation**: Improves model performance by adding synthetic examples; needed to demonstrate the practical utility of the generated counterfactuals

## Architecture Onboarding
- **Component Map**: Individual knowledge subset T(k) -> Conformal Prediction Intervals -> Loss Function -> Counterfactual Generation -> Augmented Dataset -> Improved Classifier
- **Critical Path**: The sequence from modeling individual knowledge through T(k) to generating counterfactuals via the loss function optimization is the core workflow
- **Design Tradeoffs**: Balancing λ for proximity vs. uncertainty reduction; choosing α for coverage probability vs. interval width; synthetic vs. real data for evaluation
- **Failure Signatures**: Quantile crossing producing invalid intervals; poor parameter tuning leading to suboptimal counterfactuals; small T(k) subsets providing insufficient coverage
- **First Experiments**: 1) Test CPICF generation with varying λ values on synthetic data, 2) Compare CPICF performance against unconstrained counterfactuals on Adult dataset, 3) Evaluate data augmentation impact on classifier performance with different training set sizes

## Open Questions the Paper Calls Out
### Open Question 1
- Question: What is the relationship between the conformal prediction error rate (α) and the optimal value of the trade-off parameter (λ)?
- Basis in paper: The authors state "Investigating possible relationships between α and the best λ will be part of future work" when discussing how different α values led to different optimal λ values in experiments
- Why unresolved: The empirical results showed that optimal λ differs depending on α (λ = 1 or 100 for α = 0.1, versus λ = 10 for α = 0.2), but no theoretical or systematic empirical characterization was provided
- What evidence would resolve it: A systematic study varying both parameters across multiple datasets to establish a functional relationship or heuristic for choosing λ given α

### Open Question 2
- Question: Can theoretical coverage guarantees be maintained for conformal prediction intervals after a CPICF is added to the training set?
- Basis in paper: The authors note that "once the counterfactual is added, the conformal prediction guarantees no longer hold" because CPICFs are "not exchangeable" with calibration data, and mention investigating "ideas from Hore and Barber (2025) to randomize the intervals" as future work
- Why unresolved: The standard conformal prediction framework requires exchangeability, which is violated when counterfactuals are intentionally generated based on prediction intervals
- What evidence would resolve it: A formal proof or empirical demonstration that randomized conformal prediction intervals can maintain coverage guarantees in the CPICF setting

### Open Question 3
- Question: Can the assumption that individuals have access to the black-box classifier's probabilities/scores be relaxed?
- Basis in paper: The authors acknowledge that individuals having access to "the probabilities or scores of these points in the full black box classifier" is "a somewhat strong assumption which could be relaxed in future work"
- Why unresolved: The current method requires the entity to provide the individual with classifier scores for their subset T(k), which may not be available in practical scenarios due to privacy or model confidentiality
- What evidence would resolve it: A modified CPICF framework that works when individuals only have access to binary labels (not probabilities), with comparative performance evaluation

### Open Question 4
- Question: How can quantile crossing in conformalized quantile regression (CQR) be prevented while maintaining the benefits of asymmetric prediction intervals?
- Basis in paper: The authors note that "typically the upper and lower quantile models are computed independently, which can result in quantile crossing" and suggest "concurrent quantile regression models Cannon (2018) might be used to obtain non-crossing quantile models which could be explored"
- Why unresolved: CQR provides more flexibility for asymmetric intervals near estimation range edges but produces invalid negative-width intervals when quantiles cross
- What evidence would resolve it: Implementation and evaluation of concurrent/monotone quantile regression methods within the CPICF framework, comparing resulting counterfactual quality

## Limitations
- Evaluation relies heavily on synthetic datasets and a single real-world dataset (Adult), limiting generalizability assessment
- Method requires access to classifier probabilities/scores, which may not be available in practical scenarios due to privacy or model confidentiality
- Sensitive to parameter tuning (λ), with optimal values varying depending on the conformal prediction error rate α, lacking clear guidance for practical deployment
- Quantile crossing in CQR can produce invalid intervals, requiring additional methods to ensure valid prediction intervals

## Confidence
- High confidence: The methodological framework combining counterfactual generation with conformal prediction intervals is technically valid
- Medium confidence: The experimental results showing performance improvements on limited datasets are credible but require broader validation
- Low confidence: The practical applicability and user-specific modeling accuracy in real-world deployment scenarios

## Next Checks
1. Evaluate CPICFs on diverse real-world datasets across multiple domains (e.g., healthcare, finance, criminal justice) to assess generalizability beyond the Adult dataset
2. Conduct user studies to empirically validate whether the generated counterfactuals actually reduce uncertainty for individuals with varying levels of domain knowledge
3. Compare CPICFs against established counterfactual explanation methods (e.g., DiCE, LIME counterfactuals, SHAP-based approaches) using standardized benchmarks to isolate the contribution of the conformal prediction interval component