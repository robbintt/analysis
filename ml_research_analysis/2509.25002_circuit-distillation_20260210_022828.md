---
ver: rpa2
title: Circuit Distillation
arxiv_id: '2509.25002'
source_url: https://arxiv.org/abs/2509.25002
tags:
- circuit
- distillation
- teacher
- student
- align
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces circuit distillation, a method that transfers
  specific internal algorithms (circuits) from a large teacher model to a smaller
  student model, rather than just mimicking outputs. The approach identifies functionally
  analogous circuit components between models using ablation impact similarity, then
  aligns their representations using a composite loss combining task performance and
  Centered Kernel Alignment (CKA).
---

# Circuit Distillation

## Quick Facts
- arXiv ID: 2509.25002
- Source URL: https://arxiv.org/abs/2509.25002
- Reference count: 23
- Key result: Up to 5 percentage point accuracy improvement over standard distillation by transferring internal circuits rather than just outputs

## Executive Summary
This paper introduces circuit distillation, a method that transfers specific internal algorithms (circuits) from a large teacher model to a smaller student model, rather than just mimicking outputs. The approach identifies functionally analogous circuit components between models using ablation impact similarity, then aligns their representations using a composite loss combining task performance and Centered Kernel Alignment (CKA). Evaluated on entity tracking and theory of mind tasks using Llama3 models, circuit distillation achieved accuracy improvements of up to 5 percentage points over standard distillation, while only adjusting 11-15% of parameters. A control condition using random head assignments performed worse than baseline, confirming that principled alignment matters.

## Method Summary
Circuit distillation identifies task-specific circuits in a teacher model (using path or activation patching), maps corresponding attention heads to a student model based on ablation impact similarity, and trains only those matched circuit heads using a composite loss of task cross-entropy and CKA alignment. The method targets only 11-15% of attention heads rather than full model training, achieving better efficiency while transferring mechanistic understanding rather than just surface behaviors.

## Key Results
- Achieved up to 5 percentage point accuracy improvement over standard distillation on entity tracking and theory of mind tasks
- Only required adjusting 11-15% of attention head parameters versus full model training
- Control condition with random head assignments performed worse than baseline, confirming principled alignment is necessary
- CKA-based alignment converged faster than task loss alone, suggesting denser gradient signal

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ablation impact similarity can identify functionally analogous attention heads across models of different scales, enabling targeted circuit transfer.
- Mechanism: For each head in student and teacher, measure the performance drop when that head is ablated (mean activation replacement). Map student heads to teacher heads with the most similar ablation impact magnitudes.
- Core assumption: Heads causing similar performance degradation when removed perform functionally similar computations, even across architectures.
- Evidence anchors: [abstract] "The approach identifies functionally analogous circuit components between models using ablation impact similarity"; [section 2.2] "We propose an ablation-based strategy to map student heads to teacher heads based on their respective contributions to task performance"
- Break condition: If student lacks heads with comparable ablation impact to key teacher heads, mapping fails and alignment degrades.

### Mechanism 2
- Claim: Centered Kernel Alignment (CKA) provides a differentiable, transformation-invariant measure of representational similarity that enables cross-architecture circuit alignment.
- Mechanism: Compute Gram matrices from head activations. CKA normalizes HSIC to be invariant to orthogonal transformations and isotropic scaling, yielding scores 0-1. Minimize L_CKA = 1 - CKA during training.
- Core assumption: Representational similarity (similar pairwise activation patterns across inputs) indicates functional similarity of computation.
- Evidence anchors: [abstract] "aligns their representations using a composite loss combining task performance and Centered Kernel Alignment (CKA)"; [section 2.1] "CKA is invariant to orthogonal transformations... making it well-suited to compare activations from different architectures"
- Break condition: If activations lie in fundamentally different representational spaces, CKA may yield spurious correlations without true functional alignment.

### Mechanism 3
- Claim: Composite loss (task cross-entropy + CKA alignment) guides student to adopt teacher's algorithmic pathway rather than just mimicking outputs.
- Mechanism: L_total = L_task + λ × Σ L_CKA. Task loss ensures correct outputs; CKA loss forces internal representations of mapped head pairs to align.
- Core assumption: The teacher circuit implements a learnable algorithm; forcing representational alignment transfers this algorithm rather than just surface patterns.
- Evidence anchors: [abstract] "A control condition using random head assignments performed worse than baseline, confirming that principled alignment matters"; [Table 1] CE + Align CKA achieves 0.82 accuracy vs. 0.63 for CE + Rand CKA
- Break condition: If λ is too high, student may overfit to teacher's internal representations at cost of task performance.

## Foundational Learning

- Concept: **Circuits (in mechanistic interpretability)**
  - Why needed here: Circuit distillation assumes teacher has identifiable subgraphs implementing specific algorithms. Without understanding circuits as localized computational units, the premise of "transferring a circuit" is meaningless.
  - Quick check question: Can you explain why a "circuit" differs from a "layer" in terms of functional localization?

- Concept: **Ablation studies / causal tracing**
  - Why needed here: The method identifies correspondent heads via ablation impact. Understanding how removing components reveals causal importance is essential for interpreting the mapping strategy.
  - Quick check question: If ablating head A drops accuracy by 15% and head B by 2%, which head is more likely part of the core task circuit?

- Concept: **Knowledge distillation basics**
  - Why needed here: Circuit distillation builds on standard behavioral distillation (KL divergence between output distributions). Understanding the baseline helps contextualize the mechanistic extension.
  - Quick check question: In standard distillation, what does the student learn from—the teacher's weights, logits, or labels?

## Architecture Onboarding

- Component map: Teacher model -> Circuit identifier -> Head mapper -> Student model -> Alignment trainer -> Task evaluator
- Critical path:
  1. Identify teacher circuit heads using prior mechanistic work (e.g., Prakash et al. 2024 path patching)
  2. Run ablation sweep on student to compute ΔP_s(h_s) for all candidate heads
  3. Run ablation sweep on teacher to compute ΔP_t(h_t) relative to student baseline
  4. Map each student head to teacher head minimizing |ΔP_s - ΔP_t|
  5. Train student circuit heads only using L_total = L_task + λ × Σ L_CKA
  6. Evaluate on held-out task data; compare to CE-only baseline and random-mapping control
- Design tradeoffs:
  - Targeting circuit heads only vs. full model: Circuit-only updates are more parameter-efficient (11-15% of heads) but require upfront circuit discovery
  - λ tuning: Higher λ prioritizes mechanistic fidelity over task accuracy; lower λ risks weak alignment
  - Ablation mapping heuristic vs. learned mapping: Current approach is simple absolute difference; more sophisticated correspondence methods may improve alignment
- Failure signatures:
  - Random mapping control underperforms baseline (observed: 0.49-0.63 vs. 0.58-0.72 baseline): Indicates CKA loss applied to wrong pairs is actively harmful
  - Large teacher-student capability gap: If student lacks capacity to implement teacher's algorithm, alignment loss may fail to converge
  - Circuit misidentification: If teacher circuit discovery is incorrect, alignment targets wrong computation
- First 3 experiments:
  1. Reproduce entity tracking results: Use provided dataset, Llama3-3B student, Llama3-8B teacher. Compare CE-only vs. CE + Align CKA on circuit heads.
  2. Ablation sweep visualization: For both teacher and student, plot ΔP for each attention head. Visualize mapping M to confirm heads cluster in similar layers/positions.
  3. λ sensitivity analysis: Sweep λ from 0.1 to 2.0 on validation set. Plot task accuracy vs. CKA score to find Pareto frontier.

## Open Questions the Paper Calls Out
- Question: Does circuit distillation maintain its efficiency and performance advantages when scaled to significantly larger model architectures and more complex reasoning tasks?
- Question: Can more sophisticated methods for identifying functional correspondence improve upon the heuristic ablation-based mapping used in this study?
- Question: Is it possible to integrate automated circuit discovery into the distillation process to remove the dependency on pre-existing mechanistic interpretations?

## Limitations
- Hyperparameter sensitivity: The paper doesn't specify optimal λ values or training duration, suggesting the approach may require task-specific tuning
- Circuit identification dependency: Success hinges on accurate prior identification of teacher circuits via path/activation patching
- Architectural assumptions: The method assumes student can implement teacher's algorithm given aligned heads

## Confidence
- High confidence: Mechanism 3 (composite loss improves over random mapping), evidenced by controlled experiments
- Medium confidence: Mechanism 1 (ablation mapping works), supported by results but lacking direct visualization studies
- Medium confidence: Mechanism 2 (CKA alignment transfers algorithms), reasonable given CKA's theoretical properties but weak empirical validation

## Next Checks
1. **Ablation mapping verification**: Visualize ablation impacts ΔP for teacher and student heads. Confirm mapped pairs show similar impact magnitudes and cluster in comparable model positions.
2. **Component importance analysis**: Run ablation study on student after distillation. Remove each aligned head pair individually and measure performance drops.
3. **Architecture transfer robustness**: Test circuit distillation across different model families. Measure whether CKA alignment and ablation mapping remain effective when architectures differ more substantially.