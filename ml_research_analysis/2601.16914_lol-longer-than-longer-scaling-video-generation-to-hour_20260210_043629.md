---
ver: rpa2
title: 'LoL: Longer than Longer, Scaling Video Generation to Hour'
arxiv_id: '2601.16914'
source_url: https://arxiv.org/abs/2601.16914
tags:
- generation
- video
- arxiv
- sink
- sink-collapse
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the sink-collapse problem in autoregressive
  video generation models, where generated content repeatedly reverts to initial frames,
  causing abrupt scene resets and cyclic motion patterns. The authors identify that
  this issue stems from an inherent conflict between the periodic structure of Rotary
  Position Embedding (RoPE) and multi-head attention mechanisms.
---

# LoL: Longer than Longer, Scaling Video Generation to Hour

## Quick Facts
- arXiv ID: 2601.16914
- Source URL: https://arxiv.org/abs/2601.16914
- Reference count: 40
- Primary result: Solves sink-collapse problem in autoregressive video generation, enabling real-time, streaming, and infinite-length video generation up to 12 hours

## Executive Summary
This paper addresses the sink-collapse problem in autoregressive video generation models, where generated content repeatedly reverts to initial frames, causing abrupt scene resets and cyclic motion patterns. The authors identify that this issue stems from an inherent conflict between the periodic structure of Rotary Position Embedding (RoPE) and multi-head attention mechanisms. To solve this, they propose a lightweight, training-free approach called multi-head RoPE jitter, which introduces head-wise frequency shifts to break inter-head attention homogenization and mitigate long-horizon collapse. Extensive experiments demonstrate that this method effectively suppresses sink-collapse while preserving generation quality.

## Method Summary
The proposed method introduces multi-head RoPE jitter, a training-free approach that addresses the sink-collapse problem by modifying the Rotary Position Embedding mechanism. The key insight is that the periodic nature of RoPE conflicts with multi-head attention, leading to repetitive content generation over long sequences. By applying frequency shifts on a per-head basis, the method breaks the homogenization of attention patterns across different heads, allowing the model to maintain diversity and continuity in generated content. This approach is lightweight and does not require additional training, making it an efficient solution for scaling video generation to longer durations.

## Key Results
- Achieves the first demonstration of real-time, streaming, and infinite-length video generation with minimal quality decay
- Successfully generates continuous videos up to 12 hours in length
- Effectively suppresses the sink-collapse problem while preserving generation quality

## Why This Works (Mechanism)
The sink-collapse problem arises from the inherent conflict between the periodic structure of Rotary Position Embedding (RoPE) and the multi-head attention mechanism. RoPE's periodic nature causes attention patterns to repeat over long sequences, leading to cyclic motion and scene resets. The proposed multi-head RoPE jitter introduces head-wise frequency shifts, breaking the homogenization of attention patterns across different heads. This allows the model to maintain diversity and continuity in generated content, effectively mitigating the sink-collapse issue.

## Foundational Learning
1. **Rotary Position Embedding (RoPE)**: A positional encoding technique that encodes position information in the frequency domain. It is crucial for capturing temporal dependencies in autoregressive models. Quick check: Verify that RoPE's periodic structure is indeed the root cause of the sink-collapse problem.
2. **Multi-head Attention**: A mechanism that allows the model to attend to different parts of the input sequence simultaneously. It is essential for capturing long-range dependencies. Quick check: Confirm that the homogenization of attention patterns across heads contributes to the sink-collapse issue.
3. **Sink-collapse Problem**: A phenomenon in autoregressive video generation where the model repeatedly reverts to initial frames, causing abrupt scene resets and cyclic motion patterns. Quick check: Ensure that the proposed solution effectively addresses this problem.

## Architecture Onboarding
- **Component Map**: Input sequence -> RoPE -> Multi-head Attention -> Multi-head RoPE Jitter -> Output
- **Critical Path**: The multi-head RoPE jitter modifies the attention patterns by introducing head-wise frequency shifts, breaking the homogenization across heads.
- **Design Tradeoffs**: The method is training-free and lightweight, but it may introduce computational overhead or impact model complexity.
- **Failure Signatures**: If the frequency shifts are not properly calibrated, the method may fail to suppress sink-collapse or introduce artifacts in the generated content.
- **First Experiments**: 1) Evaluate the computational overhead of multi-head RoPE jitter compared to existing methods. 2) Test the robustness of the method across different video generation tasks and datasets. 3) Verify the claim of being the first demonstration of long-duration video generation.

## Open Questions the Paper Calls Out
None

## Limitations
- The paper does not extensively discuss potential trade-offs or limitations of the multi-head RoPE jitter approach in different video generation scenarios.
- The computational overhead and impact on model complexity introduced by the method are not thoroughly analyzed.
- The claim of being the "first demonstration" of long-duration video generation should be verified against recent literature.

## Confidence
- **High**: The technical explanation of the sink-collapse problem and the proposed solution are well-articulated and supported by experimental evidence.
- **Medium**: The claim of generating videos up to 12 hours in length is supported, but the broader implications and potential limitations of this capability are not fully explored.
- **Low**: The assertion of being the "first demonstration" of real-time, streaming, and infinite-length video generation should be cross-referenced with recent publications.

## Next Checks
1. Conduct a comparative study to evaluate the computational overhead and model complexity introduced by the multi-head RoPE jitter approach against existing methods.
2. Perform a robustness analysis of the method across different video generation tasks and datasets to identify any potential limitations or failure modes.
3. Verify the claim of being the first demonstration by conducting a thorough literature review of recent advancements in long-duration video generation to ensure no concurrent developments have been overlooked.