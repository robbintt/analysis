---
ver: rpa2
title: Addressing Tokenization Inconsistency in Steganography and Watermarking Based
  on Large Language Models
arxiv_id: '2508.20718'
source_url: https://arxiv.org/abs/2508.20718
tags:
- tokens
- token
- watermarking
- language
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses tokenization inconsistency (TI) between sender
  and receiver in LLM-based steganography and watermarking, which undermines robustness.
  Inconsistent tokens were found to be infrequent and temporary.
---

# Addressing Tokenization Inconsistency in Steganography and Watermarking Based on Large Language Models

## Quick Facts
- arXiv ID: 2508.20718
- Source URL: https://arxiv.org/abs/2508.20718
- Reference count: 40
- Primary result: Proposes methods to handle tokenization inconsistency (TI) between sender and receiver in LLM-based steganography and watermarking, improving robustness.

## Executive Summary
This paper addresses tokenization inconsistency (TI) in LLM-based steganography and watermarking, where different tokenizers or detokenization-retokenization processes can lead to mismatched token sequences between sender and receiver, undermining extraction accuracy and robustness. The authors identify that inconsistent tokens are infrequent (<0.5% token-level inconsistency) and often temporary. Based on these characteristics, they propose a stepwise verification method for steganography (removing candidate-level inconsistent tokens at each step) and a post-hoc rollback method for watermarking (rolling back generation if TI persists after a brief observation period). Experiments on Llama-2-7b, Swallow-7b, and Qwen2.5-7b demonstrate improved fluency, imperceptibility, and anti-steganalysis for steganography, and enhanced detectability and robustness for watermarking.

## Method Summary
The paper proposes two tailored solutions to handle tokenization inconsistency (TI) in LLM-based steganography and watermarking. For steganography, a stepwise verification method is introduced where both sender and receiver filter out candidate-level inconsistent tokens from the generation pool at each step, ensuring 100% extraction accuracy. For watermarking, a post-hoc rollback method is proposed where the system observes for a brief period after detecting a potential TI; if inconsistency persists, generation is rolled back and resampled from a filtered pool. Both methods leverage the observation that inconsistent tokens are infrequent and temporary, allowing for targeted, low-overhead solutions that maintain text quality while improving robustness.

## Key Results
- Stepwise verification method for steganography improves fluency (14.12% lower perplexity), imperceptibility (47.86% lower KL divergence), and anti-steganalysis (3.53% lower accuracy) compared to baselines.
- Post-hoc rollback method for watermarking enhances detectability and robustness against attacks while maintaining lower perplexity.
- Tokenization inconsistency rates are found to be below 0.5% at the token level and often temporary across tested models.

## Why This Works (Mechanism)

### Mechanism 1: Tokenization Inconsistency (TI) Identification and Characteristics
The paper identifies two key characteristics of problematic tokens that cause TI: infrequency (low token-level inconsistency rates <0.5%) and temporariness (many candidate-level ITs do not lead to final TI). These properties suggest that solutions do not need to modify the entire vocabulary or generation process but can instead focus on detecting and handling the rare, problematic instances.

### Mechanism 2: Stepwise Verification for Steganography (SIT Removal)
Before steganographic encoding at each step, the sender and receiver independently verify each token in the candidate pool using a simulated detokenization-retokenization pipeline. Candidate-level ITs are removed from the pool. By ensuring no SITs are ever generated, the receiver's retokenization will always match the sender's token list, guaranteeing perfect synchronization.

### Mechanism 3: Post-Hoc Rollback for Watermarking (Stable TI Avoidance)
When a potential TI is detected during generation, the system enters an observation period of length $q$. If consistency is restored (due to temporariness), generation continues. If TI persists (stable TI), the generation process is rolled back to the state before the problematic token was generated, and the token is resampled from a pool excluding the candidate-level IT. This leverages both infrequency (rare rollbacks) and temporariness (many false alarms resolve).

## Foundational Learning

- **Concept: Tokenization and Subword Tokenizers (e.g., BPE, SentencePiece)**
  - **Why needed here:** The entire problem (TI) stems from how text is split into tokens by different tokenizers and how that split can change (detokenize -> retokenize).
  - **Quick check question:** Why might the tokenizer used by Alice to generate text produce a different sequence of tokens for the string "nobody" than the tokenizer used by Bob to process the same string?

- **Concept: Probability Distributions and Sampling in LLMs**
  - **Why needed here:** The proposed solutions modify the candidate pool from which tokens are sampled. The paper argues that removing infrequent tokens causes minimal disturbance to the original probability distribution $p(t)$ or make valid steganographic encoding impossible.
  - **Quick check question:** If you remove the single most probable token from a model's candidate pool at each step, how would that affect the perplexity of the generated text compared to removing the 1000th most probable token?

- **Concept: Steganography vs. Watermarking Goals**
  - **Why needed here:** The paper proposes different solutions for each. Steganography requires perfect extraction (hence the stricter, proactive stepwise verification), while watermarking focuses on detectability and robustness (hence the more relaxed, reactive post-hoc rollback).
  - **Quick check question:** For which application is it more critical to guarantee 100% that no tokenization inconsistency occurs, even if it means modifying the candidate pool at every single generation step?

## Architecture Onboarding

- **Component Map:** Language Model (LM) -> Tokenizer -> Inconsistency Detector (Algorithm 1) -> Steganography/Watermarking Module
- **Critical Path:**
  1. LM produces a probability distribution over the vocabulary.
  2. A subset of tokens (e.g., top-k) is selected as the candidate pool.
  3. Consistency Check (Core Intervention):
     - *For Steganography:* For *each* token in the candidate pool, the Inconsistency Detector is called. ITs are filtered out.
     - *For Watermarking:* After a token is sampled and added to the history, the Inconsistency Detector checks the *new history*.
  4. Action/Encoding:
     - *For Steganography:* The secret message is encoded using the filtered pool.
     - *For Watermarking:* If TI is detected, the observation counter increments. If it exceeds threshold `q`, the history is reverted and generation is re-sampled.

- **Design Tradeoffs:**
  - **Proactive vs. Reactive:** Steganography uses a proactive, per-step filter, guaranteeing 100% consistency but adding O(n) cost at each step. Watermarking uses a reactive, post-hoc rollback, which is lighter but only handles TI *after* it occurs and persists.
  - **Strictness vs. Flexibility:** Steganography's method is strict (remove all ITs). Watermarking's method is flexible (allow temporary TI). The choice is dictated by the different failure modes (extraction error vs. detection difficulty).
  - **Observation Period (`q`):** For watermarking, `q` is a hyperparameter. A larger `q` is needed for models with more temporary inconsistencies (like Swallow-7b), while a smaller `q` is suitable for models with more stable inconsistencies (like Llama-2-7b).

- **Failure Signatures:**
  - **Steganography:** If the filtered candidate pool is empty, the algorithm falls back to selecting a non-IT token from the full vocabulary. This could reduce embedding efficiency or fluency. If TI still occurs, it indicates a bug in Algorithm 1.
  - **Watermarking:** If rollback is triggered too frequently, it indicates a high rate of stable ITs, violating the "infrequency" assumption and increasing latency. If TI is not detected when it should be, it suggests the detection logic or observation period `q` is flawed.

- **First 3 Experiments:**
  1. **Reproduce TI Statistics:** Generate text with a chosen LM (e.g., Llama-2-7b) and tokenizer. Implement the TI detection logic to calculate text-level, token-level, and candidate-level inconsistency rates. Compare with the paper's reported values (Table 1, 2, 3). This validates the core problem statement.
  2. **Implement and Test Steganography Method:** Implement the stepwise verification method (Algorithm 2 & 3). Generate stegotexts and verify 100% correct message extraction by the receiver. Compare the KL divergence and perplexity of generated text against a baseline without the method to confirm the "minimal impact" claim.
  3. **Implement and Test Watermarking Method:** Implement the post-hoc rollback method (Algorithm 4). Integrate it with a simple logit-based watermarking scheme (e.g., LeftHash). Measure watermark detection accuracy and robustness against a simple attack (e.g., token substitution) compared to a baseline without the rollback. Analyze the number of rollbacks to verify low overhead.

## Open Questions the Paper Calls Out
None

## Limitations
- The characterization of tokenization inconsistency as "infrequent and temporary" is derived from a limited set of models and datasets, and generalizability to diverse tokenizers and languages is not rigorously established.
- The optimal observation period $q$ for the watermarking rollback method is determined empirically per model, without a systematic method for configuration.
- The impact of rollback on the semantic coherence of generated text beyond perplexity and KL divergence metrics is not deeply explored.

## Confidence
- **High Confidence**: The identification of tokenization inconsistency as a real and measurable problem affecting both steganography and watermarking extraction/detection accuracy.
- **Medium Confidence**: The proposed mechanisms effectively mitigate TI in the tested models and scenarios, with promising improvements in fluency, imperceptibility, and anti-steganalysis.
- **Low Confidence**: The claim that the solutions have "minimal impact" on text quality is based on comparisons with specific baselines and may not hold across all model architectures or when the candidate pool is heavily filtered.

## Next Checks
1. **Generalizability of TI Characteristics**: Validate the "infrequent and temporary" characterization of tokenization inconsistencies across a broader range of LLMs (e.g., larger models like Llama-3-70b, models with different tokenizer architectures like GPT-4's tokenizer, and multilingual models).
2. **Robustness of Stepwise Verification Under Edge Cases**: Implement the steganography method and deliberately test scenarios where the candidate pool is likely to be sparse after filtering (e.g., early in generation, with low top-k values, or with models known to have many rare ITs).
3. **Systematic Evaluation of Observation Period $q$**: For the watermarking rollback method, conduct a grid search over different values of $q$ (e.g., 1, 2, 5, 10, 20) across the three tested models. Measure not only the final watermark detection accuracy and robustness but also the average number of rollbacks and the average generation latency. Identify the optimal $q$ for each model and analyze the tradeoff between detection accuracy and computational overhead.