---
ver: rpa2
title: Can LLMs Reason Over Non-Text Modalities in a Training-Free Manner? A Case
  Study with In-Context Representation Learning
arxiv_id: '2509.17552'
source_url: https://arxiv.org/abs/2509.17552
tags:
- icrl
- question
- answer
- representations
- drug
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a training-free framework for integrating
  non-text modality representations into text-based large language models (LLMs).
  The proposed method, called In-Context Representation Learning (ICRL), allows LLMs
  to adaptively utilize non-text foundation model representations through few-shot
  learning without requiring additional supervised training.
---

# Can LLMs Reason Over Non-Text Modalities in a Training-Free Manner? A Case Study with In-Context Representation Learning

## Quick Facts
- **arXiv ID**: 2509.17552
- **Source URL**: https://arxiv.org/abs/2509.17552
- **Reference count**: 40
- **Primary result**: A training-free framework that enables LLMs to reason over non-text modalities through in-context representation learning with OT-based alignment

## Executive Summary
This paper introduces In-Context Representation Learning (ICRL), a framework that enables text-based large language models to reason over non-text modalities without additional training. The method leverages few-shot learning to adaptively utilize representations from foundation models through two main injection strategies: text-level injection using PCA dimensionality reduction, and embedding-level injection using methods like zero-padding, random projection, and optimal transport alignment. Experimental results on molecular property prediction tasks demonstrate that ICRL can achieve performance comparable to traditional in-context learning, with OT-based methods showing particularly strong results.

## Method Summary
The ICRL framework extracts representations from a Foundation Model (FM) encoder (e.g., Uni-Mol for molecular features), projects them to the LLM's embedding dimension using a randomly initialized linear projector, aligns their distribution via Optimal Transport to match the LLM's native embedding statistics, and injects them into the prompt. Two injection strategies are explored: text-level injection where PCA-reduced vectors are converted to strings, and embedding-level injection where vectors directly replace token embeddings. The method requires no gradient updates and maintains efficiency while enabling multimodal reasoning.

## Key Results
- ICRL with OT-based alignment achieved RMSE of 0.48 on ESOL dataset, comparable to standard ICL performance
- OT alignment consistently outperformed zero-padding baseline across all tested molecular datasets
- Text-level (PCA) injection consumed 20 tokens per sample while embedding-level injection used only 1 token per sample with similar performance
- Random linear projectors without training were sufficient for effective representation transformation

## Why This Works (Mechanism)

### Mechanism 1: Distribution Alignment for "Native" Interpretation
Aligning the statistical distribution (mean, variance) of external Foundation Model representations to match the LLM's native embedding space allows the LLM to process non-text modalities as if they were text, conditionally improving performance over zero-shot baselines. The Optimal Transport alignment method adjusts the scale and shift of projected FM representations so their dimensions match the mean and variance of the LLM's target embedding distribution. The LLM's stability and inference capability rely on input embeddings adhering to the distributional statistics encountered during pre-training. If the target distribution statistics are incorrect or the source representations are zero-padded without alignment, the LLM perceives inputs as noise.

### Mechanism 2: Preservation of Representation Geometry via Linear Mapping
Linear projectors (without activation functions) preserve the relative geometry (norms and angles) of FM representations better than non-linear alternatives, preventing the "collapse" of useful information. Random linear mappings concentrate norms and preserve cosine similarity, keeping distinct examples distinguishable. Non-linear activations (e.g., ReLU) distort angles and inflate similarities, causing the LLM to treat different examples as identical. The LLM requires distinct inputs to perform few-shot mapping; high similarity among few-shot examples leads to random predictions. If a non-linear projector is used, or if the representation space has inherently high similarity, the mechanism fails due to loss of diversity.

### Mechanism 3: Representation Diversity as a Signal for Task Learning
ICRL effectiveness relies on the LLM operating in a "task learning" mode, which is triggered when prompt inputs are novel (representations) and distinct (high diversity). Unlike "task retrieval" (triggered by familiar text), task learning forces the model to derive the label from the provided few-shot exemplars. This requires that the projected representations have low inter-sample similarity to map uniquely to labels. High internal similarity in the representation space makes the mapping to specific labels ambiguous, reducing the prompt to noise. If the FM features are highly homogeneous, the projected representations become nearly identical, and the LLM outputs random labels based on the distribution of example labels.

## Foundational Learning

- **Concept**: In-Context Learning (ICL) Scaling Laws
  - **Why needed here**: ICRL inherits ICL's dependency on the number of examples. Understanding that performance improves with more shots is critical for setting expectations.
  - **Quick check question**: Does the framework require gradient updates to learn the new modality? (No).

- **Concept**: Embedding Space Distribution (OOD vs. ID)
  - **Why needed here**: The core failure mode of ICRL is feeding Out-Of-Distribution vectors (wrong scale/mean) into the LLM, which destabilizes inference.
  - **Quick check question**: Why does zero-padding fail but Optimal Transport succeed? (Zero-padding ignores distribution statistics; OT aligns them).

- **Concept**: Dimensionality Reduction (PCA)
  - **Why needed here**: A primary injection method involves reducing high-dimensional vectors to strings to fit context windows.
  - **Quick check question**: How does PCA affect the information density vs. context window length tradeoff? (Lowers density to fit window).

## Architecture Onboarding

- **Component map**: FM Encoder -> Linear Projector -> OT Aligner -> Injector
- **Critical path**: FM Extraction → Linear Projection → OT Alignment → Injection. *Warning*: Do not skip the alignment step; raw projections cause "unrelated/nonsensical outputs."
- **Design tradeoffs**:
  - Text-level (PCA) vs. Embedding-level: Text-level (PCA) preserves interpretability but consumes context tokens (e.g., 20 tokens/sample). Embedding-level is opaque but highly efficient (1 token/sample).
  - Linear vs. MLP: Only use linear projectors. MLPs destroy representation diversity via activation functions.
- **Failure signatures**:
  - "Random Guessing" Behavior: If output values are highly similar or simply copy the example distribution, check representation similarity scores. If cosine similarity ≈ 0.99, the mechanism fails.
  - Unstable Outputs / NaNs: Check normalization settings. Disabling normalization sometimes helps ICRL but hurts combined ICL+ICRL.
- **First 3 experiments**:
  1. Baseline Integrity Check: Run ICRL with Random Noise vs. Real FM representations. If Real Reps ≤ Random Noise, the injection path is broken.
  2. Alignment Ablation: Compare Zero-Padding vs. OT-Alignment on a single dataset (e.g., ESOL). Verify that OT significantly lowers RMSE.
  3. Geometry Preservation: Swap a Linear projector for a Non-linear (ReLU) one. Verify the performance drop.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can lightweight training strategies be integrated into the ICRL framework to bridge the performance gap with fully supervised methods?
- Basis in paper: The Conclusion states that despite success, ICRL "underperforms compared to supervised methods" and the authors plan to "explore lightweight training strategies" in future work.
- Why unresolved: The current framework relies strictly on training-free projection, which prioritizes efficiency over the raw predictive power offered by fine-tuning.
- What evidence would resolve it: Experiments demonstrating that a minimally trained projector achieves competitive performance with baselines like GPT-MolBERTa without incurring significant training overhead.

### Open Question 2
- Question: What is the optimal layer or feature extraction method from Foundation Models for ICRL, given that CLS tokens may be suboptimal?
- Basis in paper: Appendix F.6 states "using CLS features may not be the optimal choice," and experiments with non-CLS features showed mixed results where simple methods sometimes outperformed complex ones.
- Why unresolved: While the main paper uses CLS features, the appendix analysis suggests that shallower layers or different pooling strategies might offer better diversity for specific tasks, but no single strategy was universally dominant.
- What evidence would resolve it: A systematic benchmarking of ICRL performance using embeddings from various FM layers across all molecular and protein datasets to identify a generalizable selection strategy.

### Open Question 3
- Question: How can ICRL be adapted to handle domains with extremely high internal representation similarity where current methods fail?
- Basis in paper: Appendix F.7 notes that on protein/DTI tasks with high sequence similarity (sim ~0.99), "all methods performed close to random guessing," identifying this as a limitation.
- Why unresolved: The current projection and alignment techniques fail to create distinct representations when the input features are nearly identical, causing the LLM to treat samples as duplicates.
- What evidence would resolve it: A modified projection technique that successfully enforces diversity in the projected embeddings for high-similarity datasets, resulting in non-random predictive performance.

## Limitations
- **Implementation complexity**: The embedding injection mechanism requires modifying model internals by overriding token embeddings during inference, creating significant reproducibility challenges
- **Distribution calibration ambiguity**: Unclear whether OT alignment should use specific SMILES tokens, PCA representations, or general corpus statistics for target distribution computation
- **High similarity failure mode**: ICRL fails completely on domains with extremely homogeneous representations (e.g., protein sequences with cosine similarity ~0.99)

## Confidence

- **High Confidence**: OT-based alignment significantly outperforms zero-padding methods across multiple molecular datasets; mathematical framework for OT alignment is clearly specified
- **Medium Confidence**: Linear projectors outperform non-linear alternatives is supported by ablation studies, but theoretical justification requires validation; effectiveness of random linear projectors without training is surprising
- **Medium Confidence**: Dual operational mode hypothesis (task learning vs. task retrieval) provides compelling framework but empirical evidence is primarily correlational

## Next Checks

1. **Implementation Verification**: Reproduce the zero-padding vs. OT alignment comparison on a single dataset (ESOL) to verify that OT alignment reduces RMSE by the reported margin (>20% improvement)

2. **Geometry Preservation Test**: Systematically compare linear vs. non-linear projectors (ReLU, GELU) across multiple molecular datasets to confirm that activation functions consistently degrade performance by increasing representation similarity

3. **Similarity Threshold Analysis**: Measure inter-sample cosine similarity for both successful and failed ICRL runs to identify quantitative thresholds beyond which performance degrades. Test with artificially homogeneous representations to confirm the similarity-failure relationship