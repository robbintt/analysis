---
ver: rpa2
title: Lower Bounds on Adversarial Robustness for Multiclass Classification with General
  Loss Functions
arxiv_id: '2510.01969'
source_url: https://arxiv.org/abs/2510.01969
tags:
- loss
- problem
- function
- adversarial
- functions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies adversarially robust classification in a multiclass
  setting under arbitrary loss functions and derives dual and barycentric reformulations
  of the corresponding learner-agnostic robust risk minimization problem. The authors
  provide explicit characterizations for important cases such as the cross-entropy
  loss, loss functions with a power form, and the quadratic loss, extending available
  results for the 0-1 loss.
---

# Lower Bounds on Adversarial Robustness for Multiclass Classification with General Loss Functions

## Quick Facts
- **arXiv ID**: 2510.01969
- **Source URL**: https://arxiv.org/abs/2510.01969
- **Reference count**: 40
- **Primary result**: General duality and barycenter reformulations for adversarial risk bounds in multiclass classification with arbitrary convex losses

## Executive Summary
This paper establishes learner-agnostic lower bounds for adversarial risk in multiclass classification using optimal transport duality. The authors develop a general framework that reformulates the adversarial robustness problem into a convex program and connects it to generalized entropy-regularized barycenter problems. The work extends beyond the standard 0-1 loss case to arbitrary convex losses, providing explicit constructions for optimal robust classifiers under cross-entropy, α-logarithmic, and quadratic losses. Numerical experiments demonstrate tighter bounds for cross-entropy loss compared to 0-1 loss, with performance varying systematically across different loss functions and adversarial budgets.

## Method Summary
The method centers on solving a learner-agnostic robust risk minimization problem through duality. For empirical data, this reduces to identifying conflict sets—subsets of data points from different classes whose adversarial perturbation balls intersect. The dual problem is then formulated as an α-fair packing convex program with variables at each data point and constraints for each conflict set. The solution provides optimal dual potentials that can be transformed into an explicit robust classifier. The framework is implemented using CVXOPT, with warm-start strategies for solving across different α values. Computational efficiency is maintained by truncating conflict sets to manageable sizes (typically |A| ≤ 3).

## Key Results
- A general duality theorem reformulating adversarial robustness into convex programs for any convex loss satisfying structural assumptions
- Explicit optimal classifier formulas for cross-entropy (softmax on c-transforms), α-logarithmic, and quadratic losses
- Generalized barycenter reformulation connecting robustness to optimal transport with entropy regularization
- Numerical experiments showing cross-entropy loss provides tighter lower bounds than 0-1 loss, with risk increasing systematically with adversarial budget and α parameter

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The infinite-dimensional adversarial min-max risk problem can be reformulated into a finite-dimensional convex program (specifically, an α-fair packing problem for discrete data).
- **Mechanism:** The paper applies a duality argument (Theorem 3) to the learner-agnostic risk problem. By introducing dual potentials φᵢ and applying the c-transform (a concept from optimal transport), the inner maximization over adversarial measures is replaced by a set of linear constraints on the potentials. For empirical data, this reduces to a convex optimization with variables at each data point.
- **Core assumption:** The loss function ℓ is convex (Assumption 1), and the cost function c is lower-semicontinuous with specific coercivity (Assumption 2).
- **Evidence anchors:**
  - [abstract] "general duality theorem (Theorem 3) that reformulates the adversarial robustness problem into a convex program"
  - [section 1.1] Theorem 3 and Remark 5 regarding the reduction to finite dimensions for empirical measures.
  - [corpus] Corpus evidence for this specific OT-based duality mechanism in multiclass settings is weak; neighbors focus on consistency or binary bounds.
- **Break condition:** Non-convex loss functions would break the duality gap closure required for the convex reformulation.

### Mechanism 2
- **Claim:** The optimal robust classifier f* can be explicitly constructed from the solution of the dual problem using a softmax-like operation on the c-transforms of the dual potentials.
- **Mechanism:** The paper establishes that the primal and dual solutions are linked. For cross-entropy loss, the optimal classifier at point ẽx is proportional to exp(-φᵢᶜ(ẽx)) / Σ exp(-φⱼᶜ(ẽx)) (Corollary 8). This effectively turns the optimization variables (potentials) directly into the probability outputs of the robust classifier.
- **Core assumption:** Existence of a solution to the dual problem and Borel measurability of the classifier.
- **Evidence anchors:**
  - [abstract] "Explicit formulas for optimal classifiers under various loss functions (Corollaries 8, 15, 22)..."
  - [section 1.2.1] Corollary 8: "f*i(ẽx) = exp(-φ*iᶜ(ẽx)) / Σ exp(-φ*jᶜ(ẽx))".
  - [corpus] "Multiclass Loss Geometry Matters" discusses geometry effects, supporting the idea that loss choice dictates classifier structure.
- **Break condition:** If the dual potentials are only approximate (e.g., from truncated constraints), the constructed classifier provides a lower bound but is not guaranteed to be the exact optimal Bayes classifier.

### Mechanism 3
- **Claim:** The adversarial robustness problem is structurally equivalent to a generalized optimal transport barycenter problem with entropy regularization.
- **Mechanism:** Theorem 7 reframes the problem from the adversary's perspective: finding a perturbed measure ẽμ close to μ (transport cost) while minimizing a penalty on the density ratio (entropy). For cross-entropy, this penalty is KL-divergence; for α-logarithmic losses, it is Tsallis entropy.
- **Core assumption:** The loss function must satisfy specific structural separability, ℓ(v,i) = β(vᵢ) (Section 1.1, Theorem 7 assumption).
- **Evidence anchors:**
  - [abstract] "...connects adversarial robustness to optimal transport and generalized entropy-regularized barycenter problems..."
  - [section 1.1] Theorem 7 and the definition of the penalty φ(s).
  - [corpus] Weak support; most neighbors focus on surrogate bounds rather than the barycenter geometry.
- **Break condition:** Loss functions like quadratic loss (which depend on the full vector v, not just vᵢ) do not fit the specific barycenter form with scalar entropy penalties derived in Theorem 7.

## Foundational Learning

- **Concept: Kantorovich Duality / c-transform**
  - **Why needed here:** The paper's core engine (Theorem 3) relies on swapping a maximization over measures for a minimization over potentials using the c-transform. Without this, the "convex program" result is opaque.
  - **Quick check question:** Can you explain how the c-transform φᶜ(ẽx) = infₓ {c(x, ẽx) - φ(x)} relates the transport cost to the dual potential?

- **Concept: α-Fair Packing / Utility Theory**
  - **Why needed here:** The paper reduces the cross-entropy and α-log loss cases to an "α-fair packing" problem (Eq 21, 56) to leverage existing optimization algorithms.
  - **Quick check question:** How does the parameter α in the isoelastic utility Uα(t) = logα(t) control the trade-off between sparsity (0-1 loss behavior) and smoothness (cross-entropy behavior)?

- **Concept: Rademacher Complexity / Generalization Bounds**
  - **Why needed here:** To understand the context of "Lower Bounds." While this paper computes fundamental limits via OT, related literature (cited in intro) uses complexity measures to upper-bound these risks.
  - **Quick check question:** Why is a "learner-agnostic" lower bound (achieved by the Bayes classifier) useful for evaluating the robustness of restricted hypothesis classes (like neural networks)?

## Architecture Onboarding

- **Component map:** Input (xᵢ, yᵢ) → Conflict Set Identification → Dual Convex Program (α-fair packing) → CVXOPT Solver → Dual Potentials φᵢ → Optimal Classifier f* (softmax on c-transforms) → Lower Bound Estimate

- **Critical path:** Identifying the interacting subsets A (conflict hypergraph) is the computational bottleneck. The solver scales with the number of these interactions.

- **Design tradeoffs:**
  - **Truncation:** Restricting constraints to subsets A with |A| ≤ 2 or 3 (Remark 4) significantly improves speed but relaxes the bound (makes it looser/lower).
  - **Distance Metric:** Chebyshev distance shows "staircase" behavior in risk (Fig 4) vs. smooth increase in Euclidean; choice impacts the geometry of the conflict sets.

- **Failure signatures:**
  - **Non-convergence:** The optimizer may fail to converge for large α (e.g., α=1 cross-entropy) at high adversarial budgets ε, as observed in the MNIST Chebyshev experiment.
  - **Loose Bounds:** If the true robust classifier requires high-order interactions (|A| > 3) and you truncate to |A|=2, the lower bound will be strictly lower than the true optimal risk.

- **First 3 experiments:**
  1. **Synthetic Triplet (2D):** Implement the synthetic example (Fig 2) with 3 classes in ℝ². Verify that the risk increases monotonically with ε and α.
  2. **Truncation Ablation:** On a subset of MNIST (e.g., digits 1,4,7), compare the bounds achieved by allowing |A| ≤ 2 vs |A| ≤ 3 interactions. Quantify the gap.
  3. **α-Interpolation:** Fix ε and plot the optimal risk as a function of α (sweeping α ∈ [0,1.5]). Confirm that intermediate α values provide "sharper" lower bounds for cross-entropy than the α=0 (0-1 loss) baseline.

## Open Questions the Paper Calls Out

- **Question:** Can distributed optimization algorithms be developed to solve the dual problem (14) efficiently for large-scale datasets?
- **Basis in paper:** [explicit] The conclusion states future work may explore "computational aspects more deeply, including the development of distributed algorithms for the dual problem."
- **Why unresolved:** Current experiments utilized a centralized solver (CVXOPT) which faced scalability and convergence issues on larger datasets like MNIST with high adversarial budgets.
- **What evidence would resolve it:** A scalable, distributed algorithm that computes the dual potentials for large datasets with theoretical convergence guarantees.

- **Question:** How can warm-start strategies and the sparsity of α-logarithmic losses be systematically exploited to accelerate convergence for non-sparse losses like cross-entropy?
- **Basis in paper:** [explicit] The conclusion proposes the "further exploitation of warm-start strategies and sparsity properties to accelerate convergence."
- **Why unresolved:** The authors observed empirically that initializing with solutions from smaller ᾱ helps, but a formalized method to leverage the sparsity of α < 1 to aid the α=1 case is not established.
- **What evidence would resolve it:** A specific initialization protocol or algorithm that demonstrably reduces iteration counts for cross-entropy loss by utilizing solutions from sparse α-logarithmic regimes.

- **Question:** How can the numerical optimization challenges for the cross-entropy loss under large Chebyshev adversarial budgets be overcome?
- **Basis in paper:** [inferred] Section 3.2 notes that for α=1 with a large Chebyshev budget, "the optimizer that we used did not converge in the specified number of iterations."
- **Why unresolved:** The geometry of the constraint set or the objective function landscape in this specific regime prevents current solvers from finding the lower bound.
- **What evidence would resolve it:** A modified optimization routine or a reformulation of the dual problem that allows successful computation of bounds in the high-budget, cross-entropy setting.

## Limitations

- The framework requires convex loss functions; non-convex losses break the duality gap closure needed for the convex reformulation
- The explicit barycenter reformulation (Mechanism 3) only applies to losses with specific separability structure, excluding quadratic loss
- Numerical precision issues may affect the strict optimality guarantee when dual potentials are approximate from truncated constraints
- Computational complexity scales exponentially with the number of conflict interactions, requiring truncation that loosens bounds

## Confidence

- **High:** The reduction to α-fair packing problems for discrete data - well-established OT duality with clear empirical support
- **Medium:** The generalized barycenter reformulation - theoretically sound but depends on specific loss structure assumptions that limit applicability to quadratic loss
- **Low:** The exact numerical equivalence between dual potentials and classifier outputs - while the theory is clear, numerical precision issues in practice may affect the strict optimality guarantee

## Next Checks

1. **Scalability Verification:** Reproduce the synthetic experiment with increasing numbers of data points (10, 20, 50 per class) and measure how constraint identification and solver time scale. This tests the practical limits of the truncation approach.

2. **Loss Function Coverage:** Implement the framework for quadratic loss (which doesn't fit the barycenter form) and compare the resulting lower bounds to those from cross-entropy and α-logarithmic losses. This validates the scope limitations of Theorem 7.

3. **Generalization Gap Analysis:** Using the MNIST data, compute both the learner-agnostic lower bound and the Rademacher complexity-based upper bound for the same hypothesis class (e.g., linear classifiers). This contextualizes the theoretical lower bounds within practical generalization constraints.