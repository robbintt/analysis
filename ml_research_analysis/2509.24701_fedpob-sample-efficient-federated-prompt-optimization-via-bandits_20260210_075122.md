---
ver: rpa2
title: 'FedPOB: Sample-Efficient Federated Prompt Optimization via Bandits'
arxiv_id: '2509.24701'
source_url: https://arxiv.org/abs/2509.24701
tags:
- prompt
- agent
- optimization
- federated
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FedPOB, a novel framework for sample-efficient
  federated prompt optimization using multi-armed bandits. The approach addresses
  challenges of black-box access to proprietary LLMs, sample efficiency due to query
  costs, and privacy-preserving collaboration among multiple users.
---

# FedPOB: Sample-Efficient Federated Prompt Optimization via Bandits

## Quick Facts
- **arXiv ID**: 2509.24701
- **Source URL**: https://arxiv.org/abs/2509.24701
- **Reference count**: 40
- **Primary result**: Introduces FedPOB, a federated prompt optimization framework using multi-armed bandits that enables privacy-preserving collaboration while achieving sample efficiency

## Executive Summary
This paper presents FedPOB, a novel framework for sample-efficient federated prompt optimization using multi-armed bandits. The approach addresses the challenges of black-box access to proprietary LLMs, high query costs, and privacy-preserving collaboration among multiple users. By employing federated Linear UCB algorithms where agents share model parameters rather than raw data, FedPOB enables collaborative prompt optimization while maintaining data privacy. The framework includes FedPOB-Pref, an extension that handles preference-based feedback through federated dueling bandits. Extensive experiments demonstrate that both algorithms significantly outperform existing baselines, with performance improving as more agents participate in collaboration.

## Method Summary
FedPOB addresses the challenge of optimizing prompts for large language models under constraints of black-box access, query costs, and privacy requirements. The framework employs federated Linear UCB algorithms where multiple agents collaboratively optimize prompts without sharing raw data. Each agent maintains local model parameters and shares only these parameters with a central server, which aggregates them to improve the global model. The key innovation is extending linear bandit algorithms to a federated setting where the linear model represents prompt effectiveness. FedPOB-Pref extends this approach to handle preference-based feedback using federated dueling bandits, where agents compare pairs of prompts and share preference outcomes rather than absolute ratings. This preference-based variant achieves superior performance-to-communication trade-offs in practical settings.

## Key Results
- FedPOB significantly outperforms existing baselines in sample-efficient prompt optimization
- Performance improves monotonically with increasing number of participating agents
- FedPOB-Pref achieves superior performance-to-communication trade-off in preference feedback settings
- Both algorithms maintain privacy through parameter sharing rather than raw data exchange

## Why This Works (Mechanism)
FedPOB works by leveraging the structure of linear bandits in a federated setting. Each agent explores the prompt space locally using Linear UCB, which balances exploration and exploitation based on uncertainty estimates. The key mechanism is that agents share only their model parameters (weights and covariance matrices) rather than their observed data or prompts. This allows the central server to aggregate information across agents without compromising privacy. The federated dueling bandit extension (FedPOB-Pref) handles preference feedback by having agents compare prompt pairs and share pairwise outcomes, which is more practical than absolute ratings in many real-world scenarios.

## Foundational Learning
- **Linear Bandits**: Why needed - to model the relationship between prompt features and effectiveness; Quick check - verify the linear assumption holds for your specific LLM and task
- **Upper Confidence Bound (UCB) Algorithm**: Why needed - to balance exploration and exploitation in unknown environments; Quick check - confirm the confidence bounds appropriately capture uncertainty in your setting
- **Federated Learning**: Why needed - to enable collaboration without sharing sensitive data; Quick check - measure communication overhead versus performance gains
- **Dueling Bandits**: Why needed - to handle preference feedback which is often more reliable than absolute ratings; Quick check - verify pairwise comparisons are meaningful for your use case
- **Privacy-Preserving Parameter Sharing**: Why needed - to maintain data confidentiality while enabling collaboration; Quick check - assess potential information leakage through parameter updates

## Architecture Onboarding
**Component Map**: User Agents -> Parameter Server -> LLM API
**Critical Path**: Agent explores prompts → Receives feedback → Updates local model → Shares parameters → Server aggregates → Global model update → Agent receives updated model
**Design Tradeoffs**: Parameter sharing vs. data sharing (privacy vs. potential performance), synchronous vs. asynchronous updates (consistency vs. flexibility), absolute feedback vs. preference feedback (simplicity vs. practicality)
**Failure Signatures**: Poor performance indicates exploration-exploitation imbalance, privacy concerns suggest information leakage through parameters, communication bottlenecks indicate need for compression
**First Experiments**: 1) Single agent baseline comparison with non-federated Linear UCB, 2) Two-agent collaboration to verify parameter aggregation, 3) Preference feedback ablation study comparing FedPOB vs FedPOB-Pref

## Open Questions the Paper Calls Out
None

## Limitations
- Limited evaluation to single-task settings; effectiveness in multi-task environments unverified
- Theoretical rather than empirical communication overhead analysis across different network conditions
- Assumes synchronous updates across all agents, not reflecting real-world asynchronous participation
- Privacy guarantees based on parameter sharing without quantifying potential information leakage

## Confidence
- **High Confidence**: Core algorithmic contributions (federated Linear UCB and dueling bandit extensions) are mathematically sound
- **Medium Confidence**: Experimental results showing performance improvements with increased agent collaboration, though limited to specific test cases
- **Medium Confidence**: Claimed sample efficiency benefits, dependent on specific LLM query cost structures

## Next Checks
1. Evaluate FedPOB in multi-task settings where agents have heterogeneous objectives to test framework adaptability
2. Conduct empirical measurements of communication costs and latency under realistic network conditions with varying numbers of agents
3. Implement differential privacy mechanisms on parameter sharing and measure trade-off between privacy guarantees and optimization performance