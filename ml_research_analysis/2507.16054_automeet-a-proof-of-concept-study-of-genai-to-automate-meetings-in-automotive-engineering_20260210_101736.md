---
ver: rpa2
title: 'AutoMeet: a proof-of-concept study of genAI to automate meetings in automotive
  engineering'
arxiv_id: '2507.16054'
source_url: https://arxiv.org/abs/2507.16054
tags:
- meeting
- meetings
- information
- minutes
- stddev
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AutoMeet presents a proof-of-concept pipeline using generative
  AI to automate meeting documentation in automotive engineering. The system records
  meetings, generates transcripts via Whisper, and creates summaries using GPT-4o,
  which are then made searchable through a chatbot interface.
---

# AutoMeet: a proof-of-concept study of genAI to automate meetings in automotive engineering

## Quick Facts
- arXiv ID: 2507.16054
- Source URL: https://arxiv.org/abs/2507.16054
- Reference count: 0
- AutoMeet uses generative AI to automate meeting documentation in automotive engineering

## Executive Summary
AutoMeet presents a proof-of-concept pipeline that uses generative AI to automate meeting documentation in automotive engineering. The system records meetings, generates transcripts via Whisper, and creates summaries using GPT-4o, which are then made searchable through a chatbot interface. A survey of 42 developers found that 51% of work time is spent in meetings, and an AutoMeet pipeline could save ~10.5% of working time by reducing meeting needs and improving information transparency. Users reported high willingness to record meetings (median rating 1/4) and emphasized privacy features like easy recording controls and data deletion. The proof-of-concept showed average summary quality ratings of 2.58/6, with users valuing structure but noting technical limitations. The study identifies user acceptance and organizational factors—not technical ones—as the main barriers to implementation.

## Method Summary
The AutoMeet system consists of four modules: a meeting recorder that captures audio and slides, a transcriber using OpenAI Whisper for speech-to-text conversion, a summarizer using GPT-4o with iterative refinement techniques to process long transcripts, and a chatbot interface employing Retrieval-Augmented Generation (RAG) to search past meeting summaries. The proof-of-concept was implemented in Python with LangChain for LLM prompting and stored data locally rather than in a central database. A survey of 42 automotive developers assessed meeting frequency and potential time savings, while a small qualitative study with 4 users evaluated the system's functionality and user acceptance.

## Key Results
- 51% of automotive developers' work time is spent in meetings
- AutoMeet could save ~10.5% of working time by reducing meeting needs and improving information transparency
- Users rated willingness to record meetings highly (median 1/4 on 1-4 scale) but emphasized privacy features like manual recording controls and data deletion options

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Iterative LLM prompting can compress noisy, long-form transcripts into structured summaries.
- **Mechanism:** The system transcribes audio using Whisper, then feeds the text to GPT-4o. Instead of a single pass, an "iterative refinement technique" (likely via LangChain) processes the transcript in chunks or steps to handle length and maintain context, outputting both short and long summaries.
- **Core assumption:** Assumption: The "iterative refinement" prompt strategy successfully maintains semantic coherence across long, noisy transcripts better than single-pass summarization.
- **Evidence anchors:**
  - [Page 5] "To achieve this, we use an iterative refinement technique to process long transcripts."
  - [Page 5] "The summarization tool produces both a short summary... and a long summary..."
  - [corpus] Weak relevance: Neighbor papers discuss LLMs in automotive generally but do not validate this specific iterative summarization loop.
- **Break condition:** Fails if the Word Error Rate (WER) of the transcript is too high (e.g., >0.65 as noted in worst-case tests) or technical vocabulary is unrecognized, leading to hallucinations in the summary.

### Mechanism 2
- **Claim:** Retrieval-Augmented Generation (RAG) enables ad-hoc querying of meeting history without fine-tuning.
- **Mechanism:** Summaries and documents are stored (conceptually in a database, practically in local folders for the PoC). When a user queries the chatbot, relevant text segments are retrieved and appended to the LLM prompt, grounding the answer in specific past meetings rather than the model's training data.
- **Core assumption:** Assumption: The semantic search embedded in the RAG pipeline correctly retrieves the *relevant* meeting segments to answer a technical query.
- **Evidence anchors:**
  - [Page 4] "Using the Retrieval-Augmented Generation strategy... documents relevant to the user query are retrieved and forwarded to the LLM."
  - [Page 6] "The chatbot tool uses a Retrieval Augmented Generation (RAG) pipeline... to search for relevant meeting summaries."
  - [corpus] [Meeting Delegate] supports the concept of using LLMs to process meeting content, though AutoMeet focuses on search/retrieval rather than agentic delegation.
- **Break condition:** Fails if access rights are not strictly enforced (retrieving restricted docs) or if metadata (timestamps/author) is lost, preventing verification of information "hardness."

### Mechanism 3
- **Claim:** User trust is mechanistically dependent on a "Human-in-the-Loop" privacy filter rather than automated perfection.
- **Mechanism:** The pipeline includes a mandatory "Privacy filter" module where a human manually checks the AI-generated summary for personal data and accuracy before it is saved to the central database.
- **Core assumption:** Assumption: Users will not accept the system based on automated privacy scrubbing alone; they require manual verification to build trust.
- **Evidence anchors:**
  - [Page 3] "The Privacy filter module contains a manual check of the resulting summary... including both the removal of potentially remaining personal data and a correction of the technical content."
  - [Page 11] "Obligatory manual approval of minutes before integration to database was rated 2.58 (important)... users emphasized privacy concerns."
  - [corpus] Weak relevance: Neighbors focus on code generation or meeting intentionality, not specific trust mechanisms for transcription privacy.
- **Break condition:** Fails if the manual review step becomes a bottleneck (negating the "automation" benefit) or is skipped due to laziness, eroding the trust mechanism.

## Foundational Learning

- **Concept:** **Retrieval-Augmented Generation (RAG)**
  - **Why needed here:** This is the core architecture allowing the chatbot to answer questions based on specific, proprietary meeting history rather than general knowledge.
  - **Quick check question:** Can you explain why RAG reduces hallucination compared to a standard chatbot prompt?

- **Concept:** **Iterative Refinement Summarization**
  - **Why needed here:** Meeting transcripts exceed the context windows of many models or overwhelm single-pass prompts. This technique allows the model to summarize chunks and then refine them into a cohesive whole.
  - **Quick check question:** How does the "refine" chain in LangChain differ from a "map-reduce" chain for summarization?

- **Concept:** **Word Error Rate (WER)**
  - **Why needed here:** The study explicitly links transcription quality (WER 0.23–0.65) to summary quality. Understanding WER is critical to diagnosing why a summary might be hallucinating.
  - **Quick check question:** If a transcript has a WER of 0.50, what does that imply about the reliability of the resulting LLM summary?

## Architecture Onboarding

- **Component map:**
  - Meeting Recording (Audio/Video + Optional Slides) -> Whisper (Local Transcription) -> GPT-4o + LangChain (Iterative Summarization) -> Human Review (Privacy Filter) -> Storage (Local Folders/Planned Database) -> RAG Chatbot (GPT-4o + Retriever)

- **Critical path:** Audio Quality -> Transcription Accuracy (Whisper) -> Summarization Prompt -> Manual Review. If the audio is poor or transcription fails (WER > 0.6), the subsequent summarization is unreliable.

- **Design tradeoffs:**
  - **Local vs. Cloud:** The PoC runs Whisper locally for privacy but uses a corporate API for GPT-4o.
  - **PoC vs. Production:** The PoC uses local folders for storage (easy setup) vs. a Central Database (secure, scalable, but high implementation effort).
  - **Speed vs. Quality:** Real-time summarization was rejected in favor of post-meeting processing to allow for document integration and manual review.

- **Failure signatures:**
  - **"Sintering" vs "Centering":** Domain-specific vocabulary failure in Whisper (Page 5).
  - **Hallucinations:** Users noted GPT-4o summaries are not comparable to human experts (Page 6).
  - **Trust Collapse:** If recordings are stored permanently rather than deleted, users refuse to participate (Page 11).

- **First 3 experiments:**
  1. **WER Baseline:** Run Whisper on 5 sample meetings with known ground truth to measure Word Error Rate specifically for your domain's technical vocabulary.
  2. **Summary Rating:** Blind-test GPT-4o "Short" vs. "Long" summaries against human minutes to validate the paper's claim of "satisfactory" structure vs. detail.
  3. **Privacy Leakage Check:** Deliberately include names/personal data in a test recording to verify if the "prompt-based removal" actually works before relying on it.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can access rights be managed at the individual user level while maintaining efficient retrieval across heterogeneous meeting documentation?
- Basis in paper: [explicit] The authors state that "a database with access rights defined on the level of individual users and an effective management of the hardness/quality of information require substantial implementation efforts."
- Why unresolved: The proof-of-concept used local folder management rather than a unified database system.
- What evidence would resolve it: A working implementation with role-based access control tested across multiple projects with varying permission levels.

### Open Question 2
- Question: What safeguards effectively prevent misuse of meeting recordings beyond the intended documentation purpose?
- Basis in paper: [explicit] Users expressed "concerns regarding premeditated misuse of recordings beyond the intended context" and the authors note that "the full recordings have to be deleted permanently and securely."
- Why unresolved: Technical deletion mechanisms and verification procedures were not implemented or tested in the PoC.
- What evidence would resolve it: User trust ratings before and after implementing verified deletion protocols with audit trails.

### Open Question 3
- Question: How does long-term deployment affect user acceptance and actual meeting cancellation rates compared to estimated projections?
- Basis in paper: [explicit] The authors state they "explicitly do not want to create or offer an IT system that can be deployed for long-term daily usage" and note the approach "is currently being transferred towards such a more stable deployment setup."
- Why unresolved: The PoC study captured estimates and intentions, not longitudinal behavioral data.
- What evidence would resolve it: A longitudinal study measuring actual meeting reduction rates after 6-12 months of deployment.

### Open Question 4
- Question: How can transcription accuracy for domain-specific technical vocabulary be improved without sacrificing data privacy through cloud-based model fine-tuning?
- Basis in paper: [inferred] The paper reports that "special vocabulary is not recognized by the current transcription model, e.g., 'centering' instead of 'sintering'" while emphasizing local processing for data protection.
- Why unresolved: Local Whisper deployment trades off accuracy for privacy; domain adaptation typically requires cloud resources.
- What evidence would resolve it: Comparison of WER on technical vocabulary between local baseline and privacy-preserving adaptation techniques.

## Limitations
- The study is a proof-of-concept with limited scale—42 survey participants and qualitative feedback from only 4 users on the PoC system
- The reported 10.5% time savings are extrapolated from survey data, not directly measured
- Privacy and trust mechanisms rely on manual review, which may not scale

## Confidence
- **High Confidence:** User willingness to record meetings (median rating 1/4) and privacy feature importance (manual recording control, deletion options)
- **Medium Confidence:** The overall concept that generative AI can automate meeting documentation in automotive engineering, based on survey results
- **Low Confidence:** The claim of ~10.5% time savings is extrapolated from survey data, not directly measured. The specific quality of the LLM summaries (average rating 2.58/6) is based on a small, qualitative sample

## Next Checks
1. **WER Baseline:** Run Whisper on 5 sample meetings with known ground truth to measure Word Error Rate specifically for your domain's technical vocabulary.
2. **Summary Rating:** Blind-test GPT-4o "Short" vs. "Long" summaries against human minutes to validate the paper's claim of "satisfactory" structure vs. detail.
3. **Privacy Leakage Check:** Deliberately include names/personal data in a test recording to verify if the "prompt-based removal" actually works before relying on it.