---
ver: rpa2
title: 'Spatial Coordinates as a Cell Language: A Multi-Sentence Framework for Imaging
  Mass Cytometry Analysis'
arxiv_id: '2506.01918'
source_url: https://arxiv.org/abs/2506.01918
tags:
- cell
- spatial
- cells
- expression
- status
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of integrating spatial information
  into single-cell language models for imaging mass cytometry (IMC) analysis. Existing
  models fail to incorporate spatial context and cell-cell interactions, limiting
  their biological relevance.
---

# Spatial Coordinates as a Cell Language: A Multi-Sentence Framework for Imaging Mass Cytometry Analysis

## Quick Facts
- **arXiv ID:** 2506.01918
- **Source URL:** https://arxiv.org/abs/2506.01918
- **Reference count:** 9
- **Primary result:** Spatial2Sentence improves cell-type classification by 5.98% and clinical status prediction by 4.18% on diabetes IMC dataset by integrating spatial context into LLM analysis

## Executive Summary
This paper addresses the challenge of incorporating spatial information into single-cell language models for imaging mass cytometry (IMC) analysis. Existing models fail to capture cell-cell interactions and spatial context, limiting their biological relevance. The authors propose Spatial2Sentence, a novel framework that converts protein expression and spatial coordinates into multi-sentence prompts for large language models (LLMs). By constructing expression similarity and distance matrices, the method pairs spatially adjacent and expressionally similar cells as positive examples, while using distant and dissimilar cells as negatives. Experiments on diabetes and brain tumor IMC datasets demonstrate that Spatial2Sentence outperforms existing single-cell LLMs while enhancing interpretability of disease-relevant cell types and markers.

## Method Summary
The framework processes IMC data by first converting each cell's protein expression profile into a rank-ordered sequence of protein names, creating a "cell sentence." It then computes cosine similarity matrices from expression profiles and Euclidean distance matrices from spatial coordinates. For each cell, the method selects top-K most similar and spatially nearest cells as positive pairs, and most dissimilar and distant cells as negative pairs. These are formatted as multi-sentence prompts combining the current cell with neighbor sentences and task descriptions. The framework fine-tunes Llama-3.2-1B (or other LLMs) on these prompts for simultaneous cell-type classification and clinical status prediction.

## Key Results
- Spatial2Sentence improves cell-type classification accuracy by 5.98% on diabetes IMC dataset
- Clinical status prediction accuracy improves by 4.18% compared to existing single-cell LLMs
- Ablation studies confirm both spatial and expression components contribute to performance gains
- Framework enhances interpretability of disease-relevant cell types and markers

## Why This Works (Mechanism)

### Mechanism 1: Multi-Sentence Contrastive Prompting for Cell Context
The framework constructs contrastive pairs of cell sentences to enable LLMs to learn cell-cell interactions that single-sentence representations miss. For each cell, positive pairs use top-K most expression-similar and spatially-nearest cells, while negative pairs use most dissimilar and distant cells. These are formatted as multi-sentence prompts providing explicit contrastive context during fine-tuning. Core assumption: LLMs can leverage relational context between cell sentences to improve classification, analogous to natural language context usage. Evidence shows pairing spatially adjacent and expressionally similar cells as positives while using distant and dissimilar cells as negatives enables LLMs to learn cellular interactions.

### Mechanism 2: Expression Rank-Ordering as Cell Tokenization
The framework converts protein expression vectors to rank-ordered protein name sequences, preserving cell-identifying information in LLM-processable format. Each cell's expression profile is transformed by ranking proteins in descending order of expression, creating sequences like "CD44 · Ir191 · IR192 · ... · IR193" where token order encodes relative expression levels. Core assumption: Rank of protein expression reflects cell-type-specific properties, and ordinal information suffices for classification without exact values. Evidence from Cell2Sentence shows similar gene-ranking approaches preserve key information in the majority of cases.

### Mechanism 3: Dual-Channel Spatial-Expression Context Integration
The framework jointly encodes expression similarity and spatial proximity, providing complementary signals that improve predictions. It computes two independent matrices—cosine similarity from expression profiles and Euclidean distance from spatial coordinates—then uses both to construct prompts. This captures both molecular similarity and tissue microenvironment context. Core assumption: Cell identity depends on both intrinsic molecular state and spatial neighborhood; ignoring either reduces predictive power. Evidence shows removing spatial proximal sentences drops accuracy from 41.35% to 40.16% on diabetes dataset, while removing expression similarity drops to 39.86%.

## Foundational Learning

- **Concept: Imaging Mass Cytometry (IMC) Data Structure**
  - **Why needed here:** IMC produces cell × protein expression matrices plus 2D spatial coordinates. Understanding this dual structure is essential to grasp why existing LLMs (trained on expression alone) fail to capture spatial context.
  - **Quick check question:** Given an IMC dataset with 10,000 cells and 38 proteins, what are the dimensions of the expression matrix V and the coordinate matrix C?

- **Concept: Contrastive Learning with Positive/Negative Pairs**
  - **Why needed here:** The framework's core innovation is constructing contrastive cell pairs. Without understanding contrastive objectives, the multi-sentence prompt design appears arbitrary.
  - **Quick check question:** If cell A has high cosine similarity to cell B (0.92) but they are spatially distant (500 μm apart), should they form a positive pair, negative pair, or neither under this framework?

- **Concept: Prompt Engineering for Structured Data**
  - **Why needed here:** The method converts structured biological data into natural language prompts. Understanding how to format multi-sentence inputs for LLMs is critical for reproducing or extending the approach.
  - **Quick check question:** How would you format a positive-pair prompt for a cell with top-3 similar neighbors? What fields must be included?

## Architecture Onboarding

- **Component map:** Raw IMC data → Preprocessing (Cellpose + SLIC) → Expression matrix V (N×M) and coordinate matrix C (N×2) → Cell sentence generation → Similarity matrix computation (G) and distance matrix computation (D) → Pair selector (top-K positive/negative) → Prompt constructor → LLM fine-tuning → Multi-task heads (cell-type + clinical status)

- **Critical path:** Expression matrix → Cell sentence generation → Similarity matrix computation → Positive/negative pair selection → Multi-sentence prompt construction → LLM fine-tuning → Inference
  *Failure at any upstream stage (especially pair selection or sentence generation) propagates to final predictions.*

- **Design tradeoffs:**
  - **K value selection:** Higher K provides more context but increases prompt length, potentially exceeding smaller model context windows. Paper shows K=1-3 optimal; larger K degrades performance.
  - **Distance metric choice:** Euclidean distance outperforms L1 and cosine distance for spatial proximity (Table 4). Switch requires re-validation.
  - **Negative pair strategy:** Top 1-3 most dissimilar cells work best; extremely distant pairs (Top 7-9) reduce contrastive effectiveness (Table 6).

- **Failure signatures:**
  - **Low classification accuracy (<35% on diabetes):** Check if expression matrix contains valid protein names; verify rank-ordering produces meaningful sequences
  - **No improvement from spatial info:** Inspect coordinate matrix for NaN/zero values; confirm distance matrix is computed correctly
  - **Performance drop with multi-task learning:** Task conflict; verify label quality and consider single-task baseline first
  - **Memory overflow during training:** Reduce batch size or K value; sequence length scales with K and protein count

- **First 3 experiments:**
  1. **Baseline reproduction:** Run Spatial2Sentence (K=1) on provided diabetes dataset with Llama-3.2-1B; target ~41% cell-type accuracy. Verify data loading and sentence generation produce expected outputs.
  2. **Ablation sweep:** Remove spatial proximity component (use expression similarity only); compare to full model. Expected drop of ~1-2% confirms spatial contribution. Then reverse: remove expression, keep spatial only.
  3. **K-value sensitivity:** Test K ∈ {0, 1, 3, 5, 10} on brain tumor dataset. Plot accuracy vs. K; expect peak at K=1-3, degradation at higher K. This validates contrastive signal strength and context window constraints.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the Spatial2Sentence framework be effectively extended to a multi-modal system that incorporates multi-omic data (e.g., genomics, transcriptomics) alongside proteomics?
- **Basis in paper:** The authors state in the "Limitations and Future Works" section that there are "substantial opportunities to expand this methodology to multi-model framework, incorporating multi-omic data."
- **Why unresolved:** The current study validates the framework exclusively on Imaging Mass Cytometry (IMC) data, which provides spatial protein expression but does not integrate other omics layers.
- **What evidence would resolve it:** A modified version of Spatial2Sentence that successfully processes and integrates RNA sequencing or genomic data with spatial proteomics, demonstrating improved performance on cell classification or clinical prediction tasks compared to the proteomics-only model.

### Open Question 2
- **Question:** Does scaling the model to significantly larger architectures (e.g., 70B-80B parameters) yield substantial improvements in capturing complex biological insights compared to the lightweight models (e.g., 1B parameters) tested?
- **Basis in paper:** The authors note that "enhancing our model into large LLMs, e.g., with 70B-80B parameters will further improve its ability to capture more complex biological insights."
- **Why unresolved:** The primary experiments utilized Llama-3.2-1B and GPT-2 variants, leaving the potential gains from massive parameter scaling in this specific biological context unverified.
- **What evidence would resolve it:** Benchmarking the Spatial2Sentence prompting strategy on 70B parameter models to observe if there is a significant increase in accuracy for cell-type classification or clinical status prediction over the 1B baseline.

### Open Question 3
- **Question:** What learning strategies can make the framework robust to missing modalities, such as incomplete spatial coordinates or expression profiles?
- **Basis in paper:** The authors identify the need to "explore robust learning strategies for scenarios when some modalities are missing" to ensure the model remains effective with incomplete data.
- **Why unresolved:** The current implementation relies on the construction of distance and similarity matrices, which requires complete spatial coordinate and expression data for the cells involved.
- **What evidence would resolve it:** The development of an imputation or masking mechanism within the multi-sentence generation phase that maintains high classification accuracy even when specific spatial or expression inputs are randomly masked or corrupted.

## Limitations
- The effectiveness of rank-ordered protein sequences versus direct expression embeddings remains unclear, with no ablation comparing these representations
- The framework's reliance on accurate cell segmentation and spatial coordinates introduces sensitivity to preprocessing quality
- The claim that the approach "enhances interpretability of disease-relevant cell types and markers" is qualitative and lacks quantitative validation metrics

## Confidence
- **High Confidence:** The multi-sentence contrastive prompting mechanism and its implementation details are well-specified and reproducible
- **Medium Confidence:** The claim that Spatial2Sentence improves cell-type classification by 5.98% and clinical status prediction by 4.18% is supported by Table 1 but requires verification of preprocessing pipeline and dataset accessibility
- **Low Confidence:** The assertion that the approach "enhances interpretability of disease-relevant cell types and markers" is qualitative and lacks quantitative validation metrics

## Next Checks
1. **Rank-Ordering Ablation:** Implement an alternative cell sentence generation using normalized expression vectors directly (rather than ranked protein names) and compare classification accuracy to validate the ranking hypothesis
2. **Spatial Distance Sensitivity:** Test alternative spatial distance metrics (e.g., Mahalanobis distance, learned spatial embeddings) and evaluate impact on classification performance to confirm Euclidean distance optimality
3. **Negative Pair Strategy Validation:** Replace structured negative pair selection with random negatives and measure performance degradation to isolate the contribution of contrastive learning versus raw context length effects