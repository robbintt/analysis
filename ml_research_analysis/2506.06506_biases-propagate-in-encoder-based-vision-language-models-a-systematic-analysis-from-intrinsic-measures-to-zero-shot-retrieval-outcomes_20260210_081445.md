---
ver: rpa2
title: 'Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis
  From Intrinsic Measures to Zero-shot Retrieval Outcomes'
arxiv_id: '2506.06506'
source_url: https://arxiv.org/abs/2506.06506
tags:
- group
- valence
- bias
- intrinsic
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study quantifies how intrinsic biases in vision-language models
  (VLMs) propagate to downstream tasks. It introduces a controlled framework that
  correlates intrinsic SC-EAT bias measures in model representations with extrinsic
  bias outcomes in zero-shot text-to-image (TTI) and image-to-text (ITT) retrieval
  tasks.
---

# Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis From Intrinsic Measures to Zero-shot Retrieval Outcomes

## Quick Facts
- arXiv ID: 2506.06506
- Source URL: https://arxiv.org/abs/2506.06506
- Reference count: 34
- Primary result: Intrinsic biases in VLMs consistently correlate with downstream retrieval bias outcomes (ρ = 0.83 ± 0.10)

## Executive Summary
This study systematically examines how biases embedded in vision-language model (VLM) representations propagate to real-world retrieval tasks. The researchers develop a controlled framework that measures intrinsic biases using the SC-EAT method and correlates these with extrinsic bias outcomes in zero-shot text-to-image and image-to-text retrieval. Across 114 analyses spanning six model architectures, the study finds consistently high positive correlations between intrinsic and extrinsic biases, demonstrating that biases in model representations directly manifest in retrieval outputs. The research also reveals that larger, better-performing models exhibit greater bias propagation, while underrepresented groups experience less robust propagation, potentially skewing outcomes for marginalized populations.

## Method Summary
The study introduces a controlled experimental framework to analyze bias propagation in encoder-based VLMs. The methodology involves measuring intrinsic biases in model representations using the SC-EAT (Sentence Completion with Explicit Attribute Terms) technique, then correlating these measures with extrinsic bias outcomes in zero-shot retrieval tasks. The researchers conduct 114 analyses across six different VLM architectures, examining both text-to-image and image-to-text retrieval scenarios. By systematically varying model size and performance characteristics, they establish causal relationships between model properties and bias propagation patterns, while also investigating how biases affect different demographic groups.

## Key Results
- Consistently high positive correlations (ρ = 0.83 ± 0.10) between intrinsic and extrinsic biases across 114 analyses
- Larger and better-performing models exhibit greater bias propagation to downstream tasks
- Underrepresented groups experience less robust bias propagation, potentially skewing their retrieval outcomes

## Why This Works (Mechanism)
The study demonstrates that biases embedded in model representations serve as the foundational mechanism for bias propagation. When VLMs process and encode visual and textual information, systematic biases present in the training data become encoded in the model's internal representations. These intrinsic biases then directly influence the model's decision-making in retrieval tasks, where the biased representations affect how the model matches queries with relevant content. The controlled experimental design allows researchers to isolate and measure this propagation effect, establishing clear causal pathways from representation-level biases to observable downstream outcomes.

## Foundational Learning

**SC-EAT Method**: Systematic bias measurement technique for analyzing model representations - needed to quantify intrinsic biases in a controlled manner; quick check: verify the method captures relevant bias dimensions for your use case.

**Zero-shot Retrieval**: Task evaluation without task-specific fine-tuning - needed to assess natural bias propagation patterns; quick check: ensure retrieval tasks reflect realistic application scenarios.

**Spearman's Correlation**: Non-parametric measure of monotonic relationships - needed to quantify the strength of bias propagation; quick check: confirm monotonic relationships exist between measured variables.

**Encoder-based VLM Architecture**: Dual-encoder models for vision-language tasks - needed to understand how representations are formed and used; quick check: verify the architecture supports the analysis framework.

**Intrinsic vs Extrinsic Bias**: Distinction between representation-level and task-level biases - needed to establish the propagation mechanism; quick check: ensure both measurement approaches are aligned.

## Architecture Onboarding

**Component Map**: Data Preprocessing -> SC-EAT Bias Measurement -> Model Representations -> Zero-shot Retrieval -> Bias Outcome Measurement

**Critical Path**: The measurement pipeline follows: (1) prepare controlled test data, (2) measure intrinsic biases using SC-EAT, (3) perform zero-shot retrieval, (4) measure extrinsic bias outcomes, (5) compute correlation between intrinsic and extrinsic measures.

**Design Tradeoffs**: Controlled experiments provide clear causal evidence but may not capture all real-world complexity. Single intrinsic measurement method (SC-EAT) offers consistency but may miss bias types not captured by this approach.

**Failure Signatures**: Low correlation between intrinsic and extrinsic measures may indicate: (1) SC-EAT not capturing relevant biases, (2) retrieval tasks not sensitive to measured biases, or (3) model-specific architecture affecting propagation patterns.

**First Experiments**: 1) Verify SC-EAT captures known biases in your dataset, 2) Test correlation analysis on a subset of models to establish baseline patterns, 3) Compare bias propagation across different demographic groups to identify vulnerable populations.

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on single intrinsic bias measurement method (SC-EAT) may not capture full bias spectrum
- Controlled experimental setup may not reflect real-world deployment complexity
- Correlation findings may not generalize to all bias types or model architectures beyond tested set

## Confidence

**High confidence**: Claim that biases in model representations directly propagate to retrieval outcomes, supported by systematic correlation analysis across 114 experiments showing consistently high positive correlations (ρ = 0.83 ± 0.10).

**Medium confidence**: Finding that larger/better-performing models exhibit greater bias propagation, based on direct comparisons but with partially unexplained causal mechanisms.

**Medium confidence**: Observation that underrepresented groups experience less robust propagation, based on specific subgroup analyses that may not capture all demographic variations.

## Next Checks

1. Replicate the correlation analysis using multiple alternative intrinsic bias measurement methods to verify that SC-EAT captures the primary mechanisms of bias propagation.

2. Test the framework on additional vision-language model architectures and training datasets to assess generalizability across different model families and pretraining approaches.

3. Conduct real-world deployment studies to validate whether the controlled experimental findings translate to actual usage scenarios, particularly focusing on user-facing applications where bias impacts are most critical.