---
ver: rpa2
title: Neural Signals Generate Clinical Notes in the Wild
arxiv_id: '2601.22197'
source_url: https://arxiv.org/abs/2601.22197
tags:
- clinical
- report
- text
- generation
- celm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CELM is the first clinical EEG-to-language foundation model for
  automated EEG report generation. It addresses the challenge of summarizing long-duration
  EEG recordings by integrating pretrained EEG encoders with language models through
  epoch-aggregated tokenization, sequence-aware alignment, and prompt fusion.
---

# Neural Signals Generate Clinical Notes in the Wild

## Quick Facts
- arXiv ID: 2601.22197
- Source URL: https://arxiv.org/abs/2601.22197
- Reference count: 28
- First clinical EEG-to-language foundation model achieving 70%–95% relative improvements in generation metrics.

## Executive Summary
CELM introduces the first clinical EEG-to-language foundation model (ELM) for automated generation of EEG reports from long-duration recordings. The model integrates pretrained EEG encoders with frozen large language models through epoch-aggregated tokenization and sequence-aware alignment. Trained on ~11,000 hours of EEG from 9,048 patients, CELM achieves strong performance on multiple clinical report sections, including descriptions and seizure events, with notable gains when patient history is included.

## Method Summary
CELM processes long EEG recordings by first tokenizing each 10-second epoch using a frozen CBraMod encoder, then aligning these tokens to clinical report text via a small trainable linear-attention transformer projector. This projector is the only trainable component (~1.5M parameters), which learns to map EEG tokens into the language model's embedding space. The aligned embeddings are then fused with a frozen LLM (Qwen3-4B-Instruct) to generate report sections. Training uses next-token prediction with AdamW, weight decay, and mixed-precision optimization. The approach handles sessions up to 10,000 seconds and is designed for multi-section report generation.

## Key Results
- 70%–95% relative improvements in ROUGE-1 and METEOR metrics over baselines (0.2–0.3 to 0.4–0.6 with patient history).
- 0.43–0.52 generation performance in zero-context settings, versus baseline 0.17–0.26.
- Strong performance across multiple clinical report sections (description, background, abnormalities, events, impressions).

## Why This Works (Mechanism)
CELM leverages frozen, pretrained models for both EEG encoding and language generation, allowing a small trainable projector to efficiently bridge the modalities. Epoch-aggregated tokenization reduces the input length to match LLM context limits while preserving signal information. The linear-attention transformer projector captures temporal dependencies between epochs before aligning them to language space, enabling coherent report generation.

## Foundational Learning
- **Epoch-Aggregated Tokenization**: Compresses long EEG sequences into fixed-length tokens per epoch; needed to fit within LLM context limits.
- **Sequence-Aware Alignment**: Uses a small trainable projector to map EEG tokens to language embeddings; ensures temporal coherence across epochs.
- **Prompt Fusion**: Integrates aligned EEG embeddings with frozen LLM via special tokens; enables multi-section report generation.
- **Preprocessing Standards**: 0.1–75 Hz band-pass + 60 Hz notch filter, 200 Hz resampling, 22-channel 10-20 system; ensures consistency across recordings.
- **Clinical Report Structuring**: Automated section detection and normalization; needed for supervised training from raw reports.
- **Quick Check**: Verify epoch aggregation preserves signal features critical for clinical events.

## Architecture Onboarding

**Component Map**: EEG Recording -> CBraMod Encoder -> Epoch Tokens -> Linear-Attention Projector -> Aligned Embeddings -> Qwen3-4B-Instruct -> Generated Report

**Critical Path**: EEG Recording -> Epoch-Aggregated Tokenization -> Sequence-Aware Alignment -> Prompt Fusion -> Report Generation

**Design Tradeoffs**: Freezes large pretrained models to reduce training cost; uses small trainable projector for efficiency; trades off memory for some performance with compression variants.

**Failure Signatures**: Memory overflow with long sessions; projector overfitting (decreasing training but increasing validation loss); degraded performance on rare clinical events.

**First Experiments**:
1. Validate epoch tokenization preserves waveform features using a held-out validation subset.
2. Confirm projector improves alignment over naive linear projection.
3. Evaluate generation quality on manually annotated test set for clinical accuracy.

## Open Questions the Paper Calls Out
- What efficient compression strategies can preserve clinically relevant information from long EEG sequences while remaining within LLM context limits?
- How can clinical EEG-to-language models be evaluated using benchmarks that capture clinical correctness rather than just lexical similarity?
- How can ELM architectures be improved to accurately model rare and clinically complex events, such as interictal epileptiform abnormalities?

## Limitations
- Performance degrades on rare and clinically complex events, especially interictal epileptiform abnormalities.
- No clinical validation or human evaluation of generated reports for diagnostic accuracy.
- Reliance on a single large clinical database may limit generalizability.

## Confidence
- Methodology description: High
- Absolute performance numbers: Medium
- Clinical utility claims: Low

## Next Checks
1. Verify publicly released code and weights produce identical preprocessing and tokenization outputs on a held-out validation subset.
2. Run ablation studies to confirm the 2-layer linear-attention projector yields statistically significant improvements over simpler alternatives.
3. Assess model outputs on a small, manually annotated test set for factual accuracy and coherence, especially for critical clinical sections.