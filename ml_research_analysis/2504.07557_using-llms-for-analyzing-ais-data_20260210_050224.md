---
ver: rpa2
title: Using LLMs for Analyzing AIS Data
arxiv_id: '2504.07557'
source_url: https://arxiv.org/abs/2504.07557
tags:
- data
- llms
- queries
- ship
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study evaluates Large Language Models (LLMs) for analyzing
  Automatic Identification System (AIS) maritime data using four approaches: natural
  language interfaces to spatial databases, reasoning on raw data, compressed trajectories,
  and semantic trajectories. We designed 27 queries across four categories (attribute,
  individual trajectory, interaction, and data-fusion) and established ground truth
  for evaluation.'
---

# Using LLMs for Analyzing AIS Data

## Quick Facts
- **arXiv ID**: 2504.07557
- **Source URL**: https://arxiv.org/abs/2504.07557
- **Reference count**: 32
- **Primary result**: NLIDB method showed stable performance across dataset sizes while ZSA methods degraded with increased data volume

## Executive Summary
This study evaluates Large Language Models (LLMs) for analyzing Automatic Identification System (AIS) maritime data using four approaches: natural language interfaces to spatial databases, reasoning on raw data, compressed trajectories, and semantic trajectories. The research team designed 27 queries across four categories and established ground truth for evaluation. The NLIDB method (using PostGIS) demonstrated superior scalability compared to ZSA methods, particularly as dataset size increased. The raw data ZSA approach showed surprisingly strong performance on smaller datasets, outperforming compressed and semantic variants and demonstrating LLMs' ability to directly process spatiotemporal data.

## Method Summary
The researchers developed four distinct approaches for using LLMs to analyze AIS maritime data: (1) Natural Language Interface to Database (NLIDB) using PostGIS, (2) Zero-Shot Analysis (ZSA) on raw AIS data, (3) ZSA on compressed trajectories, and (4) ZSA on semantic trajectories. They created a comprehensive test suite of 27 queries spanning four categories: attribute queries, individual trajectory queries, interaction queries, and data-fusion queries. Ground truth answers were manually constructed for each query. The evaluation used a dataset of 10,000 AIS records and tested each approach's accuracy and performance under a 30-second time constraint. GPT-4 was used as the LLM model throughout the experiments.

## Key Results
- NLIDB method demonstrated stable performance across different dataset sizes, while ZSA methods showed significant degradation as data volume increased
- Raw data ZSA approach outperformed compressed and semantic trajectory methods on smaller datasets, indicating LLMs can directly process spatiotemporal data effectively
- All methods struggled with complex interaction queries, particularly those involving ship cluster detection and multi-ship trajectory analysis

## Why This Works (Mechanism)
LLMs can effectively translate natural language queries into structured operations for spatial data analysis when provided with appropriate context and frameworks. The study demonstrates that LLMs possess latent capabilities for spatiotemporal reasoning that can be activated through different architectural approaches. When given raw AIS data, LLMs can directly identify patterns and answer queries without requiring traditional preprocessing or feature engineering. The performance differences between approaches reveal how LLM reasoning capabilities interact with data representation formats, with some formats better leveraging the model's inherent strengths in pattern recognition and contextual understanding.

## Foundational Learning
- **Automatic Identification System (AIS)**: Maritime vessel tracking system providing location, speed, and identification data; needed to understand the domain and data structure being analyzed
- **Zero-Shot Analysis (ZSA)**: LLM approach where the model reasons directly on data without specialized training; needed to evaluate the model's inherent reasoning capabilities
- **Natural Language Interface to Database (NLIDB)**: System translating natural language queries into database operations; needed as a performance baseline and comparison point
- **Semantic Trajectories**: Data representation encoding movement patterns with semantic meaning; needed to test whether abstracted representations improve LLM reasoning
- **Spatiotemporal Data Analysis**: Methods for analyzing data with both spatial and temporal dimensions; needed to contextualize the query types and evaluation metrics
- **Ground Truth Construction**: Manual creation of correct answers for evaluation; needed to establish a benchmark for measuring LLM performance

## Architecture Onboarding

**Component Map**: User Query -> Query Categorizer -> NLIDB Engine -> PostGIS Database OR ZSA Raw Data Engine -> LLM OR ZSA Compressed Engine -> LLM OR ZSA Semantic Engine -> LLM -> Answer Generator -> Response

**Critical Path**: User Query → Query Categorizer → NLIDB Engine → PostGIS Database → Answer Generator → Response

**Design Tradeoffs**: The study balances between leveraging LLMs' reasoning capabilities directly on raw data versus using traditional spatial databases for performance. NLIDB offers better scalability but requires database infrastructure, while ZSA approaches are more flexible but struggle with larger datasets. The choice of data representation (raw, compressed, semantic) affects both performance and accuracy, with raw data surprisingly effective for smaller datasets but less scalable.

**Failure Signatures**: Degradation in performance with increasing dataset size, particularly for ZSA methods; struggles with complex multi-ship interaction queries; time-outs or incomplete responses when processing exceeds 30-second limit; incorrect spatial reasoning when data representation lacks sufficient context.

**First 3 Experiments**:
1. Replicate the 27-query evaluation using a larger dataset (100K+ records) to verify scalability claims
2. Test the same methodology with multiple LLM models including open-source alternatives
3. Conduct a blinded validation where independent experts verify ground truth without prior knowledge of expected results

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation based on a specific 10,000-record dataset that may not represent full complexity of real-world maritime traffic
- Manual ground truth creation could introduce human bias in query design and result verification
- Experiments conducted using GPT-4 only, limiting generalizability across different LLM architectures
- 30-second time constraint may not reflect practical deployment scenarios where longer processing times could be acceptable

## Confidence

**High Confidence**: The comparative performance between NLIDB and ZSA methods, particularly the scalability advantage of NLIDB over ZSA approaches

**Medium Confidence**: The specific performance differences between raw data ZSA and compressed/semantic trajectory methods, as these may vary with different data characteristics

**Medium Confidence**: The identified struggle with complex interaction queries, as this could be influenced by the specific query formulation and ground truth construction

## Next Checks
1. Replicate the experiments with larger datasets (100K+ records) to verify scalability claims and assess performance degradation patterns
2. Test the same methodology with multiple LLM models (including open-source alternatives) to evaluate model-specific performance variations
3. Conduct a blinded validation where independent experts verify the ground truth and assess query interpretation accuracy without prior knowledge of expected results