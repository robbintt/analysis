---
ver: rpa2
title: Mapping Faithful Reasoning in Language Models
arxiv_id: '2510.22362'
source_url: https://arxiv.org/abs/2510.22362
tags:
- reasoning
- safety
- cases
- internal
- step
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Concept Walk, a method to track how language\
  \ models\u2019 internal safety-related representations evolve across reasoning steps.\
  \ By projecting step-level activations onto a learned safety direction, it measures\
  \ temporal shifts in safety alignment during chain-of-thought reasoning."
---

# Mapping Faithful Reasoning in Language Models

## Quick Facts
- arXiv ID: 2510.22362
- Source URL: https://arxiv.org/abs/2510.22362
- Authors: Jiazheng Li; Andreas Damianou; J Rosser; José Luis Redondo García; Konstantina Palla
- Reference count: 40
- Primary result: Introduces Concept Walk method to track safety-related representation changes during chain-of-thought reasoning

## Executive Summary
This paper presents Concept Walk, a novel method to analyze how language models' internal safety representations evolve during reasoning steps. The method tracks temporal shifts in safety alignment by projecting step-level activations onto a learned safety direction, measuring how safety concepts are processed through chain-of-thought reasoning. Applied to Qwen 3-4B on synthetic safety prompts, the authors find that in "hard" cases where CoTs genuinely influence outputs, safety activation changes are sustained and structured, while in "easy" cases where CoTs are decorative, changes are transient and self-corrected. This provides a quantitative tool for distinguishing faithful reasoning from superficial chains of thought.

## Method Summary
Concept Walk tracks safety-related representation changes during chain-of-thought reasoning by learning a "safety direction" in activation space from supervised data. The method projects step-level activations onto this direction to measure temporal shifts in safety alignment. For evaluation, the authors apply this to Qwen 3-4B on synthetic safety prompts, comparing trajectories between baseline CoTs and perturbed CoTs containing logical flaws. They classify cases as "hard" (perturbed CoTs change outputs) versus "easy" (perturbed CoTs don't change outputs) based on output divergence, then analyze differences in activation trajectories between these groups.

## Key Results
- In "hard" cases (where perturbed CoTs change outputs), safety activation changes are sustained and structured
- In "easy" cases (where perturbed CoTs are decorative), safety changes are transient and self-corrected
- Concept Walk can distinguish genuine from superficial reasoning, identifying when CoTs are trustworthy

## Why This Works (Mechanism)
The method works by capturing the temporal evolution of safety-related representations during reasoning. When CoTs are genuinely processing safety concepts, the model's internal representations show sustained shifts in the safety direction across multiple reasoning steps. In contrast, when CoTs are merely decorative, the model's representations briefly deviate but self-correct, showing only transient changes. This difference in activation trajectory patterns provides a measurable signature of reasoning faithfulness.

## Foundational Learning
- Activation space projection: Mapping high-dimensional activations onto specific concept directions to measure representation changes
- Chain-of-thought perturbation: Systematically introducing logical flaws into reasoning steps to test reasoning faithfulness
- Direction learning from supervised data: Creating interpretable concept vectors by learning from labeled examples
- Temporal activation tracking: Monitoring how internal representations evolve across sequential processing steps

## Architecture Onboarding
- Component map: Input prompt → CoT generation → Step-by-step activation extraction → Safety direction projection → Trajectory analysis
- Critical path: Prompt → Model processing → Activation extraction at each step → Projection onto safety direction → Temporal analysis
- Design tradeoffs: Static vs. mode-specific safety directions (reduced variability vs. potential representation shifts)
- Failure signatures: Transient activation changes may be misinterpreted as faithful reasoning if perturbation timing is off
- First experiments: 1) Compare safety trajectory in thinking vs non-thinking modes, 2) Test different perturbation injection timings, 3) Apply to non-safety domains like fairness

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Do internal safety representations shift significantly between thinking and non-thinking modes, requiring mode-specific concept directions for accurate measurement?
- Basis in paper: The authors compute the safety direction in non-thinking mode and apply it to thinking mode, noting that "computing mode-specific... directions could address potential representation shifts."
- Why unresolved: The current study assumes a static safety encoding across modes to reduce variability, but this assumption remains unverified.
- What evidence would resolve it: Comparing the efficacy and alignment of safety vectors learned separately from thinking versus non-thinking mode activations.

### Open Question 2
- Question: Does the classification of "hard" versus "easy" reasoning cases depend on the timing or intensity of the perturbation?
- Basis in paper: The authors state that "systematic variation of perturbation timing and strength would clarify temporal sensitivity."
- Why unresolved: The current methodology relies on a fixed midpoint injection strategy, leaving the sensitivity of these findings to different perturbation configurations unknown.
- What evidence would resolve it: Ablation studies varying the injection step (early vs. late) and the severity of the logical flaw to observe changes in the Concept Walk trajectory.

### Open Question 3
- Question: Can the Concept Walk framework reliably distinguish faithful from decorative reasoning in non-safety domains such as fairness or bias?
- Basis in paper: The authors identify the study as an initial step and suggest "the same approach could be applied to other domains such as fairness, bias or toxicity."
- Why unresolved: It is unclear if the sustained activation shifts observed in safety-critical "hard" cases generalize to concepts that may not have distinct refusal mechanisms.
- What evidence would resolve it: Applying Concept Walk to datasets labeled for fairness or bias and testing for the same divergence between perturbed and baseline trajectories.

## Limitations
- Results are based solely on a 4B parameter model on synthetic safety prompts, limiting external validity
- The method relies on a learned safety direction from supervised data, which may not generalize well to other safety concepts or domains
- The perturbation methodology, while innovative, may not capture all forms of superficial reasoning
- The safety direction learning process could introduce biases that affect interpretation

## Confidence
- High Confidence: The technical methodology for tracking activation changes through Concept Walk is sound and well-executed
- Medium Confidence: The interpretation that sustained activation changes indicate faithful reasoning is plausible but requires additional validation
- Low Confidence: The generalizability of findings to larger models, different safety concepts, or real-world applications remains largely untested

## Next Checks
1. Test Concept Walk on safety-related reasoning tasks with larger models (8B+ parameters) to assess scalability
2. Apply the method to non-safety domains (e.g., mathematical reasoning or commonsense QA) to evaluate domain generalization
3. Compare Concept Walk results with human evaluations of reasoning faithfulness on the same prompts