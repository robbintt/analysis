---
ver: rpa2
title: 'RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual
  Compensation'
arxiv_id: '2505.24442'
source_url: https://arxiv.org/abs/2505.24442
tags:
- residual
- rmoa
- broadway
- arxiv
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Residual Mixture-of-Agents (RMoA), an enhanced
  multi-agent architecture that addresses high computational costs, information loss,
  and robustness issues in traditional Mixture-of-Agents systems. The method incorporates
  greedy diversity embedding selection to maximize information heterogeneity, residual
  extraction and aggregation agents to preserve cross-layer incremental information,
  and an adaptive termination mechanism to dynamically halt processing based on residual
  convergence.
---

# RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation

## Quick Facts
- **arXiv ID:** 2505.24442
- **Source URL:** https://arxiv.org/abs/2505.24442
- **Reference count:** 40
- **Primary result:** State-of-the-art performance on AlpacaEval 2.0, MATH, CRUX, and MMLU-redux with lower computational cost than baseline MoA

## Executive Summary
This paper introduces Residual Mixture-of-Agents (RMoA), an enhanced multi-agent architecture that addresses high computational costs, information loss, and robustness issues in traditional Mixture-of-Agents systems. The method incorporates greedy diversity embedding selection to maximize information heterogeneity, residual extraction and aggregation agents to preserve cross-layer incremental information, and an adaptive termination mechanism to dynamically halt processing based on residual convergence. Experiments across four benchmarks—AlpacaEval 2.0, MATH, CRUX, and MMLU-redux—demonstrate that RMoA achieves state-of-the-art performance with significantly lower computational overhead compared to baseline methods. Ablation studies confirm the effectiveness of each component, while analysis shows the framework enables deeper iteration without performance degradation.

## Method Summary
RMoA optimizes Mixture-of-Agents architecture through three key innovations: (1) greedy diversity embedding selection that selects K maximally diverse responses via cosine similarity minimization, (2) residual extraction and aggregation agents that capture and preserve incremental information between processing layers, and (3) adaptive termination that dynamically halts processing when residuals converge. The system processes queries through multiple layers of proposer agents, each generating responses with role-specific prompts. Diversity selection reduces computational overhead by filtering redundant responses, while residual agents maintain information flow across layers by capturing differences between consecutive outputs. The adaptive termination mechanism stops processing early when no meaningful residuals are detected, preventing unnecessary computation and potential hallucination from over-optimization.

## Key Results
- RMoA achieves state-of-the-art performance on AlpacaEval 2.0, MATH, CRUX, and MMLU-redux benchmarks
- The method demonstrates significant computational cost reduction compared to baseline MoA systems
- Ablation studies confirm each component (diversity selection, residual extraction, adaptive termination) contributes positively to overall performance
- RMoA maintains performance improvements at deeper layer counts where baseline MoA typically degrades

## Why This Works (Mechanism)

### Mechanism 1: Greedy Diversity Embedding Selection
- **Claim:** Selecting K responses via embedding-based greedy diversity maximizes information heterogeneity while reducing computational overhead from redundant tokens.
- **Mechanism:** Compute cosine similarity matrix S for all response pairs via embedding vectors. Initialize by selecting the response with lowest global average similarity. Iteratively add candidates that minimize maximum similarity to already-selected set, stopping at K selections.
- **Core assumption:** Semantic diversity in embedding space correlates with information diversity useful for downstream reasoning (distinct perspectives reduce redundancy).
- **Evidence anchors:**
  - [abstract]: "innovatively design an embedding-based diversity selection mechanism that greedily selects responses via vector similarity"
  - [section 3.2.1]: Equations 1-4 formalize similarity matrix construction, initialization, and iterative selection phases
  - [corpus]: Weak direct evidence; "Attention-MoA" (FMR=0.58, 0 citations) also combines attention with MoA but uses different selection criteria
- **Break condition:** If embedding model poorly captures task-relevant semantics (e.g., code syntax), diversity selection may filter informative responses.

### Mechanism 2: Residual Extraction Agent
- **Claim:** Capturing inter-layer response differences preserves incremental information and mitigates degradation during deep aggregation.
- **Mechanism:** Concatenate current and previous layer responses. Residual Extraction Agent (LLM with structured prompt) identifies differences: content errors/hallucinations, detail discrepancies, additional information. Extracted residuals are concatenated with previous responses for next-layer reference.
- **Core assumption:** The delta between iterations ("residual") contains valuable incremental information that would otherwise be lost in standard aggregation.
- **Evidence anchors:**
  - [abstract]: "introduce a Residual Extraction Agent to preserve cross-layer incremental information by capturing inter-layer response differences"
  - [section 3.2.2]: Equations 5-7 formalize concatenation, residual extraction via Res agent, and residual reference construction
  - [corpus]: No direct corpus evidence for this specific residual extraction approach in multi-agent systems
- **Break condition:** If residual extractor model lacks capability, it may miss critical differences or hallucinate residuals. Table 3 shows weaker models (Llama2-7B) decrease performance by 2.84%.

### Mechanism 3: Adaptive Termination
- **Claim:** Dynamic halting based on residual convergence prevents over-optimization hallucinations and reduces unnecessary computation.
- **Mechanism:** Monitor residual extraction output. If no residuals detected for m consecutive layers (i.e., Residual Extraction Agent returns "no change" repeatedly), terminate iteration early rather than processing all L layers.
- **Core assumption:** Absence of detected residuals signals convergence; continuing risks introducing errors through unnecessary modifications.
- **Evidence anchors:**
  - [abstract]: "propose an adaptive termination mechanism that dynamically halts processing based on residual convergence"
  - [section 3.2.3]: Formal termination condition described; Table 4 shows AT saves $17.01 cost; Table 10 shows hallucination rate reduction (5.91%→2.13% for Qwen round 2)
  - [corpus]: No direct corpus evidence for residual-based termination in multi-agent systems
- **Break condition:** If residual extractor incorrectly reports "no residuals" on incomplete solutions, early termination yields under-optimized outputs.

## Foundational Learning

- **Concept: ResNet-style residual connections**
  - **Why needed here:** The paper explicitly draws inspiration from ResNet; understanding how skip connections preserve gradient flow and mitigate degradation is essential for grasping why inter-layer residuals help.
  - **Quick check question:** Why does ResNet add the input to the output of a block rather than just passing through the transformed output?

- **Concept: Mixture-of-Agents (MoA) architecture**
  - **Why needed here:** RMoA is a modification of baseline MoA; you must understand the layered proposer-aggregator structure to see what residual connections modify.
  - **Quick check question:** In standard MoA, what is concatenated and passed between layers?

- **Concept: Cosine similarity for semantic diversity**
  - **Why needed here:** The greedy selection mechanism relies on embedding similarity to quantify response diversity.
  - **Quick check question:** If two responses have cosine similarity of 0.95, what does that imply about their semantic content?

## Architecture Onboarding

- **Component map:**
  Query → Greedy Diversity Selection → Residual Extraction → Layer Proposers → (repeat until termination or L layers) → Residual Aggregation → Final Response

- **Critical path:** Greedy Diversity Selection → Residual Extraction → Layer Proposers → (repeat until termination or L layers) → Residual Aggregation

- **Design tradeoffs:**
  - **K (selection count):** Table 2 shows K=3 balances performance and cost; higher K increases tokens without proportional gains
  - **Layer depth:** Figures 3-4 show RMoA improves with depth while MoA degrades; but deeper = more cost
  - **Extractor/Aggregator model capability:** Table 3 shows stronger models (Qwen2.5-72B) dramatically improve aggregation (+28%), but increase cost

- **Failure signatures:**
  - Performance plateaus or drops on knowledge-intensive tasks (MMLU-redux MoA baseline: -3.5% to -7.2%) → possible information overload
  - High hallucination rates in deep layers without AT → over-optimization
  - Residual extractor returns empty or trivial differences → extractor model underpowered or prompts unclear

- **First 3 experiments:**
  1. **Ablate each component individually** (remove ES, RA, AT) on MATH subset to reproduce Table 4; validates implementation correctness
  2. **Sweep K ∈ {2,3,4,5}** on single dataset; confirm cost-performance tradeoff inflection point matches paper's K=3 finding
  3. **Test adaptive termination threshold** (vary m consecutive "no residual" layers); measure cost savings vs. accuracy impact to calibrate early-stopping sensitivity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the theoretical performance limits and scaling laws for RMoA as the number of processing layers increases significantly (e.g., >6 layers)?
- Basis in paper: [explicit] The authors state in the Limitations section that they "have not yet explored the performance limits of our approach" and plan to "analyze the scaling laws that govern these limits" in future work.
- Why unresolved: Time and cost constraints limited the experimental depth, leaving the saturation point where performance plateaus or degrades unidentified.
- What evidence would resolve it: Empirical results from experiments running RMoA with significantly deeper architectures (e.g., 10–20 layers) across the MATH and MMLU-redux benchmarks.

### Open Question 2
- Question: To what extent does the RMoA performance gain stem from the aggregator's internal knowledge (cognitive bias) rather than the synthesis of provided residuals?
- Basis in paper: [inferred] In Section 5.1 (Table 3), the authors note that using a stronger model like Qwen2.5-72B for aggregation significantly improves performance, attributing this to the model "leveraging its own knowledge" and referencing "cognitive biases" in LLMs.
- Why unresolved: The paper does not isolate whether the aggregator is faithfully integrating residuals or simply overwriting them with its own parametric knowledge.
- What evidence would resolve it: An ablation study measuring the faithfulness of the aggregator by checking if the final output contradicts the provided residuals in favor of the aggregator's pre-training data, particularly on hallucination-prone tasks.

### Open Question 3
- Question: Can quantitative metrics (like embedding similarity) be improved to reliably replace LLM-based judgments for adaptive termination in reasoning tasks?
- Basis in paper: [inferred] Appendix C.1 (Table 6) demonstrates that embedding-based similarity thresholds perform worse than LLM-based judgments, leading the authors to conclude that "semantic similarity and residual convergence are weakly correlated."
- Why unresolved: While the paper identifies this gap, it defaults to LLM judgment without solving the inefficiency of using a model to detect convergence.
- What evidence would resolve it: The development and validation of a hybrid or fine-tuned embedding metric that achieves comparable termination accuracy to LLM judgments on the MATH500 dataset.

## Limitations

- The adaptive termination mechanism lacks a specified threshold value (m consecutive "no residual" layers), creating implementation ambiguity
- The exact number of proposers per layer (N) in main experiments remains unclear, with only ablation studies showing 4-8 proposers
- Residual extraction agent effectiveness depends heavily on prompt engineering, which is not fully specified in the paper
- Computational cost analysis assumes specific hardware configurations that may not generalize across different deployment environments

## Confidence

- **High Confidence:** The core architectural innovations (greedy diversity selection, residual extraction, and adaptive termination) are well-defined and supported by ablation studies. The performance improvements on benchmark tasks appear robust and reproducible with proper implementation.
- **Medium Confidence:** The computational cost savings estimates depend on specific hardware and inference settings. The trade-offs between layer depth and performance may vary significantly across different model families and task domains.
- **Low Confidence:** The effectiveness of the residual extraction agent across diverse task types is not fully established. The paper provides limited analysis of failure cases or edge conditions where the approach might degrade performance.

## Next Checks

1. **Implement adaptive termination sensitivity analysis** by varying the m threshold value across {1, 2, 3, 4} consecutive "no residual" layers on MATH dataset to determine optimal stopping point and measure trade-offs between cost savings and accuracy retention.

2. **Conduct cross-model capability evaluation** by running RMoA with different extractor/aggregator combinations (e.g., Llama3.1-8B, Qwen2.5-32B) on the same benchmark tasks to quantify the impact of model capability on residual extraction quality and final performance.

3. **Test embedding model robustness** by comparing BGE-m3 diversity selection performance against alternative embedding models (e.g., OpenAI embeddings, Sentence-BERT) on tasks with different semantic structures (text vs. code) to validate the generalizability of the diversity maximization approach.