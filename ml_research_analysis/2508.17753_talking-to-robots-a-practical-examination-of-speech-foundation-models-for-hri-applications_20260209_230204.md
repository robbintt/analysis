---
ver: rpa2
title: 'Talking to Robots: A Practical Examination of Speech Foundation Models for
  HRI Applications'
arxiv_id: '2508.17753'
source_url: https://arxiv.org/abs/2508.17753
tags:
- speech
- recognition
- performance
- accented
- spontaneous
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper evaluates four state-of-the-art ASR models\u2014Whisper-large\
  \ v3, CrisperWhisper, Canary-1B, and Parakeet-TDT-1.1B\u2014across eight public\
  \ datasets covering six challenging dimensions: domain-specific, accented, noisy,\
  \ age-variant (children and elderly), impaired, and spontaneous speech. The study\
  \ measures performance using word error rate (WER) and examines hallucination tendencies\
  \ and bias."
---

# Talking to Robots: A Practical Examination of Speech Foundation Models for HRI Applications

## Quick Facts
- arXiv ID: 2508.17753
- Source URL: https://arxiv.org/abs/2508.17753
- Reference count: 18
- Parakeet-TDT-1.1B achieves best average WER, outperforming others by 10–50%

## Executive Summary
This paper evaluates four state-of-the-art ASR models—Whisper-large v3, CrisperWhisper, Canary-1B, and Parakeet-TDT-1.1B—across eight public datasets covering six challenging dimensions: domain-specific, accented, noisy, age-variant (children and elderly), impaired, and spontaneous speech. The study measures performance using word error rate (WER) and examines hallucination tendencies and bias. Results show wide performance variations, with Parakeet-TDT-1.1B achieving the best average WER, outperforming others by 10–50%. Canary-1B is competitive for spontaneous and noisy speech. Performance degrades significantly in multi-dimensional difficulty cases, especially for impaired, age-variant, and spontaneous speech, with hallucination being a major issue. These findings highlight the need for careful model selection in HRI applications, where recognition errors can impact task effectiveness, user trust, and safety.

## Method Summary
The study evaluates four ASR models (Whisper-large v3, CrisperWhisper, Canary-1B, Parakeet-TDT-1.1B) on eight public datasets representing six difficulty dimensions. Audio is standardized to 16 kHz WAV format and segmented sentence-wise using timestamps. WER is computed on normalized transcripts, with cases exceeding 100% indicating hallucination. Each dataset is mapped to its relevant dimensions, with control speakers and scripted segments excluded where appropriate. The analysis aggregates per-dimension performance by averaging across relevant datasets.

## Key Results
- Parakeet-TDT-1.1B achieves the best average WER, outperforming other models by 10–50%
- Canary-1B shows competitive performance for spontaneous and noisy speech
- Performance degrades significantly when multiple difficulty dimensions coincide
- Hallucination is a major issue, especially for short utterances in HRI contexts

## Why This Works (Mechanism)

### Mechanism 1
Character-based decoding in Transducer models may reduce hallucination frequency compared to subword-based methods. Character-level tokenization constrains output space, limiting the model's ability to generate fluent but incorrect word sequences when facing ambiguous or degraded input.

### Mechanism 2
Performance degradation appears additive when multiple difficulty dimensions coincide. Each deviation from training distribution (e.g., accent + noise + impairment) compounds recognition uncertainty, producing cumulative WER increases rather than isolated errors.

### Mechanism 3
Short utterances disproportionately amplify the measured impact of hallucination. With limited ground-truth tokens, any over-generation dominates WER calculation, potentially exceeding 100% and obscuring semantic correctness.

## Foundational Learning

- **Word Error Rate (WER)**: Primary evaluation metric; WER >100% indicates hallucination (over-generation), which is critical for interpreting results
  - Quick check: If ground truth is "stop" and model outputs "please stop now", what is the WER?

- **Transducer vs. attention-based decoding**: Paper hypothesizes character-based Transducer decoding reduces hallucinations; understanding this distinction clarifies model selection
  - Quick check: What constraint does character-level output impose that subword-level does not?

- **Hallucination in sequence models**: Identified as critical failure mode for HRI safety and trust; language misidentification (Arabic/Korean) is a specific symptom
  - Quick check: How does hallucination differ from a simple substitution error in ASR output?

## Architecture Onboarding

- **Component map**: Audio Input (16kHz WAV) → Preprocessing: format conversion, sentence segmentation → ASR Model Selection → Transcript → WER Evaluation

- **Critical path**:
  1. Standardize audio to 16kHz WAV
  2. Select model based on expected speech characteristics:
     - Impaired/age-variant → Parakeet-TDT-1.1B (86.09 vs. 258.48 WER on impaired)
     - Noisy/spontaneous only → Canary-1B (competitive)
  3. Monitor for language misidentification and character sequence hallucinations

- **Design tradeoffs**:
  - **Parakeet-TDT-1.1B**: Best average WER (10-50% better); unknown real-time latency
  - **Canary-1B**: Better on noisy/spontaneous; severe hallucination on impaired speech
  - **CrisperWhisper**: Trained on CV11 (data contamination marked with *); better timestamps
  - **Whisper-large v3**: High hallucination risk on edge cases

- **Failure signatures**:
  - WER >100% → hallucination/over-generation
  - Random non-Latin character sequences → language misidentification
  - Sharp WER spikes on single-word inputs → short-command vulnerability

- **First 3 experiments**:
  1. Replicate baseline WER on clean held-out data to validate evaluation pipeline
  2. Stress-test with progressively degraded audio to identify hallucination thresholds per model
  3. Evaluate combined-dimension samples (e.g., accented + noisy) to quantify additive penalties in your deployment context

## Open Questions the Paper Calls Out

### Open Question 1
Can the evaluated ASR models maintain real-time latency on standard robotic hardware without significant accuracy degradation? The study evaluates recognition accuracy but does not measure inference speed or computational load.

### Open Question 2
How do specific ASR error types, particularly hallucinations in short commands, quantitatively impact user trust and task safety in live HRI scenarios? The methodology is restricted to offline dataset evaluation and does not measure downstream effects on human-robot interaction.

### Open Question 3
Is the observed reduction in hallucinations for Parakeet-TDT-1.1B universally attributable to its Transducer decoder architecture across diverse difficult dimensions? This is a post-hoc architectural hypothesis based on a limited comparison of model outputs.

## Limitations
- WER poorly captures hallucination severity when over-generation dominates short utterances
- Model selection is complicated by unknown real-time latency characteristics
- Additive penalty hypothesis for multi-dimensional difficulty remains unconfirmed without direct testing

## Confidence

- **High Confidence**: Parakeet-TDT-1.1B achieves superior average WER across all dimensions (10-50% better than alternatives)
- **Medium Confidence**: Character-based Transducer decoding reduces hallucination frequency
- **Medium Confidence**: Performance degradation is additive when multiple difficulty dimensions coincide

## Next Checks

1. **Intent-Level Validation**: Test whether Parrot-TDT's lower WER translates to acceptable command recognition accuracy by evaluating a small set of multi-turn HRI scenarios with semantic similarity metrics alongside WER

2. **Combined-Dimension Stress Test**: Create synthetic test samples combining the most problematic dimensions (e.g., accented + impaired + noisy) to verify the additive penalty hypothesis and identify performance cliffs in your target deployment environment

3. **Latency and Resource Profiling**: Benchmark real-time factor and GPU memory consumption for all four models under identical conditions to ensure Parrot-TDT's accuracy advantage doesn't compromise deployment feasibility in your HRI hardware constraints