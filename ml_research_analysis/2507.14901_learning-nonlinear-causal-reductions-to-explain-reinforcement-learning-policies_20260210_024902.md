---
ver: rpa2
title: Learning Nonlinear Causal Reductions to Explain Reinforcement Learning Policies
arxiv_id: '2507.14901'
source_url: https://arxiv.org/abs/2507.14901
tags:
- causal
- high-level
- linear
- learning
- press
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces nonlinear Targeted Causal Reduction (nTCR)
  to explain reinforcement learning (RL) policies by treating agent-environment interactions
  as a low-level causal model and learning a simplified high-level causal model that
  preserves interventional consistency. The method introduces random perturbations
  to policy actions during execution and observes their effects on cumulative rewards,
  learning interpretable nonlinear reduction functions that summarize the most influential
  factors determining policy success or failure.
---

# Learning Nonlinear Causal Reductions to Explain Reinforcement Learning Policies

## Quick Facts
- arXiv ID: 2507.14901
- Source URL: https://arxiv.org/abs/2507.14901
- Reference count: 40
- Primary result: nTCR explains RL policies through causal abstractions using action perturbations to identify influential factors affecting policy success.

## Executive Summary
This paper introduces nonlinear Targeted Causal Reduction (nTCR) to explain reinforcement learning (RL) policies by treating agent-environment interactions as a low-level causal model and learning a simplified high-level causal model that preserves interventional consistency. The method introduces random perturbations to policy actions during execution and observes their effects on cumulative rewards, learning interpretable nonlinear reduction functions that summarize the most influential factors determining policy success or failure. Theoretical analysis establishes uniqueness and existence guarantees for exact solutions under specific conditions. Experiments on synthetic causal models demonstrate the method's ability to identify ground-truth solutions with near-zero consistency loss. Applied to a pendulum swing-up task, nTCR uncovers unexpected policy biases (e.g., better performance with clockwise vs. counterclockwise motion) and identifies actionable improvements (e.g., applying more negative torque at critical moments). In a robot table tennis simulation, the method reveals specific ball trajectories and racket positions that lead to successful returns versus failures, identifying that balls traveling toward the table edge and bouncing closer to the net present greater challenges. The approach provides interpretable policy-level explanations that can guide more efficient training regimes and enable improvements to policy architecture or learning algorithms.

## Method Summary
nTCR learns interpretable high-level causal models from low-level RL interactions by introducing shift interventions on policy actions and measuring their effects on cumulative rewards. The method constructs a low-level causal model from perturbed episodes and learns reduction maps τ₁ and ω₁ that preserve interventional consistency with a high-level causal model H(Y,Z). A normality regularization term encourages the high-level cause Z to remain approximately Gaussian for interpretability. The approach uses an interpretable function class with Gaussian kernels for nonlinear transformations and optimizes a total loss combining consistency loss (divergence between push-forward and high-level distributions) and normality loss (Wasserstein distance to standard normal). The framework establishes theoretical uniqueness guarantees for exact solutions under specific additive noise structural causal model assumptions.

## Key Results
- nTCR achieves near-zero consistency loss on synthetic causal models with known ground truth, validating its ability to recover exact solutions
- Applied to pendulum swing-up, the method identifies that policies perform better with clockwise vs. counterclockwise motion and suggests applying more negative torque at critical moments
- In robot table tennis simulation, nTCR reveals that balls traveling toward table edges and bouncing closer to the net are more challenging, providing specific actionable insights for policy improvement

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Random perturbations to policy actions enable causal probing of agent-environment interactions.
- Mechanism: By applying shift interventions δAt ~ N(0, σt) to actions before execution, the method constructs a low-level causal model where the interventions' downstream effects on cumulative reward can be observed. This transforms the RL episode into a causal graph amenable to analysis.
- Core assumption: The intervention distribution is sufficiently broad relative to exogenous noise to produce detectable signal in the target (per Appendix D and Fig. D normality regularization analysis).
- Evidence anchors:
  - [abstract]: "We introduce random perturbations to policy actions during execution and observe their effects on the cumulative reward"
  - [section 3]: "These perturbations serve as shift interventions in our causal framework and allow us to observe how deviations from the policy's intended actions propagate to the cumulative reward."
  - [corpus]: Weak direct corpus support for this specific mechanism; related work on causal RL focuses on confounding rather than explanation through perturbation.
- Break condition: If intervention variance is too small relative to task noise, the causal signal becomes indistinguishable and learned reductions may overfit to spurious patterns.

### Mechanism 2
- Claim: Interventional consistency between low-level and high-level models yields meaningful causal explanations.
- Mechanism: The consistency loss Lcons minimizes divergence between (i) push-forward distributions of the intervened low-level model and (ii) corresponding high-level model distributions. This forces the learned reduction maps to preserve causal relationships rather than merely correlational patterns.
- Core assumption: A constructible transformation exists where high-level interventions ω(i) meaningfully correspond to low-level interventions i.
- Evidence anchors:
  - [section 2.3]: "TCR forces explanations to flow through the learned high-level cause Z... ω shows which types of interventions most effectively change these properties."
  - [section 4.1]: Theoretical uniqueness guarantee (Proposition 4.1) under additive noise SCM with non-vanishing Fourier transform.
  - [corpus]: "Causal Abstraction Inference under Lossy Representations" (arXiv 2509.21607) provides related theoretical grounding for low-level to high-level causal mappings.
- Break condition: If the low-level SCM violates additive noise assumptions or has vanishing Fourier characteristics, uniqueness is not guaranteed and multiple competing explanations may exist.

### Mechanism 3
- Claim: Normality regularization prevents overfitting in high-noise regimes and maintains interpretability.
- Mechanism: The Wasserstein distance between standardized push-forward distributions and standard normal (Lnorm) constrains the high-level cause to remain approximately Gaussian. This prevents the nonlinear function class from exploiting flexibility to artificially minimize consistency loss through multi-modal distributions.
- Core assumption: A unimodal Gaussian high-level cause distribution is more interpretable and aligns with the theoretical high-level model specification.
- Evidence anchors:
  - [section 4.1]: "normality regularization encouraging τ1(X) to be Gaussian... allows for easier interpretation of the learned causes"
  - [appendix F.1, Fig. D]: "normality regularization has the strongest beneficial effect in the high-noise regime, where it substantially improves the identification of ground truth solutions"
  - [corpus]: No direct corpus comparison for this specific regularization technique.
- Break condition: If ηnorm is set too high, it may suppress legitimate multi-modal causal structure; if too low, learned causes become uninterpretable.

## Foundational Learning

- Concept: **Structural Causal Models (SCMs)**
  - Why needed here: The entire framework formalizes RL episodes as SCMs with structural equations, exogenous variables, and interventions. Without this foundation, the notions of "interventional consistency" and "causal reduction" are unintelligible.
  - Quick check question: Given an SCM with structural equation X := f(Pa_X, U_X), what happens to the joint distribution when we perform a shift intervention X := f(Pa_X, U_X) + δ?

- Concept: **Push-forward Distributions**
  - Why needed here: The consistency loss is defined in terms of τ#[PL], the push-forward of the low-level distribution through the reduction map. Understanding how deterministic transformations induce distributional changes is essential.
  - Quick check question: If X ~ N(μ, Σ) and τ(x) = Ax + b, what is the distribution of τ(X)?

- Concept: **KL Divergence and Gaussian Approximation**
  - Why needed here: Linear TCR uses a Gaussian KL-divergence approximation that only matches first and second moments. Understanding why this is insufficient (necessitating normality regularization) requires facility with information geometry.
  - Quick check question: Why does minimizing KL(N(μ₁,Σ₁) || N(μ₂,Σ₂)) not guarantee that the first distribution is Gaussian if we're optimizing over arbitrary distributions?

## Architecture Onboarding

- Component map: [RL Policy] → [Environment] → [Episodes with Shift Interventions] → [Low-level SCM Variables X] → [Reduction Maps τ₁, ω₁] ← [Normality Regularizer] → [High-level Cause Z] → [Consistency Loss vs. High-level Model H]

- Critical path:
  1. **Data collection**: Generate N_int distinct interventions, N_ep episodes per intervention. For pendulum: N_int=100,000, N_ep=100.
  2. **Feature encoding**: Apply Gaussian kernels ϕ_{j,t}(x) = exp(-(x-μ_{j,t})²/2σ²_{j,t}) to each feature-time pair. Pendulum uses 128 kernels per variable-time pair.
  3. **Optimization loop**: Minimize L_total = L_cons + η_norm · L_norm using Adam with cosine annealing. Batch over interventions, not episodes.

- Design tradeoffs:
  - **Intervention strength (σ)**: Too low → insufficient causal signal; too high → destroys policy behavior. Paper selects at threshold where performance degrades (Fig. A).
  - **Kernel count vs. memory**: More kernels improve resolution but scale memory. Table tennis uses 32 kernels (vs. 128 for pendulum) due to GPU constraints.
  - **Normality weight (η_norm)**: Paper uses 10 for pendulum, 1.0 for synthetic. Higher values crucial in high-noise regimes (Fig. D).

- Failure signatures:
  - **Consistency loss plateaus without converging**: Intervention variance too low; increase σ.
  - **Learned τ-maps show chaotic/unstructured patterns**: Normality regularization too weak or function class over-parameterized; increase η_norm or reduce kernel count.
  - **Identification loss remains high despite low consistency loss**: Potential non-identifiability; verify low-level SCM satisfies Proposition 4.1 assumptions.

- First 3 experiments:
  1. **Synthetic validation**: Generate data from known SCM satisfying Proposition 4.2 structure. Verify near-zero consistency loss and low identification loss against ground truth τ*, ω*.
  2. **Ablation on normality regularization**: Train with η_norm ∈ {0, 0.1, 1.0, 10} across low/medium/high noise regimes. Confirm regularization benefit is strongest in high-noise setting.
  3. **Policy explanation on simple domain**: Train PPO on Pendulum, collect intervention data, learn nTCR. Verify discovered asymmetries (e.g., clockwise vs. counterclockwise performance) by comparing mean rewards across predicted high/low Z quintiles.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can the uniqueness and existence guarantees for exact nonlinear causal reductions be extended beyond the specific model class defined in Propositions 4.1 and 4.2 to more general nonlinear causal models?
  - Basis in paper: [explicit] "However, those are limited to the class of nonlinear causal models presented in Props. 4.1 and 4.2, and extending these guarantees to more general model classes should be addressed by future work."
  - Why unresolved: Current proofs rely on specific structural assumptions (additive noise with Gaussian exogenous variables and linear mixing through matrix B) that enable analytic solutions.
  - What evidence would resolve it: A generalization of Propositions 4.1 and 4.2 to broader function classes, or counterexamples showing identifiability fails without current constraints.

- **Open Question 2**: How can nTCR be adapted to handle discrete action spaces common in many RL settings?
  - Basis in paper: [explicit] "However, there are no fundamental restrictions preventing the use of other interventions more adapted to discrete action spaces, which are common in many RL settings. Those could be implemented as perturbations of the continuous parameters controlling the policy function used to sample discrete actions."
  - Why unresolved: Current formulation relies on shift interventions that require continuous action spaces; discrete actions pose fundamental challenges for perturbation-based intervention design.
  - What evidence would resolve it: A modified intervention scheme (e.g., Gumbel-softmax perturbations) with corresponding theoretical analysis and empirical validation on discrete-action RL benchmarks.

- **Open Question 3**: What preprocessing or architectural modifications enable nTCR to handle high-dimensional, unstructured state representations such as image inputs?
  - Basis in paper: [explicit] "More complex or less structured state/action data, such as for policies leveraging image inputs may require additional steps for representing them appropriately, e.g. segmentation methods or saliency maps."
  - Why unresolved: The Gaussian kernel-based interpretable function class assumes structured, low-dimensional features; raw pixels lack the temporal-feature decomposition the method exploits.
  - What evidence would resolve it: Demonstration of nTCR applied to vision-based RL tasks (e.g., Atari) with comparison of different state preprocessing approaches and their impact on explanation interpretability.

- **Open Question 4**: How does dropping the linear additive Gaussian high-level model assumption affect both interpretability and identifiability of the learned causal reductions?
  - Basis in paper: [explicit] "Notably, dropping the linear and Gaussian high-level model assumptions may be needed in some applications, although it poses further interpretability challenges."
  - Why unresolved: The Gaussian assumption enables tractable optimization and clear interpretation of the high-level cause Z; non-Gaussian models introduce additional complexity in both learning and explanation.
  - What evidence would resolve it: Empirical comparison of nTCR variants with flexible high-level distributions on tasks where the true causal structure is known to be non-Gaussian, measuring consistency loss and explanation quality.

## Limitations

- **Empirical scope**: The method is validated on two simulated domains (pendulum and table tennis) without real-world policy testing, limiting confidence in real-world applicability.
- **Computational cost**: Requires massive data collection - 100,000 interventions × 100 episodes each for pendulum, totaling 10 million episodes, which limits scalability to more complex domains.
- **Theoretical assumptions**: Uniqueness guarantees rely on additive noise SCMs with non-vanishing Fourier transforms, which may not hold for real-world policies.

## Confidence

- **High confidence**: The core mechanism of using interventions to probe causal structure (Mechanism 1) and the consistency loss formulation are well-grounded.
- **Medium confidence**: The theoretical guarantees under specific SCM assumptions are sound, but their practical applicability to learned RL policies is uncertain.
- **Low confidence**: Real-world generalization, computational scalability, and the specific implementation details of the discrepancy function for nTCR.

## Next Checks

1. **Cross-domain robustness**: Apply nTCR to a third RL task (e.g., CartPole or LunarLander) with varying policy architectures (CNN vs MLP) to test generalizability across domains and architectures.

2. **Real-world pilot**: Implement a small-scale physical experiment (e.g., robot arm reaching) to validate whether nTCR explanations transfer from simulation to reality.

3. **Theoretical relaxation**: Test the framework on SCMs that violate additive noise assumptions (e.g., multiplicative noise) to quantify the sensitivity of identification guarantees to assumption violations.