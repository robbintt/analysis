---
ver: rpa2
title: 'SUGAR: A Sweeter Spot for Generative Unlearning of Many Identities'
arxiv_id: '2512.06562'
source_url: https://arxiv.org/abs/2512.06562
tags:
- identities
- unlearning
- identity
- forgetting
- guide
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of removing multiple identities
  from a generative model without retraining. It introduces SUGAR, which uses a learnable
  de-identification process to map each forgotten identity to a personalized surrogate
  target in latent space.
---

# SUGAR: A Sweeter Spot for Generative Unlearning of Many Identities

## Quick Facts
- arXiv ID: 2512.06562
- Source URL: https://arxiv.org/abs/2512.06562
- Reference count: 40
- Primary result: Up to 700% improvement in retention utility (ID and FID scores) when unlearning up to 200 identities from generative models

## Executive Summary
This paper introduces SUGAR, a method for removing multiple identities from pretrained generative models without retraining. Unlike existing approaches that either collapse forgotten identities to a mean face or require full model retraining, SUGAR learns personalized surrogate targets for each forgotten identity in latent space. The method employs a two-phase pipeline: first training a de-identification network to map each identity to a counterfactual surrogate, then fine-tuning the generator with remapping loss, neighbor consistency, and EWC regularization to preserve retained identity quality.

## Method Summary
SUGAR operates on pretrained 3D-aware GANs (EG3D) using a frozen inversion network (GOAE) to map images to latent codes. The method learns a U-Net de-identification network T_Θ that transforms each forgotten identity vector w_id into a personalized surrogate target w_t^id. During the forgetting phase, the generator is fine-tuned using a combination of remapping loss (forcing forgotten identities toward their surrogates), neighbor remapping loss (ensuring consistency across local latent neighborhoods), and EWC regularization (protecting parameters important for retained identities via Fisher Information Matrix computation over vicinity samples).

## Key Results
- Achieves up to 700% improvement in retention utility (ID and FID scores) over baselines when unlearning up to 200 identities
- Maintains visual quality of retained identities while effectively removing forgotten identities (low ID similarity to source)
- Outperforms single-identity unlearning methods by learning personalized surrogates rather than collapsing to mean-face templates
- Successfully handles both simultaneous and sequential unlearning requests

## Why This Works (Mechanism)

### Mechanism 1: Personalized Surrogate Generation
Mapping forgotten identities to learned, personalized surrogates preserves visual coherence better than collapsing to noise or a fixed template. A de-identification network T_Θ learns to transform each identity vector w_id into a counterfactual identity w_t^id. The surrogate target w_t = w̄ − d · (T_Θ(w_id)/||T_Θ(w_id)||) displaces from the mean identity along a learned direction, scaled by distance parameter d. This preserves coarse attributes (pose, lighting, gender) while altering identity-specific features.

### Mechanism 2: EWC Regularization for Retention
EWC regularization applied to vicinity samples protects nearby retained identities from collateral degradation. Fisher Information Matrix (FIM) is computed over vicinity probe set fW (samples on a spherical shell around each forgotten latent). The EWC penalty constrains parameters critical for reconstructing these probes to remain near pre-unlearning values.

### Mechanism 3: Neighbor Remapping for Consistent Forgetting
Neighbor remapping loss enforces consistent forgetting across the local latent neighborhood, preventing partial identity recovery. For each forgotten latent w_u, a perturbed neighbor w_{u,a} is sampled. Both anchor and neighbor are mapped to their respective surrogate targets via Θ, and L_forget applies remapping loss to both.

## Foundational Learning

- **GAN Latent Space and Inversion**: Understanding that w = E_ψ(x) encodes identity and that the generator G_θ(w) produces images is essential to grasp how de-identification and remapping work.
  - Quick check: Given a face image x, what does the encoder output and how does the generator use it?

- **Continual Learning and Catastrophic Forgetting**: Sequential unlearning requests require the model to forget new identities without forgetting previous forgetting (retained identity preservation). EWC is a continual learning technique adapted here for unlearning.
  - Quick check: What happens to a neural network's performance on task A when fine-tuned on task B without regularization?

- **Elastic Weight Consolidation (EWC)**: The FIM-weighted penalty prevents parameters important for retained identities from drifting. Understanding why some parameters are "important" (high gradient sensitivity) clarifies the retention mechanism.
  - Quick check: How does EWC decide which parameters to protect, and what does the Fisher Information capture?

## Architecture Onboarding

- **Component map**: E_ψ (frozen encoder/inversion network) -> T_Θ (learnable de-identification network) -> G_θ (EG3D generator being fine-tuned) -> R (frozen renderer)
- **Critical path**: Phase 1: Train T_Θ using L_de on forgetting set W_u (200 epochs, batch size 2); Phase 2: Compute FIM over vicinity probes fW using frozen source model; Phase 3: Fine-tune G_θ using L_unlearn = L_forget + λ_ewc · L_ewc; For sequential unlearning: iterate Phase 2-3 with cumulative forget sets
- **Design tradeoffs**:
  - Distance d: Higher values retain more original features (softer forgetting), lower values increase identity separation but risk artifacts. Paper uses d=25.
  - λ_nei: Controls neighbor remapping strength. Too low → incomplete forgetting; too high → over-regularization. Paper uses 0.1.
  - α_r (vicinity radius): Controls how far from forgotten latents to protect. Paper uses 30.
- **Failure signatures**:
  - Mean-face collapse: All forgotten identities produce near-identical outputs → T_Θ has mode collapsed
  - Retained identity degradation: High FID on retain set → EWC weight λ_ewc too low or vicinity radius α_r too small
  - Incomplete forgetting: High ID similarity on forget set → T_Θ not producing sufficiently distinct counterfactuals
- **First 3 experiments**:
  1. Single-identity unlearning: Unlearn one identity, verify surrogate is visually distinct while retained set FID stays within 5% of baseline
  2. Ablate L_nei: Remove neighbor loss, confirm that unseen images of forgotten identities show residual identity features
  3. Sequential stress test: Run 4 sequential unlearning stages with 2 identities each, measure retained ID/FID degradation per stage

## Open Questions the Paper Calls Out

### Open Question 1
How can the de-identification framework be natively adapted for text-conditioned diffusion models where identity information is distributed across token embeddings and cross-attention layers? The current architecture relies on a frozen image encoder and does not inherently handle the disentanglement of text-image associations found in latent diffusion models.

### Open Question 2
What quantitative metric or ID score threshold definitively constitutes "sufficient forgetting" that aligns with human perception? The paper relies on human judgment studies to verify unlearning but does not establish a universal mathematical boundary for when an identity is effectively removed versus just altered.

### Open Question 3
How robust is the latent remapping against adaptive adversarial attacks designed specifically to reverse the de-identification process? While the method avoids static templates, a dedicated adaptive attacker might still identify the specific transformation signature Θ applied to the forgotten identities.

## Limitations
- Effectiveness validated only on controlled datasets (FFHQ, CelebA-HQ), not on truly out-of-distribution faces or non-facial identities
- Sequential unlearning performance after many cycles (>4) is not explored, potentially masking gradual utility degradation
- No explicit privacy guarantees provided; membership inference or reconstruction attacks on the unlearning process are not addressed

## Confidence
- **High confidence**: Multi-identity unlearning improves over single-identity baselines (supported by quantitative metrics: 700% ID reduction, stable FID retention)
- **Medium confidence**: Personalized surrogate generation preserves visual coherence better than collapsing to mean-face (qualitative support in Figure 5; quantitative via human study)
- **Medium confidence**: EWC regularization prevents collateral degradation of nearby retained identities (supported by comparison to "Ours-v1" and stable FID on retain set)

## Next Checks
1. Test SUGAR on truly out-of-distribution identities (e.g., non-Western faces, animal faces) to confirm latent space mappings remain meaningful and unlearning is effective beyond the training domain
2. Perform ablation on the de-identification network capacity (smaller U-Net) to determine if the gains scale with model size or are robust to architectural constraints
3. Conduct a membership inference attack on the unlearning model to assess whether the unlearning process itself leaks information about forgotten identities, providing privacy guarantees beyond identity score reduction