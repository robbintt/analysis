---
ver: rpa2
title: Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy
  Recommendation
arxiv_id: '2507.10911'
source_url: https://arxiv.org/abs/2507.10911
tags:
- clinical
- conflicts
- case
- systems
- ratio
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explored LLM-based multi-agent systems for therapy recommendations
  in multimorbidity cases, simulating multidisciplinary team collaboration. Four LLM
  models were evaluated using a conflict resolution workflow involving a general practitioner
  coordinating specialist agents.
---

# Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation

## Quick Facts
- **arXiv ID**: 2507.10911
- **Source URL**: https://arxiv.org/abs/2507.10911
- **Reference count**: 0
- **Primary result**: Multi-agent LLM systems show promise in reducing therapy recommendation conflicts while maintaining medication levels, though current LLMs have limitations in completeness and clinical reasoning.

## Executive Summary
This study evaluates LLM-based multi-agent systems for therapy recommendations in complex multimorbidity cases, simulating multidisciplinary team collaboration. The research compares four LLM models using a conflict resolution workflow where a general practitioner coordinates specialist agents. Results show that multi-agent systems can effectively reduce conflicts while maintaining medication levels and aligning with expert judgment. However, the study reveals that current LLMs have significant limitations in completeness and clinical reasoning, with most errors being omissions rather than incorrect recommendations.

## Method Summary
The study developed a systematic conflict resolution workflow where a general practitioner LLM coordinates with specialist agents (e.g., cardiologists, endocrinologists) to generate therapy recommendations for patients with multiple chronic conditions. Four different LLM models were evaluated using synthetic patient data representing 100 cases of multimorbidity. The evaluation framework included metrics for correctness, completeness, drug-drug interaction ratio, contraindication ratio, and medication ratio. The approach specifically tested whether multi-agent collaboration could improve upon single-agent therapy recommendations by reducing conflicts between specialist recommendations.

## Key Results
- Multi-agent systems showed promise in reducing conflicts while maintaining medication levels compared to single-agent approaches
- Single-agent systems with intermediate reasoning performed comparably to multi-agent systems across most evaluation metrics
- Most LLM errors were omissions rather than commissions, indicating conservative but incomplete recommendations
- Current LLMs demonstrated obvious limitations in completeness and clinical reasoning capabilities

## Why This Works (Mechanism)
Multi-agent systems work by distributing specialized knowledge across different LLM agents, each representing a medical specialty, while a coordinating agent resolves conflicts and ensures holistic patient care. This approach mimics real-world multidisciplinary team dynamics where specialists provide input that is then synthesized by a primary care physician. The mechanism relies on the LLM's ability to maintain contextual awareness across multiple domains while the conflict resolution workflow ensures that recommendations don't contradict each other, potentially reducing dangerous drug interactions or contraindications that might arise from uncoordinated specialist input.

## Foundational Learning
- **Synthetic patient generation**: Creating representative multimorbidity cases for testing therapy recommendations without risking real patient safety; quick check: verify distribution of conditions matches real-world prevalence patterns.
- **Conflict resolution workflow**: Structured approach for resolving contradictory recommendations from different specialist agents; quick check: ensure resolution criteria are clinically sound and consistently applied.
- **Multi-agent coordination**: System design where different LLMs specialize in different domains while maintaining overall coherence; quick check: validate that the coordinating agent properly integrates all specialist inputs.
- **Evaluation metrics for therapy recommendations**: Quantitative measures including correctness, completeness, DDI ratio, contraindication ratio, and medication ratio; quick check: confirm metrics align with clinical safety priorities.
- **Intermediate reasoning levels**: Finding that moderate-depth reasoning outperforms both shallow and excessive reasoning; quick check: test consistency across different clinical scenarios.

## Architecture Onboarding
**Component Map**: GP Agent -> Specialist Agents (Cardiology, Endocrinology, etc.) -> Conflict Resolution Module -> Final Recommendation

**Critical Path**: Patient case input → Specialist assessments → GP coordination → Conflict identification → Resolution → Final therapy recommendation

**Design Tradeoffs**: 
- Multiple agents increase complexity but improve specialization
- Conflict resolution adds safety but increases computational overhead
- Synthetic data enables safe testing but may not capture real-world complexity

**Failure Signatures**: 
- Omissions of critical medications
- Incomplete clinical reasoning chains
- Inconsistent application of medical guidelines across agents
- Over-reliance on single-agent recommendations despite availability of multi-agent options

**First 3 Experiments**:
1. Compare single-agent vs. multi-agent recommendations on identical synthetic cases to quantify conflict reduction
2. Test different reasoning depths to identify optimal balance between thoroughness and efficiency
3. Evaluate error types (omissions vs. commissions) to understand safety profile and areas for improvement

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation conducted on synthetic dataset of 100 simulated patients rather than real clinical cases
- Simplified model of actual multidisciplinary team dynamics
- Current LLMs show obvious limitations in completeness and clinical reasoning
- Small sample size and limited diversity in clinical scenarios

## Confidence
- **High confidence**: Comparative performance between single-agent and multi-agent systems is robust within controlled environment
- **Medium confidence**: Generalizability to actual clinical practice is uncertain due to synthetic evaluation dataset
- **Low confidence**: Long-term reliability and safety of LLM-based therapy recommendation systems cannot be determined from this framework

## Next Checks
1. Test the multi-agent system on actual patient cases from electronic health records with input from practicing clinicians to assess practical utility and safety
2. Conduct detailed analysis of omission patterns to understand whether critical medication interactions or contraindications are being missed systematically
3. Evaluate system performance with larger, more diverse patient populations and more complex multimorbidity scenarios to determine robustness limits