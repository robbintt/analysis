---
ver: rpa2
title: 'HouseTour: A Virtual Real Estate A(I)gent'
arxiv_id: '2510.18054'
source_url: https://arxiv.org/abs/2510.18054
tags:
- trajectory
- camera
- generation
- video
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HouseTour is a method for generating spatially-aware 3D camera
  trajectories and natural language summaries from a set of posed images. It combines
  a diffusion-based trajectory planner (Residual Diffuser) with a vision-language
  model enhanced for 3D reasoning (Qwen2-VL-3D) to create smooth, human-like navigation
  paths and detailed real estate descriptions.
---

# HouseTour: A Virtual Real Estate A(I)gent

## Quick Facts
- **arXiv ID**: 2510.18054
- **Source URL**: https://arxiv.org/abs/2510.18054
- **Reference count**: 40
- **Primary result**: Achieves SLS score of 76.0 vs baseline 71.7, outperforming Catmull-Rom spline + VLM on translation recall, rotation accuracy, and textual preference.

## Executive Summary
HouseTour generates spatially-aware 3D camera trajectories and natural language summaries from posed RGB images for automated real estate video tours. The system combines a diffusion-based trajectory planner (Residual Diffuser) with a vision-language model enhanced for 3D reasoning (Qwen2-VL-3D). Trained on 1,200+ house-tour videos with 3D reconstructions and professional descriptions, HouseTour outperforms baselines on trajectory accuracy and summary quality metrics. The approach enables high-quality virtual tours without specialized equipment, though dataset availability and reconstruction quality pose challenges for reproduction.

## Method Summary
HouseTour operates in two stages: first, a 1D U-Net-based Residual Diffuser predicts camera trajectory residuals relative to Catmull-Rom spline baselines, trained with L2 and geodesic losses on uniformly sampled dense points. Second, Qwen2-VL-7B is fine-tuned via LoRA (rank/alpha=64) for 20 epochs, with an adapter mapping diffusion bottleneck features plus denoised poses to language tokens. The system processes sparse camera poses with RGB frames, generating smooth camera paths and detailed real estate descriptions. Special tokens (<|traj_start|>, <|traj_pad|>, <|traj_end|>) manage trajectory boundaries during generation.

## Key Results
- SLS score: 76.0 (HouseTour) vs 71.7 (baseline) - harmonic mean of trajectory and summary quality
- Trajectory generation: superior recall@k (R@50cm/75cm/1m), lower Chamfer/Fréchet distances vs Catmull-Rom interpolation
- Scene summaries: better capture layout, materials, ambiance; higher BLEU/ROUGE-L/CIDEr scores
- VLM performance: reduced hallucinations when using temperature scaling (T=0.3) for out-of-distribution scenes

## Why This Works (Mechanism)
The method succeeds by combining geometric trajectory planning with semantic scene understanding. The Residual Diffuser adds human-like smoothness to trajectories by predicting deviations from rigid spline paths, while Qwen2-VL-3D's spatial adapter integrates 3D pose information with visual features for context-aware descriptions. This decoupling allows specialized optimization of each component while maintaining spatial coherence across the pipeline.

## Foundational Learning
- **3D reconstruction with COLMAP**: Estimates camera poses and sparse point clouds from image sequences. Needed for ground truth trajectory data and 3D spatial context. Quick check: Verify reconstruction completeness and scale alignment using Mast3r depth ratios.
- **Diffusion models for trajectory generation**: Predict residuals to improve rigid spline paths. Needed for smooth, human-like camera movements. Quick check: Compare predicted trajectories against ground truth poses using recall@k and Chamfer distance.
- **Vision-language model fine-tuning**: Adapts pre-trained VLMs to real estate domain. Needed for generating detailed, contextually accurate scene descriptions. Quick check: Evaluate generated descriptions against professional transcripts using BLEU/ROUGE-L/CIDEr scores.

## Architecture Onboarding

**Component Map**: Posed RGB images → COLMAP reconstruction → Residual Diffuser → Dense trajectory → Qwen2-VL-3D spatial adapter → Natural language summary

**Critical Path**: Input poses → Residual Diffuser → Qwen2-VL-3D with spatial adapter → Output summary. The trajectory generation must be spatially accurate before language generation can produce meaningful descriptions.

**Design Tradeoffs**: Decoupled trajectory vs. language generation allows specialized optimization but may miss semantic guidance for camera paths. Temperature scaling (T=0.3) reduces hallucinations but indicates model bias toward training distribution.

**Failure Signatures**: 40% dataset rejection due to reconstruction failures; VLM hallucinations mentioning non-existent rooms; scale mismatches between predicted and ground truth trajectories. Common failure modes include incomplete COLMAP reconstructions and regional vocabulary bias in descriptions.

**First Experiments**: 1) Validate 3D reconstruction pipeline on sample videos and measure scale alignment accuracy. 2) Train Residual Diffuser with varying sparse pose frequencies (5-15 frames) and evaluate trajectory smoothness. 3) Fine-tune Qwen2-VL-7B with spatial adapter and test description accuracy on validation scenes.

## Open Questions the Paper Calls Out

1. **Semantic Trajectory Guidance**: Can VLM-derived semantic information jointly guide the trajectory diffusion process to produce semantically-aware camera paths? Current approach decouples trajectory from language generation, missing opportunities for semantic awareness of content that should be highlighted.

2. **Gaussian Splatting for Sparse Views**: Can Gaussian splatting methods fill gaps between sparse input images without generating non-existent content? Current approach excludes sparse-view synthesis, relying on all ground-truth poses for visualization.

3. **OOD Generalization Without Temperature Scaling**: Can the method generalize to out-of-distribution architectural styles without requiring temperature scaling adjustments? Model exhibits domain-specific priors that don't transfer to OOD scenes like offices without manual intervention.

4. **Dataset Bias and Regional Generalization**: How does the dataset bias toward upscale properties in a specific region affect generalization to diverse architectural styles and lower-end real estate? Linguistic analysis shows regional vocabulary tied to specific preferences, potentially limiting applicability elsewhere.

## Limitations

- Dataset availability uncertain - HouseTour dataset claimed but URL may not be live
- Heavy reliance on 3D reconstruction quality - 40% of data discarded due to failures
- Architecture specifications incomplete - U-Net channel dimensions and exact configurations unspecified
- Regional bias - dataset skewed toward upscale properties in specific geographic area

## Confidence

- **High confidence**: Trajectory generation results and architectural choices (Residual Diffuser + Catmull-Rom baseline, evaluation metrics like recall@k, Chamfer/Fréchet distances)
- **Medium confidence**: Qwen2-VL-3D fine-tuning procedure and spatial adapter effectiveness
- **Medium confidence**: End-to-end SLS metric as comprehensive evaluation measure

## Next Checks

1. **Dataset Acquisition and Quality**: Verify HouseTour dataset availability or reproduce the dataset creation pipeline using COLMAP + Mast3r reconstruction and Whisper transcription. Measure reconstruction success rate and scale alignment accuracy across diverse property types.

2. **Architecture Specification Completion**: Reconstruct missing U-Net architectural details (channel dimensions, 1D convolution configurations) by reverse-engineering from reported parameter counts and GPU memory usage, then validate against baseline performance.

3. **VLM Hallucination Robustness**: Test Qwen2-VL-3D's scene description accuracy on held-out validation sets with known ground truth descriptions. Quantify hallucination rates for objects not present in scenes and evaluate the effectiveness of temperature scaling (T=0.3 for OOD) in mitigating this failure mode.