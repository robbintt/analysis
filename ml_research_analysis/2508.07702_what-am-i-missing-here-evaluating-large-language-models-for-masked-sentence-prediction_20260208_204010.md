---
ver: rpa2
title: 'What am I missing here?: Evaluating Large Language Models for Masked Sentence
  Prediction'
arxiv_id: '2508.07702'
source_url: https://arxiv.org/abs/2508.07702
tags:
- sentence
- fidelity
- masked
- gemini
- claude
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper evaluates how well commercial LLMs perform masked sentence
  prediction (MSP), a task requiring them to infill a randomly removed sentence while
  maintaining fidelity to the original content and cohesion with the surrounding context.
  The authors test GPT-4o, Claude 3.5 Sonnet, and Gemini 2.0 Flash on three domains:
  ROCStories (narrative), Recipe1M (procedural), and Wikipedia (expository).'
---

# What am I missing here?: Evaluating Large Language Models for Masked Sentence Prediction

## Quick Facts
- **arXiv ID**: 2508.07702
- **Source URL**: https://arxiv.org/abs/2508.07702
- **Authors**: Charlie Wyatt; Aditya Joshi; Flora Salim
- **Reference count**: 7
- **Primary result**: LLMs achieve moderate fidelity in masked sentence prediction, with structured domains easier to reconstruct but human preference showing inverse relationship with fidelity scores

## Executive Summary
This paper evaluates commercial LLMs (GPT-4o, Claude 3.5 Sonnet, Gemini 2.0 Flash) on masked sentence prediction across three domains: ROCStories, Recipe1M, and Wikipedia. The task requires models to infill a randomly removed sentence while maintaining both fidelity to the original content and cohesion with surrounding context. Results show that while models achieve moderate automatic fidelity scores, human evaluators often prefer generated sentences over originals, especially in open-ended domains. The study reveals an inverse relationship between fidelity and perceived cohesion, suggesting NTP training creates systematic limitations for long-range coherence tasks.

## Method Summary
The authors test MSP by replacing a target sentence with `<|mask id|>` token and prompting LLMs to fill the gap with specific instructions. They use 400 documents from three domains (ROCStories, Recipe1M, Wikipedia), segmenting sentences via spaCy en_core_web_sm. Fidelity is measured using BLEURT, SBERT cosine similarity, ROUGE-1, and BLEU against ground truth sentences. Human preference tests compare original vs. generated sentences in blind evaluations. The study varies mask position (first/middle/last) and density (1-3 contiguous sentences) to analyze positional effects and task difficulty scaling.

## Key Results
- BLEURT scores rarely exceed 0.55, indicating moderate fidelity reconstruction
- Structured domains (Recipe1M) show higher fidelity than open-ended domains (ROCStories, Wikipedia)
- Human evaluators often prefer generated sentences over originals, especially in open domains
- Inverse relationship between fidelity and cohesion: higher fidelity in structured domains correlates with higher human preference for original sentences
- Middle-position masking yields best performance due to bidirectional context

## Why This Works (Mechanism)

### Mechanism 1: Domain Structure Constraints
- Claim: Structured domains constrain the solution space for sentence infilling
- Mechanism: Procedural text (recipes) has predictable sequential dependencies that reduce uncertainty compared to narrative/expository text
- Core assumption: Reconstruction ability correlates with domain constraint level
- Evidence: Structured domains consistently yield higher fidelity; fidelity declines as more steps are masked
- Break condition: If fidelity remains high in structured domains even when task-relevant constraints are removed

### Mechanism 2: Bidirectional Context Advantage
- Claim: Bidirectional context improves sentence prediction
- Mechanism: Masking middle sentences provides both upward and downward discourse constraints
- Core assumption: LLMs can perform inference approximating "what must have been said"
- Evidence: Middle positions yield highest BLEURT scores across all domains
- Break condition: If advantage disappears when succeeding context is shuffled

### Mechanism 3: NTP Fidelity-Cohesion Trade-off
- Claim: NTP training creates optimization for local plausibility over faithful reconstruction
- Mechanism: NTP rewards fluent continuation but provides no signal to prefer original sentence
- Core assumption: Humans tolerate semantic drift in open contexts but not in procedural contexts
- Evidence: Inverse relationship between fidelity and cohesion across domains
- Break condition: If fine-tuning on MSP objectives improves fidelity without degrading cohesion

## Foundational Learning

- **Concept**: Next Token Prediction (NTP) as unsupervised objective
  - Why needed: Explains why models can be fluent but incoherent
  - Quick check: Given "The chef added salt, then [MASK]," what does NTP optimize for, and what does it ignore?

- **Concept**: Masked Language Modeling (MLM) vs. NTP
  - Why needed: MSP is sentence-level analog of MLM; asks if NTP models can approximate MLM behavior
  - Quick check: How does MLM's bidirectional context differ from NTP's unidirectional conditioning?

- **Concept**: Fidelity vs. Cohesion as evaluation dimensions
  - Why needed: Paper's key insight is these metrics can diverge
  - Quick check: If a model generates "The car wouldn't start" instead of "The battery was dead," is this fidelity failure, cohesion failure, or both?

## Architecture Onboarding

- **Component map**: Document -> Sentence Segmentation -> Masking -> Prompt Construction -> LLM API -> Generation -> Evaluation Metrics
- **Critical path**: 1) Sample document, 2) Segment and mask sentence, 3) Construct prompt, 4) Call LLM API, 5) Compute fidelity metrics, 6) (Subset) Human preference test
- **Design tradeoffs**: Temperature=1.0 preserves stochasticity but increases variance; single-sentence masking isolates understanding but may underestimate natural gap handling
- **Failure signatures**: High cohesion/low fidelity (fluent but semantically different), logical inconsistency (fluent but violates structure), verbosity/tone mismatch, unresolved narrative
- **First 3 experiments**:
  1. Position sensitivity test: Mask first/middle/last across 100 documents per domain, measure BLEURT delta
  2. Density scaling test: Mask 1-3 sentences in Recipe1M, plot fidelity degradation curve
  3. Cohesion-fidelity divergence test: For 50 low-fidelity samples, run human preference to check metric alignment

## Open Questions the Paper Calls Out

- **Open Question 1**: Can architectures capturing local/global context (hierarchical attention, planning-based generation) overcome NTP limitations in MSP tasks?
- **Open Question 2**: Would fine-tuning on MSP objectives or richer prompting strategies improve model reliability?
- **Open Question 3**: Do performance limitations stem from genuine capability gaps or data contamination in closed-source models?

## Limitations

- Single annotator design for human preference tests lacks inter-rater reliability
- Automatic fidelity metrics were not validated against human judgments for this specific task
- Temperature=1.0 generation increases output variance, making systematic patterns harder to distinguish
- Structured domain advantage may reflect dataset-specific patterns rather than generalizable procedural text benefits

## Confidence

- **High confidence**: Domain structure effects on fidelity (Recipe1M > ROCStories â‰ˆ Wikipedia)
- **Medium confidence**: Bidirectional context advantage for middle-position masking
- **Medium confidence**: NTP training creates fidelity-cohesion trade-off
- **Low confidence**: Human preference results (single annotator limitation)

## Next Checks

1. **Inter-rater reliability test**: Replicate human preference evaluation with 3-5 independent annotators per sample, measuring Cohen's kappa
2. **Controlled decoding experiment**: Generate outputs across temperature range (0.2, 0.5, 0.8, 1.0) for 100 samples per domain, measuring both fidelity and cohesion
3. **NTP fine-tuning ablation**: Fine-tune GPT-4o on MSP-style span corruption tasks using Recipe1M and ROCStories, then re-run fidelity and human preference tests