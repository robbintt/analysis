---
ver: rpa2
title: Bayesian generative models can flag performance loss, bias, and out-of-distribution
  image content
arxiv_id: '2503.17477'
source_url: https://arxiv.org/abs/2503.17477
tags:
- skin
- uncertainty
- bias
- generative
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the need for uncertainty quantification (UQ)
  in generative models, particularly variational autoencoders (VAEs), to detect performance
  loss, bias, and out-of-distribution (OOD) content in medical imaging. The authors
  propose SLUG, a scalable UQ method that extends the Sketched Lanczos Uncertainty
  (SLU) algorithm using stochastic trace estimators to handle high-dimensional image
  data.
---

# Bayesian generative models can flag performance loss, bias, and out-of-distribution image content

## Quick Facts
- **arXiv ID:** 2503.17477
- **Source URL:** https://arxiv.org/abs/2503.17477
- **Authors:** Miguel López-Pérez; Marco Miani; Valery Naranjo; Søren Hauberg; Aasa Feragen
- **Reference count:** 32
- **Primary result:** SLUG provides scalable epistemic uncertainty quantification for VAEs, detecting performance loss, racial bias, and OOD content in medical imaging.

## Executive Summary
This work addresses the need for uncertainty quantification (UQ) in variational autoencoders (VAEs) to detect performance loss, bias, and out-of-distribution (OOD) content in medical imaging. The authors propose SLUG, a scalable UQ method that extends the Sketched Lanczos Uncertainty (SLU) algorithm using stochastic trace estimators to handle high-dimensional image data. SLUG provides both image-level and pixel-wise uncertainty scores, making it suitable for flagging errors, underrepresentation bias, and OOD elements like rulers or ink in dermatological images.

Experiments on three datasets—Fitzpatrick17k, PASSION, and ISIC—demonstrate that SLUG strongly correlates with reconstruction error and racial bias across skin tone subgroups, outperforming standard VAE encoder variances. It also effectively highlights OOD content, which could help mitigate shortcut learning in diagnostic models. The primary result is that SLUG offers a practical, scalable solution for safeguarding generative model deployment in clinical settings by reliably detecting bias and OOD issues.

## Method Summary
SLUG extends the Sketched Lanczos Uncertainty (SLU) algorithm to enable scalable epistemic uncertainty quantification for high-dimensional VAE outputs. It combines Laplace approximations with stochastic trace estimators, using Hutchinson's method to approximate the trace of the predictive covariance matrix with S Monte Carlo samples. The method computes a low-rank approximation of the Generalized Gauss-Newton (GGN) matrix to capture epistemic uncertainty, then applies stochastic trace estimation to obtain both image-level uncertainty scores and pixel-wise uncertainty maps. The approach is specifically designed to detect performance degradation, racial bias in dermatological imaging, and OOD artifacts like rulers and ink.

## Key Results
- SLUG strongly correlates with reconstruction error across all skin tone subgroups, outperforming standard encoder variance
- Pixel-wise uncertainty maps effectively highlight OOD content (rulers, ink, patches) even when VAE reconstructions appear accurate
- SLUG detects racial bias in Fitzpatrick17k dataset, with higher uncertainty scores for underrepresented skin tones
- Method scales to 128×128 images using S=500 stochastic samples, trading exactness for tractability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Generalized Gauss-Newton (GGN) matrix, approximated through sketching, captures epistemic uncertainty in VAE decoders that standard encoder variances miss.
- Mechanism: The GGN matrix G = Σᵢ J(xᵢ)ᵀ H(xᵢ) J(xᵢ) encodes how parameter uncertainty propagates to output uncertainty. By computing a low-rank approximation via the Sketched Lanczos algorithm, SLUG extracts the leading eigenvectors U that span the high-curvature directions of the loss landscape. The residual projector (I - UUᵀ) captures uncertainty in directions poorly constrained by training data.
- Core assumption: The linearized Laplace approximation reasonably approximates the true posterior over decoder weights; epistemic uncertainty correlates with distribution shift.
- Evidence anchors:
  - [abstract] "combines recent advances in Laplace approximations with stochastic trace estimators"
  - [section 3] "The GGN commonly appears as the inverse covariance of the linearized Laplace approximation (LLA) to the true posterior"
  - [corpus] Related work on Bayesian VAEs (Daxberger et al., Miani et al.) supports Laplace approximations for OOD detection, though corpus evidence for the specific GGN-sketching mechanism is limited.
- Break condition: If the loss landscape is highly non-convex or the true posterior is multimodal, the Laplace approximation may poorly capture uncertainty, and SLUG scores could be misleading.

### Mechanism 2
- Claim: Stochastic trace estimation enables tractable global uncertainty scoring for high-dimensional image outputs.
- Mechanism: Computing per-pixel uncertainty naively requires O(WHC) SLU invocations. SLUG replaces this with Hutchinson's estimator: SLUG(x) = E[ϵ J(I-UUᵀ)Jᵀϵᵀ] where ϵ ~ N(0,I). This reduces computation to S Monte Carlo samples (S=500 in experiments), trading exact computation for an unbiased estimate with controllable variance.
- Core assumption: The trace of the predictive covariance matrix is a meaningful summary of total epistemic uncertainty; S samples provide sufficient estimation accuracy.
- Evidence anchors:
  - [section 3.2] "This can be implemented using only S invocations of SLU"
  - [section 4] "we utilize S = 500 samples" with demonstrated correlation to MSE
  - [corpus] Stochastic trace estimation is standard in numerical linear algebra (Hutchinson 1989), but corpus lacks direct validation for this specific UQ application.
- Break condition: If S is too small, estimator variance may swamp the signal; if per-pixel uncertainties are heterogeneous (some high, some low), the summed score may obscure localized issues.

### Mechanism 3
- Claim: Pixel-wise epistemic uncertainty highlights OOD image content (rulers, ink, patches) even when the VAE reconstructs them accurately.
- Mechanism: By replacing the trace estimator with a stochastic diagonal estimator, SLUG produces uncertainty maps. OOD objects lie outside the training manifold, so the decoder's Jacobian in those regions has high uncertainty in directions orthogonal to U. This yields high pixel-wise scores for OOD content regardless of reconstruction quality.
- Core assumption: OOD content triggers higher epistemic uncertainty than in-distribution lesions; reconstruction quality and epistemic uncertainty are decoupled for OOD.
- Evidence anchors:
  - [abstract] "pixel-wise uncertainty can detect out-of-distribution image content such as ink, rulers, and patches"
  - [section 4, Fig 4] "the VAE reconstructs OOD data, but SLU detects the OOD content... the rulers, ink and patch are all highlighted well"
  - [corpus] Related work (NERO, Preventing Shortcut Learning) addresses OOD detection in medical imaging but uses different mechanisms.
- Break condition: If the VAE has memorized specific OOD artifacts during training (e.g., many images with rulers), uncertainty may be low despite OOD status.

## Foundational Learning

- Concept: Variational Autoencoders and the ELBO
  - Why needed here: SLUG is a post-hoc UQ method applied to trained VAEs; understanding the encoder-decoder structure, latent space, and reconstruction is essential.
  - Quick check question: Can you explain why VAE encoder variances (σ(x)) fail to capture epistemic uncertainty for OOD inputs?

- Concept: Laplace Approximation for Bayesian Neural Networks
  - Why needed here: SLUG builds on the linearized Laplace approximation, which approximates the posterior over weights as Gaussian with covariance related to the GGN matrix.
  - Quick check question: What does the GGN matrix represent, and why does it scale poorly for high-dimensional outputs?

- Concept: Stochastic Trace Estimation (Hutchinson's Method)
  - Why needed here: Core computational trick enabling SLUG to scale; understanding the bias-variance tradeoff in Monte Carlo estimation is critical.
  - Quick check question: Given SLUG uses S random probe vectors, how would halving S affect estimation quality?

## Architecture Onboarding

- Component map: VAE backbone -> SLUG post-processor -> Image-level score + Optional pixel-wise map
- Critical path:
  1. Train VAE to convergence on target dataset (1000 epochs observed)
  2. Compute Laplace approximation: extract GGN eigenvectors U (rank-k approximation)
  3. For each test image x, compute SLUG(x) via S stochastic probes through Jacobian
  4. Optional: generate pixel-wise uncertainty map for OOD localization
- Design tradeoffs:
  - Higher rank k in Lanczos: better uncertainty approximation, more memory/time
  - Higher S (probe count): lower estimator variance, slower inference
  - Perceptual vs. pixel-wise loss: perceptual improves semantic quality but may affect what the VAE learns to reconstruct faithfully
  - Pixel-wise uncertainty: useful for localization but scales poorly for 3D/high-res data (acknowledged limitation in paper)
- Failure signatures:
  - SLUG uncorrelated with reconstruction error → check if VAE is undertrained or Laplace approximation is poor
  - Encoder variance outperforms SLUG → suggests possible implementation error; encoder variance should NOT capture epistemic uncertainty per paper's claims
  - All images have similar SLUG scores → eigenvector rank k may be too low, or GGN computation may have failed
- First 3 experiments:
  1. Reproduce Fig. 4 (left): Plot SLUG vs. MSE on a held-out validation set; verify strong correlation (Pearson r > 0.7 would be consistent with paper).
  2. Ablation on S: Compare SLUG quality with S ∈ {50, 200, 500, 1000}; measure correlation stability and inference time.
  3. OOD localization test: Apply pixel-wise SLUG to images with known artifacts (rulers, text); qualitatively assess whether uncertainty maps highlight these regions more than background.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the root causes of performance degradation on dark skin tones in VAEs, given that bias persists even when models are trained exclusively on dark skin samples?
- Basis in paper: [explicit] The authors note that representation does not explain all observed bias and state, "Discovering the true causes of bias therefore remains an important open challenge."
- Why unresolved: The paper demonstrates that SLUG can *flag* the bias, but it only hypothesizes potential causes (e.g., higher image variability or relaxed inclusion criteria) without verifying them.
- Evidence to resolve: A comparative analysis of dataset complexity and inclusion criteria across skin tone subgroups that correlates these factors with the observed reconstruction errors.

### Open Question 2
- Question: Can the SLUG algorithm be modified to scale efficiently for pixel-wise uncertainty quantification in high-resolution or 3D medical images?
- Basis in paper: [explicit] The authors identify the main limitation of the work: "the computation of pixelwise uncertainty does not scale well, posing a bottleneck for high-resolution or 3D images."
- Why unresolved: While SLUG improves scalability for image-level scores using stochastic trace estimators, the computational cost remains prohibitive for the dense per-pixel maps required in 3D modalities like MRI or CT.
- Evidence to resolve: A demonstration of SLUG applied to 3D volumetric data where the computational cost of pixel-wise uncertainty remains tractable without significant loss of fidelity.

### Open Question 3
- Question: Does the incorporation of SLUG uncertainty maps into the training pipeline effectively mitigate shortcut learning in downstream diagnostic models?
- Basis in paper: [inferred] The authors show SLUG detects OOD content like rulers and ink, which "is known to induce learning shortcuts," and suggest this "could help mitigate shortcut learning."
- Why unresolved: The paper validates the *detection* of these artifacts but does not experiment with using the uncertainty estimates to actively regularize or correct a diagnostic classifier.
- Evidence to resolve: An experiment showing that a classifier trained with a mechanism to ignore or down-weight high-SLUG regions achieves improved generalization on artifact-free test data.

## Limitations

- **Scalability constraint:** Pixel-wise uncertainty computation does not scale well for high-resolution or 3D medical images, limiting practical deployment in volumetric modalities
- **Mechanism validity uncertainty:** The Laplace approximation's ability to capture true epistemic uncertainty depends on the loss landscape being approximately convex, which may not hold for complex VAE decoders
- **Implementation specificity:** Critical hyperparameters including rank-k approximation, perceptual loss configuration, and VAE architecture details are underspecified, making exact replication challenging

## Confidence

- **High confidence:** SLUG's computational scalability through stochastic trace estimation; empirical demonstration of correlation with MSE; qualitative OOD localization capability
- **Medium confidence:** GGN-sketching mechanism for epistemic uncertainty; scalability to high-dimensional images; detection of racial bias through uncertainty stratification
- **Low confidence:** Theoretical guarantees for the Laplace approximation in VAE decoders; universal applicability across different generative architectures; robustness to hyperparameter choices

## Next Checks

1. **Mechanism stress test:** Systematically vary VAE architecture complexity (latent dimension, network depth) and train VAEs to different convergence levels. Measure how SLUG performance degrades with underfitting, overfitting, and architectural changes to establish bounds on the Laplace approximation's validity.

2. **OOD dataset expansion:** Test SLUG on additional OOD datasets beyond dermatological artifacts, including natural OOD splits (e.g., different medical imaging modalities, synthetic corruption types) to verify whether pixel-wise uncertainty consistently flags distribution shift rather than just memorized OOD patterns.

3. **Ablation on stochastic estimation:** Perform a systematic ablation study varying the number of Monte Carlo samples S from 50 to 1000, measuring both correlation with MSE and computational overhead. This would establish the minimum S required for reliable uncertainty estimation and clarify the bias-variance tradeoff.