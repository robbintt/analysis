---
ver: rpa2
title: 'Emergence of Episodic Memory in Transformers: Characterizing Changes in Temporal
  Structure of Attention Scores During Training'
arxiv_id: '2502.06902'
source_url: https://arxiv.org/abs/2502.06902
tags:
- heads
- attention
- scores
- positional
- induction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates temporal biases in transformer attention
  heads and outputs using cognitive science methodologies, particularly lag-CRP analysis.
  The authors train GPT-2 small and medium models on Wikitext-103 and FineWeb datasets,
  finding that attention heads exhibit human-like episodic memory effects including
  temporal contiguity, primacy, and recency.
---

# Emergence of Episodic Memory in Transformers: Characterizing Changes in Temporal Structure of Attention Scores During Training

## Quick Facts
- **arXiv ID**: 2502.06902
- **Source URL**: https://arxiv.org/abs/2502.06902
- **Reference count**: 21
- **Key outcome**: Transformers exhibit human-like episodic memory effects (temporal contiguity, primacy, recency) with local temporal focus (2-4 tokens)

## Executive Summary
This study investigates temporal biases in transformer attention heads and outputs using cognitive science methodologies, particularly lag-CRP analysis. The authors train GPT-2 small and medium models on Wikitext-103 and FineWeb datasets, finding that attention heads exhibit human-like episodic memory effects including temporal contiguity, primacy, and recency. Transformer outputs show strong serial recall preferences, which disappear after ablating induction heads. The study reveals that temporal properties emerge gradually during training, with positional encoding magnitude influencing the strength of these effects. Most notably, transformers focus attention on very local temporal contexts (2-4 tokens) when retrieving information, unlike human memory which operates across broader temporal scales.

## Method Summary
The study employs lag-CRP (lag conditional response probability) analysis, a cognitive science tool adapted from episodic memory research, to examine temporal structures in transformer attention mechanisms. The authors train GPT-2 small and medium models on Wikitext-103 and FineWeb datasets, analyzing attention scores and output probabilities throughout training. They systematically ablate induction heads to test causal relationships between specific attention mechanisms and observed temporal effects. The methodology includes controlled experiments varying positional encoding magnitudes and comparing different attention head types. Validation against human data establishes the appropriateness of lag-CRP for transformer analysis.

## Key Results
- Attention heads exhibit human-like episodic memory effects: temporal contiguity, primacy, and recency
- Transformer outputs show strong serial recall preferences that disappear after ablating induction heads
- Temporal properties emerge gradually during training, with positional encoding magnitude influencing effect strength
- Transformers focus attention on very local temporal contexts (2-4 tokens), unlike human memory's broader temporal scales

## Why This Works (Mechanism)
The emergence of episodic memory-like properties in transformers stems from their self-attention mechanism's inherent capacity to track temporal relationships between tokens. During training, the model learns to associate recently encountered tokens more strongly than distant ones, creating temporal contiguity effects. The self-attention mechanism allows each token to attend to previous tokens with varying weights, and through gradient descent, the model optimizes these attention patterns to maximize prediction accuracy. Induction heads, which detect and propagate repeated patterns, play a crucial role in serial recall by creating attention loops that reinforce sequential dependencies. The positional encoding provides the model with absolute and relative position information, enabling it to learn position-dependent attention patterns that manifest as primacy and recency effects.

## Foundational Learning
- **Lag-CRP Analysis**: Statistical method measuring probability of attending to tokens at specific lags from current position; needed to quantify temporal attention patterns, check by comparing against human episodic memory data
- **Episodic Memory Theory**: Framework describing how humans remember sequences with contiguity, primacy, and recency effects; needed to establish baseline for comparison, check by validating against established human memory studies
- **Transformer Self-Attention**: Mechanism allowing tokens to attend to all previous tokens with learned weights; needed to understand how temporal relationships are encoded, check by examining attention score distributions
- **Induction Heads**: Special attention heads that detect and propagate repeated patterns; needed to identify source of serial recall effects, check by ablation studies
- **Positional Encoding**: Method of injecting position information into token embeddings; needed to enable position-dependent attention, check by varying encoding magnitude
- **Serial Recall**: Tendency to remember items in sequence order; needed to understand output generation patterns, check by analyzing output probability distributions

## Architecture Onboarding

**Component Map**: Input tokens -> Positional Encoding -> Embedding Layer -> Multi-Head Self-Attention -> Feed-Forward Networks -> Output Layer

**Critical Path**: Token sequence → Positional encoding injection → Multi-head attention computation → Attention score aggregation → Output probability generation

**Design Tradeoffs**: Local temporal focus (2-4 tokens) enables efficient computation but limits long-range dependency capture; strong induction heads improve sequential pattern learning but may create attention loops; positional encoding magnitude affects temporal effect strength but too much can overwhelm semantic information

**Failure Signatures**: Loss of temporal contiguity when positional encoding is removed; disappearance of serial recall effects after induction head ablation; reduced primacy/recency effects with decreased positional encoding magnitude

**First Experiments**:
1. Measure lag-CRP curves for individual attention heads to identify which heads contribute most to temporal effects
2. Compare temporal attention patterns across different positional encoding schemes (absolute vs. relative)
3. Track evolution of temporal properties throughout training to identify emergence patterns

## Open Questions the Paper Calls Out
None

## Limitations
- Findings based on GPT-2 small/medium architectures limit generalizability to larger models and different domains
- Lag-CRP methodology may not capture all relevant temporal dynamics in transformer attention mechanisms
- Local temporal focus (2-4 tokens) represents a narrow slice of transformer behavior that may not reflect full capacity for long-range dependencies

## Confidence
- **High**: Empirical observations of temporal contiguity, primacy, and recency effects in attention heads; presence of serial recall preferences in transformer outputs; ablation results showing induction heads' role
- **Medium**: Gradual emergence of temporal properties during training; influence of positional encoding magnitude on temporal effects
- **Low**: Direct comparison of transformer temporal scales to human memory systems; claim that transformers "focus" attention locally as a fundamental limitation

## Next Checks
1. Replicate temporal bias analyses across diverse transformer architectures (BERT, RoBERTa, LLaMA) and domains (code, medical text, scientific literature) to assess generalizability
2. Conduct controlled experiments varying positional encoding schemes, embedding dimensions, and attention head configurations to isolate architectural factors driving local temporal focus
3. Implement longitudinal tracking of attention head temporal properties across extended training periods to verify gradual emergence pattern and identify potential phase transitions in temporal learning dynamics