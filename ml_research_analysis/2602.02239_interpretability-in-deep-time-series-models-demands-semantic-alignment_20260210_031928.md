---
ver: rpa2
title: Interpretability in Deep Time Series Models Demands Semantic Alignment
arxiv_id: '2602.02239'
source_url: https://arxiv.org/abs/2602.02239
tags:
- time
- series
- concepts
- alignment
- concept
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper argues that true interpretability in deep time series
  models requires semantic alignment - where model variables and mechanisms correspond
  to human-understandable concepts and reasoning patterns. The authors formalize this
  requirement through two conditions: (1) instantaneous concepts must align with encoder
  outputs, and (2) dynamic concepts must maintain alignment through temporal propagation.'
---

# Interpretability in Deep Time Series Models Demands Semantic Alignment

## Quick Facts
- arXiv ID: 2602.02239
- Source URL: https://arxiv.org/abs/2602.02239
- Authors: Giovanni De Felice; Riccardo D'Elia; Alberto Termine; Pietro Barbiero; Giuseppe Marra; Silvia Santini
- Reference count: 39
- Key outcome: True interpretability requires semantic alignment where model variables correspond to human-understandable concepts, with instantaneous and dynamic alignment conditions.

## Executive Summary
This paper argues that deep time series models cannot be truly interpretable without semantic alignment - where internal representations and mechanisms correspond to domain-relevant concepts and reasoning patterns. The authors formalize this requirement through two alignment conditions: instantaneous concepts must align with encoder outputs, and dynamic concepts must maintain alignment through temporal propagation. They propose a blueprint architecture that encodes raw observations into interpretable concepts, propagates these concepts through time using aligned mechanisms, and optionally decodes them for task-specific outputs. The framework enables properties like actionability, verifiability, and fairness analysis by maintaining interpretable concepts throughout the model pipeline.

## Method Summary
The proposed method implements a three-stage blueprint for semantically aligned time series models. First, a concept encoder maps raw observations to interpretable source concepts. Second, a propagation module maintains temporal and spatio-temporal mechanisms that align with domain reasoning patterns. Third, an optional task decoder translates concepts to task outputs. The training objective combines three terms: task performance, spatial alignment (instantaneous concept prediction), and temporal alignment (dynamic concept propagation). The model is trained to satisfy two formal alignment conditions: perfect prediction of instantaneous concepts from observations, and perfect prediction of dynamic concepts through temporal propagation.

## Key Results
- Semantic alignment requires both instantaneous concept alignment with encoder outputs and dynamic concept alignment through temporal propagation
- Existing interpretability methods (attention weights, saliency maps, linearized dynamics) fail to achieve true semantic alignment as they operate at computational rather than conceptual levels
- Concept bottleneck models demonstrate that semantic alignment need not trade off against performance, matching black-box accuracy while maintaining interpretability
- The framework enables actionable interventions, formal verification, and fairness analysis through concept-level traceability

## Why This Works (Mechanism)
The framework works by maintaining interpretable concepts throughout the model pipeline rather than treating interpretability as an afterthought. By enforcing alignment constraints during training, the model learns representations that directly correspond to domain concepts rather than arbitrary internal features. The temporal propagation mechanism ensures that dynamic concepts evolve in ways that align with human reasoning about time series dependencies. This creates a model where users can understand and intervene at the concept level, verify against domain properties, and trace decision influences back to interpretable causes.

## Foundational Learning
**Concept Encoding** - Maps raw time series observations to interpretable domain concepts. Why needed: Raw observations are often not directly interpretable; encoding transforms them into human-understandable representations. Quick check: Verify concept prediction accuracy at each timestep exceeds baseline threshold.

**Temporal Mechanism Alignment** - Ensures dynamic concepts evolve according to domain-consistent rules. Why needed: Without alignment, temporal propagation may capture spurious correlations rather than genuine causal relationships. Quick check: Measure concept accuracy degradation across timesteps under different mechanism constraints.

**Spatio-Temporal Propagation** - Models interactions between concepts across both space and time. Why needed: Real-world time series exhibit both temporal dependencies and cross-variable interactions that must be captured coherently. Quick check: Validate that concept interactions align with known domain relationships.

## Architecture Onboarding

**Component Map:** Raw observations → Concept Encoder → Propagation Module → (Optional) Task Decoder

**Critical Path:** The encoder-propagation path is essential for maintaining semantic alignment. The decoder is optional when concepts themselves are the final output.

**Design Tradeoffs:** Complete concept sets enable full alignment but may be expensive to annotate; incomplete sets require residual pathways that trade some alignment for practical feasibility.

**Failure Signatures:** Concept drift over time indicates insufficient temporal alignment regularization; performance collapse suggests concept set incompleteness without adequate residual pathways.

**First Experiments:**
1. Implement on healthcare time series with clinical state annotations, tracking concept accuracy across timesteps
2. Compare semantic alignment preservation with and without mechanism constraints
3. Systematically vary concept annotation completeness to quantify performance trade-offs

## Open Questions the Paper Calls Out
None

## Limitations
- Implementation details for mechanism alignment constraints remain unspecified, limiting direct reproducibility
- Evaluation framework for measuring semantic alignment in practice is not fully specified
- Scalability to domains with sparse or expensive concept annotations is not addressed

## Confidence

**High confidence:** The conceptual argument that semantic alignment requires both instantaneous and dynamic concept alignment is logically sound and well-articulated.

**Medium confidence:** The claim that semantic alignment need not trade off against performance is supported by reference to concept bottleneck literature, but lacks direct empirical validation in this paper.

**Low confidence:** The assertion that existing interpretability methods fundamentally fail to achieve semantic alignment is presented as self-evident without rigorous comparative analysis.

## Next Checks

1. **Implementation validation:** Implement the blueprint on a concrete dataset (e.g., healthcare time series with clinical state annotations) and verify whether the three-term loss function can be optimized effectively with reasonable hyperparameter settings.

2. **Alignment preservation test:** Conduct controlled experiments tracking concept prediction accuracy degradation across timesteps. Measure whether alignment is maintained when propagation mechanisms are constrained versus unconstrained.

3. **Performance trade-off analysis:** Systematically compare task performance between semantically aligned models and black-box baselines across multiple datasets, varying the completeness of concept annotations to quantify the performance gap when concepts are incomplete.