---
ver: rpa2
title: 'Dataset Distillation as Data Compression: A Rate-Utility Perspective'
arxiv_id: '2507.17221'
source_url: https://arxiv.org/abs/2507.17221
tags:
- dataset
- synthetic
- distillation
- imagenet
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a joint rate-utility optimization method for
  dataset distillation, addressing the trade-off between storage efficiency and downstream
  task performance. The approach parameterizes synthetic samples as multiscale latent
  codes decoded by lightweight networks, estimating the Shannon entropy of quantized
  latents as the rate measure and integrating any existing distillation loss as the
  utility measure.
---

# Dataset Distillation as Data Compression: A Rate-Utility Perspective

## Quick Facts
- arXiv ID: 2507.17221
- Source URL: https://arxiv.org/abs/2507.17221
- Reference count: 40
- Primary result: Achieves up to 170× greater compression than standard distillation at comparable accuracy through joint rate-utility optimization

## Executive Summary
This work introduces a joint rate-utility optimization framework for dataset distillation that explicitly accounts for storage efficiency. The method parameterizes synthetic samples as multiscale latent codes decoded by lightweight networks, estimating Shannon entropy of quantized latents as the rate measure while integrating any existing distillation loss as the utility measure. A key contribution is the bits per class (bpc) metric, which accounts for sample, label, and decoder parameter costs to enable fair cross-method comparisons. Experiments demonstrate consistently better rate-utility trade-offs across diverse budgets, losses, and architectures compared to vanilla distillation.

## Method Summary
The approach uses a three-phase training procedure: (1) overfitted compression initialization via latent encoding and decoding, (2) joint optimization with rate and utility terms using a Lagrange multiplier, and (3) post-quantization. Synthetic samples are represented as multiscale latent codes (L=6) that are decoded by lightweight convolutional networks (v4-*/v5-* variants). An entropy network estimates the probability of quantized latents using a context-aware Laplace distribution, allowing the system to minimize storage cost while maintaining training utility. The method supports multiple distillation losses including trajectory matching, gradient matching, and distribution matching.

## Key Results
- Achieves up to 170× greater compression than standard distillation at comparable accuracy
- Consistently better rate-utility trade-offs across diverse budgets, losses, and architectures
- Demonstrated on CIFAR-10, CIFAR-100, and ImageNet-128 with bits per class (bpc) metric

## Why This Works (Mechanism)

### Mechanism 1: Entropy-Regularized Latent Representation
Minimizing the estimated Shannon entropy of latent codes forces the synthetic dataset into a compressed representation that retains only task-critical information. Synthetic samples are parameterized as multiscale latent codes, with a lightweight entropy network modeling the probability of these codes using a context-aware Laplace distribution. This drives latents toward values that are both highly compressible and useful for training, assuming semantic information required for the downstream task is uncorrelated with high-entropy noise in raw pixel space.

### Mechanism 2: Hybrid Parameterization (Latents + Lightweight Decoders)
Decoupling storage of sample-specific details (latents) from structural generation mechanisms (decoders) achieves higher efficiency than storing raw pixels or using a single large generator. The system allocates bits dynamically: low budgets rely more on the implicit bias of the decoder, while high budgets allocate more to explicit latent codes. This assumes structural information required to reconstruct valid training images can be captured by extremely small neural networks without significant loss of training utility.

### Mechanism 3: Soft Label Quantization Penalty
Treating labels as information sources subject to rate constraints reveals the hidden cost of soft labels, forcing a reversion to hard labels or compressed proxies to save bits for image quality. The method calculates the bitrate for soft labels, showing they can require massive bit-depth, implicitly penalizing these complex labels in favor of low-entropy (hard) labels or compressed representations which free up the bpc budget for sample fidelity.

## Foundational Learning

- **Rate-Distortion Theory (R-D)**: The entire method is built on the R-D Lagrangian (R + λD). You must understand that "Rate" is the storage cost (entropy) and "Utility" (Distortion inverse) is the task performance. *Quick check: If λ is set very high, will the resulting dataset be larger or smaller, and will accuracy likely rise or fall?*

- **Entropy Coding & Probability Models**: The "Rate" term is not file size; it is the estimated entropy derived from a learned probability distribution (Laplace). Understanding how a context model predicts the probability of a symbol is key to debugging the rate loss. *Quick check: Why does the method use a "context-aware" Laplace distribution rather than a fixed Gaussian distribution for the latents?*

- **Bilevel Optimization**: Dataset distillation is inherently a meta-learning problem (an "outer loop" optimizing data for an "inner loop" training process). The joint rate-utility objective adds a regularization term to this outer loop. *Quick check: In the context of Eq. (1) and Eq. (5), is the rate term r(S) part of the inner loop training loss or the outer loop distillation loss?*

## Architecture Onboarding

- **Component map**: Latent Bank (Z) -> Entropy Network (h) -> Decoder (g) -> Utility Evaluator
- **Critical path**: Quantization of latents must use straight-through estimator to bypass non-differentiable rounding; entropy network must strictly see only "causal" neighbors to avoid data leakage
- **Design tradeoffs**: Decoder Size vs. Latent Size (implicit vs explicit bits allocation); Hard vs. Soft Labels (storage cost vs. training signal quality)
- **Failure signatures**: Post-quantization collapse (decoded images differ significantly from latents); Rate leakage (entropy network predicts uniform distributions); Slow convergence (requires Phase 1 initialization)
- **First 3 experiments**: 1) Sanity Check: Can v4-480 decoder reconstruct a single image perfectly from latent? 2) Metric Validation: Compare vanilla distillation vs proposed method at same bpc (e.g., 10 kB) 3) Ablation on λ: Sweep Lagrange multiplier to generate Rate-Utility curve

## Open Questions the Paper Calls Out

1. Can fully joint optimization of soft labels and differentiable neural architecture search (NAS) significantly tighten the rate-utility frontier compared to fixed architectures?

2. Does incorporating staged pipelines (e.g., SRe2L) effectively resolve scalability bottlenecks for high-resolution datasets like ImageNet-1K?

3. Can the joint rate-utility optimization framework be generalized to non-image modalities such as text or graphs?

## Limitations
- The lightweight decoder capacity may become a bottleneck for complex datasets, limiting achievable utility even at high bpc
- The context-aware Laplace distribution entropy model may be inaccurate if latent codes deviate significantly from assumed distribution
- Joint rate-utility optimization is computationally expensive compared to standard distillation methods

## Confidence
- **High Confidence**: Core mechanism of entropy-regularized latent representation is well-supported by information theory literature
- **Medium Confidence**: Hybrid parameterization approach is plausible with some evidence but needs more validation across diverse datasets
- **Low Confidence**: Soft label quantization penalty claims are novel with theoretical derivation but limited practical exploration

## Next Checks
1. Test the same lightweight decoder architecture (v4-*) on a significantly different dataset (e.g., SVHN or STL-10) to validate cross-dataset generalization and identify potential decoder bottlenecks

2. Replace the context-aware Laplace distribution with a simpler fixed Gaussian model and measure changes in rate estimate accuracy and downstream utility to validate the importance of the sophisticated entropy model

3. Create a synthetic dataset with known theoretical entropy (e.g., images with simple predictable patterns) and compare actual compressed file size to estimated bpc to validate practical accuracy of the bpc metric as file-size predictor