---
ver: rpa2
title: Closing the Modality Gap Aligns Group-Wise Semantics
arxiv_id: '2601.18525'
source_url: https://arxiv.org/abs/2601.18525
tags:
- modality
- space
- loss
- latent
- modalities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that the modality gap, while irrelevant
  to instance-wise tasks like retrieval, strongly impacts group-wise tasks such as
  clustering. To address this, the authors introduce a novel objective combining true-pair
  alignment and centroid-based uniformity to effectively close the gap in both bimodal
  and trimodal settings.
---

# Closing the Modality Gap Aligns Group-Wise Semantics

## Quick Facts
- arXiv ID: 2601.18525
- Source URL: https://arxiv.org/abs/2601.18525
- Reference count: 30
- This paper demonstrates that the modality gap, while irrelevant to instance-wise tasks like retrieval, strongly impacts group-wise tasks such as clustering. To address this, the authors introduce a novel objective combining true-pair alignment and centroid-based uniformity to effectively close the gap in both bimodal and trimodal settings. Their method consistently reduces the gap, improves clustering performance by several points in V-Measure, and maintains or slightly increases retrieval accuracy. These findings highlight the modality gap as a central factor shaping multimodal latent space geometry and show it can be minimized through a simple objective to enable better semantic organization without compromising instance-level precision.

## Executive Summary
This paper identifies and addresses the modality gap—the systematic offset between embeddings of the same semantic content in different modalities. The authors demonstrate that while this gap has negligible impact on instance-wise tasks like retrieval, it significantly degrades group-wise tasks such as clustering. They propose a novel objective combining true-pair alignment (L_ATP) and centroid-based uniformity (L_CU) to effectively close the gap. Their method shows consistent improvements in clustering performance (V-Measure) across multiple datasets while maintaining or slightly improving retrieval accuracy. The work provides both theoretical insights and practical solutions for improving multimodal representation learning.

## Method Summary
The authors introduce a combined loss function that addresses the modality gap in multimodal contrastive learning. The approach builds on InfoNCE but adds two components: (1) L_ATP, an L2 alignment loss that explicitly pulls true modality pairs together, and (2) L_CU, a centroid-based uniformity loss that spreads multimodal centroids across the hypersphere. The total loss combines bidirectional InfoNCE with these gap-specific terms. The method is evaluated on four datasets (CIFAR-10, AV-MNIST, MSCOCO, MSR-VTT) with various modality combinations, showing consistent gap reduction and improved clustering while preserving retrieval performance.

## Key Results
- Gap reduction: Method consistently reduces modality gap across all datasets (e.g., MSCOCO: Gap reduced from 0.47 to near 0.0)
- Clustering improvement: V-Measure increases by 5-10 points across datasets when gap is closed
- Retrieval preservation: R@1 scores maintained or slightly improved (e.g., MSCOCO R@1: 74.97 → 75.28)
- Theoretical validation: Shows gap inflates within-class scatter uniformly, explaining clustering degradation

## Why This Works (Mechanism)

### Mechanism 1: Task-Type Dependent Impact of Modality Gap
- Claim: The modality gap negligibly affects instance-wise tasks (retrieval) but significantly degrades group-wise tasks (clustering).
- Mechanism: Retrieval depends only on relative similarity rankings—satisfied when sim(true pair) > max(negatives). Clustering requires absolute positioning; the gap vector δ adds uniformly to within-class scatter (E[||z - μ_δ||²] ≈ E[||z - μ₀||²] + ||δ||²), inflating cluster radii regardless of semantics.
- Core assumption: The gap vector is approximately constant and orthogonal to the span of semantic vectors across classes.
- Evidence anchors:
  - [abstract] "the modality gap, while irrelevant to instance-wise tasks like retrieval, strongly impacts group-wise tasks such as clustering"
  - [section 3.3, eq. 6] Derivation showing gap term adds to expected within-class scatter
  - [corpus] Weak direct support; appears to be a novel decomposition of gap effects
- Break condition: If gap variance across semantic classes is high (Table 3 shows variance ≈ 0.004–0.016, suggesting low break risk), the theoretical constant-δ assumption fails.

### Mechanism 2: True-Pair Alignment Loss (L_ATP) Breaks Local Minima
- Claim: An explicit L2 alignment loss on true pairs overcomes InfoNCE's tendency to stall at non-zero gap.
- Mechanism: InfoNCE gradients vanish when sim(true) ≈ sim(hardest negative), yielding equilibrium at θ ≈ 60° (Fig 3a). L_ATP ∝ ||z_m - z_a||² provides gradient ∂L_ATP = 2sin(θ) that always pulls toward θ=0, shifting the stationary point to zero gap.
- Core assumption: The RBF kernel in L_CU relates to uniform distribution on the unit hypersphere (Wang & Isola, 2020).
- Evidence anchors:
  - [section 4, eq. 7] Definition of L_ATP
  - [section 5.3, Fig 3b] Gradient magnitude shifts from matching to non-matching pairs as gap closes
  - [corpus] Limited corpus coverage for this specific loss design
- Break condition: Without L_CU, L_ATP alone causes latent space collapse (Table 10: Angular Value increases from 0.001 to 0.122).

### Mechanism 3: Centroid-Based Uniformity Preserves Cross-Modal Alignment
- Claim: Applying uniformity to multimodal centroids (not individual embeddings) maintains semantic separation while avoiding cross-modal disruption.
- Mechanism: Standard uniformity spreads all embeddings independently, which can decouple aligned pairs. L_CU spreads centroids of matched sets (μ_k = avg of all modalities for sample k), ensuring semantic concepts remain distinguishable while modalities for the same concept stay clustered.
- Core assumption: Centroids adequately represent semantic class structure across modalities.
- Evidence anchors:
  - [section 4, eq. 8–9] Centroid definition and L_CU formulation
  - [Table 11] L_CU achieves 84.64 R@1 vs 82.47 for standard uniformity
  - [corpus] Minimal corpus precedent for centroid-level uniformity
- Break condition: High intra-class variance may cause centroids to misrepresent cluster structure.

## Foundational Learning

- Concept: **InfoNCE Contrastive Loss**
  - Why needed here: Understanding why standard CLIP creates and preserves the gap despite semantic alignment.
  - Quick check question: Why does InfoNCE converge to θ ≈ 60° rather than θ ≈ 0° in the presence of a gap?

- Concept: **Alignment vs Uniformity Decomposition**
  - Why needed here: The paper builds on Wang & Isola (2020)'s insight that contrastive learning optimizes both alignment (positive pairs) and uniformity (distribution on hypersphere).
  - Quick check question: What happens if you optimize alignment without uniformity?

- Concept: **Within-Class and Between-Class Scatter**
  - Why needed here: The theoretical argument hinges on how the gap uniformly inflates within-class scatter.
  - Quick check question: If δ is orthogonal to semantic directions, why does it affect clustering but not retrieval ranking?

## Architecture Onboarding

- Component map: Modality encoders f_m → L2 normalization → Projection layer → Shared d-dim latent space

- Critical path:
  1. Encode and normalize each modality to unit vectors
  2. Compute L_ATP: mean L2 distance between true pairs across modalities
  3. Compute per-sample centroids μ_k across modalities
  4. Compute L_CU: log-sum-exp of RBF kernel on centroid distances
  5. Combine with bidirectional InfoNCE

- Design tradeoffs:
  - Table 9 suggests λ₂ ≥ 1.0 for best clustering; λ₁ less sensitive
  - Higher λ₂ improves both R@1 and V-Measure up to a point
  - Assumption: λ₁ = λ₂ = 1.0 is a reasonable default

- Failure signatures:
  - Collapse without L_CU: Angular Value > 0.1 indicates embeddings concentrated in narrow cone
  - Retrieval drop with excess L_ATP: R@1 degrades if centroids not spread
  - Persistent gap with InfoNCE-only: Gap stays at 0.4–0.5 on MSCOCO (Table 2)

- First 3 experiments:
  1. Measure baseline gap and Cos_TP on pretrained CLIP using MSCOCO validation (expect Gap ≈ 0.47, Cos_TP ≈ 0.34 per Table 2)
  2. Ablate λ₁=λ₂=0 vs λ₁=λ₂=1.0 on CIFAR10; track Gap, V-Measure, R@1 (expected ΔV-Measure ≈ +5–10)
  3. PCA visualization of latent space before/after training; verify gap closure and elimination of modality-specific clustering (cf. Fig 6)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the proposed gap-closure method perform on datasets with highly imbalanced modalities or weak semantic correspondence?
- **Basis in paper:** [explicit] Appendix A.5 states the method "does not directly address potential limitations arising from highly imbalanced datasets or scenarios where semantic alignment is ambiguous or weakly defined."
- **Why unresolved:** Empirical results showed smaller improvements on the imbalanced CIFAR10 compared to balanced datasets like MSCOCO, suggesting sensitivity to data structure.
- **What evidence would resolve it:** Evaluation on datasets with modality cardinality mismatches (e.g., 1 image : N captions) or noisy/weak positive pairings.

### Open Question 2
- **Question:** Does the centroid-based uniformity approach scale effectively to learning environments with more than three modalities?
- **Basis in paper:** [explicit] Appendix A.5 notes that "extending the evaluation to more complex or underexplored modality combinations remains future work," despite the theoretical extension to $n$-modal cases.
- **Why unresolved:** The paper only validates the approach on bimodal (Image-Text) and trimodal (Audio-Visual-Text) benchmarks.
- **What evidence would resolve it:** Empirical validation on benchmarks containing 4+ modalities (e.g., video, audio, text, and depth simultaneously).

### Open Question 3
- **Question:** Does forcing a zero modality gap adversely affect instance-wise discrimination tasks in large-scale, open-vocabulary settings?
- **Basis in paper:** [inferred] The paper claims retrieval is "mostly unaffected," but Table 1 shows a slight performance drop in Text-Video R@1 (34.2 to 32.8) on MSR-VTT.
- **Why unresolved:** It is unclear if this minor degradation is an artifact of the specific dataset or a general trade-off of closing the gap in complex latent spaces.
- **What evidence would resolve it:** Large-scale analysis specifically correlating gap reduction magnitude with granular changes in retrieval precision-recall curves.

## Limitations

- Limited theoretical justification: The mathematical derivations are relatively shallow, relying on assumptions about the gap vector being approximately constant and orthogonal to semantic directions without rigorous proof.
- Ablation scope: Focus primarily on CIFAR-10 and MSCOCO with limited exploration across diverse datasets and hyperparameters.
- Unknown implementation details: Critical hyperparameters for larger-scale experiments are not specified, making exact reproduction challenging.

## Confidence

**High Confidence**: The empirical demonstration that closing the modality gap improves clustering performance while maintaining retrieval accuracy is well-supported by experimental results across multiple datasets (CIFAR-10, MSCOCO, MSR-VTT).

**Medium Confidence**: The theoretical mechanism explaining why the gap affects clustering but not retrieval is plausible but relies on simplifying assumptions that may not hold universally.

**Low Confidence**: The assertion that centroid-based uniformity is superior to individual embedding uniformity lacks extensive comparative analysis and strong theoretical justification.

## Next Checks

1. **Gap variance analysis**: Systematically measure gap variance across semantic classes on multiple datasets to verify the assumption that the gap vector is approximately constant.

2. **Alternative uniformity formulations**: Compare centroid-based uniformity against other approaches (e.g., class-conditional uniformity, pairwise uniformity between modalities) to determine if the centroid method is optimal.

3. **Cross-modal transfer**: Evaluate whether models trained with gap closure show improved performance on cross-modal transfer tasks (e.g., image-to-text retrieval after text-to-image training) compared to standard CLIP models.