---
ver: rpa2
title: Automated Prompt Generation for Creative and Counterfactual Text-to-image Synthesis
arxiv_id: '2509.21375'
source_url: https://arxiv.org/abs/2509.21375
tags:
- prompt
- image
- counterfactual
- evaluator
- size
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AutoContra, a framework for generating counterfactual
  size images (e.g., tiny walruses next to giant buttons) by automatically rewriting
  prompts. The method combines an image evaluator, prompt rewriter, and prompt ranker.
---

# Automated Prompt Generation for Creative and Counterfactual Text-to-image Synthesis

## Quick Facts
- arXiv ID: 2509.21375
- Source URL: https://arxiv.org/abs/2509.21375
- Reference count: 0
- Primary result: AutoContra achieves 30.3% accuracy in generating counterfactual size images

## Executive Summary
This paper introduces AutoContra, a framework for automatically generating counterfactual size images (e.g., tiny walruses next to giant buttons) by rewriting text prompts. The method combines an image evaluator, prompt rewriter, and prompt ranker. The image evaluator, built on Grounded SAM with adaptive refinements, identifies faithful counterfactual size generations. Using this evaluator, the authors construct the first counterfactual size dataset and train the rewriter and ranker via supervised learning and Direct Preference Optimization. Experiments on CoMat show AutoContra significantly outperforms baseline approaches including ChatGPT-4o and Promptist.

## Method Summary
AutoContra automatically generates counterfactual size images through a pipeline of prompt rewriting and evaluation. The framework consists of three main components: an image evaluator that detects and scores counterfactual size relationships in generated images, a prompt rewriter that generates multiple rewritten prompt candidates, and a prompt ranker that selects the optimal candidate. The image evaluator extends Grounded SAM with refinements including tiny-region filtering, exclusive mask processing, label verification via CLIP embeddings, and adaptive thresholding based on image-text alignment. The prompt rewriter is a fine-tuned GPT-2 model trained on positive rewrite pairs, while the ranker uses Direct Preference Optimization on triplets. The method achieves 30.3% accuracy on generating counterfactual size images compared to 10.2% for base prompts and 27.5% for ChatGPT-4o.

## Key Results
- AutoContra achieves 30.3% accuracy in generating counterfactual size images on CoMat
- Outperforms ChatGPT-4o (27.5%) and Promptist (8.2%) baselines
- Ablation studies confirm the importance of image evaluator refinements and the ranker component
- Constructs the first counterfactual size dataset with 1004 test pairs

## Why This Works (Mechanism)

### Mechanism 1
Adaptive thresholding in the image evaluator improves counterfactual size detection by dynamically adjusting Grounded SAM parameters based on image-text alignment. CLIP similarity between generated image I and text prompt T determines whether to use lower thresholds (bl, tl) for weaker alignment or higher thresholds (bg, tg) for stronger alignment. This prevents both false positives (masking irrelevant regions) and false negatives (missing true objects). Core assumption: CLIP similarity correlates with the likelihood that Grounded SAM will produce clean segmentations.

### Mechanism 2
Label verification via CLIP embedding comparison against a reference database corrects Grounded SAM misclassifications, enabling accurate size ratio computation. Extract masked image region → encode with CLIP → compare against precomputed embeddings of web objects → assign label with maximum cosine similarity. This separates detection (Grounded SAM) from classification (CLIP + reference DB). Core assumption: The reference database contains representative embeddings for all target object categories.

### Mechanism 3
Separating prompt generation (rewriter) from prompt selection (ranker) improves counterfactual accuracy by combining generative diversity with discriminative filtering. Rewriter (GPT-2, supervised fine-tuned on successful rewrites) generates 15 candidates via stochastic sampling. Ranker (GPT-2-large, DPO-trained on positive/negative pairs) scores candidates; highest score selected. This decouples exploration (rewrite) from exploitation (rank). Core assumption: The rewriter produces at least one viable candidate among the 15 samples; the ranker's preferences align with actual image evaluator rewards.

## Foundational Learning

- **Direct Preference Optimization (DPO)**: The ranker is trained via DPO on (base, positive, negative) triplets. Understanding how DPO converts preference data into policy optimization—without training a separate reward model—is essential for debugging ranker behavior.
- **Grounded SAM (Segment Anything Model with grounding)**: The image evaluator builds on Grounded SAM to produce segmentation masks with text labels. Understanding its box and text thresholds, and failure modes (overlapping masks, mislabeling), is critical for extending or debugging the evaluator.
- **CLIP multimodal embeddings**: CLIP is used twice: (1) adaptive threshold selection via image-text similarity, and (2) label verification via embedding comparison. Understanding cosine similarity in shared embedding space is necessary for both tasks.

## Architecture Onboarding

- **Component map**: Base prompt → GPT2 (rewriter, SFT) → 15 candidates → GPT2-large (ranker, DPO) → CoMat SDXL (image gen) → Image Evaluator (Grounded SAM + refinements) → Score
- **Critical path**: Base prompt → Rewriter (15 candidates) → Ranker (top-1 selection) → CoMat SDXL (image generation) → Evaluator (counterfactual verification)
- **Design tradeoffs**: Rewriter capacity vs speed (GPT-2 lightweight but limited diversity); candidate count vs latency (15 candidates linearly increases time); evaluator precision vs recall (adaptive thresholds balance false positives/negatives)
- **Failure signatures**: Single object missing (score = -τR × (1 + g)); both objects present but wrong size ratio (negative score = max(-τR, -Ab/As)); low CLIP similarity (below μb=0.33) triggers secondary handling path
- **First 3 experiments**:
  1. Validate evaluator on human-labeled subset: Replicate Section 3.5 ablation on the 235-image dataset
  2. Test rewriter candidate diversity: Generate 15 candidates for 20 base prompts; compute lexical diversity
  3. Ranker alignment check: For 50 held-out prompts, compute correlation between ranker scores and evaluator rewards

## Open Questions the Paper Calls Out

- **Open Question 1**: Can the AutoContra framework be effectively extended to control counterfactual attributes other than physical size, such as texture, material, or physical laws? (Basis: authors state method is "readily extensible to other counterfactual attributes")
- **Open Question 2**: Can the accuracy of counterfactual generation be improved beyond the current 30.3% ceiling to handle more complex or diverse object pairs? (Basis: authors note "overall accuracy remains relatively low" at 30.3%)
- **Open Question 3**: Do the revised prompts optimized for CoMat transfer effectively to other state-of-the-art text-to-image models? (Basis: method is trained and evaluated exclusively on CoMat SDXL)

## Limitations
- Dataset construction relies on undisclosed ChatGPT-4o few-shot prompts and τ_reward threshold
- Reference database of CLIP embeddings for label verification is not publicly specified
- Performance ceiling at 30.3% suggests significant room for improvement
- Framework only validated on counterfactual size, not other counterfactual attributes

## Confidence

| Claim | Confidence |
|-------|------------|
| AutoContra achieves 30.3% accuracy on CoMat | High |
| Adaptive threshold mechanism improves performance | Medium |
| Framework generalizes beyond 91-object dataset | Low |

## Next Checks

1. **Evaluator Robustness Test**: Apply the full image evaluator pipeline to a human-annotated subset of 50 counterfactual images. Verify that F1 score remains above 0.85 with all refinements active.
2. **Candidate Diversity Audit**: For 20 base prompts, generate 15 candidates using the fine-tuned rewriter. Measure lexical diversity (distinct n-gram ratio) and ensure it exceeds 0.3 to rule out mode collapse.
3. **Ranker Alignment Validation**: Compute Spearman correlation between ranker scores and evaluator rewards on 50 held-out prompts. If correlation falls below 0.5, retrain ranker with expanded triplet diversity or adjusted regularization.