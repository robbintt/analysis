---
ver: rpa2
title: Differentially Private High-dimensional Variable Selection via Integer Programming
arxiv_id: '2510.22062'
source_url: https://arxiv.org/abs/2510.22062
tags:
- have
- algorithm
- then
- support
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces two new differentially private algorithms
  for high-dimensional variable selection using mixed integer programming (MIP). The
  methods, called top-R and mistakes, leverage modern MIP techniques to efficiently
  explore the non-convex objective landscape without exhaustive combinatorial search.
---

# Differentially Private High-dimensional Variable Selection via Integer Programming

## Quick Facts
- **arXiv ID:** 2510.22062
- **Source URL:** https://arxiv.org/abs/2510.22062
- **Reference count:** 40
- **Primary result:** Two new differentially private algorithms for high-dimensional variable selection using mixed integer programming, achieving state-of-the-art support recovery in problems with up to 10,000 variables.

## Executive Summary
This paper introduces two novel differentially private algorithms for high-dimensional variable selection in sparse regression and classification settings. The methods leverage modern mixed integer programming (MIP) techniques to efficiently explore the non-convex objective landscape without exhaustive combinatorial search. The first method, "top-R," restricts the exponential mechanism to a tractable subset of high-quality solutions, while the second, "mistakes," improves empirical accuracy by grouping solutions based on Hamming distance from the optimal support. Both methods provide pure differential privacy guarantees and achieve superior support recovery compared to existing approaches, including MCMC-based methods.

## Method Summary
The paper proposes two algorithms for pure differentially private high-dimensional variable selection using mixed integer programming. Both methods operate by solving a sequence of MIPs to find the top R supports with the lowest loss, then sampling from a carefully constructed distribution over these supports. The "top-R" method assigns probabilities proportional to the exponential mechanism score for the top R supports, while the "mistakes" method partitions the support space based on Hamming distance from the optimal solution. The Outer Approximation algorithm is used to make the MIP approach scalable by avoiding exhaustive search through iterative linearization and cutting-plane methods.

## Key Results
- The top-R method provides pure DP guarantees with a mild identifiability condition and achieves state-of-the-art support recovery in sparse regression settings.
- The mistakes method achieves similar privacy guarantees under a slightly stronger but still realistic separation assumption, while performing better empirically.
- Both methods successfully handle problems with up to 10,000 variables, outperforming existing algorithms including MCMC-based approaches.
- Theoretical support recovery guarantees are provided for Best Subset Selection, showing sufficient conditions on the identifiability margin.

## Why This Works (Mechanism)

### Mechanism 1: Top-R Method
- **Claim:** Enables scalable pure differential privacy by restricting the exponential mechanism to a tractable subset of high-quality solutions.
- **Mechanism:** Solves MIP to find top R supports with lowest loss, assigns probabilities proportional to $\exp(-\epsilon R / 2\Delta)$ for these top R, and uses rejection sampling for the tail.
- **Core assumption:** Data boundedness (Assumption 1) is required to bound global sensitivity $\Delta$.
- **Evidence anchors:** [abstract] mentions "structured sampling procedures"; [section 2.1.1] details Algorithm 1; [corpus] supports MIP's role in interpretable ML.

### Mechanism 2: Mistakes Method
- **Claim:** Improves empirical accuracy by grouping solutions based on Hamming distance from the optimal support.
- **Mechanism:** Partitions support space into $P_0, \dots, P_s$ based on disagreements with optimal support $\tilde{S}_0$, samples from distribution where score depends on best objective value within each partition.
- **Core assumption:** Requires objective gap condition: $R(\hat{S}_2) - R(\hat{S}_1) > 2\Delta$.
- **Evidence anchors:** [abstract] states method "requires an additional separation assumption but performs better empirically"; [section 2.1.2] defines partitioning strategy.

### Mechanism 3: Outer Approximation
- **Claim:** Makes MIP approach scalable by avoiding exhaustive search of non-convex objective.
- **Mechanism:** Solves sequence of MIPs by linearizing loss function around current estimates, adds cutting planes to iteratively refine lower bound.
- **Core assumption:** Loss function $\ell$ must be convex in $\beta$ to allow gradient-based lower bounds.
- **Evidence anchors:** [section 4] details iterative cutting-plane method; [corpus] supports efficacy of advanced cut selection in MIP solvers.

## Foundational Learning

- **Concept: Global Sensitivity & Clipping**
  - **Why needed here:** Pure DP requires bounded sensitivity $\Delta$; clipping features $X$ and targets $y$ to constants $b_x, b_y$ bounds sensitivity.
  - **Quick check question:** If you clip the data too aggressively (small $b_x$), how might this affect the "Identifiability Margin" $\tau$?

- **Concept: Best Subset Selection (BSS) vs. Lasso**
  - **Why needed here:** This paper solves BSS ($\ell_0$ constraint) rather than convex relaxations; BSS is NP-hard, explaining why "structured sampling" is novel.
  - **Quick check question:** Why does the paper claim BSS is preferable for "interpretability" compared to Lasso?

- **Concept: The Exponential Mechanism**
  - **Why needed here:** Theoretical parent of proposed methods; utility is proportional to $\exp(-\epsilon \cdot \text{loss})$, explaining why only "Top-R" low-loss solutions are needed.
  - **Quick check question:** In standard exponential mechanism, why is probability of sampling high-loss solution practically zero, justifying truncation in "Top-R"?

## Architecture Onboarding

- **Component map:** Preprocessing (clipping) -> Optimization Core (MIP Solver) -> Privacy Engine (construct distribution) -> Sampler
- **Critical path:** MIP solver is bottleneck; Privacy Engine cannot instantiate until Optimization Core returns top R supports and their losses.
- **Design tradeoffs:**
  - $R$ (Number of Supports): Increasing $R$ improves support recovery probability but linearly increases MIP computation time.
  - Clipping Bounds ($b_x, b_y$): Large bounds increase noise ($\Delta$), hurting utility; small bounds clip signal, hurting $\tau$.
- **Failure signatures:**
  - Low Recovery Rate: If $n$ is small relative to $p$, signal is indistinguishable from noise.
  - MIP Timeout: If $p > 10,000$ or $s$ is large, Outer Approximation may stall.
  - Pure DP Violation: Running "Mistakes" without verifying gap condition may theoretically violate pure DP guarantees.
- **First 3 experiments:**
  1. Replicate Figure 1a (Least Squares): Run Top-R on synthetic data ($p=10,000, s=5$) to verify support recovery curve against MCMC baseline.
  2. Ablation on $R$ (Figure D.3): Vary $R$ to find "knee" in curve where support recovery saturates but runtime is acceptable.
  3. Clipping Sensitivity: Test how varying $b_x$ affects F1 score to determine if default 0.5 is robust for your data distribution.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the privacy guarantees for the "mistakes" method be achieved without relying on the high-probability separation assumption regarding the objective gap?
  - **Basis in paper:** [explicit] Conclusion states "it remains an open question whether a lighter assumption can be made to yield privacy guarantees for the mistakes method."
  - **Why unresolved:** Current proof relies on condition $R(\hat{S}_2) - R(\hat{S}_1) > 2\Delta$ occurring with high probability.
  - **What evidence would resolve it:** Modified proof strategy showing "mistakes" satisfies $(\epsilon, 0)$-DP under only standard boundedness assumption.

- **Open Question 2:** Are the sufficient conditions on the identifiability margin $\tau$ provided in Theorems 3 and 4 tight, or do significant gaps exist between these sufficient conditions and the necessary conditions?
  - **Basis in paper:** [explicit] Conclusion notes "it would be interesting to find necessary conditions as well, to see if our bounds on $\tau$ are tight."
  - **Why unresolved:** Paper establishes upper bounds for signal strength required for recovery but does not derive corresponding lower bounds.
  - **What evidence would resolve it:** Derivation of matching lower bounds (necessary conditions) for support recovery under differential privacy constraints.

- **Open Question 3:** Can rigorous theoretical support recovery guarantees be derived for the proposed methods when applied to general convex loss functions, such as hinge loss?
  - **Basis in paper:** [inferred] While abstract claims framework "applies broadly," theoretical analysis is restricted specifically to BSS setting.
  - **Why unresolved:** Theoretical proofs utilize properties specific to least squares objective and linear models.
  - **What evidence would resolve it:** Extending theoretical analysis of Theorems 3 and 4 to general convex loss functions.

## Limitations
- **Solver scalability:** While paper claims success for $p \leq 10,000$, exact solver configurations enabling this are not specified, creating uncertainty about reproducibility.
- **Separation margin sensitivity:** Theoretical guarantees depend on identifiability margin $\tau$ that may not hold in real-world data with correlated features.
- **Pure DP requirement:** The claim that "no prior work achieves pure DP" is technically true but should be qualified regarding $(\epsilon, \delta)$-DP with exponentially small $\delta$.

## Confidence

- **High Confidence:** Core mechanism (MIP-based sampling for pure DP) is sound and well-supported by theory; empirical results demonstrating superior performance are compelling.
- **Medium Confidence:** Theoretical guarantees (Theorems 3-4) are rigorous but rely on strong assumptions about data boundedness and identifiability that may not hold in practice.
- **Low Confidence:** Claim that "no prior work achieves pure DP" is technically true but requires qualification regarding practical sufficiency of $(\epsilon, \delta)$-DP.

## Next Checks
1. **Solver Configuration Validation:** Replicate the $p=10,000$ experiment using official code, documenting exact Gurobi parameters to verify claimed scalability.
2. **Real Data Transfer:** Test algorithms on real-world high-dimensional dataset (e.g., genomics) to assess performance when synthetic data assumptions are violated.
3. **Privacy Accounting Audit:** For "Mistakes" method, implement numerical check that Hamming distance-based partitioning satisfies required gap condition for pure DP on your data.