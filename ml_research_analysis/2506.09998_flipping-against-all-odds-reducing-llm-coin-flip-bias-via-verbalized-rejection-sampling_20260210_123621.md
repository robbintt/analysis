---
ver: rpa2
title: 'Flipping Against All Odds: Reducing LLM Coin Flip Bias via Verbalized Rejection
  Sampling'
arxiv_id: '2506.09998'
source_url: https://arxiv.org/abs/2506.09998
tags:
- sampling
- probability
- sample
- llms
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of large language models (LLMs)
  generating biased samples from Bernoulli distributions despite being able to accurately
  describe them. The authors introduce Verbalized Rejection Sampling (VRS), a method
  that adapts classical rejection sampling to work within natural language by prompting
  the LLM to accept or reject proposed samples based on textual descriptions of target
  and proposal distributions.
---

# Flipping Against All Odds: Reducing LLM Coin Flip Bias via Verbalized Rejection Sampling

## Quick Facts
- **arXiv ID:** 2506.09998
- **Source URL:** https://arxiv.org/abs/2506.09998
- **Reference count:** 40
- **Primary result:** VRS reduces sampling bias by 50%+ in STVD scores across four LLMs

## Executive Summary
This paper addresses the problem of large language models (LLMs) generating biased samples from Bernoulli distributions despite being able to accurately describe them. The authors introduce Verbalized Rejection Sampling (VRS), a method that adapts classical rejection sampling to work within natural language by prompting the LLM to accept or reject proposed samples based on textual descriptions of target and proposal distributions. Experiments across four different LLMs show that VRS substantially reduces sampling bias, with Sum of TV Distance (STVD) scores dropping by over 50% compared to direct sampling in most cases. Theoretical analysis demonstrates that VRS can produce less biased samples than direct sampling under mild assumptions, with improvements arising from both the algorithm itself and prompt design.

## Method Summary
VRS adapts classical rejection sampling to LLM workflows by verbalizing the accept/reject decision process. For each target probability p, the LLM is prompted to evaluate whether a proposed sample x from a fixed proposal distribution Q (Bern(0.5) in experiments) should be accepted to produce a sample from the target Bernoulli(p) distribution. The LLM computes the acceptance probability A(x) = p/(M·q) where M is the likelihood ratio bound, then outputs T/F for acceptance. This process repeats until 100 accepted samples are collected. The method is compared against direct sampling where the LLM directly generates samples from the target distribution. Four prompt phrasings are tested, and performance is evaluated using Sum of TV Distance (STVD) across 101 probability values from 0.0 to 1.0.

## Key Results
- VRS reduces STVD scores by over 50% compared to direct sampling across all four tested LLMs (Llama-3.1 70B, GPT-4.1-nano, DeepSeekV3, Qwen-2.5 72B)
- Theoretical analysis shows VRS can outperform direct sampling when the biased event is rare (Q(x̂) small) and the LLM's accept/reject bias is bounded
- Prompt phrasing affects direct sampling performance significantly, but VRS reduces this gap, making the method more robust to phrasing choices
- The fixed proposal distribution Q = Bern(0.5) provides good performance but may be suboptimal for extreme probability values

## Why This Works (Mechanism)

### Mechanism 1: Algorithmic Error Dampening via Rejection Sampling Structure
VRS reduces bias primarily through the mathematical structure of rejection sampling, which dampens LLM sampling errors when the proposal distribution is well-chosen. When the LLM's acceptance decision is biased (Ã(x) = A(x) + e(x)), the resulting distribution error is bounded by Q(x̂)Mc/(1 - Q(x̂)Mc), where Q(x̂) ≤ 1 acts as a multiplicative dampener on the bias term c. The proposal distribution's probability mass "absorbs" some of the error. This works when the LLM can accurately perform accept/reject decisions for trivial cases (A(x) = 1) and bias is concentrated in non-trivial cases.

### Mechanism 2: Accept/Reject Framing Disrupts Default Sampling Biases
Framing the task as evaluating whether to accept/reject a proposed sample engages different reasoning patterns than direct sample generation, partially reducing bias. The VRS prompt template positions the LLM as a rejection sampler evaluating a candidate, which may bypass pretraining-induced biases toward generating "1" (observed in direct sampling's tendency toward positive outcomes). This framing effect contributes to VRS's improvement, though it's not the primary mechanism.

### Mechanism 3: Asymmetric Error Propagation from Fixed Proposal
Using a fixed proposal Q = Bern(0.5) creates asymmetric conditions where acceptance probability varies with target p, allowing partial error cancellation across repeated trials. For p > 0.5, A(1) = 1 (always accept x=1), placing no demands on stochastic decision-making. For p < 0.5, A(0) = 1. This asymmetry means the LLM only needs stochastic behavior for one outcome at any given p, halving the opportunity for bias injection.

## Foundational Learning

- **Concept: Rejection Sampling**
  - Why needed here: VRS is a direct adaptation of classical rejection sampling. Without understanding how M bounds the likelihood ratio and how acceptance probability A(x) = P(x)/(M·Q(x)) guarantees correct target distribution, the algorithm's error-dampening properties are opaque.
  - Quick check question: Given target Bern(0.3) and proposal Bern(0.5), compute M and the acceptance probability for x=1.

- **Concept: Total Variation (TV) Distance**
  - Why needed here: The paper quantifies bias using Sum of TV Distance (STVD). TV distance measures the maximum probability difference between distributions—essential for interpreting whether VRS's 50%+ STVD reduction is practically meaningful.
  - Quick check question: Two Bernoulli distributions with parameters 0.3 and 0.45—what is their TV distance?

- **Concept: LLM Token Sampling (Temperature, Top-k)**
  - Why needed here: The paper deliberately fixes decoding hyperparameters to defaults, assuming no access. Understanding how temperature affects token probability distributions clarifies why the authors treat the LLM as a black-box sampler rather than manipulating logits.
  - Quick check question: If temperature → 0, how does this affect the diversity of LLM outputs for a sampling task?

## Architecture Onboarding

- **Component map:** Python-side Proposal Generator -> VRS Prompt Template (target P, proposal Q, sample x) -> LLM (outputs T/F) -> Sample Collector (accumulates accepted samples) -> Evaluation Pipeline (computes STVD)

- **Critical path:**
  1. For each target p ∈ {0.0, 0.01, ..., 1.0}:
     2. Loop until 100 samples accepted:
        3. Generate x ~ Bern(0.5) externally
        4. Construct VRS prompt with target p, proposal q=0.5, sample x
        5. Query LLM, parse output for T/F
        6. If T, append x to accepted samples
  7. Compute empirical frequency of 1s in accepted samples
  8. Compute STVD across all p values

- **Design tradeoffs:**
  - Proposal distribution choice: Q = Bern(0.5) is simple but may be suboptimal for extreme p values where M is large. Closer proposal to target reduces M and tightens error bounds, but requires adaptive proposal selection.
  - Acceptance rate vs. sample quality: Lower acceptance rate α = 1/M means more queries per accepted sample, increasing cost. Trade-off between efficiency and bias reduction.
  - Prompt phrasing: Four variants (P1, P0, P10, P01) tested. Balanced phrasings (stating both probabilities) performed better for direct sampling but VRS reduces the gap across all phrasings.

- **Failure signatures:**
  - VRS outputs all T or all F: LLM not engaging in stochastic decision-making; check temperature settings or prompt formatting.
  - Calibration plot shows step function: Suggests LLM is thresholding rather than sampling (e.g., always accepting for p > 0.5, always rejecting otherwise).
  - STVD > direct sampling: Indicates c exceeds bound in Corollary 1; proposal may be poorly matched to target, or LLM has severe bias even for A(x) = 1.
  - Infinite loop: Acceptance rate too low (M >> 1); consider switching proposal distribution or falling back to direct sampling for extreme p.

- **First 3 experiments:**
  1. Baseline calibration: Run direct sampling with your target LLM across p ∈ {0.0, 0.25, 0.5, 0.75, 1.0} (subset for speed), 50 samples each. Plot empirical frequency vs. true p. Confirm bias pattern matches paper (tendency toward 1s for imbalanced prompts).
  2. VRS acceptance rate validation: Fix p=0.3, q=0.5. Run 100 VRS accept/reject queries with fixed sample x=1. Analytical acceptance probability is A(1) = 0.3/(1.5×0.5) = 0.4. Check if empirical acceptance rate approximates 0.4.
  3. Full VRS calibration: Run VRS across same p values, collect 50 accepted samples per p. Compare STVD to direct sampling baseline. Expect 40-60% reduction based on paper results.

## Open Questions the Paper Calls Out

- **Can VRS be extended to categorical or continuous distributions?** The authors state that the study is limited to the Bernoulli case and that extending the framework to broader families remains an important direction. The theoretical bounds and prompt templates were derived specifically for binary outcomes; natural language evaluation of complex probability densities or high-dimensional spaces may not yield the same error correction.

- **How does the choice of proposal distribution Q affect performance?** The experiments fix Q to a uniform Bernoulli (q=0.5), while the theoretical error bound depends on the ratio M and the acceptance rate α. A proposal distribution that is poorly matched to the target increases M and decreases the acceptance rate, which theoretically amplifies the impact of the LLM's inherent decision bias (c).

- **Can other classical probabilistic algorithms be verbalized?** The authors conclude that VRS illustrates how classical tools can be verbalized, implying that rejection sampling is just one instance of a broader class of potential interventions. It is unclear if the specific "accept/reject" binary decision is uniquely suited to mitigate LLM bias, or if other mechanisms like weighted resampling would fail due to similar reasoning errors.

## Limitations

- The method's effectiveness depends on prompt phrasing, though VRS reduces this sensitivity compared to direct sampling
- Theoretical guarantees assume the LLM is unbiased when acceptance probability is 1, which is empirically supported but not rigorously proven
- Fixed proposal distribution Q = Bern(0.5) may be suboptimal for extreme probability values, limiting gains for p near 0 or 1
- Results are limited to Bernoulli sampling; generalization to multi-class or continuous distributions remains unexplored

## Confidence

- **High confidence**: VRS consistently reduces sampling bias across multiple LLMs and prompt phrasings, with STVD improvements exceeding 50% in most cases. The theoretical error bound showing VRS can outperform direct sampling under mild conditions is mathematically sound.
- **Medium confidence**: The relative contributions of algorithm vs. prompt framing to bias reduction are partially understood but not definitively quantified. The assumption that LLM bias concentrates in non-trivial acceptance cases (A(x) < 1) is empirically supported but not rigorously proven.
- **Low confidence**: Generalization of VRS to continuous distributions or multi-class settings remains unexplored. The paper's focus on Bernoulli sampling limits claims about broader applicability.

## Next Checks

1. **Prompt framing ablation**: Systematically vary prompt templates beyond the four tested phrasings to isolate the contribution of framing effects vs. algorithmic improvements. Test prompts that explicitly instruct the LLM to "sample" vs. "evaluate acceptance."

2. **Proposal distribution optimization**: Implement adaptive proposal selection where Q is chosen based on target p to minimize M and improve acceptance rates. Compare STVD against fixed Q = Bern(0.5) for extreme probability values.

3. **Cross-distribution generalization**: Extend VRS to categorical distributions with k > 2 outcomes. Measure whether the error-dampening mechanism scales to higher-dimensional spaces or if new failure modes emerge.