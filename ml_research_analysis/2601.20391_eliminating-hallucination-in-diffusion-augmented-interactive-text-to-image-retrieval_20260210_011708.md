---
ver: rpa2
title: Eliminating Hallucination in Diffusion-Augmented Interactive Text-to-Image
  Retrieval
arxiv_id: '2601.20391'
source_url: https://arxiv.org/abs/2601.20391
tags:
- query
- diffusion
- retrieval
- text
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Diffusion-augmented interactive text-to-image retrieval (DAI-TIR)
  can be undermined by hallucinated visual cues in diffusion-generated query images.
  These cues conflict with the user's textual intent, degrading retrieval performance.
---

# Eliminating Hallucination in Diffusion-Augmented Interactive Text-to-Image Retrieval

## Quick Facts
- **arXiv ID**: 2601.20391
- **Source URL**: https://arxiv.org/abs/2601.20391
- **Reference count**: 40
- **Primary result**: DMCL achieves up to 7.37% improvement in multi-round Hits@10 by suppressing hallucinated cues in diffusion-augmented retrieval

## Executive Summary
Diffusion-augmented interactive text-to-image retrieval (DAI-TIR) faces a critical challenge: hallucinated visual details in diffusion-generated query images that conflict with user intent and degrade retrieval performance. This paper proposes Diffusion-aware Multi-view Contrastive Learning (DMCL), a training framework that aligns multiple query views (text, diffusion, and fused) with target images while suppressing hallucinated details. Through semantic-consistency and diffusion-aware contrastive objectives, DMCL enforces multi-view alignment and reduces cross-view drift. Extensive experiments on five benchmarks demonstrate consistent improvements in retrieval performance, with attention visualization and embedding-space analyses confirming the method's ability to filter hallucinated cues.

## Method Summary
The paper addresses hallucination in diffusion-augmented retrieval by introducing DMCL, which trains models to align multiple query representations while suppressing hallucinated details. The framework generates three query views: textual, diffusion-generated, and fused representations. DMCL employs semantic-consistency objectives to ensure all views align with the target image, while diffusion-aware contrastive learning specifically targets the reduction of hallucinated cues by comparing clean and hallucinated views. During training, synthetic hallucination injection helps the model learn to distinguish between faithful and unfaithful visual details. The multi-view alignment approach ensures that retrieval remains grounded in user intent rather than diffusion artifacts.

## Key Results
- DMCL achieves consistent improvements in multi-round Hits@10 across five benchmarks
- Performance gains reach up to 7.37% over prior methods
- Attention visualization confirms effective filtering of hallucinated cues
- Embedding-space analyses demonstrate improved semantic alignment between query and target images

## Why This Works (Mechanism)
The method works by training the retrieval model to recognize and suppress hallucinated visual details through contrastive learning across multiple query representations. By forcing alignment between text, diffusion, and fused views while specifically addressing cross-view drift, DMCL teaches the model to prioritize user intent over diffusion artifacts. The semantic-consistency objective ensures all views represent the same semantic content, while the diffusion-aware contrastive component learns to distinguish faithful visual details from hallucinations.

## Foundational Learning
- **Multi-view contrastive learning**: Needed to align different representations of the same query; check by verifying consistent embeddings across text/diffusion/fused views
- **Cross-view drift reduction**: Required to prevent semantic misalignment between query representations; verify through embedding similarity metrics
- **Hallucination detection**: Essential for identifying unfaithful visual details; validate using synthetic hallucination injection experiments
- **Semantic-consistency objectives**: Critical for maintaining alignment with user intent; test through retrieval performance on ambiguous queries
- **Diffusion-aware contrastive objectives**: Necessary to specifically target hallucinated content; evaluate by comparing clean vs. hallucinated view embeddings
- **Attention visualization analysis**: Important for qualitative verification of hallucination filtering; confirm through attention map comparison

## Architecture Onboarding

**Component Map**: User query -> Text encoder, Diffusion generator, Fuser -> Multi-view representations -> Contrastive learning modules -> Aligned embeddings -> Retrieval

**Critical Path**: Query input → Multi-view generation (text, diffusion, fused) → Contrastive learning (semantic-consistency + diffusion-aware) → Aligned embeddings → Retrieval scoring

**Design Tradeoffs**: Multi-view alignment increases computational complexity but improves retrieval accuracy; synthetic hallucination injection during training may not fully capture real-world patterns but provides controlled learning signals

**Failure Signatures**: Retrieval performance degrades when diffusion artifacts strongly contradict textual intent; attention maps show diffusion-generated details dominating over semantic content; embedding spaces show poor alignment between text and diffusion views

**First Experiments**: 1) Ablation study removing diffusion-aware contrastive objective, 2) User study comparing retrieved images for complex queries, 3) Real-world testing on naturally ambiguous textual descriptions

## Open Questions the Paper Calls Out
None

## Limitations
- Synthetic hallucination injection may not capture all real-world hallucinatory patterns
- Evaluation focuses on retrieval performance metrics without deeper analysis of user intent alignment
- Multi-view alignment assumes views can be effectively harmonized when they may fundamentally disagree

## Confidence
- **Claim that DMCL effectively suppresses hallucinated cues**: Medium confidence - retrieval performance improves but evidence is primarily qualitative
- **Claim that multi-view alignment is key to improving retrieval**: Medium confidence - consistent improvements observed but alternative explanations not fully explored
- **Claim of robustness across different datasets**: High confidence - consistent performance improvements across five benchmarks

## Next Checks
1. Conduct user studies to verify retrieved images using DMCL better match user intent compared to baseline methods, particularly for complex queries
2. Perform ablation studies removing the diffusion-aware contrastive objective to isolate its specific contribution to hallucination suppression
3. Test DMCL on real-world queries with known hallucinatory tendencies to evaluate performance on naturally occurring hallucination scenarios