---
ver: rpa2
title: 'Skip-Thinking: Chunk-wise Chain-of-Thought Distillation Enable Smaller Language
  Models to Reason Better and Faster'
arxiv_id: '2505.18642'
source_url: https://arxiv.org/abs/2505.18642
tags:
- reasoning
- training
- answer
- rationale
- chunks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces chunk-wise training (CWT) and skip-thinking
  training (STT) to address two issues in chain-of-thought (CoT) distillation: (1)
  gradient over-smoothing caused by long rationales, leading to superficial understanding,
  and (2) slow response time due to full rationale generation. CWT divides rationales
  into semantically coherent chunks and trains the model on one chunk per iteration,
  reducing token-level batch size and focusing learning on core reasoning logic.'
---

# Skip-Thinking: Chunk-wise Chain-of-Thought Distillation Enable Smaller Language Models to Reason Better and Faster

## Quick Facts
- arXiv ID: 2505.18642
- Source URL: https://arxiv.org/abs/2505.18642
- Authors: Xiao Chen; Sihang Zhou; Ke Liang; Xiaoyu Sun; Xinwang Liu
- Reference count: 23
- Key outcome: CWT+STT improves reasoning accuracy and inference speed compared to state-of-the-art baselines on seven reasoning tasks across three SLMs

## Executive Summary
This paper addresses two limitations in chain-of-thought (CoT) distillation for small language models: gradient over-smoothing from long rationales and slow inference due to full rationale generation. The authors propose chunk-wise training (CWT) that segments rationales into semantically coherent chunks and trains on one chunk per iteration, reducing token-level batch size and focusing learning on core reasoning logic. Building on CWT, skip-thinking training (STT) identifies non-essential chunks that can be skipped during inference, enabling faster responses while preserving accuracy. Experiments across seven reasoning tasks show significant improvements in both accuracy and speed compared to baseline methods.

## Method Summary
The method combines chunk-wise training (CWT) with skip-thinking training (STT). First, rationales are generated by a large language model and segmented into M chunks using search-based chunking (SBC) that iteratively merges adjacent steps based on loss reduction. CWT trains the small language model (SLM) on one chunk per iteration with stage prefixes ([1], [2], etc.), reducing gradient over-smoothing. After CWT convergence, skip data generation identifies chunks whose removal doesn't affect answer correctness. STT retrains the SLM from scratch using both CWT data and skip data with [skip] prefixes for non-essential chunks. At inference, prompting with [skip]⊕question enables the model to output key chunks plus the answer.

## Key Results
- CWT with SBC improves reasoning accuracy over full-thinking training and average chunking across all tasks
- STT achieves 1.08-1.89x speedup with minimal accuracy loss compared to full-thinking models
- The method generalizes across three SLM sizes (124M-774M) and seven reasoning benchmarks
- Base models with SBC outperform average chunking baselines on all tested tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Chunk-wise training (CWT) mitigates gradient over-smoothing by reducing token-level batch size per iteration, allowing core reasoning tokens to contribute proportionally more to parameter updates.
- **Mechanism:** The paper formalizes gradient as ∂L/∂ϑ = (1/N)(Σ∂ℓ_core/∂ϑ + Σ∂ℓ_non-core/∂ϑ). When rationales are long, N (token-level batch size) is large, and |S_non-core| ≫ |S_core|, causing core reasoning token gradients to be smoothed away. CWT segments rationales into M chunks, training on one chunk per iteration, thereby reducing N and increasing the relative contribution of core tokens in reasoning-focused chunks.
- **Core assumption:** Core reasoning tokens (e.g., mathematical expressions, key intermediate results) are sparsely distributed; non-reasoning tokens (transitions, summaries) are semantically similar across samples and thus compound gradient averaging.
- **Evidence anchors:**
  - [abstract] "Long rationales lead to a large token-level batch size during training, making gradients of core reasoning tokens over-smoothed as they contribute a tiny fraction of the rationale."
  - [section 3, equation 3] Formal decomposition showing |S2| ≫ |S1| causes smoothing.
  - [corpus] Related work on rationale quality (arXiv:2509.23574) supports selective distillation but doesn't address gradient dynamics directly.
- **Break condition:** If core reasoning tokens are uniformly distributed across chunks (no concentration), chunk isolation won't increase their relative gradient contribution; CWT effectiveness degrades.

### Mechanism 2
- **Claim:** Search-based chunking (SBC) produces semantically coherent chunks that preserve reasoning fluency better than average chunking.
- **Mechanism:** SBC uses model loss as heuristic information—iteratively adjusting chunk boundaries by merging adjacent reasoning steps and evaluating loss reduction. Lower loss indicates the SLM better comprehends the chunk's internal logic, suggesting semantic coherence.
- **Core assumption:** Loss on a token sequence correlates with the model's comprehension of that sequence's semantic unity.
- **Evidence anchors:**
  - [section 4.1.2] "As the loss decreases, we infer that the reasoning steps allocated to this chunk are more comprehensible to the SLM."
  - [table 1] Base w. SBC outperforms Base w. AC across all tasks; AC sometimes degrades performance.
  - [corpus] No direct corpus validation of loss-based chunking heuristics; evidence is internal to this paper.
- **Break condition:** Greedy search may converge to local optima; simulated annealing can mitigate (Appendix H), but global optimality isn't guaranteed.

### Mechanism 3
- **Claim:** Skip-thinking training (STT) accelerates inference by internalizing non-essential chunks while preserving accuracy.
- **Mechanism:** After CWT, the skip data generator sequentially removes chunks and evaluates answer correctness. If the answer remains correct without a chunk, that chunk is deemed non-essential and replaced with a [thought] token, training the model to perform implicit reasoning for that segment.
- **Core assumption:** Language models can encode some reasoning in latent space without degrading final answer correctness, provided key reasoning steps remain explicit.
- **Evidence anchors:**
  - [section 4.2] "STT makes the SLM automatically skip non-reasoning medium chunks to reach the answer."
  - [table 4] Speedup ratios of 1.08–1.89x across datasets; minimal accuracy loss vs. full-thinking.
  - [corpus] ICoT-SI (Deng et al., 2024) supports latent reasoning but notes accuracy tradeoffs; STT differs by selective externalization.
- **Break condition:** Tasks requiring parallel reasoning (e.g., LLC dataset) or where all steps are interdependent show minimal speedup—internalization fails when no chunk is safely skippable.

## Foundational Learning

- **Concept:** Gradient over-smoothing in large-batch training
  - **Why needed here:** Understanding why long rationales hurt learning requires grasping how averaged gradients across many tokens dilute signal from sparse "important" tokens.
  - **Quick check question:** If you double the sequence length while keeping the number of core reasoning tokens constant, what happens to each core token's gradient contribution?

- **Concept:** Chain-of-thought distillation mechanics
  - **Why needed here:** The method builds on standard CoT distillation; you need to understand the baseline (teacher generates rationale → student learns to predict it) to see what CWT modifies.
  - **Quick check question:** In standard CoT distillation, what token sequence does the student model learn to generate?

- **Concept:** Reasoning internalization vs. explicit scratchpad
  - **Why needed here:** STT's core hypothesis is that some reasoning can be latent; you need to understand the tradeoff between externalized reasoning (transparent, slower) and latent reasoning (opaque, faster).
  - **Quick check question:** What could go wrong if you internalize too many reasoning steps in a multi-step arithmetic problem?

## Architecture Onboarding

- **Component map:** Rationale Generator -> Chunk Data Generator (SBC) -> CWT Training Loop -> Skip Data Generator -> STT Training Loop
- **Critical path:**
  1. Generate rationales from LLM (few-shot CoT prompts).
  2. Initialize chunks via average chunking, then refine with SBC before each epoch.
  3. Train SLM with CWT until convergence.
  4. Generate skip data by chunk removal + correctness check.
  5. Train SLM with STT (reinitialize from pretrained weights, not CWT checkpoint).
  6. At inference: prompt with [skip] ⊕ question → model outputs key chunks + answer.
- **Design tradeoffs:**
  - **M (chunk count):** Higher M → smaller chunks → better gradient isolation but more training stages. Paper suggests M ≈ average reasoning steps for structured tasks; higher for variable tasks (math).
  - **η (SBC threshold):** Controls how aggressively chunks are merged. η = 0.1 used; lower = more conservative.
  - **Skip aggressiveness:** SkipALL (all chunks → [thought]) degrades accuracy severely on parallel-reasoning tasks. STT's correctness gate is essential.
- **Failure signatures:**
  - **Repetitive generation:** Sentence-wise or step-wise training (no fixed M) causes loops—model doesn't know when to stop.
  - **Sharp minima:** Base model generates fluent but incorrect rationales; confident on non-reasoning tokens, uncertain on core tokens.
  - **Hallucination in long rationales:** Full-thinking models accumulate errors; skip-thinking reduces surface for hallucination.
- **First 3 experiments:**
  1. **Reproduce gradient smoothing claim:** Train GPT-2-base on a single arithmetic dataset (e.g., AddSub) with full rationale vs. CWT (M=4). Measure accuracy gap and token-level confidence on core vs. non-core tokens.
  2. **Validate SBC vs. AC:** Compare chunk coherence by inspecting boundaries on 20 samples. Verify Table 1's SBC > AC trend holds on a held-out task.
  3. **Pilot STT speedup:** After CWT, run skip data generation on TSO (deterministic swaps) vs. LLC (parallel subtasks). Measure speedup ratio and accuracy delta; expect TSO ~1.3x, LLC ~1.0x.

## Open Questions the Paper Calls Out
- Can globally optimal chunking algorithms outperform the greedy search-based chunking (SBC) method, and what efficiency-accuracy trade-offs exist?
- What principled method can automatically determine the optimal number of chunks M for different reasoning tasks?
- Why does the skip-thinking acceleration ratio vary dramatically across task types (1.08x for LLC vs. 1.89x for MA)?

## Limitations
- Gradient over-smoothing theory relies on simplified gradient decomposition without direct empirical validation
- Skip data generation depends on binary correctness checking that may not capture nuanced reasoning quality
- Method shows strongest results on structured reasoning tasks; generalization to open-domain reasoning remains limited

## Confidence
**High Confidence:** CWT improves accuracy over full-thinking training on structured reasoning tasks; SBC produces more coherent chunks than average chunking; STT provides measurable inference speedups on skippable tasks; [answer] prefix is essential for stage-aware training
**Medium Confidence:** Gradient over-smoothing is the primary mechanism limiting full-thinking training effectiveness; Skip-thinking preserves accuracy while achieving speedups (task-dependent); The proposed method generalizes across different SLM sizes
**Low Confidence:** The specific value M=4 is optimal for all arithmetic tasks; SBC's greedy search reliably finds globally optimal chunk boundaries; Skip-thinking will scale effectively to open-domain reasoning without modification

## Next Checks
- **Validation Check 1:** Measure actual gradient magnitudes for core vs. non-core tokens during full-thinking vs. CWT training to validate gradient over-smoothing hypothesis
- **Validation Check 2:** Test stability of skip data generation across multiple runs and implement "near-miss" tolerance for answer checking
- **Validation Check 3:** Apply complete CWT+STT pipeline to numerical commonsense reasoning or multi-hop QA to test cross-domain generalization