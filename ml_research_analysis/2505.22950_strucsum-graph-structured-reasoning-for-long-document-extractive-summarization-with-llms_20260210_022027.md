---
ver: rpa2
title: 'StrucSum: Graph-Structured Reasoning for Long Document Extractive Summarization
  with LLMs'
arxiv_id: '2505.22950'
source_url: https://arxiv.org/abs/2505.22950
tags:
- sentence
- summarization
- prompting
- sentences
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of extractive summarization
  for long documents using large language models (LLMs) in a zero-shot setting. The
  authors propose StrucSum, a structure-aware prompting framework that leverages sentence-level
  graph structures to enhance LLM reasoning.
---

# StrucSum: Graph-Structured Reasoning for Long Document Extractive Summarization with LLMs

## Quick Facts
- **arXiv ID**: 2505.22950
- **Source URL**: https://arxiv.org/abs/2505.22950
- **Reference count**: 16
- **Primary result**: StrucSum improves extractive summarization for long documents by leveraging graph-structured sentence relationships, achieving 19.2% higher FactCC and 8.0% higher SummaC scores on ArXiv compared to vanilla prompting

## Executive Summary
This paper addresses the challenge of extractive summarization for long documents using large language models (LLMs) in a zero-shot setting. The authors propose StrucSum, a structure-aware prompting framework that leverages sentence-level graph structures to enhance LLM reasoning. StrucSum incorporates three strategies: Neighbor-Aware Prompting (NAP) for local context, Centrality-Aware Prompting (CAP) for importance estimation, and Centrality-Guided Masking (CGM) for efficient input reduction. Experiments on ArXiv, PubMed, and Multi-News datasets demonstrate consistent improvements in both summary quality and factual consistency compared to vanilla prompting and unsupervised baselines.

## Method Summary
StrucSum operates as a zero-shot, training-free framework that constructs a Text-Attributed Graph (TAG) from document sentences using Sentence-BERT embeddings and cosine similarity thresholds. The framework extracts structural signals including neighbor lists and centrality scores, then injects these signals into LLM prompts through three strategies: NAP appends neighbor information for local context, CAP includes centrality scores to guide importance estimation, and CGM masks low-centrality sentences to reduce input length. The LLM selects sentence indices based on these prompts, which are then assembled into the final summary.

## Key Results
- On ArXiv dataset, StrucSum increases FactCC factual consistency scores by 19.2 percentage points and SummaC scores by 8.0 percentage points compared to vanilla prompting
- StrucSum achieves consistent ROUGE improvements across ArXiv, PubMed, and Multi-News datasets
- Individual strategies outperform combined approaches in ablation studies, with NAP showing the strongest factual consistency gains while CGM provides the most efficient ROUGE improvements

## Why This Works (Mechanism)
StrucSum leverages graph-structured reasoning by representing documents as Text-Attributed Graphs where sentences are nodes connected by semantic similarity edges. This structure captures local context (through neighbor relationships), global importance (through centrality scores), and enables selective information preservation (through masking). By injecting these structural signals into LLM prompts, the model gains explicit awareness of sentence relationships and importance, leading to more coherent and factually consistent summaries. The zero-shot approach avoids the need for domain-specific fine-tuning while still achieving strong performance through careful prompt engineering.

## Foundational Learning

- **Concept**: Text-Attributed Graph (TAG)
  - **Why needed here**: This is the core data structure StrucSum uses to represent a document. Understanding it is essential because all three prompting strategies (NAP, CAP, CGM) are derived from the TAG's nodes (sentences) and edges (semantic similarity links).
  - **Quick check question**: How would a TAG change if you used a different sentence embedding model or a different similarity threshold? How would that affect the edges and subsequent centrality scores?

- **Concept**: Extractive vs. Abstractive Summarization
  - **Why needed here**: StrucSum is explicitly designed for *extractive* summarization, which selects sentences. This is a key design choice that limits the search space to sentences that exist in the source, aiming for higher factual consistency. This is in contrast to *abstractive* methods which can hallucinate.
  - **Quick check question**: Why might an extractive summary be preferred in a legal or scientific domain, even if it's less fluent than an abstractive one?

- **Concept**: Zero-Shot, Training-Free Inference
  - **Why needed here**: The entire StrucSum framework operates under this paradigm. It means there are no gradient updates or fine-tuning. The LLM is used "out of the box" via a carefully constructed prompt. This has major implications for cost, speed of iteration, and generalizability.
  - **Quick check question**: What are the primary trade-offs of a zero-shot prompting approach compared to fine-tuning a smaller model, especially regarding latency and per-query cost?

## Architecture Onboarding

- **Component map**:
  1. Pre-processor -> Text-Attributed Graph construction using Sentence-BERT and similarity threshold
  2. Signal Extractor -> Derives neighbor lists and centrality scores from TAG
  3. Prompt Constructor -> Assembles final prompt with structural signals
  4. LLM Executor -> Sends prompt to LLM and receives selected sentence indices
  5. Post-processor -> Gathers selected sentences to form summary

- **Critical path**:
  1. Accurate Graph Construction: The entire system depends on the TAG. If the sentence embeddings or similarity threshold are poor, the structural signals will be noisy.
  2. Reliable LLM Output Parsing: The LLM must output sentence indices in the expected JSON format. A failure here breaks the pipeline. The prompt must be robustly designed to enforce this.

- **Design tradeoffs**:
  - **NAP**: Highest factual consistency gains (FactCC/SummaC) but significantly increases prompt length (+50-60%). Best when accuracy is paramount and context window is not a bottleneck.
  - **CAP**: A middle ground, adding some length (+15-18%). Explicitly guides the model with importance scores. Good when you want to steer but not filter.
  - **CGM**: Most efficient, reducing prompt length by 40-50%. Maximizes ROUGE scores but may discard nuanced details. Best for very long documents or latency/cost-sensitive applications.

- **Failure signatures**:
  - Spurious Edges: A low similarity threshold creates an overly dense graph, making centrality scores meaningless and neighbor lists too long and noisy.
  - Aggressive Masking (CGM): If the cumulative centrality threshold (ρ) is too low, key but less central sentences are masked, reducing recall.
  - LLM Format Drift: The model returns prose instead of a JSON list of indices, requiring retry logic or output parsing heuristics.
  - Neighbor List Overload: For a very large document, NAP could create a prompt that exceeds the LLM's context window.

- **First 3 experiments**:
  1. Baseline & Hyperparameter Sweep: Establish a baseline with vanilla prompting. Then, perform a grid search over the key hyperparameters: k (number of sentences to select) and θ (similarity threshold for TAG). The paper suggests k=7 and θ≈0.7-0.8 are good starting points on ArXiv/PubMed. Measure ROUGE and FactCC.
  2. Ablation by Strategy: Run experiments using each strategy (NAP, CAP, CGM) individually. Compare their ROUGE, FactCC, and SummaC scores to the baseline to understand which structural signal provides the most value for a given dataset (e.g., NAP for factuality, CGM for ROUGE).
  3. Failure Analysis on Masking: Use CGM with a moderate threshold (ρ=0.8). For a sample of documents, manually inspect the sentences that were masked. Correlate this with any drop in ROUGE score to understand what kind of information is being lost and if ρ should be tuned.

## Open Questions the Paper Calls Out
None

## Limitations
- The zero-shot prompting approach may not generalize well across domains with different discourse structures, requiring domain-specific hyperparameter tuning
- The structural signals derived from sentence similarity graphs may not transfer effectively to domains like legal documents or creative writing
- The ablation study reveals that combining strategies degrades performance, suggesting potential interference between structural signals that needs further investigation

## Confidence
- **High confidence**: The experimental results demonstrating improved ROUGE and factual consistency scores compared to vanilla prompting and unsupervised baselines are robust, with specific metrics (FactCC +19.2%, SummaC +8.0% on ArXiv) providing clear evidence of effectiveness.
- **Medium confidence**: The claim that individual strategies perform better than combinations is well-supported by ablation results, but the underlying reasons for this interference pattern remain speculative without deeper analysis of the model's reasoning process.
- **Medium confidence**: The assertion that structure-aware prompting represents a promising direction is supported by results, but the zero-shot limitation means these gains may not scale to more complex summarization tasks or different document genres without adaptation.

## Next Checks
1. Test StrucSum on legal documents (court opinions or contracts) where sentence centrality and neighbor relationships follow different patterns than scientific text, measuring both ROUGE and factual consistency metrics.
2. Conduct a systematic study varying the similarity threshold θ across multiple orders of magnitude to map the robustness of each strategy to graph construction quality, particularly examining how low thresholds affect CAP's performance.
3. Implement a dynamic masking strategy that adjusts ρ based on document length and content density rather than using a fixed threshold, evaluating whether this improves ROUGE retention while maintaining factual accuracy gains.