---
ver: rpa2
title: Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic
  Stress
arxiv_id: '2512.19935'
source_url: https://arxiv.org/abs/2512.19935
tags:
- adversarial
- stress
- risk
- robustness
- calm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies Conditional Adversarial Fragility in financial
  machine learning, where adversarial vulnerability is systematically amplified during
  macroeconomic stress. The study proposes a regime-aware evaluation framework that
  conditions adversarial robustness analysis on external market stress indicators,
  using volatility-based regime segmentation.
---

# Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic Stress

## Quick Facts
- arXiv ID: 2512.19935
- Source URL: https://arxiv.org/abs/2512.19935
- Authors: Samruddhi Baviskar
- Reference count: 11
- Key outcome: Adversarial vulnerability in financial ML is systematically amplified during macroeconomic stress, with RAF=1.97 and FNR degradation up to threefold at operational thresholds

## Executive Summary
This paper identifies Conditional Adversarial Fragility in financial machine learning, where adversarial vulnerability is systematically amplified during macroeconomic stress periods. The study proposes a regime-aware evaluation framework that conditions adversarial robustness analysis on external market stress indicators, using volatility-based regime segmentation. Empirical results on Lending Club credit risk data show that while baseline performance remains comparable across calm and stress regimes (AUROC≈1.0), models operating during stress periods experience substantially greater adversarial degradation under PGD attacks, with false negative rates increasing up to threefold at operational thresholds. Additionally, explanation stability (measured via Semantic Robustness Index) degrades by 24.4% more in stress regimes, providing an early-warning governance signal.

## Method Summary
The framework partitions data by macroeconomic stress using VIX thresholds (τ_calm=15, τ_stress=20) into Calm and Stress regimes. Independent LightGBM classifiers are trained per regime with identical hyperparameters. PGD attacks with ε=0.1 and 10 iterations are applied to test samples, using finite-difference gradients for tree models. Robustness is evaluated through AUROC degradation, Risk Amplification Factor (RAF=∆AUROC_stress/∆AUROC_calm), FNR at operational thresholds, and Semantic Robustness Index (SRI) computed from SHAP-based explanation cosine similarity, rank correlation, and LLM consistency scoring.

## Key Results
- RAF = 1.97 indicates stress-regime models exhibit nearly double the adversarial fragility of calm-regime models under identical perturbation budgets
- FNR-Amplification at balanced threshold = 2.93, showing near-threefold increase in missed high-risk cases during stress
- SRI degrades by 24.4% more in stress regimes while AUROC degrades by 8.77%, suggesting explanation drift precedes performance degradation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adversarial vulnerability in financial ML models is amplified during macroeconomic stress periods, as measured by the Risk Amplification Factor (RAF).
- Mechanism: Score distributions compress around operational decision thresholds during stress due to elevated baseline risk and compressed margins. Small adversarial perturbations become more likely to induce decision flips in this compressed geometry. Additionally, stress regimes may increase reliance on correlated, economically sensitive features (e.g., debt-to-income ratios) that exhibit heightened gradient sensitivity under perturbation.
- Core assumption: Volatility-based regime segmentation (VIX thresholds) adequately proxy macroeconomic stress conditions.
- Evidence anchors:
  - [abstract] "models operating during stress periods experience substantially greater adversarial degradation under PGD attacks (RAF=1.97)"
  - [Section 4.2] "RAF = 1.97 indicates that stress-regime models exhibit nearly double the adversarial fragility of calm-regime models under identical perturbation budgets"
  - [corpus] Related work on adversarial robustness in financial ML (arxiv 2512.15780) confirms degradation under gradient-based attacks but does not condition on regimes
- Break condition: If baseline performance differs significantly across regimes (indicating confounding task difficulty), RAF may reflect distributional shift rather than conditional fragility. The paper controls for this by showing AUROC≈1.0 in both regimes.

### Mechanism 2
- Claim: False negative rate degradation is disproportionately amplified at operational decision thresholds during stress periods.
- Mechanism: Stress conditions compress predicted risk scores around thresholds. Adversarial perturbations that marginally shift scores cause more threshold crossings during stress, directly increasing missed high-risk cases.
- Core assumption: Type II errors (missed defaults) are costlier than Type I errors in credit risk contexts.
- Evidence anchors:
  - [abstract] "false negative rates increasing up to threefold at operational thresholds"
  - [Section 4.4] "FNR-Amplification at balanced threshold = 2.93... near-threefold amplification demonstrates that stress-regime models are disproportionately vulnerable"
  - [corpus] No direct corpus evidence on threshold-conditional FNR amplification
- Break condition: If FPR increases similarly to FNR, the effect may reflect general distributional disruption rather than asymmetric risk amplification.

### Mechanism 3
- Claim: Explanation stability (semantic robustness) degrades more severely than predictive performance during stress, providing an early-warning governance signal.
- Mechanism: Adversarial perturbations alter model reasoning patterns (feature attribution rankings and magnitudes) before substantially affecting final predictions. The SRI captures this via SHAP cosine similarity, rank correlation, and LLM-evaluated narrative consistency.
- Core assumption: LLM-based semantic evaluation reliably captures human-interpretable explanation drift.
- Evidence anchors:
  - [abstract] "explanation stability (measured via Semantic Robustness Index) degrades by 24.4% more in stress regimes"
  - [Section 4.5] "SRI declines by 24.4% while AUROC degrades by 8.77%. This 2.8-to-1 ratio suggests that adversarial perturbations disrupt model reasoning patterns more severely"
  - [corpus] Covert et al. (2021) demonstrated explanation sensitivity under perturbations but not regime-conditional amplification
- Break condition: If LLM consistency scores are highly sensitive to prompt design, SRI may reflect prompt artifacts rather than genuine semantic drift.

## Foundational Learning

- Concept: **Projected Gradient Descent (PGD) attacks**
  - Why needed here: PGD is the canonical first-order adversarial attack method used throughout the paper to generate perturbations. Understanding iterative gradient-based optimization is essential to interpret RAF results.
  - Quick check question: Given a perturbation budget ε=0.1 and step size α, how many PGD iterations are needed to reach the constraint boundary?

- Concept: **SHAP values and feature attribution**
  - Why needed here: The Semantic Robustness Index relies on SHAP-based explanation extraction. Understanding how Shapley values allocate feature importance is required to interpret SRI components (cosine similarity, rank correlation).
  - Quick check question: Why do SHAP values satisfy the additive feature attribution property, and how does this enable comparison across clean vs. adversarial inputs?

- Concept: **Regime segmentation via external indicators**
  - Why needed here: The framework partitions data by macroeconomic stress using VIX thresholds. Understanding threshold-based regime classification is necessary to replicate the methodology.
  - Quick check question: What are the tradeoffs between discrete threshold-based regime classification versus continuous stress conditioning?

## Architecture Onboarding

- Component map: Regime Segmentation -> Train separate models -> Generate PGD attacks -> Compute RAF and FNR-amplification -> Audit explanation stability via SRI
- Critical path: Regime segmentation → Train separate models → Generate PGD attacks per regime → Compute RAF and FNR-amplification → Audit explanation stability via SRI
- Design tradeoffs:
  - Discrete regime thresholds enable clean separation but lose granularity; continuous stress conditioning would provide finer resolution
  - LLM-based semantic evaluation adds interpretability but introduces prompt-dependence and model bias
  - Training separate models per regime isolates regime effects but doubles training overhead
- Failure signatures:
  - Baseline AUROC differs significantly across regimes → confounding by task difficulty
  - SRI components disagree (e.g., cosine high but rank correlation low) → unstable explanation drift signal
  - RAF≈1.0 but high absolute degradation in both regimes → regime-independent fragility
- First 3 experiments:
  1. Replicate regime segmentation on a different dataset (e.g., fraud detection) with alternative stress proxy to test framework generalizability
  2. Vary perturbation budget ε (0.05, 0.1, 0.2) to characterize RAF sensitivity to attack strength
  3. Replace VIX with multi-factor stress indicator (e.g., combining volatility, unemployment, liquidity) to assess robustness to regime definition choice

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the causal mechanisms linking macroeconomic stress to amplified adversarial fragility, and how do score distribution geometry and feature sensitivity interact to produce this effect?
- Basis in paper: [explicit] Discussion Section 5.1 poses this as "a central question raised by our findings" and offers hypotheses (score compression around thresholds, heightened gradient sensitivity of correlated features) but notes establishing causality "would require controlled simulation environments or structural modeling."
- Why unresolved: The study is empirical and observational; it demonstrates the phenomenon exists but does not isolate the causal pathways through which stress conditions amplify vulnerability.
- What evidence would resolve it: Controlled experiments manipulating score distribution compression and feature correlation structures independently, or structural models that predict amplification magnitude from measurable distributional properties.

### Open Question 2
- Question: Does conditional adversarial fragility persist across alternative threat models such as feature-constrained attacks, adaptive black-box methods, and distribution-aware perturbations?
- Basis in paper: [explicit] Limitations Section 6 states "Alternative threat models—such as feature-constrained attacks, optimization-based evasion methods, or adaptive black-box attacks—may exhibit different sensitivity to macroeconomic regimes" and Future Work Section 7 calls for extending evaluation to these methods.
- Why unresolved: Only PGD attacks under ℓ∞ constraints were tested; the reported RAF=1.97 may represent a lower bound specific to this attack class.
- What evidence would resolve it: Replicating the regime-aware evaluation framework using diverse attack strategies and comparing RAF magnitudes across threat models.

### Open Question 3
- Question: Does explanation-level semantic drift consistently precede numerical performance degradation in longitudinal real-world deployments, validating SRI as a proactive governance mechanism?
- Basis in paper: [explicit] Future Work Section 7 proposes "integrating the Semantic Robustness Index (SRI) into longitudinal monitoring frameworks to study whether explanation-level drift consistently precedes performance degradation in real-world deployments."
- Why unresolved: The 2.8-to-1 ratio of SRI degradation to AUROC degradation was observed in a controlled experimental setting; temporal precedence in production systems remains unverified.
- What evidence would resolve it: Time-series analysis of production model monitoring data tracking SRI and performance metrics, demonstrating that SRI crossings of governance thresholds predict subsequent AUROC decay.

## Limitations
- The regime segmentation relies on VIX thresholds that may not capture all dimensions of macroeconomic stress; alternative stress proxies (unemployment, credit spreads, liquidity measures) could yield different RAF values
- LLM-based semantic consistency scoring introduces prompt-dependence and model bias that may inflate or deflate SRI values without transparent auditability
- Finite-difference gradient estimation for tree ensembles may underestimate true adversarial vulnerability compared to analytic gradients available for neural networks

## Confidence

- **High confidence**: Regime-conditional degradation of predictive performance (AUROC, FNR) - directly measured with standard metrics and reproducible PGD attacks
- **Medium confidence**: Risk Amplification Factor as a measure of conditional fragility - assumes comparable baseline performance and may conflate distributional shift with true vulnerability
- **Medium confidence**: Semantic Robustness Index as early-warning signal - dependent on LLM consistency scoring methodology and SHAP attribution stability

## Next Checks

1. Test framework generalizability by applying identical methodology to fraud detection data with alternative stress proxies (e.g., transaction volume volatility, economic indicators)
2. Characterize RAF sensitivity by varying perturbation budget ε across multiple magnitudes (0.05, 0.1, 0.2) to determine if amplification effect persists at different attack strengths
3. Validate LLM scoring robustness by comparing SRI across multiple prompt templates and different LLM models to assess sensitivity to implementation choices