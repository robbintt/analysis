---
ver: rpa2
title: Scaling Up Temporal Domain Generalization via Temporal Experts Averaging
arxiv_id: '2509.26045'
source_url: https://arxiv.org/abs/2509.26045
tags:
- temporal
- domain
- domains
- learning
- averaging
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses temporal domain generalization (TDG), which
  aims to adapt models to unseen future data under temporal distribution shifts. Prior
  TDG methods either predict entire model weights (computationally prohibitive) or
  only the classifier (limiting generalization).
---

# Scaling Up Temporal Domain Generalization via Temporal Experts Averaging

## Quick Facts
- **arXiv ID:** 2509.26045
- **Source URL:** https://arxiv.org/abs/2509.26045
- **Reference count:** 40
- **Primary result:** State-of-the-art TDG performance with up to 69% accuracy gain and 60× efficiency improvement

## Executive Summary
This paper introduces Temporal Experts Averaging (TEA), a framework that addresses the computational and generalization challenges in temporal domain generalization (TDG). Unlike prior approaches that either predict entire model weights (computationally prohibitive) or only the classifier (limiting generalization), TEA creates expert models through domain-agnostic pretraining followed by constrained incremental fine-tuning on individual temporal domains. The framework then assigns adaptive averaging coefficients based on expert-future proximity in a low-dimensional principal component space, achieving state-of-the-art performance across 7 benchmarks, 5 models, and 2 TDG settings.

## Method Summary
TEA addresses TDG by first pretraining a domain-agnostic base model on all source domains, then fine-tuning individual experts on each temporal domain while constraining weight changes using Synaptic Intelligence (SI). The method projects expert deviations into a low-dimensional PCA space, forecasts future domain positions using ARIMA models, and computes adaptive averaging coefficients based on expert-future distances. This approach updates the entire model while maintaining computational efficiency, achieving SOTA results with up to 60× speedup compared to prior methods.

## Key Results
- Achieves up to 69% accuracy improvement over prior TDG methods
- Provides up to 60× efficiency gains compared to weight-difference-based approaches
- Demonstrates state-of-the-art performance across 7 benchmarks, 5 models, and 2 TDG settings
- Outperforms single last-expert and uniform averaging baselines consistently

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Constraining expert weights near a shared base maintains approximation validity while enabling functional diversity.
- Mechanism: The framework pretrains a domain-agnostic base on all source domains, then fine-tunes per-domain experts with Synaptic Intelligence (SI) to penalize large parameter deviations. This keeps weights within a local basin where first-order Taylor approximations of function space remain accurate, reducing the BVCL decomposition's locality penalty term O(Δ̄²).
- Core assumption: Weight proximity translates to functional proximity; the loss landscape permits smooth interpolation within basins.
- Evidence anchors:
  - [abstract] "create expert models with functional diversity yet parameter similarity by fine-tuning a domain-agnostic base model on individual temporal domains while constraining weight changes"
  - [section 3.1] "locality constraint Δ̄² demands parameter similarity among experts"
  - [corpus] Neighbor work on weight averaging (SeWA, Weight Averaging for OOD Generalization) similarly leverages flat minima and basin smoothness but does not address temporal trajectories.
- Break condition: If domain shifts require large functional changes violating the locality constraint, the Taylor approximation degrades and TEA reverts toward uniform averaging (see abrupt shift ablation).

### Mechanism 2
- Claim: Low-dimensional principal component trajectories capture temporal evolution for future position forecasting.
- Mechanism: PCA is applied to expert deviations {θᵢ - θ_base}, projecting experts into P-dimensional space where temporal dynamics are smoother and more predictable. ARIMA models each component's trajectory independently to forecast the future domain position c_f, from which expert-future distances determine averaging coefficients.
- Core assumption: Temporal evolution is approximately smooth and linear in the principal component subspace; P << D suffices for relative proximity rankings.
- Evidence anchors:
  - [section 3.3] "we apply PCA to {δθᵢ} to decompose the principal components of weight temporal evolution and reduce noise"
  - [section 3.3] Equation (5): "cᵖ(t_f) = ARIMA({(cᵖᵢ, tᵢ)}, t_f)"
  - [corpus] Related TDG spectral dynamics work uses similar subspace modeling but does not integrate weight averaging with trajectory forecasting.
- Break condition: If domain count S is very small (few historical points) or evolution is non-smooth, ARIMA forecasts become unreliable; coefficient assignments may favor incorrect experts.

### Mechanism 3
- Claim: Distance-based adaptive coefficients optimize bias-variance tradeoff compared to uniform averaging.
- Mechanism: Coefficients are assigned inversely proportional to expert-future distance in PC space (Equation 6), with hyperparameter r controlling concentration. This concentrates weight on temporally proximate experts with lower expected bias while partially distributing weight to reduce variance—balancing Lemma 2 (bias minimization favors single best expert) and Lemma 3 (variance minimization favors uniform weights).
- Core assumption: PC-space proximity correlates with future-domain bias; Assumption 1 (ordered bias magnitudes) and Assumption 2 (equal variances) approximately hold.
- Evidence anchors:
  - [section 3.1] "Reducing variance V requires averaging weights evenly, while reducing bias B demands concentrating coefficients on experts with lower bias magnitudes"
  - [section 4.2] Reversed coefficients cause performance below ERM baseline (Table 5), validating directional correctness
  - [corpus] Neighbor papers on selective/weighted averaging (SeWA, DiWA) show variance reduction benefits but do not use temporal proximity for coefficient assignment.
- Break condition: If temporal smoothness assumption is violated (abrupt shifts), adaptive coefficients lose advantage but method remains comparable to strong DG baselines (Table 9).

## Foundational Learning

- Concept: Bias-Variance Tradeoff in Ensembles
  - Why needed here: The theoretical analysis (BVCL decomposition) frames TEA's design as balancing expert concentration (lower bias) against weight spreading (lower variance/covariance).
  - Quick check question: Can you explain why uniformly averaging expert weights reduces variance but may increase bias compared to selecting a single expert?

- Concept: Weight Averaging vs Functional Ensembling
  - Why needed here: The paper leverages the first-order approximation that weight averaging (WA) approximates output averaging (ENS) when weights are close, enabling efficient deployment without ensemble inference costs.
  - Quick check question: Under what condition does θ_avg ≈ average of f(·, θᵢ) outputs? What term in the decomposition captures approximation error?

- Concept: Continual Learning Constraints (SI/EWC)
  - Why needed here: Temporal fine-tuning uses Synaptic Intelligence to prevent catastrophic forgetting of the base representation while adapting to domain specifics.
  - Quick check question: How does SI balance plasticity (learning new domain features) against stability (preserving base knowledge)?

## Architecture Onboarding

- Component map: Base pretraining -> Temporal fine-tuning (reverse order) -> PCA projection -> ARIMA forecasting -> Distance-based coefficient computation -> Expert weight averaging

- Critical path:
  1. Train base model on concatenated source domains
  2. Fine-tune experts in reverse temporal order (t_S → t_1) with SI constraint
  3. Compute deviations, apply PCA, fit ARIMA per component
  4. Forecast c_f at target timestamp t_f
  5. Compute distances d_i = ||c_i - c_f||, derive coefficients via Equation (6)
  6. Aggregate: θ_TEA = Σ αᵢ θᵢ

- Design tradeoffs:
  - P (PCA components): Higher P captures more variance but may introduce noise and reduce forecast reliability
  - r (coefficient sharpness): Higher r concentrates on nearest expert (lower variance, higher bias risk); lower r approaches uniform averaging
  - Fine-tuning order: Reverse order prioritizes recent domains, which better approximate future under smooth shift assumption
  - K (samples per expert): More samples reduce expert variance but increase training cost

- Failure signatures:
  - Coefficients collapse to uniform (r≈0 or all distances similar): check if PCA captures meaningful temporal structure
  - Performance degrades vs ERM under abrupt shifts (Table 9): verify domain ordering and smoothness assumption
  - Memory overflow in CDGTD: reduce buffer size (5% often sufficient per Table 7) or limit fine-tuning to recent domains

- First 3 experiments:
  1. **Sanity check:** Compare TEA vs uniform averaging vs single last expert on a small benchmark (e.g., Yearbook) to validate adaptive coefficient benefit.
  2. **Ablation on P and r:** Sweep P ∈ {3, 5, 10, 20} and r ∈ {0.5, 1, 5} on FMoW to understand sensitivity and identify stable operating regions.
  3. **Scale test:** Apply TEA to CLEAR-100 with ResNet-50, comparing training cost vs W-Diff/EvoS to verify efficiency claims (target: <2× ERM cost, Table 3).

## Open Questions the Paper Calls Out

- Can TEA be effectively extended to Continuous Temporal Domain Generalization (CTDG) settings where timestamps are continuous rather than discrete?
  - Basis: The authors explicitly state in the Limitations section that while TEA can theoretically accommodate CTDG, they were constrained by the lack of large-scale datasets and will explore this in future work.

- Does the reliance on linear ARIMA models for trajectory forecasting limit performance in scenarios with complex, non-linear temporal dynamics?
  - Basis: The authors mention they "simply model the P-dimensional trajectory as P separate time series" and use ARIMA because limited domains lead to few historical points, implying a simpler choice necessitated by data scarcity.

- How can TEA be modified to guarantee robustness under abrupt, non-smooth distribution shifts?
  - Basis: The authors identify the reliance on smooth distribution shift assumptions as a key limitation, noting they "cannot guarantee performance with abrupt shifts."

## Limitations
- Relies on smooth temporal distribution shifts; performance degrades under abrupt domain changes
- Theoretical framework assumes weight proximity translates to functional similarity, which may not hold for complex domain shifts
- Scalability to hundreds of temporal domains remains unproven, with potential computational and generalization challenges

## Confidence

- **High Confidence:** TEA's superior performance metrics (up to 69% gain) across 7 benchmarks and 5 models; computational efficiency claims (up to 60× faster) supported by direct comparisons to W-Diff/EvoS baselines.
- **Medium Confidence:** The theoretical justification for adaptive coefficients based on PC-space proximity; the generalization of reverse-order fine-tuning benefits beyond the evaluated datasets.
- **Low Confidence:** Scalability to hundreds of temporal domains; robustness under non-smooth temporal dynamics or when Assumption 1-2 break down.

## Next Checks

1. **Smoothness Stress Test:** Evaluate TEA on synthetic temporal datasets with controlled abrupt shifts (e.g., sudden domain jumps) to quantify performance degradation and validate the method's limitations under non-smooth dynamics.

2. **Component Sensitivity Analysis:** Systematically sweep P ∈ {3, 5, 10, 20} and r ∈ {0.5, 1, 5} across all benchmarks to establish stable operating regions and identify overfitting risks.

3. **Memory Efficiency Benchmark:** Implement TEA on CLEAR-100 with ResNet-50, measuring wall-clock training time vs. W-Diff/EvoS baselines, and validate the ≤2× ERM cost claim under realistic computational constraints.