---
ver: rpa2
title: 'Leveraging ChatGPT''s Multimodal Vision Capabilities to Rank Satellite Images
  by Poverty Level: Advancing Tools for Social Science Research'
arxiv_id: '2501.14546'
source_url: https://arxiv.org/abs/2501.14546
tags:
- images
- wealth
- ranking
- chatgpt
- satellite
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores the application of Large Language Models (LLMs)
  with vision capabilities for village-level poverty prediction using satellite imagery.
  By employing a pairwise comparison approach with ChatGPT-4o, the research demonstrates
  that LLMs can rank satellite images based on poverty levels with accuracy comparable
  to domain experts.
---

# Leveraging ChatGPT's Multimodal Vision Capabilities to Rank Satellite Images by Poverty Level: Advancing Tools for Social Science Research

## Quick Facts
- arXiv ID: 2501.14546
- Source URL: https://arxiv.org/abs/2501.14546
- Reference count: 22
- Primary result: ChatGPT-4o can rank satellite images by poverty level with accuracy comparable to domain experts

## Executive Summary
This study explores the application of Large Language Models (LLMs) with vision capabilities for village-level poverty prediction using satellite imagery. By employing a pairwise comparison approach with ChatGPT-4o, the research demonstrates that LLMs can rank satellite images based on poverty levels with accuracy comparable to domain experts. The methodology involved comparing all possible pairs of satellite images from 608 DHS survey sites and using the I-LSR algorithm to produce an overall ranking. Results show that ChatGPT achieved a Spearman's rank correlation of 0.56 and a quintile Matthew's correlation coefficient of 0.20, performing on par with a Random Forest model using expert-defined features. Notably, ChatGPT outperformed the expert model in detecting very poor areas, while the expert model was better at identifying wealthy areas.

## Method Summary
The research employed a pairwise comparison methodology where ChatGPT-4o was asked to compare all possible pairs of satellite images from 608 DHS survey sites. Each comparison asked which image appeared to depict a poorer area. The I-LSR (Iterative Least Squares Ranking) algorithm was then used to convert these pairwise comparisons into an overall ranking of the images by poverty level. This approach was compared against both domain expert rankings and a Random Forest model trained on expert-defined features. The study focused on Malawi and used satellite imagery covering the entire country.

## Key Results
- ChatGPT-4o achieved Spearman's rank correlation of 0.56 and quintile Matthew's correlation coefficient of 0.20 in ranking poverty levels
- Performance was comparable to a Random Forest model using expert-defined features
- ChatGPT outperformed the expert model in detecting very poor areas, while the expert model was better at identifying wealthy areas

## Why This Works (Mechanism)
The mechanism relies on ChatGPT-4o's ability to extract visual features from satellite imagery that correlate with poverty indicators. The model likely identifies patterns such as building density, infrastructure quality, vegetation health, and land use patterns that are indicative of economic conditions. The pairwise comparison approach simplifies the complex task of poverty assessment into a series of binary decisions, which can be more effectively handled by the model's reasoning capabilities.

## Foundational Learning
- **Satellite Image Analysis**: Understanding visual indicators of poverty in satellite imagery (why needed: to interpret what the model is detecting; quick check: compare model-identified features with known poverty indicators)
- **Pairwise Ranking Algorithms**: Methods for converting pairwise comparisons into overall rankings (why needed: to understand the I-LSR algorithm; quick check: verify the ranking consistency across different implementations)
- **Poverty Assessment Metrics**: Spearman correlation and Matthew's correlation coefficient for evaluating ranking performance (why needed: to interpret the evaluation results; quick check: calculate these metrics on synthetic data)
- **LLM Vision Capabilities**: How multimodal models process and interpret visual information (why needed: to understand the model's strengths and limitations; quick check: test the model on varied image types)
- **Machine Learning vs Expert Systems**: Comparison of automated vs human-based poverty assessment approaches (why needed: to contextualize the study's findings; quick check: compare model performance with human expert consistency)

## Architecture Onboarding

Component Map: Satellite Images -> ChatGPT-4o Pairwise Comparisons -> I-LSR Algorithm -> Poverty Ranking

Critical Path: The core workflow involves feeding image pairs to ChatGPT-4o, collecting comparison results, and processing these through the I-LSR algorithm to generate the final ranking.

Design Tradeoffs: The pairwise comparison approach trades computational efficiency for accuracy, as it requires evaluating all possible pairs (n*(n-1)/2 comparisons). This ensures thorough evaluation but becomes computationally intensive with large datasets.

Failure Signatures: Potential failures could include inconsistent comparisons from ChatGPT-4o, geographic bias in the model's poverty indicators, or algorithmic convergence issues in the I-LSR ranking process.

First Experiments:
1. Test ChatGPT-4o consistency by comparing the same image pairs multiple times
2. Validate I-LSR algorithm convergence with synthetic pairwise comparison data
3. Compare model performance on different geographic regions to identify potential biases

## Open Questions the Paper Calls Out
None

## Limitations
- The study focuses solely on village-level poverty prediction in Malawi, limiting generalizability
- The pairwise comparison methodology requires significant computational resources for large datasets
- Reliance on ChatGPT-4o may exhibit variability in responses across different instances or updates

## Confidence

High Confidence:
- ChatGPT-4o can rank satellite images based on poverty levels with accuracy comparable to domain experts

Medium Confidence:
- ChatGPT-4o outperforms traditional machine learning models in detecting very poor areas

Low Confidence:
- LLMs can serve as scalable, cost-effective alternatives to traditional survey methods

## Next Checks
1. Test the methodology on satellite imagery from diverse geographic regions and poverty contexts to assess generalizability
2. Evaluate ChatGPT-4o against other state-of-the-art vision models and LLMs to determine relative performance
3. Conduct a cost and resource analysis to determine the feasibility of deploying this approach at scale, including computational requirements and potential bottlenecks