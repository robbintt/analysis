---
ver: rpa2
title: Deterministic Coreset Construction via Adaptive Sensitivity Trimming
arxiv_id: '2508.18340'
source_url: https://arxiv.org/abs/2508.18340
tags:
- sensitivity
- coreset
- deterministic
- aduwt
- weight
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents a deterministic coreset construction method\
  \ for empirical risk minimization (ERM) using adaptive sensitivity trimming. The\
  \ ADUWT algorithm constructs a coreset by removing points with lowest sensitivity\
  \ bounds and applying a data-dependent uniform weight to the remainder, achieving\
  \ a uniform (1 \xB1 \u03B5) relative-error approximation over the entire hypothesis\
  \ space."
---

# Deterministic Coreset Construction via Adaptive Sensitivity Trimming

## Quick Facts
- arXiv ID: 2508.18340
- Source URL: https://arxiv.org/abs/2508.18340
- Reference count: 18
- Deterministic coreset construction for ERM using adaptive sensitivity trimming

## Executive Summary
This paper introduces ADUWT, a deterministic coreset construction method for empirical risk minimization that achieves uniform (1±ε) relative-error approximation. The method trims points with lowest sensitivity bounds and applies a data-dependent uniform weight to the remainder. The approach introduces a Sensitivity Heterogeneity Index to analyze when deterministic trimming outperforms randomized sampling, and provides tractable sensitivity oracles for kernel ridge regression, regularized logistic regression, and linear SVM.

## Method Summary
The ADUWT algorithm constructs a coreset by computing sensitivity bounds for each data point, trimming those with lowest bounds up to a threshold ε', and applying an adaptive uniform weight α = √((1-ε²)/(1-T_U)) to the remaining points. The method guarantees (1±ε) relative error over the entire hypothesis space under the assumption that sensitivity oracle bounds are valid. Sensitivity oracles are provided for kernel ridge regression, regularized logistic regression, and linear SVM, with empirical evaluation on KRR with Bike Sharing data showing deterministic guarantees versus randomized sampling failures.

## Key Results
- ADUWT achieves uniform (1±ε) relative-error approximation for ERM with deterministic guarantees
- Sensitivity Heterogeneity Index (SHI = σ/μ) predicts when deterministic trimming outperforms randomized sampling
- Empirical results show ADUWT reduces worst-case relative error compared to data-oblivious weighting
- Randomized importance sampling violated the (1±ε) guarantee in 5/100 trials on Bike Sharing data

## Why This Works (Mechanism)

### Mechanism 1
Trimming low-sensitivity points preserves the ERM objective within (1±ε) relative error because points with low sensitivity cannot significantly affect the objective regardless of which hypothesis is chosen. The collective loss of trimmed points is bounded by T_U·L(f;D), where T_U is the sum of their sensitivity bounds. Keeping T_U ≤ ε' ensures the trimmed mass is small enough to absorb into the scaling factor.

### Mechanism 2
The adaptive uniform weight α = √((1-ε²)/(1-T_U)) is minimax-optimal for the (1±ε) guarantee. After trimming, the remaining loss L_S falls in [1-T_U, 1] relative to L(f;D). The multiplicative scaling α must simultaneously satisfy both bounds: α·L_S ≤ (1+ε)L and α·L_S ≥ (1-ε)L. The geometric mean of feasible endpoints equalizes worst-case multiplicative slack in both directions.

### Mechanism 3
High Sensitivity Heterogeneity Index (SHI = σ/μ) predicts when deterministic trimming outperforms randomized sampling. When sensitivity distribution is heterogeneous (high variance relative to mean), many points cluster near zero sensitivity. If the empirical CDF satisfies F(t₀) ≥ ρ for small t₀, then a ρ-fraction of points can be trimmed while contributing ≤ ρt₀n ≤ ε' total sensitivity mass.

## Foundational Learning

- **Sensitivity in coreset theory**: The entire ADUWT framework hinges on computing and interpreting sensitivity bounds; s_i = sup_{f∈F} ℓ(f;z_i)/L(f;D) measures worst-case influence. Quick check: Given a point with sensitivity 0.01 in a dataset of n=1000, what is its maximum possible contribution to the total loss for any hypothesis?

- **Empirical Risk Minimization (ERM) with regularization**: The oracles derive sensitivity bounds specific to regularized objectives; understanding the role of λ, B, and norm constraints is essential. Quick check: Why does the KRR sensitivity bound depend on both the label magnitude Y and the kernel bound κ?

- **(1±ε)-approximation guarantees**: The paper's core claim is a uniform relative-error guarantee over the entire hypothesis space; distinguishing relative from absolute error is critical. Quick check: If L(f;D) = 0.01 and ε = 0.1, what is the acceptable range for the coreset estimate L̂?

## Architecture Onboarding

- **Component map**: Sensitivity Oracle → Sorting → Prefix scan → Weight Calculator → Evaluation Harness
- **Critical path**: Oracle computation (O(n) to O(n²)) → Sorting (O(n log n)) → Prefix scan (O(n)) → Weight computation (O(1))
- **Design tradeoffs**: δ parameter in oracles affects sensitivity bound tightness; smaller δ yields tighter bounds but requires stronger norm assumptions; ε vs. coreset size tradeoff; oracle tightness affects trimming efficiency
- **Failure signatures**: Guarantee violations indicate oracle assumptions violated or numerical precision issues; coreset size ≈ n suggests low SHI dataset or overly loose oracle bounds; negative weight or NaN indicates T_U ≥ 1
- **First 3 experiments**:
  1. Sanity check on synthetic data with known sensitivity distribution to verify ADUWT achieves (1±ε) on held-out hypothesis sweep
  2. SHI ablation on Bike Sharing data to compare ADUWT vs. importance sampling across ε values and validate Proposition 3.6 empirically
  3. Oracle tightness probe for KRR by varying δ parameter to measure impact on T_U, coreset size, and worst-case relative error

## Open Questions the Paper Calls Out

- **Instance-optimal oracles**: Can data-dependent geometry or influence functions be used to construct instance-optimal sensitivity oracles that are tighter than current worst-case uniform bounds? The provided oracles for logistic regression and SVM yield uniform bounds, preventing effective trimming.

- **Deterministic streaming**: Can deterministic coreset construction be extended to streaming settings with additive error guarantees rather than multiplicative error accumulation? Standard merge-reduce frameworks compound error multiplicatively, degrading the strict (1±ε) guarantee.

- **Fairness-constrained ERM**: Does the ADUWT framework extend to vector-valued objectives required for fairness-constrained ERM? The current minimax optimality and uniform weight derivation rely on scalar loss approximations; it is unclear if uniform weights remain optimal under coupled fairness constraints.

## Limitations

- Sensitivity oracle fidelity limits core guarantees since all guarantees rely on upper bounds s̄_i ≥ s_i; oracle tightness directly impacts trimming efficiency and coreset size
- SHI empirical validation lacks systematic validation across diverse datasets and models, with Table 1 providing only a single data point
- Generalization beyond KRR is uncertain as all experiments focus on kernel ridge regression with one dataset, while oracles for logistic regression and SVM are not empirically validated

## Confidence

- **High**: Theoretical framework for ADUWT, proof of (1±ε) guarantee under oracle assumptions, sensitivity bound derivations for KRR
- **Medium**: Empirical evaluation on Bike Sharing dataset, comparison with randomized sampling, SHI definition
- **Low**: Oracle performance for logistic regression and SVM, SHI as practical predictor, generalization to other datasets and models

## Next Checks

1. **Oracle tightness ablation study**: Systematically vary δ in KRR oracle and measure impact on T_U, coreset size |S|, and worst-case relative error across multiple datasets to quantify the tradeoff between sensitivity bound tightness and coreset efficiency.

2. **SHI correlation analysis**: Compute SHI for 10+ diverse datasets and measure correlation between SHI values and the relative performance gap between ADUWT and sensitivity sampling in terms of |S| and max relative error.

3. **Multi-model validation**: Implement and evaluate sensitivity oracles for regularized logistic regression and linear SVM on at least two datasets each, reporting (1±ε) guarantee compliance rates and coreset sizes relative to KRR results.