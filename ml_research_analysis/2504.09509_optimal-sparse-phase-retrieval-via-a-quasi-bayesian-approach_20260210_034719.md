---
ver: rpa2
title: Optimal sparse phase retrieval via a quasi-Bayesian approach
arxiv_id: '2504.09509'
source_url: https://arxiv.org/abs/2504.09509
tags:
- phase
- sparse
- retrieval
- sparsity
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of sparse phase retrieval, where
  a signal must be reconstructed using only the magnitude of its transformation without
  phase information. The method introduces a novel sparse quasi-Bayesian approach
  using a scaled Student's t-distribution as a continuous shrinkage prior to enforce
  sparsity, and analyzes it using the PAC-Bayesian inequality framework.
---

# Optimal sparse phase retrieval via a quasi-Bayesian approach

## Quick Facts
- arXiv ID: 2504.09509
- Source URL: https://arxiv.org/abs/2504.09509
- Reference count: 40
- Primary result: Establishes minimax-optimal convergence rates for sparse phase retrieval using a quasi-Bayesian approach with scaled Student's t-prior

## Executive Summary
This paper introduces a novel sparse quasi-Bayesian approach for phase retrieval, where a signal must be reconstructed using only the magnitude of its transformation without phase information. The method uses a scaled Student's t-distribution as a continuous shrinkage prior to enforce sparsity and analyzes it using the PAC-Bayesian inequality framework. The primary theoretical result establishes that this Bayesian estimator achieves minimax-optimal convergence rates under sub-exponential noise, matching state-of-the-art frequentist methods. The approach employs an efficient Langevin Monte Carlo sampling algorithm for computational feasibility.

## Method Summary
The method reconstructs a sparse signal from quadratic measurements using a quasi-Bayesian framework. It constructs a Gibbs posterior (quasi-posterior) that combines an empirical risk term with a scaled Student's t-prior to enforce sparsity. The estimator is computed using unadjusted Langevin Monte Carlo sampling, which leverages gradients of the quasi-log-posterior for efficient exploration. The approach decouples inference from strict likelihood assumptions, allowing optimal error bounds under sub-exponential noise distributions while maintaining computational tractability through gradient-based sampling.

## Key Results
- Achieves minimax-optimal convergence rates O(σ²s*log(mp/s)/m) under sub-exponential noise
- Scaled Student's t-prior effectively enforces sparsity through continuous shrinkage
- LMC sampling provides computationally feasible inference with performance comparable to frequentist baselines
- Theoretical guarantees include non-asymptotic upper bounds on estimation error

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A scaled Student's t-distribution prior enforces sparsity effectively in high-dimensional phase retrieval without requiring explicit ℓ₀ constraints.
- **Mechanism:** The heavy-tailed nature of the distribution places high probability mass near zero (shrinking noise) while allowing large non-zero values to persist (preserving signal), acting as a continuous relaxation of the spike-and-slab prior.
- **Core assumption:** The true signal θ* admits a sparse representation in the chosen basis.
- **Evidence anchors:**
  - [Section 2.2]: "heavy-tailed nature... ensures that a few components deviate significantly from zero."
  - [Section 4.3.4]: Shows ς < 1 yielding lowest error, validating the shrinkage scale.
  - [Corpus]: "False Discovery Rate Control via Frequentist-assisted Horseshoe" confirms the efficacy of global-local shrinkage priors (like Horseshoe/Student-t) in high-dimensional sparsity.
- **Break condition:** If the signal is dense (low sparsity s* ≈ p), the shrinkage prior may erroneously attenuate true signal components.

### Mechanism 2
- **Claim:** The PAC-Bayesian quasi-posterior achieves minimax-optimal convergence rates by generalizing the likelihood to an empirical risk Gibbs distribution.
- **Mechanism:** Instead of a true likelihood (which requires specific noise distribution knowledge), the method constructs a Gibbs posterior ∝ exp(-λr(θ))π(θ). This decouples the inference from strict Gaussian assumptions, allowing optimal error bounds under sub-exponential noise.
- **Core assumption:** The noise is independent and sub-exponential (Assumption 2), and the restricted eigenvalue-like condition (Assumption 3) holds.
- **Evidence anchors:**
  - [Abstract]: "...analyze the method using the PAC-Bayesian inequality framework... minimax-optimal convergence rates."
  - [Section 3.2]: Theorem 1 explicitly bounds the error by Cσ²s*log(mp/s*)/m.
  - [Corpus]: Weak direct evidence in provided corpus; mechanism relies on theoretical derivation in [10, 22] referenced in the text.
- **Break condition:** If the noise distribution deviates significantly from sub-exponential (e.g., infinite variance), the PAC-bound derivation may fail.

### Mechanism 3
- **Claim:** Unadjusted Langevin Monte Carlo (LMC) provides computationally feasible sampling by exploiting the gradient of the quasi-log-posterior.
- **Mechanism:** LMC uses stochastic differential equations guided by the gradient ∇logρ̂_λ to drift the Markov chain toward high-density regions. This gradient-based drift allows larger effective step sizes compared to random-walk Metropolis in high dimensions.
- **Core assumption:** The step-size γ is tuned correctly; the log-posterior is sufficiently smooth to allow gradient-based exploration.
- **Evidence anchors:**
  - [Section 4.1]: Defines the gradient update θ_{k+1} = θ_k - γ∇logρ̂_λ + √(2γ)N_k.
  - [Section 4.3.1]: Shows LMC/MALA converge comparably to Mirror Descent as sample size grows.
  - [Corpus]: "Accelerated Frank-Wolfe" discusses gradient methods for sparse constraints, supporting the utility of first-order information in constrained/sparse settings.
- **Break condition:** If the step-size γ is too large, the discretization error causes instability; if too small, the chain mixes too slowly.

## Foundational Learning

- **Concept: Phase Retrieval (Quadratic Inverse Problems)**
  - **Why needed here:** The fundamental problem is recovering θ from squared magnitudes y = |⟨a, θ⟩|² + ε, meaning the phase is lost. Understanding this explains why the problem is ill-posed without sparsity or sufficient measurements.
  - **Quick check question:** Why can we only recover θ up to a sign (±θ*)?

- **Concept: Gibbs Posteriors vs. Bayesian Posteriors**
  - **Why needed here:** This paper uses a "quasi-Bayesian" approach. Unlike standard Bayes, which requires a true likelihood p(y|θ), Gibbs posteriors use exp(-λ × Risk). This is critical for the theoretical guarantees under generic sub-exponential noise.
  - **Quick check question:** Does the Gibbs parameter λ correspond to the inverse temperature or noise variance?

- **Concept: Convergence Rates (Minimax Optimality)**
  - **Why needed here:** The paper claims "optimal" performance. This refers to the minimax rate σ²s*log(p/s)/m. Understanding this helps contextualize that the method is theoretically as good as any frequentist estimator can be under the worst-case scenario.
  - **Quick check question:** How does the error scale with the sparsity s* and dimension p?

## Architecture Onboarding

- **Component map:** Inputs (y, A) -> Core (Quasi-Posterior: Empirical Risk + Scaled Student-t Prior) -> Solver (LMC) -> Outputs (Final estimator θ̂)

- **Critical path:**
  1. **Gradient Calculation:** Compute ∇r(θ) (requires passing data through model) and ∇π(θ) (analytic regularizer).
  2. **Sampling Loop:** Run LMC update (Eq 4.1) for K iterations.
  3. **Burn-in & Aggregation:** Discard initial samples; average remaining samples to reduce variance.

- **Design tradeoffs:**
  - **LMC vs. MALA:** LMC is faster (no rejection step) but approximates the target distribution less accurately than Metropolis-Adjusted Langevin (MALA). Paper suggests LMC is sufficient if step-size is small.
  - **Parameter ς (Scale):** Must be ≪ 1 for sparsity (Figure 4). Tuning is sensitive; theoretical value ς* = (4Cpm)⁻¹ is conservative.
  - **Parameter λ (Temperature):** Controls confidence in data. Too large λ degrades performance (overfitting noise in risk minimization).

- **Failure signatures:**
  - **Exploding Gradients:** If λ or γ are too large, iterates diverge.
  - **Overshrinkage:** If ς is too small or prior strength too high, signal components are crushed to zero.
  - **Sign Ambiguity:** The posterior will be bimodal (θ and -θ); an initializer or post-processing step is needed to align signs.

- **First 3 experiments:**
  1. **Baseline Reconstruction:** Generate synthetic sparse signal with p=100, s=10, m=500. Verify θ̂ aligns with ±θ*.
  2. **Sensitivity Sweep:** Replicate Figure 4. Vary ς on a log-scale (e.g., 10⁻⁴ to 10¹) to confirm the "Valley" of optimal sparsity.
  3. **Noise Robustness:** Compare LMC vs. Mirror Descent (frequentist baseline) specifically in the high-noise regime (σ/‖θ‖ > 1) to validate the paper's claim of Bayesian robustness.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the quasi-Bayesian framework be extended to enforce structured sparsity, such as group or hierarchical structures, rather than just element-wise sparsity?
  - **Basis in paper:** [explicit] The conclusion explicitly lists extending the framework to "handle more general structured sparsity or hierarchical network structure" as a promising direction for future research.
  - **Why unresolved:** The current theoretical analysis and the scaled Student's t-prior are designed for standard element-wise sparsity (ℓ₀ norm). Structured sparsity requires different prior specifications and likely modifies the PAC-Bayesian complexity terms (KL divergence).
  - **What evidence would resolve it:** Derivation of error bounds for a group-sparsity prior or a hierarchical prior within this framework, demonstrating rates that adapt to the group structure.

- **Open Question 2:** Can the tuning parameters λ and ς be determined adaptively using empirical Bayes or hierarchical methods without sacrificing theoretical guarantees?
  - **Basis in paper:** [explicit] The conclusion identifies the "development of adaptive or data-driven choices for hyper-parameters such as using empirical Bayes or using hierarchical priors" as an important open question.
  - **Why unresolved:** The paper provides fixed theoretical values for these parameters (λ*, ς*) and relies on manual tuning or cross-validation for experiments. Theoretical guarantees for adaptive selection within this PAC-Bayesian context are not yet established.
  - **What evidence would resolve it:** An algorithm that selects λ and ς from data, accompanied by a theorem proving that the resulting estimator retains the minimax-optimal convergence rate.

- **Open Question 3:** Does the proposed method retain its theoretical and practical superiority when applied to real-world phase retrieval tasks, such as optical imaging?
  - **Basis in paper:** [explicit] The conclusion states that "applying the methodology to real-world tasks, such as in optics or signal processing, would further validate its practical utility."
  - **Why unresolved:** The numerical studies rely on synthetic data (random Gaussian matrices) and a specific image dataset (MNIST) with synthetically generated measurements. Real optical systems involve physical constraints, correlated noise, and different measurement operators (e.g., Fourier masks) not covered by the current simulations.
  - **What evidence would resolve it:** Successful application of the method to experimental data from optical hardware, demonstrating robust performance against physical noise and system imperfections.

## Limitations

- The theoretical framework relies on sub-exponential noise assumptions that may not capture heavy-tailed noise distributions common in real-world applications.
- The computational approach using unadjusted LMC introduces discretization error not fully characterized in theoretical analysis, with critical step-size parameter γ unspecified.
- Restricted eigenvalue condition requires careful measurement design and may fail with correlated sensing matrices or poorly aligned signal basis.

## Confidence

**High Confidence** - The theoretical minimax optimality result (Theorem 1) is well-established given the assumptions. The convergence rate O(σ²s*log(mp/s)/m) matches state-of-the-art frequentist methods, and the PAC-Bayesian framework is mathematically rigorous.

**Medium Confidence** - The Student's t-distribution prior effectiveness for sparsity is supported by empirical results (Figure 4) showing optimal performance at specific scale parameters. However, theoretical justification for why this prior works better than alternatives (like Horseshoe) is less developed.

**Low Confidence** - The computational efficiency claims for LMC are based on comparisons that may not fully account for step-size tuning burden. The paper shows LMC performs comparably to Mirror Descent but doesn't demonstrate clear advantages in wall-clock time or ease of hyperparameter selection.

## Next Checks

1. **Step-size Sensitivity Analysis**: Reproduce the LMC algorithm with a systematic sweep of step sizes (γ = 10^-4, 10^-5, 10^-6) to quantify the impact on convergence speed and final estimation error. This would validate whether the method is truly robust to this critical hyperparameter.

2. **Noise Distribution Robustness**: Test the method under heavy-tailed noise distributions (e.g., t-distribution with 3 degrees of freedom) to verify whether the sub-exponential assumption is necessary for good performance, or if the quasi-Bayesian approach provides genuine robustness advantages.

3. **Prior Comparison Experiment**: Implement the same framework with alternative sparsity-inducing priors (Horseshoe, Laplace) to determine whether the scaled Student's t-distribution provides unique advantages, or if the Gibbs posterior framework is the primary driver of good performance regardless of the specific prior choice.