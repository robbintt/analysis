---
ver: rpa2
title: Do LLMs Encode Frame Semantics? Evidence from Frame Identification
arxiv_id: '2509.19540'
source_url: https://arxiv.org/abs/2509.19540
tags:
- frame
- framenet
- definitions
- frames
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates whether large language models (LLMs) inherently\
  \ encode knowledge of frame semantics, focusing on the task of frame identification\u2014\
  selecting the correct semantic frame for a target word in context. Using the FrameNet\
  \ lexical resource, the authors evaluate LLMs under prompt-based inference and find\
  \ that they can perform frame identification effectively even without explicit task-specific\
  \ supervision."
---

# Do LLMs Encode Frame Semantics? Evidence from Frame Identification

## Quick Facts
- arXiv ID: 2509.19540
- Source URL: https://arxiv.org/abs/2509.19540
- Authors: Jayanth Krishna Chundru; Rudrashis Poddar; Jie Cao; Tianyu Jiang
- Reference count: 31
- Primary result: LLMs can perform frame identification effectively even without explicit task-specific supervision, achieving 91.7-91.9% in-domain accuracy

## Executive Summary
This paper investigates whether large language models inherently encode knowledge of frame semantics through the lens of frame identification tasks. Using FrameNet as the lexical resource, the authors evaluate LLMs under prompt-based inference and find they can perform frame identification effectively without explicit supervision. The study further demonstrates that fine-tuning Llama-3.1-8B on minimal FrameNet data substantially improves performance, achieving state-of-the-art results on both in-domain and out-of-domain benchmarks. Additionally, the models can generate semantically coherent frame definitions that maintain task performance when used in place of gold definitions.

## Method Summary
The authors evaluate LLMs on frame identification by prompting them to select the correct semantic frame for target words in context using FrameNet annotations. They conduct both prompt-based inference experiments and fine-tuning experiments using Llama-3.1-8B. The fine-tuning approach uses only 500 examples from FrameNet 1.7, yet achieves high accuracy on both in-domain benchmarks (FrameNet 1.5 and 1.7) and out-of-domain datasets (YAGS and Artifacts). The study also explores frame definition generation capabilities, where models generate definitions that can substitute for gold definitions while maintaining comparable task performance.

## Key Results
- LLMs perform frame identification effectively without explicit task-specific supervision
- Fine-tuned Llama-3.1-8B achieves 91.7% accuracy on FrameNet 1.5 and 91.9% on FrameNet 1.7
- Strong out-of-domain generalization: 80.7% on YAGS and 49.6% on Artifacts benchmarks
- Generated frame definitions maintain semantic coherence and comparable task performance

## Why This Works (Mechanism)
The paper suggests that LLMs capture frame-semantic knowledge through pre-training on large corpora where semantic frames and their contextual patterns are implicitly learned. The effectiveness of minimal fine-tuning indicates that LLMs have already internalized many frame-semantic relationships during pre-training, requiring only adaptation rather than learning from scratch. The ability to generate coherent frame definitions suggests that LLMs have formed meaningful representations of frame semantics that go beyond simple pattern matching.

## Foundational Learning
- Frame semantics: Understanding how words evoke structured conceptual representations in context - needed for semantic parsing tasks
- FrameNet: Lexical resource organizing words into semantic frames with frame-to-frame relations - needed for evaluation benchmarks
- Prompt-based inference: Zero-shot or few-shot learning through carefully crafted prompts - needed for initial LLM evaluation
- Fine-tuning: Adapting pre-trained models to specific tasks using labeled data - needed for improving model performance
- Semantic coherence: Measuring how logically consistent generated definitions are - needed for evaluating definition generation quality

## Architecture Onboarding

Component map: FrameNet annotations -> Prompt engineering -> LLM inference -> Frame identification output

Critical path: Input sentence with target word -> FrameNet frame selection -> LLM processing -> Frame prediction

Design tradeoffs: Minimal fine-tuning data (500 examples) vs. high performance, generated definitions vs. gold definitions

Failure signatures: Model confusion between semantically similar frames, degradation on out-of-domain examples, definition generation quality issues

First experiments:
1. Test prompt-based inference on FrameNet examples to establish baseline performance
2. Evaluate generated frame definitions for semantic coherence and accuracy
3. Compare fine-tuned model performance against zero-shot baseline

## Open Questions the Paper Calls Out
- How do different fine-tuning strategies (learning rates, batch sizes, data augmentation) affect frame identification performance?
- Can models transfer frame-semantic knowledge across different lexical resources beyond FrameNet?
- What is the relationship between frame identification accuracy and other semantic understanding tasks?

## Limitations
- Limited evaluation of model robustness to adversarial or out-of-distribution contexts
- Small training set size (500 examples) raises questions about scalability and overfitting
- Frame definition generation evaluation lacks rigorous quantitative metrics beyond semantic coherence
- No exploration of computational efficiency or comparison of multiple fine-tuning strategies

## Confidence
- LLMs encode latent frame-semantic knowledge: High - Strong experimental results across multiple benchmarks
- Fine-tuning with minimal data achieves state-of-the-art performance: Medium - Results are strong but limited by small training set size and lack of comparison to larger fine-tuning approaches
- Generated frame definitions are semantically coherent and task-effective: Medium - Qualitative evidence provided, but lacks rigorous quantitative evaluation

## Next Checks
1. Conduct ablation studies varying training data size (e.g., 100, 250, 500, 1000 examples) to determine minimum effective training requirements and assess overfitting risks
2. Implement adversarial testing with semantically similar but incorrect frames to evaluate model robustness and identify failure modes
3. Perform cross-lingual evaluation using FrameNet annotations in other languages to test whether frame-semantic knowledge generalizes across linguistic boundaries