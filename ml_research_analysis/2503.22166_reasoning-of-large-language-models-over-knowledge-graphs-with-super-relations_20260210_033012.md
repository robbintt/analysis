---
ver: rpa2
title: Reasoning of Large Language Models over Knowledge Graphs with Super-Relations
arxiv_id: '2503.22166'
source_url: https://arxiv.org/abs/2503.22166
tags:
- reasoning
- super-relation
- path
- super-relations
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ReKnoS, a framework that leverages super-relations
  to improve reasoning over knowledge graphs with large language models (LLMs). Super-relations
  are defined as groups of relations within a specific field, enabling both forward
  and backward reasoning by summarizing and connecting various relational paths.
---

# Reasoning of Large Language Models over Knowledge Graphs with Super-Relations

## Quick Facts
- arXiv ID: 2503.22166
- Source URL: https://arxiv.org/abs/2503.22166
- Reference count: 32
- Key outcome: ReKnoS framework achieves 2.92% average accuracy gain over state-of-the-art baselines, with 25% improvement in retrieval success rate and 87% larger search space.

## Executive Summary
This paper introduces ReKnoS, a framework that leverages super-relations to improve reasoning over knowledge graphs with large language models (LLMs). Super-relations are defined as groups of relations within a specific field, enabling both forward and backward reasoning by summarizing and connecting various relational paths. The framework significantly expands the search space and improves retrieval efficiency by representing multiple relation paths simultaneously without discarding valuable connections during reasoning. Experiments on nine real-world datasets demonstrate consistent performance gains, particularly benefiting smaller LLM models.

## Method Summary
ReKnoS constructs super-relations by grouping related relations from KG hierarchies (or clustering when hierarchies are absent), then uses these abstractions to guide LLM-based path reasoning. At each step, the LLM scores candidate super-relations connected to the current entity, and the top N are retained and propagated. This approach expands both search width and effective depth while maintaining constant LLM call complexity. The framework extracts entities along valid relation chains from selected super-relation paths and uses the LLM to decide whether to continue reasoning or answer. The method employs 3-shot in-context learning and tests multiple LLM backbones including GPT-3.5, GPT-4o-mini, Llama-2-7B, Mistral-7B, Llama-3-8B, and GPT-4.

## Key Results
- Achieves 2.92% average accuracy gain over state-of-the-art baselines across nine datasets
- Improves retrieval success rate by 25% compared to ToG
- Expands search space by 87% on average while maintaining constant LLM call complexity
- Particularly effective for smaller LLMs (Llama-2-7B, Mistral-7B) compared to larger models

## Why This Works (Mechanism)

### Mechanism 1: Super-Relation Abstraction Reduces Search Complexity
- Claim: Grouping fine-grained relations into super-relations expands the effective search space while keeping LLM call complexity constant (independent of search width N).
- Mechanism: Instead of scoring each individual relation, ReKnoS queries the LLM once per step to score super-relations, each representing a cluster of detailed relations. This allows exploring multiple underlying relation paths simultaneously without exponential LLM calls. As shown in Figure 5, ToG requires exponentially growing LLM calls, while ReKnoS maintains linear complexity (2L* + 1 calls per question).
- Core assumption: Relations within a super-relation share sufficient semantic coherence that scoring the abstraction is a reliable proxy for scoring individual members.

### Mechanism 2: Score-Based Path Selection Mitigates Misdirection
- Claim: By retaining multiple candidate super-relation paths (top N scored) rather than committing greedily to a single path, ReKnoS reduces retrieval failures caused by early misdirection.
- Mechanism: At each reasoning step, the LLM assigns scores to candidate super-relations. The top N are retained, normalized, and propagated. Final path selection (Eq. 8) sums scores along complete paths, selecting top K paths for entity extraction. This provides recovery opportunities if an initially promising path proves incorrect.
- Core assumption: The LLM can reliably assess relation-to-query relevance via scoring; cumulative path scores correlate with answer correctness.

### Mechanism 3: Constrained Search Space Expansion Balances Breadth and Depth
- Claim: Super-relations expand both search width (covering more relations per step) and effective depth (enabling longer paths within max length L), addressing both misdirection and depth limitation failure modes.
- Mechanism: By representing multiple relations compactly, a super-relation path of length l implicitly covers N^l relation combinations. Theorem 4.1 guarantees at least one valid relation path exists per super-relation path. Entity extraction (Eq. 9) filters to entities connected through valid relation chains, ensuring grounded answers.
- Core assumption: The KG connectivity structure ensures super-relation paths correspond to realizable relation paths; entity filtering is tractable.

## Foundational Learning

- Concept: **Knowledge Graph Triple Structure (head entity, relation, tail entity)**
  - Why needed here: The entire ReKnoS framework operates over KGs; understanding that `⟨e, r, e′⟩` encodes facts, and that paths are sequences of such triples, is prerequisite to grasping super-relation path definitions.
  - Quick check question: Given triples ⟨Alice, worksAt, IBM⟩ and ⟨IBM, locatedIn, NY⟩, what is the 2-hop path from Alice to NY?

- Concept: **Beam Search / Width-Limited Search**
  - Why needed here: ReKnoS's N parameter (retaining top N scored super-relations per step) is a beam-width analog. Understanding that increasing N expands exploration but increases computational cost helps interpret Table 4 results.
  - Quick check question: If beam width N=2 and you have 5 candidates with scores [0.9, 0.7, 0.6, 0.4, 0.2], which are retained?

- Concept: **LLM In-Context Scoring**
  - Why needed here: ReKnoS relies on LLMs assigning relevance scores to relations without fine-tuning. Understanding that prompts with examples (Section 4.2) guide this scoring is essential for debugging or improving the prompt.
  - Quick check question: If an LLM consistently scores relations containing query keywords higher, is this a feature or potential bias?

## Architecture Onboarding

- Component map: Entity Extractor -> Candidate Selector -> LLM Scorer -> Path Selector -> Entity Extractor -> Answer Decider (loop until L or answer found)
- Critical path: Candidate Selection → LLM Scoring → Path Selection → Entity Extraction → Answer Decision (loop until L or answer found)
- Design tradeoffs:
  - **N (width)**: Higher N improves retrieval (Table 4: N=3 vs N=1 drops Hits@1 by ~5%) but increases candidate pool; LLM calls remain constant.
  - **L (max depth)**: Higher L captures longer reasoning chains (Table 4: L=5 vs L=1 improves retrieval rate from 57% to 72.9%) but increases latency.
  - **Super-relation granularity**: Coarser groupings expand search space but risk diluting relevance; finer groupings improve precision but reduce coverage.

- Failure signatures:
  1. **Empty candidate set (|Cl| = 0)**: Indicates sparse KG connectivity; check relation existence.
  2. **Zero entities extracted (|E(kl)l| = 0)**: Super-relation path has no valid relation-chain realization; connectivity assumption violated.
  3. **High non-retrieval rate despite large N, L**: Likely KG missing required paths (Path Absence category, ~6-11% per Table 10) or LLM scoring failure.

- First 3 experiments:
  1. **Ablate N**: Run ReKnoS with N ∈ {1, 3, 5} on GrailQA subset (1,000 samples), measure Hits@1 and retrieval rate. Expect monotonic improvement per Table 4.
  2. **Compare LLM backbones**: Run with Llama-2-7B vs GPT-3.5 vs GPT-4o-mini on WebQSP, tracking LLM call counts and accuracy. Expect smaller models to benefit more (Table 2).
  3. **Visualize search space**: Log |fact triples encountered| per sample for ToG vs ReKnoS, replicate Figure 6 analysis. Expect 40-55% increase for ReKnoS.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the ReKnoS framework perform when applied to knowledge graphs in highly specialized domains (e.g., biomedical or legal) or graph types that differ significantly from the encyclopedic structures (Freebase/Wikidata) used in the current evaluation?
- Basis in paper: [explicit] The Conclusion states, "In future work, we will apply our work to knowledge graphs of other domains and types."
- Why unresolved: The current experiments are restricted to general-purpose knowledge graphs (Freebase, Wikidata), and it is unclear if the "super-relation" abstraction holds semantic value in sparser, domain-specific graphs.
- What evidence would resolve it: Benchmarking results (Hits@1 and Retrieval Rate) on domain-specific datasets like UMLS (biomedical) or industrial knowledge graphs.

### Open Question 2
- Question: To what extent does the semantic quality of the "super-relation" construction method (hierarchy vs. clustering) impact reasoning accuracy, particularly for graphs lacking inherent hierarchical structure?
- Basis in paper: [inferred] Section 3.2 suggests using clustering for graphs without hierarchy but notes cluster centers must be "textually coherent," implying a potential fragility in the construction method not fully analyzed in the main results.
- Why unresolved: The paper utilizes existing Wikidata hierarchies for primary results; the robustness of generated super-relations via clustering (shown in Appendix D.6) requires deeper ablation regarding the "coherence" of the clusters.
- What evidence would resolve it: A sensitivity analysis comparing the accuracy of ReKnoS using expert-crafted hierarchies versus varying granularity levels of algorithmic clustering.

### Open Question 3
- Question: Can the ReKnoS framework be enhanced to detect "Path Absence" (where no valid path exists) to reduce unnecessary reasoning steps, distinct from the "Misdirection" it currently solves?
- Basis in paper: [inferred] Figure 2 identifies "Path Absence" (6.0% of cases) as a distinct cause of non-retrieval, separate from Misdirection (68.8%), yet the framework focuses primarily on expanding the search space to overcome depth and misdirection limits.
- Why unresolved: The framework currently assumes a path might exist if the search space is expanded enough; it lacks a mechanism to verify path non-existence early in the reasoning chain.
- What evidence would resolve it: A study on the framework's ability to output "unanswerable" correctly when the graph is incomplete, measuring the reduction in average reasoning steps for such cases.

## Limitations
- The core premise relies on assumptions about LLM scoring reliability and KG hierarchical structures that are not independently validated.
- The framework focuses on expanding search space but lacks mechanisms to detect "Path Absence" cases where no valid path exists.
- Current experiments are limited to encyclopedic knowledge graphs, leaving domain-specific applicability uncertain.

## Confidence
- **High confidence**: Empirical accuracy improvements (2.92% average gain) and retrieval rate gains (25% improvement) are directly measurable and reproducible.
- **Medium confidence**: The claimed mechanism of super-relation abstraction reducing search complexity is plausible but not directly isolated from other factors like increased N or L.
- **Low confidence**: The claim that smaller LLMs benefit more is supported by one comparison (Table 2) but lacks systematic ablation across multiple model sizes and prompts.

## Next Checks
1. **Randomized super-relation test**: Implement ReKnoS with randomly assigned super-relations (breaking semantic coherence) and measure if accuracy gains persist. This would isolate whether semantic structure or breadth of search drives improvements.
2. **LLM scoring reliability**: For a fixed set of questions, record LLM scores for both individual relations and their super-relations. Compute correlation to verify the abstraction assumption.
3. **Cross-KG generalization**: Apply ReKnoS to a KG without natural hierarchical relation structure (e.g., a flat schema) and evaluate whether the framework still provides benefits or breaks down.