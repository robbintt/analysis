---
ver: rpa2
title: 'PhysDrive: A Multimodal Remote Physiological Measurement Dataset for In-vehicle
  Driver Monitoring'
arxiv_id: '2507.19172'
source_url: https://arxiv.org/abs/2507.19172
tags:
- data
- physdrive
- physiological
- driving
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PhysDrive is a large-scale multimodal dataset for contactless in-vehicle
  physiological monitoring, featuring synchronized RGB, NIR, and mmWave radar data
  from 48 drivers under diverse real-world driving conditions. It provides six synchronized
  ground truth signals (ECG, BVP, RESP, HR, RR, SpO2) and extensive scenario variations
  including different lighting, vehicle types, and road conditions.
---

# PhysDrive: A Multimodal Remote Physiological Measurement Dataset for In-vehicle Driver Monitoring

## Quick Facts
- **arXiv ID:** 2507.19172
- **Source URL:** https://arxiv.org/abs/2507.19172
- **Reference count:** 24
- **Primary result:** Large-scale multimodal dataset for contactless in-vehicle physiological monitoring with synchronized RGB, NIR, and mmWave radar data from 48 drivers under diverse real-world driving conditions.

## Executive Summary
PhysDrive is a comprehensive multimodal dataset designed for contactless in-vehicle physiological monitoring. It features synchronized data from RGB, NIR, and mmWave radar sensors alongside six ground truth physiological signals (ECG, BVP, RESP, HR, RR, SpO2) collected from 48 drivers across diverse driving scenarios. The dataset enables robust benchmarking of remote physiological measurement techniques in real-world driving conditions with varying lighting, vehicle types, and road surfaces. Extensive evaluations demonstrate mmWave radar's superior performance for heart rate and respiratory rate estimation compared to vision-based methods, particularly in challenging conditions.

## Method Summary
The dataset was collected using synchronized multimodal sensors including RGB cameras, NIR cameras, and mmWave radar sensors mounted in vehicle cabins. Six physiological ground truth signals were captured simultaneously: ECG, BVP, RESP, HR, RR, and SpO2. Data collection involved 48 drivers across various real-world driving scenarios including different lighting conditions (daytime, nighttime, dawn/dusk), vehicle types (sedan, SUV, minivan), and road conditions (highway, urban, rural). The dataset provides extensive annotations and preprocessing pipelines to enable research on multimodal sensor fusion and intelligent cockpit systems.

## Key Results
- mmWave radar outperforms vision-based methods with MAE of 3.65 for HR and 1.49 for RR
- Dataset demonstrates robustness to driver motion and road surface variations
- Vision-based methods show significant performance degradation under poor lighting conditions
- STMap preprocessing improves RGB/NIR method performance but introduces computational overhead

## Why This Works (Mechanism)
The dataset's effectiveness stems from its multimodal nature, combining the complementary strengths of different sensing modalities. mmWave radar provides direct physiological motion measurement unaffected by lighting conditions, while RGB/NIR cameras offer rich spatial information when lighting is adequate. The synchronization of six ground truth signals enables precise validation across multiple physiological parameters simultaneously. The diverse driving scenarios ensure the dataset captures real-world variability in illumination, motion patterns, and environmental conditions that affect physiological measurement accuracy.

## Foundational Learning
**Multimodal Sensor Fusion**: Combining multiple sensing modalities to leverage their complementary strengths for robust physiological measurement. *Why needed:* Different sensors have varying strengths and weaknesses under different conditions. *Quick check:* Compare single-modality vs. fused performance across challenging scenarios.
**Remote Photoplethysmography (rPPG)**: Extracting blood volume pulse information from video using optical properties of skin. *Why needed:* Enables contactless heart rate monitoring using standard cameras. *Quick check:* Validate rPPG performance across different skin tones and lighting conditions.
**mmWave Radar Signal Processing**: Extracting physiological signals from Doppler shifts and micro-movements captured by radar. *Why needed:* Provides lighting-invariant physiological measurements through clothing. *Quick check:* Test radar sensitivity to driver motion and vehicle vibrations.
**Spatio-Temporal Mapping (STMap)**: Preprocessing technique for video-based physiological measurement that captures temporal patterns. *Why needed:* Enhances signal quality for rPPG methods. *Quick check:* Measure STMap computational overhead vs. accuracy gains.
**Physiological Signal Synchronization**: Aligning multiple sensor streams and ground truth signals in time. *Why needed:* Ensures accurate validation of multimodal measurements. *Quick check:* Verify synchronization accuracy across all modalities.

## Architecture Onboarding

**Component Map**: Sensors (RGB, NIR, mmWave) -> Preprocessing (STMap, signal extraction) -> Physiological Estimation (HR, RR, ECG, BVP, RESP, SpO2) -> Ground Truth Validation

**Critical Path**: Data Collection -> Synchronization -> Preprocessing -> Signal Extraction -> Performance Evaluation

**Design Tradeoffs**: 
- mmWave offers lighting invariance but struggles with waveform reconstruction
- Vision-based methods provide rich spatial information but fail in poor lighting
- STMap improves accuracy but increases computational complexity
- Multiple ground truth signals enable comprehensive validation but increase collection complexity

**Failure Signatures**: 
- Vision-based methods fail under low illumination or rapid lighting changes
- mmWave methods show sensitivity to synchronization errors in waveform recovery
- All methods degrade with excessive driver motion or vehicle vibrations
- Performance varies significantly across different physiological parameters

**First 3 Experiments**:
1. Baseline evaluation: Compare single-modality performance for HR and RR estimation across all driving scenarios
2. Lighting condition analysis: Evaluate vision-based method degradation under different illumination levels
3. Motion robustness test: Assess all methods' performance under varying driver motion intensities

## Open Questions the Paper Calls Out
### Open Question 1
- **Question:** Can dynamic modality selection or adaptive fusion strategies effectively leverage the complementary strengths of RGB, NIR, and mmWave sensors across varying driving conditions?
- **Basis in paper:** [explicit] The Discussion states: "This suggests the possibility of dynamic modality selection or adaptive fusion to leverage each sensor's strengths effectively."
- **Why unresolved:** The paper evaluates modalities independently and reports that mmWave excels in accuracy while vision-based methods struggle with lighting; no fusion approach was tested.
- **What evidence would resolve it:** Benchmarking multimodal fusion models on PhysDrive that adaptively weight modalities based on scenario (e.g., lighting, road condition), demonstrating improved MAE/RMSE over single-modality baselines.

### Open Question 2
- **Question:** Can training schemes be developed that confer temporal robustness to mmWave models, reducing their sensitivity to synchronization errors during waveform recovery?
- **Basis in paper:** [explicit] The paper identifies this as "a key research direction" after observing mmWave's performance drop in ECG waveform recovery versus direct parameter regression.
- **Why unresolved:** Current mmWave methods show high accuracy for HR/RR regression but fail at reconstructing ECG waveforms, likely due to temporal misalignment sensitivity.
- **What evidence would resolve it:** Development of temporally-robust mmWave architectures that achieve comparable performance between waveform recovery and direct regression tasks, evaluated under controlled synchronization perturbations.

### Open Question 3
- **Question:** How do camera-based rPPG methods generalize across diverse skin tones in real-world driving conditions?
- **Basis in paper:** [explicit] The Limitations section states: "our participant cohort predominantly consists of individuals of East Asian descent, which limits the evaluation of camera-based methods across a diverse range of skin tones."
- **Why unresolved:** The dataset lacks skin tone diversity; existing benchmarks from indoor datasets may not transfer to driving scenarios with different lighting and motion profiles.
- **What evidence would resolve it:** Extended data collection with diverse skin tones and systematic evaluation showing whether RGB/NIR methods maintain consistent performance across Fitzpatrick skin types under driving conditions.

### Open Question 4
- **Question:** Can learnable or more efficient preprocessing techniques maintain STMap's robustness while enabling real-time inference?
- **Basis in paper:** [explicit] The Discussion notes: "Future research should explore learnable or more efficient preprocessing techniques that maintain the robustness of STMap while minimizing computational overhead."
- **Why unresolved:** STMap-based methods outperformed direct video input but introduce preprocessing latency unsuitable for real-time in-vehicle applications.
- **What evidence would resolve it:** End-to-end learnable architectures achieving comparable or better accuracy than STMap baselines with reduced latency measured in milliseconds per frame.

## Limitations
- Limited sample size of 48 participants may not capture full population variability
- Dataset focuses on Chinese participants, limiting generalizability to other populations
- Testing conducted primarily under controlled conditions, not full spectrum of real-world scenarios
- STMap preprocessing introduces computational overhead unsuitable for real-time applications

## Confidence
- **High confidence:** Dataset's comprehensive multimodal nature and synchronized ground truth signals
- **Medium confidence:** mmWave radar's superior performance for HR and RR estimation under tested conditions
- **Medium confidence:** Claims of robustness to driver motion and road surface variations within tested scenarios

## Next Checks
1. Conduct cross-population validation studies with participants from different ethnic backgrounds and age groups to assess generalizability
2. Perform extended real-world testing across diverse driving conditions including extreme weather, varying road surfaces, and different vehicle types beyond current scope
3. Implement long-term monitoring studies to evaluate sensor performance and physiological measurement accuracy over extended driving periods (several hours) to assess temporal stability and potential drift in measurements