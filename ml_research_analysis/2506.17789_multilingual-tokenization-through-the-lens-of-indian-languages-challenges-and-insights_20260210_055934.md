---
ver: rpa2
title: 'Multilingual Tokenization through the Lens of Indian Languages: Challenges
  and Insights'
arxiv_id: '2506.17789'
source_url: https://arxiv.org/abs/2506.17789
tags:
- languages
- tokenizers
- multilingual
- language
- tokenizer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a comprehensive intrinsic evaluation of tokenization
  strategies across 17 Indian languages, addressing the challenge of building fair
  and effective tokenizers for morphologically rich and script-diverse languages underrepresented
  in existing NLP tools. The authors evaluate Byte Pair Encoding (BPE) and Unigram
  Language Model (ULM) algorithms across vocabulary sizes from 32K to 256K, comparing
  joint and cluster-based multilingual vocabulary construction approaches.
---

# Multilingual Tokenization through the Lens of Indian Languages: Challenges and Insights

## Quick Facts
- arXiv ID: 2506.17789
- Source URL: https://arxiv.org/abs/2506.17789
- Reference count: 18
- 17 Indian languages evaluated for multilingual tokenization quality

## Executive Summary
This paper presents a comprehensive intrinsic evaluation of tokenization strategies across 17 Indian languages, addressing the challenge of building fair and effective tokenizers for morphologically rich and script-diverse languages underrepresented in existing NLP tools. The authors evaluate Byte Pair Encoding (BPE) and Unigram Language Model (ULM) algorithms across vocabulary sizes from 32K to 256K, comparing joint and cluster-based multilingual vocabulary construction approaches. Key findings include: normalization significantly improves tokenization quality, with language-specific rules like anusvāra conversion reducing fertility scores; ULM outperforms BPE in morphological alignment (IndicMorphScore); cluster-based training achieves lower word fragmentation rates (WFR) for morphologically rich languages compared to joint training; and multilingual tokenizers can effectively transfer to extremely low-resource languages when trained on related high-resource languages, with fertility scores ranging from 1.307-1.758 and character-per-token (CPT) values from 2.820-3.880 in zero-shot settings.

## Method Summary
The study evaluates tokenization quality across 17 Indian languages using two primary algorithms: Byte Pair Encoding (BPE) and Unigram Language Model (ULM). Vocabulary sizes range from 32K to 256K tokens, with both joint and cluster-based multilingual training approaches compared. The evaluation framework includes language-specific normalization rules (such as anusvāra conversion), fertility scores to measure token efficiency, Word Fragmentation Rate (WFR) to assess morphological preservation, Character-Per-Token (CPT) ratios, and IndicMorphScore for morphological alignment quality. The authors also explore zero-shot transfer to extremely low-resource languages by training on related high-resource language clusters.

## Key Results
- Normalization rules (including anusvāra conversion) significantly improve tokenization quality with fertility scores of 1.307-1.758 and CPT values of 2.820-3.880
- ULM algorithm outperforms BPE in morphological alignment across all evaluated languages
- Cluster-based multilingual training achieves lower WFR compared to joint training for morphologically rich languages
- Zero-shot transfer to extremely low-resource languages succeeds when trained on related high-resource languages

## Why This Works (Mechanism)
The effectiveness of the proposed approach stems from addressing the unique challenges of Indian languages through careful preprocessing and algorithm selection. Language-specific normalization rules handle script variations and phonetic consistency issues that commonly fragment tokens. The ULM algorithm's probabilistic framework better captures morphological patterns in agglutinative and morphologically rich languages compared to BPE's frequency-based approach. Cluster-based training respects linguistic similarities between languages, allowing tokenizers to learn shared morphological patterns while preserving language-specific characteristics.

## Foundational Learning

**Byte Pair Encoding (BPE)**: A data compression algorithm that iteratively merges frequent character pairs into single tokens. Why needed: Forms the basis for many modern tokenizers and provides a simple, efficient approach to vocabulary construction. Quick check: Verify that merge operations align with meaningful linguistic units in the target language.

**Unigram Language Model (ULM)**: A probabilistic approach that assigns scores to tokenizations based on likelihood, allowing for multiple segmentation candidates. Why needed: Better captures morphological patterns in languages with complex word formation processes. Quick check: Compare likelihood scores across different segmentations to ensure optimal tokenization.

**Fertility Score**: Measures the average number of tokens generated per word, with lower scores indicating more efficient tokenization. Why needed: Provides a quantitative measure of tokenizer effectiveness in preserving word integrity. Quick check: Calculate fertility scores across different vocabulary sizes to identify optimal trade-offs.

**Word Fragmentation Rate (WFR)**: The percentage of words that are split into multiple tokens, indicating morphological preservation quality. Why needed: Directly measures how well tokenizers maintain meaningful word boundaries. Quick check: Analyze fragmentation patterns to identify systematic issues in specific language groups.

**IndicMorphScore**: A metric specifically designed to evaluate morphological alignment quality in Indian languages. Why needed: Standard metrics may not capture the nuances of morphological richness in these languages. Quick check: Compare IndicMorphScore with standard morphological evaluation metrics to validate its effectiveness.

## Architecture Onboarding

**Component Map**: Raw Text -> Normalization Rules -> Tokenization Algorithm (BPE/ULM) -> Vocabulary Construction (Joint/Cluster) -> Evaluation Metrics

**Critical Path**: Normalization → Tokenization → Evaluation forms the core pipeline, where normalization quality directly impacts tokenization effectiveness.

**Design Tradeoffs**: Joint multilingual training offers simplicity and cross-lingual benefits but may sacrifice language-specific morphological preservation, while cluster-based training provides better morphological alignment at the cost of increased complexity in managing multiple vocabularies.

**Failure Signatures**: High WFR values indicate poor morphological preservation, while elevated fertility scores suggest inefficient tokenization that breaks words unnecessarily. Low IndicMorphScore values reveal morphological misalignment in the tokenizer output.

**3 First Experiments**:
1. Apply normalization rules to a sample corpus and measure pre/post fertility score improvements
2. Compare BPE and ULM tokenization on morphologically complex words to quantify morphological preservation differences
3. Train joint vs cluster-based tokenizers on high-resource language pairs and evaluate WFR differences

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses on intrinsic metrics rather than downstream task performance, limiting generalizability to real-world applications
- Analysis constrained to BPE and ULM algorithms, excluding other relevant approaches like SentencePiece variants
- Zero-shot transfer results based on limited set of extremely low-resource languages, effectiveness for languages with minimal orthographic overlap remains uncertain

## Confidence
- Normalization improvements: High confidence (systematic evaluation across 17 languages with clear quantitative improvements)
- ULM superiority over BPE: Medium confidence (consistent pattern across languages though specific metric-dependent)
- Cluster-based training benefits: Medium confidence (improved WFR shown but practical significance requires further validation)

## Next Checks
1. Evaluate tokenization quality on downstream NLP tasks (machine translation, NER, sentiment analysis) to verify that improved intrinsic metrics translate to better performance
2. Test the zero-shot transfer approach on additional extremely low-resource languages with minimal orthographic overlap to establish robustness boundaries
3. Compare the proposed normalization rules against language-specific morphological analyzers to quantify trade-offs between simple rule-based approaches and more sophisticated linguistic preprocessing