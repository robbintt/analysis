---
ver: rpa2
title: From STLS to Projection-based Dictionary Selection in Sparse Regression for
  System Identification
arxiv_id: '2512.14404'
source_url: https://arxiv.org/abs/2512.14404
tags:
- score
- dictionary
- system
- terms
- dsub
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work revisits dictionary-based sparse regression for system\
  \ identification, focusing on Sequential Threshold Least Squares (STLS) and proposing\
  \ a score-guided library selection method. The key idea is to use projected reconstruction\
  \ errors\u2014referred to as scores\u2014to identify and filter non-informative\
  \ dictionary terms before applying regression."
---

# From STLS to Projection-based Dictionary Selection in Sparse Regression for System Identification

## Quick Facts
- arXiv ID: 2512.14404
- Source URL: https://arxiv.org/abs/2512.14404
- Reference count: 40
- Key outcome: Score-guided dictionary selection improves sparse regression accuracy and interpretability by filtering non-informative terms before regression, especially for small coefficients and noisy systems.

## Executive Summary
This paper revisits Sequential Threshold Least Squares (STLS) for sparse regression in system identification, proposing a projection-based score metric to guide dictionary term selection. The key innovation is using the increase in reconstruction error when removing a term as a measure of its importance, rather than relying on coefficient magnitude. This score is shown to be theoretically related to STLS outcomes, and numerical experiments demonstrate improved accuracy and robustness, particularly for small-coefficient terms and noisy data. The method integrates naturally with weak SINDy formulations and reduces reliance on thresholding, offering a principled way to refine model structure.

## Method Summary
The method computes projection-based scores Score(dᵢ;D,y) = ||(P_D - P_{D\{i}})y||₂ / ||y||₂ to evaluate dictionary term importance, then applies a Greedy Backward Stepwise Regressor (GBSR) to iteratively remove lowest-score terms. It uses weak formulation (Weak SINDy) for noise robustness, replacing point-wise derivatives with integration against test functions. The approach defaults to polynomial libraries up to degree 3 plus trigonometric functions, and identifies optimal sparsity by observing sharp increases in score sequences when removing informative terms.

## Key Results
- Score-based filtering successfully identifies correct terms in Lorenz, Hopf, and pitchfork systems where standard SINDy fails for small coefficients
- Integration with weak SINDy improves robustness against noise compared to standard derivative-based regression
- Theoretical analysis proves STLS coefficients are scaled versions of projection scores
- Numerical experiments show improved term recovery rates and model interpretability

## Why This Works (Mechanism)

### Mechanism 1
The "score" (||P_D - P_{D\D_{sub}}||y||) acts as a theoretically grounded proxy for the importance of a dictionary term, independent of its coefficient magnitude. Unlike standard STLS which thresholds based on coefficient size, this method evaluates a term's contribution by measuring the increase in projection error when that term is removed. Lemma 1 proves that STLS coefficient magnitude is actually a scaled version of this projection score. The method assumes the dictionary is full-rank and the target lies within the span of library terms.

### Mechanism 2
Optimal model sparsity can be identified by observing a "sharp increase" in the minimal score sequence during iterative term removal. The algorithm removes least informative terms first, keeping reconstruction error low. When a critical term is removed to satisfy stricter sparsity, the projection error spikes, indicating the true number of active terms. This requires a clear separation between contributions of true and spurious terms.

### Mechanism 3
Integrating score-based selection with weak formulation improves robustness against noise compared to standard regression. The weak formulation replaces point-wise derivative approximation with integration against test functions, filtering out high-frequency noise. Calculating scores within this integral domain allows better distinction between signal and noise energy.

## Foundational Learning

- **Concept: Orthogonal Projection (P_D)**
  - Why needed here: The entire scoring mechanism relies on projecting the target signal y onto the column space of the dictionary D
  - Quick check question: If you add a new column to D that is a linear combination of existing columns, does the projection P_D y change? (Answer: No)

- **Concept: Sparsity (l₀ "Norm")**
  - Why needed here: The goal is finding the simplest model with fewest terms, balancing reconstruction error and number of non-zero coefficients
  - Quick check question: Why is minimizing ||Dξ - y||² + λ||ξ||₀ considered "hard" compared to LASSO (l₁)?

- **Concept: Galerkin/Weak Formulation**
  - Why needed here: The paper defaults to "Weak SINDy" for numerical experiments, moving regression from time domain to test function domain to avoid noisy derivatives
  - Quick check question: How does integration by parts move the derivative from data (ẋ) to test function (φ)?

## Architecture Onboarding

- **Component map:** Input (X) -> Preprocessor (Weak Form engine OR Numerical Differentiator) -> Library Builder (polynomials, trigs) -> Scoring Engine (computes projection scores) -> Selector (GBSR or ESR) -> Final Regressor (Least Squares)

- **Critical path:** The GBSR Loop (Algorithm 1). It starts with all terms and iteratively removes the one with lowest projection score until only one remains. The history of scores determines the final model.

- **Design tradeoffs:**
  - ESR vs. GBSR: ESR finds global minimum score for each sparsity level but scales combinatorially (O(2ⁿ)). GBSR is O(n²) but may get stuck in local minima
  - Noise vs. Resolution: Higher polynomial degrees in test functions capture more dynamics but may overfit noise

- **Failure signatures:**
  - Flat Score Curve: If plot of Score vs Filtering Order shows no sharp jump, method cannot automatically select sparsity level
  - Sensitivity: Small changes in test function width cause large changes in identified terms

- **First 3 experiments:**
  1. Sanity Check (Lorenz): Generate clean Lorenz data, run GBSR, verify score "jump" occurs exactly when first true term is removed
  2. Small Coefficient Stress Test (Hopf): Use Hopf with μ = -10⁻⁵, compare standard SINDy (which fails if threshold > μ) vs. Score-based filtering
  3. Noise Limit Test: Add 5-10% Gaussian noise to Pitchfork system, compare identification success rates of Standard SINDy vs. Weak-Score-SINDy

## Open Questions the Paper Calls Out

### Open Question 1
Can an automatic selection criterion be developed to detect the "jump" in relative scores and determine the optimal sparsity level without empirical observation? The conclusion states future work includes "developing an automatic selection algorithm" to replace current empirical observation of score patterns. Users must visually identify the "sharp increase" in scores to determine when a correct term is being filtered out.

### Open Question 2
Does utilizing multiple trajectories or parametric simulations significantly reduce the sensitivity of the score-based method to weak formulation hyperparameters? Section 5.1.4 notes that "using multiple trajectories generated under different simulation parameters may mitigate this sensitivity," and Section 6 lists exploring "parametric systems with multiple simulation at once" as future work.

### Open Question 3
Can the Greedy Backward Stepwise Regressor (GBSR) be modified to retain reliability in high-noise regimes where the "sharp increasing pattern" currently disappears? Section 5.1.5 states that "the sharp increasing pattern was not observed in the presence of noise, indicating that exhaustive search (ESR) is the recommended method in such cases."

## Limitations
- Performance depends heavily on weak formulation hyperparameters (test function degree, support width) which are not universally prescribed
- Claim of "automatic" sparsity selection lacks algorithmic detection method—empirical observation is used instead
- Method remains vulnerable to noise-induced smoothing of score jumps, requiring fallback to exhaustive search at higher computational cost

## Confidence

- **High confidence:** Mathematical relationship between STLS coefficients and projection scores (Lemma 1); general mechanism of using reconstruction error to identify non-informative terms
- **Medium confidence:** Claims about improved noise robustness when combined with weak SINDy—supported by numerical results but sensitive to parameter choices
- **Low confidence:** Claim of automatic sparsity selection without specifying detection criteria; generalizability across diverse dynamical systems without parameter tuning

## Next Checks

1. Test the algorithm on a system with three terms of equal magnitude—verify it correctly identifies all terms versus removing one due to arbitrary score ties
2. Implement an automated jump-detection algorithm (e.g., derivative-based or elbow-method) and assess whether it matches human-identified sparsity levels across all numerical examples
3. Compare computational cost and accuracy trade-offs between GBSR and ESR on a medium-sized library (20-30 terms) to quantify when exhaustive search becomes necessary