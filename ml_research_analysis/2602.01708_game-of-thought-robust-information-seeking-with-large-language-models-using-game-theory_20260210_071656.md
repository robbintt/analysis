---
ver: rpa2
title: 'Game of Thought: Robust Information Seeking with Large Language Models Using
  Game Theory'
arxiv_id: '2602.01708'
source_url: https://arxiv.org/abs/2602.01708
tags:
- questions
- game
- item
- items
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of robust information-seeking with
  large language models (LLMs) under worst-case assumptions. The authors formalize
  the Strategic Language Search (SLS) problem as a two-player zero-sum extensive-form
  game, where an adversarial Item Chooser selects an item and a Questioner seeks it
  through Yes/No questions.
---

# Game of Thought: Robust Information Seeking with Large Language Models Using Game Theory

## Quick Facts
- **arXiv ID**: 2602.01708
- **Source URL**: https://arxiv.org/abs/2602.01708
- **Reference count**: 40
- **Primary result**: Game of Thought (GoT) improves worst-case performance in information-seeking games by optimizing for worst-case scenarios rather than average-case information gain.

## Executive Summary
This paper addresses the challenge of robust information seeking with large language models (LLMs) under worst-case assumptions. The authors formalize the Strategic Language Search (SLS) problem as a two-player zero-sum extensive-form game, where an adversarial Item Chooser selects an item and a Questioner seeks it through Yes/No questions. They propose Game of Thought (GoT), a game-theoretic framework that approximates a Nash equilibrium strategy using depth-limited subgame search and heuristic evaluation. GoT demonstrates improved worst-case performance across multiple settings including 20 Questions, medical diagnosis, and troubleshooting scenarios, showing that optimizing for worst-case scenarios yields more robust performance than optimizing for average-case information gain.

## Method Summary
The Game of Thought framework approaches information-seeking as a two-player zero-sum extensive-form game where an adversarial Item Chooser selects from a known set of items and a Questioner identifies the item through sequential Yes/No questions. The method performs depth-limited subgame search (d=3) with m=3 candidate questions per information set, using an LLM to generate questions and classify items into YES/NO groups. A truncated extensive-form game tree is built with heuristic evaluation at leaf nodes (log₂ of remaining items), then solved using counterfactual regret minimization (LiteEFG) to approximate a Nash equilibrium strategy. The process repeats until the item is identified, with results showing improved worst-case interaction lengths compared to prompting-based methods and uncertainty-guided search.

## Key Results
- GoT achieves worst-case interaction length of 10.2 on Common dataset vs 11 for UoT baseline
- Weighted variants show up to 40% improvement when item severity is considered
- Across multiple domains (20 Questions, medical diagnosis, troubleshooting), GoT consistently outperforms average-case optimizing methods
- Optimizing for worst-case scenarios proves more effective than optimizing for average-case information gain

## Why This Works (Mechanism)
The framework works by explicitly modeling the adversarial nature of information-seeking problems, where the worst-case scenario must be optimized rather than average performance. By treating the problem as a two-player zero-sum game and approximating a Nash equilibrium strategy through depth-limited subgame search, GoT ensures robustness against adversarial item selection. The heuristic evaluation at leaf nodes provides a computationally tractable approximation of subgame values, while the iterative question generation and answer classification using LLM oracles enables practical implementation.

## Foundational Learning
- **Extensive-form games**: Why needed - The problem structure requires modeling sequential decisions with imperfect information; Quick check - Can you represent the game tree with player nodes, chance nodes, and information sets?
- **Counterfactual regret minimization (CFR)**: Why needed - Provides a practical algorithm for finding approximate Nash equilibria in large extensive-form games; Quick check - Can you implement the regret matching update rule for action selection?
- **Zero-sum game theory**: Why needed - The adversarial nature of the problem maps naturally to zero-sum game formulation; Quick check - Can you verify that the sum of player utilities equals zero at each terminal node?
- **Heuristic evaluation in game trees**: Why needed - Enables tractable approximation of subgame values without full tree expansion; Quick check - Does log₂(|S(l)|) provide reasonable estimates for remaining game complexity?
- **Information sets in imperfect information games**: Why needed - Models the Questioner's uncertainty about which items remain after each answer; Quick check - Can you correctly group game states that are indistinguishable to the player?

## Architecture Onboarding
- **Component map**: LLM (question generation) -> Subgame search (tree building) -> CFR solver (strategy computation) -> Question selection -> Oracle (item classification) -> Update item set
- **Critical path**: Generate candidate questions → Classify items via oracle → Build truncated EFG tree → Solve with CFR → Sample question from NE → Observe answer → Update item set
- **Design tradeoffs**: Depth-limited search vs. computational cost; m candidate questions vs. coverage of solution space; heuristic evaluation vs. exact subgame values; NE sampling vs. deterministic best response
- **Failure signatures**: LLM questions that don't split item set (violating Assumption 3.8); Inconsistent oracle answers between simulation and gameplay; CFR solver failing to converge; Heuristic values that poorly approximate true subgame values
- **First experiments**: 1) Test LLM question generation compliance with Assumption 3.8 on Breeds dataset; 2) Compare heuristic evaluation accuracy against full-depth analysis on small item sets; 3) Measure CFR solver sensitivity to iteration count on truncated EFGs

## Open Questions the Paper Calls Out
None specified in the provided text.

## Limitations
- Assumption 3.8 compliance is not guaranteed in practice, requiring resampling of non-compliant questions
- Heuristic evaluation at leaf nodes (log₂(|S(l)|)) may not accurately reflect true subgame values, especially for complex item sets
- CFR solver parameters (iterations, convergence thresholds) are not fully specified, potentially affecting equilibrium quality

## Confidence
- **High confidence**: Worst-case interaction length results for GoT vs. UoT and prompting methods are directly supported by reported tables and figures
- **Medium confidence**: Effectiveness of depth-limited subgame search demonstrated empirically, but hyperparameter choices (d=3, m=3) lack rigorous justification
- **Low confidence**: Exact behavior of LLM in weighted variant question generation not fully specified, particularly JSON parsing and retry mechanisms

## Next Checks
1. **Check Assumption 3.8 compliance**: Run controlled experiment measuring frequency of non-compliant LLM-generated questions and impact on subgame search quality
2. **Validate heuristic evaluation**: Compare log₂(|S(l)|) heuristic values against true subgame values for full-depth analysis on Breeds dataset
3. **Test CFR solver sensitivity**: Run LiteEFG with varying iterations and convergence thresholds on truncated EFGs to measure strategy stability and quality<|end_of_text|><|begin_of_text|>4. **Verify dataset availability**: Confirm that item lists and weight annotations are accessible in released code/datasets as stated in paper

5. **Benchmark against other game-theoretic approaches**: Compare GoT performance with alternative equilibrium-finding methods (e.g., fictitious play, smooth CFR) on the same problem instances