---
ver: rpa2
title: Characterising the Inductive Biases of Neural Networks on Boolean Data
arxiv_id: '2505.24060'
source_url: https://arxiv.org/abs/2505.24060
tags:
- functions
- function
- neural
- networks
- complexity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a toy model for understanding neural network
  generalization by exploiting the one-to-one correspondence between depth-2 discrete
  fully connected networks (DFCNs) and disjunctive normal forms (DNFs) on Boolean
  functions. The authors derive analytical bounds showing that randomly initialized
  DFCNs exhibit strong simplicity bias in their prior distribution over Boolean functions,
  with P(f) ~ 2^(-K(f)) where K(f) is the DNF complexity.
---

# Characterising the Inductive Biases of Neural Networks on Boolean Data

## Quick Facts
- arXiv ID: 2505.24060
- Source URL: https://arxiv.org/abs/2505.24060
- Reference count: 40
- This paper presents a toy model for understanding neural network generalization by exploiting the one-to-one correspondence between depth-2 discrete fully connected networks (DFCNs) and disjunctive normal forms (DNFs) on Boolean functions.

## Executive Summary
This paper establishes a toy model for understanding neural network generalization through a bijection between depth-2 discrete fully connected networks (DFCNs) and disjunctive normal forms (DNFs) on Boolean functions. The authors derive analytical bounds showing that randomly initialized DFCNs exhibit strong simplicity bias, with low-complexity functions occupying exponentially larger volumes in parameter space. Through Metropolis-Hastings and greedy SGD-like algorithms, they demonstrate that generalization correlates with prior probability: simple functions generalize well while complex ones like high-order parity are unlearnable. Weight decay introduces a multiplicative bias that improves generalization on simple targets by learning minimal DNF representations.

## Method Summary
The method exploits a one-to-one correspondence between depth-2 discrete fully-connected networks (DFCNs) with ternary weights {−1, 0, 1} and disjunctive normal forms (DNFs) on Boolean functions. The framework uses three training algorithms: Metropolis-Hastings MCMC for Bayesian sampling, a min-norm oracle using sympy's SOPform, and a greedy SGD-like algorithm with neighborhood evaluation. Prior probabilities are estimated via Monte Carlo sampling of 10^8 random weight configurations. The study focuses on Boolean functions f: {0,1}^n → {0,1} with n=7, training on sets of size m ∈ {16, 32, 64, 96} and testing on the remainder.

## Key Results
- DFCNs exhibit strong simplicity bias: low-complexity functions occupy exponentially larger volumes in parameter space
- Generalization correlates with prior probability: simple functions (low K(f)) generalize well while complex ones are unlearnable
- Weight decay introduces a multiplicative bias e^(-λK(f)) that improves generalization on simple targets
- More training data can harm generalization for complex functions due to convergence to lower-complexity interpolants

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DFCNs exhibit strong simplicity bias because low-complexity functions occupy exponentially larger volumes in parameter space.
- Mechanism: The bijection between DFCNs and DNF formulas maps each weight configuration to an interpretable function. Since K(f) = min ||W^(1)||_1, functions requiring fewer non-zero weights have exponentially more parameter configurations that implement them.
- Core assumption: Uniform sampling over discrete ternary weights {−1, 0, 1} accurately reflects the prior over functions.
- Evidence anchors:
  - [abstract]: "low-complexity functions occupying exponentially larger volumes in parameter space"
  - [Section 3.2]: "P(f) ≲ 2^{−K_{LZ}(f)+O(1)}" and empirical Figure 2(a) showing constant functions dominate
  - [corpus]: Corpus lacks direct corroboration; related work (Valle-Pérez et al. 2018) cited but not in neighbor set

### Mechanism 2
- Claim: Weight decay amplifies simplicity bias by adding a multiplicative factor e^{−λK(f)} to the posterior.
- Mechanism: The DNF-DFCN correspondence makes ||θ||_1 ≈ K(f). With MCMC sampling, the posterior becomes P_λ(f|S) ∝ e^{−λK(f)} P_{λ=0}(f|S). This penalizes complex functions, pushing the network toward minimal DNF representations.
- Core assumption: The norm is dominated by the smallest attainable ||θ||_1 for a given f, and ||θ||_1 ≈ ||W^(1)||_1.
- Evidence anchors:
  - [Section 4.2]: "weight decay approximately acts as a multiplicative bias e^{−λK(f)}"
  - [Figure 3(c)]: Weight decay (λ=0.01) achieves 100% test accuracy on 4-parity by learning exact minimal DNF
  - [corpus]: No direct corpus corroboration; mechanism is paper-specific

### Mechanism 3
- Claim: More training data can harm generalization for complex functions because the network converges to lower-complexity interpolants.
- Mechanism: With limited data, the minimum-norm interpolant may be simpler than the target. Adding data forces higher-complexity interpolants that still differ from the target, reducing test accuracy.
- Core assumption: Training converges to or near the minimum-norm solution consistent with the training set.
- Evidence anchors:
  - [Section 4.3]: "k=6,7 never exceed chance level despite more data"
  - [Appendix B.6]: Detailed example showing 4-parity with m=8 yields 0% test accuracy vs. 33% with m=4
  - [corpus]: No corpus corroboration; this is a counterintuitive finding specific to the paper's framework

## Foundational Learning

- Concept: **Disjunctive Normal Form (DNF)**
  - Why needed here: The entire framework depends on understanding that any Boolean function can be written as an OR of AND-clauses, and that the minimum literal count K(f) measures complexity.
  - Quick check question: Given f outputs 1 on inputs {00, 01, 11}, what's the minimal DNF? (Answer: ¬x₁ OR x₂, K(f)=2)

- Concept: **Prior probability P(f) as parameter-space volume**
  - Why needed here: The paper's core claim is that P(f) predicts generalization—functions with larger P(f) generalize better because they're more likely to be found by random initialization and training.
  - Quick check question: If function A has P(f_A)=10^{−4} and function B has P(f_B)=10^{−8}, which requires more samples to learn? (Answer: B, by ~10^4×)

- Concept: **Bayesian posterior with weight decay**
  - Why needed here: Understanding why ℓ₁ regularization translates to e^{−λK(f)} requires viewing training as sampling from a posterior.
  - Quick check question: How does increasing λ affect the relative probability of a function with K(f)=10 vs. K(f)=20? (Answer: The ratio becomes e^{−10λ}× more favorable to the simpler function)

## Architecture Onboarding

- Component map:
  - Input x -> W^(1)x + b^(1) -> ReLU -> W^(2)· + b^(2) > 0 -> output

- Critical path: Input x → W^(1)x + b^(1) → ReLU → W^(2)· + b^(2) > 0 → output. The ReLU + bias construction ensures each hidden unit outputs 1 iff its clause is satisfied; W^(2) aggregates via OR.

- Design tradeoffs:
  - **Width α_w**: Must be ≥1 for full expressivity, but larger α_w biases toward constant functions. Paper uses α_w=2.
  - **Training algorithm**: MCMC (Alg. 1) is Bayesian but slow; greedy SGD-like (Alg. 3) scales poorly for large n due to neighborhood enumeration.
  - **Complexity measure**: K(f) (literals) vs. K_θ(f) (literals + clauses) vs. K_C(f) (clauses only). Each has different theoretical properties.

- Failure signatures:
  - **High test error with zero train error**: Likely a complex target (high K(f))—check if target is high-order parity.
  - **Test accuracy decreases with more data**: Strong indicator of severe prior-target mismatch; minimum-norm interpolant is wrong.
  - **Weight norm doesn't decrease during training**: Weight decay not inducing feature learning; may need higher λ or different target.

- First 3 experiments:
  1. **Verify simplicity bias**: Sample 10^6 random DFCN parameter configurations for n=4, compute P(f) vs. K(f). Confirm constant functions dominate and parity is suppressed (replicate Figure 2a).
  2. **Weight decay ablation**: Train on k-parity (k=1,2,3,4,5) with λ ∈ {0, 0.001, 0.01, 0.1}. Plot test accuracy vs. λ for each k to find the complexity threshold where decay stops helping (replicate Figure 4).
  3. **Data scaling on complex targets**: Train on 7-parity with m ∈ {16, 32, 64, 96}. Confirm test accuracy decreases as m increases. Visualize W^(1) heatmap to show failure to find minimal representation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the DFCN framework replicate the "grokking" phenomenon, and does it occur via similar circuit formation mechanisms to those observed in transformers?
- Basis in paper: [explicit] In the Future Directions, the authors state, "Exploiting this to study other phenomena... such as grokking... would be interesting to explore."
- Why unresolved: The current study focuses on standard training dynamics rather than the specific phase transitions characteristic of grokking.
- What evidence would resolve it: Experiments showing sudden generalization improvements long after overfitting on algorithmic tasks within the DFCN model.

### Open Question 2
- Question: How do different optimization algorithms influence the posterior distribution over functions in DFCNs?
- Basis in paper: [explicit] The authors ask to "better understand how different optimisers and training schemes influence the posterior, or whether a Bayesian formulation is even possible at all."
- Why unresolved: The paper primarily relies on Metropolis-Hastings and a greedy SGD-like algorithm, leaving the behavior of other optimizers undefined.
- What evidence would resolve it: Theoretical derivations or empirical mappings of the implicit priors induced by alternative discrete optimization methods.

### Open Question 3
- Question: To what extent does the strong simplicity bias observed in discrete DFCNs persist in continuous networks with real-valued weights?
- Basis in paper: [explicit] The authors identify the "gap between our theory and typical continuous deep learning applications" as a primary limitation.
- Why unresolved: The theoretical results rely on the specific bijection between DFCNs and DNFs, which does not hold for continuous weights.
- What evidence would resolve it: Comparative studies showing similar scaling laws between parameter space volume and function complexity in continuous networks.

### Open Question 4
- Question: Can the analytical bounds on the prior probability $P(f)$ be tightened to provide more precise generalization guarantees?
- Basis in paper: [explicit] The authors note that "improving the bounds on $P(f)$ as a function of $K(f)$... may provide additional insight."
- Why unresolved: The current bounds (Table 2) capture scaling trends but may be loose for specific function classes like parity versus t-entropy.
- What evidence would resolve it: Mathematical derivation of tighter inequalities linking DNF complexity directly to generalization error.

## Limitations
- The framework is constrained to depth-2 networks, which may not capture deeper architectures' inductive biases
- The paper demonstrates strong performance on Boolean tasks but doesn't establish transfer to continuous domains
- The MCMC method's computational cost prevents exploration of larger architectures or higher dimensions

## Confidence

**High Confidence (Level A):**
- The analytical framework connecting DFCNs to DNFs is mathematically sound (Propositions 2.7-2.9)
- Empirical demonstration of simplicity bias in prior distribution (Figure 2a)
- Weight decay mechanism creating multiplicative bias e^{-λK(f)} (Section 4.2)

**Medium Confidence (Level B):**
- Generalization correlates with prior probability (Section 4.1)
- Weight decay improves generalization on simple targets (Figure 4)
- Counterintuitive finding that more training data can harm generalization for complex functions

**Low Confidence (Level C):**
- The SGD-like algorithm's neighborhood evaluation is computationally infeasible for larger problems
- Extrapolation to continuous-weight networks is not rigorously justified
- The framework's applicability to non-Boolean domains remains speculative

## Next Checks

1. **Convergence validation:** Run MCMC with explicit convergence criteria and compare results to fixed iteration counts used in the paper. Document the number of iterations needed for stable P(f) estimates across different function complexities.

2. **Cross-validation of complexity measures:** Implement and compare K(f), K_θ(f), and K_C(f) across the same function class. Verify that the paper's choice of K(f) consistently predicts generalization better than alternatives.

3. **Real-world benchmark transfer:** Apply the DFCN framework to a simplified continuous dataset (e.g., binary classification on MNIST digits) using thresholded activations. Measure whether simplicity bias predictions hold in this regime.