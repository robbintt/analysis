---
ver: rpa2
title: A Trustworthiness-based Metaphysics of Artificial Intelligence Systems
arxiv_id: '2506.03233'
source_url: https://arxiv.org/abs/2506.03233
tags:
- identity
- systems
- system
- kinds
- artifacts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a metaphysics of artificial intelligence
  systems grounded in the concept of trustworthiness, proposing identity criteria
  for AI artifacts. The core method involves defining AI system kinds via techno-functions
  (technical capabilities) and trustworthiness profiles (collections of capabilities
  maintained over time), and formulating identity criteria for synchronic and diachronic
  identity.
---

# A Trustworthiness-based Metaphysics of Artificial Intelligence Systems

## Quick Facts
- arXiv ID: 2506.03233
- Source URL: https://arxiv.org/abs/2506.03233
- Authors: Andrea Ferrario
- Reference count: 40
- Primary result: Introduces trustworthiness-based identity criteria for AI systems, establishing that AI artifacts can be treated as real metaphysical kinds with well-defined synchronic and diachronic identity conditions.

## Executive Summary
This paper develops a metaphysical framework for identifying and counting artificial intelligence systems by grounding their identity in trustworthiness profiles rather than physical constitution or mere functional capabilities. The approach builds on Carrara and Vermaas' function+ framework, extending it to AI systems by defining identity through techno-functions (technical capabilities), trustworthiness profiles (collections of maintained capabilities), and trustworthiness levels. The framework demonstrates that AI systems can have well-posed identity and persistence conditions, challenging the traditional view that artifacts lack real metaphysical status. The approach is sensitive to socio-technical context, allowing identity to be relative to design and deployment environments.

## Method Summary
The paper employs a theoretical metaphysics approach, extending Carrara and Vermaas' function+ framework to characterize AI system kinds via three components: techno-function (technical capability specification), operational principle (encoded as trustworthiness contracts), and equivalence classes of normal configurations. Identity criteria are formally defined for both synchronic (same-time) and diachronic (across-time) identity using trustworthiness functions τ(t) that quantify capability levels. The method involves defining AI kinds through techno-function specifications, establishing trustworthiness profiles as collections of measurable contracts, and formulating τ functions to enable identity comparisons. The approach treats AI systems as real kinds comparable to natural entities by grounding identity in systematic, context-sensitive operational principles rather than physical constitution.

## Key Results
- AI systems can be treated as real metaphysical kinds with well-defined identity conditions, not merely deficient entities lacking persistence criteria.
- Formal identity criteria established: two AI systems are identical if and only if they have the same techno-function, equal trustworthiness profiles, and equal trustworthiness levels at compared times.
- The framework provides both synchronic (same-time) and diachronic (across-time) identity rules, enabling systematic counting and persistence tracking of AI systems through changes like retraining.
- Trustworthiness profiles capture socio-technical context sensitivity, allowing identity to be relative to design and deployment environments while maintaining formal rigor.

## Why This Works (Mechanism)

### Mechanism 1: Trustworthiness-Based Identity Criteria
- Claim: AI systems can be precisely identified and counted using formal identity criteria grounded in trustworthiness profiles.
- Mechanism: Identity is determined by three conditions: (1) belonging to the same kind (same techno-function), (2) having equal trustworthiness profiles (same operational principle), and (3) having equal trustworthiness levels τ(t) at compared times. This yields both synchronic (same-time) and diachronic (across-time) identity rules.
- Core assumption: Trustworthiness can be meaningfully quantified through contracts and measured consistently over time.
- Evidence anchors:
  - [abstract]: "The identity criteria of AI systems are determined by their trustworthiness profiles—the collection of capabilities that the systems must uphold over time throughout their artifact histories, and their effectiveness in maintaining these capabilities"
  - [section 5.2, Definition 5.1]: Formal synchronic and diachronic identity criteria with τ equality conditions
  - [corpus]: Weak—no direct corpus support; paper 105168 addresses trustworthiness assessment methods but not identity criteria
- Break condition: If trustworthiness contracts cannot be standardized or measured consistently across systems or time.

### Mechanism 2: Function+ Framework with Relativized Operational Principles
- Claim: AI system kinds are real metaphysical kinds, not deficient entities lacking identity conditions.
- Mechanism: Building on Carrara and Vermaas' function+ approach, AI system identity combines (1) techno-function (technical capability specification), (2) operational principle (encoded as trustworthiness contracts), and (3) equivalence classes of normal configurations. This allows physically different systems to be identical if they satisfy the same functional and operational requirements.
- Core assumption: Complex artifacts governed by "laws of action" can have real kinds comparable to natural entities.
- Evidence anchors:
  - [abstract]: "Building on Carrara and Vermaas' account of fine-grained artifact kinds"
  - [section 3.1.2]: "function+ promotes the realism of artifact kinds by combining the functions of these objects with their internal structures and engineering principles"
  - [corpus]: Paper 69729 discusses pragmatic AI personhood frameworks, suggesting broader philosophical engagement with AI categorization
- Break condition: If AI systems lack unifying operational principles due to unconstrained socio-technical variability.

### Mechanism 3: Socio-Technical Context Sensitivity
- Claim: AI identity and persistence depend on the normative context of design and deployment.
- Mechanism: Operational principles (trustworthiness requirements) are not universal but relative to social systems. Contracts encode context-specific normative expectations (e.g., fairness constraints, transparency requirements), making identity contingent on socio-cultural and regulatory environments.
- Core assumption: Normative expectations across social systems can be systematically captured and compared through contract specifications.
- Evidence anchors:
  - [abstract]: "identity and persistence of AI systems is sensitive to the socio-technical context of their design and utilization via their trustworthiness"
  - [section 4.2.2]: "operational principles are relative to the social system where these systems are designed and deployed and can be modified throughout the artifact history"
  - [corpus]: Paper 105168 bridges ethical principles and algorithmic trustworthiness methods, supporting socio-technical framing
- Break condition: If contracts cannot be meaningfully compared across different social systems with incommensurable norms.

## Foundational Learning

- Concept: Sortal terms and identity criteria
  - Why needed here: Identity is always relative to a kind; different kinds have different identity rules (Locke's "man" vs. "person" example).
  - Quick check question: Why can't we ask "Is x identical to y?" without specifying the kind?

- Concept: Synchronic vs. diachronic identity
  - Why needed here: The paper distinguishes identity at a time from persistence over time—fundamentally different questions with different criteria.
  - Quick check question: If a model is retrained and its accuracy changes, does it persist as the same system?

- Concept: Mereological essentialism vs. technological identity
  - Why needed here: The paper rejects physical-constitution identity (same parts = same object) in favor of functional+operational identity, enabling physically different systems to be identical.
  - Quick check question: Why would mereological essentialism make AI system identity impractical?

## Architecture Onboarding

- Component map:
  - Techno-function: Technical capability specification (e.g., "predict credit risk using financial data")
  - Trustworthiness profile: Collection of contracts defining operational principle (accuracy ≥90%, fairness constraints, reliability)
  - Trustworthiness function τ(t): Quantifies trustworthiness level at time t
  - Deployment time t₀: Reference point for identity comparisons
  - Retraining events: Partition points where τ may be discontinuous

- Critical path:
  1. Define kind φ (techno-function specification)
  2. Establish trustworthiness profile (contracts + evaluation methods)
  3. Formulate τ function consistently across compared systems
  4. Measure τ at relevant times
  5. Apply identity criteria (Definition 6.1)

- Design tradeoffs:
  - Contract granularity: Finer contracts narrow normal configurations but may be impractical to enforce
  - τ complexity: Equality conditions preserve transitivity; distance-based measures risk transitivity violations
  - Kind depth: Finer-grained kinds enable precise comparisons but reduce scope

- Failure signatures:
  - Transitivity violation: Using distance-based τ comparisons instead of equality
  - Persistence interruption: τ dropping breaks diachronic identity
  - Profile mismatch: Different contracts = non-identical even with equal τ

- First 3 experiments:
  1. Compare two deployments of the same model in different environments (cloud vs. on-premises); verify synchronic identity holds when τ values match despite different physical infrastructure.
  2. Track τ(t) through a retraining event; identify when persistence breaks and a new system emerges numerically.
  3. Compare systems with identical techno-functions but different fairness contracts (e.g., EU vs. US deployment); verify non-identity despite functional similarity.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can mathematically complex conditions for comparing trustworthiness levels be formulated that preserve transitivity while remaining conceptually grounded in the function+ framework?
- Basis in paper: [explicit] Page 10, Appendix.
- Why unresolved: The author notes that strict equality preserves transitivity, but more complex conditions (e.g., distance metrics) risk violating the triangular inequality or losing their connection to the artifact's operational principle.
- Evidence: A formal comparison metric for trustworthiness profiles that satisfies the properties of an equivalence relation without relying on strict identity.

### Open Question 2
- Question: What formal standards are required for specifying trustworthiness contracts to ensure that identity comparisons are valid across different social systems?
- Basis in paper: [explicit] Page 7, Section 5.1.
- Why unresolved: The framework assumes a "common level of formulation" for contracts to enable comparison, but the paper acknowledges "no universal standard" currently exists for how these contracts should be written.
- Evidence: A standardized ontology or language for AI trustworthiness contracts that allows for objective cross-system comparison.

### Open Question 3
- Question: How can the trustworthiness function $\tau_x$ be rigorously defined to aggregate heterogeneous capabilities (e.g., accuracy vs. fairness) into a single comparable level?
- Basis in paper: [inferred] Page 7, Section 5.1.
- Why unresolved: While the paper asserts $\tau_x$ is a function of individual capability levels, it does not specify the aggregation logic or weighting required to combine conflicting or incommensurable metrics into a unified level.
- Evidence: A formal functional definition of $\tau_x$ that demonstrates stability under small variations of constituent capabilities.

## Limitations
- The formalism assumes trustworthiness contracts can be consistently quantified and measured across different contexts, but practical standardization challenges remain unaddressed.
- The mechanism connecting socio-technical context to identity criteria relies on contracts as proxies for normative expectations, but the paper doesn't demonstrate how to handle incommensurable ethical frameworks across jurisdictions.
- The formalism uses exact equality for trustworthiness functions (τ_x(t) = τ_y(t)), which may be too restrictive for practical applications where minor variations exist due to measurement error or environmental factors.

## Confidence

- **High confidence**: The core metaphysical argument that AI systems can be treated as real kinds with well-defined identity conditions. The function+ framework extension is logically coherent and builds on established philosophical foundations.
- **Medium confidence**: The specific trustworthiness-based identity criteria are formally sound, but practical implementation faces significant challenges in contract standardization, measurement consistency, and handling socio-technical complexity.
- **Low confidence**: The claim that this approach provides a complete metaphysical foundation for epistemological, ethical, and legal discussions. While it offers a useful framework, bridging to practical legal and ethical applications requires substantial additional work.

## Next Checks
1. Test transitivity preservation: Apply the synchronic identity criterion to three systems where System A equals System B at time t₁, and System B equals System C at time t₂, then verify whether A equals C at the appropriate comparison time.
2. Implement case study: Select a real AI system (e.g., credit scoring model) and construct its techno-function, trustworthiness profile, and τ function. Track identity through a retraining event to identify persistence breaks.
3. Cross-jurisdictional comparison: Define identical techno-functions with different trustworthiness profiles (e.g., EU vs. US fairness requirements) and verify the formalism correctly identifies non-identity despite functional similarity.