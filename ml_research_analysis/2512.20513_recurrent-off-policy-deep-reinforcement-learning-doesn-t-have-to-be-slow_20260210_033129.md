---
ver: rpa2
title: Recurrent Off-Policy Deep Reinforcement Learning Doesn't Have to be Slow
arxiv_id: '2512.20513'
source_url: https://arxiv.org/abs/2512.20513
tags:
- rise
- hours
- learning
- context
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RISE enables recurrent models in off-policy RL without significant
  computational overhead by using non-learnable encodings for historical observations,
  requiring only the current observation to pass through expensive encoder layers.
  This architecture provides long-term context to recurrent networks without the computational
  burden of re-encoding entire observation sequences.
---

# Recurrent Off-Policy Deep Reinforcement Learning Doesn't Have to be Slow

## Quick Facts
- arXiv ID: 2512.20513
- Source URL: https://arxiv.org/abs/2512.20513
- Authors: Tyler Clark; Christine Evers; Jonathon Hare
- Reference count: 40
- Primary result: 35.6% human-normalized IQM performance improvement on Atari-57 with RISE + BTR

## Executive Summary
RISE (Recurrent Inference with Stored Embeddings) addresses the computational overhead of recurrent models in off-policy RL by using non-learnable encodings for historical observations. The architecture stores precomputed embeddings in the replay buffer, requiring only the current observation to pass through expensive encoder layers during training. When integrated with Beyond The Rainbow (BTR), RISE achieves state-of-the-art performance on Atari-57 while maintaining practical walltime, with consistent improvements across multiple domains including Procgen, Vizdoom, and Miniworld environments.

## Method Summary
RISE employs a dual-stream architecture where recent observations are processed through learnable encoders while long context windows are encoded via non-learnable pretrained models (e.g., ResNet18). These non-learnable encodings are precomputed and stored in the replay buffer, eliminating expensive recomputation during training. The method uses a sigmoid-gated multiplication to combine the learnable CNN features with upscaled LSTM outputs, creating an attention-like mechanism that modulates which features are emphasized based on historical context. RISE samples individual transitions with precomputed historical embeddings, avoiding the temporal correlation issues of trajectory-based methods while maintaining long temporal context.

## Key Results
- 35.6% human-normalized IQM performance improvement on Atari-57 benchmark
- Achieves state-of-the-art performance on a single desktop PC within a day of walltime
- Consistent improvements across multiple domains: Procgen, Vizdoom, and Miniworld
- Particularly effective in tasks requiring long-term credit assignment and handling partial observability

## Why This Works (Mechanism)

### Mechanism 1
Using non-learnable encodings for historical observations enables recurrent models in off-policy RL without significant computational overhead. RISE employs a dual-stream architecture where recent observations are processed through learnable encoders (as in standard approaches), while the long context window is encoded via a non-learnable encoding (e.g., pretrained ResNet18). These non-learnable encodings are precomputed and stored in the replay buffer, eliminating expensive recomputation during training.

Core assumption: Pretrained vision models trained on general datasets (e.g., ImageNet) can provide sufficiently useful representations for RL tasks, even when the visual domain differs significantly from training data.

### Mechanism 2
Multiplying learnable CNN features with upscaled LSTM outputs via sigmoid gating provides an effective attention-like combination mechanism. The LSTM output is projected via a linear layer to match the CNN encoder's dimensionality, passed through a sigmoid function, and multiplied element-wise with the CNN features. This allows the recurrent stream to modulate which CNN features are emphasized based on historical context.

Core assumption: A sigmoid-gated multiplication provides sufficiently flexible combination without requiring learned attention weights or complex fusion architectures.

### Mechanism 3
Transition-based learning with pre-stored embeddings eliminates temporal correlation issues inherent in trajectory-based methods while maintaining long temporal context. Unlike R2D2 which learns from correlated trajectory sequences, RISE samples individual transitions with precomputed historical embeddings (context length k=160). This decouples batch size from context length, enabling diverse sampling while preserving temporal information through the LSTM.

Core assumption: Storing non-learnable embeddings remains feasible within replay buffer memory constraints; temporal correlation in batches is detrimental to learning.

## Foundational Learning

- **Concept: Off-Policy vs. On-Policy Learning**
  - Why needed here: RISE addresses the unique computational challenge of off-policy methods—they reuse stored experiences but must recompute encodings for recurrent models, creating overhead that on-policy methods avoid.
  - Quick check question: Can you explain why a replay buffer creates a unique challenge for recurrent networks compared to feedforward networks?

- **Concept: LSTM Hidden State Staleness**
  - Why needed here: Understanding why stored hidden states become inaccurate as network parameters update is essential to appreciating RISE's precomputation strategy.
  - Quick check question: Why does "stored-state" become increasingly inaccurate during training, and what is "burn-in" as an alternative?

- **Concept: Pretrained Vision Encoders and Transfer Learning**
  - Why needed here: RISE relies on pretrained encoders providing useful features despite domain shift (ImageNet → Atari). Understanding when transfer works is critical for encoder selection.
  - Quick check question: What properties of visual features make them transferable, and what might cause a pretrained encoder to fail on a new task?

## Architecture Onboarding

- **Component map:**
```
Input: Current observation ot + Historical embeddings (precomputed)
│
├─ Stream 1 (Learnable): ot → CNN Encoder ϕ → Features (2304-dim for BTR)
│
├─ Stream 2 (Non-Learnable): 
│   Stored embeddings → LSTM ψ → Linear Ω → Upscaled (2304-dim) → Sigmoid
│
└─ Combination: Stream 1 × Sigmoid(Stream 2) → MLP → Q-values
```

- **Critical path:**
  1. Precompute embeddings for all observations using frozen pretrained encoder; store in replay buffer
  2. During training: sample transitions with precomputed embeddings, process current observation through learnable CNN, pass embedding sequence through LSTM, combine streams
  3. Gradient update affects only CNN, LSTM, and downstream layers (not pretrained encoder)

- **Design tradeoffs:**
  - Embedding size: 512-dim (ResNet18) vs. larger; paper found 512 sufficient
  - Context length: Longer improves credit assignment but increases walltime linearly; default 160
  - Combination method: Multiplication with sigmoid slightly outperforms alternatives
  - Encoder staleness: Surprisingly, even stale encodings from the main network performed well

- **Failure signatures:**
  1. Memory exhaustion if embedding size × buffer size × context length exceeds RAM
  2. Domain mismatch where pretrained encoder fails to capture task-relevant features
  3. LSTM instability in some environments (noted in Vizdoom/MiniWorld during training)

- **First 3 experiments:**
  1. Replicate BTR + RISE on Atari-5 with ResNet18, context=160; verify ~2× IQM improvement within 20-32 hours on RTX4090-class hardware
  2. Encoder ablation: test downsampling, EfficientNet-v2, and stale main-network encoder to validate robustness and identify domain-specific needs
  3. Context length scaling: run [20, 40, 80, 160] on Atari-10 to map walltime-performance tradeoff curve for your hardware

## Open Questions the Paper Calls Out

### Open Question 1
Can integrating more sophisticated pre-trained representations (e.g., foundation models or vision-language models) into RISE improve performance or generalization compared to the standard ResNet18 used in the study? The authors state, "RISE naturally opens up the door for future work regarding the implementation of its non-learnable encoding... work combining RISE with existing research on pre-trained representations may hold further benefit."

### Open Question 2
Does RISE maintain its computational efficiency and performance improvements when applied to non-image-based domains with expensive encoders, such as text-based RL? The authors explicitly suggest, "RISE is not limited to only images, but rather any task with expensive early encoder layers. For example, RISE could be used with transformers for text-based tasks..."

### Open Question 3
Can the non-learnable encoder in RISE be adapted or fine-tuned during training to improve feature extraction without reintroducing significant computational overhead? The paper notes the trade-off of the current design: "the use of a fixed, pre-trained encoder may limit the model's ability to extract useful features in some environments... in exchange for less adaptability."

## Limitations
- Domain transfer capability of frozen pretrained encoders remains under-examined, with minimal analysis of feature quality or domain adaptation
- Memory constraints may limit embedding size or buffer capacity in very long-horizon tasks or larger state spaces
- Claims about avoiding temporal correlation in transitions versus trajectories lack direct ablation evidence

## Confidence

**High Confidence:** The computational efficiency claim is well-supported by the architecture description and empirical timing data.

**Medium Confidence:** The performance improvements across multiple benchmarks are robust, but the specific mechanisms driving success in different domains are not fully analyzed.

**Low Confidence:** The claims about avoiding temporal correlation in transitions versus trajectories lack direct ablation evidence.

## Next Checks

1. **Encoder Domain Transfer Analysis:** Run RISE with three different encoder variants (ImageNet ResNet18, EfficientNet-v2, and a domain-specific encoder trained on Atari) to quantify the impact of domain transfer on performance across different game types.

2. **Memory-Performance Tradeoff:** Systematically vary embedding dimensionality (256, 512, 1024) and context length (40, 80, 160) while measuring both walltime and performance to identify the optimal point for different hardware constraints.

3. **Temporal Correlation Ablation:** Implement a variant of RISE that uses trajectory-based sampling (like R2D2) with precomputed embeddings to isolate whether the performance gains stem from avoiding temporal correlation or from the RISE architecture itself.