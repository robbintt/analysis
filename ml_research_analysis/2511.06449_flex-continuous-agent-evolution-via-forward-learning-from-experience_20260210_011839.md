---
ver: rpa2
title: 'FLEX: Continuous Agent Evolution via Forward Learning from Experience'
arxiv_id: '2511.06449'
source_url: https://arxiv.org/abs/2511.06449
tags:
- experience
- arxiv
- learning
- library
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes FLEX, a gradient-free learning paradigm enabling
  LLM agents to evolve continuously through accumulated experience rather than parameter
  tuning. Instead of backpropagation, FLEX constructs an evolving experience library
  via forward exploration and reflection, organizing knowledge hierarchically for
  reuse.
---

# FLEX: Continuous Agent Evolution via Forward Learning from Experience

## Quick Facts
- arXiv ID: 2511.06449
- Source URL: https://arxiv.org/abs/2511.06449
- Reference count: 40
- Primary result: Gradient-free LLM agent evolution via experience libraries achieves up to 23% accuracy gains on AIME25, 10% on USPTO50k, and 14% Spearman correlation improvement on ProteinGym

## Executive Summary
FLEX introduces a gradient-free learning paradigm enabling large language model (LLM) agents to evolve continuously through accumulated experience rather than traditional parameter tuning. Instead of backpropagation, FLEX constructs an evolving experience library via forward exploration and reflection, organizing knowledge hierarchically for reuse. Experiments demonstrate substantial performance improvements across mathematical reasoning, chemical retrosynthesis, and protein fitness prediction tasks, with the method also revealing a scaling law for experience accumulation and cross-agent knowledge inheritance capabilities.

## Method Summary
FLEX operates through a forward learning mechanism that builds experience libraries without gradient updates. The system uses exploration to generate new experiences and reflection to distill insights, organizing them hierarchically from LLM2 (highest) down to LLM0 (lowest). When encountering new tasks, agents query these libraries for relevant experiences rather than adjusting weights. The framework enables continuous evolution by accumulating experiences over time, with performance improvements following a predictable scaling relationship. Cross-agent knowledge transfer is achieved by sharing experience libraries between different models, allowing knowledge from one agent to benefit others without retraining.

## Key Results
- 23% accuracy improvement on AIME25 mathematical reasoning benchmark
- 10% performance gain on USPTO50k chemical retrosynthesis tasks
- 14% Spearman correlation improvement on ProteinGym protein fitness prediction
- Demonstrated scaling law: performance improves predictably with accumulated experience
- Cross-agent experience inheritance successfully transfers knowledge between different LLM agents

## Why This Works (Mechanism)
The forward learning paradigm succeeds by shifting from weight-based adaptation to knowledge-based adaptation. Instead of backpropagation, FLEX accumulates structured experiences that capture successful reasoning patterns. The hierarchical organization enables efficient retrieval—higher-level experiences provide abstract strategies while lower-level ones offer concrete solutions. This mirrors human learning where accumulated experience becomes increasingly organized and transferable. The absence of gradient updates avoids catastrophic forgetting and enables continuous evolution without capacity constraints.

## Foundational Learning
**Experience Library Construction** - Why needed: Traditional fine-tuning overwrites knowledge and requires gradient computation; quick check: verify library grows systematically without performance degradation
**Hierarchical Knowledge Organization** - Why needed: Flat experience storage becomes inefficient at scale; quick check: measure retrieval efficiency vs library size
**Forward Exploration-Reflection Cycle** - Why needed: Generates diverse, high-quality experiences without gradient feedback; quick check: track experience diversity metrics
**Cross-Agent Transfer** - Why needed: Enables knowledge sharing without retraining; quick check: validate transferred experiences improve target agent performance
**Scaling Law Discovery** - Why needed: Provides predictability for resource allocation; quick check: confirm performance follows predicted scaling curve

## Architecture Onboarding

**Component Map**: Exploration Module → Reflection Module → Hierarchical Library → Query Engine → Agent Interface

**Critical Path**: When agent encounters task → Query Engine searches hierarchical library → Relevant experiences retrieved → Agent applies retrieved knowledge → Performance measured → New experiences generated through Exploration → Reflection distills insights → Library updated

**Design Tradeoffs**: Memory vs Performance (larger libraries improve accuracy but increase retrieval time), Granularity vs Efficiency (finer-grained experiences are more precise but slower to search), Static vs Dynamic Organization (fixed hierarchies are faster but less adaptable)

**Failure Signatures**: Performance plateaus despite library growth (experience saturation), Retrieval becomes bottleneck (inefficient indexing), Cross-agent transfer fails (incompatible experience representations), Exploration produces low-quality experiences (poor reflection mechanisms)

**3 First Experiments**:
1. Verify basic library construction by measuring performance improvement on simple tasks as library grows
2. Test hierarchical organization by comparing retrieval speed and accuracy against flat storage
3. Validate cross-agent transfer by sharing libraries between differently-initialized models

## Open Questions the Paper Calls Out
None

## Limitations
- Experimental scope limited to three narrow domains (mathematical reasoning, chemical synthesis, protein prediction)
- Computational overhead and memory scaling for large experience libraries not fully characterized
- Cross-agent inheritance validation lacks systematic testing across diverse model architectures
- Hierarchical organization implementation details remain somewhat abstract

## Confidence

**Major Claim Confidence:**
- Experience library effectiveness: Medium (significant gains but domain-constrained)
- Hierarchical organization benefits: Medium (theoretical framework needs more empirical validation)
- Cross-agent inheritance: Low (promising but minimally validated)
- Forward learning paradigm: High (core concept well-demonstrated within tested domains)

## Next Checks

1. Evaluate FLEX performance on multi-domain agents requiring diverse reasoning capabilities, testing generalization beyond the three current domains
2. Measure computational overhead and memory scaling as experience libraries grow beyond tested size ranges
3. Systematically test cross-agent inheritance across different model architectures (not just different parameter scales of the same model) to validate true transferability