---
ver: rpa2
title: 'Mechanistic Interpretability of GPT-2: Lexical and Contextual Layers in Sentiment
  Analysis'
arxiv_id: '2512.06681'
source_url: https://arxiv.org/abs/2512.06681
tags:
- sentiment
- layers
- contextual
- processing
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a mechanistic interpretability study of GPT-2
  that causally examines how sentiment information is processed across its transformer
  layers. Using systematic activation patching across all 12 layers, we test the hypothesized
  two-stage sentiment architecture comprising early lexical detection and mid-layer
  contextual integration.
---

# Mechanistic Interpretability of GPT-2: Lexical and Contextual Layers in Sentiment Analysis

## Quick Facts
- arXiv ID: 2512.06681
- Source URL: https://arxiv.org/abs/2512.06681
- Authors: Amartya Hatua
- Reference count: 4
- This paper causally examines GPT-2's sentiment processing architecture through systematic activation patching across all 12 layers.

## Executive Summary
This mechanistic interpretability study investigates how GPT-2 processes sentiment through systematic activation patching experiments across all 12 transformer layers. The research tests a hypothesized two-stage architecture where early layers detect lexical sentiment and middle layers integrate contextual modifications. Results confirm early layers (0-3) as lexical sentiment detectors with position-specific, context-independent polarity encoding. However, all three contextual integration hypotheses are falsified—contextual phenomena like negation and sarcasm are integrated primarily in late layers (8-11) through a unified, non-modular mechanism rather than specialized middle-layer modules.

## Method Summary
The study employs activation patching methodology across all 12 layers of GPT-2 to test causal contributions to sentiment classification. Experiments systematically replace activations from sentiment-containing sentences with activations from non-sentiment sentences at different layer positions. The research evaluates 15 contextual phenomena including negation, sarcasm, intensifiers, and domain shifts. Layer importance is quantified through specificity scores measuring the difference between patching at sentiment positions versus non-sentiment positions. Statistical significance is assessed through repeated trials across diverse sentence contexts.

## Key Results
- Early layers (0-3) act as lexical sentiment detectors with position-specific, context-independent polarity encoding
- All three contextual integration hypotheses (middle layer concentration, phenomenon specificity, distributed processing) are falsified
- Contextual phenomena integrate primarily in late layers (8-11) through a unified, non-modular mechanism with 87% sharing identical top-3 contributing layers

## Why This Works (Mechanism)

### Mechanism 1: Early Layer Lexical Detection
- Claim: Layers 0-3 encode position-specific, context-independent lexical sentiment signals
- Mechanism: Activation patching at sentiment word positions produces significantly stronger effects at early layers than non-sentiment positions (mean specificity score 0.147, p < 0.001)
- Core assumption: Lexical sentiment features are extracted before contextual modulation begins
- Evidence anchors:
  - [abstract] "early layers (0-3) act as lexical sentiment detectors, encoding stable, position specific polarity signals"
  - [section 5.1.4] "results support all four hypotheses: lexical sensitivity, early layers show strongest sensitivity, effects are position specific, detection is context independent"
  - [corpus] Related work confirms early-layer feature extraction patterns across transformer architectures
- Break condition: If sentiment word substitutions produce equal/weaker effects at early layers vs. middle/late layers

### Mechanism 2: Late-Layer Unified Contextual Integration Hub
- Claim: Contextual phenomena route through a shared late-layer hub (L8-L11) rather than specialized modules
- Mechanism: 87% of tested phenomena share identical top-3 contributing layers [L11, L10, L9]
- Core assumption: GPT-2 uses phenomenon-agnostic semantic integration rather than modularity
- Evidence anchors:
  - [abstract] "contextual phenomena such as negation, sarcasm, domain shifts etc. are integrated primarily in late layers (8-11) through a unified, non-modular mechanism"
  - [section 5.2.2] "8 phenomena (53%) peak at the exact same layer L11... convergence encompasses semantically diverse contextual modifications"
- Break condition: If different contextual types show distinct, non-overlapping layer patterns

### Mechanism 3: Bimodal Processing with Middle-Layer Gap
- Claim: Sentiment processing exhibits bimodal distribution with minimal middle-layer (L4-L7) contribution
- Mechanism: 0 of 15 phenomena peak in predicted middle layers; 57% peak at L11, 43% at early layers (L0-L2)
- Core assumption: Middle layers serve transitional rather than specialized semantic functions for sentiment
- Evidence anchors:
  - [abstract] "all three contextual integration hypotheses: Middle Layer Concentration, Phenomenon Specificity, and Distributed Processing are falsified"
  - [section 5.2.1] "bimodal distribution where phenomena cluster in either early L0-L3 or late layers (8-11), with no phenomena peaking in predicted middle range L4-L7"
- Break condition: If middle layers show significant peaks for any contextual phenomena in replication

## Foundational Learning

- **Concept: Activation Patching (Causal Intervention)**
  - Why needed here: Distinguishes what information exists in representations vs. what the model actually uses
  - Quick check question: Can you explain why replacing activations from a "positive" sentence into a "negative" sentence at a specific layer tests causal contribution?

- **Concept: Transformer Layer Specialization Hypothesis**
  - Why needed here: Provides the theoretical framework being tested—early=lexical, middle=syntax, late=semantics
  - Quick check question: What three-stage processing pattern did Jawahar et al. (2019) propose, and how does this paper's findings differ?

- **Concept: Contextual Integration in Sentiment**
  - Why needed here: Sentiment requires dynamic reasoning (negation flips polarity, sarcasm inverts meaning) beyond lexical lookup
  - Quick check question: Why can't a purely lexical model correctly classify "The movie wasn't bad at all"?

## Architecture Onboarding

- **Component map:** L0-L3 (lexical detection) → L4-L7 (transition zone) → L8-L11 (unified contextual hub) → L11 (peak integration)
- **Critical path:** Sentiment word tokens → early-layer polarity encoding → late-layer contextual modification → output distribution
- **Design tradeoffs:** Unified late-layer hub (simple, generalizable) vs. phenomenon-specific modules (interpretable, potentially more robust)
- **Failure signatures:**
  - If middle layers (L4-L7) show significant peaks in your data, the bimodal pattern is not replicating
  - If different contextual types show divergent layer patterns, the unified hub hypothesis fails
  - If early-layer patching doesn't localize to sentiment word positions, lexical detection isn't position-specific
- **First 3 experiments:**
  1. Replicate lexical sensitivity test: Patch activations at sentiment words vs. non-sentiment words across all 12 layers; confirm early-layer concentration and position specificity
  2. Test one contextual phenomenon (e.g., simple negation): Patch across all layers to identify peak contribution; expect late-layer (L11) peak
  3. Compare layer patterns across two diverse phenomena (e.g., negation vs. sarcasm): Test whether top-3 layers converge to [L11, L10, L9] pattern or diverge

## Open Questions the Paper Calls Out
None

## Limitations
- The activation patching methodology may oversimplify complex interaction effects between layers
- Binary classification task limits generalizability to more nuanced sentiment analysis
- Findings are based on GPT-2 specifically and may not transfer to other transformer architectures

## Confidence

- **High confidence:** Early-layer lexical detection mechanism (L0-L3 position-specific sentiment encoding) - supported by strong statistical significance and low variability across contexts
- **Medium confidence:** Late-layer unified contextual integration hub (L8-L11) - pattern is robust across multiple phenomena but relies on specific patching methodology
- **Low confidence:** Middle-layer gap hypothesis (L4-L7 minimal contribution) - limited to this model/task combination with no cross-validation on alternative architectures

## Next Checks
1. Test replication on different transformer architectures (BERT, RoBERTa) to assess whether the bimodal pattern generalizes beyond GPT-2
2. Implement ablation studies where entire middle layers (L4-L7) are removed to measure functional necessity rather than just contribution strength
3. Extend analysis to multi-class sentiment classification to verify that early-layer lexical detection remains position-specific when polarity distinctions are more nuanced