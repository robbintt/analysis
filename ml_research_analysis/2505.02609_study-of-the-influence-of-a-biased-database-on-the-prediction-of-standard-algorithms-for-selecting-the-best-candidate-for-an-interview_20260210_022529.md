---
ver: rpa2
title: Study of the influence of a biased database on the prediction of standard algorithms
  for selecting the best candidate for an interview
arxiv_id: '2505.02609'
source_url: https://arxiv.org/abs/2505.02609
tags:
- threshold
- biased
- figure
- each
- variables
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates the impact of biased training data on the
  performance of standard machine learning algorithms in recruitment. Five algorithms
  (logistic regression, AIC logistic regression, L-nearest neighbors, multilayer perceptron,
  SVM) were trained on simulated recruitment data with varying levels of discrimination
  bias (binary and continuous thresholds) and self-censorship effects.
---

# Study of the influence of a biased database on the prediction of standard algorithms for selecting the best candidate for an interview

## Quick Facts
- arXiv ID: 2505.02609
- Source URL: https://arxiv.org/abs/2505.02609
- Reference count: 7
- Algorithms trained on biased datasets perform significantly worse at identifying best candidates, with accuracy dropping from approximately 97% to as low as 55% in severe bias conditions

## Executive Summary
This study systematically evaluates how biased training data affects the performance of standard machine learning algorithms in recruitment contexts. Five common algorithms (logistic regression, AIC logistic regression, L-nearest neighbors, multilayer perceptron, SVM) were tested on simulated recruitment data with varying levels of discrimination bias. The research demonstrates that algorithms trained on biased datasets show significantly reduced ability to identify the best candidates compared to those trained on unbiased data. Anonymization of candidate data only improves predictions when discrimination variables are weakly correlated with other variables, and sophisticated algorithms do not outperform simpler transparent methods in mitigating bias.

## Method Summary
The study employed simulated recruitment data with controlled bias parameters to evaluate five standard machine learning algorithms. Researchers created datasets with varying levels of discrimination bias (binary and continuous thresholds) and self-censorship effects. The algorithms were trained on these biased datasets and compared against performance on unbiased data. Key performance metrics included accuracy in identifying the best candidates, with evaluation across different bias intensities and anonymization strategies.

## Key Results
- Algorithm accuracy drops from ~97% to as low as 55% when trained on severely biased data
- L-nearest neighbors uniquely showed improved performance when trained on biased data
- Anonymization only improves predictions when discrimination variables are weakly correlated with other variables
- Sophisticated algorithms do not outperform simpler transparent methods in mitigating bias

## Why This Works (Mechanism)
The effectiveness of recruitment algorithms depends critically on the quality and representativeness of training data. When historical data contains biases (whether from discrimination or self-censorship), algorithms learn and perpetuate these patterns rather than identifying true candidate merit. The correlation structure between discrimination variables and other candidate attributes determines whether anonymization can effectively remove bias signals. Algorithms that rely heavily on complex pattern recognition may amplify subtle biases, while simpler methods may be more robust to data imperfections.

## Foundational Learning
- Bias propagation in machine learning: Why needed - Understanding how historical discrimination becomes embedded in algorithmic decision-making. Quick check - Examine training data distributions for protected attribute correlations.
- Correlation structure analysis: Why needed - Determines whether anonymization can effectively remove bias signals. Quick check - Compute correlation matrices between protected and non-protected attributes.
- Algorithm complexity vs. bias robustness: Why needed - Sophisticated methods may amplify subtle biases. Quick check - Compare performance across algorithm families with different complexity levels.

## Architecture Onboarding

Component map:
Simulated Data Generator -> Bias Injection Module -> Algorithm Training Pipeline -> Performance Evaluation Framework

Critical path:
Data generation → Bias parameter specification → Algorithm training → Performance measurement → Statistical analysis

Design tradeoffs:
- Simulation vs. real data: Simulation allows controlled bias manipulation but may not capture real-world complexity
- Algorithm selection: Standard methods are interpretable but may miss advanced fairness techniques
- Bias quantification: Binary vs. continuous thresholds affect generalizability of findings

Failure signatures:
- High accuracy on biased data but poor performance on unbiased test sets
- Performance degradation correlating with bias intensity
- Anonymization effectiveness varying with correlation structure

First experiments:
1. Test algorithm performance on unbiased data to establish baseline accuracy
2. Gradually increase bias intensity and measure performance degradation
3. Evaluate anonymization effectiveness at different correlation thresholds

## Open Questions the Paper Calls Out
None

## Limitations
- Simulation-based approach may not fully capture real-world recruitment complexity
- Focus on specific discrimination variables may limit generalizability
- Performance metrics may not capture all aspects of algorithmic fairness

## Confidence

High confidence in the core finding that biased training data significantly reduces algorithmic performance in candidate selection
Medium confidence in the comparative analysis of different algorithms' resistance to bias
Medium confidence in the effectiveness of anonymization strategies
Low confidence in the generalizability to all recruitment contexts

## Next Checks

1. Validate findings using real-world recruitment data from multiple organizations to assess external validity
2. Test additional fairness-aware machine learning algorithms and techniques beyond standard methods
3. Conduct longitudinal studies to examine how algorithmic bias affects long-term recruitment outcomes and organizational diversity