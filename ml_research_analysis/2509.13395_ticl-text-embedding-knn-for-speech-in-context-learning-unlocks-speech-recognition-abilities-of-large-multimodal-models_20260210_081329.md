---
ver: rpa2
title: 'TICL: Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition
  Abilities of Large Multimodal Models'
arxiv_id: '2509.13395'
source_url: https://arxiv.org/abs/2509.13395
tags:
- speech
- in-context
- sicl
- ticl
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of selecting effective in-context
  examples for Speech In-Context Learning (SICL) to improve automatic speech recognition
  (ASR) performance. The proposed method, TICL (Text-Embedding KNN for SICL), uses
  semantic retrieval via sentence embeddings to select high-quality in-context examples
  without fine-tuning.
---

# TICL: Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models

## Quick Facts
- **arXiv ID:** 2509.13395
- **Source URL:** https://arxiv.org/abs/2509.13395
- **Reference count:** 0
- **Primary result:** TICL achieves up to 84.7% relative WER reduction across three ASR tasks

## Executive Summary
This work introduces TICL (Text-Embedding KNN for SICL), a novel approach to Speech In-Context Learning that leverages semantic retrieval via sentence embeddings to select high-quality in-context examples for automatic speech recognition. By avoiding fine-tuning while achieving significant performance improvements, TICL demonstrates that carefully selected in-context examples can dramatically enhance the ASR capabilities of large multimodal models. The method shows robust performance across different speech domains including accented English, multilingual speech, and children's speech.

## Method Summary
TICL addresses the challenge of selecting effective in-context examples for Speech In-Context Learning by using text-embedding KNN (k-nearest neighbors) retrieval. The approach involves extracting semantic embeddings from speech transcriptions to identify the most relevant examples for a given target utterance. This semantic retrieval strategy operates without requiring model fine-tuning, making it computationally efficient while maintaining strong performance. The method demonstrates effectiveness across multiple challenging ASR tasks and shows robustness to different large multimodal models and retrieval methods, with optimal performance typically achieved using around four in-context examples.

## Key Results
- Achieved up to 84.7% relative word error rate (WER) reduction compared to zero-shot performance
- Demonstrated consistent improvements across three challenging ASR tasks: accented English, multilingual speech, and children's speech
- Showed robustness across different large multimodal models and retrieval methods
- Optimal performance achieved with approximately four in-context examples

## Why This Works (Mechanism)
The effectiveness of TICL stems from its ability to semantically match in-context examples to target utterances based on their textual content. By leveraging sentence embeddings, the method identifies examples that share similar linguistic patterns, vocabulary, and semantic content with the target speech, providing the model with contextually relevant information. This semantic alignment helps the large multimodal model better understand the specific characteristics of the target utterance, leading to improved recognition accuracy without requiring parameter updates.

## Foundational Learning
- **Sentence Embeddings**: Dense vector representations of text that capture semantic meaning - needed to quantify similarity between speech transcriptions for retrieval
- **k-Nearest Neighbors (KNN)**: Instance-based learning algorithm that finds the most similar examples - needed to select relevant in-context examples based on embedding similarity
- **In-Context Learning**: Prompt-based learning paradigm where models learn from demonstrations in the prompt - needed to understand how example selection impacts ASR performance
- **Speech In-Context Learning (SICL)**: Application of in-context learning to speech tasks - needed to contextualize the problem domain and challenges
- **Word Error Rate (WER)**: Standard metric for ASR evaluation measuring edit distance between reference and hypothesis - needed to quantify performance improvements

## Architecture Onboarding

**Component Map**: Speech Input -> Sentence Embedding Model -> KNN Retrieval -> Prompt Construction -> Large Multimodal Model -> ASR Output

**Critical Path**: The most critical components are the sentence embedding model quality and the KNN retrieval strategy, as these directly determine which examples are selected. The large multimodal model's ability to leverage the retrieved examples is also crucial for final performance.

**Design Tradeoffs**: The method trades potential fine-tuning benefits for computational efficiency and flexibility. Using text embeddings rather than audio features simplifies the retrieval process but may miss some acoustic similarities. The choice of k (number of examples) represents a balance between providing sufficient context and overwhelming the model with information.

**Failure Signatures**: Poor performance may manifest when the sentence embedding model fails to capture domain-specific terminology, when the target utterance contains significant out-of-domain content, or when the optimal number of examples exceeds the model's context window capacity.

**First Experiments**:
1. Test TICL performance with varying numbers of in-context examples (1-10) to identify optimal k value
2. Compare TICL with random example selection across different ASR tasks to validate semantic retrieval benefits
3. Evaluate TICL performance using different sentence embedding models to assess embedding quality impact

## Open Questions the Paper Calls Out
None specified in the source material.

## Limitations
- Performance optimization appears sensitive to the number of in-context examples, which may vary by task characteristics
- Evaluation limited to three specific ASR tasks, raising questions about generalization to other speech domains or languages
- Comparative analysis with existing retrieval methods could be more comprehensive, particularly regarding computational efficiency
- Does not explore potential benefits of hybrid approaches combining retrieval with light parameter adaptation

## Confidence

**Major Claim Confidence Assessment:**
- TICL achieves state-of-the-art performance for speech in-context learning: High confidence
- Semantic retrieval via text embeddings is superior to random selection: High confidence
- Four in-context examples represent an optimal balance: Medium confidence (task-dependent)
- TICL generalizes across different large multimodal models: Medium confidence

## Next Checks
1. Evaluate TICL performance on additional speech domains (e.g., telephony speech, spontaneous conversation) to assess generalization beyond the current task set.
2. Conduct ablation studies comparing TICL with fine-tuned retrieval models to quantify the trade-off between performance and computational overhead.
3. Test TICL's robustness to varying sentence embedding quality by comparing different embedding models and their impact on ASR performance.