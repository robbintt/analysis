---
ver: rpa2
title: 'HARP: Hallucination Detection via Reasoning Subspace Projection'
arxiv_id: '2509.11536'
source_url: https://arxiv.org/abs/2509.11536
tags:
- reasoning
- subspace
- hallucination
- semantic
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes HARP, a hallucination detection method for
  large language models (LLMs) that focuses on reasoning subspace projection. The
  key idea is that LLM hidden states can be decomposed into semantic and reasoning
  subspaces, with the reasoning subspace capturing the model's internal reasoning
  process.
---

# HARP: Hallucination Detection via Reasoning Subspace Projection

## Quick Facts
- arXiv ID: 2509.11536
- Source URL: https://arxiv.org/abs/2509.11536
- Reference count: 40
- Key outcome: Achieves 92.8% AUROC on TriviaQA, outperforming previous best by 7.5%

## Executive Summary
HARP introduces a novel hallucination detection method for LLMs by decomposing hidden states into semantic and reasoning subspaces. The approach leverages SVD decomposition of Unembedding layer parameters to identify basis vectors for these subspaces, then projects hidden states onto the reasoning subspace basis. This projection reduces feature dimensionality to approximately 5% of the original while filtering out noise, resulting in enhanced robustness. Experiments demonstrate state-of-the-art performance with 92.8% AUROC on TriviaQA and show strong robustness across different models and datasets.

## Method Summary
The HARP method operates by first performing SVD on the Unembedding layer parameters of LLMs to identify basis vectors for semantic and reasoning subspaces. Hidden states are then projected onto the reasoning subspace basis, effectively filtering out semantic noise while retaining reasoning-related information. This dimensionality reduction to approximately 5% of the original feature space enhances robustness by focusing on the model's internal reasoning process rather than surface-level semantic content. The resulting projected features are used for hallucination detection, achieving superior performance compared to existing methods while demonstrating strong generalization across different model architectures and datasets.

## Key Results
- Achieves 92.8% AUROC on TriviaQA, outperforming previous best method by 7.5%
- Reduces feature dimensionality to approximately 5% while maintaining detection effectiveness
- Demonstrates strong robustness and generalization across GPT-3.5, GPT-4, and Gemini Pro models

## Why This Works (Mechanism)
The method exploits the observation that LLM hidden states contain both semantic and reasoning components that can be mathematically separated. By projecting onto the reasoning subspace, HARP filters out semantic noise that often obscures the model's actual reasoning process. The SVD-based decomposition of Unembedding layer parameters provides a computationally efficient way to identify the relevant basis vectors. This focused representation captures the model's internal reasoning state more accurately than raw hidden states, making hallucination detection more robust to variations in semantic expression while remaining sensitive to reasoning errors.

## Foundational Learning

**SVD decomposition**: Singular Value Decomposition separates matrix parameters into orthogonal components representing different information subspaces. Why needed: Enables mathematical separation of semantic and reasoning components. Quick check: Verify that the top singular vectors capture reasoning-relevant patterns.

**Unembedding layer analysis**: The Unembedding layer transforms hidden states back to token space and contains rich information about model behavior. Why needed: Provides accessible parameters for subspace decomposition without modifying model internals. Quick check: Confirm that Unembedding parameters correlate with reasoning vs semantic content.

**Subspace projection**: Projecting vectors onto specific basis vectors extracts relevant features while reducing dimensionality. Why needed: Filters noise and focuses detection on reasoning-relevant signals. Quick check: Measure AUROC changes with different projection dimensions.

## Architecture Onboarding

**Component map**: Input tokens -> Hidden states -> SVD on Unembedding -> Reasoning subspace basis -> Projection -> Feature extraction -> Classifier -> Hallucination score

**Critical path**: Token embedding → Hidden state generation → SVD decomposition → Reasoning subspace projection → Feature extraction → Detection

**Design tradeoffs**: The method trades computational overhead of SVD computation against improved detection accuracy and robustness. Using Unembedding layer parameters provides a balance between accessibility and information richness, though alternative decomposition methods might offer different performance characteristics.

**Failure signatures**: Poor performance may occur when reasoning and semantic subspaces are not well-separated, when models lack clear reasoning patterns, or when synthetic hallucination injection doesn't match real-world error patterns. Over-aggressive dimensionality reduction could lose critical reasoning information.

**3 first experiments**:
1. Test different SVD rank thresholds to find optimal balance between dimensionality reduction and information retention
2. Compare performance using different layer parameters (e.g., attention matrices vs Unembedding) for subspace decomposition
3. Evaluate sensitivity to synthetic vs naturally occurring hallucinations on real-world datasets

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions in the provided content.

## Limitations
- Performance metrics rely heavily on synthetic datasets with artificial hallucination injection, potentially not reflecting real-world complexity
- Theoretical foundation lacks rigorous mathematical proof for why SVD decomposition reliably separates semantic from reasoning components
- Experimental validation is limited to three models and two datasets, with no comprehensive ablation studies

## Confidence

| Claim | Confidence |
|-------|------------|
| Performance claims (AUROC scores) | Medium - Strong on controlled benchmarks but limited real-world validation |
| Theoretical framework | Low-Medium - Intuitive but lacks rigorous mathematical grounding |
| Robustness and generalization | Medium - Promising but needs broader testing across architectures and domains |

## Next Checks

1. Conduct extensive ablation studies varying SVD rank thresholds and projection dimensions to establish optimal parameter ranges and sensitivity analysis

2. Validate performance on real-world datasets with naturally occurring hallucinations rather than synthetic injection to assess practical applicability

3. Test across diverse model families including open-source models (Llama, Mistral) and smaller models to evaluate scalability and robustness to architectural differences