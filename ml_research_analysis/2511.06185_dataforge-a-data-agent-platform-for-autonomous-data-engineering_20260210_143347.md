---
ver: rpa2
title: 'Dataforge: A Data Agent Platform for Autonomous Data Engineering'
arxiv_id: '2511.06185'
source_url: https://arxiv.org/abs/2511.06185
tags:
- data
- agent
- feature
- routing
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Dataforge is an autonomous data agent that performs end-to-end
  tabular data engineering without human supervision. It uses hierarchical routing
  to identify tasks and select actions, then applies grounded validation and dual
  feedback loops to ensure safety and optimize performance.
---

# Dataforge: A Data Agent Platform for Autonomous Data Engineering

## Quick Facts
- arXiv ID: 2511.06185
- Source URL: https://arxiv.org/abs/2511.06185
- Reference count: 9
- Primary result: Autonomous tabular data engineering achieving top predictive performance with zero training cost

## Executive Summary
Dataforge is an autonomous data agent that performs end-to-end tabular data engineering without human supervision. It uses hierarchical routing to identify tasks and select actions, then applies grounded validation and dual feedback loops to ensure safety and optimize performance. The system integrates LLM reasoning with structured control, supporting cleaning, feature transformation, and selection across classification, regression, and clustering tasks. Evaluations across nine datasets show it achieves top predictive performance (e.g., F1-score up to 97.14%) with zero training cost and no invalid operations. In a heart-disease detection case, it reduced features from 44 to 20 while improving accuracy from 0.772 to 0.840, demonstrating its utility for efficient, reliable, and interpretable data preparation.

## Method Summary
Dataforge implements a six-stage pipeline for autonomous tabular data engineering. It begins with data cleaning in three modes (light, aggressive, time-series), followed by rule-based task-level routing to classify the problem type. An LLM-based action-level router then proposes feature operations, which undergo grounding validation to ensure safety before execution. Dual feedback loops monitor action validity and performance metrics, updating configurations only when improvements occur. Experience replay accumulates successful patterns as benchmark data. The hierarchical routing architecture constrains the LLM's action space, reducing hallucination risk while maintaining flexibility for diverse datasets.

## Key Results
- Achieved F1-score up to 97.14% and AUC up to 0.9729 across nine datasets
- Reduced heart disease dataset from 44 to 20 features while improving accuracy from 0.772 to 0.840
- Completed workflows in 3.9 seconds on average with only two LLM calls, versus RL baselines requiring 1,400+ seconds of training

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Routing Reduces Decision Space Complexity
- A two-level routing architecture (rule-based task identification → LLM-based action selection) improves both speed and reliability compared to monolithic LLM planning. Task-level routing uses deterministic heuristics on schema metadata to classify the problem, constraining the LLM planner's action space. This reduces hallucination risk and accelerates processing.

### Mechanism 2: Dual Feedback Loops Enable Autonomous Self-Correction
- Nested feedback loops (action validation + performance optimization) allow the system to converge on valid, high-performing configurations without human intervention. The inner loop performs pre-execution grounding and rejects invalid actions, while the outer loop evaluates task-specific metrics and triggers re-planning when performance doesn't improve.

### Mechanism 3: Zero-Shot LLM Reasoning Eliminates Training Overhead
- LLM-based action planning achieves competitive performance without task-specific training by leveraging pre-trained domain knowledge and iterative feedback. The LLM reasons over dataset metadata and past experiences, with validation and performance loops pruning failures and reinforcing successful trajectories.

## Foundational Learning

- **LLM Agent Architectures (Perception-Planning-Grounding-Execution)**
  - Why needed here: Dataforge implements this paradigm; understanding how LLMs interact with structured environments is prerequisite to reasoning about the system's behavior.
  - Quick check question: Can you explain why grounding (connecting LLM outputs to executable operations) is necessary before action execution?

- **Feature Engineering Fundamentals (Selection, Transformation, Generation)**
  - Why needed here: The action-level router operates on these three categories; without this knowledge, you cannot evaluate whether the LLM planner's choices are reasonable.
  - Quick check question: Given a dataset with correlated features, would you expect the system to prioritize selection, transformation, or generation?

- **Feedback Control Systems (Safety Constraints + Objective Optimization)**
  - Why needed here: The dual-loop mechanism mirrors control theory: inner loop for stability (safety), outer loop for performance optimization.
  - Quick check question: In a control system, what happens if the inner loop fails to detect an invalid state before the outer loop executes?

## Architecture Onboarding

- Component map: Raw Data → Schema Alignment + Cleaning → Task-Level Router (Rule-Based) → Action-Level Router (LLM) → Grounding Validator → Execution Engine (Python/SQL) → Evaluator (F1/AUC/RMSE) → Experience Logger → (loops back to Action-Level Router)

- Critical path: The action-level router + grounding validator pair determines both system capability (what transformations are proposed) and reliability (what actually executes). Failures here cascade to all downstream metrics.

- Design tradeoffs:
  - Rule-based task routing vs. LLM-based: Faster and more reliable, but less flexible for ambiguous or novel task types.
  - LLM action planner vs. RL policy: Zero training cost and faster inference, but may lack fine-grained optimization in high-dimensional feature spaces.
  - Aggressive vs. conservative grounding: Stricter validation reduces errors but may reject beneficial but unconventional operations.

- Failure signatures:
  - Infinite re-planning loops: Performance metric never improves; check if evaluator is misconfigured or if action space is insufficient.
  - Schema validation rejects all actions: Likely type mismatch between LLM-generated operations and actual column types; inspect metadata extraction.
  - Sudden performance drops after valid operations: Possible data leakage or overfitting to validation set; review feature transformations.

- First 3 experiments:
  1. **Baseline validation**: Upload one classification and one regression dataset from the paper (e.g., German Credit, Airfoil). Verify that reported metrics (79.60% F1, 0.7849 1-RAE) are reproducible within tolerance.
  2. **Stress test grounding**: Intentionally provide a dataset with mismatched schema metadata (e.g., numeric column labeled as categorical). Observe whether the validator catches type errors and how the system recovers.
  3. **Loop convergence analysis**: Enable verbose logging and run on a multi-class dataset. Track the number of action retries, validation rejections, and performance deltas per iteration to characterize convergence behavior.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the hierarchical routing and dual-loop architecture effectively generalize to unstructured data modalities (e.g., text, images) or multi-modal datasets?
- Basis in paper: The authors explicitly limit the system scope to being "specialized for tabular data" and evaluate solely on structured datasets (UCI, OpenML).
- Why unresolved: The current design relies on schema metadata and feature-level transformations that assume discrete columns, leaving the adaptation to unstructured inputs unexplored.
- What evidence would resolve it: Successful application of the Dataforge framework to text classification or image processing tasks without fundamental architectural changes.

### Open Question 2
- Question: Does the reliance on deterministic heuristics for task-level routing limit the system's ability to handle hybrid or ambiguous task types?
- Basis in paper: The paper notes that task-level routing uses "deterministic heuristics" rather than LLM reasoning to ensure speed, which may lack flexibility for complex edge cases.
- Why unresolved: Rule-based routers can fail when datasets fit multiple task definitions or fall outside the standard classification/regression/clustering categories.
- What evidence would resolve it: Evaluation on datasets requiring multi-label classification or complex hierarchical outputs to test the router's decision boundaries.

### Open Question 3
- Question: What is the cumulative inference cost and latency of the LLM-driven feedback loops compared to traditional AutoML baselines when scaled to high-dimensional data?
- Basis in paper: The paper emphasizes "zero training cost" and speed compared to RL, but does not quantify the monetary cost or token consumption of the iterative LLM calls.
- Why unresolved: While faster than RL training, multiple LLM calls per action may incur significant API costs on wide datasets.
- What evidence would resolve it: A cost-analysis breakdown (tokens and time) as feature count scales into the thousands.

## Limitations
- Exact LLM model and prompt templates used for action-level routing are not specified, making exact replication difficult
- Validation logic for grounding (e.g., division-by-zero checks, type consistency) is described conceptually but not detailed enough for implementation
- No explicit mention of dataset splits or cross-validation strategy for performance metrics, raising questions about statistical reliability

## Confidence
- **High Confidence**: The dual feedback loop mechanism (action validation + performance optimization) is well-specified and logically sound. The hierarchical routing approach is clearly defined and experimentally supported.
- **Medium Confidence**: The claimed performance improvements (e.g., F1-score up to 97.14%, feature reduction from 44 to 20) are impressive but depend on the LLM planner's ability to propose optimal actions, which is not fully characterized.
- **Low Confidence**: Zero-shot performance in specialized domains (e.g., molecular fingerprints) is not demonstrated and may fail without task-specific tuning.

## Next Checks
1. **Baseline Validation**: Reproduce F1-score (79.60%) on German Credit and 1-RAE (0.7849) on Airfoil datasets within 5% tolerance.
2. **Grounding Robustness**: Provide a dataset with intentionally mismatched schema metadata and verify that the validator rejects invalid actions and triggers safe recovery.
3. **Loop Convergence Analysis**: Run on a multi-class dataset with verbose logging to measure action retries, validation rejections, and performance deltas per iteration, ensuring convergence within 10 steps.