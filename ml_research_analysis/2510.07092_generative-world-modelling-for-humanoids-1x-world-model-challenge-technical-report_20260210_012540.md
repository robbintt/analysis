---
ver: rpa2
title: 'Generative World Modelling for Humanoids: 1X World Model Challenge Technical
  Report'
arxiv_id: '2510.07092'
source_url: https://arxiv.org/abs/2510.07092
tags:
- world
- video
- arxiv
- wang
- sampling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents solutions for the 1X World Model Challenge,
  which benchmarks generative world models for humanoid robots. The sampling track
  adapts Wan-2.2 TI2V-5B, a large-scale video generation foundation model, to predict
  future frames conditioned on robot states using AdaLN-Zero for state conditioning
  and LoRA for efficient fine-tuning.
---

# Generative World Modelling for Humanoids: 1X World Model Challenge Technical Report

## Quick Facts
- arXiv ID: 2510.07092
- Source URL: https://arxiv.org/abs/2510.07092
- Reference count: 40
- Primary result: First place in both tracks of 1X World Model Challenge with PSNR 23.0 dB (sampling) and Top-500 cross-entropy 6.6386 (compression)

## Executive Summary
This work presents solutions for the 1X World Model Challenge, which benchmarks generative world models for humanoid robots. The sampling track adapts Wan-2.2 TI2V-5B, a large-scale video generation foundation model, to predict future frames conditioned on robot states using AdaLN-Zero for state conditioning and LoRA for efficient fine-tuning. The compression track employs a spatio-temporal Transformer architecture trained from scratch on discrete latent token sequences. The proposed methods achieve first place in both tracks, with a PSNR of 23.0 dB for sampling and a Top-500 cross-entropy of 6.6386 for compression. These results demonstrate the effectiveness of leveraging foundation models and specialized architectures for high-fidelity video prediction in robotics applications.

## Method Summary
The sampling track uses Wan-2.2 TI2V-5B with AdaLN-Zero state conditioning and LoRA adapters (rank 32) trained for 23k steps with AdamW (LR 4×10⁻⁴, batch 1024). The compression track uses a 24-layer spatio-temporal Transformer with alternating spatial and temporal attention blocks, trained from scratch for 80 epochs with cross-entropy loss, teacher forcing, and greedy decoding at inference. Both methods process robot states through MLP → 1D convolution → AdaLN modulation to guide video generation.

## Key Results
- First place in sampling track with PSNR of 23.0 dB on future frame prediction
- First place in compression track with Top-500 cross-entropy of 6.6386
- Ensemble averaging of 20 samples improves PSNR from 22.63 to 24.88 dB in sampling track
- ST-Transformer achieves efficient training (17 hours vs 36 hours) compared to foundation model approach

## Why This Works (Mechanism)

### Mechanism 1: State-Conditioned Video Generation via AdaLN-Zero
Conditioning video generation on robot proprioceptive states enables future frame prediction that reflects intended robot actions. Robot states (angles, velocities) are projected through MLP → downsampled via 1D convolution to match video latent temporal resolution → transformed into scale/shift modulation parameters via AdaLN-Zero. These modulations are applied within DiT blocks alongside flow-matching timestep embeddings, with state modulations operating on frame-specific latent slices. Core assumption: Robot state sequences encode sufficient information about motion dynamics to guide visual prediction.

### Mechanism 2: Ensemble Averaging Exploits Predictive Uncertainty
Averaging multiple stochastic predictions selectively blurs high-uncertainty regions, improving pixel-level metrics more effectively than uniform post-processing. Sample N predictions from the generative model; compute pixel-wise mean. High-variance regions (fast-moving limbs) naturally blur; low-variance regions (static background) remain sharp. Core assumption: PSNR and similar metrics penalize sharp errors more heavily than blur; predictive variance correlates with error magnitude.

### Mechanism 3: Factorized Spatio-Temporal Attention Reduces Complexity
Separating attention into spatial (within-frame) and temporal (cross-frame, same-position) components reduces memory from quadratic to linear scaling with frame count while preserving predictive capacity. Spatial attention operates over 32×32 tokens per frame independently. Temporal attention uses causal masking across T frames at identical spatial positions. Core assumption: Temporal dependencies are adequately captured by attending to same spatial locations across time; cross-position motion can propagate through stacked layers.

## Foundational Learning

- **Flow Matching / Diffusion Models**
  - Why needed here: The sampling track uses Wan 2.2's flow-matching backbone; understanding noise schedules, timesteps, and sampling is essential for adapting inference strategies.
  - Quick check question: Can you explain why classifier-free guidance (CFG) improves conditional generation, and what happens when CFG scale is too high?

- **Adaptive Layer Normalization (AdaLN)**
  - Why needed here: State conditioning injects robot information via AdaLN-Zero modulation; misunderstanding this blocks comprehension of how states influence generation.
  - Quick check question: How does AdaLN differ from standard LayerNorm, and why does "AdaLN-Zero" include a learned scaling gate initialized to zero?

- **Autoregressive Token Prediction with Teacher Forcing**
  - Why needed here: The compression track trains with teacher forcing (ground-truth context) but evaluates autoregressively; this train-test gap affects real performance.
  - Quick check question: What is exposure bias in autoregressive models, and why might scheduled sampling attempt to address it?

## Architecture Onboarding

- **Component map**: Wan2.2-VAE → 30-layer DiT backbone with AdaLN-Zero state injection → LoRA adapters → flow-matching denoising → decode to pixels (sampling track). Cosmos tokenizer → 24-layer Spatio-Temporal Transformer → autoregressive next-token prediction (compression track).

- **Critical path**: Sampling: State preprocessing → downsampling → sinusoidal augmentation → MLP projection → 1D conv compression → MLP to modulation → DiT forward → flow-matching objective. Compression: 6144 tokens → ST-Transformer blocks → cross-entropy loss → greedy decoding.

- **Design tradeoffs**: Pre-trained foundation model (Wan 2.2) vs. training from scratch (ST-Transformer): foundation models leverage internet-scale data but require careful adaptation; scratch training is faster (17 hours vs. 36 hours) but requires sufficient in-domain data. Ensemble inference vs. single sample: improves PSNR (+2.25 dB) but increases inference cost 20×; unsuitable for real-time robotics without caching/parallelization. Greedy vs. sampling decoding (compression): greedy is deterministic and efficient; sampling introduces diversity but yields higher loss.

- **Failure signatures**: PSNR improves but LPIPS/FID degrades: ensemble averaging over-smoothing. Teacher-forced loss much lower than autoregressive loss: exposure bias; model over-reliant on ground-truth context. Generated frames ignore robot states: AdaLN modulation magnitude too small or learning rate too low for LoRA adapters.

- **First 3 experiments**:
  1. Ablate state conditioning: Run sampling with zeroed states vs. true states; expect PSNR drop if conditioning is effective.
  2. Vary ensemble size: Plot PSNR vs. number of samples (1, 5, 10, 20, 50) to find diminishing returns point.
  3. Compare attention factorization: Train a small full-attention baseline vs. ST-Transformer on compression; measure gap in cross-entropy and memory usage.

## Open Questions the Paper Calls Out

### Open Question 1
What is the most suitable inference strategy for generative world models when deployed for downstream robotic decision-making? The authors note that while averaging ensemble samples optimized PSNR scores, "the most suitable inference strategy for downstream decision-making remains an open question." The challenge benchmark optimized for pixel-wise accuracy (PSNR) rather than actionability. An evaluation on downstream control tasks comparing PSNR-optimized inference against deterministic or sharp sampling methods would resolve this.

### Open Question 2
How can video generation models be trained to improve PSNR without degrading perceptual quality (LPIPS/FID)? Table 2 shows that increasing the number of averaged samples monotonically improves PSNR but significantly degrades perceptual metrics, suggesting a fundamental trade-off. A training objective that simultaneously improves PSNR and FID/LPIPS, or a demonstration that high-fidelity sharp predictions can achieve competitive PSNR scores without post-hoc blurring, would resolve this.

### Open Question 3
How can the performance gap between teacher-forced training and autoregressive inference be effectively reduced in spatio-temporal transformers? The authors note that teacher-forced validation loss represents an "idealised" lower bound, while autoregressive validation performs significantly worse. They mention that scheduled sampling was attempted but "did not lead to meaningful improvements." Successful implementation of training regularization techniques beyond scheduled sampling would resolve this.

## Limitations
- State conditioning effectiveness relies heavily on the assumption that robot proprioceptive states contain sufficient information about future visual dynamics, with limited ablation studies on alternative conditioning methods.
- Ensemble averaging improves PSNR but may not translate to better downstream task performance and increases inference cost 20×, making it impractical for real-time robotics.
- The ST-Transformer factorization may fail for complex motion patterns requiring cross-position temporal relationships, as it assumes temporal dependencies are adequately captured by same-position attention across frames.

## Confidence

- **High confidence**: Architectural implementations (Wan-2.2 adaptation, ST-Transformer design) are clearly specified and follow established principles. Training procedures and hyperparameters are detailed enough for reproduction attempts.
- **Medium confidence**: State-conditioning mechanism's effectiveness is demonstrated through challenge performance but lacks comprehensive ablation studies on different state representations or conditioning strengths.
- **Low confidence**: Generalization of these methods to real-world humanoid deployment scenarios, particularly regarding computational constraints and handling of external environmental factors not captured in training data.

## Next Checks

1. Ablation study varying AdaLN modulation magnitude (learned gate initialization) to quantify state conditioning contribution beyond foundation model capabilities.
2. Comparative evaluation of ensemble averaging vs. alternative uncertainty-aware inference methods (Monte Carlo dropout, temperature scaling) on downstream task metrics.
3. Stress testing ST-Transformer factorization by introducing controlled cross-position motion patterns to identify breaking points where factorization fails.