---
ver: rpa2
title: "Moir\xE9XNet: Adaptive Multi-Scale Demoir\xE9ing with Linear Attention Test-Time\
  \ Training and Truncated Flow Matching Prior"
arxiv_id: '2506.15929'
source_url: https://arxiv.org/abs/2506.15929
tags:
- image
- moir
- demoir
- ieee
- eing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a hybrid MAP-based framework for image and\
  \ video demoir\xE9ing that combines a supervised learning model with generative\
  \ priors. The supervised component uses linear attention Test-Time Training (TTT)\
  \ modules and frequency-enhanced filters to directly learn nonlinear RAW-to-sRGB\
  \ mappings, while a Truncated Flow Matching Prior (TFMP) refines outputs by aligning\
  \ them with the clean image distribution."
---

# MoiréXNet: Adaptive Multi-Scale Demoiréing with Linear Attention Test-Time Training and Truncated Flow Matching Prior

## Quick Facts
- **arXiv ID**: 2506.15929
- **Source URL**: https://arxiv.org/abs/2506.15929
- **Reference count**: 40
- **Primary result**: Achieves state-of-the-art PSNR of 30.21 dB for image demoiréing and 30.214 dB after TFMP refinement on benchmark datasets

## Executive Summary
This paper introduces MoiréXNet, a hybrid MAP-based framework that combines supervised learning with generative priors for image and video demoiréing. The approach uses linear attention Test-Time Training (TTT) modules and frequency-enhanced filters to learn nonlinear RAW-to-sRGB mappings, while a Truncated Flow Matching Prior (TFMP) refines outputs by aligning them with the clean image distribution. The model demonstrates state-of-the-art performance on benchmark datasets, achieving PSNR of 30.21 dB for image demoiréing and 30.214 dB after TFMP refinement.

## Method Summary
MoiréXNet processes RAW Bayer pattern images (4-channel RGGB) through a shallow feature extraction network, invertible neural network (INN), learnable frequency enhanced filter (LFEF), and TTT linear attention blocks. For video, it adds PCD alignment and temporal fusion. The framework uses a two-stage training approach: initial L1+VGG loss training for 175 epochs, followed by wavelet loss fine-tuning for 41 epochs. TFMP refinement operates from t=0.95 for approximately 15 iterations to improve reconstruction quality. The model is trained on RawVDemoiré and TMM22 datasets using patches of 256×256 for training and 512×512 for testing.

## Key Results
- Achieves PSNR of 29.590 dB for image demoiréing (MoiréXNet alone)
- Improves to 30.214 dB with TFMP refinement on video benchmarks
- Surpasses existing methods in both reconstruction quality and computational efficiency
- Reduces computational complexity from O(t²) to O(t) via TTT linear attention

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: TTT linear attention reduces computational complexity from O(t²) to O(t) while preserving long-range dependency modeling for demoiréing.
- **Mechanism**: Replaces explicit Key-Value cache with parametric hidden state `s_t = f(s_{t-1}, x_t; W)` that is iteratively updated, avoiding pairwise token comparisons.
- **Core assumption**: Compressed hidden state sufficiently captures global context for moiré pattern removal without full token-to-token interaction matrices.
- **Evidence anchors**: [abstract] "efficient linear attention Test-Time Training (TTT) modules"; [section III-A] "fixed-size representation with O(1) memory requirements".
- **Break condition**: Complex spatially-diverse moiré patterns requiring precise non-local token interactions exceed compressed state's capacity.

### Mechanism 2
- **Claim**: LFEF counteracts attention's low-pass filtering tendency by adaptively amplifying both low- and high-frequency components before TTT processing.
- **Mechanism**: Applies frequency-domain processing (via FFT) with learnable weights to enhance high-frequency details that standard attention would otherwise suppress.
- **Core assumption**: Moiré patterns have distinguishable frequency signatures separable from legitimate image high-frequency content via learned filtering.
- **Evidence anchors**: [abstract] "frequency-enhanced filters"; [section III-A] "self-attention behaves like a low-pass filter... Learnable Frequency Enhanced Filter (LFEF)".
- **Break condition**: Unseen moiré patterns with frequency characteristics diverging from training data cause filter to amplify artifacts or suppress legitimate details.

### Mechanism 3
- **Claim**: TFMP refines supervised outputs by learning a velocity field that iteratively maps degraded outputs toward clean image distribution in few steps.
- **Mechanism**: Applies `x_{t-1} = x_t + Δt · v(x_t, t)` where `v(x_t, t)` is pretrained velocity field, starting from t=0.95.
- **Core assumption**: Supervised model outputs lie near clean image manifold, enabling short learned trajectories to bridge residual gap without hallucination.
- **Evidence anchors**: [abstract] "Truncated Flow Matching Prior (TFMP) that further refines outputs"; [section III-B] "x_t = x̃, with t starting from a higher value (e.g., t = 0.95)".
- **Break condition**: Supervised outputs too distant from clean image distribution cause TFMP divergence or artifact introduction.

## Foundational Learning

- **Concept**: Test-Time Training (TTT)
  - **Why needed**: Core architectural component replacing standard attention for efficient long-sequence processing.
  - **Quick check**: How does TTT's parametric hidden state differ from standard attention's KV cache?

- **Concept**: Flow Matching / Continuous Normalizing Flows
  - **Why needed**: Foundation for TFMP refinement module; understanding velocity fields and ODE-based generative processes.
  - **Quick check**: Why does starting flow matching at t=0.95 (vs. t=0) reduce computational cost while still improving outputs?

- **Concept**: Image Signal Processor (ISP) Pipeline
  - **Why needed**: Demoiréing operates on RAW-to-sRGB mapping; understanding nonlinear ISP transformations clarifies why moiré removal is challenging.
  - **Quick check**: What information is lost during sRGB conversion that makes RAW-domain demoiréing advantageous?

## Architecture Onboarding

- **Component map**: Shallow Feature Extraction (SFE) → Invertible Neural Network (INN) → Learnable Frequency Enhanced Filter (LFEF) → TTT Linear Attention Blocks → Reconstruction
- **For video**: Add PCD alignment and temporal fusion before reconstruction
- **Optional**: TFMP refinement stage post-reconstruction

- **Critical path**:
  1. RAW input (4-channel RGGB) → SFE → INN (lossless feature preservation)
  2. Multi-scale decomposition → LFEF (frequency enhancement) → TTT blocks (global context)
  3. Feature fusion → Reconstruction → sRGB output
  4. Optional: TFMP iterative refinement (5-15 iterations from t=0.95)

- **Design tradeoffs**:
  - TTT vs. full attention: Gains linear complexity but may sacrifice expressiveness for complex patterns
  - TFMP refinement: Improves PSNR (+0.087 dB) but may increase LPIPS (perceptual artifacts)
  - RAW vs. sRGB input: RAW preserves more information but requires specialized datasets

- **Failure signatures**:
  - Oversmoothed outputs: Insufficient high-frequency preservation (check LFEF)
  - Residual moiré artifacts: TTT capacity insufficient (consider hidden size increase)
  - TFMP artifacts: Starting t too low or iteration count exceeded (Fig. 5 peak ~15 iterations)
  - Color distortion: RAW processing pipeline mismatch

- **First 3 experiments**:
  1. Ablate INN, LFEF, and TTT individually to measure each component's contribution (baseline: Table III shows +0.99 dB PSNR from INN, +0.09 dB from LFEF)
  2. Sweep TFMP starting t values (0.90-0.98) and iteration counts (5-20) to find optimal refinement parameters
  3. Compare RAW vs. sRGB input performance on held-out moiré pattern types to assess generalization capacity

## Open Questions the Paper Calls Out
- **Open Question 1**: How can adaptive techniques be integrated to refine the data fidelity gradient within the MoiréXNet framework to further enhance the supervised model's performance?
- **Open Question 2**: Can the hybrid MAP-based framework combining linear attention TTT and TFMP effectively generalize to other nonlinear inverse problems, such as blind deblurring or JPEG artifact removal?
- **Open Question 3**: Is it possible to develop a content-adaptive mechanism for determining the truncation start point t in the Truncated Flow Matching Prior (TFMP) to optimize restoration for varying degrees of moiré severity?

## Limitations
- Architectural innovations (TTT, TFMP) lack complete implementation details in main text
- Performance claims rely on specialized datasets (RawVDemoiré, TMM22) not publicly available
- RAW-to-sRGB mapping assumes fixed ISP characteristics that may not generalize across camera systems

## Confidence
- **High Confidence**: MoiréXNet architecture improves demoiréing PSNR from 29.503 dB to 29.590 dB; TFMP refinement provides consistent PSNR gains; computational complexity reduction from O(t²) to O(t) via TTT is theoretically sound
- **Medium Confidence**: LFEF frequency enhancement specifically targets moiré patterns; TFMP starting at t=0.95 optimizes trade-off; multi-scale decomposition effectively captures patterns
- **Low Confidence**: Exact mechanism by which TTT's compressed hidden state captures long-range dependencies; whether RAW-domain processing provides practical advantages; generalization to unseen moiré patterns

## Next Checks
1. **Ablation of Core Components**: Implement and test individual components (INN, LFEF, TTT) in isolation to verify their claimed contributions (baseline PSNR 29.503 → 29.590 dB with INN, +0.09 dB from LFEF)
2. **TFMP Parameter Sweep**: Systematically vary TFMP starting t values (0.90-0.98) and iteration counts (5-20) to identify optimal parameters and validate the claimed peak at ~15 iterations
3. **RAW vs. RGB Generalization Test**: Compare model performance on RAW versus standard RGB inputs across diverse moiré pattern types to assess whether the RAW-domain approach provides meaningful generalization advantages or is dataset-specific