---
ver: rpa2
title: GAN-based synthetic FDG PET images from T1 brain MRI can serve to improve performance
  of deep unsupervised anomaly detection models
arxiv_id: '2505.07364'
source_url: https://arxiv.org/abs/2505.07364
tags:
- data
- images
- detection
- image
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that realistic FDG PET images of healthy
  subjects can be generated from T1 MRI data using GAN-based architectures. A Cycle-GAN
  architecture with an additional MSE loss term was shown to outperform other GAN
  variants in terms of visual quality metrics (SSIM 0.897, PSNR 23.8, LPIPS 0.019).
---

# GAN-based synthetic FDG PET images from T1 brain MRI can serve to improve performance of deep unsupervised anomaly detection models

## Quick Facts
- arXiv ID: 2505.07364
- Source URL: https://arxiv.org/abs/2505.07364
- Reference count: 40
- GAN-based Cycle-GAN with MSE loss outperforms other variants for T1-to-PET translation, achieving 74% sensitivity for epilepsy lesion detection versus 42% with real PET training data

## Executive Summary
This study demonstrates that realistic FDG PET images of healthy subjects can be generated from T1 MRI data using GAN-based architectures. A Cycle-GAN architecture with an additional MSE loss term was shown to outperform other GAN variants in terms of visual quality metrics (SSIM 0.897, PSNR 23.8, LPIPS 0.019). The generated synthetic PET data was shown to have distributions similar to real PET data in both image and latent spaces, validating their use for training unsupervised anomaly detection (UAD) models. The UAD model trained on synthetic PET data achieved 74% sensitivity in detecting subtle epilepsy lesions, outperforming the model trained on real PET data (42% sensitivity), with mean cluster ranks of 2.1 versus 3.9. This demonstrates that GAN-generated synthetic PET images can effectively replace scarce real PET data for training UAD models in medical imaging applications.

## Method Summary
The study employed a Cycle-GAN architecture with an additional mean squared error (MSE) loss term to translate T1 MRI images to synthetic FDG PET images. The Cycle-GAN was trained on 32 healthy subjects with both T1 and PET scans, with the MSE loss helping to preserve structural information during translation. The synthetic PET images were evaluated using three quantitative metrics: Structural Similarity Index (SSIM), Peak Signal-to-Noise Ratio (PSNR), and Learned Perceptual Image Patch Similarity (LPIPS). For unsupervised anomaly detection, a Variational Autoencoder (VAE) was trained on the synthetic PET data and tested on a separate cohort of 5 epilepsy patients. The VAE generated reconstruction errors that were used to identify abnormal regions, with clustering analysis determining the most likely lesion locations.

## Key Results
- Cycle-GAN with MSE loss achieved SSIM 0.897, PSNR 23.8, and LPIPS 0.019 on synthetic PET generation
- Synthetic PET images showed similar distributions to real PET data in both image and latent spaces
- UAD model trained on synthetic PET achieved 74% sensitivity for epilepsy lesion detection vs 42% for real PET training
- Mean cluster rank for lesion detection was 2.1 with synthetic training vs 3.9 with real training

## Why This Works (Mechanism)
The success of this approach relies on the Cycle-GAN's ability to learn a mapping between T1 MRI and FDG PET domains while preserving anatomical structure. The additional MSE loss term ensures that the generated PET images maintain fidelity to the input MRI structure, which is crucial for accurate anomaly detection. By training on healthy subjects only, the model learns a normative distribution of brain metabolism that can be used to identify deviations in pathological cases. The synthetic data effectively augments the limited real PET training data available, enabling the UAD model to learn robust representations of normal brain activity patterns.

## Foundational Learning
- **Cycle-GAN architecture**: Essential for cross-modality image translation between T1 MRI and PET, learning bidirectional mappings with cycle consistency
- **Unsupervised Anomaly Detection (UAD)**: Needed to identify pathological regions without labeled training data, using reconstruction error as anomaly score
- **Variational Autoencoder (VAE)**: Quick check - VAE learns latent representation of normal brain patterns, reconstruction error indicates deviation from normality
- **Image quality metrics (SSIM, PSNR, LPIPS)**: Required to quantitatively assess synthetic image quality and ensure clinical utility
- **Cluster analysis for lesion detection**: Needed to aggregate reconstruction errors and identify most probable lesion locations in 3D space

## Architecture Onboarding

**Component Map**
T1 MRI -> Cycle-GAN -> Synthetic PET -> VAE (trained on synthetic PET) -> Reconstruction Error -> Clustering -> Lesion Detection

**Critical Path**
The critical path for anomaly detection performance is: Cycle-GAN translation quality -> VAE training on synthetic data -> Reconstruction error generation -> Clustering analysis

**Design Tradeoffs**
The addition of MSE loss to Cycle-GAN improves structural fidelity but may reduce creative translation capabilities. Using only healthy subjects for synthetic data generation ensures normality learning but limits the model's exposure to diverse pathologies.

**Failure Signatures**
- Poor SSIM/PSNR/LPIPS scores indicate inadequate translation quality
- High reconstruction error on healthy data suggests VAE overfitting
- Low clustering accuracy indicates poor anomaly localization

**First Experiments**
1. Test Cycle-GAN translation quality on held-out healthy subjects
2. Evaluate VAE reconstruction performance on synthetic vs real PET data
3. Assess lesion detection accuracy on patients with known epilepsy foci

## Open Questions the Paper Calls Out
The paper does not explicitly call out additional open questions beyond those addressed in the limitations section.

## Limitations
- Small sample size (37 subjects) may not capture full variability of brain anatomy and metabolism
- Focus on epilepsy detection limits generalizability to other neurological conditions
- Cycle-GAN architecture may not be optimal for all cross-modality translation tasks

## Confidence

**High Confidence**: The technical implementation of the Cycle-GAN architecture with MSE loss, the evaluation metrics (SSIM, PSNR, LPIPS), and the comparative performance against real PET training data

**Medium Confidence**: The clinical relevance of the 74% sensitivity improvement for epilepsy lesion detection, as this was tested on a limited dataset with specific characteristics

**Medium Confidence**: The assumption that synthetic PET distributions are sufficiently similar to real PET data for broader clinical applications

## Next Checks

1. Test the trained UAD model on an independent, larger cohort with diverse neurological conditions to assess generalizability
2. Perform ablation studies to determine the optimal loss function combination and architecture parameters for different disease states
3. Validate the clinical utility through radiologist evaluation comparing synthetic versus real PET image interpretation accuracy and diagnostic confidence