---
ver: rpa2
title: 'Large Language Models for Pedestrian Safety: An Application to Predicting
  Driver Yielding Behavior at Unsignalized Intersections'
arxiv_id: '2509.19657'
source_url: https://arxiv.org/abs/2509.19657
tags:
- yielding
- pedestrian
- driver
- behavior
- traffic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that multimodal large language models (LLMs)
  can effectively predict driver yielding behavior at unsignalized intersections by
  integrating visual, textual, and structured data through domain-specific prompts.
  Among evaluated models, GPT-4o achieved the highest accuracy (91.06%) and recall
  (92.41%), while Deepseek-V3 excelled in precision (92.06%).
---

# Large Language Models for Pedestrian Safety: An Application to Predicting Driver Yielding Behavior at Unsignalized Intersections

## Quick Facts
- arXiv ID: 2509.19657
- Source URL: https://arxiv.org/abs/2509.19657
- Reference count: 11
- Large language models can predict driver yielding behavior at unsignalized intersections with high accuracy

## Executive Summary
This study explores the application of multimodal large language models (LLMs) to predict driver yielding behavior at unsignalized intersections, addressing critical pedestrian safety concerns. The research integrates visual data, textual descriptions, and structured information through domain-specific prompts to enable context-aware inference. Among evaluated models, GPT-4o achieved the highest accuracy (91.06%) and recall (92.41%), while Deepseek-V3 excelled in precision (92.06%). The approach demonstrates strong generalization capabilities across complex traffic environments and offers interpretable reasoning for safety-critical decisions.

## Method Summary
The study employs multimodal LLMs to predict driver yielding behavior by processing visual inputs (traffic scene images), textual descriptions (pedestrian characteristics and environmental conditions), and structured data (traffic regulations). Domain-specific prompts guide the models to analyze these diverse data sources and generate binary predictions about whether drivers will yield to pedestrians. The methodology emphasizes context-aware inference through integrated reasoning across multiple modalities, moving beyond traditional computer vision approaches to leverage the comprehensive understanding capabilities of large language models.

## Key Results
- GPT-4o achieved highest accuracy (91.06%) and recall (92.41%) for driver yielding prediction
- Deepseek-V3 demonstrated superior precision (92.06%) among evaluated models
- Multimodal integration through domain-specific prompts enabled interpretable reasoning and strong generalization across traffic environments

## Why This Works (Mechanism)
The success of this approach stems from LLMs' ability to integrate multiple data modalities (visual, textual, structured) through sophisticated reasoning patterns. Unlike traditional computer vision models that rely solely on image analysis, multimodal LLMs can contextualize visual information with textual descriptions and structured rules, creating a more comprehensive understanding of complex traffic scenarios. The domain-specific prompts act as structured reasoning frameworks that guide the models to consider relevant safety factors, pedestrian characteristics, and traffic regulations when making predictions.

## Foundational Learning
- Multimodal input processing - LLMs can simultaneously process images, text, and structured data, enabling holistic scene understanding necessary for complex traffic analysis
- Domain-specific prompting - Structured prompts guide models to focus on relevant safety factors and apply appropriate reasoning patterns for traffic scenarios
- Context-aware inference - Models integrate environmental, behavioral, and regulatory information to make nuanced predictions about driver behavior
- Interpretable reasoning - The approach provides transparent decision-making processes that can be audited for safety-critical applications
- Generalization across scenarios - Models demonstrate ability to apply learned patterns to novel intersection types and traffic conditions

## Architecture Onboarding

**Component Map:** Visual Input → Textual Processing → Structured Data Integration → Domain-Specific Prompting → Yielding Prediction

**Critical Path:** Image recognition → Context extraction → Rule application → Safety assessment → Binary output

**Design Tradeoffs:** The multimodal approach sacrifices some computational efficiency for enhanced accuracy and interpretability compared to traditional computer vision methods. While single-modality models might be faster, they lack the contextual understanding necessary for complex safety predictions.

**Failure Signatures:** Models may struggle with unusual lighting conditions, obscured pedestrian visibility, or scenarios that deviate significantly from training data patterns. Performance degradation could occur in highly dynamic environments with multiple conflicting stimuli.

**First 3 Experiments:**
1. Test model performance across different intersection types (roundabouts, four-way stops, uncontrolled crossings)
2. Evaluate prediction accuracy under various weather and lighting conditions
3. Compare LLM predictions against human expert assessments in ambiguous traffic scenarios

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Dataset diversity and geographic representation remain unclear, potentially limiting model generalizability
- Evaluation metrics may not fully capture real-world deployment challenges like latency and edge-case handling
- Binary yielding prediction approach doesn't address intermediate driver behaviors or multi-pedestrian scenarios

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Model performance metrics (accuracy, recall, precision) | High |
| Generalization capabilities across traffic environments | Medium |
| Practical applicability for safety systems | Medium |

## Next Checks
1. Deploy models in diverse real-world settings across multiple cities and intersection types to validate cross-regional performance
2. Conduct A/B testing comparing LLM predictions against human expert assessments in ambiguous scenarios
3. Perform latency and computational efficiency analysis under realistic edge computing constraints for practical deployment viability