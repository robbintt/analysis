---
ver: rpa2
title: 'KisMATH: Do LLMs Have Knowledge of Implicit Structures in Mathematical Reasoning?'
arxiv_id: '2507.11408'
source_url: https://arxiv.org/abs/2507.11408
tags:
- reasoning
- answer
- which
- question
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Causal CoT Graphs (CCGraphs) to model fine-grained\
  \ causal dependencies in LLM reasoning traces. By automatically extracting these\
  \ graphs from mathematical reasoning traces across 1671 problems from MATH500, GSM8K,\
  \ and AIME datasets, the authors find that reasoning nodes in the CCGraphs are effective\
  \ mediators between questions and answers\u2014a necessary condition for reasoning."
---

# KisMATH: Do LLMs Have Knowledge of Implicit Structures in Mathematical Reasoning?

## Quick Facts
- arXiv ID: 2507.11408
- Source URL: https://arxiv.org/abs/2507.11408
- Reference count: 40
- Primary result: Reasoning nodes in extracted CCGraphs are causal mediators between questions and answers, and models assign higher probability to reasoning paths, suggesting internal structural alignment.

## Executive Summary
This paper introduces Causal CoT Graphs (CCGraphs) to model fine-grained causal dependencies in LLM reasoning traces. By automatically extracting these graphs from mathematical reasoning traces across 1671 problems from MATH500, GSM8K, and AIME datasets, the authors find that reasoning nodes in the CCGraphs are effective mediators between questions and answers—a necessary condition for reasoning. Empirical analysis with 15 open-weight LLMs (1B-70B parameters) shows that these models emphasize reasoning paths captured by the CCGraphs, indicating internal realization of similar structures. Attention suppression experiments demonstrate that removing reasoning nodes significantly increases answer uncertainty, while reasoning paths consistently receive higher probability mass compared to random paths.

## Method Summary
The method extracts Causal CoT Graphs (CCGraphs) from LLM reasoning traces by parsing mathematical expressions with SymPy, matching them across the trace, and constructing a DAG from answer backwards. The framework then applies attention suppression to reasoning nodes to test their causal mediation effect, and compares path probabilities between reasoning paths and random paths. The approach uses 1671 math problems across three datasets, generates CoT traces with OpenAI o3, and tests 15 open-weight LLMs ranging from 1B to 70B parameters.

## Key Results
- Attention suppression over reasoning nodes significantly increases answer uncertainty (D_KS > 0.8, p < 10^-12), demonstrating mediation.
- Models assign higher probability to reasoning paths (R-paths) compared to random paths of equal length, suggesting internal structural alignment.
- Bell-shaped models (like DeepSeek R1 32B) show improved pass@k performance with higher sample counts, indicating exploration via high-entropy "fork" tokens.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Mathematical expressions in CoT traces serve as causal mediators between questions and final answers.
- Mechanism: Reasoning nodes in CCGraphs carry information from question nodes to answer nodes through directed edges; suppressing attention to these nodes disrupts the indirect causal pathway, increasing answer uncertainty significantly.
- Core assumption: If reasoning traces are mere decoration (not genuine reasoning), suppressing intermediate nodes should not affect final answer distributions.
- Evidence anchors:
  - [abstract]: "reasoning nodes in the CCGraphs are causal contributors to the final answer, which we argue is constitutive of reasoning"
  - [section 5.1]: "attention suppression over all tokens corresponding to every reasoning node in a CCGraph significantly increases uncertainty in the answer (p < 10^-12)"
  - [corpus]: Causal Prompting paper (FMR=0.65) supports causal intervention approaches for implicit reasoning analysis.
- Break condition: If attention suppression does not increase answer entropy, mediation claim fails.

### Mechanism 2
- Claim: LLMs internally represent structures similar to CCGraphs, assigning higher probability to graph-aligned reasoning paths.
- Mechanism: Models assign higher transition probabilities (P(R)) to reasoning paths (R-paths) extracted from CCGraphs compared to random paths of equal length, suggesting implicit alignment with the extracted causal structure.
- Core assumption: Higher probability on graph-aligned paths indicates internal representation of similar structures, not artifact of extraction.
- Evidence anchors:
  - [section 5.3]: "All tested LLMs across the 3 different splits show a spike at 100 percentile... indicating that P(R) is high for a considerable fraction of R paths"
  - [section 5.3]: "This hints at the fact that a structure similar to the proposed CCGraph is implicitly realized in CoT traces"
  - [corpus]: Weak corpus signal—no direct replication of this specific probability-ranking method found.
- Break condition: If random paths consistently outperform R-paths in probability ranking, internal structure claim fails.

### Mechanism 3
- Claim: Models exhibit two behavioral regimes—"exponential" (high-confidence traversal) and "bell-shaped" (exploration via high-entropy "fork" tokens).
- Mechanism: Bell-shaped models produce occasional low-probability transitions along R-paths, enabling broader exploration of solution paths; this correlates with better pass@k performance at higher sample counts.
- Core assumption: High-entropy tokens reflect intrinsic uncertainty in reasoning (legitimate exploration), not just extrinsic noise.
- Evidence anchors:
  - [section 6.2]: "The 'bell'-shaped model (DeepSeek R1 32B) indeed shows improved performance indicating that it explores a greater variety of reasoning paths"
  - [section 6.2]: pass@k widens with increasing sample count (87% vs 90% at k=10 for exponential vs bell-shaped models)
  - [corpus]: Related work (Wang et al. 2025) found similar high-entropy "fork" tokens enable exploration.
- Break condition: If higher entropy does not correlate with improved pass@k, exploration benefit claim weakens.

## Foundational Learning

- Concept: Directed Acyclic Graphs (DAGs) and causal mediation
  - Why needed here: CCGraphs are DAGs where reasoning nodes mediate question-to-answer causal flow; understanding direct vs indirect effects is essential.
  - Quick check question: If suppressing node M breaks the Q→A relationship, is M a mediator?

- Concept: Attention suppression intervention
  - Why needed here: Core methodology for testing causal contribution by zeroing attention from suppressed tokens.
  - Quick check question: What does it mean when suppressing reasoning tokens increases answer entropy?

- Concept: Kolmogorov-Smirnov test for distribution shift
  - Why needed here: Quantifies whether attention suppression significantly shifts answer entropy distributions.
  - Quick check question: What does a high D_KS value with low p-value indicate?

## Architecture Onboarding

- Component map: Expression parser (SymPy) -> CCGraph builder -> Attention suppressor -> Path probability analyzer -> Rank comparator
- Critical path: Parse expressions -> Build CCGraph -> Extract R-paths -> Apply attention suppression -> Measure entropy shift -> Compare path probabilities
- Design tradeoffs:
  - Manual intervention required in ~10% of cases where graph degenerates (LaTeX errors, natural language interruptions)
  - Geometry/abstract math problems excluded due to parsing limitations
  - Attention suppression assumes OOD behavior is not problematic (per Bogdan et al.)
- Failure signatures:
  - Singleton graph (answer node only): indicates parsing or matching failure
  - Low D_KS values: attention suppression not affecting answers (mediation weak)
  - Random paths outranking R-paths: internal structure alignment absent
- First 3 experiments:
  1. Replicate attention suppression on GSM8K split with a single model; verify D_KS > 0.8 and p < 10^-10
  2. Compute rank_10(R) distribution for Qwen3-8B on 50 samples; confirm 100th percentile spike
  3. Compare pass@1 vs pass@5 for a bell-shaped vs exponential model on 20 AIME problems; check for widening gap

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the CCGraph extraction framework be extended to reasoning domains like geometry or commonsense reasoning where relationships cannot be derived solely from algebraic parsing?
- Basis in paper: [explicit] The authors state in the Limitations section that the current approach is "not directly applicable" to geometry or abstract mathematics because "it is difficult to decipher the relationship between the entities from algebraic parsing alone."
- Why unresolved: The current algorithm (Algorithm 1) relies on symbolic mathematical matching (SymPy) to construct edges. It cannot parse spatial, semantic, or abstract relationships expressed purely in natural language (e.g., "Let H be a normal subgroup").
- What evidence would resolve it: A modification of the extraction pipeline that integrates semantic parsing or visual encoders, successfully applied and validated on non-algebraic datasets like GeoQA.

### Open Question 2
- Question: How does the discourse structure of the natural language "glue" specifically interact with mathematical entities to mediate reasoning in complex problems?
- Basis in paper: [inferred] Section 6.1 notes that while mathematical nodes are the primary mediators for GSM8K, MATH500 and AIME results suggest natural language context is necessary to resolve "heterogeneous meaning and structure," though the exact causal contribution of this discourse remains unquantified.
- Why unresolved: The intervention experiments compare "math-only" vs. "math-suppressed" contexts, but they do not isolate the specific function of discourse connectives or semantic relations in bridging mathematical entities.
- What evidence would resolve it: Targeted interventions on discourse connectives (e.g., suppressing "therefore" or "since") in complex traces to measure their isolated impact on the indirect effect (IE) of the reasoning path.

### Open Question 3
- Question: Does the specific post-training method (e.g., Reinforcement Learning with Verifiable Rewards vs. Distillation) deterministically cause the "exponential" versus "bell-shaped" reasoning path distributions?
- Basis in paper: [inferred] Section 6.2 observes that the "bell-shaped" model (DeepSeek R1 32B, distilled) exhibits greater exploration (higher pass@k) compared to the "exponential" model (Qwen3 32B, RLVR), but the paper stops short of confirming training method as the sole cause.
- Why unresolved: The comparison is confounded by different base models and architectures. It is unclear if the uncertainty distribution is a property of the model family or a direct result of the RLVR vs. distillation optimization process.
- What evidence would resolve it: Ablation studies training identical base models using isolated RLVR and distillation pipelines, followed by analysis of their respective reasoning path rank distributions.

## Limitations

- CCGraph extraction relies on symbolic mathematical parsing, excluding geometry and diagram-based problems that constitute a significant portion of mathematical reasoning tasks.
- The attention suppression methodology assumes out-of-distribution behavior doesn't distort results, though this assumption isn't explicitly validated.
- Path probability analysis depends on specific random path generation that avoids CCGraph nodes—the robustness of findings to alternative random sampling strategies remains untested.

## Confidence

- **High confidence**: Mediation finding—attention suppression experiments show consistently large Kolmogorov-Smirnov distances (D_KS > 0.8, p < 10^-12) across multiple models and datasets.
- **Medium confidence**: Internal structure alignment—while probability ranking shows R-paths outperforming random paths, effect sizes vary and interpretation of "internal representation" remains ambiguous.
- **Medium confidence**: Behavioral regime claims—correlation between bell-shaped models and improved pass@k is suggestive but based on limited comparisons between two models.

## Next Checks

1. **Replicate mediation effect with alternative suppression**: Apply attention suppression to reasoning nodes while also suppressing an equal number of random nodes in the same traces. If only reasoning node suppression increases entropy significantly, this strengthens the mediation claim by controlling for general attention disruption effects.

2. **Test path probability robustness**: Generate random paths that include some CCGraph nodes (not just those that avoid them entirely) and recompute rank distributions. If R-paths maintain their probability advantage even when random paths share some structural overlap, this strengthens the internal structure alignment claim.

3. **Validate behavioral regime mechanism**: Systematically manipulate token entropy during inference (e.g., through temperature scaling or top-k sampling) and measure its effect on pass@k performance across multiple models. If entropy manipulation directly correlates with exploration behavior and accuracy improvements, this establishes a causal link between the proposed behavioral regimes and performance outcomes.