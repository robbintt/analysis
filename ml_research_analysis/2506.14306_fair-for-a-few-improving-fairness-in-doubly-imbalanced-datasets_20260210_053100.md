---
ver: rpa2
title: 'Fair for a few: Improving Fairness in Doubly Imbalanced Datasets'
arxiv_id: '2506.14306'
source_url: https://arxiv.org/abs/2506.14306
tags:
- dataset
- fairness
- data
- level
- ratio
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses fairness challenges in machine learning when
  datasets are imbalanced both in label distribution and sensitive attribute groups,
  termed "doubly imbalanced datasets." Existing debiasing methods often fail in such
  scenarios, particularly when balancing only one aspect of the dataset. The authors
  propose a multi-criteria optimization approach that jointly balances both the label
  distribution and sensitive attribute groups.
---

# Fair for a few: Improving Fairness in Doubly Imbalanced Datasets

## Quick Facts
- arXiv ID: 2506.14306
- Source URL: https://arxiv.org/abs/2506.14306
- Reference count: 40
- This study proposes a multi-criteria optimization approach that jointly balances both label distribution and sensitive attribute groups in doubly imbalanced datasets, significantly improving both fairness and accuracy compared to baseline methods.

## Executive Summary
This study addresses fairness challenges in machine learning when datasets are imbalanced both in label distribution and sensitive attribute groups, termed "doubly imbalanced datasets." Existing debiasing methods often fail in such scenarios, particularly when balancing only one aspect of the dataset. The authors propose a multi-criteria optimization approach that jointly balances both the label distribution and sensitive attribute groups. The method uses three parameters to control balancing across privileged/unprivileged groups and favorable/unfavorable labels, then applies grid search to find optimal trade-offs between fairness (measured by Disparate Impact Ratio) and classification accuracy (measured by Matthews Correlation Coefficient). Experiments on fraud detection datasets demonstrate significant improvements in both fairness and accuracy compared to baseline methods, with Pareto front analysis showing the trade-off between these objectives. The approach is model-agnostic and applicable to both doubly and singly imbalanced datasets.

## Method Summary
The method introduces a three-parameter sampling space (α, β, γ) that interpolates between original distribution and balanced distribution across privilege group balance, label balance, and relative favorable-label rates between privilege groups. A two-level grid search (Level 0: 0.1 intervals, Level 1: 0.01 intervals around top candidates) identifies Pareto-optimal trade-offs between fairness (DI Ratio) and classification accuracy (MCC). The approach is model-agnostic and can be composed with existing in-processing debiasing methods. Experiments use the BAF fraud detection dataset with age-based sensitive attribute (old ≥50 = unprivileged).

## Key Results
- The three-parameter sampling approach achieves DI Ratio improvements from 1.18 to 0.96 when combined with LFR, while MCC improves from 0.1063 to 0.1160
- Pareto front analysis reveals a trade-off between fairness and accuracy, with the proposed method achieving significant improvements on both metrics compared to baselines
- The method successfully handles doubly imbalanced datasets where existing approaches fail, producing non-NaN DI Ratio values where LFR alone produces NaN
- Grid search optimization identifies optimal parameter combinations (α, β, γ) that balance fairness and accuracy for different classifiers

## Why This Works (Mechanism)

### Mechanism 1: Three-Parameter Sampling Space Decomposition
- **Claim:** The double imbalance problem can be decomposed into three orthogonal controllable dimensions that jointly determine the distribution of the four data partitions (privileged/unprivileged × favorable/unfavorable).
- **Mechanism:** Parameters α, β, and γ interpolate between original distribution and balanced distribution across three axes: (α) privilege group balance, (β) label balance, and (γ) the relative favorable-label rates between privilege groups. This parameterization ensures monotonic movement from original imbalance toward balance while preserving structural constraints.
- **Core assumption:** The optimal fairness-accuracy trade-off lies somewhere between the original imbalanced distribution and complete balance; extreme rebalancing (50/50 on all axes) is not assumed optimal.
- **Evidence anchors:**
  - Equation 6 defines P', F', A' as linear interpolations controlled by α, β, γ with bounds in [0,1]
  - Restrictions 1-6 (Equation 3) formalize constraints preventing role-reversal and ensuring monotonic improvement
  - Related work on subgroup fairness addresses multiple sensitive attributes but not the joint label-group imbalance decomposition
- **Break condition:** If the optimal solution consistently sits at boundary values (α, β, γ ∈ {0, 1}) across diverse datasets, the interpolation space may be misspecified or constraints too tight

### Mechanism 2: Two-Level Grid Search with Pareto Front Characterization
- **Claim:** A coarse-to-fine grid search over (α, β, γ) can locate Pareto-optimal trade-offs between fairness (DI Ratio) and classification accuracy (MCC) without requiring gradient information.
- **Mechanism:** Level 0 search samples the parameter space at 0.1 intervals, identifying top-k candidates. Level 1 refines around these candidates at 0.01 intervals. The combined loss (c₁·MCC_loss + c₂·DI_loss) guides selection, but the full Pareto front reveals trade-off structure, enabling practitioners to choose operating points based on domain requirements.
- **Core assumption:** The fairness-accuracy landscape is sufficiently smooth that local refinement around Level 0 candidates improves solutions; discontinuities or multimodality could cause Level 1 to miss global optima.
- **Evidence anchors:**
  - Section 5.2 describes the two-level grid search with intervals of 0.1 (Level 0) and 0.01 (Level 1)
  - "Experiments on fraud detection datasets demonstrate significant improvements in both fairness and accuracy compared to baseline methods, with Pareto front analysis showing the trade-off"
  - Corpus lacks direct comparisons to gradient-based or Bayesian optimization for this specific problem; efficiency claims are relative to naive baselines
- **Break condition:** If Level 1 consistently fails to improve upon Level 0 (or degrades results), the parameter space may have sharp optima or the discretization is too coarse

### Mechanism 3: Model-Agnostic Pre-Processing for Compatibility with Existing Debiasing Methods
- **Claim:** The sampling-based approach can be composed with in-processing debiasing methods (e.g., LFR) to achieve additive or synergistic fairness improvements.
- **Mechanism:** By rebalancing the training data distribution before model training, the method addresses the root cause of why existing debiasing methods fail on doubly imbalanced data—namely, that methods like LFR cannot learn meaningful fair representations when minority (fraud + unprivileged) instances are vanishingly rare. The preprocessing creates a feasible optimization landscape for downstream methods.
- **Core assumption:** The failure of LFR and similar methods on doubly imbalanced data is primarily due to data distribution rather than fundamental algorithmic limitations.
- **Evidence anchors:**
  - Table 4 shows LFR produces NaN DI Ratio on privilege-balanced and double-imbalanced setups (failure to detect any fraud)
  - Table 8 shows LFR combined with proposed method achieves DI Ratio 0.96 (acceptable range) vs. 1.18 without
  - Controlled Model Debiasing paper addresses incremental updates but assumes a reasonably balanced starting point; corpus evidence for compositionality is limited
- **Break condition:** If downstream debiasing methods fail to improve (or worsen) results when applied after sampling, the methods may be optimizing conflicting objectives or overcorrecting

## Foundational Learning

- **Concept: Disparate Impact (DI) Ratio**
  - **Why needed here:** The primary fairness metric being optimized. Measures whether the rate of unfavorable predictions differs between privileged and unprivileged groups. Values in [0.8, 1.2] are typically considered acceptable.
  - **Quick check question:** If a model predicts "fraud" for 5% of privileged applicants but 15% of unprivileged applicants, what is the DI Ratio? (Answer: 0.15/0.05 = 3.0, indicating bias against unprivileged group)

- **Concept: Matthews Correlation Coefficient (MCC)**
  - **Why needed here:** Chosen over F1 or accuracy because it remains informative under severe class imbalance by accounting for all four confusion matrix cells.
  - **Quick check question:** Why would F1 score be misleading for a fraud dataset with 1% fraud prevalence where a model predicts "not fraud" for everyone? (Answer: F1 for the minority class would be undefined/zero, but accuracy would be 99%, masking the failure)

- **Concept: Pareto Front**
  - **Why needed here:** The solution explicitly frames fairness-accuracy optimization as multi-objective; the Pareto front characterizes the achievable trade-off frontier.
  - **Quick check question:** If point A has (DI_loss=0.1, MCC_loss=0.3) and point B has (DI_loss=0.2, MCC_loss=0.15), which is Pareto-dominated? (Answer: Neither—A is better on fairness, B on accuracy; both are on the Pareto front if no other point improves both)

## Architecture Onboarding

- **Component map:**
  ```
  Original Dataset D
       ↓
  [Parameterized Sampler] ← (α, β, γ) from Grid Search
       ↓
  Sampled Dataset D'
       ↓
  [Train/Val/Test Split]
       ↓
  [Classifier Training] — LR, RF, SVM, NB, or LFR
       ↓
  [Evaluation] → DI Ratio, MCC, Combined Loss
       ↓
  [Pareto Front Construction]
  ```

- **Critical path:**
  1. Identify sensitive attribute and privilege/unprivileged split (domain-dependent)
  2. Characterize original imbalance ratios for labels and groups
  3. Implement sampling constraints (Equations 3-8) ensuring valid D' for any (α, β, γ)
  4. Run two-level grid search with combined loss (c₁=c₂=1 as default)
  5. Extract Pareto front and select operating point based on domain requirements

- **Design tradeoffs:**
  - **Grid granularity vs. compute:** 0.1/0.01 intervals balance precision with feasibility; finer grids increase cost by O(n³) for three parameters
  - **Undersampling vs. information loss:** Method uses undersampling to meet ratios; synthetic oversampling (SMOTE) could preserve more data but introduces distributional assumptions
  - **Model-specific vs. universal parameters:** Optimal (α*, β*, γ*) vary by classifier (Table 7); practitioners must rerun grid search when changing models

- **Failure signatures:**
  - NaN DI Ratio: Model predicts zero unfavorable labels for privileged group (divide-by-zero); indicates insufficient unfavorable-label sampling
  - MCC near -1 or 0 with high accuracy: Model predicts only majority class; increase β (label balancing)
  - Pareto front is a single point: No trade-off exists; either constraint space too narrow or objectives perfectly aligned/conflicting
  - Level 1 grid search degrades Level 0 results: Optimization landscape has sharp local minima; consider random restarts or Bayesian optimization

- **First 3 experiments:**
  1. **Baseline characterization:** Run basic classifiers (LR, RF, SVM, NB) on original doubly imbalanced data to establish DI Ratio and MCC baselines (expect NaN or severely biased results per Table 3)
  2. **Ablation on parameter dimensions:** Fix two of (α, β, γ) at 0 and sweep the third to isolate individual effects of group-balancing, label-balancing, and favorable-rate-balancing
  3. **Pareto front validation:** For a single classifier (recommend RF), run full two-level grid search, plot Pareto front, and verify that Combined Loss minima lie on the front (sanity check for Equation 13)

## Open Questions the Paper Calls Out
None

## Limitations
- The method's effectiveness is demonstrated primarily on fraud detection datasets; generalizability to other domains with different imbalance patterns remains untested
- The choice of MCC as primary accuracy metric, while appropriate for imbalanced data, may not capture all aspects of classification performance relevant to practitioners
- The assertion that the method can be composed with existing in-processing debiasing approaches lacks extensive empirical support beyond the LFR example

## Confidence
- **High confidence**: The three-parameter sampling framework is mathematically sound and the grid search methodology is well-specified
- **Medium confidence**: The effectiveness claims are supported by experiments on the BAF dataset but lack external validation on diverse domains
- **Low confidence**: The assertion that the method can be composed with existing in-processing debiasing approaches lacks extensive empirical support beyond the LFR example

## Next Checks
1. **Domain generalization test**: Apply the method to a non-fraud dataset (e.g., COMPAS criminal justice data) with different imbalance characteristics to verify robustness
2. **Pareto front stability analysis**: Run multiple random seeds for the same experimental setup to quantify variance in Pareto front locations and solution quality
3. **Alternative optimization methods**: Compare the two-level grid search against Bayesian optimization or evolutionary algorithms on computational efficiency and solution quality