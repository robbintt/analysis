---
ver: rpa2
title: Comparative Explanations via Counterfactual Reasoning in Recommendations
arxiv_id: '2510.10920'
source_url: https://arxiv.org/abs/2510.10920
tags:
- counterfactual
- explanations
- recommendation
- item
- items
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes CoCountER, a comparative counterfactual explanation
  method for recommendations. It addresses factual inaccuracies in prior approaches
  by introducing a swap-based counterfactual operation that enables explanation generation
  for arbitrary pairs of comparative items.
---

# Comparative Explanations via Counterfactual Reasoning in Recommendations

## Quick Facts
- arXiv ID: 2510.10920
- Source URL: https://arxiv.org/abs/2510.10920
- Reference count: 33
- Primary result: CoCountER improves Probability of Necessity (PN) by 42-49% and Probability of Sufficiency (PS) by 5-7% compared to CountER baseline

## Executive Summary
This paper proposes CoCountER, a comparative counterfactual explanation method for recommendations that addresses factual inaccuracies in prior approaches. The method introduces swap-based counterfactual operations enabling explanation generation for arbitrary pairs of comparative items, formulated as an optimization problem minimizing swap operations to reverse item rankings. Experiments on three Amazon review datasets show CoCountER outperforms baselines in counterfactual metrics and achieves better Precision and Recall than matching-based and sorting-based approaches.

## Method Summary
CoCountER creates counterfactual explanations through soft swap operations between aspect values of recommended and reference items. The method constructs user-aspect attention and item-aspect quality matrices from review data, trains a differentiable recommendation model, then optimizes swap variables to reverse the relative ranking with minimal intervention. Explanations are extracted as aspects where swap values exceed a threshold, ensuring the resulting comparisons accurately reflect why one item is preferred over another.

## Key Results
- CoCountER improves Probability of Necessity (PN) by 42-49% compared to CountER baseline
- Probability of Sufficiency (PS) improves by 5-7% over CountER
- Better Precision and Recall than matching-based (EFM, A2CF) and sorting-based baselines
- Performance improves with lower-ranked reference items but degrades with too many references due to noise

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Swap-based counterfactual operations generate more faithful comparative explanations than reduction-based approaches by preserving factual accuracy in pairwise item comparisons.
- Mechanism: Instead of reducing aspect values toward an aggregated decision boundary (which can produce factually incorrect explanations), CoCountER performs soft swap operations between aspect values of the recommended item and a reference item. The optimization identifies which aspects, when swapped, reverse the relative ranking with minimal intervention. This ensures explanations reflect actual comparative advantages rather than potentially misleading absolute thresholds.
- Core assumption: Users find explanations more trustworthy when they accurately reflect why item A is preferred over item B, rather than why item A exceeds some global threshold.
- Evidence anchors:
  - [abstract]: "CoCountER creates counterfactual data based on soft swap operations, enabling explanations for recommendations of arbitrary pairs of comparative items."
  - [section]: Figure 2 demonstrates that swapping price values between Headphones A and B reverses their ranking, identifying price as the explanatory factor—a comparison that reduction-based methods would miss.
  - [corpus]: Related work on comparative explanations (Yang et al., WWW 2022, found via corpus search) supports comparative framing but uses autoregressive text generation rather than counterfactual reasoning.
- Break condition: If the recommended item is genuinely inferior to the reference item across all aspects, no swap operation can validly reverse the ranking without introducing factual inaccuracies.

### Mechanism 2
- Claim: Formulating explanation generation as a constrained optimization problem over differentiable swap variables enables gradient-based identification of minimal causal interventions.
- Mechanism: The swap operation uses sigmoid functions to create continuous variables ψ ∈ [0,1] where values near 0 indicate no swap and values near 1 indicate full swap. This differentiable formulation allows the objective (minimize swaps subject to ranking reversal) to be optimized via stochastic gradient descent with automatic differentiation. The L1 norm ||σ(ψ)||₁ encourages sparsity, while the margin ranking loss enforces the counterfactual constraint.
- Core assumption: The underlying recommendation model g_θ is differentiable with respect to item aspect features, allowing gradients to flow through the swap operations.
- Evidence anchors:
  - [section]: Equation 5 defines the soft swap function; Equations 9-10 derive the gradient update rules showing how ψ_a is updated based on both sparsity and ranking loss terms.
  - [section]: Section 3.2 explicitly states the optimization formulation: "minimize Σ swap variables subject to r*_{u,i} < r*_{u,j}"
  - [corpus]: "Counterfactual Language Reasoning for Explainable Recommendation Systems" (arXiv:2503.08051) addresses counterfactual reasoning but decouples explanation from recommendation generation, violating causal precedence—highlighting the importance of integrated optimization.
- Break condition: Non-differentiable recommendation models (e.g., tree-based recommenders) would require alternative optimization strategies such as reinforcement learning or discrete search methods.

### Mechanism 3
- Claim: The position and quantity of reference items directly affect explanation quality through their influence on optimization constraint tightness.
- Mechanism: When the reference item is ranked much lower than the recommended item, the constraint (reverse ranking) is easier to satisfy, allowing more aspects to qualify as valid counterfactuals. Conversely, comparing to a highly similar item creates a tighter constraint, potentially yielding fewer but more discriminative explanations. Multiple reference items increase recall by providing diverse comparative contexts, though with diminishing returns and added noise.
- Core assumption: Users benefit from understanding how a recommended item compares to specific alternatives rather than receiving a single aggregate explanation.
- Evidence anchors:
  - [section]: Section 3.4 states "lower-ranked reference items yield more potential explanations" and Figure 3(a) shows PN and PS improve as reference position decreases.
  - [section]: Figure 3(b) shows performance initially improves with more reference items then slightly declines due to noise.
  - [corpus]: Limited corpus evidence on reference item selection strategies; related papers focus on explanation generation rather than reference selection heuristics.
- Break condition: Using too many low-ranked reference items may generate explanations that are technically valid but practically irrelevant (comparing to items users would never consider).

## Foundational Learning

- **Counterfactual Reasoning in ML**
  - Why needed here: CoCountER is built on counterfactual logic—"what minimal change would reverse this decision?"—requiring understanding of intervention, necessity, and sufficiency.
  - Quick check question: Given that a user was recommended item A over item B, what does it mean for aspect X to be "necessary" vs "sufficient" for this recommendation?

- **Constrained Optimization with Lagrangian Formulation**
  - Why needed here: The method formalizes explanation generation as minimizing swap operations subject to ranking reversal, using a Lagrangian objective combining L1 sparsity with margin ranking loss.
  - Quick check question: How does increasing λ (the scaling factor balancing sparsity vs constraint satisfaction) affect the tradeoff between fewer swaps and successful ranking reversal?

- **Aspect-Based Recommender Systems**
  - Why needed here: The method operates on user-aspect attention matrices X and item-aspect quality matrices Y, requiring understanding of how these representations are constructed from review data.
  - Quick check question: Given Equation 1, how would increasing the scaling factor N affect the range of user attention scores X_{u,a}?

## Architecture Onboarding

- **Component map:**
  1. Sentiment Analysis Module (Sentires) -> Feature Engineering -> Black-box Recommendation Model g_θ -> Reference Item Selector -> Swap Optimization Module -> Explanation Extractor

- **Critical path:**
  1. Preprocess data: Run Sentires on review corpus → aspect-sentiment lexicon
  2. Build matrices: Compute X and Y per Equation 1 (handle unmentioned aspects as 0)
  3. Train recommender: Fit g_θ with cross-entropy loss, 1:2 positive:negative sampling
  4. For each (user, recommended item) pair:
     - Select reference items J = {j : r_{u,j} < r_{u,i}}
     - For each j ∈ J: initialize ψ, optimize Equation 7
     - If ranking successfully reversed, extract aspects with σ(ψ_a) > 0.5
  5. Aggregate explanations across all reference items

- **Design tradeoffs:**
  - **Reference item position**: Lower-ranked references → more explanations but potentially less meaningful comparisons
  - **Number of reference items**: More references → higher recall but increased computation and noise
  - **Margin threshold m**: Larger m → easier optimization but risk of missing tight counterfactuals
  - **Model choice**: Paper uses simple MLP for g_θ; more complex models (GNN, transformers) may improve recommendation accuracy but complicate gradient computation

- **Failure signatures:**
  - **Empty explanation set**: Reference item too similar to recommended item OR margin m too large OR λ too small (constraint not enforced)
  - **Excessive explanations (low precision)**: Reference item ranked too low (overly unconstrained) OR λ too large (sparsity penalty weak)
  - **Optimization divergence**: Learning rate η too high; try reducing by 10x
  - **Ranking not reversed**: Margin m too small OR recommendation model gradients vanishing; check gradient norms during optimization
  - **Factual inaccuracies persist**: Verify swap function Equation 5 correctly implemented (both items must be updated symmetrically)

- **First 3 experiments:**
  1. **Baseline replication on single dataset**: Implement CoCountER on Amazon Electronics, compare PN/PS against CountER, EFM, A2CF to validate implementation correctness (target: PN improvement ~42%+ per Table 2)
  2. **Reference position ablation**: Fix number of references at 5, vary reference rank position from 2 to 50; plot PN and PS to identify optimal position range (expect monotonic improvement per Figure 3a)
  3. **Hyperparameter sensitivity on λ**: Test λ ∈ {0.1, 1.0, 10.0, 100.0} on CDs & Vinyl dataset; measure tradeoff between average number of explanations per item and ranking reversal success rate

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can counterfactual reasoning be effectively integrated with generative models to produce fluent natural language explanations?
- Basis in paper: [explicit] The conclusion explicitly states: "Future work will explore integrating counterfactual reasoning with generative models to produce natural language explanations of counterfactual scenarios."
- Why unresolved: The current CoCountER framework outputs discrete aspect sets (e.g., "price", "comfort") rather than generating readable text sentences describing the counterfactual logic.
- What evidence would resolve it: A model architecture that successfully maps CoCountER's aspect interventions into coherent natural language text, validated by human evaluation for fluency and logic.

### Open Question 2
- Question: What is the optimal strategy for selecting reference items to balance explanation diversity against computational noise?
- Basis in paper: [inferred] Section 3.4 and 4.2.2 discuss how the position and number of reference items affect results, noting that while more references improve recall, excessive references introduce noise.
- Why unresolved: The paper empirically tests fixed ranges but does not propose an automated, adaptive heuristic for selecting the single best reference item or optimal subset for a specific user-item pair.
- What evidence would resolve it: An algorithm that dynamically selects reference items based on user context and demonstrates higher Probability of Necessity (PN) with lower computational cost than the current brute-force approach.

### Open Question 3
- Question: Can the framework be generalized to incorporate counterfactual operations beyond "soft swaps," such as feature addition or deletion?
- Basis in paper: [explicit] Section 3.4 states: "future research may explore incorporating various operations into counterfactual frameworks to enhance their versatility and effectiveness."
- Why unresolved: The current method relies solely on swapping values between items, which assumes a comparative context where values exist to be exchanged, potentially missing cases where features should be removed entirely.
- What evidence would resolve it: An extended optimization objective including addition/deletion operators that identifies necessary explanations in sparse data environments where swaps are impossible.

## Limitations

- Empirical validation confined to three Amazon product categories with short reviews (49-60 words)
- Method requires differentiable recommendation models, excluding tree-based or ensemble approaches
- Reference item selection strategy uses simple ranking without considering item similarity or user intent

## Confidence

- **High confidence**: The swap-based counterfactual mechanism is well-supported by both theoretical formulation and empirical results showing 42-49% PN improvement over CountER.
- **Medium confidence**: The constrained optimization formulation is mathematically sound, but assumes the recommendation model's gradients remain stable during counterfactual optimization - this could break for deeper networks or non-differentiable components.
- **Medium confidence**: The reference item position effects are empirically validated, but the tradeoff between explanation quantity and quality lacks formal characterization beyond the observed diminishing returns.

## Next Checks

1. **Robustness to recommendation model complexity**: Test CoCountER with a deeper MLP (5+ layers) and a non-differentiable baseline (e.g., LightFM) to verify gradient stability and identify necessary adaptations.
2. **Cross-domain generalization**: Apply CoCountER to datasets with longer reviews (e.g., Yelp, TripAdvisor) and measure whether the 42-49% PN improvement persists when aspect extraction must handle more complex language.
3. **Human evaluation of factual accuracy**: Conduct user studies comparing explanations from CoCountER versus reduction-based methods, specifically measuring perceived factual correctness and trustworthiness when aspect values are altered through swapping versus aggregation.