---
ver: rpa2
title: Scalable Linearized Laplace Approximation via Surrogate Neural Kernel
arxiv_id: '2601.21835'
source_url: https://arxiv.org/abs/2601.21835
tags:
- kernel
- neural
- surrogate
- training
- jacobian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces ScaLLA, a scalable approximation to the Linearized
  Laplace Approximation (LLA) that learns a surrogate neural network to emulate the
  Neural Tangent Kernel (NTK) without explicitly computing large Jacobians. This approach
  enables efficient Bayesian uncertainty estimation in large-scale deep neural networks
  by leveraging Jacobian-vector products and compact feature representations.
---

# Scalable Linearized Laplace Approximation via Surrogate Neural Kernel

## Quick Facts
- arXiv ID: 2601.21835
- Source URL: https://arxiv.org/abs/2601.21835
- Authors: Luis A. Ortega; Simón Rodríguez-Santana; Daniel Hernández-Lobato
- Reference count: 7
- Primary result: A scalable approximation to Linearized Laplace Approximation (LLA) that learns a surrogate neural network to emulate the Neural Tangent Kernel (NTK) without explicit Jacobian computation.

## Executive Summary
This paper introduces ScaLLA, a method for scalable Bayesian uncertainty estimation in large-scale deep neural networks. ScaLLA approximates the Linearized Laplace Approximation by learning a surrogate neural network to emulate the Neural Tangent Kernel (NTK) without explicitly computing large Jacobians. The approach leverages efficient Jacobian-vector products and compact feature representations to achieve competitive accuracy, calibration, and predictive likelihood while significantly improving out-of-distribution detection.

## Method Summary
ScaLLA approximates LLA's kernel by training a surrogate network g_ϕ(x) to match the NTK structure computed via Jacobian-vector products (JVPs). The surrogate learns compact features whose inner products approximate the projected statistics of the true NTK. During training, batches combine training samples with context points sampled from an auxiliary dataset resembling evaluation data. A bias variant zeroes cross-covariances between training and context points to enforce stronger out-of-distribution uncertainty. The method achieves scalability by computing JVPs in O(P) rather than O(CP) complexity, where P is parameter count and C is output dimension.

## Key Results
- Achieves 91.03% accuracy on FMNIST
- Maintains excellent calibration with ECE 0.008
- Delivers strong predictive likelihood (NLL 0.2528)
- Significantly improves OOD detection (AUC 0.982) when using biased kernel

## Why This Works (Mechanism)

### Mechanism 1
The surrogate network approximates the NTK without explicit Jacobian computation by matching Jacobian-vector product (JVP) statistics. For any random vector v with zero mean and unit covariance, E[J_θ*(x)v(J_θ*(x')v)^T] = J_θ*(x)J_θ*(x')^T = K_NTK(x,x'). The surrogate g_ϕ(x) learns compact features (m ≪ P) whose inner products match these projected statistics, trained via L(ϕ) = E[||g_ϕ(x)g_ϕ(x')^T - z_v(x)z_v(x')^T||²]. Rademacher projections reduce variance compared to Gaussian. The core assumption is that NTK structure is learnable through random projections with sufficient surrogate capacity.

### Mechanism 2
Context points enable the surrogate kernel to generalize to regions beyond the training manifold, including OOD areas. During training, inputs concatenate training samples with context points X_batch = [X_train; X_context]. The surrogate minimizes ||K - Q||² over this extended set, forcing g_ϕ to approximate LLA variances across both in-distribution and OOD regions simultaneously. The core assumption is that context points meaningfully represent the evaluation/OOD distribution and the surrogate can interpolate between training and context regions.

### Mechanism 3
Zeroing cross-covariances between training and context points enforces a "back-to-prior" behavior that amplifies OOD uncertainty. Setting K_ij^ab = 0 when x_i ∈ X_train, x_j ∈ X_context creates block-diagonal covariance, asserting statistical independence between distributions. OOD inputs (similar to context) then yield higher posterior variance while in-distribution calibration remains stable. The core assumption is that training and OOD data should be modeled as independent without corrupting in-distribution predictions.

## Foundational Learning

- Concept: **Linearized Laplace Approximation (LLA)**
  - Why needed here: ScaLLA approximates LLA's kernel; understanding the parent method clarifies what's being approximated and why the kernel matters for uncertainty.
  - Quick check question: Can you explain why LLA uses a first-order Taylor expansion around MAP weights and how the GGN matrix relates to posterior covariance?

- Concept: **Neural Tangent Kernel (NTK)**
  - Why needed here: The surrogate explicitly learns to replicate K_NTK(x,x') = J_θ*(x)J_θ*(x')^T; without this concept, the training objective is opaque.
  - Quick check question: What does the NTK capture about a neural network's local behavior, and why does its structure determine LLA predictive variance?

- Concept: **Jacobian-Vector Products (JVPs) via Automatic Differentiation**
  - Why needed here: ScaLLA's scalability hinges on computing J_θ*(x)v without materializing J_θ*(x); this is the core efficiency gain.
  - Quick check question: Given a function f: R^P → R^C, why is computing Jv for a random v typically O(P) rather than O(CP)?

## Architecture Onboarding

- Component map: Pre-trained DNN (f_θ*) -> Surrogate network (g_ϕ) -> Projection sampler -> Kernel comparator -> Context dataset

- Critical path:
  1. Sample batch X_batch = [X_train; X_context]
  2. For each x, compute JVP z_v(x) using Rademacher v
  3. Form kernel K_ij = z_v(x_i)z_v(x_j)^T
  4. Compute surrogate features g_ϕ(x_i), form Q_ij = g_ϕ(x_i)g_ϕ(x_j)^T
  5. If biasing: zero K entries crossing train/context
  6. Backprop through ||K - Q||² to update ϕ
  7. At inference, use g_ϕ(x*)g_ϕ(x*)^T for predictive variance

- Design tradeoffs:
  - Surrogate dimensionality (m): Larger m improves approximation but increases memory/compute. Paper uses m=100 per class.
  - Biasing vs. unbiased kernel: Biasing dramatically improves OOD (AUC 0.982 vs. 0.784) but requires representative context points.
  - Rademacher vs. Gaussian projections: Rademacher has lower variance (Eq. 6); paper uses Rademacher.

- Failure signatures:
  - OOD AUC ≈ in-distribution baseline: Context points likely unrepresentative; check alignment between context and actual OOD.
  - Training instability: JVP variance may be high; increase projection samples or check surrogate capacity.
  - Degraded in-distribution calibration: Over-biasing or context leakage; verify block-diagonal masking is correct.

- First 3 experiments:
  1. Sanity check: On a small MLP (P < 10K), compare ScaLLA's learned kernel against explicit NTK computation; verify ||K_NTK - g_ϕg_ϕ^T|| converges.
  2. Ablation on context selection: Run FMNIST→KMNIST with (a) MNIST context, (b) random noise context, (c) no context; measure OOD AUC gap.
  3. Scaling test: Fix m=100, vary backbone size from small CNN to ResNet-50; measure memory usage and wall-clock time per training step to confirm sub-linear scaling.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can optimal context points be selected for biasing the learned kernel when the target OOD distribution is unknown at training time?
- Basis in paper: Section 2.4 states "since OOD samples are not available during training, finding a suitable dataset of context points can be challenging in practice."
- Why unresolved: The paper acknowledges this dependency but does not propose a systematic method for context point selection beyond using an auxiliary dataset.
- What evidence would resolve it: A principled framework or heuristic for context point selection that maintains OOD detection performance across varied OOD types without requiring prior knowledge of the test distribution.

## Limitations
- Base architecture specification is not provided, making exact replication impossible without architectural tuning.
- Hyperparameter sensitivity exists due to unspecified learning rate, batch size, projection count, and training duration for the surrogate.
- Context point selection impact is not systematically analyzed across different distributions.

## Confidence
- **High confidence**: The core mechanism of using JVPs to approximate NTK without explicit Jacobian computation is mathematically sound and empirically validated on FMNIST.
- **Medium confidence**: The biasing technique for improved OOD detection is novel but lacks corpus validation; effectiveness depends heavily on context point quality.
- **Medium confidence**: The computational scaling claims are supported by the O(P) complexity argument, but actual wall-clock benchmarks across diverse architectures are not provided.

## Next Checks
1. **Architecture ablation**: Reproduce results on both small (P < 10K) and large (P > 100K) networks to verify sub-linear scaling and kernel approximation quality.
2. **Context sensitivity analysis**: Systematically vary context point distributions (random noise, overlapping, disjoint) to quantify impact on OOD detection performance.
3. **Cross-dataset generalization**: Apply ScaLLA to CIFAR-10 → CIFAR-100 OOD task to test robustness beyond FMNIST/KMNIST domain.