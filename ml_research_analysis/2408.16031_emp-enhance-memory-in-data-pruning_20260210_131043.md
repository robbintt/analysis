---
ver: rpa2
title: 'EMP: Enhance Memory in Data Pruning'
arxiv_id: '2408.16031'
source_url: https://arxiv.org/abs/2408.16031
tags:
- pruning
- data
- learning
- memory
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a data pruning method called EMP to address
  the issue of insufficient model memory under high pruning rates. The key insight
  is that traditional pruning methods based on sample loss lead to Low-Frequency Learning
  (LFL), where samples are not trained enough times to be effectively learned by the
  model.
---

# EMP: Enhance Memory in Data Pruning

## Quick Facts
- arXiv ID: 2408.16031
- Source URL: https://arxiv.org/abs/2408.16031
- Reference count: 40
- Key outcome: +2.2% accuracy on CIFAR100 with 70% pruning vs state-of-the-art

## Executive Summary
This paper proposes EMP, a data pruning method that addresses insufficient model memory under high pruning rates. Traditional loss-based pruning creates Low-Frequency Learning (LFL), where samples are trained too few times to be effectively memorized. EMP adds a memory term to the scoring function, encouraging the model to remember important samples. The memory term differs for supervised learning (SL) and self-supervised learning (SSL). In SL, it's based on mutual information between model weights and samples; in SSL, it's based on similarity of hidden layer representations of positive pairs. EMP significantly outperforms existing methods at high pruning rates across image classification, NLU, and model pre-training tasks.

## Method Summary
EMP enhances model memory in data pruning by adding a memory term to the sample scoring function. For supervised learning, the scoring function is `score = loss + β*H(f(x,θ))` where H is entropy of model outputs, encouraging selection of samples that maximize mutual information with model weights. For self-supervised learning, the scoring function is `score = NT-Xent - β*||f(x_i)-f(x_j)||₂` where f represents hidden layer representations and the L2 distance measures similarity between positive pairs. The method uses dynamic pruning at checkpoints with an annealing phase that trains on the full dataset for the final portion of training. The memory term counteracts Low-Frequency Learning by ensuring samples receive repeated exposure needed for memorization.

## Key Results
- CIFAR100-ResNet18: +2.2% accuracy at 70% pruning (76.2% vs 74.0% for InfoBatch)
- CIFAR100-ResNet50: +2.5% accuracy at 70% pruning (78.6% vs 76.1% for InfoBatch)
- ImageNet-1K: +1.4% accuracy at 70% pruning (73.6% vs 72.2% for InfoBatch)
- GLUE benchmark: Improved performance across all tasks at 30% pruning
- SimCLR pre-training: Improved performance across all downstream tasks at 30% pruning

## Why This Works (Mechanism)

### Mechanism 1
Traditional loss-based pruning creates Low-Frequency Learning (LFL), preventing samples from being trained enough times to be memorized. At each checkpoint, high-loss samples are selected, but gradient descent reduces their losses, causing them to be pruned in the next round. This creates uniform, low-frequency training across samples, denying the repeated exposure required for memorization.

### Mechanism 2
Adding a mutual-information-derived memory term to the scoring function enhances model memory in supervised learning. The scoring function `score(x, y) = L(x, y, θ) + βH(f(x, θ))` balances sample loss with conditional entropy of model output. Higher entropy outputs indicate samples that strengthen weight-label mutual information, serving as a memory signal.

### Mechanism 3
In self-supervised contrastive learning, memory can be enhanced by measuring representation similarity between positive sample pairs. The scoring function `score(x) = NX(g(f(x_i)), g(f(x_j))) - β||f(x_i) - f(x_j)||₂` combines NT-Xent loss with L2 distance between encoder hidden representations. When the model remembers a sample, representations of augmented views converge, reducing distance.

## Foundational Learning

- **Cross-entropy decomposition**: The theoretical foundation relies on decomposing CE(D, θ) = H(Y|X) - I(θ;Y|X) + E[KL] to identify that loss-based selection minimizes I(θ;Y|X), reducing memory. *Quick check*: If selecting high-loss samples minimizes I(θ;Y|X), what does Theorem 1 predict about training accuracy bounds?

- **Mutual information in neural networks**: The memory term is derived from I(θ;Y|X), quantifying how much information model weights encode about labels. *Quick check*: Why is directly computing I(θ;Y|X) intractable, and what approximation does EMP use?

- **Contrastive learning fundamentals**: EMP's SSL variant requires understanding NT-Xent loss, positive/negative pairs, and why pre-projection representations are preferred. *Quick check*: In SimCLR, the projection head g(·) is discarded after pre-training. Why might f(x) contain more "memorable" information than g(f(x))?

## Architecture Onboarding

- **Component map**: Scoring module -> Pruning scheduler -> Memory term estimator -> Annealing controller
- **Critical path**: 1) Initialize: Train epoch 0 on full dataset D 2) Score computation: For each epoch t > 0, compute scores using current θ 3) Selection: Retain top (1-s)% samples as Dt 4) Training: Update θ on Dt 5) Annealing phase: In final α×T epochs, train on full D
- **Design tradeoffs**: β (memory weight) optimally at 5; lower values approach LFL behavior, higher values over-prioritize easy samples. Annealing fraction α improves final accuracy but adds training cost; EMP is more robust to low α than LFL methods. Dynamic pruning avoids proxy model overhead but requires per-epoch scoring.
- **Failure signatures**: Performance matching random pruning → β too low or memory term not computing correctly. Sharp accuracy drop in late training without annealing → indicates insufficient early/mid-phase memorization. Retaining noisy samples at high rates → loss-only scoring without memory term. Class imbalance in retained subset → expected behavior; paper shows enforcing balance degrades performance.
- **First 3 experiments**: 1) β sensitivity analysis: On CIFAR100-ResNet18 at 70% pruning, sweep β ∈ {1, 3, 5, 7, 10} to validate optimal region; expect peak near β=5 with degradation at extremes. 2) Annealing ablation: Compare EMP vs InfoBatch with/without annealing at 50-90% pruning rates on CIFAR10; expect EMP to show smaller accuracy drop when annealing disabled. 3) Label noise robustness: Inject 20% random label noise; compare EMP vs UCB/Greedy on CIFAR10 at 70% pruning; expect EMP to maintain performance while loss-only methods degrade by retaining noisy samples.

## Open Questions the Paper Calls Out
1. **Question**: How do memory mechanisms and optimal memory terms differ across various layers of a neural network or structurally distinct model architectures?
   - **Basis**: The authors explicitly state this is a future research direction in the "Limitations and Future Works" section.
   - **Why unresolved**: The current implementation applies a unified scoring function across the network, failing to account for findings that shallow layers learn general knowledge while deeper layers handle task-specific memory.
   - **What evidence would resolve it**: A study demonstrating layer-specific EMP variants that outperform the uniform approach.

2. **Question**: How can data pruning performance be stabilized in Self-Supervised Learning (SSL) under extreme pruning rates (e.g., >90%)?
   - **Basis**: In Section 3.4, the paper notes that performance drops sharply when the approximation in Equation (11) fails under extreme pruning.
   - **Why unresolved**: The authors currently disregard a computationally expensive term for efficiency, an approximation that fails when the dataset is reduced drastically.
   - **What evidence would resolve it**: An updated SSL pruning algorithm that effectively estimates the neglected term, showing maintained accuracy at extreme pruning rates.

3. **Question**: Is the conditional entropy H(Y|X) a sufficiently tight lower bound for the mutual information I(θ; Y|X) to act as the optimal memory term for all supervised learning tasks?
   - **Basis**: The paper derives the memory term by establishing I(θ; Y|X) ≥ H(Y|X), effectively using conditional entropy as a proxy.
   - **Why unresolved**: While mathematically valid, the gap between the bound and the actual mutual information might vary across datasets.
   - **What evidence would resolve it**: A comparative analysis where the memory term is calculated using more complex mutual information estimators versus the proposed entropy approximation.

## Limitations
- The SSL memory term approximation degrades at extreme pruning rates (>90%), causing training instability.
- The method requires computing entropy or representation distances at each checkpoint, adding computational overhead.
- Class imbalance naturally emerges in retained subsets without explicit balancing, though the paper shows balancing degrades performance.

## Confidence
- Experimental methodology: High
- Theoretical foundation: Medium
- Reproducibility of results: Medium
- Generalizability across tasks: High

## Next Checks
1. Verify β=5 sensitivity on CIFAR100-ResNet18 at 70% pruning to confirm optimal performance range.
2. Implement and test the annealing phase with varying α values to determine its impact on final accuracy.
3. Conduct a controlled experiment with injected label noise to validate EMP's robustness compared to loss-only methods.