---
ver: rpa2
title: Knowledge Graph Fusion with Large Language Models for Accurate, Explainable
  Manufacturing Process Planning
arxiv_id: '2506.13026'
source_url: https://arxiv.org/abs/2506.13026
tags:
- knowledge
- graph
- drill
- size
- machining
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents ARKNESS, a hybrid framework that fuses automatically
  constructed knowledge graphs with large language models to deliver precise, traceable
  answers for CNC process planning. By distilling heterogeneous machining documents
  into semantically rich triples and retrieving context-aware subgraphs, ARKNESS addresses
  hallucinations and missing provenance in LLMs.
---

# Knowledge Graph Fusion with Large Language Models for Accurate, Explainable Manufacturing Process Planning

## Quick Facts
- **arXiv ID:** 2506.13026
- **Source URL:** https://arxiv.org/abs/2506.13026
- **Reference count:** 40
- **Key outcome:** Hybrid KG-LLM framework ARKNESS matches GPT-4o accuracy with 3B Llama-3, reducing hallucinations by 22 pp and enabling on-prem deployment for CNC process planning.

## Executive Summary
This paper introduces ARKNESS, a hybrid framework that fuses automatically constructed knowledge graphs with large language models to deliver precise, traceable answers for CNC process planning. By distilling heterogeneous machining documents into semantically rich quadruples (subject, relation, object, description) and retrieving context-aware subgraphs, ARKNESS addresses hallucinations and missing provenance in LLMs. Experiments on 155 industry-curated questions show that a lightweight 3B-parameter Llama-3 augmented with ARKNESS matches GPT-4o accuracy, achieving up to +25 percentage points in multiple-choice accuracy, +22.4 pp in F1-score, and 8.1× ROUGE-L in open-ended responses. The framework enables smaller models to run fully on-premise, reducing hallucinations by 22 pp and supporting privacy-preserving, real-time shop-floor inference.

## Method Summary
ARKNESS operates through a pipeline: heterogeneous CNC documents (PDFs, manuals, G-code) are parsed with Docling into Markdown; GPT-4o extracts entity-relation quadruples with verbatim context; PostgreSQL stores triples in hierarchical tables; semantic embeddings retrieve Top-K relevant triples via cosine similarity; beam search expands context to depth d_max; retrieved subgraph is injected into LLM prompt alongside system instructions and query. The framework was tested on 155 questions (65 content MC, 45 machining MC, 104 content open-ended, 45 machining open-ended) using models including Llama-3.2-3B, Llama-3.1-8B, Qwen-2.5-7B, GPT-4o/mini, and Gemini-2.0-Flash/Lite. Final KG contains 4,329 triples, 6,659 entities, and 1,251 relations.

## Key Results
- +25 percentage points accuracy improvement for multiple-choice questions
- +22.4 pp F1-score gains and 8.1× ROUGE-L improvement in open-ended responses
- 22 percentage point reduction in numeric hallucinations (e.g., drill sizes)
- 3B Llama-3 with ARKNESS matches GPT-4o accuracy on CNC process planning tasks

## Why This Works (Mechanism)

### Mechanism 1: Context-Preserving Triple Extraction
Augmenting standard entity-relation triples with verbatim textual descriptions preserves domain context that vanilla KGs lose, enabling more accurate retrieval for precision-critical queries. A zero-shot LLM extracts (subject, relation, object, description) quadruples from heterogeneous documents, storing the original text snippet alongside each triple. This retained context disambiguates relations like "requires" that would otherwise lack tool-material-tolerance specificity.

### Mechanism 2: Beam-Search Graph Traversal for Context Expansion
Expanding retrieval beyond top-K nearest triples via beam search captures multi-hop dependencies required for machining-specific quantitative queries. Initial top-K triples are selected via cosine similarity, then beam search recursively explores adjacent triples up to depth d_max, selecting top-b candidates per node. This retrieves connected context (e.g., tool → material → speed recommendations) that isolated triples miss.

### Mechanism 3: Grounded Prompting Reduces Numeric Hallucination
Injecting retrieved triples with provenance into the LLM prompt constrains numeric outputs to grounded values, reducing hallucination rates by ~22 percentage points. Retrieved subgraphs are formatted as context and concatenated with system instructions and the user query. The LLM generates answers conditioned on this explicit evidence, shifting from plausible ranges to precise values.

## Foundational Learning

- **Knowledge Graph Triple Structure**: ARKNESS stores domain knowledge as (subject, relation, object, description) tuples; understanding this representation is prerequisite to debugging retrieval failures.
  - Quick check: Given "5-axis CNC milling machine tool — performs — MILLING, DRILLING, CUTTING," what is the subject, relation, and object?

- **Cosine Similarity for Semantic Retrieval**: Retrieval ranks triples by embedding similarity to the query; misalignment between query phrasing and triple language causes retrieval misses.
  - Quick check: If a query uses "spindle rpm" but triples store "spindle speed," will cosine similarity reliably match them? Why or why not?

- **Beam Search in Graphs**: ARKNESS expands retrieval via beam search; understanding tradeoffs between beam width, depth, and computational cost is essential for tuning.
  - Quick check: Increasing beam width from b=3 to b=10 will likely ___ recall and ___ latency. (Fill in: increase/decrease)

## Architecture Onboarding

- **Component map**: Document Ingestion (Docling → Markdown) -> Triple Extraction (GPT-4o) -> Graph Storage (PostgreSQL) -> Embedding Layer -> Retrieval Engine (Top-K + beam search) -> Prompt Compiler -> LLM Generator
- **Critical path**: Document quality → Extraction accuracy → Graph coverage → Retrieval relevance → Prompt grounding → Answer precision. Breaks at extraction or retrieval cause cascading failures.
- **Design tradeoffs**: Depth d_max: Higher improves machining-specific recall but adds latency and noise for content queries; Beam width b: Wider beams explore more paths but increase compute; Top-K: More initial triples improve coverage but may dilute relevance; Model size: Smaller models (3B) gain most from KG augmentation but may mishandle complex context formatting
- **Failure signatures**: Retrieval returns irrelevant triples → check embedding quality, query-triple vocabulary mismatch; LLM ignores context → verify prompt formatting, context window limits, instruction clarity; Numeric answers still hallucinated → confirm KG contains relevant parameter tables; F1 drops with augmentation → reduce context volume or simplify formatting
- **First 3 experiments**:
  1. Ablation on depth: Run content vs. machining queries at depths 0, 1, 2 with fixed Top-K=10, beam=3. Confirm depth 0 optimal for content, depth 2 for machining.
  2. Graph completeness test: Randomly drop 25%, 50%, 75% of triples and measure accuracy degradation. Expect linear decline for machining queries, flat for content.
  3. Hallucination audit: Select 10 numeric questions; compare baseline vs. KG-augmented outputs against ground truth. Count correct values, broad ranges, and outright errors.

## Open Questions the Paper Calls Out

- **How does extending ARKNESS to heterogeneous multimodal knowledge graphs affect the accuracy of process planning for complex geometries?**: The conclusion states future work will focus on "extending ARKNESS to a heterogeneous multimodal knowledge graphs." The current implementation relies solely on textual data and does not integrate visual models or sensor telemetry.

- **What architectural modifications are required to transition ARKNESS from static retrieval to real-time, closed-loop decision support?**: The authors list enabling "closed-loop decision support in advanced manufacturing environments" as a future objective. The current framework demonstrates high accuracy on static benchmarks but lacks a mechanism for ingesting live shop-floor data to update the graph dynamically.

- **To what extent do extraction errors in the zero-shot graph construction phase propagate into the final answers provided by smaller models?**: The paper claims reduced hallucinations via retrieval, but relies on GPT-4o to build the KG without validating the fidelity of the extracted triples. If the "zero-shot" extraction step hallucinates false relations, the retrieval mechanism will ground the smaller LLM in incorrect "facts."

## Limitations

- Embedding model unspecified: The paper states retrieval uses cosine similarity between query and triple embeddings but does not specify which embedding model was used.
- Benchmark data unavailable: The 155 CNC machining questions and ground-truth answers are not publicly released, making independent validation impossible.
- Document ingestion quality unclear: While Docling is specified for parsing, no evaluation of how well it handles CNC-specific formatting is provided.

## Confidence

- **High confidence**: The +25 percentage point accuracy improvement for multiple-choice questions and +22.4 pp F1-score gains are directly supported by Tables 3-6 showing baseline vs. KG-augmented outputs.
- **Medium confidence**: The 22 percentage point hallucination reduction is based on comparing numeric answers between baseline and KG-augmented models, though the exact hallucination counting methodology isn't fully specified.
- **Low confidence**: The optimal retrieval configuration (Top-K=10, depth=0, beam=5) is presented as a general recommendation, but Figure 4 shows significant variation by question type that isn't resolved in the paper.

## Next Checks

1. Reproduce depth ablation study: Run content and machining queries at depths 0, 1, 2 with fixed Top-K=10, beam=3. Verify depth 0 optimal for content, depth 2 for machining (per Figure 4).
2. Graph completeness sensitivity: Randomly drop 25%, 50%, 75% of triples and measure accuracy degradation. Confirm linear decline for machining queries, flat for content (per Figure 5).
3. Hallucination type audit: Select 10 numeric questions; compare baseline vs. KG-augmented outputs against ground truth. Count correct values, broad ranges, and outright errors using Tables 3-6 methodology.