---
ver: rpa2
title: 'VADIS: A Visual Analytics Pipeline for Dynamic Document Representation and
  Information-Seeking'
arxiv_id: '2504.05697'
source_url: https://arxiv.org/abs/2504.05697
tags:
- document
- relevance
- attention
- documents
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents VADIS, a visual analytics pipeline designed
  to address key challenges in biomedical information-seeking. The main challenges
  addressed are: (1) static document embeddings that cannot adapt to user interests,
  (2) inability to effectively display document relevance to user queries, and (3)
  lack of interpretability in embedding generation.'
---

# VADIS: A Visual Analytics Pipeline for Dynamic Document Representation and Information-Seeking

## Quick Facts
- **arXiv ID**: 2504.05697
- **Source URL**: https://arxiv.org/abs/2504.05697
- **Reference count**: 40
- **Key outcome**: Introduces VADIS, a visual analytics pipeline with Prompt-based Attention Model (PAM) for dynamic document embeddings, achieving 70.1% Top 10 accuracy and 79.6% Top 20 accuracy on emrQA dataset

## Executive Summary
VADIS addresses critical challenges in biomedical information-seeking by introducing dynamic document embeddings that adapt to user queries. The system combines a Prompt-based Attention Model (PAM) with novel visualization techniques to provide both relevance and interpretability. Through a relevance-preserving circular grid layout and corpus-level attention visualization, VADIS enables users to iteratively explore document collections while understanding why certain documents are retrieved. The system demonstrates strong performance on biomedical datasets and provides practical value for domain experts in research contexts.

## Method Summary
VADIS implements a three-stage visual analytics pipeline consisting of embedding generation, mapping, and visualization. The core innovation is the Prompt-based Attention Model (PAM), which generates dynamic document embeddings based on user-provided prompts rather than static pre-trained embeddings. The system uses a circular grid layout where relevance scores determine position and semantic similarity determines angular placement. A corpus-level attention visualization displays attention weights across all document embeddings, providing interpretability. The pipeline supports iterative exploration by allowing users to refine prompts and update visualizations dynamically, creating an interactive information-seeking experience.

## Key Results
- PAM achieves 70.1% Top 10 accuracy and 79.6% Top 20 accuracy on emrQA biomedical dataset
- Relevance-preserving mapping achieves silhouette score of 0.33 for clustering quality
- Clustering accuracy (ARI) improves from 0.26 to 0.71 when using population-based prompts
- Case study with domain experts demonstrates practical usability in ADHD research

## Why This Works (Mechanism)
VADIS works by bridging the gap between static document representations and dynamic user needs through prompt-conditioned embeddings. The PAM model captures query-specific relevance while preserving semantic relationships between documents. The circular grid layout effectively encodes two dimensions of information (relevance and similarity) in a single visualization, while the attention visualization provides transparency into the embedding generation process. The iterative exploration framework allows users to refine their information-seeking strategy based on system feedback, creating a feedback loop that improves retrieval quality over time.

## Foundational Learning

**Prompt-based Attention Model**: Learns to generate document embeddings conditioned on user prompts, enabling dynamic adaptation to information needs. *Why needed*: Static embeddings cannot capture query-specific relevance. *Quick check*: Compare retrieval accuracy with and without prompt conditioning.

**Relevance-preserving Mapping**: Combines relevance scores and semantic similarity into a single visualization space using circular layout. *Why needed*: Traditional methods show either relevance or similarity, not both. *Quick check*: Verify that highly relevant documents appear near the center while semantically similar documents cluster together.

**Corpus-level Attention Visualization**: Displays attention weights across all document embeddings to explain retrieval decisions. *Why needed*: Black-box models lack transparency needed for trust in critical domains. *Quick check*: Confirm attention weights correlate with human judgments of document relevance.

## Architecture Onboarding

**Component Map**: User Query -> PAM Model -> Document Embeddings -> Circular Grid Layout -> Visualization + Attention Map -> User Feedback Loop

**Critical Path**: The PAM model serves as the critical component, as all downstream visualization and exploration depends on its ability to generate relevant embeddings. Any failure in prompt processing or embedding generation cascades through the entire pipeline.

**Design Tradeoffs**: The system prioritizes interpretability over pure retrieval performance, using attention visualization that may add computational overhead but provides crucial transparency. The circular layout balances visual clarity with information density, though it may become cluttered with large document collections.

**Failure Signatures**: Poor prompt formulation leads to irrelevant document retrieval; insufficient attention visualization makes it difficult to understand retrieval decisions; large document collections may cause visual clutter in the circular layout.

**First Experiments**: 
1. Test PAM with simple single-word prompts to verify basic functionality
2. Validate circular grid layout with known document clusters
3. Evaluate attention visualization accuracy against human relevance judgments

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies primarily on quantitative metrics and a single case study, limiting real-world validation
- Performance metrics suggest room for improvement compared to established information retrieval systems
- Domain-specific validation with biomedical experts may limit generalizability to other fields

## Confidence

**High confidence**: The technical architecture of VADIS and the PAM model are clearly described and implementable

**Medium confidence**: The visualization techniques (circular grid layout, corpus-level attention) are novel but require further empirical validation

**Medium confidence**: The evaluation results are promising but based on limited datasets and user studies

## Next Checks

1. Conduct a controlled user study with multiple domain experts comparing VADIS against existing information retrieval systems on benchmark datasets

2. Test the system's generalizability by applying it to non-biomedical domains and measuring performance degradation

3. Perform longitudinal analysis to evaluate how well the system supports complex multi-step information-seeking tasks over extended periods