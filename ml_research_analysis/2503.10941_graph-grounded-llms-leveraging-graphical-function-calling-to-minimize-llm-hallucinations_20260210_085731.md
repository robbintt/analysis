---
ver: rpa2
title: 'Graph-Grounded LLMs: Leveraging Graphical Function Calling to Minimize LLM
  Hallucinations'
arxiv_id: '2503.10941'
source_url: https://arxiv.org/abs/2503.10941
tags:
- graph
- function
- llms
- tasks
- node
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of Large Language Models (LLMs)
  suffering from hallucinations and mathematical inaccuracies when applied to graph-related
  tasks. The proposed solution, Graph-Grounded LLMs, integrates a graph library with
  the function-calling capabilities of LLMs, allowing the model to offload graph computations
  and iteratively construct graphs through closed-loop function calls.
---

# Graph-Grounded LLMs: Leveraging Graphical Function Calling to Minimize LLM Hallucinations

## Quick Facts
- arXiv ID: 2503.10941
- Source URL: https://arxiv.org/abs/2503.10941
- Reference count: 32
- Key outcome: Graph-Grounded LLMs achieve near 100% accuracy on most graph reasoning tasks by grounding LLMs with a function-calling interface to a graph library.

## Executive Summary
This paper addresses the persistent problem of LLM hallucinations in graph-related tasks by proposing Graph-Grounded LLMs, a method that integrates a graph library with LLM function-calling capabilities. Instead of attempting to solve graph problems entirely through reasoning, the LLM plans and iteratively constructs graphs by calling external graph functions in a closed loop. Evaluation on the NLGraph benchmark shows dramatic accuracy improvements across eight graph reasoning tasks, with near-perfect performance on most tasks. The approach also demonstrates practical robustness in a disaster response application where the system dynamically re-plans based on changing conditions.

## Method Summary
The approach builds a graph library with 29 functions using networkx and provides JSON function descriptions to the LLM as callable tools. The LLM uses 0-shot chain-of-thought reasoning to plan and invoke functions via closed-loop calls, with a function manager executing the calls and returning outputs for iterative reasoning. This offloads computational graph operations to the library while the LLM handles high-level planning and integration. The system was evaluated using gpt-4-0613 on the NLGraph benchmark containing 6,022 problems across eight tasks including connectivity, cycle detection, topological sort, shortest path, maximum flow, bipartite matching, Hamilton path, and GNN message passing.

## Key Results
- Graph-Grounded LLMs achieve near 100% accuracy on most graph reasoning tasks compared to significantly lower performance from standalone LLMs
- The approach demonstrates robustness in a disaster response application with dynamic replanning based on changing environmental conditions
- The system successfully handles tasks ranging from basic connectivity checks to complex operations like maximum flow and Hamilton path detection

## Why This Works (Mechanism)
The method works by separating concerns: the LLM handles high-level planning and reasoning while offloading precise graph computations to a specialized library. This prevents the LLM from hallucinating mathematical or structural details while still leveraging its planning capabilities. The closed-loop function calling allows iterative refinement and error correction during problem solving.

## Foundational Learning
- Graph reasoning benchmarks (why needed: provides standardized evaluation; quick check: examine NLGraph task diversity)
- Function calling APIs (why needed: enables LLM-tool integration; quick check: verify JSON schema format)
- Closed-loop reasoning (why needed: allows iterative refinement; quick check: trace function call sequences)
- Graph library implementation (why needed: provides computational accuracy; quick check: validate networkx function coverage)
- Chain-of-thought prompting (why needed: guides planning process; quick check: review prompt templates)
- Token limit management (why needed: prevents context overflow; quick check: monitor token usage per query)

## Architecture Onboarding

Component map: NLGraph problem -> LLM planning -> Function manager -> Graph library -> Results -> LLM refinement

Critical path: Problem statement → LLM planning (via CoT) → Function selection → Execution → Result integration → Next planning step

Design tradeoffs:
- Static library vs. dynamic generation: Static provides reliability but limits adaptability
- Full tool loading vs. retrieval: Full loading ensures availability but hits token limits
- Open-weight vs. proprietary models: Open models offer transparency but may sacrifice accuracy

Failure signatures:
- Function selection errors: LLM picks wrong similar function (e.g., Hamilton path instead of topological sort)
- Context overflow: Token limits exceeded on large graphs
- Iterative loop failure: Function calls don't converge to solution

First experiments:
1. Test function selection accuracy on simple NLGraph tasks with minimal graphs
2. Verify closed-loop execution works by tracing a complete solution from start to finish
3. Measure token usage and identify breaking points for context limits

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can an LLM autonomously generate, modify, and integrate new functions into the graph library to adapt to novel problem types?
- Basis in paper: The authors state in the Future Work section that they "aim to investigate automated graph library modifications and function additions by the LLM, enabling it to adapt and expand its capabilities over time."
- Why unresolved: The current implementation relies on a static, user-built library of 29 functions; the system cannot yet write or debug its own computational tools.
- What evidence would resolve it: A demonstration where the system successfully identifies a missing operation, writes the code for it, and utilizes it to solve a subsequent problem without human intervention.

### Open Question 2
- Question: How does integrating Retrieval-Augmented Generation (RAG) for dynamic tool selection impact the accuracy and latency of the closed-loop function calling process?
- Basis in paper: The authors note context length limitations with large libraries and propose exploring "retrieval-augmented generation to dynamically select a relevant subset of tools based on the graph problem" as future work.
- Why unresolved: The current system loads tool descriptions into the context window, which limits scalability; the trade-offs between retrieving tools versus full loading remain untested.
- What evidence would resolve it: A comparative study evaluating task accuracy and computation time when using a RAG-based tool selector versus the current static loading method on a large-scale library.

### Open Question 3
- Question: What mechanisms can effectively mitigate function misuse when natural language prompts are ambiguous or overlap with similar graph operations?
- Basis in paper: The paper analyzes failure cases where the LLM misused similar functions (calling Hamilton Path instead of Topological Sort) due to ambiguous problem phrasing, noting the model is "highly sensitive to problem prompts."
- Why unresolved: The current solution relies on manual prompt engineering to disambiguate tasks, rather than a robust architectural safeguard against semantic confusion.
- What evidence would resolve it: An experiment showing improved robustness to ambiguous prompts using semantic verification or automated prompt clarification strategies compared to the baseline.

## Limitations
- Complete function list and JSON schema descriptions are not provided, creating implementation uncertainty
- Evaluation relies entirely on proprietary gpt-4-0613, limiting generalization to open-weight models
- Token limits may constrain handling of very large graphs or extensive libraries

## Confidence

High confidence in core technical contribution: using function calling to offload graph computations is a sound and practical approach that demonstrably reduces hallucinations.

Medium confidence in quantitative claims: given that exact prompts and complete function schemas are not provided, making exact replication uncertain.

Medium confidence in real-world application results: as the disaster response case study provides only high-level description without detailed evaluation metrics or system specifications.

## Next Checks

1. Obtain and analyze the NLGraph benchmark from Wang et al. [25] to understand the exact task formulations and expected outputs for each of the 8 graph reasoning problems.

2. Reconstruct the complete JSON function description schema for all 29 graph library functions by reverse-engineering from the single example provided and typical networkx API patterns.

3. Implement a baseline evaluation using a smaller open-weight model (such as Llama-3-8B) with the same graph library to test whether the approach's effectiveness depends on model size/capability or is a general function-calling pattern.