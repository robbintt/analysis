---
ver: rpa2
title: 'Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual
  Storytelling'
arxiv_id: '2602.02453'
source_url: https://arxiv.org/abs/2602.02453
tags:
- reasoning
- visual
- comic
- comics
- thinking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Thinking with Comics (TwC), a visual reasoning
  paradigm that uses comics as an intermediate medium positioned between static images
  and videos. Comics are leveraged for their ability to encode temporal structure,
  embedded text, and narrative coherence while avoiding the redundancy and high computational
  cost of videos.
---

# Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling

## Quick Facts
- **arXiv ID**: 2602.02453
- **Source URL**: https://arxiv.org/abs/2602.02453
- **Reference count**: 40
- **Primary result**: Comics achieve 85.8% on MathVista, outperforming Thinking with Images and Thinking with Video by leveraging temporal structure and embedded text.

## Executive Summary
This paper introduces Thinking with Comics (TwC), a visual reasoning paradigm that uses comics as an intermediate medium positioned between static images and videos. Comics are leveraged for their ability to encode temporal structure, embedded text, and narrative coherence while avoiding the redundancy and high computational cost of videos. The approach is instantiated through two paths: (1) end-to-end comic generation as the reasoning process, and (2) comics used as conditioning context for a vision-language model. Evaluated across reasoning tasks (MATH500, GSM8K, MathVista) and context understanding tasks (DocVQA, CulturalBench), TwC achieves 85.8% accuracy on MathVista and 99.4% on DocVQA, outperforming both Thinking with Images and Thinking with Video. Ablation studies show that narrative style, panel count, temporal sequence, and embedded text significantly influence performance. TwC offers a cost-efficient, structured, and interpretable alternative for multimodal reasoning.

## Method Summary
TwC uses comics as an intermediate representation for multimodal reasoning, instantiated through two inference paths. Path I generates comics end-to-end and extracts answers from the final panel using an external model. Path II generates comics and conditions a vision-language model with both the question and comic for reasoning. The method relies on narrative styles (detective, slice-of-life, documentary) and panel counts (4-6 optimal) to structure temporal reasoning. Generation uses Gemini-3 Pro Image, with answer extraction via GPT-5.2 (Path I) or Gemini-3 Pro (Path II). The approach is evaluated zero-shot on reasoning and context understanding benchmarks.

## Key Results
- TwC achieves 85.8% accuracy on MathVista reasoning benchmark
- 99.4% accuracy on DocVQA visual context understanding
- Outperforms Thinking with Images and Thinking with Video across all tested tasks
- Detective narrative style shows +28.5% average improvement over documentary style

## Why This Works (Mechanism)

### Mechanism 1: Temporal Structure Compression
Comics preserve reasoning-critical temporal dependencies while avoiding video's redundancy by discretizing continuous temporal trajectories into key states. Sequential panels retain causal structure via panel ordering while eliminating redundant frames that provide diminishing marginal information.

### Mechanism 2: Textual Anchoring for Semantic Disambiguation
Embedded text in comics (bubbles, narration) reduces cross-modal semantic ambiguity by providing an explicit semantic channel that supplements pure visual information, reducing the search space for correct solutions.

### Mechanism 3: Narrative Structure as Implicit Prompt Engineering
Role-playing narrative styles (detective, slice-of-life) function as visual system prompts that activate specific reasoning pathways. Narrative conventions carry domain-specific priors—detective frames emphasize causal deduction, slice-of-life grounds abstract concepts in familiar scenarios.

## Foundational Learning

- **Chain-of-Thought (CoT) Reasoning**
  - Why needed here: TwC extends CoT from text to visual domain—understanding intermediate reasoning steps is prerequisite.
  - Quick check question: Can you explain why explicit intermediate steps improve reasoning over direct answers?

- **Information Bottleneck Principle**
  - Why needed here: Comics are formulated as a compressed intermediate representation that maximizes task-relevant information I(a;z|q) while minimizing generation cost C(z).
  - Quick check question: Why might a compressed representation outperform a more detailed one for reasoning tasks?

- **Multimodal Alignment**
  - Why needed here: The paradigm relies on text-visual coherence within panels and cross-panel consistency.
  - Quick check question: What failure modes occur when visual and textual modalities are misaligned?

## Architecture Onboarding

- **Component map:** Question → Image Generator → Comic Panels → Answer Extractor/Reasoning Model → Final Answer
- **Critical path:**
  1. Comic generation quality (structural completeness, panel consistency)
  2. Cross-panel temporal coherence maintenance
  3. Text-visual anchoring accuracy within panels
  4. Answer extraction reliability (Path I) or MLLM reasoning integration (Path II)

- **Design tradeoffs:**
  - Path I vs Path II: Path I is cheaper (single generation model) but reasoning capacity limited by generator; Path II adds MLLM reasoning flexibility at ~2x inference cost
  - Panel count (N): N=4-6 is Pareto optimal; N<4 loses temporal structure, N>6 adds redundancy
  - Narrative style: Task-dependent; detective for logic, slice-of-life for grounded problems, cultural-context for understanding tasks

- **Failure signatures:**
  - Layout collapse: Multi-step prompt generates merged/collapsed panels instead of discrete sequence
  - Entity drift: Characters/elements inconsistent across panels
  - Textual grounding failure: Bubbles/narration misaligned with visual action
  - Temporal incoherence: Panel order violates causal logic

- **First 3 experiments:**
  1. Baseline replication on MathVista/GSM8K: Compare TwC (both paths) against TWI and direct MLLM inference; measure accuracy and token/latency cost to validate efficiency claims
  2. Panel ablation study: Systematically vary N ∈ {1,2,4,6,8} on held-out reasoning tasks to identify task-specific optimal panel counts and validate scaling behavior
  3. Narrative style transfer test: Apply detective/slice-of-life/documentary styles to same problem set; quantify style-task alignment to determine if narrative effects generalize beyond tested benchmarks

## Open Questions the Paper Calls Out
None

## Limitations
- Comic representation may lose critical information for tasks requiring fine-grained motion analysis or continuous dynamics
- Narrative style effects may be task-specific and brittle, with no evidence of generalizability beyond tested benchmarks
- The paper assumes Gemini-3 Pro's ability to consistently generate structurally sound comics but does not systematically measure generation failure rates

## Confidence

- **High Confidence**: Efficiency claims (token/latency cost comparison with TWI and TWV) and baseline performance comparisons on standard benchmarks
- **Medium Confidence**: Temporal compression mechanism and its submodular diminishing-returns property—supported by ablation studies but requires broader task validation
- **Low Confidence**: Narrative style as Visual System Prompt hypothesis—strong performance gains but no mechanistic explanation or generalization testing

## Next Checks

1. **Fine-Grained Motion Analysis Test**: Apply TwC to a benchmark requiring continuous motion tracking (e.g., physics simulations or trajectory prediction) to test whether the comic representation loses critical information that videos preserve. Measure accuracy degradation and identify failure patterns.

2. **Narrative Style Transfer Robustness**: Take problems where detective style shows superior performance and systematically apply all three narrative styles (detective, slice-of-life, documentary) across diverse reasoning tasks. Quantify whether style-task alignment is consistent or brittle, and test whether narrative effects transfer to novel problem types.

3. **Generation Quality Assessment**: Systematically measure comic generation failure modes across 100+ diverse problems: quantify layout collapse frequency, entity drift consistency, and textual grounding accuracy. Correlate generation quality metrics with downstream reasoning performance to determine whether observed accuracy gains are limited by generation reliability rather than reasoning capability.