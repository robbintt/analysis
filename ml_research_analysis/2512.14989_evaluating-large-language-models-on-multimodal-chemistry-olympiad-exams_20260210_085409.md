---
ver: rpa2
title: Evaluating Large Language Models on Multimodal Chemistry Olympiad Exams
arxiv_id: '2512.14989'
source_url: https://arxiv.org/abs/2512.14989
tags:
- national
- reasoning
- chemistry
- local
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates 40 multimodal large language models on a benchmark
  of Olympiad-style chemistry problems, USNCO-V, revealing significant limitations
  in scientific reasoning despite advances in generic multimodal understanding. Chain-of-Thought
  prompting markedly improves accuracy and interpretability, shifting models from
  pattern matching to structured, comparative reasoning.
---

# Evaluating Large Language Models on Multimodal Chemistry Olympiad Exams

## Quick Facts
- arXiv ID: 2512.14989
- Source URL: https://arxiv.org/abs/2512.14989
- Authors: Yiming Cui; Xin Yao; Yuxuan Qin; Xin Li; Shijin Wang; Guoping Hu
- Reference count: 40
- 40 multimodal LLMs evaluated on USNCO-V, a benchmark of Olympiad-style chemistry problems

## Executive Summary
This study evaluates 40 multimodal large language models on USNCO-V, a benchmark of 473 Olympiad-style chemistry problems with visual components. Chain-of-Thought prompting significantly improves accuracy and interpretability, shifting models from pattern matching to structured, comparative reasoning. The research reveals that while generic multimodal understanding has advanced, scientific reasoning remains challenging, with smaller models sometimes performing better when visual input is removed. Occlusion-based saliency analysis demonstrates that CoT prompts models to attend to chemically relevant features more systematically.

## Method Summary
The evaluation uses the USNCO-V dataset containing 473 multiple-choice chemistry problems with text, images, and four answer options. Models are tested using zero-shot, few-shot (1-5 examples), and Chain-of-Thought prompting strategies. Proprietary models use API inference with 5 runs per condition, while open-source models use greedy decoding on A100/H100 GPUs. Ablation studies systematically remove question text, choices, or images to assess modality importance. Occlusion-based saliency analysis measures attention shifts when CoT prompting is applied.

## Key Results
- Chain-of-Thought prompting significantly improves accuracy and shifts reasoning from pattern matching to structured comparison
- Visual input can hinder performance for smaller models, indicating misaligned vision-language integration
- Mid-tier models gain the most from CoT scaffolding compared to few-shot prompting
- CoT prompts systematic attention to chemically relevant features versus localized pattern matching

## Why This Works (Mechanism)
None

## Foundational Learning
- **Multimodal reasoning**: Understanding how models integrate text and visual information in scientific domains. Why needed: USNCO-V problems require both chemical knowledge and interpretation of molecular structures, charts, and apparatus. Quick check: Verify models can correctly answer simple chemistry questions with and without images.
- **Chain-of-Thought prompting**: Structured reasoning approach that breaks problems into step-by-step analysis. Why needed: Moves models beyond pattern matching to systematic problem decomposition. Quick check: Compare accuracy on simple vs complex chemistry problems with and without CoT.
- **Occlusion-based saliency analysis**: Method to identify which image regions models attend to during reasoning. Why needed: Reveals whether models focus on chemically relevant features versus superficial patterns. Quick check: Manually verify saliency maps highlight expected chemical structures or data points.

## Architecture Onboarding

**Component map**: Data extraction -> Prompt template generation -> Model inference -> Result validation -> Statistical analysis -> Saliency analysis

**Critical path**: Image extraction and transcription → Unified prompt template → Model inference pipeline → Accuracy computation with Wilson CI → Statistical significance testing

**Design tradeoffs**: The study prioritizes interpretability through CoT over raw accuracy, accepting potential computational overhead for better reasoning insights. Proprietary model access limits transparency but enables testing cutting-edge systems.

**Failure signatures**: Invalid model outputs (non A-D responses) indicate prompt parsing failures; image degradation for small models suggests vision-language misalignment; inconsistent results across runs suggest temperature or implementation issues.

**3 first experiments**:
1. Run zero-shot baseline on a small subset of 10 questions across 5 models to verify pipeline functionality
2. Test CoT prompting on 5 simple chemistry problems to confirm reasoning improvement
3. Perform image ablation on 5 small models to verify the degradation pattern

## Open Questions the Paper Calls Out
None

## Limitations
- Proprietary model API implementations are opaque, making it unclear whether improvements stem from genuine reasoning or internal heuristics
- Manual transcription from historical PDFs introduces potential transcription errors and inconsistencies
- Ablation findings showing image removal sometimes improves performance lack full characterization of when visual information helps versus hurts
- Saliency analysis provides qualitative insights but lacks quantitative validation against ground truth chemical relevance

## Confidence

**High confidence**: Baseline finding that most models struggle without CoT prompting; statistical significance of accuracy improvements; well-specified metadata and evaluation methodology.

**Medium confidence**: Comparative effectiveness of prompting strategies across model tiers; saliency findings about attention pattern shifts (due to exemplar selection and prompt variations not fully specified).

**Low confidence**: Claims about specific nature of reasoning improvements and whether gains reflect genuine scientific reasoning versus pattern matching.

## Next Checks
1. Replicate ablation findings across model tiers by systematically testing image/mode removal on a representative subset of models to confirm consistency and identify thresholds for multimodal benefit
2. Validate saliency analysis with ground truth by manually annotating sample questions with chemically relevant features and computing quantitative correlation with occlusion-identified regions
3. Test prompt sensitivity by running controlled experiments varying CoT phrasing and few-shot exemplar selection on 2-3 key models to establish robustness of prompting improvements