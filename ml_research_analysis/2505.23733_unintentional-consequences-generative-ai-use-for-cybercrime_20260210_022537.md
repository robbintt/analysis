---
ver: rpa2
title: 'Unintentional Consequences: Generative AI Use for Cybercrime'
arxiv_id: '2505.23733'
source_url: https://arxiv.org/abs/2505.23733
tags:
- time
- malicious
- these
- genai
- cybercrime
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study investigates the unintended consequences of generative
  AI democratization on cybercrime. The authors employ affordance theory and technological
  amplification to theorize how generative AI enables cybercriminals, then empirically
  test this framework using interrupted time series analysis of two large datasets:
  464,190,074 malicious IP reports from AbuseIPDB and 281,115 cryptocurrency scam
  reports from Chainabuse.'
---

# Unintentional Consequences: Generative AI Use for Cybercrime

## Quick Facts
- arXiv ID: 2505.23733
- Source URL: https://arxiv.org/abs/2505.23733
- Authors: Truong Jack Luu; Binny M. Samuel
- Reference count: 0
- This study finds statistically significant increases in reported cybercrime following the public release of ChatGPT 3.0, with immediate and sustained growth in malicious IP reports and cryptocurrency scams.

## Executive Summary
This study investigates how the democratization of generative AI technologies has unintentionally enabled and amplified cybercrime activities. Using affordance theory and technological amplification as theoretical frameworks, the authors empirically test whether the public release of ChatGPT 3.0 (November 30, 2022) led to measurable increases in cybercrime. The research employs interrupted time series analysis on two large datasets: 464,190,074 malicious IP reports from AbuseIPDB and 281,115 cryptocurrency scam reports from Chainabuse, examining patterns before and after the ChatGPT release intervention point.

The findings demonstrate that generative AI has created new action possibilities for cybercriminals while magnifying existing criminal capabilities at scale. The study reveals immediate increases in reported cybercrime incidents following ChatGPT's public release, with an immediate jump of over 1.12 million weekly malicious IP reports and about 722 weekly cryptocurrency scam reports, accompanied by sustained growth in cryptocurrency-related scams. These results suggest that generative AI democratization has created an unintended amplification effect on cybercrime, enabling both new forms of attacks and scaling existing ones.

## Method Summary
The authors employ affordance theory and technological amplification frameworks to theorize how generative AI enables cybercriminals, then empirically test this framework using interrupted time series analysis. They analyze two large datasets: 464,190,074 malicious IP reports from AbuseIPDB and 281,115 cryptocurrency scam reports from Chainabuse. The public release of ChatGPT 3.0 (November 30, 2022) serves as the intervention point, with analysis comparing cybercrime patterns before and after this date to identify statistically significant changes in reporting rates.

## Key Results
- Immediate increase of over 1.12 million weekly malicious IP reports following ChatGPT 3.0 release
- Sustained increase of approximately 722 weekly cryptocurrency scam reports
- Statistical significance in both immediate and sustained growth patterns across both datasets

## Why This Works (Mechanism)
The study demonstrates that generative AI amplifies malicious intent at scale by creating new affordances for cybercriminals while magnifying existing criminal capabilities. The technology provides new action possibilities that lower barriers to entry for cybercrime activities and enable scaling of existing attack vectors. The interrupted time series analysis captures the causal impact of AI democratization on cybercrime patterns by establishing a clear temporal relationship between ChatGPT's public release and subsequent increases in malicious activities.

## Foundational Learning
- **Affordance Theory**: Understanding how technology creates new action possibilities - needed to explain how generative AI enables new forms of cybercrime
- **Technological Amplification**: Framework for understanding how technology magnifies existing capabilities - needed to explain scaling effects on traditional cybercrime
- **Interrupted Time Series Analysis**: Statistical method for evaluating intervention effects - needed to establish causal relationship between ChatGPT release and cybercrime increases
- **Secondary Data Analysis**: Using existing databases for research - needed to leverage large-scale cybercrime reporting data
- **Causal Attribution Challenges**: Limitations in observational studies - needed to understand why specific AI-generated attribution is uncertain

## Architecture Onboarding
**Component Map**: ChatGPT release -> Cybercrime reporting patterns -> Statistical analysis
**Critical Path**: Public release of generative AI → Increased malicious activity → Reporting database updates → Statistical detection of change points
**Design Tradeoffs**: Observational data provides real-world evidence but lacks controlled conditions; large datasets offer statistical power but may contain reporting biases
**Failure Signatures**: Inability to distinguish AI-generated vs. traditional cybercrime; potential confounding from other concurrent cybersecurity developments
**First Experiments**: 1) Analyze temporal patterns in specific attack types before and after ChatGPT release; 2) Compare reporting rates across different geographic regions; 3) Test robustness using alternative intervention points

## Open Questions the Paper Calls Out
None

## Limitations
- Observational data from secondary sources may contain reporting biases
- Cannot distinguish between AI-generated and traditionally generated cybercrime incidents
- Focuses only on publicly reported incidents, missing unreported activities

## Confidence
- High confidence in statistical methodology and data analysis techniques
- Medium confidence in causal relationship between ChatGPT release and cybercrime increases
- Low confidence in specific attribution of increased reports to AI-generated content

## Next Checks
1. Conduct natural language analysis of reported incidents to identify AI-generated patterns
2. Expand analysis to include additional cybercrime reporting databases and timeframes
3. Perform controlled experiment comparing AI-generated vs. traditional cybercrime indicators