---
ver: rpa2
title: 'HiWave: Training-Free High-Resolution Image Generation via Wavelet-Based Diffusion
  Sampling'
arxiv_id: '2506.20452'
source_url: https://arxiv.org/abs/2506.20452
tags:
- image
- hiwave
- diffusion
- generation
- details
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HiWave is a training-free method for high-resolution image generation
  that addresses object duplication and structural incoherence in patch-based approaches.
  The core idea combines patch-wise DDIM inversion to preserve global coherence with
  a wavelet-based detail enhancer that selectively guides high-frequency components
  while retaining low-frequency structure from the base image.
---

# HiWave: Training-Free High-Resolution Image Generation via Wavelet-Based Diffusion Sampling

## Quick Facts
- arXiv ID: 2506.20452
- Source URL: https://arxiv.org/abs/2506.20452
- Reference count: 28
- Primary result: Training-free method produces coherent 4096×4096 images without object duplication artifacts

## Executive Summary
HiWave presents a novel training-free approach for generating high-resolution images that addresses critical limitations in existing patch-based methods. The system combines patch-wise DDIM inversion with a wavelet-based detail enhancer to preserve global coherence while enhancing fine details. Using Stable Diffusion XL as the base model, HiWave successfully generates 4096×4096 images without the object duplication and structural incoherence issues common in prior approaches. A user study demonstrates that HiWave is preferred over the state-of-the-art Pixelsmith method in over 80% of comparisons.

## Method Summary
HiWave employs a two-stage process for high-resolution image generation. First, it uses patch-wise DDIM inversion to maintain global structural coherence across the image. Second, it applies a wavelet-based detail enhancer that selectively guides high-frequency components while preserving low-frequency structure from the base image. This approach allows for fine detail enhancement without compromising the overall composition or introducing artifacts like object duplication. The method operates entirely without retraining or architectural modifications to the base diffusion model.

## Key Results
- Generates coherent 4096×4096 images without object duplication artifacts
- Outperforms prior methods in perceptual