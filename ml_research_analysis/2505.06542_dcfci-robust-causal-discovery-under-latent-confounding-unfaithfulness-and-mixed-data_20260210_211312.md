---
ver: rpa2
title: 'dcFCI: Robust Causal Discovery Under Latent Confounding, Unfaithfulness, and
  Mixed Data'
arxiv_id: '2505.06542'
source_url: https://arxiv.org/abs/2505.06542
tags:
- dcfci
- pags
- causal
- cfci
- conditional
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of inferring causal relationships
  from observational data in the presence of latent confounding, empirical unfaithfulness,
  and mixed data types. The proposed data-compatible Fast Causal Inference (dcFCI)
  algorithm integrates a novel nonparametric data-PAG compatibility score into a greedy
  (Anytime-)FCI-guided search, systematically exploring, ranking, and validating candidate
  Partial Ancestral Graphs (PAGs).
---

# dcFCI: Robust Causal Discovery Under Latent Confounding, Unfaithfulness, and Mixed Data

## Quick Facts
- **arXiv ID:** 2505.06542
- **Source URL:** https://arxiv.org/abs/2505.06542
- **Reference count:** 40
- **Key outcome:** dcFCI infers causal relationships from observational data under latent confounding, empirical unfaithfulness, and mixed data types by integrating a novel nonparametric data-PAG compatibility score into a greedy (Anytime-)FCI-guided search, achieving higher data-PAG compatibility and MEC validity than state-of-the-art methods.

## Executive Summary
This paper addresses the challenge of inferring causal relationships from observational data in the presence of latent confounding, empirical unfaithfulness, and mixed data types. The proposed data-compatible Fast Causal Inference (dcFCI) algorithm integrates a novel nonparametric data-PAG compatibility score into a greedy (Anytime-)FCI-guided search, systematically exploring, ranking, and validating candidate Partial Ancestral Graphs (PAGs). Unlike state-of-the-art methods, dcFCI ensures the validity of the Markov Equivalence Class (MEC) characterization and achieves significantly higher data-PAG compatibility, even with small or heterogeneous datasets. Experiments on synthetic and real-world data demonstrate that dcFCI consistently outperforms existing approaches, recovering the true PAG more accurately and providing robust uncertainty quantification, supporting more reliable causal reasoning and decision-making.

## Method Summary
dcFCI is a hybrid causal discovery algorithm that builds upon the FCI framework to handle latent confounding. It uses a greedy, anytime search strategy guided by a novel nonparametric data-PAG compatibility score. The algorithm iteratively expands a list of candidate PAGs, evaluating them based on their compatibility with observed data using posterior probabilities of conditional independence hypotheses derived from likelihood-ratio tests. It enforces MEC validity by discarding any candidate PAG that is not a valid representation of a Markov Equivalence Class. The scoring mechanism focuses on the hypotheses that differentiate candidate structures, using Fréchet bounds to estimate the joint probability of conflicting independencies. This approach ensures the output is a valid PAG suitable for downstream causal inference.

## Key Results
- dcFCI consistently achieves higher data-PAG compatibility scores than FCI, cFCI, and MAGSL on both Gaussian and mixed-type synthetic data.
- The algorithm maintains MEC validity by design, a feature not shared by FCI or cFCI.
- On real-world data (Diabetes Health Indicators Dataset), dcFCI provides a list of plausible PAGs with uncertainty quantification, highlighting areas of structural ambiguity.
- The greedy search with k=1 often matches the performance of MAGSL's exact search, demonstrating the efficiency of the heuristic approach.

## Why This Works (Mechanism)

### Mechanism 1: Nonparametric Data-PAG Compatibility Score
The paper introduces a necessary and sufficient nonparametric score to assess the alignment between a candidate Partial Ancestral Graph (PAG) and observed mixed-type data. The score aggregates posterior probabilities of essential conditional (in)dependence hypotheses—specifically those determining the skeleton and colliders with order (which fully define the Markov Equivalence Class)—using Fréchet bounds to estimate their joint probability. These posteriors are derived from Bayes factors applied to standard test statistics (e.g., $\chi^2$) from likelihood-ratio tests. This mechanism provides a robust, assumption-light quantification of evidence for (in)dependence.

### Mechanism 2: Hybrid Greedy Search with Validity Enforcement
dcFCI guides its search using a greedy, Anytime-FCI-like procedure, systematically exploring and pruning the space of candidate PAGs based on the compatibility score while strictly enforcing MEC validity. The algorithm iterates over conditioning set sizes ($r$). At each step, it expands top-scoring PAGs by considering plausible separating sets derived from tests with high posterior probability of independence. It generates new candidates, applies FCI orientation rules, and **discards any resulting graph that is not a valid PAG**, ensuring the output remains suitable for downstream causal inference. It retains only the top $k$ candidates for the next iteration.

### Mechanism 3: Targeted MEC Scoring for Discrimination
To enable tractable comparison between PAGs, the scoring mechanism focuses exclusively on the conditional (in)dependence hypotheses that differentiate candidate structures. Instead of scoring all implied (in)dependencies, the algorithm identifies the set of hypotheses common to all candidates in a list and computes each PAG's score conditional on these shared hypotheses. The score is then derived only from the conflicting hypotheses, using a simplified Fréchet bound. This focuses the scoring power on the actual points of structural contention.

## Foundational Learning

- **Concept: Partial Ancestral Graph (PAG) and Markov Equivalence Class (MEC)**
  - Why needed here: The entire goal of the dcFCI algorithm is to output a valid PAG that represents the MEC of the true underlying causal model, accounting for latent confounders. Understanding PAG edge marks (tails, arrowheads, circles) and what they represent (definite vs. possible causal relationships) is essential.
  - Quick check question: What does a circle (◦) edge mark on a PAG indicate about the relationship between two variables? (Answer: It indicates a non-invariant relationship, meaning that within the MEC, there is at least one model where the edge mark is a tail and another where it is an arrowhead.)

- **Concept: Latent Confounding and Fast Causal Inference (FCI)**
  - Why needed here: The paper builds directly upon the FCI algorithm, which is designed to handle latent confounding. dcFCI's "hybrid" nature and its search strategy are modifications of the standard FCI procedure. Understanding FCI's skeleton and separation phase is key to understanding dcFCI's iterative construction.
  - Quick check question: What is the graphical representation used by FCI to handle latent confounding, and what are its main limitations? (Answer: FCI uses PAGs. Its main limitations, addressed by dcFCI, are its high sensitivity to errors in conditional independence tests (empirical unfaithfulness) and its inability to quantify uncertainty.)

- **Concept: Bayesian Hypothesis Testing and Fréchet Inequalities**
  - Why needed here: The paper's core innovation is its scoring mechanism. It moves beyond binary p-value decisions by computing posterior probabilities for (in)dependence hypotheses using Bayes factors. It then uses Fréchet inequalities to bound the joint probability of multiple such hypotheses. A grasp of these concepts is necessary to understand how the score is calculated and what it represents.
  - Quick check question: Why does the paper use Fréchet bounds instead of a direct joint probability calculation for the set of (in)dependence hypotheses? (Answer: Because the multiple conditional (in)dependence hypotheses are typically not mutually independent, making the exact joint probability difficult to calculate. Fréchet bounds provide a way to estimate the bounds on this joint probability.)

## Architecture Onboarding

- **Component map:** Input Data & Hyperparameters -> Greedy Search Loop -> Candidate Expansion -> Validity Filter -> Scoring Engine (MEC-targeted) -> Pruning -> Output List of Valid PAGs
- **Critical path:** The success of the algorithm hinges on the **Validity Filter** and the **Scoring Engine**. The filter ensures all downstream analysis is sound, while the scoring engine's ability to meaningfully discriminate between candidates using the Fréchet bounds on conflicting hypotheses determines the quality of the final output.
- **Design tradeoffs:**
    - **Greedy vs. Exact Search:** dcFCI uses a greedy search ($k$ candidates) which is faster than the exact search of MAGSL but is not guaranteed to find the globally optimal PAG. The paper shows it often matches MAGSL's performance with $k=1$.
    - **Candidate Breadth ($k$):** A larger $k$ increases robustness by exploring more paths but raises computational cost and may reduce the discriminative power of the score as more candidates share common hypotheses. The paper recommends $k=1$ or $2$.
    - **Score Complexity:** The MEC-targeted score is a practical compromise, avoiding the combinatorial explosion of the "straightforward" score but focusing only on hypotheses relevant for MEC characterization.
- **Failure signatures:**
    - **Outputting many PAGs with low, overlapping scores:** Indicates high uncertainty in the data, possibly due to small sample size or high noise. The paper's real-world application showed this when increasing variables beyond five.
    - **Producing invalid PAGs:** A bug in the validity filter. The paper claims dcFCI never produces invalid PAGs.
    - **No discrimination between candidates:** The score bounds are identical or overlapping for all top candidates. This suggests the Fréchet bounds are too wide or the conditional independence tests lack power.
- **First 3 experiments:**
    1.  **Gaussian vs. Mixed Data Comparison:** Run dcFCI on a synthetic dataset with purely Gaussian variables and then on the same underlying structure but with mixed data types (continuous, binary, multinomial). Compare the true PAG recovery rate and Structural Hamming Distance (SHD) against baselines like FCI, cFCI, and MAGSL to validate the paper's central claim of versatility.
    2.  **Varying Sample Size and $k$:** Systematically evaluate dcFCI's performance across different sample sizes (e.g., 1,000 to 50,000) while varying the $k$ parameter (e.g., 1, 2, 5). This will reveal the sensitivity of the greedy search to the breadth parameter and how it interacts with statistical power, directly testing the tradeoffs discussed.
    3.  **Real-world Uncertainty Analysis:** Apply dcFCI to the Diabetes Health Indicators Dataset (or a similar real-world dataset) as in the paper, but focus on analyzing the distribution of the top $k$ PAGs. For a given variable subset, compare the conflicting edges and orientations among the top candidates to understand what structural aspects the data supports with high confidence versus what remains ambiguous.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the greedy search strategy be improved to guarantee it does not overlook Partial Ancestral Graphs (PAGs) that might become more compatible with the data in later iterations?
- **Basis in paper:** [explicit] The authors acknowledge in the Conclusion that "its greedy search may overlook PAGs that, with additional iterations, could evolve into more compatible structures."
- **Why unresolved:** dcFCI selects the top $k$ candidates at each step to manage computational complexity, risking the pruning of paths that lead to the global optimum.
- **What evidence would resolve it:** Development of a hybrid heuristic (e.g., incorporating occasional random restarts or beam search) that consistently matches the recovery rate of exact search methods like MAGSL in low-sample regimes without incurring prohibitive computational costs.

### Open Question 2
- **Question:** What methodologies can be developed to automatically and dynamically select the optimal number of candidate PAGs ($k$) during the search process?
- **Basis in paper:** [explicit] The Conclusion states, "Future work should explore strategies for selecting the optimal k, balancing computational efficiency with accuracy."
- **Why unresolved:** Currently, $k$ is a static hyperparameter; larger values reduce the risk of pruning good candidates but increase computational load and may reduce the score's discriminative power.
- **What evidence would resolve it:** An adaptive algorithm that adjusts $k$ based on the variance or overlap of score bounds within the candidate list, validated by showing it maintains high accuracy (SHD) while minimizing runtime compared to static $k$ settings.

### Open Question 3
- **Question:** Can the nonparametric Bayesian score be effectively extended to incorporate prior domain knowledge or ancestral constraints without violating the Markov Equivalence Class characterization?
- **Basis in paper:** [explicit] The authors list as a future direction leveraging "the Bayesian score... to incorporate prior knowledge, by either adjusting (in)dependency priors or updating scores based on known (non-)ancestral relations."
- **Why unresolved:** The current implementation relies on non-informative priors (0.5) for conditional independence hypotheses to ensure data-compatibility.
- **What evidence would resolve it:** Simulation studies demonstrating that integrating "hard" constraints (e.g., known causal directions) significantly improves the Structural Hamming Distance (SHD) and convergence speed compared to the baseline dcFCI.

## Limitations

- The greedy search strategy may overlook globally optimal PAGs, as it only explores a subset of the candidate space.
- The performance on real-world datasets with more than five variables shows a significant drop in data-PAG compatibility scores, indicating a potential scalability limit.
- The Fréchet-bound-based joint probability estimation for multiple conditional (in)dependence hypotheses is an approximation, and the width of the bounds may limit discriminative power in complex or noisy datasets.

## Confidence

- **High Confidence:** The core mechanism of using a nonparametric score to assess PAG-data compatibility and the validity of the MEC-targeted scoring approach are well-supported by the theoretical framework and synthetic experiments.
- **Medium Confidence:** The practical performance of the greedy search and the specific hyperparameter choices (particularly $k$) are supported by experiments but may not generalize optimally to all domains or require careful tuning.
- **Medium Confidence:** The scalability claims and the specific performance on real-world datasets (especially with $p > 5$) are based on a single application and require further validation.

## Next Checks

1. **Scalability Test:** Apply dcFCI to a real-world dataset with a larger number of variables (e.g., 10-15) to empirically validate the performance degradation observed for $p > 5$ and test the limits of the greedy search strategy.
2. **Hyperparameter Sensitivity Analysis:** Systematically vary the significance level $\alpha$ and the candidate breadth $k$ on synthetic data with known ground truth to quantify their impact on PAG recovery and determine optimal default values for different dataset characteristics.
3. **Robustness to Model Misspecification:** Evaluate dcFCI's performance on synthetic data generated from non-linear SEMs or with different latent confounding structures to test the robustness of the nonparametric scoring mechanism to violations of its underlying assumptions.