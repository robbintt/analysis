---
ver: rpa2
title: Optimization through In-Context Learning and Iterative LLM Prompting for Nuclear
  Engineering Design Problems
arxiv_id: '2503.19620'
source_url: https://arxiv.org/abs/2503.19620
tags:
- optimization
- solutions
- prompting
- nuclear
- engineering
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates the application of large language models
  (LLMs) for optimizing nuclear engineering design problems, specifically focusing
  on boiling water reactor (BWR) fuel lattice configurations. The Optimization by
  Prompting (OPRO) approach uses iterative refinement with natural language descriptions
  to optimize uranium enrichment and gadolinium content in fuel pins while meeting
  reactivity and power peaking constraints.
---

# Optimization through In-Context Learning and Iterative LLM Prompting for Nuclear Engineering Design Problems

## Quick Facts
- arXiv ID: 2503.19620
- Source URL: https://arxiv.org/abs/2503.19620
- Reference count: 8
- Key outcome: LLMs optimize nuclear fuel lattice configurations using natural language descriptions, with reasoning-focused variants outperforming traditional genetic algorithms

## Executive Summary
This study demonstrates that large language models can serve as effective optimizers for nuclear engineering design problems through an approach called Optimization by Prompting (OPRO). The methodology enables domain experts to describe optimization problems in plain English, eliminating the need for hyperparameter tuning and specialized optimization knowledge. The research focuses on boiling water reactor (BWR) fuel lattice configurations, specifically optimizing uranium enrichment and gadolinium content in fuel pins while meeting reactivity and power peaking constraints.

The OPRO approach uses iterative refinement with natural language descriptions, where the LLM generates solutions that are evaluated and used to create new prompts for subsequent iterations. The study shows that reasoning-focused LLM variants like Gemini 2.0 Flash Thinking can achieve optimal solutions more efficiently than traditional genetic algorithms and other LLM variants. This represents a significant advancement in making optimization accessible to nuclear engineers without requiring deep expertise in optimization algorithms.

## Method Summary
The OPRO methodology employs iterative refinement through natural language prompts to optimize nuclear fuel lattice configurations. The approach uses a fixed prompt template containing the objective function, constraints, and sample solutions, which is updated iteratively with newly generated solutions. Each iteration involves the LLM generating a new solution based on the current prompt, evaluating it against the objective and constraints, and using the results to refine the next prompt. The optimization targets uranium enrichment and gadolinium content in fuel pins while ensuring reactivity (CR) remains above 0.95 and power peaking factors stay within specified bounds.

The study compares OPRO against traditional genetic algorithms and tests multiple LLM variants including GPT-4, Gemini 1.5 Flash, and Gemini 2.0 Flash Thinking. Performance is evaluated based on solution quality, convergence speed, and the number of iterations required to reach optimal configurations. The methodology emphasizes accessibility, allowing domain experts to formulate optimization problems using natural language without requiring knowledge of optimization algorithm hyperparameters or prompt engineering techniques.

## Key Results
- Reasoning-focused LLM variants (Gemini 2.0 Flash Thinking) achieve optimal solutions (score of 100) more efficiently than traditional genetic algorithms
- OPRO approach requires no hyperparameter tuning and enables domain experts to describe optimization problems in plain English
- Current methodology successfully optimizes 4-pin lattice configurations but faces scalability challenges for larger fuel assemblies

## Why This Works (Mechanism)
The OPRO approach works by leveraging the LLM's reasoning capabilities through iterative refinement of natural language prompts. Each iteration builds upon previous solutions, allowing the model to learn from its own outputs and progressively improve optimization results. The fixed prompt template structure ensures consistency while the dynamic content updates guide the LLM toward better solutions. Reasoning-focused variants like Gemini 2.0 Flash Thinking demonstrate superior performance because they can engage in chain-of-thought reasoning, systematically evaluating multiple solution approaches before generating outputs.

The natural language interface eliminates the need for specialized optimization knowledge, making the approach accessible to domain experts. By framing optimization as a language understanding and generation task, the methodology taps into the LLM's ability to process complex constraints and objective functions expressed in plain English. The iterative nature allows for continuous improvement without requiring explicit gradient information or mathematical optimization techniques.

## Foundational Learning

**Nuclear Fuel Lattice Optimization**: Understanding how fuel assemblies are configured in nuclear reactors and the importance of reactivity control and power distribution. Why needed: Provides context for the specific engineering problem being optimized. Quick check: Can you explain the difference between uranium enrichment and gadolinium content in fuel pins?

**In-Context Learning**: The ability of LLMs to learn from examples provided within the prompt rather than through fine-tuning. Why needed: Core mechanism enabling OPRO to improve solutions iteratively. Quick check: How does providing sample solutions in the prompt help the LLM generate better subsequent solutions?

**Chain-of-Thought Reasoning**: LLM's ability to work through problems step-by-step before providing a final answer. Why needed: Explains why reasoning-focused variants like Gemini 2.0 Flash Thinking outperform others. Quick check: What advantages does step-by-step reasoning provide for complex optimization problems?

**Iterative Refinement**: The process of using previous outputs to generate improved subsequent inputs. Why needed: Fundamental to how OPRO progressively improves solutions. Quick check: How does each iteration build upon previous results to guide the optimization process?

## Architecture Onboarding

Component Map: Domain Expert -> Natural Language Problem Description -> Prompt Template -> LLM Engine -> Solution Evaluation -> Updated Prompt -> Next Iteration

Critical Path: The optimization process flows from natural language problem formulation through iterative LLM prompting to final solution. The critical path involves prompt construction, solution generation, evaluation against constraints, and prompt refinement for subsequent iterations.

Design Tradeoffs: The methodology trades computational efficiency for accessibility and ease of use. While traditional optimization algorithms may converge faster on simple problems, OPRO's natural language interface eliminates the need for specialized optimization knowledge. The iterative approach requires more LLM API calls but provides transparency and interpretability through natural language explanations.

Failure Signatures: Poor convergence indicates either insufficient prompt specificity or inadequate constraint formulation. Model hallucination becomes more prevalent with complex, high-dimensional problems that exceed context window limitations. Reasoning-focused variants may struggle with problems requiring extensive numerical computation rather than logical reasoning.

First Experiments:
1. Test OPRO on a simple 2-variable optimization problem with known optimal solution to verify basic functionality
2. Compare convergence rates between reasoning-focused and non-reasoning LLM variants on the same problem
3. Evaluate sensitivity of OPRO performance to prompt template structure and sample solution quality

## Open Questions the Paper Calls Out
Major uncertainties remain regarding the scalability of the OPRO approach to higher-dimensional nuclear engineering problems. The current study successfully optimizes a 4-pin lattice configuration but faces significant challenges when scaling to more complex 10x10 or 17x17 fuel assemblies due to context window limitations and increased risk of model hallucination with complex constraints.

## Limitations
- Scalability challenges when moving from 4-pin to larger 10x10 or 17x17 fuel assembly configurations
- Increased risk of model hallucination with complex constraints in higher-dimensional problems
- Dependence on specific LLM variants, particularly the superior performance of Gemini 2.0 Flash Thinking

## Confidence
High: LLMs can effectively optimize nuclear fuel lattice configurations using natural language descriptions, with reasoning-focused variants outperforming traditional genetic algorithms
Medium: LLMs represent a viable general-purpose optimization tool for broader nuclear engineering applications beyond the specific BWR fuel lattice problem studied

## Next Checks
1. Test OPRO scalability by applying the methodology to larger 10x10 and 17x17 fuel assembly configurations, documenting context window utilization and hallucination rates as problem dimensionality increases
2. Compare performance across multiple LLM variants (including open-source models) using identical problem formulations to assess generalizability and identify model-specific optimization strategies
3. Implement cross-validation by having multiple nuclear engineering experts independently formulate the same optimization problem using natural language to evaluate consistency and reproducibility of results