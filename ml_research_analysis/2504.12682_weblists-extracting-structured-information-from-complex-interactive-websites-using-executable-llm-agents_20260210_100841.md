---
ver: rpa2
title: 'WebLists: Extracting Structured Information From Complex Interactive Websites
  Using Executable LLM Agents'
arxiv_id: '2504.12682'
source_url: https://arxiv.org/abs/2504.12682
tags:
- agent
- data
- agents
- page
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces WebLists, a benchmark for evaluating web agents
  on structured data extraction tasks across diverse websites. The benchmark addresses
  the gap between academic web agent evaluations (focused on navigation and transactions)
  and real-world business needs (requiring structured data extraction at scale).
---

# WebLists: Extracting Structured Information From Complex Interactive Websites Using Executable LLM Agents

## Quick Facts
- **arXiv ID**: 2504.12682
- **Source URL**: https://arxiv.org/abs/2504.12682
- **Reference count**: 14
- **Primary result**: Introduces WebLists benchmark and BardeenAgent framework that achieves 66% recall for structured data extraction from interactive websites

## Executive Summary
WebLists addresses a critical gap in web agent evaluation by focusing on structured data extraction tasks rather than navigation and transactions. The benchmark includes 200 tasks across four real-world use-cases (blogs, testimonials, jobs, job categories) on 50 diverse websites. The paper introduces BardeenAgent, a novel framework that converts agent actions into executable programs with CSS selectors, enabling scalable and cost-effective data extraction from complex interactive websites.

The proposed approach demonstrates significant improvements over state-of-the-art web agents, achieving more than double the performance with 66% recall while reducing cost per output row by 3x. By leveraging HTML structure regularity and executable programs, BardeenAgent transforms web extraction from an unreliable interactive process into a repeatable, scalable solution that better aligns with real-world business needs.

## Method Summary
The WebLists benchmark provides a standardized evaluation framework for structured data extraction from interactive websites. It includes 200 tasks across four use-cases (blogs, testimonials, jobs, job categories) on 50 websites, requiring agents to navigate dynamic content and extract data following specific schemas. The benchmark enables consistent comparison of web agent performance on real-world extraction challenges.

BardeenAgent operates through a two-phase approach: recording and replay. During recording, the agent navigates to target pages and extracts the first item while logging all actions. During replay, these actions are converted into an executable program with CSS selectors and loops for systematic data extraction. The framework leverages HTML structure regularity to create scalable extraction programs that can be executed repeatedly with minimal cost.

## Key Results
- BardeenAgent achieves 66% recall on WebLists benchmark, more than doubling state-of-the-art web agent performance
- The framework reduces cost per output row by 3x compared to baseline approaches
- Automated evaluation shows consistent performance across the four use-cases (blogs, testimonials, jobs, job categories)

## Why This Works (Mechanism)
The approach succeeds by transforming web extraction from an interactive, unreliable process into a repeatable, executable program. By recording agent actions during initial navigation and converting them into CSS selector-based programs with loops, the system creates a reliable extraction pipeline that can be executed multiple times at low cost. This executable program approach leverages the inherent regularity in HTML structures across similar pages, enabling systematic data extraction that scales effectively.

## Foundational Learning
**Executable Programs**: Converting agent actions into code-like programs with CSS selectors - needed to enable repeatable, scalable extraction; quick check: verify programs can be executed multiple times with consistent results
**HTML Structure Regularity**: The assumption that similar pages share consistent HTML patterns - needed to create reliable CSS selectors; quick check: test selector robustness across different pages of the same site
**Two-Phase Architecture**: Separate recording and replay phases - needed to balance exploration with efficient execution; quick check: ensure recorded actions translate correctly to executable programs
**Cost-Effective Scaling**: Using executable programs to reduce per-row extraction costs - needed for business viability; quick check: measure cost per row compared to interactive approaches
**Automated Evaluation**: Systematic assessment of extraction quality - needed for benchmarking progress; quick check: validate evaluation metrics against ground truth

## Architecture Onboarding

**Component Map**: Agent Interface -> Recording Module -> Program Generator -> Executable Program -> CSS Selector Engine -> Data Extractor -> Validation Module

**Critical Path**: User Query -> Agent Navigation -> First Item Extraction -> Action Recording -> Program Generation -> CSS Selector Creation -> Data Extraction Loop -> Output Validation

**Design Tradeoffs**: Interactive exploration vs. automated execution (flexibility vs. scalability), CSS selector precision vs. robustness (accuracy vs. coverage), program complexity vs. maintainability (completeness vs. simplicity)

**Failure Signatures**: Incomplete HTML structure regularity (broken CSS selectors), dynamic content loading issues (missing data), anti-scraping measures (blocked access), schema mismatches (incorrect data mapping)

**First Experiments**:
1. Test recording phase on a simple static website with consistent structure
2. Validate CSS selector generation on pages with varying complexity
3. Measure cost per row extraction compared to interactive baseline approaches

## Open Questions the Paper Calls Out
None

## Limitations
- Benchmark covers only 50 websites and four specific use-cases, potentially limiting generalizability to other extraction scenarios
- Performance depends heavily on HTML structure regularity, which may not hold for highly dynamic or inconsistently structured websites
- 66% recall, while significant improvement, still leaves substantial room for enhancement in complete data extraction

## Confidence

**High confidence**: WebLists benchmark creation and methodology are novel and well-defined contributions with clear reproducibility.

**Medium confidence**: 3x cost reduction claim depends on specific implementation details and pricing models that may vary across contexts.

**Medium confidence**: More than doubling performance assertion depends on chosen baselines and evaluation methodology.

## Next Checks
1. Test BardeenAgent on websites beyond the 50 included in WebLists, especially those with dynamic content or anti-scraping measures
2. Conduct human evaluation to validate automated metrics and assess real-world data quality and usability
3. Evaluate framework performance on additional use-cases like e-commerce product listings or financial data extraction to test generalizability