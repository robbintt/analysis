---
ver: rpa2
title: 'FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly
  Knowledge Graphs'
arxiv_id: '2508.10467'
source_url: https://arxiv.org/abs/2508.10467
tags:
- sparql
- queries
- query
- knowledge
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces FIRESPARQL, a modular framework for generating\
  \ SPARQL queries over Scholarly Knowledge Graphs (SKGs) using fine-tuned Large Language\
  \ Models (LLMs). The authors identify two main error types in LLM-generated queries\u2014\
  structural inconsistencies and semantic inaccuracies\u2014and address them through\
  \ fine-tuning, optional Retrieval-Augmented Generation (RAG), and a SPARQL correction\
  \ layer."
---

# FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs

## Quick Facts
- arXiv ID: 2508.10467
- Source URL: https://arxiv.org/abs/2508.10467
- Reference count: 25
- Fine-tuning with LoRA adaptation achieves 0.90 ROUGE-L and 0.85 RelaxedEM on SciQA benchmark

## Executive Summary
This paper introduces FIRESPARQL, a modular framework for generating SPARQL queries over Scholarly Knowledge Graphs (SKGs) using fine-tuned Large Language Models (LLMs). The authors identify two main error types in LLM-generated queries—structural inconsistencies and semantic inaccuracies—and address them through fine-tuning, optional Retrieval-Augmented Generation (RAG), and a SPARQL correction layer. Experiments on the SciQA benchmark show that fine-tuning achieves the highest performance, with 0.90 ROUGE-L for query accuracy and 0.85 RelaxedEM for result accuracy using LLaMA3-8B-Instruct fine-tuned for 15 epochs. The study also finds that larger models outperform smaller ones and that RAG integration can degrade performance due to noisy context. The framework is open-sourced, and the best model is available on Hugging Face.

## Method Summary
The FIRESPARQL framework processes natural language questions into SPARQL queries through a modular pipeline. It uses LoRA-based fine-tuning to adapt LLMs to SKG-specific patterns, optionally integrates RAG for context retrieval from ORKG, and applies a lightweight LLM correction layer to fix syntactic errors before query execution. The framework evaluates performance using ROUGE-L for query structure similarity and RelaxedEM for result accuracy against ground truth answers.

## Key Results
- Fine-tuning with LoRA adaptation achieves 0.90 ROUGE-L and 0.85 RelaxedEM on SciQA benchmark
- Larger models (8B vs 3B) converge faster and achieve better results with fewer training epochs
- RAG integration degrades performance due to noisy or misaligned retrieved context

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning with LoRA adaptation enables the model to internalize SKG-specific ontology patterns, addressing structural inconsistencies. By training on NLQ-SPARQL pairs from the target domain, the model implicitly learns the graph schema, entity-relationship patterns, and query structures specific to the scholarly knowledge graph, which are not captured in general pre-training. The core assumption is that the training data sufficiently represents the ontological patterns and query structures needed for the target SKG domain. Evidence includes the abstract's mention of fine-tuned LLMs, Section 4.1's explanation of implicit pattern capture during training, and Section 6.1's demonstration of significant improvements over zero-shot baselines. This mechanism breaks when the SKG schema is highly complex or the training data is insufficient/incomplete.

### Mechanism 2
A lightweight LLM-based SPARQL correction layer can fix syntactic errors that prevent query execution, improving execution success rates. A secondary LLM pass identifies and corrects common syntactic issues (missing punctuation, extra text, spacing problems) in generated queries before execution, increasing the likelihood of valid, executable queries. The core assumption is that the correction LLM has sufficient SPARQL syntax knowledge to identify and fix errors without introducing new semantic errors. Evidence includes the abstract's mention of the SPARQL correction layer and Section 4.3's explanation of refining queries for syntactic validity. This mechanism breaks when the correction layer encounters novel error types or complex structural issues.

### Mechanism 3
RAG integration with property retrieval does NOT improve performance and can degrade it due to noisy or misaligned retrieved context. The paper's RAG module retrieves candidate properties from ORKG to provide context, but irrelevant or incorrect suggestions can confuse the model rather than guide it, conflicting with knowledge already encoded during fine-tuning. The core assumption is that the retrieved context would be helpful, but the evidence suggests this assumption does not hold for their implementation. Evidence includes Section 6.1's finding that incorporating RAG degrades performance and the explanation that this decline can be attributed to noisy or misaligned context. This mechanism is essentially a negative result—the RAG approach breaks when context quality is poor or when there's no context validation.

## Foundational Learning

- Concept: **SPARQL Query Language and RDF Triple Patterns**
  - Why needed here: Understanding SPARQL syntax (SELECT, WHERE, triple patterns, aggregation, GROUP BY) is essential to comprehend why structural errors occur and how the correction layer operates.
  - Quick check question: Can you identify the subject-predicate-object pattern in a basic SPARQL triple like `?paper orkgp:P34 ?contribution`?

- Concept: **LoRA (Low-Rank Adaptation) Fine-Tuning**
  - Why needed here: The framework uses LoRA for parameter-efficient fine-tuning; understanding how it injects trainable matrices while freezing pre-trained weights helps explain the efficiency gains.
  - Quick check question: What are the key advantages of LoRA over full-parameter fine-tuning for domain adaptation?

- Concept: **Knowledge Graph Schemas and Ontologies**
  - Why needed here: Structural inconsistencies stem from not understanding the underlying SKG schema; grasping how ontologies define classes, properties, and relationships is crucial.
  - Quick check question: How does a knowledge graph ontology constrain what constitutes a valid query path between entities?

## Architecture Onboarding

- Component map: Input (NLQ) → Prompt Template → [Optional: RAG retrieves properties from SKG] → Fine-tuned LLM (LoRA) → Raw SPARQL Output → LLM Correction Layer → Cleaned SPARQL → Query Execution Engine (QLever) → Results evaluated against ground truth

- Critical path: The fine-tuned LLM (LLaMA-3-8B-Instruct with LoRA) is the core component; all other modules are optional layers around it. The correction layer is the final safeguard before execution.

- Design tradeoffs:
  - Fine-tuning vs. few-shot: Fine-tuning requires labeled data and compute but yields significantly better results (0.85 vs 0.40 RelaxedEM)
  - RAG inclusion: Current implementation degrades performance; future iterations would need better retrieval mechanisms and context validation
  - Model size: 8B model converges faster (optimal at 15 epochs) but 3B model requires more training (20 epochs) to achieve competitive results
  - Epoch count: Performance is not monotonic—early decline from epoch 3-7, then recovery

- Failure signatures:
  - Aggregation errors: "Variable is selected but not aggregated...must be part of GROUP BY clause" (11/14 syntax errors)
  - Subquery structure errors: "mismatched input 'SELECT' expecting '}'" (3/14 syntax errors)
  - Empty results: 51 queries executed successfully but returned no results (semantic mismatch with ground truth)

- First 3 experiments:
  1. **Baseline zero-shot test**: Run vanilla LLaMA-3-8B-Instruct on SciQA without fine-tuning or examples to establish baseline performance (expected near-zero RelaxedEM)
  2. **Fine-tuning sweep**: Train LLaMA-3-8B-Instruct with LoRA on NLQ-SPARQL pairs across epochs (3, 5, 7, 10, 15, 20) to identify optimal training duration and observe non-monotonic performance patterns
  3. **Error analysis on failures**: Execute generated queries and categorize syntax failures (aggregation vs subquery) vs empty-result semantic failures to identify which error type dominates

## Open Questions the Paper Calls Out
None

## Limitations
- The study focuses on a single scholarly knowledge graph (ORKG), limiting generalizability to other SKGs with different schemas and complexity levels
- RAG integration underperformed due to noisy context, suggesting the framework's robustness to context quality remains unproven
- The error analysis identifies structural and semantic errors but doesn't quantify which error type is more detrimental to overall performance

## Confidence
- **High confidence**: Fine-tuning with LoRA adaptation improves SPARQL generation performance (multiple experiments show consistent improvements over baselines)
- **Medium confidence**: Larger models (8B vs 3B) converge faster and achieve better results with fewer training epochs
- **Low confidence**: The SPARQL correction layer's effectiveness is based on limited error analysis (14 syntax errors), and its generalization to other error types is unclear

## Next Checks
1. Test FIRESPARQL on a different SKG domain (e.g., biomedical or geospatial) to assess generalizability of fine-tuned patterns
2. Implement a context validation mechanism for RAG to filter noisy property suggestions before model input
3. Conduct ablation studies removing the correction layer to quantify its actual contribution to execution success rates