---
ver: rpa2
title: '$\texttt{BluePrint}$: A Social Media User Dataset for LLM Persona Evaluation
  and Training'
arxiv_id: '2510.02343'
source_url: https://arxiv.org/abs/2510.02343
tags:
- social
- bsky
- user
- media
- cluster
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SIMPACT introduces a privacy-preserving framework for constructing
  behaviorally grounded social media datasets by clustering users into personas and
  anonymizing interaction data. The BluePrint dataset, built from Bluesky political
  discourse, contains 6.8M actions across 236K users, enabling next-action prediction
  tasks for training and evaluating LLM-based social media agents.
---

# $\texttt{BluePrint}$: A Social Media User Dataset for LLM Persona Evaluation and Training

## Quick Facts
- arXiv ID: 2510.02343
- Source URL: https://arxiv.org/abs/2510.02343
- Authors: Aurélien Bück-Kaeffer; Je Qin Chooi; Dan Zhao; Maximilian Puelma Touzel; Kellin Pelrine; Jean-François Godbout; Reihaneh Rabbany; Zachary Yang
- Reference count: 40
- Primary result: SIMPACT framework builds privacy-preserving BluePrint dataset (6.8M actions, 236K users) showing models fine-tuned on clustered personas are nearly indistinguishable from real users (56% identification accuracy) while highlighting action prediction remains challenging.

## Executive Summary
The BluePrint dataset addresses the critical challenge of building socially grounded LLM agents by providing a privacy-preserving framework for persona-based training and evaluation. By clustering 236K users from Bluesky political discourse into behavioral personas and anonymizing interaction data, the dataset enables next-action prediction tasks that capture both textual content and interaction behaviors. The SIMPACT framework demonstrates that fine-tuning on clustered data improves human-likeness significantly (identification accuracy drops from 71.9% to 56%) while revealing that action prediction accuracy remains comparable to baseline models, highlighting a fundamental challenge in behavioral modeling.

## Method Summary
The SIMPACT framework constructs the BluePrint dataset through a multi-stage pipeline: collecting Bluesky posts filtered by political keywords, embedding users via multilingual-e5-large, clustering into personas (K=2, 25, 100, 1000) with minimum cluster size 10, applying privacy transformations (PII removal, timestamp obfuscation, per-thread pseudonymization), and structuring data as JSON threads for next-action prediction. Models are fine-tuned using LoRA adapters on Qwen-2.5-7B-Instruct with focal loss and cross-entropy variants, augmented with databricks-dolly-15k to preserve instruction-following capabilities. Evaluation combines lexical metrics (Jaccard, JS divergence), embedding similarity, F1 scores for action prediction, and human evaluation targeting 50% identification accuracy.

## Key Results
- Human evaluation shows fine-tuned models are nearly indistinguishable from real users (56% identification accuracy vs 71.9% for untrained models)
- Lexical alignment improves dramatically (Jaccard +10x, JS divergence -2x) while action prediction F1 scores remain essentially unchanged (~0.34)
- Multi-scale clustering (K=2, 25, 100, 1000) provides flexibility for different evaluation needs
- Cluster-level metrics reveal stronger distributional alignment compared to baseline models

## Why This Works (Mechanism)

### Mechanism 1
Clustering users into behavioral personas improves both training data availability and privacy preservation by aggregating users via embedding-based clustering (constrained K-means, min cluster size 10) to create archetypes that capture diverse interaction patterns while abstracting individual identities. Core assumption: Behavioral similarity in embedding space correlates with meaningful interaction patterns that agents can learn to replicate. Evidence: Clustering framework increases data availability, reduces overfitting risk, and mitigates ethical risks of simulating identifiable individuals.

### Mechanism 2
Next-action prediction framing enables LLMs to learn both textual content and interaction behaviors contextually by structuring data as threads (post sequences ending in an action) that train models to predict contextually appropriate responses. Core assumption: User actions are primarily responses to immediately visible context rather than unobserved external factors. Evidence: BNF thread definition; 12 action types spanning text-directed and user-directed behaviors.

### Mechanism 3
Fine-tuning on cluster-specific data improves human-likeness but not necessarily action prediction accuracy by learning stylistic features separately from behavioral decision-making. Core assumption: Stylistic features are easier to capture from aggregated data than strategic action selection. Evidence: Fine-tuned models show 0.122 vs 0.013 Jaccard; JS divergence 0.258 vs 0.389; F1 essentially unchanged (~0.34).

## Foundational Learning

- **Embedding-based user representation**: Users are represented as averaged sentence embeddings (multilingual-e5-large) before clustering—understanding embedding semantics is essential for interpreting cluster quality. Quick check: Can you explain why averaging post embeddings might lose temporal or interaction-specific signals?

- **Constrained K-means clustering**: The minimum cluster size constraint (10) prevents trivial clusters that would leak individual identities or provide insufficient training data. Quick check: What tradeoff does the minimum cluster size introduce between privacy and behavioral granularity?

- **LoRA (Low-Rank Adaptation) fine-tuning**: The paper uses LoRA adapters rather than full fine-tuning—understanding parameter-efficient training is necessary to reproduce results on limited compute. Quick check: Why might LoRA preserve instruction-following capabilities better than full fine-tuning on domain-specific data?

## Architecture Onboarding

- **Component map**: Jetstream client → raw Bluesky posts/likes/follows → E5-large encoder → averaged user vectors → constrained K-means clustering → persona assignments → Presidio PII removal → timestamp obfuscation → per-thread pseudonymization → BNF parser → JSON thread objects → LoRA adapters (focal loss / CE loss) → multi-metric evaluation.

- **Critical path**: Raw data → clustering → privacy transformation → thread construction → LoRA training → evaluation. Privacy pipeline must complete before any data release.

- **Design tradeoffs**: Per-thread pseudonymization prevents cross-thread linkage but loses long-term user modeling capability; most-recent-post heuristic for user-directed actions is tractable but may misattribute intent; multi-scale clustering provides flexibility but requires deciding which granularity fits downstream tasks.

- **Failure signatures**: High Max Cosine Similarity with low Jaccard suggests embedding artifacts rather than genuine alignment; F1 score stagnation despite improved human-likeness indicates action prediction requires different training signals; cluster imbalance may bias multi-cluster training.

- **First 3 experiments**: 1) Cluster coherence validation: Compute silhouette scores and TF-IDF interpretability checks for each K setting before training—catches meaningless clusterings early. 2) Privacy regression test: Attempt re-identification using timestamp proximity and username patterns on a held-out validation set—validates pseudonymization effectiveness. 3) Baseline comparison: Train identical LoRA adapters on raw (non-clustered) data vs. clustered data with identical compute—quantifies clustering's contribution to metrics.

## Open Questions the Paper Calls Out

### Open Question 1
How can modeling approaches be refined to improve the reliability of specific action predictions (e.g., F1 scores) while maintaining textual realism? Basis: Despite gains in generating plausible text, "action prediction remains challenging, highlighting the need for more sophisticated modeling approaches." Why unresolved: Current fine-tuned models show improved lexical alignment but action prediction F1 scores remain comparable to untrained baselines. Evidence needed: A model architecture or training objective that achieves significantly higher F1 scores in next-action prediction without degrading textual similarity metrics.

### Open Question 2
To what extent does the inclusion of automated (bot) accounts skew the formation of behavioral personas and the evaluation of agent fidelity? Basis: The framework "does not distinguish between human and automated accounts, potentially introducing bot-generated noise" into the clustered personas. Why unresolved: The dataset aggregates users based on behavior without filtering for non-human actors, potentially conflating scripted bot patterns with human behavioral archetypes. Evidence needed: A comparative analysis of cluster coherence and model evaluation metrics before and after applying bot-detection filtering to the raw dataset.

### Open Question 3
How valid is the simplifying assumption that user-directed actions (follow, block) are primarily responses to the target's most recent post? Basis: Linking actions like "follow" to the most recent post is a "simplification and may not reflect the true motivation behind every user-directed action." Why unresolved: The dataset forces a context link for user-directed actions, but the actual user intent might relate to older posts, profile views, or external factors. Evidence needed: A user study or analysis on a dataset with full session histories correlating actual action triggers against the "most recent post" heuristic.

## Limitations

- Uncontrolled behavioral variables: The dataset focuses on political discourse, potentially limiting generalizability to other domains. User behavior may be influenced by factors outside the dataset (external events, private conversations).

- Temporal dynamics: Thread construction assumes sequential user responses, but real social media behavior includes asynchronous interactions, multi-threaded conversations, and non-linear engagement patterns.

- Sparse action distribution: With 12 action types and significant imbalance (rare actions likely underrepresented), models may struggle with comprehensive behavioral modeling even with cluster aggregation.

## Confidence

- **Mechanism 1** (Clustering improves training and privacy): Medium confidence. Clear privacy benefits through identity abstraction, but behavioral coherence of clusters remains partially validated.
- **Mechanism 2** (Next-action prediction framing): Medium confidence. Well-defined formulation, but simplifying assumption for user-directed actions is unverified and may systematically misattribute intent.
- **Mechanism 3** (Fine-tuning improves human-likeness but not action prediction): High confidence. Robust empirical results show substantial improvements in lexical alignment while maintaining F1 scores, with human evaluation confirming near-random identification accuracy.

## Next Checks

1. **Cluster behavioral coherence**: Conduct qualitative analysis of cluster contents by sampling threads from high, medium, and low silhouette score clusters. Verify that clusters represent distinct interaction patterns rather than random groupings, using TF-IDF analysis and human annotation of behavioral themes.

2. **Cross-cluster generalization**: Train models on clusters 0-4, then evaluate on clusters 5-24 (unseen during training). This tests whether learned behavioral patterns transfer across personas or overfit to specific clusters, revealing the robustness of the clustering approach.

3. **Temporal validation**: Reconstruct user timelines using available timestamp data (before obfuscation) to verify that the most-recent-post heuristic for user-directed actions holds empirically. Measure the correlation between action targets and post recency across different action types.