---
ver: rpa2
title: 'Hierarchical Label Propagation: A Model-Size-Dependent Performance Booster
  for AudioSet Tagging'
arxiv_id: '2503.21826'
source_url: https://arxiv.org/abs/2503.21826
tags:
- audioset
- audio
- label
- labels
- ontology
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates Hierarchical Label Propagation (HLP) to
  address inconsistent hierarchical labeling in AudioSet, where child labels should
  logically imply parent labels but often do not. The proposed method propagates positive
  labels up the ontology hierarchy during training or evaluation, increasing the average
  positive labels per audio clip from 1.98 to 2.39 and affecting 109 out of 527 classes.
---

# Hierarchical Label Propagation: A Model-Size-Dependent Performance Booster for AudioSet Tagging

## Quick Facts
- arXiv ID: 2503.21826
- Source URL: https://arxiv.org/abs/2503.21826
- Reference count: 20
- Key outcome: Hierarchical label propagation consistently improves performance across various model architectures, with smaller models showing more significant gains than larger models

## Executive Summary
This paper addresses inconsistent hierarchical labeling in AudioSet, where child labels should logically imply parent labels but often do not. The proposed Hierarchical Label Propagation (HLP) method propagates positive labels up the ontology hierarchy during training or evaluation, increasing average positive labels per audio clip from 1.98 to 2.39 and affecting 109 out of 527 classes. Results demonstrate consistent performance improvements across multiple model architectures, with smaller models showing more substantial gains than larger models.

## Method Summary
The authors propose a simple yet effective approach to address inconsistent hierarchical labeling in AudioSet. During training or evaluation, when a child label is predicted as positive, the corresponding parent label is also set as positive, propagating labels up the ontology hierarchy. This method addresses cases where audio clips containing specific sound events are labeled with the child category but not the parent category, despite the hierarchical relationship in the ontology. The approach is model-agnostic and can be applied to any audio tagging system without architectural modifications.

## Key Results
- CNN6 trained with HLP achieved a 3.1 percentage point increase in mAP on AudioSet
- Larger models (PaSST-B, ConvNeXt-nano) showed modest improvements of 0.3 percentage point
- HLP benefits transferred to FSD50K evaluation without fine-tuning, particularly for smaller models

## Why This Works (Mechanism)
The mechanism works by correcting hierarchical inconsistencies in the labeling process. In AudioSet's ontology, parent labels should logically encompass their child labels (e.g., if "dog" is present, "animal" should also be present). However, many audio clips are labeled with child categories without their corresponding parent categories. By propagating positive labels up the hierarchy, the method ensures logical consistency between parent and child labels, effectively expanding the positive label set in a semantically meaningful way. This reduces false negatives for parent classes and improves overall classification performance, particularly for models that may struggle to infer parent-child relationships implicitly.

## Foundational Learning
- AudioSet ontology structure: Understanding the hierarchical relationship between sound event categories is crucial for implementing label propagation correctly
- Multi-label classification metrics: Familiarity with mAP and other evaluation metrics for multi-label tasks is needed to interpret results
- Label propagation concepts: Basic understanding of how propagating labels through a graph structure affects model training and evaluation
- Audio tagging architectures: Knowledge of common CNN and transformer-based models used for audio classification

## Architecture Onboarding
**Component Map:**
Audio Input -> Model Backbone (CNN/Transformer) -> Classifier Head -> HLP Layer -> Final Predictions

**Critical Path:**
The critical path involves the interaction between the model's predictions and the HLP layer. During inference, the model outputs predicted probabilities for each class, which are then thresholded to determine positive predictions. The HLP layer takes these positive predictions and propagates them up the ontology hierarchy, potentially activating parent classes. This modified prediction set is then used for final evaluation.

**Design Tradeoffs:**
The primary tradeoff is between computational overhead and performance gains. HLP adds a simple graph traversal step after prediction but can significantly improve performance, especially for smaller models. The method is model-agnostic, avoiding architectural complexity but requiring access to the ontology structure. The threshold selection for positive predictions affects how aggressively labels are propagated.

**Failure Signatures:**
- Over-propagation: If thresholds are too low, labels may be propagated too aggressively, introducing false positives for parent classes
- Missed propagation: If the ontology structure is incorrect or incomplete, propagation may miss necessary label assignments
- Model-specific limitations: For very large models that already capture hierarchical relationships well, HLP may provide minimal benefit

**First Experiments:**
1. Apply HLP to a simple CNN6 model on AudioSet and measure mAP improvement
2. Compare HLP performance across different threshold values to find optimal sensitivity
3. Evaluate HLP on a subset of classes with known hierarchical inconsistencies to measure targeted improvement

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation primarily conducted on AudioSet, with FSD50K results showing transfer without fine-tuning
- Performance gains inversely correlated with model size, suggesting HLP may compensate for limited model capacity
- Computational overhead of HLP during training and inference is not quantified

## Confidence
- HLP improves performance on AudioSet: High
- HLP benefits transfer to FSD50K without fine-tuning: Medium
- Inverse relationship between model size and HLP effectiveness: Medium
- HLP addresses a meaningful labeling issue in AudioSet: High

## Next Checks
1. Evaluate HLP performance when models are fine-tuned on FSD50K rather than tested without adaptation to determine if benefits persist under domain-specific training.
2. Implement and compare alternative label propagation strategies (e.g., probabilistic vs. deterministic propagation) to assess whether the observed gains are specific to the proposed method or represent a general class of hierarchical consistency approaches.
3. Conduct ablation studies measuring the computational overhead of HLP during both training and inference to quantify the practical trade-offs between performance gains and resource requirements.