---
ver: rpa2
title: 'CoMet: Metaphor-Driven Covert Communication for Multi-Agent Language Games'
arxiv_id: '2505.18218'
source_url: https://arxiv.org/abs/2505.18218
tags:
- word
- metaphor
- players
- your
- metaphors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CoMet, a framework that enables large language
  model agents to engage in metaphor-driven covert communication during multi-agent
  language games. The key innovation is combining a hypothesis-based metaphor reasoner
  with a self-improving metaphor generator, allowing agents to interpret and generate
  metaphors strategically.
---

# CoMet: Metaphor-Driven Covert Communication for Multi-Agent Language Games

## Quick Facts
- arXiv ID: 2505.18218
- Source URL: https://arxiv.org/abs/2505.18218
- Reference count: 40
- Key outcome: CoMet improves multi-agent covert communication through metaphor reasoning, achieving 47% higher attacker win rates and 30% higher defender win rates in Adversarial Taboo

## Executive Summary
This paper introduces CoMet, a framework enabling large language model agents to engage in metaphor-driven covert communication during multi-agent language games. The key innovation combines a hypothesis-based metaphor reasoner with a self-improving metaphor generator, allowing agents to interpret and generate metaphors strategically. Experiments on two games—Undercover and Adversarial Taboo—demonstrate significant performance improvements, with CoMet reducing failure rates below 15% across four different LLM models (GPT-4o, Claude 3.5 Sonnet, Llama 3.3-70B, Qwen2.5-72B).

## Method Summary
CoMet operates through a dual-component architecture: a hypothesis-based metaphor reasoner that interprets metaphors through candidate hypothesis generation and verification, and a self-improving metaphor generator that learns from past successes and failures. The framework is evaluated in two game scenarios—Undercover (covert communication) and Adversarial Taboo (semantic evasion)—where agents must communicate strategically while avoiding detection. The self-improving component accumulates experience to enhance metaphor generation success rates, achieving up to 29% improvement through iterative learning.

## Key Results
- Attackers win 47% more often and defenders win 30% more often compared to baseline methods in Adversarial Taboo
- Metaphor reasoning module achieves 50-60% success rate in interpreting metaphors
- Failure rates below 15% across four diverse LLM models (GPT-4o, Claude 3.5 Sonnet, Llama 3.3-70B, Qwen2.5-72B)

## Why This Works (Mechanism)
CoMet leverages the natural language understanding capabilities of LLMs to generate and interpret metaphors as a form of covert communication. The hypothesis-based reasoning module systematically generates and tests candidate interpretations of metaphors, while the self-improving generator learns from successful communication patterns. This dual approach allows agents to develop shared metaphorical vocabularies and adapt their communication strategies based on contextual feedback.

## Foundational Learning

**Metaphor Generation** - Creating figurative expressions to convey hidden meanings. Needed for establishing covert communication channels. Quick check: Can agents generate metaphors that avoid keyword detection while preserving semantic intent?

**Hypothesis-Based Reasoning** - Systematically testing multiple interpretations of ambiguous communication. Needed for robust metaphor interpretation. Quick check: Does the reasoning module successfully identify correct interpretations among multiple candidates?

**Experience Accumulation** - Learning from past communication successes and failures. Needed for improving metaphor generation over time. Quick check: Does the success rate improve across multiple game iterations?

**Semantic Evasion** - Communicating while avoiding detection of specific keywords. Needed for Adversarial Taboo game mechanics. Quick check: Can agents maintain game-relevant communication while avoiding prohibited terms?

## Architecture Onboarding

**Component Map:** Input Text -> Metaphor Reasoner -> Hypothesis Generator -> Metaphor Generator -> Output Text

**Critical Path:** Communication input → Hypothesis generation → Verification → Metaphor generation → Experience update

**Design Tradeoffs:** The framework balances computational complexity (multiple hypothesis testing) against communication accuracy, prioritizing robust interpretation over speed.

**Failure Signatures:** High failure rates indicate either inadequate hypothesis generation or poor experience accumulation; specific error patterns can diagnose whether the issue lies in interpretation or generation.

**Three First Experiments:**
1. Test metaphor interpretation accuracy with increasing numbers of candidate hypotheses
2. Measure performance degradation when experience accumulation is disabled
3. Evaluate communication success rates across different metaphor complexity levels

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses on two specific game scenarios, limiting generalizability to broader multi-agent contexts
- Metaphor reasoning module's 50-60% success rate indicates substantial room for improvement
- Performance gains from self-improving mechanism may be context-dependent

## Confidence

**High confidence:**
- 47% increase in attacker wins and 30% increase in defender wins in Adversarial Taboo
- Failure rates below 15% across four diverse LLM models
- Consistent performance improvements across different LLM variants

**Medium confidence:**
- Framework enables metaphor-driven covert communication (moderate success rates)
- Self-improving metaphor generator effectiveness (context-dependent improvements)
- Generalization across different LLMs (limited model diversity tested)

## Next Checks

1. Test CoMet's performance in open-ended dialogue scenarios beyond the two structured games to assess real-world applicability of metaphor-driven communication

2. Evaluate the framework with additional LLM variants, including smaller models and those specifically trained on metaphor-rich datasets, to determine robustness across the model spectrum

3. Conduct ablation studies removing the self-improving component to quantify its actual contribution versus the baseline hypothesis-based reasoning module alone