---
ver: rpa2
title: 'Cost-Efficient Cross-Lingual Retrieval-Augmented Generation for Low-Resource
  Languages: A Case Study in Bengali Agricultural Advisory'
arxiv_id: '2601.02065'
source_url: https://arxiv.org/abs/2601.02065
tags:
- bengali
- agricultural
- language
- system
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a cost-efficient cross-lingual RAG framework
  for Bengali agricultural advisory, addressing the language barrier between English
  agricultural manuals and Bengali-speaking farmers. The system uses a translation-centric
  pipeline where Bengali queries are translated to English, enriched with domain-specific
  keywords, retrieved from English manuals, and the response is translated back to
  Bengali.
---

# Cost-Efficient Cross-Lingual Retrieval-Augmented Generation for Low-Resource Languages: A Case Study in Bengali Agricultural Advisory

## Quick Facts
- **arXiv ID:** 2601.02065
- **Source URL:** https://arxiv.org/abs/2601.02065
- **Reference count:** 18
- **Primary result:** Cost-efficient cross-lingual RAG framework for Bengali agricultural advisory using translation-centric pipeline on consumer hardware.

## Executive Summary
This paper presents a cost-efficient cross-lingual RAG framework for Bengali agricultural advisory, addressing the language barrier between English agricultural manuals and Bengali-speaking farmers. The system uses a translation-centric pipeline where Bengali queries are translated to English, enriched with domain-specific keywords, retrieved from English manuals, and the response is translated back to Bengali. The approach avoids paid APIs and runs on consumer hardware using open-source models. Experiments show the system produces source-grounded responses, rejects out-of-domain queries, and achieves an average end-to-end latency below 20 seconds. The results demonstrate that cross-lingual retrieval with controlled translation offers a practical solution for agricultural knowledge access in low-resource language settings.

## Method Summary
The method employs a "sandwich" translation architecture that separates user interaction language (Bengali) from reasoning language (English). Bengali agricultural queries are first translated to English using Helsinki-NLP opus-mt-bn-en, then enriched with domain-specific keywords mapping colloquial farmer terms to scientific nomenclature. The translated query is embedded using Sentence-Transformers all-MiniLM-L6-v2 and retrieved from a FAISS index over ~650-700 chunks of English agricultural manuals. A 4-bit quantized Llama-3-8B-Instruct LLM generates responses grounded in retrieved context, following strict instructions to cite sources and reject unanswerable queries. The English response is translated back to Bengali using NLLB-200. The entire pipeline runs on a single NVIDIA Tesla T4 GPU (16GB VRAM) with end-to-end latency of ~15.6 seconds.

## Key Results
- Achieves sub-20-second end-to-end latency on consumer hardware
- Produces source-grounded responses that cite retrieved agricultural manuals
- Successfully rejects out-of-domain queries without generating unsafe content
- Avoids paid API dependencies while maintaining response quality

## Why This Works (Mechanism)

### Mechanism 1: Translation-Centric Language Separation
Separating user interaction language (Bengali) from reasoning/retrieval language (English) improves factual accuracy and fluency compared to direct low-resource generation. Bengali query → English translation → retrieval from English corpus → English response generation → Bengali back-translation. The LLM reasons in its strongest language while users interact in their native language.

### Mechanism 2: Domain Keyword Injection for Vocabulary Alignment
Injecting scientific terminology alongside colloquial terms in translated queries improves retrieval recall by bridging the vocabulary gap between farmer language and manual nomenclature. When a known colloquial term is detected in the translated query, the corresponding scientific term is appended before embedding, enabling matching against formal manual terminology.

### Mechanism 3: Constrained Generation with Explicit Rejection
Prompting the LLM with strict instructions to generate only from retrieved context—and to explicitly reject unanswerable queries—produces reliable, source-grounded responses while preventing unsafe hallucinations in agricultural advisory. Retrieved document chunks + prompt with grounding instructions → LLM generates response citing context → if information absent, LLM outputs rejection message.

## Foundational Learning

- **Concept: Retrieval-Augmented Generation (RAG)**
  - Why needed here: Core architecture enabling source-grounded responses by retrieving relevant documents before generation, critical for high-stakes agricultural advice.
  - Quick check question: Can you explain why providing retrieved context to an LLM reduces hallucinations compared to standalone generation?

- **Concept: Neural Machine Translation for Low-Resource Languages**
  - Why needed here: The system's "sandwich architecture" depends on bidirectional Bengali-English translation; understanding failure modes (domain term loss, ambiguity) is essential for debugging.
  - Quick check question: What happens to an agricultural disease name if it has no direct English equivalent in the translation model's vocabulary?

- **Concept: Model Quantization (4-bit)**
  - Why needed here: Enables deployment on 16GB VRAM consumer hardware by reducing memory footprint; introduces potential accuracy tradeoffs that must be monitored.
  - Quick check question: If you observe degraded instruction-following behavior, what parameter would you investigate first?

## Architecture Onboarding

- **Component map:** Bengali input → Translate (opus-mt-bn-en) → Inject keywords → Embed (all-MiniLM-L6-v2) → FAISS retrieval → LLM generation (Llama-3-8B-Instruct 4-bit) → Translate output (NLLB-200) → Bengali output
- **Critical path:** Bengali input → Translate → Inject keywords → Embed → FAISS retrieval → Context + strict prompt → LLM generation → Translate back → Bengali output (~15.6s end-to-end on T4 GPU)
- **Design tradeoffs:** Latency (~15.6s) vs. zero API cost and offline capability, Translation error propagation vs. direct low-resource generation errors, Static knowledge base vs. factual grounding reliability, Standard Bengali assumption vs. dialect coverage
- **Failure signatures:** Empty or irrelevant retrieval (check keyword mapping coverage and translation quality), Hallucinated advice (verify prompt constraints, check if quantization degraded instruction-following), Rejection of valid queries (embedding model may not align translated+injected query with manual chunks), Out-of-domain accepted (prompt constraints may be insufficient)
- **First 3 experiments:** 1) Translation isolation test: Feed 50 agricultural queries through Bengali→English translation only; manually assess semantic preservation and domain term accuracy. 2) Keyword ablation: Run retrieval with and without keyword injection on a held-out query set; measure retrieval recall delta. 3) Rejection boundary probe: Submit 20 out-of-domain queries (politics, sports, weather) and 20 borderline agricultural queries; verify rejection behavior matches design intent.

## Open Questions the Paper Calls Out

### Open Question 1
How can cross-lingual RAG systems be adapted to handle regional Bengali dialects (Sylheti, Chittagonian, Rangpuri) that differ from Standard Bengali in spelling, pronunciation, and vocabulary? The authors acknowledge this limitation but propose and test no dialect-handling mechanism.

### Open Question 2
To what extent do Bengali-to-English translation errors propagate through retrieval and generation, and how does this quantitatively affect end-to-end answer accuracy? The paper does not isolate or quantify translation error impact on downstream performance.

### Open Question 3
How effectively can automatic speech recognition (ASR) be integrated to serve illiterate farmers, and what accuracy degradation occurs when ASR errors compound with translation errors? The paper proposes ASR but does not implement or evaluate any speech input mechanism.

### Open Question 4
What latency optimization techniques can reduce the ~15.6 second end-to-end response time to enable real-time conversational interaction while preserving answer quality on consumer hardware? The authors identify latency as a constraint but explore no optimization strategies.

## Limitations
- The domain keyword mapping table is manually curated and not provided, creating uncertainty about coverage completeness
- The system assumes standard Bengali input and does not handle regional dialects or colloquial variations
- 4-bit quantization may degrade the LLM's instruction-following capability, affecting rejection reliability
- Static knowledge base limits the system to information present in the English agricultural manuals

## Confidence
- **High Confidence:** Translation-centric architecture is technically sound and avoids paid APIs while achieving sub-20-second latency
- **Medium Confidence:** Domain keyword injection improves retrieval recall and the system reliably rejects out-of-domain queries
- **Low Confidence:** Manual keyword mapping is scalable and complete for the target domain, quantization does not significantly impair grounding effectiveness, and system performs robustly across regional Bengali dialects

## Next Checks
1. **Keyword Mapping Coverage Audit:** Conduct systematic testing with 100+ colloquial agricultural terms from regional farmers to quantify mapping coverage gaps and measure their impact on retrieval recall.

2. **Quantization Impact Analysis:** Compare hallucination rates and rejection accuracy between 4-bit quantized and full-precision versions of Llama-3-8B-Instruct using controlled test sets of answerable and unanswerable queries.

3. **Dialect Robustness Evaluation:** Test the system with Bengali queries containing regional dialectal variations and local agricultural terminology to assess translation model performance and pipeline resilience.