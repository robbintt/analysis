---
ver: rpa2
title: Legal Infrastructure for Transformative AI Governance
arxiv_id: '2602.01474'
source_url: https://arxiv.org/abs/2602.01474
tags:
- registration
- regulatory
- legal
- they
- regulation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper highlights that transformative AI challenges traditional
  regulatory approaches, calling for new legal infrastructure. Three key innovations
  are proposed: AI model registration regimes to enhance state legibility; AI agent
  registration regimes to ensure accountability in legal and economic transactions;
  and regulatory markets that leverage private sector expertise to translate government-set
  outcomes into technical compliance standards.'
---

# Legal Infrastructure for Transformative AI Governance

## Quick Facts
- **arXiv ID:** 2602.01474
- **Source URL:** https://arxiv.org/abs/2602.01474
- **Reference count:** 0
- **Primary result:** Proposes three legal infrastructure innovations—model registration, agent registration, and regulatory markets—to address state legibility, accountability, and capacity challenges in transformative AI governance

## Executive Summary
This paper addresses the fundamental challenge that transformative AI presents to traditional regulatory approaches. As AI systems become more capable and autonomous, conventional governance mechanisms struggle to maintain oversight and accountability. The paper proposes three key innovations: registration regimes for frontier AI models to establish state legibility; registration regimes for autonomous AI agents to ensure legal accountability in transactions; and regulatory markets that leverage private sector expertise to translate government-set outcomes into technical compliance standards. These infrastructure-focused proposals aim to build effective AI governance in the face of rapid technological change and uncertainty.

## Method Summary
The paper presents a conceptual framework for AI governance infrastructure, drawing on analogies from corporate registration systems and performance-based regulation. It develops theoretical mechanisms for how registration regimes and regulatory markets could function, identifying key design choices and potential failure modes. The analysis is primarily theoretical, building on legal scholarship and regulatory theory rather than empirical testing.

## Key Results
- Registration regimes for frontier models would create state legibility by requiring disclosure of key model characteristics
- Agent registration infrastructure would enable accountability for autonomous economic transactions
- Regulatory markets could address both technical and democratic deficits by licensing private regulators to translate outcomes into standards

## Why This Works (Mechanism)

### Mechanism 1: Frontier Model Registration Enables State Legibility
- Claim: Requiring registration of advanced AI models with government can establish the informational foundation needed for effective oversight.
- Mechanism: Registration mandates → government gains visibility into model capabilities, training data, and risk evaluations → experts develop landscape view of technological development → evidence-based regulatory decisions become possible → registration verification by buyers creates enforcement leverage.
- Core assumption: Governments can staff registries with personnel who can interpret disclosed technical details and maintain confidentiality.
- Evidence anchors:
  - [abstract] "Registration regimes for frontier AI models to address state legibility challenges and enable effective oversight"
  - [section] "On the theory that you can't regulate what you can't see, we proposed that developers seeking to deploy a model in the country be required to register their most advanced models with a national registry" (Page 6)
  - [corpus] Weak direct evidence; corpus papers focus on governance frameworks generally, not empirical validation of registration outcomes. One neighbor paper discusses "AI Deployment Authorisation" as a governance standard.
- Break condition: If key model development shifts to jurisdictions without registration requirements, or if enforcement via buyer verification is circumvented through illicit markets.

### Mechanism 2: Agent Registration Enables Legal Accountability
- Claim: Autonomous AI agents require registration infrastructure to maintain accountability in economic transactions.
- Mechanism: Agent registration requirement → agents have traceable legal identity → counterparties can verify standing before transacting → contracts become enforceable → registration revocation functions as "off-switch" for non-compliant agents.
- Core assumption: AI agents will achieve sufficient autonomy to conduct multi-step economic transactions without real-time human oversight.
- Evidence anchors:
  - [abstract] "Registration regimes for autonomous AI agents to ensure accountability in economic transactions and legal systems"
  - [section] "The missing ingredient for all this to work and make sense is registration... they too will need to have public, durable, and traceable identification, just as other market participants do" (Pages 8-9)
  - [corpus] Neighbors include "Infrastructure for AI Agents" (Chan et al.) and "On the Regulatory Potential of User Interfaces for AI Agent Governance"—suggesting active research but no empirical validation yet.
- Break condition: If agents can economically transact through unregistered channels or if legal personhood frameworks create liability shields rather than accountability.

### Mechanism 3: Regulatory Markets Address Technical and Democratic Deficits
- Claim: Licensing competitive private regulatory service providers (RSPs) can overcome government capacity limitations while maintaining democratic accountability.
- Mechanism: Government sets outcome metrics → licenses multiple competing RSPs → RSPs invest in developing regulatory technology/methods → target companies must engage a licensed RSP → RSPs face license loss if outcomes not achieved → market incentives align with public goals.
- Core assumption: Government can effectively evaluate whether RSPs are achieving outcome metrics even without knowing the technical methods used.
- Evidence anchors:
  - [abstract] "Regulatory markets to overcome technical and democratic deficits in AI governance by licensing private regulatory service providers"
  - [section] "The integrity of the model rests entirely on the capacity of government to regulate RSPs effectively... governments can evaluate performance (outcomes) even if they don't know what the right technology or process is for achieving that performance" (Page 14)
  - [corpus] Weak evidence; no corpus papers validate regulatory market outcomes empirically.
- Break condition: If RSPs become captured by target companies, if insufficient competition emerges, or if government cannot reliably audit RSP performance.

## Foundational Learning

- Concept: **State legibility** (from James Scott)
  - Why needed here: The paper's core argument is that governments cannot regulate what they cannot "see"—registration creates the visibility infrastructure.
  - Quick check question: Can you explain why frontier AI models are currently "illegible" to governments compared to conventional technologies like automobiles?

- Concept: **Performance-based regulation vs. command-and-control**
  - Why needed here: Regulatory markets build on performance-based approaches but add the innovation of licensed third-party translators.
  - Quick check question: What is the key difference between telling a company "implement a risk management system" (command) vs. "achieve X safety outcome" (performance)?

- Concept: **Legal personhood and corporate analogy**
  - Why needed here: The paper uses corporate registration as the historical template for understanding how AI agents might become legally recognizable actors.
  - Quick check question: Why did law evolve to treat corporations as "persons" capable of suing and being sued, and how might this apply to AI agents?

## Architecture Onboarding

- Component map:
  - **Model Registry**: Database of frontier model disclosures (compute, data, parameters, tests conducted)
  - **Agent Registry**: Identity system linking agents to accountable parties or conferring legal standing
  - **RSP Licensing Framework**: Government entity that sets outcomes, evaluates RSP methods, and enforces compliance
  - **Verification Infrastructure**: Technical systems enabling buyers/counterparties to check registration status

- Critical path:
  1. Define registration thresholds (e.g., compute/training data cutoffs for "frontier")
  2. Build secure registry infrastructure with expert staff
  3. Enact verification requirements for buyers/counterparties
  4. Establish outcome metrics for RSP licensing
  5. License initial RSPs and mandate target company engagement

- Design tradeoffs:
  - Disclosure scope vs. compliance burden: Minimal disclosure reduces burden but may limit regulatory utility
  - Registry confidentiality vs. public transparency: Paper explicitly chooses government-only disclosure for legibility (not public transparency)
  - Number of RSPs: Too few risks capture/monopoly; too many may fragment expertise and reduce oversight quality

- Failure signatures:
  - Registry becomes "checkbox compliance" without building real government expertise
  - RSPs converge on lowest-cost methods that nominally satisfy outcomes without achieving safety
  - Agents operate through shell registrations that shield true accountability
  - Foreign developers route through jurisdictions without registration requirements

- First 3 experiments:
  1. Pilot a voluntary disclosure registry to test what information frontier labs can feasibly provide and government experts can interpret
  2. Model the agent registration system on existing corporate registration frameworks to identify gaps for autonomous actors
  3. Conduct regulatory sandbox with 2-3 candidate RSPs in a narrow domain (e.g., biorisk evaluation) to test outcome-setting and oversight feasibility

## Open Questions the Paper Calls Out
None

## Limitations
- The paper provides minimal empirical evidence that governments can effectively process and utilize technical model disclosures
- The timeline for autonomous AI agents achieving transaction-level autonomy remains highly uncertain
- No jurisdiction has successfully implemented regulatory markets for AI or comparably complex domains
- The proposal assumes sufficient competition will emerge among RSPs to prevent capture and ensure quality

## Confidence
- **Medium confidence**: Model registration can improve state legibility if properly staffed and secured
- **Low confidence**: Autonomous AI agents will achieve transaction-level autonomy within policy-relevant timeframes
- **Medium confidence**: Regulatory markets could work in principle, but implementation challenges are substantial and under-specified

## Next Checks
1. **Technical feasibility assessment**: Conduct structured interviews with frontier AI labs to determine what model information they can practically disclose without compromising intellectual property or security, and with regulatory experts to assess what information would actually be useful for oversight.

2. **Agent autonomy timeline survey**: Survey AI researchers and legal scholars to establish probabilistic estimates for when AI agents might achieve sufficient autonomy for independent economic transactions, informing realistic policy timelines.

3. **Regulatory market pilot design**: Develop a detailed implementation plan for a narrow regulatory market pilot (e.g., in a specific safety domain like biorisk) including governance structures, outcome metrics, and oversight mechanisms, then stress-test this design with legal and technical experts.