---
ver: rpa2
title: Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop
  Question Answering
arxiv_id: '2509.18655'
source_url: https://arxiv.org/abs/2509.18655
tags:
- knowledge
- retrieval
- edited
- consistency
- editing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of parameter-preserving knowledge
  editing for multi-hop question answering, where existing methods struggle with consistency
  issues such as knowledge contamination, unstable updates, and misaligned retrieval
  behaviors. The proposed CAPE-KG framework introduces a consistency-aware approach
  by constructing a multi-layer knowledge graph architecture that separates factual
  and edited knowledge, implementing case-isolated update mechanisms with conflict
  arbitration, and designing an edit-aware retrieval module with progressive strategies.
---

# Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering

## Quick Facts
- arXiv ID: 2509.18655
- Source URL: https://arxiv.org/abs/2509.18655
- Reference count: 29
- Key outcome: CAPE-KG achieves 78.03% multi-hop accuracy and 70.35% holistic accuracy on MQuAKE-CF-3K, and 93.39% multi-hop accuracy and 84.52% holistic accuracy on MQUAKE-T, significantly outperforming parameter-preserving baselines.

## Executive Summary
This paper addresses the challenge of parameter-preserving knowledge editing for multi-hop question answering (MHQA), where existing methods struggle with consistency issues such as knowledge contamination, unstable updates, and misaligned retrieval behaviors. The proposed CAPE-KG framework introduces a consistency-aware approach by constructing a multi-layer knowledge graph architecture that separates factual and edited knowledge, implementing case-isolated update mechanisms with conflict arbitration, and designing an edit-aware retrieval module with progressive strategies. Extensive experiments on the MQuAKE benchmark demonstrate that CAPE-KG significantly outperforms existing baselines, achieving 78.03% multi-hop accuracy and 70.35% holistic accuracy on MQuAKE-CF-3K, and 93.39% multi-hop accuracy and 84.52% holistic accuracy on MQUAKE-T, representing substantial improvements over prior parameter-preserving methods. The results validate that enforcing consistency across knowledge boundary, updates, and retrieval effectively enhances the reliability and accuracy of multi-hop knowledge editing.

## Method Summary
CAPE-KG is a parameter-preserving knowledge editing framework for multi-hop question answering that addresses consistency issues through three mechanisms: (1) Knowledge boundary consistency via multi-layer knowledge graphs separating base factual triples from case-specific overlay layers, (2) Update consistency through case-isolated editing with conflict arbitration preventing cross-case contamination, and (3) Intent consistency via edit-aware retrieval routing with progressive strategies. The framework constructs a base layer of original factual triples and dynamic overlay layers for specific editing cases, routes queries based on edit impact surfaces, and employs a progressive retrieval strategy combining high-confidence filtering, LLM selection, and failure fallback with edit injection. The method is evaluated on MQuAKE-CF-3K and MQuAKE-T benchmarks using LLaMA-2-7B, Vicuna-7B, and GPT-3.5-turbo-instruct.

## Key Results
- CAPE-KG achieves 78.03% multi-hop accuracy and 70.35% holistic accuracy on MQuAKE-CF-3K, surpassing parameter-preserving baselines by 17.41% and 17.35% respectively.
- On MQuAKE-T, CAPE-KG reaches 93.39% multi-hop accuracy and 84.52% holistic accuracy, outperforming baselines by 2.61% and 2.62%.
- The framework maintains consistency across 100+ simultaneous edits with minimal accuracy degradation, validating the effectiveness of case-isolated update mechanisms.

## Why This Works (Mechanism)

### Mechanism 1: Knowledge Boundary Isolation via Multi-Layer Graphs
The authors propose that maintaining strict separation between immutable facts and edited facts prevents "knowledge contamination" during multi-hop reasoning. CAPE-KG replaces a single global knowledge graph with a multi-layer architecture where a Base Layer stores original factual triples while Overlay Layers are constructed on-demand for specific editing cases. Queries are explicitly routed; factual queries hit the Base Layer while edit-sensitive queries hit the Overlay. This prevents unrelated edits in the graph from polluting the reasoning chain for general queries.

### Mechanism 2: Update Consistency via Case-Isolated Overlays
The framework suggests that strict isolation of edit storage prevents "update conflicts" (overwrites) observed in global graph editing approaches. Updates are applied atomically to case-specific Overlays using a copy-on-write mechanism. Unlike global graphs where sequential edits might overwrite previous states or conflict, CAPE-KG maintains update consistency by ensuring edits for Case A never modify the base graph or the overlay of Case B. A conflict arbitration module prioritizes the current edit within its specific case scope.

### Mechanism 3: Intent Consistency via Edit-Aware Routing
Routing retrieval based on the "edit impact surface" ensures the system retrieves answers aligned with the user's editing intent, rather than falling back to outdated parametric knowledge. The system calculates an edit impact surface consisting of subjects and relations affected by the edit. A Retrieval Router checks if a sub-question intersects with this surface, routing to the Overlay if it does and to the Base otherwise. Furthermore, a Progressive Retrieval strategy suppresses edit-irrelevant entities and injects the edited triple into the LLM context during failure fallback, forcing intent alignment.

## Foundational Learning

- **Concept: Parameter-Preserving Knowledge Editing (PPKE)**
  - Why needed here: CAPE-KG is a PPKE method. Unlike ROME or MEMIT (which modify weights), PPKE relies on external structures. Understanding this distinction is critical to grasping why "consistency" in the external graph is the primary lever for performance.
  - Quick check question: How does PPKE handle knowledge updates differently from fine-tuning, and what structural component does CAPE-KG rely upon?

- **Concept: Knowledge Graph Triples & Multi-Hop Paths**
  - Why needed here: The paper defines knowledge as triples (s, r, o) and reasoning as paths. The "Knowledge Boundary" mechanism operates entirely on the topology of these triples. You must understand how a multi-hop question decomposes into a chain of triples to understand why contamination breaks the chain.
  - Quick check question: If an edit changes (s₁, r₁, o₁) → (s₁, r₁, o₁*), why is it critical to update the starting point of the next hop (s₂=r₁*, ...)?

- **Concept: Case-Isolated Assumption**
  - Why needed here: This is a core constraint of the paper. The architecture is built to enforce this isolation. Without understanding this assumption, the complexity of the "Overlay" system seems unnecessary compared to a simple global update.
  - Quick check question: In CAPE-KG, if User A edits "The capital of France" to "Lyon" and User B asks "What is the capital of France?", which layer does the system query for User B?

## Architecture Onboarding

- **Component map:** Input Question → Decomposition → Sub-Question Loop: [Router checks edit impact surface] → [Route to Base or Overlay] → [Retrieve candidate entities] → [Progressive Filtering/Scoring] → Final Answer

- **Critical path:** The system decomposes the input question, routes each sub-question based on whether it intersects with the edit impact surface, retrieves candidates from the appropriate layer, applies progressive filtering and scoring, and generates the final answer.

- **Design tradeoffs:** The paper explicitly notes Progressive Retrieval introduces inference overhead (Table 7 shows ~20-40ms increase per sub-question) compared to single-pass retrieval, justified by higher accuracy. The system prioritizes preventing cross-case contamination (isolation), potentially at the cost of not supporting globally shared knowledge updates efficiently.

- **Failure signatures:** Contamination occurs when retrieval returns an entity from an unrelated edit case. Retrieval Collapse happens when high uncertainty scores lead to repeated LLM fallback calls, increasing latency and potentially hallucinations. Router Miss occurs when the Edit-Aware Router fails to match the sub-question to the edit surface, causing the query to hit the Base Layer and return old (incorrect) facts.

- **First 3 experiments:** (1) Ablation of Consistency Types: Disable each consistency mechanism (Boundary, Update, Intent) one by one to measure the drop in Hop Accuracy. (2) Batch Edit Scaling: Stress test the "Update Consistency" by increasing the number of edits per batch (comparing 1-edit vs. 100-edit vs. All-edit) to verify the stability of Overlay isolation vs. global graph baselines. (3) Router Stress Test: Evaluate the Edit-Aware Router on ambiguous questions where the subject is implied but not explicit, to test the robustness of the "edit impact surface" detection.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can CAPE-KG be extended to support continual knowledge editing over time?
- Basis in paper: The conclusion states that future work involves extending the framework to "continual knowledge editing, ensuring consistency as edits evolve over time."
- Why unresolved: The current framework is designed for case-isolated batch edits but does not address the complexities of maintaining consistency as edits accumulate or change sequentially.
- What evidence would resolve it: Evaluation of the framework on a continual editing benchmark demonstrating maintained consistency and accuracy across sequential edit operations.

### Open Question 2
- Question: Can the inference latency introduced by progressive retrieval be reduced without sacrificing consistency?
- Basis in paper: The Limitations section acknowledges that the "progressive retrieval strategy introduces additional inference latency," which is accepted as a trade-off for consistency.
- Why unresolved: The paper prioritizes accuracy over efficiency, leaving the optimization of the multi-stage retrieval process for real-time applications as an open challenge.
- What evidence would resolve it: A modified retrieval strategy that significantly lowers average latency per sub-question while retaining comparable Match Accuracy.

### Open Question 3
- Question: How can the framework be adapted for settings requiring globally shared knowledge updates?
- Basis in paper: The method relies on a "case-isolated edit assumption," and the authors explicitly exclude scenarios where "knowledge updates are globally shared" from the scope.
- Why unresolved: The current case-isolation mechanism prevents an edit from propagating across different users or contexts, limiting applicability in collaborative or global knowledge base environments.
- What evidence would resolve it: An extension of the architecture that supports global edit propagation and successful evaluation on a benchmark designed for shared updates.

## Limitations
- Evaluation Scope: The experimental validation focuses on two specialized benchmarks (MQuAKE-CF-3K and MQuAKE-T) rather than general knowledge bases, limiting generalizability to real-world applications.
- Implementation Details: Critical components like the entity/relation detector architecture and the specific base knowledge graph source are underspecified, requiring assumptions for reproduction.
- Inference Overhead: The progressive retrieval strategy introduces additional inference latency (~20-40ms per sub-question), which may impact real-time applications.

## Confidence
- **High Confidence**: The multi-layer graph architecture and case-isolated update mechanism are well-defined and empirically validated (Table 1, Table 2).
- **Medium Confidence**: The edit-aware retrieval routing mechanism's effectiveness is demonstrated, but the entity/relation detection component lacks implementation specifics.
- **Low Confidence**: The claim about knowledge contamination prevention in general settings relies heavily on the specific benchmark setup rather than broader testing.

## Next Checks
1. **Cross-Case Contamination Test**: Implement a stress test with 100+ simultaneous edits to verify that CAPE-KG maintains >95% hop accuracy while baselines degrade significantly.
2. **General Knowledge Base Validation**: Test CAPE-KG on a standard knowledge base like Wikidata to assess performance outside the specialized MQuAKE benchmarks.
3. **Entity/Relation Detector Benchmark**: Evaluate the detection component's precision and recall on ambiguous questions to quantify routing accuracy and identify failure patterns.