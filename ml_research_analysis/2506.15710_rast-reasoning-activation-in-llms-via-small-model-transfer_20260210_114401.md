---
ver: rpa2
title: 'RAST: Reasoning Activation in LLMs via Small-model Transfer'
arxiv_id: '2506.15710'
source_url: https://arxiv.org/abs/2506.15710
tags:
- reasoning
- rast
- base
- arxiv
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RAST, a decoding-time method that transfers
  reasoning behaviors from small RL-tuned models to larger base models by injecting
  logit-level adjustments, avoiding the computational cost of full RL training at
  scale. The key insight is that RL-induced changes in output distributions are largely
  model-size invariant, concentrating on a small set of reasoning-critical tokens.
---

# RAST: Reasoning Activation in LLMs via Small-model Transfer
## Quick Facts
- arXiv ID: 2506.15710
- Source URL: https://arxiv.org/abs/2506.15710
- Reference count: 40
- Key outcome: Achieves up to 80.7% pass@1 on MATH500 by transferring reasoning behaviors from a small RL-tuned model to a 32B base model via logit-level adjustments, significantly outperforming the base model (68.6%) and approaching RL-tuned performance (81.3%).

## Executive Summary
RAST introduces a decoding-time method to activate reasoning in large language models by transferring behaviors from a small RL-tuned expert. Instead of costly full RL fine-tuning, RAST applies delta logits from the expert to guide the larger base model during inference. The key insight is that RL-induced changes in output distributions are largely model-size invariant, concentrating on a small set of reasoning-critical tokens. This enables effective reasoning transfer without the computational expense of scaling RL to larger models.

## Method Summary
RAST works by first RL-tuning a small base model on reasoning tasks, then extracting the logit differences (delta logits) between this expert and the original small base model. These delta logits are applied during inference to a larger target model, effectively transferring the reasoning behavior. The method leverages the observation that RL tuning concentrates output distribution changes on a small set of tokens critical for reasoning. By focusing on these tokens, RAST achieves reasoning improvements in larger models without requiring full RL fine-tuning at scale.

## Key Results
- RAST with ∆R14B applied to a 32B base model achieved 80.7% pass@1 on MATH500 versus 68.6% for the base and 81.3% for RL.
- Across Qwen-2.5 and Llama-3.1 model families, RAST consistently improved performance on MATH500, AIME, GSM8K, Olympiad Bench, HumanEval+, and LiveCodeBench.
- RAST significantly reduces GPU memory usage compared to full RL training while maintaining or surpassing RL-tuned performance.

## Why This Works (Mechanism)
RAST works because RL-induced changes in output distributions are largely model-size invariant, concentrating on a small set of reasoning-critical tokens. By extracting and applying these changes as delta logits during inference, the method transfers reasoning behaviors without requiring full RL fine-tuning at scale. This approach is efficient because it focuses only on the tokens most important for reasoning, avoiding the need to retrain large models end-to-end.

## Foundational Learning
- **Reinforcement Learning (RL) fine-tuning**: Used to train a small expert model on reasoning tasks, creating a reference for desired reasoning behaviors.
  - Why needed: Establishes a high-quality reasoning model whose behaviors can be transferred.
  - Quick check: Verify RL fine-tuning improves reasoning performance on target tasks.
- **Logit-level adjustments**: Small changes to model output logits that guide reasoning behavior during inference.
  - Why needed: Enables transfer of reasoning behaviors without modifying model weights.
  - Quick check: Confirm delta logits improve reasoning when applied during inference.
- **Model-size invariance**: The observation that RL-induced output distribution changes are similar across model sizes.
  - Why needed: Allows transfer from small expert to large target models.
  - Quick check: Compare delta logits across different model sizes to verify similarity.

## Architecture Onboarding
- **Component map**: Small RL-tuned expert -> Delta logit extraction -> Target base model inference
- **Critical path**: RL fine-tuning (small model) → Delta logit generation → Inference-time logit adjustment (large model)
- **Design tradeoffs**: Balances computational efficiency (avoiding full RL on large models) against potential performance ceiling from expert quality
- **Failure signatures**: Poor expert quality, mismatch between expert and target model architectures, or non-reasoning-aligned delta logits
- **3 first experiments**:
  1. Verify RL fine-tuning improves small model reasoning performance
  2. Test delta logit application on small target model to confirm transfer works at same scale
  3. Apply delta logits to larger target model and measure performance gains

## Open Questions the Paper Calls Out
- None

## Limitations
- Performance depends heavily on the quality and reasoning alignment of the small RL-tuned expert model
- The model-size invariance assumption may not generalize to all reasoning domains or model architectures
- Effectiveness is constrained to domains with well-defined, predictable reasoning traces

## Confidence
- High: Empirical results on standard reasoning benchmarks are comprehensive and comparisons include strong baselines
- Medium: Model-size invariance hypothesis is well-supported but not rigorously proven across all sizes and tasks
- Low: Claims about generalization to non-mathematical or abstract reasoning tasks lack evaluation

## Next Checks
1. Test RAST on non-mathematical reasoning tasks (e.g., common sense reasoning, multi-step planning) to assess generalizability beyond the evaluated domains.
2. Evaluate RAST across a broader range of model families and architectures (e.g., decoder-only vs. encoder-decoder) to confirm robustness to architectural differences.
3. Measure the sensitivity of RAST's performance to the quality and diversity of the small RL-tuned expert model, including ablation studies with weaker or misaligned experts.