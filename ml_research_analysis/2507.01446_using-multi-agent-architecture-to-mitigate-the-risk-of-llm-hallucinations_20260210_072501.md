---
ver: rpa2
title: Using multi-agent architecture to mitigate the risk of LLM hallucinations
arxiv_id: '2507.01446'
source_url: https://arxiv.org/abs/2507.01446
tags:
- agent
- will
- message
- agents
- customer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents a multi-agent system for processing SMS-based\
  \ customer requests in pharmacy settings, integrating Large Language Models (LLMs)\
  \ with fuzzy logic to reduce hallucination risks. The system uses an orchestration\
  \ agent to dynamically route messages to specialized worker agents\u2014one using\
  \ regex and fuzzy logic, another leveraging LLM tools for complex parsing."
---

# Using multi-agent architecture to mitigate the risk of LLM hallucinations

## Quick Facts
- **arXiv ID**: 2507.01446
- **Source URL**: https://arxiv.org/abs/2507.01446
- **Reference count**: 0
- **Primary result**: Multi-agent system for SMS-based pharmacy requests reduces LLM hallucinations through cross-validation and fuzzy logic

## Executive Summary
This paper presents a multi-agent system designed to process SMS-based customer requests in pharmacy settings while mitigating the risk of LLM hallucinations. The architecture combines Large Language Models (LLMs) with fuzzy logic and orchestration agents to dynamically route messages to specialized worker agents. The system employs validation agents that compare outputs across different LLMs (Gemini, ChatGPT) to detect hallucinations, while fuzzy rules assess confidence and risk levels. Testing on 10 SMS samples showed promising results with accurate keyword extraction and only one false positive across 50 repeated trials.

## Method Summary
The system implements a multi-agent architecture where an orchestration agent dynamically routes SMS messages to specialized worker agents based on message complexity. Simple requests are processed by a regex and fuzzy logic agent, while complex requests are handled by an LLM-powered agent. Two validation agents cross-check outputs from different LLMs (Gemini and ChatGPT) to identify potential hallucinations. The fuzzy logic component evaluates confidence scores and applies risk assessment rules to flag uncertain outputs. The approach integrates domain-specific knowledge through carefully designed fuzzy rules that assess the reliability of extracted information from pharmacy-related messages.

## Key Results
- System achieved accurate keyword extraction from pharmacy SMS requests with only one false positive across 50 repeated trials
- Cross-validation between Gemini and ChatGPT effectively identified potential hallucinations in processed messages
- Fuzzy logic rules successfully assessed confidence levels and flagged high-risk outputs for pharmacist review

## Why This Works (Mechanism)
The multi-agent architecture reduces hallucination risk through redundancy and specialization. By having multiple LLMs process the same request independently, the system can identify discrepancies that may indicate hallucinations. The fuzzy logic component provides an additional layer of validation by applying domain-specific confidence thresholds rather than relying solely on LLM outputs. The orchestration agent's ability to route requests to appropriate specialized agents ensures that each task is handled by the most suitable processing method, reducing the likelihood of errors that could lead to hallucinations.

## Foundational Learning

**Multi-agent orchestration** - why needed: Coordinates specialized agents for optimal task routing; quick check: Verify message routing logic correctly identifies agent capabilities

**Cross-model validation** - why needed: Identifies hallucinations through output discrepancies; quick check: Test with known hallucinated outputs to confirm detection

**Fuzzy logic confidence scoring** - why needed: Provides domain-specific reliability assessment beyond LLM confidence scores; quick check: Validate fuzzy rules against expert pharmacist judgments

**Regex + LLM hybrid processing** - why needed: Balances efficiency of pattern matching with flexibility of LLMs; quick check: Measure processing time and accuracy trade-offs

## Architecture Onboarding

**Component map**: SMS input -> Orchestration Agent -> [Regex Agent | LLM Agent] -> Validation Agents (Gemini & ChatGPT) -> Fuzzy Logic Assessor -> Output/Flag

**Critical path**: SMS reception → Orchestration → Specialized processing → Cross-validation → Fuzzy confidence scoring → Result delivery

**Design tradeoffs**: Simplicity vs. accuracy (single LLM vs. multi-agent), processing speed vs. thoroughness (direct vs. validated output), domain specificity vs. generalization (custom fuzzy rules vs. generic confidence scores)

**Failure signatures**: False positives in validation (low-confidence but correct outputs flagged), routing errors (complex requests sent to regex agent), fuzzy rule misclassification (incorrect confidence scoring)

**3 first experiments**:
1. Test routing accuracy by sending mixed-complexity SMS samples through orchestration agent
2. Validate cross-model consistency by comparing Gemini and ChatGPT outputs on identical inputs
3. Evaluate fuzzy logic effectiveness by measuring confidence score correlation with actual accuracy

## Open Questions the Paper Calls Out
None

## Limitations
- Small test corpus of only 10 SMS samples limits generalizability to broader pharmacy contexts
- Unclear testing methodology regarding "50 repeated trials" - whether same samples or different
- Lack of detailed methodology for developing and validating fuzzy logic rules

## Confidence

**Accurate keyword extraction**: Medium confidence - based on limited sample size of 10 SMS messages
**Successful hallucination mitigation**: Low confidence - no baseline comparisons or detailed evaluation metrics provided
**Fuzzy logic effectiveness**: Medium confidence - validation methodology not fully specified

## Next Checks

1. Test the system on a larger, more diverse corpus of pharmacy SMS messages to assess generalizability across different request types and language patterns
2. Implement controlled experiments comparing the multi-agent approach against single-agent LLM solutions to quantify the actual improvement in hallucination reduction
3. Conduct a detailed error analysis of the false positive case and develop a systematic evaluation framework for fuzzy logic rule effectiveness across various message complexities