---
ver: rpa2
title: Can You Tell the Difference? Contrastive Explanations for ABox Entailments
arxiv_id: '2511.11281'
source_url: https://arxiv.org/abs/2511.11281
tags:
- qdiff
- qcom
- since
- abox
- size
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces contrastive ABox explanations (CEs) to answer
  questions like "Why is a an instance of C, but b is not?" Unlike traditional justifications
  or abductions, CEs consider both entailments jointly, focusing on relevant commonalities
  and differences. The authors formalize CEs, analyze their computational complexity
  across multiple dimensions (DLs, optimality criteria, etc.), and implement a first
  prototype for computing difference-minimal syntactic CEs.
---

# Can You Tell the Difference? Contrastive Explanations for ABox Entailments

## Quick Facts
- **arXiv ID:** 2511.11281
- **Source URL:** https://arxiv.org/abs/2511.11281
- **Reference count:** 40
- **Key outcome:** Introduces contrastive ABox explanations (CEs) that consider both fact and foil entailments jointly, enabling answers like "Why is a an instance of C, but b is not?" The work formalizes CEs, analyzes their complexity, and implements a prototype for difference-minimal syntactic CEs.

## Executive Summary
This paper introduces contrastive ABox explanations (CEs) to answer questions like "Why is a an instance of C, but b is not?" Unlike traditional justifications or abductions, CEs consider both entailments jointly, focusing on relevant commonalities and differences. The authors formalize CEs, analyze their computational complexity across multiple dimensions (DLs, optimality criteria, etc.), and implement a first prototype for computing difference-minimal syntactic CEs. Theoretical results show that verifying subset difference-minimality is tractable (P for EL/EL⊥, EXPTIME for ALC), while cardinality-based and conflict-minimality are harder. Experiments on realistic ontologies show CEs are typically small, though computation can be slow due to large intermediate structures. Conflicts are rare in practice. The work opens avenues for more efficient CE computation and integration into ontology-based query answering.

## Method Summary
The method computes contrastive explanations by constructing a CE super-structure containing all possible variable mappings between fact and foil individuals, then iteratively removing assertions to satisfy minimality constraints while preserving entailment. The algorithm builds a maximal ABox pattern structure ($E_m$) containing all possible variable mappings between the "fact" (individual $a$) and the "foil" (individual $b$). It then iteratively removes atoms (assertions) from this structure to satisfy minimality constraints while preserving entailment, using the reasoner as an oracle. The approach supports different DLs (EL/EL⊥, ALC) and optimality criteria (difference-minimality, conflict-minimality).

## Key Results
- Difference-minimal syntactic CEs can be computed in polynomial time given an entailment oracle
- Verifying subset difference-minimality is P for EL/EL⊥ and EXPTIME for ALC
- Conflict-minimality and cardinality-based variants are EXPTIME-complete with exponential size bounds
- CEs are typically small in realistic ontologies, though computation can be slow
- Conflicts are rare in practice according to evaluation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Contrastive Explanations (CEs) can be computed tractably for syntactic variants by embedding the search space into a "CE Super-Structure."
- **Mechanism:** Rather than searching the infinite space of possible logical formulas, the system constructs a maximal ABox pattern structure ($E_m$) containing all possible variable mappings between the "fact" (individual $a$) and the "foil" (individual $b$). It then iteratively removes atoms (assertions) from this structure to satisfy minimality constraints while preserving entailment, using the reasoner as an oracle.
- **Core assumption:** The number of relevant assertions in the neighborhood of the fact and foil is bounded, allowing the super-structure to fit in memory despite potential exponential worst-case scenarios for other variants.
- **Evidence anchors:**
  - [Section 4] Theorem 11 states that difference-minimal syntactic CEs can be computed in polynomial time with an entailment oracle.
  - [Section 4] Describes the "CE super-structure" construction using pairs of individuals.
  - [corpus] *Why this and not that? A Logic-based Framework for Contrastive Explanations* explores similar logical frameworks, but this paper focuses specifically on the structural embedding mechanism.
- **Break condition:** The mechanism fails if the "justification" for the fact involves a massive number of interconnected individuals, causing the super-structure to grow unmanageably large.

### Mechanism 2
- **Claim:** Explanations are rendered more interpretable by explicitly partitioning evidence into "Commonality" ($q_{com}$) and "Difference" ($q_{diff}$) patterns.
- **Mechanism:** The algorithm identifies assertions that hold for the *fact* ($a$) but are missing for the *foil* ($b$). It groups assertions common to both into $q_{com}$ and discriminative assertions into $q_{diff}$. This filters out irrelevant information that would appear in isolated positive/negative justifications.
- **Core assumption:** Users find contrastive comparisons ("X has Feature F, but Y does not") more cognitively tractable than independent justifications for X and Y.
- **Evidence anchors:**
  - [Section 3] Definition 1 formalizes the split between $q_{com}$ and $q_{diff}$.
  - [Section 1] Introduction highlights that contrastive explanations focus on "relevant commonalities and differences."
- **Break condition:** If the fact and foil share no properties (disconnected graph components), $q_{com}$ remains empty, potentially resulting in a less insightful explanation.

### Mechanism 3
- **Claim:** Enforcing "Conflict-Minimality" (avoiding contradictions with the KB) transforms the problem from polynomial-time to exponential complexity.
- **Mechanism:** To explain a foil's failure without contradicting known facts, the system often requires the introduction of "fresh individuals" (hypothetical entities). The existence of these entities must be verified against all possible "types" in the ontology (type-elimination), which is computationally expensive.
- **Core assumption:** Realistic ontologies rarely contain the dense conflicts that trigger the worst-case exponential blowup.
- **Evidence anchors:**
  - [Section 5] Theorem 17 and 18 prove EXPTIME-completeness and exponential size bounds for conflict-minimal CEs.
  - [Section 7] Evaluation notes that "conflicts are a relatively rare occasion" in realistic data.
- **Break condition:** If the ontology contains axioms that force individuals to belong to many overlapping or disjoint types (high interaction), the conflict-checking phase will stall.

## Foundational Learning

- **Concept:** **Description Logic (DL) ABoxes & TBoxes**
  - **Why needed here:** The entire framework is built on DL semantics (specifically $\mathcal{EL}$ and $\mathcal{ALC}$). Understanding the distinction between the TBox (schema/rules) and ABox (data/instances) is required to parse how entailments ($\models$) propagate.
  - **Quick check question:** Can you distinguish between a GCI (General Concept Inclusion) in the TBox and a concept assertion in the ABox?

- **Concept:** **Justification-based Explanation**
  - **Why needed here:** The paper's "Super-Structure" relies on computing "Justifications" (minimal subsets of axioms that support an entailment) as a preprocessing step. You must understand that a justification is a minimal proof fragment.
  - **Quick check question:** Given a Knowledge Base $K$ where $K \models \alpha$, what is the definition of a justification $J$ for $\alpha$?

- **Concept:** **Homomorphisms & Variable Mapping**
  - **Why needed here:** The core solution involves ABox "patterns" (queries with variables). The mechanism works by finding homomorphisms (mappings) from these variable patterns to the concrete individuals in the Knowledge Base.
  - **Quick check question:** If a pattern $q(x)$ contains $r(x, y)$, what condition must hold for a mapping $\sigma$ to be a valid homomorphism to the ABox?

## Architecture Onboarding

- **Component map:** Input Parser -> Justification Extractor -> Super-Structure Builder -> Minimizer (The Optimizer) -> Output Formatter

- **Critical path:** The system bottlenecks at the **Justification Extractor** and the **Minimizer's** calls to the reasoner. While the algorithm is polynomial *given an oracle*, the practical runtime depends heavily on the underlying reasoner's speed (ELK for $\mathcal{EL}$, HermiT for $\mathcal{ALC}$).

- **Design tradeoffs:**
  - **Syntactic vs. Semantic CEs:** Syntactic CEs only use explicit assertions (faster, PTime). Semantic CEs require pre-computing all entailed assertions (closure materialization), which increases preprocessing time but yields deeper explanations.
  - **Difference vs. Conflict Minimality:** The prototype defaults to Difference-minimality. Enabling Conflict-minimality is safer for correctness but introduces risk of exponential hangs on complex ontologies.

- **Failure signatures:**
  - **Trivial Explanations:** If the ABox is sparse, the system returns "trivial CEs" (e.g., $q_{diff} = \{C(x)\}$). This implies the data lacks the depth for meaningful contrastive analysis.
  - **Timeouts in Minimizer:** If the P4 step (minimizing conflicts) loops indefinitely, the ontology likely contains dense contradictions or requires too many fresh individuals.
  - **Out-of-Memory during Super-Structure Creation:** This occurs if the justification for the fact $C(a)$ involves an extremely large number of connected individuals.

- **First 3 experiments:**
  1. **Sanity Check (Syntactic):** Run the prototype on a simple hiring ontology (like the paper's example). Verify that $q_{com}$ captures shared traits and $q_{diff}$ captures the specific discriminator.
  2. **Scalability Test:** Execute against the ORE 2015 competition corpus. Plot computation time against the size of the ABox justification to validate the polynomial claim.
  3. **Conflict Stress Test:** Construct a synthetic ontology with dense disjointness axioms (e.g., $A \sqsubseteq \neg B$, $B \sqsubseteq \neg C \dots$). Attempt to compute conflict-minimal CEs and verify the exponential runtime behavior.

## Open Questions the Paper Calls Out

- **Open Question 1:** What is the computational complexity of counting and enumerating all optimal contrastive explanations (CEs)?
  - **Basis in paper:** [explicit] The conclusion states that "one can address the counting and enumeration complexity for CEs" as a direction for future work.
  - **Why unresolved:** The current theoretical analysis focuses on the decision and verification problems for single explanations, not the complexity of finding all of them.
  - **What evidence would resolve it:** A formal complexity analysis (e.g., #P-completeness) for counting CEs, or algorithms with bounded delay for enumeration.

- **Open Question 2:** Can the definition of contrastive explanations be extended to use quantified variables in the fact and foil vectors?
  - **Basis in paper:** [explicit] The authors mention, "We are also exploring a variant of CEs which use quantified variables in the fact and foil vectors."
  - **Why unresolved:** The current definition uses vectors of individual names; introducing quantified variables would change the expressivity and structure of the explanation patterns.
  - **What evidence would resolve it:** A formalization of this variant and an analysis of its computational properties.

- **Open Question 3:** Can dedicated algorithms be developed to compute contrastive explanations more efficiently than the current super-structure approach?
  - **Basis in paper:** [explicit] The conclusion proposes to "investigate dedicated algorithms for computing CEs more efficiently," noting the prototype is slow.
  - **Why unresolved:** The current method relies on constructing a large "super-structure" ($E_m$), which the authors note "often results in very large super-structures" and long computation times.
  - **What evidence would resolve it:** An algorithm that avoids the explicit construction of the full super-structure, demonstrating significantly lower runtimes on the benchmark corpora used in Section 7.

## Limitations

- **Super-structure scalability:** While theoretically polynomial, practical scalability depends heavily on justification size and may become prohibitive for larger ontologies.
- **Conflict-minimality rarity:** The evaluation suggests conflicts are rare, limiting empirical validation of more complex conflict-minimality algorithms.
- **Implementation dependencies:** Prototype relies on specific implementations of justification computation and reasoning (EVEE-LIB, ELK, HermiT), which may have their own limitations.

## Confidence

- **High confidence:** Theoretical complexity results (PTime for difference-minimal syntactic CEs, EXPTIME for conflict-minimality) are well-established through formal proofs.
- **Medium confidence:** Empirical evaluation shows approach works on tested ontologies, but restricted KB size and rarity of conflicts limit generalizability.
- **Low confidence:** Long-term practical viability for very large ontologies or those with frequent conflicts, as these cases were not thoroughly tested.

## Next Checks

1. **Benchmark on larger ontologies:** Test the prototype on ontologies exceeding 10,000 axioms to assess scalability limitations and identify thresholds where computation becomes impractical.

2. **Stress-test conflict scenarios:** Construct synthetic ontologies with frequent conflicts (dense disjointness axioms) to verify exponential behavior of conflict-minimality algorithms and measure actual runtime blowup.

3. **Cross-reasoner validation:** Implement CE computation using alternative justification and reasoning tools to ensure results are not artifacts of specific ELK/HermiT implementations used in the prototype.