---
ver: rpa2
title: 'HiVA: Self-organized Hierarchical Variable Agent via Goal-driven Semantic-Topological
  Evolution'
arxiv_id: '2509.00189'
source_url: https://arxiv.org/abs/2509.00189
tags:
- agent
- feedback
- task
- tool
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HiVA introduces a novel multi-agent framework that evolves both
  agent semantics and collaboration topology from a singleton, enabling adaptive intelligence
  in complex tasks. By unifying Semantic-Topological Evolution (STEV) with textual
  gradients as discrete-domain surrogates for backpropagation, HiVA jointly optimizes
  agent behaviors and their interaction structures through a dynamic computational
  graph.
---

# HiVA: Self-organized Hierarchical Variable Agent via Goal-driven Semantic-Topological Evolution

## Quick Facts
- arXiv ID: 2509.00189
- Source URL: https://arxiv.org/abs/2509.00189
- Reference count: 38
- Improves multi-agent task accuracy by 5-10% over state-of-the-art baselines

## Executive Summary
HiVA introduces a novel multi-agent framework that evolves both agent semantics and collaboration topology from a singleton, enabling adaptive intelligence in complex tasks. By unifying Semantic-Topological Evolution (STEV) with textual gradients as discrete-domain surrogates for backpropagation, HiVA jointly optimizes agent behaviors and their interaction structures through a dynamic computational graph. Experiments across mathematical, long-context, programmatic, and textual reasoning tasks demonstrate improvements of 5-10% in accuracy over state-of-the-art baselines, with enhanced resource efficiency in agentic environments. Qualitative analyses and ablation studies confirm the necessity of co-evolving semantics and topology for optimal performance. HiVA establishes a scalable, self-organizing approach to multi-agent coordination, offering a foundation for future advances in autonomous task execution.

## Method Summary
HiVA implements a self-evolving multi-agent system using Semantic-Topological Evolution (STEV) that jointly optimizes agent prompts and collaboration topology through textual gradient descent. The system starts as a singleton agent and iteratively refines both semantic parameters (prompts, tools) and graph structure (agent connections) based on environmental feedback. Forward passes route tasks through a dynamically constructed subgraph using Knowledge-Aware Bayesian-Bandit (KABB) routing, while backward passes propagate textual gradients parsed from LLM feedback to update both agent semantics (via f_P) and topology (via f_G). The framework employs Thompson Sampling for agent selection, penalized by a knowledge-based cost function, and uses a textual gradient parser to convert natural language feedback into structured update commands. The optimization loop iterates for up to 10 cycles on sampled datasets including MATH, GSM-8K, HotpotQA, HumanEval, and MBPP.

## Key Results
- Achieves 5-10% accuracy improvements over state-of-the-art baselines across mathematical, programmatic, and reasoning tasks
- Demonstrates superior resource efficiency with a cost-efficiency score (CS) combining accuracy and computational cost
- Validates the necessity of co-evolving semantics and topology through ablation studies showing performance degradation when either component is removed

## Why This Works (Mechanism)

### Mechanism 1: Textual Gradient Descent as a Surrogate for Backpropagation
- Claim: Treating natural language feedback as a gradient signal enables optimization in non-differentiable agent graphs.
- Mechanism: The framework uses a Textual Gradient Parser (an LLM) to convert environmental feedback into structured update instructions. This global textual gradient is then decomposed via a "textual chain rule" into localized, agent-specific critiques that guide modifications to prompts and topology. The update rule is defined symbolically as: s_{t+1} ← s_t ⊕ Δs_t, where Δs_t is the textual gradient command.
- Core assumption: The "gradient" generated by an LLM is a semantically consistent and useful signal that can be effectively parsed into actionable commands for modifying agent behavior and structure.
- Evidence anchors:
  - [abstract] "...optimizes hybrid semantic-topological spaces using textual gradients as discrete-domain surrogates for backpropagation."
  - [section 3.1] "...introduce the Textual Gradient...as a functional substitute...This reframes the optimization as a Generalized Gradient Descent process, with an update rule s_{t+1} ← s_t ⊕ Δs_t..."
  - [corpus] SEW: Self-Evolving Agentic Workflows for Automated Code Generation (arXiv:2505.18646) discusses evolving agentic workflows, suggesting a broader interest in these optimization methods, but does not validate this specific textual gradient mechanism.
- Break condition: The mechanism fails if the LLM generating the textual gradient cannot reliably diagnose the root cause of a failure, leading to a corrupted update signal (local optimum trap).

### Mechanism 2: Co-evolution of Agent Semantics and Collaboration Topology
- Claim: A multi-agent system achieves superior adaptability by jointly optimizing what agents do (prompts/tools) and how they are connected (graph topology).
- Mechanism: The Semantic-Topological Evolution (STEV) algorithm iterates through forward passes (task execution) and backward passes (feedback propagation). In the backward pass, two functions are triggered: f_P (semantic evolution) refines an agent's prompt and tools based on its localized textual gradient, while f_G (topological evolution) modifies the agent's connections (adding/removing successors). This allows the system to self-organize from a singleton into a specialized, complex graph.
- Core assumption: The optimal problem-solving architecture is not fixed and can be dynamically discovered through iterative feedback and structural mutation.
- Evidence anchors:
  - [abstract] "...HiVA jointly optimizes agent behaviors and their interaction structures..."
  - [section 3.6] "...core innovation lies in simultaneously optimizing agent semantic parameters and network topology from singleton through two complementary functions f_P and f_G..."
  - [corpus] Alita: Generalist Agent Enabling Scalable Agentic Reasoning (arXiv:2505.20286) emphasizes "minimal predefinition and maximal self-evolution," which aligns with the core principle but does not validate the specific STEV algorithm.
- Break condition: The mechanism fails if the topological modifications create cycles (which break the feedback flow) or if the system grows too complex for the routing mechanism to manage efficiently.

### Mechanism 3: Knowledge-Aware Bayesian-Bandit (KABB) Routing
- Claim: Integrating a knowledge graph with a Multi-Armed Bandit (MAB) policy enables efficient, context-aware selection of agents for a given task.
- Mechanism: Agent selection is modeled as an MAB problem. A Knowledge-Based Cost Function (Dist(A_i, I_task)) quantifies the semantic mismatch between an agent's capabilities and a task's requirements using an external knowledge graph. This cost acts as a penalty term, biasing the Thompson Sampling policy to select agents that are both historically successful and semantically relevant.
- Core assumption: A domain-specific knowledge graph can accurately encode the semantic relationship between tasks and agent capabilities, and that this formal knowledge improves upon purely performance-based (reward-only) selection.
- Evidence anchors:
  - [abstract] "...iterative process comprises Multi-Armed Bandit-infused forward routing..."
  - [section 3.4] "Dynamic routing underpins HiVA's efficiency... It models agent selection as a Multi-Armed Bandit (MAB) problem, solved using Thompson Sampling...penalized by a knowledge-based cost function..."
  - [corpus] Corpus evidence for this specific KABB implementation is weak or missing among the provided neighbors.
- Break condition: The mechanism fails if the knowledge graph's domain is mismatched with the task environment, or if the cost function parameters (weights ω_k) are poorly calibrated, leading to suboptimal routing decisions.

## Foundational Learning

- Concept: **Directed Acyclic Graphs (DAGs) for computational workflows**
  - Why needed here: HiVA models its multi-agent system as a dynamic DAG where nodes are agents and edges represent data flow. The framework relies on topological ordering to ensure predictable forward execution and backward gradient propagation.
  - Quick check question: Can you explain why a cycle in the agent graph would break the backward pass of the textual gradient propagation?

- Concept: **Multi-Armed Bandits & Thompson Sampling**
  - Why needed here: The system must choose which agents to activate for a task, balancing exploration (trying new agents) with exploitation (using known good agents). Thompson Sampling provides a probabilistic framework for this decision-making process.
  - Quick check question: In the KABB routing formula, what does the term P_i ∝ α_i / (α_i + β_i) represent in terms of an agent's historical performance?

- Concept: **Prompt Engineering & Optimization**
  - Why needed here: The "semantics" of an agent are primarily encoded in its system prompt. Understanding how to structure prompts for specific roles (e.g., "You are a tool generation specialist...") is essential, as the f_P function automatically rewrites these prompts.
  - Quick check question: How might a poorly written initial system prompt hinder the semantic evolution process, even with accurate textual gradients?

## Architecture Onboarding

- Component map: The system centers on an **Agent Graph (G)**. Each **Agent (v_i)** holds mutable semantic parameters (Θ_i: prompt, tools). The **KABB Router** constructs a task-specific subgraph for the **Forward Pass**. The **Aggregator (v_a)** produces the final output. The environment's feedback is fed to the **Textual Gradient Parser**, which drives the **Backward Pass**, updating agents via the **f_P** (semantic) and **f_G** (topological) evolution functions. A **RepairTopology** function maintains graph validity.

- Critical path: **Forward Pass Execution** → **Environment Evaluation** → **Textual Gradient Generation** → **Backward Propagation of Gradients** → **Coordinated Update (f_P & f_G)** → **KABB Parameter Update**. This loop repeats for a set number of optimization iterations or until a performance threshold is met.

- Design tradeoffs: The primary tradeoff is between optimization power and computational cost. More iterations and a larger graph allow for more sophisticated solutions but increase LLM API calls and latency (average $0.1/sample on GAIA). The granularity of textual gradients (e.g., simple vs. detailed critiques) also impacts optimization quality versus token cost.

- Failure signatures:
  1. **Local Optimum Trap:** The system enters a loop where it repeatedly refines a fundamentally flawed solution without making global progress (e.g., the MATH failure case where the aggregator got "stuck").
  2. **Runaway Topology:** The graph grows too large with redundant or low-utility agents, causing routing failures and increased cost.
  3. **Corrupted Gradient:** An LLM generates an ambiguous or incorrect textual gradient, leading to damaging updates to prompts or structure.

- First 3 experiments:
  1. **Validate Core Loop:** Run HiVA on a small subset of a simple dataset (e.g., GSM-8K) for 5 iterations. Manually inspect the generated textual gradients and the resulting prompt/topology changes to verify the f_P and f_G functions are producing sensible, targeted updates.
  2. **Ablate KABB:** Compare performance with and without the knowledge-aware cost function (HiVA vs. HiVA w/o KABB) on a multi-hop reasoning task (e.g., HotpotQA). This isolates the contribution of intelligent routing versus naive activation.
  3. **Scalability Test:** Run the full optimization loop for 10 iterations on a more complex benchmark (e.g., HumanEval). Monitor the growth of the agent graph, the total number of LLM calls, and the final accuracy to assess cost-benefit.

## Open Questions the Paper Calls Out
None

## Limitations
- The scalability of textual gradient parsing as agent graphs grow complex
- Sensitivity to LLM API reliability and cost, which could create optimization bottlenecks
- Lack of rigorous analysis of local optimum traps in the semantic-topological search space

## Confidence
- Textual Gradient Mechanism: Medium
- Co-evolution Execution: Medium
- KABB Routing Contribution: Low

## Next Checks
1. **Gradient Fidelity Audit**: Run HiVA on a controlled task (e.g., GSM-8K) and manually evaluate 50 textual gradient outputs for semantic consistency, actionable specificity, and alignment with true failure causes. Quantify the percentage that would lead to correct agent modifications.

2. **KABB Robustness Test**: Replace the domain-specific knowledge graph in KABB routing with a random graph of identical structure. Measure performance degradation on HotpotQA to isolate the contribution of meaningful semantic knowledge versus baseline MAB performance.

3. **Topology Evolution Stress Test**: Execute HiVA for 20 optimization iterations on HumanEval and log the agent graph's growth trajectory (|V|, |E|) and routing success rate. Identify the iteration at which computational cost outweighs accuracy gains, and test whether aggressive pruning maintains performance.