---
ver: rpa2
title: Group size effects and collective misalignment in LLM multi-agent systems
arxiv_id: '2510.22422'
source_url: https://arxiv.org/abs/2510.22422
tags:
- time
- consensus
- word
- bias
- collective
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how group size influences collective behavior
  in multi-agent systems of large language models (LLMs). It focuses on the phenomenon
  of collective misalignment, where interacting LLMs can develop emergent biases absent
  in individual models during a naming game.
---

# Group size effects and collective misalignment in LLM multi-agent systems

## Quick Facts
- arXiv ID: 2510.22422
- Source URL: https://arxiv.org/abs/2510.22422
- Reference count: 40
- Primary result: Group size determines the strength and form of collective bias in LLM multi-agent systems through non-linear dynamics

## Executive Summary
This paper investigates how group size influences collective behavior in multi-agent systems of large language models (LLMs). It focuses on the phenomenon of collective misalignment, where interacting LLMs can develop emergent biases absent in individual models during a naming game. The study shows that group size affects the strength and form of collective bias in a non-linear way, revealing model-dependent dynamical regimes. Small populations exhibit rapid consensus driven by random fluctuations, while larger populations show slower, more coordinated convergence. Above a critical population size, the system's behavior becomes deterministic, with outcomes predictable by mean-field theory. These findings demonstrate that population size is a key determinant of multi-agent dynamics, with implications for the safe deployment of LLM-based systems at scale.

## Method Summary
The researchers used a naming game protocol where LLM agents interact pairwise to coordinate on word choices. They extracted probabilistic policies from LLMs by caching response distributions for all possible memory states, enabling large-scale simulations with up to one million agents. The system was analyzed through both agent-based simulations and mean-field theory, comparing convergence times and collective biases across different population sizes (N) and model types. Consensus was defined as >98% of recent interactions being successful, and collective bias was measured as the difference between strong and weak word success rates.

## Key Results
- Group size affects collective bias strength in a non-linear, model-dependent way
- Small populations show rapid consensus driven by random fluctuations
- Above critical population size N_c, outcomes become deterministic and predictable via mean-field theory
- Interactions can amplify, induce, or override individual LLM biases through memory-mediated feedback loops

## Why This Works (Mechanism)

### Mechanism 1: Deterministic Convergence at Critical Population Size
- **Claim:** Increasing population size reduces outcome stochasticity, eventually locking the system into a deterministic consensus state above a model-specific threshold N_c.
- **Mechanism:** In small groups, early random fluctuations dominate, allowing "weak" conventions to win by chance. As N increases, the law of large numbers dampens these fluctuations. The system shifts from noise-driven dynamics to a deterministic trajectory governed by the mean-field drift, which favors the "strong" convention.
- **Core assumption:** Agents are homogenous (identical probabilistic policies) and interaction partners are selected randomly.
- **Evidence anchors:**
  - [abstract] "Above a critical population size, the system's behavior becomes deterministic..."
  - [page 7] "Once N exceeds a threshold, the collective outcome becomes fully deterministic: if the population can reach consensus, then it will always converge on the strong word."
  - [corpus] Related work "Emergent Coordination..." supports information-theoretic integration in collectives, though specific N_c thresholds are unique to this paper's formulation.
- **Break condition:** If the underlying LLM policy has no preference (truly uniform random) or if the population is heterogeneous (mixing different model types), the threshold may shift or disappear.

### Mechanism 2: Memory-Mediated Collective Misalignment
- **Claim:** Interactions can produce collective biases that amplify, nullify, or reverse the individual biases of the isolated agents.
- **Mechanism:** Agents possess a finite memory (context window) of past interactions. The LLM generates a probabilistic policy based on this memory state. Positive feedback loops emerge: if a word gains slight prevalence, it appears more often in agent memories, prompting the LLM to select it more frequently to ensure coordination. This dynamic "induction" creates bias even when individual agents start neutral.
- **Core assumption:** The LLM's policy q(M_h) is context-dependent and rewards coordination (maximizing payoff), leading to herding behavior.
- **Evidence anchors:**
  - [abstract] "...interacting LLMs playing a simple coordination game can generate collective biases absent in individual models."
  - [page 5] "Interaction gives rise to three distinct forms of misalignment... amplify, induce... or override."
  - [corpus] "The Coming Crisis of Multi-Agent Misalignment" posits this as a general dynamic risk, though this paper provides the specific causal evidence via the naming game.
- **Break condition:** If the agent logic ignores history (zero memory) or if the prompt explicitly forbids following crowd trends (sycophancy break).

### Mechanism 3: Basins of Attraction and Fixed Point Stability
- **Claim:** The final consensus is determined by the stability of the system's homogeneous fixed points and their basins of attraction, calculable via mean-field theory.
- **Mechanism:** The system state is described by the density of agents holding specific memories. The mean-field equation shows that the system evolves toward stable fixed points (where everyone agrees on one word). If one fixed point has a larger basin of attraction (region of initial states leading to it), it becomes the inevitable outcome in large populations.
- **Core assumption:** The reaction-diffusion mapping accurately captures the stochastic interactions in the limit of infinite agents.
- **Evidence anchors:**
  - [page 10] "...simulations converge to deterministic predictions that expose the basins of attraction of competing equilibria."
  - [page 23] "...fixed points take the form of homogeneous absorbing states, corresponding to full consensus..."
  - [corpus] "On the Dynamics of Multi-Agent LLM Communities..." discusses value diversity impact, but this paper uniquely quantifies the attraction basins mathematically.
- **Break condition:** If mixed/marginal fixed points exist (e.g., Llama "{old, young}"), the system may fail to converge, remaining in a metastable state.

## Foundational Learning

- **Concept: The Naming Game**
  - **Why needed here:** This is the experimental protocol used to force coordination. Understanding the rules (pairwise interaction, score maximization) is prerequisite to analyzing the emergent bias.
  - **Quick check question:** In this game, does an agent succeed by choosing a unique word or by matching their partner?

- **Concept: Probabilistic Policy Extraction**
  - **Why needed here:** The paper bridges LLM behavior and agent-based simulation by extracting a probability distribution over actions (logits) rather than using direct text generation. This allows for massive scale simulations.
  - **Quick check question:** How does caching the probability distribution for every possible memory state enable large-scale simulation?

- **Concept: Mean-Field Theory**
  - **Why needed here:** This is the analytical tool used to predict large population behavior without running infinite simulations. It approximates discrete stochastic agents with continuous deterministic flows.
  - **Quick check question:** What does the stability of a "fixed point" tell us about the likely final state of a large LLM population?

## Architecture Onboarding

- **Component map:** LLM -> Policy Cache -> Agent Memory -> Interaction Pair -> Score Update -> Consensus Check
- **Critical path:**
  1. **Pre-computation:** Query LLM to extract probability vectors for all possible memory states (up to size H).
  2. **Simulation:** Initialize N agents with empty memory. Iterate: Select pair -> Retrieve Policy -> Sample Action -> Update Memory/Scores.
  3. **Validation:** Compare simulation outputs (consensus bias) against Mean-Field predictions and small-N experimental runs.
- **Design tradeoffs:**
  - **Cache vs. Live Query:** Caching policies enables N=10^6 simulations but assumes policies are static and independent of prompt variations.
  - **Binary vs. W-ary:** Restricting to 2 options (W=2) allows for binary bias analysis and cleaner mean-field math, but reduces the complexity of the convention space.
- **Failure signatures:**
  - **Non-consensus:** Simulation runs indefinitely or oscillates (seen in Llama "less/more"). Check fixed point eigenvalues for instability.
  - **Unexpected Bias Reversal:** Strong individual preference loses in small groups. Check finite-size fluctuation effects.
- **First 3 experiments:**
  1. **Replication:** Run the simulation for GPT-4o on {White, African} with N=24 to verify the amplification effect observed in Figure 1.
  2. **Threshold Hunting:** Systematically vary N (10^1 to 10^5) for a specific model to identify the exact N_c where variance drops to zero.
  3. **Heterogeneity Test (Extension):** Mix two different models (e.g., GPT and Llama) in one population to see if one model's policy dominates the collective consensus or if consensus fails.

## Open Questions the Paper Calls Out
None

## Limitations
- Deterministic regime claims rely on homogeneous agent populations and static LLM policies
- Findings constrained to binary choice spaces (W=2) and specific memory lengths (H)
- Model-dependent critical population thresholds lack systematic prediction framework

## Confidence

- **High Confidence**: Deterministic convergence behavior above N_c and the non-linear relationship between population size and collective bias strength
- **Medium Confidence**: The amplification, induction, and override mechanisms of collective misalignment
- **Low Confidence**: The exact value of critical population thresholds across different models and domains

## Next Checks
1. **Heterogeneous Population Stress Test**: Mix GPT-4o and Llama agents in varying proportions to determine whether consensus emerges, which model dominates, or if the population remains fragmented.
2. **Memory Length Sensitivity Analysis**: Systematically vary H (memory window size) to quantify how finite context windows affect collective misalignment strength and the location of N_c thresholds.
3. **Multi-Word Coordination Game**: Extend beyond binary choices (W=2) to W=3 or W=4 options to test whether the deterministic convergence and bias amplification mechanisms generalize to richer convention spaces.