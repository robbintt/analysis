---
ver: rpa2
title: 'Interpreting Public Sentiment in Diplomacy Events: A Counterfactual Analysis
  Framework Using Large Language Models'
arxiv_id: '2509.20367'
source_url: https://arxiv.org/abs/2509.20367
tags:
- public
- sentiment
- diplomatic
- events
- diplomacy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a computational framework to measure and influence
  public sentiment towards diplomatic events. The authors fine-tune a BERT model on
  a dataset of Reddit posts and comments about diplomatic events to predict public
  sentiment, achieving 70% overall accuracy.
---

# Interpreting Public Sentiment in Diplomacy Events: A Counterfactual Analysis Framework Using Large Language Models

## Quick Facts
- arXiv ID: 2509.20367
- Source URL: https://arxiv.org/abs/2509.20367
- Authors: Leyi Ouyang
- Reference count: 7
- Primary result: Framework successfully shifts negative public sentiment on diplomatic events to neutral/positive in 70% of cases through strategic narrative modifications

## Executive Summary
This study presents a computational framework that predicts public sentiment toward diplomatic events and systematically modifies narratives to shift negative sentiment to neutral or positive. The approach combines a fine-tuned BERT model trained on Reddit discussions about diplomatic events with an iterative counterfactual generation algorithm using a large language model. The framework identifies five key narrative modification categories (participants, process, communication, substance, context) and achieves 70% success rate in transforming sentiment across 2,760 diplomatic articles. The method demonstrates how strategic narrative framing can influence public perception of international events, offering policymakers a data-driven tool for anticipating and shaping public reactions.

## Method Summary
The framework operates in three stages: First, it trains a BERT model on a dataset of 8,000 Reddit posts about diplomatic events, where sentiment is derived from user comments weighted by upvotes/downvotes. Second, it implements an iterative algorithm that uses a large language model to generate counterfactual modifications across five categories (participants, process, communication, substance, context). Third, it applies these modifications sequentially until the fine-tuned BERT model predicts a sentiment shift from negative to neutral/positive. The approach preserves core factual content while altering narrative framing to influence predicted public sentiment.

## Key Results
- BERT model achieves 70% overall accuracy in predicting public sentiment (Positive: 0.75, Negative: 0.69, Neutral: 0.16)
- 70% success rate in shifting negative sentiment to neutral/positive through counterfactual modifications
- Participants (30.19%) and Context (28.62%) modifications prove most effective, accounting for ~60% of successful transformations
- 77.23% of successful cases require only first three modification categories (Participants, Context, Communication)
- 29.23% of articles resistant to all modifications, indicating limits of narrative reframing

## Why This Works (Mechanism)

### Mechanism 1: Domain-Adapted Sentiment Proxy via Fine-Tuned BERT
- Claim: A BERT model fine-tuned on diplomatic event descriptions paired with Reddit-derived sentiment labels can serve as a reliable proxy for public sentiment prediction.
- Mechanism: The model learns associations between linguistic features of diplomatic narratives (terminology, framing, tone) and aggregated public reaction patterns encoded in the training data.
- Core assumption: Reddit discussions and voting patterns constitute a valid, generalizable proxy for broader public sentiment toward diplomatic events.
- Evidence anchors: BERT achieved 70% accuracy on title+text input; related work on political stance detection suggests counterfactual approaches can reduce model bias.
- Break condition: If diplomatic discourse contains irony, sarcasm, or strategic hedging that pre-trained representations cannot capture; or if Reddit demographics systematically differ from target populations.

### Mechanism 2: Structured Counterfactual Generation for Sentiment Intervention
- Claim: Systematic modifications to event narratives across predefined theory-grounded categories can shift predicted sentiment from negative to neutral/positive.
- Mechanism: An LLM generates alternative narratives by altering one category at a time (participants, process, communication, substance, context) while preserving core facts.
- Core assumption: Changes to narrative framing—without altering factual content—can meaningfully influence public perception, consistent with framing theory and agenda-setting theory.
- Evidence anchors: Five categories defined with specific modification types; prompts instruct LLM to maintain "core facts" while altering framing.
- Break condition: If generated counterfactuals violate factual constraints, produce incoherent narratives, or if LLM introduces confounding changes beyond the targeted category.

### Mechanism 3: Sequential Intervention Accumulation
- Claim: Applying modifications iteratively across categories achieves higher success rates than single-shot interventions because effects accumulate.
- Mechanism: Each modification builds on the previous altered text, progressively shifting sentiment. Early successes terminate the loop; failures trigger the next category.
- Core assumption: Category effects are at least partially independent and cumulative; the order of application reflects descending effectiveness.
- Evidence anchors: 77.23% of cases of public sentiment are modified successfully only using the first three steps; Participants and Context account for ~60% of successful transformations.
- Break condition: If early modifications irreversibly constrain the narrative space, or if later modifications produce diminishing/negative returns due to accumulated artifacts.

## Foundational Learning

### Concept: Counterfactual Reasoning in Explainable AI
- Why needed here: The framework uses "what-if" scenarios to probe which features drive sentiment predictions, opening the black box of the BERT model.
- Quick check question: If changing the "communication tone" from assertive to conciliatory flips sentiment from negative to neutral, what can you infer about the model's decision factors?

### Concept: Narrative Framing Effects (Framing Theory)
- Why needed here: The paper's theoretical foundation relies on framing theory—the idea that how an event is described shapes perception independently of the event itself.
- Quick check question: Two news articles describe the same trade negotiation. One emphasizes "concessions made"; the other emphasizes "partnership built." How might audience reactions differ?

### Concept: Transfer Learning and Domain Adaptation
- Why needed here: Understanding why a generally pre-trained BERT requires fine-tuning on diplomatic text to handle domain-specific terminology and nuance.
- Quick check question: Why might a model trained on general web text misinterpret diplomatic hedging (e.g., "we note with concern") compared to domain-specific training?

## Architecture Onboarding

### Component Map:
Reddit posts → Sentiment BERT labels comments → Weighted aggregation → Event-level sentiment scores → Fine-tuned BERT (Title+Text → Sentiment) → LLM (Category + Original → Modified) → Re-predict → Return success/failure

### Critical Path:
Original event text → Predictor labels "Negative" → Apply Participants modification via LLM → Re-predict → If still negative, apply Context modification → Re-predict → Continue through Communication → Substance → Process → Return success or failure

### Design Tradeoffs:
- **Sequential vs. parallel**: Sequential is simpler and interpretable but may miss optimal multi-category combinations
- **Category granularity**: 5 categories balance theory-grounded coverage with operational simplicity; finer granularity could improve precision but increase complexity
- **Factual preservation**: Prompts instruct LLM to preserve "core facts," but automated verification is not implemented—manual review assumed

### Failure Signatures:
- **Neutral class collapse**: F1-score of 0.16 on "Neutral" sentiment due to training data imbalance (274 samples vs. 849 negative)
- **Irreversible negativity**: ~30% of events resistant to all modifications—possibly due to factual constraints or deeply embedded negative narratives
- **Participant interventions underperforming**: Only 9.92% success rate for participant changes vs. 18.49% for communication—suggests discursive features matter more than actor substitution

### First 3 Experiments:
1. **Category ablation**: Test each modification category in isolation on a held-out set to confirm individual contribution rates (paper partially does this—replicate to validate)
2. **Order sensitivity analysis**: Permute the category sequence (e.g., Communication first) to test whether the 77% early-success rate is order-dependent or category-inherent
3. **Cross-community generalization**: Apply the same counterfactuals to events discussed in different subreddit communities (e.g., r/geopolitics vs. r/worldnews) to test whether intervention effects transfer across audience segments

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Is public sentiment more volatile in Digital Diplomacy compared to traditional diplomatic forms, and how does this affect predictive stability?
- Basis in paper: The authors state in Section 4.1 that their categorization methodology "allows us to ask more sophisticated questions, for example... Is public sentiment more volatile in Digital Diplomacy than in traditional forms?"
- Why unresolved: The paper establishes the capability to ask this question via categorization but focuses the results on the success rates of counterfactual interventions rather than analyzing the temporal volatility of the sentiment itself.
- What evidence would resolve it: A time-series analysis comparing the variance and standard deviation of sentiment scores for Digital Diplomacy events against traditional categories like Bilateral or Summit Diplomacy.

### Open Question 2
- Question: Can augmenting the training dataset with a larger sample of neutral instances significantly enhance the model's predictive accuracy for the 'Neutral' class?
- Basis in paper: In Section 3.1, the authors note the model is constrained by weak performance on the 'Neutral' class due to data imbalance and state, "it is anticipated that augmenting the training dataset... could significantly enhance the model’s predictive accuracy."
- Why unresolved: The current dataset contained notably fewer neutral instances, resulting in a low recall (0.1) for that class, which lowers overall accuracy.
- What evidence would resolve it: Re-training the BERT model using resampled data or data augmentation techniques to balance the 'Neutral' class and observing changes in the classification report.

### Open Question 3
- Question: How would the inclusion of multilingual datasets and cross-cultural comparisons alter the identification of sentiment drivers?
- Basis in paper: The Conclusion states, "Future work could expand the scope to include multilingual datasets, and cross-cultural comparisons would provide a more comprehensive understanding of global public sentiment dynamics."
- Why unresolved: The current study primarily relies on English and Chinese text analysis, potentially limiting the generalizability of the identified "drivers" (like communication style) to non-Western or non-English speaking contexts.
- What evidence would resolve it: Replicating the framework on non-English social media data (e.g., regional platforms) to test if the same counterfactual categories (e.g., Context vs. Substance) remain equally influential.

## Limitations

- **Proxy validity**: Reddit-derived sentiment may not generalize to broader populations or different demographic groups
- **Neutral class weakness**: F1-score of 0.16 for Neutral class due to data imbalance significantly impacts model performance
- **Factual verification gap**: LLM-generated counterfactuals lack automated factual consistency checking, introducing reliability concerns

## Confidence

- **High Confidence**: The BERT model's 70% overall accuracy for sentiment prediction and the general framework architecture for counterfactual generation
- **Medium Confidence**: The effectiveness rankings of modification categories and the 70% overall success rate for sentiment transformation
- **Low Confidence**: The generalizability of Reddit-based sentiment labels to broader populations and the long-term stability of LLM-generated counterfactuals

## Next Checks

1. **Cross-Platform Sentiment Validation**: Test whether the fine-tuned BERT model's predictions correlate with sentiment expressed on other social media platforms (Twitter, Facebook) or traditional media sources to validate Reddit as a sentiment proxy
2. **Factual Consistency Audit**: Implement automated fact-checking mechanisms to verify that LLM-generated counterfactuals preserve core factual content, addressing potential hallucination risks
3. **Multi-Category Intervention Experiment**: Design controlled experiments testing simultaneous modifications across multiple categories versus the current sequential approach to identify potential performance improvements