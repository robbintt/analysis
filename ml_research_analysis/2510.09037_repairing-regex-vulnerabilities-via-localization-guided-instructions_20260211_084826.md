---
ver: rpa2
title: Repairing Regex Vulnerabilities via Localization-Guided Instructions
arxiv_id: '2510.09037'
source_url: https://arxiv.org/abs/2510.09037
tags:
- repair
- regex
- regexes
- vulnerability
- similarity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work introduces LRR, a hybrid framework that combines precise\
  \ vulnerability localization with LLM-based repair to fix regex patterns vulnerable\
  \ to ReDoS attacks. By first identifying the vulnerable sub-pattern via symbolic\
  \ analysis and then generating a targeted repair with the LLM, LRR improves the\
  \ repair rate by 15.4 percentage points over the state-of-the-art, achieving up\
  \ to 59% repair success while preserving high semantic similarity (Jaccard \u2248\
  \ 84%)."
---

# Repairing Regex Vulnerabilities via Localization-Guided Instructions

## Quick Facts
- **arXiv ID:** 2510.09037
- **Source URL:** https://arxiv.org/abs/2510.09037
- **Reference count:** 30
- **Primary result:** LRR improves regex ReDoS repair rate by 15.4 percentage points over state-of-the-art, achieving up to 59% success while maintaining high semantic similarity (Jaccard ≈ 84%).

## Executive Summary
This work introduces LRR, a hybrid framework that combines precise vulnerability localization with LLM-based repair to fix regex patterns vulnerable to ReDoS attacks. By first identifying the vulnerable sub-pattern via symbolic analysis and then generating a targeted repair with the LLM, LRR improves the repair rate by 15.4 percentage points over the state-of-the-art, achieving up to 59% repair success while preserving high semantic similarity (Jaccard ≈ 84%). The framework overcomes limitations of both rule-based and LLM-only methods, demonstrating robust performance across multiple LLM models.

## Method Summary
LRR operates in two stages: (1) a symbolic localization module based on RegexScalpel heuristics identifies vulnerable sub-patterns (nested quantifiers, quantified overlapping adjacent, etc.) within the full regex, and (2) a 5-shot chain-of-thought prompt guides an LLM to repair the localized segment. The framework tests multiple LLMs (Phi4, Qwen3, GPT-5) and evaluates repairs using ReDoSHunter for vulnerability detection and Jaccard similarity on sampled languages. The approach achieves significant improvements over both rule-based and LLM-only methods by constraining the repair problem space.

## Key Results
- **15.4 percentage point improvement** over state-of-the-art repair methods
- **Up to 59% repair success rate** with Phi4 model while maintaining 84% semantic similarity
- **Significant ablation study findings**: Localization and 5-shot CoT prompting are critical components, with non-reasoning models heavily dependent on CoT examples and reasoning models on localization

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Localizing the vulnerable sub-pattern before LLM invocation transforms an open-ended generation task into a constrained repair problem, improving reliability.
- **Mechanism:** A deterministic symbolic module (based on RegexScalpel heuristics) identifies vulnerable sub-patterns (e.g., nested quantifiers, quantified overlapping adjacent) within the full regex. This localized segment is then explicitly marked in the LLM prompt, narrowing the model's attention from the entire pattern (~100–1000 characters) to a specific problematic span (typically 5–20 characters). The LLM no longer needs to diagnose *where* the vulnerability lies—it only needs to generate a semantically equivalent replacement for the identified segment.
- **Core assumption:** The symbolic localizer correctly identifies the vulnerable sub-pattern; if localization fails or is imprecise, the LLM receives misleading guidance.
- **Evidence anchors:**
  - [abstract] "First, a deterministic, symbolic module localizes the precise vulnerable subpattern, creating a constrained and tractable problem space."
  - [section 4] "The symbolic module in our framework functions as a precise vulnerability localizer... pinpoint the vulnerable sub-pattern s′ within the original regex s."
  - [corpus] Related work on localization (Tang et al., Pamies-Juarez et al.) supports localization as a general strategy for program repair, but no corpus evidence directly validates localization for regex-specific repair.
- **Break condition:** If the symbolic analyzer's heuristics do not cover the vulnerability type present in the input regex, the localization will fail, and the LLM must fall back to analyzing the full pattern—negating the framework's core advantage.

### Mechanism 2
- **Claim:** Converting rule-based repair heuristics into chain-of-thought (CoT) examples enables the LLM to learn repair *procedures* rather than memorizing specific patterns.
- **Mechanism:** The authors analyze RegexScalpel's four major repair rule categories (nested quantifiers, QOD, QOA, SLQ) and translate each into a natural language reasoning trace. A 5-shot prompt is constructed with one complex example demonstrating multiple rule applications and four simpler examples showing single rules. This teaches the LLM both *how* individual repairs work and that multiple sequential repairs may be needed.
- **Core assumption:** The LLM can generalize procedural knowledge from few-shot examples to unseen vulnerability patterns; this generalization does not require explicit formal guarantees.
- **Evidence anchors:**
  - [section 5.1] "We convert these heuristics into a natural language chain-of-thought reasoning process to effectively guide LLMs."
  - [section 6.2] Ablation study shows removing 5-shot CoT drops Phi4 repair rate from 59% to 49.7%, demonstrating critical dependency.
  - [corpus] Corpus evidence is weak—no direct studies validate CoT effectiveness for regex repair specifically; related work on CoT for code repair is tangential.
- **Break condition:** If the input regex contains vulnerability types not represented in the 5-shot examples, the LLM may fail to generalize repair strategies, though localization guidance may partially compensate.

### Mechanism 3
- **Claim:** The framework exploits complementary strengths of reasoning vs. non-reasoning models through targeted prompt components.
- **Mechanism:** Non-reasoning models (e.g., Phi4) depend heavily on 5-shot CoT examples to learn repair procedures, achieving higher repair rates (59%) but with greater syntactic deviation (RLI=100.43%). Reasoning models (e.g., Qwen3) depend more on localization guidance, achieving better semantic preservation (Jaccard=90.24% for GPT-5) but slightly lower repair rates. The framework's dual-component prompt accommodates both model types.
- **Core assumption:** Different LLM architectures benefit differentially from explicit procedure examples vs. focused context; this is an empirical observation, not a theoretically derived principle.
- **Evidence anchors:**
  - [section 6.2] "For the non-reasoning Phi4 model, the 5-shot CoT prompting is the most critical component... In contrast, the reasoning-based Qwen3 model is most impacted by removing localization."
  - [section 6.3] "Reasoning model is more capable of maintaining semantic correctness while repairing vulnerabilities."
  - [corpus] No corpus evidence directly addresses differential prompt dependency across reasoning/non-reasoning model types.
- **Break condition:** Applying a reasoning-optimized prompt to a non-reasoning model (or vice versa) may yield suboptimal results; practitioners should match prompt emphasis to model type.

## Foundational Learning

- **Catastrophic Backtracking in ReDoS**
  - Why needed here: The entire repair task hinges on understanding *why* certain regex patterns cause exponential backtracking. Nested quantifiers like `(a+)+` create overlapping match possibilities, causing the regex engine to explore exponentially many paths.
  - Quick check question: Given `^(a|ab)+$`, why does input "aab" cause more backtracking than "ab"?

- **In-Context Learning with Chain-of-Thought**
  - Why needed here: LRR relies on the LLM learning repair procedures from examples without weight updates. CoT prompting provides the intermediate reasoning steps that bridge the gap between vulnerable and repaired patterns.
  - Quick check question: If you provide only input-output pairs without reasoning traces, what types of regex repair tasks would likely fail?

- **Semantic vs. Syntactic Similarity in Regex**
  - Why needed here: The evaluation distinguishes between character-level changes (syntactic) and language-level changes (semantic). A repair that adds look-aheads may be syntactically dissimilar but semantically equivalent.
  - Quick check question: If a repaired regex matches all the same strings as the original but is twice as long, which similarity metric (RLI, NLS, Jaccard) would penalize this most?

## Architecture Onboarding

- **Component map:**
  ```
  Input Regex
       │
       ▼
  ┌─────────────────┐
  │ Symbolic Module │ (RegexScalpel-based analyzer)
  │ - Detects vuln. │
  │ - Localizes s′  │
  └────────┬────────┘
           │ sub-pattern spans + vulnerability type labels
           ▼
  ┌─────────────────┐
  │ Prompt Builder  │
  │ - 5-shot CoT    │
  │ - Localization  │
  │ - Task spec     │
  └────────┬────────┘
           │ structured prompt
           ▼
  ┌─────────────────┐
  │      LLM        │ (Phi4, Qwen3, GPT-5, etc.)
  │ - Generates     │
  │   repair        │
  └────────┬────────┘
           │ repaired regex
           ▼
  ┌─────────────────┐
  │   Validator     │ (ReDoSHunter + Jaccard)
  │ - ReDoS check   │
  │ - Sem. check    │
  └─────────────────┘
  ```

- **Critical path:** Vulnerability localization → Prompt construction (localization + CoT integration) → LLM repair → Post-hoc validation. If localization fails, the system degrades to LLM-only mode with lower success rates.

- **Design tradeoffs:**
  - **Repair rate vs. semantic preservation:** Phi4 achieves 59% repair but with higher RLI (100.43%); Qwen3 achieves 51% repair with lower RLI (68.79%). Choose model based on whether coverage or minimal-change is prioritized.
  - **Heuristic coverage vs. generalization:** Symbolic module is precise but limited to known patterns; LLM generalizes but can introduce semantic drift. Hybrid approach balances both.
  - **Timeout threshold:** 1-minute timeout for ReDoSHunter determines vulnerability classification. Tighter timeouts reduce false negatives but may miss slow-building attacks.

- **Failure signatures:**
  - **Localization failure:** Symbolic module returns no vulnerable sub-pattern for a regex that ReDoSHunter later flags as vulnerable. Check for patterns outside the four heuristic categories.
  - **Semantic drift:** Repaired regex has Jaccard < 0.5. Often caused by over-aggressive application of multiple repair rules simultaneously (common in non-reasoning models).
  - **Ill-formed output:** Regex fails to compile. More common with reasoning models (DS-R1-Qwen: 80.7% well-formed) than non-reasoning (Gemma3: 99.4%).

- **First 3 experiments:**
  1. **Sanity check with known patterns:** Run LRR on 20 regexes with documented vulnerabilities from ReDoSHunter test cases. Verify localization identifies the correct sub-pattern and LLM generates syntactically valid output.
  2. **Ablation on your target model:** If deploying with a specific LLM, replicate the ablation study (remove localization, remove 5-shot, remove both) on 100-sample subset to determine optimal prompt configuration.
  3. **Edge case probing:** Test on regexes with multiple vulnerability types in a single pattern. Compare repair success when vulnerabilities appear in independent vs. nested sub-patterns to understand localization interaction effects.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can LRR's localization module be extended to detect vulnerability patterns beyond the four known anti-patterns (NQ, QOD, QOA, SLQ), and how would such extensions affect repair accuracy?
- **Basis in paper:** [explicit] The Limitations section states "LRR's effectiveness is constrained by the knowledge of the underlying analyzer, potentially limiting its ability to precisely localize vulnerability patterns that fall outside of these known anti-patterns."
- **Why unresolved:** The symbolic module relies entirely on existing rule-based heuristics; discovering new vulnerability patterns would require either expanding these rules or developing learning-based localization.
- **What evidence would resolve it:** Evaluation on a dataset containing novel vulnerability types not covered by current heuristics, with analysis of localization accuracy and subsequent repair success rates.

### Open Question 2
- **Question:** Can formal verification methods be integrated to provide provable guarantees of ReDoS-invulnerability, rather than relying on empirical dynamic detection timeouts?
- **Basis in paper:** [explicit] "The validation of our repair success is empirical, not a formal, provable guarantee of safety, as it relies on the dynamic detection tool ReDoSHunter."
- **Why unresolved:** Current validation depends on ReDoSHunter failing to find attack strings within one minute, which is practical but not mathematically rigorous.
- **What evidence would resolve it:** Integration of a formal verifier (e.g., static analysis with complexity bounds) that provides provable polynomial-time guarantees, evaluated against the current empirical approach.

### Open Question 3
- **Question:** How does LRR perform on non-backtracking regex engines (e.g., RE2, Rust regex) where ReDoS vulnerabilities manifest differently than in backtracking engines?
- **Basis in paper:** [inferred] The paper notes "the definition of a ReDoS vulnerability is often context-dependent, varying across different execution environments and regex engines," but all experiments use Python's `re` module (backtracking engine).
- **Why unresolved:** Different engines have different vulnerability profiles; super-linear behavior in backtracking engines may not translate to non-backtracking engines that face different attack vectors (e.g., counting vulnerabilities).
- **What evidence would resolve it:** Cross-engine evaluation of LRR on regexes deployed across backtracking and non-backtracking engines, measuring transferability of repairs.

### Open Question 4
- **Question:** What mechanisms could improve the trade-off between repair rate and syntactic/semantic similarity, particularly for non-reasoning models that show higher repair rates but lower similarity scores?
- **Basis in paper:** [inferred] Section 6.3 shows Phi4 achieves 59% repair rate with 100.43% RLI, while Qwen3 achieves 51% with 68.79% RLI, indicating non-reasoning models apply more aggressive modifications.
- **Why unresolved:** Non-reasoning models tend to apply multiple repair strategies simultaneously, increasing regex length and reducing readability, while reasoning models apply minimal fixes.
- **What evidence would resolve it:** Development of a constrained decoding mechanism or post-processing step that limits syntactic deviation while maintaining repair effectiveness.

## Limitations

- **Heuristic coverage dependency:** LRR's effectiveness is constrained by RegexScalpel's four known anti-pattern categories; vulnerabilities outside these patterns may evade localization.
- **Empirical validation only:** The framework relies on dynamic detection timeouts rather than formal guarantees of ReDoS-invulnerability.
- **Backtracking engine specificity:** All experiments use Python's backtracking `re` module; performance on non-backtracking engines remains untested.

## Confidence

- **Hybrid repair mechanism effectiveness (High):** The 15.4 percentage point improvement over state-of-the-art and consistent performance across multiple LLM architectures provides strong empirical support.
- **Localization-guided prompting advantage (Medium):** While ablation studies show component importance, the specific advantage of localization over other context-providing methods lacks direct comparison.
- **Semantic preservation through reasoning models (Medium):** The observed Jaccard differences are statistically significant, but the evaluation corpus size and sampling methodology limit generalizability claims.

## Next Checks

1. **Heuristic coverage validation:** Test LRR on 100 regexes containing vulnerability types beyond the four RegexScalpel categories (e.g., lookbehind assertions, recursive patterns). Measure repair success rate and identify failure modes when localization cannot find sub-patterns.

2. **Semantic equivalence stress test:** Generate adversarial test cases where repaired regexes pass all sampled language tests but fail on specific edge strings. Use fuzzing to discover counterexamples where Jaccard similarity overestimates true equivalence.

3. **Prompt component sensitivity analysis:** Systematically vary the localization guidance (different sub-pattern spans, multiple vulnerable segments) and CoT example selection (different rule orderings, additional examples) on a 200-regex subset to quantify robustness to prompt engineering choices.