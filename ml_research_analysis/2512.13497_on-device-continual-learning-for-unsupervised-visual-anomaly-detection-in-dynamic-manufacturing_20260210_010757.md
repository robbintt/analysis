---
ver: rpa2
title: On-Device Continual Learning for Unsupervised Visual Anomaly Detection in Dynamic
  Manufacturing
arxiv_id: '2512.13497'
source_url: https://arxiv.org/abs/2512.13497
tags:
- learning
- data
- memory
- training
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of deploying visual anomaly
  detection in dynamic manufacturing environments where frequent product changes and
  limited computational resources on edge devices make traditional cloud-based retraining
  impractical. The authors propose an on-device continual learning framework extending
  PatchCore by incorporating online learning, a lightweight MobileNetV3 feature extractor,
  and an incremental k-center selection mechanism for memory-efficient coreset updates.
---

# On-Device Continual Learning for Unsupervised Visual Anomaly Detection in Dynamic Manufacturing

## Quick Facts
- **arXiv ID:** 2512.13497
- **Source URL:** https://arxiv.org/abs/2512.13497
- **Reference count:** 29
- **Primary result:** 12% AUROC improvement and 80% memory reduction over baseline on edge hardware

## Executive Summary
This paper addresses the challenge of deploying visual anomaly detection in dynamic manufacturing environments where frequent product changes and limited computational resources on edge devices make traditional cloud-based retraining impractical. The authors propose an on-device continual learning framework extending PatchCore by incorporating online learning, a lightweight MobileNetV3 feature extractor, and an incremental k-center selection mechanism for memory-efficient coreset updates. Evaluated on a testbed with five interchangeable workpieces and frequent configuration changes, the method achieves a 12% improvement in AUROC over the baseline, reduces memory usage by 80%, and enables faster training compared to batch learning. The approach is validated on a Jetson Orin Nano, demonstrating its suitability for real-time, resource-constrained industrial edge deployment.

## Method Summary
The proposed method extends PatchCore for on-device continual learning in manufacturing by replacing the Wide-ResNet backbone with MobileNetV3 (3.9M parameters) for lightweight feature extraction, implementing online learning with single-sample processing to eliminate batch memory overhead, and introducing an incremental k-center selection mechanism for memory-efficient coreset updates. For each incoming sample, patch features are extracted and compared against the existing memory bank using minimum L2 distance, with features having highest distance scores incrementally added to maintain diverse representation without redundant storage. The framework processes one sample at a time, updating the model and then discarding it, while optional data augmentation (sharpening/blurring) is applied to improve generalization across product variants.

## Key Results
- 12% improvement in AUROC compared to baseline PatchCore on a testbed with 5 workpieces and 35 unseen variants
- 80% reduction in memory usage through incremental k-center selection and lightweight MobileNetV3 backbone
- Real-time inference capability demonstrated on Jetson Orin Nano with faster training than batch learning approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incremental k-center selection enables memory-efficient coreset updates that preserve prior knowledge while selectively adding informative new features.
- Mechanism: For each incoming sample, patch features are extracted and compared against the existing memory bank using minimum L2 distance. Features with highest distance scores (i.e., most dissimilar to existing memory) are incrementally added, ensuring diverse representation without redundant storage.
- Core assumption: The distance metric in feature space meaningfully captures information novelty; features far from existing memory provide complementary coverage of the normal distribution.
- Evidence anchors:
  - [abstract] "incremental coreset update mechanism based on k-center selection, enabling rapid, memory-efficient adaptation from limited data"
  - [section 1.2.4] "Features with the highest distance scores are incrementally added to M′... By referencing prior feature distributions, this continual coreset growth mechanism has two major advantages: It maintains representational knowledge from previously seen samples, and efficiently selects diverse new representations"
  - [corpus] Related work "Memory Efficient Continual Learning for Edge-Based Visual Anomaly Detection" addresses similar constraints, suggesting this is an active research direction with shared assumptions.
- Break condition: If new product variants introduce features that are consistently distant from all prior distributions (e.g., radical geometric changes), the memory bank may grow unboundedly or fail to generalize without selective forgetting.

### Mechanism 2
- Claim: Lightweight backbone substitution (MobileNetV3 for Wide-ResNet) reduces resource demands while maintaining sufficient representational capacity for anomaly discrimination.
- Mechanism: MobileNetV3 (3.9M parameters) replaces Wide-ResNet (69M parameters), reducing memory footprint and inference latency. Features are still extracted at patch level, preserving spatial localization capability.
- Core assumption: The pre-trained ImageNet features from MobileNetV3 transfer sufficiently to industrial inspection domains; the representational gap does not critically degrade anomaly detection accuracy.
- Evidence anchors:
  - [abstract] "lightweight MobileNetV3 feature extractor"
  - [section 1.2.3] "Compared to the default Wide-ResNet backbone used in PatchCore, which has approximately 69 million parameters, it offers a more resource-efficient alternative that achieves a balance between efficiency and performance"
  - [corpus] Corpus papers do not provide direct comparison of MobileNetV3 vs. larger backbones for VAD; this assumption remains under-tested across domains.
- Break condition: If anomalies manifest as subtle texture defects requiring high-resolution feature discrimination, MobileNetV3's reduced capacity may miss fine-grained differences.

### Mechanism 3
- Claim: Online learning with single-sample processing eliminates batch memory overhead and enables real-time adaptation on edge hardware.
- Mechanism: Each sample is processed, used to update the model, then discarded—only one data instance resides in memory at any time. This removes the need to store historical datasets locally.
- Core assumption: Sequential single-sample updates converge to stable representations without the variance reduction benefits of batch gradient estimation (though PatchCore is non-gradient-based, this applies to coreset stability).
- Evidence anchors:
  - [abstract] "incorporating online learning...enabling rapid, memory-efficient adaptation from limited data while eliminating costly cloud retraining"
  - [section 1.2.1] "This paradigm updates the model using one sample per iteration and then discards it, ensuring that only a single data instance is held in memory at any given time"
  - [corpus] Insufficient corpus evidence on convergence properties of single-sample coreset updates; this remains a potential vulnerability.
- Break condition: If samples arrive in a non-representative order (e.g., all variants of one product type before others), the coreset may become biased toward early distributions.

## Foundational Learning

- **Concept:** PatchCore memory-bank architecture
  - Why needed here: The entire method extends PatchCore; understanding coreset construction, nearest-neighbor anomaly scoring, and patch-level localization is prerequisite.
  - Quick check question: Can you explain how PatchCore determines anomaly scores for a test image patch given a memory bank?

- **Concept:** Online vs. batch learning tradeoffs
  - Why needed here: The paper explicitly contrasts online single-sample updates against batch retraining; understanding when each is appropriate informs deployment decisions.
  - Quick check question: What information does batch learning have access to that online learning cannot assume?

- **Concept:** Edge resource constraints (memory, latency)
  - Why needed here: All design choices are justified by edge deployment requirements; understanding realistic hardware limits helps evaluate applicability.
  - Quick check question: Given a device with 8GB RAM and no GPU, what would be the maximum feasible backbone size for real-time inference?

## Architecture Onboarding

- **Component map:** Input stream → optional data augmentation → MobileNetV3 backbone → patch-level feature extraction → incremental k-center selector → memory bank → inference module (nearest-neighbor search)

- **Critical path:** Feature extraction quality → k-center selection threshold → coreset coverage → inference accuracy. The distance threshold for feature selection directly controls memory growth vs. representation completeness.

- **Design tradeoffs:**
  - Larger backbone → better features but higher memory/latency
  - Aggressive k-center filtering → smaller coreset but potential coverage gaps
  - More augmentation → better generalization but longer training time

- **Failure signatures:**
  - Memory bank grows unboundedly → k-center threshold too permissive
  - High false positive rate → coreset under-represents normal variation
  - Slow convergence on new variants → backbone features not transferring well

- **First 3 experiments:**
  1. **Baseline replication:** Implement standard PatchCore with Wide-ResNet on MVTec AD subset to verify anomaly detection performance before modifications.
  2. **Backbone ablation:** Replace Wide-ResNet with MobileNetV3 on same data; measure AUROC degradation and memory savings to quantify the tradeoff.
  3. **Incremental update validation:** Simulate continual learning by feeding samples sequentially; compare final coreset (and AUROC) against batch-constructed coreset to verify k-center selection preserves coverage.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can memory bank optimization techniques, such as dimension reduction and quantization, further reduce the resource footprint without compromising detection accuracy?
  - **Basis in paper:** [explicit] The authors state that "exploring memory bank optimisation techniques such as dimension reduction and quantisation can further reduce the resource requirements of our method."
  - **Why unresolved:** While the current method reduces memory via incremental selection, the features remain high-dimensional and uncompressed, which may still be heavy for extreme edge devices.
  - **What evidence would resolve it:** Evaluation of model accuracy (AUROC/AUPR) and latency on the Jetson platform after applying specific quantization or compression algorithms to the memory bank.

- **Open Question 2:** How does the framework perform when deployed across diverse, real-world industrial use cases beyond the controlled testbed?
  - **Basis in paper:** [explicit] The conclusion suggests future efforts should focus on "deploying the framework across additional industrial use cases to validate its generality and robustness."
  - **Why unresolved:** The current study is limited to a specific testbed with five workpieces and controlled lighting, which may not capture the full variability of factory environments.
  - **What evidence would resolve it:** Successful deployment and benchmarking of the framework in operational production lines with varying environmental conditions and product types.

- **Open Question 3:** Can more advanced continual learning mechanisms be integrated to enhance long-term knowledge retention and prevent catastrophic forgetting?
  - **Basis in paper:** [explicit] The authors identify "integrating more advanced continual learning mechanisms, such as enhanced knowledge retention," as a promising direction.
  - **Why unresolved:** The paper focuses on resource-efficient adaptation, but does not deeply evaluate complex scenarios where features from early tasks might be diluted or forgotten over many updates.
  - **What evidence would resolve it:** Ablation studies showing performance stability on initial product variants after the model has sequentially learned a large number of new variants.

- **Open Question 4:** Is the method feasible on microcontroller-class (TinyML) hardware, or is it limited to more powerful embedded systems like the Jetson Orin?
  - **Basis in paper:** [inferred] The paper positions the work within "TinyML" and "Edge AI," but validates it on a Jetson Orin Nano (CPU-only), which is significantly more powerful than the microcontrollers usually implied by TinyML.
  - **Why unresolved:** The current evaluation platform has 8GB RAM, whereas strict TinyML devices often have kilobytes of RAM; the feasibility of the nearest-neighbor search on such constrained hardware is unknown.
  - **What evidence would resolve it:** Benchmarks for memory usage and latency on a microcontroller unit (MCU) (e.g., ARM Cortex-M series).

## Limitations

- The effectiveness of MobileNetV3 features for industrial anomaly detection remains under-tested across diverse manufacturing domains
- The incremental k-center selection mechanism's convergence properties and robustness to sample ordering are not formally analyzed
- The memory growth bound under repeated variant introduction is unclear, potentially limiting long-term deployment scalability

## Confidence

- **High confidence:** AUROC improvement metrics and memory reduction claims are directly measured on the testbed with reproducible methodology
- **Medium confidence:** The claimed edge deployment feasibility on Jetson Orin Nano, while demonstrated, lacks comparison to alternative lightweight VAD approaches
- **Low confidence:** Generalization to radically different product geometries or when anomalies are subtle texture variations, given the limited domain diversity in validation

## Next Checks

1. **Cross-domain transfer validation:** Evaluate the method on MVTec AD or a semiconductor manufacturing dataset to assess backbone feature generalization beyond the original testbed
2. **Memory growth analysis:** Simulate extended deployment with 50+ product variants; measure coreset size scaling and compute the ratio of unique vs. redundant features added over time
3. **Order sensitivity test:** Process the same set of variant samples in different orders (e.g., grouped by type vs. randomized); measure variance in final AUROC and coreset composition to validate online learning stability