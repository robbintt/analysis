---
ver: rpa2
title: Can Bayesian Neural Networks Make Confident Predictions?
arxiv_id: '2501.11773'
source_url: https://arxiv.org/abs/2501.11773
tags:
- predictive
- distribution
- posterior
- networks
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether Bayesian neural networks (BNNs)
  can make confident predictions by analyzing their posterior predictive distributions.
  The authors introduce a discretized prior on inner layer weights, which allows exact
  characterization of the posterior predictive as a Gaussian mixture.
---

# Can Bayesian Neural Networks Make Confident Predictions?

## Quick Facts
- arXiv ID: 2501.11773
- Source URL: https://arxiv.org/abs/2501.11773
- Reference count: 40
- Primary result: Bayesian neural networks with discrete priors exhibit multimodal posterior predictive distributions that do not contract with proportional growth of network and training set sizes.

## Executive Summary
This paper investigates whether Bayesian neural networks can produce confident predictions by analyzing their posterior predictive distributions. The authors introduce a discretized prior on inner layer weights, enabling exact characterization of the posterior predictive as a Gaussian mixture. They demonstrate that distinct parameter realizations with low training error often map to distinct modes in the posterior predictive distribution, leading to multimodal predictions. The study reveals that unimodal posterior approximations are overconfident as they underestimate true predictive uncertainty, and that the posterior predictive distribution does not contract as network and training set sizes grow proportionally. These findings raise fundamental questions about whether BNNs can produce confident predictions in overparameterized regimes and highlight the need for approximate inference methods that capture the full complexity of Bayesian uncertainty.

## Method Summary
The authors analyze two-layer ReLU networks with discrete priors on inner layer weights to obtain analytical Gaussian mixture predictive distributions. They sample J candidate parameter sets from a prior N(0, c/d) where c = 2π/(π-1), then compute posterior predictive distributions via Bayes rule using marginal likelihoods. The approach enables identification of equivalence classes of network parameters that produce identical training error but different predictive modes. For optimal parameter construction, they generate candidates through rotations of X*_L, ReLU preimage samples, and column-space samples of X1. The framework allows exact computation of predictive distributions and identification of multimodality, providing insights into the behavior of Bayesian neural networks under different scaling regimes.

## Key Results
- Distinct parameter realizations with low training error often map to distinct modes in the posterior predictive distribution, leading to multimodal predictions
- Unimodal posterior approximations are overconfident as they underestimate true predictive uncertainty
- The posterior predictive distribution does not contract as network and training set sizes grow proportionally, suggesting BNNs struggle to "forget their priors" in overparameterized regimes

## Why This Works (Mechanism)
The mechanism relies on constructing a discrete prior over inner-layer weights that produces a finite set of candidate parameter configurations. Each configuration corresponds to a specific arrangement of hidden activations X_L = ReLU(Θ^(j)ᵀ X1), and these different arrangements can yield identical training performance but distinct predictive behaviors. By computing marginal likelihoods for each candidate and applying Bayes rule, the authors obtain a weighted mixture of Gaussian predictive distributions. The multimodality emerges because different parameter configurations that fit the training data equally well can produce systematically different predictions on test points. The non-contraction property arises because the discrete prior maintains a finite set of candidate modes regardless of how large the network grows relative to the training set.

## Foundational Learning
- **Gaussian mixture posterior predictive**: Understanding that the posterior predictive is a weighted sum of Gaussian distributions, each corresponding to a different parameter configuration. This is needed to grasp how multimodality arises and to compute predictive uncertainty. Quick check: Verify that mixing weights sum to 1 and that each component's variance includes both observation noise and parameter uncertainty.
- **Discrete prior construction**: Recognizing that the prior puts mass on a finite set of candidate parameter configurations rather than a continuous distribution. This is essential for obtaining analytical results and understanding the source of multimodality. Quick check: Confirm that candidate parameters are sampled from N(0, c/d) with c = 2π/(π-1).
- **Equivalence classes of parameters**: Identifying that different parameter configurations can produce identical training error but different predictive modes. This concept explains why BNNs can have rich predictive uncertainty even with low training loss. Quick check: Find two different Θ^(j) that yield the same X_L but different predictions on test data.

## Architecture Onboarding

### Component Map
X1 (input data) -> Θ^(j) (candidate parameters) -> X_L (hidden activations) -> L(Θ^(j)) (marginal likelihood) -> ρ_j (mixture weights) -> Predictive distribution (Gaussian mixture)

### Critical Path
The critical path flows from data generation through parameter sampling to predictive computation. First, synthetic data X1 and Y are generated from the unknown data-generating function g. Then J candidate parameter sets Θ^(j) are sampled from the discrete prior. For each candidate, hidden activations X_L are computed via ReLU(Θ^(j)ᵀ X1), followed by marginal likelihood calculation. Mixture weights are obtained via Bayes rule, and finally the predictive distribution is evaluated as a Gaussian mixture.

### Design Tradeoffs
The primary tradeoff is between computational tractability and approximation quality. Using a discrete prior enables exact analytical results but requires sampling a large number of candidates (J = 200,000) to capture all significant modes. The choice of c = 2π/(π-1) balances between having enough candidate parameters to represent the posterior while maintaining computational feasibility. The uniform prior assumption simplifies calculations but may not reflect realistic beliefs about parameter distributions.

### Failure Signatures
- Insufficient J causing mode undercounting, visible as log(mode count) continuing to increase with larger J
- Numerical instability in marginal likelihood when X_LᵀX_L eigenvalues are small, leading to inaccurate mixture weights
- Mode collapse when the prior puts insufficient mass on high-likelihood regions, resulting in overly concentrated predictive distributions

### First Experiments
1. Verify convergence by comparing mode counts for J ∈ {2000, 20000, 200000} and checking when log(mode count) stabilizes
2. Test prior sensitivity by varying c values around 2π/(π-1) and observing changes in multimodality
3. Validate non-contraction by systematically varying (d, n, p) ratios while keeping n/d constant and measuring posterior predictive variance scaling

## Open Questions the Paper Calls Out
- What are the minimum scaling rates between network size and training set size required to ensure the posterior predictive distribution contracts around the true value? Future work will establish minimum rates at which network size must grow with respect to training set size such that the predictive distribution does not contract.
- How does the predictive uncertainty resulting from multiple posterior modes quantitatively impact generalization error? The authors aim to quantify the impact of predictive uncertainty on generalization error in future research.
- Do the predictive distributions of partially stochastic networks significantly diverge from the full Bayesian predictive distribution characterized by discrete priors? The discussion notes that a future application is to determine whether distributions from partially stochastic networks diverge significantly from the full Bayesian predictive distribution.

## Limitations
- The exact data-generating function g(x₁) used to produce Y from X1 is not specified, limiting reproducibility of specific numerical results
- Implementation details for constructing rotations of X*_L that preserve ReLU nonnegativity constraints are only conceptually described
- The construction of optimal parameter candidates via sampling from ReLU preimages and column spaces is underspecified

## Confidence
- **High confidence**: The analytical framework for Gaussian mixture posterior predictive distributions is well-defined and verifiable through synthetic data experiments
- **Medium confidence**: The claim about multimodal predictions and overconfidence in unimodal approximations is supported by the mathematical framework, though exact numerical results depend on unspecified implementation details
- **Medium confidence**: The non-contraction result for posterior predictive variance under proportional scaling follows logically from the discrete prior construction but requires careful numerical verification

## Next Checks
1. **Convergence test**: Verify mode count stability by comparing results across J ∈ {2000, 20000, 200000} as specified in Appendix A.3
2. **Prior sensitivity**: Test how predictive multimodality changes when using alternative priors (e.g., different c values or non-uniform priors ρ_j)
3. **Architecture scaling**: Validate the non-contraction claim by systematically varying (d, n, p) ratios while keeping n/d constant, and measuring how posterior predictive variance scales