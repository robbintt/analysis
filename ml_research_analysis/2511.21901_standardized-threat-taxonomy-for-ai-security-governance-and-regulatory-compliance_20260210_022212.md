---
ver: rpa2
title: Standardized Threat Taxonomy for AI Security, Governance, and Regulatory Compliance
arxiv_id: '2511.21901'
source_url: https://arxiv.org/abs/2511.21901
tags:
- risk
- threat
- taxonomy
- management
- framework
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces the AI System Threat Vector Taxonomy, a
  structured ontology categorizing AI-specific risks into nine domains: Misuse, Poisoning,
  Privacy, Adversarial, Biases, Unreliable Outputs, Drift, Supply Chain, and IP Threat,
  comprising 53 operationally defined sub-threats. The framework uniquely maps technical
  vulnerabilities directly to business loss categories (Confidentiality, Integrity,
  Availability, Legal, Reputation), enabling quantitative risk assessment.'
---

# Standardized Threat Taxonomy for AI Security, Governance, and Regulatory Compliance

## Quick Facts
- **arXiv ID**: 2511.21901
- **Source URL**: https://arxiv.org/abs/2511.21901
- **Authors**: Hernan Huwyler
- **Reference count**: 28
- **Primary result**: Introduces a 9-domain, 53-sub-threat AI security taxonomy validated on 133 incidents with 100% coverage

## Executive Summary
This paper introduces the AI System Threat Vector Taxonomy, a structured ontology that categorizes AI-specific risks into nine domains: Misuse, Poisoning, Privacy, Adversarial, Biases, Unreliable Outputs, Drift, Supply Chain, and IP Threat. The framework uniquely maps technical vulnerabilities directly to business loss categories (Confidentiality, Integrity, Availability, Legal, Reputation), enabling quantitative risk assessment and regulatory compliance. Validated through analysis of 133 AI incidents from 2025, the taxonomy achieves complete classification coverage and is aligned with NIST AI RMF functions and ISO/IEC 42001 controls.

## Method Summary
The methodology involves developing a structured ontology of 53 operationally defined sub-threats across nine domains, validated through empirical analysis of 133 AI incidents from 2025. The framework maps technical vulnerabilities to business loss categories (CIA-L-R) and aligns with NIST AI RMF functions and ISO/IEC 42001 controls. The approach emphasizes quantitative risk assessment through Monte Carlo simulations, transitioning from qualitative "heat maps" to financial exposure analysis.

## Key Results
- Introduces 9-domain, 53-sub-threat AI security taxonomy validated on 133 incidents with 100% coverage
- Enables translation of technical threats into measurable financial impact through CIA-L-R mapping
- Aligns with NIST AI RMF functions and ISO/IEC 42001 controls for regulatory compliance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The taxonomy bridges the communication gap between technical security teams and governance/compliance professionals.
- **Mechanism:** By mapping technical vulnerabilities (e.g., "Model Inversion") directly to business loss categories (CIA-L-R), the framework functions as a translation layer. This allows non-technical stakeholders to understand algorithmic failures in terms of financial liability and regulatory fines.
- **Core assumption:** Stakeholders prioritize decisions based on financial impact and compliance risk over purely technical severity scores.
- **Evidence anchors:**
  - [abstract] "Uniquely, each domain maps technical vectors directly to business loss categories... enabling the translation of abstract threats into measurable financial impact."
  - [section 1.2] "A 'Model Inversion' attack is technically a data privacy breach, but its financial impact is realized through regulatory fines... a linkage often missed by purely technical threat models."
  - [corpus] Related work on "Unified Control Framework" supports the need for integrating governance and risk management.
- **Break condition:** If the mapping between a technical threat and a business loss category becomes ambiguous or subjective (e.g., determining the reputational cost of a minor drift event).

### Mechanism 2
- **Claim:** The taxonomy improves risk coverage by including non-adversarial, operational failures often missed by security-focused frameworks.
- **Mechanism:** Unlike frameworks such as MITRE ATLAS which focus on malicious intent, this ontology includes domains like "Unreliable Outputs" (hallucinations) and "Drift." This aligns risk assessment with operational reality, where accidental failures may occur more frequently than adversarial attacks.
- **Core assumption:** AI system failure is more frequently caused by data quality and model reliability issues than by active malicious attacks in standard enterprise deployments.
- **Evidence anchors:**
  - [abstract] "The framework categorizes AI-specific risks into nine critical domains... comprising 53 operationally defined sub-threats."
  - [section 6.1] "Empirical validation confirms that while academia prioritizes adversarial novelty, operational reality is dominated by Misuse and Unreliable Outputs."
  - [corpus] Weak support; neighbor papers focus on security/adversarial robustness or high-level governance, with less emphasis on operational reliability failures like drift.
- **Break condition:** If an organization's threat landscape is exclusively dominated by sophisticated adversarial actors (e.g., defense contractors), requiring a return to specialized attack frameworks.

### Mechanism 3
- **Claim:** Standardized threat definitions enable Quantitative Risk Assessment (QRA) and probabilistic modeling.
- **Mechanism:** The structured ontology provides the necessary discrete inputs (frequency and impact distributions) for Monte Carlo simulations. This replaces subjective "heat maps" with financial metrics (e.g., Value at Risk), allowing for evidence-based insurance and reserve setting.
- **Core assumption:** Organizations have access to sufficient historical data or expert estimation to calibrate the probability distributions for the 53 sub-threats.
- **Evidence anchors:**
  - [abstract] "...designed explicitly for Quantitative Risk Assessment (QRA)... allows organizations to transition from subjective, qualitative 'heat maps' to rigorous financial exposure analysis."
  - [section 5.1] "Parameter Calibration: Calibrating expected frequency and impact distributions... Controls are modeled as reductions in frequency or loss magnitude."
  - [corpus] "Engineering Risk-Aware... Frameworks" supports the move towards quantitative assurance.
- **Break condition:** If data availability is insufficient to parameterize the distributions, leading to "garbage in, garbage out" simulations.

## Foundational Learning

- **Concept: CIA-L-R Framework (Confidentiality, Integrity, Availability, Legal, Reputation)**
  - **Why needed here:** This is the "target" schema for the taxonomy. Learners must understand these five buckets to correctly classify technical threats into business impacts.
  - **Quick check question:** Does a "Poisoning" attack primarily impact the *Integrity* of the model or the *Availability* of the service?

- **Concept: Model Drift vs. Adversarial Attacks**
  - **Why needed here:** Distinguishing between environmental degradation (Drift) and malicious manipulation (Adversarial/Poisoning) is critical for correct classification and remediation.
  - **Quick check question:** If a model's accuracy declines because user behavior changed over six months, which domain does this fall under?

- **Concept: Probabilistic Risk Assessment**
  - **Why needed here:** The paper advocates moving away from deterministic "if-then" logic to probabilistic modeling. Understanding basic probability distributions is a prerequisite for the quantification workflow.
  - **Quick check question:** Why does the framework recommend Monte Carlo simulations over a simple qualitative Risk Matrix?

## Architecture Onboarding

- **Component map:** AI System Architecture & 133 Validated Incidents -> 9-Domain Taxonomy -> CIA-L-R Mapping -> Quantitative Risk Models & Compliance Audits

- **Critical path:**
  1.  **Scoping:** Define the AI system boundary.
  2.  **Classification:** Map system components to the 9 domains (e.g., identifying external data feeds triggers "Supply Chain").
  3.  **Quantification:** Assign frequency/impact values to the mapped threats.
  4.  **Compliance Mapping:** Link identified threats to ISO 42001 controls (e.g., Control 6.3.1 for Poisoning).

- **Design tradeoffs:**
  - **Breadth vs. Depth:** The taxonomy covers 9 domains to ensure governance-level coverage, potentially sacrificing the extreme technical granularity found in specialized attack frameworks like MITRE ATLAS.
  - **Generality vs. Specificity:** Aligned with NIST/ISO for broad auditability, but may require customization for niche industry risks.

- **Failure signatures:**
  - **The "Heat Map" Relapse:** Falling back to qualitative "High/Medium/Low" ratings instead of calibrating financial loss distributions.
  - **The "Technical Silo":** Classifying "Prompt Injection" solely as a security bug without mapping it to the "Legal" or "Reputation" loss categories.

- **First 3 experiments:**
  1.  **Retroactive Classification:** Take the last 3 AI incidents your organization experienced and attempt to classify them into the 9 domains to test coverage.
  2.  **Loss Mapping Drill:** Pick one domain (e.g., "Unreliable Outputs") and explicitly define the financial impact if it occurred (e.g., cost of customer churn).
  3.  **Control Gap Analysis:** Select a high-risk domain (e.g., "Supply Chain") and check if existing ISO 42001 controls (Annex A) are actually implemented for that vector.

## Open Questions the Paper Calls Out

None

## Limitations

- **Data Availability for QRA**: The framework's quantification mechanism assumes sufficient historical data or expert estimation exists to calibrate frequency and impact distributions for all 53 sub-threats, which many organizations may lack.
- **Dynamic Threat Landscape**: AI security threats evolve rapidly, and the taxonomy's static nature may not capture emerging attack vectors without regular updates and extensions.
- **Industry-Specific Customization Needs**: The framework's broad applicability may require significant tailoring for highly regulated industries where specific compliance requirements may not map cleanly to the generic domains.

## Confidence

- **High Confidence**: The taxonomy's coverage and alignment with ISO/NIST frameworks, supported by empirical validation using 133 incidents achieving 100% classification coverage.
- **Medium Confidence**: The translation mechanism between technical threats and business loss categories, as the actual quantification of financial impact for some threats remains inherently subjective and organization-specific.
- **Medium Confidence**: The claim that operational failures (drift, unreliable outputs) dominate over adversarial attacks, which may be context-dependent and vary across industries.

## Next Checks

1. **Cross-Industry Applicability Test**: Apply the taxonomy to incident datasets from multiple industry sectors (healthcare, finance, manufacturing) to validate whether the nine-domain structure maintains coverage and relevance across different operational contexts.
2. **Financial Quantification Validation**: Conduct a pilot study where multiple organizations independently attempt to quantify the financial impact of selected threats using the CIA-L-R framework, measuring inter-rater reliability and identifying sources of subjective variation.
3. **Control Effectiveness Assessment**: Analyze whether ISO/IEC 42001 controls mapped to each domain actually reduce the frequency or impact of corresponding threats in real-world implementations, measuring the delta between theoretical and actual risk reduction.