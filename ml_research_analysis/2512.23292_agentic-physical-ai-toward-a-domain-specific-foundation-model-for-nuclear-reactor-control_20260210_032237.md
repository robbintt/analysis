---
ver: rpa2
title: Agentic Physical AI toward a Domain-Specific Foundation Model for Nuclear Reactor
  Control
arxiv_id: '2512.23292'
source_url: https://arxiv.org/abs/2512.23292
tags:
- control
- physical
- foundation
- agentic
- success
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Agentic Physical AI, a framework for training
  compact language models as control agents in nuclear reactor systems. By combining
  a two-phase curriculum (grammar learning followed by task conditioning) with outcome-centric
  validation in a high-fidelity reactor simulator, the method enables a 360-million-parameter
  model to autonomously discover robust control strategies.
---

# Agentic Physical AI toward a Domain-Specific Foundation Model for Nuclear Reactor Control

## Quick Facts
- arXiv ID: 2512.23292
- Source URL: https://arxiv.org/abs/2512.23292
- Reference count: 40
- One-line primary result: Scaling training data from 1,000 to 100,000 synthetic scenarios induces a phase transition: success rates jump from 26.2% to 92% at ±1% tolerance, variance collapses 500-fold, and the model concentrates 76% of runtime execution on a single-bank strategy despite balanced training.

## Executive Summary
This paper introduces Agentic Physical AI, a framework for training compact language models as control agents in nuclear reactor systems. By combining a two-phase curriculum (grammar learning followed by task conditioning) with outcome-centric validation in a high-fidelity reactor simulator, the method enables a 360-million-parameter model to autonomously discover robust control strategies. Scaling training data from 1,000 to 100,000 synthetic scenarios induces a phase transition: success rates jump from 26.2% to 92% at ±1% tolerance, variance collapses 500-fold, and the model concentrates 76% of runtime execution on a single-bank strategy despite balanced training. The approach transfers to a different physics engine (PyRK) with >94% success and demonstrates tail-risk collapse with zero severe failures at 100K scale. This represents a paradigm shift from optimization-based to generation-based control, enabling safe, reliable, and computationally efficient learning-enabled actuation in safety-critical nuclear systems.

## Method Summary
Agentic Physical AI trains compact language models as control agents using a two-phase curriculum: first, models learn the symbolic grammar of reactor control (rod positions, time steps, safety limits) via a masked-language modeling objective, then they learn task-specific policies via supervised fine-tuning on paired initial/final states and control trajectories. Training data is synthesized from a high-fidelity simulator (KOMODO), generating diverse power transition scenarios. The framework employs outcome-centric validation: instead of traditional numerical error, success is measured by whether the reactor reaches the target power state within tight tolerances and without violating safety limits. Decoding uses a sliding window approach, predicting rod positions at each step conditioned on the evolving reactor state. A 360M-parameter model is trained on up to 100K scenarios, and transfer is tested to a different simulator (PyRK).

## Key Results
- Scaling training data from 1,000 to 100,000 synthetic scenarios induces a phase transition: success rates jump from 26.2% to 92% at ±1% tolerance, variance collapses 500-fold, and the model concentrates 76% of runtime execution on a single-bank strategy despite balanced training.
- The approach transfers to a different physics engine (PyRK) with >94% success and demonstrates tail-risk collapse with zero severe failures at 100K scale.
- This represents a paradigm shift from optimization-based to generation-based control, enabling safe, reliable, and computationally efficient learning-enabled actuation in safety-critical nuclear systems.

## Why This Works (Mechanism)
The success of Agentic Physical AI hinges on a curriculum that first instills the symbolic grammar of reactor control, enabling the model to generate syntactically valid and physically plausible control actions. This grammar learning acts as a scaffold, ensuring that subsequent task-specific fine-tuning occurs within a constrained, meaningful space. The outcome-centric validation—measuring success by final state accuracy and safety adherence rather than step-by-step error—enables the model to discover efficient, safe strategies that may not be obvious to traditional optimizers. The combination of large-scale synthetic data generation and outcome-focused assessment induces a phase transition: at sufficient scale, the model rapidly learns robust, generalizable policies that collapse solution variance and concentrate on the most effective strategies, even when the training set is balanced. Transfer to a different simulator (PyRK) shows that the learned control policies are not simulator-specific, but capture generalizable reactor physics principles.

## Foundational Learning
- **Symbolic grammar of reactor control**: Rod positions, time steps, safety limits. Needed to ensure model-generated actions are physically valid and executable; quick check: mask-predict task, no constraint violations in generated sequences.
- **Reactor physics fundamentals**: Power rate of change, xenon poisoning, boron effects. Needed to capture system dynamics for accurate prediction; quick check: simulated vs. actual state divergence < 1% per step.
- **Curriculum learning**: Grammar first, then task-specific fine-tuning. Needed to prevent model from generating physically impossible actions; quick check: training loss curve shows stable decrease, no divergence.
- **Outcome-centric validation**: Success measured by final state accuracy and safety adherence. Needed to focus learning on practical, safe control rather than step-by-step error minimization; quick check: success rate ≥ 90% at ±1% tolerance, zero severe failures.
- **Synthetic data generation**: Diverse power transition scenarios from high-fidelity simulator. Needed to cover the operational envelope and expose the model to edge cases; quick check: training set covers all control rod bank combinations, power ranges, and xenon/boron states.
- **Transfer learning**: Validation across different physics engines (KOMODO to PyRK). Needed to ensure policies are generalizable, not simulator-specific; quick check: >94% success on transferred simulator, comparable variance collapse.

## Architecture Onboarding
- **Component map**: Synthetic scenario generator -> Curriculum learning pipeline (grammar -> task) -> Outcome-centric validation -> Model deployment
- **Critical path**: Data generation → Grammar learning → Task conditioning → Outcome validation → Transfer testing
- **Design tradeoffs**: Grammar-first curriculum ensures safety but may slow task-specific learning; outcome-centric validation focuses on practical success but may overlook subtle error accumulation; transfer tests generalizability but at risk of performance drop.
- **Failure signatures**: Constraint violations (rod limits, safety margins), high variance in solution trajectories, simulator-specific artifacts not captured by transfer.
- **First experiment**: Train on 1K scenarios, evaluate success rate and variance; repeat with 10K, 50K, 100K to observe phase transition.
- **Second experiment**: Test transfer to PyRK, measure success rate and solution variance.
- **Third experiment**: Introduce adversarial perturbations (sensor noise, actuator failures) and measure model robustness and failure modes.

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can the observed agentic behavior and phase transitions scale to multi-step temporal procedures like startup sequences or load-following with equipment constraints?
- Basis in paper: [explicit] The authors state that "Extension to multi-step procedures... defines the path toward a complete domain-specific foundation model," noting current work is limited to single-step maneuvers.
- Why unresolved: Current validation measures success on static power transitions, not sequential decision-making where early actions constrain future states.
- What evidence would resolve it: Successful validation of the model on multi-step benchmarks (e.g., startup to full power) requiring temporal planning without performance degradation.

### Open Question 2
- Question: Will the learned structural priors transfer to reactors with fundamentally different physics and actuation modalities, such as liquid-salt or gas-cooled designs?
- Basis in paper: [explicit] The paper notes transfer is "unvalidated" for types beyond PWR-like systems and lists "diverse reactor types" as a required extension for complete coverage.
- Why unresolved: The current transfer experiments (KOMODO to PyRK) involve similar rod-based PWR physics; different reactor classes have orthogonal control mechanisms (e.g., chemical shim, void feedback).
- What evidence would resolve it: Demonstration of cross-simulator transfer to a BWR or fast reactor simulator without architectural modification or significant retraining data.

### Open Question 3
- Question: How can the framework integrate uncertainty quantification to distinguish high-confidence control proposals from uncertain extrapolations?
- Basis in paper: [explicit] The authors identify a limitation where the "model generates point predictions without confidence bounds," preventing operators from assessing proposal reliability.
- Why unresolved: The current decoding produces deterministic numeric tokens, offering no internal metric for trustworthiness in edge cases.
- What evidence would resolve it: Integration of Bayesian methods or ensemble outputs that provide calibrated confidence intervals alongside control proposals while maintaining variance collapse.

## Limitations
- The reported phase transition in scaling from 1K to 100K training samples is compelling but hinges on the assumed physical fidelity of the surrogate simulators; discrepancies between simulator physics and actual reactor dynamics could produce misleading success metrics.
- The focus on a single-bank strategy, while efficient, raises questions about robustness under unexpected disturbances or sensor failures, and the paper does not quantify model brittleness under such perturbations.
- There is also a lack of formal safety validation under adversarial conditions, which is critical for safety-critical nuclear control.

## Confidence
- **High**: Scaling law evidence, phase transition from 1K to 100K samples, success rate gains, variance collapse.
- **Medium**: Generalization to a different simulator (PyRK), tail-risk improvement.
- **Low**: Safety guarantees under perturbations, adversarial conditions, and real-world physical validation.

## Next Checks
1. Conduct adversarial robustness testing by injecting sensor noise, actuator failures, and unexpected disturbances to measure model failure modes.
2. Validate performance across multiple reactor core designs and operating conditions to confirm generalizability beyond the tested PWR configuration.
3. Perform formal safety analysis and worst-case scenario simulation to certify compliance with nuclear regulatory standards.