---
ver: rpa2
title: 'CCHall: A Novel Benchmark for Joint Cross-Lingual and Cross-Modal Hallucinations
  Detection in Large Language Models'
arxiv_id: '2505.19108'
source_url: https://arxiv.org/abs/2505.19108
tags:
- hallucination
- cross-lingual
- image
- cross-modal
- hallucinations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CCHall, a novel benchmark for detecting joint
  cross-lingual and cross-modal hallucinations in large language models. Unlike prior
  work that focuses on single scenarios, CCHall integrates both cross-lingual and
  cross-modal hallucination detection to better reflect real-world complexity.
---

# CCHall: A Novel Benchmark for Joint Cross-Lingual and Cross-Modal Hallucinations Detection in Large Language Models

## Quick Facts
- arXiv ID: 2505.19108
- Source URL: https://arxiv.org/abs/2505.19108
- Authors: Yongheng Zhang; Xu Liu; Ruoxi Zhou; Qiguang Chen; Hao Fei; Wenpeng Lu; Libo Qin
- Reference count: 36
- Primary result: Introduces CCHall, a benchmark for detecting joint cross-lingual and cross-modal hallucinations in LLMs, showing performance gaps across 12 models

## Executive Summary
This paper introduces CCHall, a novel benchmark designed to evaluate joint cross-lingual and cross-modal hallucination detection in large language models. Unlike prior work that addresses hallucinations in single modalities or languages, CCHall integrates both dimensions to better reflect real-world complexity. The benchmark is constructed using multimodal tasks such as visual question answering and image captioning, covering 9 languages across different resource levels. Evaluation of 12 models including GPT-4o, Gemini-1.5-Flash, and open-source variants demonstrates significant performance gaps, with the best model achieving 77.5% accuracy. The study reveals that high-resource languages and high-resolution images improve detection accuracy, while longer responses correlate with higher hallucination rates.

## Method Summary
CCHall is constructed using multimodal tasks including visual question answering and image captioning, covering 9 languages across low, medium, and high-resource categories. The benchmark integrates both cross-lingual and cross-modal hallucination detection to address real-world complexity. Evaluation involves 12 models, including GPT-4o, Gemini-1.5-Flash, and various open-source variants. The methodology systematically varies language resource levels and image resolution to assess detection performance under different conditions.

## Key Results
- CCHall benchmark integrates cross-lingual and cross-modal hallucination detection
- Best model achieves 77.5% accuracy across 12 evaluated models
- High-resource languages and high-resolution images improve detection accuracy
- Longer responses correlate with increased hallucination rates

## Why This Works (Mechanism)
The benchmark's effectiveness stems from its integration of cross-lingual and cross-modal dimensions, which creates a more realistic evaluation scenario that reflects real-world complexity. By covering 9 languages across different resource levels and using multimodal tasks, CCHall captures the diverse conditions under which hallucinations occur. The systematic variation in language resources and image resolution allows for nuanced analysis of model performance across different contexts, revealing specific patterns such as the advantage of high-resource languages and high-resolution images for hallucination detection.

## Foundational Learning
1. Cross-lingual hallucinations: Why needed - Models often perform poorly on low-resource languages due to limited training data; Quick check - Compare detection accuracy across language resource levels
2. Cross-modal hallucinations: Why needed - Multimodal models can generate inconsistent or incorrect information when processing visual and textual inputs together; Quick check - Evaluate model performance on VQA vs image captioning tasks
3. Hallucination detection: Why needed - Identifying when models generate false or unsupported information is crucial for reliability; Quick check - Measure detection accuracy as a function of response length

## Architecture Onboarding
**Component Map**: Benchmark construction -> Model evaluation -> Performance analysis -> Pattern identification
**Critical Path**: Image/text input → Multimodal processing → Response generation → Hallucination detection → Accuracy measurement
**Design Tradeoffs**: Covers 9 languages for breadth vs. deeper analysis of fewer languages; includes 12 models for comprehensive evaluation vs. more detailed individual model analysis
**Failure Signatures**: Lower accuracy on low-resource languages; decreased performance with lower image resolution; increased hallucinations with longer responses
**3 First Experiments**: 1) Replicate benchmark with additional task types to test generalizability; 2) Conduct controlled experiments varying only image resolution; 3) Perform ablation studies on prompt engineering methodology

## Open Questions the Paper Calls Out
None identified in the provided information.

## Limitations
- Benchmark covers only 9 languages, potentially limiting generalizability to broader multilingual contexts
- Evaluation based on only two task types (VQA and image captioning) may not capture all hallucination scenarios
- Performance improvements with high-resolution images may be influenced by model pre-training data distribution

## Confidence
- Novel benchmark claim: High - Well-supported by evaluation methodology and empirical results
- Real-world complexity representation: Medium - Limited by scope of 9 languages and 2 task types
- High-resource language advantage: Medium - Requires consideration of confounding factors like training data distribution
- Response length correlation: Medium - Potential correlation with task difficulty or model uncertainty

## Next Checks
1. Replicate the benchmark evaluation across additional task types (e.g., visual question answering with temporal reasoning, multimodal summarization) to assess robustness beyond the current scope
2. Conduct controlled experiments varying only image resolution while holding other factors constant to isolate the specific impact on hallucination detection accuracy
3. Perform ablation studies on the prompt engineering methodology to determine how sensitive detection performance is to prompt design variations across different language-resource levels