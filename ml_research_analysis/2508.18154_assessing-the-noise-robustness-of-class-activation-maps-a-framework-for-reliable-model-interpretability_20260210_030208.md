---
ver: rpa2
title: 'Assessing the Noise Robustness of Class Activation Maps: A Framework for Reliable
  Model Interpretability'
arxiv_id: '2508.18154'
source_url: https://arxiv.org/abs/2508.18154
tags:
- robustness
- noise
- methods
- across
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the robustness of Class Activation Maps (CAMs)
  under input perturbations, a critical issue for reliable model interpretability.
  The authors propose a novel framework that evaluates CAM robustness through two
  key properties: consistency (stability under class-preserving perturbations) and
  responsiveness (sensitivity to class-changing perturbations).'
---

# Assessing the Noise Robustness of Class Activation Maps: A Framework for Reliable Model Interpretability

## Quick Facts
- **arXiv ID:** 2508.18154
- **Source URL:** https://arxiv.org/abs/2508.18154
- **Reference count:** 40
- **Primary result:** Proposed framework evaluates CAM robustness through consistency (stability under class-preserving perturbations) and responsiveness (sensitivity to class-changing perturbations), showing GradCAM++ consistently achieves highest robustness scores across 4 models, 7 datasets, and 8 perturbation types.

## Executive Summary
This paper addresses the critical issue of evaluating Class Activation Maps (CAMs) under input perturbations, which is essential for reliable model interpretability. The authors propose a novel framework that quantifies CAM robustness through two complementary properties: consistency (stability when predictions don't change) and responsiveness (sensitivity when predictions do change). Using Rank-Biased Overlap (RBO) for rank stability and a binary classifier for responsiveness, the method provides a comprehensive, quantitative approach to comparing CAM methods under noise. Experiments demonstrate that while some methods show high stability, they fail to be responsive to meaningful changes, highlighting the need for dual-property evaluation.

## Method Summary
The framework evaluates CAM robustness by first segmenting images into superpixels (QuickShift default), then generating CAMs for both clean and perturbed images across six methods. Segment-wise mean intensities are computed and ranked, with RBO (p=0.9) measuring rank stability between clean and perturbed versions. Consistency is defined as median RBO when predictions remain unchanged, while responsiveness is the AUC of a linear classifier trained to predict class-change events from RBO scores. The final Robustness Metric equals Consistency × Responsiveness. The framework is model- and perturbation-agnostic, enabling systematic comparison across architectures, datasets, and noise types.

## Key Results
- GradCAM++ consistently achieves the highest robustness scores across all evaluated conditions
- EigenCAM and AblationCAM are least robust, showing dramatic drops at higher perturbation levels despite high stability at low levels
- Adversarial attacks cause prediction changes even at low severity, while natural noise requires higher severity, asymmetrically triggering the responsiveness component
- ViT models show significantly higher variance in robustness scores compared to CNNs, suggesting CAM methods designed for CNNs may be unstable on transformers

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Rank-Biased Overlap (RBO) captures meaningful structural changes in CAM outputs more reliably than pixel-wise distance metrics.
- **Mechanism:** RBO computes similarity between ranked segment lists rather than raw intensity values. It weights top-ranked segments more heavily via a persistence parameter (p=0.9), making it sensitive to reordering of salient regions while ignoring pixel-level noise that doesn't affect region hierarchy.
- **Core assumption:** Segment importance rankings, not raw pixel intensities, reflect the semantic structure of model explanations.
- **Evidence anchors:**
  - [abstract]: "We propose a robustness metric for CAMs that captures two key properties: consistency and responsiveness."
  - [section 2.6 / Appendix A.1]: Figure A.10 demonstrates that normalized L1 distance can decrease (0.289→0.237) even when CAM structure changes significantly, while RBO drops appropriately (0.779→0.502).
  - [corpus]: CF-CAM paper acknowledges gradient-based interpretability reliability issues, supporting the need for rank-based evaluation over raw gradients.
- **Break condition:** If perturbations cause uniform intensity shifts without reordering segments, RBO may underreport changes that pixel-wise metrics would capture.

### Mechanism 2
- **Claim:** Robustness requires both stability under class-preserving perturbations (consistency) AND sensitivity when predictions change (responsiveness).
- **Mechanism:** The Robustness Metric = Consistency × Responsiveness. Consistency is computed as median RBO only when predicted class is unchanged. Responsiveness is the AUC of a classifier predicting class-change from RBO scores. High scores require excelling at both conditions.
- **Core assumption:** A faithful explanation method should reflect the model's decision boundary—not be arbitrarily stable nor chaotically sensitive.
- **Evidence anchors:**
  - [abstract]: "Consistency reflects the ability of CAMs to remain stable under input perturbations that do not alter the predicted class, while responsiveness measures the sensitivity of CAMs to changes in the prediction."
  - [section 4.3.3 / Table 13]: EigenCAM achieves highest robustness at low perturbation levels (0.643-0.755) due to high consistency, but drops dramatically (to ~0.21) at higher levels where responsiveness becomes critical—exposing its class-insensitivity.
  - [corpus]: DiffGradCAM paper addresses CAM sensitivity to adversarial training, corroborating that stability alone is insufficient.
- **Break condition:** If class-change events are rare in the evaluation set, responsiveness estimation becomes unreliable due to class imbalance in the binary classifier.

### Mechanism 3
- **Claim:** Superpixel-based aggregation provides noise-robust quantification of region importance independent of segmentation algorithm choice.
- **Mechanism:** Images are segmented into superpixels (QuickShift default). CAM intensities are averaged per segment, then segments are ranked by mean saliency. This spatial pooling reduces sensitivity to localized pixel noise while preserving region-level structure.
- **Core assumption:** Salient regions are spatially coherent; averaging within superpixels preserves relative importance.
- **Evidence anchors:**
  - [section 2.1]: "We use QuickShift as the segmentation algorithm, and the resulting superpixels are held fixed for all CAM and perturbation variants."
  - [section 4.3.1 / Tables 8-10]: Across QuickShift, SLIC, and Felzenszwalb segmentation methods with matched segment counts, robustness scores vary only marginally (e.g., GradCAM++: 0.417-0.419 under Gaussian noise), and relative CAM rankings remain unchanged (Kendall's W = 0.97-1.0).
  - [corpus]: Weak direct evidence; neighbor papers focus on robustness mechanisms rather than evaluation methodology.
- **Break condition:** If segmentation boundaries cut through semantically meaningful regions, segment-level averages may misrepresent true importance distributions.

## Foundational Learning

- **Concept: Class Activation Mapping (CAM) variants**
  - Why needed here: The paper evaluates six methods (GradCAM, GradCAM++, EigenCAM, HiResCAM, XGradCAM, AblationCAM) with fundamentally different computation strategies—gradient-based, eigen decomposition-based, and ablation-based.
  - Quick check question: Can you explain why EigenCAM, which uses principal components rather than class-specific gradients, might show high visual stability but low responsiveness to class changes?

- **Concept: Perturbation taxonomy (natural vs. adversarial)**
  - Why needed here: Results show adversarial attacks cause prediction changes even at low severity, while natural noise (Gaussian, blur) requires higher severity. This asymmetrically triggers the responsiveness component.
  - Quick check question: Why might adversarial training improve classification robustness without improving CAM stability (as noted in Section 4 and Appendix A.6)?

- **Concept: Rank correlation metrics and RBO specifically**
  - Why needed here: RBO's persistence parameter (p=0.9) allows tunable emphasis on top-ranked segments, unlike Kendall's τ or Spearman's ρ which treat all ranks equally. This matters for medical/safety-critical applications where top regions are most important.
  - Quick check question: Given p=0.9, what fraction of the RBO score weight is concentrated in the top-10 segments of a 100-segment ranking?

## Architecture Onboarding

- **Component map:** Segmentation module → Perturbation generator → CAM computation → Aggregation layer → RBO calculator → Responsiveness classifier → Robustness scorer

- **Critical path:** Segmentation → CAM generation (clean + perturbed) → Segment aggregation → RBO computation → Filter by class-change condition → Median (consistency) and AUC (responsiveness) aggregation. Runtime ~0.445s per image/CAM/noise combination.

- **Design tradeoffs:**
  - RBO persistence (p=0.9): Higher p emphasizes top ranks; if application cares about all regions equally, lower p or Kendall's τ may be appropriate
  - Segmentation granularity: More segments capture finer detail but increase variance; paper uses ~120 segments as a balance point
  - Binary classifier for responsiveness: Linear model chosen for interpretability; more complex models could improve AUC but reduce transparency

- **Failure signatures:**
  - EigenCAM showing high robustness at low noise but dramatic drop at higher levels indicates false sense of security from consistency-only metrics
  - ViT models showing significantly higher variance in robustness scores (Figure 7 vs. Figures 4-6) indicates CAM methods designed for CNNs may be unstable on transformers
  - L1 distance decreasing while RBO drops (Figure A.10) indicates pixel-wise metrics can be actively misleading

- **First 3 experiments:**
  1. **Sanity check:** Run the framework on a single ImageNet image with GradCAM and Gaussian noise at 3 severity levels. Verify that RBO values cluster near 0.85 (low noise) and drop toward 0.5 (high noise), matching Table 13 patterns.
  2. **Segmentation ablation:** Compare QuickShift vs. SLIC on 100 OxfordPets images with GradCAM++. Confirm that robustness scores differ by <0.02 and relative CAM rankings are preserved (Kendall's W > 0.95).
  3. **Adversarial training validation:** Evaluate a standard ResNet-50 vs. an adversarially-trained ResNet-50 on the same ImageNet subset with FGSM attacks. Confirm that classification robustness improves but CAM robustness scores remain similar (within ±0.02), as reported in Appendix A.6.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the proposed robustness framework generalize to volumetric medical imaging modalities (e.g., MRI, CT) which possess distinct structural and noise characteristics compared to the 2D natural images evaluated?
- Basis in paper: [explicit] The authors explicitly state in the Limitations section that they "have not specifically studied modality-specific scenarios such as CT, MRI, or X-ray imaging" and identify this as a direction for future work.
- Why unresolved: The current evaluation is restricted to 2D datasets (e.g., ImageNet, Melanoma), and the framework relies on 2D superpixel segmentation (QuickShift), which may not translate directly to 3D volumetric data or the specific texture noise found in clinical scans.
- What evidence would resolve it: Applying the framework to a 3D medical dataset (e.g., BraTS) using supervoxel segmentation, comparing the robustness rankings of CAM methods against the 2D natural image benchmarks provided in the paper.

### Open Question 2
- Question: Can specialized training objectives be designed to simultaneously improve the model's classification robustness and the proposed CAM Robustness Metric (RM), resolving the current trade-off observed with adversarial training?
- Basis in paper: [explicit] The paper concludes that "adversarial training improves classification robustness, it does not necessarily improve CAM stability," highlighting a disconnect between model robustness and explanation stability.
- Why unresolved: The study evaluates existing training regimes but does not propose a method to optimize for explanation stability (Consistency and Responsiveness) during the training process itself.
- What evidence would resolve it: A training experiment where the Robustness Metric or its components are incorporated as a differentiable regularization loss, resulting in a model that maintains high classification accuracy while achieving higher RM scores than standard or adversarially trained models.

### Open Question 3
- Question: Is the observed high variance in Vision Transformer (ViT) CAM robustness an inherent property of the architecture or a byproduct of using gradient-based CAM methods designed for CNNs?
- Basis in paper: [inferred] The results show ViT exhibits "significantly greater variance in robustness score values across all CAM methods" compared to CNNs, yet the paper does not determine if this is due to the patch-based nature of ViTs or the applicability of the explanation method.
- Why unresolved: The paper benchmarks existing methods on ViT but leaves open the question of whether transformer-specific explanation mechanisms would yield the stability seen in ResNet or VGG architectures.
- What evidence would resolve it: Evaluating transformer-native attribution methods (e.g., Attention Rollout) using the proposed framework to see if they reduce the variance and achieve stability comparable to CNN-based methods.

## Limitations

- **Segmentation quality dependency:** Framework effectiveness depends on segmentation quality, with poor boundaries cutting through semantically meaningful regions potentially misrepresenting importance distributions.
- **Rare class-change bias:** Responsiveness component becomes unreliable when class changes are rare under certain perturbation-severity combinations, potentially inflating robustness scores for methods that maintain predictions despite structural CAM changes.
- **Model prediction confound:** Framework depends on pre-trained model predictions, meaning fundamental model weaknesses may confound CAM-specific robustness assessments.

## Confidence

- **High confidence:** The framework's dual-property approach (consistency × responsiveness) correctly captures the distinction between stable and class-sensitive explanations. This is well-supported by experimental evidence showing EigenCAM's high consistency but low responsiveness at higher perturbation levels.
- **Medium confidence:** RBO is superior to pixel-wise metrics for capturing structural changes in CAM outputs. While the paper demonstrates this with specific examples, broader validation across different types of semantic changes would strengthen this claim.
- **Medium confidence:** The segmentation-based aggregation method provides noise-robust quantification. The cross-algorithm validation is convincing, but edge cases involving fine-grained features near segment boundaries remain untested.

## Next Checks

1. **Segmentation boundary sensitivity test:** Evaluate the framework on images where segmentation boundaries cut through critical object parts (e.g., cat faces split across segments) to quantify impact on robustness scores.

2. **Rare class-change scenario validation:** Systematically reduce perturbation severity until class changes become infrequent (<10% of samples) and verify whether responsiveness estimates become unstable or biased.

3. **Model-agnostic robustness verification:** Apply the framework to transformer-based vision models beyond ViT (e.g., Swin Transformer) to determine if the observed instability extends to other transformer architectures or is specific to ViT's architectural details.