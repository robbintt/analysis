---
ver: rpa2
title: Biomedical Hypothesis Explainability with Graph-Based Context Retrieval
arxiv_id: '2511.05498'
source_url: https://arxiv.org/abs/2511.05498
tags:
- biomedical
- context
- hypothesis
- retrieval
- explainability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study presents HGCR, a graph-based biomedical hypothesis explainability
  framework that combines semantic path retrieval with large language models (LLMs).
  The system constructs dynamic biomedical co-occurrence graphs from MEDLINE literature
  and retrieves semantic paths between concept pairs, using them as context for LLM-generated
  explanations.
---

# Biomedical Hypothesis Explainability with Graph-Based Context Retrieval

## Quick Facts
- arXiv ID: 2511.05498
- Source URL: https://arxiv.org/abs/2511.05498
- Reference count: 32
- HGCR framework combines semantic path retrieval with LLMs to generate explainable biomedical hypotheses

## Executive Summary
HGCR introduces a graph-based biomedical hypothesis explainability framework that retrieves semantic paths from dynamic co-occurrence graphs and uses them as context for LLM-generated explanations. The system implements a feedback loop that iteratively validates extracted predicates against AGATHA, correcting unsupported claims to improve scientific plausibility. Evaluation shows HGCR-based explanations achieve higher semantic similarity to future reference abstracts compared to baseline RAG systems, with the feedback loop reducing error rates by approximately 50-70% across multiple LLMs.

## Method Summary
HGCR constructs dynamic biomedical co-occurrence graphs from MEDLINE literature where nodes are UMLS CUIs and edges represent abstract co-occurrences. The system retrieves shortest paths between concept pairs using a cross-attention ranker trained with contrastive learning on future-validated labels. LLM-generated explanations incorporate top-k ranked paths, with a feedback loop extracting structured predicates via SemRep and validating them against AGATHA. Invalid predicates trigger context refinement through MedCPT similarity-based PMID replacement, iterating up to 5 times.

## Key Results
- HGCR-based explanations achieve higher lexical and semantic similarity to future reference abstracts than baseline RAG systems
- Feedback loop reduces error rates from ~4.5% to ~1.5-2% across multiple LLMs
- Cross-attention ranking achieves ~0.89 micro-AUC on 2022+ test set using pre-2022 training data
- Context size k=7 provides optimal tradeoff between explanation quality and computational cost

## Why This Works (Mechanism)

### Mechanism 1: Cross-Attention Path Ranking with Contrastive Learning
The model learns to distinguish plausible biomedical reasoning paths by aligning graph structure with textual context through cross-attention. Positive paths (whose intermediate nodes appear in future literature) are scored higher than negatives using margin ranking loss, assuming future reference terms indicate valid reasoning trajectories.

### Mechanism 2: Predicate Extraction and External Validation Feedback Loop
LLM explanations are refined by extracting structured triples and validating them against AGATHA's semantic network. Predicates below the 10th percentile plausibility threshold trigger rework, with PMIDs replaced via MedCPT similarity search, iteratively improving explanation quality.

### Mechanism 3: Temporal Graph Construction with Literature Co-occurrence
Time-indexed co-occurrence graphs enable retrospective evaluation by simulating real discovery constraints. Training uses pre-2022 data while testing evaluates on edges first appearing in 2022+, preventing information leakage and measuring alignment with future scientific literature.

## Foundational Learning

- **Knowledge Graphs and Co-occurrence Networks**: Understanding node-edge representations is essential for the retrieval system. Quick check: Given two concepts appearing together in 50 abstracts, what additional information determines if this represents a meaningful biological relationship?

- **Retrieval-Augmented Generation (RAG)**: HGCR uses structured path-based retrieval instead of flat document retrieval. Quick check: How does providing retrieved context to an LLM differ from fine-tuning the LLM on the same documents?

- **Semantic Predicate Extraction (SemRep-style)**: The feedback loop depends on parsing explanations into structured triples. Quick check: Given "Icariin demonstrates neuroprotective effects on dopaminergic neurons," what is the extracted (subject, predicate, object) triple?

## Architecture Onboarding

- **Component map**: Graph Builder -> Path Sampler -> HGCR Ranker -> Prompt Assembler -> LLM Generator -> Predicate Extractor -> AGATHA Validator -> Context Refiner (loop to Prompt Assembler)

- **Critical path**: Graph construction → Path sampling → HGCR ranking → Prompt assembly → LLM generation → Predicate extraction → Validation → (if flagged) Context refinement → loop back to Prompt assembly (max 5 iterations)

- **Design tradeoffs**: Path length limited to 4 for computational tractability; context size k=7 chosen via ablation; near-zero temperature for reproducibility sacrifices output diversity

- **Failure signatures**: High error rate after feedback loop indicates AGATHA coverage gaps; low MedCPT similarity suggests HGCR ranking issues; >5 iterations indicate contradictory evidence or persistent hallucinations

- **First 3 experiments**: 1) Reproduce HGCR ranking with target ~0.89 micro-AUC, 2) Compare baseline vs. feedback loop error rate reduction, 3) Test context size sensitivity with k∈{1,3,5,7,9,11}

## Open Questions the Paper Calls Out

1. Can more sophisticated context update strategies replace local similarity-based heuristics to prevent context drift and bias amplification from early generation errors?

2. Do longer reasoning paths (beyond 4 hops) provide meaningful improvements for complex biomedical hypotheses?

3. How robust is HGCR to temporal distribution shift when deployed on emerging biomedical literature outside training periods?

## Limitations

- Future reference term extraction may be incomplete or noisy, potentially misleading positive path labels
- LLM parametric knowledge contamination cannot be fully ruled out, particularly for larger models
- Co-occurrence edges may miss important relationships not explicitly mentioned together in abstracts

## Confidence

- **High Confidence**: HGCR ranking architecture, feedback loop mechanism design, temporal graph construction methodology
- **Medium Confidence**: Error rate reduction claims (dependent on AGATHA coverage assumptions), semantic similarity improvements
- **Low Confidence**: Knowledge leakage prevention claims, generalizability beyond Dyport benchmark domain

## Next Checks

1. Manually verify a sample of HGCR-retrieved paths against expert annotations to assess future reference term validity
2. Quantify AGATHA's coverage of common biomedical predicates and evaluate false rework flagging rates
3. Design ablation studies using LLMs trained exclusively on pre-2022 data to isolate retrieval contribution from parametric knowledge effects