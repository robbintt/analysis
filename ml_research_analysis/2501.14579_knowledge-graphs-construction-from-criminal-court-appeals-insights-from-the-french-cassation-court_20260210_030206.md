---
ver: rpa2
title: 'Knowledge Graphs Construction from Criminal Court Appeals: Insights from the
  French Cassation Court'
arxiv_id: '2501.14579'
source_url: https://arxiv.org/abs/2501.14579
tags:
- knowledge
- ontology
- data
- such
- legal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework for constructing knowledge graphs
  from criminal court appeals in the French Cassation Court, addressing the challenge
  of accurately representing unstructured legal data. The framework combines a domain-specific
  ontology with generative AI to automate knowledge extraction from court decisions,
  enabling scalable and reliable analysis of judicial practices.
---

# Knowledge Graphs Construction from Criminal Court Appeals: Insights from the French Cassation Court

## Quick Facts
- arXiv ID: 2501.14579
- Source URL: https://arxiv.org/abs/2501.14579
- Reference count: 22
- Primary result: RDF-based knowledge graph extraction from criminal appeals achieves 93% precision, 89% recall using LLM with domain ontology

## Executive Summary
This paper introduces a framework for constructing knowledge graphs from criminal court appeals in the French Cassation Court, addressing the challenge of accurately representing unstructured legal data. The framework combines a domain-specific ontology with generative AI to automate knowledge extraction from court decisions, enabling scalable and reliable analysis of judicial practices. The methodology employs iterative prompt engineering with large language models to generate RDF triples based on a tailored criminal law ontology, validated through expert review.

Experiments on 2,820 appeals demonstrate an average of 30 triples per document, with high precision (>90%) and recall (89%) on a ground truth dataset. The approach outperforms traditional methods by enabling large-scale, structured data representation, revealing negligible correlations between punishment severity and appeal outcomes. This work provides a robust foundation for legal data analysis, offering insights into judicial decision-making and potential applications in predictive analytics and retrieval-augmented generation.

## Method Summary
The framework constructs knowledge graphs by extracting RDF triples from criminal court appeals using a domain-specific ontology and large language models. PDF documents are parsed and processed through an LLM (GPT-4o mini) with prompts that embed the criminal law ontology and extraction guidelines. The LLM generates turtle-format triples which are validated using RDF libraries and stored in a triple store (Apache Fuseki). The ontology was developed semi-automatically through iterative collaboration with LLMs and domain experts, defining classes like Person, Crime, Punishment, and their relations. Property graph approaches were evaluated but rejected due to significantly lower accuracy (50-60% vs >90%).

## Key Results
- Achieved 93% precision and 89% recall on ground truth dataset of 20 criminal appeals
- Generated average of 30 RDF triples per appeal document across 2,820 processed appeals
- Revealed negligible correlation between punishment severity and appeal outcomes through structured data analysis
- Outperformed property graph approach by >30% accuracy, validating RDF's semantic consistency benefits

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Embedding a domain-specific ontology directly into the LLM prompt constrains output to valid RDF triples, substantially improving extraction accuracy over schema-free approaches.
- **Mechanism:** The ontology provides explicit class definitions (e.g., `Person`, `Crime`, `Punishment`) and relation types that guide entity recognition and relation extraction simultaneously, reducing hallucination and schema drift.
- **Core assumption:** The LLM has sufficient parametric knowledge of legal domain concepts to correctly classify entities when given ontology constraints.
- **Evidence anchors:** [abstract] "methodology employs iterative prompt engineering with large language models to generate RDF triples based on a tailored criminal law ontology"; [section: Knowledge Graph Construction] "in order to normalize the generation of triples we developed a RDF criminal ontology (incorporated into the prompt)"; [corpus] LINK-KG and CORE-KG papers similarly use ontology-driven LLM approaches for legal document KG construction, showing convergent methodology.
- **Break condition:** If the ontology exceeds the LLM's effective context window, the model may "forget" schema constraints, leading to malformed triples.

### Mechanism 2
- **Claim:** Semi-automated ontology development via iterative LLM collaboration produces more domain-aligned schemas than manual design alone.
- **Mechanism:** Human experts validate LLM-proposed classes and relations, catching projection errors (e.g., misidentifying court location as crime location) while the LLM suggests edge cases and property refinements.
- **Core assumption:** Domain experts can efficiently identify and correct ontology errors without requiring exhaustive upfront specification.
- **Evidence anchors:** [section: Ontology Design] "The ontology was developed in a semi-automated way, via interaction with the GPT-4o mini and Claude 3.5 Sonnet models. We iterated starting from the first version"; [section: Ontology Design] "all the while making sure the generated output is standardized, corresponds to our expectations and covers certain edge cases"; [corpus] Limited direct corpus evidence for this specific iterative methodology; related papers do not emphasize ontology co-creation.
- **Break condition:** If expert validation is cursory or domain expertise is shallow, systematic ontology errors may propagate across all extracted graphs.

### Mechanism 3
- **Claim:** RDF triple extraction with explicit ontology constraints outperforms property graph extraction for legal documents requiring semantic consistency and interoperability.
- **Mechanism:** RDF enforces schema-on-write validation through ontology compliance, while property graphs allow flexible but less constrained representations that introduce more extraction errors.
- **Core assumption:** The target application values semantic consistency and cross-system interoperability over query convenience.
- **Evidence anchors:** [section: Approaches] "We evaluated the property graph approach accuracy in the ballpark of 50-60% while the triple approach results a priori demonstrated > 90% accuracy"; [section: RDF Triple representation] "RDF triples also leverage ontologies to enforce semantic consistency, which is essential for interoperability in complex domains such as law"; [corpus] CORE-KG and related legal KG papers do not provide comparative accuracy benchmarks for property graphs vs. RDF; this comparison appears novel.
- **Break condition:** If downstream applications require frequent schema evolution or prioritize developer ergonomics over standardization, the RDF overhead may outweigh accuracy benefits.

## Foundational Learning

- **Concept: RDF Triples and Turtle Format**
  - Why needed here: The framework outputs knowledge graphs as RDF triples in Terse RDF Triple Language (turtle) format. Understanding subject-predicate-object structure is essential for debugging malformed extractions.
  - Quick check question: Given the triple `:Case001 :hasDefendant :PersonA . :PersonA :hasRole "Convict" .`, what queries could retrieve all convicts?

- **Concept: Ontology Classes and Relations**
  - Why needed here: The criminal ontology defines domain concepts (`Crime`, `Punishment`, `Appeal`) and their permissible relations. Modifying the ontology directly affects extraction scope.
  - Quick check question: If you add a `hasFineAmount` property to `Punishment`, what constraints should apply to the literal value?

- **Concept: Prompt Engineering for Structured Output**
  - Why needed here: Extraction quality depends on prompt design—embedding the ontology, specifying format constraints (ISO 8601, non-negative integers), and handling stochastic LLM outputs.
  - Quick check question: The paper notes LLMs sometimes fail to output valid durations in ISO 8601 format. What prompt strategies could reduce this error rate?

## Architecture Onboarding

- **Component map:** `pymupdf` (PDF parsing) → `langchain` + GPT-4o mini (LLM extraction) → `rdflib` (validation) → Apache Fuseki (triple store)

- **Critical path:** Ontology definition → Prompt construction → PDF preprocessing → LLM extraction → RDF validation → Triple store ingestion. Any failure in validation requires prompt refinement or ontology correction; re-processing is not automatic.

- **Design tradeoffs:**
  - **Property Graph (Neo4j) vs. RDF (Fuseki):** Property graphs offer intuitive querying and flexible schemas; RDF provides W3C-standard interoperability and semantic consistency. Paper chose RDF due to 50-60% vs. >90% accuracy difference.
  - **Ontology granularity vs. cost:** Larger ontologies improve guidance but increase token costs and may exceed context window effectiveness.
  - **Model selection:** GPT-4o mini chosen over llama-3.1 7B due to output quality; smaller models failed preliminary tests.

- **Failure signatures:**
  - Malformed Turtle syntax (LLM generates invalid RDF despite instructions)
  - Ontology projection errors (court location misclassified as crime location)
  - Literal format violations (non-ISO dates, negative ages)
  - Context overflow (large ontologies causing the model to "forget" constraints)

- **First 3 experiments:**
  1. **Reproduce baseline accuracy:** Run the provided prompt + ontology on the 20-document CCP2023 ground truth subset. Verify precision (~93%) and recall (~89%) match reported figures.
  2. **Ontology ablation:** Remove 50% of ontology classes/relations and measure precision/recall degradation to quantify ontology contribution.
  3. **Error taxonomy analysis:** On 100 random appeals, manually classify validation failures (format errors, projection errors, missing entities) to prioritize prompt or ontology improvements.

## Open Questions the Paper Calls Out

- **Question:** To what extent does pretraining the LLM on domain-specific labeled datasets improve knowledge graph generation quality compared to the out-of-the-box GPT-4o mini performance?
  - **Basis in paper:** [explicit] The authors list "pretraining the LLM using domain specific labeled datasets" as a specific future improvement for KG generation performance in the Conclusion.
  - **Why unresolved:** The current methodology relied on iterative prompt engineering with a general-purpose model rather than a specialized one.
  - **What evidence would resolve it:** A comparative evaluation of precision and recall scores between the baseline GPT-4o mini and a version fine-tuned on French legal texts.

- **Question:** Does providing the ontology via a vector store offer a better trade-off between context window usage and extraction guidance than including the full ontology in the prompt?
  - **Basis in paper:** [explicit] The authors explicitly suggest "providing the ontology in a vector store" as a method to improve KG generation performance.
  - **Why unresolved:** The current approach faces trade-offs where larger ontologies provide better guidance but increase costs and risk surpassing the model's short memory capacity.
  - **What evidence would resolve it:** Metrics comparing triple extraction accuracy and latency when using RAG-based ontology retrieval versus full-prompt inclusion.

- **Question:** Can the accuracy of the property graph approach be improved to match the RDF triple method, or is RDF inherently superior for maintaining legal semantic consistency?
  - **Basis in paper:** [inferred] The authors mention evaluating the property graph approach at only 50-60% accuracy before abandoning it for RDF, leaving its potential viability in the legal domain unexplored.
  - **Why unresolved:** The paper does not investigate whether the lower score was due to the method itself or the specific implementation (e.g., SchemaLLMPathExtractor).
  - **What evidence would resolve it:** Experiments optimizing the property graph schema and extraction logic to see if it can achieve parity with the >90% precision of the RDF method.

## Limitations
- The framework depends on proprietary LLM outputs whose behavior may shift with model updates, introducing long-term stability concerns.
- The criminal ontology remains partially unspecified in the paper, limiting complete reproducibility of the extraction system.
- Expert validation was performed but the exact validation protocol and inter-annotator agreement metrics are not disclosed.

## Confidence
- **High confidence:** RDF triple extraction methodology, overall architecture (PDF→LLM→RDF→Fuseki), and the empirical finding of negligible correlation between punishment severity and appeal outcomes.
- **Medium confidence:** Ontology-driven accuracy gains and the superiority of GPT-4o mini over smaller models, due to limited comparative data.
- **Low confidence:** Long-term stability of LLM-based extraction and generalizability to other legal domains or languages.

## Next Checks
1. Replicate the 20-document ground truth experiment to verify reported precision (93%) and recall (89%) scores.
2. Conduct an ontology ablation study by removing 50% of classes/properties and measuring accuracy degradation.
3. Perform a systematic error taxonomy analysis on 100 random appeals to classify and quantify validation failures (format errors, projection errors, missing entities).