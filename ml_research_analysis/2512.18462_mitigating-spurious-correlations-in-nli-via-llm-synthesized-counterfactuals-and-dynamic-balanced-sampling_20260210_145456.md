---
ver: rpa2
title: Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals
  and Dynamic Balanced Sampling
arxiv_id: '2512.18462'
source_url: https://arxiv.org/abs/2512.18462
tags:
- contrast
- original
- premise
- lf-lmi
- hypothesis
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of spurious correlations in Natural
  Language Inference (NLI) models, where models rely on superficial patterns in hypotheses
  rather than genuine semantic reasoning. The author introduces Log-Frequency LMI
  (LF-LMI) to detect these artifacts by modifying the standard LMI metric with a logarithmic
  frequency term, reducing the dominance of high-frequency but uninformative n-grams.
---

# Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals and Dynamic Balanced Sampling
## Quick Facts
- arXiv ID: 2512.18462
- Source URL: https://arxiv.org/abs/2512.18462
- Reference count: 11
- Primary result: Improved NLI consistency from 63.5% to 81.0% on synthetic contrast set while preserving in-domain accuracy

## Executive Summary
This paper addresses the problem of spurious correlations in Natural Language Inference (NLI) models, where models rely on superficial patterns in hypotheses rather than genuine semantic reasoning. The author introduces Log-Frequency LMI (LF-LMI) to detect these artifacts by modifying the standard LMI metric with a logarithmic frequency term, reducing the dominance of high-frequency but uninformative n-grams. Using LF-LMI, the paper generates a synthetic contrast set via an LLM-driven pipeline with multi-judge verification, perturbing premises while anchoring hypotheses to eliminate spurious correlations. To prevent catastrophic forgetting during fine-tuning, the author proposes Dynamic Balanced Sampling, which rotates the original data distribution in each epoch to maintain in-domain performance. Experiments on SNLI show that this approach improves consistency on the contrast set from 63.5% to 81.0% while preserving in-domain accuracy at 88.4%, outperforming naive fine-tuning which suffers a 5.3% drop in original accuracy.

## Method Summary
The paper presents a comprehensive approach to mitigating spurious correlations in NLI models. First, it introduces Log-Frequency LMI (LF-LMI), a modified version of the standard Log-Mutual Information metric that incorporates logarithmic frequency weighting to reduce the influence of high-frequency but uninformative n-grams. This metric is used to identify spurious correlations in the SNLI dataset. Second, the paper proposes a synthetic contrast set generation pipeline that uses large language models (LLMs) to create counterfactual examples by perturbing premises while keeping hypotheses constant, with multi-judge verification to ensure quality. Third, Dynamic Balanced Sampling is introduced as a fine-tuning strategy that rotates the data distribution across epochs to prevent catastrophic forgetting of in-domain patterns while learning to handle the new counterfactual examples. The approach is evaluated on SNLI, demonstrating improved consistency on the generated contrast set while maintaining original task performance.

## Key Results
- Consistency on synthetic contrast set improved from 63.5% to 81.0%
- In-domain accuracy preserved at 88.4% on SNLI
- Outperformed naive fine-tuning, which experienced a 5.3% drop in original accuracy
- LF-LMI successfully identified and reduced spurious correlation artifacts in the dataset

## Why This Works (Mechanism)
The approach works by addressing spurious correlations at multiple levels. LF-LMI reduces the influence of high-frequency n-grams that models can exploit without genuine reasoning, shifting focus to more informative features. The counterfactual generation pipeline creates challenging examples that force models to rely on actual semantic content rather than shortcuts, while the multi-judge verification ensures these examples are meaningful and not introducing new artifacts. Dynamic Balanced Sampling prevents catastrophic forgetting by maintaining exposure to the original data distribution throughout fine-tuning, allowing the model to learn both the new counterfactual patterns and preserve its ability to handle standard examples. This multi-pronged strategy ensures that improvements on the contrast set translate to genuine reasoning capabilities rather than overfitting to synthetic patterns.

## Foundational Learning
- **Log-Mutual Information (LMI)**: A metric for detecting feature importance in classification tasks. Why needed: To identify which n-grams are most predictive of labels. Quick check: Verify that high-LMI features align with semantically meaningful patterns rather than artifacts.
- **Spurious correlations in NLI**: Situations where models use superficial patterns instead of genuine reasoning. Why needed: These correlations lead to poor generalization and unreliable predictions. Quick check: Test model performance on perturbed examples where superficial patterns are broken.
- **Catastrophic forgetting**: The tendency of neural networks to lose previously learned information when trained on new tasks. Why needed: Fine-tuning on synthetic data risks losing original task performance. Quick check: Monitor accuracy on validation set from original distribution during fine-tuning.
- **Counterfactual examples**: Modified inputs designed to test specific model behaviors or assumptions. Why needed: These examples reveal whether models rely on spurious patterns. Quick check: Verify that counterfactuals maintain semantic coherence while breaking superficial correlations.
- **Multi-judge verification**: Using multiple LLM outputs to validate generated examples. Why needed: Ensures quality and consistency of synthetic data. Quick check: Measure agreement rate between different LLM judges on the same examples.
- **Dynamic sampling strategies**: Adaptive data sampling approaches that change during training. Why needed: To balance learning from new data while preserving old knowledge. Quick check: Track performance on both original and synthetic data throughout training.

## Architecture Onboarding
Component map: LF-LMI metric calculation -> Counterfactual generation pipeline -> Dynamic Balanced Sampling -> Fine-tuning loop -> Evaluation on contrast set and original data
Critical path: Data analysis with LF-LMI → Counterfactual generation → Fine-tuning with dynamic sampling → Evaluation
Design tradeoffs: The paper trades computational overhead for improved generalization by using LLMs for counterfactual generation and multi-judge verification. This ensures higher quality synthetic data but increases generation time. The dynamic sampling approach adds complexity to the training loop but prevents catastrophic forgetting.
Failure signatures: If LF-LMI fails to identify true spurious correlations, the counterfactual generation will miss important patterns. Poor multi-judge verification could introduce noise into the synthetic dataset. Inadequate dynamic sampling could lead to either overfitting to counterfactuals or insufficient learning from them.
First experiments: 1) Apply LF-LMI to SNLI to identify top spurious correlations, 2) Generate a small batch of counterfactuals and manually verify quality, 3) Test dynamic sampling with a simplified rotation strategy on a subset of data.

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- LF-LMI's reliance on n-gram frequency patterns may not capture more complex spurious correlations involving syntactic or semantic patterns beyond simple n-grams
- The logarithmic transformation assumes that reducing influence of high-frequency n-grams is sufficient, but may not address all types of artifacts
- Multi-judge verification depends on LLM quality and consistency, potentially introducing variability or systematic biases

## Confidence
- High confidence in the reported improvement of consistency from 63.5% to 81.0% on the contrast set (direct empirical measurement)
- Medium confidence in the preservation of in-domain accuracy at 88.4% (depends on Dynamic Balanced Sampling effectiveness)
- Medium confidence in the overall claim of outperforming naive fine-tuning (straightforward comparison but baseline drop should be verified)

## Next Checks
1. Test LF-LMI on multiple NLI datasets with different spurious correlation patterns to verify generalizability beyond SNLI
2. Evaluate the counterfactual generation pipeline with different LLM models and judge configurations to assess robustness to model variability
3. Conduct ablation studies removing Dynamic Balanced Sampling to quantify its specific contribution to preserving in-domain performance while improving contrast set consistency