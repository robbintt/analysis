---
ver: rpa2
title: Sampling and Loss Weights in Multi-Domain Training
arxiv_id: '2511.06913'
source_url: https://arxiv.org/abs/2511.06913
tags:
- weights
- sampling
- domain
- data
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work studies two distinct types of domain weighting in multi-domain
  training: loss weights and sampling weights. Loss weights adjust how much each domain
  contributes to the empirical risk, reducing the generalization gap, while sampling
  weights determine how often data from each domain is sampled during optimization,
  reducing gradient variance.'
---

# Sampling and Loss Weights in Multi-Domain Training

## Quick Facts
- arXiv ID: 2511.06913
- Source URL: https://arxiv.org/abs/2511.06913
- Reference count: 40
- Key outcome: This work studies two distinct types of domain weighting in multi-domain training: loss weights and sampling weights.

## Executive Summary
This paper analyzes domain weighting in multi-domain training through two distinct mechanisms: loss weights that adjust domain contributions to the empirical risk (reducing generalization gap) and sampling weights that determine data sampling frequency (reducing gradient variance). The authors demonstrate these mechanisms are complementary and can be optimized separately. Through theoretical analysis in linear and logistic regression, plus experiments with neural networks on MNIST, they show both weighting strategies provide measurable improvements individually, with further gains when combined. The work reveals that domain weighting is inherently two-dimensional, offering both a clearer theoretical framework and practical guidance for large-scale training.

## Method Summary
The method involves two separate weighting mechanisms: (1) Loss weights that scale each domain's contribution to the loss function, optimized via Generalized Least Squares (GLS) or ERMA for non-linear models, and (2) Sampling weights that determine how often data from each domain is sampled during training, optimized to minimize gradient variance. The implementation includes a warm-up period followed by periodic weight updates using held-out estimation batches to avoid bias in over-parameterized regimes. For linear regression, One-shot FGLS estimates optimal loss weights based on domain-specific noise variance. For sampling weights, Variance-Aware (VA) sampling allocates batch proportions proportional to πᵢwᵢvᵢ where vᵢ is gradient variance. Both mechanisms are implemented within standard SGD/Adam frameworks.

## Key Results
- Loss weights and sampling weights provide measurable improvements individually in linear, logistic, and neural network models
- Combining both weighting strategies yields further gains than using either alone
- The proposed One-shot FGLS estimator converges to optimal Aitken weights as estimation batch size increases
- Decoupling loss and sampling weights is essential - combining them into a single weight yields suboptimal results

## Why This Works (Mechanism)

### Mechanism 1: Loss Weighting via Generalized Least Squares (GLS)
Adjusting loss contribution based on domain label noise variance minimizes the variance of the model parameter estimator. By weighting domains inversely proportional to their noise variance (wᵢ ∝ 1/σᵢ²), the optimization prioritizes reliable gradients and approximates GLS, producing the Best Linear Unbiased Estimator (BLUE) in regression settings. This mechanism assumes domains share a true underlying model but differ in label noise.

### Mechanism 2: Sampling Weighting via Gradient Variance Reduction
Allocating samples proportional to domain-specific gradient variance minimizes the variance of the stochastic gradient estimator. By sampling more frequently from domains with high gradient variance relative to their weight, the signal-to-noise ratio of update steps improves. This mechanism assumes iterative optimization (SGD) is used and domains exhibit differing levels of data redundancy or gradient diversity.

### Mechanism 3: Decoupled Complementarity
Loss weights and sampling weights are distinct control levers - loss weights target the objective (what the model learns) while sampling weights target the path (how efficiently it learns). Optimizing one does not automatically optimize the other. This assumes domain heterogeneity is multi-factorial, where a domain can be clean/low-noise but high-variance/redundant.

## Foundational Learning

- **Concept: Generalized Least Squares (GLS) & Heteroskedasticity**
  - Why needed: Theoretical justification for loss weights comes directly from GLS (Aitken's Theorem)
  - Quick check: If one domain has 4x the label variance of another, how much should its loss weight decrease? (Answer: 1/4x)

- **Concept: Variance of Stochastic Gradients**
  - Why needed: Understanding why we sample high-variance domains more frequently requires knowing that gradient variance is a sum of per-domain variances scaled by batch size
  - Quick check: Why does reducing gradient variance allow for larger learning rates or faster convergence?

- **Concept: Generalization Gap vs. Optimization Error**
  - Why needed: Paper explicitly separates domain weighting into solving generalization gap (via loss weights) and optimization error (via sampling weights)
  - Quick check: Does changing sampling frequency change the optimal solution or just the speed/route of getting there?

## Architecture Onboarding

- **Component map:**
  Data Input -> Weight Estimators (Loss Weight Estimator -> Sampling Weight Estimator) -> Batch Constructor -> Trainer

- **Critical path:**
  1. Initialize weights uniformly
  2. Run warm-up steps to generate initial residuals and gradient statistics
  3. Periodically: Estimate noise/variance on held-out batch, update wᵢ and bᵢ
  4. Construct next batch using updated bᵢ and apply updated wᵢ in loss calculation

- **Design tradeoffs:**
  - Estimation overhead: Extra forward/backward passes needed for gradient variance
  - Sensitivity: Loss weights can be sensitive in over-parameterized models where training loss goes to 0
  - Hyperparameters: Update intervals, learning rates for weights, split ratios

- **Failure signatures:**
  - Weight Collapse: Loss weights for all but one domain go to zero
  - Divergence: Sampling weights oscillate wildly if gradient variance estimates are noisy
  - Overfitting the Estimator: Using training data for weight estimation in over-parameterized regimes

- **First 3 experiments:**
  1. Train on 2 synthetic domains (one high noise, one high gradient variance). Compare uniform vs. optimal loss only vs. optimal sampling only vs. combined.
  2. In linear regression, vary estimation batch size for One-shot FGLS. Confirm convergence to optimal Aitken weights.
  3. Attempt to combine optimal wᵢ and bᵢ into single scalar weight. Verify performance degradation vs. decoupled approach.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can ERMA be extended to handle dependent samples in autoregressive language models?
- Basis: "In the training of autoregressive language models, where samples are inherently dependent. Extending ERMA to handle such cases would therefore be an important avenue for future work."
- Why unresolved: ERMA assumes independent samples per domain, but autoregressive models create sequential dependencies
- What evidence would resolve it: Modified ERMA formulation with theoretical guarantees for dependent data, validated on language modeling benchmarks

### Open Question 2
- Question: Can Variance-Aware sampling be leveraged for deduplication by down-weighting repetitive domains?
- Basis: "We can leverage VA to sample less frequently from domains that are repetitive or duplicative in the training dynamics"
- Why unresolved: Connection between gradient variance and data duplication is hypothesized but not empirically validated
- What evidence would resolve it: Experiments showing VA automatically reduces sampling from known-duplicate domains without explicit deduplication

### Open Question 3
- Question: How can loss and sampling weights be jointly optimized in adaptive procedures for large-scale pretraining?
- Basis: "This perspective... points to promising future directions, such as adaptive procedures that jointly optimize both forms of weights"
- Why unresolved: Paper treats weights separately; joint dynamics are discussed but not optimized together
- What evidence would resolve it: Unified algorithm dynamically updating both weight types with convergence guarantees and empirical gains

### Open Question 4
- Question: Can periodic estimation of gradient variances for VA sampling be improved beyond the simple approach?
- Basis: "There remains room for improving these estimation methods, which we leave for future work"
- Why unresolved: Current approach estimates vi periodically with large batches, which is data-intensive and computationally costly
- What evidence would resolve it: Streaming or incremental variance estimator maintaining accuracy with lower overhead

## Limitations
- Theoretical analysis relies on strong assumptions (homoskedastic linear models, quadratic loss) that may not hold in practice
- Empirical validation focuses primarily on synthetic data and controlled scenarios with limited real-world domain heterogeneity testing
- Effectiveness highly dependent on accurate variance estimation, which becomes problematic in over-parameterized regimes

## Confidence

- **High Confidence**: The core insight that loss weights and sampling weights serve distinct purposes (generalization gap vs. optimization path) is well-supported by both theory and empirical evidence
- **Medium Confidence**: The practical effectiveness of proposed estimators (One-shot FGLS, VA sampling, ERMA) across diverse real-world scenarios, as algorithms are theoretically sound but sensitive to hyperparameters
- **Low Confidence**: The scalability claims for large-scale training and generalizability to highly imbalanced or continuously evolving domain distributions, as experiments are limited to small-scale synthetic data

## Next Checks
1. Apply decoupled weighting framework to multi-domain NLP dataset (e.g., Amazon reviews) where domains exhibit varying noise levels, gradient variances, and class imbalances. Compare against single-weight baselines and measure both convergence speed and final accuracy.

2. Test One-shot FGLS estimator in deep neural networks where training loss approaches zero. Validate whether held-out estimation batch approach prevents weight collapse, and quantify impact of different estimation batch sizes on weight stability.

3. Implement online variant where domain distributions shift over time (concept drift in streaming data). Evaluate whether periodic weight updates maintain effectiveness under distribution shift, and compare against adaptive baselines that continuously update weights.