---
ver: rpa2
title: 'SUMMPILOT: Bridging Efficiency and Customization for Interactive Summarization
  System'
arxiv_id: '2601.08475'
source_url: https://arxiv.org/abs/2601.08475
tags:
- system
- summary
- user
- summarization
- interactive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper presents SUMMPILOT, an interactive summarization system
  that combines automatic summarization efficiency with customizable user control
  through a large language model. The system provides two modes: BASICMODE for automatic
  summarization and ADVANCEDMODE for interactive customization with semantic graphs,
  entity clustering, and explainable evaluation.'
---

# SUMMPILOT: Bridging Efficiency and Customization for Interactive Summarization System

## Quick Facts
- arXiv ID: 2601.08475
- Source URL: https://arxiv.org/abs/2601.08475
- Reference count: 22
- Combines automatic summarization efficiency with customizable user control through LLM-based semantic graphs and entity clustering

## Executive Summary
SUMMPILOT is an interactive summarization system that bridges the gap between automatic summarization efficiency and user customization needs. The system provides two modes: BASICMODE for quick automatic summaries and ADVANCEDMODE for interactive customization with semantic graph visualization, entity clustering, and explainable evaluation. A user study with six participants demonstrated excellent usability (average SUS score 86.3, classified as "excellent") and high satisfaction with interactive features. The system achieved 90% accuracy in problem-solving tasks, with ADVANCEDMODE users spending more time (5:02 minutes) but showing significantly enhanced document comprehension compared to BASICMODE (3:33 minutes).

## Method Summary
SUMMPILOT uses a Flask backend with Bootstrap frontend, orchestrated through GPT-4o LLM API calls. The system processes input documents through relation extraction (generating subject-relation-object triples), entity clustering via coreference resolution, and graph visualization. For interactive summarization, users select/deselect triples in the semantic graph to control summary focus. The evaluation module decomposes summaries into atomic facts and verifies them against source documents, flagging unverified facts as "possible errors." The system supports both automatic (BASICMODE) and interactive (ADVANCEDMODE) summarization, with CPU-only deployment possible.

## Key Results
- Average SUS score of 86.3 (classified as "excellent" usability)
- Semantic graph rated highly for document understanding (4.4/5)
- Relation extraction found intuitive (5.0/5)
- 90% accuracy in problem-solving tasks
- ADVANCEDMODE users spent 5:02 minutes vs. 3:33 minutes in BASICMODE

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Semantic graph visualization of relational triples improves document comprehension by making content structure explicit.
- Mechanism: LLM extracts (subject, relation, object) triples from source documents → triples rendered as directed graph with node sizing based on entity frequency → users interactively select/deselect triples to control summary focus. This externalizes the latent relationship structure that users would otherwise need to infer from linear text.
- Core assumption: Users can more efficiently identify relevant information through graph-based exploration than through sequential reading; the extraction quality is sufficient that key relationships are captured.
- Evidence anchors:
  - [abstract]: "Users can engage with the system to understand document content and personalize summaries through interactive components such as semantic graphs"
  - [section]: "SUMMPILOT's graph visualization maps these triples with directed edges to indicate relationships and adjusts node sizes to emphasize key entities. This helps users better understand the content structure"
  - [corpus]: Weak direct corpus support for graph-based summarization specifically; neighbor papers focus on hierarchical/interactive reading (TreeReader) and alert summarization (CLARITY) but not semantic graphs.
- Break condition: If relation extraction produces noisy or incomplete triples (missing key relationships, spurious connections), the graph will mislead rather than guide users. Performance degrades with documents containing implicit relationships not captured in explicit subject-relation-object form.

### Mechanism 2
- Claim: Entity clustering with coreference resolution reduces cognitive load by unifying variant expressions of the same entity.
- Mechanism: LLM performs coreference resolution on extracted entities → variants grouped (e.g., "Tom's wife" + "Jane" → "[Tom's wife, Jane]") → representative entity selected by frequency → unified nodes displayed in interface. This prevents users from independently tracking synonymous references.
- Core assumption: The LLM correctly identifies coreferent expressions; frequency-based representative selection aligns with user expectations for display labels.
- Evidence anchors:
  - [abstract]: "entity clustering" listed as key interactive component
  - [section]: "For example, the triples <Tom-is married to-Jane> and <Tom's wife-aged-30> are combined into <[Tom's wife, Jane]-aged-30>. This clustering clarifies variations in expressions referring to the same concept"
  - [corpus]: No direct corpus validation of entity clustering in summarization systems found in neighbors.
- Break condition: If coreference resolution incorrectly merges distinct entities or fails to merge true coreferences, users will encounter either redundant nodes or missing connections. Domain-specific entities (e.g., organizations with similar names) are particularly vulnerable.

### Mechanism 3
- Claim: Explainable evaluation with atomic fact verification creates a feedback loop that improves summary trustworthiness and user correction efficiency.
- Mechanism: Generated summary decomposed into atomic facts via LLM → each fact verified against source documents → unverified facts flagged as "possible errors" in UI → users identify and correct issues. This makes hallucination detection transparent rather than opaque.
- Core assumption: Atomic fact decomposition is granular enough to isolate errors; verification against source is reliable; users act appropriately on flagged errors (neither over-trusting nor ignoring).
- Evidence anchors:
  - [abstract]: "explainable evaluation" as interactive component
  - [section]: "Unverified facts are flagged as 'possible errors' in the interface... This allows users quickly identify possible errors and understand how their input influences the summary"
  - [corpus]: sui-1 paper addresses verifiable summarization with inline citations for compliance-sensitive domains, supporting the broader need for grounded verification.
- Break condition: If the verification LLM has systematic blind spots (e.g., correctly verifying plausible but fabricated facts), users gain false confidence. Conversely, over-flagging correct facts as errors trains users to ignore warnings.

## Foundational Learning

- Concept: **Abstractive vs. Extractive Summarization**
  - Why needed here: SUMMPILOT generates abstractive summaries via LLM rather than selecting passages, which introduces hallucination risk and requires the evaluation module.
  - Quick check question: Can you explain why abstractive summaries require explicit factual consistency checking while extractive summaries do not?

- Concept: **Coreference Resolution**
  - Why needed here: The entity clustering module depends on correctly identifying when different noun phrases refer to the same real-world entity.
  - Quick check question: Given "Apple announced earnings. The company beat expectations.", what should a coreference system output?

- Concept: **Atomic Fact Decomposition**
  - Why needed here: The evaluation module breaks summaries into atomic facts for verification; understanding this granularity is essential for interpreting "possible error" flags.
  - Quick check question: How would you decompose "The CEO, who joined in 2019, announced record quarterly revenue of $2B" into atomic facts?

## Architecture Onboarding

- Component map:
  - Frontend: Bootstrap-based UI with semantic graph visualization, relation triple checkboxes, entity cluster panel, open-form command input, evaluate button
  - Backend: Python Flask server orchestrating LLM calls
  - LLM Core: GPT-4o accessed via API for: (1) automatic summarization, (2) relation extraction + coreference resolution, (3) interactive summarization with user constraints, (4) atomic fact decomposition, (5) factual verification
  - Data Flow: Input documents → Relation Extraction → Entity Clustering → Graph Rendering → User Selection → Interactive Summarization → Evaluation → Flagged Output

- Critical path:
  1. Document ingestion and relation extraction (latency depends on document length and LLM API)
  2. Graph rendering and user interaction (blocking: user must explore before generating custom summary)
  3. Interactive summarization with constraints (another LLM call)
  4. Evaluation pass (decomposition + verification: multiple LLM calls per summary sentence)

- Design tradeoffs:
  - BASICMODE vs. ADVANCEDMODE: Paper shows 3:33 min vs. 5:02 min for equivalent accuracy—ADVANCEDMODE trades time for control and comprehension
  - CPU-only deployment: System requires no GPU, but API costs and latency scale with document count and interaction rounds
  - Frequency-based representative entity selection: Simple and fast, but may select less informative variants (e.g., pronouns over full names)

- Failure signatures:
  - Empty or sparse semantic graph: Relation extraction prompt failed or document lacks explicit relational content
  - High "possible error" count on ground-truth facts: Verification module over-sensitive or source document not properly passed to verification prompt
  - User selections ignored in final summary: Interactive summarization prompt not correctly incorporating constraint text
  - Entity clusters merging unrelated entities: Coreference resolution prompt producing false positives

- First 3 experiments:
  1. Validate relation extraction quality: Run the relation extraction prompt on 10-20 multi-document sets with known entities/relationships; manually precision-recall the extracted triples against gold annotations.
  2. Test evaluation module calibration: Generate summaries with intentionally injected hallucinations; measure recall of "possible error" flags. Also test on fully accurate summaries to measure false positive rate.
  3. Compare mode efficiency: Replicate the paper's problem-solving task with new participants and document types (e.g., technical reports vs. news) to test whether ADVANCEDMODE's comprehension advantage generalizes beyond news articles.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does multilingual support affect the accuracy of semantic graph construction and entity clustering across typologically diverse languages?
- Basis in paper: [explicit] The authors state: "Future work will focus on multilingual support and the integration of multimodal LLMs to handle various data types."
- Why unresolved: Relation extraction and entity clustering depend on language-specific syntactic patterns; performance may degrade for morphologically rich or non-subject-verb-object languages.
- What evidence would resolve it: Cross-lingual evaluation measuring triple extraction F1-scores and clustering purity across at least three typologically distinct languages (e.g., English, Korean, Arabic).

### Open Question 2
- Question: How robust is SUMMPILOT's performance when evaluated with professional users (e.g., journalists) and documents outside the news domain?
- Basis in paper: [inferred] The user study recruited only six volunteer students from the authors' department; the system targets "reporters and students" but evaluated only students on Multi-News articles.
- Why unresolved: Domain expertise and document genre may influence usability, information needs, and satisfaction; student populations may not generalize to professional workflows.
- What evidence would resolve it: Comparative user study with professional journalists summarizing business documents, scientific papers, or legal texts, reporting SUS scores and task accuracy.

### Open Question 3
- Question: How can the efficiency-customization tradeoff be optimized so that ADVANCEDMODE reduces the 42% time increase (3:33 to 5:02 minutes) while maintaining comprehension benefits?
- Basis in paper: [inferred] The paper reports ADVANCEDMODE users spent 5:02 minutes versus 3:33 minutes in BASICMODE; this substantial overhead may limit adoption in time-constrained settings.
- Why unresolved: The paper does not investigate which interactive components contribute most to time cost or whether selective feature use can reduce overhead.
- What evidence would resolve it: Ablation study timing each component (semantic graph, entity clustering, evaluation) and measuring time-accuracy tradeoffs with component combinations.

## Limitations
- Six participants in user study limits statistical power and generalizability
- Performance tested only on news articles, not domain-specific documents
- Evaluation module effectiveness unverified against known hallucination benchmarks
- 42% time increase in ADVANCEDMODE may limit adoption in time-constrained settings

## Confidence

- Semantic graph comprehension benefit: Medium - supported by qualitative user feedback (4.4/5) but lacks objective comprehension metrics
- Entity clustering accuracy: Low - no quantitative validation of coreference resolution quality provided
- Explainable evaluation effectiveness: Low - accuracy depends entirely on verification LLM performance, which is untested
- Mode time tradeoff: Medium - measured in study but limited by sample size and document types

## Next Checks

1. Test the semantic graph's comprehension benefit objectively by measuring recall of key facts after graph exploration versus linear reading on the same document set
2. Validate the evaluation module's precision/recall on a benchmark of known hallucinated vs. factual summaries to measure false positive/negative rates
3. Replicate the mode comparison study with 20+ participants across multiple document domains (news, technical reports, legal documents) to assess generalizability of the 5:02 vs. 3:33 minute tradeoff