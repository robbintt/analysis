---
ver: rpa2
title: Cognitive networks highlight differences and similarities in the STEM mindsets
  of human and LLM-simulated trainees, experts and academics
arxiv_id: '2502.19529'
source_url: https://arxiv.org/abs/2502.19529
tags:
- human
- networks
- associations
- gpt-3
- stem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compared cognitive networks of human participants and
  GPT-3.5 in STEM-related associations. Using behavioural forma mentis networks (BFMNs),
  177 humans (trainees, experts, academics) and 177 GPT-3.5 simulations were asked
  to generate word associations and valence ratings for 10 STEM-related cue words.
---

# Cognitive networks highlight differences and similarities in the STEM mindsets of human and LLM-simulated trainees, experts and academics

## Quick Facts
- **arXiv ID:** 2502.19529
- **Source URL:** https://arxiv.org/abs/2502.19529
- **Reference count:** 7
- **Key outcome:** Human cognitive networks showed significantly higher clustering than GPT-3.5 simulations, indicating stronger triadic closures and more integrated knowledge structures in semantic memory.

## Executive Summary
This study compared cognitive networks between 177 human participants and 177 GPT-3.5 simulations across STEM-related associations using Behavioral Forma Mentis Networks (BFMNs). Humans demonstrated significantly higher clustering coefficients, indicating stronger triadic closures and more integrated knowledge structures than the sparser, less interconnected networks produced by GPT-3.5. While both humans and GPT-3.5 framed mathematics positively, GPT-3.5 showed negative biases toward non-STEM concepts like "art" when prompted as science experts, highlighting context-dependent limitations. These results demonstrate that while GPT-3.5 can partially replicate human associative patterns, it falls short in forming complex, human-like cognitive networks.

## Method Summary
The study used 10 STEM cue words to elicit continued free associations (3 responses per cue) and valence ratings (1-5 Likert scale) from both human participants and GPT-3.5 simulations. Human data came from 177 participants (59 trainees, 57 experts, 61 academics), while GPT-3.5 simulations were prompted to impersonate these roles. Text preprocessing included lemmatization, spelling correction, and filtering idiosyncratic responses mentioned by fewer than 2 participants. Directed networks were constructed linking cues to responses, with node attributes including valence labels determined through Kruskal-Wallis tests. Network metrics (ASPL, Diameter, Modularity, CC) were calculated and validated against 500 configuration models.

## Key Results
- Human networks showed significantly higher clustering coefficients than GPT-3.5, indicating stronger triadic closures and more integrated knowledge structures
- GPT-3.5 produced sparser, less interconnected networks with weaker conceptual integration compared to humans
- Both humans and GPT-3.5 framed mathematics positively, contrasting with previous findings of math anxiety in students

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Higher clustering coefficients in human networks indicate robust conceptual integration via triadic closure, absent or weaker in LLM simulations.
- **Mechanism:** Humans build semantic memory by linking new concepts to existing neighbors. If concept A links to B and C, humans tend to form a link between B and C (triadic closure) to reduce uncertainty, creating dense clusters that facilitate retrieval.
- **Core assumption:** Network topology (specifically local interconnectivity) serves as a valid proxy for the robustness of knowledge structures and "gap-filling" in semantic memory.
- **Evidence anchors:**
  - [abstract] "Human networks showed significantly higher clustering coefficients... indicating stronger triadic closures and more integrated knowledge structures."
  - [section] "In highly clustered semantic networks, the presence of denser connections... can enable the rapid retrieval of closely related concepts."
  - [corpus] Related work (Paper 71462) supports that associative knowledge structures differ significantly between students and LLMs, specifically regarding how anxiety is entwined with structure.
- **Break condition:** If high clustering resulted from repetitive loops rather than distinct conceptual triads, or if GPT-3.5's lower clustering still yielded superior retrieval efficiency in downstream tasks.

### Mechanism 2
- **Claim:** LLM associative outputs are highly sensitive to "task framing" or persona prompting, leading to context-dependent semantic biases not present in human controls.
- **Mechanism:** When prompted to impersonate a "science expert," the model likely activates a subspace of its weights associated with scientific rigor, which may implicitly down-regulate or negatively weight concepts perceived as "non-scientific" (e.g., art), creating artificial emotional polarities.
- **Core assumption:** The model's simulation of a persona involves stereotypical feature amplification that overrides a neutral "worldview."
- **Evidence anchors:**
  - [abstract] "GPT-3.5 showed negative biases toward non-STEM concepts like 'art'... when prompted as science experts, highlighting context-dependent limitations."
  - [section] "This possible context-dependence highlights the potential biases of AI models... The negative framing of art in our study could reflect an over-specialization."
  - [corpus] Paper 83338 (Word Synchronization Challenge) notes LLMs often fail to mimic human cognitive processes in associations without specific benchmarks.
- **Break condition:** If the negative bias toward "art" persisted even when GPT was prompted to be a "liberal arts expert" (suggesting a training data bias rather than prompt framing).

### Mechanism 3
- **Claim:** Valence ratings combined with network structure reveal affective dimensions—like the absence of math anxiety—that standard text analysis might miss.
- **Mechanism:** By explicitly asking for valence ratings alongside associations, the method forces an evaluation of the "feeling" of a concept, mapping emotion onto the semantic network.
- **Core assumption:** Self-reported valence in a controlled setting accurately reflects the participants' internal emotional framing of a concept.
- **Evidence anchors:**
  - [abstract] "Both humans and GPT-3.5 framed mathematics in neutral or positive terms, contrasting with previous findings of math anxiety in students."
  - [section] "In BFMNs, concepts rated as negative and linked with other negative concepts... might indicate anxious perceptions."
  - [corpus] Paper 71462 explicitly contrasts this, finding math anxiety entwined in psychology students' structures but not LLMs, suggesting the mechanism is sensitive to population expertise.
- **Break condition:** If participants provided socially desirable valence ratings that contradicted their actual physiological responses or reaction times.

## Foundational Learning

- **Concept: Behavioral Forma Mentis Networks (BFMNs)**
  - **Why needed here:** This is the core representation used to compare human and AI cognition. It differs from standard semantic networks by explicitly encoding emotional valence.
  - **Quick check question:** How does a BFMN differ from a standard semantic network generated purely from text co-occurrence?

- **Concept: Triadic Closure**
  - **Why needed here:** This network property explains the structural "robustness" found in humans but not GPT-3.5.
  - **Quick check question:** If Node A connects to B and C, what must happen for a "triadic closure" to occur, and what does this imply about the learner's memory?

- **Concept: Configuration Models (Null Models)**
  - **Why needed here:** The study uses random graphs with the same degree sequence to prove that human clustering is "significant" and not just a product of random chance.
  - **Quick check question:** Why compare the empirical network to 500 random graphs rather than just comparing the raw clustering numbers directly?

## Architecture Onboarding

- **Component map:**
  - **Input Layer:** 10 STEM Cue Words (e.g., "mathematics", "art")
  - **Processing Agent:** Human subjects (N=177) vs. GPT-3.5 simulations (N=177, prompted as trainees/experts/academics)
  - **Extraction Module:** Continued Free Association (3 responses per cue) + Likert Valence (1-5)
  - **Preprocessing:** Lemmatization (spaCy), spelling correction, filtering (remove idiosyncratic responses mentioned by <2 participants)
  - **Network Construction:** Directed edges (Cue -> Response); Node attributes (Valence: Positive/Negative/Neutral)
  - **Analysis Engine:** Calculation of Clustering Coefficient (CC), Average Shortest Path Length (ASPL), Modularity

- **Critical path:**
  1. **Prompt Engineering:** Defining the persona (Trainee vs. Expert) is the most sensitive step for GPT-3.5 data generation
  2. **Filtering:** Removing responses with >25% blanks and idiosyncratic associations is critical to ensure network density metrics are valid
  3. **Statistical Validation:** The Kruskal-Wallis test determines valence labels; this must be run before network visualization

- **Design tradeoffs:**
  - **Prompt Specificity vs. Bias:** Highly specific prompts (e.g., "Impersonate a science expert") generate role-consistent data but introduce "context-dependent bias" (e.g., negative view of Art), as seen in the results
  - **Association Limit (3 words):** Limiting to 3 associations standardizes the network degree but may cap the observable complexity of expert knowledge structures

- **Failure signatures:**
  - **Disconnected Graphs:** GPT-3.5 produced "chemistry" and "art" as isolated nodes, failing to integrate them into the main component
  - **Random-Level Clustering:** If the clustering coefficient falls within the distribution of the configuration model (p > 0.05, as seen in GPT-Experts), the network structure is statistically indistinguishable from random noise

- **First 3 experiments:**
  1. **Persona Stability Test:** Run the same GPT prompt with varying temperature settings to see if the "negative art bias" is robust or an artifact of low-temperature sampling
  2. **Semantic Frame Comparison:** Isolate the "mathematics" semantic frame and compare edge overlap between Human Experts and GPT Experts to quantify semantic alignment vs. structural alignment
  3. **Graph Disturbance:** Remove the top 10% most connected nodes (hubs) from both Human and GPT networks and measure the drop in connectivity to test network resilience

## Open Questions the Paper Calls Out

- **Question:** Does prompting LLMs with specific demographic profiles (e.g., gender, culture) align their associative networks more closely with human subgroups?
  - **Basis in paper:** [explicit] The authors note that GPT-3.5 simulations were not informed by demographics like age or culture, which limits the alignment of its patterns with human participants.
  - **Why unresolved:** It is currently unknown if the gap between human and AI networks is due to the model's architecture or the lack of demographic specificity in the prompt.
  - **What evidence would resolve it:** Running the BFMN task with prompts specifying distinct demographic backgrounds and comparing the resulting network structures to humans with those backgrounds.

- **Question:** Can advanced LLMs (e.g., GPT-4) achieve human-level clustering coefficients and triadic closure in STEM knowledge representation?
  - **Basis in paper:** [explicit] The authors highlight the need for future research on enhancing LLM capacity to form "richer and more interconnected networks" to match human cognitive integration.
  - **Why unresolved:** This study focused on GPT-3.5, which produced sparser networks; newer models may have different semantic integration capabilities.
  - **What evidence would resolve it:** Replicating this study's methodology with more recent LLMs and statistically comparing their clustering coefficients to human baselines.

- **Question:** Does the negative bias toward non-STEM concepts (like "art") in LLMs persist regardless of the specific scientific persona adopted?
  - **Basis in paper:** [explicit] The paper observes that GPT-3.5 showed a "striking difference" by rating "art" negatively when prompted as a science expert, a bias attributed to task framing.
  - **Why unresolved:** It is unclear if this is a rigid, context-dependent limitation of the model or a flexible behavior that varies by specific scientific discipline.
  - **What evidence would resolve it:** Testing a wider variety of expert personas (e.g., "artistic scientist" vs. "analytical scientist") to see if the negative valence toward non-STEM concepts fluctuates.

## Limitations

- **Unknown GPT-3.5 hyperparameters:** The exact model version, temperature, and top_p settings are not specified, potentially affecting the observed "negative art bias"
- **Dataset availability:** The raw human dataset is not explicitly linked as open access, making independent verification difficult
- **Valence labeling implementation:** The detailed implementation of Kruskal-Wallis tests for valence labeling lacks specification, raising questions about consistency

## Confidence

- **High Confidence:** The finding that human networks exhibit significantly higher clustering coefficients than GPT-3.5 simulations is well-supported by data and statistical validation against configuration models
- **Medium Confidence:** The interpretation that higher human clustering indicates "stronger triadic closures and more integrated knowledge structures" assumes network topology directly reflects cognitive robustness
- **Low Confidence:** The claim that GPT-3.5's negative bias toward "art" when prompted as a science expert represents "context-dependent limitations" is highly sensitive to prompt engineering specifics not fully detailed

## Next Checks

1. **Persona Stability Test:** Re-run GPT-3.5 simulations with varying temperature settings (0.1, 0.5, 1.0) using identical prompts to determine if the "negative art bias" persists across sampling strategies or represents a sampling artifact

2. **Semantic Frame Alignment:** Isolate and compare the "mathematics" semantic frame across Human Experts and GPT Experts by calculating edge overlap percentages to quantify actual semantic alignment beyond structural metrics

3. **Graph Resilience Analysis:** Remove the top 10% most connected nodes (hubs) from both human and GPT networks, then measure changes in average shortest path length and clustering coefficient to test network resilience differences