---
ver: rpa2
title: 'RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation'
arxiv_id: '2506.15455'
source_url: https://arxiv.org/abs/2506.15455
tags:
- reasoning
- alarm
- question
- original
- code
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces RE-IMAGINE, a framework for systematically
  evaluating reasoning abilities in Large Language Models (LLMs) across a three-level
  hierarchy: observe, mutate, and imagine. By converting benchmark problems into symbolic
  code representations, the method generates variations that cannot be solved through
  memorization alone.'
---

# RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation

## Quick Facts
- arXiv ID: 2506.15455
- Source URL: https://arxiv.org/abs/2506.15455
- Reference count: 40
- Primary result: Framework reveals LLMs rely heavily on memorization over reasoning when benchmark problems are systematically mutated

## Executive Summary
RE-IMAGINE introduces a systematic framework for evaluating reasoning abilities in Large Language Models by converting benchmark problems into symbolic code representations and generating variations across three complexity levels: observe, mutate, and imagine. The method exposes limitations in current LLMs by creating problems that cannot be solved through memorization alone, revealing that performance degrades significantly as reasoning complexity increases. Experiments on math (GSM8K, CLadder) and code (CRUXEval, Loop) benchmarks demonstrate substantial performance drops, particularly for Level-3 counterfactual mutations, indicating LLMs rely more on statistical recall than genuine reasoning.

## Method Summary
RE-IMAGINE converts benchmark problems into symbolic code representations, enabling systematic generation of problem variations through three mutation levels. Level-1 (observe) introduces minor syntactic changes, Level-2 (mutate) alters problem structure while preserving solution approach, and Level-3 (imagine) creates counterfactual scenarios requiring fundamentally different reasoning. The symbolic representation allows for domain-general application and ensures variations are semantically equivalent but structurally distinct from original problems. This approach prevents memorization-based solutions while maintaining consistent evaluation criteria across difficulty levels.

## Key Results
- LLM performance drops significantly as reasoning complexity increases from Level-1 to Level-3 mutations
- Level-3 counterfactual mutations show the steepest performance decline across all benchmark types
- Results indicate current LLMs rely heavily on statistical recall rather than true reasoning capabilities

## Why This Works (Mechanism)
RE-IMAGINE works by transforming natural language or code-based reasoning problems into symbolic representations that can be systematically varied while preserving semantic meaning. The three-level hierarchy ensures that each mutation level requires progressively more sophisticated reasoning, from simple pattern recognition to counterfactual thinking. By generating variations that are structurally distinct but semantically similar, the framework prevents LLMs from relying on memorized solutions while still testing the same underlying reasoning skills. The symbolic approach enables domain-general application and provides precise control over reasoning complexity.

## Foundational Learning
- Symbolic problem representation: Converting natural language problems into code-like structures that capture logical relationships while enabling systematic variation
- Reasoning complexity hierarchy: Three-level framework (observe, mutate, imagine) that quantifies different reasoning demands
- Counterfactual mutation generation: Creating problem variants that require different solution approaches while maintaining semantic equivalence
- Benchmark variation methodology: Systematic approach to generating problem variations that prevent memorization
- Why needed: To create evaluation benchmarks that test genuine reasoning rather than memorization
- Quick check: Apply symbolic representation to simple problems and verify that variations maintain semantic meaning while changing structure

## Architecture Onboarding
- Component map: Problem Parser -> Symbolic Encoder -> Mutation Engine -> Problem Generator -> Evaluation Suite
- Critical path: Input Problem → Symbolic Representation → Mutation Application → Generated Variation → LLM Evaluation
- Design tradeoffs: Symbolic precision vs. natural language ambiguity; controlled variation vs. real-world complexity; domain-general vs. domain-specific optimizations
- Failure signatures: Memorization-based solutions on mutated problems; inconsistent performance across similar problem types; inability to handle counterfactual scenarios
- First experiments: 1) Test symbolic representation on simple arithmetic problems, 2) Generate Level-1 variations and compare LLM performance, 3) Create Level-3 counterfactuals and measure reasoning capability

## Open Questions the Paper Calls Out
None

## Limitations
- Symbolic representation may not capture all forms of reasoning complexity, particularly for problems with natural language ambiguity
- Three-level hierarchy boundaries may not be universally applicable across all problem domains
- Cannot completely eliminate statistical pattern matching in LLMs trained on vast code datasets

## Confidence
- High: LLM performance degradation with increasing reasoning complexity is consistently observed
- Medium: Claims about memorization versus reasoning are supported but may be influenced by symbolic representation limitations
- Low: None identified in the source material

## Next Checks
1. Apply RE-IMAGINE to additional reasoning domains beyond math and code (e.g., logical reasoning, commonsense reasoning, scientific problem-solving)
2. Compare RE-IMAGINE-generated variations against human-created analogous problems to assess reasoning complexity capture
3. Test whether fine-tuning on RE-IMAGINE variations improves true reasoning performance versus memorization-dependent accuracy on original benchmarks