---
ver: rpa2
title: Bandit and Delayed Feedback in Online Structured Prediction
arxiv_id: '2502.18709'
source_url: https://arxiv.org/abs/2502.18709
tags:
- loss
- theorem
- bound
- feedback
- surrogate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper develops algorithms for online structured prediction\
  \ under bandit and delayed feedback, extending prior work on full-information settings.\
  \ The authors propose gradient estimators tailored to weaker feedback: an inverse-weighted\
  \ estimator for bandit feedback yielding O(\u221AKT) surrogate regret, and a pseudo-inverse\
  \ matrix estimator for O(T^{2/3}) regret independent of K."
---

# Bandit and Delayed Feedback in Online Structured Prediction

## Quick Facts
- arXiv ID: 2502.18709
- Source URL: https://arxiv.org/abs/2502.18709
- Reference count: 40
- This paper develops algorithms for online structured prediction under bandit and delayed feedback, extending prior work on full-information settings.

## Executive Summary
This paper addresses the challenge of online structured prediction under bandit and delayed feedback settings, which are more realistic than full-information settings but harder to optimize. The authors develop gradient estimators specifically designed for these weaker feedback scenarios and analyze their theoretical regret bounds. They show that their proposed methods achieve favorable regret guarantees that depend on the number of classes K and delay D, with particular attention to scenarios where these quantities can be large.

## Method Summary
The authors propose gradient estimators tailored to bandit and delayed feedback scenarios in online structured prediction. For bandit feedback, they introduce an inverse-weighted estimator that achieves O(√KT) surrogate regret and a pseudo-inverse matrix estimator that achieves O(T^{2/3}) regret independent of K. For delayed feedback settings, they develop algorithms that handle arbitrary delays and achieve bounds of O(min{D^2+1,(D+1)^{2/3}T^{1/3}}) and O(D+1) under full information, and O(√((K+D)T)) under bandit feedback. The methods build upon online convex optimization frameworks and leverage the linear model class structure.

## Key Results
- The inverse-weighted estimator for bandit feedback achieves O(√KT) surrogate regret
- The pseudo-inverse matrix estimator achieves O(T^{2/3}) regret independent of K
- Delayed feedback algorithms achieve bounds of O(min{D^2+1,(D+1)^{2/3}T^{1/3}}) and O(D+1) under full information, and O(√((K+D)T)) under bandit feedback

## Why This Works (Mechanism)
The proposed algorithms work by constructing appropriate gradient estimators that can handle the limited feedback information while maintaining theoretical guarantees. The inverse-weighted estimator leverages importance weighting to correct for the selection bias in bandit feedback, while the pseudo-inverse matrix estimator uses a more sophisticated approach to achieve K-independent regret bounds. For delayed feedback, the algorithms use techniques to handle the temporal gap between prediction and feedback, maintaining convergence properties despite the delay.

## Foundational Learning
- Online convex optimization: Fundamental framework for analyzing sequential decision-making problems where decisions are made iteratively based on previous outcomes
  - Why needed: Provides the theoretical foundation for analyzing regret bounds in online learning scenarios
  - Quick check: Verify understanding of regret minimization concepts and online-to-batch conversion

- Structured prediction: Framework for predicting complex outputs with internal structure (sequences, trees, graphs) rather than simple scalar values
  - Why needed: The paper specifically addresses the structured prediction setting, which is more complex than standard classification
  - Quick check: Understand the difference between structured and unstructured prediction tasks

- Bandit feedback: Setting where only the loss of the chosen prediction is revealed, not the losses for other possible predictions
  - Why needed: More realistic than full-information settings but harder to optimize due to incomplete feedback
  - Quick check: Compare bandit feedback with full-information and semi-bandit feedback scenarios

## Architecture Onboarding

**Component map:**
Linear model -> Gradient estimator -> Parameter update -> Prediction

**Critical path:**
Input -> Linear prediction -> Loss computation -> Gradient estimation -> Parameter update -> Output

**Design tradeoffs:**
The paper balances between theoretical guarantees and practical applicability. The inverse-weighted estimator provides stronger theoretical bounds but may suffer from high variance in practice. The pseudo-inverse matrix estimator sacrifices some theoretical performance for K-independent bounds. The delayed feedback algorithms must balance between immediate updates and waiting for delayed feedback.

**Failure signatures:**
- High variance in gradient estimates leading to unstable training
- Poor performance when delays are very large relative to T
- Suboptimal performance on tasks where K is small (pseudo-inverse estimator not beneficial)

**First experiments:**
1. Compare the proposed estimators on a simple multiclass classification task with synthetic data
2. Test the delayed feedback algorithms with varying delay distributions
3. Evaluate the K-independent bound empirically by comparing performance as K increases

## Open Questions the Paper Calls Out
None

## Limitations
- Restricted to convex loss functions and linear model classes, which may not capture complex prediction tasks
- Theoretical analysis assumes unbiased gradient estimators, but estimator variance could impact practical performance
- Experiments focus on multiclass and multilabel classification, leaving generalizability to other structured prediction domains unclear

## Confidence
- Theoretical claims about regret bounds appear well-supported by the analysis (High confidence)
- Experimental results showing empirical alignment with theoretical predictions have High confidence
- Claims about practical advantages in real-world scenarios would benefit from more extensive evaluation across diverse structured prediction tasks (Medium confidence)

## Next Checks
1. Evaluate the proposed algorithms on structured prediction tasks beyond multiclass/multilabel classification, such as sequence tagging or parsing, to test generalizability
2. Conduct experiments varying the delay distribution parameters to better understand the robustness of the delayed feedback algorithms
3. Implement and test variance reduction techniques for the gradient estimators to assess practical performance beyond the theoretical bounds