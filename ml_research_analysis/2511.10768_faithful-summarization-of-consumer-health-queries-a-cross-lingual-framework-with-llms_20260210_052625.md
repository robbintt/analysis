---
ver: rpa2
title: 'Faithful Summarization of Consumer Health Queries: A Cross-Lingual Framework
  with LLMs'
arxiv_id: '2511.10768'
source_url: https://arxiv.org/abs/2511.10768
tags:
- medical
- summarization
- faithfulness
- summaries
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a framework for faithful summarization of consumer
  health questions (CHQs) by combining TextRank-based sentence extraction with medical
  named entity recognition (NER) to guide large language models (LLMs). The method
  fine-tunes LLaMA-2-7B on English (MeQSum) and Bangla (BanglaCHQ-Summ) datasets,
  using TextRank to extract relevant sentences containing medical entities and then
  generating summaries with the LLM.
---

# Faithful Summarization of Consumer Health Queries: A Cross-Lingual Framework with LLMs

## Quick Facts
- arXiv ID: 2511.10768
- Source URL: https://arxiv.org/abs/2511.10768
- Reference count: 5
- Primary result: Combines TextRank and NER-guided LLMs to improve faithfulness in consumer health summarization across English and Bangla

## Executive Summary
This paper presents a framework for generating faithful summaries of consumer health questions by integrating TextRank-based sentence extraction with medical named entity recognition to guide large language models. The approach fine-tunes LLaMA-2-7B on MeQSum (English) and BanglaCHQ-Summ (Bangla) datasets, extracting relevant sentences containing medical entities before generating summaries. The method demonstrates consistent improvements over zero-shot baselines and prior systems, with best-of-3 selection achieving ROUGE-1/2/L scores of 50.50/34.38/47.74 on MeQSum and 32.35/16.32/29.09 on BanglaCHQ-Summ. Human evaluation confirms that over 80% of generated summaries preserve critical medical information, while automated faithfulness metrics also show improvement.

## Method Summary
The framework combines TextRank-based sentence extraction with medical named entity recognition (NER) to guide large language models in summarizing consumer health questions. LLaMA-2-7B is fine-tuned on MeQSum (English) and BanglaCHQ-Summ (Bangla) datasets. The process begins with TextRank extracting relevant sentences from consumer health questions, prioritizing those containing medical entities identified through NER. These extracted sentences are then used to prompt the fine-tuned LLM for summary generation. The best-of-3 selection strategy is employed to choose the most faithful summary from multiple generations. This approach addresses the challenge of maintaining factual accuracy while condensing complex medical information from laypersons into coherent, clinically relevant summaries.

## Key Results
- ROUGE-1/2/L scores reach 50.50/34.38/47.74 on MeQSum and 32.35/16.32/29.09 on BanglaCHQ-Summ
- SummaC faithfulness score improves to 0.57 on MeQSum
- Over 80% of summaries preserve critical medical information according to human evaluation
- Framework outperforms zero-shot baselines and prior systems across both languages

## Why This Works (Mechanism)
The framework improves faithfulness by using TextRank to identify the most relevant sentences containing medical entities, which are then used to guide the LLM generation process. This approach ensures that the summary generation is grounded in medically relevant content rather than potentially irrelevant or misleading information from the original query. By combining NER to identify important medical concepts with TextRank's sentence importance ranking, the system focuses the LLM on clinically meaningful content. The fine-tuning on domain-specific datasets (MeQSum and BanglaCHQ-Summ) further adapts the LLM to the medical summarization task, while the best-of-3 selection helps filter out less accurate generations.

## Foundational Learning
- TextRank algorithm: A graph-based ranking algorithm for identifying important sentences in text; needed for sentence extraction and relevance ranking, quick check: verify it identifies key sentences containing medical entities
- Medical Named Entity Recognition (NER): Process of identifying and classifying medical terms in text; needed to ensure extracted sentences contain clinically relevant information, quick check: confirm high precision in detecting medical entities
- ROUGE metrics: Evaluation metrics for summarization quality measuring n-gram overlap; needed for quantitative assessment of summary quality, quick check: compare against human judgment for correlation
- Faithfulness metrics (SummaC, AlignScore): Automated measures of factual consistency in generated summaries; needed to evaluate whether summaries accurately represent source content, quick check: validate against clinical accuracy standards
- Cross-lingual evaluation: Assessment of model performance across different languages; needed to demonstrate generalizability of the approach, quick check: ensure comparable evaluation standards across languages

## Architecture Onboarding
**Component Map**: Consumer Health Query -> TextRank Extraction -> NER Filtering -> LLM Generation -> Best-of-3 Selection -> Summary Output

**Critical Path**: The critical path follows: TextRank extraction of relevant sentences containing medical entities → fine-tuned LLM generation → best-of-3 selection. Each step builds on the previous one, with NER filtering ensuring medical relevance before summary generation.

**Design Tradeoffs**: The framework trades computational efficiency for faithfulness by using multiple generation attempts (best-of-3) and complex sentence extraction. The reliance on NER systems introduces potential errors but ensures medical relevance. Fine-tuning on domain-specific data improves quality but requires labeled datasets.

**Failure Signatures**: Summaries may miss implicit medical context spanning multiple sentences if TextRank extraction is too aggressive. Entity recognition failures can lead to omission of critical medical information. The best-of-3 selection may still produce summaries with factual inconsistencies despite improvements.

**First Experiments**:
1. Test TextRank extraction performance with and without NER filtering on a subset of MeQSum data
2. Compare single vs. best-of-3 generation quality on 100 randomly selected consumer health questions
3. Evaluate summary faithfulness with and without fine-tuning on the MeQSum dataset

## Open Questions the Paper Calls Out
None

## Limitations
- Automated metrics may not fully capture medical accuracy and faithfulness in real-world consumer health queries
- Framework's dependence on NER systems introduces potential errors from entity recognition failures
- Cross-lingual comparison assumes comparable evaluation standards without establishing parallel annotation quality

## Confidence
- Combining TextRank and NER improves summarization quality: High
- Framework outperforms zero-shot baselines and prior systems: High
- Human evaluation confirms over 80% preservation of critical medical information: Medium
- Generalizability to other languages or medical domains: Low

## Next Checks
1. Conduct a blinded medical expert review of 100 randomly sampled summaries from each language to assess clinical accuracy and potential harm from misinformation, measuring inter-rater reliability.

2. Test the framework on additional languages with varying linguistic structures and medical terminology systems to evaluate cross-linguistic generalizability and identify language-specific limitations.

3. Implement ablation studies removing either the NER component or TextRank to quantify their individual contributions to faithfulness improvements and identify whether simpler approaches might suffice.