---
ver: rpa2
title: Interpretable Clustering Ensemble
arxiv_id: '2506.05877'
source_url: https://arxiv.org/abs/2506.05877
tags:
- clustering
- data
- ensemble
- interpretable
- uni00000013
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ICE (Interpretable Clustering Ensemble),
  the first interpretable clustering ensemble algorithm. ICE constructs a decision
  tree in the original feature space by treating base partitions as categorical variables
  and using statistical association tests to guide the tree building process.
---

# Interpretable Clustering Ensemble

## Quick Facts
- arXiv ID: 2506.05877
- Source URL: https://arxiv.org/abs/2506.05877
- Reference count: 40
- First interpretable clustering ensemble algorithm using decision trees

## Executive Summary
This paper introduces ICE (Interpretable Clustering Ensemble), a novel algorithm that addresses the critical gap of interpretability in clustering ensemble methods. Traditional clustering ensembles sacrifice interpretability for improved accuracy, making them unsuitable for high-stakes applications like medical diagnosis and financial risk assessment. ICE constructs a decision tree in the original feature space by treating base partitions as categorical variables and using statistical association tests to guide the tree building process, achieving competitive clustering accuracy while maintaining interpretability.

The algorithm evaluates candidate splits using chi-squared statistics between binary splits and base partitions, selecting the split with the strongest statistical association. Experimental results on 33 datasets demonstrate that ICE outperforms existing interpretable clustering approaches in clustering quality metrics (F1-score and NMI) while producing decision trees with reasonable depth and structure.

## Method Summary
ICE treats base partitions as categorical variables and constructs a decision tree in the original feature space. The algorithm evaluates candidate splits using chi-squared statistics between binary splits and base partitions, selecting the split with the strongest statistical association. This approach transforms the clustering ensemble problem into a supervised learning problem where the base partitions serve as labels, enabling the use of decision tree algorithms while maintaining interpretability. The method addresses the fundamental challenge of making clustering ensembles interpretable by leveraging statistical tests to guide the tree building process in the feature space rather than the cluster space.

## Key Results
- ICE achieves competitive clustering accuracy compared to state-of-the-art methods
- Outperforms existing interpretable clustering approaches in F1-score and NMI metrics
- Produces decision trees with reasonable depth and structure while maintaining clustering quality

## Why This Works (Mechanism)
ICE works by transforming the unsupervised clustering ensemble problem into a supervised learning problem. By treating base partitions as categorical labels, the algorithm can leverage decision tree algorithms that naturally provide interpretability. The chi-squared statistical association test identifies splits that best separate different base partitions, effectively learning which features distinguish between cluster assignments. This approach combines the strengths of ensemble methods (reduced variance and improved accuracy) with the interpretability of decision trees, creating a framework where the resulting tree structure provides insights into the clustering process while maintaining competitive performance.

## Foundational Learning
- **Base Partitions**: Multiple clustering results from different algorithms or parameter settings; needed because they provide diverse views of the data structure; quick check: verify base partitions have reasonable quality and diversity
- **Chi-Squared Statistics**: Measures association between categorical variables; needed to quantify the relationship between feature splits and cluster assignments; quick check: ensure chi-squared values are properly normalized and thresholded
- **Decision Tree Construction**: Recursive partitioning algorithm that creates interpretable models; needed to provide the interpretable structure while learning from base partitions; quick check: verify tree depth and pruning parameters
- **Ensemble Methods**: Combining multiple models to improve robustness and accuracy; needed as the theoretical foundation for clustering ensembles; quick check: assess diversity among base clustering algorithms
- **Feature Space vs. Cluster Space**: Distinction between original data features and clustering assignments; needed because ICE operates in feature space for interpretability; quick check: map relationships between feature splits and resulting clusters
- **Statistical Association Testing**: Framework for identifying meaningful relationships between variables; needed to guide split selection in a principled way; quick check: validate statistical significance thresholds

## Architecture Onboarding

**Component Map**: Data -> Base Partitioners -> Base Partitions -> ICE Decision Tree -> Interpretable Clusters

**Critical Path**: The algorithm's critical path involves generating base partitions, computing chi-squared statistics for all candidate splits, selecting the optimal split based on statistical significance, recursively partitioning the data, and producing interpretable cluster assignments through the final tree structure.

**Design Tradeoffs**: The method trades computational efficiency for interpretability by evaluating all possible splits using chi-squared tests, which becomes expensive in high dimensions. The approach assumes base partitions are of reasonable quality, making it dependent on the underlying clustering algorithms. The interpretability comes at the cost of potentially suboptimal clustering compared to black-box ensemble methods.

**Failure Signatures**: Poor performance may manifest as shallow trees with low statistical significance across all splits, indicating weak relationships between features and base partitions. High computational times on high-dimensional data suggest scalability issues. Inconsistent cluster assignments across different base partition sets indicate sensitivity to base partition quality.

**First Experiments**: 1) Test on synthetic datasets with known cluster structures to verify interpretability claims, 2) Evaluate sensitivity to base partition quality by varying the number and type of base clustering algorithms, 3) Measure computational scaling with increasing feature dimensions and dataset sizes.

## Open Questions the Paper Calls Out
None

## Limitations
- Computational complexity becomes prohibitive for high-dimensional datasets due to evaluating chi-squared statistics across all candidate splits
- Reliance on base partition quality assumes these partitions are available and of reasonable quality, but impact on final results is not extensively discussed
- While interpretability is claimed through decision trees, the relationship between tree depth and interpretability could be more thoroughly examined

## Confidence
- Algorithm approach: High confidence
- Experimental setup and comparisons: Medium confidence
- Interpretability claims: Medium confidence

## Next Checks
1. Conduct computational complexity analysis to determine scalability limits with increasing feature dimensions and dataset sizes
2. Perform ablation studies to quantify the impact of base partition quality on final clustering results
3. Implement user studies to validate the claimed interpretability advantage through human evaluation of decision tree outputs