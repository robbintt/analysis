---
ver: rpa2
title: 'AdParaphrase v2.0: Generating Attractive Ad Texts Using a Preference-Annotated
  Paraphrase Dataset'
arxiv_id: '2505.20826'
source_url: https://arxiv.org/abs/2505.20826
tags:
- texts
- text
- were
- paraphrase
- preference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces ADPARAPHRASE V 2.0, a large-scale dataset
  of ad text paraphrases annotated with human preference data, designed to analyze
  linguistic factors influencing ad attractiveness. This dataset is 20 times larger
  than its predecessor and contains 16,460 paraphrase pairs, each rated by ten evaluators.
---

# AdParaphrase v2.0: Generating Attractive Ad Texts Using a Preference-Annotated Paraphrase Dataset

## Quick Facts
- arXiv ID: 2505.20826
- Source URL: https://arxiv.org/abs/2505.20826
- Reference count: 34
- 20x larger than v1.0 with 16,460 paraphrase pairs rated by 10 evaluators each

## Executive Summary
AdParaphrase v2.0 introduces a large-scale dataset of ad text paraphrases annotated with human preference data to analyze linguistic factors influencing ad attractiveness. The dataset contains 16,460 Japanese ad text paraphrase pairs, each rated by ten evaluators, enabling researchers to isolate how expression choices affect perceived attractiveness while controlling for semantic content. Through experiments comparing multiple ad text generation methods including instruction tuning, preference tuning (DPO), and in-context learning, the study identifies specific linguistic features that enhance attractiveness and validates these findings with online A/B tests showing statistically significant improvements in conversion rates and cost efficiency.

## Method Summary
The researchers constructed a preference-annotated paraphrase dataset by first collecting source ad texts from the CAMERA dataset, then generating paraphrase candidates using both LLMs with stylistic instructions and crowdworkers following annotation guidelines. After rule-based filtering and manual paraphrase identification (5 annotators per pair), preference judgments were collected from 10 evaluators per pair using majority voting. The dataset was split into training (8,721 pairs), validation, and test sets. Three methods were evaluated for generating attractive ad texts: instruction tuning, direct preference optimization (DPO), and in-context learning with various few-shot examples. Linguistic feature analysis used chi-square tests to identify correlations between 26 features and human preferences, while online A/B tests validated performance on actual advertising platforms.

## Key Results
- DPO-based models achieved the highest attractiveness pass rates (84.4% for CALM3-22B) but generated texts exceeding length constraints (42 characters vs 30-character limit)
- Specific linguistic features strongly correlated with human preferences: brackets (ϕ=0.907 effect size), character count (ϕ=0.497), more nouns, and lower perplexity
- Human preferences showed strong correlation with predicted click-through rates (r=0.946), and online A/B tests demonstrated significant improvements in conversion rates and cost efficiency for DPO-generated ads

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Paraphrase pairs isolate "how-to-say" factors from "what-to-say" factors
- Mechanism: By comparing texts with identical semantic content but different linguistic expressions, preference differences can only be attributed to expression choices rather than content differences
- Core assumption: Paraphrase identification is reliable and evaluators truly judge only expression quality
- Evidence anchors: [abstract] "comprising 16,460 ad text paraphrase pairs, each annotated with preference data from ten evaluators"; [section 3.3] "Manual labeling was conducted to indicate whether the generated candidates are really a paraphrase at the sentence level"
- Break condition: If paraphrase pairs systematically differ in information content, observed preferences may reflect content differences rather than expression quality

### Mechanism 2
- Claim: Preference tuning (DPO) aligns model outputs with human preference signals more effectively than instruction tuning
- Mechanism: DPO directly optimizes the policy to increase likelihood of preferred responses while decreasing likelihood of rejected responses, using the preference-annotated paraphrase pairs as training signal
- Core assumption: The preference judgments generalize beyond the specific paraphrase pairs in the training set
- Evidence anchors: [section 5.2.2] "in terms of attractiveness, DPO-based models performed best overall"; [table 5] DPO-zeroshot achieves 84.4% attractiveness pass rate for CALM3-22B vs. 31.5% for instruction tuning
- Break condition: If DPO models exploit length heuristics (generating longer texts that evaluators prefer) rather than genuinely learning attractiveness patterns, the mechanism may not generalize to constrained settings

### Mechanism 3
- Claim: Specific linguistic features correlate with human preferences and predicted CTR
- Mechanism: Chi-square analysis identifies features (brackets, character count, noun density, lower perplexity) that co-occur with preferred texts, potentially capturing readability, informativeness, and attention-capturing properties
- Core assumption: The correlation between linguistic features and preferences reflects a causal relationship rather than spurious association
- Evidence anchors: [table 4] Brackets show ϕ=0.907 effect size; character count shows ϕ=0.497; [section 6.1] "Pearson's correlation coefficient: 0.946" between human preference and pCTR
- Break condition: If features are proxies for unmeasured confounds (e.g., product category, brand strength), interventions targeting these features may not improve performance

## Foundational Learning

- Concept: Paraphrase identification
  - Why needed here: Critical for ensuring preference judgments reflect expression quality rather than content differences
  - Quick check question: Given two texts "50% off first purchase" and "Half price for new customers," would you classify these as paraphrases? What about "50% off" vs. "Free shipping"?

- Concept: Direct Preference Optimization (DPO)
  - Why needed here: The best-performing method for generating attractive ad texts
  - Quick check question: How does DPO differ from reinforcement learning from human feedback (RLHF)? What data format does DPO require?

- Concept: Reference-free evaluation metrics
  - Why needed here: Traditional metrics (BLEU, ROUGE) require reference texts and may not capture "attractiveness"
  - Quick check question: Why would BLEU scores negatively correlate with attractiveness (-0.707 correlation in Table 8)? What does this imply about using BLEU for ad text evaluation?

## Architecture Onboarding

- Component map: Source texts (CAMERA) -> Paraphrase generation (LLMs + crowdworkers) -> Rule-based filtering -> Paraphrase identification (5 annotators) -> Preference judgment (10 annotators)

- Critical path:
  1. Obtain source ad texts from CAMERA dataset (CC BY-NC-SA 4.0 licensed)
  2. Generate paraphrase candidates using LLMs with stylistic instructions (40 types defined in Table 9) and crowdworkers following annotation guidelines
  3. Filter candidates: rule-based (length, content preservation) -> manual paraphrase identification (majority vote of 5 workers)
  4. Collect preference judgments (10 workers per pair, "skip" option for equal attractiveness)
  5. Format as preference triplets for DPO training or input-output pairs for instruction tuning
  6. Evaluate using three metrics: PI pass rate, attractiveness pass rate, attractiveness-with-length-constraint pass rate

- Design tradeoffs:
  1. Scale vs. quality: Using LLMs and crowdworkers enables 20x scale-up vs. v1.0's professional writers, but may introduce distributional differences from real ad texts
  2. Annotation depth vs. inter-annotator agreement: 10 evaluators per pair improves reliability but preference judgment IAA remains low (κ=0.167), reflecting inherent subjectivity
  3. DPO vs. ICL: DPO achieves highest attractiveness but generates longer texts that violate length constraints; ICL with few-shot examples balances attractiveness and length compliance
  4. Reference-based vs. reference-free evaluation: GPT-4o evaluation correlates best with human judgments but adds cost and potential API dependency

- Failure signatures:
  1. Length heuristics exploitation: DPO models generate texts averaging 42 characters vs. 30-character constraint (Table 6), suggesting optimization exploits evaluator preference for longer text
  2. Low paraphrase agreement: Moderate IAA (κ=0.442) for paraphrase identification may leak non-paraphrase pairs into analysis
  3. Preference-cap gap: Even with 10-evaluator consensus, only ~60% of preferred texts have higher predicted CTR (Figure 2), indicating human preference doesn't fully translate to click behavior
  4. Language specificity: Features like kanji/hiragana ratios and Japanese bracket styles may not generalize to other languages

- First 3 experiments:
  1. Reproduce linguistic feature analysis: Download AdParaphrase v2.0, extract the 26 features (definitions in Appendix F), run chi-square tests on the 3,570 high-agreement pairs. Verify that brackets (ϕ=0.907) and character count (ϕ=0.497) replicate as top features
  2. Compare ICL configurations: Using GPT-4o API, test zeroshot, zeroshot-findings, and fewshot-findings on 100 held-out source texts. Measure attractiveness using the same human evaluation protocol (10 evaluators)
  3. Pilot DPO training: Fine-tune CALM3-22B using QLoRA on the 8,721 training triplets. Evaluate on test set using both automatic metrics (GPT-4o evaluation) and linguistic feature analysis

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the linguistic features identified as attractive in Japanese ad texts (e.g., character types, use of brackets) generalize to other languages with different linguistic properties?
- Basis in paper: [explicit] The authors state in the Limitations section that their findings are specific to Japanese and that "Future work could extend the dataset to multiple languages to explore whether certain linguistic features affecting preferences are shared across languages."
- Why unresolved: The current dataset (ADPARAPHRASE V 2.0) is comprised exclusively of Japanese ad texts, and features like "character types" (hiragana, kanji) are language-specific
- What evidence would resolve it: Constructing datasets from scratch for target languages like English or Chinese—rather than translating—and performing a comparative analysis of feature correlations with human preference

### Open Question 2
- Question: How can preference tuning methods like Direct Preference Optimization (DPO) be modified to strictly adhere to practical length constraints while maintaining high attractiveness?
- Basis in paper: [explicit] The paper notes in the Conclusion that "enhancing ATG methods by addressing challenges such as adhering to length constraints" is a task for future work. In the results, DPO achieved the best attractiveness but failed length constraints (Table 5)
- Why unresolved: Current DPO implementations tend to exploit "length heuristics" (generating longer text), which conflicts with the strict character limits (e.g., 30 characters) required by ad platforms
- What evidence would resolve it: A modified training objective or constrained decoding strategy that maintains high "Att&Length" scores comparable to or better than few-shot prompting baselines

### Open Question 3
- Question: To what extent do demographic factors (age, gender, nationality) influence human preferences for ad text paraphrases?
- Basis in paper: [explicit] The authors note in the Limitations section that the study recruited only Japanese participants and that "collecting such additional information... would be a valuable future direction."
- Why unresolved: The current annotation process involved only ten participants per pair without collecting demographic data, making it impossible to determine if preferences are universal or segmented by user characteristics
- What evidence would resolve it: A re-annotation of the dataset with demographic tagging, followed by a cluster analysis to identify statistically significant preference variances across different user groups

## Limitations
- The dataset focuses exclusively on Japanese ad texts, limiting generalizability to other languages or cultural contexts
- Preference judgments show low inter-annotator agreement (κ=0.167), suggesting inherent subjectivity in "attractiveness"
- DPO models generate significantly longer texts than constraints (42 vs 30 characters), potentially exploiting length heuristics
- Online A/B tests only show correlation between predicted CTR and human preference, not causation

## Confidence
- **High**: Paraphrase identification isolates expression quality from content; DPO outperforms instruction tuning on attractiveness; linguistic features correlate with human preferences
- **Medium**: Online A/B test results showing DPO improvements; GPT-4o evaluation correlates with human judgments
- **Low**: Causal impact of specific linguistic features on CTR; generalizability of findings beyond Japanese e-commerce ads

## Next Checks
1. Replicate feature analysis: Verify the chi-square results on brackets (ϕ=0.907) and character count (ϕ=0.497) using the 3,570 high-agreement pairs to confirm data integrity
2. Test DPO length constraints: Fine-tune DPO models with explicit length penalties and compare Att&Length scores to baseline instruction tuning
3. Cross-linguistic validation: Generate and evaluate paraphrases in English or another language using the same methodology to test generalizability of linguistic feature effects