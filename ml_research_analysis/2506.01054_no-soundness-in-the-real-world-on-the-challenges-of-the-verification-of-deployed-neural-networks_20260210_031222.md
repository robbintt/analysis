---
ver: rpa2
title: 'No Soundness in the Real World: On the Challenges of the Verification of Deployed
  Neural Networks'
arxiv_id: '2506.01054'
source_url: https://arxiv.org/abs/2506.01054
tags:
- sound
- verification
- network
- neural
- networks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that existing neural network verification
  tools, despite being theoretically sound, are not practically sound when deployed
  in real-world environments. The authors show that floating-point arithmetic and
  deployment-specific factors can lead to significant discrepancies between theoretical
  and deployed network behavior.
---

# No Soundness in the Real World: On the Challenges of the Verification of Deployed Neural Networks

## Quick Facts
- arXiv ID: 2506.01054
- Source URL: https://arxiv.org/abs/2506.01054
- Authors: Attila Sz치sz; Bal치zs B치nhelyi; M치rk Jelasity
- Reference count: 40
- This paper demonstrates that existing neural network verification tools, despite being theoretically sound, are not practically sound when deployed in real-world environments.

## Executive Summary
This paper reveals a critical gap between theoretical and practical soundness in neural network verification. While existing verifiers are proven sound for idealized mathematical models, they fail to account for floating-point arithmetic and deployment-specific factors that can lead to significant discrepancies between theoretical and deployed network behavior. The authors construct adversarial networks with precision detectors that exploit these discrepancies, causing state-of-the-art verifiers to miss malicious backdoors. Through empirical evaluation, they prove that verifiers based on interval analysis, symbolic bound propagation, and mixed-integer programming are vulnerable to these deployment-specific attacks, demonstrating that theoretical soundness does not guarantee practical soundness in real-world deployments.

## Method Summary
The authors construct adversarial neural networks with "detector neurons" designed to behave differently in verification versus deployment environments. They exploit floating-point non-associativity and precision differences by using constants that behave differently depending on bit-width (e.g., $2^{24} + 1 - 2^{24}$ yields 1 in 64-bit but 0 in 32-bit). They test multiple state-of-the-art verifiers including CROWN, DeepZ, DeepPoly, and MIP-based methods on these networks. The verification problem is formally distinguished between the theoretical problem (bounding full-precision outputs) and the deployed verification problem (bounding floating-point outputs in a potentially stochastic environment), proving that current verifiers fail the latter.

## Key Results
- None of the tested verifiers (DeepZ, DeepPoly, CROWN variants, MIP-based) could correctly identify the planted backdoors in adversarial networks
- Accuracy drops from 98.11% to 0.11% when transitioning from verification environment (64-bit) to deployment environment (32-bit)
- Theoretical soundness (bounding full-precision outputs) does not imply practical soundness (bounding floating-point outputs in stochastic environments)
- The attack works by exploiting non-associative floating-point arithmetic and precision differences between verification and deployment settings

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Theoretical soundness (verifying the full-precision mathematical model) does not guarantee practical soundness (verifying the actual floating-point implementation), allowing adversarial behaviors to hide from verifiers.
- **Mechanism:** Current verifiers bound the output of an idealized real-valued function $f(x; \theta)$. However, the deployed network is a distinct function $r(x; \theta, E)$ dependent on the environment $E$ (hardware, precision, operation order). Because floating-point arithmetic involves rounding errors and non-associativity, the set of possible outputs in deployment can diverge significantly from the full-precision theoretical model.
- **Core assumption:** The deployment environment introduces variations (stochasticity or specific deterministic orders) that differ from the idealized mathematical model or the verifier's internal computation model.
- **Evidence anchors:**
  - [Abstract]: "Theoretical soundness (bounding the full-precision output while computing with floating point) does not imply practical soundness (bounding the floating point output in a potentially stochastic environment)."
  - [Section 5.2]: Defines the deployed verification problem as distinct from the theoretical problem, noting $P_E \not\subset P$.
  - [Corpus]: "Floating-Point Neural Network Verification at the Software Level" supports the distinction between abstract model verification and software-level faults.
- **Break condition:** If the deployment environment uses exact real-number arithmetic (impossible on standard hardware) or if the verifier explicitly models every detail of the deployment environment $E$ (precision, rounding mode, operation order).

### Mechanism 2
- **Claim:** Adversarial networks can exploit the difference in floating-point precision between the verification environment and the deployment environment to trigger backdoors.
- **Mechanism:** The authors construct "detector neurons" using constants that behave differently depending on the bit-width (e.g., 32-bit vs 64-bit). Specifically, they use a value $\omega$ (e.g., $2^{24}$ for 32-bit) such that $\omega + 1 = \omega$ in the target precision but not in higher precision. If a verifier uses higher precision (e.g., 64-bit) to verify a network intended for lower precision (e.g., 32-bit), the detector neuron outputs different values, failing to trigger the backdoor during verification while activating it in deployment.
- **Core assumption:** The attacker has knowledge of the target deployment's floating-point format (e.g., IEEE 754 binary32) and the verifier uses a different or higher precision format.
- **Evidence anchors:**
  - [Section 7.1]: Describes the precision detector $\omega + 1 - \omega$ and how it differentiates 32-bit vs 64-bit environments.
  - [Table 1]: Shows empirical evidence where accuracy drops to 0.11% in the target precision but remains high (98.11%) in the other.
  - [Corpus]: The "SoundnessBench" paper suggests evaluating verifiers specifically on their ability to handle such numeric edge cases.
- **Break condition:** If the verifier strictly enforces the exact same floating-point precision and rounding mode as the deployment environment during the verification process.

### Mechanism 3
- **Claim:** Interval analysis and zonotope-based methods fail to guarantee practical soundness because they cannot account for the non-associative nature of floating-point operations across all possible operation orders.
- **Mechanism:** Methods like Interval Bound Propagation (IBP) or DeepZ evaluate expressions using a specific expression tree (order of operations). In floating-point arithmetic, $(a+b)+c \neq a+(b+c)$. The paper proves (Prop 6.2, 6.5) that for any fixed expression tree used by a verifier, there exists a valid alternative execution order in a stochastic environment that produces an output outside the verifier's calculated bounds.
- **Core assumption:** The deployment environment allows for variations in the order of summation (common in parallel GPU computations or different compiler optimizations).
- **Evidence anchors:**
  - [Section 6.2]: "Proposition 6.2... interval arithmetic fails to cover $L_r$ [minimum floating point output], hence it is not sound."
  - [Section 6.4]: Extends the proof to zonotope-based approaches (DeepZ/RefineZono), showing they simplify to interval methods or widen bounds insufficiently.
  - [Corpus]: "Nondeterminism-Aware Optimistic Verification" (neighbor paper) reinforces the challenge of nondeterminism in floating-point environments.
- **Break condition:** If the deployed network executes operations in a strictly deterministic order known a priori to the verifier, and the verifier uses that exact order.

## Foundational Learning

- **Concept: Floating-Point Non-Associativity**
  - **Why needed here:** This is the fundamental mathematical property exploited by the paper. Understanding that the order of addition changes the result in standard IEEE 754 arithmetic is crucial for grasping why "theoretical" (associative) math differs from "deployment" (non-associative) reality.
  - **Quick check question:** If $x = 10^{20}$, $y = -10^{20}$, and $z = 1$, does $(x+y)+z$ equal $x+(y+z)$ in 32-bit floating point?

- **Concept: Interval Bound Propagation (IBP)**
  - **Why needed here:** Most verifiers attacked in the paper (DeepZ, CROWN variants) rely on this or similar abstract domains. IBP propagates intervals $[l, u]$ through layers to bound outputs, but the paper demonstrates these bounds are insufficient for floating-point variations.
  - **Quick check question:** In IBP, if you multiply an input interval $[1, 2]$ by a weight $-1$, what is the resulting interval?

- **Concept: Soundness vs. Completeness in Verification**
  - **Why needed here:** The paper redefines "soundness." Traditionally, a sound verifier never returns "true" for a false property. The paper argues this definition is insufficient ("theoretical soundness") if it ignores deployment realities ("practical soundness").
  - **Quick check question:** A verifier returns "Safe" for a network that crashes in deployment due to a NaN error. Was the verifier theoretically sound? Was it practically sound?

## Architecture Onboarding

- **Component map:**
  - **Theoretical Model ($f$):** The ideal mathematical function (e.g., real numbers).
  - **Deployed Network ($r$):** The actual function executed on hardware, defined by $f$ AND the Environment $E$ (precision, rounding, operation order).
  - **Detector Neuron:** A specialized neuron added by the attacker (e.g., $\omega + 1 - \omega$) designed to output one value in verification and another in deployment.
  - **Expression Tree:** The binary tree structure defining the order of arithmetic operations; varies by environment (e.g., CPU sequential vs GPU parallel).

- **Critical path:**
  1. **Input:** Standard input (e.g., MNIST image).
  2. **Detection:** The input (or a constant bias) passes through the *Detector Neuron*.
  3. **Trigger:** The *Detector Neuron* calculates a result based on the environment's floating-point behavior (precision/order).
  4. **Action:** If the result matches the "adversarial" condition (e.g., $\neq 0$), the network shifts logits/activates the backdoor.
  5. **Verification Failure:** The verifier, running in a "clean" environment, calculates the *Detector Neuron* output as "safe" (e.g., $0$), missing the backdoor.

- **Design tradeoffs:**
  - **Verifier Precision:** Running verifiers in high precision (64-bit) is standard for stability but creates a gap from 32-bit deployments.
  - **Abstract Domains:** Zonotopes (DeepZ) trade tightness for speed compared to polyhedra (DeepPoly), but both fail to capture the discrete "jumps" in floating-point outputs caused by operation reordering.
  - **Determinism:** Enforcing deterministic operation orders in deployment improves verifiability but may sacrifice hardware acceleration/parallelism performance.

- **Failure signatures:**
  - **False Positives (Safety):** Verifier reports "Verified/Robust" (e.g., 97% accuracy) while the actual deployment accuracy is 0%.
  - **Gap Divergence:** The difference between the computed lower bound of the verifier and the actual minimum output $L_r$ of the deployed network.
  - **Environment Specificity:** A network verified as safe on CPU (specific expression tree) becomes unsafe when deployed on GPU (different expression tree).

- **First 3 experiments:**
  1. **Reproduce the Precision Attack:** Implement the detector $2^{24} + 1 - 2^{24}$ in a simple neural network. Run a standard verifier (e.g., DeepPoly) in 64-bit mode against a 32-bit simulated deployment to observe the robustness gap.
  2. **Operation Order Fuzzing:** Take a standard robust network and measure output variance when performing inference with different batch sizes or parallelization settings (simulating different expression trees) to observe non-determinism.
  3. **Bound Tightening:** Attempt to fix a verifier by manually forcing it to use a specific "worst-case" expression tree (e.g., sorting weights in decreasing order) and observe if verification time becomes intractable (validating the implied complexity claim).

## Open Questions the Paper Calls Out
None

## Limitations
- The attacks primarily target verifiers configured with high precision (64-bit) while deployed networks use lower precision (32-bit), which may not reflect all real-world configurations.
- The practicality of such adversarial attacks in real-world systems without access to verification settings remains unclear.
- Many real-world deployments use deterministic computation orders, particularly in safety-critical applications where this work is most relevant.

## Confidence
- **High Confidence:** The core observation that floating-point non-associativity creates verification gaps is mathematically sound and well-demonstrated. The distinction between theoretical and practical soundness is valuable and clearly articulated.
- **Medium Confidence:** The adversarial network constructions are clever and effective against tested verifiers, but their generalizability to arbitrary network architectures and verification pipelines requires further validation.
- **Low Confidence:** The claim that "no verifiers" can detect these attacks may be overstated, as it depends heavily on verifier configuration and the specific deployment environment assumptions.

## Next Checks
1. **Precision-matching evaluation:** Test whether verifiers configured to use the same floating-point precision as the deployment environment can detect the planted backdoors, or if the attacks work even under matched precision settings.
2. **Real-world deployment assessment:** Implement the adversarial networks on actual hardware (GPUs with different precision modes) to measure the gap between verification predictions and real deployment behavior under controlled conditions.
3. **Alternative verification approaches:** Evaluate whether sound verifiers using abstract domains with better floating-point handling (e.g., affine arithmetic, constraint-based methods) can overcome the identified vulnerabilities, or if the problem is fundamental to any abstraction-based approach.