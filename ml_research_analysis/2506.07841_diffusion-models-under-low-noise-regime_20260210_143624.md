---
ver: rpa2
title: Diffusion models under low-noise regime
arxiv_id: '2506.07841'
source_url: https://arxiv.org/abs/2506.07841
tags:
- diffusion
- noise
- denoising
- training
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study examines diffusion models'' behavior under low-noise
  conditions, addressing a critical gap in understanding how these models perform
  when denoising small perturbations. Using CelebA subsets and synthetic Gaussian
  mixtures, the authors systematically analyze three diffusion model variants: UNet
  denoiser, Noise-Conditional Score Networks (NCSN), and Sliced Score Matching (SSM).'
---

# Diffusion models under low-noise regime

## Quick Facts
- arXiv ID: 2506.07841
- Source URL: https://arxiv.org/abs/2506.07841
- Authors: Elizabeth Pavlova; Xue-Xin Wei
- Reference count: 40
- Primary result: Diffusion models trained on disjoint datasets diverge near data manifold even when high-noise outputs converge

## Executive Summary
This study systematically investigates diffusion models' behavior under low-noise conditions, revealing critical limitations when denoising small perturbations. The authors demonstrate that models trained on different datasets produce increasingly divergent outputs as noise levels decrease, with L2 distances between trajectories increasing while cosine similarity of denoising directions decreases. This divergence occurs despite convergence at high noise levels, suggesting fundamental challenges in how diffusion models capture data manifold structure. The research also uncovers that small-dataset models encode training samples as discrete attractors, consistently returning to the same outputs when perturbed.

The empirical analysis spans three diffusion model variants (UNet denoiser, NCSN, and SSM) across CelebA subsets and synthetic Gaussian mixtures. Results show that while models effectively locate density centers in simple geometric structures, they struggle with complex manifolds like anisotropic covariances and curved surfaces. Score-matching objectives demonstrate superior performance in low-density regions compared to direct reconstruction objectives, highlighting architectural implications for model design.

## Method Summary
The study employs a systematic experimental framework examining diffusion models across varying noise levels using CelebA subsets and synthetic Gaussian mixtures. Three model variants are analyzed: UNet denoiser, Noise-Conditional Score Networks (NCSN), and Sliced Score Matching (SSM). The experimental design progressively decreases noise levels from high (σ=1.0) to low (σ=0.05) while measuring L2 distances between trajectories from models trained on disjoint datasets. Cosine similarity of denoising directions is tracked to assess alignment in learned representations. Synthetic datasets with varying geometric complexity (isotropic covariances, anisotropic covariances, curved manifolds) enable controlled analysis of model behavior across different structural challenges.

## Key Results
- Models trained on disjoint datasets show increasing divergence (higher L2 distances) near the data manifold while converging at high noise levels
- Cosine similarity of denoising directions decreases as noise approaches zero, indicating divergent learned representations
- Small-dataset models encode training images as discrete attractors, consistently returning to same samples when perturbed
- Score-matching objectives (NCSN, SSM) outperform direct reconstruction objectives in low-density regions

## Why This Works (Mechanism)
The divergence near data manifold appears driven by models learning distinct local minima in the score-matching landscape when trained on different datasets. At high noise levels, global structure dominates learning, enabling convergence. As noise decreases, models must capture fine-grained manifold details, where different training data induce divergent gradient estimates. The attractor behavior in small-dataset models likely stems from limited diversity causing overfitting to specific training samples, creating basins of attraction around memorized points. Score-matching objectives provide better low-density performance by explicitly optimizing the gradient of log-density rather than reconstructing noisy inputs, enabling more stable learning in regions with sparse data coverage.

## Foundational Learning
- **Diffusion process**: Gradual noise addition and removal in data space - needed for understanding model training objective
  - Quick check: Can trace forward and reverse processes mathematically
- **Score matching**: Estimating gradient of log-density - needed for understanding NCSN and SSM objectives
  - Quick check: Can differentiate log-probability expressions
- **Data manifold**: Low-dimensional structure in high-dimensional space - needed for interpreting model behavior near data
  - Quick check: Can explain manifold hypothesis intuitively
- **Attractor dynamics**: State convergence in dynamical systems - needed for understanding training sample memorization
  - Quick check: Can describe basic stability concepts
- **Geometric structures**: Covariance matrices and manifold curvature - needed for synthetic dataset analysis
  - Quick check: Can interpret eigenvalues of covariance matrices

## Architecture Onboarding

**Component Map**: Input data -> Noise addition (forward process) -> UNet/NCSN/SSM denoiser -> Denoised output

**Critical Path**: Forward diffusion process generates noisy data → Denoiser network estimates denoising direction → Output refined through iterative denoising steps

**Design Tradeoffs**: Score-matching objectives provide better low-density performance but require more complex training procedures compared to direct reconstruction; smaller datasets enable attractor memorization but reduce generalization

**Failure Signatures**: Increasing L2 distance between models on disjoint datasets as noise decreases; cosine similarity decay in denoising directions; consistent return to training samples (attractors) in small-dataset regimes

**3 First Experiments**:
1. Measure L2 distance and cosine similarity across noise levels σ=1.0, 0.5, 0.25, 0.1, 0.05
2. Compare attractor behavior between models trained on full CelebA vs. CelebA subset
3. Evaluate performance on synthetic Gaussian mixtures with varying covariance structures

## Open Questions the Paper Calls Out
None

## Limitations
- Limited to CelebA subsets and synthetic Gaussian mixtures, raising generalizability concerns to other data types
- Quantitative metrics may not capture perceptual quality differences in denoised outputs
- Does not explore mitigation strategies for attractor behavior or architectural modifications
- Qualitative analysis of complex geometric structures lacks comprehensive quantitative benchmarks

## Confidence
**High Confidence**: Divergence between models on disjoint datasets near data manifold; attractor behavior in small-dataset models
**Medium Confidence**: Superior performance of score-matching objectives in low-density regions
**Low Confidence**: Fundamental struggles with complex geometric structures; practical implications for real-world applications

## Next Checks
1. Evaluate low-noise behavior patterns on non-image datasets (text embeddings, audio spectrograms, molecular structures) to assess cross-domain generalizability
2. Measure downstream task performance impact (inpainting, super-resolution, anomaly detection) to quantify practical significance
3. Implement architectural modifications (contrastive learning, manifold regularization) to mitigate attractor behaviors and measure effectiveness across dataset scales