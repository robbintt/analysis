---
ver: rpa2
title: 'On the Cost and Benefits of Training Context with Utterance or Full Conversation
  Training: A Comparative Stud'
arxiv_id: '2505.07202'
source_url: https://arxiv.org/abs/2505.07202
tags:
- training
- context
- conversational
- speech
- speaker
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compares utterance-level training with contextual conditioning
  versus full conversation training for conversational TTS. Using the Dia model architecture
  and 20 GPU-hours on an NVIDIA H100, both approaches were trained on the same dialogue
  dataset.
---

# On the Cost and Benefits of Training Context with Utterance or Full Conversation Training: A Comparative Stud

## Quick Facts
- arXiv ID: 2505.07202
- Source URL: https://arxiv.org/abs/2505.07202
- Authors: Hyouin Liu; Zhikuan Zhang
- Reference count: 15
- Primary result: Utterance-level training with contextual conditioning outperforms full conversation training for conversational TTS

## Executive Summary
This study compares two training approaches for conversational text-to-speech systems: utterance-level training with contextual conditioning versus full conversation training. Using the Dia model architecture and a game dialogue dataset, the authors demonstrate that utterance-level training achieves superior output quality (MOS 4.3 vs 3.7) while requiring 37% less training time. The full conversation approach suffers from speaker similarity hallucinations where voice characteristics drift across turns. The results establish utterance-level training with contextual conditioning as the recommended approach for efficient conversational TTS development.

## Method Summary
The study trains two variants of the Dia 1.6B transformer model on 33 hours of Honkai: Star Rail character dialogues. The utterance-level approach trains on individual speech segments with k=3 context utterances concatenated using a `<speech>` token, while the conversation-level approach concatenates full three-sentence dialogue chunks. Both models are trained for 20 GPU-hours on NVIDIA H100 hardware with identical hyperparameters (lr=5e-5 cosine decay, batch=1, grad_accum=4, bfloat16). Evaluation includes MOS ratings, WER via ASR, speaker similarity via pretrained verification models, and context coherence scores. Memory usage is monitored throughout training.

## Key Results
- Utterance-level training achieved MOS score of 4.3/5.0 versus 3.7/5.0 for conversation-level training
- Training throughput reached 126 utterances/hour for utterance-level versus 43 utterances/hour for conversation-level
- Speaker similarity hallucinations observed in conversation-level training with voice characteristics drifting across turns
- Peak memory usage was 23.6GB for conversation-level versus 14.3GB for utterance-level training

## Why This Works (Mechanism)
Utterance-level training with contextual conditioning works better because it avoids the compounding error problem inherent in full conversation training. When training on entire conversations, errors in early turns propagate and amplify through later turns, leading to speaker identity drift and reduced coherence. The utterance-level approach isolates each training example, preventing error accumulation while still providing necessary context through the k=3 previous utterances. This architectural choice enables more stable optimization and prevents the "voice wandering" effect where speaker characteristics gradually change across a conversation.

## Foundational Learning
- **Contextual conditioning**: Why needed - provides conversation history without full sequence training complexity; Quick check - verify k=3 context provides sufficient information without overwhelming model capacity
- **Speaker verification models**: Why needed - quantitative measure of voice consistency across turns; Quick check - ensure cosine similarity scores remain stable within 0.1 range for same speaker
- **Conversational coherence metrics**: Why needed - quality measure beyond standard MOS for dialogue systems; Quick check - validate 1-5 scale with multiple raters shows consistent ratings
- **Memory-efficient batching**: Why needed - enables larger context windows within GPU constraints; Quick check - confirm gradient accumulation maintains training stability
- **Dialogue segmentation strategies**: Why needed - determines how conversational structure maps to training examples; Quick check - verify segmentation preserves speaker turns and natural pauses

## Architecture Onboarding

**Component Map:** Dia 1.6B transformer -> Text encoder -> Context conditioner -> Decoder -> Codec output

**Critical Path:** Text encoder → Context conditioner → Decoder → Codec output (most compute-intensive)

**Design Tradeoffs:** Context window size k=3 balances memory efficiency against conversational coherence needs

**Failure Signatures:** Speaker identity drift >0.1 cosine similarity across turns indicates conversation-level training instability

**First Experiments:**
1. Train utterance-level model with k=1, k=3, and k=5 context to find optimal balance
2. Implement speaker similarity monitoring during conversation-level training to quantify hallucination severity
3. Test memory usage profiling during both training approaches to verify reported 23.6GB vs 14.3GB difference

## Open Questions the Paper Calls Out
- Would hybrid training approaches that combine utterance-level stability with selective full-conversation training for challenging contexts outperform either method alone?
- How would the utterance-level versus conversation-level training comparison change across different TTS architectures beyond Dia?
- Do the findings generalize beyond game character dialogues to naturalistic human conversations with different prosodic patterns?
- Can reinforcement learning specifically targeting cross-utterance coherence resolve the speaker identity drift observed in conversation-level training?

## Limitations
- Analysis based on single model architecture (Dia), other architectures might show different sensitivity to training methodology
- Dataset limited to game character dialogues which may not fully represent all conversational contexts and styles
- Study focuses on resource efficiency and basic quality metrics without exploring long-form conversation capabilities
- Does not investigate hybrid approaches that might combine benefits of both training paradigms

## Confidence
- MOS score comparison and resource efficiency claims: High
- Speaker similarity hallucination mechanism: Medium
- Training time measurements: Medium

## Next Checks
1. Implement speaker similarity tracking during conversation-level training to verify the hallucination effect quantitatively
2. Test the utterance-level approach on a different conversational dataset to assess generalizability
3. Profile memory usage during both training approaches to confirm the 23.6GB vs 14.3GB peak memory difference