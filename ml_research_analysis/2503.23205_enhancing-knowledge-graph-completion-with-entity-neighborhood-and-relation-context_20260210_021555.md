---
ver: rpa2
title: Enhancing Knowledge Graph Completion with Entity Neighborhood and Relation
  Context
arxiv_id: '2503.23205'
source_url: https://arxiv.org/abs/2503.23205
tags:
- entity
- relation
- context
- knowledge
- kgc-erc
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KGC-ERC addresses the problem of incomplete knowledge graphs by
  integrating entity neighborhood and relation context into a generative language
  model for knowledge graph completion. The framework enriches the input sequence
  with sampled contextual information from both the entity's neighbors and other triples
  involving the same relation, using a sampling strategy to select relevant context
  within token constraints.
---

# Enhancing Knowledge Graph Completion with Entity Neighborhood and Relation Context

## Quick Facts
- **arXiv ID:** 2503.23205
- **Source URL:** https://arxiv.org/abs/2503.23205
- **Reference count:** 31
- **Primary result:** Achieves MRR 0.386 and H@1 0.360 on Wikidata5M using only 60M parameters

## Executive Summary
KGC-ERC addresses the problem of incomplete knowledge graphs by integrating entity neighborhood and relation context into a generative language model for knowledge graph completion. The framework enriches the input sequence with sampled contextual information from both the entity's neighbors and other triples involving the same relation, using a sampling strategy to select relevant context within token constraints. Experiments on Wikidata5M, Wiki27K, and FB15K-237-N datasets demonstrate that KGC-ERC outperforms state-of-the-art baselines, achieving MRR of 0.386 and H@1 of 0.360 on Wikidata5M with only 60M parameters. The approach shows that incorporating relation context and using a customized sampling strategy are crucial for enhancing model performance in knowledge graph completion tasks.

## Method Summary
KGC-ERC treats knowledge graph completion as a sequence-to-sequence generation task using T5. The model verbalizes the query triple (h, r, ?) and enriches it with sampled contextual information from two sources: the entity's 1-hop neighbors and other triples containing the same relation. A sampling strategy optimizes context selection based on relation cardinality (1-n, n-1, n-n, 1-1) to ensure diverse and relevant examples within the 512-token limit. During inference, the model generates candidate entities, filters invalid outputs, and ranks valid candidates by generation likelihood.

## Key Results
- Achieves MRR 0.386 and H@1 0.360 on Wikidata5M with 60M parameters
- Outperforms state-of-the-art baselines across Wikidata5M, Wiki27K, and FB15K-237-N datasets
- Demonstrates that relation context sampling is crucial for performance enhancement

## Why This Works (Mechanism)

### Mechanism 1: Dual-Context Enrichment (Neighborhood + Relation)
The model verbalizes the query triple and appends sampled 1-hop neighbors of the head entity along with sampled triples containing the same relation. This provides the attention mechanism with explicit graph structure and relational semantics that act as ancillary cues, reducing ambiguity for the decoder.

### Mechanism 2: Cardinality-Aware Relation Sampling
The framework classifies relations by cardinality and optimizes sampling strategy accordingly. For 1-n relations, it prioritizes triples involving both the head entity and relation; for n-1 relations, it ensures diversity in tail entities. This ensures the limited context window displays the most logically diverse and informative examples.

### Mechanism 3: Generative Ranking via Constrained Decoding
The model generates text tokens autoregressively and filters invalid outputs that don't map to valid KG entities. This approach avoids the computational bottleneck of scoring all entities in large graphs by restricting the search space to the generative model's "belief."

## Foundational Learning

- **Concept: Sequence-to-Sequence (Seq2Seq) KGC**
  - Why needed: The architecture uses T5, a generative model that predicts strings rather than ranking embeddings
  - Quick check: How does the model handle an entity that appears in training set but has a text representation longer than the token limit?

- **Concept: Relation Cardinality (1-n, n-1, n-n, 1-1)**
  - Why needed: The core innovation of the "Selector" module depends on classifying relations by their mapping properties
  - Quick check: In a `1-n` relation triple (Head, Relation, ?), should the sampling strategy prioritize triples with the same Head or diverse Heads?

- **Concept: Context Verbalization**
  - Why needed: The bridge between the discrete graph structure and the language model is the text template
  - Quick check: If the separator token `<SEP>` is removed from the input construction, how might the model misinterpret the boundary between query and neighborhood context?

## Architecture Onboarding

- **Component map:** Input Constructor -> Selector Module (Neighborhood Sampler, Relation Context Sampler) -> Verbalizer -> Generator (T5) -> Validator
- **Critical path:** The Relation Context Sampler is the critical new logic. A bug here (e.g., defaulting to random sampling or ignoring the 1-n/1-1 logic) results in the ablation performance (MRR drop from 0.386 to 0.382)
- **Design tradeoffs:** Uses only 60M parameters (T5-small) to handle Wikidata5M, trading model depth/size for explicit context enrichment; hard truncation at 512 tokens means high-degree entities lose structural information
- **Failure signatures:** Empty candidate set indicates tokenizer/verbalization mismatch; context truncation bias occurs if the 512-token limit is filled mostly by "Entity Neighborhood" before "Relation Context" is added
- **First 3 experiments:**
  1. Sanity Check (Overfit): Train on a tiny subset (e.g., 100 triples) with context enabled; verify the model can generate the exact tail entity string
  2. Ablation on Sampling: Run evaluation on validation set using full "Customized Sampling" vs. "Random Sampling"; verify the MRR gap (~0.004 observed in paper) exists
  3. Cardinality Stress Test: Isolate evaluation on `1-n` relations specifically; compare performance with and without "Relation Context"

## Open Questions the Paper Calls Out
- Can a learned adaptive sampling mechanism outperform the current static, heuristic-based selector in identifying relevant context?
- Does expanding the input token limit beyond 512 yield proportional performance gains, or does the current truncation suffice?
- How sensitive is the Relation Context Sampling strategy to errors in the pre-defined relation cardinality classifications (1-n, n-1, etc.)?

## Limitations
- The current Selector module relies on random sampling within relation groups and fixed rules based on relation cardinality types, rather than assessing semantic relevance
- Hard truncation at 512 tokens guarantees information loss for high-degree entities (those with >100 neighbors)
- The paper does not address how the model handles relations that are ambiguous or exhibit mixed cardinality

## Confidence
- High: Core experimental results (MRR, H@k metrics) and methodology are well-specified and reproducible
- Medium: The effectiveness of the sampling strategy and relation context is demonstrated but could benefit from more ablation studies
- Low: The paper does not provide detailed implementation of the relation cardinality classification method or the diversity algorithm for n-1 relations

## Next Checks
1. Verify that the relation cardinality classification method correctly categorizes relations by analyzing a sample of classified relations
2. Implement and test the diversity algorithm for n-1 relation context sampling to ensure it produces the intended variety of tail entities
3. Conduct an ablation study comparing performance with and without the customized sampling strategy to quantify its contribution to overall results