---
ver: rpa2
title: 'CodeMEM: AST-Guided Adaptive Memory for Repository-Level Iterative Code Generation'
arxiv_id: '2601.02868'
source_url: https://arxiv.org/abs/2601.02868
tags:
- code
- memory
- context
- codemem
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes CodeMEM, an AST-guided dynamic memory management
  system designed to improve iterative repository-level code generation. The core
  idea is to use two specialized memory components: Code Context Memory dynamically
  maintains and updates repository context through AST-guided LLM operations, while
  Code Session Memory constructs a code-centric representation of interaction history
  and explicitly detects and mitigates forgetting through AST-based analysis.'
---

# CodeMEM: AST-Guided Adaptive Memory for Repository-Level Iterative Code Generation

## Quick Facts
- arXiv ID: 2601.02868
- Source URL: https://arxiv.org/abs/2601.02868
- Reference count: 16
- Key outcome: CodeMEM improves iterative repository-level code generation with 12.2% increase in instruction following accuracy, 11.5% improvement in session-level accuracy, and reduces interaction rounds by 2-3.

## Executive Summary
This paper introduces CodeMEM, an AST-guided adaptive memory system designed to enhance iterative repository-level code generation. The system addresses key challenges in maintaining context relevance and preventing forgetting across multi-turn code interactions through two specialized memory components. Code Context Memory dynamically manages repository context using AST-guided selection based on API intersections, while Code Session Memory constructs code-centric representations of interaction history with AST-based forgetting detection. Evaluated on CodeIF-Bench and CoderEval benchmarks, CodeMEM demonstrates substantial improvements in instruction accuracy, conversation accuracy, and forgetting rate reduction while maintaining competitive inference latency.

## Method Summary
CodeMEM employs a dual-memory architecture consisting of Code Context Memory and Code Session Memory to manage repository-level iterative code generation. Code Context Memory maintains repository context through AST-guided operations, using a selector that filters code blocks based on API intersection with generated code's external APIs. The memory uses a key-value representation with function signatures, attributes, and methods as keys. Code Session Memory constructs a code-centric representation of interaction history, organizing memory blocks around code units with diff-based modification notes linked by instruction similarity. The system uses AST-based analysis to detect and mitigate forgetting through contradictory change detection, where conflicting add-delete operations on the same AST nodes trigger LLM-guided regeneration.

## Key Results
- 12.2% increase in instruction following accuracy for current turn compared to baseline
- 11.5% improvement in session-level conversation accuracy (CA metric)
- Reduction of interaction rounds by 2-3 while maintaining competitive inference latency
- Substantial reduction in forgetting rate (IFR metric) as shown in Figure 4
- Token efficiency improvements through key-value code block representation (~30k tokens reduced)

## Why This Works (Mechanism)

### Mechanism 1: AST-Guided Context Selection via API Intersection
Code Context Memory filters repository context to only blocks whose APIs intersect with generated code's external APIs, improving relevance while reducing noise. After each round, the Selector extracts external APIs from generated code and retains only memory blocks where API intersection is non-empty, ensuring interface-level validity while preserving semantically related implementation patterns.

### Mechanism 2: AST-Based Forgetting Detection via Contradictory Change Analysis
Code Session Memory detects forgetting by identifying AST-node-level contradictions between current changes and historical modifications. For each candidate memory block, the Detector computes conflict scores based on contradictory add-delete operations on the same AST nodes, triggering LLM-guided regeneration when conflicts are detected.

### Mechanism 3: Code-Centric Session Memory with Linked Modification Sequences
The session memory organizes interaction history around code units with diff-based modification notes, linked by instruction similarity. Each memory block stores instruction, code, diff, and note, with blocks for the same function forming sequences linked across sequences by instruction similarity. This provides compact yet informative session representation that captures change rationale.

## Foundational Learning

- **Abstract Syntax Trees (ASTs) for Code Structure**: Essential for understanding how both context selection and forgetting detection operate on AST nodes rather than raw text. Understanding function/class boundaries, API calls, and node-level diffs is fundamental to the system's operation.

- **Incremental Code Diffs (Δadd, Δdel)**: Critical for understanding how the conflict detector compares current diffs against historical diffs to find contradictions. This concept enables the detection of forgetting through analysis of code change patterns.

- **Multi-Turn Instruction Following Evaluation**: Necessary for interpreting the paper's metrics (IA, CA, IFR) which differ from single-turn Pass@k evaluations. Understanding these metrics is crucial for evaluating iterative code generation performance.

## Architecture Onboarding

- **Component map**: Repository-level code blocks → AST-guided Selector (API intersection filtering) → Code Context Memory → Generation → Session memory update → AST-based Detector (conflict analysis) → LLM regeneration if conflicts detected

- **Critical path**: Initial instruction → LLM decides context update (ADD/KEEP) → Code generation with context + session memory → Post-generation: Selector filters context, Detector checks for conflicts → If conflicts detected → LLM regeneration; else → output

- **Design tradeoffs**: Key-value representation reduces tokens but requires accurate key extraction; similarity threshold τ=0.95 is conservative; LLM-dependent decisions introduce latency and potential hallucination; Detector adds 17.7s inference time for forgetting mitigation

- **Failure signatures**: Over-pruned context leading to IA drops; false conflict detection flagging legitimate refactoring; note propagation errors from incorrect modification notes; non-functional requirement struggles in later rounds

- **First 3 experiments**:
  1. Reproduce Table 1 ablations on CodeIF-Bench to validate 3.6-4.4% IA degradation claims and verify CA degradation in later rounds
  2. Stress test Detector false positive rate with synthetic multi-turn dialogues containing legitimate reversions
  3. Measure token efficiency for key-value context representation vs. full-text baselines to validate ~30k token reduction

## Open Questions the Paper Calls Out

- **Limited Evaluation Scenarios**: The efficacy has not been validated on longer interaction rounds and more intricate conversational scenarios, as the current evaluation is limited to approximately 9 rounds.

- **Efficient Forgetting Handling**: Exploring more efficient mechanisms to handle contradictions is identified as future work, as the current mechanism requires additional inference calls creating trade-offs between reliability and efficiency.

- **LLM Decision Reliability**: The system's reliance on LLM for decision-making may lead to erroneous decisions and hallucinations, with no fail-safe if the LLM overlooks pertinent context.

- **Cross-Language Applicability**: The methodology relies exclusively on Python's AST library and Python repositories, raising questions about effectiveness for languages with different syntactic structures.

## Limitations

- **Missing implementation details**: Complete LLM prompt templates for context update decisions, note generation, and conflict resolution are not provided, making faithful reproduction challenging.

- **Computational overhead**: AST-based Selector and Detector components add significant latency (17.7s for Detector alone), with practical deployment tradeoffs not fully characterized.

- **Generalizability concerns**: Evaluation focuses on Python repositories and specific instruction-following tasks, with uncertain transferability to other languages and open-ended generation tasks.

## Confidence

- **High confidence** in the core architectural innovation: The dual-memory approach with AST-guided operations represents a novel and well-motivated solution to repository-level iterative code generation.
- **Medium confidence** in empirical results: Substantial improvements are reported and supported by ablation studies, but evaluation setup may not capture all real-world scenarios.
- **Low confidence** in practical deployment feasibility: Without complete implementation details, reproducing the system's behavior is challenging, and LLM dependency introduces variability risks.

## Next Checks

1. **Reconstruct and test LLM prompt templates**: Build complete prompts for context update decisions, session note generation, and conflict resolution using partial information from Appendix D, validating consistent behavior across diverse scenarios.

2. **Measure false positive/false negative rates in conflict detection**: Systematically evaluate the AST-based forgetting detector on synthetic multi-turn dialogues to quantify precision, recall, and F1-score, assessing whether the 17.7s inference overhead provides net benefit.

3. **Cross-language AST mechanism validation**: Implement CodeMEM for a non-Python language (e.g., Java or JavaScript) and evaluate on a comparable iterative code generation benchmark to validate generalization beyond Python's AST structure.