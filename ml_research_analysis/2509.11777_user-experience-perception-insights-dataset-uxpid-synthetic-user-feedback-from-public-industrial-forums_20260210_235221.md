---
ver: rpa2
title: 'User eXperience Perception Insights Dataset (UXPID): Synthetic User Feedback
  from Public Industrial Forums'
arxiv_id: '2509.11777'
source_url: https://arxiv.org/abs/2509.11777
tags:
- user
- requirements
- dataset
- software
- topic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces UXPID, a dataset of 7,130 synthetic user
  feedback branches from industrial automation forums. The dataset is enriched with
  LLM-annotated UX insights, severity ratings, sentiment scores, and topic classifications,
  making it suitable for training NLP models in requirements engineering and user
  experience analysis.
---

# User eXperience Perception Insights Dataset (UXPID): Synthetic User Feedback from Public Industrial Forums

## Quick Facts
- arXiv ID: 2509.11777
- Source URL: https://arxiv.org/abs/2509.11777
- Reference count: 25
- Synthetic dataset of 7,130 user feedback branches from industrial automation forums with LLM-annotated UX insights

## Executive Summary
This paper introduces UXPID, a dataset of 7,130 synthetic user feedback branches from industrial automation forums. The dataset is enriched with LLM-annotated UX insights, severity ratings, sentiment scores, and topic classifications, making it suitable for training NLP models in requirements engineering and user experience analysis. Each JSON record includes anonymized comments, metadata, and structured insights derived from conversation summaries. The authors validated the dataset using DistilBERT across classification tasks, achieving F1 scores between 0.61–0.74 for topic and sentiment classification.

## Method Summary
The dataset was constructed by extracting user feedback from public industrial automation forums and processing it through LLMs to generate synthetic conversations with structured annotations. The LLM-generated insights include UX perception analysis, severity ratings, sentiment classification, and topic categorization. The dataset preserves privacy through anonymization while maintaining the conversational structure and technical context of the original forum discussions.

## Key Results
- Dataset contains 7,130 synthetic feedback branches with structured annotations
- Achieved F1 scores of 0.61–0.74 for topic and sentiment classification using DistilBERT
- Provides a privacy-preserving alternative to real user feedback for training NLP models

## Why This Works (Mechanism)
The dataset leverages LLM capabilities to generate synthetic user feedback that preserves the essential characteristics of real forum discussions while avoiding privacy concerns. By annotating each conversation branch with structured UX insights, the dataset creates a rich training environment for models that need to understand user sentiment, topic relevance, and severity levels in technical contexts.

## Foundational Learning
- NLP classification techniques: Required for understanding how DistilBERT was applied to validate the dataset
- Privacy-preserving data synthesis: Important for balancing data utility with user privacy protection
- UX analysis methodologies: Needed to interpret the structured annotations and their applicability to real-world scenarios
- Industrial automation domain knowledge: Helpful for contextualizing the technical discussions in the dataset

## Architecture Onboarding
Component map: Forum data extraction -> LLM synthesis -> Annotation generation -> JSON structuring
Critical path: Raw forum data -> LLM processing -> Structured JSON output with annotations
Design tradeoffs: Synthetic data vs. authentic user feedback; LLM annotation accuracy vs. privacy preservation
Failure signatures: LLM hallucinations in annotations; loss of contextual nuance during anonymization
First experiments: 1) Test DistilBERT classification on topic labels; 2) Validate sentiment annotation accuracy; 3) Assess severity rating consistency

## Open Questions the Paper Calls Out
None

## Limitations
- Synthetic nature may not capture authentic user experience nuances
- LLM-generated annotations could introduce biases and hallucinations
- Domain specificity to industrial automation may limit generalizability

## Confidence
- Dataset utility for NLP training: High
- LLM annotation accuracy: Low
- Claims about addressing data scarcity: Medium

## Next Checks
1. Compare LLM-generated annotations against human-labeled subsets to quantify annotation quality and bias
2. Test dataset transferability to non-industrial domains through cross-domain classification experiments
3. Evaluate model performance using UXPID versus traditional user feedback datasets on real-world UX analysis tasks