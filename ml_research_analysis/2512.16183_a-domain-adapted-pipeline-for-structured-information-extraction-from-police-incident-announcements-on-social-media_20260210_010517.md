---
ver: rpa2
title: A Domain-Adapted Pipeline for Structured Information Extraction from Police
  Incident Announcements on Social Media
arxiv_id: '2512.16183'
source_url: https://arxiv.org/abs/2512.16183
tags:
- extraction
- information
- police
- data
- structured
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed a domain-adapted pipeline for structured information
  extraction from police incident announcements on social media. The pipeline combined
  task-specific prompt engineering with LoRA-based fine-tuning of the Qwen2.5-7B model
  to extract 15 key fields from Chinese Weibo police briefings.
---

# A Domain-Adapted Pipeline for Structured Information Extraction from Police Incident Announcements on Social Media

## Quick Facts
- **arXiv ID:** 2512.16183
- **Source URL:** https://arxiv.org/abs/2512.16183
- **Reference count:** 0
- **Primary result:** Developed a pipeline combining LoRA fine-tuning and prompt engineering to extract 15 structured fields from Chinese police Weibo posts, achieving high accuracy on mortality detection and location extraction.

## Executive Summary
This study presents a domain-adapted pipeline for extracting structured information from police incident announcements on Chinese social media platform Weibo. The approach combines task-specific prompt engineering with LoRA-based fine-tuning of the Qwen2.5-7B model to extract 15 key fields including location, event type, and impact metrics. Trained on a manually annotated dataset of 4,933 instances, the pipeline achieved 98.36% accuracy for mortality detection, 95.31% exact match rate for fatality counts, and 95.54% for province-level location extraction. The results demonstrate that parameter-efficient fine-tuning with carefully engineered prompts can enable mid-sized models to match or exceed the performance of larger models in specialized structured extraction tasks.

## Method Summary
The pipeline uses LoRA fine-tuning on Qwen2.5-7B with rank-decomposition matrices to adapt the base model to police briefing terminology. A rigid system prompt enforces JSON schema compliance for 15 structured fields including location, event characteristics, and impact assessment. The training data consists of 4,933 manually annotated instances using a dual-verification process achieving 94% inter-annotator agreement. Training was conducted with LLaMA-Factory using 60 epochs, learning rate 2e-4, and max sequence length 1024, with 5-fold cross-validation.

## Key Results
- **Mortality Detection:** 98.36% accuracy for detecting whether fatalities occurred
- **Fatality Count Extraction:** 95.31% exact match rate for extracting number of deaths
- **Location Extraction:** 95.54% accuracy for extracting province-level locations
- **Overall Performance:** Fine-tuned model outperformed base and instruction-tuned models on objective extraction tasks

## Why This Works (Mechanism)

### Mechanism 1: Low-Rank Adaptation (LoRA) for Domain Alignment
- **Claim:** LoRA fine-tuning induces domain-specific syntactic and semantic alignment more effectively than general instruction tuning
- **Mechanism:** Freezes pre-trained weights and injects trainable rank-decomposition matrices to adjust latent space for mapping informal police terminology to structured ontologies
- **Core assumption:** Task-specific updates reside in a low-rank intrinsic dimension that can be captured by a small number of parameters
- **Evidence anchors:** LoRA outperformed base and instruction-tuned models; methodology described with W₀ + ΔW = W₀ + BA factorization

### Mechanism 2: Prompt-Enforced Schema Constraint
- **Claim:** Rigid system prompts force generative models to prioritize syntactic compliance over creative continuation
- **Mechanism:** System prompt defines immutable role and strictly defines output schema (JSON with specific keys), channeling probability distribution to favor JSON structure tokens
- **Core assumption:** Base model has sufficient instruction-following capability to adhere to structural rules when processing noisy input
- **Evidence anchors:** Base models failed JSON schema compliance while LoRA/prompted versions produced schema-compliant outputs; neighbor paper supports prompt strategies for social media analysis

### Mechanism 3: Task-Specific Smoothing via Manual Annotation
- **Claim:** High consistency results from reduction of label noise during training via high inter-annotator agreement
- **Mechanism:** Dual-verification process where two annotators label data and third resolves conflicts, creating gold standard signal that trains LoRA adapters
- **Core assumption:** Semantic boundaries in codebook are stable and reproducible across dataset
- **Evidence anchors:** High-quality manually annotated dataset of 4,933 instances; dual-verification process with 94% Kappa resolution

## Foundational Learning

- **Parameter-Efficient Fine-Tuning (PEFT)**
  - **Why needed:** Adapt 7B parameter model to niche domain without computational costs of full fine-tuning
  - **Quick check:** Does LoRA method modify pre-trained weights W₀ directly, or add parallel layers?

- **JSON Schema Enforcement**
  - **Why needed:** Goal is structured data analysis, not reading natural text; model must output parsable code
  - **Quick check:** Why use "System Prompt" for JSON structure rather than just asking in "User Prompt"?

- **Exact Match Rate (EMR) vs. Cosine Similarity**
  - **Why needed:** Different fields require different error metrics; numbers require exactness, descriptive text allows semantic similarity
  - **Quick check:** Which metric should be used for evaluating extraction of "Province" names?

## Architecture Onboarding

- **Component map:** Weibo Crawler → OCR Engine → Regex Cleaner → Length Filter → Manual double-verification → Qwen2.5-7B Base + LoRA Adapters → JSON Validator

- **Critical path:** Prompt design. If prompt does not strictly define 15 keys and Event Type Coding Table, model will hallucinate fields or return unstructured text

- **Design tradeoffs:** Small fine-tuned vs. large API models - trade general reasoning capability for rigid reliability and lower inference cost

- **Failure signatures:**
  - Hallucinated Hierarchy: Model selects sub-prefectural location as "City"
  - Literal Interpretation: Model classifies "network" mentions as "Cybercrime" incorrectly
  - Format Drift: Model generates conversational text instead of JSON

- **First 3 experiments:**
  1. Zero-shot Baseline: Run raw police text through base model with JSON prompt to verify format drift failure rate
  2. LoRA Rank Sensitivity: Train adapters with rank r=8 vs r=64 to see if "Illegal Means" extraction improves
  3. Subjectivity Threshold: Compare fine-tuned model vs large API model on "Social Impact" field to quantify gap in subjective reasoning

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can reinforcement learning integration with LoRA fine-tuning improve performance on tasks requiring subjective judgment?
- **Basis:** Future research directions could integrate fine-tuning with reinforcement learning to enhance model robustness
- **Why unresolved:** Fine-tuned model achieved only 68.18% accuracy on social impact assessment versus 88.86-91.6% for full-parameter models
- **Evidence needed:** Empirical comparison of LoRA-only vs LoRA+RL training on same dataset, measuring accuracy gains on social impact

### Open Question 2
- **Question:** How can model hallucinations and biases be mitigated in case-type classification requiring legal domain expertise?
- **Basis:** Future research should investigate discriminative capabilities of LLMs across case types to mitigate hallucinations and biases
- **Why unresolved:** Error analysis revealed models over-generalized charges and lacked legal expertise to differentiate crime types
- **Evidence needed:** Per-category precision/recall analysis across 11 case-type codes with qualitative error categorization

### Open Question 3
- **Question:** How well does fine-tuned compact model generalize to police announcements from different time periods, regions, or platforms beyond Weibo?
- **Basis:** Generalization capabilities were not thoroughly validated, constraining applicability beyond specific dataset
- **Why unresolved:** Dataset limited to Weibo posts from 2019-2020 and 31 provincial regions with no out-of-distribution testing
- **Evidence needed:** Zero-shot or few-shot evaluation on police briefings from 2021-2024, non-Weibo sources, or underrepresented regions

## Limitations

- **LoRA Configuration Ambiguity:** Critical hyperparameters including rank, alpha, and dropout rate not specified, making exact reproduction challenging
- **Dataset Accessibility:** Promised dataset release but no direct access link provided, preventing independent verification of quality and representativeness
- **Comparative Benchmark Scope:** Performance comparisons limited to specific model families, potentially limiting generalizability of claims about mid-sized models outperforming larger ones

## Confidence

- **High Confidence (90-100%):** Fundamental claim that LoRA fine-tuning with prompt engineering achieves high accuracy in structured extraction tasks from police social media posts
- **Medium Confidence (70-89%):** Assertion that parameter-efficient fine-tuning enables mid-sized models to match or exceed larger models for objective extraction tasks
- **Low Confidence (0-69%):** Generalizability of approach to other domains or languages without modification

## Next Checks

1. **LoRA Sensitivity Analysis:** Systematically vary LoRA rank parameter (r=8, 16, 32, 64) to determine minimum rank required for optimal performance on most challenging extraction tasks

2. **Cross-Domain Transferability:** Apply trained pipeline to police social media posts from different jurisdiction or language to test robustness of domain adaptation

3. **Annotation Quality Impact:** Conduct ablation study removing dual-verification annotation process to quantify impact of high inter-annotator agreement on final model performance