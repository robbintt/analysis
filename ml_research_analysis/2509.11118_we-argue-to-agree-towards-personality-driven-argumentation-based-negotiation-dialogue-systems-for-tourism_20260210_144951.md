---
ver: rpa2
title: 'We Argue to Agree: Towards Personality-Driven Argumentation-Based Negotiation
  Dialogue Systems for Tourism'
arxiv_id: '2509.11118'
source_url: https://arxiv.org/abs/2509.11118
tags:
- negotiation
- dialogue
- package
- traveler
- personality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a novel task for generating personality-driven\
  \ argumentation-based negotiation dialogues in the tourism domain, along with a\
  \ dataset of over 8,000 high-quality conversations generated using LLMs. The proposed\
  \ PACT dataset incorporates three personality profiles\u2014Argumentation, Preference,\
  \ and Buying Style\u2014to simulate realistic negotiation scenarios."
---

# We Argue to Agree: Towards Personality-Driven Argumentation-Based Negotiation Dialogue Systems for Tourism

## Quick Facts
- **arXiv ID:** 2509.11118
- **Source URL:** https://arxiv.org/abs/2509.11118
- **Reference count:** 40
- **Primary result:** Proposed PACT dataset and fine-tuned LLMs achieve strong performance in generating personalized, rational, and contextually accurate argumentation-based negotiation dialogues for tourism.

## Executive Summary
This paper introduces a novel task for generating personality-driven argumentation-based negotiation dialogues in the tourism domain. The authors propose the PACT dataset containing over 8,000 high-quality conversations generated using LLMs, incorporating three domain-specific personality profiles: Argumentation, Preference, and Buying Style. Through extensive experiments, they demonstrate that fine-tuned LLMs, especially when incorporating background knowledge, personality profiles, and dialog act information, significantly outperform pre-trained models. The work provides a foundation for advancing personalized and reasoning-capable negotiation dialogue systems in tourism.

## Method Summary
The authors introduce the PACT dataset generated using Gemini-1.5-Flash with multi-profile personality modeling. The framework employs a structured ABN Pathway Encoding with 23 dialog acts to guide negotiation flows. Fine-tuning is performed using a multi-task learning approach (PR, DAP, RG) with LoRA adaptation on Vicuna-7b, incorporating RAG-based knowledge retrieval for factual grounding. The system conditions responses on predicted personality profiles and dialog acts, validated through comprehensive filtering (GCQE, PCE, NEE, AEE, TE) and extensive human evaluation across 9 metrics.

## Key Results
- FT-Ours (Vicuna) achieves 73.9% P-ACC, a 27.2% improvement over FT-Vanilla
- FEQA score reaches 52.74% for FT-Ours, reducing hallucination compared to baseline
- Human evaluation shows FT-Ours achieves 77.98% faithfulness and 70.43% personalization relevance
- Fine-tuned models significantly outperform pre-trained models across all evaluation metrics

## Why This Works (Mechanism)

### Mechanism 1: Multi-Profile Personality Modeling for Negotiation Behavior
Three domain-specific personality profiles (Argumentation, Preference, Buying Style) jointly shape negotiation trajectories more effectively than monolithic personality frameworks. Argumentation Profile controls persuasive stance, Preference Profile determines tourism-specific priorities, and Buying Style Profile governs price-quality tradeoffs. These are randomly sampled and combined during dataset generation, creating diverse negotiation scenarios.

### Mechanism 2: Structured Dialog Act Sequencing via ABN Pathway Encoding
Pre-defining 23 ABN-specific dialog acts and encoding their transition patterns constrains generation to rational, goal-directed negotiation flows. The framework simulates negotiator behavior using probability distributions over amenities and normal distributions for budget/tolerance limits, following structured progression through greeting, preference elicitation, information exchange, and negotiation phases.

### Mechanism 3: Multi-Task Learning with RAG for Factual Grounding
Joint training on PR, DAP, and RG tasks with RAG-based knowledge retrieval produces more faithful, personality-aligned, and contextually appropriate responses. The model shares dialogue context encoding across tasks, and during inference, predicted personality and dialog act are fed back as conditioning signals. RAG retrieves relevant package details via BERT embeddings and cosine similarity, grounding responses in factual amenities/prices.

## Foundational Learning

- **Concept: Argumentation-Based Negotiation (ABN)**
  - **Why needed here:** The entire framework builds on ABN principles—exchanging justifications, critiques, and persuasive arguments rather than simple offer-counteroffer dynamics.
  - **Quick check question:** Can you explain why ABN differs from game-theoretic negotiation, and why "Justify-price" is distinct from "Negotiate-price-increase"?

- **Concept: Multi-Task Learning (MTL) with Shared Representations**
  - **Why needed here:** The paper's FT-Ours setup relies on MTL where PR, DAP, and RG share context encoders. Understanding how gradient signals from different tasks interact is essential for debugging why FT-Ours outperforms FT-Vanilla.
  - **Quick check question:** If PR task loss decreases but RG quality degrades, what might be happening in the shared representation layer?

- **Concept: Retrieval-Augmented Generation (RAG)**
  - **Why needed here:** RAG grounds responses in actual package data (amenities, prices), reducing hallucination. Understanding embedding-based retrieval and fallback mechanisms is critical for reproducing results.
  - **Quick check question:** How would you handle a traveler requesting an amenity not in any package—what should the fallback behavior be?

## Architecture Onboarding

- **Component map:** PACT Generation (Gemini-1.5-Flash) → ABN Pathway Encoding → PACT Filtering (GPT-4 MoE) → Fine-tuning (FT-Ours) → Inference (Vicuna-7b with LoRA)
- **Critical path:** Dataset quality hinges on filtering pipeline; if PCE (Personality Consistency Expert) is too lenient, downstream PR task becomes impossible. Monitor survival rates at each filtering step.
- **Design tradeoffs:** Synthetic vs. human data enables scale but risks LLM biases; profile granularity vs. data sparsity creates uneven distribution; concession aggressiveness varies by budget scenario.
- **Failure signatures:** Low P-ACC with high D-ACC indicates personality conditioning failure; high perplexity with low FEQA suggests RAG retrieval issues; repetitive utterances indicate LLM overfitting to prompt templates.
- **First 3 experiments:**
  1. Ablate personality profiles: Train FT-Ours with only Argumentation Profile, only Preference Profile, etc.
  2. Filtering threshold sensitivity: Vary GCQE/PCE/NEE/AEE/TE thresholds to find quality-quantity tradeoff.
  3. No-RAG baseline: Disable RAG retrieval to quantify hallucination reduction from grounding.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does modeling multi-faceted personalities, which reflect combinations of traits rather than single dominant profiles, impact the performance and realism of negotiation dialogue systems?
- Basis in paper: [explicit] The Limitations section states that the current approach models traveler personality using a single dominant trait and suggests that "Future work could explore incorporating multi-faceted personalities that reflect combinations of traits."
- Why unresolved: The current PACT dataset assigns distinct profiles to ensure balance, which oversimplifies the complexity of real human behavior where traits often coexist.
- What evidence would resolve it: A comparative study measuring user satisfaction and negotiation success rates between agents trained on single-trait profiles versus those trained on a modified dataset featuring blended personality profiles.

### Open Question 2
- Question: Can the current argumentation-based negotiation framework be effectively extended to support multi-session dialogues where interactions occur iteratively over time?
- Basis in paper: [explicit] The Limitations section notes that the current framework models negotiations as self-contained sessions and acknowledges that "Extending our framework to support such multi-session dialogues represents a promising future direction."
- Why unresolved: Real-world negotiations, particularly in tourism, often span multiple interactions, whereas the current methodology assumes a fluent, continuous conversation flow without breaks or external interruptions.
- What evidence would resolve it: Successful implementation of a memory mechanism that retains context (user preferences, previous offers) across distinct, separated dialogue sessions in a longitudinal user study.

### Open Question 3
- Question: Can weak supervision techniques or additional prompt controls significantly improve the controllability and consistency of synthetic negotiation data compared to standard prompting?
- Basis in paper: [explicit] The Limitations section highlights that prompting is an "uncontrolled generation process" and suggests "Future research could explore incorporating additional controls in the prompt or employing weak supervision techniques... to further improve the quality of synthetic data."
- Why unresolved: The dataset generation relies heavily on the LLM's adherence to prompts without strict enforcement mechanisms, leading to potential quality variations that manual filtering cannot fully catch.
- What evidence would resolve it: Quantitative analysis showing a reduction in logical inconsistencies and an increase in adherence to argumentation structures in datasets generated via weak supervision compared to the current PACT generation pipeline.

## Limitations
- Dataset is entirely LLM-generated rather than human-annotated, raising concerns about naturalness and bias propagation
- The 23 ABN dialog acts may not capture all negotiation behaviors, particularly emotional or deceptive tactics
- Personality profile decomposition assumes orthogonality between dimensions, but real-world correlations could reduce effectiveness

## Confidence
- **High confidence:** Multi-task learning framework with RAG grounding effectively reduces hallucination (FEQA improvements, human evaluation scores)
- **Medium confidence:** Three-profile personality modeling significantly improves personalization (P-ACC improvements, human evaluation), though real-world correlations remain untested
- **Low confidence:** Specific contribution of each personality profile component to overall performance, as ablation studies for individual profiles are not provided

## Next Checks
1. **Profile Correlation Analysis:** Analyze PACT dataset for correlations between three personality profiles and measure impact on downstream task performance
2. **Human Evaluation on Synthetic vs. Real Data:** Compare PACT-generated conversations against real human negotiation dialogues in tourism domain
3. **Stress Test RAG Grounding:** Systematically test RAG retrieval failure modes by querying for non-existent amenities or extreme price points