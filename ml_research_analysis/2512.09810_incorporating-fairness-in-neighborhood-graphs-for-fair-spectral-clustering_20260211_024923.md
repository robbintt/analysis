---
ver: rpa2
title: Incorporating Fairness in Neighborhood Graphs for Fair Spectral Clustering
arxiv_id: '2512.09810'
source_url: https://arxiv.org/abs/2512.09810
tags:
- fair
- clustering
- graph
- neighborhood
- balance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of bias in traditional graph clustering
  methods, particularly in spectral clustering, where unfair graph constructions can
  perpetuate disparities. The authors introduce novel approaches for constructing
  fair k-nearest neighbor (kNN) and fair epsilon-neighborhood graphs that proactively
  enforce demographic parity during graph formation.
---

# Incorporating Fairness in Neighborhood Graphs for Fair Spectral Clustering

## Quick Facts
- arXiv ID: 2512.09810
- Source URL: https://arxiv.org/abs/2512.09810
- Reference count: 40
- Primary result: Fair graph construction methods achieve 15-25% improvement in Balance score compared to baselines while maintaining competitive clustering quality

## Executive Summary
This paper addresses bias in spectral clustering by introducing novel approaches for constructing fair k-nearest neighbor and fair epsilon-neighborhood graphs. The authors proactively enforce demographic parity during graph formation by ensuring proportional representation of sensitive groups in each node's neighborhood. Their framework operates as a pre-processing step that doesn't require modifications to the spectral clustering algorithm, making it easy to integrate into existing pipelines. Experimental results on synthetic and real-world datasets demonstrate significant improvements in fairness metrics while maintaining competitive clustering quality.

## Method Summary
The method constructs fair kNN and epsilon-neighborhood graphs by enforcing demographic parity constraints during neighborhood selection. For kNN, each node's neighborhood must satisfy |different-group neighbors|/|same-group neighbors| ≥ α (typically 0.8). This is achieved by iteratively replacing the farthest same-group neighbor with the nearest different-group candidate from an expanded pool. For epsilon-neighborhoods, density-reachable different-group nodes are added when neighborhoods violate fairness constraints. The fair adjacency matrix is then used with standard spectral clustering (eigenvector decomposition of Laplacian, followed by k-means), requiring no internal algorithm modifications.

## Key Results
- Fair epsilon-SC achieves Balance of 0.471 on Adult dataset vs baseline 0.333
- Fair kNN-SC achieves Balance of 0.449 on Bank dataset vs SFC's 0.442, knn-FSC's 0.438, and epsilon-FSC's 0.301
- Methods outperform current baselines across 3 synthetic, 7 real-world tabular, and 3 real-world image datasets
- Fair graph construction maintains competitive NCut and Silhouette Score while improving fairness metrics

## Why This Works (Mechanism)

### Mechanism 1: Constrained Neighborhood Composition
Enforcing demographic parity at the neighborhood level propagates fairness to downstream clustering without algorithm modification. Each node's neighborhood must satisfy |N*(vi) ∩ D(vi)| / |N*(vi) ∩ S(vi)| ≥ α, ensuring cross-group connections in local topology that influence Laplacian eigenvectors. Core assumption: Topological fairness in graph structure causally determines fairness in spectral clustering outcomes. Break condition: If α is too high relative to data distribution, neighborhoods may include geometrically distant nodes, degrading clustering quality.

### Mechanism 2: Iterative Neighbor Replacement for Geometric-Fairness Tradeoff
Systematic replacement of worst same-group neighbors with best different-group candidates minimizes geometric distortion while satisfying fairness constraints. For kNN, identify s* = argmax_{xj ∈ same-group} ||xi - xj|| and replace with d* = argmin_{xj ∈ different-group candidates} ||xi - xj||. Core assumption: Candidate pool contains sufficient different-group nodes within reasonable geometric distance. Break condition: If k'/k ratio is insufficient or data is highly segregated, no valid replacement candidates exist within reasonable distance.

### Mechanism 3: Density-Preserving Fair Adjustment for ε-Neighborhoods
Using density reachability to select replacement nodes preserves local cluster structure better than pure geometric selection. When ε-neighborhood violates fairness, identify density-reachable nodes R from vi, then add r closest different-group nodes from R prioritized by smallest hop lengths. Core assumption: Density-reachable nodes belong to same underlying cluster structure even if from different sensitive groups. Break condition: If sensitive groups occupy distinct density regions, no valid density-reachable replacements exist.

## Foundational Learning

- **Spectral Clustering via Graph Laplacian**: Why needed: The paper modifies graph structure assuming standard spectral clustering workflow (L = D - A, eigenvector computation, k-means on embedding). Quick check: Can you explain why modifying adjacency matrix A affects the spectral embedding?
- **Demographic Parity / Balance in Clustering**: Why needed: The fairness condition directly operationalizes Balance—each cluster should mirror overall sensitive group proportions. Quick check: Given clusters C1 with 80 privileged/20 unprivileged and C2 with 20 privileged/80 unprivileged, what is the Balance score?
- **k-Nearest Neighbor Graph Construction Variants**: Why needed: The paper modifies standard kNN construction; understanding directed vs. mutual vs. fully-symmetrized variants is essential for implementation. Quick check: In a mutual kNN graph, if node A has B in its k-nearest but B does not have A in its k-nearest, is edge (A,B) included?

## Architecture Onboarding

- **Component map**: Input: Dataset X, sensitive labels s, parameters (k/ε, α) -> Base Graph Construction -> Fairness Evaluation -> Candidate Pool Generation -> Iterative Replacement -> Fair Adjacency Matrix -> Standard Spectral Clustering -> Output: Clusters with Balance scores
- **Critical path**: Component candidate pool generation and replacement logic are the novel contributions; bugs here cascade to all downstream metrics
- **Design tradeoffs**: Higher α → better Balance, potential NCut/Silhouette degradation; higher k'/k ratio → more replacement candidates, increased preprocessing time; choice between fair kNN vs. fair ε: kNN gives fixed neighborhood size, ε adapts to density but may have sparse neighborhoods
- **Failure signatures**: Balance remains low despite high α: Candidate pool exhausted; check group segregation in data; Silhouette Score drops dramatically: α too aggressive for data distribution; reduce α or increase k'; ε-neighborhood fails fairness check: Sparse regions have insufficient density-reachable nodes; increase ε or switch to kNN approach
- **First 3 experiments**: 1) Reproduce synthetic SBM baseline with n=1000, c=4 clusters, h=2 groups; 2) Parameter sensitivity analysis on Adult dataset with α ∈ {0.2, 0.4, 0.6, 0.8, 1.0}; 3) Ablation on candidate pool size for fair kNN with k' ∈ {k, 2k, 3k, 5k}

## Open Questions the Paper Calls Out

### Open Question 1
Does the current formulation ensure equitable representation among all distinct sensitive groups in a neighborhood, or does it merely enforce a binary "own vs. other" ratio? The definition risks allowing a node to satisfy the fairness constraint by connecting to only one specific out-group, potentially ignoring other minority groups in multi-group scenarios. Evidence: Experiments on datasets with >2 sensitive attributes measuring the specific distribution of each group within constructed neighborhoods.

### Open Question 2
How does the forced inclusion of cross-group neighbors impact geometric consistency and cluster validity in high-dimensional feature spaces? The method relies on replacing the "worst" same-group neighbor with the "best" different-group neighbor, which may force connections to nodes that are geometrically distant or irrelevant in high-dimensional spaces. Evidence: Theoretical analysis or empirical study showing change in average neighbor distance and Silhouette Score as dimensionality increases while maintaining constant fairness constraints.

### Open Question 3
Can this fair graph construction framework be effectively adapted for semi-supervised tasks like Graph Neural Networks (GNNs) without degrading node classification performance? While the method improves spectral clustering, modifying topology for fairness in GNNs might disrupt the message-passing mechanisms required for accurate node classification. Evidence: Applying fair kNN/Epsilon construction to GNN architectures (e.g., GCN, GAT) and evaluating both classification accuracy and fairness metrics.

## Limitations

- Candidate pool size k' is unspecified, critical for fair kNN performance
- Gaussian kernel bandwidth σ is unspecified, affects edge weights
- Trade-off curve between α and clustering quality is empirical, not theoretically bounded
- Generalization to higher-dimensional data beyond d=100 is untested

## Confidence

- **High**: Core mechanism of enforcing demographic parity at neighborhood level
- **Medium**: Geometric-fairness tradeoff via iterative replacement
- **Medium**: Density-preserving adjustment for ε-neighborhoods

## Next Checks

1. **Candidate pool sensitivity**: Test k' ∈ {1.5k, 2k, 3k} on Adult dataset; verify Balance stabilizes beyond certain ratio
2. **Extreme group imbalance**: Generate synthetic data with 90-10 sensitive group ratio; test if α=0.8 remains achievable without severe quality loss
3. **Runtime scalability**: Measure preprocessing time for n=10K, 50K, 100K on MNIST-USPS; confirm O(n log n) scaling holds