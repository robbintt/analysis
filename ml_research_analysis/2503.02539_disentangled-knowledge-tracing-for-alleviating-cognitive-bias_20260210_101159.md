---
ver: rpa2
title: Disentangled Knowledge Tracing for Alleviating Cognitive Bias
arxiv_id: '2503.02539'
source_url: https://arxiv.org/abs/2503.02539
tags:
- uni00000013
- knowledge
- student
- uni00000011
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper tackles cognitive bias in Knowledge Tracing (KT), which\
  \ causes overperformers to be under-challenged and underperformers to be overwhelmed\
  \ due to unbalanced question-concept distributions. The bias is traced to a confounder\u2014\
  the historical correct rate distribution\u2014that distorts student representation."
---

# Disentangled Knowledge Tracing for Alleviating Cognitive Bias

## Quick Facts
- arXiv ID: 2503.02539
- Source URL: https://arxiv.org/abs/2503.02539
- Reference count: 40
- Primary result: DisKT outperforms 16 baselines in AUC, ACC, and RMSE while significantly reducing cognitive bias (EKL scores) on 11 benchmarks and 3 synthetic datasets.

## Executive Summary
This paper addresses cognitive bias in Knowledge Tracing (KT), where unbalanced question-concept distributions lead to overperformers being under-challenged and underperformers being overwhelmed. The bias stems from a confounder—the historical correct rate distribution—that distorts student representation. The authors propose Disentangled Knowledge Tracing (DisKT), a causal model that separately tracks familiar and unfamiliar abilities, uses contradiction attention to mitigate guessing and mistaking, and integrates a variant of Item Response Theory for interpretability. Evaluated on 11 benchmarks and 3 synthetic datasets, DisKT demonstrates superior performance and significant bias alleviation.

## Method Summary
DisKT implements a causal intervention to eliminate the confounder effect of historical correct rates by disentangling student representations into familiar and unfamiliar branches. The model uses a Rasch embedding layer to incorporate question difficulty, a transformer encoder for knowledge extraction, and a contradiction attention mechanism to down-weight guessing and mistaking signals. A variant IRT prediction head explicitly accounts for student ability and question difficulty. The training objective includes a regularization term that enforces separation between familiar and unfamiliar representations.

## Key Results
- DisKT outperforms 16 baselines in AUC, ACC, and RMSE on 11 public benchmarks and 3 synthetic datasets
- Significant reduction in cognitive bias measured by lower EKL scores compared to all baselines
- Better shielding of guessing and mistaking effects, with higher shielding rates than baseline models

## Why This Works (Mechanism)

### Mechanism 1: Causal Intervention via Disentangled Representation
The paper identifies historical correct rate distribution as a confounder affecting both student features and predictions. DisKT performs approximate causal intervention by splitting student representation into familiar (correct responses) and unfamiliar (incorrect responses) branches, then subtracting their influence to isolate true knowledge state from historical bias.

### Mechanism 2: Contradiction Attention for Noise Shielding
Standard KT models are vulnerable to guessing on hard questions and mistaking on easy ones. DisKT uses a contradiction attention mechanism that detects these anomalies by comparing responses against concept difficulty and down-weights contradictory signals during knowledge extraction.

### Mechanism 3: Variant IRT for Interpretable Prediction
Instead of standard MLP prediction, DisKT uses a variant IRT layer that explicitly incorporates question difficulty and student ability differences. This forces predictions based on the distance between student ability and question difficulty, enhancing interpretability.

## Foundational Learning

- **Concept:** Confounders in Causal Inference
  - **Why needed here:** Understanding how a third variable influences both cause and effect is essential to grasp why historical correct rates create bias.
  - **Quick check question:** If students who get high scores also do easier questions, why can't we conclude that doing easy questions causes high scores?

- **Concept:** Item Response Theory (IRT)
  - **Why needed here:** DisKT uses IRT concepts in its prediction layer, requiring understanding of ability vs. difficulty relationships.
  - **Quick check question:** In standard IRT, if student ability is significantly lower than question difficulty, what is the predicted probability of a correct response?

- **Concept:** Transformer Self-Attention (Query-Key-Value)
  - **Why needed here:** The knowledge extractor relies on transformer encoders for processing interaction sequences.
  - **Quick check question:** In student interaction sequences, what does the "Query" represent vs. the "Key" when calculating attention weights?

## Architecture Onboarding

- **Component map:** Rasch Embeddings → Transformer Encoder → Contradictory Attention → Variant IRT Head
- **Critical path:** The Subtraction Operation (Eq. 13) implements the causal intervention. Without this step, the model reverts to standard Transformer-based KT.
- **Design tradeoffs:** Uses approximate causal effect via correct/incorrect separation rather than exact do-calculus for computational efficiency. Relies on threshold parameters for contradiction detection that may not generalize.
- **Failure signatures:** High EKL scores indicate causal intervention failure; continued cognitive overload in underperformers suggests confounder dominance; improved AUC with worsening EKL suggests overfitting biased data.
- **First 3 experiments:** 1) Ablation on synthetically biased data (ednet-high vs ednet-low) to test bias resilience; 2) Guessing/Mistaking rate comparison between DisKT and DisKT without contradiction attention; 3) Hyperparameter sensitivity analysis on contradiction thresholds.

## Open Questions the Paper Calls Out

### Open Question 1
How can critical points between simple and difficult questions be dynamically determined for individual students to improve familiar/unfamiliar ability separation?
- **Basis in paper:** [explicit] The conclusion lists this as a future avenue.
- **Why unresolved:** Current method uses heuristic classification based on historical response rates rather than personalized difficulty thresholds.
- **What evidence would resolve it:** A mechanism learning student-specific difficulty boundaries that demonstrates improved AUC or interpretability.

### Open Question 2
What additional fine-grained causal relations exist within the student-question interaction graph beyond the historical correct rate confounder?
- **Basis in paper:** [explicit] The conclusion calls for discovering more fine-grained causal relations.
- **Why unresolved:** Focuses on global confounder but suggests the causal graph could be refined with more specific variables.
- **What evidence would resolve it:** An extended causal graph identifying specific mediators (e.g., time-decay, prerequisites) that further reduce bias when intervened upon.

### Open Question 3
How can temporal dynamics of forgetting be integrated into the causal intervention framework to better model knowledge state evolution?
- **Basis in paper:** [explicit] The conclusion calls for exploring educational psychology concepts like forgetting.
- **Why unresolved:** Model uses contradiction attention but doesn't explicitly model forgetting curves or knowledge decay.
- **What evidence would resolve it:** An extension incorporating forgetting functions that results in lower RMSE on datasets with long time gaps.

### Open Question 4
To what extent does DisKT mitigate cognitive bias amplification in live Intelligent Tutoring System feedback loops compared to static evaluations?
- **Basis in paper:** [inferred] Introduction highlights bias amplification through recommendations, but experiments use static benchmarks.
- **Why unresolved:** Paper verifies on fixed datasets but doesn't evaluate behavior when model's own recommendations alter future data distributions.
- **What evidence would resolve it:** A simulation or online deployment study measuring EKL stability and accuracy over multiple recommendation cycles.

## Limitations
- Assumes historical correct rate is the primary confounder, potentially oversimplifying other factors like learning rate heterogeneity
- Contradiction attention relies on binary correctness masks that may not capture nuanced guessing/mistaking behaviors
- Variant IRT assumes learnable difficulty parameters accurately capture psychometric properties without validation against expert annotations

## Confidence
- **High:** Disentangled representation architecture and implementation details (Equations 12-13) are clearly specified and reproducible
- **Medium:** Contradiction attention effectiveness is empirically demonstrated but relies on threshold parameters that may not generalize
- **Low:** EKL scores as direct measures of "cognitive bias alleviation" assumes perfect metric-theoretical alignment requiring further validation

## Next Checks
1. Conduct ablation studies on the contradiction attention mechanism across datasets with varying guessing/mistaking rates to verify robustness
2. Test DisKT on datasets with known class imbalance distributions to quantify bias-alleviation performance under controlled conditions
3. Evaluate interpretability claims by comparing learned difficulty embeddings against expert-annotated question difficulties