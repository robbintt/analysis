---
ver: rpa2
title: 'Towards Accurate UAV Image Perception: Guiding Vision-Language Models with
  Stronger Task Prompts'
arxiv_id: '2512.07302'
source_url: https://arxiv.org/abs/2512.07302
tags:
- task
- prompt
- visual
- enhancement
- perception
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AerialVP, an agent framework for task prompt
  enhancement in UAV image perception, addressing the challenge of image-text alignment
  inconsistency in complex UAV imagery. The core method involves using an LLM-based
  Task Engine and a Tool Repository to analyze task prompts, select appropriate enhancement
  tools, and generate enriched prompts incorporating semantic, spatial position, and
  spatial relationship information.
---

# Towards Accurate UAV Image Perception: Guiding Vision-Language Models with Stronger Task Prompts

## Quick Facts
- arXiv ID: 2512.07302
- Source URL: https://arxiv.org/abs/2512.07302
- Reference count: 40
- Key outcome: Task prompt enhancement improves UAV visual grounding, reasoning, and QA accuracy by 15-45% across multiple VLMs

## Executive Summary
This paper addresses the challenge of image-text alignment inconsistency in UAV imagery by introducing AerialVP, an agent framework for task prompt enhancement. The approach leverages an LLM-based Task Engine and Tool Repository to analyze task prompts and generate enriched prompts incorporating semantic, spatial position, and spatial relationship information. Experiments on the newly introduced AerialSense benchmark demonstrate significant performance improvements across UAV visual grounding, reasoning, and question answering tasks, with GPT-4o's visual grounding accuracy increasing from 2.04% to 45.05%.

## Method Summary
AerialVP introduces a novel task prompt enhancement framework that uses an LLM-based Task Engine to analyze task prompts and select appropriate tools from a Tool Repository. The framework generates enriched prompts by incorporating semantic, spatial position, and spatial relationship information. The method is evaluated on the newly introduced AerialSense benchmark, which includes challenging UAV imagery scenarios. The approach shows consistent performance improvements across multiple VLMs, addressing the fundamental challenge of image-text alignment inconsistency in complex UAV imagery.

## Key Results
- GPT-4o's visual grounding accuracy increased from 2.04% to 45.05%
- Most VLMs showed consistent gains of 15-45% across visual grounding, reasoning, and QA tasks
- Experimental results validate the effectiveness of task prompt enhancement for UAV image perception

## Why This Works (Mechanism)
The framework works by leveraging LLM reasoning to decompose complex UAV tasks into actionable components, then using specialized tools to extract and integrate relevant spatial and semantic information. This systematic approach addresses the inherent complexity of UAV imagery where objects may be small, occluded, or contextually ambiguous.

## Foundational Learning
1. **Task Prompt Enhancement** - Why needed: UAV imagery contains complex spatial relationships and contextual ambiguities that standard prompts cannot capture. Quick check: Verify prompt enrichment adds specific spatial and semantic details beyond baseline prompts.

2. **Tool Repository Architecture** - Why needed: Different UAV perception tasks require different types of information extraction (semantic, spatial, relational). Quick check: Confirm each tool addresses a distinct aspect of UAV image analysis.

3. **Vision-Language Model Alignment** - Why needed: UAV images often contain multiple objects with complex relationships that challenge standard image-text alignment. Quick check: Test model performance on images with varying object densities and spatial configurations.

4. **LLM-based Task Analysis** - Why needed: Automated task decomposition enables scalable prompt enhancement without manual engineering. Quick check: Validate LLM's ability to correctly identify task requirements across diverse UAV scenarios.

## Architecture Onboarding

**Component Map**: User Query -> LLM Task Engine -> Tool Selection -> Tool Execution -> Prompt Enrichment -> VLM Processing

**Critical Path**: The LLM Task Engine analyzes the user query and selects appropriate tools from the Tool Repository. These tools extract semantic, spatial position, and spatial relationship information, which is then integrated into an enriched prompt for the VLM.

**Design Tradeoffs**: The framework trades computational overhead for accuracy improvements. Using an LLM for task analysis adds processing time but enables more sophisticated prompt engineering. The Tool Repository approach balances specificity with flexibility.

**Failure Signatures**: 
- Poor LLM reasoning leading to incorrect tool selection
- Tool execution failures when extracting spatial information from complex UAV scenes
- Over-enrichment causing prompt confusion rather than clarification

**First Experiments**:
1. Test baseline VLM performance on simple UAV visual grounding tasks
2. Evaluate enriched prompt performance on the same tasks
3. Compare computational overhead between standard and enhanced prompt processing

## Open Questions the Paper Calls Out
None

## Limitations
- Results primarily validated on a single dataset (AerialSense), limiting generalizability claims
- Methodology relies heavily on LLM-based task analysis, which may vary with different LLM choices
- No detailed analysis of computational overhead or real-time processing implications for UAV applications

## Confidence
- Task prompt enhancement universally benefits UAV visual perception (High)
- LLM-based task analysis effectiveness (Medium)
- Approach addresses image-text alignment inconsistency (Medium)

## Next Checks
1. Cross-dataset validation: Test AerialVP on at least three additional UAV image datasets to verify generalizability beyond AerialSense
2. Ablation study: Conduct detailed analysis of individual component contributions by testing models with selective tool activation (e.g., semantic only, spatial only)
3. Real-time performance evaluation: Measure end-to-end processing time and computational requirements for UAV deployment scenarios to assess practical viability