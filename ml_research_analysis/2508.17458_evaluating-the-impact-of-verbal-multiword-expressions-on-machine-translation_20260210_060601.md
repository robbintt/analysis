---
ver: rpa2
title: Evaluating the Impact of Verbal Multiword Expressions on Machine Translation
arxiv_id: '2508.17458'
source_url: https://arxiv.org/abs/2508.17458
tags:
- translation
- vmwe
- sentence
- machine
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents a comprehensive study on how verbal multiword\
  \ expressions (VMWEs) affect machine translation quality across eight state-of-the-art\
  \ MT systems and seven language pairs. The study evaluates three VMWE types\u2014\
  verbal idioms, verb-particle constructions, and light verb constructions\u2014using\
  \ both established VMWE datasets and WMT data, with reference-free quality estimation\
  \ and human direct assessment scores."
---

# Evaluating the Impact of Verbal Multiword Expressions on Machine Translation

## Quick Facts
- **arXiv ID:** 2508.17458
- **Source URL:** https://arxiv.org/abs/2508.17458
- **Reference count:** 40
- **Primary result:** VMWEs consistently degrade MT quality; degree correlates with non-compositionality; LLM paraphrasing improves translation of verbal idioms and verb-particle constructions.

## Executive Summary
This paper presents a comprehensive study on how verbal multiword expressions (VMWEs) affect machine translation quality across eight state-of-the-art MT systems and seven language pairs. The study evaluates three VMWE types—verbal idioms, verb-particle constructions, and light verb constructions—using both established VMWE datasets and WMT data, with reference-free quality estimation and human direct assessment scores. Results show VMWEs consistently degrade translation quality, with the degree of degradation correlating with non-compositionality: verbal idioms most affected, followed by verb-particle constructions, and light verb constructions least affected. To address this issue, the authors propose an LLM-based paraphrasing approach that replaces VMWEs with their literal equivalents prior to translation. Experimental results demonstrate significant quality improvements for verbal idioms and verb-particle constructions, validating the approach's effectiveness.

## Method Summary
The study employs a multi-stage pipeline: VMWE extraction using GPT-4o following PARSEME guidelines, LLM-based paraphrasing (Llama-3.3 70B) to replace VMWEs with literal equivalents, translation using eight MT systems, and evaluation using reference-free quality estimation metrics (MetricX-24 and xCOMET-QE). The approach tests three VMWE categories (verbal idioms, verb-particle constructions, light verb constructions) across seven language pairs, comparing translation quality of original VMWE sentences against paraphrased versions and non-VMWE control sentences.

## Key Results
- VMWEs degrade MT quality consistently across all tested systems and language pairs
- Degradation severity correlates with non-compositionality: verbal idioms > verb-particle constructions > light verb constructions
- LLM-based paraphrasing significantly improves translation quality for verbal idioms and verb-particle constructions
- Translation quality improvement (δmix) is consistently positive across all three VMWE categories
- Human direct assessment confirms automated QE results

## Why This Works (Mechanism)

### Mechanism 1: Non-Compositionality Gradient
The degradation of translation quality correlates with the degree to which an expression's meaning is opaque (non-compositional). Verbal idioms suffer the highest degradation because their meaning cannot be inferred from constituent tokens, forcing models to hallucinate or translate literally. Light verb constructions degrade the least because the noun often retains its literal semantic weight, making the phrase partially inferable. Core assumption: Current MT attention mechanisms distribute semantic focus across tokens, failing to treat fixed expressions as single semantic units.

### Mechanism 2: Paraphrasing as Semantic Normalization
Pre-processing text to replace VMWEs with literal equivalents improves translation quality by reducing ambiguity for the downstream MT system. An LLM (Llama-3.3 70B) converts non-literal phrases into literal ones. The MT system then translates the normalized input, avoiding the pitfall of literal translation of the idiom. Core assumption: The paraphrasing LLM preserves the semantic intent of the sentence while stripping the idiomatic structure; the MT system is more capable of translating the literal form accurately.

### Mechanism 3: Reference-Free Quality Estimation
Translation quality for complex linguistic phenomena can be reliably evaluated without human-generated reference translations using specific encoder-based metrics. Models like MetricX-24 and xCOMET-QE assess the semantic overlap and error severity between the source and the hypothesis translation directly. This allows evaluation on datasets where human references are unavailable or biased. Core assumption: The embeddings of the QE models capture semantic adequacy and fluency sufficiently to mimic human judgment for idiomatic content.

## Foundational Learning

- **Concept: Non-Compositionality in MWEs**
  - **Why needed here:** The paper categorizes VMWEs based on how much their meaning differs from their parts. Understanding this spectrum (Idiom > VPC > LVC) is essential to diagnosing why translation fails.
  - **Quick check question:** Does "take a walk" (LVC) degrade translation quality more or less than "kick the bucket" (VID), and why?

- **Concept: Reference-Free Quality Estimation (QE)**
  - **Why needed here:** The study relies on MetricX-24 and xCOMET to measure success without ground truth translations. Distinguishing these from reference-based metrics (like BLEU) is critical.
  - **Quick check question:** What two inputs does a reference-free QE model require to generate a score?

- **Concept: Paraphrasing for Data Augmentation/Normalization**
  - **Why needed here:** The proposed solution is not a new MT architecture, but a pre-processing step. You must understand how style/semantic transfer works to implement the intervention.
  - **Quick check question:** In the paper's pipeline, does the MT system see the original sentence or the paraphrase?

## Architecture Onboarding

- **Component map:** Extractor (GPT-4o) -> Normalizer (Llama-3.3 70B) -> Translator (8 MT Systems) -> Evaluator (MetricX-24 / xCOMET)
- **Critical path:** The accuracy of the Extractor limits the ceiling of the study; the Normalizer is the intervention point. If the extractor misses the idiom, the normalizer never triggers.
- **Design tradeoffs:**
  - Paraphrasing increases translation accuracy of the meaning but may strip cultural flavor or stylistic nuance of the original text.
  - Evaluation using QE metrics avoids the cost of human annotation but may inherit the biases of the QE model's training data.
- **Failure signatures:**
  - Literal Translation: "Dead to the world" translates as "physically deceased"
  - Mistranslation: Model outputs text in the wrong language
  - Semantic Drift: The paraphrase changes the meaning, leading to a correct translation of the wrong meaning
- **First 3 experiments:**
  1. Baseline Verification: Replicate the delta between VMWE and Non-VMWE sentences on a small subset using MetricX-24 to confirm quality degradation exists.
  2. Paraphrase Ablation: Run translation pipeline with paraphrasing step enabled vs. disabled for Verbal Idioms only. Measure δmix to confirm positive improvement.
  3. Extraction Validation: Test GPT-4o extractor on 50 manually labeled sentences to ensure correct distinction between VPCs and literal preposition usage.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can "deep paraphrasing" strategies effectively improve the translation of Light Verb Constructions (LVCs), given that current lexical substitution methods failed to yield gains?
- Basis in paper: Section 4.5 states that LVC paraphrasing resulted in "minor lexical substitution rather than a deep paraphrase" and concludes that "Paraphrasing the LVC phrase also does not improve the translation score."
- Why unresolved: The authors demonstrated that the specific LLM prompting strategy used was insufficient for LVCs, but they did not test alternative strategies that restructure the sentence more significantly (deep paraphrasing).
- What evidence would resolve it: Experimental results showing that complex restructuring prompts for LVCs lead to positive δmix scores in translation quality.

### Open Question 2
- Question: How can Machine Translation architectures be modified to internalize the handling of Verbal Multiword Expressions (VMWEs) without relying on external pre-processing steps?
- Basis in paper: The paper proposes a pipeline solution (LLM paraphrasing → MT) and concludes by highlighting "crucial limitations in current MT architecture," implying that the need for an external fix is a fundamental architectural deficit.
- Why unresolved: The study validates a workaround rather than solving the underlying representation issue within the MT models themselves.
- What evidence would resolve it: The development of a single-stage MT model that matches or exceeds the performance of the proposed pipeline system on VMWE datasets.

### Open Question 3
- Question: Does the translation of paraphrased verbal idioms result in a loss of stylistic nuance that is not captured by Quality Estimation (QE) metrics?
- Basis in paper: The evaluation relies on semantic similarity metrics (MetricX, xCOMET) and general human assessment, but does not explicitly measure if the "flavor" or register of the text is lost when idioms are replaced by literal text.
- Why unresolved: A literal translation of a paraphrased idiom may be semantically accurate (high QE score) but stylistically poor compared to a target-language idiom, a distinction the current methodology does not isolate.
- What evidence would resolve it: A targeted human evaluation assessing the "stylistic appropriateness" or "idiomaticity" of the translations generated via the paraphrasing pipeline versus direct translation.

## Limitations

- Reliance on automated extraction and evaluation methods may miss nuanced VMWEs or misclassify borderline cases
- Paraphrasing approach assumes perfect semantic preservation, but semantic drift remains a risk
- Reference-free QE metrics may harbor biases toward literal fluency over idiomatic adequacy
- Results may not generalize to colloquial or domain-specific language beyond the tested datasets

## Confidence

- **High Confidence:** The observed degradation pattern across VMWE types (VID > VPC > LVC) is well-supported by consistent QE and human DA scores across multiple language pairs.
- **Medium Confidence:** The effectiveness of the LLM-based paraphrasing approach is demonstrated but may not generalize to all VMWE types equally.
- **Low Confidence:** The generalizability of results to broader domains beyond the selected datasets remains uncertain.

## Next Checks

1. **Extraction Precision Validation:** Manually annotate 100 sentences from the EPIE dataset to verify GPT-4o's VMWE classification accuracy, particularly distinguishing LVCs from literal constructions.

2. **Paraphrase Semantic Drift Analysis:** Implement a semantic similarity check (e.g., Sentence-BERT) between original VMWE sentences and their paraphrased versions. Identify and categorize instances where the LLM alters meaning beyond the intended literalization.

3. **QE Model Bias Assessment:** Test the MetricX-24 and xCOMET models on a controlled set of sentences where the correct idiomatic translation is known. Measure whether the QE models penalize structurally divergent but semantically adequate translations.