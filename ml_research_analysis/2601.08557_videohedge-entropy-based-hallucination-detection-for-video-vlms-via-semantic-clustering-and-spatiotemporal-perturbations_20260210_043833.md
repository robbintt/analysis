---
ver: rpa2
title: 'VideoHEDGE: Entropy-Based Hallucination Detection for Video-VLMs via Semantic
  Clustering and Spatiotemporal Perturbations'
arxiv_id: '2601.08557'
source_url: https://arxiv.org/abs/2601.08557
tags:
- clustering
- semantic
- video
- hallucination
- vase
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces VideoHEDGE, a modular framework for detecting
  hallucinations in video-capable vision-language models (Video-VLMs). By generating
  multiple high-temperature answers from clean and perturbed video clips, clustering
  the outputs semantically, and measuring entropy over these clusters, VideoHEDGE
  provides reliability estimates for video question answering.
---

# VideoHEDGE: Entropy-Based Hallucination Detection for Video-VLMs via Semantic Clustering and Spatiotemporal Perturbations

## Quick Facts
- arXiv ID: 2601.08557
- Source URL: https://arxiv.org/abs/2601.08557
- Reference count: 40
- Introduces entropy-based framework for detecting hallucinations in video-capable vision-language models

## Executive Summary
VideoHEDGE is a modular framework designed to detect hallucinations in video vision-language models (Video-VLMs) by leveraging semantic clustering and spatiotemporal perturbations. The method generates multiple high-temperature answers from clean and perturbed video clips, clusters these outputs semantically, and measures entropy over the clusters to estimate answer reliability. Tested on the SoccerChat benchmark, VideoHEDGE's Vision-Amplated Semantic Entropy (VASE) achieves the highest ROC-AUC for hallucination detection, particularly with larger distortion budgets. The framework also shows that embedding-based clustering can match NLI-based clustering in performance while being computationally cheaper.

## Method Summary
VideoHEDGE operates by applying spatiotemporal perturbations to video clips and generating multiple high-temperature answers from both clean and perturbed inputs. These answers are then clustered semantically using either natural language inference (NLI) models or embedding distances. Entropy is calculated over these clusters to provide reliability estimates for video question answering. The framework's core innovation is the Vision-Amplified Semantic Entropy (VASE), which leverages the gap between clean and perturbed semantic distributions to detect hallucinations more effectively than baseline entropy measures.

## Key Results
- Vision-Amplified Semantic Entropy (VASE) achieves the highest ROC-AUC for hallucination detection on SoccerChat benchmark
- Embedding-based clustering matches NLI-based clustering in performance at far lower computational cost
- Domain fine-tuning reduces hallucination frequency but only modestly improves calibration

## Why This Works (Mechanism)
The framework works by exploiting the sensitivity of Video-VLMs to input perturbations. When a model hallucinates, its outputs tend to be inconsistent under minor visual changes, leading to higher entropy in the clustered answer space. By comparing the semantic distributions of clean and perturbed inputs, VideoHEDGE can identify unreliable answers. The use of high-temperature sampling increases answer diversity, making entropy a more reliable indicator of model uncertainty.

## Foundational Learning
- **Semantic Clustering**: Groups similar model outputs to identify consistent versus inconsistent answers. Why needed: To quantify answer reliability by measuring output consistency under perturbation. Quick check: Verify cluster purity and stability across multiple perturbation runs.
- **Entropy-Based Reliability Estimation**: Uses entropy as a proxy for uncertainty. Why needed: High entropy indicates low confidence or potential hallucination. Quick check: Correlate entropy scores with known hallucination labels.
- **Spatiotemporal Perturbations**: Applies controlled distortions to video frames and temporal order. Why needed: To probe model robustness and expose hallucinations. Quick check: Measure perturbation impact on answer consistency.

## Architecture Onboarding

**Component Map:**
Video Input -> Perturbation Module -> Video-VLM Inference (multiple samples) -> Answer Clustering -> Entropy Calculation -> Reliability Score

**Critical Path:**
Perturbation → Multiple VLM Inferences → Clustering → Entropy → Reliability Decision

**Design Tradeoffs:**
- Multiple perturbations increase detection sensitivity but add computational overhead
- High-temperature sampling improves entropy sensitivity but may slow inference
- Embedding-based clustering is faster but may miss nuanced semantic differences compared to NLI

**Failure Signatures:**
- False positives: Correct answers flagged as hallucinated due to perturbation sensitivity
- False negatives: Hallucinations undetected due to clustering merging distinct wrong answers
- High computational cost: Multiple forward passes limit real-time deployment

**Three First Experiments:**
1. Baseline entropy calculation on clean inputs only
2. VASE calculation with clean and perturbed inputs
3. Ablation study comparing NLI vs embedding clustering methods

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation restricted to soccer video domain; generalization to other video types untested
- Perturbation strategy may flag correct answers as hallucinated if sensitive to minor visual changes
- Computational overhead from multiple forward passes may limit real-time deployment

## Confidence

**High Confidence:**
- Core methodology of using semantic entropy from perturbed and clean inputs is technically sound
- Superior performance of VASE over baseline entropy measures is consistently demonstrated

**Medium Confidence:**
- Embedding-based clustering achieves comparable performance to NLI-based clustering at lower cost
- Domain fine-tuning provides modest calibration improvements but is not transformative

**Low Confidence:**
- Generalization claims to other video domains are not empirically validated
- Long-term stability of entropy-based detection against adaptive models remains untested

## Next Checks
1. **Cross-Domain Generalization Test**: Evaluate VideoHEDGE on multiple video datasets (e.g., movies, surveillance, instructional videos) to assess robustness and domain transferability. Measure performance variance across domains and identify failure modes.

2. **Perturbation Sensitivity Analysis**: Systematically vary perturbation types (e.g., temporal frame reordering, brightness changes, occlusions) and magnitudes to determine the optimal balance between hallucination detection sensitivity and false positive rates. Test whether certain perturbations consistently misclassify correct answers.

3. **Real-Time Feasibility Assessment**: Benchmark the computational overhead of VideoHEDGE in a streaming video QA scenario. Measure latency introduced by multiple forward passes and entropy computation, and explore model compression or approximation techniques to enable practical deployment.