---
ver: rpa2
title: Leveraging GPT-4o Efficiency for Detecting Rework Anomaly in Business Processes
arxiv_id: '2502.06918'
source_url: https://arxiv.org/abs/2502.06918
tags:
- anomaly
- anomalies
- activity
- process
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates GPT-4o's effectiveness in detecting rework
  anomalies in business processes using synthetic datasets with normal, uniform, and
  exponential anomaly distributions. The research compares zero-shot, one-shot, and
  few-shot prompting techniques.
---

# Leveraging GPT-4o Efficiency for Detecting Rework Anomaly in Business Processes

## Quick Facts
- **arXiv ID**: 2502.06918
- **Source URL**: https://arxiv.org/abs/2502.06918
- **Reference count**: 38
- **Primary result**: GPT-4o achieves 97.94% accuracy with few-shot prompting on uniform anomaly distributions

## Executive Summary
This study evaluates GPT-4o's effectiveness in detecting rework anomalies in business processes using synthetic datasets with normal, uniform, and exponential anomaly distributions. The research compares zero-shot, one-shot, and few-shot prompting techniques, finding that GPT-4o achieved its highest accuracy (97.94%) with few-shot prompting on uniformly distributed anomalies. The model outperformed traditional methods like PCA, Isolation Forest, and DAGMM, demonstrating 46-30% higher accuracy. Performance varied significantly with anomaly distribution, showing that uniform distributions yielded optimal results while exponential distributions posed challenges.

## Method Summary
The study used synthetic event logs generated with ReworkNet, creating datasets with normal, uniform, and exponential anomaly distributions. GPT-4o was evaluated using zero-shot, one-shot, and few-shot prompting techniques across these distributions. The research compared GPT-4o's performance against traditional anomaly detection methods including PCA, Isolation Forest, and DAGMM. Accuracy, precision, recall, and F1-score were measured to assess performance across different prompting strategies and anomaly types.

## Key Results
- GPT-4o achieved 97.94% accuracy with few-shot prompting on uniform anomaly distributions
- Traditional methods like PCA, Isolation Forest, and DAGMM were outperformed by 46-30% accuracy
- Performance degraded significantly with exponential anomaly distributions, highlighting distribution-specific limitations

## Why This Works (Mechanism)
GPT-4o leverages its large language model capabilities to understand process patterns and identify deviations through contextual analysis of event sequences. The model's few-shot learning ability allows it to generalize from limited examples, making it effective for detecting rework anomalies without extensive training data. The prompt engineering approach enables the model to focus on relevant features and patterns specific to business process rework detection.

## Foundational Learning
- **Rework anomaly detection**: Understanding process inefficiencies through repeated activities; needed to frame the problem context; quick check: verify anomaly definitions align with business process standards
- **Synthetic dataset generation**: Creating controlled test environments with known anomalies; needed to enable reproducible testing; quick check: validate ReworkNet generation parameters
- **Prompt engineering techniques**: Zero-shot, one-shot, and few-shot approaches; needed to optimize model performance; quick check: compare prompt effectiveness across different anomaly types
- **Traditional anomaly detection methods**: PCA, Isolation Forest, DAGMM baselines; needed for performance benchmarking; quick check: verify implementation accuracy against established libraries
- **Anomaly distribution patterns**: Normal, uniform, exponential distributions; needed to test model robustness; quick check: confirm distribution parameters match synthetic data generation
- **Business process mining concepts**: Event logs, process flows, rework patterns; needed to contextualize the application domain; quick check: validate event log structure against BPMN standards

## Architecture Onboarding

**Component Map**: Synthetic Data Generator -> GPT-4o Model -> Anomaly Detection -> Performance Evaluation -> Traditional Methods Comparison

**Critical Path**: Data Generation → Prompt Engineering → Model Inference → Accuracy Measurement → Comparative Analysis

**Design Tradeoffs**: GPT-4o offers higher accuracy and accessibility but requires API access and computational resources, while traditional methods are more established but less effective at 46-30% lower accuracy rates.

**Failure Signatures**: Performance degradation occurs with exponential anomaly distributions, suggesting limitations in handling certain pattern types. The model may struggle with highly irregular or complex rework patterns that deviate significantly from training examples.

**First Experiments**:
1. Test GPT-4o across additional anomaly distribution types to map performance boundaries
2. Compare few-shot prompting effectiveness with varying numbers of examples
3. Evaluate model performance on real-world business process logs to assess practical applicability

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on synthetic datasets limits generalizability to real-world business processes
- Exponential distribution anomalies showed notably lower performance, indicating potential blind spots
- Lack of empirical validation with actual non-technical users for accessibility claims

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| GPT-4o performance superiority over traditional methods | High |
| Prompt engineering impact on detection accuracy | High |
| Anomaly distribution effects on performance | Medium |
| Practical usability for non-technical users | Low |

## Next Checks
1. Validate findings using real-world business process logs from multiple industries to assess generalizability and robustness against complex, irregular rework patterns
2. Conduct a user study with non-technical business analysts to empirically evaluate the claimed accessibility benefits and identify usability barriers
3. Test hybrid approaches combining GPT-4o with traditional methods across diverse anomaly distributions to determine optimal detection frameworks for different business contexts