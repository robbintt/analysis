---
ver: rpa2
title: Retrieval Visual Contrastive Decoding to Mitigate Object Hallucinations in
  Large Vision-Language Models
arxiv_id: '2505.20569'
source_url: https://arxiv.org/abs/2505.20569
tags:
- image
- rvcd
- objects
- decoding
- object
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RVCD (Retrieval Visual Contrastive Decoding) is a train-free decoding
  method that mitigates object hallucination in large vision-language models by leveraging
  negative and positive logits from explicitly retrieved single-concept images. The
  method retrieves AI-generated images representing objects detected or hallucinated
  by the model, then adjusts logits during decoding to suppress incorrect objects
  while preserving accurate ones.
---

# Retrieval Visual Contrastive Decoding to Mitigate Object Hallucinations in Large Vision-Language Models

## Quick Facts
- **arXiv ID:** 2505.20569
- **Source URL:** https://arxiv.org/abs/2505.20569
- **Reference count:** 28
- **Primary result:** RVCD reduces object hallucination scores by up to 52% while maintaining caption quality

## Executive Summary
RVCD (Retrieval Visual Contrastive Decoding) is a train-free decoding method that addresses object hallucinations in large vision-language models by leveraging negative and positive logits from explicitly retrieved single-concept images. The method retrieves AI-generated images representing objects detected or hallucinated by the model, then adjusts logits during decoding to suppress incorrect objects while preserving accurate ones. RVCD achieves state-of-the-art performance on multiple benchmarks, reducing CHAIR hallucination scores by up to 52% compared to baseline decoding methods while maintaining comparable BLEU scores for caption quality. On POPE evaluation, RVCD improves accuracy by up to 29% over existing decoding approaches.

## Method Summary
RVCD operates by retrieving single-concept images that correspond to objects detected or hallucinated by the vision-language model. During decoding, it performs contrastive logit adjustment by suppressing logits associated with hallucinated objects (negative samples) while preserving or enhancing logits for correctly identified objects (positive samples). This approach is train-free, requiring only inference without additional model training. The method works by generating negative and positive logit adjustments based on retrieved images, which are then applied during the decoding process to guide the model toward more accurate object recognition and description.

## Key Results
- Reduces CHAIR hallucination scores by up to 52% compared to baseline decoding methods
- Improves POPE evaluation accuracy by up to 29% over existing decoding approaches
- Maintains comparable BLEU scores for caption quality while significantly reducing hallucinations

## Why This Works (Mechanism)
The mechanism works by leveraging visual contrastive learning principles during decoding. By retrieving single-concept images that represent both hallucinated and correctly identified objects, RVCD creates a contrastive space where the model can distinguish between accurate and inaccurate object predictions. The negative logits from hallucinated objects are suppressed, while positive logits from correctly identified objects are preserved or enhanced, effectively guiding the model's attention toward accurate object recognition during text generation.

## Foundational Learning
- **Vision-Language Models (VLMs):** Models that process both visual and textual inputs, crucial for understanding the integration of image features with language generation.
- **Object Hallucination:** The phenomenon where VLMs generate text describing objects not present in input images, representing a critical failure mode.
- **Contrastive Learning:** A training approach that learns representations by contrasting positive and negative pairs, adapted here for decoding.
- **Logit Adjustment:** The process of modifying model output scores to influence generation, essential for steering model behavior without retraining.
- **Retrieval-Augmented Generation:** Using external knowledge sources to improve generation quality, forming the basis for RVCD's approach.

## Architecture Onboarding

**Component Map:** VLM backbone → Object detection → Image retrieval → Logit adjustment → Text generation

**Critical Path:** The critical path flows from object detection through image retrieval to logit adjustment, with each step building on the previous to create the contrastive adjustments that guide final text generation.

**Design Tradeoffs:** The method trades computational overhead during inference (for image retrieval) against improved accuracy and hallucination reduction. The train-free approach avoids retraining costs but depends on the quality of retrieved images.

**Failure Signatures:** Poor retrieval quality leads to incorrect contrastive adjustments, potentially introducing new hallucinations or failing to suppress existing ones. Over-aggressive suppression may reduce caption completeness.

**First Experiments:** 
1. Evaluate retrieval quality on a held-out image set to ensure relevance of retrieved images
2. Test logit adjustment sensitivity by varying suppression strength parameters
3. Compare performance across different VLM backbones to assess generalizability

## Open Questions the Paper Calls Out
None

## Limitations
- Scalability concerns when handling complex or diverse object sets, as retrieval of single-concept images may not generalize to novel or compound objects
- Heavy dependence on retrieval quality, where poor image retrieval could undermine hallucination mitigation benefits
- Limited cross-model testing, with primary validation on specific LLaVA-1.5, MiniGPT-4, and mPLUG-Owl2 backbones

## Confidence
**High:** RVCD's ability to reduce object hallucination scores on tested benchmarks (CHAIR and POPE) is highly reliable due to direct, quantifiable measurements.
**Medium:** Claims of state-of-the-art performance compared to existing decoding approaches, though may not encompass all hallucination mitigation methods.
**Low:** Generalizability to real-world scenarios with diverse, uncontrolled image inputs remains uncertain, as evaluation focuses on benchmark datasets.

## Next Checks
1. Test RVCD on more diverse and complex object categories, including compound objects and objects in varied contexts, to assess scalability and robustness.
2. Conduct ablation studies to quantify the impact of retrieval quality on hallucination mitigation performance, isolating the contribution of the contrastive decoding mechanism from the retrieval process.
3. Evaluate the method's performance across a broader range of vision-language model architectures and training datasets to establish cross-model generalization capabilities.