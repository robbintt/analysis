---
ver: rpa2
title: An empathic GPT-based chatbot to talk about mental disorders with Spanish teenagers
arxiv_id: '2505.05828'
source_url: https://arxiv.org/abs/2505.05828
tags:
- users
- user
- chatbot
- about
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed a chatbot-based system to engage Spanish teenagers
  in mental health awareness using a self-disclosure technique. The system integrates
  controlled dialogue with GPT-3 to facilitate open conversations about mental disorders.
---

# An empathic GPT-based chatbot to talk about mental disorders with Spanish teenagers

## Quick Facts
- arXiv ID: 2505.05828
- Source URL: https://arxiv.org/abs/2505.05828
- Reference count: 40
- Key outcome: 70% of Spanish teenagers emotionally engaged with the chatbot, sharing mental health concerns

## Executive Summary
This study developed a Telegram chatbot system to engage Spanish teenagers in mental health awareness using a self-disclosure technique. The system integrates controlled dialogue with GPT-3 to facilitate open conversations about mental disorders. Tested with 44 teenagers aged 12-18, the chatbot achieved significant emotional engagement, with 70% of users sharing their concerns. The study identified differences in language use between healthy and indicated users, particularly in coordinating conjunctions, emotions, and lexical diversity.

## Method Summary
The chatbot uses a hybrid architecture combining controlled psychologist-designed prompts with GPT-3 open dialogue generation. Users interact via Telegram, selecting from three bot personas (Ada, Hugo, or Big) based on gender preference. The system employs a translation layer (DeepL API) to convert Spanish inputs to English for GPT-3 processing, then back to Spanish. Every five user interactions, controlled dialogue intervenes to maintain topic focus and prevent hallucination drift. The system includes an alert mechanism for detecting suicidal ideation and self-harm language.

## Key Results
- 70% of users emotionally engaged with the chatbot and shared their concerns
- Over 50% of users reported positive attitudes toward the system
- Differences identified in language use between healthy and indicated users, particularly in coordinating conjunctions, emotions, and lexical diversity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Self-disclosure by the chatbot increases user emotional openness
- Mechanism: The bot initiates conversations by sharing its own "worries and fears," creating reciprocal vulnerability
- Core assumption: Users will reciprocate vulnerability when the agent models it first
- Evidence anchors: Abstract mentions "self-disclosure technique... to establish a more empathetic communication"; Section 4.3 shows "100% of users expressing concerns have previously engaged in empathetic interactions"

### Mechanism 2
- Claim: Hybrid controlled-open dialogue maintains topic focus while allowing expressive freedom
- Mechanism: Controlled dialogue inserts every 5 interactions to redirect or ground conversation; GPT-3 enables free-form responses between interventions
- Core assumption: Periodic structured interventions can prevent LLM hallucination drift without breaking engagement
- Evidence anchors: Abstract states "dialogue engine mixes closed and open conversations"; Section 3.2.1 specifies "every five free interactions, the chatbot asks the user to continue... or to chat about another disorder"

### Mechanism 3
- Claim: Bot gender selection correlates with user comfort and self-disclosure depth
- Mechanism: Offering Ada (female), Hugo (male), or Big (neutral) allows users to select a persona they identify with
- Core assumption: Users have conscious or unconscious preferences that affect their willingness to share sensitive information
- Evidence anchors: Section 2.2 states "gender and self-disclosure are two related variables"; Section 3.2.2 notes users are asked to choose the bot they prefer

## Foundational Learning

- Concept: Self-disclosure theory (Social Penetration Theory)
  - Why needed here: Explains why bot vulnerability may trigger reciprocal user openness
  - Quick check question: Can you distinguish between peripheral and central self-disclosure in a sample dialogue?

- Concept: Controlled dialogue injection
  - Why needed here: Understanding when and how to interject structured prompts into LLM-driven conversation is critical for safety
  - Quick check question: At what interaction interval does this system insert controlled prompts, and why that frequency?

- Concept: Translation layer tradeoffs (DeepL + GPT-3 English)
  - Why needed here: The system translates Spanish→English→Spanish, introducing latency and potential mistranslation of colloquialisms
  - Quick check question: What types of translation errors were observed, and how might they affect user trust?

## Architecture Onboarding

- Component map: Telegram Bot API -> Dialogue Manager -> GPT-3 (Davinci-002) -> DeepL API -> MongoDB -> Alert System
- Critical path: User sends `/start` → Welcome + gender selection → Alias creation → Triage questions → Controlled dialogue → GPT-3 open dialogue → Every 5 messages → Controlled intervention → Risk detection → Human psychologist alert
- Design tradeoffs: Translation layer improves GPT-3 quality but introduces colloquialism errors and gender agreement issues; high temperature (0.9) increases creativity but may cause repetition loops
- Failure signatures: Repetition loops when users respond with short messages; translation mismatches for colloquial Spanish terms; gender pronoun drift; negation misunderstanding
- First 3 experiments: A/B test gender persona assignment; translation ablation comparing native Spanish vs. DeepL-mediated English; controlled dialogue frequency sweep at 3, 5, and 7-turn intervals

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do in-depth user interviews compare to survey-based evaluations in assessing the efficacy of mental health chatbots for teenagers?
- Basis in paper: Authors expect to perform deeper evaluation by interviewing users instead of relying on surveys
- Why unresolved: Current evaluation relied on anonymous surveys due to resource constraints
- What evidence would resolve it: Qualitative data from post-interaction interviews revealing user experiences and psychological impacts

### Open Question 2
- Question: Can RAG or native Spanish models effectively mitigate translation errors and misunderstandings of colloquialisms?
- Basis in paper: Authors propose using native language models or RAG techniques for colloquial term consultation
- Why unresolved: Current system used GPT-3 via DeepL translation, causing errors with local slang
- What evidence would resolve it: Comparative analysis of error rates between current architecture and native LLM or RAG-enhanced system

### Open Question 3
- Question: To what extent do advanced multimodal models (e.g., GPT-4) improve engagement and naturalness compared to GPT-3?
- Basis in paper: Authors note studying GPT-4 performance deserves further research
- Why unresolved: Study utilized older Davinci-002 model which occasionally hallucinated and failed to understand negation
- What evidence would resolve it: User engagement metrics and linguistic fluidity scores from deploying GPT-4 versus current GPT-3 implementation

## Limitations

- Controlled dialogue corpus (100 variants per disorder) not specified in detail, making exact replication difficult
- Gender persona effects lack direct experimental validation in the corpus
- Translation pipeline introduces unmeasured error rates for colloquial Spanish

## Confidence

- High: The hybrid dialogue architecture successfully balances engagement and safety
- Medium: Self-disclosure mechanism drives emotional openness
- Medium: Gender persona selection affects user comfort

## Next Checks

1. Conduct A/B testing of gender persona assignment (forced vs. choice) to measure differential effects on disclosure depth and satisfaction
2. Implement translation quality analysis comparing DeepL-mediated English responses vs. native Spanish GPT-3 models on colloquial phrase accuracy
3. Test controlled dialogue frequency at 3, 5, and 7-turn intervals to optimize the balance between safety and conversational naturalness