---
ver: rpa2
title: Analyzing decision tree bias towards the minority class
arxiv_id: '2501.04903'
source_url: https://arxiv.org/abs/2501.04903
tags:
- decision
- trees
- class
- tree
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors challenge the common belief that decision trees are
  biased towards the majority class in imbalanced data settings. They show theoretically
  that decision trees fit to purity can actually be biased towards the minority class,
  depending on the data generating process and tree structure.
---

# Analyzing decision tree bias towards the minority class

## Quick Facts
- arXiv ID: 2501.04903
- Source URL: https://arxiv.org/abs/2501.04903
- Reference count: 32
- Decision trees can be biased towards minority class, not majority class as commonly believed

## Executive Summary
This paper challenges the conventional wisdom that decision trees are inherently biased towards the majority class in imbalanced datasets. Through theoretical analysis and simulations, the authors demonstrate that decision trees optimized for purity can actually exhibit bias towards the minority class, depending on the data distribution and tree structure. The bias manifests when minority class observations occur at extreme predictor values, leading to over-prediction of minority cases. This finding has significant implications for tree-based ensemble methods like random forests, suggesting that current practices may need reconsideration.

## Method Summary
The authors employ a combination of analytical proofs and simulation studies to investigate decision tree bias. They analyze the theoretical behavior of decision trees under various data generating processes, focusing on how impurity reduction criteria interact with class distributions. Simulations are conducted to validate theoretical predictions across different scenarios, including varying numbers of predictors and stochastic settings. The study examines both binary and multi-class classification problems, considering different impurity measures and tree depths.

## Key Results
- Decision trees optimized for purity can be biased towards the minority class, contrary to common belief
- The bias is particularly pronounced when minority class observations occur at extreme predictor values
- Regularization techniques such as limiting tree depth or post-hoc calibration can mitigate this bias

## Why This Works (Mechanism)
The bias arises from how decision trees optimize for purity. When minority class observations are located at extreme values of predictors, splits that isolate these observations can achieve significant impurity reduction, even if they represent a small portion of the data. This creates a preference for minority class predictions in certain tree regions. The effect is amplified in high-dimensional spaces with limited predictors, where the algorithm has fewer options for achieving purity through majority class splits.

## Foundational Learning
1. Decision Tree Purity Optimization
   - Why needed: Understanding the fundamental mechanism that creates bias
   - Quick check: Verify that purity measures (Gini, entropy) prioritize splits that create homogeneous nodes

2. Imbalanced Data Classification
   - Why needed: Contextualizes the problem within broader machine learning challenges
- Quick check: Confirm that class imbalance affects classifier performance metrics and behavior

3. Tree-Based Ensemble Methods
   - Why needed: Connects individual tree behavior to forest-level effects
   - Quick check: Verify that random forests aggregate predictions from multiple decision trees

## Architecture Onboarding

Component Map: Root Node -> Internal Nodes -> Leaf Nodes -> Class Predictions

Critical Path: Data Splitting -> Impurity Calculation -> Best Split Selection -> Node Assignment -> Prediction

Design Tradeoffs: Purity vs Generalization (depth limits), Bias vs Variance (ensemble size), Computational Cost vs Model Complexity

Failure Signatures: Over-prediction of minority class, Inconsistent predictions across similar instances, Poor calibration on balanced datasets

First Experiments:
1. Generate synthetic imbalanced dataset with known minority class distribution at extreme values
2. Train decision tree with varying depths and compare class prediction frequencies
3. Apply regularization techniques and measure changes in bias direction

## Open Questions the Paper Calls Out
The paper acknowledges several areas requiring further investigation, including how different impurity measures affect bias direction, the impact of correlated predictors on bias behavior, and the generalizability of findings to non-linear relationships. Additionally, the authors suggest exploring how these biases manifest in real-world datasets across different domains and tree algorithms.

## Limitations
- Theoretical analysis focuses on specific data generating processes
- Real-world datasets may exhibit different bias behaviors
- Impact of correlated predictors and non-linear relationships not fully explored

## Confidence
- Theoretical analysis of minority class bias: High
- Simulation results supporting the claims: Medium
- Practical implications for random forests: Low
- Effectiveness of proposed regularization methods: Medium

## Next Checks
1. Test the bias phenomenon across multiple real-world imbalanced datasets with varying class distributions and feature types
2. Compare the bias behavior across different decision tree implementations (scikit-learn, XGBoost, LightGBM) and impurity measures
3. Evaluate the proposed regularization methods on multiple tree-based ensemble models in terms of both bias reduction and overall classification performance