---
ver: rpa2
title: Extend Adversarial Policy Against Neural Machine Translation via Unknown Token
arxiv_id: '2501.12183'
source_url: https://arxiv.org/abs/2501.12183
tags:
- adversarial
- perturbations
- policy
- character
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the DexChar policy, which extends mainstream
  adversarial attacks against neural machine translation by incorporating dexterous
  character-level perturbations. The key innovation is using the "unknown token" (UNK)
  as an entry point to enable character-based adversarial examples while maintaining
  semantic constraints.
---

# Extend Adversarial Policy Against Neural Machine Translation via Unknown Token

## Quick Facts
- **arXiv ID**: 2501.12183
- **Source URL**: https://arxiv.org/abs/2501.12183
- **Authors**: Wei Zou; Shujian Huang; Jiajun Chen
- **Reference count**: 29
- **Primary result**: DexChar policy extends adversarial attacks to character-level perturbations using UNK tokens, achieving better semantic constraints and efficiency than baseline methods

## Executive Summary
This paper introduces DexChar, an extension to reinforcement learning-based adversarial attacks on neural machine translation (NMT) that enables character-level perturbations. The key innovation is using the "unknown token" (UNK) as an entry point for character-based adversarial examples while maintaining semantic constraints. By incorporating noisy data augmentation for the semantic discriminator, the method addresses false-negative discrimination from character perturbations. Experiments on WMT14 English-German and CWMT17 English-Chinese datasets show that DexChar achieves superior semantic constraints (higher PA scores) and more efficient adversarial examples (higher DPE) compared to baseline methods, while retaining computational efficiency.

## Method Summary
The DexChar policy extends standard substitution-based RL adversaries by mapping character-level perturbations to UNK token substitutions. When the policy selects "Substitute with UNK," a DexChar module applies character-level operations (swap, insert, substitute) until the resulting string falls out of the model's vocabulary. To address semantic discriminator false negatives caused by tokenization shifts from character edits, the authors implement noisy data augmentation—training the discriminator with semantically equivalent examples that include the same character perturbations. The system uses an actor-critic RL framework where the actor proposes edits and the critic estimates state values, interacting with both a semantic discriminator and the target NMT model. The method is evaluated across three NMT settings (base, shared embedding, mBART) on two language pairs.

## Key Results
- DexChar achieves higher Pairing Accuracy (PA) scores than baseline methods, indicating better semantic constraint preservation
- The method demonstrates higher Degradation per Edit (DPE) efficiency compared to alternatives
- DexChar outperforms baseline approaches in both semantic constraint and efficiency metrics while maintaining comparable generation speed to RL baselines

## Why This Works (Mechanism)

### Mechanism 1: UNK as Character Perturbation Entry Point
Standard substitution policies fail when character edits change tokenization length (e.g., "pineapple" → "pi@@ en@@ apple"). The DexChar policy solves this by using UNK tokens as universal entry points for character-level perturbations. When the policy selects "Substitute with UNK," the DexChar module executes character swaps, insertions, or substitutions until the resulting string becomes an UNK token, disrupting the internal language model while maintaining human readability.

### Mechanism 2: Noisy Data Augmentation for Semantic Discriminator
Character-level perturbations often re-segment text, causing standard semantic discriminators to incorrectly flag valid adversarial examples as semantic drifts (false negatives). By augmenting the discriminator's training data with the same character noise used by the DexChar policy, the discriminator learns to recognize semantic equivalence even when token boundaries change, providing reliable reward signals to the RL agent.

### Mechanism 3: RL Framework for Variable-Length Sequences
Unlike gradient-based methods that rely on static token positions, the RL framework uses a value function to estimate degradation potential based on the current state. This allows the policy to navigate variable-length sequences and tokenization shifts without requiring gradient flow through the tokenization step, making it more robust to character-level perturbations that change sequence length.

## Foundational Learning

- **Subword Tokenization (e.g., BPE)**: Why needed: The paper attacks NMT brittleness caused by mismatch between character noise and rigid subword vocabularies. Quick check: How does a character swap inside a subword token affect the input embedding dimension of a Transformer?

- **Actor-Critic Reinforcement Learning**: Why needed: The system uses Actor (proposing edits) and Critic (estimating value) interacting with Environment (NMT + Discriminator). Quick check: Which component determines if a perturbation preserves semantics, and which determines if translation quality degraded?

- **Semantic Constraints in Text Adversaries**: Why needed: Valid adversarial examples must degrade machine performance without changing human meaning. The paper uses discriminator and BLEURT scores to enforce this. Quick check: Why is "Metric Degradation" (MD) alone insufficient to claim a successful attack?

## Architecture Onboarding

- **Component map**: Input text → Actor FFN (substitution probability) → DexChar module (character perturbations) → Discriminator (semantic validity) → Target NMT (translation quality) → BLEU/BLEURT degradation → Reward signal → Update Actor/Critic

- **Critical path**:
  1. Input text enters Agent
  2. Actor decides to substitute token with UNK or embedding neighbor
  3. If UNK: DexChar module applies character perturbations until UNK generated
  4. Perturbed text checked by Discriminator
     - If Fail: Negative reward, terminate
     - If Pass: Positive reward, feed to Target NMT
  5. NMT produces translation; calculate BLEU/BLEURT degradation (Final Reward)
  6. Update Actor/Critic weights

- **Design tradeoffs**:
  - Speed vs. Quality: RL is faster than Beam Search but requires training a specific agent
  - Attack Surface: Including "UNK" expands attack surface to character noise but risks generating gibberish if discriminator is weak

- **Failure signatures**:
  - Low PA: Adversarial examples changing meaning (semantic drift)
  - Low MD: Target NMT too robust or perturbations being ignored
  - Discriminator False Negatives: High semantic validity but low reward signal suggests discriminator needs retraining

- **First 3 experiments**:
  1. Run Gradient Search vs. RL-attacker on shared-vocabulary model to confirm GS failure modes
  2. Disable noisy data augmentation for discriminator and measure drop in PA to validate Mechanism 2
  3. Measure generation time per sample to verify DexChar adds negligible overhead

## Open Questions the Paper Calls Out
None

## Limitations

- **UNK-tokenization dependency**: The attack strategy fundamentally depends on target models having UNK tokens as a failure mode, which modern NMT systems increasingly minimize through byte-level or robust subword tokenization
- **Discriminator sensitivity**: The solution to false-negative discrimination through noisy data augmentation is heuristic and not systematically validated for robustness across different perturbation types
- **Limited perturbation scope**: The DexChar module focuses on specific character operations (Swap, Insert, Sub) and doesn't explore other realistic character-level attacks like deletion or diacritic manipulation

## Confidence

- **High confidence**: Experimental results showing DexChar outperforms baseline methods on standard metrics (PA, DPE) across two language pairs and three model settings
- **Medium confidence**: Claim that RL provides superior search compared to gradient-based methods in shared-vocabulary settings, though comparison would be stronger with identical perturbation capabilities
- **Low confidence**: Generality of UNK-entry-point mechanism across different tokenization strategies, as paper doesn't test against byte-level tokenization or robust BPE variants

## Next Checks

1. **UNK-tokenization dependency test**: Run DexChar attacks against Transformer models with BPE dropout or byte-level SentencePiece to measure attack success rate when UNK tokens are eliminated

2. **Discriminator robustness ablation**: Systematically vary noisy data augmentation amounts for discriminator and measure correlation between discriminator accuracy and overall attack success rate

3. **Cross-perturbation transferability**: Generate DexChar adversarial examples against one model and test transfer to models with different tokenization strategies or architectures, measuring both degradation rate and semantic preservation across model boundaries