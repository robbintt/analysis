---
ver: rpa2
title: 'Artwork Interpretation with Vision Language Models: A Case Study on Emotions
  and Emotion Symbols'
arxiv_id: '2511.22929'
source_url: https://arxiv.org/abs/2511.22929
tags:
- vlms
- emotion
- images
- emotions
- artwork
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates the ability of current vision language models
  (VLMs) to interpret emotions in artworks, focusing on concrete and symbolic expressions
  of emotion. The authors present a case study with 38 artworks from various periods
  and three VLMs (Llava-Llama-8B, Qwen-7B, Qwen-32B-AWQ).
---

# Artwork Interpretation with Vision Language Models: A Case Study on Emotions and Emotion Symbols

## Quick Facts
- arXiv ID: 2511.22929
- Source URL: https://arxiv.org/abs/2511.22929
- Authors: Sebastian Pad√≥; Kerstin Thomas
- Reference count: 40
- Primary result: VLMs accurately interpret basic artwork content and concrete emotions but struggle with abstract/symbolic interpretation and exhibit confirmation bias

## Executive Summary
This paper evaluates three vision language models (VLMs) on their ability to interpret emotions and emotion symbols in artworks. The authors present a qualitative case study using 38 artworks from various periods and three VLMs (Llava-Llama-8B, Qwen-7B, Qwen-32B-AWQ). Through eight increasingly complex questions about artwork content, emotion, and symbols, they find that VLMs perform well on basic content recognition but struggle with abstract interpretation and symbol recognition. The study reveals systematic issues including confirmation bias, inconsistency in emotion polarity judgments, and concept overextension. The results suggest VLMs could support art analysis tasks with expert oversight, particularly for basic cataloging and audio description generation.

## Method Summary
The study presents 38 artworks to three VLMs, asking eight questions in hierarchical order from basic content description to emotion symbol interpretation. Questions range from identifying artwork type and content to detecting emotions, determining emotional polarity, identifying specific emotions, describing expression means, recognizing symbols, and assessing intensity. VLMs were tested in their default configurations without fine-tuning, using a single GPU with 48GB RAM. Expert qualitative evaluation assessed response correctness, errors, and consistency across questions. Images were presented without titles to require pure visual interpretation.

## Key Results
- VLMs excel at basic content recognition (Q1) and concrete emotion detection (Q3-Q5) but fail on abstract/symbolic images (Q7)
- All models exhibit confirmation bias, answering "yes" to yes/no questions about emotion presence and symbols in 90%+ of cases
- Qwen-32B-AWQ consistently outperforms other models on most tasks
- Models struggle with nuanced emotional descriptions and often provide generic or repetitive responses
- Performance degrades significantly when moving from concrete to abstract interpretation tasks

## Why This Works (Mechanism)
The VLMs appear to leverage learned visual-textual associations from training data to map visual features to semantic concepts. Their success on basic content recognition likely stems from strong feature extraction capabilities developed through large-scale pretraining. For emotion detection, models may rely on learned correlations between facial expressions, body language, and emotional labels in their training corpus. However, the models' inability to handle abstract interpretation suggests they lack genuine semantic understanding and instead rely on surface-level pattern matching.

## Foundational Learning
The models demonstrate strong transfer learning capabilities, applying general visual and language understanding to the domain of art interpretation. Their performance on concrete tasks suggests effective pretraining on diverse visual data, while struggles with abstract concepts indicate limitations in deeper semantic comprehension. The hierarchical nature of the question set reveals that models build upon basic recognition capabilities but fail to develop sophisticated interpretive reasoning.

## Architecture Onboarding
The study tests three VLMs with different architectural approaches. Llava-Llama-8B uses a vision transformer for image encoding combined with Llama language modeling. Qwen-7B and Qwen-32B-AWQ employ different parameter scales and training objectives. The superior performance of Qwen-32B-AWQ suggests that larger model capacity and specific training objectives (AWQ quantization) may enhance interpretive capabilities, though all models share similar limitations in abstract reasoning.

## Open Questions the Paper Calls Out
- How would VLMs perform on a larger, more diverse dataset of artworks?
- Would fine-tuning on art-specific data improve performance on abstract interpretation tasks?
- How do VLMs compare to human experts in terms of interpretive accuracy and consistency?
- Can architectural modifications improve abstract reasoning capabilities?
- What is the impact of providing contextual information (titles, artist information) on interpretation accuracy?

## Limitations
The study has several limitations: the small sample size of 38 artworks may not represent the full diversity of art, qualitative expert evaluation lacks standardized metrics, and the single GPU constraint may have limited testing capacity. Additionally, the absence of titles and contextual information, while ensuring pure visual interpretation, may not reflect real-world usage scenarios where VLMs would have access to metadata.

## Confidence
High confidence in basic content recognition results, as these align with known VLM capabilities. Medium confidence in emotion interpretation results, given the subjective nature of emotional assessment. Lower confidence in symbol recognition results due to the complexity of abstract interpretation and limited dataset size.

## Next Checks
- Replicate the study with a larger, more diverse dataset of artworks
- Test additional VLMs with different architectural approaches
- Evaluate performance with and without contextual information
- Compare VLM interpretations with human expert assessments
- Investigate fine-tuning approaches for improving abstract interpretation capabilities