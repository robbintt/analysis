---
ver: rpa2
title: 'MEDEQUALQA: Evaluating Biases in LLMs with Counterfactual Reasoning'
arxiv_id: '2510.12818'
source_url: https://arxiv.org/abs/2510.12818
tags:
- reasoning
- arxiv
- preprint
- which
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MEDEQUALQA introduces a counterfactual benchmark to test reasoning
  stability in medical LLMs by perturbing only patient pronouns (he/him, she/her,
  they/them) while holding clinical content constant. Using semantic textual similarity,
  the study finds overall high reasoning stability (mean STS 0.80), but reveals localized
  divergences in cited risk factors, guideline anchors, and differential ordering
  even when final diagnoses remain unchanged.
---

# MEDEQUALQA: Evaluating Biases in LLMs with Counterfactual Reasoning

## Quick Facts
- **arXiv ID:** 2510.12818
- **Source URL:** https://arxiv.org/abs/2510.12818
- **Reference count:** 16
- **Primary result:** Counterfactual benchmark reveals reasoning instability in medical LLMs when patient pronouns are perturbed, with localized divergences in clinical reasoning paths despite stable final diagnoses.

## Executive Summary
MEDEQUALQA introduces a counterfactual benchmark to test reasoning stability in medical LLMs by perturbing only patient pronouns (he/him, she/her, they/them) while holding clinical content constant. Using semantic textual similarity, the study finds overall high reasoning stability (mean STS >0.80), but reveals localized divergences in cited risk factors, guideline anchors, and differential ordering even when final diagnoses remain unchanged. Error analysis identifies cases where subtle pronoun changes lead to clinically relevant shifts in reasoning paths, underscoring potential for inequitable care. This controlled diagnostic setting offers a novel method for auditing reasoning consistency and fairness in medical AI.

## Method Summary
The study constructs 69,000 clinical vignettes from 2,000 base USMLE-style questions by applying pronoun variants (original, gender-swapped via Llama 3.1 405B, non-binary via NeuTral Rewriter) and CSC ablations. GPT-4.1 generates reasoning traces for each variant, which are then compared using sentence-transformer semantic textual similarity (STS). Low-STS pairs (bottom 5%) are manually categorized into four divergence types: factor shifts, differential reordering, management rationale changes, and tonal shifts.

## Key Results
- Overall reasoning stability is high (mean STS = 0.82 ± 0.03), with ~90% of pairs exceeding 0.75 similarity
- Bottom 5% STS threshold (0.73) identifies a reasoning instability region with clinically relevant divergences
- Manual analysis of 200 low-STS pairs shows ~80% exhibit factor shifts or differential reordering
- Final diagnoses remain stable across pronoun variants, but reasoning paths diverge in risk factor attribution and clinical prioritization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pronoun-only counterfactuals isolate demographic influences on reasoning while controlling for clinical content.
- Mechanism: By perturbing only patient pronouns (he/him ↔ she/her ↔ they/them) across identical clinical vignettes, any divergence in reasoning traces can be causally attributed to demographic priors rather than clinical uncertainty. The CSC spans are held constant, and ablations remove one CSC at a time to further localize sensitivity.
- Core assumption: Pronoun changes serve as a valid proxy for gender-related demographic priors embedded in the model's training distribution.
- Evidence anchors:
  - [abstract] "counterfactual benchmark that perturbs only patient pronouns (he/him, she/her, they/them) while holding critical symptoms and conditions (CSCs) constant"
  - [section 3.3-3.4] Describes pronoun variant creation via Llama 3.1 405B for gender-swaps and NeuTral Rewriter for non-binary, with CSC ablations producing (m+1) versions per item
  - [corpus] Related work (DeVisE, FairMedQA) uses similar minimal-pair behavioral testing but typically perturbs broader demographic attributes
- Break condition: If pronoun perturbations inadvertently alter grammatical structure or introduce tokenization artifacts, observed divergences may confound demographic bias with surface-level noise.

### Mechanism 2
- Claim: Semantic Textual Similarity (STS) on reasoning traces detects subtle reasoning instability even when final diagnoses match.
- Mechanism: Reasoning traces are embedded using sentence-transformer encoders, and cosine similarity between pronoun-variant pairs quantifies semantic alignment. Low STS (<0.73, the 5th percentile) identifies a "reasoning instability region" where demographic cues shift inferential pathways.
- Core assumption: STS captures clinically relevant reasoning differences; lower scores reflect meaningful divergence rather than stylistic variation.
- Evidence anchors:
  - [abstract] "measure stability across pronoun variants... mean STS >0.80, but reveal consistent localized divergences in cited risk factors, guideline anchors, and differential ordering"
  - [section 4.1] "mean STS = 0.82 ± 0.03, with ~90% of pairs exceeding 0.75. The bottom 5% falls below an STS score of 0.73"
  - [corpus] DeVisE (arXiv:2506.15339) similarly uses behavioral testing for fine-grained clinical reasoning probes
- Break condition: If STS fails to capture clinically meaningful logical differences (e.g., reordering of differentials without semantic change), instability may be underestimated.

### Mechanism 3
- Claim: Manual categorization of low-STS pairs reveals four distinct divergence types with different clinical implications.
- Mechanism: Sampling 200 pairs around the 5th percentile STS threshold, human annotators classified divergences into: factor shifts (changed causal attribution), differential reordering (reprioritized steps), management rationale (added/omitted procedures), and tonal shifts (confidence/assertiveness changes). ~80% of instability-region pairs showed factor shifts or reordering.
- Core assumption: The 200 sampled pairs generalize to the broader dataset's divergence patterns.
- Evidence anchors:
  - [section 4.2] "sampled 200 STS pairs that fell ±0.01 around the 5th percentile per comparison and performed pairwise reasoning analysis"
  - [Table 6] Shows ~160-167 factor shifts and ~160-166 reordering cases per comparison, vs. only 5-48 management/tonal shifts
  - [corpus] Related fairness audits (CLIMB, EquityGuard) focus on outcome disparities rather than reasoning-path categorization
- Break condition: If divergence categories are not mutually exclusive or annotator judgment varies significantly, classification reliability degrades.

## Foundational Learning

- Concept: Counterfactual fairness testing
  - Why needed here: The paper's core methodology relies on generating minimally different inputs (pronoun swaps) to isolate causal effects of demographic cues on model behavior.
  - Quick check question: If you swap "he" to "she" in a clinical vignette and the model's diagnosis changes, what can you conclude? What if only the reasoning changes but the diagnosis stays the same?

- Concept: Semantic Textual Similarity (STS)
  - Why needed here: STS serves as the primary metric for quantifying reasoning stability; understanding its limitations is critical for interpreting results.
  - Quick check question: Two reasoning traces receive STS=0.85. Does this guarantee they recommend the same clinical actions? What might be missed?

- Concept: CSC (Critical Symptoms and Conditions) ablation
  - Why needed here: The dataset construction uses CSC ablations to create controlled variations; understanding this helps interpret why the benchmark has 69K items from 2K base questions.
  - Quick check question: A vignette has 12 CSC spans. How many ablated versions are created? Why ablate one CSC at a time rather than all simultaneously?

## Architecture Onboarding

- Component map:
  - Source data: 2,000 US medical QA items from EquityGuard
  - CSC annotation: Board-certified physicians label clinically decisive spans
  - Pronoun variants: Original → Gender-swapped (Llama 3.1 405B) → Non-binary (NeuTral Rewriter)
  - Ablation engine: Creates (m+1) versions per item, grammar-corrected via GEC-ToR RoBERTa
  - Evaluation: GPT-4.1 generates reasoning traces; sentence-transformers compute STS
  - Analysis: Manual categorization of low-STS pairs into divergence types

- Critical path:
  1. CSC annotation quality determines ablation validity
  2. Pronoun rewriting must preserve all clinical content exactly
  3. STS threshold (0.73) defines instability region for downstream analysis
  4. Manual categorization generalizes to full dataset

- Design tradeoffs:
  - Pronoun-only perturbations provide controlled causal inference but miss race, age, SES effects (explicitly noted in Limitations)
  - Single model (GPT-4.1) tested; patterns may not generalize to other architectures
  - STS captures semantic similarity but may miss nuanced clinical argumentation differences
  - 5th percentile threshold is arbitrary but empirically identifies a long tail of instability

- Failure signatures:
  - Grammar repair introducing unintended content changes
  - Gender-swap prompting failing on complex coreference chains
  - Non-binary rewriting producing awkward phrasing that affects model interpretation
  - STS conflation of stylistic vs. clinical reasoning differences
  - CSC annotations missing clinically relevant spans

- First 3 experiments:
  1. Replicate on additional LLMs (e.g., Claude, Med-PaLM) to assess generalization of instability patterns across architectures.
  2. Extend counterfactuals to race and age markers to test whether pronoun-specific findings hold for other demographic axes.
  3. Develop automated divergence classification (factor shifts, reordering, etc.) to scale beyond 200 manually annotated pairs.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the reasoning instability patterns observed with pronoun perturbations generalize to other demographic attributes such as race, age, or socioeconomic status?
- Basis in paper: [explicit] "Future work should extend this methodology to a broader range of demographic attributes."
- Why unresolved: The study deliberately restricted counterfactuals to pronouns only, leaving other demographic dimensions untested.
- What evidence would resolve it: Applying the same CSC-controlled counterfactual framework to race, age, and SES attributes and comparing STS distributions and divergence types.

### Open Question 2
- Question: Do the observed reasoning instability patterns generalize across different LLM architectures and training paradigms?
- Basis in paper: [explicit] "Replicating this study across a diverse set of LLMs would be necessary to draw more general conclusions."
- Why unresolved: Only GPT-4.1 was evaluated; the authors note patterns may not generalize to models with different architectures or training data.
- What evidence would resolve it: Running the same MEDEQUALQA benchmark on diverse medical and general-purpose LLMs (e.g., Claude, Med-PaLM, open-source models) and comparing instability regions.

### Open Question 3
- Question: Can metrics more sophisticated than STS better capture nuanced differences in clinical argumentation and logical flow?
- Basis in paper: [explicit] "STS provides a high-level measure of semantic equivalence but may not capture more nuanced differences in clinical argumentation or logical flow."
- Why unresolved: STS captures surface-level semantic similarity but may miss clinically meaningful structural reasoning changes.
- What evidence would resolve it: Developing and validating clinical reasoning coherence metrics (e.g., argument graph similarity, guideline adherence scoring) and correlating with expert human judgments of reasoning quality.

## Limitations
- Pronoun-only perturbations cannot capture intersectional effects or other demographic dimensions (race, age, SES)
- STS similarity may conflate clinically meaningful reasoning differences with stylistic variations
- Manual categorization of 200 pairs may not generalize to the full dataset's divergence patterns

## Confidence
- High confidence: Overall STS scores (>0.80 mean stability) and basic methodological validity
- Medium confidence: Specific divergence categories and their clinical implications
- Low confidence: Generalization to other LLMs, demographic axes, and clinical settings

## Next Checks
1. Replicate the analysis across multiple LLM architectures (Med-PaLM, Claude) to assess pattern generalizability
2. Extend counterfactual perturbations to include race and age markers while maintaining CSC controls
3. Develop automated divergence classification to validate manual annotation reliability across the full dataset