---
ver: rpa2
title: Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE
arxiv_id: '2509.03626'
source_url: https://arxiv.org/abs/2509.03626
tags:
- arxiv
- knowledge
- graph
- responses
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes KG-SMILE, a perturbation-based explainability
  framework that extends SMILE for Knowledge Graph Retrieval-Augmented Generation
  (KG-RAG). The approach addresses the opacity of GraphRAG systems by identifying
  the most influential KG entities and relations using controlled perturbations, similarity
  computations (cosine, Wasserstein distance), and weighted linear surrogate models.
---

# Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE

## Quick Facts
- **arXiv ID**: 2509.03626
- **Source URL**: https://arxiv.org/abs/2509.03626
- **Reference count**: 40
- **Primary result**: KG-SMILE demonstrates high fidelity, faithfulness, consistency, and stability for explainable GraphRAG, enabling transparent reasoning in high-stakes domains like healthcare.

## Executive Summary
KG-SMILE is a perturbation-based explainability framework that extends SMILE for Knowledge Graph Retrieval-Augmented Generation (KG-RAG). It addresses the opacity of GraphRAG systems by identifying the most influential KG entities and relations using controlled perturbations, similarity computations (cosine, Wasserstein distance), and weighted linear surrogate models. Evaluated on biomedical datasets, KG-SMILE effectively bridges interpretability and performance, enabling transparent reasoning in high-stakes domains like healthcare.

## Method Summary
KG-SMILE systematically removes triples from a knowledge graph to create perturbed versions, then measures how these perturbations affect the LLM's generated responses. The framework computes similarity between original and perturbed response embeddings using cosine similarity and Inverse Wasserstein distance. These similarity scores serve as labels for training a weighted linear regression surrogate model, where binary perturbation vectors indicate which triples were removed. The resulting regression coefficients quantify each triple's contribution to the output, providing interpretable attributions for the GraphRAG system.

## Key Results
- KG-SMILE achieves high fidelity with R² values near 1.0 for the linear regression surrogate
- Inverse Wasserstein distance provides better attribution fidelity than cosine similarity alone
- Temperature=0 setting ensures deterministic retrieval with optimal stability for attribution fidelity
- The framework demonstrates consistent performance across multiple evaluation metrics including AUC, Jaccard index, and Pearson correlation

## Why This Works (Mechanism)

### Mechanism 1: Perturbation-based Attribution via Surrogate Modeling
Systematically removing graph components (triples) and measuring output shifts enables identification of influential KG entities and relations. The framework removes subsets of triples from the KG to create perturbed graphs, generates responses from both original and perturbed graphs, computes Wasserstein distance and cosine similarity between response embeddings, and uses these as labels for training a weighted linear regression surrogate.

### Mechanism 2: Inverse Wasserstein Distance for Faithful Attribution
Inverse Wasserstein distance captures contrastive distributional shifts in text-based responses better than cosine similarity. Unlike cosine similarity which measures angular alignment, Wasserstein distance measures the cost of transforming one probability distribution into another, highlighting divergences in the underlying distributions of text embeddings.

### Mechanism 3: Temperature-Controlled Retrieval for Stability-Accuracy Tradeoff
Setting the LLM temperature to 0 ensures deterministic, highly stable attributions. At temperature 0, the LLM consistently selects the most probable tokens, leading to reproducible retrieval paths and response generation. This stability makes the mapping from KG triples to outputs consistent across runs.

## Foundational Learning

- **Knowledge Graph (KG) Triples (Subject-Predicate-Object)**: KG-SMILE's core unit of perturbation and attribution is the KG triple. Understanding this structure is fundamental to interpreting which entities and relations are being removed and evaluated.
  - *Quick check*: Given the triple ("glucagon receptor activity", "inhibited by", "insulin"), which component would you remove to test the influence of the "inhibited by" relation?

- **Linear Surrogate Models (LIME-style interpretability)**: KG-SMILE uses a weighted linear regression as a surrogate to approximate the complex GraphRAG model locally. Understanding that coefficients represent feature importance is crucial for interpreting the output.
  - *Quick check*: If the coefficient for a perturbation variable (representing the removal of a triple) is large and positive, what does that imply about the triple's relationship to the response similarity score?

- **Wasserstein Distance (Earth Mover's Distance)**: This metric is central to the proposed method. It's a measure of distributional difference, not just vector alignment. Understanding its properties is needed to justify its use over simpler metrics.
  - *Quick check*: Why might a distributional distance metric like Wasserstein be preferred over cosine similarity when comparing text embeddings from a generative model, which can have variable density and spread?

## Architecture Onboarding

- **Component map**: Knowledge Graph (G) -> GraphRAG System -> Perturbation Engine -> Response Generator -> Embedding Module -> Similarity/Distance Calculator -> Weighting/Probability Function -> Surrogate Model

- **Critical path**: 1. Receive query (q) and KG (G) 2. Generate baseline response (Rorg) using original G 3. Create N perturbed graphs (P(G)i) by removing different sets of triples 4. Generate N perturbed responses (Rpromi) 5. Embed all responses and compute similarity/distance metrics 6. Train weighted linear regression surrogate 7. Extract and visualize coefficients as attribution scores

- **Design tradeoffs**:
  - Perturbation count vs. cost: More perturbations provide more data but increase computational cost linearly
  - Determinism vs. diversity: Temperature=0 ensures stable attributions but may miss valid alternative reasoning paths
  - Linearity vs. fidelity: Linear surrogate is interpretable but may fail to capture non-linear interactions between triples

- **Failure signatures**:
  - Unstable coefficients: High variance in regression coefficients across runs with different random seeds
  - Zero attributions: All coefficients near zero, suggesting perturbations do not significantly affect output
  - Contradictory attributions: Different metrics identify different important triples

- **First 3 experiments**:
  1. **Baseline Reproduction**: Re-implement the 20-perturbation setup on a subset of the PrimeKGQA dataset to verify reported R² values near 1.0
  2. **Temperature Sweep**: Run the full pipeline at T=0, T=0.5, and T=1.0 to measure stability-accuracy tradeoff
  3. **Perturbation Sensitivity**: Systematically vary the number of perturbations (10, 20, 30, 50) to identify diminishing returns

## Open Questions the Paper Calls Out
- How to scale KG-SMILE to industrial-sized knowledge graphs with millions of nodes and edges
- Expanding GraphRAG applications to complex domains like finance and legal compliance
- Evaluating attribution accuracy when subjected to specifically crafted adversarial noise in KG triples

## Limitations
- The perturbation approach assumes linear additivity of triple contributions, which may not hold for complex GraphRAG models
- Study is limited to biomedical domain datasets, raising questions about generalizability
- Surrogate model's fidelity depends heavily on the choice of perturbation size and distribution

## Confidence
- **High**: Perturbation-based attribution mechanism works as described, Inverse Wasserstein distance provides better attribution fidelity than cosine similarity
- **Medium**: Temperature=0 setting provides optimal stability-accuracy tradeoff for attribution fidelity
- **Low**: The approach generalizes well beyond biomedical domains and maintains performance with larger, more complex knowledge graphs

## Next Checks
1. **Cross-Domain Validation**: Apply KG-SMILE to a non-biomedical knowledge graph and compare attribution stability and fidelity metrics against the biomedical baseline
2. **Surrogate Model Robustness**: Systematically vary perturbation sizes (5%, 20%, 50%) and measure changes in R² values and attribution consistency to identify the linear approximation breaking point
3. **Alternative Attribution Methods**: Implement a post-hoc SHAP-based attribution method on the same GraphRAG model and compare the top-5 attributed triples with KG-SMILE's results to validate consistency and identify potential method-specific biases