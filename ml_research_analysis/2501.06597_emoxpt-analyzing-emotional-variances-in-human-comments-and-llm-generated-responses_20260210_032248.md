---
ver: rpa2
title: 'EmoXpt: Analyzing Emotional Variances in Human Comments and LLM-Generated
  Responses'
arxiv_id: '2501.06597'
source_url: https://arxiv.org/abs/2501.06597
tags:
- chatgpt
- data
- responses
- human
- sentiment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates emotional differences between human comments
  and LLM-generated responses on generative AI topics. It introduces EmoXpt, a sentiment
  analysis framework that applies K-means clustering to BERT embeddings at both word
  and sentence levels.
---

# EmoXpt: Analyzing Emotional Variances in Human Comments and LLM-Generated Responses

## Quick Facts
- **arXiv ID:** 2501.06597
- **Source URL:** https://arxiv.org/abs/2501.06597
- **Reference count:** 31
- **Primary result:** Human comments on generative AI topics are predominantly negative (72%) while ChatGPT responses are largely positive (90%)

## Executive Summary
This study introduces EmoXpt, a sentiment analysis framework that compares emotional patterns between human comments and LLM-generated responses on generative AI topics. The framework applies K-means clustering to BERT embeddings at both word and sentence levels to analyze sentiment distributions. The research found significant differences in emotional expression, with human tweets showing predominantly negative sentiment while ChatGPT responses displayed consistent positive sentiment. The study demonstrates that LLM-generated responses are more emotionally cohesive than human responses, though they lack the nuanced emotional expression characteristic of human communication.

## Method Summary
The research collected human tweets referencing ChatGPT, OpenAI, Copilot, and LLMs, then generated corresponding responses using ChatGPT. Both datasets were processed using the EmoXpt framework, which employed BERT embeddings to represent text at word and sentence levels. K-means clustering was applied to these embeddings to identify sentiment patterns, with silhouette scores used to measure clustering consistency. The framework performed binary sentiment classification (positive/negative) and compared the emotional characteristics between human and AI-generated content through quantitative analysis of sentiment distributions and clustering quality metrics.

## Key Results
- Human comments on generative AI topics were predominantly negative (72%)
- ChatGPT responses were largely positive (90%)
- K-means clustering achieved higher silhouette scores for ChatGPT responses (0.58) compared to human comments (0.19), indicating more consistent positive sentiment patterns in AI-generated content

## Why This Works (Mechanism)
The study's methodology leverages BERT embeddings to capture semantic meaning at multiple granularities, then uses K-means clustering to identify sentiment patterns. The higher silhouette scores for ChatGPT responses indicate that the model's responses cluster more tightly around positive sentiment, suggesting greater emotional consistency. The contrast with human comments, which show more dispersed clustering patterns, demonstrates the difference in emotional expression between humans and LLMs. The framework's ability to quantify these differences through computational methods provides objective evidence of the emotional variances between human and AI-generated content.

## Foundational Learning
- **BERT embeddings**: Why needed - To capture semantic meaning of text at word and sentence levels; Quick check - Verify embeddings preserve context and sentiment information
- **K-means clustering**: Why needed - To group similar sentiment expressions and identify patterns; Quick check - Assess cluster quality using silhouette scores
- **Silhouette scores**: Why needed - To measure clustering consistency and compare between datasets; Quick check - Higher scores indicate more cohesive clusters
- **Sentiment classification**: Why needed - To categorize emotional polarity of text; Quick check - Validate classification accuracy against human-annotated data
- **LLM-generated responses**: Why needed - To provide controlled comparison against human emotional expression; Quick check - Ensure responses are generated using consistent prompts
- **Twitter data collection**: Why needed - To obtain real-world human opinions on generative AI; Quick check - Filter for relevant topics and language quality

## Architecture Onboarding

**Component map:**
Twitter API -> Data preprocessing -> BERT embedding generation -> K-means clustering -> Silhouette score calculation -> Sentiment classification -> Comparative analysis

**Critical path:**
Data collection and preprocessing -> BERT embedding generation -> K-means clustering and evaluation -> Sentiment analysis and comparison

**Design tradeoffs:**
The framework balances computational efficiency (K-means clustering) with semantic richness (BERT embeddings), but sacrifices nuance by using binary sentiment classification rather than multi-dimensional emotional analysis.

**Failure signatures:**
Low silhouette scores may indicate either genuinely mixed sentiment or limitations in the clustering approach's ability to capture complex emotional states.

**First experiments:**
1. Apply EmoXpt to a gold-standard sentiment dataset to validate accuracy
2. Test clustering performance on synthetic datasets with known sentiment distributions
3. Compare results using alternative clustering algorithms (e.g., hierarchical clustering)

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How does the emotional consistency of ChatGPT compare to that of other prominent LLMs like Gemini, Claude, and Llama?
- Basis in paper: The conclusion states that future research could expand the study by "including content from AI models like Gemini, Claude, and Llama for comparative emotional analysis."
- Why unresolved: The current study exclusively analyzes ChatGPT, leaving the emotional patterns of other state-of-the-art models unexplored.
- Evidence: Applying the EmoXpt framework to identical prompt datasets processed by Gemini, Claude, and Llama to compare silhouette scores and sentiment distributions.

### Open Question 2
- Question: Can the EmoXpt framework effectively detect complex emotional states such as sarcasm, irony, or ambivalence?
- Basis in paper: The conclusion suggests that "exploring complex sentiments such as sarcasm and ambivalence" is necessary to deepen insights.
- Why unresolved: The study utilized K-means clustering on BERT embeddings for binary (positive/negative) classification, which struggles with the nuance of complex sentiments (evidenced by low silhouette scores for human text).
- Evidence: Testing the framework against a gold-standard dataset annotated specifically for sarcasm and mixed emotions to evaluate clustering accuracy beyond binary labels.

### Open Question 3
- Question: How do emotional variances in human comments and LLM responses fluctuate over extended periods?
- Basis in paper: The paper notes the data was collected over only two months and suggests "longitudinal studies of emotional patterns" as future work.
- Why unresolved: The short timeframe (Marchâ€“April 2023) prevents the observation of long-term trends, seasonal shifts in opinion, or the impact of major LLM updates on public sentiment.
- Evidence: A time-series analysis of sentiment scores spanning multiple years or major model version releases to track the evolution of emotional dynamics.

## Limitations
- Binary sentiment classification oversimplifies complex emotional expression and may miss nuanced emotional states
- Dataset limited to English-language tweets on specific generative AI topics, reducing generalizability
- K-means clustering approach may not capture full complexity of emotional variances, particularly for human comments
- Short two-month data collection period prevents analysis of temporal trends and seasonal patterns

## Confidence
- **High confidence**: The observed quantitative difference in sentiment polarity between human comments (72% negative) and ChatGPT responses (90% positive) is robust and well-supported by the methodology
- **Medium confidence**: The interpretation that LLM responses are "more cohesive" based on higher silhouette scores (0.58 vs 0.19) requires caution, as this metric primarily reflects clustering consistency rather than emotional nuance or quality
- **Medium confidence**: The conclusion about lack of nuanced emotional expression in LLM responses is supported but would benefit from qualitative analysis to identify specific types of nuance missing

## Next Checks
1. Conduct cross-cultural validation using multilingual datasets to assess whether the observed sentiment patterns hold across different linguistic and cultural contexts, particularly testing whether the positivity bias in LLM responses persists across languages
2. Implement a more granular sentiment classification system (e.g., fine-grained sentiment categories or emotional dimensions like joy, anger, fear) to capture emotional nuances that binary classification may miss, and compare these patterns between human and AI-generated content
3. Perform temporal analysis by collecting data at multiple time points to determine whether sentiment patterns toward generative AI are stable or evolving, and whether LLM sentiment consistency changes as models are updated