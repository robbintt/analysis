---
ver: rpa2
title: 'Beyond Natural Language Perplexity: Detecting Dead Code Poisoning in Code
  Generation Datasets'
arxiv_id: '2502.20246'
source_url: https://arxiv.org/abs/2502.20246
tags:
- code
- depa
- dead
- onion
- perplexity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DEPA, a line-level detection method designed
  to identify dead code poisoning in code generation datasets. By computing line-level
  perplexity tailored to the structural properties of code and comparing each line's
  perplexity to the overall file distribution, DEPA effectively detects anomalous
  lines that may serve as backdoor triggers.
---

# Beyond Natural Language Perplexity: Detecting Dead Code Poisoning in Code Generation Datasets

## Quick Facts
- arXiv ID: 2502.20246
- Source URL: https://arxiv.org/abs/2502.20246
- Reference count: 24
- Primary result: DEPA achieves 0.14-0.19 improvement in F1-score and 44-65% increase in poisoned segment localization precision compared to existing methods

## Executive Summary
This paper introduces DEPA, a line-level detection method designed to identify dead code poisoning in code generation datasets. By computing line-level perplexity tailored to the structural properties of code and comparing each line's perplexity to the overall file distribution, DEPA effectively detects anomalous lines that may serve as backdoor triggers. Experiments show that DEPA significantly outperforms existing methods, achieving a 0.14-0.19 improvement in detection F1-score and a 44-65% increase in poisoned segment localization precision, while also being 0.62-23x faster. This approach provides a robust and efficient solution for safeguarding the integrity of code generation model training datasets.

## Method Summary
DEPA (Dead code Perplexity Analysis) detects dead code poisoning by computing line-level perplexity scores for code files. For each line, it generates n-1 variants of the file (each excluding one other line), then averages the resulting perplexity scores to measure how contextually coherent that line is within the broader code structure. The method calculates the mean and standard deviation of these line-level perplexity scores within each file, flagging lines that exceed the mean plus 1.5 times the standard deviation as potential poison. This statistical outlier detection approach adapts to each file's intrinsic complexity distribution, making it more effective than global thresholding methods.

## Key Results
- DEPA achieves 0.14-0.19 improvement in detection F1-score compared to token-level methods like ONION
- Poisoned segment localization precision increases by 44-65% over baseline approaches
- DEPA processes 88.16 samples/minute, making it 0.62-23x faster than comparable methods
- Performance degrades significantly with high poisoning rates (e.g., 86% in Random-20 experiments)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Line-level perplexity analysis captures structural anomalies in code that token-level methods miss.
- Mechanism: DEPA computes perplexity for each code line by generating n-1 variants of the file (each variant excludes one other line), then averages the resulting perplexity scores. This measures how contextually coherent a line is within the broader code structure, rather than evaluating tokens in isolation.
- Core assumption: Dead code triggers, while syntactically valid, create semantic discontinuities that manifest as elevated perplexity when analyzed as functional units.
- Evidence anchors:
  - [abstract] "DePA computes line-level perplexity by leveraging the contextual relationships between code lines and identifies anomalous lines by comparing their perplexity to the overall distribution within the file."
  - [Section 4] "For each task, the input comprises a text segment describing the intended behavior of the accompanying code segment. To compute the perplexity for line 0, we generate variants by sequentially removing each of the other lines..."
  - [corpus] Evidence from corpus is weak—no directly comparable line-level mechanism found in provided neighbors.

### Mechanism 2
- Claim: File-relative statistical outlier detection handles varying code complexity better than global thresholds.
- Mechanism: DEPA calculates the mean (μ) and standard deviation (σ) of PPL-Line scores within each file. Lines exceeding μ + T×σ (default T=1.5) are flagged. This adapts detection thresholds to each file's intrinsic complexity distribution.
- Core assumption: Poisoned lines are statistical outliers within their specific file context; a global threshold would fail across diverse codebases.
- Evidence anchors:
  - [Section 4] "After calculating perplexity for all lines, we compute the overall mean (µ) and standard deviation (σ) of these values. Finally, we perform the following test for each line: Test(i) = (True, if PPL-Line(i) > µ+Tσ, False, otherwise."
  - [abstract] "...identifies anomalous lines by comparing their perplexity to the overall distribution within the file."
  - [corpus] "Detecting Stealthy Data Poisoning Attacks in AI Code Generators" references loss-based outlier detection conceptually similar but not identical.

### Mechanism 3
- Claim: Larger Code LLMs provide more reliable perplexity signals for semantic anomaly detection than smaller models.
- Mechanism: DEPA uses CodeLlama-7B-Instruct for perplexity computation. Compared to ONION(CodeGPT, 124M params), this yields 44-57% improvement in poisoned segment localization accuracy. Even versus ONION(CodeLlama), DEPA gains 54-65% from its detection strategy.
- Core assumption: Larger models have more accurate internal representations of code semantics, making their perplexity scores a stronger signal for detecting semantic anomalies.
- Evidence anchors:
  - [Section 5.2] "This performance gain is mainly due to the larger CodeLlama model. On the other hand, compared to ONION(CodeLlama), DEPA achieves nearly a 54-65% increase in accuracy."
  - [Section 5.1] "For a fair comparison, we also introduce a second baseline, ONION(CodeLlama), which integrates ONION with CodeLlama-7B-Instruct."

## Foundational Learning

- Concept: **Perplexity as a measure of model surprise**
  - Why needed here: DEPA uses perplexity to quantify how "surprising" a code line is to a trained Code LLM. Lower perplexity indicates the model expected that code; higher perplexity signals potential anomalies.
  - Quick check question: If a line of code has perplexity significantly higher than the file average, what does that suggest about its relationship to surrounding code?

- Concept: **Dead code poisoning vs. traditional backdoors**
  - Why needed here: Dead code is syntactically valid but functionally unreachable (e.g., `while random() > 68: print("warning")`). Unlike trigger words in NLP, dead code exploits structural properties of programming languages.
  - Quick check question: Why might token-level perplexity (like ONION) fail to detect dead code that line-level perplexity catches?

- Concept: **Statistical outlier detection (μ + T×σ thresholding)**
  - Why needed here: DEPA flags lines exceeding 1.5 standard deviations above the file's mean perplexity. This is a simple but effective anomaly detection technique.
  - Quick check question: What happens to detection accuracy if T is set too low (e.g., 0.5) or too high (e.g., 3.0)?

## Architecture Onboarding

- Component map: Preprocessing -> Variant generation -> Perplexity computation -> Statistical thresholding -> Flagging
- Critical path: Line-splitting → Variant generation → Perplexity computation → Statistical thresholding → Flagging. The variant generation loop (O(n²) perplexity calls per file) is the computational bottleneck.
- Design tradeoffs:
  - **Threshold T**: Lower T increases recall but raises false positives; higher T increases precision but may miss subtle attacks. Paper finds T=1.9 yields peak F1 (0.45) but uses T=1.5 as balanced default.
  - **Model size**: Larger models (CodeLlama-7B) improve accuracy but slow processing. ONION(CodeLlama) processes only 3.71 samples/min vs. DEPA's 88.16 samples/min.
  - **Line-level vs. token-level**: Line-level preserves code structure but may miss variable/function name modifications (noted as a limitation).
- Failure signatures:
  - **High poison ratio**: Random-20 (86% dead code) causes DEPA's accuracy to drop to 0.86; poisoned lines no longer appear as outliers.
  - **Adaptive attacks**: Genetic algorithm-generated triggers reduce DEPA's F1 from 0.28 to 0.19 (still outperforms ONION baselines).
  - **Multi-statement lines**: C++ allows multiple commands per line; DEPA may misidentify poisoned code due to line-level granularity.
  - **Cross-line statements**: Python PEP8 splits long statements across lines; DEPA may struggle, increasing false positives.
- First 3 experiments:
  1. **Baseline comparison**: Replicate F1-score comparison on MBPP dataset with 5% poisoning rate across DEPA, ONION(CodeGPT), and ONION(CodeLlama). Verify DEPA achieves ~0.28 F1 vs. baselines' 0.09-0.14.
  2. **Threshold sensitivity**: Vary T from 1.0 to 2.5 on MBPP Random-1 dataset; plot F1-score curve. Expect peak around T=1.9 per Figure 3.
  3. **Scalability test**: Measure processing time (samples/min) on MathQA-Python (21,495 tasks). Expect DEPA ~68 samples/min vs. ONION(CodeLlama) ~2.9 samples/min per Table 4.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can DEPA be adapted to effectively detect dead code in programming languages with different structural constraints, such as C++ or Java?
- Basis in paper: [explicit] The authors state in the Limitations section that DEPA focuses on Python and may not generalize seamlessly to languages like C++, where semicolons allow multiple commands on a single line, potentially leading to misidentification.
- Why unresolved: The current line-level parsing logic assumes a correlation between lines and operational units typical of Python, which does not hold for all languages.
- What evidence would resolve it: A modified version of DEPA demonstrating high F1-scores on datasets written in semicolon-delimited languages like C++ or Java.

### Open Question 2
- Question: Can DEPA be extended to identify "covert" poisoning techniques that modify variable names or function signatures rather than inserting functionally redundant code?
- Basis in paper: [explicit] The Discussion section notes that DEPA produces false positives against covert attacks (e.g., modifying variables) and suggests future research should refine detection for these scenarios.
- Why unresolved: DEPA relies on identifying anomalous lines based on functional redundancy and contextual fit; subtle semantic changes within valid lines do not trigger the current perplexity-based anomaly detection mechanism.
- What evidence would resolve it: Experiments showing DEPA's detection performance on datasets poisoned with non-dead-code triggers, such as the variable-renaming attacks described in Sun et al. (2023).

### Open Question 3
- Question: Does incorporating static analysis tools or syntax rule checks into the DEPA pipeline significantly reduce false positives without compromising detection speed?
- Basis in paper: [explicit] The authors mention in the Discussion that "future research should refine perplexity-based detection and incorporate additional features, including static analysis and syntax rule checks, to reduce false positives."
- Why unresolved: While the paper compares DEPA against static tools (Vulture, Pylint) separately, it does not evaluate a hybrid approach that combines DEPA's perplexity analysis with rule-based static checking.
- What evidence would resolve it: Ablation studies comparing standard DEPA against a hybrid DEPA-static-analysis model on metrics of precision and processing time.

## Limitations

- **Syntax Sensitivity**: The "leave-one-out" variant generation can create syntactically invalid code when removing critical lines, potentially distorting perplexity scores.
- **Poison Ratio Dependence**: DEPA's performance degrades significantly with high poisoning rates, as the statistical outlier detection assumes poisoned lines are minority anomalies.
- **Granularity Constraints**: Line-level analysis may miss dead code embedded within longer statements or across multiple lines, particularly in Python where control structures can span multiple lines.

## Confidence

- **High Confidence**: The mechanism for computing line-level perplexity and the superiority over token-level methods (ONION baselines) are well-supported by quantitative comparisons (0.14-0.19 F1 improvement, 44-65% localization precision gains).
- **Medium Confidence**: The claim that CodeLlama-7B-Instruct is optimal for this task is supported by performance data but lacks ablation studies comparing different model sizes or architectures.
- **Low Confidence**: The paper's assumption that all dead code manifests as semantic discontinuities detectable by perplexity is not fully validated against semantically coherent but unreachable code.

## Next Checks

1. **Syntax Robustness Test**: Run DEPA on a subset of variants with automatic syntax validation to measure how often "leave-one-out" generation creates invalid Python and quantify the impact on detection accuracy.

2. **Adaptive Attack Resilience**: Evaluate DEPA against dead code that is syntactically valid and semantically coherent with surrounding code (e.g., unreachable code within complex conditional expressions) to identify failure modes beyond simple statistical outliers.

3. **Cross-Language Generalization**: Test DEPA on C++ and Java codebases to validate performance across different code structures, particularly for multi-statement lines and cross-line control flow patterns.