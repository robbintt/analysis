---
ver: rpa2
title: 'Bayesian Optimization with Expected Improvement: No Regret and the Choice
  of Incumbent'
arxiv_id: '2508.15674'
source_url: https://arxiv.org/abs/2508.15674
tags:
- regret
- lemma
- bound
- cumulative
- bpmi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper analyzes the cumulative regret upper bound of the classic
  noisy Gaussian process expected improvement (GP-EI) algorithm, which has remained
  an open question despite its widespread use in Bayesian optimization. The study
  focuses on the Bayesian setting where the objective function is assumed to be a
  sample from a Gaussian process, and examines three commonly used incumbents: best
  posterior mean incumbent (BPMI), best sampled posterior mean incumbent (BSPMI),
  and best observation incumbent (BOI).'
---

# Bayesian Optimization with Expected Improvement: No Regret and the Choice of Incumbent

## Quick Facts
- **arXiv ID**: 2508.15674
- **Source URL**: https://arxiv.org/abs/2508.15674
- **Reference count**: 10
- **Primary result**: Establishes that GP-EI with Best Posterior Mean Incumbent (BPMI) and Best Sampled Posterior Mean Incumbent (BSPMI) are no-regret algorithms with sublinear cumulative regret bounds, while Best Observation Incumbent (BOI) exhibits brittle behavior in high-noise settings.

## Executive Summary
This paper resolves a long-standing open question about the cumulative regret properties of the classic noisy Gaussian process expected improvement (GP-EI) algorithm. The authors demonstrate that the choice of incumbent (current best value) critically determines whether GP-EI achieves sublinear cumulative regret. Specifically, BPMI and BSPMI enable GP-EI to be a no-regret algorithm with bounds of $O(T^{3/4} \log^{d+2/2}(T))$ for squared exponential kernels and $O(T^{(3ν+2d)/(4ν+2d)} \log^{(4ν+d)/(4ν+2d)}(T))$ for Matérn kernels, while BOI fails to guarantee sublinear cumulative regret due to its sensitivity to noisy observations. The theoretical analysis is validated through experiments on six benchmark functions showing BPMI and BSPMI exhibit no-regret behavior while BOI performs worse under high noise conditions.

## Method Summary
The paper analyzes GP-EI in a Bayesian setting where the objective function is a sample from a Gaussian process. The method examines three incumbent definitions: BPMI (minimizer of posterior mean over the domain), BSPMI (minimum of posterior mean over sampled points), and BOI (minimum of noisy observations). Theoretical analysis derives cumulative regret bounds using super-martingale techniques and probability bounds conditioned on the history. The analysis transforms instantaneous regret bounds to eliminate dependence on the posterior standard deviation at the unknown optimum, revealing new exploration-exploitation properties of the non-convex EI functions. Numerical experiments validate these bounds by comparing cumulative regret per iteration across six benchmark functions with varying noise levels and kernels.

## Key Results
- GP-EI with BPMI achieves cumulative regret bound $O(T^{3/4} \log^{d+2/2}(T))$ for SE kernels and $O(T^{(3ν+2d)/(4ν+2d)} \log^{(4ν+d)/(4ν+2d)}(T))$ for Matérn kernels
- GP-EI with BSPMI has slightly looser regret bounds than BPMI but maintains sublinear cumulative regret with better computational efficiency
- GP-EI with BOI either achieves sublinear cumulative regret or exhibits fast converging noisy simple regret, explaining its brittleness in high-noise settings
- Experimental validation shows BPMI and BSPMI exhibit no-regret behavior while BOI performs worse under high noise conditions

## Why This Works (Mechanism)

### Mechanism 1
The theoretical guarantee of GP-EI depends critically on how the incumbent is defined. BPMI and BSPMI allow for bounding cumulative regret such that $R_T/T \to 0$ (sublinear), while BOI creates brittleness where a large negative noise sample can permanently depress the incumbent. This occurs because the objective function is assumed to be a sample from a Gaussian Process with noisy observations. The evidence shows BPMI achieves regret bounds while GP-EI with BOI is not guaranteed to be no-regret due to the presence of noise events in the cumulative upper bound. The break condition occurs when observation noise is extremely high relative to function range, causing BOI's performance to degrade.

### Mechanism 2
Bounding cumulative regret requires transforming instantaneous regret bounds to remove dependence on the posterior standard deviation at the unknown optimum. The authors derive a transformed instantaneous regret bound by analyzing the exploration-exploitation trade-off inherent in EI. If regret were too high, the acquisition function value at the optimal discretized point would exceed that of the selected point—a contradiction. This relies on Lipschitz continuity of $f$ and time-varying discretization. The break condition is that if the kernel does not support the necessary smoothness, the discretization error might dominate.

### Mechanism 3
Standard probability bounds produce constants too large to prove sublinear regret. The analysis uses super-martingales with a filtration instead of union bounds, conditioning on history and introducing a specific failure probability parameter $\alpha$ to balance analytic constants against failure probability. This requires Gaussian noise assumptions. The break condition is that the choice of $\alpha$ is kernel-dependent, and choosing the wrong $\alpha$ for a specific kernel type theoretically prevents achieving the optimal regret rate.

## Foundational Learning

- **Concept**: **Gaussian Process (GP) Posterior**
  - **Why needed here**: The paper analyzes "GP-EI," meaning the surrogate model is a GP. Understanding that the posterior consists of a mean $\mu_t(x)$ and variance $\sigma^2_t(x)$ is essential, as the "incumbent" definitions directly manipulate these values.
  - **Quick check question**: How does the posterior variance $\sigma^2_t(x)$ typically change as more points are observed near $x$?

- **Concept**: **Cumulative vs. Simple Regret**
  - **Why needed here**: The paper's central thesis distinguishes between "no-regret" algorithms (minimizing cumulative regret $R_T = \sum r_t$) and "optimization" algorithms (minimizing simple regret $f(x^+) - f(x^*)$). BOI is shown to trade off cumulative regret guarantees for fast simple regret convergence.
  - **Quick check question**: If an algorithm samples the optimal point $x^*$ immediately but continues to sample poor points afterward, does it have low simple regret? What about cumulative regret?

- **Concept**: **Acquisition Functions (Expected Improvement)**
  - **Why needed here**: The mechanism of EI relies on the trade-off between "exploitation" ($\xi^+ - \mu(x)$) and "exploration" ($\sigma(x)$). The "incumbent" $\xi^+$ is the lever the paper adjusts.
  - **Quick check question**: In the EI formula, if the incumbent $\xi^+$ is set too low (e.g., due to noise), does the algorithm become more exploratory or more exploitative?

## Architecture Onboarding

- **Component map**: Surrogate Model (GP) -> Incumbent Selector (BPMI/BSPMI/BOI) -> Acquisition Optimizer (EI maximization) -> Noise Handler (observation processing)
- **Critical path**: The selection of the incumbent $\xi^+$. If implementing BPMI, you must perform an internal optimization of the GP mean (computationally costly). If implementing BOI, you simply look up the lowest observed value (cheap), but risk the "brittleness" described in Remark 8.
- **Design tradeoffs**:
  - **BPMI**: Best theoretical cumulative regret; computationally expensive (requires nested optimization)
  - **BSPMI**: Good regret (slightly looser bounds than BPMI); computationally cheap (only checks sampled points)
  - **BOI**: Fast simple regret convergence (good for pure optimization); potentially poor cumulative regret in high noise (bad for bandit setting)
- **Failure signatures**:
  - **BOI Stagnation**: In high-noise environments, $y^+_{t-1}$ drops below $f(x^*)$ due to negative noise shock, causing EI to "turn off" exploitation near optimum
  - **BPMI Overhead**: Runtime bloat due to solving $\min_x \mu_t(x)$ at every iteration
- **First 3 experiments**:
  1. **Noise Sensitivity Test**: Run GP-EI with BOI vs. BSPMI on Branin while ramping up observation noise (0.01, 0.1, 0.5). Observe if BOI's cumulative regret $R_T/T$ stops converging to 0 while BSPMI continues to converge.
  2. **Incumbent Efficiency Benchmark**: Compare wall-clock time per iteration of BPMI vs. BSPMI on Hartmann 6D to quantify the cost of global mean optimization in BPMI.
  3. **Simple Regret Race**: Test if BOI actually finds a point with lower simple regret faster than BPMI/BSPMI in the low-noise regime.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can cumulative regret bounds for classic GP-EI be established in the frequentist setting where the objective function is fixed rather than sampled from a GP?
- **Basis in paper**: Section 5.4 states that extending results to the frequentist setting is "challenging, mainly due to the lack of tight confidence interval on $|f(x) - \mu_{t-1}(x)|$ at given $t$."
- **Why unresolved**: The Bayesian setting allows for point-wise confidence intervals with specific probabilities that facilitate the summation of regret terms; current frequentist bounds result in constants too large to produce sublinear cumulative regret.
- **What evidence would resolve it**: A derivation of sublinear cumulative regret for GP-EI under standard frequentist assumptions (e.g., RKHS norm bounded).

### Open Question 2
- **Question**: Is the failure of BOI to guarantee no-regret a fundamental property caused by the exploitation-exploration trade-off decaying too quickly?
- **Basis in paper**: Remark 8 conjectures that for BOI, the relative importance of exploitation decreases at a rate of $O(\sigma_{t-1}(x_t))$, which might be "decreasing to 0 too quickly... to attain a sublinear cumulative regret."
- **Why unresolved**: The theoretical bound for BOI remains conditional on $n_y(T)$, and a definitive proof regarding the asymptotic behavior of the exploitation ratio has not been established.
- **What evidence would resolve it**: A formal proof linking the decay rate of the EI derivatives to linear regret, or a modified proof demonstrating sublinear regret is achievable under specific conditions.

### Open Question 3
- **Question**: Are the derived regret upper bounds (e.g., $O(T^{3/4})$) for GP-EI with BPMI and BSPMI tight, or could they be improved to match GP-UCB rates?
- **Basis in paper**: Remark 12 notes that the regret bounds for GP-EI are larger than those for GP-UCB and GP-TS, and attributes the maintenance of the rate to "intrinsic properties of EI" and the "analytic tool" $\alpha$.
- **Why unresolved**: The proof technique requires introducing auxiliary parameters ($\alpha_t, \zeta_t$) to manage confidence probabilities, which may inflate the final bound order.
- **What evidence would resolve it**: Derivation of lower bounds for GP-EI regret that match the paper's upper bounds, or a novel proof technique eliminating auxiliary parameter dependencies.

## Limitations
- The theoretical analysis relies heavily on the Bayesian framework where the objective function is a sample from a Gaussian Process, limiting practical relevance for functions that don't align well with GP priors
- The computational complexity of BPMI (requiring global optimization of the posterior mean at each iteration) may limit its practical adoption despite superior theoretical guarantees
- The super-martingale approach for handling failure probabilities introduces the parameter $\alpha$ whose optimal selection depends on kernel characteristics but is not universally specified

## Confidence

- **High Confidence**: The distinction between BPMI/BSPMI and BOI for cumulative regret behavior, supported by experimental validation showing BOI's performance degradation under high noise
- **Medium Confidence**: The specific regret bounds for BPMI and BSPMI, as they depend on kernel-specific constants and the effectiveness of the transformation technique
- **Medium Confidence**: The computational complexity claims, as exact implementation details of the nested optimizations are not fully specified

## Next Checks

1. **Implementation Fidelity Test**: Re-implement the three incumbent definitions (BPMI, BSPMI, BOI) and reproduce the cumulative regret convergence plots from Section 5.1 to verify theoretical bounds match empirical behavior

2. **Noise Sensitivity Validation**: Systematically vary observation noise levels ($\sigma$) across multiple benchmark functions to confirm that BOI's performance degradation follows the predicted pattern while BPMI/BSPMI maintain sublinear regret

3. **Computational Overhead Measurement**: Benchmark the wall-clock time per iteration for BPMI versus BSPMI on high-dimensional functions to quantify the practical cost of the nested posterior mean optimization