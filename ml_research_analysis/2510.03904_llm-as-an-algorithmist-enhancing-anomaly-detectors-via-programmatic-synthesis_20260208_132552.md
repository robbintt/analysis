---
ver: rpa2
title: 'LLM as an Algorithmist: Enhancing Anomaly Detectors via Programmatic Synthesis'
arxiv_id: '2510.03904'
source_url: https://arxiv.org/abs/2510.03904
tags:
- anomalies
- data
- code
- anomaly
- detector
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces LLM-DAS, a novel framework that enhances existing
  anomaly detectors by leveraging Large Language Models (LLMs) as "algorithmists"
  rather than data processors. LLM-DAS addresses the challenge of fragile assumptions
  in traditional anomaly detection methods by generating detector-specific, data-agnostic
  Python code that synthesizes "hard-to-detect" anomalies.
---

# LLM as an Algorithmist: Enhancing Anomaly Detectors via Programmatic Synthesis

## Quick Facts
- arXiv ID: 2510.03904
- Source URL: https://arxiv.org/abs/2510.03904
- Reference count: 12
- One-line primary result: LLM-DAS achieves 84.49% relative AUC-PR improvement for OCSVM on tabular anomaly detection benchmarks

## Executive Summary
This paper introduces LLM-DAS, a novel framework that enhances existing anomaly detectors by leveraging Large Language Models (LLMs) as "algorithmists" rather than data processors. LLM-DAS addresses the challenge of fragile assumptions in traditional anomaly detection methods by generating detector-specific, data-agnostic Python code that synthesizes "hard-to-detect" anomalies. The LLM analyzes the detector's logic and produces reusable code to create anomalies that exploit the detector's weaknesses. These synthetic anomalies are then used to augment training data, transforming the problem into a more discriminative two-class classification task.

## Method Summary
LLM-DAS operates in two phases: first, it uses an LLM to generate detector-specific Python code that synthesizes "hard-to-detect" anomalies by analyzing the detector's assumptions and weaknesses; second, it executes this code to create synthetic anomalies from borderline normal samples, augments the training data, and trains a binary classifier whose scores are fused with the original detector's scores. The framework is designed to be data-agnostic, with the code generation occurring only once per detector type and being reusable across datasets.

## Key Results
- Achieves average AUC-PR improvement of 0.0723 (84.49% relative improvement) for OCSVM across 36 tabular datasets
- Consistently improves performance across mainstream detectors including PCA, IForest, OCSVM, ECOD, and DRL
- Demonstrates that detector-specific code generation is critical, as cross-detector synthesis can harm performance

## Why This Works (Mechanism)

### Mechanism 1: Detector-Aware Algorithmic Reasoning
The LLM generates effective anomaly synthesis code by reasoning about detector assumptions without accessing raw data. It receives a detector's abstract description and pseudo-code, identifies structural weaknesses (e.g., IForest assumes anomalies have short isolation paths), and outputs Python code that programmatically targets those weaknesses. This decouples reasoning from data, enabling reusable synthesis logic.

### Mechanism 2: Borderline Sample Identification and Controlled Extrapolation
The framework synthesizes "hard" anomalies by transforming borderline normal samples, which yields more informative augmentation than random perturbation. The generated code queries the fitted detector's score function to identify normal training samples in the top percentile of anomaly scores (borderline samples), then applies controlled transformations that push these seeds into sparse regions while avoiding transformations that would make them "easy" anomalies for that specific detector.

### Mechanism 3: Two-Stage Score Fusion
The framework fuses the original detector's scores with a binary classifier trained on augmented data, preserving original biases while adding discriminative patterns. After synthesizing anomalies, the augmented dataset trains a binary classifier (default: RandomForest), and the final score is the sum of min-max normalized scores from the original detector and enhancement classifier.

## Foundational Learning

- **Concept**: One-Class vs. Two-Class Anomaly Detection Paradigms
  - Why needed: LLM-DAS explicitly transforms one-class (normal-only training) into two-class (normal + synthetic anomalies). Understanding this shift is essential for interpreting why augmentation helps.
  - Quick check: Can you explain why adding synthetic anomalies changes the learning objective from density estimation to discrimination?

- **Concept**: Detector-Specific Assumptions (Reconstruction, Isolation, Density, Boundary)
  - Why needed: The framework's core premise is that each detector has fragile assumptions (e.g., IForest: short paths; PCA: high reconstruction error). The LLM targets these specifically.
  - Quick check: For a density-based detector like ECOD, what type of anomaly would be "hard" and why?

- **Concept**: Prompt Engineering for Code Generation (Description + Objective + Requirements)
  - Why needed: The framework uses a structured prompt with three components. Understanding each component's role is critical for extending to new detectors.
  - Quick check: What goes wrong if you remove p_description (detector pseudo-code) from the prompt?

## Architecture Onboarding

- **Component map**: Detector description -> LLM generates p_description -> constructs p_code -> outputs Code^t -> Interface I^t with D_train, f_t, N_syn -> execute Code^t -> D_syn^t -> D_aug = D_train ∪ D_syn^t -> train binary classifier f̃_t -> fuse via F_t

- **Critical path**:
  1. Generate p_description via LLM self-prompting (Eq. 2)
  2. Construct p_code with symbolic interface definitions (e.g., model.predict_score(), X_train)
  3. Execute generated code locally with fitted detector and training data
  4. Train RandomForest enhancement classifier on augmented data
  5. Normalize and sum scores at inference

- **Design tradeoffs**:
  - N_syn (number of synthetic anomalies): Default 10% of training size; higher may improve recall but risks synthetic-to-real distribution drift
  - Enhancement classifier choice: RandomForest default provides interpretability; deeper models may overfit synthetic patterns
  - Score fusion weights: Equal weighting is simple but may underweight the more reliable component for certain detectors

- **Failure signatures**:
  - Generated code fails to parse: Check prompt formatting; ensure requirements section specifies strict Python syntax
  - No improvement over baseline: Verify borderline percentile is not too low (may select easy anomalies) or too high (may select too few seeds)
  - Performance degradation on specific datasets: Cross-detector synthesis shows mismatched codes can harm performance; ensure Code^t matches detector type t

- **First 3 experiments**:
  1. Replicate OCSVM enhancement on 3 datasets from Table 1 (e.g., Vertebral, Glass, Cardio) to validate AUC-PR gains; compare against random noise baseline.
  2. Ablate borderline selection: Replace top-percentile seed selection with random normal sample selection; measure AUC-PR drop.
  3. Cross-detector test: Apply Code^IForest to enhance OCSVM; confirm inconsistent or negative results per Table 2 to validate detector-awareness requirement.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the "LLM as an algorithmist" paradigm be generalized to enhance detectors in non-tabular domains, such as time-series or graph anomaly detection?
- Basis in paper: The conclusion states that the paradigm opens "exciting new avenues, such as enhancing algorithms in other domains."
- Why unresolved: The current study strictly evaluates tabular anomaly detection (TAD) benchmarks and does not provide experimental validation for data types with different structural constraints.
- What evidence would resolve it: Successful application of the LLM-DAS framework to time-series or graph datasets, demonstrating consistent performance improvements similar to those observed in tabular benchmarks.

### Open Question 2
- Question: How robust is the synthesis code generation when the LLM's understanding of a detector's logic is imperfect or hallucinated?
- Basis in paper: The method relies on the LLM generating a "Detector description" and "Pseudo code" to identify weaknesses; however, the paper does not analyze failure cases where the LLM might misunderstand the algorithm.
- Why unresolved: The experiments utilize mainstream detectors on which the LLM is likely well-trained, leaving the system's resilience to misinterpretations of complex or novel algorithms untested.
- What evidence would resolve it: An analysis of performance degradation or error rates when applying LLM-DAS to obscure or newly proposed detectors that are potentially under-represented in the LLM's training data.

### Open Question 3
- Question: Is the performance of LLM-DAS dependent on the specific proprietary model (Gemini-2.5-Pro), or can it be replicated with open-source alternatives?
- Basis in paper: The implementation details specify the exclusive use of the Gemini-2.5-Pro API for the code generation phase.
- Why unresolved: While the code is reusable, the initial reasoning step relies on a specific high-capacity model; it is unclear if smaller or open-source LLMs possess the necessary reasoning capabilities to generate effective synthesis policies.
- What evidence would resolve it: Comparative experiments using different base LLMs (e.g., GPT-4, Llama 3) to generate the synthesis code, measuring the resulting detection performance on the same benchmarks.

## Limitations

- The exact prompt templates are not provided, making faithful reproduction challenging
- The framework relies heavily on the LLM's prior knowledge of anomaly detection algorithms, which may be insufficient for novel or poorly documented detectors
- There is a risk of synthetic-to-real distribution drift if synthetic anomalies generated from normal samples do not adequately represent real anomaly distributions

## Confidence

- **High Confidence**: The core mechanism of detector-aware algorithmic reasoning and the two-stage score fusion are well-supported by the experimental results
- **Medium Confidence**: The effectiveness of borderline sample identification and controlled extrapolation is supported by ablation studies, but implementation details are not fully specified
- **Low Confidence**: The generalizability of the approach to novel detectors or domains is uncertain due to reliance on LLM's prior knowledge

## Next Checks

1. Reconstruct prompt templates based on paper description and test their effectiveness in generating valid synthesis code for different detectors; measure success rate and quality of generated anomalies
2. Apply synthesis code generated for one detector (e.g., IForest) to enhance a different detector (e.g., OCSVM); confirm performance degradation validates detector-specific nature
3. Analyze distribution of synthetic anomalies generated by LLM-DAS compared to real anomalies using statistical measures (KL divergence, Wasserstein distance) to assess similarity and distribution drift risk