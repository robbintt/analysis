---
ver: rpa2
title: 'Catch Me If You Can: How Smaller Reasoning Models Pretend to Reason with Mathematical
  Fidelity'
arxiv_id: '2512.00552'
source_url: https://arxiv.org/abs/2512.00552
tags:
- reasoning
- mathematical
- logical
- across
- transitivity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a diagnostic framework to distinguish genuine
  mathematical reasoning from superficial pattern matching in language models. By
  evaluating Qwen3-0.6B on MenatQA, the authors reveal that while the model achieves
  70%+ answer accuracy, it demonstrates poor backward consistency (15%), limited transitivity
  coverage (32.2%), and brittle perturbation sensitivity.
---

# Catch Me If You Can: How Smaller Reasoning Models Pretend to Reason with Mathematical Fidelity

## Quick Facts
- arXiv ID: 2512.00552
- Source URL: https://arxiv.org/abs/2512.00552
- Authors: Subramanyam Sahoo; Vinija Jain; Saanidhya Vats; Siddharth Mohapatra; Rui Min; Aman Chadha; Divya Chaudhary
- Reference count: 5
- The paper introduces a diagnostic framework to distinguish genuine mathematical reasoning from pattern matching in small language models

## Executive Summary
This study exposes how small reasoning models like Qwen3-0.6B can achieve high answer accuracy while relying on superficial pattern matching rather than genuine mathematical reasoning. The authors introduce a diagnostic framework evaluating four dimensions: forward-backward consistency, transitivity coverage, counterfactual sensitivity, and perturbation robustness. Testing on the MenatQA benchmark reveals that while the model achieves 70%+ answer accuracy, it demonstrates only 15% backward consistency and 32.2% transitivity coverage, indicating brittle reasoning patterns. The framework provides model-agnostic tools for detecting reasoning failures invisible to traditional accuracy metrics, with released protocols for community use.

## Method Summary
The authors developed a diagnostic framework to evaluate mathematical reasoning quality in small language models by examining four key dimensions: forward-backward consistency (checking if answers remain consistent when reversing the problem), transitivity coverage (verifying logical chain completeness), counterfactual sensitivity (testing robustness to hypothetical modifications), and perturbation robustness (assessing stability under input variations). They applied this framework to evaluate Qwen3-0.6B on the MenatQA benchmark, analyzing both answer accuracy and reasoning chain quality. The methodology moves beyond surface-level accuracy metrics to expose whether models truly understand mathematical relationships or merely match patterns from training data.

## Key Results
- Qwen3-0.6B achieves 70%+ answer accuracy on MenatQA but shows only 15% backward consistency
- Transitivity coverage remains low at 32.2%, indicating incomplete logical reasoning chains
- Performance degrades significantly with increased reasoning complexity and input perturbations
- The model demonstrates heavy reliance on pattern matching rather than genuine logical computation

## Why This Works (Mechanism)
The framework works by systematically probing the reasoning process at multiple structural levels. Forward-backward consistency checks whether mathematical relationships are bidirectional and logically sound. Transitivity coverage verifies that intermediate reasoning steps form complete logical chains rather than isolated pattern matches. Counterfactual sensitivity tests whether the model can handle hypothetical modifications to problem parameters, revealing whether it understands underlying principles or memorized solutions. Perturbation robustness examines stability under input variations, exposing brittle pattern dependencies. Together, these metrics create a multi-dimensional probe that reveals superficial reasoning invisible to answer accuracy alone.

## Foundational Learning
- Mathematical reasoning fidelity - Understanding what constitutes genuine versus superficial mathematical reasoning; needed to establish evaluation criteria and distinguish pattern matching from logical computation
- Chain-of-thought analysis - Examining intermediate reasoning steps rather than just final answers; required to identify where reasoning breaks down and whether logical chains are complete
- Perturbation testing methodology - Systematic modification of inputs to test robustness; essential for exposing brittle pattern dependencies and model overconfidence

## Architecture Onboarding
- Component map: Input Problem -> Chain-of-Thought Generation -> Answer Prediction -> Reasoning Chain Analysis -> Consistency/Robustness Evaluation
- Critical path: The reasoning chain generation and analysis stages are most critical, as they determine whether logical relationships are properly established and verified
- Design tradeoffs: High accuracy requires pattern matching capabilities, but this conflicts with genuine reasoning fidelity; the framework exposes this tension
- Failure signatures: High answer accuracy combined with low backward consistency, low transitivity coverage, and high perturbation sensitivity indicates superficial reasoning
- First experiments:
  1. Apply forward-backward consistency test to simple arithmetic problems
  2. Test transitivity coverage on multi-step word problems
  3. Evaluate perturbation robustness using controlled input modifications

## Open Questions the Paper Calls Out
None

## Limitations
- Findings are based on a single small model (Qwen3-0.6B), limiting generalizability to all smaller reasoning models
- Evaluation metrics depend on gold standard reasoning chains that may not capture all valid reasoning paths
- Perturbation analysis uses limited perturbations that may not exhaustively test model robustness
- Study focuses only on mathematical reasoning domains, not testing framework applicability to other reasoning types

## Confidence
- Core finding (Qwen3-0.6B exhibits superficial reasoning): High
- Framework utility for exposing reasoning failures: Medium-High
- Generalizability to all smaller reasoning models: Medium

## Next Checks
1. Apply the diagnostic framework to at least three additional small reasoning models (â‰¤2B parameters) to determine whether the observed patterns of superficial reasoning are consistent across architectures and training approaches.

2. Conduct ablation studies removing the CoT component to establish whether the observed failures stem from the reasoning process itself versus the underlying model capabilities.

3. Extend evaluation to non-mathematical reasoning domains (causal inference, logical deduction, commonsense reasoning) to assess whether the framework's diagnostic power generalizes beyond mathematical problem-solving.