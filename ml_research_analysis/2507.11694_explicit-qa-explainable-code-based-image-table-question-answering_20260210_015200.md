---
ver: rpa2
title: 'ExpliCIT-QA: Explainable Code-Based Image Table Question Answering'
arxiv_id: '2507.11694'
source_url: https://arxiv.org/abs/2507.11694
tags:
- table
- code
- reasoning
- question
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ExpliCIT-QA addresses the challenge of creating explainable systems
  for visual question answering over complex table images. It builds on the MRT approach,
  using a modular pipeline combining multimodal table understanding, chain-of-thought
  reasoning, automatic code generation, code execution, and natural language explanation.
---

# ExpliCIT-QA: Explainable Code-Based Image Table Question Answering

## Quick Facts
- arXiv ID: 2507.11694
- Source URL: https://arxiv.org/abs/2507.11694
- Authors: Maximiliano Hormazábal Lagos; Álvaro Bueno Sáez; Pedro Alonso Doval; Jorge Alcalde Vesteiro; Héctor Cerezo-Costas
- Reference count: 30
- Primary result: Achieves 27.69% average accuracy on TableVQA-Bench using code-based reasoning, compared to 60.7% for GPT-4V+GPT-4, with superior interpretability

## Executive Summary
ExpliCIT-QA introduces a modular, code-based approach to visual question answering over complex table images, prioritizing interpretability over raw accuracy. The system combines multimodal table understanding, chain-of-thought reasoning, automatic Python/Pandas code generation, and deterministic execution to create fully auditable question-answering pipelines. While achieving lower accuracy (27.69%) compared to end-to-end models like GPT-4V+GPT-4 (60.7%), ExpliCIT-QA provides complete transparency through intermediate artifacts including extracted CSV tables, reasoning steps, and executable code. The approach is particularly suited for high-stakes domains where auditability is critical, though it struggles with irregular table layouts and semantic verification tasks.

## Method Summary
ExpliCIT-QA implements a five-step inference pipeline that transforms table images into executable code for deterministic answer computation. The system uses Qwen-2.5-VL to extract structured CSV data from table images through chain-of-thought reasoning, then employs Qwen-3 to generate natural language reasoning steps and convert them into Python/Pandas code. A Python execution environment runs the generated code with up to three retries on error, and a code-to-text model summarizes the executed steps into the final answer. The approach leverages Program-Aided Language (PAL) principles, replacing direct answer generation with code generation to eliminate arithmetic hallucinations. All intermediate outputs—including extracted CSV tables, reasoning chains, and Python scripts—are available for inspection, enabling full traceability of the answer generation process.

## Key Results
- Achieves 27.69% average accuracy across four TableVQA-Bench subdatasets using Qwen3-4B
- Performance improves to 31.50% with Qwen3-14B, still trailing GPT-4V+GPT-4 at 60.7%
- Scores only 3-5% on VTabFact fact verification tasks, indicating architecture limitations for semantic tasks
- Successfully handles VWTQ and VWTQ-Syn subsets with ~25% accuracy despite complex visual layouts
- FinTabNetQA performance degrades to ~30% due to challenges with multi-row headers and merged cells

## Why This Works (Mechanism)

### Mechanism 1: Code-Grounded Determinism
The pipeline employs Program-Aided Language (PAL) paradigm, translating reasoning steps into executable Python/Pandas code rather than direct answer tokens. This deterministic computation eliminates arithmetic hallucinations by having a Python interpreter derive final values from syntactically valid code. The core assumption is that generated code matches extracted data schema exactly, though this breaks if column names are hallucinated or the execution environment lacks dependencies.

### Mechanism 2: Visual-to-Structure Normalization
A Vision-Language Model (Qwen-2.5-VL) flattens complex table images into standardized CSV structures, isolating visual understanding from logical reasoning. This transformation assumes the VLM can accurately resolve visual ambiguities like spanning cells into linear row-column formats. The mechanism fails when layouts are too irregular (e.g., nested tables), producing garbled CSV that causes "Garbage In, Garbage Out" in subsequent reasoning.

### Mechanism 3: Traceability via Intermediate Artifacts
The modular pipeline exposes intermediate states through human-readable artifacts: raw CSV for data verification, Chain-of-Thought steps for intent verification, and Python code for logic verification. This transparency assumes users have domain knowledge to validate extracted CSV and code logic. However, plausible CoT reasoning with subtly wrong code implementation can create false security unless rigorously reviewed.

## Foundational Learning

**Program-Aided Language Models (PAL)**
- Why needed: Core of ExpliCIT-QA generates Python/Pandas syntax rather than conversational text
- Quick check: Can you explain why delegating calculation to Python interpreter reduces arithmetic errors versus standard LLM response?

**Multimodal Table Structure Recognition (TSR)**
- Why needed: System success depends on first step; understanding VLM handling of OCR + structure vs pure OCR is critical
- Quick check: How would you handle table image with merged header cells when converting to strict row-column CSV format?

**Chain-of-Thought (CoT) Reasoning**
- Why needed: System uses CoT twice—first for visual extraction, then for code generation planning
- Quick check: Does system use CoT to generate final answer directly, or to plan steps for secondary process (code gen)?

## Architecture Onboarding

**Component map:** Table Image → Vision (Qwen-2.5-VL) → CSV + CoT → Reasoning (Qwen-3) → Natural Language Plan → Coding (Qwen-3) → Python/Pandas Code → Execution (Python Env) → Answer + Retries → Explanation (Code-to-Text)

**Critical path:** Table Understanding (Module 1) is bottleneck; misaligned column headers in extracted CSV cause subsequent code generation to reference non-existent columns, causing runtime errors or silent failures.

**Design tradeoffs:** System explicitly sacrifices accuracy (27.69% vs 60.7% SOTA) for interpretability, prioritizing audit trails over raw performance. Suitable for finance/healthcare but potentially insufficient for high-volume consumer apps.

**Failure signatures:**
- VTabFact performance (~3-5%) shows architecture ill-suited for semantic verification versus quantitative retrieval
- Exact-match metrics fail without post-processing normalization when system retrieves "44517" versus ground truth "$44,517"

**First 3 experiments:**
1. Isolate Vision Extraction: Feed gold-standard CSVs directly into Reasoning module to measure upper bound of code-generation accuracy
2. Error Analysis of Retries: Log specific Python exceptions during Code Execution phase to determine if errors are syntactic (LLM failure) or semantic (Column name mismatch)
3. VLM Ablation: Test Table Understanding module on FinTabNetQA subset to identify visual features (merged cells, footnotes) causing extraction breakdowns

## Open Questions the Paper Calls Out

**Open Question 1:** How can multimodal table understanding be improved to robustly handle irregular layouts like multilevel headers and merged cells? The paper identifies Table Understanding phase as main improvement point, noting mechanisms to handle irregular layouts cause recurrent errors. Evidence: Modified pipeline achieving significantly higher FinTabNetQA accuracy without manual intervention.

**Open Question 2:** What methodologies can effectively measure internal coherence of Chain-of-Thought reasoning and fidelity of generated explanations? The Future Work section explicitly states this priority, noting paper lacks quantitative metric to verify correlation between CoT fidelity and answer correctness. Evidence: Proposed metric successfully correlating high CoT fidelity scores with answer correctness.

**Open Question 3:** Can code-based reasoning approaches be adapted to handle semantic tasks like fact verification, or are they inherently limited to numeric computation? Results show VTabFact scores below 5%, suggesting such tasks are less compatible with current code-based reasoning approach. Evidence: Demonstrating code-generation strategy significantly improving VTabFact performance.

## Limitations

- Accuracy significantly lower than end-to-end models (27.69% vs 60.7% SOTA), particularly on semantic verification tasks
- Architecture struggles with irregular table layouts including multi-row headers and merged cells, causing extraction failures
- Reliance on deterministic code execution creates fragility when table extraction fails, with errors propagating irreversibly
- No exact prompt templates or helper function implementations provided, creating reproducibility challenges

## Confidence

**High Confidence:** Code execution mechanism eliminating arithmetic hallucinations is well-supported by empirical results and aligns with PAL literature; traceability benefits clearly demonstrated
**Medium Confidence:** Visual-to-structure normalization works reliably for standard layouts but has documented failure modes with complex visual features
**Low Confidence:** Exact accuracy improvement from Qwen3-14B (31.50%) versus Qwen3-4B (27.69%) requires careful interpretation due to potential stochastic factors

## Next Checks

1. **Upper Bound Isolation Test:** Run reasoning and code generation modules directly on ground-truth CSV files to determine maximum achievable accuracy and isolate whether limitations stem from visual understanding or reasoning execution

2. **Error Attribution Analysis:** Implement comprehensive logging of Python execution errors, categorizing failures by type to quantify whether 3-retry mechanism effectively mitigates common failure modes or masks systematic issues

3. **Visual Feature Ablation:** Systematically test table understanding module on progressively complex table layouts to create failure taxonomy and identify specific visual features causing extraction breakdowns for targeted improvements