---
ver: rpa2
title: Generating Causal Temporal Interaction Graphs for Counterfactual Validation
  of Temporal Link Prediction
arxiv_id: '2602.02161'
source_url: https://arxiv.org/abs/2602.02161
tags:
- causal
- event
- events
- temporal
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a framework for counterfactual validation
  of temporal link prediction (TLP) models by generating causal temporal interaction
  graphs (CTIGs) with known ground-truth causal structure. A structural equation model
  for continuous-time event sequences is proposed, supporting both excitatory and
  inhibitory effects, and extended to temporal interaction graphs.
---

# Generating Causal Temporal Interaction Graphs for Counterfactual Validation of Temporal Link Prediction

## Quick Facts
- arXiv ID: 2602.02161
- Source URL: https://arxiv.org/abs/2602.02161
- Reference count: 16
- Primary result: Introduces a framework for counterfactual validation of temporal link prediction models by generating causal temporal interaction graphs with known ground-truth causal structure.

## Executive Summary
This paper introduces a framework for counterfactual validation of temporal link prediction (TLP) models by generating causal temporal interaction graphs (CTIGs) with known ground-truth causal structure. A structural equation model for continuous-time event sequences is proposed, supporting both excitatory and inhibitory effects, and extended to temporal interaction graphs. To quantify causal model differences, a distance metric based on cross-model predictive error is introduced. The hypothesis that predictors trained on one causal model degrade when evaluated on sufficiently distant models is empirically validated. Counterfactual evaluation is instantiated under controlled causal shifts and timestamp shuffling as a stochastic distortion with measurable causal distance. Experiments show that TGN performs better on original data compared to its distorted counterpart, while JODIE remains largely flat, supporting the framework's ability to benchmark TLP models for causality-aware performance assessment.

## Method Summary
The framework generates synthetic causal temporal interaction graphs using a structural equation model (SEM) with Poisson triggers and influence parameters. Event occurrence is determined by parent events within a time window and trigger indicators. Causal graphs are constructed with excitatory/inhibitory effects, then extended to temporal interaction graphs using node features and edge influence functions. A distance metric quantifies causal dissimilarity via cross-model predictive error. The framework tests whether TLP models trained on one causal model degrade when evaluated on data from a sufficiently different causal model, using both controlled causal shifts and timestamp shuffling as counterfactual scenarios.

## Key Results
- Introduces a structural equation model for continuous-time event sequences supporting excitatory and inhibitory effects
- Proposes a distance metric based on cross-model predictive error to quantify causal model differences
- Empirically validates that predictors trained on one causal model degrade when evaluated on sufficiently distant models
- Shows TGN outperforms on original data compared to distorted counterparts, while JODIE remains flat under temporal shifts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Event occurrence can be modeled as a function of trigger events and historically active parent events within a bounded time window.
- Mechanism: A structural equation model (SEM) defines event occurrence via `x_i(t) = u_i(t) · I{Σ Θ_{i,j} x'_j(t) ≥ 0}`, where `u_i(t)` is a trigger indicator (from a Poisson process with rate λ_i), and `x'_j(t)` indicates whether parent event j occurred in window `(t-τ̄, t)`. Parameters `Θ_{i,j} ∈ [-1,1]` encode excitatory (positive) or inhibitory (negative) influence.
- Core assumption: Temporal dependencies exist; causal relationships propagate with delay; cause and effect unfold on a single continuous timeline.
- Evidence anchors:
  - [abstract] "We first introduce a structural equation model for continuous-time event sequences that supports both excitatory and inhibitory effects."
  - [section 2, Eq. 2] Defines the SEM formally with parent sets and influence parameters.
  - [corpus] Related work on causal event sequences (Cüppers et al., 2024; Jalaldoust et al., 2022) supports plausibility but does not validate this specific SEM.
- Break condition: If events in the target domain lack time-indexed triggers or have no historical influence structure, the SEM reduces to random noise.

### Mechanism 2
- Claim: The dissimilarity between two causal models can be quantified via cross-model predictive error aggregated over sampled event sequences.
- Mechanism: For models C_A and C_B, define `d_B(S_A, Φ_A)` as the mean absolute error when C_B's parameters predict occurrences in sequences generated by C_A (Eq. 7). Symmetrize via geometric mean (Eq. 8) and average over multiple realizations to obtain stable distance `d̄_{A,B}` (Eq. 9).
- Core assumption: The predictive error of an oracle with access to true parameters meaningfully reflects causal dissimilarity.
- Evidence anchors:
  - [section 4, Eq. 7-9] Formal definition of distance metric.
  - [Figure 3] Empirical variance of estimated distance decreases with sample size, suggesting estimator stability.
  - [corpus] No direct corpus validation; distance metrics for causal temporal models remain underexplored.
- Break condition: If sequences are too short or models share near-identical parameter structure, the distance estimate may have high variance or fail to discriminate.

### Mechanism 3
- Claim: Predictive models trained on data from one causal model will degrade when evaluated on data from a sufficiently distant causal model.
- Mechanism: Generate CTIGs from true model C_0 and distorted model C_†. Train predictor on S_0, evaluate on both S_test and S̄_test (from C_†). Performance gap `Δ* = d*(S†) - d*(S0)` increases with causal distance `d̄_{0,†}` beyond threshold β.
- Core assumption: The causal distance metric correctly captures the shift that should degrade a causally-aware predictor.
- Evidence anchors:
  - [Hypothesis 6.1] Formal statement of the degradation hypothesis.
  - [Figure 5] Empirical visualization showing positive performance gap when `d̄_{0,†} > β ≈ 0.45` and model error `d* < δ* ≈ 0.2`.
  - [Figure 6-7] TGN shows increasing performance gap with causal distance; JODIE remains flat—suggesting differential causal sensitivity.
  - [corpus] Prior work (Rahman et al., 2025b) found TLP models insensitive to temporal distortions on real data, but lacked ground-truth causal structure.
- Break condition: If the predictor is purely correlational (e.g., frequency-based), it may not degrade even under large causal shifts.

## Foundational Learning

- **Structural Causal Models (Pearl, 2009)**:
  - Why needed here: The paper's SEM instantiates Pearl's causal model framework; understanding exogeneity, monotonicity, and identifiability is required to interpret Propositions 6-12.
  - Quick check question: Can you explain why a semi-Markovian model allows unobserved confounders among background variables while a Markovian model does not?

- **Point Processes (Poisson, Hawkes)**:
  - Why needed here: Trigger events are sampled from homogeneous Poisson processes; Appendix A defines the 1-D Poisson point process formally.
  - Quick check question: For a Poisson process with rate λ, what is the distribution of the number of events in an interval of length T?

- **Temporal Graph Learning (TGN, JODIE)**:
  - Why needed here: The counterfactual experiments benchmark TGN and JODIE; interpreting results requires basic familiarity with their architectures.
  - Quick check question: How does TGN's memory module differ from JODIE's trajectory embedding approach for handling temporal interactions?

## Architecture Onboarding

- **Component map**:
  1. Trigger Generator → Causal Graph Constructor → Event Evaluator → Distance Estimator → CTIG Extension
  2. Node features → Edge features → Influence matrix Θ → Causal graph A
  3. Trigger sequences → SEM evaluation → Event sequence S
  4. Train TLP model on S_train → Evaluate on S_test and counterfactual test → Compute performance gap

- **Critical path**:
  1. Generate node features → compute edge features → construct influence matrix Θ → derive causal graph A
  2. Generate trigger sequences → evaluate SEM at each trigger time → output event sequence S
  3. Train TLP model on S_train → evaluate on S_test and distorted/counterfactual test → compute performance gap

- **Design tradeoffs**:
  - **Sparsity control**: Higher threshold ν₁ reduces causal graph density, potentially making sequences less predictable but more interpretable
  - **Time window τ̄**: Larger windows allow more historical influence but increase computational cost and may dilute signal
  - **Non-causal edges (l)**: Increasing l adds noise; balances realistic spurious correlations against clean causal signal

- **Failure signatures**:
  - **Empty or near-empty event sequences**: Likely due to aggressive thresholding or overly inhibitory Θ values
  - **Distance estimator high variance**: Increase T × iterations (see Figure 3) or reduce event type count n
  - **No performance gap under distortion**: Model may be learning frequency-only statistics; consider reducing non-causal edges or increasing causal distance

- **First 3 experiments**:
  1. Reproduce Figure 5: Generate pairs (C_0, C_†) at varying distances, train an oracle predictor, and verify that `P(Δ* > 0 | d* < δ*, d̄ > β)` approaches 1 as β increases
  2. Reproduce Figure 6 for TGN: Train TGN on CTIGs from a fixed C_0, evaluate on S_test vs. S̄_test from C_† at increasing distances, confirm positive trend in performance gap
  3. Ablate non-causal edges: Set l = 0, E/4, E/2 and measure how the separation between original and shuffled test performance (Figure 7) changes; hypothesize that fewer non-causal edges increase counterfactual sensitivity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do state-of-the-art temporal graph architectures beyond TGN and JODIE perform under the proposed counterfactual validation framework?
- Basis in paper: [explicit] The authors state in Footnote 14 (Page 11) that "Extending the benchmark to additional TLP models is left to future work."
- Why unresolved: The empirical study was limited to only two representative models (TGN and JODIE), leaving the behavior of other architectures unknown.
- What evidence would resolve it: Evaluation results of additional models (e.g., DyRep, EdgeBank) on the generated CTIGs using the proposed causal distance metric.

### Open Question 2
- Question: Can the proposed framework for counterfactual validation be effectively adapted to other predictive domains involving continuous-time events?
- Basis in paper: [explicit] The conclusion (Page 12) states that "the same methodology can be extended to other predictive domains where the performance of a model under causal shifts is of interest."
- Why unresolved: The current work focuses strictly on temporal interaction graphs; the generalization of the Structural Equation Model (SEM) and distance metric to other domains remains untested.
- What evidence would resolve it: Successful application of the CTIG generation and validation pipeline to domains like financial transactions or biological interaction networks.

### Open Question 3
- Question: How does the approximation error introduced by the negative sampling strategy affect the reliability of the causal distance metric?
- Basis in paper: [inferred] The authors acknowledge (Page 10) that negative samples "are not guaranteed to be infeasible," and attribute "outliers" in the Oracle's performance to this limitation.
- Why unresolved: The paper uses negative sampling as a practical heuristic to handle unobserved trigger events but does not quantify the bias introduced by potentially sampling feasible events as negatives.
- What evidence would resolve it: A theoretical analysis or ablation study comparing the current estimator against an oracle with access to "true" negative events.

## Limitations

- Framework relies on synthetic data with known causal ground truth, which may not fully capture real-world temporal interaction complexity
- Distance metric assumes oracle access to true parameters, which is not available in practice
- Causal shift mechanism (timestamp shuffling) may not represent all realistic distribution shifts in temporal data

## Confidence

- High confidence: The SEM framework for generating synthetic causal temporal data with known ground truth
- Medium confidence: The cross-model distance metric accurately captures causal dissimilarity
- Medium confidence: Predictors trained on one causal model degrade when evaluated on sufficiently distant models
- Low confidence: The timestamp shuffling counterfactual faithfully represents realistic temporal distribution shifts

## Next Checks

1. Validate the distance metric on real-world temporal datasets where partial causal structure is known (e.g., medical records with documented treatment effects) to assess its practical utility beyond synthetic data.

2. Test alternative counterfactual generation methods beyond timestamp shuffling, such as attribute perturbation or intervention-based shifts, to evaluate robustness of the framework.

3. Conduct ablation studies varying the sparsity of the influence matrix Θ and the number of non-causal edges to quantify their impact on predictor sensitivity to causal shifts.