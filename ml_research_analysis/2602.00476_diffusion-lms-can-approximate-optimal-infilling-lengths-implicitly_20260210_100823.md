---
ver: rpa2
title: Diffusion LMs Can Approximate Optimal Infilling Lengths Implicitly
arxiv_id: '2602.00476'
source_url: https://arxiv.org/abs/2602.00476
tags:
- length
- infilling
- confidence
- diffusion
- oracle
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper identifies a fundamental limitation in diffusion language
  models (DLMs) for infilling tasks: their sensitivity to pre-specified mask lengths.
  The authors discover two key statistical phenomena in first-step denoising confidence:
  an Oracle Peak that emerges near the ground-truth length and a systematic Length
  Bias that obscures this signal.'
---

# Diffusion LMs Can Approximate Optimal Infilling Lengths Implicitly

## Quick Facts
- arXiv ID: 2602.00476
- Source URL: https://arxiv.org/abs/2602.00476
- Authors: Hengchang Liu; Zhao Yang; Bing Su
- Reference count: 33
- Key outcome: Training-free CAL method achieves up to 47.7% Pass@1 improvement in code infilling and 40.5% over chat-based methods

## Executive Summary
Diffusion language models face a fundamental challenge in infilling tasks: their performance heavily depends on pre-specified mask lengths, which are often unavailable at inference time. This paper identifies two key statistical phenomena in first-step denoising confidence - an Oracle Peak near the ground-truth length and a systematic Length Bias - and demonstrates how these can be leveraged to approximate optimal infilling lengths without specialized training. The authors propose CAL (Calibrated Adaptive Length), a training-free method that uses calibrated confidence scores to guide a bidirectional hill-climbing search for the optimal mask length before formal decoding. Empirical results show significant improvements across multiple benchmarks and domains, decoupling infilling quality from rigid mask length requirements.

## Method Summary
The CAL method operates through a two-stage process. First, it probes the model's confidence landscape by evaluating denoising predictions at multiple candidate lengths using a calibrated confidence score (NCC), which measures agreement between first-step and second-step denoising predictions. This creates a confidence curve across lengths. Second, it performs a bidirectional hill-climbing search along this curve to locate the length with maximum confidence, interpreted as the Oracle Peak. The calibration function is pre-fitted using a small sample of ground-truth lengths and predictions. Unlike prior adaptive methods that rely on autoregressive decoding with length constraints, CAL's training-free approach works directly with the diffusion model's confidence signals and requires no modification to the underlying DLM architecture.

## Key Results
- Up to 47.7% increase in Pass@1 over fixed-length baselines and 40.5% over chat-based adaptive methods in code infilling
- BLEU-2 and ROUGE-L gains up to 8.5% and 9.9% in text infilling tasks
- Consistent improvements across multiple DLMs (DiffuSeq, DeepSeekLM-2.5, DeepSeekLM-Instruct-2.5, GLM-4) and domains
- Outperforms autoregressive baselines in both accuracy and computational efficiency

## Why This Works (Mechanism)
CAL exploits the statistical regularity that diffusion models' first-step denoising predictions exhibit higher confidence scores near the ground-truth infilling length. This Oracle Peak phenomenon, while obscured by a systematic Length Bias (which CAL corrects through pre-fitting), provides a reliable signal for length optimization. By decoupling the length selection process from the formal decoding stage through calibrated confidence evaluation, CAL avoids the computational overhead of autoregressive methods while maintaining or improving output quality. The bidirectional hill-climbing search efficiently navigates the confidence landscape to locate optimal lengths without exhaustive evaluation.

## Foundational Learning
- **Diffusion Language Models**: Generate text through iterative denoising of Gaussian noise, requiring mask length specification for infilling tasks. Why needed: Understanding DLM mechanics is crucial for grasping how CAL leverages first-step denoising confidence.
- **Confidence Calibration**: Adjusting model confidence scores to better reflect true prediction accuracy, enabling more reliable comparison across different lengths. Why needed: Calibration is essential for making confidence scores comparable across different mask lengths.
- **Bidirectional Hill-Climbing Search**: An optimization algorithm that searches in both directions from a starting point to find local maxima in a function landscape. Why needed: This algorithm efficiently locates the Oracle Peak in the confidence landscape without exhaustive search.
- **BLEU and ROUGE Metrics**: Standard evaluation metrics for text generation quality, measuring n-gram overlap between generated and reference texts. Why needed: Understanding these metrics is necessary to interpret the empirical results and performance claims.
- **Pass@1 Metric**: Measures whether the top-ranked output matches the ground truth, commonly used in code generation evaluation. Why needed: This metric is the primary evaluation criterion for code infilling tasks in the paper.
- **Length Bias Function**: A statistical correction derived from observed systematic deviations between predicted and actual optimal lengths. Why needed: Understanding this correction is key to grasping how CAL addresses the limitations of raw confidence scores.

## Architecture Onboarding
- **Component Map**: DLM -> Confidence Probing (multiple lengths) -> Calibration Function -> Bidirectional Hill-Climbing -> Optimal Length -> Formal Decoding
- **Critical Path**: Input text with mask → Length probing with NCC scoring → Calibration correction → Hill-climbing search → Selected optimal length → Final denoising decoding
- **Design Tradeoffs**: Training-free approach vs. potential for domain-specific optimization; computational overhead of length search vs. quality gains over fixed-length baselines
- **Failure Signatures**: Absence of clear Oracle Peak, highly variable Length Bias across domains, computational constraints in latency-sensitive applications
- **Three First Experiments**: 1) Verify Oracle Peak existence on a simple DLM with synthetic data, 2) Test calibration function fitting on a small validation set, 3) Compare hill-climbing search vs. exhaustive search on a toy confidence landscape

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can the Length Bias function be estimated online to adapt dynamically to specific input contexts?
- Basis in paper: [explicit] Section 7 states that "developing an online estimation method that adapts dynamically to each input represents a promising direction for future improvement."
- Why unresolved: The current CAL framework relies on a pre-fitted static bias function derived from a limited sample, which may not capture context-specific biases or generalize perfectly to all domains without re-fitting.
- What evidence would resolve it: A method that iteratively updates bias estimates during inference and demonstrates statistically significant improvements in length prediction accuracy or BLEU/Pass@1 scores over the static baseline.

### Open Question 2
- Question: Can the calibrated search mechanism be extended to handle multi-span or disjoint infilling scenarios?
- Basis in paper: [explicit] Section 7 notes that "extending the calibrated search mechanism to handle multi-span or disjoint infilling scenarios remains a valuable direction for future research."
- Why unresolved: The current formulation assumes a single contiguous masked region ($M$), and it is unknown how the Oracle Peak signal behaves or aggregates when multiple distinct spans must be optimized simultaneously.
- What evidence would resolve it: A modified algorithm capable of determining optimal lengths for multiple non-adjacent masks simultaneously, validated on benchmarks requiring discontinuous infilling.

### Open Question 3
- Question: How can the computational overhead of the length probing stage be minimized for ultra-low-latency applications?
- Basis in paper: [explicit] Section 7 acknowledges that "the introduced latency might still be a consideration for ultra-low-latency real-time applications."
- Why unresolved: CAL currently requires an average of 11 to 18 additional forward passes for the bidirectional hill-climbing search, which increases total inference time.
- What evidence would resolve it: Optimization strategies (e.g., early termination, coarser search steps, or approximation heuristics) that reduce the number of search steps while maintaining comparable performance gains over fixed-length baselines.

## Limitations
- Domain Generalization: Primarily validated on Python code and English text; limited evidence for other languages or specialized domains
- Statistical Assumptions: Oracle Peak phenomenon lacks rigorous theoretical explanation and may not generalize across all DLMs and noise schedules
- Computational Efficiency: Multiple forward passes required for hill-climbing search may limit real-time applications despite being faster than exhaustive search

## Confidence
- Domain Generalization (Medium Confidence): Effective primarily on Python code and English text; insufficient evidence for cross-domain robustness
- Statistical Assumptions (High Confidence): Oracle Peak signal is empirically observed but not theoretically proven; consistency across implementations uncertain
- Computational Efficiency (Medium Confidence): Trade-off between quality improvements and increased computation not thoroughly analyzed for latency-sensitive applications

## Next Checks
1. Test CAL on non-English languages and specialized technical domains (medical, legal, scientific) to evaluate cross-domain robustness and identify potential failure modes.
2. Conduct ablation studies varying the number of hill-climbing iterations and candidate lengths to establish the relationship between computational cost and quality improvements, including comparison with simpler heuristics.
3. Investigate the Oracle Peak phenomenon through controlled experiments varying noise schedules, DLM architectures, and training procedures to determine whether this signal is an inherent property of diffusion models or an artifact of specific implementations.