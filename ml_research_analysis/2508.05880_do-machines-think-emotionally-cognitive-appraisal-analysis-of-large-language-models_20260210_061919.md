---
ver: rpa2
title: Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language
  Models
arxiv_id: '2508.05880'
source_url: https://arxiv.org/abs/2508.05880
tags:
- emotion
- emotions
- appraisal
- cognitive
- gemini
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CoRE, a benchmark to evaluate how LLMs internally
  reason about emotions through cognitive appraisal dimensions. Drawing from cognitive
  appraisal theory, the authors assess whether models produce coherent reasoning when
  confronted with emotionally charged scenarios, moving beyond surface-level emotion
  recognition tasks.
---

# Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models

## Quick Facts
- **arXiv ID**: 2508.05880
- **Source URL**: https://arxiv.org/abs/2508.05880
- **Reference count**: 40
- **Primary result**: CoRE benchmark reveals LLMs preserve human-like emotional structures but diverge in fine-grained appraisals for specific emotions

## Executive Summary
This paper introduces CoRE, a benchmark designed to evaluate whether Large Language Models (LLMs) internally reason about emotions through cognitive appraisal dimensions rather than merely recognizing surface-level emotional expressions. Drawing from cognitive appraisal theory, the authors assess LLMs' ability to produce coherent reasoning when confronted with emotionally charged scenarios. Using 308 scenarios across 15 emotion categories and 16 appraisal dimensions, they evaluate 7 LLMs including both open-source and proprietary models. The results reveal that while LLMs broadly preserve human-like emotional structures and capture valence-based groupings, they diverge in fine-grained appraisals for specific emotions, with inconsistent representations of ambiguous emotions like surprise, hope, or challenge.

## Method Summary
The authors developed the Cognitive Reasoning of Emotions (CoRE) benchmark based on cognitive appraisal theory, which posits that emotions arise from how individuals evaluate events rather than from the events themselves. The benchmark comprises 308 scenarios spanning 15 emotion categories and 16 appraisal dimensions, with scenarios presented as brief narratives (e.g., "You are waiting in line at the store and someone cuts in front of you"). Each scenario is evaluated across multiple appraisal dimensions such as goal relevance, goal congruence, and accountability. Seven LLMs were tested including open-source models (Llama 3.1-70B-Instruct, Qwen2.5-72B-Instruct) and proprietary models (GPT-4o, Claude 3.5 Sonnet, Gemini-1.5-Pro, Gemini-1.5-Flash). Model responses were compared against human-validated ground truth labels using precision, recall, and F1-score metrics. A hierarchical clustering analysis was also performed to examine how models' appraisal distributions relate to human patterns.

## Key Results
- LLMs broadly preserve human-like emotional structures and capture valence-based groupings across appraisal dimensions
- Models diverge significantly in fine-grained appraisals for specific emotions, with inconsistent representations of ambiguous emotions like surprise, hope, or challenge
- No universal appraisal distribution exists across models, and cross-model variability suggests biases and limitations in current LLM-based emotional reasoning

## Why This Works (Mechanism)
The mechanism relies on cognitive appraisal theory as a framework for understanding how LLMs internally process emotional content. Rather than treating emotions as surface labels, the approach examines whether models can reason about the underlying cognitive evaluations that generate emotions. By mapping scenario-based prompts to 16 appraisal dimensions (such as goal relevance, goal congruence, accountability, certainty, and legitimacy), the benchmark tests whether models can articulate the specific cognitive evaluations that would lead to particular emotional responses. This moves beyond simple emotion classification to assess whether models possess coherent internal representations of emotional reasoning processes.

## Foundational Learning
- **Cognitive Appraisal Theory**: Framework positing that emotions arise from how individuals evaluate events rather than from the events themselves. Needed to understand the theoretical foundation for testing emotional reasoning beyond surface recognition.
- **Appraisal Dimensions**: Specific cognitive evaluations like goal relevance, goal congruence, accountability, certainty, and legitimacy that contribute to emotional responses. Needed to operationalize the theoretical framework into measurable components.
- **Emotional Valence**: The intrinsic attractiveness (positive valence) or averseness (negative valence) of an event or object. Needed to understand how emotions cluster and relate to appraisal patterns.
- **Cross-Model Variability**: Differences in performance and reasoning patterns across different LLMs. Needed to identify systematic biases and limitations in current model architectures.
- **Scenario-Based Evaluation**: Using narrative scenarios to elicit emotional reasoning rather than direct classification tasks. Needed to test reasoning capabilities in context-rich situations.

## Architecture Onboarding
**Component Map**: Scenarios -> Appraisal Dimension Prompts -> LLM Response -> Human Validation -> Performance Metrics -> Clustering Analysis
**Critical Path**: Scenario generation and validation → Appraisal dimension definition → Prompt engineering → LLM evaluation → Human-LLM comparison → Cross-model analysis
**Design Tradeoffs**: Fixed prompts provide consistency but may introduce sensitivity; human validation provides ground truth but may not capture model internal states; multiple models enable comparison but introduce architectural heterogeneity
**Failure Signatures**: Inconsistent responses across similar scenarios; over-reliance on surface emotion labels; failure to maintain coherent appraisal reasoning across multiple dimensions
**3 First Experiments**:
1. Evaluate model consistency by presenting the same scenario with slight variations in framing
2. Test cross-linguistic consistency by evaluating models in multiple languages
3. Examine temporal consistency by evaluating models' responses to scenarios presented in different orders

## Open Questions the Paper Calls Out
None

## Limitations
- The study's reliance on fixed prompts to elicit emotional reasoning introduces significant structural uncertainty and may reflect prompt sensitivity rather than genuine emotional reasoning capabilities
- The evaluation framework assumes textual responses accurately reflect internal cognitive appraisal processes, conflating output generation with internal representation
- The absence of prompt variation or robustness testing means results may not generalize to different prompting strategies

## Confidence
- **Human-like emotional structure preservation**: Medium confidence - findings show broad valence-based groupings are captured, but methodological constraints limit certainty
- **Divergent fine-grained appraisals for specific emotions**: High confidence - cross-model variability and inconsistent representations are empirically observable patterns
- **Current training paradigms inadequate for coherent emotional reasoning**: Low confidence - this interpretive claim extrapolates from behavioral patterns to internal representational adequacy

## Next Checks
1. Conduct prompt sensitivity analysis by systematically varying prompt formulations across multiple dimensions to determine whether observed appraisal patterns persist or shift dramatically with prompt changes
2. Implement ablation studies comparing model performance on CoRE scenarios with and without emotion labels present, to test whether models are genuinely reasoning about appraisal dimensions or simply pattern-matching to labeled emotion categories
3. Design controlled experiments using scenarios with identical appraisal dimension profiles but different emotion labels to test whether models can distinguish between emotions based on cognitive appraisal reasoning versus relying on surface-level emotional category recognition