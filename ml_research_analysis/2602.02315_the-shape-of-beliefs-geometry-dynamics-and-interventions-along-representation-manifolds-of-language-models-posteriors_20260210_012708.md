---
ver: rpa2
title: 'The Shape of Beliefs: Geometry, Dynamics, and Interventions along Representation
  Manifolds of Language Models'' Posteriors'
arxiv_id: '2602.02315'
source_url: https://arxiv.org/abs/2602.02315
tags:
- linear
- geometry
- distribution
- steering
- field
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates how large language models encode beliefs
  over latent parameters of data distributions and how interventions can be made to
  steer those beliefs while respecting the underlying geometry. The authors use a
  controlled setup where Llama-3.2 infers parameters (mean and standard deviation)
  of a normal distribution from in-context examples, forming curved "belief manifolds"
  in representation space.
---

# The Shape of Beliefs: Geometry, Dynamics, and Interventions along Representation Manifolds of Language Models' Posteriors

## Quick Facts
- arXiv ID: 2602.02315
- Source URL: https://arxiv.org/abs/2602.02315
- Reference count: 27
- Primary result: Belief representations in LLMs form curved manifolds; linear interventions often fail to respect this geometry, while manifold-aware methods preserve belief family structure.

## Executive Summary
This paper investigates how large language models encode beliefs over latent parameters of data distributions and how interventions can be made to steer those beliefs while respecting the underlying geometry. The authors use a controlled setup where Llama-3.2 infers parameters (mean and standard deviation) of a normal distribution from in-context examples, forming curved "belief manifolds" in representation space. They show that beliefs update along these manifolds when the input distribution changes, and that standard linear steering often pushes activations off-manifold, producing unintended effects on related parameters like variance. Linear field probes are introduced to tile the manifold and reveal its geometry; these probes vary smoothly with the parameter and only transfer locally, indicating curvature. Interventions based on manifold or field geometry preserve the intended belief family better than linear approaches. The findings demonstrate that belief representations are geometrically structured, and that linear concept representations are often inadequate abstractions. This suggests that future interpretability and steering methods should account for manifold structure to achieve more reliable control.

## Method Summary
The authors create a controlled synthetic task where Llama-3.2-1B must infer the mean and standard deviation of a normal distribution from in-context examples. They extract activation vectors from the model and identify belief manifoldsâ€”curved subspaces where representations of specific parameter values reside. To characterize these manifolds, they train linear field probes that predict parameter values while varying along directions that preserve the belief family. They then compare linear steering interventions (which apply fixed weight updates) against manifold-aware interventions that respect the curved geometry. The effectiveness of interventions is evaluated by measuring how well the steered activations preserve the intended parameter while minimizing unintended changes to related parameters (e.g., variance when steering mean).

## Key Results
- Belief representations in Llama-3.2-1B form curved manifolds in activation space, not linear subspaces.
- Linear steering interventions often push activations off-manifold, causing unintended changes to related parameters like variance.
- Linear field probes trained to tile the manifold show smooth responses along the parameter but only transfer locally, indicating curvature.
- Manifold-aware interventions preserve the intended belief family better than linear approaches, demonstrating the importance of geometric structure.

## Why This Works (Mechanism)
The mechanism underlying this work is that language models encode probabilistic beliefs as structured representations in activation space, forming curved manifolds that reflect the underlying geometry of the belief family (e.g., normal distributions). When inputs change, beliefs update by moving along these manifolds rather than in arbitrary directions. Linear interventions fail because they assume flat, Euclidean geometry, pushing activations off-manifold and disrupting related parameters. By contrast, interventions that respect the manifold geometry preserve the belief family structure, achieving more targeted control.

## Foundational Learning
- **Belief manifolds**: Curved subspaces in activation space where representations of specific parameter values reside. Why needed: To understand how beliefs are geometrically structured and how interventions should respect this structure. Quick check: Do representations vary smoothly along the manifold?
- **Linear field probes**: Probes trained to predict parameter values while varying along directions that preserve the belief family. Why needed: To characterize the geometry of belief manifolds without assuming linearity. Quick check: Do probe responses transfer locally?
- **Manifold-aware interventions**: Steering methods that respect the curved geometry of belief manifolds. Why needed: To achieve targeted control without disrupting related parameters. Quick check: Do interventions preserve the intended belief family?
- **Off-manifold effects**: Unintended changes to related parameters when linear interventions push activations off-manifold. Why needed: To demonstrate the limitations of linear approaches and the importance of geometric structure. Quick check: Are unintended changes minimized with manifold-aware methods?

## Architecture Onboarding
**Component map**: Input examples -> Llama-3.2-1B -> Activation vectors -> Belief manifold identification -> Linear field probe training -> Intervention application -> Evaluation

**Critical path**: The critical path is from input examples through the model to activation vectors, as these representations encode the beliefs that are being studied and manipulated. Manifold identification and probe training are preparatory steps, while interventions and evaluation test the core hypothesis about geometric structure.

**Design tradeoffs**: The controlled synthetic task provides clean interpretability but limits generalizability. Linear probes are simple to train but may miss non-linear structure. Manifold-aware interventions are more complex but achieve better control.

**Failure signatures**: Linear interventions fail when they push activations off-manifold, causing unintended changes to related parameters. Probes fail when they cannot capture the curved geometry, showing poor local transfer.

**3 first experiments**:
1. Verify that belief representations form smooth manifolds by visualizing probe responses along parameter values.
2. Test linear interventions on mean and variance parameters to confirm off-manifold effects.
3. Apply manifold-aware interventions and measure preservation of the intended belief family versus linear methods.

## Open Questions the Paper Calls Out
None explicitly stated in the provided content.

## Limitations
- The experiments are conducted on a controlled synthetic task using Llama-3.2-1B, limiting generalizability to real-world tasks or larger models.
- The evidence for curved belief manifolds is primarily observational (smooth probe responses, local transfer) rather than mathematically rigorous.
- The absolute magnitude of improvements from manifold-aware interventions and their robustness to noise are not quantified.
- The claim that linear probes are insufficient depends on the specific probe architecture and training procedure, and alternative designs might yield better results.
- The causal interpretation of interventions is not fully established; it is unclear whether activation changes causally alter belief states or merely produce correlated behavior.

## Confidence
- Belief representations lie on curved manifolds: Medium
- Linear interventions are insufficient: Medium
- Manifold-aware interventions preserve belief families: Medium
- Generalization to real tasks: Low-Medium
- Mathematical characterization of manifolds: Medium
- Effectiveness of interventions: Medium
- Interpretation of linear probes: Medium
- Causal interpretation of interventions: Low-Medium

## Next Checks
1. **Generalization to real tasks**: Apply the same methodology to natural language tasks (e.g., sentiment analysis with belief-like parameters) to test whether belief manifolds exist and can be intervened upon outside the synthetic setting.

2. **Mathematical characterization**: Use differential geometry tools (e.g., principal geodesic analysis, curvature estimation) to rigorously characterize the belief manifold structure rather than relying on probe smoothness alone.

3. **Alternative probe designs**: Test whether non-linear or structured probes (e.g., kernel methods, geometric deep learning) can better capture belief representations, challenging the claim that linear probes are inherently insufficient.