---
ver: rpa2
title: 'CEGA: A Cost-Effective Approach for Graph-Based Model Extraction and Acquisition'
arxiv_id: '2506.17709'
source_url: https://arxiv.org/abs/2506.17709
tags:
- cega
- nodes
- graph
- node
- extraction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work proposes CEGA, a novel framework for cost-effective\
  \ graph-based model extraction under realistic budget and batch size constraints.\
  \ CEGA leverages historical information from previous queries and combines three\
  \ complementary node selection criteria\u2014representativeness, uncertainty, and\
  \ diversity\u2014to iteratively identify the most informative nodes for extraction."
---

# CEGA: A Cost-Effective Approach for Graph-Based Model Extraction and Acquisition

## Quick Facts
- arXiv ID: 2506.17709
- Source URL: https://arxiv.org/abs/2506.17709
- Reference count: 40
- Key outcome: CEGA achieves superior performance over state-of-the-art baselines in terms of accuracy, fidelity, and F1 score under strict query budget limitations on six benchmark datasets.

## Executive Summary
This work proposes CEGA, a novel framework for cost-effective graph-based model extraction under realistic budget and batch size constraints. CEGA leverages historical information from previous queries and combines three complementary node selection criteria—representativeness, uncertainty, and diversity—to iteratively identify the most informative nodes for extraction. Extensive experiments on six benchmark datasets demonstrate that CEGA achieves superior performance over state-of-the-art baselines in terms of accuracy, fidelity, and F1 score under strict query budget limitations. Notably, CEGA maintains a consistently lower performance gap compared to subgraph models, showcasing its effectiveness in maximizing information recovery with minimal queries. Theoretical analysis further confirms the feasibility and efficiency of CEGA's uncertainty measurement approach. Overall, CEGA provides a practical solution for both defending against model extraction attacks and supporting ethical, low-resource research environments.

## Method Summary
CEGA is a graph-based model extraction framework that iteratively selects nodes for querying under strict budget constraints. The method combines three complementary selection criteria: representativeness (via PageRank centrality), uncertainty (via prediction entropy or perturbation-based measurement), and diversity (via K-Means clustering on interim model embeddings). An adaptive weighting scheme balances these criteria over time, with early cycles prioritizing structural centrality and later cycles emphasizing uncertainty and diversity. The framework operates in cycles, each selecting κ nodes, querying their labels from the target model, and retraining an interim GNN to inform the next selection round.

## Key Results
- CEGA achieves superior accuracy, fidelity, and F1 score compared to state-of-the-art baselines on six benchmark datasets
- CEGA maintains consistently lower performance gaps compared to subgraph models under strict query budget limitations
- The three-component selection framework (representativeness, uncertainty, diversity) demonstrates complementary benefits through ablation studies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Representativeness-based node selection enables extraction of graph topology even when the interim model is unreliable.
- Mechanism: CEGA ranks candidate nodes by PageRank scores, prioritizing nodes with high structural centrality (more inbound edges). The objective function Lγ₁ computes recursive importance scores that capture localized graph topology independent of any trained model. Higher-ranked nodes provide information about the graph's structural backbone, enabling accurate behavior reconstruction across the network.
- Core assumption: Graph structure encodes meaningful information about the task distribution; structurally central nodes carry disproportionate information for model behavior replication.
- Evidence anchors:
  - [abstract] "combines three complementary node selection criteria—representativeness, uncertainty, and diversity—to iteratively identify the most informative nodes"
  - [section 3.2] "Lγ₁(v, Gₐ) = 1 − ξ/N + ξ Σ Lγ₁(w, Gₐ)/L(w)" and "to ensure that the queried nodes in each cycle are representative of the overall graph structure"
  - [corpus] Weak direct corpus evidence; neighboring papers focus on GNN efficiency/expressivity rather than extraction via centrality.
- Break condition: If the task has weak correlation between graph structure and labels (e.g., random edge structure, low homophily), centrality may not prioritize informative nodes.

### Mechanism 2
- Claim: Uncertainty-guided queries efficiently identify decision boundary regions that maximize information gain per query.
- Mechanism: CEGA evaluates the entropy of softmax outputs from the interim GNN model fγ₋₁ for each candidate node. Nodes with high entropy (uncertain predictions) are prioritized as they likely reside near decision boundaries. An alternative perturbation-based approach measures label stability under Gaussian noise to identify sensitive nodes. This focuses queries on regions where the model has not yet learned a confident mapping.
- Core assumption: Prediction entropy correlates with regions of high learning value; the interim model's uncertainty is a reliable proxy for where additional labels will most improve the extracted model.
- Evidence anchors:
  - [abstract] "uncertainty" listed among the three criteria; "theoretical analysis further confirms the feasibility and efficiency of CEGA's uncertainty measurement approach"
  - [section 3.2] "Lγ₂(v, Gₐ) = − Σ by(i)_v;γ₋₁ log(by(i)_v;γ₋₁)" and "nodes with high uncertainty... are prioritized, as they likely reside near decision boundaries"
  - [corpus] No strong corpus support; related work focuses on GNN expressivity and efficiency, not uncertainty-based extraction.
- Break condition: If the interim model is systematically miscalibrated (overconfident on hard examples), entropy-based selection may miss informative nodes. The perturbation-based alternative (Eq. 3) mitigates this but increases computational cost.

### Mechanism 3
- Claim: Diversity-based selection prevents query clustering and stabilizes extraction performance across varied graph regions.
- Mechanism: CEGA clusters previously queried nodes via K-Means (K = number of classes) on their embeddings from fγ₋₁. For each candidate node, it computes distance to centroids and penalizes queries in over-represented regions. The diversity objective Lγ₃ combines: (1) distance to nearest centroid and (2) inverse of the count of already-queried nodes in that cluster. This ensures comprehensive graph exploration.
- Core assumption: Balanced coverage of the embedding space leads to more robust model extraction; over-querying certain regions yields diminishing returns.
- Evidence anchors:
  - [abstract] "diversity" listed as one of three complementary criteria
  - [section 3.2] "Lγ₃(v, Gₐ) = ρφ[0,1](1/(1+δᵥ)) + (1−ρ)φ[0,1](1/(1+|Qᵥ|))" and "to prevent query clustering at the structural level and improve stability"
  - [corpus] Weak corpus evidence; neighboring papers do not address diversity in extraction contexts.
- Break condition: If class boundaries are not well-aligned with embedding clusters, K-Means with K=C may not meaningfully partition the space for diversity purposes. Adaptive K or alternative clustering may be needed.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) for node classification
  - Why needed here: CEGA extracts GNNs performing node classification; understanding message passing, aggregation, and how node features propagate through graph structure is essential to grasp why centrality and uncertainty matter for extraction.
  - Quick check question: Can you explain how a 2-layer GCN propagates information from a node's 2-hop neighborhood to its final prediction?

- Concept: Model Extraction Attacks (MEAs)
  - Why needed here: CEGA is framed as both an attack methodology and an ethical research tool; understanding the threat model (black-box access via API, query budget constraints) clarifies the problem constraints and evaluation setup.
  - Quick check question: What information does an attacker have access to in a black-box MEA setting, and what is the objective?

- Concept: Active Learning for Node Classification
  - Why needed here: CEGA's iterative query selection adapts active learning principles to graph data; familiarity with uncertainty sampling, diversity sampling, and budget-constrained acquisition helps contextualize CEGA's design choices.
  - Quick check question: In active learning, why might entropy-based uncertainty sampling fail, and what alternatives exist?

## Architecture Onboarding

- Component map:
  Initialization module -> Representativeness scorer -> Uncertainty scorer -> Diversity scorer -> Adaptive ranker -> Query executor -> Interim model trainer

- Critical path:
  1. Initialize with I random nodes → train f₀
  2. For each cycle γ: compute Lγ₁, Lγ₂, Lγ₃ → rank nodes → combine with ω₁(γ), ω₂(γ), ω₃(γ) → query top-κ → retrain fγ
  3. After Γ cycles, return final queried node set for extraction training

- Design tradeoffs:
  - Entropy vs. perturbation-based uncertainty: Entropy is O(CN + N log N); perturbation adds O(SLN²d) for S samples. Choose perturbation only if interim model may be miscalibrated.
  - κ (nodes per cycle): Paper uses κ = 1 for fine-grained adaptation; larger κ reduces cycles but may miss optimal ordering.
  - Weight schedule: Exponential decay (ω₁ = α₁ + Δe^(-λγ)) smoothly transitions from structure-driven to history-driven selection. Alternative schedules may better suit datasets where early uncertainty is informative.
  - ρ in diversity: High ρ (0.8 per paper) prioritizes underrepresented labels; lower ρ shifts emphasis to spatial dispersion.

- Failure signatures:
  - Low fidelity despite high budget: Check if ω schedule is maladapted (e.g., ω₁ too low early when fγ is unreliable); verify class imbalance isn't causing diversity to dominate over informativeness.
  - High variance across runs: Diversity component may be underweighted; increase ω₃ or check K-Means initialization stability.
  - Poor performance on high-class-count datasets (e.g., Cora-Full with 70 classes): K = C may create overly fragmented clusters; consider capping K or using hierarchical clustering.

- First 3 experiments:
  1. Reproduce CEGA vs. baselines on one small dataset (e.g., DBLP) with budget 2C → 10C, plotting accuracy/fidelity curves to validate implementation.
  2. Ablate one component at a time (No-Centrality, No-Uncertainty, No-Diversity) on 2–3 datasets; compare fidelity gaps to Table 2 to confirm each mechanism's contribution.
  3. Vary the weight schedule (e.g., fix ω₁ = ω₂ = ω₃ = 1/3 vs. adaptive) on a dataset with known low homophily; observe if adaptive weighting still provides benefit or if structure-driven queries underperform.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the CEGA framework be effectively adapted for inductive Graph Neural Networks (GNNs) rather than transductive ones?
- Basis in paper: [explicit] The conclusion states the current framework relies on a "transductive assumption" and explicitly lists extending CEGA to "inductive GNNs" as a future direction.
- Why unresolved: Inductive learning requires generalizing to unseen nodes or graphs without retraining, whereas CEGA currently relies on fixed graph topology ($G_a$) and node sets during the extraction cycles.
- What evidence would resolve it: A modified CEGA implementation applied to inductive benchmarks (e.g., PPI dataset) demonstrating high fidelity without requiring full graph knowledge during training.

### Open Question 2
- Question: Can leveraging edge information improve the efficiency of node selection, particularly during the early stages of querying?
- Basis in paper: [explicit] The conclusion suggests that "refining our approach by leveraging edge information, especially in the early query cycles when the number of selected nodes is small, could further improve CEGA's performance."
- Why unresolved: The current methodology prioritizes node-level metrics (centrality, uncertainty, diversity) and may overlook structural nuances or relational information encoded in the edges.
- What evidence would resolve it: An ablation study incorporating edge-weighted metrics into the selection criteria, showing a statistically significant reduction in the performance gap compared to the node-only approach.

### Open Question 3
- Question: How robust is CEGA in "Attack 1" or "Attack 2" scenarios where the attacker lacks knowledge of the target graph's structure or node attributes?
- Basis in paper: [inferred] The methodology explicitly defines the problem setting as "Attack 0," assuming the attacker possesses the graph structure $G_a$ and attributes $X_a$.
- Why unresolved: The node selection mechanisms (specifically representativeness via PageRank and diversity) depend heavily on known topology; performance failure in "black-box" settings (unknown structure) remains untested.
- What evidence would resolve it: Experimental results measuring extraction fidelity when CEGA is forced to estimate or synthesize the missing graph structure or attributes prior to selection.

## Limitations
- Empirical validation lacks systematic ablation studies isolating each selection criterion's individual contribution
- Theoretical analysis focuses on uncertainty measurement feasibility rather than overall extraction guarantees
- Several design parameters appear tuned to specific datasets without cross-dataset validation
- Claims about superiority relative to subgraph models require more careful experimental isolation

## Confidence
- High confidence: CEGA's three-component framework (representativeness, uncertainty, diversity) is technically sound and logically coherent. The PageRank-based structural selection and entropy-based uncertainty measurement are standard, well-understood techniques.
- Medium confidence: The adaptive weight scheduling effectively balances the three criteria over time, though optimal parameter settings may be dataset-dependent. The empirical performance improvements over baselines appear robust but may not generalize to all graph types.
- Low confidence: Claims about CEGA's superiority in "maximizing information recovery with minimal queries" relative to subgraph models require more careful experimental isolation. The perturbation-based uncertainty alternative lacks practical validation.

## Next Checks
1. Conduct systematic ablation studies (No-Centrality, No-Uncertainty, No-Diversity) on 3-4 datasets to quantify each component's individual contribution to fidelity improvements.
2. Implement and evaluate the perturbation-based uncertainty alternative (L2_alt) on at least one dataset, testing sensitivity to perturbation magnitude ε and sample count S.
3. Design experiments comparing CEGA against a standardized subgraph extraction baseline where both use identical GNN architectures, isolating query efficiency from architectural advantages.