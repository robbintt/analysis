---
ver: rpa2
title: 'ROSA: Addressing text understanding challenges in photographs via ROtated
  SAmpling'
arxiv_id: '2506.03665'
source_url: https://arxiv.org/abs/2506.03665
tags:
- text
- rosa
- visual
- images
- oriented
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Visually impaired individuals struggle with text recognition in
  photos they take, as existing VQA models perform poorly on images with misaligned
  text. This work introduces ROSA (ROtated SAmpling), a decoding strategy that improves
  VQA performance by generating multiple predictions from rotated versions of the
  input image and selecting the most confident one.
---

# ROSA: Addressing text understanding challenges in photographs via ROtated SAmpling

## Quick Facts
- arXiv ID: 2506.03665
- Source URL: https://arxiv.org/abs/2506.03665
- Reference count: 6
- Improves VQA accuracy on misaligned text by up to 11.7 absolute points via rotated sampling

## Executive Summary
ROSA addresses a critical challenge in VQA for visually impaired users: text recognition in photos with misaligned text. By generating predictions from multiple rotated versions of the input image and selecting the most confident one, ROSA achieves substantial improvements over standard greedy decoding. Evaluated on datasets derived from VizWiz-VQA that reflect real-world capture patterns, ROSA consistently outperforms baselines across multiple state-of-the-art multimodal models.

## Method Summary
ROSA is a decoding strategy that improves VQA performance on images with misaligned text by applying four canonical rotations (0°, 90°, 180°, 270°) to the input image and generating multiple predictions for each rotation using temperature-based sampling (T=0.5, top_k=50). For each answer generated, ROSA computes likelihood scores p(a|v,q) via the chain rule and selects the answer with the highest confidence. The method breaks ties through majority voting, then random selection. Unlike training-time augmentation, ROSA operates entirely at inference time without modifying model weights.

## Key Results
- Achieves up to 11.7 absolute points improvement in Exact Match accuracy over standard Greedy decoding on VizWiz-Text dataset
- Consistently outperforms baselines across multiple state-of-the-art multimodal models including LLaVA-1.6-Vicuna-7B, Molmo-7B-D, and GPT-4o-mini
- Approaches oracle performance under ideal conditions while maintaining robustness to real-world capture patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sampling predictions from multiple rotated versions of an image and selecting the highest-confidence output improves VQA performance on misoriented text compared to single-pass greedy decoding.
- Core assumption: Models trained on predominantly well-oriented text datasets will assign higher confidence to correctly oriented text; at least one canonical rotation will bring misoriented text closer to the model's training distribution.
- Evidence anchors:
  - [abstract] "ROSA...generating multiple predictions from rotated versions of the input image and selecting the most confident one...achieves up to 11.7 absolute points improvement in Exact Match accuracy over standard Greedy decoding."
  - [section 5] "The final prediction returned by ROSA corresponds to the answer (i.e., inference) with the highest confidence likelihood-based score."
- Break condition: If the model assigns higher confidence to incorrect orientations or if none of the rotations produce a confident answer (e.g., extremely blurry images), ROSA will not improve over greedy.

### Mechanism 2
- Claim: Selecting the highest-confidence prediction implicitly aligns the input with the model's training distribution, where well-oriented text is overrepresented.
- Core assumption: The model's confidence score correlates with answer correctness for text recognition tasks.
- Evidence anchors:
  - [section 5] "Given this bias in the training data, it is reasonable to assume that models tend to develop a stronger affinity for such configurations [standard orientations]."
  - [section 6.3] "The first column shows that most of ROSA's correct predictions come from images with correctly oriented text...supports the logic behind the design of our strategy."
- Break condition: If confidence is miscalibrated (e.g., overconfident on incorrect orientations) or if training data includes substantial rotated text, the correlation breaks.

### Mechanism 3
- Claim: Sampling-based decoding with moderate temperature (T=0.5) produces diverse but plausible answers, reducing the risk of missing the correct answer due to a single greedy error.
- Core assumption: At least one of the sampled answers will be correct if the model has sufficient capability.
- Evidence anchors:
  - [section 5] "This configuration strikes a balance between variability and coherence, allowing the model to explore a broader range of plausible answers while maintaining response consistency."
  - [section 6.2] "RepeatRot...performs better than Greedy...likely by introducing controlled variability that enhances answer diversity."
- Break condition: If temperature is too high, samples become incoherent; if too low, diversity vanishes. If the model fundamentally cannot read the text, sampling won't help.

## Foundational Learning

- Concept: **Inference-Time Augmentation vs. Training-Time Augmentation**
  - Why needed here: ROSA applies rotation at inference, not training. Understanding this distinction clarifies why the method works without retraining.
  - Quick check question: Why does ROSA not require modifying the model's weights?

- Concept: **Decoding Strategies (Greedy vs. Sampling)**
  - Why needed here: ROSA relies on sampling with specific hyperparameters (T=0.5, top_k=50). Understanding how these affect output diversity is critical.
  - Quick check question: What happens to answer diversity if you set T=0?

- Concept: **Confidence Calibration in VLMs**
  - Why needed here: ROSA selects the highest-confidence answer. If confidence is poorly calibrated, the selection may be unreliable.
  - Quick check question: If a model is overconfident on incorrect answers, will ROSA's selection strategy still work?

## Architecture Onboarding

- Component map: Input Image/Question -> Rotation Module (0°, 90°, 180°, 270°) -> Inference Engine (Sampling with T=0.5, top_k=50) -> Scorer (Compute p(a|v_rot, q)) -> Selector (Highest confidence, tie-break by majority vote then random)
- Critical path: Rotation → Sampling → Scoring → Selection. The selection step is the sole determinant of the final output.
- Design tradeoffs:
  - Number of rotations: 4 canonical rotations chosen for coverage vs. compute cost
  - Temperature T: Higher T increases diversity but risks incoherence; 0.5 is a heuristic balance
  - Number of samples k: More samples increase the chance of a correct answer but linearly increase compute
- Failure signatures:
  - Low confidence scores across all rotations: Model is uncertain; may indicate blurry images or out-of-distribution inputs
  - High variance in selected answers across runs: Sampling is too stochastic; reduce T
  - ROSA underperforms greedy on well-oriented datasets: Unnecessary rotations introduce noise
- First 3 experiments:
  1. **Ablate temperature**: Run ROSA with T ∈ {0.3, 0.5, 0.7, 1.0} on VizWiz(Conventional). Measure EM and answer diversity.
  2. **Ablate rotations**: Test ROSA with only {0°, 180°} rotations vs. full {0°, 90°, 180°, 270°} on VizWiz(Random). Quantify the performance gap.
  3. **Calibration check**: On a held-out set, plot confidence score vs. EM accuracy. If poorly calibrated, explore confidence calibration techniques or alternative selection metrics.

## Open Questions the Paper Calls Out

- Can an adaptive mechanism be developed to prevent ROSA's performance degradation on correctly oriented images?
  - Basis: ROSA underperforms compared to Greedy decoding on datasets with correctly oriented text because unnecessary rotations negatively affect confidence.

- How can ROSA's likelihood-based confidence scores be calibrated for reliable abstention in safety-critical assistive contexts?
  - Basis: The authors state it is crucial to assess the uncertainty of model predictions to allow models to abstain or request clarification before deployment.

- Is ROSA effective when applied to blurry or low-quality images typical of uncontrolled real-world capture by visually impaired users?
  - Basis: Evaluation was restricted to images with adequate quality, but real-world images exhibit blurriness which the strategy does not explicitly address.

## Limitations
- Performance gain depends on presence of text-orientation bias in training data, which may not hold for all VLMs or datasets
- Method shows degradation on correctly oriented images due to unnecessary rotations introducing noise
- Relies on confidence-based selection which is vulnerable to model miscalibration, not explicitly addressed

## Confidence
- Claim: 11.7 absolute EM points improvement on VizWiz-Text dataset -> High confidence
- Claim: Generalizability to other VQA datasets -> Medium confidence
- Claim: Confidence scores correlate with correctness -> Medium confidence

## Next Checks
1. **Confidence Calibration Validation**: On a held-out validation set, plot confidence score distributions against EM accuracy for ROSA-selected answers. If the correlation is weak or inverted, investigate confidence calibration techniques.

2. **Ablation of Samples per Rotation**: Systematically vary the number of samples per rotation (e.g., 1, 3, 5, 10) and measure EM, answer diversity, and runtime. Identify the point of diminishing returns.

3. **Cross-Dataset Generalization Test**: Apply ROSA to a standard VQA dataset (e.g., VQAv2) with minimal text-orientation issues. If ROSA underperforms or harms performance, it confirms the method's specificity to misaligned-text scenarios.