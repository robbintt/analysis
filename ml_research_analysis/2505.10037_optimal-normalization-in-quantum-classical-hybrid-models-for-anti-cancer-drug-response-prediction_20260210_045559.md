---
ver: rpa2
title: Optimal normalization in quantum-classical hybrid models for anti-cancer drug
  response prediction
arxiv_id: '2505.10037'
source_url: https://arxiv.org/abs/2505.10037
tags:
- quantum
- normalization
- data
- performance
- values
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of unstable training in quantum-classical
  hybrid models for anti-cancer drug response prediction, particularly due to the
  periodicity of quantum rotation gates and the crowding of values caused by normalization
  functions. The authors propose a novel normalization strategy using a moderated
  gradient version of the tanh function, which transforms neural network outputs without
  concentrating them at extreme ranges.
---

# Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction

## Quick Facts
- arXiv ID: 2505.10037
- Source URL: https://arxiv.org/abs/2505.10037
- Authors: Takafumi Ito; Lysenko Artem; Tatsuhiko Tsunoda
- Reference count: 18
- Key outcome: Novel moderated tanh normalization enables stable quantum-classical hybrid models for drug response prediction, outperforming classical models and other normalization methods.

## Executive Summary
This study addresses the challenge of unstable training in quantum-classical hybrid models for anti-cancer drug response prediction, particularly due to the periodicity of quantum rotation gates and the crowding of values caused by normalization functions. The authors propose a novel normalization strategy using a moderated gradient version of the tanh function, which transforms neural network outputs without concentrating them at extreme ranges. The method was evaluated on a dataset of gene expression and drug response measurements for five anti-cancer drugs, comparing classical deep learning models with quantum-classical hybrid models using different normalization approaches. Results showed that the proposed normalization significantly improved hybrid model performance, achieving higher AUC scores than both classical models and hybrid models with other normalization methods. The optimal hyperparameters of the normalization function varied by drug, suggesting the need for careful parameter tuning.

## Method Summary
The study combines classical neural networks with quantum circuits to predict cancer drug sensitivity from gene expression data. The classical encoder consists of a 3-layer feedforward network (512→128→n qubits) with SiLU activation and batch normalization. The quantum component uses a parameterized quantum circuit (PQC) with encoding and variational layers. The key innovation is a moderated tanh normalization function (φ' = r·tanh(φ/a) with a=20, r=π/2) that transforms encoder outputs to quantum rotation angles. This addresses the crowding problem where standard normalizations push many values to extremes, causing unstable gradients during training. The model was trained using MSE loss on normalized log(IC50) values and evaluated on AUC for binary drug response classification.

## Key Results
- Proposed moderated tanh normalization achieved significantly higher AUC scores than classical models and hybrid models with other normalization methods
- Optimal hyperparameters (a=20, r=π/2) varied by drug, indicating the need for drug-specific parameter tuning
- The method effectively addressed the instability caused by quantum rotation gate periodicity and value crowding
- Hybrid models with the proposed normalization demonstrated stable training and improved performance across all five tested anti-cancer drugs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Moderating the gradient of the tanh function prevents extreme value concentration while maintaining sufficient range for quantum rotations
- **Evidence:** The moderated gradient version φ' = r·tanh(φ/a) with a=20 and r=π/2 transforms neural network outputs to a range that avoids crowding at extremes while providing adequate variation for quantum rotation angles

### Mechanism 2
- **Claim:** Proper normalization enables stable gradient flow through the quantum-classical interface
- **Evidence:** By avoiding value crowding at extreme ranges, the moderated tanh normalization maintains diverse quantum rotation angles, preventing gradient vanishing or explosion during training

## Foundational Learning

### Quantum Rotation Gates
- **Why needed:** These are fundamental quantum operations that rotate qubits around specific axes, and their periodicity creates challenges for continuous parameter mapping
- **Quick check:** Rotation gates like R_x(θ), R_y(θ), and R_z(θ) apply rotations by angle θ to qubits

### Parameterized Quantum Circuits (PQC)
- **Why needed:** PQCs are the core quantum component that can be optimized for specific tasks by adjusting rotation angles
- **Quick check:** PQCs consist of repeated layers of parameterized gates interleaved with entangling gates, forming a variational circuit

### Quantum-Classical Hybrid Training
- **Why needed:** This approach combines the representational power of quantum circuits with classical neural networks for tasks where quantum advantage is anticipated
- **Quick check:** Hybrid models train both classical and quantum parameters simultaneously, requiring careful interface design between components

## Architecture Onboarding

### Component Map
- Gene Expression Data -> Classical Encoder (3-layer NN with SiLU) -> Normalization Layer (moderated tanh) -> Quantum Circuit (PQC with encoding and variational layers) -> Measurement -> Prediction

### Critical Path
1. Input gene expression vectors pass through classical encoder
2. Encoder outputs undergo moderated tanh normalization
3. Normalized values become rotation angles for quantum circuit
4. Quantum circuit executes parameterized rotations and measurements
5. Measurement results feed into loss calculation for backpropagation

### Design Tradeoffs
- Classical-only models are simpler but may miss quantum advantages
- Standard normalizations cause value crowding, while the proposed moderated tanh balances range and gradient stability
- More quantum layers increase expressivity but require more qubits and training complexity

### Failure Signatures
- Value crowding at extremes indicates need for normalization adjustment
- Unstable training or poor convergence suggests improper mapping of classical outputs to quantum parameters
- Suboptimal performance may result from insufficient quantum circuit depth or width

### 3 First Experiments
1. Compare different normalization methods (softmax, sigmoid, moderated tanh) on a subset of data
2. Test varying the hyperparameters a and r to find optimal values for specific drugs
3. Evaluate the impact of quantum circuit depth on model performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the proposed normalization method maintain its performance when applied to independent external datasets, specifically real patient data?
- Basis in paper: [explicit] The authors note they "were only able to validate the performance using randomly split test data rather than independent external test data" and wish to "conduct such additional tests using real patient data in the future."
- Why unresolved: The current study relied solely on the GDSC cell line dataset with random splits, lacking validation on clinical patient samples which may have different distribution characteristics.
- What evidence would resolve it: Replication of the improved AUC performance on independent clinical cohorts comparing the proposed hybrid model against classical baselines.

### Open Question 2
- Question: How does quantum noise affect the optimal hyperparameters $a$ and $r$, and does the proposed normalization remain stable on real quantum hardware?
- Basis in paper: [explicit] The authors state, "In future work, we plan to conduct experiments using noisy simulators and real quantum devices to investigate the effect of noise on the optimal hyperparameters a and r."
- Why unresolved: All experiments in the current study were conducted on a noiseless simulator, whereas real devices suffer from decoherence and gate errors that may interact unpredictably with the normalization strategy.
- What evidence would resolve it: Benchmarking the model on noisy simulators and Noisy Intermediate-Scale Quantum (NISQ) devices to determine if optimal $a$ and $r$ values shift or if performance degrades significantly.

### Open Question 3
- Question: Can the normalization hyperparameters $a$ and $r$ be optimized effectively as trainable parameters rather than static values determined by grid search?
- Basis in paper: [explicit] The authors suggest, "One potential method of determining a and r is to set a and r as parameters and adjust them during the training process to search for the optimal values."
- Why unresolved: Currently, $a$ and $r$ are fixed hyperparameters requiring manual tuning (grid search), which is computationally expensive and may not find the global optimum for specific datasets.
- What evidence would resolve it: Implementation of $a$ and $r$ as learnable weights in the neural network, demonstrating convergence to stable values without loss of performance.

### Open Question 4
- Question: Is the proposed moderated tanh normalization applicable to other high-dimensional domains such as image recognition?
- Basis in paper: [explicit] The authors state, "The applicability of the proposed normalization method... should be studied in the future... [for] image recognition, where high-dimensional data is handled."
- Why unresolved: The study focused exclusively on gene expression data for drug response, leaving the utility of this encoding strategy for other data modalities unverified.
- What evidence would resolve it: Application of the quantum-classical hybrid model with the proposed normalization to standard image classification benchmarks.

## Limitations

- Hyperparameter sensitivity requires drug-specific tuning of parameters a and r
- Results based on simulation rather than real quantum hardware
- Limited to 5 drugs and cell line data, restricting generalizability
- Encoding strategy may struggle with complex patterns in certain datasets

## Confidence

**High Confidence**: The core observation that normalization affects hybrid model stability and performance is well-supported. The mathematical reasoning for why the proposed tanh-based normalization avoids value crowding is sound.

**Medium Confidence**: The comparative performance claims between normalization methods. While results show improvement, the relatively small dataset (465 cell lines) and the stochastic nature of neural network training suggest some uncertainty in the magnitude of improvements reported.

**Low Confidence**: Generalizability claims to other biomedical prediction tasks. The method shows promise for anti-cancer drug response prediction specifically, but broader claims about quantum-classical hybrid models for general biomedical data analysis are not yet fully supported.

## Next Checks

1. Cross-dataset validation: Test the normalization approach on independent cancer cell line datasets (e.g., CCLE) and for drugs not included in the original study to assess generalizability.

2. Real quantum hardware testing: Implement the optimized models on available quantum hardware (IBM Quantum, Rigetti) to validate that simulation-based performance gains translate to actual quantum devices.

3. Hyperparameter transfer analysis: Systematically study whether optimal normalization parameters for one drug can inform initial values for new drugs, reducing the need for extensive re-tuning.