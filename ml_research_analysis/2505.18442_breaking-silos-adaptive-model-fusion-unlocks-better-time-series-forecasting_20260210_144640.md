---
ver: rpa2
title: 'Breaking Silos: Adaptive Model Fusion Unlocks Better Time Series Forecasting'
arxiv_id: '2505.18442'
source_url: https://arxiv.org/abs/2505.18442
tags:
- time
- forecasting
- series
- fuse
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TimeFuse is a framework for adaptive ensemble time series forecasting
  that leverages the distinct strengths of diverse models at the sample level. It
  extracts meta-features from input time series and uses a learnable fusor to predict
  optimal model fusion weights, enabling dynamic combination of heterogeneous models.
---

# Breaking Silos: Adaptive Model Fusion Unlocks Better Time Series Forecasting

## Quick Facts
- arXiv ID: 2505.18442
- Source URL: https://arxiv.org/abs/2505.18442
- Reference count: 40
- TimeFuse is a framework for adaptive ensemble time series forecasting that leverages the distinct strengths of diverse models at the sample level.

## Executive Summary
TimeFuse is a framework for adaptive ensemble time series forecasting that leverages the distinct strengths of diverse models at the sample level. It extracts meta-features from input time series and uses a learnable fusor to predict optimal model fusion weights, enabling dynamic combination of heterogeneous models. Extensive experiments on long- and short-term forecasting tasks show that TimeFuse consistently outperforms state-of-the-art individual models, achieving near-universal performance improvements across various benchmark datasets. For example, it reduces average MSE by up to 11.77% on long-term tasks and MAPE by up to 20.46% on short-term traffic forecasting, demonstrating strong generalizability and adaptability.

## Method Summary
TimeFuse is an adaptive model fusion framework that addresses the limitations of static ensemble methods by dynamically combining heterogeneous time series forecasting models. The framework extracts meta-features from input time series to capture temporal patterns and model behaviors. A learnable fusor component then predicts optimal fusion weights for each sample, allowing the system to leverage the strengths of different models depending on the input characteristics. This approach enables sample-level adaptation rather than fixed ensemble weights, improving performance across diverse forecasting scenarios. The framework has been evaluated on both long-term and short-term forecasting tasks, demonstrating consistent improvements over individual state-of-the-art models.

## Key Results
- Reduces average MSE by up to 11.77% on long-term forecasting tasks
- Reduces MAPE by up to 20.46% on short-term traffic forecasting
- Demonstrates strong generalizability and adaptability across various benchmark datasets

## Why This Works (Mechanism)
TimeFuse works by recognizing that different forecasting models have distinct strengths and weaknesses depending on the underlying data characteristics. Rather than using static ensemble weights, the framework dynamically assigns optimal weights to each model based on the input time series characteristics. This is achieved through meta-feature extraction that captures temporal patterns and model behaviors, combined with a learnable fusor that predicts the best combination for each specific sample. By breaking the silos between models and allowing them to complement each other's strengths, TimeFuse achieves superior performance compared to any individual model.

## Foundational Learning
- **Meta-feature extraction**: Capturing statistical and temporal characteristics of time series to inform model selection - needed to understand which model works best for which type of input data; quick check: verify that extracted features capture relevant patterns
- **Sample-level adaptive weighting**: Dynamically adjusting model contributions per input rather than using fixed weights - needed to leverage model diversity effectively; quick check: ensure weights change meaningfully across different inputs
- **Learnable fusor architecture**: Using neural networks to predict optimal fusion weights - needed to capture complex relationships between input features and model performance; quick check: validate that fusor learns non-trivial weight assignments
- **Ensemble diversity exploitation**: Understanding how different models complement each other - needed to maximize the benefits of combining multiple approaches; quick check: analyze correlation between individual model errors
- **Temporal pattern recognition**: Identifying relevant patterns in time series data - needed for effective forecasting; quick check: verify pattern detection accuracy
- **Cross-model performance mapping**: Relating input characteristics to model effectiveness - needed for intelligent weight assignment; quick check: validate performance predictions against actual results

## Architecture Onboarding

**Component Map**: Time series -> Meta-feature Extractor -> Fusor -> Model Weights -> Individual Models -> Weighted Output

**Critical Path**: The critical path flows from input time series through meta-feature extraction, then to the fusor for weight prediction, and finally to the weighted combination of individual model outputs. The fusor module is the core innovation, as it learns to predict optimal weights based on input characteristics rather than using static weights.

**Design Tradeoffs**: The framework trades increased computational complexity for improved accuracy through the learnable fusor component. While this adds inference overhead compared to simple ensemble methods, it enables dynamic adaptation to input characteristics. The approach requires sufficient training data to learn effective weight assignments and may face challenges with highly non-stationary or chaotic time series where model performance relationships are less predictable.

**Failure Signatures**: The system may underperform if meta-features fail to capture relevant input characteristics, if the fusor overfits to training data, or if individual model diversity is insufficient. Computational overhead could become prohibitive for real-time applications with large numbers of models or high-frequency forecasting requirements.

**First Experiments**:
1. Compare TimeFuse against simple ensemble baselines (uniform weighting, inverse error weighting) on the same datasets to quantify the marginal benefit of the learnable fusor
2. Test the framework on additional datasets with different characteristics (e.g., financial time series, highly non-stationary data) to evaluate robustness
3. Measure inference time and memory requirements relative to individual models to assess practical deployment feasibility

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability to highly non-stationary or chaotic time series remains uncertain due to limited exploration of feature selection sensitivity
- Computational overhead of the fusor module relative to forecasting gains is not thoroughly characterized
- Absence of comparison against simpler ensemble methods makes it difficult to assess the value of the learnable fusor

## Confidence
- Performance improvements: High
- Adaptability claims: Medium
- Computational efficiency: Low
- Generalizability across domains: Medium

## Next Checks
1. Compare TimeFuse against simple ensemble baselines (uniform weighting, inverse error weighting) on the same datasets to quantify the marginal benefit of the learnable fusor
2. Conduct experiments on additional datasets with different characteristics (e.g., financial time series, highly non-stationary data) to test the framework's robustness across diverse domains
3. Perform a detailed computational complexity analysis, measuring inference time and memory requirements relative to individual models, particularly for large-scale deployment scenarios