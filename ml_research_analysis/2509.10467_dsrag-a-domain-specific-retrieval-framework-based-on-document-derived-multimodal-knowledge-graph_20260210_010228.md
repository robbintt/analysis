---
ver: rpa2
title: 'DSRAG: A Domain-Specific Retrieval Framework Based on Document-derived Multimodal
  Knowledge Graph'
arxiv_id: '2509.10467'
source_url: https://arxiv.org/abs/2509.10467
tags:
- knowledge
- graph
- domain-specific
- retrieval
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DSRAG tackles the problem of knowledge hallucination and poor domain-specific
  adaptability in large language models by proposing a multimodal knowledge graph-driven
  retrieval-augmented generation framework. It constructs a hierarchical multimodal
  knowledge graph integrating both conceptual and instance layers from domain-specific
  documents, including text, images, and tables.
---

# DSRAG: A Domain-Specific Retrieval Framework Based on Document-derived Multimodal Knowledge Graph

## Quick Facts
- **arXiv ID:** 2509.10467
- **Source URL:** https://arxiv.org/abs/2509.10467
- **Reference count:** 19
- **Primary result:** 83% faithfulness, 87% answer relevancy, 85% contextual precision on database technical documents

## Executive Summary
DSRAG addresses the critical challenge of knowledge hallucination and poor domain adaptability in large language models by introducing a multimodal knowledge graph-driven retrieval-augmented generation framework. The system constructs a hierarchical multimodal knowledge graph from domain-specific documents, integrating both conceptual and instance layers with text, images, and tables. Through a two-stage retrieval process combining semantic pruning with structured subgraph retrieval and vector-based search, DSRAG significantly improves answer accuracy and relevance. Evaluations on database technical documentation using 100 expert-designed questions demonstrate substantial performance gains over baseline RAG methods, achieving state-of-the-art faithfulness and contextual precision metrics.

## Method Summary
DSRAG employs a three-stage pipeline: data preprocessing using Mineru + OCR to parse multimodal PDFs into structured formats, hierarchical multimodal knowledge graph construction with concept and instance layers, and two-stage retrieval combining graph-guided semantic pruning with vector similarity search. The framework processes text, tables, and images from technical documentation, extracting entities and relationships through three-layer extraction agents. Retrieval operates by first traversing the concept knowledge graph with layer-wise pruning, then performing vector-based search on chapter-constrained candidate chunks. The system generates answers using GPT-4o-mini with combined context from both retrieval stages, achieving superior performance on domain-specific question answering tasks.

## Key Results
- Achieves 83% faithfulness score measured via Langfuse evaluation
- Delivers 87% answer relevancy across 100 expert-designed test questions
- Maintains 85% contextual precision in generated responses

## Why This Works (Mechanism)
The framework's effectiveness stems from grounding LLM responses in structured multimodal knowledge rather than relying solely on parametric memory. By constructing hierarchical knowledge graphs that capture both conceptual relationships and instance-level details, DSRAG provides verifiable context that reduces hallucination. The two-stage retrieval mechanism first narrows search space through semantic pruning on the concept graph, then refines results with vector similarity search, ensuring both relevance and precision. Integration of multiple modalities (text, tables, images) creates a richer representation that captures complex domain relationships missed by text-only approaches.

## Foundational Learning
- **Multimodal Document Parsing**: Converting PDFs with mixed content types into structured data formats; needed for handling real-world technical documentation; quick check: verify JSON-LD output contains all text, table, and image elements from source documents.
- **Hierarchical Knowledge Graph Construction**: Building concept and instance layers from document structure and content; needed to capture both abstract relationships and concrete entities; quick check: validate that concept nodes align with document hierarchy and instance nodes contain accurate extracted entities.
- **Graph-Guided Semantic Pruning**: Using knowledge graph traversal to constrain search space before vector retrieval; needed to improve retrieval efficiency and relevance; quick check: measure reduction in candidate documents after pruning versus baseline vector search.
- **Three-Layer Entity Extraction**: Systematic extraction of macro relationships, core entities, and technical parameters; needed for comprehensive domain coverage; quick check: inspect extracted triples for completeness across all document sections.

## Architecture Onboarding

**Component Map**: PDF Parser -> Multimodal Preprocessor -> Concept KG Builder -> Instance KG Builder -> Graph DB -> Two-Stage Retriever -> LLM Generator

**Critical Path**: Document parsing → Knowledge graph construction → Graph-guided pruning → Vector retrieval → Answer generation

**Design Tradeoffs**: Prioritizes accuracy over latency by using expensive knowledge graph construction and two-stage retrieval; trades computational overhead for reduced hallucination and improved domain adaptability; assumes availability of expert annotations and domain ontologies.

**Failure Signatures**: Poor entity extraction leads to incomplete knowledge graphs; retrieval misses relevant context despite pruning; generated answers contain hallucinations when graph grounding is insufficient.

**First Experiments**:
1. Parse a sample technical document and verify multimodal output structure
2. Extract entities from a single chapter and validate against ground truth
3. Test two-stage retrieval on a simple query with known answer location

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to single domain (database documentation) with custom test set
- Performance depends heavily on availability of expert annotations and domain ontologies
- Method assumes structured multimodal documents, limiting applicability to unstructured text sources
- No direct comparison of hallucination rates against baseline RAG methods on identical inputs

## Confidence

| Claim | Confidence |
|-------|------------|
| Performance metrics accurate | Medium |
| Method generalizes to other domains | Low |
| Knowledge graph construction scalable | Medium |
| Two-stage retrieval improves relevance | Medium |

## Next Checks

1. Implement the three-layer extraction pipeline using a publicly available domain ontology and evaluate entity/relation extraction quality on a held-out document set.
2. Replicate the two-stage retrieval approach on a different multimodal technical domain (e.g., medical device documentation) and measure performance degradation/gains.
3. Conduct ablation studies comparing DSRAG's graph-guided pruning against pure vector retrieval and pure graph traversal baselines on identical document collections.