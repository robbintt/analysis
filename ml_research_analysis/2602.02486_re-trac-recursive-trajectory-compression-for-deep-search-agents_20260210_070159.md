---
ver: rpa2
title: 'RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents'
arxiv_id: '2602.02486'
source_url: https://arxiv.org/abs/2602.02486
tags:
- re-trac
- search
- state
- answer
- deep
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RE-TRAC addresses the limitations of ReAct-style linear reasoning
  workflows in deep research agents, where strict sequential execution hinders revisiting
  earlier states, branching into alternative search directions, and maintaining global
  awareness under long contexts. This often leads to local optima, redundant exploration,
  and inefficient search.
---

# RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents

## Quick Facts
- arXiv ID: 2602.02486
- Source URL: https://arxiv.org/abs/2602.02486
- Reference count: 40
- Primary result: RE-TRAC improves deep research agents by 15-20% on BrowseComp through recursive trajectory compression

## Executive Summary
RE-TRAC addresses the limitations of ReAct-style linear reasoning workflows in deep research agents, where strict sequential execution hinders revisiting earlier states, branching into alternative search directions, and maintaining global awareness under long contexts. This often leads to local optima, redundant exploration, and inefficient search. RE-TRAC introduces a recursive trajectory compression framework that generates structured state representations after each trajectory, summarizing evidence, uncertainties, failures, and future plans. Subsequent trajectories are conditioned on this state representation, enabling iterative reflection and globally informed planning. Empirical results show that RE-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, RE-TRAC-aware supervised fine-tuning achieves state-of-the-art performance at comparable scales. Notably, RE-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search.

## Method Summary
RE-TRAC implements a recursive loop where each trajectory generates a structured state representation summarizing evidence, uncertainties, failures, and future plans. This compressed state is prepended to subsequent trajectories, enabling cross-trajectory exploration and reflection. The system uses two tools (search and visit) and runs for N rounds (default 8 for inference, 4 for SFT). Training involves generating 33K QA pairs from Wikipedia entity-trees, collecting 4-round compressed trajectories from teacher models (GLM-4.7), and fine-tuning student models (Qwen3-4B-Instruct, Tongyi-DeepResearch-30B-A3B). The compression format includes answer conclusions, evidence base, uncertainties, and exploration traces, with frontier LLMs using an extended format including failed attempts and discarded possibilities.

## Key Results
- RE-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs
- RE-TRAC-aware SFT achieves state-of-the-art performance for smaller models at comparable scales
- Monotonic reduction in tool calls and token usage across rounds indicates progressively targeted exploration

## Why This Works (Mechanism)

### Mechanism 1: Structured State Representation as Cross-Trajectory Memory
- **Claim:** Explicitly summarizing trajectory outcomes into a structured state reduces catastrophic forgetting and preserves unexplored branches.
- **Mechanism:** After each trajectory Ï„_t, the system generates a structured state S_t containing: (1) Answer & Analytical Conclusions, (2) Evidence Base & Source Verification, (3) Uncertainties & Exploration Trace. This state is prepended to the next round's input, providing compressed but actionable memory rather than raw trajectory history.
- **Core assumption:** Models can more effectively reason from structured summaries than from growing linear context (unproven in paper but empirically supported by performance gains).
- **Evidence anchors:**
  - [abstract]: "generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans"
  - [Section 4.1]: "This structured state is added to the input of the subsequent rollout, ensuring that the agent starts each new attempt with a clear understanding of what is verified"
  - [corpus]: ReSum (arXiv 2509

## Foundational Learning

### Concept 1: Cross-Trajectory Exploration
**Why needed:** Linear reasoning agents get stuck in local optima because they can't revisit earlier states or explore alternative branches.
**Quick check:** Does the system show increased search space coverage across rounds compared to single-trajectory approaches?

### Concept 2: Structured State Compression
**Why needed:** Raw trajectory context grows linearly and overwhelms models; structured summaries preserve key information while enabling efficient reasoning.
**Quick check:** Does the compressed state reduce token usage by >50% while maintaining >95% of search effectiveness?

### Concept 3: Recursive Reflection Loop
**Why needed:** Deep research requires iterative refinement where each attempt builds on previous insights rather than starting fresh.
**Quick check:** Does tool usage decrease monotonically across rounds, indicating more targeted exploration?

## Architecture Onboarding

### Component Map
Teacher Model (GLM-4.7) -> Trajectory Collection -> Structured State Compression -> SFT Training -> Student Models (Qwen3-4B, Tongyi-DeepResearch-30B-A3B)

### Critical Path
Search Tool -> Visit Tool -> Structured State Generation -> Continuation Prompt -> Next Trajectory

### Design Tradeoffs
- **Structured vs. raw context:** Structured states reduce token usage but may lose nuanced information; paper shows this tradeoff favors structured approaches
- **Compression granularity:** Full structured states vs. minimal summaries; frontier LLMs use extended format including failed attempts
- **Recursion depth:** Default 8 rounds balances exploration depth with computational cost

### Failure Signatures
- Over-reliance on summaries leading to "logic loops" in exploration
- Incomplete branch exploration (93% in failed trajectories)
- 4B model weak summarization limiting search efficiency

### 3 First Experiments
1. **State fidelity ablation:** Compare raw trajectory context vs. compressed structured state as round 2+ input
2. **Cross-trajectory diversity:** Instrument to log branch selection entropy across rounds
3. **Small model scalability:** Train Re-TRAC-SFT vs baseline ReAct-SFT on identical data

## Open Questions the Paper Calls Out
None

## Limitations
- Entity-tree synthesis method details are unspecified, affecting reproducibility of training data
- Teacher model sampling strategies and termination criteria are not detailed
- Limited empirical coverage beyond BrowseComp, lacking comprehensive error analysis

## Confidence
- **High:** Core architectural claim supported by monotonic reduction in tool calls/tokens and consistent BrowseComp performance gains
- **Medium:** SFT results rely on referenced work without direct comparative baselines in the paper
- **Low:** Claims about preventing "logic loops" lack empirical validation metrics

## Next Checks
1. **State representation fidelity test:** Implement ablation comparing raw trajectory context vs. compressed structured state as input for round 2+ on BrowseComp. Measure whether compression maintains >95% of original search effectiveness while reducing token usage by >50%.

2. **Cross-trajectory diversity analysis:** Instrument Re-TRAC to log branch selection entropy across rounds. Verify that the continuation prompt actually increases search space diversity rather than converging to local optima, particularly after round 3.

3. **Small model scalability validation:** Train Re-TRAC-SFT on both Qwen3-4B and a baseline ReAct-SFT model using identical data. Compare not just accuracy but also per-round tool call counts and final answer quality across BrowseComp's full test set.