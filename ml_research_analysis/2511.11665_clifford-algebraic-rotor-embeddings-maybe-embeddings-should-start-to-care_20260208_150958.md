---
ver: rpa2
title: 'Clifford Algebraic Rotor Embeddings : Maybe embeddings should start to CARE'
arxiv_id: '2511.11665'
source_url: https://arxiv.org/abs/2511.11665
tags:
- rope
- embeddings
- quatro
- rotary
- care
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Quaternion Rotary Embeddings (QuatRo) and
  Clifford Algebraic Rotary Embeddings (CARE) as extensions of Rotary Positional Embeddings
  (RoPE) to higher dimensions and richer geometric representations. QuatRo replaces
  Euler angles in Spherical RoPE with quaternions, allowing arbitrary rotation axes
  in 3D and subsuming both Mixed RoPE and Spherical RoPE as special cases.
---

# Clifford Algebraic Rotor Embeddings : Maybe embeddings should start to CARE

## Quick Facts
- arXiv ID: 2511.11665
- Source URL: https://arxiv.org/abs/2511.11665
- Reference count: 3
- Top-1 accuracy on CIFAR100: CARE achieves 74.8%, slightly outperforming QuatRo (74.3%) and Spherical RoPE (74.3%)

## Executive Summary
This paper introduces Quaternion Rotary Embeddings (QuatRo) and Clifford Algebraic Rotary Embeddings (CARE) as extensions of Rotary Positional Embeddings (RoPE) to higher dimensions and richer geometric representations. QuatRo replaces Euler angles in Spherical RoPE with quaternions, allowing arbitrary rotation axes in 3D and subsuming both Mixed RoPE and Spherical RoPE as special cases. CARE generalizes this further by using Clifford rotors to act on multivectors of all grades in Cl(3,0,0), enabling richer positional encoding schemes. Preliminary experiments on CIFAR100 using a ViT-B architecture show CARE achieving 74.8% top-1 accuracy, slightly outperforming QuatRo (74.3%) and Spherical RoPE (74.3%). The authors note that while QuatRo is marginally slower than previous methods, CARE is significantly slower due to geometric product computations. The work remains preliminary, with results from a single CIFAR100 run, and future work planned to extend CARE to higher-dimensional data and explore different algebras.

## Method Summary
The paper extends RoPE to 3D embeddings using quaternion-based rotations (QuatRo) and Clifford rotors (CARE). QuatRo parameterizes rotation axes via unit quaternions r = cos(θ/2) + u·sin(θ/2) where u is a learnable 3D vector, enabling arbitrary rotation axes rather than fixed principal axes. CARE further extends this by representing embeddings as multivectors in Cl(3,0,0) basis {1, e₁, e₂, e₁₂, e₃, e₃₁, e₂₃, e₁₂₃}, applying rotors through the geometric product. Both methods use sandwich product q̃ = RᵧRₓqRₓ⁻¹Rᵧ⁻¹ for rotations, with standard RoPE frequency schedules for angle parameters. QuatRo uses 3D sub-vectors while CARE splits into 8D multivector coefficients.

## Key Results
- CARE achieves 74.8% top-1 accuracy on CIFAR100 with ViT-B, slightly outperforming QuatRo (74.3%) and Spherical RoPE (74.3%)
- CARE subsumes both QuatRo and Spherical RoPE as special cases within the Clifford algebraic framework
- QuatRo is marginally slower than previous methods, while CARE is significantly slower due to geometric product computations
- All methods show similar performance despite different theoretical advantages

## Why This Works (Mechanism)

### Mechanism 1: Quaternion-based rotation parameterization
- Claim: Quaternions provide more flexible axis parameterization for 3D rotations than Euler angles
- Mechanism: Unit quaternions r = cos(θ/2) + u·sin(θ/2) encode arbitrary rotation axes u, enabling composition without gimbal lock. Query/key sub-vectors are rotated via the sandwich product q' = r·q·r⁻¹
- Core assumption: Rotation around arbitrary (learnable) axes provides better inductive bias than rotations fixed to principal axes
- Evidence anchors:
  - [abstract]: "leveraging quaternions' ability to represent 3D rotations to parameterize the axes of rotation"
  - [section 4]: "This allows us to parameterize the axes of rotation in each sub-vector rather than rotating around orthogonal axes"
  - [corpus]: "A Circular Argument" (FMR=0.64) explores non-commutative RoPE variants for vision, suggesting equivariance may not be essential
- Break condition: If arbitrary rotation axes provide no benefit over principal axes—empirical results show Mixed RoPE (74.2%) slightly underperforms Spherical RoPE (74.3%), suggesting equivariance may have small inductive bias value

### Mechanism 2: Multi-grade positional encoding via Clifford rotors
- Claim: Acting on multivectors of all grades (scalar through trivector) enables richer positional transformations than vector-only methods
- Mechanism: CARE embeds query/key as 8D multivector coefficients in Cl(3,0,0) basis {1, e₁, e₂, e₁₂, e₃, e₃₁, e₂₃, e₁₂₃}. Rotors act on all grades simultaneously through the geometric product
- Core assumption: Higher-grade components (bivectors, trivectors) will learn meaningful positional representations, not just noise
- Evidence anchors:
  - [abstract]: "encoding positional information in multivectors of multiple grades, not just vectors"
  - [section 5]: "the query and key are split into 8D sub-vectors corresponding to each scalar coefficient in Cl(3,0,0)"
  - [corpus]: Weak corpus evidence—no prior work directly compares multi-grade vs. vector-only positional encoding
- Break condition: If the model underutilizes higher grades—authors note: "we have not done this as of yet" regarding grade utilization analysis

### Mechanism 3: Algebraic unification of RoPE variants
- Claim: Clifford algebra provides a principled framework that subsumes Spherical, Mixed, and QuatRo as special cases
- Mechanism: Quaternions are isomorphic to the even subalgebra of Cl(3,0,0). By restricting CARE to vector-grade only with orthogonal/parallel bivectors, it collapses to Spherical/Mixed RoPE respectively
- Core assumption: The algebraic structure provides implementation consistency and potential extension paths
- Evidence anchors:
  - [abstract]: "Viewing quaternions as the even subalgebra of Cl(3,0,0), we extend the notion of rotary embeddings from quaternions to Clifford rotors"
  - [section A]: "vector-only CARE with orthogonal bivectors recovers Spherical RoPE, even-grade CARE restricted to the even subalgebra reduces to QuatRo"
  - [corpus]: LieRE (cited) takes a related approach using skew-symmetric matrix generators, but CARE extends beyond this to multivectors
- Break condition: If computational overhead of geometric product outweighs architectural benefits—authors explicitly state "CARE is significantly slower due to geometric product"

## Foundational Learning

- **Concept: Geometric (Clifford) Algebra basics**
  - Why needed here: CARE represents embeddings as multivectors and applies rotors via the geometric product
  - Quick check question: In Cl(3,0,0), what do the 8 basis elements {1, e₁, e₂, e₁₂, e₃, e₃₁, e₂₃, e₁₂₃} represent in terms of grades?

- **Concept: Quaternion rotation formula**
  - Why needed here: QuatRo uses r·q·r⁻¹ sandwich product to rotate 3D embedding sub-vectors
  - Quick check question: Given unit quaternion r = cos(θ/2) + u·sin(θ/2), how would you rotate a pure quaternion v representing a 3D vector?

- **Concept: RoPE's relative position encoding**
  - Why needed here: All methods extend RoPE's core insight that position-dependent rotations enable relative position recovery via qᵀk ∝ f(m-n)
  - Quick check question: Why does RoPE's rotation-based encoding preserve relative positional information in attention scores?

## Architecture Onboarding

- **Component map:**
  Input layer -> Split query/key into sub-vectors (3D for QuatRo, 8D for CARE) -> Rotor generator -> Rotation module (sandwich product) -> Frequency scheduler

- **Critical path:**
  1. Implement geometric product efficiently (current bottleneck)—consider lookup tables or specialized kernels
  2. Initialize rotor axes for numerical stability (unit norm constraint)
  3. Ensure sub-vector alignment matches algebra grade structure

- **Design tradeoffs:**
  - CARE (8D sub-vectors) vs QuatRo (3D): richer encoding vs. 2-3× slower
  - Non-commutative rotations: better performance possible, but loses strict shift-equivariance
  - Assumption: "CARE is significantly slower due to geometric product" may improve with optimized CA libraries

- **Failure signatures:**
  - Training divergence from non-unit rotors (enforce normalization)
  - Underutilized higher grades (check coefficient magnitudes per grade)
  - Single-run results mean high variance—authors note "conclusions are hard to draw from the results of one run"

- **First 3 experiments:**
  1. Reproduce Table 1 on CIFAR100 with ViT-B across multiple seeds to establish variance bounds
  2. Grade utilization analysis: log learned multivector coefficient magnitudes to test authors' prediction that "scalar channels which remain position invariant" may be emphasized
  3. Ablate between QuatRo and CARE with identical compute budgets to isolate expressivity vs. efficiency tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does CARE's utilization of multiple multivector grades provide meaningful benefits, and does it preferentially emphasize scalar channels as the authors predict?
- Basis in paper: [explicit] "While it would be interesting to look its utilization of each grade, we have not done this as of yet. We predict that it may emphasize the scalar channels which remain position invariant."
- Why unresolved: The authors have not conducted grade-level analysis to determine which components of the multivector representation are actually being utilized by the model during training and inference.
- What evidence would resolve it: Ablation studies analyzing the learned coefficients across all 8 grades of Cl(3,0,0) multivectors, particularly examining whether scalar (grade-0) coefficients show different positional sensitivity patterns compared to vector (grade-1) and higher-grade components.

### Open Question 2
- Question: Can CARE's computational overhead from geometric product computations be substantially reduced through optimized implementations?
- Basis in paper: [explicit] "CARE is significantly slower due to the geometric product. It is unclear if this limit is unsurpassable or due to the current lack of well optimized CA computations."
- Why unresolved: The current implementation uses naive geometric algebra operations without specialized optimization, leaving unclear whether the quadratic-like scaling of multivector operations is fundamental or an engineering limitation.
- What evidence would resolve it: Development and benchmarking of optimized geometric product kernels (e.g., custom CUDA implementations, exploiting sparsity patterns in Cl(3,0,0)) comparing throughput against baseline RoPE variants while maintaining numerical accuracy.

### Open Question 3
- Question: Do the preliminary CIFAR-100 results generalize to higher-dimensional data where CARE's theoretical advantages should be more pronounced?
- Basis in paper: [explicit] "While CARE generalizes QuatRo to higher-dimensional data such as video or point clouds, this work is still in progress, and experiments are currently restricted to 2D images."
- Why unresolved: CARE is designed for arbitrary dimensions and richer geometric representations, but has only been validated on 2D image classification where its multivector structure may be underutilized.
- What evidence would resolve it: Systematic evaluation on 3D point clouds (e.g., ModelNet40), video datasets, or 4D spatiotemporal data comparing CARE against QuatRo, Mixed RoPE, and Spherical RoPE to assess whether the multivector encoding provides measurable benefits as dimensionality increases.

## Limitations

- Empirical validation is severely constrained by single-run CIFAR100 results, making statistical significance impossible to establish
- Computational overhead of CARE's geometric product remains unquantified, creating uncertainty about practical utility
- Lack of grade utilization analysis leaves unclear whether multi-grade encoding provides meaningful benefits beyond simpler methods

## Confidence

**High confidence** in mathematical correctness of Clifford algebraic framework and quaternion rotation implementation
**Medium confidence** in claim that arbitrary rotation axes provide better inductive bias than principal axes (0.5% accuracy advantage not statistically significant)
**Low confidence** in practical utility of multi-grade encoding without further empirical validation

## Next Checks

1. **Statistical validation**: Run CIFAR100 experiments with ViT-B across 5-10 random seeds to establish confidence intervals and determine whether CARE's 0.5% advantage over QuatRo is statistically significant.

2. **Grade utilization analysis**: Log and visualize the learned multivector coefficient magnitudes across all eight grades during training to test whether higher-grade components (bivectors, trivectors) are actually learning meaningful positional information or being dominated by scalar/vector components.

3. **Computational efficiency benchmarking**: Measure wall-clock training time and memory usage for CARE vs QuatRo vs baseline RoPE implementations, then calculate the accuracy-per-compute tradeoff to determine whether the theoretical expressivity gains justify the practical cost.