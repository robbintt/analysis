---
ver: rpa2
title: 'Better audio representations are more brain-like: linking model-brain alignment
  with performance in downstream auditory tasks'
arxiv_id: '2511.16849'
source_url: https://arxiv.org/abs/2511.16849
tags:
- audio
- mel256
- brain
- speech
- representations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Better audio representations are more brain-like: linking model-brain alignment with performance in downstream auditory tasks

## Quick Facts
- **arXiv ID:** 2511.16849
- **Source URL:** https://arxiv.org/abs/2511.16849
- **Reference count:** 40
- **Key outcome:** Self-supervised masked reconstruction models trained on diverse audio data show strongest alignment with human auditory cortex fMRI responses, and this alignment correlates with downstream task performance (r=0.72-0.76)

## Executive Summary
This paper systematically analyzes the relationship between audio model representations and human auditory cortex responses across 36 different models. The authors find that self-supervised masked reconstruction models trained on diverse audio data (speech, music, environmental sounds) achieve the strongest brain alignment, as measured by both voxel-wise regression and representational similarity analysis (RSA). Critically, this brain alignment correlates with downstream task performance on the HEAREval benchmark, suggesting that brain-like representations are beneficial for auditory processing. The study also shows that brain alignment emerges as an emergent property during pretraining, without requiring explicit neural supervision.

## Method Summary
The study compares 36 audio models against fMRI data from 28 human subjects (8 in NH2015, 20 in B2021) who listened to 165 natural sound clips. Brain alignment is measured through two complementary approaches: voxel-wise ridge regression to predict neural responses, and RSA comparing representational dissimilarity matrices. Models are evaluated at multiple layers to identify where brain-like representations emerge. The analysis also correlates brain alignment with downstream performance across six auditory tasks (speech, music, environmental sound classification, etc.) using HEAREval. Key models include transformer-based masked reconstruction approaches (EnCodecMAE, BEATs, Dasheng) versus traditional models (VGGish, Wav2Vec2, CochDNN).

## Key Results
- Self-supervised masked reconstruction models (EnCodecMAE, BEATs, Dasheng) show significantly stronger brain alignment than traditional models
- Brain alignment correlates with downstream task performance (r=0.72-0.76 across metrics)
- Pretraining data diversity—not just model architecture—drives brain alignment improvements
- Brain alignment emerges progressively during pretraining without explicit neural supervision
- Finetuning on specific tasks does not improve brain alignment, suggesting it captures general auditory processing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Self-supervised masked reconstruction produces representations that converge toward brain-like organization without explicit neural supervision.
- Mechanism: The model learns to predict masked audio segments from visible context. This reconstruction pressure forces the model to discover latent structure in natural audio signals—spectral patterns, temporal dependencies, and object-level regularities. Because the human auditory system evolved to solve similar prediction problems under ecological constraints (e.g., phonemic restoration, predictive coding), representations optimized for reconstruction naturally overlap with neural representations.
- Core assumption: Biological auditory processing implements some form of predictive coding or missing-information reconstruction.
- Evidence anchors:
  - [abstract] "brain-like representations can be an emergent byproduct of learning to reconstruct missing information from naturalistic audio data"
  - [section 2.4] Figure 6 shows Spearman's ρ increases progressively across pretraining steps for EnCodecMAE layers, despite no fMRI data in training
  - [corpus] BrainWavLM (arXiv:2502.08866) shows fine-tuning speech models with brain responses improves semantic understanding, suggesting bidirectional alignment potential
- Break condition: If a model achieves strong brain alignment *without* reconstruction-based pretraining (e.g., purely supervised), or if reconstruction-trained models systematically diverge from brain patterns, this mechanism would be weakened.

### Mechanism 2
- Claim: Training data diversity—spanning multiple auditory domains—improves brain alignment by constraining the solution space toward more general representations.
- Mechanism: When a model must solve diverse tasks (speech, music, environmental sounds), the set of representations that simultaneously support all tasks shrinks. This convergence pressure pushes models toward " Platonic" representations that capture shared structure across domains—structure that biological systems also extract because they operate in the same acoustic world.
- Core assumption: The human auditory system processes diverse sound categories using partially shared computational substrates.
- Evidence anchors:
  - [section 2.1] "models trained on mixtures of diverse audio sources show the strongest prediction capabilities"; EnCodecMAE trained only on speech (LibriLight) shows lower alignment than when trained on mixture (AudioSet + LibriLight + FMA)
  - [section 2.3] "models trained exclusively on speech or music are not the best predictors of the corresponding music and speech selective components. Instead, the top-performing models are those trained on a combination of datasets"
  - [corpus] Disentangling the Factors of Convergence (arXiv:2508.18226) independently finds that training data properties drive brain-model similarity in vision, consistent with cross-modal pattern
- Break condition: If specialized models (trained on single domains) consistently achieve *higher* brain alignment than diverse-trained models within their specialty domain, diversity as a mechanism would be questioned.

### Mechanism 3
- Claim: Hierarchical depth enables correspondence between model stages and brain regions, but this correspondence is layer-specific rather than uniformly distributed.
- Mechanism: Early layers capture low-level spectro-temporal features (similar to primary auditory cortex), while deeper layers integrate context and abstract structure (similar to higher auditory areas). The pretraining process causes early differentiation—certain layers specialize away from primary regions toward posterior/lateral areas.
- Core assumption: The auditory cortex has functionally distinct sub-regions that process different levels of abstraction.
- Evidence anchors:
  - [section 2.4] Figure 7 shows layers 7–8 exhibit early decrease in similarity with primary auditory region while maintaining high similarity with posterior region
  - [section 2.3] Figure 5 shows early components (LF, HF—spectral features) correlate with cochleagram-input models, while speech/music components correlate with deeper transformer models
  - [corpus] TopoNets (arXiv:2501.16396) introduces topographic organization to vision/language models, showing brain-like spatial organization is compatible with high performance—suggesting hierarchy and topography are complementary
- Break condition: If all layers show uniform similarity to all brain regions, or if shallow models match deep-brain regions as well as deep models, hierarchical correspondence would not hold.

## Foundational Learning

- Concept: **Representation Similarity Analysis (RSA)**
  - Why needed here: Core methodology for comparing model and brain representations without requiring dimensionality matching. The paper uses RDMs (representation dissimilarity matrices) computed as 1 minus Pearson correlation between stimulus pairs.
  - Quick check question: Given two representation matrices (165 stimuli × D1 and 165 stimuli × D2), can you explain why comparing their RDMs is valid even when D1 ≠ D2?

- Concept: **Self-Supervised Masked Modeling (Masked Autoencoding)**
  - Why needed here: The top-performing models (EnCodecMAE, BEATs, Dasheng) all use variants of masked prediction. Understanding what targets are predicted (discrete tokens vs. continuous spectrograms) is crucial for interpreting results.
  - Quick check question: EnCodecMAE predicts discrete EnCodec tokens; Dasheng predicts continuous melspectrograms. What inductive bias might each target introduce?

- Concept: **Brain Encoding via Linear Regression**
  - Why needed here: Alternative to RSA; trains ridge regressors to predict voxel activity from model features. Can identify subspaces of model representations relevant to brain prediction—unlike RSA which is holistic.
  - Quick check question: Why might regression show stronger differences between models than RSA (as observed in section 2.2)?

## Architecture Onboarding

- Component map:
  - **EnCodecMAE**: Melspectrogram -> Patch embedding -> Transformer encoder (10–20 layers) -> Predict discrete EnCodec tokens at masked positions
  - **BEATs**: Melspectrogram -> Patch embedding -> 12-layer ViT -> Predict discrete labels (iteratively refined tokenizer)
  - **Dasheng**: Melspectrogram -> Patch embedding -> 12–40 layer Transformer -> Reconstruct melspectrogram (MSE loss)
  - **Analysis pipeline**: Audio stimuli (165 clips, 2s each) -> Forward pass through all layers -> Extract activations -> Compare to fMRI via (a) voxel-wise ridge regression, (b) RSA via RDMs, (c) component regression (6 ICA components)

- Critical path:
  1. Select pretrained audio model (architecture + checkpoint)
  2. Extract layer-wise activations for all 165 stimuli
  3. Compute alignment: (a) Train ridge regressor per voxel with nested CV; (b) Compute RDM, Spearman correlation with brain RDM
  4. Aggregate: median R² across voxels -> mean across subjects; or max ρ across layers -> mean across subjects

- Design tradeoffs:
  - **Regression vs. RSA**: Regression finds task-relevant subspaces but may ignore global structure; RSA captures holistic similarity but cannot filter irrelevant dimensions. Paper finds high correlation (r=0.92) between methods, but RSA shows smaller model differences.
  - **Layer selection**: Evaluating all layers is computationally expensive; sampling evenly (as done for Large models) risks missing the optimal alignment layer.
  - **Component vs. voxel regression**: Components (6) reduce computation and isolate functional selectivity, but lose 20% variance and anatomical specificity.

- Failure signatures:
  - Model shows high downstream performance but low brain alignment -> check training data composition (Dasheng's ACAV100M bias toward audio-visual correlation may reduce ecological validity)
  - Finetuning decreases alignment -> suggests task-specific representations diverge from general brain-like structure (observed: finetuning on acoustic event detection showed no improvement)
  - Early layers outperform deep layers on all brain regions -> suggests hierarchical correspondence failed; check model architecture for information bottlenecks

- First 3 experiments:
  1. **Reproduce regression vs. RSA comparison**: Take 2–3 diverse models (EnCodecMAE Large, Wav2Vec2, VGGish). Extract activations, compute both voxel-wise R² and RSA ρ. Verify correlation r > 0.85 between metrics.
  2. **Pretraining data ablation**: Train EnCodecMAE Base on (a) speech-only (LibriLight), (b) music-only (FMA), (c) mixture. Measure alignment to speech-selective vs. music-selective brain components. Expect mixture model to outperform on both.
  3. **Checkpoint progression analysis**: Load EnCodecMAE checkpoints at steps 0, 20k, 40k, 60k, 80k, 100k. Plot ρ for layers 2, 4, 6, 8, 10 against primary vs. posterior brain regions. Verify early differentiation pattern (layers 7–8 diverge from primary).

## Open Questions the Paper Calls Out
None

## Limitations
- The study establishes correlation but cannot definitively prove causation between brain alignment and downstream performance
- RSA methodology may miss task-relevant subspaces where brain alignment drives performance gains
- Model diversity is uneven, with transformer-based models dominating top performers

## Confidence
- **High confidence**: Self-supervised masked reconstruction models show strongest brain alignment; pretraining data diversity drives improvements
- **Medium confidence**: Brain alignment emerges as emergent property without neural supervision; causal mechanism between alignment and performance remains speculative
- **Medium confidence**: Correlation between brain alignment and downstream performance is robust but may reflect shared underlying properties

## Next Checks
1. **Causal intervention test:** Train a masked reconstruction model on diverse data, then explicitly align it to brain responses using brainWavLM-style fine-tuning. Compare downstream performance to original model.
2. **Architecture ablation study:** Train a convolutional model with exact training data and objective of a transformer model. If alignment remains low, supports architectural contribution.
3. **Cross-modal validation:** Apply same RSA and regression pipeline to vision models using BrainScore data. If correlation holds across modalities, strengthens general principles.