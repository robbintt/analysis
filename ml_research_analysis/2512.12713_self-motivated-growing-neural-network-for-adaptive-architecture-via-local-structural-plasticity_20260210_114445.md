---
ver: rpa2
title: Self-Motivated Growing Neural Network for Adaptive Architecture via Local Structural
  Plasticity
arxiv_id: '2512.12713'
source_url: https://arxiv.org/abs/2512.12713
tags:
- growth
- learning
- structural
- smgrnn
- local
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Self-Motivated Growing Neural Network
  (SMGrNN), a controller whose topology evolves online through a local Structural
  Plasticity Module (SPM). The SPM monitors neuron activations and edge-wise weight
  update statistics over short temporal windows and uses these signals to trigger
  neuron insertion and pruning, while synaptic weights are updated by a standard gradient-based
  optimizer.
---

# Self-Motivated Growing Neural Network for Adaptive Architecture via Local Structural Plasticity

## Quick Facts
- **arXiv ID:** 2512.12713
- **Source URL:** https://arxiv.org/abs/2512.12713
- **Reference count:** 38
- **Primary result:** SMGrNN achieves similar or higher returns than MLP baselines while using smaller, task-appropriate network sizes through online structural adaptation.

## Executive Summary
This paper introduces SMGrNN, a neural network controller whose topology evolves during learning through a local Structural Plasticity Module (SPM). The SPM monitors neuron activations and edge-wise weight update statistics over short temporal windows, using these signals to trigger neuron insertion and pruning while standard gradient-based optimization updates synaptic weights. This design enables network capacity to be regulated during learning without manual architectural tuning. Evaluated on control benchmarks via policy distillation, SMGrNN demonstrates similar or higher returns than MLP baselines, lower variance, and task-appropriate network sizes. Ablation studies with growth disabled and growth-only variants isolate the role of structural plasticity, showing that adaptive topology improves reward stability. The local and modular design enables future integration of Hebbian plasticity and spike-timing-dependent plasticity for broader applicability.

## Method Summary
SMGrNN is a directed graph with tanh activations, initialized with input/output nodes and zero hidden nodes at 0.8 edge density. A standard gradient optimizer (assumed Adam) updates weights via supervised distillation loss against a pre-trained expert MLP. The SPM maintains rolling T-step buffers of activations and weight updates per node/edge. On each episode, the network performs forward pass, computes loss, backward pass for weight updates, then updates history buffers. Every s steps, the SPM evaluates pruning conditions (low-magnitude, low-activity edges and orphan nodes) and alternately checks for edge-driven growth (instability detection via μ_Δ and σ_Δ² statistics) and random exploratory growth (Bernoulli trigger). Structural changes are applied immediately, with new weights initialized small. The system operates for 2000 episodes with 10 seeds per task.

## Key Results
- SMGrNN achieves similar or higher episodic returns compared to static MLP baselines across CartPole, Acrobot, and LunarLander tasks
- Network size trajectories show task-appropriate capacity: 10-50 hidden nodes versus 64-128 in MLP baselines
- Growth-enabled variants show lower reward variance across seeds compared to growth-disabled ablations
- Growth-only variant (pruning disabled) requires 50-80× more parameters while maintaining comparable performance

## Why This Works (Mechanism)

### Mechanism 1: Instability-Triggered Capacity Expansion
Edges with fluctuating gradient statistics signal unresolved representational needs; inserting relay nodes at these locations provides additional computational capacity where the optimizer cannot settle. The SPM computes mean (μ_Δ) and variance (σ_Δ²) of weight updates over a sliding window T. When |μ_Δ| < ½σ_Δ AND σ_Δ² > λ_edge|μ_Δ| (high variance relative to near-zero mean), a new relay node is inserted along the unstable edge, creating a parallel two-step pathway while preserving the original connection. Core assumption: Gradient instability reflects insufficient representational capacity along that path rather than noise, hyperparameter issues, or data problems. Break condition: If gradient fluctuations stem from noisy rewards, sparse gradients, or learning rate issues rather than capacity constraints, this mechanism may grow unnecessarily.

### Mechanism 2: Magnitude-Based Pruning with Orphan Removal
Removing low-magnitude, low-activity edges prevents unbounded expansion and concentrates representational power on effective pathways. Edges are marked for removal when |w_k| ≤ τ_w AND |μ_Δ_k| ≤ τ_Δ (small weight magnitude and stalled updates). A fraction η_prune of candidates is randomly deleted each pruning step. Hidden nodes with zero in-degree or out-degree are then removed as orphans. Core assumption: Small weights with negligible updates indicate connections that do not contribute meaningfully to the policy output. Break condition: If τ_w is set too high, useful sparse connections may be pruned; if too low, ineffective connections accumulate.

### Mechanism 3: Decoupled Structural and Synaptic Plasticity
Separating topology decisions (local statistics) from weight optimization (global gradients) allows each to operate at appropriate timescales without interference. The SPM accesses only local activation and weight-update statistics via rolling history buffers; it never sees the loss function or reward signal. Gradient-based optimization handles weight updates independently. Growth and pruning alternate on a fixed schedule Σ(t). Core assumption: Local activity statistics are sufficient proxies for determining where capacity is needed or excess. Break condition: If local statistics are poor proxies for task-relevant capacity needs, structural changes may not align with performance improvements.

## Foundational Learning

- **Sliding-window statistics (mean, variance over time series)**: The SPM triggers decisions based on T-step rolling statistics of weight updates, not instantaneous values. Understanding how window length affects signal smoothing is essential for tuning T. Quick check: If T=100 and weight updates alternate between +0.1 and -0.1, what are μ_Δ and σ_Δ?

- **Policy distillation (teacher-student imitation)**: SMGrNN is evaluated via distillation from a pretrained expert MLP, not direct RL. The loss L_t(θ) is supervised between expert and student actions. Quick check: Why might distillation obscure how SMGrNN would perform under direct reinforcement learning?

- **Graph topology in neural networks (nodes, directed edges, skip connections, cycles)**: SMGrNN is a directed graph G_t = (V_t, E_t) with no acyclicity constraint; cycles and skip connections can emerge. Understanding topological implications for forward/backward passes is critical. Quick check: What happens to gradient flow if a cycle forms during growth?

## Architecture Onboarding

- **Component map:**
  - State → SMGrNN graph (input/hidden/output nodes with weighted edges) → Action
  - History buffers: rolling T-step storage of activations and weight updates per node/edge
  - SPM: edge-driven growth (instability detection), random exploratory growth (Bernoulli trigger), pruning (magnitude + stall + orphan removal)
  - Gradient optimizer: standard backpropagation on distillation loss

- **Critical path:**
  1. Initialize graph with input/output nodes, zero hidden nodes, connection density 0.8
  2. Forward pass: state → G_t → action
  3. Compute distillation loss vs expert action
  4. Backward pass: update weights via gradient descent
  5. Update history buffers with new activations and Δw values
  6. SPM evaluation: if t mod s = 0, prune; else, check edge-driven and random growth triggers
  7. Apply structural edits (insert nodes/edges, remove pruned elements)
  8. Repeat per episode

- **Design tradeoffs:**
  - Window length T: Longer windows smooth noise but delay response to genuine instability
  - λ_edge scaling factor: Lower values make growth more aggressive; higher values require stronger instability
  - Pruning fraction η_prune: High values cause abrupt changes; low values allow bloat
  - Pruning period s: Frequent pruning may destabilize; infrequent pruning allows temporary bloat

- **Failure signatures:**
  - No growth: Instability threshold too strict; check if σ_Δ actually exceeds λ_edge|μ_Δ|
  - Unbounded growth: Pruning disabled or thresholds too permissive; monitor parameter count trajectory
  - Catastrophic performance drop: Pruning removing critical connections; check if τ_w removes edges with large gradient magnitudes
  - High variance across seeds: Random growth dominates; reduce p_rand or increase T for more stable statistics

- **First 3 experiments:**
  1. Reproduce CartPole ablation: Train SMGrNN vs static-SMGrNN (growth disabled) for 2000 episodes with 10 seeds; verify that growth-enabled achieves lower reward variance and reaches similar or higher final return
  2. Growth-only sanity check: Disable pruning and train for 1000 episodes on CartPole; confirm parameter count grows 10-100× while reward remains comparable to standard SMGrNN
  3. Threshold sensitivity sweep: Vary λ_edge ∈ {0.05, 0.1, 0.2} and τ_w ∈ {0.05, 0.1, 0.2} on a single task; plot final parameter count vs late-training reward to identify stable operating region

## Open Questions the Paper Calls Out

### Open Question 1
Can SMGrNN's local structural plasticity mitigate catastrophic forgetting in explicit continual learning settings with sequential tasks? Basis: Current experiments only test within-task capacity adaptation via policy distillation from fixed experts, not retention of previously learned skills across task boundaries. What evidence would resolve it: Evaluate SMGrNN on standard continual learning benchmarks measuring both forward transfer and backward interference metrics.

### Open Question 2
Can the SPM be combined with local synaptic plasticity rules (Hebbian, STDP) to achieve fully local learning without backpropagation? Basis: The modular design enables this integration conceptually, but compatibility has not been empirically validated—weight update statistics in history buffers currently come from gradient-based optimizers. What evidence would resolve it: Implement an HPM or STDP module replacing backpropagation, then test whether SPM growth/pruning signals derived from local co-activation statistics produce comparable capacity adaptation and performance.

### Open Question 3
Can SPM hyperparameters (thresholds, growth ratios, pruning schedules) be meta-learned rather than hand-tuned? Basis: Current hyperparameters are fixed across tasks after tuning on CartPole; it is unclear whether optimal structural policies are environment-specific or generalizable. What evidence would resolve it: Meta-learn SPM hyperparameters on a distribution of training environments, then evaluate zero-shot transfer to held-out control tasks, comparing final network sizes and returns against hand-tuned baselines.

### Open Question 4
What is the computational and memory overhead of maintaining rolling history buffers and dynamic graph operations in larger-scale settings? Basis: Experiments use small control benchmarks with ~50 hidden nodes at most; scalability to high-dimensional inputs or deeper architectures remains untested. What evidence would resolve it: Profile training time, memory usage, and wall-clock overhead for SMGrNN versus static baselines on larger tasks.

## Limitations
- Performance evaluation restricted to policy distillation rather than direct reinforcement learning, leaving open questions about online reward optimization capability
- Instability criterion assumes gradient fluctuations indicate capacity needs rather than optimization artifacts, without direct validation
- Limited testing on complex, high-dimensional environments; scalability and computational overhead characterization remains incomplete

## Confidence

- **High confidence**: SMGrNN achieves competitive returns with smaller networks based on reported experimental results and ablation studies
- **Medium confidence**: Proposed instability-driven growth mechanism effectiveness, as the underlying assumption about gradient instability is not directly validated
- **Medium confidence**: Pruning effectiveness shown through growth-only variants, but precise relationship between threshold choices and functional impact underexplored
- **Low confidence**: Claim that local statistics suffice for structural decisions, as this separation principle is asserted but not empirically tested against global information

## Next Checks

1. Evaluate SMGrNN directly under reinforcement learning (not just distillation) to confirm generalization to online reward optimization
2. Test instability-triggered growth on a noisy-gradient benchmark to determine whether the mechanism responds to capacity needs versus optimization artifacts
3. Perform a systematic sweep of SPM hyperparameters (T, λ_edge, τ_w, p_rand) across multiple tasks to map the stability/robustness frontier