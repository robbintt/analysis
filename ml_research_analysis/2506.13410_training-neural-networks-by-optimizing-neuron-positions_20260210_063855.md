---
ver: rpa2
title: Training Neural Networks by Optimizing Neuron Positions
arxiv_id: '2506.13410'
source_url: https://arxiv.org/abs/2506.13410
tags:
- neurons
- baseline
- neural
- weights
- number
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors propose a parameter-efficient neural architecture where
  neurons are embedded in 3D Euclidean space and their positions are optimized during
  training. Connection weights are computed as the inverse of spatial distance between
  neurons, replacing traditional weight matrices.
---

# Training Neural Networks by Optimizing Neuron Positions

## Quick Facts
- arXiv ID: 2506.13410
- Source URL: https://arxiv.org/abs/2506.13410
- Reference count: 18
- 3D-embedded MLPs achieved 92.17% accuracy on MNIST with 10,576 parameters (vs 97.45% for traditional MLPs with 1.6M parameters)

## Executive Summary
This paper proposes a parameter-efficient neural architecture where neurons are embedded in 3D Euclidean space and their positions are optimized during training. Connection weights are computed as the inverse of spatial distance between neurons, replacing traditional weight matrices. This approach significantly reduces parameters (from O(n²) to O(n)) while introducing biologically inspired inductive biases. The spatially embedded models show improved robustness to pruning, maintaining performance at >80% sparsity rates.

## Method Summary
The authors embed neurons in d-dimensional Euclidean space, where each neuron stores only its position coordinates rather than explicit connection weights. Weights are computed on-the-fly as the inverse of spatial distance between neurons (w_ij = 1/||p_i - p_j||²). Each neuron also has a learnable inhibition value transformed through a steep sigmoid to enable both excitatory and inhibitory connections. During training, both positions and inhibition values are optimized via backpropagation. The framework is applied to both traditional MLPs and spiking neural networks (SNNs), with neurons constrained to fixed z-coordinates per layer by default but optionally relaxed.

## Key Results
- 3D-embedded MLPs achieved 92.17% accuracy on MNIST with 10,576 parameters (vs 97.45% for traditional MLPs with 1.6M parameters)
- 3D SNNs outperformed parameter-matched traditional SNNs (92.16% vs 90.31%)
- Spatially embedded models maintained performance at >80% pruning rates, outperforming traditional networks with equivalent parameters
- Relaxing spatial constraints by allowing z-coordinate optimization improved accuracy to 93.37%

## Why This Works (Mechanism)

### Mechanism 1: Distance-dependent wiring rules reduce parameters while preserving expressiveness
Replacing explicit weight matrices with inverse-distance-based weight computation achieves O(n) parameter scaling while maintaining competitive accuracy. Each neuron stores only its position coordinates, and connection weights are computed on-the-fly as w_ij = 1/||p_i - p_j||². This couples all weights involving a shared neuron, reducing degrees of freedom from n² independent weights to n×d position parameters plus n inhibition values.

### Mechanism 2: Inhibition masks enable sign flexibility within distance constraints
Learnable per-neuron inhibition values transformed through steep sigmoid allow the network to express both excitatory and inhibitory connections despite distance-based weights always being positive. Each neuron has a continuous inhibition value optimized during training. A scaled steep sigmoid maps positive values to masks ≈+1 (excitatory) and negative values to ≈-1 (inhibitory). The effective weight becomes w_ij × mask_j, enabling negative effective connections.

### Mechanism 3: Spatial embedding provides inherent pruning robustness
Spatially embedded networks outperform parameter-matched baselines under high sparsity (>60%) because pruning removes noise from the distance constraint while reducing harmful weight coupling. Distance-based weights cannot reach zero (distances are finite), so every neuron receives noisy input from all predecessors. Magnitude-based pruning eliminates weak, noisy inputs while also reducing interdependence—neurons can reposition with fewer cascading effects on other connections.

## Foundational Learning

- Concept: Gradient flow through position parameters
  - Why needed here: Understanding how ∂L/∂p_i propagates through the inverse-distance function is essential for debugging training dynamics
  - Quick check question: Can you derive ∂w_ij/∂p_i for w_ij = 1/||p_i - p_j||²?

- Concept: SNN temporal dynamics (LIF neurons)
  - Why needed here: The paper shows spatially embedded SNNs outperform parameter-matched baselines while MLPs underperform theirs
  - Quick check question: How does leaky integrate-and-fire dynamics allow a neuron to encode information beyond instantaneous weighted sums?

- Concept: Inductive bias from spatial constraints
  - Why needed here: The core tradeoff is parameter efficiency vs. expressiveness
  - Quick check question: What types of tasks would benefit from "nearby neurons should connect more strongly" as an inductive bias?

## Architecture Onboarding

- Component map:
  NeuronPositionStore -> WeightComputer -> InhibitionMask -> SparseConnector

- Critical path:
  1. Initialize neuron positions (random or structured within layer bounds)
  2. Initialize inhibition values (random near zero)
  3. Forward pass: compute all pairwise distances → inverse-distance weights → mask outputs → standard layer computation
  4. Backward pass: gradients flow to positions and inhibition values (not explicit weights)
  5. Pruning (optional): mask smallest weights before or during training

- Design tradeoffs:
  - Fixed vs. learned z-coordinates: Fixed preserves layer structure (clearer visualization, O(n) params); learned increases expressiveness but blurs layer boundaries
  - Embedding dimensionality: Higher dimensions (5D-32D) improve performance but increase parameters; returns diminish beyond 16D
  - Pruning during vs. after training: During-training pruning helps spatially embedded models; post-training pruning at extreme rates (95%) lets 3D MLP outperform even larger baselines

- Failure signatures:
  - Accuracy plateaus below baseline with same parameter count: Weight coupling too restrictive; try higher embedding dimension or relaxed z-constraint
  - Training instability: Position gradients may explode for very close neurons; add minimum distance floor
  - SNN works but MLP fails for same task: Task may require temporal coding to compensate for reduced weight flexibility

- First 3 experiments:
  1. Replicate MNIST 3D MLP with 2,048 hidden neurons, fixed layer distances; verify ~92% accuracy matches paper
  2. Ablate inhibition masks (force all excitatory) to measure sign flexibility contribution
  3. Test pruning at 80% during training on 3D SNN vs. 3D MLP to verify differential robustness

## Open Questions the Paper Calls Out

### Open Question 1
Can spatially embedded architectures maintain their efficiency and accuracy when scaled to deeper networks and complex datasets? The authors state validation is "limited to shallow networks trained on the MNIST dataset" and call for investigating "application to deeper architectures and more complex, diverse datasets."

### Open Question 2
Does relaxing the rigid layer-wise connectivity to allow for learned topology significantly improve model expressiveness? The conclusion proposes exploring "more flexible spatial embeddings" by "relaxing rigid layer-wise connectivity structure and allowing the network to learn its connectivity."

### Open Question 3
Can this spatial embedding framework improve performance on Graph Neural Networks (GNNs) utilizing sparse long-range connections? The authors suggest the approach "may also be well-suited for other neural architectures, such as Graph Neural Networks (GNNs)" and propose introducing "sparse long-range connections."

## Limitations
- The approach may struggle with tasks requiring highly specific weight patterns that don't align with spatial distance metrics
- The gap to traditional MLPs (92.17% vs 97.45%) suggests the spatial constraint still limits representational capacity
- The biological plausibility (Achterberg et al.) provides intuition but doesn't guarantee task performance

## Confidence
- Parameter reduction mechanism (O(n²) → O(n)): High confidence
- Pruning robustness claims: High confidence  
- Accuracy results for traditional MLPs (92.17%): Medium confidence
- SNN performance comparisons (92.16% vs 90.31%): High confidence

## Next Checks
1. Compute and verify ∂L/∂p_i for the inverse-distance weight formula to ensure stable training dynamics
2. Test performance when z-coordinates are fixed vs. learned across multiple embedding dimensions (3D, 16D, 32D)
3. Systematically evaluate pruning behavior during vs. after training for both MLPs and SNNs at 60-95% sparsity