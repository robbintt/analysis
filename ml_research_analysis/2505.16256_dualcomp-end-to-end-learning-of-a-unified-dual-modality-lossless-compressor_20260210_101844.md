---
ver: rpa2
title: 'DualComp: End-to-End Learning of a Unified Dual-Modality Lossless Compressor'
arxiv_id: '2505.16256'
source_url: https://arxiv.org/abs/2505.16256
tags:
- compression
- image
- text
- dualcomp
- lossless
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces DualComp, the first unified and lightweight
  dual-modality lossless compressor for image and text. It addresses the limitations
  of single-modality compressors and heavy LLM-based approaches by proposing a lightweight
  backbone with three key enhancements: modality-unified tokenization, modality-switching
  contextual learning, and modality-routing mixture-of-experts.'
---

# DualComp: End-to-End Learning of a Unified Dual-Modality Lossless Compressor

## Quick Facts
- **arXiv ID**: 2505.16256
- **Source URL**: https://arxiv.org/abs/2505.16256
- **Reference count**: 40
- **Primary result**: First unified and lightweight dual-modality lossless compressor achieving state-of-the-art compression efficiency for both images and text

## Executive Summary
DualComp introduces the first unified and lightweight dual-modality lossless compressor for image and text data. The system addresses limitations of single-modality compressors and heavy LLM-based approaches by employing a lightweight backbone with three key enhancements: modality-unified tokenization, modality-switching contextual learning, and modality-routing mixture-of-experts. A reparameterization training strategy further boosts performance without increasing complexity. DualComp achieves superior compression ratios while maintaining a small model footprint and supporting near real-time inference on desktop CPUs.

## Method Summary
DualComp employs a unified architecture that processes both image and text data through shared components while maintaining modality-specific optimizations. The system uses a lightweight backbone enhanced with three key innovations: modality-unified tokenization that converts diverse inputs into a common representation space, modality-switching contextual learning that adapts to different data patterns, and modality-routing mixture-of-experts that dynamically allocates computational resources based on input characteristics. A reparameterization training strategy enables improved performance without architectural complexity increases.

## Key Results
- Achieves 9% improvement over previous best image compressor on Kodak dataset
- Uses only 1.2% of the model size compared to competing approaches
- Supports near real-time inference at 200KB/s on desktop CPUs
- Matches or surpasses state-of-the-art methods with far fewer parameters on both image and text datasets

## Why This Works (Mechanism)
The effectiveness of DualComp stems from its unified approach to handling different data modalities while maintaining computational efficiency. The modality-unified tokenization creates a common representation space that enables shared learning across domains. The modality-switching contextual learning adapts to different statistical patterns in images versus text, while the modality-routing mixture-of-experts dynamically allocates resources based on input characteristics. The reparameterization training strategy optimizes parameter usage without architectural bloat.

## Foundational Learning

**Modality-unified tokenization** - Why needed: Enables shared processing of diverse data types through common representation. Quick check: Verify that tokenization preserves essential information for both image and text reconstruction.

**Contextual learning mechanisms** - Why needed: Captures local and global dependencies in sequential data. Quick check: Confirm that learned contexts improve compression ratios compared to non-contextual approaches.

**Mixture-of-experts routing** - Why needed: Dynamically allocates computational resources based on input complexity. Quick check: Validate that routing decisions improve efficiency without degrading compression quality.

## Architecture Onboarding

**Component map**: Input -> Modality Detection -> Tokenization -> Contextual Encoding -> MoE Routing -> Entropy Coding

**Critical path**: The sequence from tokenization through contextual encoding to MoE routing represents the core compression pipeline where most computational resources are allocated.

**Design tradeoffs**: The architecture balances between unified processing (shared components) and modality-specific optimization (dedicated routing and learning mechanisms). This creates tension between model simplicity and compression efficiency.

**Failure signatures**: Poor compression ratios on out-of-distribution data, routing inefficiencies leading to computational waste, tokenization failures causing information loss.

**Exactly 3 first experiments**:
1. Test compression performance on simple, well-structured datasets (standard images and clean text) to establish baseline functionality
2. Evaluate routing decisions on mixed-modality inputs to verify dynamic resource allocation
3. Measure compression ratios on synthetic data with known statistical properties to validate learning mechanisms

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the provided content.

## Limitations

- Generalizability to out-of-distribution data types remains untested beyond the specific datasets evaluated
- Security and privacy implications of learned compression patterns are not addressed
- Inference speed claims lack comprehensive hardware benchmarking across different CPU architectures

## Confidence

**Compression efficiency claims**: High - Well-documented quantitative results with standard evaluation metrics
**Unified dual-modality capability**: Medium - Architecture supports both modalities but broader validation needed
**Lightweight design claims**: Medium - Parameter comparisons clear but relationship to performance needs more benchmarking

## Next Checks

1. Evaluate DualComp's compression performance and rate-distortion characteristics on additional image datasets representing diverse domains (medical imaging, remote sensing, scientific visualization) and text types (programming languages, legal documents, scientific literature).

2. Conduct ablation studies specifically isolating the contributions of each proposed component (modality-unified tokenization, modality-switching contextual learning, modality-routing MoE) to quantify their individual impact on compression efficiency and model complexity.

3. Benchmark inference performance across a range of CPU architectures and specifications, including low-power mobile processors and high-performance desktop CPUs, to establish realistic deployment expectations and identify hardware constraints.