---
ver: rpa2
title: 'FuelCast: Benchmarking Tabular and Temporal Models for Ship Fuel Consumption'
arxiv_id: '2510.08217'
source_url: https://arxiv.org/abs/2510.08217
tags:
- data
- fuel
- consumption
- ship
- tabpfn
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors address the challenge of accurate ship fuel consumption
  prediction, crucial for economic and environmental optimization in maritime operations.
  They present FuelCast, a new benchmark dataset comprising operational and environmental
  data from three diverse ships, and evaluate models across tabular and time-series
  regression tasks.
---

# FuelCast: Benchmarking Tabular and Temporal Models for Ship Fuel Consumption

## Quick Facts
- **arXiv ID**: 2510.08217
- **Source URL**: https://arxiv.org/abs/2510.08217
- **Reference count**: 26
- **Primary result**: TabPFN foundation model achieves competitive fuel consumption prediction with only 500-1000 training samples, outperforming traditional ML models in data-scarce regimes.

## Executive Summary
This paper addresses the critical need for accurate ship fuel consumption prediction to optimize maritime operations economically and environmentally. The authors introduce FuelCast, a new benchmark dataset comprising operational and environmental data from three diverse ships, and evaluate models across tabular and time-series regression tasks. The study presents TabPFN, a foundation model using in-context learning, as a novel approach in this domain. Results show that models incorporating environmental conditions and temporal context consistently outperform simple baselines, with TabPFN slightly outperforming other techniques, especially with limited training data, highlighting the potential of foundation models for tabular prediction.

## Method Summary
The FuelCast dataset contains operational and environmental data from three ships (CPS Triton: 25,351 samples; CPS Poseidon: 105,422; OSS Ceto: 43,213) at 5-minute resolution. Two regression tasks are defined: Task 1 uses single-timestep features; Task 2 uses sliding windows (T=11, 1-hour context) with lagged features. Environmental data from Copernicus Marine and Open-Meteo is interpolated to 5-minute resolution and merged by timestamp and position. Models evaluated include polynomial regression baseline, CatBoost, MLP, LSTM, and TabPFN (using random 500/1000 sample contexts). Evaluation uses 5-fold temporal cross-validation with MAE and R² metrics. Directional features are transformed to vessel-relative coordinates and decomposed to sin/cos components for neural models.

## Key Results
- Models incorporating environmental features (wind, waves, currents) consistently outperform speed-only polynomial baselines.
- Adding temporal context through sliding windows improves accuracy by capturing dynamic vessel behavior and transitional patterns.
- TabPFN slightly outperforms other techniques across all vessel types, particularly excelling with limited training data (500-1000 samples).
- The benchmark establishes a standardized evaluation framework for reproducible research in maritime fuel optimization.

## Why This Works (Mechanism)

### Mechanism 1
Incorporating environmental features (wind, waves, currents) improves prediction accuracy compared to speed-only baselines because fuel consumption is governed by both vessel speed and external resistance forces. By including features like wind speed/direction, wave height/period, and ocean current velocity—transformed into the vessel's local coordinate system—models can account for these physical forces that polynomial baselines ignore. Interpolated environmental data from coarse grids sufficiently represents true conditions at each 5-minute timestamp.

### Mechanism 2
Adding temporal context through lagged features or sequence modeling captures dynamic vessel behavior (acceleration, maneuvering) that single-timestep models miss. A sliding window of T=11 observations (1 hour) provides trajectory information, enabling models to learn transitional patterns. The chosen window size is sufficient to capture relevant dynamics for fuel consumption prediction.

### Mechanism 3
TabPFN achieves competitive prediction with only 500-1000 training samples by leveraging in-context learning. Pre-trained on synthetic tabular data to approximate Bayesian inference, TabPFN conditions on provided training examples without gradient updates, using learned priors about tabular regression tasks. This enables strong performance in data-scarce regimes where traditional models have insufficient signal.

## Foundational Learning

- **Concept: Tabular vs. Time-Series Regression Tasks** - Why needed: The benchmark defines two distinct tasks requiring different feature engineering and model selection. Quick check: Can you explain why an LSTM might be more appropriate for Task 2 than Task 1?

- **Concept: In-Context Learning (Foundation Models for Tabular Data)** - Why needed: TabPFN operates without a training phase, requiring only inference-time context. Quick check: How does TabPFN's prediction process differ from CatBoost's during inference?

- **Concept: Feature Transformation for Directional Data** - Why needed: Directional features must be transformed to prevent discontinuity and align with physical effects. Quick check: Why would raw compass degrees (0-360) be problematic for an MLP, and how does sine/cosine decomposition address this?

## Architecture Onboarding

- **Component map**: Data ingestion (ship sensors + environmental data) -> Data integration (interpolation + merge) -> Preprocessing (imputation + scaling + feature transformation) -> Task-specific feature engineering (pointwise or sliding windows) -> Model layer (baseline, CatBoost, MLP, LSTM, TabPFN) -> Evaluation (temporal cross-validation with MAE/R²)

- **Critical path**: Data integration (interpolation quality) → Feature transformation (directional encoding) → Model selection (match task type) → Evaluation (temporal split prevents leakage)

- **Design tradeoffs**: Window size (T=11) captures 1-hour dynamics but may miss longer-range patterns; TabPFN sample limit (500/1000) enables data efficiency but restricts scalability; temporal cross-validation preserves structure but assumes i.i.d. across intervals

- **Failure signatures**: High variance across CV folds → regime-aware splitting needed; LSTM underperforming CatBoost with lag features → may need more tuning; TabPFN 500 < TabPFN 1000 consistently → sample selection matters

- **First 3 experiments**: 1) Baseline replication: Train polynomial regression and CatBoost on Task 1 for all vessels; verify MAE/R² match Table 3. 2) Ablation on environmental features: Remove weather/sea features; quantify MAE degradation. 3) TabPFN sample sensitivity: Test with 250, 500, 1000, 2000 samples; plot MAE vs. sample count.

## Open Questions the Paper Calls Out

- Can foundation models like TabPFN maintain their performance advantage in multi-step-ahead forecasting scenarios compared to single-step regression? (The current study is limited to current and immediate past contexts, with future work planned for k-step-ahead prediction.)

- Does optimized or diversity-based sample selection for TabPFN significantly improve performance over the simple random sampling used in the paper? (The authors note they only used simple sampling techniques due to resource constraints.)

- To what extent can models trained on steady-route vessels (cruise ships) generalize to vessels with highly variable operational profiles like offshore supply ships? (The paper establishes a benchmark for individual vessel modeling but does not explicitly test cross-vessel transfer learning.)

## Limitations
- Moderate sample size of FuelCast dataset, particularly for CPS Triton (25,351 samples), constrains model training and evaluation
- Geographic and operational scope limited to specific routes and timeframes, reducing generalizability
- TabPFN's computational constraints (O(n²) attention) necessitated restricting training contexts to 500-1000 samples, leaving performance with larger datasets untested

## Confidence
- High: Core finding that environmental features improve prediction accuracy (supported by clear quantitative comparisons and physical reasoning)
- Medium: Superiority of TabPFN with limited data (novel application with weak corpus validation but consistent experimental results)
- Medium: Temporal context benefits (mechanism plausible but limited corpus evidence for maritime-specific temporal dynamics)

## Next Checks
1. Test TabPFN with progressively larger sample sizes (up to full training sets) to characterize scalability and data efficiency curves.
2. Implement regime-aware cross-validation that accounts for operational mode heterogeneity to reduce variance in R² scores.
3. Validate environmental interpolation accuracy by comparing interpolated values against high-resolution observational data where available.