---
ver: rpa2
title: 'Clozing the Gap: Exploring Why Language Model Surprisal Outperforms Cloze
  Surprisal'
arxiv_id: '2601.09886'
source_url: https://arxiv.org/abs/2601.09886
tags:
- cloze
- surprisal
- both
- gpt2-h
- probabilities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study compares human cloze-based and LM-based predictability
  estimates for modeling reading times, finding that GPT2 surprisal generally outperforms
  cloze surprisal. Three hypotheses for this advantage are tested through targeted
  manipulations of GPT2 probabilities: resolution (sampling to match cloze response
  counts), semantic clustering (reducing fine-grained word distinctions), and frequency
  constraints (limiting probabilities to high-frequency tokens).'
---

# Clozing the Gap: Exploring Why Language Model Surprisal Outperforms Cloze Surprisal

## Quick Facts
- arXiv ID: 2601.09886
- Source URL: https://arxiv.org/abs/2601.09886
- Reference count: 40
- One-line primary result: GPT-2 surprisal generally outperforms cloze surprisal as a predictor of reading times; targeted manipulations reveal resolution, semantic granularity, and frequency coverage as key mechanisms.

## Executive Summary
This study investigates why language model (LM) surprisal predicts human reading times better than cloze-based surprisal estimates. Through systematic manipulations of GPT-2 probabilities—matching cloze resolution, clustering semantically similar words, and restricting to high-frequency tokens—the authors demonstrate that all three factors contribute to LM advantages. The findings suggest cloze studies could benefit from higher response counts and more ecologically valid designs, while also highlighting that LM advantages may stem from aspects of prediction that differ from human processes.

## Method Summary
The paper compares GPT-2 and cloze surprisal as predictors of reading times across four datasets (BK21 SPR/ET, Provo ET, UCL SPR/ET) using linear mixed-effects regression with 10-fold cross-validation. Cloze probabilities are smoothed and power-transformed (S=200), while GPT-2 includes whitespace probability. Three targeted manipulations test hypotheses: resolution matching via sampling (H1), semantic clustering via k-means on embeddings (H2), and frequency thresholding (H3). Model comparison uses Δ log-likelihood with permutation tests.

## Key Results
- GPT-2 surprisal consistently outperforms cloze surprisal in predicting reading times
- Resolution matching (sampling to match cloze response counts) significantly reduces GPT-2's advantage
- Semantic clustering (reducing fine-grained word distinctions) degrades predictive power
- Frequency constraints (limiting to high-frequency tokens) eliminate GPT-2's advantage on several measures

## Why This Works (Mechanism)

### Mechanism 1: Resolution Advantage
- Claim: LM surprisal outperforms cloze surprisal partly because LMs provide fine-grained probability distributions over the full vocabulary rather than discrete counts from limited samples.
- Mechanism: LMs compute continuous probability densities over all possible continuations via softmax over vocabulary, whereas cloze probabilities are estimated from typically <100 human responses, creating quantization artifacts and zero-probability issues.
- Core assumption: Each cloze response represents an independent sample from a subject's subjective probability distribution (Smith and Levy, 2011 view).
- Evidence anchors:
  - [abstract] "not suffering from low resolution"
  - [section 3.1] "cloze probabilities suffer from poor resolution, as they are based on counts from typically fewer than 100 responses. In contrast, LMs can estimate probabilities for any arbitrary continuation using their vector representations"
  - [corpus] No direct corpus neighbors address resolution effects on surprisal quality.
- Break condition: When GPT-2 probabilities are sampled with N samples matching cloze response counts, the predictive advantage over cloze diminishes significantly (Figure 4, H1 panels).

### Mechanism 2: Semantic Granularity
- Claim: LMs predict RTs better because they assign differentiated probabilities to semantically similar alternatives (e.g., couch vs. sofa), whereas human cloze responses may reflect shared semantic features rather than lexical distinctions.
- Mechanism: K-means clustering of token embeddings groups semantically similar words; when probability mass is redistributed to clusters rather than individual words, GPT-2's predictive power decreases.
- Core assumption: Human prediction during comprehension operates on semantic feature bundles, not just specific lexical items (Federmeier and Kutas, 1999).
- Evidence anchors:
  - [abstract] "distinguishing semantically similar words"
  - [section 3.1] "Human lexical predictions, however, are influenced by shared semantic features across possible alternatives"
  - [corpus] Neighbor paper "Surprisal and Metaphor Novelty Judgments" explores semantic processing but not this specific mechanism.
- Break condition: With k=80 semantic clusters, manipulated GPT-2 surprisal loses advantage over cloze on several measures (Figure 4, H2 panels).

### Mechanism 3: Low-Frequency Word Coverage
- Claim: LMs maintain predictive advantage because they assign calibrated probabilities to low-frequency continuations that human subjects rarely produce in cloze tasks.
- Mechanism: Vocabulary partitioned into frequent (VF) and infrequent (VI) subsets by frequency threshold; probability mass from VI redistributed to VF via renormalization.
- Core assumption: Human subjects strategically avoid low-frequency completions in cloze tasks even when contextually licensed.
- Evidence anchors:
  - [abstract] "accurately assigning probabilities to low-frequency words"
  - [section 3.1] "human subjects may not ever produce low-frequency continuations to a context. In contrast, LMs assign probabilities to arbitrary low-frequency continuations"
  - [corpus] Neighbor "Large Language Model probabilities cannot distinguish between possible and impossible language" suggests LM probability calibration has limits.
- Break condition: With frequency threshold of 10⁴ per billion, GPT-2-H3 loses predictive advantage on multiple measures (Figure 4, H3 panels).

## Foundational Learning

- Concept: Surprisal Theory
  - Why needed here: This paper's core dependent variable; surprisal (−log P(w)) quantifies processing difficulty as information content.
  - Quick check question: Why use log probability rather than raw probability for predicting reading times?

- Concept: Cloze Probability Estimation
  - Why needed here: The baseline method being compared; requires understanding of smoothing, zero-count handling, and sampling limitations.
  - Quick check question: What happens to cloze surprisal when a word never appears in the response set?

- Concept: Cross-Validated Model Comparison
  - Why needed here: Paper uses 10-fold CV with nested model comparison to assess whether one predictor subsumes another.
  - Quick check question: Why compare a model with both predictors against models with each predictor alone?

## Architecture Onboarding

- Component map:
  GPT-2 (small) → conditional probability distribution P(wt|w<sub><1:t</sub>) → Subword tokenizer + whitespace correction → word-level probabilities → Manipulation modules (Resolution sampler, Semantic clusterer, Frequency filter) → LME regression framework → Δ log-likelihood evaluation

- Critical path:
  1. Load reading time dataset with aligned cloze responses
  2. Compute GPT-2 probabilities with whitespace inclusion (P(word) includes P(leading space))
  3. Apply transformation: S(wt)² with smoothing S=200 for cloze; raw surprisal for GPT-2
  4. Fit baseline LME (length, position, unigram surprisal, fixation lag)
  5. Add surprisal predictor(s), evaluate via 10-fold CV
  6. Run permutation tests with Bonferroni correction

- Design tradeoffs:
  - Smoothing factor S=200 selected via grid search on 50% of data
  - Power transform S(wt)² outperformed linear and untransformed surprisal for cloze
  - k=80 clusters balanced granularity vs. semantic coherence
  - Frequency threshold 10⁴/billion preserved adequate vocabulary coverage

- Failure signatures:
  - Zero cloze counts → log undefined → requires add-one smoothing
  - Subword tokens without whitespace correction → P(multi-token word) ≤ P(prefix token)
  - Resolution sampling variance → results unstable across runs → use median of 5 runs
  - SA-surprisal (Experiment 3) → performed poorly, count-and-divide preferred

- First 3 experiments:
  1. Replicate Experiment 1 on one dataset (e.g., Provo FP): Compare cloze vs. GPT-2 surprisal using the LME framework with cross-validation.
  2. Implement H1 resolution matching: Sample N tokens from GPT-2 distribution matching cloze response counts, recalculate surprisal, verify predictive power drops.
  3. Implement H2 semantic clustering: Run k-means on GPT-2 embeddings with k∈{40,80,100}, redistribute probability to clusters, measure fit degradation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Are human comprehenders sensitive to the fine-grained semantic and frequency-based distinctions in word prediction that LM surprisal captures?
- Basis in paper: [explicit] "Future experiments should target whether humans' expectations differentiate between e.g. semantically related words or low-frequency words—perhaps using stimuli informed by LM probabilities."
- Why unresolved: The paper shows LM manipulations reduce fit to RTs, but cannot determine whether humans truly make such fine-grained predictions or whether LM surprisal succeeds for other reasons.
- What evidence would resolve it: Targeted experiments using stimuli designed to contrast semantically similar or low-frequency alternatives, directly measuring whether RTs reflect sensitivity to these distinctions.

### Open Question 2
- Question: Would collecting substantially more cloze responses per context close the predictive gap between cloze and LM surprisal?
- Basis in paper: [explicit] "This suggests that cloze surprisal that is based on more responses than are typically collected may be a stronger predictor of RTs."
- Why unresolved: Resolution-matched LM sampling reduced fit, but the study did not test whether high-resolution cloze collection itself would improve predictions.
- What evidence would resolve it: Large-scale cloze studies collecting hundreds or thousands of responses per context, evaluated against RT data.

### Open Question 3
- Question: Do timed or online prediction tasks yield surprisal estimates that better predict reading times than offline cloze tasks?
- Basis in paper: [explicit] "We call for methodological triangulation: In addition to the traditional cloze task, timed versions of the cloze task or a maze-like variant may help control for factors like conscious reflection."
- Why unresolved: The offline cloze task may invoke different cognitive processes than real-time prediction during reading.
- What evidence would resolve it: Comparison of surprisal derived from timed cloze or maze tasks against traditional cloze in predicting RTs.

### Open Question 4
- Question: Do the identified causes of LM advantage generalize to other language models and to non-English languages?
- Basis in paper: [explicit] "It remains to be seen whether the findings will generalize to other language models and data collected in other languages."
- Why unresolved: The study used only GPT-2 and English datasets; different LMs may have different advantages, and cross-linguistic cloze-RT datasets are unavailable.
- What evidence would resolve it: Replication with other LMs (e.g., LLaMA, GPT-3/4) and construction of aligned cloze-RT datasets in other languages.

## Limitations

- Sampling variance in H1 manipulation not quantified; results based on median of 5 runs without reported variance
- Semantic clustering granularity (k=80) not theoretically justified; relationship between granularity and effect size unexplored
- Frequency threshold (10⁴/billion) arbitrarily chosen without sensitivity analysis across different cutoffs

## Confidence

- High Confidence: GPT-2 surprisal consistently outperforms cloze surprisal across datasets
- Medium Confidence: Three hypothesized mechanisms supported but with methodological limitations
- Low Confidence: These three mechanisms are the primary drivers of LM superiority (not directly tested)

## Next Checks

1. Implement bootstrap analysis of H1 variance to quantify stability of resolution-matching effects
2. Systematically vary clustering granularity (k=20, 40, 60, 80, 100, 200) to map relationship between semantic granularity and predictive power
3. Test multiple frequency thresholds (10³, 10⁴, 10⁵, 10⁶ per billion) to assess sensitivity of H3 manipulation