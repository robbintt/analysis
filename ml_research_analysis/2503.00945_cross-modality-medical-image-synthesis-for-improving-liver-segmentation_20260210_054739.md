---
ver: rpa2
title: Cross Modality Medical Image Synthesis for Improving Liver Segmentation
arxiv_id: '2503.00945'
source_url: https://arxiv.org/abs/2503.00945
tags:
- images
- segmentation
- image
- data
- real
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving liver segmentation
  accuracy in medical imaging by addressing data scarcity through cross-modality image
  synthesis. The authors propose a two-stage approach that first uses an EssNet architecture,
  a CycleGAN-based network, to synthesize abdominal MRI images from unpaired CT images
  while simultaneously performing liver segmentation.
---

# Cross Modality Medical Image Synthesis for Improving Liver Segmentation

## Quick Facts
- arXiv ID: 2503.00945
- Source URL: https://arxiv.org/abs/2503.00945
- Reference count: 40
- Primary result: 1.17% IoU and 0.65% dice coefficient improvements over using only real MRI images

## Executive Summary
This paper addresses the challenge of improving liver segmentation accuracy in medical imaging by addressing data scarcity through cross-modality image synthesis. The authors propose a two-stage approach that first uses an EssNet architecture, a CycleGAN-based network, to synthesize abdominal MRI images from unpaired CT images while simultaneously performing liver segmentation. The generated MRI images are then combined with real MRI images to train a U-Net segmentation model. The method aims to overcome alignment and domain-specific deformation issues that commonly occur in CycleGAN-based synthesis methods.

## Method Summary
The proposed approach employs a two-stage methodology for liver segmentation. First, an EssNet architecture - a CycleGAN-based network - synthesizes abdominal MRI images from unpaired CT images while simultaneously performing liver segmentation. Second, the generated MRI images are combined with real MRI images to train a U-Net segmentation model. This approach addresses data scarcity challenges by leveraging cross-modality synthesis, specifically targeting alignment and domain-specific deformation issues common in traditional CycleGAN-based methods.

## Key Results
- 1.17% improvement in Intersection over Union (IoU) compared to using only real MRI images
- 0.65% improvement in dice coefficient compared to using only real MRI images
- Experimental validation on CHAOS dataset with 40 patients showing improved U-Net segmentation performance

## Why This Works (Mechanism)
The method leverages cross-modality image synthesis to address data scarcity in medical imaging. By generating synthetic MRI images from CT data using an EssNet architecture, the approach expands the training dataset for segmentation models. The simultaneous segmentation capability during synthesis helps maintain anatomical accuracy. Combining synthetic and real MRI images for U-Net training provides more diverse training data, potentially improving generalization and robustness of the segmentation model.

## Foundational Learning
- **Cross-modality medical image synthesis**: Converting images from one medical imaging modality (e.g., CT) to another (e.g., MRI) to leverage complementary information and address data scarcity.
  - Why needed: Different imaging modalities provide different tissue contrast and information; synthesis enables leveraging data across modalities.
  - Quick check: Can the synthesis network preserve anatomical structures while changing imaging characteristics?

- **CycleGAN-based synthesis**: Generative Adversarial Network architecture that learns to translate images between domains without requiring paired examples.
  - Why needed: Medical datasets often have unpaired images across modalities due to different acquisition protocols or patient populations.
  - Quick check: Does the cycle-consistency loss ensure that synthetic images can be mapped back to original domain?

- **Simultaneous segmentation during synthesis**: Integrating segmentation task into the image synthesis network to ensure anatomical consistency.
  - Why needed: Pure synthesis may not preserve anatomical boundaries; joint optimization ensures clinically relevant outputs.
  - Quick check: Does segmentation accuracy on synthetic images correlate with synthesis quality?

## Architecture Onboarding

Component map: CT Images -> EssNet (CycleGAN + Segmentation) -> Synthetic MRI -> Combined with Real MRI -> U-Net Segmentation

Critical path: The pipeline flows from unpaired CT images through EssNet synthesis (which includes simultaneous segmentation), then combines synthetic MRI with real MRI images to train the final U-Net segmentation model.

Design tradeoffs: The approach trades computational complexity (two-stage training) for improved segmentation performance. The EssNet architecture adds segmentation capability to CycleGAN but may require careful balancing of synthesis and segmentation objectives.

Failure signatures: Poor segmentation performance may indicate: 1) Insufficient synthesis quality, 2) Domain gap between synthetic and real MRI too large, 3) U-Net overfitting to synthetic data, or 4) EssNet not properly capturing anatomical structures during synthesis.

First experiments to run:
1. Evaluate synthetic MRI image quality using both quantitative metrics (e.g., structural similarity index) and qualitative radiologist assessment
2. Test segmentation performance using only synthetic MRI images to understand their standalone utility
3. Compare against baseline CycleGAN without simultaneous segmentation to quantify the benefit of the joint approach

## Open Questions the Paper Calls Out
None

## Limitations
- Modest absolute performance gains (1.17% IoU, 0.65% dice coefficient) may not represent clinically meaningful improvements
- Reliance on CHAOS dataset with only 40 patients raises scalability concerns
- Computational efficiency and inference time not addressed, which are critical for clinical deployment
- Limited comparison with other state-of-the-art cross-modality synthesis methods beyond basic CycleGAN

## Confidence

High Confidence:
- Experimental methodology is sound
- Use of CHAOS dataset is appropriate for this research domain

Medium Confidence:
- Reported improvements are statistically valid
- Improvements may not represent clinically meaningful gains

Low Confidence:
- Generalizability claims to other datasets and clinical settings are not sufficiently supported

## Next Checks

1. Test the approach on larger, multi-institutional datasets to assess scalability and robustness across different acquisition protocols
2. Conduct ablation studies comparing EssNet against other advanced cross-modality synthesis architectures (e.g., latent diffusion models, transformers)
3. Perform clinical validation with radiologist feedback to determine if the segmentation improvements translate to practical diagnostic value