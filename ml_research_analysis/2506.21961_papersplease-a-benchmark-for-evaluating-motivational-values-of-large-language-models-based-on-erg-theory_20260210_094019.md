---
ver: rpa2
title: 'PapersPlease: A Benchmark for Evaluating Motivational Values of Large Language
  Models Based on ERG Theory'
arxiv_id: '2506.21961'
source_url: https://arxiv.org/abs/2506.21961
tags:
- llms
- social
- scenarios
- human
- moral
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces PapersPlease, a benchmark of 3,700 role-playing\
  \ immigration scenarios to evaluate how large language models (LLMs) prioritize\
  \ human needs based on ERG theory. The scenarios embed three motivational values\u2014\
  Existence, Relatedness, and Growth\u2014along with social identity cues like gender,\
  \ race, and religion."
---

# PapersPlease: A Benchmark for Evaluating Motivational Values of Large Language Models Based on ERG Theory

## Quick Facts
- arXiv ID: 2506.21961
- Source URL: https://arxiv.org/abs/2506.21961
- Reference count: 9
- This paper introduces PapersPlease, a benchmark of 3,700 role-playing immigration scenarios to evaluate how large language models (LLMs) prioritize human needs based on ERG theory

## Executive Summary
PapersPlease introduces a benchmark of 3,700 role-playing immigration scenarios to evaluate how large language models prioritize human needs based on ERG theory. The benchmark embeds three motivational values—Existence, Relatedness, and Growth—along with social identity cues like gender, race, and religion. Six LLMs were evaluated under three settings: individual decisions, comparative prioritization, and social identity impact. Results show statistically significant differences in motivational prioritization across models, with some aligning more closely with ERG theory than others. Social identity cues influenced decisions, revealing biases against marginalized groups in certain models. The findings highlight the need for more nuanced evaluation of LLM alignment with human values and social fairness.

## Method Summary
PapersPlease presents a systematic benchmark of 3,700 role-playing immigration scenarios designed to evaluate how large language models prioritize human needs according to ERG theory. The benchmark incorporates three motivational values—Existence, Relatedness, and Growth—alongside social identity cues including gender, race, and religion. Six LLMs were evaluated across three distinct settings: individual decision-making, comparative prioritization of needs, and analysis of social identity impacts on decision outcomes. The methodology employs statistical analysis to identify significant differences in motivational prioritization across models and examines how social identity factors influence these decisions.

## Key Results
- Statistically significant differences in motivational prioritization across six evaluated LLMs
- Some models align more closely with ERG theory than others in their decision-making patterns
- Social identity cues influenced model decisions, revealing measurable biases against marginalized groups in certain LLMs

## Why This Works (Mechanism)
The benchmark leverages role-playing immigration scenarios as a controlled environment where motivational priorities can be systematically observed and measured. By embedding specific motivational values within structured decision contexts, the framework creates observable patterns that map directly to ERG theory's framework of human needs. The inclusion of social identity cues provides additional variables that reveal how models handle intersectional considerations in their reasoning processes.

## Foundational Learning

**ERG Theory**: A human motivation framework categorizing needs into Existence (basic survival), Relatedness (social connections), and Growth (personal development). Needed because it provides the theoretical foundation for evaluating whether LLMs align with human value systems.

**Social Identity Cues**: Demographic markers like gender, race, and religion embedded in scenarios. Needed to test whether models exhibit systematic biases when making decisions involving different identity groups.

**Benchmark Design**: The creation of standardized evaluation scenarios with embedded variables. Needed to enable reproducible, comparable measurements across different LLM models.

**Statistical Significance Testing**: Methods for determining whether observed differences in model behavior are meaningful rather than random variation. Needed to validate that findings represent genuine model differences rather than noise.

## Architecture Onboarding

**Component Map**: PapersPlease scenarios -> LLM input processing -> Motivational value extraction -> Statistical analysis -> Bias detection

**Critical Path**: Scenario generation and validation -> Model evaluation across three settings -> Statistical analysis of motivational prioritization -> Social identity bias assessment

**Design Tradeoffs**: Controlled scenarios enable systematic evaluation but may not capture real-world complexity; focus on ERG theory provides theoretical grounding but limits scope to specific motivational frameworks

**Failure Signatures**: Models that show inconsistent prioritization across similar scenarios, extreme bias against specific identity groups, or complete failure to recognize embedded motivational values

**First Experiments**:
1. Run baseline evaluation with simple motivational scenarios to verify model understanding of ERG categories
2. Test cross-model consistency by evaluating the same scenarios across all six LLMs
3. Conduct sensitivity analysis by varying the prominence of social identity cues to assess their impact on decision outcomes

## Open Questions the Paper Calls Out
None

## Limitations
- Focus on specific motivational values from ERG theory may not capture the full complexity of human decision-making
- Use of simulated scenarios may not fully represent real-world complexity and nuance
- English-language scenarios limit generalizability across linguistic and cultural contexts

## Confidence
High: Core findings about motivational prioritization differences across LLMs
Medium: Social identity bias findings
Low-Medium: Broader implications for LLM alignment and value representation

## Next Checks
1. Validate results across additional motivational frameworks beyond ERG theory to assess generalizability
2. Test benchmark scenarios with multilingual LLMs and cross-cultural validation to examine linguistic and cultural dependencies
3. Conduct real-world scenario testing or expert evaluation of scenario realism to assess external validity of the simulated contexts