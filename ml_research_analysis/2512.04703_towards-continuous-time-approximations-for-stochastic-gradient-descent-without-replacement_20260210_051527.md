---
ver: rpa2
title: Towards Continuous-Time Approximations for Stochastic Gradient Descent without
  Replacement
arxiv_id: '2512.04703'
source_url: https://arxiv.org/abs/2512.04703
tags:
- brownian
- then
- sgdo
- have
- stochastic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a continuous-time approximation to stochastic
  gradient descent without replacement (SGDo) using Young differential equations driven
  by epoched Brownian motions. The method models the SGDo dynamics as a stochastic
  differential equation with additive noise, where the driving process reflects the
  finite-data reuse pattern of SGDo.
---

# Towards Continuous-Time Approximations for Stochastic Gradient Descent without Replacement
## Quick Facts
- arXiv ID: 2512.04703
- Source URL: https://arxiv.org/abs/2512.04703
- Reference count: 5
- Introduces continuous-time approximation for SGDo using epoched Brownian motions

## Executive Summary
This paper presents a novel continuous-time approximation framework for stochastic gradient descent without replacement (SGDo) using Young differential equations driven by epoched Brownian motions. The approach generalizes previous work by capturing both single shuffle and random reshuffling schemes within a unified stochastic differential equation framework. For strongly convex objectives with H"older continuous Hessians, the authors establish almost sure convergence of the approximation under specific learning rate schedules.

The theoretical contributions include proving convergence for previously excluded learning rate exponents and providing improved asymptotic convergence bounds for the random reshuffling setting. The methodology employs Young-Loeve inequalities rather than traditional martingale techniques, enabling the analysis of cases where β ∈ (0,1/2] in the learning rate schedule. While the theoretical framework is rigorous, the paper acknowledges limitations regarding practical applicability to modern non-convex deep learning problems.

## Method Summary
The paper introduces a continuous-time approximation for SGDo using Young differential equations driven by epoched Brownian motions. The epoched Brownian motion captures the finite-data reuse pattern inherent in SGDo, generalizing both single shuffle and random reshuffling schemes. The driving process reflects the stochastic nature of data permutation strategies, while the differential equation models the evolution of the parameter updates. For strongly convex objectives with H"older continuous Hessians, the authors establish convergence guarantees using Young-Loeve inequalities, which handle the rougher sample paths compared to traditional Itô calculus.

The key innovation lies in the use of epoched Brownian motion as the driving noise process, which accounts for the epoch structure of SGDo where data points are reused after a complete pass through the dataset. This approach enables the derivation of almost sure convergence results for learning rate schedules of the form u_t = 1/(1+t)^β with β ∈ (0,1), including the previously excluded range β ∈ (0,1/2].

## Key Results
- Proves almost sure convergence of SGDo approximation for β ∈ (0,1) learning rate schedules, including previously excluded β ∈ (0,1/2] range
- Establishes improved asymptotic convergence bounds for random reshuffling compared to previous work
- Matches existing single shuffle convergence results while generalizing to broader data permutation strategies

## Why This Works (Mechanism)
The epoched Brownian motion driving process captures the essential stochastic structure of SGDo by reflecting the finite-data reuse pattern where each data point is used exactly once per epoch before reshuffling. The Young differential equation framework handles the rougher sample paths generated by this process through Young-Loeve inequalities, which provide bounds on the solution's regularity without requiring the smoothness assumptions of Itô calculus. This enables convergence analysis for learning rates that decay more slowly (β ∈ (0,1/2]) than previously possible with martingale-based approaches.

The additive noise structure in the stochastic differential equation naturally models the variance reduction effect of without-replacement sampling compared to with-replacement sampling. The strongly convex objective with H"older continuous Hessian ensures sufficient regularity for the convergence analysis while remaining general enough to capture many practical optimization problems.

## Foundational Learning
- **Epoched Brownian motion**: A generalization of standard Brownian motion that captures the epoch structure of SGDo where data is reused in blocks. Needed to model the finite-data reuse pattern without requiring continuous-time analogues of discrete permutation schemes. Quick check: Verify the covariance structure matches the correlation decay within and across epochs.

- **Young differential equations**: Stochastic differential equations driven by processes with finite p-variation for p < 2, handled through Young integrals rather than Itô integrals. Required because epoched Brownian motion has finite 2-variation rather than finite quadratic variation. Quick check: Confirm the driving process satisfies the required regularity conditions for Young integration.

- **H"older continuous Hessians**: Functions where the Hessian satisfies |H(x) - H(y)| ≤ C|x-y|^α for some α ∈ (0,1]. Ensures sufficient smoothness for the convergence analysis while being weaker than Lipschitz continuity. Needed to balance regularity requirements with practical applicability. Quick check: Verify the objective function's Hessian satisfies the H"older condition on the relevant domain.

## Architecture Onboarding
Component map: Objective function -> Gradient computation -> Epoched Brownian motion generator -> Young differential equation solver -> Parameter updates

Critical path: The driving process (epoched Brownian motion) -> Young integral formulation -> Convergence analysis via Young-Loeve inequalities

Design tradeoffs: The use of Young-Loeve inequalities instead of martingale techniques enables analysis of slower-decaying learning rates (β ∈ (0,1/2]) but requires H"older continuity assumptions that may be restrictive. The epoched Brownian motion provides a unified framework for different permutation strategies but may not capture all possible data ordering effects.

Failure signatures: Convergence guarantees break down if the learning rate decays too quickly (β ≤ 0) or too slowly (β ≥ 1), if the objective lacks strong convexity, or if the Hessian fails to be H"older continuous. The approximation may become inaccurate for non-convex objectives or when the epoch length is very small relative to the dataset size.

First experiments:
1. Verify the epoched Brownian motion generator correctly implements the correlation structure for different permutation schemes
2. Test the Young differential equation solver on benchmark problems with known solutions to validate numerical implementation
3. Compare the continuous-time approximation predictions against actual SGDo trajectories on simple quadratic objectives

## Open Questions the Paper Calls Out
None

## Limitations
- The H"older continuity assumption on Hessians may not hold for many modern deep learning objectives which are often non-convex and non-smooth
- No empirical validation is provided to demonstrate practical advantages over existing SGDo methods
- The theoretical framework focuses exclusively on strongly convex objectives, limiting applicability to modern non-convex optimization problems

## Confidence
- Theoretical convergence proof for strongly convex objectives: **High**
- Improvement over previous random reshuffling bounds: **Medium** (depends on comparison methodology)
- Practical relevance for modern machine learning: **Low**

## Next Checks
1. Conduct empirical validation comparing the continuous-time approximation predictions against actual SGDo trajectories on standard benchmark datasets
2. Extend analysis to non-convex objective functions common in deep learning to assess the broader applicability of the theoretical framework
3. Perform sensitivity analysis on the H"older continuity assumption to understand its impact on convergence guarantees in practice