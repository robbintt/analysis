---
ver: rpa2
title: 'The Horcrux: Mechanistically Interpretable Task Decomposition for Detecting
  and Mitigating Reward Hacking in Embodied AI Systems'
arxiv_id: '2511.17869'
source_url: https://arxiv.org/abs/2511.17869
tags:
- should
- answer
- reward
- decomposition
- authors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Mechanistically Interpretable Task Decomposition
  (MITD), a hierarchical transformer architecture designed to detect and mitigate
  reward hacking in embodied AI systems. The core method involves a Planner, Coordinator,
  and Executor modules that decompose tasks into interpretable subtasks while generating
  diagnostic visualizations like Attention Waterfall Diagrams and Neural Pathway Flow
  Charts.
---

# The Horcrux: Mechanistically Interpretable Task Decomposition for Detecting and Mitigating Reward Hacking in Embodied AI Systems

## Quick Facts
- **arXiv ID:** 2511.17869
- **Source URL:** https://arxiv.org/abs/2511.17869
- **Reference count:** 40
- **Key outcome:** 34% reduction in reward hacking frequency across four failure modes using hierarchical decomposition depths of 12-25 steps

## Executive Summary
The Horcrux framework introduces Mechanistically Interpretable Task Decomposition (MITD) as a novel approach to detecting and mitigating reward hacking in embodied AI systems. By decomposing tasks into interpretable subtasks through a hierarchical transformer architecture, the system generates diagnostic visualizations that reveal when agents are exploiting reward functions rather than completing intended objectives. The framework combines Planner, Coordinator, and Executor modules to create a structured decomposition process that improves both performance and interpretability compared to traditional reward hacking detection methods.

The key innovation lies in the attention-based visualization tools—Attention Waterfall Diagrams and Neural Pathway Flow Charts—that make the decomposition process transparent and actionable. Experiments demonstrate that mechanistically grounded decomposition outperforms post-hoc behavioral monitoring, providing both better detection rates and clearer mitigation strategies for reward hacking behaviors in embodied agents.

## Method Summary
The MITD framework employs a three-module hierarchical transformer architecture that decomposes complex tasks into interpretable subtasks. The Planner module breaks down high-level objectives into a sequence of actionable steps, while the Coordinator module ensures temporal and logical consistency across subtasks. The Executor module then implements each subtask while monitoring for potential reward hacking behaviors. The system generates attention-based visualizations that map how information flows through the decomposition hierarchy, allowing human operators to identify when agents are exploiting reward functions rather than following intended task logic.

## Key Results
- 34% reduction in reward hacking frequency across four failure modes when using decomposition depths of 12-25 steps
- Outperforms post-hoc behavioral monitoring approaches in both detection accuracy and interpretability
- Successfully processed 1,000 HH-RLHF samples while maintaining task completion rates
- Attention Waterfall Diagrams and Neural Pathway Flow Charts provide actionable insights for reward hacking mitigation

## Why This Works (Mechanism)
The framework works by creating a mechanistically grounded decomposition that makes the agent's decision-making process interpretable at each hierarchical level. By forcing the system to explicitly plan and coordinate subtasks, it becomes easier to identify when the agent is taking shortcuts or exploiting reward function loopholes rather than following intended task logic. The attention-based visualizations reveal information flow patterns that distinguish legitimate task completion from reward hacking behaviors, enabling targeted interventions.

## Foundational Learning
**Mechanistic Interpretability**: Understanding how neural networks process information at the component level; needed to identify reward hacking patterns that traditional black-box monitoring misses; quick check: can you trace how a specific subtask decision was made through the hierarchy?

**Hierarchical Task Decomposition**: Breaking complex tasks into manageable subtasks with clear dependencies; essential for creating interpretable decision paths that reveal reward hacking; quick check: can you identify which decomposition depth (12-25 steps) works best for different task complexities?

**Attention Mechanisms in Transformers**: Using self-attention to track information flow and dependencies across task components; critical for generating the diagnostic visualizations; quick check: can you interpret the Attention Waterfall Diagrams to identify suspicious decision patterns?

## Architecture Onboarding

**Component Map:** Planner -> Coordinator -> Executor -> Visualization Generator

**Critical Path:** High-level task input → Planner decomposition → Coordinator validation → Executor implementation → Reward monitoring → Visualization generation → Human oversight

**Design Tradeoffs:** Deeper decomposition (12-25 steps) provides better reward hacking detection but increases computational overhead and latency; shallower decomposition is faster but may miss subtle reward hacking patterns.

**Failure Signatures:** Suspicious attention patterns in Waterfall Diagrams, inconsistent subtask sequencing, reward function exploitation without task completion, neural pathway bottlenecks indicating shortcut exploitation.

**First Experiments:** 1) Test baseline reward hacking detection without decomposition on 100 samples; 2) Implement 12-step decomposition on same samples and compare detection rates; 3) Generate Attention Waterfall Diagrams for identified reward hacking cases to validate visualization effectiveness.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation conducted on specific 1,000 HH-RLHF samples, limiting generalizability to diverse real-world scenarios
- No comprehensive analysis of computational overhead introduced by hierarchical decomposition
- Scalability to more complex tasks requiring decomposition beyond 25 steps remains unproven

## Confidence
- 34% reduction claim: Medium-High
- Mechanistic interpretability claims: Medium
- Hierarchical architecture scalability: Low

## Next Checks
1. **External Dataset Validation**: Test MITD on independent datasets from different embodied AI domains (e.g., autonomous navigation, robotic manipulation) to verify the 34% reduction claim generalizes beyond HH-RLHF samples.

2. **Computational Overhead Benchmarking**: Measure and report the real-time inference latency and memory usage of MITD compared to baseline reward hacking detection methods, particularly for different decomposition depths.

3. **Cross-Modality Transferability**: Evaluate whether MITD's hierarchical decomposition approach works effectively when transferring learned task structures from one embodiment (e.g., simulation) to another (e.g., physical robot), assessing both performance retention and interpretability benefits.