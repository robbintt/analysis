---
ver: rpa2
title: 'Diffusion with a Linguistic Compass: Steering the Generation of Clinically
  Plausible Future sMRI Representations for Early MCI Conversion Prediction'
arxiv_id: '2506.05428'
source_url: https://arxiv.org/abs/2506.05428
tags:
- smri
- data
- longitudinal
- feature
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MCI-Diff is a diffusion-based framework that synthesizes future
  sMRI representations from baseline scans to improve early MCI conversion prediction.
  It uses multi-task sequence reconstruction training to handle irregular sampling
  and LLM-driven clinical plausibility sampling to guide generation toward realistic
  disease patterns.
---

# Diffusion with a Linguistic Compass: Steering the Generation of Clinically Plausible Future sMRI Representations for Early MCI Conversion Prediction

## Quick Facts
- arXiv ID: 2506.05428
- Source URL: https://arxiv.org/abs/2506.05428
- Reference count: 32
- Primary result: Improves early MCI conversion prediction by 5-12% using LLM-guided diffusion for generating future sMRI representations

## Executive Summary
MCI-Diff is a diffusion-based framework that synthesizes future structural MRI (sMRI) representations from baseline scans to improve early conversion prediction of mild cognitive impairment (MCI) patients into progressive MCI (pMCI) versus stable MCI (sMCI). The method combines multi-task sequence reconstruction training to handle irregular sampling with LLM-driven clinical plausibility sampling to guide generation toward realistic disease patterns. Evaluated on ADNI and AIBL datasets, MCI-Diff demonstrates state-of-the-art performance with 5-12% accuracy improvements over existing baselines.

## Method Summary
The framework uses a conditional denoising diffusion probabilistic model (DDPM) that takes baseline sMRI features and generates future representations autoregressively. A shared denoiser network is trained on both interpolation (reconstructing intermediate timepoints) and extrapolation (predicting future timepoints) tasks using a progressive difficulty schedule that gradually increases the number of masked positions. At each generation step, the model produces N candidate future features, which are quantized, tokenized, and scored by an instruction-tuned LLM that predicts FreeSurfer measurements. The most clinically plausible candidate is selected based on alignment with expected structural biomarkers, then fed to a classifier for final pMCI/sMCI prediction.

## Key Results
- Achieves 5-12% improvement in early MCI conversion prediction accuracy over state-of-the-art baselines
- Multi-task training with progressive difficulty shows monotonic improvement, peaking at difficulty level d=4
- LLM guidance reduces autoregressive error accumulation, with ablation showing accuracy drops from 0.950 to 0.870 when removed
- Candidate set size N≈20 and diffusion steps T≈40 provide optimal trade-off between quality and computational cost

## Why This Works (Mechanism)

### Mechanism 1: Multi-Task Sequence Reconstruction Training for Irregular Sampling
- Claim: Training a shared denoiser on both interpolation and extrapolation tasks enables robust handling of irregularly-sampled longitudinal data.
- Mechanism: The denoiser receives masked sequences with positional embeddings and mask indicators, learning to reconstruct missing intermediate points (interpolation) and future points (extrapolation) using the same conditional diffusion process. A progressive difficulty schedule gradually increases the number of masked positions during training.
- Core assumption: The temporal evolution of sMRI features follows learnable trajectories that can be approximated from incomplete sequences.
- Evidence anchors:
  - [abstract] "a multi-task sequence reconstruction strategy trains a shared denoising network on interpolation and extrapolation tasks to handle irregular follow-up sampling and learn robust latent trajectories"
  - [section 3.1.4] "the training starts with complete sequences and gradually incorporates incomplete sequences by imputing missing data using the model itself"
  - [corpus] Related work on trajectory generation (RareGraph-Synth) similarly uses diffusion for irregular medical trajectories, suggesting the approach has precedent but in different domains.
- Break condition: If interpolation/extrapolation ablations show no performance difference, the multi-task claim weakens. Table 3 shows removing Extrapolation Task drops ACC from 0.950 to 0.838 on ADNI, confirming contribution.

### Mechanism 2: LLM-Driven Clinical Plausibility Sampling as Error Correction
- Claim: An LLM fine-tuned to predict structural biomarkers from tokenized features can identify and select clinically plausible candidates, mitigating autoregressive error accumulation.
- Mechanism: At each generation step, the diffusion model proposes N candidates. These are quantized, tokenized, and scored by an instruction-tuned LLM that predicts FreeSurfer measurements (hippocampus volume, cortical thickness, ventricle size). The candidate with biomarkers most consistent with expected MCI progression is selected.
- Core assumption: The LLM's learned mapping from features to biomarkers captures clinically meaningful patterns that correlate with real disease trajectories.
- Evidence anchors:
  - [abstract] "generated feature candidates are quantized, tokenized, and scored by a fine-tuned language model conditioned on expected structural biomarkers"
  - [section 3.2.2] "The candidate with the most clinically plausible measurements (compared to expected values) is selected"
  - [section 4.3] Ablation shows removing LLM-Guidance drops ACC from 0.950 to 0.870 on ADNI
  - [corpus] Weak direct evidence for LLM-as-plausibility-filter in medical imaging; this appears novel. COMPASS paper uses attention steering but for hallucination mitigation in text, not trajectory generation.
- Break condition: If LLM guidance fails on datasets with different biomarker distributions (e.g., non-AD neurodegeneration), domain-specific fine-tuning may be required.

### Mechanism 3: Progressive Training Difficulty for Robust Extrapolation
- Claim: Training with curriculum-style increasing difficulty (masking more positions) improves final autoregressive generation quality.
- Mechanism: Start with complete sequences, then progressively mask more intermediate and final points. At maximum difficulty (d=4), the model predicts future features conditioned only on baseline—mirroring inference conditions.
- Core assumption: Gradual exposure to harder reconstruction tasks transfers to better few-condition extrapolation.
- Evidence anchors:
  - [section 3.1.4] "At the maximum difficulty level (d = Dmax)... the model predicts the subsequent sMRI feature conditioned solely on the baseline... mirroring the initial step of autoregressive generation"
  - [section 4.4, Fig 4b] Accuracy peaks at d=4, with lower performance at easier difficulty levels
  - [corpus] No direct corpus evidence for progressive difficulty in medical trajectory diffusion.
- Break condition: If performance degrades at higher difficulty (overfitting to hard examples), the curriculum claim fails. The paper shows monotonic improvement to d=4.

## Foundational Learning

- Concept: Conditional Denoising Diffusion Probabilistic Models (DDPMs)
  - Why needed here: The core generator is a conditional DDPM; understanding forward/reverse processes, noise schedules, and conditioning is essential for debugging generation quality.
  - Quick check question: Can you explain how the denoiser conditions on both the masked sequence C and the target positional embedding Ti during the reverse process?

- Concept: Autoregressive Error Accumulation in Sequential Generation
  - Why needed here: The LLM guidance is explicitly motivated by error compounding in autoregressive diffusion; understanding this failure mode clarifies why the "linguistic compass" matters.
  - Quick check question: Why does generating τ=2 conditioned on τ=1 (which itself may be imperfect) create different failure modes than generating τ=2 conditioned on ground-truth τ=1?

- Concept: Instruction Tuning / Feature-to-Text Adaptation for LLMs
  - Why needed here: The LLM is not used off-the-shelf; it's fine-tuned to map tokenized sMRI features to FreeSurfer measurements. Understanding quantization, tokenization, and instruction formatting is critical for reproducing this component.
  - Quick check question: What information is lost when continuous sMRI features are quantized and tokenized, and how might this affect the LLM's scoring ability?

## Architecture Onboarding

- Component map:
  - **Pretrained Feature Extractor** (HFCN) -> **Conditional Denoiser** -> **Quantizer/Tokenizer** -> **Instruction-Tuned LLM** -> **Candidate Selector** -> **Classifier**
  - **Positional/Mask Embeddings** connect Feature Extractor to Denoiser
  - **FreeSurfer Measurements** connect Quantizer to LLM training

- Critical path:
  1. Extract baseline sMRI features via HFCN
  2. For each future timepoint τ (autoregressively):
     - Generate N candidate features using diffusion reverse process
     - Tokenize each candidate
     - LLM predicts biomarkers and scores plausibility
     - Select highest-scoring candidate
  3. Feed [baseline, generated future features] to classifier for pMCI/sMCI prediction

- Design tradeoffs:
  - **Candidate set size N**: Larger N improves selection but increases inference cost (Fig 4c shows gains plateau around N=20)
  - **Diffusion steps T**: More steps improve quality with diminishing returns (Fig 4a shows T≈40 is sufficient)
  - **Feature vs. pixel generation**: Paper generates low-dimensional features (not raw images), trading spatial detail for computational tractability
  - **LLM size vs. latency**: Not specified in paper; larger LLMs may score better but slow clinical deployment

- Failure signatures:
  - **Drift in autoregressive generation**: Without LLM guidance, generated features diverge from real distribution over multiple steps (Fig 5 visualizes this)
  - **Posterior collapse on sparse sequences**: If too many positions are masked early in training, the model may fail to learn meaningful trajectories
  - **LLM-tokenizer mismatch**: If quantization bins don't align with clinically meaningful biomarker ranges, LLM scores may be uninformative

- First 3 experiments:
  1. **Interpolation sanity check**: Train denoiser on complete sequences only; verify it can reconstruct masked intermediate points before attempting extrapolation.
  2. **LLM scoring validation**: Generate N candidates for a held-out test set with ground-truth future scans; verify LLM plausibility scores correlate with actual distance to ground-truth features.
  3. **Ablation of progressive difficulty**: Train with fixed difficulty (d=1) vs. progressive (d=1→4); compare final autoregressive generation quality on sequences requiring 4-step extrapolation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the LLM's clinical plausibility scoring inadvertently filter out rare but valid MCI progression trajectories that deviate from "expected" biomarker patterns?
- Basis in paper: [inferred] The LLM scoring mechanism (Section 3.2.2) selects candidates based on alignment with expected structural biomarkers, but the paper does not analyze sensitivity to atypical converters or rare progression subtypes.
- Why unresolved: No analysis of whether plausibility scoring disproportionately rejects valid outlier trajectories.
- What evidence would resolve it: Stratified evaluation of prediction accuracy on clinically identified atypical progressors; comparison of rejected vs. selected candidate distributions against ground-truth trajectories.

### Open Question 2
- Question: How robust is the LLM-guided sampling to errors or biases in the FreeSurfer ground-truth measurements used for instruction tuning?
- Basis in paper: [inferred] Section 3.2.1 describes instruction tuning using FreeSurfer measurements as clinical ground truth, assuming these measurements are themselves accurate and complete clinical indicators.
- Why unresolved: FreeSurfer has known measurement variability; the paper does not examine sensitivity to noise or systematic bias in the tuning data.
- What evidence would resolve it: Robustness experiments with synthetic noise added to FreeSurfer labels; correlation analysis between FreeSurfer uncertainty and prediction degradation.

### Open Question 3
- Question: How well does MCI-Diff generalize to clinical populations with demographic distributions, MRI protocols, or scanner hardware substantially different from ADNI and AIBL?
- Basis in paper: [inferred] All experiments use ADNI-1/ADNI-2 and AIBL (Section 4.1), which have controlled protocols and specific demographics (Table 1); external validation on diverse real-world cohorts is not performed.
- Why unresolved: The method's dependence on these specific datasets leaves generalization uncertain.
- What evidence would resolve it: Evaluation on independent datasets with different scanner manufacturers, field strengths, or population demographics (e.g., non-Western cohorts).

### Open Question 4
- Question: Does error compounding remain a limiting factor for prediction horizons significantly longer than the 36-month window tested?
- Basis in paper: [explicit] The paper identifies error compounding in autoregressive generation as a key challenge (Section 1) and introduces LLM guidance to mitigate it, but experiments are limited to the standard T = {0, 6, 12, 18, 24, 36} month schedule.
- Why unresolved: Performance degradation at extended horizons (>36 months) is not characterized.
- What evidence would resolve it: Experiments extending prediction windows to 48, 60, or 72 months with analysis of trajectory divergence from ground truth.

## Limitations
- The LLM's clinical plausibility scoring may filter out rare but valid MCI progression trajectories that deviate from expected biomarker patterns
- Computational intensity during inference with N=20 candidates and T=40 diffusion steps creates potential deployment barriers
- Domain-specific fine-tuning requirements for LLM guidance create uncertainty about generalization to non-AD neurodegenerative conditions

## Confidence
- **High Confidence**: Multi-task sequence reconstruction training's contribution is well-supported with clear ablation results (ACC drops from 0.950 to 0.838 without extrapolation)
- **Medium Confidence**: LLM-driven clinical plausibility sampling has moderate support (ACC drops from 0.950 to 0.870 when removed), though novelty limits direct comparisons
- **Low Confidence**: Generalization claims to diverse neurodegenerative diseases remain speculative without cross-condition validation data

## Next Checks
1. **Cross-Disease Validation**: Apply MCI-Diff to sMRI datasets from frontotemporal dementia and vascular cognitive impairment patients to assess whether the LLM-guided plausibility scoring generalizes beyond AD-specific biomarker patterns.
2. **Inference Efficiency Analysis**: Measure actual inference latency with varying candidate set sizes (N=10, 20, 30) and diffusion steps (T=20, 40, 60) on clinical-grade hardware to determine practical deployment thresholds.
3. **Plausibility Scoring Calibration**: Evaluate whether LLM-predicted FreeSurfer measurements correlate with actual biomarker progression rates across different MCI conversion trajectories, and whether scoring thresholds need adjustment for heterogeneous patient populations.