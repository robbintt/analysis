---
ver: rpa2
title: 'Multi-task Federated Learning with Encoder-Decoder Structure: Enabling Collaborative
  Learning Across Different Tasks'
arxiv_id: '2504.09800'
source_url: https://arxiv.org/abs/2504.09800
tags:
- tasks
- task
- learning
- encoder
- clients
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of enabling federated learning
  (FL) among clients with heterogeneous model structures and different tasks. Traditional
  FL requires all clients to perform the same task with identical model structures,
  limiting its applicability.
---

# Multi-task Federated Learning with Encoder-Decoder Structure: Enabling Collaborative Learning Across Different Tasks

## Quick Facts
- arXiv ID: 2504.09800
- Source URL: https://arxiv.org/abs/2504.09800
- Reference count: 40
- Key outcome: M-Fed achieves average improvements of 16.09% and 8.73% on MS COCO using ResNet-50 and ResNet-101 encoders respectively, compared to local training

## Executive Summary
This paper addresses the challenge of enabling federated learning (FL) among clients with heterogeneous model structures and different tasks. Traditional FL requires all clients to perform the same task with identical model structures, limiting its applicability. The proposed Multi-task Federated Learning with Encoder-Decoder Structure (M-Fed) method leverages the common encoder-decoder architecture in current models to achieve cross-task knowledge sharing. M-Fed allows clients to maintain task-specific decoders while sharing a unified encoder structure. The method uses a regularization term to minimize the distance between local and global encoder models, enabling effective knowledge transfer without replacing the local encoder. Experiments on PASCAL Context and MS COCO datasets demonstrate significant performance improvements compared to local training and traditional FL methods.

## Method Summary
The M-Fed method decomposes the aggregation process into two tiers: intra-task aggregation (traditional FL within same-task clients) and inter-task aggregation (encoder-only across all tasks). Each client maintains a task-specific decoder and a local encoder that shares the same architecture as the global encoder. During training, clients minimize a regularized loss function that includes both task-specific loss and L2 distance to the global encoder. The server aggregates decoder parameters within each task group to form task-global models, then extracts and aggregates encoder components from all task-global models to form the global encoder. This framework enables cross-task knowledge transfer while preserving task-specific performance.

## Key Results
- M-Fed achieves average improvements of 16.09% and 8.73% on MS COCO using ResNet-50 and ResNet-101 encoders respectively, compared to local training
- The method demonstrates consistent improvements across multiple task pairs on both PASCAL Context and MS COCO datasets
- M-Fed outperforms traditional FL methods that only aggregate same-task clients, showing the value of cross-task encoder knowledge transfer
- Instance segmentation showed slight degradation (-3.78%) when paired with certain tasks, highlighting the importance of task correlation for positive transfer

## Why This Works (Mechanism)

### Mechanism 1: Unified Encoder as Cross-Task Knowledge Bridge
- Claim: Clients with different tasks can share general feature extraction knowledge through a shared encoder architecture while maintaining task-specific decoders
- Mechanism: The encoder learns general visual representations (edges, textures, shapes) that transfer across vision tasks. By constraining all clients to use the same encoder architecture, their encoder parameters become directly comparable and aggregatable. The server aggregates encoder parameters across all tasks using standard FL aggregation (FedAvg-style), while decoders remain task-isolated
- Core assumption: Encoders trained on related vision tasks learn transferable low-level and mid-level features; the decoder, not the encoder, is the primary source of task-specific behavior
- Evidence anchors: [Abstract] "we leverage this structure to share intra-task knowledge through traditional federated learning methods and extract general knowledge from the encoder to achieve cross-task knowledge sharing"

### Mechanism 2: Soft Encoder Alignment via Regularization
- Claim: Aligning local encoders toward the global encoder through a regularization term enables knowledge transfer without catastrophically overwriting local task knowledge
- Mechanism: The local loss function is augmented: `h(xi, yi; wi) = Li(xi, yi; wi) + λ∥w*i - g∥²`. Rather than directly replacing the local encoder with the global encoder, the regularization term creates a soft constraint that pulls the encoder toward the global representation while the primary task loss maintains task-specific fine-tuning
- Core assumption: The optimal local encoder lies in a region that can simultaneously minimize task-specific loss and remain close to the global encoder; gradient descent can find this region
- Evidence anchors: [Abstract] "The method uses a regularization term to minimize the distance between local and global encoder models, enabling effective knowledge transfer without replacing the local encoder"

### Mechanism 3: Two-Tier Aggregation with Task and Global Models
- Claim: Decomposing aggregation into intra-task (traditional FL within same-task clients) and inter-task (encoder-only across all tasks) enables heterogeneous collaboration
- Mechanism: (1) Server receives all client models; (2) models performing the same task are aggregated to form task-global models `Fk(w)`; (3) encoder components are extracted from each task-global model and aggregated to form the global encoder `g = A(F*1(w*), F*2(w*), ..., F*|K|(w*))`; (4) server distributes both the task-global model and the global encoder to appropriate clients
- Core assumption: Tasks have sufficient client participation for meaningful intra-task aggregation; the aggregation function A is compatible across same-structure components
- Evidence anchors: [Section 3.2, Eq. 3-4] Shows the two-stage aggregation process mathematically

## Foundational Learning

- **Federated Averaging (FedAvg)**
  - Why needed here: M-Fed extends FedAvg by applying it separately to task-global models and the global encoder. Understanding how parameter aggregation works (weighted averaging based on client data size) is essential to follow the two-tier aggregation logic
  - Quick check question: Can you explain why FedAvg weights client models by their local dataset size during aggregation?

- **Encoder-Decoder Architecture Semantics**
  - Why needed here: The entire method hinges on the assumption that encoders capture general features while decoders are task-specific. Without this conceptual separation, the rationale for aggregating only encoders across tasks would be unclear
  - Quick check question: In a CNN-based segmentation model, which layers would typically be in the encoder vs. the decoder, and what type of features does each learn?

- **L2 Regularization as Soft Constraint**
  - Why needed here: The core innovation uses L2 distance to the global encoder as a regularizer. Understanding how regularization terms in loss functions create soft constraints (vs. hard parameter replacement) is critical to grasp why this avoids catastrophic forgetting
  - Quick check question: How does adding λ∥θ - θ_target∥² to a loss function affect gradient updates during training?

## Architecture Onboarding

- **Component map:**
  - Server -> K task-global models (one per task type) and one global encoder model
  - Server -> Aggregates decoder parameters within each task group
  - Server -> Extracts and aggregates encoder components from all task-global models
  - Server -> Distributes task-global models (to same-task clients) and global encoder (to all clients)
  - Client i (performing task k) -> Maintains local encoder (structure fixed by server) + task-specific decoder
  - Client i -> Trains on local data with regularized objective
  - Client i -> Uploads both encoder and decoder to server

- **Critical path:**
  1. Server initializes and distributes encoder architecture specification to all clients
  2. Client trains locally for m rounds: `wt+1 = wt - α∇F(wt) + λ∥wt,* - g∥²`
  3. Client uploads encoder parameters + decoder parameters to server
  4. Server aggregates decoders within each task group → K task-global models
  5. Server extracts encoder from each task-global model and aggregates → global encoder g
  6. Server distributes task-global models (to same-task clients) and global encoder (to all clients)
  7. Repeat from step 2 for T total aggregation rounds

- **Design tradeoffs:**
  - Encoder architecture choice: Larger encoders (ResNet-101) capture more transferable knowledge but increase communication cost; paper shows ResNet-101 gave smaller relative gains (+8.73%) vs. ResNet-50 (+16.09%), possibly due to data distribution issues
  - λ scheduling strategy: Paper uses exponentially increasing λ; too aggressive early λ harms convergence, too conservative late λ underutilizes cross-task knowledge
  - Local training rounds (m): More local rounds reduce communication but risk local model divergence from global encoder; paper uses m=5 for PASCAL-Context, m=1 for MS COCO

- **Failure signatures:**
  - Negative transfer: If tasks are unrelated (e.g., image segmentation vs. text classification), encoder aggregation may introduce noise; observed in instance segmentation showing -3.78% vs. traditional FL
  - Non-IID data degradation: If client data distributions are highly skewed, both intra-task and inter-task aggregation suffer; observed in panoptic segmentation where FL and M-Fed both underperformed local training
  - Encoder structure mismatch: If clients cannot adopt the unified encoder (e.g., vastly different input modalities), the framework is inapplicable

- **First 3 experiments:**
  1. **Single-task baseline comparison**: Train each task independently with local data only; then with traditional FL (same-task clients only); then with M-Fed. Compare mIoU/AP metrics to quantify the marginal benefit of cross-task knowledge. (Replicates Table 2 and Table 3)
  2. **λ sensitivity analysis**: Fix encoder (ResNet-50), tasks (semantic + instance segmentation), and vary λ (constant 0.01, 0.1, 1.0 vs. exponential schedule). Plot convergence curves and final task performance to validate the adaptive λ design
  3. **Task correlation ablation**: Run M-Fed on pairs of tasks with varying semantic similarity (e.g., semantic segmentation + human parts = high correlation; semantic segmentation + keypoint detection = lower correlation). Measure per-task performance delta to establish when cross-task transfer becomes neutral or negative

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the M-Fed framework be extended to support heterogeneous decoder structures for clients performing the same task?
- Basis in paper: [explicit] The limitations section states that "clients performing the same task must maintain the same model structure, otherwise intra-task knowledge fusion cannot be achieved"
- Why unresolved: The current framework relies on structural homogeneity for same-task clients to aggregate models effectively; it does not support knowledge fusion among clients with different decoders for identical tasks
- What evidence would resolve it: A modified aggregation mechanism that successfully improves performance for same-task clients utilizing different model architectures (decoders) compared to local training

### Open Question 2
- Question: How can the system autonomously mitigate negative transfer when task correlation is low, without manual hyperparameter tuning?
- Basis in paper: [explicit] The authors note that low task correlation may negatively impact performance, and the current mitigation strategy involves setting thresholds which "requires human involvement and judgment, thereby reducing the autonomy of the method"
- Why unresolved: The current reliance on manual adjustments of the regularization parameter ($\lambda$) prevents the system from automatically adapting to scenarios where cross-task knowledge is irrelevant or harmful (e.g., instance segmentation results in Section 5.3)
- What evidence would resolve it: An adaptive algorithm that dynamically adjusts the influence of the global encoder model based on real-time metrics of task correlation, demonstrating robust performance without manual threshold configuration

### Open Question 3
- Question: Can the M-Fed method be adapted to enable collaboration between clients with fundamentally different encoder architectures?
- Basis in paper: [explicit] Section 6 explicitly states that "the encoder parts of client models performing different tasks must also maintain the same structure, otherwise inter-task knowledge fusion cannot be realized"
- Why unresolved: The method relies on a unified global encoder model $g$ that requires local encoders $w^*_i$ to have the same structure for distance calculation and regularization
- What evidence would resolve it: A theoretical extension or projection mechanism allowing clients with heterogeneous encoders (e.g., ResNet vs. ViT) to share knowledge in the M-Fed framework while maintaining task performance

## Limitations

- The framework requires clients performing the same task to maintain identical model structures, preventing knowledge fusion among clients with different decoders for the same task
- Manual threshold configuration for the regularization parameter is needed to mitigate negative transfer, reducing system autonomy when task correlation is low
- The method cannot enable collaboration between clients with fundamentally different encoder architectures, limiting applicability to scenarios with heterogeneous model designs

## Confidence

- **High confidence** in the core mechanism of cross-task encoder aggregation and the two-tier aggregation framework, supported by clear mathematical formulation and experimental results showing consistent improvements across multiple task pairs
- **Medium confidence** in the regularization approach for soft encoder alignment, as the exact λ scheduling parameters are not fully specified and the paper notes potential negative transfer in certain task combinations (instance segmentation degradation of -3.78%)
- **Low confidence** in the claim that "local decoder approaches global decoder" since the algorithm only explicitly regularizes the encoder, not the decoder parameters

## Next Checks

1. Conduct ablation studies varying λ schedules (constant vs. exponential growth) to determine optimal regularization strength and validate the claim that adaptive λ improves convergence
2. Test M-Fed on task pairs with known negative transfer potential (e.g., semantic segmentation paired with keypoint detection) to quantify and characterize conditions where cross-task knowledge sharing degrades performance
3. Implement M-Fed with mixed encoder architectures (e.g., ResNet-50 for some clients, ResNet-101 for others) to determine the impact of encoder structural heterogeneity on knowledge transfer effectiveness