---
ver: rpa2
title: 'Explaining Hitori Puzzles: Neurosymbolic Proof Staging for Sequential Decisions'
arxiv_id: '2508.14294'
source_url: https://arxiv.org/abs/2508.14294
tags:
- unshaded
- proof
- shaded
- asserted
- must
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a neurosymbolic approach to explaining complex
  sequences of decisions in Hitori puzzles by combining SAT solvers with Large Language
  Models (LLMs). The method stages resolution proofs to align with human reasoning,
  prioritizing weak constraints for simpler explanations and using visual proofs for
  connectivity constraints.
---

# Explaining Hitori Puzzles: Neurosymbolic Proof Staging for Sequential Decisions

## Quick Facts
- arXiv ID: 2508.14294
- Source URL: https://arxiv.org/abs/2508.14294
- Reference count: 40
- Primary result: Neurosymbolic approach combining SAT solvers with LLMs to explain Hitori puzzle solutions through staged resolution proofs, achieving 25x shorter explanations than monolithic proofs.

## Executive Summary
This paper presents a neurosymbolic method for explaining sequential decision-making in Hitori puzzles by combining SAT solvers with Large Language Models. The approach stages resolution proofs to align with human reasoning, prioritizing weak constraints (local logic) over strong constraints (global connectivity). The system uses visual proofs for connectivity constraints and translates symbolic proofs into natural language via LLMs. Experiments demonstrate that staged proofs are significantly shorter than monolithic ones, and LLM-generated explanations are accurate and fluent for complex steps, though less so for trivial ones.

## Method Summary
The method encodes Hitori puzzles into SAT formulas using Boolean variables for cell states and constraints for uniqueness, separation, and connectivity. A greedy staging algorithm prioritizes "weak" proofs (derived from local uniqueness/separation constraints) over "strong" connectivity proofs. When weak proofs are insufficient, the system checks connectivity via graph analysis and generates visual proofs. An LLM (DeepSeek R1) translates Z3 proof objects into natural language explanations using few-shot prompting with structured context including the proof object, board state, and semantic mappings.

## Key Results
- Staged proofs are 25x shorter than monolithic proofs (e.g., 82k+ characters vs. 3k characters for complex puzzles)
- LLM explanations achieve high correctness ratings for complex steps (4.48/5) but lower ratings for trivial steps (2.96-3.34)
- Visual connectivity proofs effectively explain global constraints without verbose resolution traces
- The staged approach successfully solves all 107 benchmark puzzles with explainability

## Why This Works (Mechanism)

### Mechanism 1: Greedy Subgoal Staging via Constraint Strength
The system decomposes puzzle solutions into subgoals and iteratively selects the subgoal with the shortest resolution proof from weak constraints (Uniqueness/Separation). Only when weak constraints are exhausted does it invoke strong constraints (Connectivity). This greedy approach avoids case splitting explosion typical in monolithic SAT proofs.

### Mechanism 2: Modal Substitution (Proofs-by-Picture)
Global connectivity constraints are explained via visual graph analysis rather than textual resolution proofs. The system checks if negating a subgoal disconnects the graph and generates visual proofs (ASCII or graphic) when connectivity violations occur, leveraging users' intuitive understanding of graph connectivity.

### Mechanism 3: In-Context Learning for Symbolic Translation
LLMs translate structured symbolic resolution proofs into natural language when provided with the proof object, semantic definitions, and state history. The system treats LLMs as translators rather than reasoners, assuming the formal proof is sound and sufficient for narrative generation.

## Foundational Learning

- **Concept: Propositional Logic & CNF (Conjunctive Normal Form)**
  - Why needed here: The paper relies on encoding Hitori rules into CNF for the Z3 solver. You must understand how game rules translate into boolean variables (`c_ij` for cell state) and clauses.
  - Quick check question: How would you encode the constraint "At least one of cells A or B must be shaded" as a disjunction clause?

- **Concept: Resolution Proofs & Unit Propagation**
  - Why needed here: The "Proof Staging" hinges on preferring "weak proofs" which often rely on unit resolution. Understanding this helps distinguish why some proofs are "short" (local deduction) and others are "long" (global connectivity/strong proofs).
  - Quick check question: In the context of the paper, why is a proof derived solely from "weak constraints" considered cognitively easier for the LLM to explain than one requiring "strong constraints"?

- **Concept: Prompt Engineering / Few-Shot Learning**
  - Why needed here: The translation layer uses an LLM with specific prompts. Understanding how to structure the prompt (showing the Z3 code + explanation pairs) is critical to reproducing the results.
  - Quick check question: According to the paper (Page 6), does providing "Full History" or "Filtered History" generally yield better results for trivial steps?

## Architecture Onboarding

- **Component map:** Encoder -> Weak Solver -> Strong Solver -> Staging Manager -> Explainer (LLM)
- **Critical path:** The iterative loop in Algorithm 1: Extract subgoals, query Weak Solver for proofs, select shortest proof, fallback to Strong Solver if needed, pass to LLM/Visualizer, assert state, repeat.
- **Design tradeoffs:** Completeness vs. Cognitive Load (staging favors explainability over computational speed), Monolithic vs. Staged (staged requires repeated solver calls but produces explainable steps).
- **Failure signatures:** "Overthinking" hallucinations on trivial steps, loop stagnation when no weak proof exists, context drift on large grids exceeding LLM token limits.
- **First 3 experiments:** Reproduce the "Sandwich Lemma" Proof on a 3x3 grid, compare explanation latency between staged and monolithic approaches on 5x5 grids, test LLM robustness by corrupting semantic mappings in valid Z3 proofs.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the proof staging approach effectively generalize to complex, real-world decision-making domains beyond logic puzzles, such as regulatory compliance or chemical discovery?
- **Open Question 2:** What is the computational complexity of the proof staging problem itself?
- **Open Question 3:** How can the generation of natural language explanations be improved for trivial, early-stage proof steps where LLMs currently struggle with accuracy?
- **Open Question 4:** Is the effectiveness of proof staging dependent on the specific architecture or proof logging format of the underlying SAT/SMT solver?

## Limitations
- Results based on 107 puzzles with unknown diversity in difficulty distribution and potential bias toward solvable configurations
- Performance relies on DeepSeek R1 and may not transfer to other models without prompt adaptation
- Visual proofs may not scale effectively for larger grids (25x25) or complex non-planar connectivity scenarios

## Confidence
- High Confidence: Core mechanisms (proof staging, visual connectivity proofs) with clear algorithmic descriptions and quantitative evidence
- Medium Confidence: LLM explanation quality due to subjective human evaluation and small sample size (20 puzzles, 10 examples per category)
- High Confidence: 25x shorter proofs claim well-supported but may not generalize to all puzzle types

## Next Checks
1. Test the explanation framework with a different LLM (e.g., GPT-4) using the same prompt structure to assess model-specific performance variance
2. Evaluate staged proofs on puzzles requiring immediate connectivity reasoning to test edge cases
3. Systematically measure LLM explanation quality degradation as state history length approaches model context limits on progressively larger grids