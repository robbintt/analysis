---
ver: rpa2
title: Adaptive Layer-Wise Transformations for Post-Training Quantization of Large
  Language Models
arxiv_id: '2511.17809'
source_url: https://arxiv.org/abs/2511.17809
tags:
- transformation
- quantization
- selection
- layers
- kurtosis
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of quantization in large language
  models (LLMs), where systematic outliers in activations and weights cause performance
  degradation, especially at low-bit settings. The authors propose an adaptive layer-wise
  transformation selection framework to systematically determine optimal transformations
  on a per-layer basis.
---

# Adaptive Layer-Wise Transformations for Post-Training Quantization of Large Language Models

## Quick Facts
- arXiv ID: 2511.17809
- Source URL: https://arxiv.org/abs/2511.17809
- Authors: Cuong Pham; Hoang Anh Dung; Cuong C. Nguyen; Trung Le; Gustavo Carneiro; Jianfei Cai; Thanh-Toan Do
- Reference count: 5
- One-line primary result: Adaptive layer-wise transformation selection based on weight kurtosis achieves up to 4.58 perplexity points improvement over FlatQuant at W3A3K2V2 quantization

## Executive Summary
This paper addresses post-training quantization (PTQ) for large language models (LLMs) by proposing an adaptive layer-wise transformation selection framework that systematically determines optimal transformations on a per-layer basis. The key insight is that weight distributions vary systematically across layers, and ignoring this heterogeneity leads to suboptimal quantization performance. The authors develop both a differentiable search method and an efficient outlier-guided heuristic based on kurtosis analysis of weight distributions, achieving significant improvements over existing methods while maintaining computational efficiency.

## Method Summary
The approach formulates transformation selection as a differentiable optimization problem using a softmax mixture of affine and rotation transformations with entropy regularization, then develops an efficient outlier-guided method using kurtosis-based analysis of weight distributions. For each layer type (attention Q/K/V and FFN Gate/Up projections), excess kurtosis is computed and normalized via robust z-scores using median and MAD. The method uses threshold-based selection with β parameters to allocate layers to affine vs rotation transformations, leveraging the empirical correlation between weight distribution kurtosis and optimal transformation type. The outlier-guided method achieves comparable performance to differentiable search with significantly reduced computational overhead.

## Key Results
- Up to 4.58 perplexity points improvement and 2.11% gain in average six-task zero-shot accuracy under W3A3K2V2 quantization for LLaMA-3-8B compared to FlatQuant
- 87.5% agreement between outlier-guided heuristic and differentiable search transformation selection for LLaMA-2-7B
- Consistent improvements across all tested quantization settings (W4A4K4V4, W3A3K3V3, W4A4K2V2, W3A3K2V2) and model scales (7B/13B/70B)
- Computational efficiency: Outlier-guided method reduces transformation selection time from ~3× slower to negligible overhead

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Layer-wise heterogeneous transformations outperform homogeneous transformation settings.
- Mechanism: Weight distributions vary systematically across layers; attention layers typically exhibit higher kurtosis (concentrated outliers) favoring rotation's redistribution, while certain FFN layers show lower kurtosis where affine transformations suffice. The adaptive selection matches transformation capability to each layer's distribution characteristics.
- Core assumption: The optimal transformation type is layer-specific and correlates with statistical properties of weight distributions.
- Evidence anchors:
  - [abstract] "ignoring the heterogeneous distribution characteristics within LLMs... demonstrates the necessity of heterogeneous transformation selection"
  - [section 3.1] Table 1 shows random mixed transformation improves over fixed affine by 1.26 zero-shot accuracy points
  - [corpus] CALM (arXiv:2512.16282) similarly finds "substantial differences in algorithmic suitability among layers"

### Mechanism 2
- Claim: Weight kurtosis serves as an efficient proxy for optimal transformation selection.
- Mechanism: Excess kurtosis κ = E[(W-μ)⁴]/σ⁴ - 3 measures distribution "tailedness." Leptokurtic (high κ) indicates concentrated outliers benefiting from rotation's redistribution; platykurtic (low κ) indicates flatter distributions where affine suffices. Robust z-score normalization using MAD handles scale/skew variations.
- Core assumption: The kurtosis-transformation correlation discovered via differentiable search generalizes across model scales.
- Evidence anchors:
  - [abstract] "connection between weight distribution kurtosis and optimal transformation types"
  - [section 3.3] Figure 1 shows attention layers with κ < 2.0 favor rotation; FFN layers with κ < 0.2 favor affine
  - [corpus] No direct kurtosis-based selection methods found; this appears novel

### Mechanism 3
- Claim: Differentiable search validates transformation choices but is computationally prohibitive.
- Mechanism: Formulate selection as softmax mixture: Ŷ = π_A·Ŷ_A + π_R·Ŷ_R with entropy regularization H(π) encouraging binary decisions. After optimization, discretize via argmax. This provides ground-truth labels for analyzing kurtosis correlation.
- Core assumption: The differentiable search converges to locally optimal transformation assignments.
- Evidence anchors:
  - [section 3.2] Equations 5-7 define the optimization; λ_entropy = 0.01
  - [section 4.3] Table 4 shows 87.5% agreement between heuristic and learned selection for LLaMA-2-7B
  - [corpus] FlatQuant and OSTQuant use learned transformations but apply uniformly

## Foundational Learning

- Concept: **Kurtosis as a statistical measure**
  - Why needed here: Understanding why kurtosis—not variance or skew—captures the outlier property relevant to quantization difficulty.
  - Quick check question: Would a bimodal distribution have high or low kurtosis, and which transformation would handle it better?

- Concept: **Orthogonal vs. affine transformations**
  - Why needed here: Rotation preserves Euclidean norm (information-preserving redistribution) while affine can flatten arbitrarily but may distort geometry.
  - Quick check question: Why can rotation transformations be applied to any layer without merging, but affine transformations require careful placement?

- Concept: **Robust z-score normalization (MAD-based)**
  - Why needed here: Standard z-scores are themselves sensitive to outliers; MAD provides outlier-resistant scaling.
  - Quick check question: Why does the 1.4826 factor make MAD comparable to standard deviation under normality?

## Architecture Onboarding

- Component map:
  - Kurtosis Calculator -> Robust Normalizer -> Threshold Selector -> Transformation Assigner -> Quantization Wrapper

- Critical path:
  1. Load model weights → 2. Compute per-layer kurtosis → 3. Normalize via Eq. 9 → 4. Set β_attn=0.1, β_ffn=0.9, L ratios (0.7×n attention, 0.5×n FFN) → 5. Compute thresholds via Eqs. 13-14 → 6. Assign transformations → 7. Run calibration

- Design tradeoffs:
  - Differentiable search vs. heuristic: Search is ~3× slower but may find better assignments; heuristic achieves 85-87.5% agreement
  - β parameter sensitivity: Paper clips β_attn ∈ [0.1, 0.3], β_ffn ∈ [0.7, 0.9]; extreme values reduce adaptivity
  - Transformation placement: Only QKV (attention) and Up-Gate (FFN) use adaptive selection; other layers follow FlatQuant

- Failure signatures:
  - Perplexity degrades below FlatQuant baseline → check kurtosis computation for numerical overflow
  - All layers assigned same transformation → verify MAD ≠ 0 (add ε = 10⁻¹²)
  - Training divergence in rotation learning → RiemannAdam optimizer required for orthogonal constraint

- First 3 experiments:
  1. Reproduce Table 1 random transformation baseline on LLaMA-2-7B W3A3K3V3 to validate that mixed transformations help
  2. Plot kurtosis distribution across layers colored by differentiable search selection (reproduce Figure 1) to verify correlation
  3. Compare heuristic vs. differentiable search selection agreement on a smaller model (e.g., LLaMA-2-7B) before scaling to 70B

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do attention layers and FFN layers exhibit opposite kurtosis-transformation preferences (attention favors rotation at low kurtosis, FFN favors rotation at high kurtosis)?
- Basis in paper: [explicit] The authors observe this divergent pattern in Figure 1 but state only that "kurtosis provides guidance rather than strict thresholds" without explaining the underlying mechanism.
- Why unresolved: The paper establishes the correlation empirically but does not investigate the structural or functional differences between attention and FFN layers that cause this inversion.
- What evidence would resolve it: Ablation studies isolating layer-specific properties (e.g., weight matrix rank, activation patterns, gradient flow) coupled with theoretical analysis of how rotation vs. affine transforms interact with each layer type's distribution characteristics.

### Open Question 2
- Question: Does the kurtosis-based selection heuristic generalize to transformer architectures beyond the LLaMA family?
- Basis in paper: [inferred] All experiments are conducted exclusively on LLaMA-2 and LLaMA-3 models, leaving untested whether the β thresholds and L parameter ratios transfer to architectures with different attention mechanisms, normalization schemes, or activation functions.
- Why unresolved: Different architectures may exhibit distinct weight distribution patterns that alter the kurtosis-transformation relationship.
- What evidence would resolve it: Experiments on diverse model families (e.g., Mistral, Qwen, Gemma) using the same hyperparameters, reporting both performance and selection agreement rates.

### Open Question 3
- Question: Can the binary affine/rotation choice be extended to mixed or hybrid transformations for further gains?
- Basis in paper: [inferred] The differentiable search formulation (Equation 5) uses softmax weights that converge to binary values, but intermediate mixtures are penalized by entropy regularization rather than explored as potential solutions.
- Why unresolved: The paper does not investigate whether allowing weighted combinations of transformations at individual layers could capture finer-grained optimization.
- What evidence would resolve it: Experiments with relaxed entropy constraints or direct evaluation of mixed-π configurations compared to discretized selections.

## Limitations

- The kurtosis-transformation correlation, while empirically strong for LLaMA models, requires validation across diverse transformer architectures to confirm generalizability
- Optimal β parameters (β_attn=0.1, β_ffn=0.9) appear empirically chosen rather than theoretically derived, with sensitivity to model scale and architecture unexplored
- The method focuses only on attention Q/K/V and FFN Gate/Up projections, leaving other layer types (layer norms, embeddings) without adaptive transformation selection

## Confidence

**High confidence** in the core empirical findings: The 4.58 perplexity point improvement and 2.11% zero-shot accuracy gain over FlatQuant are well-documented with statistical significance across multiple benchmarks and quantization settings. The computational efficiency advantage of the outlier-guided heuristic versus differentiable search is clearly demonstrated.

**Medium confidence** in the generalizability of the kurtosis-transformation correlation: While the paper shows strong agreement (87.5% for LLaMA-2-7B) between heuristic and learned selection, this correlation needs validation on architectures with different weight distribution characteristics. The mechanistic explanation linking high kurtosis to rotation benefits is theoretically sound but not rigorously proven.

**Low confidence** in the optimal threshold parameters (β_attn=0.1, β_ffn=0.9): These appear to be empirically chosen rather than theoretically derived. The clipping bounds (0.1-0.3 for attention, 0.7-0.9 for FFN) are justified post-hoc, and their sensitivity to model scale and architecture remains unexplored.

## Next Checks

1. **Cross-architecture validation**: Apply the kurtosis-guided transformation selection to a non-LLaMA architecture (e.g., OPT or Mistral) to verify the generalization of the kurtosis-transformation correlation.

2. **Ablation on β parameters**: Systematically vary β_attn and β_ffn across their allowed ranges to quantify sensitivity and identify optimal values for different model scales.

3. **Statistical power analysis**: Conduct formal statistical tests (e.g., paired t-tests) on the perplexity and accuracy improvements to quantify confidence levels and effect sizes across the six zero-shot tasks.