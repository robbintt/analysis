---
ver: rpa2
title: Synthetic Financial Data Generation for Enhanced Financial Modelling
arxiv_id: '2512.21791'
source_url: https://arxiv.org/abs/2512.21791
tags:
- data
- synthetic
- timegan
- temporal
- generative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a unified multi-criteria framework for evaluating
  synthetic financial data, comparing ARIMA-GARCH, VAEs, and TimeGAN using S&P 500
  returns. We assess distributional fidelity (MMD, KS), temporal structure (ACF, volatility
  clustering), downstream utility (portfolio optimization, volatility forecasting),
  and privacy leakage (NNDT, MIA).
---

# Synthetic Financial Data Generation for Enhanced Financial Modelling

## Quick Facts
- arXiv ID: 2512.21791
- Source URL: https://arxiv.org/abs/2512.21791
- Reference count: 24
- This study introduces a unified multi-criteria framework for evaluating synthetic financial data, comparing ARIMA-GARCH, VAEs, and TimeGAN using S&P 500 returns.

## Executive Summary
This study presents a comprehensive evaluation framework for synthetic financial data generation, comparing three approaches: ARIMA-GARCH, VAEs, and TimeGAN. Using S&P 500 daily returns from 2000-2024, we assess distributional fidelity, temporal structure, downstream utility, and privacy leakage. TimeGAN demonstrates superior performance across most metrics, achieving the lowest MMD (1.84×10⁻³), highest temporal coherence, and best downstream task performance while maintaining strong privacy guarantees. VAEs exhibit over-regularization issues that smooth extreme events, while ARIMA-GARCH offers interpretability but limited realism. The results indicate that TimeGAN is best suited for high-fidelity applications, though model selection should balance fidelity, interpretability, and computational cost.

## Method Summary
The study evaluates synthetic financial data generation using S&P 500 daily returns (2000-2024), preprocessed as log-returns and normalized. Three models are implemented: VAE (Dense encoder/decoder with latent dimension 16), TimeGAN (2-layer GRU with supervised and adversarial training), and ARIMA-GARCH (orders selected via AIC). Synthetic data is generated with 30-day sequence windows and evaluated using MMD, KS statistics, ACF, and squared ACF for temporal coherence. Downstream tasks include portfolio optimization and volatility forecasting, while privacy is assessed via NNDT and MIA methods. Results are averaged over 5 random seeds.

## Key Results
- TimeGAN achieves lowest MMD (1.84×10⁻³) and highest temporal coherence across all metrics
- TimeGAN outperforms others in downstream tasks: portfolio Sharpe similarity 0.91, volatility forecasting RMSE 0.103
- VAEs produce smoothed trajectories underestimating extremes (kurtosis 3.18 vs real 5.62)
- TimeGAN exhibits strongest privacy with MIA accuracy 51.1% and NN distance 0.153

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TimeGAN's supervised loss component is the primary driver of temporal coherence in synthetic financial sequences.
- Mechanism: The supervised loss L_sup aligns latent temporal representations by training a supervisor network to predict next-step embeddings from current embeddings, forcing the generator to learn sequential dependencies rather than just marginal distributions.
- Core assumption: Financial time series contain learnable transition dynamics that can be captured via recurrent embedding spaces.
- Evidence anchors:
  - Ablation study (Table 4): removing L_sup increases MMD by +61% (1.84→2.97×10⁻³) and KS by +74%, confirming supervised loss is essential for temporal fidelity.
  - Section 3.4.3: "The supervised loss aligns latent temporal representations."
  - Limited direct corpus validation; neighbor papers focus on GAN applications without ablation of temporal loss components.
- Break condition: If the underlying time series is white noise (no autocorrelation structure), L_sup provides no benefit and may degrade sample diversity.

### Mechanism 2
- Claim: VAE over-regularization suppresses extreme financial events through KL divergence penalization.
- Mechanism: The KL term D_KL(q_φ(z|x) || p(z)) in the ELBO objective pulls the approximate posterior toward a standard Gaussian prior, compressing the latent space and smoothing reconstructions. Higher β values amplify this effect, reducing variance in generated outputs.
- Core assumption: Financial return distributions have heavy tails (excess kurtosis) that require latent representations with higher variance than a standard Gaussian prior permits.
- Evidence anchors:
  - "VAEs produce smooth trajectories that underestimate extreme events."
  - Table 3: VAE kurtosis (3.18) vs. real data (5.62), variance (1.29×10⁻⁴) vs. real (1.85×10⁻⁴).
  - Ablation (Table 4): β=2 increases MMD to 3.92; β=0.5 improves fidelity but risks oversmoothing.
  - Neighbor paper "New Money" review confirms VAEs trade off fidelity for stable training in financial applications.
- Break condition: If β→0, the VAE behaves like a standard autoencoder with no regularization, potentially overfitting and memorizing training sequences.

### Mechanism 3
- Claim: ARIMA-GARCH captures linear conditional mean and volatility dynamics but fails on nonlinear regime shifts due to parametric rigidity.
- Mechanism: ARIMA models linear autoregressive dependencies via φ(B) and θ(B) polynomials; GARCH models conditional heteroskedasticity via lagged squared residuals and variances. Both assume stationary, parametric relationships that cannot represent state-dependent or threshold dynamics.
- Core assumption: Financial returns follow approximately linear conditional mean structures with GARCH(1,1)-type volatility persistence.
- Evidence anchors:
  - "ARIMA–GARCH captures linear trends and conditional volatility but fails to reproduce nonlinear dynamics."
  - Table 2: ARIMA-GARCH shows "Moderate" temporal coherence despite "Good" mean/variance match.
  - Figure 3: PCA projection shows ARIMA-GARCH samples occupy a shifted region, indicating incomplete covariance structure reproduction.
  - Neighbor papers on hybrid models (e.g., "Stochastic Volatility Modelling with LSTM") propose neural extensions to address GARCH limitations.
- Break condition: If the true data-generating process exhibits regime-switching, leverage effects, or long-memory volatility, ARIMA-GARCH residuals will show persistent structure (ARCH effects remain).

## Foundational Learning

- Concept: Maximum Mean Discrepancy (MMD)
  - Why needed here: Primary metric for distributional fidelity between real and synthetic financial returns.
  - Quick check question: If MMD=0, are the distributions identical? (Answer: Yes in the limit of infinite samples in the RKHS; practically, low MMD indicates high similarity.)

- Concept: Evidence Lower Bound (ELBO)
  - Why needed here: Objective function for VAE training; understanding the reconstruction-KL trade-off explains over-smoothing behavior.
  - Quick check question: What happens to reconstruction quality if the KL term weight β is increased? (Answer: Latent space becomes more regularized, reconstruction fidelity typically decreases.)

- Concept: Volatility Clustering
  - Why needed here: Key stylized fact of financial returns; synthetic data must preserve autocorrelation of squared returns to be useful for risk modeling.
  - Quick check question: How is volatility clustering detected in synthetic data? (Answer: Via ACF of squared returns; slow decay indicates persistence.)

## Architecture Onboarding

- Component map:
ARIMA-GARCH: [Linear AR/MA layers] → [GARCH variance layer] → [Gaussian/Student-t sampler]
VAE: [Encoder (Dense 64→32)] → [Latent z ~ N(μ,σ²)] → [Decoder (32→64)] → [Reconstruction]
TimeGAN: [Embedder GRU] + [Generator GRU] + [Supervisor GRU] + [Discriminator GRU] + Joint training with L_recon + L_sup + L_adv

- Critical path:
  1. Data preprocessing: log-returns → stationarity check → normalization.
  2. For TimeGAN: Phase 1 (autoencoder pretraining with L_recon) → Phase 2 (joint adversarial training with all losses).
  3. Evaluation: MMD → ACF/squared-ACF → downstream tasks (portfolio optimization, volatility forecasting).

- Design tradeoffs:
  - TimeGAN: Highest fidelity (MMD 1.84×10⁻³) but 4.5 hrs training and hyperparameter sensitivity.
  - VAE: Fast training (1.5 hrs), stable, but underestimates tails (kurtosis 3.18 vs. 5.62).
  - ARIMA-GARCH: Instant training (<0.1 hrs), fully interpretable, but highest MMD (4.72×10⁻³) and cannot model nonlinearities.

- Failure signatures:
  - TimeGAN mode collapse: Generated sequences show repetitive patterns; discriminator loss → 0.
  - VAE posterior collapse: Latent dimensions become uninformative; KL → 0 per dimension.
  - ARIMA-GARCH residual ARCH effects: Ljung-Box test on squared residuals remains significant.

- First 3 experiments:
  1. Reproduce baseline fidelity: Train all three models on S&P 500 log-returns (2000–2024), compute MMD and KS statistics. Verify TimeGAN MMD ≈ 1.8×10⁻³.
  2. Ablate TimeGAN supervised loss: Remove L_sup, measure MMD degradation. Expect +50–70% increase per Table 4.
  3. Downstream validation: Fit GARCH(1,1) on synthetic data, forecast volatility on held-out real data. Compare RMSE across generators; expect TimeGAN lowest (~0.103).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the proposed evaluation framework generalize to multi-asset settings where cross-asset correlations and sector dependencies are present?
- Basis in paper: Section 7.1 identifies the single-asset dataset as a limitation, noting that "cross-asset covariance structures... were not evaluated." Section 7.2 explicitly lists "Multi-asset synthetic data generation" as a primary direction for future work.
- Why unresolved: The current study restricted experiments to a single S&P 500 time series to provide a controlled comparison, leaving the modeling of complex covariance dynamics unexplored.
- What evidence would resolve it: Empirical results demonstrating the framework's ability to replicate the correlation matrices and sector structures of a diverse portfolio of assets.

### Open Question 2
- Question: Can advanced sequential VAE architectures (e.g., VRNN, SRNN) bridge the performance gap with TimeGAN by mitigating the over-regularization observed in standard VAEs?
- Basis in paper: Section 7.1 highlights the use of a "Restricted VAE architecture" as a limitation, and Section 7.2 proposes assessing "Sequential VAE architectures" to improve temporal expressiveness.
- Why unresolved: The standard VAE used in the study produced smooth trajectories that underestimated extremes, struggling with temporal coherence compared to TimeGAN.
- What evidence would resolve it: A benchmark showing that sequential latent-variable models achieve lower MMD scores and higher autocorrelation fidelity than the static baseline.

### Open Question 3
- Question: How sensitive is TimeGAN's fidelity to hyperparameter selection and random initialization, and what are the failure modes regarding mode collapse?
- Basis in paper: Section 7.1 acknowledges the "Incomplete quantification of TimeGAN instability," and Section 7.2 calls for a "Formal stability benchmark for GAN-like models."
- Why unresolved: While the study averaged results over 5 seeds, it did not systematically quantify variance across different initializations or rigorously analyze the conditions leading to training divergence.
- What evidence would resolve it: A sensitivity analysis measuring the variance of fidelity metrics (e.g., MMD) across a wide distribution of random seeds and learning rates.

## Limitations
- TimeGAN hyperparameter sensitivity and stability across different market regimes remain incompletely characterized
- Privacy evaluation relies on proxy metrics rather than formal differential privacy guarantees
- Single-asset dataset limits generalizability to multi-asset portfolio settings with cross-asset dependencies

## Confidence

- **High confidence** (95%): ARIMA-GARCH parameter estimation and evaluation metrics (MMD, ACF, KS)
- **Medium confidence** (80%): VAE performance characterization
- **Medium confidence** (75%): TimeGAN comparative performance
- **Low confidence** (60%): Privacy leakage quantification

## Next Checks

1. **Hyperparameter Sensitivity Analysis**: Systematically vary TimeGAN's supervised loss weight (λ_sup ∈ [0.1, 0.5, 1, 2]) and GRU hidden dimension (16, 24, 32) to quantify impact on MMD, ACF, and downstream Sharpe ratio. Document variance across 10 random seeds.

2. **Regime-Switching Robustness**: Partition S&P 500 data into bull/bear/volatile regimes (e.g., 2000-2002 crash, 2008 crisis, 2020 pandemic). Retrain all three models on each regime and evaluate cross-regime fidelity and downstream utility to assess temporal generalization.

3. **Privacy Formalization**: Implement a formal differential privacy framework (e.g., moments accountant) for synthetic data generation. Compare the privacy-utility tradeoff curves of TimeGAN against a DP-VAE baseline to establish whether current NNDT/MIA metrics overestimate or underestimate true privacy leakage.