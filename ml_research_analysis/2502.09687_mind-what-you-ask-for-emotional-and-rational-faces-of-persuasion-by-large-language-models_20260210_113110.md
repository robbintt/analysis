---
ver: rpa2
title: 'Mind What You Ask For: Emotional and Rational Faces of Persuasion by Large
  Language Models'
arxiv_id: '2502.09687'
source_url: https://arxiv.org/abs/2502.09687
tags:
- emotional
- setup
- rational
- persuasion
- social
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates how different Large Language Models (LLMs)
  use rational versus emotional persuasion by analyzing 12 models across four families
  (OpenAI, Meta, Mistral, Anthropic). Models were prompted with emotional or rational
  setups and responses were analyzed using LIWC for linguistic indicators and human
  annotation for social influence principles.
---

# Mind What You Ask For: Emotional and Rational Faces of Persuasion by Large Language Models
## Quick Facts
- arXiv ID: 2502.09687
- Source URL: https://arxiv.org/abs/2502.09687
- Reference count: 8
- Models use different social influence principles depending on emotional versus rational prompts

## Executive Summary
This study investigates how different Large Language Models employ rational versus emotional persuasion strategies. Twelve models across four families (OpenAI, Meta, Mistral, Anthropic) were prompted with emotional or rational setups, and responses were analyzed using LIWC for linguistic indicators and human annotation for social influence principles. The research reveals that emotional prompts generate the most cognitively complex arguments, while baseline responses are more neutral and cautious. Social influence analysis shows that LLMs use distinct principles depending on prompt type, with emotional prompts eliciting commitment, liking, and social proof, while rational prompts trigger authority and social proof.

## Method Summary
The study employed a mixed-methods approach to analyze persuasive strategies in LLM responses. Twelve models from four major families were prompted with either emotional or rational setups, with baseline responses also collected. Responses were analyzed using LIWC (Linguistic Inquiry and Word Count) for linguistic indicators of emotional and rational content, and human annotators evaluated responses for social influence principles. The analysis compared how different prompt types influenced the nature of LLM responses across multiple dimensions of persuasion.

## Key Results
- Emotional prompts generate the most cognitively complex arguments from LLMs
- Baseline responses are more neutral and cautious compared to prompt-specific responses
- LLMs use different social influence principles based on prompt type: emotional prompts trigger commitment, liking, and social proof; rational prompts trigger authority and social proof

## Why This Works (Mechanism)
The mechanism underlying these persuasion patterns relates to how LLMs have been trained on diverse human communication data that contains both emotional and rational elements. When prompted with specific emotional or rational cues, the models retrieve and generate text that aligns with the statistical patterns associated with those communication styles from their training data. The differential use of social influence principles suggests that LLMs can adapt their persuasive strategies based on contextual cues, mirroring human communication patterns where emotional appeals activate different psychological mechanisms than rational arguments.

## Foundational Learning
1. **LIWC Analysis** - Linguistic Inquiry and Word Count software for text analysis; needed to quantify emotional versus rational content in LLM responses; quick check: verify LIWC categories align with research definitions of emotional/rational persuasion
2. **Social Influence Principles** - Psychological frameworks for understanding persuasion (commitment, authority, social proof, etc.); needed to categorize persuasive strategies used by LLMs; quick check: ensure consistent application across human annotators
3. **Prompt Engineering** - Strategic formulation of prompts to elicit specific response types; needed to control experimental conditions and isolate emotional versus rational persuasion; quick check: validate prompts effectively trigger intended response styles
4. **Cross-Model Comparison** - Analysis across multiple LLM families to identify generalizable patterns; needed to distinguish between model-specific behaviors and broader LLM characteristics; quick check: assess consistency of findings across different model architectures
5. **Human Annotation Reliability** - Quality control for subjective assessment of persuasive content; needed to ensure validity of social influence principle identification; quick check: calculate inter-rater reliability scores

## Architecture Onboarding
**Component Map**: User Prompt -> LLM Family Processing -> LIWC Analysis -> Human Annotation -> Comparative Analysis
**Critical Path**: Prompt selection → Model response generation → Linguistic analysis → Social influence evaluation → Pattern identification
**Design Tradeoffs**: Balancing computational efficiency (LIWC) with interpretive depth (human annotation) to achieve comprehensive analysis while maintaining scalability
**Failure Signatures**: Inconsistent social influence annotations, LIWC misclassification of emotional/rational content, or model-specific anomalies that don't generalize across families
**3 First Experiments**:
1. Test prompt variations to establish baseline emotional/rational response patterns
2. Conduct inter-rater reliability assessment for human annotation consistency
3. Run cross-validation using alternative linguistic analysis tools

## Open Questions the Paper Calls Out
None

## Limitations
- Exclusive reliance on LIWC-based analysis may not capture full complexity of persuasive strategies
- Limited sample of 12 models across four families may miss important variations in smaller or emerging models
- Human annotation process may introduce subjectivity and inter-rater variability
- Focus on English-language prompts limits generalizability to other languages and cultural contexts

## Confidence
- Differential use of social influence principles based on prompt type: High
- Emotional prompts generate more cognitively complex arguments: Medium
- Baseline responses are more neutral and cautious: Low

## Next Checks
1. Replicate analysis using alternative linguistic analysis tools (Empath or custom sentiment analysis) to validate LIWC-based findings
2. Conduct systematic evaluation of inter-rater reliability among human annotators for social influence principles
3. Expand corpus to include additional LLM families (LLaMA, Falcon, specialized models) and conduct cross-validation