---
ver: rpa2
title: 'From Standalone LLMs to Integrated Intelligence: A Survey of Compound Al Systems'
arxiv_id: '2506.04565'
source_url: https://arxiv.org/abs/2506.04565
tags:
- arxiv
- systems
- language
- multimodal
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey provides the first unified taxonomy and architectural
  analysis of Compound AI Systems (CAIS), which integrate large language models (LLMs)
  with external components like retrievers, agents, tools, and orchestrators to overcome
  standalone LLM limitations in memory, reasoning, real-time grounding, and multimodal
  understanding. The authors organize CAIS along four orthogonal axes: Retrieval-Augmented
  Generation (RAG), LLM Agents, Multimodal LLMs (MLLMs), and Orchestration Frameworks.'
---

# From Standalone LLMs to Integrated Intelligence: A Survey of Compound Al Systems

## Quick Facts
- **arXiv ID:** 2506.04565
- **Source URL:** https://arxiv.org/abs/2506.04565
- **Reference count:** 40
- **Primary result:** First unified taxonomy and architectural analysis of Compound AI Systems (CAIS) integrating LLMs with retrievers, agents, tools, and orchestrators

## Executive Summary
This survey provides the first comprehensive taxonomy and architectural analysis of Compound AI Systems (CAIS), which integrate large language models with external components to overcome standalone LLM limitations in memory, reasoning, real-time grounding, and multimodal understanding. The authors organize CAIS along four orthogonal axes: Retrieval-Augmented Generation (RAG), LLM Agents, Multimodal LLMs (MLLMs), and Orchestration Frameworks. Through analysis of over 120 sources, they distill architectural blueprints, coordination strategies, and component interactions while highlighting recurring patterns and failure modes. The work establishes a foundational framework for understanding and advancing the next generation of system-level artificial intelligence.

## Method Summary
The survey employs a comprehensive literature analysis approach, examining over 120 sources to develop a unified taxonomy of Compound AI Systems. The methodology involves systematic categorization of CAIS architectures along four orthogonal dimensions (RAG, Agents, MLLMs, Orchestration), analysis of architectural blueprints and component interactions, and identification of coordination strategies and failure modes. The authors synthesize findings from diverse implementations to distill common patterns and propose a comprehensive evaluation framework addressing factual accuracy, robustness, efficiency, and alignment with human goals.

## Key Results
- CAIS taxonomy organized along four orthogonal axes: RAG, LLM Agents, MLLMs, and Orchestration Frameworks
- Comprehensive analysis of over 120 sources identifying architectural blueprints and coordination strategies
- Proposed evaluation framework addressing factual accuracy, robustness, efficiency, and alignment
- Identification of key challenges: scalability, interoperability, benchmarking, and coordination

## Why This Works (Mechanism)
Compound AI Systems work by integrating large language models with specialized external components that compensate for individual LLM limitations. The integration allows systems to overcome constraints in memory through retrieval mechanisms, enhance reasoning through agent-based planning, enable multimodal understanding through specialized processing, and coordinate complex workflows through orchestration frameworks. This architectural composition creates synergistic effects where the combined system achieves capabilities beyond what any single component could provide, addressing fundamental limitations of standalone LLMs through targeted specialization and collaboration.

## Foundational Learning

**Retrieval-Augmented Generation (RAG)**: External knowledge retrieval systems that provide LLMs with current, domain-specific, or proprietary information beyond their training data. Needed to address LLM knowledge cutoff limitations and enable real-time grounding. Quick check: Verify that retrieved documents are relevant and properly integrated into LLM responses.

**LLM Agents**: Autonomous systems that use LLMs for planning, decision-making, and tool usage across multiple steps. Needed to overcome single-step reasoning limitations and enable complex task decomposition. Quick check: Evaluate agent success rate on multi-step tasks requiring tool selection and planning.

**Multimodal LLMs (MLLMs)**: Systems that process and generate multiple data types (text, images, audio, video) through unified or specialized architectures. Needed to enable comprehensive understanding beyond text-only capabilities. Quick check: Test system performance on cross-modal tasks requiring integration of different input types.

**Orchestration Frameworks**: Coordination mechanisms that manage multiple AI components, routing tasks and aggregating outputs. Needed to handle complex workflows requiring multiple specialized components. Quick check: Assess orchestration efficiency and accuracy in task routing and output integration.

## Architecture Onboarding

**Component map:** User Input -> Orchestrator -> (RAG Component / LLM Agent / MLLM / External Tools) -> LLM Core -> Output Generator -> User Output

**Critical path:** User request flows through orchestrator to appropriate components (RAG for knowledge retrieval, agents for planning, MLLMs for multimodal processing), then to LLM core for processing, and finally through output generator to user.

**Design tradeoffs:** Real-time performance vs. accuracy (retrieval vs. generation), model size vs. inference speed, specialized vs. general-purpose components, centralized vs. distributed orchestration.

**Failure signatures:** Hallucination when RAG retrieval fails, planning errors when agents misinterpret tasks, modality confusion when MLLMs process incompatible inputs, orchestration bottlenecks when component coordination breaks down.

**3 first experiments:**
1. Implement a basic RAG system with a small LLM to verify knowledge retrieval effectiveness
2. Create a simple agent loop with tool usage to test planning and execution capabilities
3. Build a minimal orchestration framework to coordinate two specialized components

## Open Questions the Paper Calls Out
- How to optimize the balance between specialized components and general-purpose models in CAIS architectures
- What are the most effective evaluation metrics for measuring CAIS performance across different task domains
- How to address the scalability challenges when deploying CAIS in production environments
- What coordination strategies work best for different types of multi-component workflows

## Limitations
- Potential selection bias in the 120-source corpus without transparent selection criteria
- Lack of empirical validation for the proposed taxonomy's practical utility
- Limited discussion of implementation challenges across different domains
- No comparative performance analysis of existing CAIS frameworks

## Confidence
- Taxonomy and architectural analysis: Medium
- Evaluation framework comprehensiveness: Medium
- Identification of key challenges: High

## Next Checks
1. Conduct a systematic literature review to verify the claim of being the first unified taxonomy and assess the representativeness of the source corpus
2. Implement a prototype CAIS using the proposed architectural blueprints and evaluate its performance against the proposed framework
3. Perform a comparative analysis of at least three existing CAIS frameworks using the proposed evaluation dimensions to test framework applicability