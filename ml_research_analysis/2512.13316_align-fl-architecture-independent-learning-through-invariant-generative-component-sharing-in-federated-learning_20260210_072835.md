---
ver: rpa2
title: 'ALIGN-FL: Architecture-independent Learning through Invariant Generative component
  sharing in Federated Learning'
arxiv_id: '2512.13316'
source_url: https://arxiv.org/abs/2512.13316
tags:
- data
- privacy
- learning
- training
- align-fl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ALIGN-FL addresses federated learning across non-overlapping data
  distributions by sharing only generative model components rather than full parameters.
  The approach enables knowledge transfer between clients with completely disjoint
  data through selective sharing of VAE decoders, while the server trains on synthetic
  data generated from these components.
---

# ALIGN-FL: Architecture-independent Learning through Invariant Generative component sharing in Federated Learning

## Quick Facts
- **arXiv ID**: 2512.13316
- **Source URL**: https://arxiv.org/abs/2512.13316
- **Reference count**: 31
- **Primary result**: Architecture-independent FL framework using VAE decoder sharing achieves 74.25% accuracy and FID 81.91 on MNIST vs FedAvg's 43.75% accuracy and FID 148.70

## Executive Summary
ALIGN-FL addresses federated learning across non-overlapping data distributions by sharing only generative model components rather than full parameters. The approach enables knowledge transfer between clients with completely disjoint data through selective sharing of VAE decoders, while the server trains on synthetic data generated from these components. The framework incorporates privacy through either DP-SGD with adaptive clipping or Lipschitz regularization of VAE decoders, both of which effectively map sensitive outliers to typical data points. Experimental results on MNIST and Fashion-MNIST show significant improvements over traditional FL methods while maintaining privacy guarantees.

## Method Summary
ALIGN-FL operates by having each client train a local VAE on their non-overlapping data distribution, then extract and transmit only the decoder parameters to the server. The server samples synthetic data from each client's decoder, aggregates this into a combined synthetic dataset, and trains a global model on this synthetic data. Privacy is enforced through either DP-SGD applied to the complete VAE or Lipschitz regularization on the decoder via gradient penalties. The framework decouples knowledge transfer from architectural uniformity, enabling clients with different model architectures to participate in the same federated learning system.

## Key Results
- FID scores of 81.91-98.46 vs FedAvg's 148.70, showing superior generation quality
- Classification accuracy of 74.25-63.25% vs FedAvg's 43.75%
- F1-scores of 74.06-60.01% demonstrating strong classification performance
- Both DP mechanisms successfully map outliers to typical samples while maintaining utility
- Architecture independence achieved through decoder-only sharing approach

## Why This Works (Mechanism)

### Mechanism 1: Selective Generative Component Sharing
Transferring only VAE decoders enables knowledge transfer across clients with non-overlapping data distributions while avoiding parameter averaging degradation. Each client trains a local VAE, extracts only the decoder parameters $p_\theta$, and transmits these to the server. The server samples synthetic data from each client's decoder, aggregates into $D_s$, then trains a global model on combined synthetic data—decoupling knowledge transfer from architectural uniformity.

### Mechanism 2: DP-SGD with Adaptive Clipping on Full VAE
Applying DP-SGD to the complete VAE (encoder + decoder) provides formal $(\epsilon, \delta)$-DP guarantees while maintaining synthetic data utility. Per-example gradient clipping with norm $C$, Gaussian noise addition calibrated to $\sigma C$, and client-specific adaptive clipping based on local gradient norm quantiles are applied to both encoder $q_\phi$ and decoder $p_\theta$.

### Mechanism 3: Lipschitz-Constrained Decoder VAE (LCD-VAE)
Enforcing Lipschitz continuity on the decoder via gradient penalties naturally limits model sensitivity to individual training examples, achieving privacy-utility trade-offs superior to DP-SGD for this task. The approach augments ELBO loss with gradient penalty $\mathcal{L}_{GP} = \mathbb{E}_{\tilde{z}}[(|\nabla_{\tilde{z}} f_\theta(\tilde{z})|_2 - 1)^2]$ interpolated over latent space.

## Foundational Learning

- **Variational Autoencoder (VAE) fundamentals**: Understanding ELBO, latent space geometry, and reconstruction is prerequisite to grasping why decoder-only sharing works. Can you explain why Gaussian encoders with small KL divergence produce minimal overlap between different inputs?
- **Differential Privacy composition**: ALIGN-FL operates over $T$ federated rounds; privacy budget accumulates across rounds via composition theorems. Given per-round $\epsilon = 1$ over 10 rounds, what is the approximate composed privacy loss under basic composition?
- **Federated averaging failure modes under extreme Non-IID**: Understanding why FedAvg/FedProx achieve only 38-43% accuracy here (vs 74% for ALIGN-FL) motivates the decoder-sharing approach. Why does parameter averaging fail when $\text{supp}(P_i) \cap \text{supp}(P_j) \approx \emptyset$?

## Architecture Onboarding

- **Component map**: Client n: Local Data D_n → Encoder q_ϕ^n → Latent z → Decoder p_θ^n → Server: Collect {p_θ^1, ..., p_θ^N} → Sample synthetic D_syn^n from each → Combine D_s = ∪D_syn^n → Train global M_s

- **Critical path**: 1) Client local training with privacy mechanism (10 local epochs, batch 128) 2) Decoder extraction and transmission 3) Server synthetic sampling (5000 global samples, 10 epochs) 4) Global model training on combined synthetic data 5) Repeat for T rounds (10 in experiments)

- **Design tradeoffs**: DP-SGD vs LCD-VAE: DP-SGD provides formal $(\epsilon, \delta)$ guarantees but lower utility; LCD-VAE achieves better utility (FID 98.46 vs 174.01) but lacks formal DP equivalence. Stateful vs stateless clients: Stateful design maintains local progress but requires per-client privacy budget tracking across rounds.

- **Failure signatures**: Outlier reconstruction visible in generated samples → privacy mechanism insufficient or disabled. Global latent space shows overlapping digit clusters → synthetic data diversity insufficient. Client accuracy diverges across rounds → state management broken, clients overwritten.

- **First 3 experiments**: 1) Baseline sanity check: Run ALIGN-FL No-DP on MNIST partition without privacy mechanisms. Expect FID ~82, accuracy ~74%. 2) Privacy mechanism comparison: Run both DP-SGD and LCD-VAE on same partition. Verify LCD-VAE achieves higher accuracy (target: 63% vs 52%) with better FID. 3) Outlier mapping validation: Introduce 5% cross-domain outliers to Client 1. Reconstruct through global model. Verify both DP mechanisms map outliers to typical digits, while No-DP reconstructs outliers directly.

## Open Questions the Paper Calls Out

- **Can formal convergence guarantees be established for the ALIGN-FL framework given its reliance on synthetic data aggregation rather than parameter averaging?** The conclusion states that "formal convergence guarantees remain to be established and are a valuable direction for future work." While empirical results show convergence, the theoretical properties of learning via synthetic data generation in a stateful, heterogeneous environment have not been mathematically proven.

- **Can a rigorous theoretical connection be established linking the Lipschitz constraints in LCD-VAE to formal $(\epsilon, \delta)$-Differential Privacy guarantees?** Section VII notes that "establishing a formal connection between Lipschitz constraints and DP guarantees remains an open theoretical challenge." LCD-VAE currently relies on structural constraints to limit sensitivity, but this does not automatically translate to certified $(\epsilon, \delta)$-DP guarantees without formal derivation.

- **How does the privacy-utility trade-off in ALIGN-FL scale when applied to significantly more complex, high-dimensional data domains compared to the simple image datasets tested?** The Conclusion lists "extending ALIGN-FL to more complex domains" as a primary future direction, and Section VIII-B notes the "quality gap... widens significantly for more complex data domains." The framework is validated only on MNIST and Fashion-MNIST; it is unclear if the generative component sharing remains efficient or if privacy mechanisms degrade utility unacceptably for complex data.

## Limitations

- **Formal privacy guarantees for Lipschitz regularization remain unproven**: While LCD-VAE shows promising empirical results, the theoretical connection to formal $(\epsilon, \delta)$-DP is not established.
- **Adaptive clipping implementation details are underspecified**: The paper describes using "local median" for adaptive clipping but does not specify exact quantile computation or update frequency, affecting reproducibility.
- **Latent space dimensionality impact is unexplored**: The paper uses 2D latent space for visualization but does not investigate how higher-dimensional latent spaces affect privacy-utility trade-offs or Lipschitz regularization effectiveness.

## Confidence

- **High Confidence**: Claims about decoder-only sharing enabling architecture independence and avoiding parameter averaging degradation are well-supported by experimental results showing 74% accuracy vs 43% for FedAvg.
- **Medium Confidence**: Privacy mechanisms (DP-SGD and LCD-VAE) effectiveness in mapping outliers to typical samples is demonstrated empirically but requires more extensive testing across diverse outlier types and data distributions.
- **Low Confidence**: The formal relationship between Lipschitz regularization and differential privacy lacks complete theoretical foundation, though empirical results show promising privacy-utility trade-offs.

## Next Checks

1. **Cross-Domain Outlier Robustness**: Introduce 5% Fashion-MNIST samples to MNIST clients (and vice versa) and verify that DP mechanisms map these outliers to typical samples while No-DP reconstructs them directly, following Figure 3 behavior.

2. **Lipschitz Bound Sensitivity**: Test LCD-VAE across different gradient penalty strengths ($\lambda_{GP}$) and latent space dimensionalities to identify the optimal privacy-utility trade-off and validate Lemma A.4's bounded latent ball assumption.

3. **Adaptive Clipping Reproducibility**: Implement the adaptive clipping mechanism with specified local median computation and verify that privacy budgets are correctly tracked across federated rounds, comparing against fixed clipping baselines.