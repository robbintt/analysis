---
ver: rpa2
title: Why do AI agents communicate in human language?
arxiv_id: '2506.02739'
source_url: https://arxiv.org/abs/2506.02739
tags:
- language
- communication
- multi-agent
- agent
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper argues that current multi-agent systems relying on natural
  language for communication suffer from structural misalignment between the high-dimensional
  semantic spaces of LLMs and the discrete token sequences of natural language. This
  misalignment leads to information loss, semantic drift, and behavioral inconsistencies
  during agent coordination.
---

# Why do AI agents communicate in human language?

## Quick Facts
- arXiv ID: 2506.02739
- Source URL: https://arxiv.org/abs/2506.02739
- Authors: Pengcheng Zhou; Yinglun Feng; Halimulati Julaiti; Zhongliang Yang
- Reference count: 40
- **Primary result:** Natural language communication between AI agents suffers from structural misalignment between high-dimensional LLM representations and discrete token sequences, causing semantic drift and coordination failures.

## Executive Summary
This position paper identifies a fundamental structural misalignment in current multi-agent systems: the high-dimensional continuous semantic spaces of large language models (LLMs) are compressed into discrete natural language tokens for agent communication, creating information loss and semantic drift. The authors argue that LLMs were trained for human interaction, not agent coordination, lacking mechanisms for role persistence, task boundaries, and multi-agent dependencies. They propose rethinking both communication mechanisms and model design paradigms, advocating for native multi-agent modeling with structured communication, role persistence, and explicit coordination graphs to address these limitations.

## Method Summary
The paper presents a theoretical analysis of why natural language communication fails in multi-agent systems, identifying the structural mismatch between LLM internal representations and token sequences as the core problem. While no specific training algorithm or implementation is provided, the authors propose conceptual mechanisms including role persistence, structured communication protocols, and inter-agent state synchronization. The validation approach involves quantifying "Cascading Semantic Loss" by measuring the distance between original and reconstructed internal states over interaction turns, though concrete experimental results are not provided in the paper.

## Key Results
- Natural language communication creates information loss when mapping high-dimensional LLM states to discrete tokens
- Semantic drift accumulates over interaction turns, degrading coordination quality
- Current multi-agent frameworks like AutoGPT and AgentVerse exhibit behavioral inconsistencies due to this misalignment
- LLMs lack fundamental mechanisms for role persistence and multi-agent coordination

## Why This Works (Mechanism)
The paper argues that natural language serves as an lossy compression mechanism between agents' internal semantic states. When an agent encodes its high-dimensional hidden state into natural language tokens for communication, and the receiving agent decodes this into its own representation space, information is lost and semantic meaning drifts. This creates a cascade of errors that compounds over interaction turns, leading to coordination failures. The mechanism is particularly problematic because LLMs were trained on human language patterns rather than agent-to-agent coordination, lacking the architectural support needed for persistent roles and explicit multi-agent dependencies.

## Foundational Learning
- **Cascading Semantic Loss**: The accumulation of information loss when converting between internal semantic states and natural language tokens. Why needed: Demonstrates the core failure mode of current communication protocols. Quick check: Measure cosine similarity between original and reconstructed states over interaction turns.
- **Role Persistence**: Maintaining agent identities and responsibilities across interaction turns. Why needed: Without persistent roles, agents cannot maintain context or coordinate effectively. Quick check: Track task completion rates with and without role binding mechanisms.
- **Coordination Graphs**: Explicit representations of agent dependencies and interaction patterns. Why needed: Provides structural framework for multi-agent reasoning beyond token sequences. Quick check: Measure coordination success rates across different graph topologies.
- **Structured Communication**: Using metadata or reduced vocabularies instead of free-form language. Why needed: Reduces semantic drift by constraining the communication space. Quick check: Compare drift metrics between structured and unstructured protocols.
- **Inter-Agent State Synchronization**: Mechanisms for agents to maintain consistent views of shared task state. Why needed: Prevents divergence in agent understanding of the task context. Quick check: Measure state divergence over time in collaborative tasks.

## Architecture Onboarding

**Component Map:** Native Multi-Agent Model -> Structured Communication Layer -> Role Binding System -> Coordination Graph

**Critical Path:** Internal State → Structured Communication → Role Binding → Coordination → Task Completion

**Design Tradeoffs:** Natural language enables human debugging but introduces semantic drift; structured communication reduces drift but loses human interpretability; role persistence improves coordination but increases architectural complexity.

**Failure Signatures:** Semantic drift manifests as increasing cosine distance between intended and received messages; coordination failures appear as agents working at cross-purposes; role confusion emerges when agents forget their assigned responsibilities.

**First 3 Experiments:**
1. Implement Cascading Semantic Loss measurement in a testbed multi-agent environment to quantify drift over interaction turns.
2. Compare coordination success rates between free-form natural language and structured communication protocols in collaborative tasks.
3. Test role persistence mechanisms by measuring task completion improvements when agents maintain explicit role bindings across turns.

## Open Questions the Paper Calls Out
**Open Question 1:** How can systems retain natural language for human debugging while implementing structured tensor alignment for agent communication? This remains unresolved because creating invertible mappings from internal semantic states to natural language explanations without contaminating multi-agent policies is currently an unsolved engineering challenge.

**Open Question 2:** Can a native multi-agent model generalize to unseen coordination structures in a zero-shot manner? This is unresolved because traditional language models excel at sequence-level generalization but struggle to transfer skills to novel role compositions and dynamic interaction dependencies.

**Open Question 3:** How can architectural mechanisms ensure fault tolerance and error recovery in high-frequency agent communication? This remains open because current systems rely on soft token-level interactions and lack robust principles for recovering from cascading semantic errors or communication noise.

## Limitations
- Theoretical claims lack empirical validation with concrete metrics or experimental results
- No implementation details provided for proposed solutions like role persistence or coordination graphs
- Assertions about LLMs being "fundamentally unsuitable" are not tested against alternative communication protocols
- Reliance on qualitative observations from existing frameworks rather than systematic measurement

## Confidence
- **High confidence:** Identification of token-representation mismatch as a structural limitation
- **Medium confidence:** Qualitative observations about semantic drift in existing frameworks
- **Low confidence:** Claims about fundamental unsuitability of LLMs without alternative mechanisms tested

## Next Checks
1. Implement the Cascading Semantic Loss measurement: Create a testbed multi-agent environment, instrument it to extract and store internal states alongside messages, and quantitatively measure semantic drift over interaction turns using embedding-based distance metrics.

2. Test alternative communication protocols: Implement a structured communication layer (e.g., using structured metadata or reduced vocabularies) between the same LLMs and measure whether semantic drift is reduced compared to free-form natural language.

3. Prototype role persistence mechanisms: Implement the proposed role binding system (Eq. 7) in a multi-agent task and evaluate whether it improves task completion rates and reduces coordination failures compared to stateless agent interactions.