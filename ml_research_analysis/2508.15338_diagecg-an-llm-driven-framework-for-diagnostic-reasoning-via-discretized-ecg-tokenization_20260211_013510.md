---
ver: rpa2
title: 'DiagECG: An LLM-Driven Framework for Diagnostic Reasoning via Discretized
  ECG Tokenization'
arxiv_id: '2508.15338'
source_url: https://arxiv.org/abs/2508.15338
tags:
- language
- tasks
- report
- tokens
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HeartLLM is a novel framework that enables large language models
  to process 12-lead ECG signals for clinical text generation tasks. The method discretizes
  continuous ECG embeddings into symbolic tokens using a lead-independent encoder
  and quantization module, allowing the model to handle both ECG and natural language
  inputs in a unified manner.
---

# DiagECG: An LLM-Driven Framework for Diagnostic Reasoning via Discretized ECG Tokenization

## Quick Facts
- **arXiv ID**: 2508.15338
- **Source URL**: https://arxiv.org/abs/2508.15338
- **Reference count**: 7
- **Primary result**: HeartLLM framework achieves 56.63% exact match accuracy on ECG question answering and BLEU-4 scores of 33.60 for diagnostic report generation

## Executive Summary
HeartLLM is a novel framework that enables large language models to process 12-lead ECG signals for clinical text generation tasks. The method discretizes continuous ECG embeddings into symbolic tokens using a lead-independent encoder and quantization module, allowing the model to handle both ECG and natural language inputs in a unified manner. HeartLLM achieves strong performance across tasks while maintaining generalization to out-of-distribution settings. It outperforms baseline models on ECG question answering, achieving 56.63% exact match accuracy on MIMIC-IV-ECG and 54.98% on PTB-XL. For diagnostic report generation, it achieves BLEU-4 scores of 33.60 on MIMIC-IV-ECG and 33.60 on PTB-XL.

## Method Summary
HeartLLM employs a three-stage pipeline: (1) an ECG tokenizer that independently encodes each of the 12 leads using Inception-TIE blocks, projects continuous embeddings, and discretizes them via Fixed-Scale Quantizer (FSQ) into a 1,296-token vocabulary; (2) autoregressive pretraining where the LLM predicts next ECG tokens to learn temporal dynamics; and (3) LoRA-based instruction tuning for QA and report generation tasks. The framework uses LLaMA-3.2-3B as the backbone, extended with ECG tokens, and trains on MIMIC-IV-ECG (78,358 ECGs) and PTB-XL (21,797 ECGs) datasets with a 7:1:2 patient-based split.

## Key Results
- HeartLLM achieves 56.63% exact match accuracy on ECG question answering on MIMIC-IV-ECG and 54.98% on PTB-XL
- Diagnostic report generation yields BLEU-4 scores of 33.60 on both MIMIC-IV-ECG and PTB-XL datasets
- The framework generalizes to out-of-distribution data, maintaining performance across different ECG datasets
- HeartLLM outperforms baseline models on both ECG question answering and report generation tasks

## Why This Works (Mechanism)

### Mechanism 1: Discrete Symbolic Interface for Continuous Signals
Converting continuous ECG waveforms into discrete symbolic tokens reduces the modality gap between physiological signals and the LLM's native text processing, facilitating unified reasoning. The framework uses a Fixed-Scale Quantizer (FSQ) to project continuous latent representations into a low-dimensional space, discretizing them into indices (e.g., integers 0â€“5). These indices are mapped to a finite "ECG vocabulary" (e.g., size 1,296) and treated exactly like text tokens by the LLM.

### Mechanism 2: Native Autoregressive Temporal Modeling
Pretraining the LLM to predict the next ECG token enables it to internalize temporal dynamics using its existing language modeling capabilities, removing the need for specialized temporal adapters. The model is trained on a "next-token prediction" task using only ECG tokens (without text). This forces the Transformer attention mechanism to learn dependencies between waveform segments across time steps, similar to how it learns syntax in text.

### Mechanism 3: Lead-wise Independence with Global Aggregation
Processing 12 ECG leads independently before aggregation preserves lead-specific morphological details while avoiding premature feature interference. The architecture employs 12 identical "Lead-wise Encoders" (ResInception blocks). Each lead is normalized and encoded separately. The resulting features are concatenated and discretized.

## Foundational Learning

- **Concept: Finite Scalar Quantization (FSQ)**
  - **Why needed here**: Unlike Vector Quantization (VQ) which requires a codebook lookup, FSQ simply rounds float values to integers. This is the critical step that turns the continuous ECG into "tokens" the LLM can process.
  - **Quick check question**: If the projection dimension is $D=4$ and levels $K=6$, how many unique tokens are in the ECG vocabulary? (Answer: $6^4 = 1296$).

- **Concept: Autoregressive Pretraining**
  - **Why needed here**: This stage bridges the modality gap. Before the model can answer questions about an ECG, it must learn the "language" of the ECG tokens (i.e., what likely comes next in a heartbeat sequence).
  - **Quick check question**: During this phase, does the model see any text or clinical reports? (Answer: No, it only sees ECG tokens to learn temporal dynamics).

- **Concept: LoRA (Low-Rank Adaptation)**
  - **Why needed here**: The paper fine-tunes a large LLM (LLaMA-3.2-3B) on medical data. LoRA allows updating the model's weights efficiently without retraining the entire backbone, preserving general language capabilities.
  - **Quick check question**: In the instruction tuning phase, which parameters are updated? (Answer: Only the LoRA modules in linear projections; the embedding table and head are typically frozen or minimally updated).

## Architecture Onboarding

- **Component map**: Input (12-lead Raw ECG) -> 12 parallel Inception-TIE blocks (Lead-wise Encoder) -> Linear projector + Sigmoid -> Fixed-Scale Quantizer (FSQ) -> Indices -> Token IDs -> LLM Backbone (LLaMA-3.2-3B with extended vocabulary) -> Text generation (Report or Answer)

- **Critical path**: The projection and quantization step (FSQ). If the gradients cannot flow effectively through the rounding operation (using the straight-through estimator) or if the rounding destroys distinct feature clusters, the LLM receives "garbage" tokens that it cannot map to clinical concepts.

- **Design tradeoffs**:
  - **Vocabulary Size vs. Resolution**: The paper uses a small vocabulary (1,296 tokens) derived from $K=6, D=4$. While efficient, this is orders of magnitude smaller than typical text vocabularies (32k+), potentially creating "collision" where distinct ECG features map to the same token.
  - **Lead-independent vs. Spatial modeling**: Independent encoders avoid interference but may miss cross-lead spatial vector information unless the aggregator and LLM are powerful enough to infer spatial relations from the concatenated sequence.

- **Failure signatures**:
  - **Reconstruction Loss**: If the autoencoder (Decoder) cannot reconstruct the waveform from the discrete tokens, the diagnostic information is lost.
  - **Low "Query" Accuracy**: If the model handles "Verify" (Yes/No) but fails "Query" (open-ended text), the alignment between ECG tokens and semantic text is broken.
  - **Modality Gap**: Visualization (like UMAP in Fig 1) showing ECG and Text clusters separated indicates the discretization failed to align the modalities.

- **First 3 experiments**:
  1. **Tokenizer Reconstruction Test**: Train only the Encoder-FSQ-Decoder on MIMIC-IV-ECG. Verify if the reconstructed signal maintains diagnostic morphology (e.g., visible P-waves, QRS complexes). Target: Low MSE.
  2. **Ablation on "w/o Discretization"**: Compare the proposed FSQ tokens against feeding continuous embeddings directly into the LLM (baseline). Expect a performance drop in the continuous version due to modality gap.
  3. **Zero-Shot Generalization Check**: Train on MIMIC-IV-ECG, test on PTB-XL without adaptation. This validates if the tokenization captures universal ECG features rather than dataset-specific artifacts.

## Open Questions the Paper Calls Out

- **Question**: Can the HeartLLM framework be effectively adapted for real-time streaming ECG analysis, or does the tokenization process inherently require offline batch processing?
- **Basis in paper**: The conclusion states, "HeartLLM assumes offline processing and does not support real-time ECG analysis. Future work may extend our approach to streaming settings."
- **Why unresolved**: The current architecture relies on a Fixed-Scale Quantization (FSQ) module and autoregressive pretraining which may introduce latency incompatible with real-time monitoring requirements.
- **What evidence would resolve it**: A demonstration of HeartLLM operating in a streaming environment with sub-second latency while maintaining diagnostic accuracy.

- **Question**: How can structured medical knowledge graphs or ontologies be integrated into the discretized token space to improve model interpretability?
- **Basis in paper**: The authors explicitly identify "incorporate medical knowledge to improve interpretability" as a direction for future work.
- **Why unresolved**: The current model aligns ECG tokens with text semantics via autoregressive pretraining, but does not explicitly enforce consistency with external medical knowledge bases.
- **What evidence would resolve it**: An extension of the framework that utilizes knowledge graphs to constrain generation, resulting in clinically validated reasoning paths.

- **Question**: To what extent does the generated text quality correlate with human clinician evaluation compared to the automated metrics (BLEU, ROUGE) currently reported?
- **Basis in paper**: The evaluation section relies entirely on automated NLP metrics (BLEU, METEOR, ROUGE) and exact match accuracy for QA.
- **Why unresolved**: Automated metrics often fail to capture clinical nuance or factual correctness in medical reports; the paper does not present a human expert evaluation study.
- **What evidence would resolve it**: A human evaluation study where cardiologists blind to the model origin rate the diagnostic accuracy and coherence of the generated reports.

## Limitations
- The discretization process may smooth over subtle pathological features, potentially losing diagnostic information
- The framework assumes offline processing and does not support real-time ECG analysis
- Clinical validation through human expert evaluation is absent, relying only on automated metrics

## Confidence

**High Confidence Claims:**
- The discretization approach enables unified processing of ECG and text inputs by the LLM
- The three-stage training pipeline (tokenizer pretraining, autoregressive pretraining, instruction tuning) is technically sound and reproducible
- The framework achieves competitive performance on established ECG-QA and report generation benchmarks

**Medium Confidence Claims:**
- The model generalizes well to out-of-distribution data
- Lead-wise independent encoding preserves diagnostic features better than early fusion approaches
- The discretization preserves sufficient information for clinical text generation

**Low Confidence Claims:**
- The model would perform equivalently on real-world clinical ECGs with noise and artifacts
- The generated reports meet clinical utility standards
- The framework is ready for clinical deployment

## Next Checks
1. **Reconstruction Quality Assessment**: Implement detailed quantitative and qualitative analysis of signal reconstruction from discrete tokens. Measure MSE across different cardiac conditions and visualize reconstructed waveforms to identify information loss patterns.

2. **Real-World Clinical Data Testing**: Evaluate the model on ECGs from diverse clinical sources with varying quality, noise levels, and non-standard lead placements. Compare performance degradation relative to controlled academic datasets to assess practical utility.

3. **Clinical Expert Review**: Conduct blinded assessment of generated reports by board-certified cardiologists. Evaluate clinical accuracy, completeness, and actionability of outputs. Identify failure modes that quantitative metrics might miss.