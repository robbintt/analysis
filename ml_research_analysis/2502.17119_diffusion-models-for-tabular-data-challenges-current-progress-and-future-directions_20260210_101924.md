---
ver: rpa2
title: 'Diffusion Models for Tabular Data: Challenges, Current Progress, and Future
  Directions'
arxiv_id: '2502.17119'
source_url: https://arxiv.org/abs/2502.17119
tags:
- data
- diffusion
- tabular
- features
- categorical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey provides the first comprehensive review of diffusion
  models for tabular data, addressing the unique challenges of this data modality
  including missing values, heterogeneous features, mixed-type single features, feature
  dependencies, small data size, and domain-specific constraints. While diffusion
  models have achieved remarkable success in domains like images and text, their application
  to tabular data requires specialized adaptations due to these inherent challenges.
---

# Diffusion Models for Tabular Data: Challenges, Current Progress, and Future Directions

## Quick Facts
- **arXiv ID:** 2502.17119
- **Source URL:** https://arxiv.org/abs/2502.17119
- **Reference count:** 40
- **Primary result:** First comprehensive survey of diffusion models for tabular data covering challenges, current methods, and future directions across data augmentation, imputation, privacy, and anomaly detection.

## Executive Summary
This survey provides the first comprehensive review of diffusion models for tabular data, addressing the unique challenges of this data modality including missing values, heterogeneous features, mixed-type single features, feature dependencies, small data size, and domain-specific constraints. While diffusion models have achieved remarkable success in domains like images and text, their application to tabular data requires specialized adaptations due to these inherent challenges. The survey systematically categorizes relevant works into four key application areas: data augmentation (including single-table and multi-relational synthesis), data imputation, trustworthy data synthesis (privacy-preserving and fairness-preserving), and anomaly detection. It covers works from June 2015 to December 2024, maintaining an updated GitHub repository. The survey identifies that diffusion models for tabular data outperform traditional methods like GANs and VAEs across various benchmarks, while highlighting ongoing challenges such as scalability, evaluation metrics, privacy concerns, interpretability, and feature correlation modeling. Future research directions include developing more efficient sampling methods, standardized benchmarks, and hybrid models that combine diffusion models with other architectures.

## Method Summary
The survey systematically categorizes diffusion models for tabular data into four main application areas: data augmentation (including single-table and multi-relational synthesis), data imputation, trustworthy data synthesis (privacy-preserving and fairness-preserving), and anomaly detection. It covers works from June 2015 to December 2024, maintaining an updated GitHub repository. The survey highlights key methodological approaches including heterogeneous feature decoupling (separate Gaussian diffusion for numerical features and Multinomial diffusion for categorical features), joint latent representation using autoencoders, and conditional imputation via observed masking. The survey identifies TabDDPM as a standard baseline approach using Gaussian diffusion for numerical features (after Quantile Transformation) and Multinomial diffusion for categorical features (after One-Hot Encoding), with a joint loss function combining Gaussian simplified loss and Multinomial diffusion loss.

## Key Results
- Diffusion models outperform traditional methods like GANs and VAEs across various benchmarks for tabular data synthesis
- Key challenges include handling missing values, heterogeneous features, small data sizes, and capturing feature correlations
- Major application areas include data augmentation, imputation, privacy-preserving synthesis, and anomaly detection
- Current limitations include scalability, lack of standardized evaluation metrics, and privacy concerns
- Future research directions include developing more efficient sampling methods and hybrid models

## Why This Works (Mechanism)

### Mechanism 1: Heterogeneous Feature Decoupling
Separating the diffusion processes for numerical and categorical features improves distribution alignment over treating them uniformly. Instead of forcing categorical data into a continuous Gaussian space, this approach applies Gaussian diffusion to numerical features (often after Quantile Transformation) and Multinomial diffusion to categorical features (using one-hot encoding). This allows the noise schedule and loss function to respect the discrete nature of categorical data while handling continuous values separately. The core assumption is that numerical and categorical features can be modeled independently without significantly degrading cross-feature correlations. Evidence shows TabDDPM employs this approach, modeling numerical and categorical features independently. This separation may fail if the dataset relies heavily on complex dependencies between numerical and categorical variables.

### Mechanism 2: Joint Latent Representation
Mapping heterogeneous inputs into a continuous latent space allows a single diffusion model to capture complex, non-linear dependencies between features of different types. An autoencoder or tokenizer (e.g., VAE in TabSyn) compresses mixed-type data into a continuous latent embedding. A score-based diffusion model (SDE) operates in this unified space to learn the joint distribution, avoiding the information loss typical of simple encoding strategies like one-hot encoding. The core assumption is that the encoder/decoder architecture is sufficiently expressive to reconstruct the original heterogeneous features from the latent space without significant information loss. Evidence shows TabSyn transforms raw numerical and categorical features into continuous embeddings to capture correlations among features. This approach may fail if the autoencoder overfits or fails to reconstruct minority categories, propagating errors to the diffusion process.

### Mechanism 3: Conditional Imputation via Observed Masking
Conditioning the reverse diffusion process on observed values enables accurate missing value imputation by learning the conditional distribution p(missing | observed) rather than the marginal distribution. Methods like TabCSDI partition data into observed (conditioning set) and missing (target set). The model is trained to denoise the target set specifically given the context of the observed set, often using a specialized transformer or attention mechanism to model correlations. The core assumption is that the "Missing At Random" (MAR) assumption holds sufficiently well for the observed data to provide the necessary context for the missing data. Evidence shows TabCSDI involves partitioning the input into observed and unobserved parts and training a conditional model. This approach will be biased if the missingness mechanism is "Not Missing At Random" (MNAR) and missing values depend on unobserved factors.

## Foundational Learning

- **Concept:** Markov Forward and Reverse Processes
  - **Why needed here:** Understanding diffusion requires grasping how data is gradually destroyed (forward) and reconstructed (reverse). In tabular data, this is complicated by the need to define transition probabilities for both continuous (Gaussian) and discrete (Multinomial) states.
  - **Quick check question:** Can you explain the difference between the transition kernel q(x_t|x_{t-1}) in a Gaussian diffusion process versus a Multinomial diffusion process?

- **Concept:** Score-Based Generative Models (SGMs) via SDEs
  - **Why needed here:** Many modern tabular diffusion models (e.g., STaSy, TabSyn) are formulated as Stochastic Differential Equations (SDEs) rather than discrete Markov chains. This provides a flexible framework for handling the complex, multi-modal distributions often found in tabular data.
  - **Quick check question:** How does the "score function" ∇_x log p(x) relate to the direction of data density increase, and how does a neural network estimate it?

- **Concept:** Feature Preprocessing (Quantile & One-Hot Encoding)
  - **Why needed here:** The paper highlights that raw tabular data is non-Gaussian and heterogeneous. The performance of diffusion models is heavily dependent on transforming these features into spaces where the noise assumptions (e.g., Gaussian noise) hold better (e.g., using Quantile Transformer for numerical data).
  - **Quick check question:** Why is Min-Max scaling often suboptimal for numerical features in diffusion models compared to Quantile Transformation?

## Architecture Onboarding

- **Component map:** Raw Tabular Data (Numerical + Categorical) -> Quantile Transformer (Num), One-Hot/Embedding (Cat) -> Core Diffusion (Gaussian DDPM + Multinomial Diffusion) -> Inverse Transform -> Synthetic Tabular Data

- **Critical path:**
  1. Select the strategy for heterogeneity: Decoupled models (easier, faster) vs. Joint Latent (better correlations, harder to train)
  2. Define the noise schedule: Linear schedules (common in images) often fail; use adaptive or feature-specific schedules (e.g., CDTD)
  3. Training loop: Optimize the noise prediction (Gaussian) or probability transition (Multinomial) loss

- **Design tradeoffs:**
  - **TabDDPM vs. TabSyn:** TabDDPM (Decoupled) is simpler and often faster but may miss cross-feature correlations. TabSyn (Joint Latent) captures correlations better but adds complexity via the VAE training stage.
  - **Gaussian vs. Multinomial:** Using Gaussian diffusion on one-hot encoded categorical data is simpler but theoretically unsound (continuous space for discrete data); Multinomial diffusion is theoretically correct but computationally heavier for high-cardinality features.

- **Failure signatures:**
  - **Low Fidelity (KST/TVD):** The preprocessing does not normalize the data effectively, or the noise schedule is too aggressive for small datasets.
  - **Poor Correlation (DPCM/DCSM):** The model is likely "Decoupled" (like vanilla TabDDPM) and failing to model cross-type dependencies.
  - **Privacy Leakage (DCR):** The model is overfitting and memorizing training records, a known risk in diffusion models.

- **First 3 experiments:**
  1. **Baseline Implementation:** Implement TabDDPM with a Gaussian branch for numerical features and a Multinomial branch for categorical features to establish a benchmark for fidelity and utility.
  2. **Correlation Ablation:** Compare the baseline against a Joint Latent model (like TabSyn) specifically on the Pairwise Column Correlation metrics (DPCM/DCSM) to quantify the cost of decoupling.
  3. **Missing Data Robustness:** Introduce artificial missingness (MCAR) to a dataset and train MissDiff or TabCSDI to verify if the model can learn directly from incomplete data without pre-imputation bias.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can diffusion models be designed to simultaneously model numerical and categorical features to accurately capture cross-feature correlations without relying on separate diffusion processes or suboptimal encoding strategies?
- **Basis in paper:** The survey notes that "Most existing diffusion models are not optimized to capture feature correlations, especially those among categorical features and those among numerical and categorical features." It states ideally a model should "model numerical and categorical simultaneously."
- **Why unresolved:** Current leading methods (e.g., TabDDPM) use separate diffusion models for different feature types, failing to capture dependencies, while others rely on suboptimal encodings like one-hot or require complex latent spaces that introduce overhead.
- **What evidence would resolve it:** The development of a unified diffusion framework that jointly processes mixed data types and significantly outperforms separate-model baselines on correlation metrics (e.g., Contingency Similarity Matrices) while maintaining high fidelity.

### Open Question 2
- **Question:** What standardized benchmarks and domain-specific evaluation metrics can be developed to robustly assess the quality of synthetic tabular data, given the absence of visual inspection methods?
- **Basis in paper:** Section IX explicitly calls for "Standardized benchmarks and evaluation metrics tailored for diffusion models on tabular data" and notes that "evaluating tabular data generation quality is complex and may require domain-specific measures."
- **Why unresolved:** Unlike images, synthetic tabular data cannot be evaluated visually (fidelity is not obvious). Current metrics (e.g., KST, TVD) focus on marginal distributions and may miss complex multi-column dependencies or domain logic.
- **What evidence would resolve it:** The adoption of a community-wide benchmark suite (beyond simple ML utility) that includes metrics for domain constraints (e.g., logical validity in finance/healthcare) and long-range dependency preservation.

### Open Question 3
- **Question:** How can strong theoretical privacy guarantees, such as Differential Privacy (DP), be integrated into the diffusion training process without causing excessive degradation in data fidelity and utility?
- **Basis in paper:** While Section IX lists "Privacy Concerns" as a future direction requiring "strong theoretical guarantees," Section VI demonstrates a trade-off. The survey notes that models incorporating DP (like DP-Fed-FinDiff) reveal a "tradeoff between privacy protection and data utility/fidelity."
- **Why unresolved:** The addition of noise required for differential privacy often disrupts the model's ability to learn the intricate, non-Gaussian distributions and correlations inherent in tabular data.
- **What evidence would resolve it:** A diffusion model training algorithm that provides formal (ε, δ)-DP guarantees while achieving Machine Learning Utility (TSTR) scores statistically indistinguishable from non-private models on complex heterogeneous datasets.

### Open Question 4
- **Question:** How can the "objective mismatch" between generation (diversity) and imputation (accuracy) be resolved in diffusion models to improve performance on missing value tasks?
- **Basis in paper:** Section V discusses limitations in models like SimpDM and NewImp, noting a "mismatch in learning objectives": diffusion models are inherently sensitive to initial noise to promote diversity (good for generation), but this sensitivity harms the accuracy required for deterministic imputation.
- **Why unresolved:** The stochastic nature of the reverse denoising process, which is a feature for synthesis, becomes a bug for imputation where a single "correct" value is expected.
- **What evidence would resolve it:** A modified training objective or sampling mechanism that allows the model to switch modes or apply constraints that minimize variance (increase accuracy) for imputation tasks without sacrificing the ability to learn the data manifold.

## Limitations
- The survey lacks direct quantitative comparisons between methods across standardized benchmarks
- Performance claims regarding diffusion models outperforming GANs and VAEs are based on cited works rather than the survey's own empirical validation
- The survey acknowledges but does not fully address computational scalability challenges for large tabular datasets

## Confidence

- **High Confidence:** The characterization of fundamental challenges in tabular data (missing values, heterogeneous features, small datasets) and the categorization of diffusion model applications are well-supported by the literature.
- **Medium Confidence:** The identification of key architectural patterns (decoupled vs. joint approaches) is plausible but requires empirical validation across diverse datasets to confirm general superiority.
- **Low Confidence:** Specific performance claims about diffusion models outperforming alternatives across all metrics lack the standardized benchmarking needed for definitive conclusions.

## Next Checks

1. **Correlation Capture Validation:** Conduct controlled experiments comparing decoupled (TabDDPM-style) and joint latent (TabSyn-style) approaches on datasets with known cross-feature dependencies to quantify correlation preservation differences.

2. **Small Dataset Generalization:** Evaluate TabCSDI and MissDiff on datasets with varying levels of missingness (MCAR, MAR, MNAR) to verify robustness claims under different missing data mechanisms.

3. **Privacy Leakage Testing:** Implement membership inference attacks on synthetic data from AutoDiff and other privacy-preserving diffusion models to empirically validate DCR metric claims against actual privacy risks.