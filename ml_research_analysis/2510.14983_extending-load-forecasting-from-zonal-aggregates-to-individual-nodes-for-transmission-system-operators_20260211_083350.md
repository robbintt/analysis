---
ver: rpa2
title: Extending Load Forecasting from Zonal Aggregates to Individual Nodes for Transmission
  System Operators
arxiv_id: '2510.14983'
source_url: https://arxiv.org/abs/2510.14983
tags:
- load
- forecast
- forecasting
- utility
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a multi-level forecasting system that extends
  transmission system operators' (TSOs) current zonal load forecasting operations
  to individual nodes (buses) while maintaining manageability and interpretability
  for human operators. The system employs a hybrid interpretable time series General
  Additive Model (hits-GAM) that combines local and global modeling approaches, enabling
  accurate forecasts across heterogeneous bus-level loads.
---

# Extending Load Forecasting from Zonal Aggregates to Individual Nodes for Transmission System Operators

## Quick Facts
- arXiv ID: 2510.14983
- Source URL: https://arxiv.org/abs/2510.14983
- Reference count: 40
- Primary result: Hybrid interpretable GAM extends TSO zonal forecasts to individual buses with 93% RMSE reduction vs. top-down methods

## Executive Summary
This paper addresses a critical gap in transmission system operations by extending load forecasting from zonal aggregates to individual nodes (buses) while maintaining interpretability and computational efficiency. The system employs a hybrid interpretable time series General Additive Model (hits-GAM) that combines global and local modeling approaches to handle both volatility reduction and heterogeneity preservation. Experimental results on MISO data demonstrate significant improvements over both benchmark models and top-down disaggregation methods, with the system achieving sub-second inference times even for systems with hundreds of buses.

## Method Summary
The system uses a hybrid interpretable time series GAM (hits-GAM) built on NeuralProphet, combining global and local modeling approaches. Global components (autoregressive net and lagged temperature regressors) are fitted across all buses to reduce volatility through cross-learning, while local components (trend and seasonality) are fitted individually to preserve heterogeneity. Buses are clustered using time series features (trend, spike, seasonality strength, entropy, ACF) into three groups, with separate global models trained per group. The system employs bottom-up hierarchical reconciliation, directly forecasting bus-level loads and summing to utility-level aggregates, achieving fully parallelized sub-second inference times.

## Key Results
- 24% improvement in zonal forecast accuracy compared to benchmark models
- 93% reduction in RMSE and 95% reduction in MAE for bus-level forecasts compared to top-down disaggregation methods
- Sub-second inference times even for systems with hundreds of buses
- Grouping buses by time series characteristics improves utility-level accuracy through error decorrelation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Global model training with selective local components reduces volatility while preserving heterogeneity handling.
- **Mechanism:** The hits-GAM architecture fits expressive components (autoregressive and lagged temperature regressors) globally across all series, providing regularization through cross-learning. Simpler components (trend, seasonality) are fitted locally per series.
- **Core assumption:** Volatility is primarily manifested in short-term dynamics (captured by AR and temperature), while heterogeneity is primarily manifested in baseline patterns (trend, seasonality).
- **Evidence anchors:**
  - [abstract] "The system employs a hybrid interpretable time series General Additive Model (hits-GAM) that combines local and global modeling approaches"
  - [section 3.2.3] "To reduce the risk of overfitting, we chose to fit the more expressive model components (autoregression and lagged regressors) in a global fashion, while the simpler model components (trend and seasonality) are fitted in a local fashion"
- **Break condition:** If AR dynamics or temperature responses differ fundamentally across buses, global fitting may introduce bias rather than reduce variance.

### Mechanism 2
- **Claim:** Bottom-up hierarchical reconciliation outperforms top-down disaggregation for nodal forecasts.
- **Mechanism:** Directly forecasting bus-level loads and summing to utility-level aggregates avoids error amplification inherent in top-down approaches.
- **Core assumption:** Bus-level forecasts, while individually noisier than aggregate forecasts, contain signal that survives aggregation and provides better utility-level accuracy than disaggregated aggregate forecasts.
- **Evidence anchors:**
  - [abstract] "For bus-level forecasts, the system achieves a 93% reduction in RMSE and 95% reduction in MAE compared to top-down disaggregation methods"
  - [table 3] Local-Utility (top-down) MASE = 2.06, MSSE = 4.04 vs. Global-Bus MASE = 0.86, MSSE = 0.67
- **Break condition:** If bus-level data quality is extremely poor or buses are too numerous with insufficient training data.

### Mechanism 3
- **Claim:** Grouping buses by time series characteristics improves aggregate forecast accuracy through error decorrelation.
- **Mechanism:** K-means clustering on time series features creates homogeneous subgroups. Separate global models per group allow specialization while pooling within-group data, improving aggregate accuracy through less correlated errors.
- **Core assumption:** Clustering features capture meaningful heterogeneity relevant to forecasting difficulty; group sizes remain large enough to avoid overfitting.
- **Evidence anchors:**
  - [section 5] "The bus load series are clustered using a k-means algorithm into three groups"
  - [table 2] Grouped Global-Bus RMSE = 17.72, MAE = 11.92 vs. Global-Bus RMSE = 18.70, MAE = 12.75 at utility level
- **Break condition:** If groups become too small or clustering features are poorly chosen.

## Foundational Learning

- **Concept: Generalized Additive Models (GAMs)**
  - Why needed here: The core model architecture decomposes forecasts into additive interpretable components. Understanding GAMs is prerequisite to modifying component structure or interpreting outputs.
  - Quick check question: Given a GAM with components y = f₁(t) + f₂(hour) + f₃(temp), what would happen if f₁ and f₂ were highly correlated?

- **Concept: Hierarchical Time Series Reconciliation**
  - Why needed here: The system must ensure coherence between bus-level and utility-level forecasts. Bottom-up and top-down are the simplest reconciliation methods; understanding their trade-offs is essential.
  - Quick check question: If three buses sum to 100 MW but individual forecasts are 40, 35, and 30 MW, what reconciliation issue exists and how would bottom-up vs. top-down handle it?

- **Concept: Global vs. Local Forecasting Models**
  - Why needed here: The central design choice is which components to fit globally vs. locally. This trade-off between volatility reduction and heterogeneity preservation determines system behavior.
  - Quick check question: A global model trained on 100 buses has lower variance but shows systematic bias on 5 outlier buses. What modification strategies exist?

## Architecture Onboarding

- **Component map:**
  - Data preprocessing: duplicate removal → outlier replacement (3σ threshold) → missing value imputation (linear for ≤20 gaps, rolling average otherwise) → bus filtering (<1 year data, >20% missing, or constant values removed)
  - Feature extraction: 11 time series features for clustering
  - K-means clustering: 3 groups
  - hits-GAM model per group: 5 additive components with mixed global/local fitting
  - Inference: fully parallelized per-bus forecasts → bottom-up aggregation
  - Output: individual bus forecasts + aggregated utility forecast + component-wise decomposition

- **Critical path:**
  1. Bus data quality determines viable buses (quarter removed in preprocessing)
  2. Clustering quality determines group homogeneity (affects utility-level accuracy gains)
  3. Global component training requires sufficient pooled data (15 days lag × all buses in group)
  4. Inference parallelization enables sub-second performance (GPU required for full benefit)

- **Design tradeoffs:**
  - Number of groups: More groups → better heterogeneity handling, but higher overfitting risk. Paper uses 3 groups as fixed heuristic.
  - Global vs. local components: Expressive components global (regularization), simple components local (heterogeneity).
  - Forecast horizon: 33-hour horizon covers remaining compute day + full target day.

- **Failure signatures:**
  - Bus-level MASE > 1.0: Model is no better than seasonal naïve; check data quality or reconsider local fitting
  - Utility-level aggregate error much lower than sum of bus errors: Error cancellation masking individual bus problems
  - Grouped model underperforms single global model: Groups may be too small or clustering features poorly chosen

- **First 3 experiments:**
  1. **Baseline replication:** Implement single global hits-GAM on bus-level data with 5 components. Measure per-bus MASE and aggregate MAE against sNaïve baseline.
  2. **Ablation of global/local split:** Compare all-local, all-global, paper's hybrid, and inverted hybrid configurations to identify which component assignment drives accuracy gains.
  3. **Clustering sensitivity:** Vary number of groups from 1-10, measuring both bus-level and utility-level accuracy. Plot accuracy vs. group count to identify overfitting threshold.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different grouping mechanisms and group sizes affect the volatility-heterogeneity trade-off in Global Forecasting Models (GFMs) for nodal load forecasting?
- Basis: [explicit] Section 6.4 states: "This motivates future research to investigate the effects of grouping mechanisms and group sizes on GFMs."
- Why unresolved: The authors implemented a basic k-means clustering approach limited to three groups to balance regularization and heterogeneity. They observed that while grouping improved aggregate utility-level accuracy, it slightly reduced individual bus-level accuracy due to overfitting risks in smaller groups.
- What evidence would resolve it: A comparative study evaluating various clustering algorithms and a range of group sizes to identify an optimal balance that maximizes accuracy at both the bus and aggregate levels without overfitting.

### Open Question 2
- Question: Can interaction effects between model components be incorporated without violating the strict interpretability requirements of TSO operators?
- Basis: [explicit] Section 6.5 notes: "Novel approaches to model component interaction effects addressing the accuracy-interpretability trade-off could be the subject of future work."
- Why unresolved: The proposed hits-GAM uses a strictly additive structure to ensure components are individually interpretable. However, this prevents the model from capturing dynamic interactions, such as temperature effects on load differing between weekdays and weekends.
- What evidence would resolve it: The development of a model structure that allows for conditional interactions and a validation study confirming that human operators can still intuitively understand and adjust these specific component interactions.

### Open Question 3
- Question: How can the uncertainty implied by bus error-cancellation effects be explicitly quantified to improve risk assessment?
- Basis: [explicit] Section 6.5 identifies as a promising direction: "develop a methodology to directly quantify the uncertainty implied by bus error-cancellation effects."
- Why unresolved: The system currently reveals that bus errors sometimes cancel each other out at the aggregate level, but this "implicit uncertainty" is not formally quantified. Current probabilistic forecasts may underestimate risk during high-error situations where residuals align rather than cancel.
- What evidence would resolve it: A novel hierarchical reconciliation methodology that adjusts aggregate prediction intervals based on the correlation and directional alignment of individual bus-level forecast residuals.

## Limitations
- Data access limitations prevent full reproduction; the MISO bus-level dataset is proprietary
- Generalization to other TSO systems remains untested beyond MISO "Utility A"
- The fixed 3-group clustering heuristic lacks theoretical justification and may not scale to systems with significantly different numbers of buses
- Short-term dynamics (AR, temperature) are assumed to be sufficiently similar across buses for global fitting, which may not hold for systems with diverse load compositions

## Confidence
- **High confidence:** The hybrid local-global component approach and bottom-up reconciliation strategy are well-grounded in hierarchical forecasting theory
- **Medium confidence:** The specific 93% RMSE reduction vs. top-down disaggregation is robust for this dataset but may vary with different system characteristics
- **Medium confidence:** The grouping strategy provides utility-level improvements, though the fixed 3-group approach appears somewhat heuristic

## Next Checks
1. **Cross-TSO validation:** Apply the system to a different TSO's bus-level data (e.g., PJM, ERCOT) to test generalization of the global component fitting assumption
2. **Component sensitivity analysis:** Systematically vary the number of groups from 1-10 and the number of Fourier terms for seasonality to identify overfitting thresholds and optimal configurations
3. **Break condition testing:** Evaluate performance when bus-level data quality degrades (introduce missing values, measurement errors) to identify failure modes of the bottom-up approach