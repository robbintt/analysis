---
ver: rpa2
title: 'L2V-CoT: Cross-Modal Transfer of Chain-of-Thought Reasoning via Latent Intervention'
arxiv_id: '2511.17910'
source_url: https://arxiv.org/abs/2511.17910
tags:
- reasoning
- vlms
- representations
- llms
- l2v-cot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of enhancing vision-language
  models' (VLMs) multi-step reasoning capabilities, which are limited by scarce multimodal
  reasoning data. The authors propose L2V-CoT, a training-free method that transfers
  Chain-of-Thought (CoT) reasoning from large language models (LLMs) to VLMs through
  latent intervention.
---

# L2V-CoT: Cross-Modal Transfer of Chain-of-Thought Reasoning via Latent Intervention

## Quick Facts
- arXiv ID: 2511.17910
- Source URL: https://arxiv.org/abs/2511.17910
- Reference count: 26
- Key outcome: L2V-CoT transfers Chain-of-Thought reasoning from LLMs to VLMs via latent intervention, achieving average 3.7% performance gains across visual reasoning benchmarks

## Executive Summary
This paper addresses the challenge of enhancing vision-language models' multi-step reasoning capabilities, which are limited by scarce multimodal reasoning data. The authors propose L2V-CoT, a training-free method that transfers Chain-of-Thought (CoT) reasoning from large language models (LLMs) to VLMs through latent intervention. By analyzing CoT representations across modalities using Linear Artificial Tomography, they discover that VLMs and LLMs share similar low-frequency CoT representations despite architectural differences. L2V-CoT extracts and resamples low-frequency CoT patterns from LLMs, then injects them into VLMs during inference.

## Method Summary
L2V-CoT employs a training-free approach to transfer CoT reasoning capabilities from LLMs to VLMs. The method uses Linear Artificial Tomography to analyze CoT representations across modalities, revealing that VLMs and LLMs share similar low-frequency CoT patterns despite architectural differences. The approach extracts these low-frequency CoT patterns from LLMs and injects them into VLMs during inference through latent intervention. This cross-modal transfer enables VLMs to leverage the rich reasoning capabilities of LLMs without requiring additional training data or fine-tuning.

## Key Results
- L2V-CoT achieves average performance gains of 3.7% across visual reasoning benchmarks
- Performance improvements reach up to 8.6% over training-free baselines
- L2V-CoT outperforms supervised fine-tuned models in several cases
- Validated on multiple benchmarks including MathVista, MathVerse, MMStar, DynaMath, and MathVision

## Why This Works (Mechanism)
The core mechanism relies on the discovery that VLMs and LLMs share similar low-frequency CoT representations despite their architectural differences. By extracting these low-frequency patterns from LLMs and injecting them into VLMs through latent intervention, the method effectively transfers reasoning capabilities across modalities without requiring additional training.

## Foundational Learning
- **Linear Artificial Tomography**: Mathematical technique for analyzing spectral patterns in representations - needed to identify shared low-frequency CoT patterns across modalities
- **Latent Intervention**: Method of modifying model behavior during inference by altering latent representations - needed to inject extracted CoT patterns without retraining
- **Chain-of-Thought Reasoning**: Step-by-step problem-solving approach - needed as the reasoning paradigm being transferred
- **Cross-Modal Transfer**: Moving knowledge between different input modalities - needed to bridge language and vision domains
- **Low-Frequency Representations**: Dominant patterns in latent spaces - needed as the shared reasoning substrate between LLMs and VLMs

## Architecture Onboarding
- **Component Map**: LLM CoT extraction -> Linear Artificial Tomography analysis -> Low-frequency pattern resampling -> Latent intervention injection into VLM
- **Critical Path**: Extract CoT representations from LLM → Analyze spectral patterns → Resample low-frequency components → Inject into VLM during inference
- **Design Tradeoffs**: Training-free approach vs. potential performance ceiling compared to end-to-end fine-tuning; latency overhead during inference vs. no training data requirements
- **Failure Signatures**: Poor transfer performance when source LLM demonstrations are domain-mismatched; degradation when CoT patterns don't align with visual reasoning requirements
- **First 3 Experiments**: 1) Baseline VLM performance on MathVista, 2) L2V-CoT performance with same benchmark, 3) Comparative analysis of frequency spectrum cutoffs

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Effectiveness may depend heavily on quality and relevance of source LLM CoT demonstrations
- Cross-modal transfer generalizability to domains far from training distribution remains uncertain
- Theoretical framework relies on assumptions about representational alignment that warrant deeper investigation

## Confidence
- High confidence: Empirical performance improvements on established benchmarks are reproducible and substantial
- Medium confidence: Theoretical framework connecting latent space intervention to cross-modal reasoning transfer is sound but relies on partially theoretical assumptions
- Medium confidence: Method's advantages over supervised fine-tuning suggest practical value, though conditions for superiority remain to be fully characterized

## Next Checks
1. Conduct ablation studies varying the frequency spectrum cutoff to determine optimal range and robustness across different reasoning tasks
2. Test L2V-CoT's performance on out-of-distribution visual reasoning tasks to assess generalization beyond mathematical and structured reasoning domains
3. Analyze computational overhead of latent intervention process during inference and compare with end-to-end training alternatives for efficiency-cost trade-offs