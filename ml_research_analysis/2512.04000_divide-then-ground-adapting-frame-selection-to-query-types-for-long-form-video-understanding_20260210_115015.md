---
ver: rpa2
title: 'Divide, then Ground: Adapting Frame Selection to Query Types for Long-Form
  Video Understanding'
arxiv_id: '2512.04000'
source_url: https://arxiv.org/abs/2512.04000
tags:
- video
- frame
- query
- frames
- sampling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper tackles the challenge of efficiently applying large\
  \ multimodal models (LMMs) to long-form video understanding, constrained by limited\
  \ context lengths and high computational costs. The authors first identify and validate\
  \ a query typology\u2014global queries requiring holistic understanding and localized\
  \ queries targeting specific temporal segments\u2014and show that uniform sampling\
  \ works well for global queries but fails for localized ones."
---

# Divide, then Ground: Adapting Frame Selection to Query Types for Long-Form Video Understanding

## Quick Facts
- arXiv ID: 2512.04000
- Source URL: https://arxiv.org/abs/2512.04000
- Reference count: 40
- Primary result: DIG outperforms existing baselines in long-form video understanding by adapting frame selection to query types

## Executive Summary
This paper addresses the challenge of applying large multimodal models (LMMs) to long-form video understanding, which is constrained by limited context lengths and high computational costs. The authors identify that different query types—global queries requiring holistic understanding and localized queries targeting specific temporal segments—demand different frame selection strategies. They propose DIG, a training-free framework that adapts its approach based on query type: uniform sampling for global queries and a specialized pipeline for localized queries. Experiments on three long-form video benchmarks demonstrate consistent improvements over existing methods across input frame counts up to 256.

## Method Summary
The paper proposes DIG, a training-free frame selection framework that adapts its strategy based on query type. For global queries requiring holistic understanding, DIG employs uniform frame sampling. For localized queries targeting specific temporal segments, DIG uses a specialized pipeline: content-adaptive frame selection to identify relevant segments, LMM-based reward assignment to evaluate frame importance, and video refinement to optimize the final selection. The method first validates that uniform sampling works well for global queries but fails for localized ones, then builds the adaptive framework on this insight. Experiments show DIG consistently outperforms existing baselines across multiple benchmarks and input frame counts.

## Key Results
- DIG outperforms existing baselines on three long-form video benchmarks
- Uniform sampling is sufficient for global queries but inadequate for localized queries
- DIG improves LMM performance across input frame counts up to 256
- The framework achieves these results without requiring model retraining

## Why This Works (Mechanism)
The method works by recognizing that different query types have fundamentally different information needs. Global queries require understanding the overall context and narrative flow, making uniform sampling effective since it captures the video's progression. Localized queries, however, target specific events or segments, requiring adaptive selection that focuses computational resources on relevant portions while avoiding redundancy. By tailoring the frame selection strategy to match these distinct requirements, DIG optimizes both efficiency and accuracy. The LMM-based reward assignment for localized queries provides a way to evaluate and prioritize frames without additional training, making the approach both effective and practical.

## Foundational Learning

**Query Typology**: Understanding that queries can be categorized as global (requiring holistic understanding) or localized (targeting specific segments) is crucial for designing appropriate processing strategies.
- Why needed: Different query types have fundamentally different information requirements
- Quick check: Verify that query classification aligns with human intuition about information needs

**Frame Sampling Strategies**: Recognizing that uniform sampling works for some tasks but fails for others based on temporal distribution of relevant information.
- Why needed: Sampling strategy directly impacts both computational efficiency and answer quality
- Quick check: Compare answer quality using uniform vs. adaptive sampling on localized queries

**LMM-based Reward Assignment**: Using the same model that will answer questions to evaluate frame importance without requiring additional training.
- Why needed: Provides a training-free way to assess frame relevance while maintaining consistency with the final inference model
- Quick check: Validate that reward scores correlate with actual contribution to correct answers

## Architecture Onboarding

**Component Map**: Query Classifier -> Frame Selector (Uniform/Adaptive) -> LMM-based Reward Assignment -> Video Refinement -> LMM Inference

**Critical Path**: The most computationally intensive path occurs for localized queries: Query Classifier → Adaptive Frame Selector → LMM-based Reward Assignment → Video Refinement → LMM Inference

**Design Tradeoffs**: The framework trades increased computational complexity for localized queries against improved accuracy. Uniform sampling is computationally cheap but ineffective for localized queries, while the adaptive pipeline is more expensive but necessary for good performance on targeted questions.

**Failure Signatures**: Poor performance on localized queries when using uniform sampling, or excessive computational overhead when the adaptive pipeline is triggered unnecessarily for global queries.

**First Experiments**:
1. Compare answer accuracy using uniform sampling vs. adaptive selection on a set of localized queries
2. Measure computational overhead of LMM-based reward assignment across different video lengths
3. Test query classification accuracy on ambiguous queries that blend global and localized characteristics

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Query type identification assumes a binary distinction that may not hold across diverse real-world datasets
- LMM-based reward assignment computational overhead and scalability to longer videos are not addressed
- Experiments limited to three benchmarks may not capture full diversity of long-form video tasks

## Confidence

**High Confidence**: Empirical results showing DIG's superiority over baselines across multiple benchmarks and frame counts (up to 256)

**Medium Confidence**: Claim that uniform sampling is sufficient for global queries, as this may depend on specific nature of queries and videos

**Low Confidence**: Assertion that proposed pipeline is universally applicable without retraining, given lack of testing on out-of-distribution data

## Next Checks

1. **Generalization Test**: Evaluate DIG on a broader range of video datasets, including those with different characteristics (e.g., longer durations, varying frame rates, or different domains)

2. **Query Ambiguity Handling**: Test robustness of query type identification when faced with ambiguous or hybrid queries that do not clearly fit into global or localized categories

3. **Computational Efficiency Analysis**: Measure computational overhead of LMM-based reward assignment and assess its scalability to longer videos or more complex queries