---
ver: rpa2
title: 'Autoregressive Image Generation with Linear Complexity: A Spatial-Aware Decay
  Perspective'
arxiv_id: '2507.01652'
source_url: https://arxiv.org/abs/2507.01652
tags:
- image
- attention
- generation
- linear
- decay
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the computational inefficiency of transformer-based
  autoregressive image generation models, which suffer from quadratic complexity and
  memory overhead due to maintaining key-value caches. The authors propose LASADGen,
  which integrates a novel Linear Attention with Spatial-Aware Decay (LASAD) mechanism
  that preserves genuine 2D spatial relationships when processing flattened image
  sequences.
---

# Autoregressive Image Generation with Linear Complexity: A Spatial-Aware Decay Perspective

## Quick Facts
- arXiv ID: 2507.01652
- Source URL: https://arxiv.org/abs/2507.01652
- Reference count: 40
- Outperforms LlamaGen across all scales with FID scores of 4.86 (B), 2.90 (L), 2.58 (XL), and 2.36 (XXL) while maintaining linear computational complexity

## Executive Summary
This paper addresses the computational inefficiency of transformer-based autoregressive image generation models, which suffer from quadratic complexity and memory overhead due to maintaining key-value caches. The authors propose LASADGen, which integrates a novel Linear Attention with Spatial-Aware Decay (LASAD) mechanism that preserves genuine 2D spatial relationships when processing flattened image sequences. Unlike standard linear attention that treats 2D images as 1D sequences, LASAD computes position-dependent decay factors based on true 2D spatial locations, resetting attention states at row boundaries to prevent inappropriate information flow between spatially disconnected regions. Experiments on ImageNet at 256×256 resolution demonstrate that LASADGen achieves state-of-the-art performance with significantly improved computational efficiency.

## Method Summary
LASADGen introduces a spatial-aware decay mechanism that computes attention scores using Manhattan distance between pixels in the flattened sequence, while resetting attention states at row boundaries. This preserves genuine 2D spatial relationships in the 1D flattened representation, addressing a fundamental limitation of existing linear attention methods that treat 2D images as 1D sequences. The model demonstrates linear computational complexity while outperforming LlamaGen across multiple model scales (from 112M to 1.4B parameters) on ImageNet generation tasks.

## Key Results
- Achieves FID scores of 4.86 (B), 2.90 (L), 2.58 (XL), and 2.36 (XXL) on ImageNet 256×256
- Outperforms LlamaGen across all tested model scales
- Maintains linear computational complexity while achieving state-of-the-art performance
- Spatial-aware decay mechanism shown to be critical, with models lacking it suffering significant performance degradation

## Why This Works (Mechanism)
The spatial-aware decay mechanism addresses a fundamental limitation in existing linear attention methods: when flattening 2D images into 1D sequences, standard approaches lose genuine spatial relationships. LASAD computes position-dependent decay factors based on true 2D spatial locations using Manhattan distance, and critically resets attention states at row boundaries. This prevents inappropriate information flow between spatially disconnected regions that would otherwise occur when treating 2D images as 1D sequences, preserving the spatial context essential for high-quality image generation.

## Foundational Learning
1. **Linear Attention** - An approximation technique that reduces attention complexity from quadratic to linear by approximating softmax computations
   - Why needed: Quadratic attention becomes computationally prohibitive for high-resolution images
   - Quick check: Verify that attention scores decay appropriately with distance

2. **Spatial-Aware Decay** - Position-dependent decay factors computed using Manhattan distance in 2D space
   - Why needed: Standard linear attention loses 2D spatial relationships when flattening images
   - Quick check: Ensure row boundary resets prevent cross-row attention

3. **Autoregressive Image Generation** - Sequential generation where each pixel is predicted based on previously generated pixels
   - Why needed: Enables coherent image synthesis by maintaining spatial context
   - Quick check: Validate that generated images maintain global structure

4. **Key-Value Caching** - Mechanism for storing intermediate attention computations to improve efficiency
   - Why needed: Essential for autoregressive generation where past context must be maintained
   - Quick check: Confirm cache reset behavior at row boundaries

5. **Manhattan Distance** - Sum of absolute differences between coordinates in 2D space
   - Why needed: Provides computationally efficient spatial distance metric for decay computation
   - Quick check: Verify distance calculations are correct for all pixel pairs

6. **Flattened Sequence Processing** - Converting 2D image data into 1D sequences for transformer processing
   - Why needed: Enables application of 1D sequence models to 2D image data
   - Quick check: Ensure flattening preserves necessary spatial information

## Architecture Onboarding
Component map: Input Image -> Flattening -> Spatial-Aware Decay Layer -> Linear Attention -> Pixel Generation
Critical path: The spatial-aware decay layer is the core innovation that differentiates LASADGen from standard linear attention approaches
Design tradeoffs: Fixed Manhattan distance-based decay vs. learned distance metrics; computational efficiency vs. potential loss of complex spatial dependencies
Failure signatures: Performance degradation when spatial context is lost; inappropriate attention between spatially disconnected regions; failure to maintain image coherence
Three first experiments:
1. Compare generated images with and without spatial-aware decay to visualize the impact on spatial coherence
2. Test different decay functions (exponential, Gaussian) against the Manhattan distance baseline
3. Evaluate model performance across varying image aspect ratios to assess robustness

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the text provided.

## Limitations
- Spatial-aware decay mechanism relies on fixed Manhattan distance function that may not capture all complex spatial dependencies
- Experimental validation limited to ImageNet at 256×256 resolution, with limited exploration of other datasets
- Practical computational efficiency claims lack detailed profiling of absolute GPU memory usage and training time

## Confidence
High confidence: The core innovation of spatial-aware decay in linear attention is well-defined and the theoretical framework appears sound. The improvement over LlamaGen across multiple model scales is demonstrated with statistical significance.

Medium confidence: The claim of "state-of-the-art performance" is supported within the specific experimental context but may not generalize to all image generation benchmarks or competing methods not included in the comparison.

Low confidence: The long-term stability and generalization of LASADGen to out-of-distribution images or different domains (e.g., medical imaging, satellite imagery) is not established.

## Next Checks
1. Evaluate LASADGen on additional image datasets with varying characteristics (e.g., CIFAR-10 for small images, LSUN for higher resolution, and domain-specific datasets) to assess generalization across different image types and resolutions.

2. Conduct ablation studies with different decay functions (e.g., exponential decay, Gaussian decay) and distance metrics (e.g., Euclidean distance, learned distance metrics) to determine whether the current Manhattan distance-based decay is optimal.

3. Perform computational profiling to measure actual GPU memory usage and training time compared to quadratic attention baselines, particularly for larger batch sizes and higher resolution images, to validate the practical efficiency claims.