---
ver: rpa2
title: 'Hadamax Encoding: Elevating Performance in Model-Free Atari'
arxiv_id: '2505.15345'
source_url: https://arxiv.org/abs/2505.15345
tags:
- encoder
- learning
- hadamax
- performance
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes Hadamax, a novel encoder architecture for model-free
  Atari reinforcement learning. Hadamax applies max-pooling to Hadamard products between
  parallel GELU-activated hidden layers, replacing convolutional strides with max-pooling
  and introducing Hadamard representations to increase effective rank without scaling
  network size.
---

# Hadamax Encoding: Elevating Performance in Model-Free Atari

## Quick Facts
- **arXiv ID:** 2505.15345
- **Source URL:** https://arxiv.org/abs/2505.15345
- **Reference count:** 40
- **Primary result:** Hadamax-PQN achieves 80% performance gain over vanilla PQN on Atari-57 and surpasses Rainbow-DQN.

## Executive Summary
Hadamax introduces a novel encoder architecture for model-free Atari reinforcement learning that leverages Hadamard products and max-pooling to increase effective feature rank without scaling network size. By replacing convolutional strides with max-pooling and applying Hadamard representations to parallel GELU-activated hidden layers, Hadamax significantly improves learning efficiency. Applied to the PQN algorithm without hyperparameter modifications, Hadamax-PQN achieves competitive scores at 90M frames instead of 260M frames, representing an 80% performance gain over vanilla PQN and surpassing Rainbow-DQN on the Atari-57 benchmark.

## Method Summary
The Hadamax encoder architecture consists of three convolutional blocks that use parallel convolutional layers with stride=1, followed by LayerNorm, GELU activation, element-wise multiplication (Hadamard product), and max-pooling for downsampling. This design increases the effective rank of learned representations while maintaining computational efficiency. The encoder is trained using the PQN algorithm with λ-return loss, operating on 4 stacked 64x64 grayscale frames from Atari games. The architecture includes specific initialization schemes (Xavier normal for Conv, He normal for Dense) and uses RAdam optimizer with gradient clipping.

## Key Results
- Hadamax-PQN achieves 80% performance gain over vanilla PQN on Atari-57 benchmark
- Surpasses Rainbow-DQN performance on Atari-57 while training at 90M frames instead of 260M frames
- Generalizes to C51, improving performance by approximately 70% on Atari-10
- Ablation studies show max-pooling is the most critical component, followed by Hadamard representations and GELU activation

## Why This Works (Mechanism)
The effectiveness of Hadamax stems from its ability to increase the effective rank of feature representations without scaling network parameters. By using Hadamard products between parallel GELU-activated layers, the architecture creates higher-dimensional interaction features that capture more complex patterns. Max-pooling provides efficient downsampling while preserving important spatial information, and the combination of these techniques allows for better feature extraction at lower computational cost compared to traditional convolutional approaches.

## Foundational Learning
- **Hadamard Product:** Element-wise multiplication of matrices - needed for creating interaction features between parallel representations; quick check: verify output shape matches input dimensions
- **Max-Pooling:** Downsampling operation that takes maximum value in local regions - needed for efficient spatial reduction without stride convolutions; quick check: confirm downsampling factor matches architectural specifications
- **GELU Activation:** Gaussian Error Linear Unit - needed for smooth, non-linear activation that works well with LayerNorm; quick check: verify output range is approximately [-1, 1] after LayerNorm
- **Layer Normalization:** Normalizes across feature dimensions - needed to prevent dead neurons when applying Hadamard products; quick check: monitor activation distributions for stability
- **λ-return:** TD(λ) style return calculation - needed for stable temporal credit assignment in PQN; quick check: verify return calculation matches theoretical formulation
- **Atari-57 Benchmark:** Standard suite of 57 Atari 2600 games - needed for comprehensive evaluation of RL algorithms; quick check: confirm all 57 games are included with proper preprocessing

## Architecture Onboarding

**Component Map:** Input Frames -> Parallel Conv Blocks -> Hadamard Products -> Max-Pooling -> Dense Layers -> Output Q-values

**Critical Path:** The encoder's three convolutional blocks form the critical path, where each block applies two parallel convolutions (stride=1), LayerNorm, GELU activation, Hadamard product, and max-pooling. This sequence is crucial for maintaining gradient flow while increasing feature rank.

**Design Tradeoffs:** The architecture trades increased feature interaction complexity (via Hadamard products) for reduced parameter count compared to deeper networks. Max-pooling replaces stride convolutions to preserve information while reducing spatial dimensions. LayerNorm before activation prevents dead neurons but adds computational overhead.

**Failure Signatures:** Dead neurons appear as zero gradients in Hadamard product outputs, often caused by improper LayerNorm placement or ReLU activation. Instability manifests as training divergence when learning rate is too high or when applying to non-PQN algorithms without stability modifications.

**3 First Experiments:**
1. Implement a single Hadamax block and verify Hadamard product output dimensions and gradient flow
2. Compare max-pooling vs stride convolution downsampling on a simple feature extraction task
3. Test LayerNorm placement (before vs after activation) on Hadamard product stability

## Open Questions the Paper Calls Out
- How can the Hadamax encoder be effectively scaled in width or depth to further improve performance? (Direct deepening to 5 or 7 layers degrades performance; successful scaling strategies remain unexplored)
- Can augmenting Hadamax-PQN with novel exploration techniques bridge the performance gap with model-based algorithms in hard-exploration games? (Struggles with sparse reward environments under epsilon-greedy regime)
- Does integrating a Mixture of Experts (MoE) prediction head with the Hadamax encoder yield further performance improvements? (Specific unexplored research direction mentioned in Section 6)

## Limitations
- Performance gains are demonstrated primarily on PQN and C51 algorithms, with unclear generalizability to other RL methods
- Computational efficiency claims focus on sample efficiency rather than wall-clock time or memory usage
- Struggles with hard-exploration games due to epsilon-greedy exploration regime
- Optimal 3-layer architecture may limit potential for further architectural improvements through simple scaling

## Confidence
- **High Confidence:** Architectural improvements (Hadamard products, max-pooling, GELU activation) and their individual contributions as identified by ablation studies; median human-normalized score improvements over PQN and Rainbow-DQN
- **Medium Confidence:** Claim of achieving competitive scores at 90M frames instead of 260M; exact comparison metrics and statistical significance across all 57 games are not fully detailed
- **Low Confidence:** Generalizability to other RL algorithms or domains beyond tested cases (PQN and C51 on Atari); broader applicability evidence is lacking

## Next Checks
1. Apply Hadamax to other model-free RL algorithms (e.g., DQN, Rainbow, IMPALA) on Atari-57 to verify consistent performance gains
2. Evaluate Hadamax on non-Atari benchmarks (e.g., DM Control Suite, ProcGen) to assess effectiveness in different environments and task types
3. Measure and compare wall-clock training time, memory usage, and FLOPs between Hadamax and baseline encoders to quantify practical efficiency improvements