---
ver: rpa2
title: Dynamic Parameter Optimization for Highly Transferable Transformation-Based
  Attacks
arxiv_id: '2511.11993'
source_url: https://arxiv.org/abs/2511.11993
tags:
- attacks
- transferability
- parameters
- surrogate
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of insufficient parameter optimization
  in transformation-based adversarial attacks, which limits their transferability.
  The authors identify three key issues: (1) attacks are typically evaluated under
  low-iteration settings, but performance differs significantly at higher iterations;
  (2) existing attacks use uniform parameters across different models, iterations,
  and tasks; and (3) traditional grid search for parameter optimization has high computational
  complexity.'
---

# Dynamic Parameter Optimization for Highly Transferable Transformation-Based Attacks

## Quick Facts
- arXiv ID: 2511.11993
- Source URL: https://arxiv.org/abs/2511.11993
- Reference count: 9
- Primary result: Re-optimized transformation parameters improve transferability by 3.2% (untargeted) to 13.9% (targeted) across multiple attacks.

## Executive Summary
This paper addresses the problem of insufficient parameter optimization in transformation-based adversarial attacks, which limits their transferability. The authors identify three key issues: (1) attacks are typically evaluated under low-iteration settings, but performance differs significantly at higher iterations; (2) existing attacks use uniform parameters across different models, iterations, and tasks; and (3) traditional grid search for parameter optimization has high computational complexity. To address these limitations, the authors propose a Dynamic Parameter Optimization (DPO) method based on the observation that transferability follows a rise-then-fall pattern with respect to transformation magnitude. They introduce the Concentric Decay Model (CDM) to explain the distribution of plausible models around the surrogate and how transformation parameters affect transferability. DPO reduces optimization complexity from O(mn) to O(nlog²m) using a bisection-based approach.

## Method Summary
The Dynamic Parameter Optimization (DPO) method dynamically tunes transformation parameters (e.g., noise level, rotation angle) for each surrogate model, attack iteration count, and task (targeted/untargeted). It is built on the observation that transferability follows a rise-then-fall pattern with respect to transformation magnitude. DPO uses a bisection-based algorithm (Algorithm 1) to efficiently search for optimal parameters by evaluating attack success rates (ASR) on a set of validation models. The method assumes that the distribution of plausible models around the surrogate decreases concentrically in KL-divergence space, and that optimal transformation magnitudes grow with iterations and vary across surrogate models. DPO is applied to existing transformation-based attacks like Admix, SSIM, STM, and BSR, significantly improving their transferability compared to fixed-parameter baselines.

## Key Results
- DPO reduces optimization complexity from O(mn) to O(nlog²m) using bisection search.
- Average ASR improvements: 3.2% in untargeted settings and up to 13.9% in targeted settings.
- Optimal parameters differ notably between surrogate models (e.g., R50 vs. ViT-S/16) and between targeted vs. untargeted attacks.
- Against adversarially trained models, DPO-equipped attacks achieve 7.8% to 12.9% average gains in targeted settings.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Transferability follows a **rise-then-fall pattern** with respect to transformation magnitude because the density of "plausible models" (those consistent with real models) around the surrogate decays concentrically outward in KL-divergence space.
- **Mechanism**: Transformations with smaller magnitudes emulate models closer to the surrogate (low KL), covering fewer plausible models but less noise from implausible models. Larger magnitudes expand the KL surface, covering more plausible models but also more implausible ones that act as perturbation noise, impairing transferability past an optimum.
- **Core assumption**: Plausible models cluster near the surrogate in KL-divergence space; implausible models dominate farther away.
- **Evidence anchors**:
  - [abstract] "transferability follows a rise-then-fall pattern with respect to transformation magnitude"
  - [section 3.3] "the density of plausible models around the surrogate decreases concentrically in the KL-divergence space... larger magnitudes... introduce more noise from implausible models, thereby may impair transferability"
  - [corpus] Neighbors discuss transferability techniques but do not directly validate the concentric decay assumption; corpus evidence for CDM is weak.
- **Break condition**: If plausible models do not decay concentrically in KL space, the rise-then-fall explanation fails.

### Mechanism 2
- **Claim**: **Optimal transformation magnitudes grow with iterations** because perturbations progressively better approximate the average vulnerability within a KL surface as iteration count increases.
- **Mechanism**: At low iterations, perturbations underfit the average vulnerability within a KL surface, favoring smaller surfaces (smaller parameters). As iterations increase, capacity to fit larger surfaces grows, shifting the optimum toward larger magnitudes; too-large surfaces still add noise, preserving rise-then-fall.
- **Core assumption**: The same KL surface has a "learning capacity" that increases with iterations; low-iteration transferability underestimates high-iteration potential.
- **Evidence anchors**:
  - [abstract] "optimal transformation magnitudes grow with iterations and vary across surrogate models"
  - [section 3.2 & 3.3] "adversarial perturbations insufficiently fit the average vulnerability within surface KL = k, preventing them from reflecting the transferability at sufficiently higher iterations"
  - [corpus] No direct corpus validation found for iteration dynamics; evidence is weak.
- **Break condition**: If optimal parameters do not increase with iterations on new architectures/tasks, the underfitting/overfitting explanation may not generalize.

### Mechanism 3
- **Claim**: **Optimal parameters vary across surrogate models and between targeted vs. untargeted tasks** because the distribution of plausible models around each surrogate differs.
- **Mechanism**: Each surrogate has a distinct local topology of plausible models in KL space; targeted attacks, which steer toward a specific label, may prefer different KL regions than untargeted attacks, shifting the rise-then-fall optimum.
- **Core assumption**: Density and angular distribution of plausible models are surrogate- and task-specific, not universal.
- **Evidence anchors**:
  - [abstract] "optimal transformation magnitudes grow with iterations and vary across surrogate models"
  - [section 4.2.2] "optimal parameters differ notably between untargeted and targeted attacks"
  - [corpus] No direct corpus support for surrogate/task-specific parameter dynamics; evidence is weak.
- **Break condition**: If parameters prove universal across surrogates/tasks, the CDM explanation requires revision.

## Foundational Learning

- **Concept: KL-divergence and model output distributions**
  - **Why needed here**: CDM quantifies how transformations move emulated models away from the surrogate in KL space; understanding KL divergence is essential to interpret why plausible models decay concentrically.
  - **Quick check question**: If two models have identical output distributions, what is their KL divergence? (Answer: Zero; KL divergence is zero when distributions match exactly.)

- **Concept: Rise-then-fall (unimodal) optimization landscape**
  - **Why needed here**: DPO exploits the rise-then-fall pattern to use bisection; recognizing unimodal landscapes is critical to avoid premature convergence or invalid assumptions.
  - **Quick check question**: Why does bisection work on a unimodal function but fail on a multimodal one? (Answer: Bisection assumes a single peak; on multimodal functions it may converge to a local, not global, optimum.)

- **Concept: Transformation-based adversarial attacks (e.g., DIM, TIM, SIM)**
  - **Why needed here**: DPO is applied to existing attacks like Admix, SSIM, STM, BSR; understanding how input transformations stabilize perturbation direction clarifies why parameter dynamics matter.
  - **Quick check question**: How does averaging perturbations from multiple transformed inputs reduce surrogate overfitting? (Answer: It smooths gradient direction, preventing reliance on surrogate-specific features.)

## Architecture Onboarding

- **Component map**: Transformation module (T) parameterized by z → KL surface boundary (k) → Surrogate model (f_S) + T(z) composition → emulated model distribution → Iterative attack loop (MI-FGSM) → perturbation updates → Validation model set → parameter scoring → Bisection-based DPO → parameter optimizer

- **Critical path**:
  1. Define parameter search intervals (e.g., rotation 20°–160°, noise 0.02–0.5)
  2. For each parameter dimension, run bisection (Algorithm 1)
  3. At each bisection step, generate adversarial examples, evaluate on validation models
  4. Select parameter half-region based on ASR comparison
  5. Output optimized z* for given surrogate/iteration/task

- **Design tradeoffs**:
  - **Bisection vs. grid search**: Bisection reduces complexity from O(m^n) to O(n log² m) but assumes rise-then-fall unimodality; may miss global optima if landscape is irregular.
  - **Validation model selection**: More diverse validation models improve generalization but increase optimization cost.
  - **Fixed vs. joint parameter optimization**: Current approach optimizes parameters sequentially (e.g., b first, then r for BSR); joint optimization may be better but is computationally expensive.

- **Failure signatures**:
  - ASR degrades after optimization (possible causes: validation models too similar to surrogate, bisection stuck in local region, rise-then-fall assumption violated)
  - Optimized parameters oscillate without convergence (possible causes: noisy ASR estimates, non-unimodal landscape)
  - Large gap between validation and test ASR (possible causes: overfitting to validation model set)

- **First 3 experiments**:
  1. **Reproduce rise-then-fall pattern**: Fix a transformation (e.g., Noise Addition), sweep z from 0.02 to 0.5, plot ASR vs. z at Epochs 2, 50, 100, 500 on 2–3 test models to confirm unimodality.
  2. **Validate iteration-dependent shift**: For a single surrogate (e.g., R50), run DPO at Epoch 10, 50, 100; verify that optimized z increases with iterations as claimed.
  3. **Surrogate comparison**: Run DPO for R50 vs. ViT-S/16 at fixed iteration (e.g., 100); confirm that optimal parameters differ, supporting surrogate-specific dynamics.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How do transferability dynamics and optimal transformation parameters behave when the attack iteration count significantly exceeds the 500-iteration cap investigated in this study?
- **Basis in paper**: [explicit] The authors explicitly state in the conclusion, "our investigation is capped at 500 iterations. The dynamics at higher iterations remain an intriguing topic for future study."
- **Why unresolved**: The study was computationally limited to a maximum of 500 iterations, leaving the long-term convergence behavior of the rise-then-fall pattern unexplored.
- **What evidence would resolve it**: Empirical results tracking the optimal parameters and attack success rates (ASR) of DPO-equipped attacks at iterations significantly greater than 500 (e.g., 1000, 5000).

### Open Question 2
- **Question**: Can optimal transformation parameters be determined theoretically or estimated without reliance on a proxy set of validation models?
- **Basis in paper**: [inferred] The proposed Dynamic Parameter Optimization (DPO) relies on evaluating adversarial examples on a specific set of "validation models" (Algorithm 1) to guide the bisection search.
- **Why unresolved**: The paper establishes that optimal parameters vary by surrogate, but the method requires access to other models to find these parameters, which may not always be available to an attacker.
- **What evidence would resolve it**: A derivation allowing the prediction of optimal parameters based solely on the surrogate model's intrinsic properties (e.g., loss landscape curvature) without external validation feedback.

### Open Question 3
- **Question**: Does the Concentric Decay Model (CDM) and the associated rise-then-fall transferability pattern hold for data modalities other than image classification, such as natural language processing or audio?
- **Basis in paper**: [inferred] The empirical analysis and the proposed CDM are constructed exclusively around image classification tasks using CNNs and Vision Transformers.
- **Why unresolved**: The distribution of "plausible models" in KL-divergence space may differ fundamentally in sequential or audio data domains compared to the image domain.
- **What evidence would resolve it**: Experiments applying transformation-based attacks with DPO to text or audio classifiers to verify if the dynamic patterns (i-iii) persist.

## Limitations

- The concentric decay model (CDM) assumes plausible models decay concentrically in KL space around the surrogate, but this geometric assumption is difficult to validate without explicit access to model output distributions.
- Optimal parameter dynamics across iterations and surrogates rely on empirical observations that may not generalize beyond tested architectures and datasets.
- The bisection-based DPO assumes unimodal rise-then-fall landscapes; real-world ASR surfaces may be noisy or multimodal, risking suboptimal convergence.

## Confidence

- **High**: The empirical improvement of DPO over fixed-parameter baselines (3.2-13.9% ASR gains) is well-supported by experimental results.
- **Medium**: The theoretical rise-then-fall explanation is plausible but not rigorously proven; CDM provides an intuitive framework but requires further validation.
- **Low**: The claim that plausible models decay concentrically in KL space is speculative and difficult to falsify without access to model ensemble distributions.

## Next Checks

1. **Validate CDM assumption**: For a fixed surrogate, generate multiple transformations, measure KL divergence between transformed and original outputs, and empirically test whether plausible models (those achieving high ASR) concentrate near the surrogate in KL space.
2. **Cross-dataset generalization**: Apply DPO to a different dataset (e.g., CIFAR-10) and verify whether optimal parameters shift with iterations and surrogate models as predicted.
3. **Robustness to initialization**: Run DPO multiple times with different random seeds and validation model subsets to ensure results are not artifacts of specific initialization choices.