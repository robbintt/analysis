---
ver: rpa2
title: 'UPRPRC: Unified Pipeline for Reproducing Parallel Resources -- Corpus from
  the United Nations'
arxiv_id: '2509.15789'
source_url: https://arxiv.org/abs/2509.15789
tags:
- corpus
- alignment
- parallel
- paragraph
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work presents a fully reproducible end-to-end pipeline for\
  \ constructing large-scale parallel corpora from United Nations documents, addressing\
  \ challenges of transparency, scalability, and alignment accuracy. The core innovation\
  \ is a Graph-Aided Paragraph Alignment (GAPA) algorithm that enables flexible M\u2013\
  N paragraph-level mapping via bipartite graph construction and Longest Common Subsequence\
  \ (LCS) detection, outperforming traditional sentence-level approaches."
---

# UPRPRC: Unified Pipeline for Reproducing Parallel Resources -- Corpus from the United Nations

## Quick Facts
- arXiv ID: 2509.15789
- Source URL: https://arxiv.org/abs/2509.15789
- Reference count: 0
- Primary result: 713M+ English tokens across 162k+ fully aligned UN documents

## Executive Summary
This work presents a fully reproducible end-to-end pipeline for constructing large-scale parallel corpora from United Nations documents, addressing challenges of transparency, scalability, and alignment accuracy. The core innovation is a Graph-Aided Paragraph Alignment (GAPA) algorithm that enables flexible M–N paragraph-level mapping via bipartite graph construction and Longest Common Subsequence (LCS) detection, outperforming traditional sentence-level approaches. The resulting corpus contains over 713 million English tokens across 162k fully aligned documents, more than doubling prior UN-based resources in size and coverage (2000–2023). An optional distributed computing mode supports scalability. The entire pipeline, including data crawling, table processing, and alignment, is open-sourced, enabling community verification and extension. LLM-based evaluation shows high alignment accuracy (>94%) at a conservative hit-rate threshold, with human audits confirming reliability. This represents the largest publicly available human-translated, non-AI-generated parallel corpus, offering significant value for machine translation research and multilingual language modeling.

## Method Summary
The UPRPRC pipeline constructs parallel corpora through a four-stage process: (1) Web scraping of UN Digital Library API for DOC/DOCX/PDF documents across six official languages; (2) Format verification and text extraction using Microsoft Word COM automation and Pandoc, with ASCII-style table flattening to prevent layout disruption; (3) Machine translation of non-English paragraphs to English using Argos Translate v1.9.6; and (4) Graph-Aided Paragraph Alignment (GAPA) that maps documents to bipartite graphs via LCS detection, filters nodes by hit rate (h_c=0.3), and extracts connected components as aligned paragraph pairs. The pipeline supports distributed execution and outputs in JSONL/HuggingFace format.

## Key Results
- Corpus size: 713M+ English tokens, 162k+ fully aligned documents (2000–2023)
- GAPA algorithm achieves >94% alignment accuracy via LLM evaluation (GPT-4: 94.1%, Qwen2: 98.1%, ChatGLM3: 99.0%)
- Outperforms prior UN-based resources by >2x in size and coverage
- Handles table structures and enables flexible M–N paragraph mappings

## Why This Works (Mechanism)

### Mechanism 1: Graph-Aided Paragraph Alignment (GAPA)
The GAPA algorithm enables flexible M-to-N paragraph alignment by reducing text matching to a connected component problem in a bipartite graph. The pipeline translates non-English paragraphs to English using Argos Translate, then identifies the Longest Common Subsequence (LCS) between the translated source and original English document. Each LCS match creates a "link" between two paragraph nodes in a bipartite graph. Connected subgraphs are merged to form the final aligned blocks (e.g., 1 source paragraph → 2 target paragraphs). Core assumption: Machine Translation quality is sufficient to generate overlapping vocabulary sequences (LCS) between source and target, and shared words indicate semantic correspondence rather than coincidence. Break condition: If the MT engine fails to produce cognates or synonyms present in the target text, the LCS will be empty, resulting in disconnected graph components and data loss.

### Mechanism 2: Noise Filtering via LCS Hit Rate
Filtering links based on an "LCS hit rate" (character coverage ratio) likely removes spurious connections caused by high-frequency common words. The algorithm calculates the ratio of characters belonging to the LCS within a specific paragraph. If the ratio falls below a threshold (h_c = 0.3), the links for that node are removed. This prevents common stop-words (e.g., "the", "is") from generating false positive links between unrelated paragraphs. Core assumption: Valid parallel paragraphs share substantial content vocabulary, whereas noise consists primarily of short, frequent function words. Break condition: Highly succinct or summarized translations where content words differ significantly might fall below the 0.3 threshold, leading to the erroneous discarding of valid parallel text.

### Mechanism 3: Table Flattening for Context Preservation
Converting complex table structures into linearized text rows purportedly prevents alignment fragmentation and information loss. Instead of ignoring tables or treating cells as isolated sentences, the pipeline detects grid patterns (ASCII-style) and flattens them into single "sentence-like" spans. This ensures that data embedded in tables contributes to the paragraph-level alignment context. Core assumption: The semantic content of a table row functions similarly to a sentence for the purpose of cross-lingual alignment. Break condition: Highly nested or irregular table layouts may fail the regex detection, resulting in either garbled text or the exclusion of valid data.

## Foundational Learning

- **Concept: Bipartite Graph Matching**
  - Why needed here: This is the mathematical structure underlying GAPA. Understanding it is required to modify the alignment logic or debug why specific paragraphs are connected (or not).
  - Quick check question: Given two sets of nodes (Source Paragraphs, Target Paragraphs), can you explain how an edge is created and how a "connected component" defines a specific M-N merge?

- **Concept: Longest Common Subsequence (LCS)**
  - Why needed here: LCS serves as the "matching signal" or edge generator in the graph. Unlike Edit Distance, it strictly measures the longest shared sequence, which determines which paragraphs link together.
  - Quick check question: If Paragraph A is "The cat sat" and Paragraph B is "The cat", what is the LCS? If the translation of A is "A dog sat", what happens to the LCS length?

- **Concept: Pivot-based Alignment**
  - Why needed here: The pipeline translates all languages to English (the pivot) to perform alignment. This relies on the quality of the intermediate translation (Argos) to bridge the gap between source and target.
  - Quick check question: Why might aligning via a pivot language (Source → Pivot → Target) introduce more error than direct alignment, and what benefit (e.g., dimensionality reduction) does it provide?

## Architecture Onboarding

- **Component map:** Ingestion: UN Digital Library API → Raw DOC/PDF download → Preprocessing: Word/Pandoc conversion → Table Flattening → Text Extraction → Pivot Gen: Argos Translate (Offline NMT) → English-translated text → Alignment Core: LCS Engine → Bipartite Graph Builder → Hit-Rate Filter → Component Aggregation → Output: JSONL / HuggingFace Datasets

- **Critical path:** The LCS Calculation and Graph Construction (Alignment Core) are the bottlenecks. While linearithmic O(N log N), they must process the full token volume of the corpus.

- **Design tradeoffs:**
  - Threshold (h_c): The paper selects 0.3. Lowering this increases recall (more data) but lowers precision (more misaligned pairs); raising it does the inverse.
  - Paragraph vs. Sentence: The authors chose paragraph-level to handle M-N merges better, but this requires the context window of the MT engine to handle longer text.

- **Failure signatures:**
  - Low "Hit Rate" stats: If the average h_c drops during a new run, it may indicate the MT model has changed or degraded.
  - Empty Graph: If the LCS step fails to find matches, the output will be empty. This often happens if the source text is effectively untranslated or the wrong language pair is processed.

- **First 3 experiments:**
  1. Reproducibility Check: Run the provided "minimalist single-machine example" on a sample of 10 documents to verify the environment setup (Pandoc + Argos + Python).
  2. Threshold Sensitivity: Manually inspect the alignment of 50 documents at h_c=0.1 vs h_c=0.5 to see the trade-off between noise and coverage.
  3. Table Integrity: Input a document with a complex table and inspect the intermediate .txt file to see if the "flattening" logic preserved the data in a readable linear format.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the strict, "any-error-is-bad" document-level alignment accuracy correlate with human judgment for non-English language pairs?
- **Basis in paper:** The authors explicitly state in Section 4.3 that the human vs. LLM audit was "English-Only" and "No other languages are included in this audit," despite the corpus covering six languages.
- **Why unresolved:** It is unclear if the high LLM-evaluated accuracy (e.g., 98-99%) generalizes to languages with distinct morphological structures or non-Latin scripts (e.g., Arabic, Chinese, Russian) where alignment noise might present differently.
- **What evidence would resolve it:** A comparative human evaluation study across all supported languages (specifically ar, zh, ru) comparing LLM judgments against ground truth.

### Open Question 2
- **Question:** Can the pipeline be extended to robustly extract and align parallel text from PDF documents?
- **Basis in paper:** Section 3.2 notes that "attempts to programmatically extract clean paragraph text from PDFs were unsuccessful," leading the authors to explicitly "skip these files."
- **Why unresolved:** A significant portion of official documentation may exist solely or primarily in PDF format. Excluding them potentially limits the corpus's comprehensiveness and introduces a format-selection bias.
- **What evidence would resolve it:** Successful integration of a PDF parsing module (e.g., using layout-aware models) that maintains the paragraph structure required by GAPA without significant text extraction errors.

### Open Question 3
- **Question:** How sensitive is the GAPA algorithm to the quality and idiosyncrasies of the specific machine translation engine (Argos) used for generating intermediate English text?
- **Basis in paper:** The method relies on translating non-English paragraphs into English to calculate the Longest Common Subsequence (LCS). If the intermediate MT system produces systematic errors or hallucinations, the LCS "hit rate" threshold (h_c) may filter out valid parallel data or retain misaligned segments.
- **Why unresolved:** The paper does not ablate the choice of the translation engine or analyze how translation errors propagate into graph construction and subsequent alignment decisions.
- **What evidence would resolve it:** An ablation study comparing GAPA performance using different intermediate translation engines (e.g., comparing Argos against a high-resource commercial API) on a fixed document set.

## Limitations
- Pipeline requires proprietary Microsoft Word 2019 for DOCX conversion, limiting fully open-source reproducibility
- Pivot-based alignment through Argos Translate introduces potential error propagation without quantified impact
- PDF documents are excluded entirely, potentially missing valuable parallel content

## Confidence

**High Confidence:**
- The GAPA algorithm's core mechanism (LCS-based bipartite graph construction) is clearly described and theoretically sound
- Corpus statistics (713M+ tokens, 162k+ documents) are verifiable through the published dataset
- The open-source pipeline enables community verification of the alignment process

**Medium Confidence:**
- Alignment accuracy metrics from LLM judges are reported consistently but not independently verified
- Table flattening's effectiveness is supported by feature comparison but lacks detailed quantitative evaluation
- The h_c=0.3 threshold is justified theoretically but optimal values for different language pairs are not explored

**Low Confidence:**
- Distributed computing scalability claims lack empirical validation
- The impact of translation quality on alignment accuracy is not quantified
- Long-term maintenance of the pipeline as UN document formats evolve is not addressed

## Next Checks
1. **Human Validation Audit:** Conduct a blind human evaluation of 100 randomly selected aligned paragraph pairs across 3 language pairs to independently verify the LLM accuracy claims and identify systematic alignment errors.

2. **Table Structure Stress Test:** Create a test suite with progressively complex table structures (nested tables, merged cells, irregular formats) to measure the failure rate of the table flattening logic and identify patterns in data loss.

3. **Translation Quality Impact Analysis:** Run the alignment pipeline using two different MT engines (Argos vs. a commercial API) on the same document subset to quantify how translation quality variations affect LCS detection rates and final alignment accuracy.