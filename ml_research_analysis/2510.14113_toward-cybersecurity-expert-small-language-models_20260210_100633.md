---
ver: rpa2
title: Toward Cybersecurity-Expert Small Language Models
arxiv_id: '2510.14113'
source_url: https://arxiv.org/abs/2510.14113
tags:
- security
- cybersecurity
- evaluation
- arxiv
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CyberPal 2.0 introduces a family of cybersecurity-expert small
  language models (SLMs) ranging from 4B-20B parameters. The approach uses an enriched
  chain-of-thought cybersecurity instruction dataset built with a data enrichment
  and formatting pipeline, SecKnowledge 2.0, which integrates expert-in-the-loop steering
  of reasoning formats alongside LLM-driven multi-step grounding.
---

# Toward Cybersecurity-Expert Small Language Models

## Quick Facts
- arXiv ID: 2510.14113
- Source URL: https://arxiv.org/abs/2510.14113
- Reference count: 40
- Primary result: CyberPal 2.0 outperforms frontier models on cybersecurity benchmarks using 4B-20B parameter SLMs

## Executive Summary
CyberPal 2.0 introduces a family of cybersecurity-expert small language models ranging from 4B to 20B parameters. The approach uses an enriched chain-of-thought cybersecurity instruction dataset built with a data enrichment and formatting pipeline, SecKnowledge 2.0, which integrates expert-in-the-loop steering of reasoning formats alongside LLM-driven multi-step grounding. Across diverse cybersecurity benchmarks, CyberPal 2.0 consistently outperforms its baselines and matches or surpasses various open and closed-source frontier models while remaining a fraction of their size.

## Method Summary
CyberPal 2.0 is built by fine-tuning base models (Qwen3-4B through 20B) on SecKnowledge 2.0, an enriched cybersecurity instruction dataset. The dataset creation pipeline uses expert-in-the-loop schema-driven format generation and multi-step grounding with query building and filtering. Models are trained for 2 epochs with partial loss on prompts, mixing chain-of-thought and short responses, from base checkpoints rather than post-trained models.

## Key Results
- CyberPal 2.0-20B outperforms GPT-4o, o1, o3-mini, and Sec-Gemini v1 on core threat-investigation tasks
- The 4B-parameter model ranks second on threat-investigation tasks while being significantly smaller
- On core cyber threat intelligence knowledge tasks, models rank second only to Sec-Gemini v1

## Why This Works (Mechanism)

### Mechanism 1: Expert-in-the-Loop Schema-Driven Format Generation
Domain experts semi-automatically defining task-specific output formats improves reasoning structure and downstream performance compared to generic reformatting approaches. The system partitions the dataset into tasks (105 unique tasks), then uses an LLM to generate candidate output formats conditioned on task descriptions and examples. Experts iteratively evaluate and edit these formats through a tight feedback loop, running the full pipeline on representative inputs and reviewing LLM-as-a-Judge scores for readability and factuality before finalizing.

### Mechanism 2: Multi-Step Grounding with Query Building and Filtering
Retrieving and conditioning on external evidence during response reformatting reduces hallucinations and improves factual accuracy. For each instruction, an LLM generates K candidate search queries; a second LLM filters queries expected to provide new information; filtered queries retrieve R results from vector databases or web search; documents are parsed and optionally summarized; the reformatting LLM conditions on this evidence when rewriting responses.

### Mechanism 3: Base Model Initialization with Adaptive Reasoning Training
Fine-tuning from base models (rather than post-trained models) with mixed CoT and short-response data yields stronger domain adaptation. Models are trained from base checkpoints (Qwen3-4B-base, etc.) using SecKnowledge 2.0, mixing long-form CoT examples (with "step-by-step" requests) with ~25% short, high-quality examples from the original dataset. Training uses partial loss on prompts rather than full masking.

## Foundational Learning

- **Concept: Chain-of-Thought (CoT) Reasoning**
  - **Why needed here:** The entire SecKnowledge 2.0 pipeline is built around expanding concise answers into explicit, step-by-step reasoning traces; evaluation also uses zero-shot CoT prompting.
  - **Quick check question:** Can you explain why prompting a model to "think step-by-step" improves performance on multi-step reasoning tasks?

- **Concept: Instruction Fine-Tuning and Loss Masking**
  - **Why needed here:** CyberPal 2.0 is trained via supervised fine-tuning on formatted instruction-response pairs; the paper discusses retaining partial loss on prompts vs. masking.
  - **Quick check question:** What is the difference between training with full loss on prompts versus masking prompt tokens, and why might partial retention help?

- **Concept: Cybersecurity Taxonomies (CWE, CVE, MITRE ATT&CK)**
  - **Why needed here:** Core benchmarks (CTIBench-RCM, Adversarial CTI, Relationship Prediction) require mapping between CVEs, CWEs, and ATT&CK TTPs; format schemas are taxonomy-aware.
  - **Quick check question:** What is the difference between a CVE and a CWE, and why might mapping between them require document-grounded reasoning?

## Architecture Onboarding

- **Component map:** SecKnowledge 2.0 dataset -> Expert-in-the-loop format generator -> Multi-step grounding pipeline -> Training pipeline -> Evaluation suite

- **Critical path:**
  1. Partition dataset into tasks and generate formats via expert-in-the-loop system
  2. Run grounding pipeline to enrich responses with retrieved evidence
  3. Train base models on mixed SecKnowledge 2.0 + original data for 2 epochs
  4. Evaluate with zero-shot CoT on cybersecurity benchmarks

- **Design tradeoffs:**
  - K×R retrieval budget (K=2, R=2): Fewer high-quality results vs. more noisy context; paper notes long documents cause "lost in the middle" attention issues
  - Base vs. post-trained initialization: Base gives 2.7× larger gains but requires more careful training; post-trained may be safer for low-data regimes
  - 8-bit vs. 4-bit quantization: 8-bit loses ~0.8% avg performance; 4-bit loses ~4% but remains superior to baselines

- **Failure signatures:**
  - LLM-as-a-Judge positional bias (mitigated by running comparisons twice with swapped order)
  - Context window overflow from excessive retrieval (addressed by limiting K×R=4)
  - Overfitting after 2 epochs (diminishing returns observed)

- **First 3 experiments:**
  1. **Reproduce ablation:** Train Qwen3-4B-base on original SecKnowledge vs. SecKnowledge 2.0 vs. Baseline Reformatting; expect CyberPal 2.0 > Baseline > Original on CTIBench-RCM
  2. **Test grounding ablation:** Disable web search in pipeline for a subset of tasks; measure factuality score drop via LLM-as-a-Judge
  3. **Quantization stress test:** Load CyberPal 2.0-8B in 8-bit and 4-bit modes; evaluate on adversarial benchmarks (Adversarial CTI) to assess robustness degradation

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How do data quality and data scale interact with the choice of starting checkpoint (base vs. post-trained) during the cybersecurity fine-tuning process?
- **Basis in paper:** Appendix B states that "further work is needed to systematically disentangle how data quality and data scale interact with the choice of starting checkpoint during fine-tuning."
- **Why unresolved:** The authors observed that base models learn more effectively but admitted their experiment was "limited in scope" and did not test varying data scales, leaving the interaction mechanism unclear.
- **What evidence would resolve it:** A comprehensive ablation study varying dataset sizes (scale) and curation levels (quality) across both base and post-trained model checkpoints to measure performance deltas.

### Open Question 2
- **Question:** Does the restriction of retrieval to a small number of high-quality results (K=2, R=2) limit performance on complex multi-hop reasoning tasks compared to using full-context capabilities?
- **Basis in paper:** Section 3.3.2 notes that retrieval was restricted to "prioritize fewer, higher-quality search results" to avoid the "lost in the middle" phenomenon and context window saturation, but does not verify if this heuristic is optimal for all security tasks.
- **Why unresolved:** The constraint was a practical choice to balance token limits and attention mechanisms, not a verified optimal setting for the specific domain of threat intelligence correlation.
- **What evidence would resolve it:** Comparing model performance when using condensed retrieval (current method) versus unconstrained retrieval on models with larger effective context windows.

### Open Question 3
- **Question:** To what extent does the removal of "strict safety guardrails" (necessary for utility in security workflows) increase the risk of misuse or hallucination in CyberPal 2.0 models?
- **Basis in paper:** The Introduction argues that frontier models' "strict safety guardrails... limit their practical utility," justifying the need for specialized SLMs, but the paper provides no evaluation of safety alignment or robustness against adversarial misuse.
- **Why unresolved:** The paper focuses entirely on capability benchmarks (CTI, RCM) and assumes that specialized training implies better utility, without quantifying the trade-off with safety.
- **What evidence would resolve it:** Evaluation results on safety benchmarks (e.g., refusal rates for harmful instructions) comparing CyberPal 2.0 against general-purpose frontier models.

## Limitations
- The SecKnowledge 2.0 dataset and expert-defined format templates remain proprietary, preventing direct replication
- The 20B-parameter model uses gpt-oss-20b, an internal or non-public backbone, requiring substitution
- The grounding pipeline's reliance on web search and vector databases introduces variability based on retrieval quality

## Confidence

**High confidence:** The architectural mechanisms described (expert-in-the-loop format generation, multi-step grounding pipeline, base model initialization with mixed CoT/short data) are technically coherent and supported by ablation results. The comparative performance on benchmark suites is reported with clear methodology.

**Medium confidence:** The claimed superiority over frontier models (GPT-4o, o1, o3-mini, Sec-Gemini v1) is based on zero-shot CoT evaluation on specific benchmarks. Performance may vary with different prompting strategies, evaluation protocols, or dataset versions.

**Low confidence:** The generalization of the expert-in-the-loop format generation approach to other cybersecurity subdomains without extensive expert involvement remains unproven. The long-term robustness of the grounding pipeline against evolving threat intelligence data quality is untested.

## Next Checks

1. **Dataset and Format Reproducibility Test:** Attempt to reconstruct a minimal SecKnowledge 2.0-like dataset using publicly available cybersecurity questions and manually defined formats. Compare the performance of a fine-tuned Qwen3-4B-base model on CTIBench-RCM against the reported CyberPal 2.0-4B results.

2. **Grounding Pipeline Robustness Evaluation:** Systematically vary the retrieval quality (e.g., by using different search engines, query formulations, or document sources) and measure the impact on factuality scores and downstream benchmark performance. Test with both high-quality and low-quality grounding documents.

3. **Cross-Model Generalization Study:** Fine-tune multiple base models (e.g., Qwen3-4B-base, Llama-3.1-8B, Gemma-2-9B) using the same SecKnowledge 2.0 dataset (or reconstructed subset) and training pipeline. Evaluate and compare their performance across the full benchmark suite to assess whether the improvements are model-specific or architecture-independent.