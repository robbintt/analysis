---
ver: rpa2
title: Human-like fleeting memory improves language learning but impairs reading time
  prediction in transformer language models
arxiv_id: '2508.05803'
source_url: https://arxiv.org/abs/2508.05803
tags:
- memory
- language
- fleeting
- reading
- decay
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether human-like fleeting memory benefits
  language learning in transformer models. The authors introduce a "fleeting memory
  transformer" that adds a power-law memory decay to self-attention, simulating human
  forgetting.
---

# Human-like fleeting memory improves language learning but impairs reading time prediction in transformer language models

## Quick Facts
- arXiv ID: 2508.05803
- Source URL: https://arxiv.org/abs/2508.05803
- Reference count: 32
- Primary result: Human-like fleeting memory improves language modeling and syntactic knowledge but impairs reading time prediction

## Executive Summary
This paper investigates whether human-like fleeting memory benefits language learning in transformer models. The authors introduce a "fleeting memory transformer" that adds a power-law memory decay to self-attention, simulating human forgetting. Training these models on a developmentally realistic BabyLM dataset (10M and 100M tokens), they find that fleeting memory consistently improves language modeling performance and BLiMP accuracy for syntactic knowledge - but only when combined with an "echoic memory buffer" that perfectly retains the first 3-7 words. Surprisingly, these same models perform worse at predicting human reading times, with the impairment concentrated on low-frequency words. This dissociation cannot be explained by prior accounts of why better language models sometimes fit reading times worse. The results support the idea that memory limitations can benefit language learning in neural networks, while also revealing that architectural constraints making models more "human-like" don't necessarily make them better at predicting human behavior.

## Method Summary
The authors implement fleeting memory as a power-law decay function in self-attention, with an optional echoic memory buffer that perfectly retains the first 3-7 words. They train GPT-2 style transformers (6 layers, 6 heads, 384 hidden dim, 13.69M params) on BabyLM datasets (10M and 100M tokens) with power-law decay bias applied after softmax normalization. The bias matrix B has retention = 1 for the first E tokens (echoic buffer), then decays as a power-law function of distance for subsequent tokens. They evaluate models on validation cross-entropy loss, BLiMP accuracy for syntactic knowledge, and reading time prediction using ∆LL on Natural Stories SPRT and Dundee eye-tracking corpora.

## Key Results
- Fleeting memory with echoic buffer improves language modeling performance on BabyLM at 10M-100M tokens
- BLiMP accuracy improves for syntactic phenomena relying on local context (Subject-Verb Agreement, Anaphor Agreement, Argument Structure)
- Fleeting memory models predict human reading times worse than perfect memory models, with impairment concentrated on low-frequency words
- The reading time impairment cannot be explained by prior memorization or scale accounts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adding a power-law decay to self-attention weights with an echoic memory buffer improves language learning in data-limited regimes.
- Mechanism: A bias matrix B with retention values [0,1] is element-wise multiplied after softmax. Retention = 1 for the first E tokens (echoic buffer, ~3-7 words), then decays as a power-law function of distance d for subsequent tokens.
- Core assumption: Most linguistic dependencies are local, so encoding this as a prior helps learning when training data is limited.
- Evidence anchors:
  - [abstract]: "The authors implement fleeting memory as a power-law decay function in self-attention, with an optional echoic memory buffer"
  - [section 3.2]: "We implement fleeting memory as a fixed, non-trainable recency bias applied to the self-attention weights after the softmax operation"
  - [corpus]: Related work (De Varda & Marelli 2024, Vaidya et al. 2023) applies similar decay at inference time; corpus evidence for training-time benefits is limited to this paper.
- Break condition: Benefits likely vanish or reverse at billion+ token scales where models can learn patterns without architectural guidance.

### Mechanism 2
- Claim: Memory decay encodes a statistical prior that dependencies in language are predominantly local, acting as an inductive bias.
- Mechanism: By reducing attention weights for distant tokens, the model is biased to learn local patterns first, which aligns with the statistical structure of natural language.
- Core assumption: Language exhibits a bias toward local dependencies (referenced from Futrell et al., 2020b).
- Evidence anchors:
  - [section 5]: "The most parsimonious explanation is statistical: memory decay encodes the prior that dependencies in language are predominantly local"
  - [section 4]: BLiMP improvements concentrated in Subject-Verb Agreement, Anaphor Agreement, and Argument Structure—phenomena relying on local context
  - [corpus]: Weak direct evidence; related paper "To model human linguistic prediction, make LLMs less superhuman" suggests reducing model capacity improves human alignment.
- Break condition: Texts with genuinely long-range dependencies (academic papers, code, novels) may show different or opposite patterns.

### Mechanism 3
- Claim: Fleeting memory creates a dissociation where improved language modeling co-occurs with degraded reading time prediction, through mechanisms distinct from prior memorization or scale accounts.
- Mechanism: The reading time impairment cannot be explained by superhuman scale (observed at 10M tokens) nor by systematic underprediction of rare words (the key memorization signature was absent).
- Core assumption: Multiple distinct mechanisms can cause competence-alignment dissociation.
- Evidence anchors:
  - [abstract]: "suggesting memory limitations can be beneficial for learning but may reduce behavioral alignment"
  - [section 4]: "we find no evidence that the worse reading time prediction of low-frequency words is driven by the underprediction of reading times for low-frequency words"
  - [corpus]: Prior work (Oh et al. 2024, Shain et al. 2024) documented dissociations attributed to scale/memorization—this paper shows a different mechanism.
- Break condition: May be specific to developmental corpora; different text types might yield different patterns.

## Foundational Learning

- Concept: Self-attention mechanism
  - Why needed here: The modification applies directly to attention weights; understanding Q, K, V interactions and softmax normalization is essential.
  - Quick check question: Can you trace how a modification to post-softmax attention weights affects gradient flow to keys and queries?

- Concept: Power-law vs. exponential decay
  - Why needed here: The paper uses power-law decay motivated by cognitive memory models; understanding why this functional form matters.
  - Quick check question: Why might power-law decay be more appropriate for modeling linguistic memory than exponential decay?

- Concept: Surprisal theory
  - Why needed here: Reading time prediction evaluation uses surprisal (negative log probability); understanding this link is critical.
  - Quick check question: What does higher surprisal predict about human reading times, and what does this assume about the relationship?

## Architecture Onboarding

- Component map: Base GPT-2 transformer -> Standard attention scores (softmax(QK^T / √d_k)) -> Apply retention bias B (post-softmax) -> Multiply by V -> Output
- Critical path:
  1. Compute standard attention scores: softmax(QK^T / √d_k)
  2. Apply retention bias: multiply by B where B[d] = 1 if d < E, else power-law decay
  3. Multiply by V to get output
  4. Backpropagation flows through bias (fixed, non-trainable)
- Design tradeoffs:
  - Decay strength vs. buffer size: Strong decay without buffer impairs learning; combined they improve it
  - Fixed vs. learnable bias: Parameter-free decay trades optimization flexibility for interpretability and cognitive grounding
  - Data regime: Effects demonstrated at 10M-100M tokens; extrapolation to larger scales uncertain
- Failure signatures:
  - No buffer: Spelling errors emerge (even within-word token dependencies disrupted)
  - Reading time fit: Impairment concentrated in low-frequency quintiles, but NOT via systematic underprediction
  - No BLiMP improvement for: Irregular forms (lexical knowledge), Determiner-Noun agreement (within buffer, no decay effect)
- First 3 experiments:
  1. **Buffer ablation**: Fix α=3, vary E ∈ {0, 5, 10}, train 5 seeds each on 10M tokens. Expect: E=0 impairs, E≥5 improves validation loss.
  2. **Frequency-stratified RT analysis**: On Natural Stories, partition by log-frequency quintile, compute MSE(fleeting - perfect). Expect: largest MSE difference in Q1 (lowest frequency).
  3. **Long-range dependency probe**: Evaluate on BLiMP phenomena requiring non-local dependencies (NPI licensing, binding). Expect: minimal improvement or slight impairment vs. local phenomena.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does fleeting memory improve learning solely by encoding a statistical prior for local dependencies, or does it actively drive the formation of qualitatively different linguistic abstractions?
- **Basis in paper:** [explicit] The Discussion asks, "What mechanisms underlie the benefits of fleeting memory?" and suggests future work could distinguish between statistical biasing and the "abstraction hypothesis" via mechanistic analyses.
- **Why unresolved:** The current results show improved performance on syntactic tasks (BLiMP) but do not reveal the internal representational changes causing the improvement.
- **What evidence would resolve it:** Mechanistic interpretability analyses, such as examining layer-wise abstraction levels or attention head specialization during training.

### Open Question 2
- **Question:** What specific mechanism causes fleeting memory models to predict human reading times worse than perfect memory models, given that prior accounts (scale and memorization) were ruled out?
- **Basis in paper:** [explicit] The Discussion notes the results "suggest that multiple distinct mechanisms can cause a dissociation" between language model quality and reading time prediction.
- **Why unresolved:** The authors demonstrated that the impairment clusters on low-frequency items but lacks the "underprediction" signature expected by memorization theories, leaving the cause unidentified.
- **What evidence would resolve it:** Experiments manipulating memory constraints to test alternative hypotheses regarding the relationship between memory retention and surprisal estimation.

### Open Question 3
- **Question:** Would replacing the current time-based decay with a content-sensitive retention function (where informative words persist longer) resolve the trade-off between learning benefits and behavioral alignment?
- **Basis in paper:** [explicit] The Discussion states, "Future work could extend it... Content-dependent retention functions (as in Hahn et al., 2022) could preserve high-information words while letting predictable ones fade."
- **Why unresolved:** The implemented decay function is a "crude approximation" that is strictly monotonic, whereas human retention is known to be content-sensitive.
- **What evidence would resolve it:** Training models with content-dependent decay functions and evaluating them on both linguistic competence (BLiMP) and reading time prediction.

## Limitations
- Benefits of fleeting memory appear specific to developmental-scale training (10M-100M tokens)
- Dissociation between improved language modeling and degraded reading time prediction may be specific to developmental corpus composition
- Fixed, non-trainable bias matrices limit exploration of learnable decay parameters

## Confidence

**High Confidence**: The core finding that fleeting memory with echoic buffer improves language modeling performance on BabyLM at 10M-100M tokens. The experimental design with multiple seeds, controlled comparisons, and consistent results across validation loss and BLiMP accuracy supports this claim strongly.

**Medium Confidence**: The claim that fleeting memory creates a dissociation between language modeling competence and reading time prediction. While the empirical dissociation is well-documented, the mechanistic explanation remains somewhat speculative, and the effect may be specific to developmental corpora.

**Medium Confidence**: The statistical prior hypothesis explaining why fleeting memory helps language learning. The concentration of BLiMP improvements in local dependency phenomena supports this, but direct evidence linking power-law decay to local dependency learning is limited.

## Next Checks

1. **Scale Extrapolation Test**: Train fleeting memory models on larger corpora (1B+ tokens) to determine whether the benefits reverse or disappear, directly testing the break condition for Mechanism 1.

2. **Corpus Composition Analysis**: Evaluate fleeting memory models on non-developmental corpora (academic papers, code, novels) to test whether the competence-alignment dissociation is specific to the BabyLM corpus composition.

3. **Learnable Decay Parameters**: Replace the fixed power-law bias with learnable decay parameters to determine whether optimization flexibility improves the reading time prediction while maintaining language modeling benefits.