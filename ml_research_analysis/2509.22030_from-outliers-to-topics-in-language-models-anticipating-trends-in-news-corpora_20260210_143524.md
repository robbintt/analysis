---
ver: rpa2
title: 'From Outliers to Topics in Language Models: Anticipating Trends in News Corpora'
arxiv_id: '2509.22030'
source_url: https://arxiv.org/abs/2509.22030
tags:
- outliers
- topic
- clustering
- articles
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether outliers in topic-based clustering
  can serve as early indicators of emerging topics in dynamic news corpora. Using
  embeddings from nine pre-trained language models, documents are projected into a
  semantic space, reduced in dimensionality via UMAP, and clustered cumulatively over
  20 monthly time windows using BERTopic with HDBSCAN.
---

# From Outliers to Topics in Language Models: Anticipating Trends in News Corpora
arXiv ID: 2509.22030
Source URL: https://arxiv.org/abs/2509.22030
Authors: Evangelia Zve; Benjamin Icard; Alice Breton; Lila Sainero; Gauvain Bourgne; Jean-Gabriel Ganascia
Reference count: 24
Primary result: Outliers in topic-based clustering evolve into coherent topics, with validation rates of 0.80 (French) and 0.81 (English).

## Quick Facts
- **arXiv ID:** 2509.22030
- **Source URL:** https://arxiv.org/abs/2509.22030
- **Reference count:** 24
- **Primary result:** Outliers evolve into coherent topics with validation rates of 0.80 (French) and 0.81 (English).

## Executive Summary
This study investigates whether outliers in topic-based clustering can serve as early indicators of emerging topics in dynamic news corpora. Using embeddings from nine pre-trained language models, documents are projected into a semantic space, reduced in dimensionality via UMAP, and clustered cumulatively over 20 monthly time windows using BERTopic with HDBSCAN. Outliers—documents not assigned to any cluster—are tracked to assess whether they later become inliers, signaling topic formation. Across both French and English datasets, outliers consistently evolve into coherent topics, with high average validation rates (0.80 for French, 0.81 for English) and strong inter-model agreement (a ≥ 0.67). Lexical and stylistic analyses reveal that conversion is influenced by language-specific features: structural simplicity and lower named entity frequency in French; reduced function words and letters in English. The results support the hypothesis that outlier-to-inlier conversion is a reliable mechanism for detecting emerging topics.

## Method Summary
The study employs a pipeline to detect emerging topics in dynamic news corpora by tracking the conversion of outliers (unclustered documents) into inliers (clustered documents) over time. Documents are embedded using nine pre-trained language models, dimensionality reduced to 10D via UMAP, and clustered cumulatively over 20 monthly windows using BERTopic with HDBSCAN. Outliers are monitored across time windows to determine if they join clusters in subsequent steps, indicating topic formation. The method is applied to two datasets: a French corpus (102 articles on TotalEnergies/École Polytechnique) and an English corpus (312 articles on greenhouse gas emissions). Validation metrics include outlier-to-inlier conversion rates, silhouette scores (target >0.5), and inter-model agreement (a ≥ 0.67).

## Key Results
- Outliers consistently evolve into coherent topics, with validation rates of 0.80 (French) and 0.81 (English).
- High inter-model agreement (a ≥ 0.67) confirms robustness across different language models.
- Language-specific features influence conversion: French outliers exhibit structural simplicity and lower named entity frequency; English outliers show reduced function words and letters.

## Why This Works (Mechanism)
The outlier-to-inlier conversion mechanism works because outliers represent novel or underrepresented content in early time windows. As the corpus accumulates, these documents gradually align with emerging themes, joining clusters that reflect new topics. The cumulative clustering approach ensures that temporal context is preserved, allowing the model to track the evolution of topics over time. The use of pre-trained language models ensures robust semantic embeddings, while UMAP and HDBSCAN enable effective dimensionality reduction and density-based clustering. The strong inter-model agreement suggests that this mechanism is not dependent on a single model's idiosyncrasies but is a generalizable phenomenon.

## Foundational Learning
- **UMAP Dimensionality Reduction:** Why needed: Reduces high-dimensional embeddings to 10D for efficient clustering. Quick check: Verify that UMAP preserves local and global structure in the embedding space.
- **HDBSCAN Clustering:** Why needed: Identifies clusters of varying densities and labels outliers (-1). Quick check: Confirm that HDBSCAN parameters (e.g., `min_cluster_size`) are tuned for the dataset's density distribution.
- **BERTopic Framework:** Why needed: Integrates UMAP and HDBSCAN for topic modeling with outlier detection. Quick check: Ensure that BERTopic's default parameters are appropriate for the corpus size and domain.
- **Cumulative Clustering:** Why needed: Tracks the evolution of topics over time by clustering all documents up to the current window. Quick check: Validate that the cumulative approach captures temporal trends without overfitting.
- **Inter-model Agreement:** Why needed: Assesses the robustness of outlier-to-inlier conversion across different language models. Quick check: Calculate agreement metrics (e.g., Cohen's kappa) to ensure consistency.
- **Silhouette Score:** Why needed: Evaluates clustering quality and coherence. Quick check: Ensure scores exceed the threshold of 0.5 for reliable topic detection.

## Architecture Onboarding
- **Component Map:** Document Embeddings -> UMAP Dimensionality Reduction -> Cumulative Clustering (BERTopic + HDBSCAN) -> Outlier Tracking -> Validation Metrics
- **Critical Path:** Embeddings -> UMAP -> HDBSCAN Clustering -> Outlier Conversion Tracking
- **Design Tradeoffs:** Cumulative clustering preserves temporal context but increases computational complexity; HDBSCAN's sensitivity to density parameters requires careful tuning.
- **Failure Signatures:** Low silhouette scores (<0.5) indicate poor clustering quality; excessive outliers (>50%) suggest overly strict density thresholds.
- **First Experiments:**
  1. Reproduce the English dataset filtering process and validate the clustering pipeline.
  2. Test the impact of UMAP hyperparameters on clustering outcomes.
  3. Evaluate the robustness of outlier-to-inlier conversion across different language models.

## Open Questions the Paper Calls Out
- **Open Question 1:** Can outliers be systematically distinguished as precursors to novel topics versus reinforcements of existing topics? The paper plans to develop a classification framework to separate outliers based on whether they join existing clusters or seed new ones, validated against ground-truth topic timelines.
- **Open Question 2:** Does the outlier-to-topic conversion mechanism remain robust in larger, heterogeneous corpora prone to informational risks? The study's reliance on small, manually curated datasets limits generalizability; scaling to large-scale, noisy datasets containing disinformation is a future direction.
- **Open Question 3:** How does the choice of density-based clustering algorithm (e.g., HDBSCAN vs. OPTICS) impact the detection of emerging topics via outliers? The paper suggests evaluating alternative clustering algorithms to assess algorithmic sensitivity and robustness.

## Limitations
- The manual curation of the French dataset (TP) is not fully transparent, limiting reproducibility.
- Hyperparameter details for UMAP and HDBSCAN are unspecified, potentially affecting clustering outcomes.
- The study's focus on two narrow, domain-specific corpora limits generalizability to broader or less structured text domains.

## Confidence
- **High:** The observed conversion of outliers into coherent topics is statistically robust, with high validation rates and strong inter-model agreement.
- **Medium:** The interpretation of language-specific patterns as drivers of conversion is plausible but requires further validation to confirm causality versus correlation.
- **Low:** The scalability of this approach to real-time, large-scale news monitoring is not demonstrated, and the sensitivity of results to hyperparameter tuning is under-specified.

## Next Checks
1. Replicate the English dataset filtering process and reproduce the clustering pipeline with the best-performing model to confirm silhouette scores and outlier conversion rates.
2. Test the pipeline on a third, independently sourced news corpus to assess generalizability beyond the French and English datasets.
3. Conduct ablation studies on UMAP and HDBSCAN hyperparameters to quantify their impact on clustering quality and conversion rates.