---
ver: rpa2
title: 'Mind the Missing: Variable-Aware Representation Learning for Irregular EHR
  Time Series using Large Language Models'
arxiv_id: '2509.22121'
source_url: https://arxiv.org/abs/2509.22121
tags:
- time
- series
- vital
- missing
- variables
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: VITAL is a variable-aware representation learning framework that
  leverages large language models (LLMs) to handle irregularly sampled EHR time series
  with high missingness. The method differentiates between frequently measured vital
  signs, which are reprogrammed into the LLM's language space with explicit missingness
  encoding, and sparsely measured laboratory tests, which are embedded using representative
  statistics or learnable [Not measured] tokens.
---

# Mind the Missing: Variable-Aware Representation Learning for Irregular EHR Time Series using Large Language Models

## Quick Facts
- arXiv ID: 2509.22121
- Source URL: https://arxiv.org/abs/2509.22121
- Authors: Jeong Eul Kwon; Joo Heung Yoon; Hyo Kyung Lee
- Reference count: 40
- Key outcome: VITAL achieves SOTA on ICU datasets, with AUROC improvements of 0.1% and 1.1%, and AUPRC improvements of 4.4% and 3.4% on P19 and P12 respectively

## Executive Summary
VITAL is a variable-aware representation learning framework that leverages frozen LLMs to handle irregularly sampled EHR time series with high missingness. The method differentiates between frequently measured vital signs, which are reprogrammed into the LLM's language space with explicit missingness encoding, and sparsely measured laboratory tests, which are embedded using representative statistics or learnable [Not measured] tokens. This approach enables effective capture of temporal patterns in dense sequences while appropriately handling sparse measurements, achieving state-of-the-art performance on two benchmark ICU datasets.

## Method Summary
VITAL partitions clinical variables by measurement frequency and temporal structure. Dense vital signs (missing rate ~32.9% in P19) are reprogrammed via cross-attention with text prototypes, with "Missing" tokens inserted at gaps, then processed by a frozen GPT-2 to extract sequence embeddings. Sparse lab tests (missing rate ~95.1%) receive non-temporal summary embeddings (min/max/median/mean) or a single learnable [Not measured] token. The two embedding types are concatenated and passed through TSMixer-style feature/dimension mixing layers before classification. The method treats each variable independently to handle heterogeneous missingness patterns.

## Key Results
- Outperforms previous methods with absolute AUROC improvements of 0.1% and 1.1% on P19 and P12
- AUPRC improvements of 4.4% and 3.4% on P19 and P12 respectively
- Demonstrates robustness under high missingness conditions and when specific variables are entirely absent
- Shows particular effectiveness in realistic clinical scenarios where laboratory tests are unavailable

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Explicitly encoding "Missing" as a token allows the LLM to reason about absence contextually rather than treating it as noise to impute.
- **Mechanism:** During reprogramming, observed vital sign values serve as queries in cross-attention with text prototypes. At missing time points, the pre-trained word embedding for "Missing" is inserted directly. The LLM (GPT-2) then processes the full sequence autoregressively, with the final timestep embedding capturing context about both observed and missing values.
- **Core assumption:** The LLM's pre-trained understanding of semantic absence transfers to temporal missingness patterns in clinical data.
- **Evidence anchors:**
  - [abstract]: "reason over missing values through explicit encoding"
  - [Section 3.2.1]: "the word embedding for 'Missing' is inserted at time steps where missing values persist... the word embeddings used here are identical to those employed during the LLM's pretraining"
  - [Section 5.5, Table 5]: "Missing" token outperforms "Null," "Apple," and "Engineering" replacements, suggesting semantic meaning matters
  - [corpus]: No direct corpus evidence on this specific mechanism
- **Break condition:** If LLM is replaced with a non-autoregressive backbone, final-timestep embedding extraction loses whole-sequence context; if missingness is uniform/random rather than informative (e.g., not correlated with patient acuity), explicit encoding provides no signal.

### Mechanism 2
- **Claim:** Variable-aware partitioning prevents misallocation of modeling capacity by matching representation strategy to data characteristics.
- **Mechanism:** Variables are partitioned by measurement frequency and temporal structure. Dense vital signs (missing rate ~32.9% in P19) receive temporal modeling via LLM; sparse lab tests (missing rate ~95.1%) receive non-temporal summary embeddings (min/max/median/mean) or a single [Not measured] token.
- **Core assumption:** Lab tests lack sufficient temporal structure for sequence modeling to be beneficial; their informational value lies in summary statistics or presence/absence.
- **Evidence anchors:**
  - [abstract]: "differentiates between two distinct types of clinical variables"
  - [Section 3.2.2]: "laboratory test variables do not follow a well-defined temporal structure... we aim to embed key information such as measurement presence and representative values"
  - [Section 4.2]: Variables with high missingness (e.g., EtCO2 at 97.12%) are reclassified as "lab-like" regardless of measurement source
  - [corpus]: Temporal Dynamic Embedding paper addresses irregular sampling but treats all variables uniformly
- **Break condition:** If a lab test becomes frequently measured (e.g., point-of-care testing changes collection patterns), summary embedding discards temporal signal; if vital sign missingness approaches lab-level sparsity, LLM sequence modeling degrades.

### Mechanism 3
- **Claim:** The learnable [Not measured] token encodes a distinct semantic representation for "never observed during observation period" that improves over zero or random embeddings.
- **Mechanism:** When a lab variable has zero measurements, a single trainable token is passed through the embedding layer. The token's representation is learned end-to-end, allowing the model to assign task-relevant semantics to complete absence.
- **Core assumption:** "Never measured" carries predictive information distinct from "measured with some value," and this information is consistent across patients.
- **Evidence anchors:**
  - [Section 3.2.2]: "a single [Not measured] token is used as input to the embedding layer, without distinguishing between variables. The reason for this uniform token assignment is to mitigate potential overfitting"
  - [Section 5.4, Table 4]: Trainable token (AUROC 89.3%) outperforms zero vector (88.5%) and random vector (86.0%) on P19
  - [Section 5.4, Figure 4]: Visualization shows learned token occupies distinct region in embedding space, separated from observed value embeddings
  - [corpus]: No corpus evidence addresses this specific token mechanism
- **Break condition:** If missingness patterns are highly heterogeneous across patients without underlying structure, a shared token cannot capture patient-specific missingness semantics.

## Foundational Learning

- **Concept: Reprogramming / Visual Prompting for Time Series**
  - **Why needed here:** VITAL does not fine-tune the LLM; it learns a projection from time series to the LLM's input space via cross-attention with text prototypes. Understanding reprogramming explains why GPT-2's weights stay frozen.
  - **Quick check question:** Can you explain why the query comes from the time series and the keys/values from text prototypes, rather than the reverse?

- **Concept: Channel Independence in Multivariate Time Series**
  - **Why needed here:** VITAL processes each vital sign variable as a univariate series (channel independence) rather than jointly modeling all variables. This design choice trades inter-variable dependency modeling for robustness to heterogeneous missingness.
  - **Quick check question:** What information is lost when processing variables independently that a joint model might capture?

- **Concept: Autoregressive Final-Timestep Extraction**
  - **Why needed here:** The model extracts the final timestep's hidden state from GPT-2 as the sequence representation. This only works because autoregressive models accumulate context; causal attention means each position attends only to prior positions.
  - **Quick check question:** Why would extracting the *first* timestep's embedding fail to capture the sequence context?

## Architecture Onboarding

- **Component map:**
  - Input Layer: Time series partitioned into vital signs (V variables) and lab tests (L variables), with masking vectors
  - Vital Sign Reprogramming Module: Per-variable cross-attention (observed values → queries, text prototypes → keys/values), "Missing" token insertion at gaps, linear projection to LLM hidden dimension
  - Backbone LLM: Frozen GPT-2, autoregressive processing, final-timestep extraction
  - Lab Embedding Module: Representative statistics (min/max/median/mean) for observed labs; learnable [Not measured] token for unobserved
  - Output Projection: Feature/Dimension mixing layers (adapted from TSMixer), demographic concatenation, classification head

- **Critical path:**
  1. Partition variables by missingness ratio (threshold empirically determined from training data)
  2. Reprogram vital signs → LLM input space → extract Hv
  3. Compute lab embeddings → Hl
  4. Concatenate Hv ⊕ Hl → mixer layers → Oi → classifier

- **Design tradeoffs:**
  - **Frozen LLM vs. fine-tuning:** Freezing preserves general reasoning but limits domain adaptation; reprogramming learns only the input projection (~0.2% of parameters per TimeLLM)
  - **Channel independence vs. joint modeling:** Independence handles irregular sampling per-variable but cannot model cross-variable dependencies (e.g., HR/BP relationships)
  - **Summary statistics for labs vs. sequence modeling:** Summaries discard temporal patterns but avoid spurious correlations from sparse, irregular measurements

- **Failure signatures:**
  - Performance collapse when vital sign missingness >80%: LLM receives nearly all "Missing" tokens, embedding lacks contextual information (Section 5.3)
  - Random [Not measured] embedding: Drops to near-baseline performance (Table 4)
  - Wrong word choice for missingness (e.g., "Engineering"): AUROC drops 5+ points (Table 5)
  - Padding applied after sequence end: Final-timestep extraction captures padding artifact, not patient data

- **First 3 experiments:**
  1. **Sanity check with synthetic missingness:** Take a fully-observed subset, artificially mask at increasing rates (10%, 30%, 50%), verify graceful degradation. Compare "Missing" token vs. mean imputation to confirm explicit encoding benefit.
  2. **Variable partition threshold sweep:** Test missingness thresholds for classifying variables as vital-like vs. lab-like (e.g., 50%, 70%, 90%). Monitor performance on held-out set to find domain-appropriate cutoff.
  3. **Leave-sensor-out robustness test:** Remove entire variable groups at test time (per Section 5.3 protocol). Verify that VITAL (lab) configuration (only removing lab variables) degrades slower than full variable removal, confirming vital sign embedding carries primary signal.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can variable-level interpretability be integrated into VITAL without degrading predictive performance?
- Basis in paper: [explicit] The authors note that the TSMixer structure and 3D tensor shape prevent standard attribution methods (e.g., SHAP), and attempts to add attention mechanisms resulted in performance drops.
- Why unresolved: The current architectural design prioritizes feature mixing over transparency, creating a trade-off between explainability and accuracy.
- What evidence would resolve it: Development of attribution techniques compatible with 3D mixing layers or a novel architecture that maintains accuracy while allowing variable contribution tracking.

### Open Question 2
- Question: Does VITAL generalize effectively to multi-institutional settings with varying clinical workflows?
- Basis in paper: [explicit] The authors state that "further validation is required to ensure the model’s generalizability... particularly when applied to multi-institutional settings."
- Why unresolved: The study evaluates VITAL only on single-source PhysioNet benchmarks (P12 and P19), which may not capture the heterogeneity of different hospital systems.
- What evidence would resolve it: External validation studies demonstrating consistent performance across distinct EHR databases (e.g., eICU versus MIMIC-IV) with different sampling protocols.

### Open Question 3
- Question: Is there an optimal, automated threshold for distinguishing between "vital sign" and "lab test" variables based on missingness ratios?
- Basis in paper: [inferred] The authors manually reclassify specific high-missingness vitals (e.g., Temperature, MAP) as "lab-like" based on exploratory data analysis, suggesting the current partitioning strategy is heuristic.
- Why unresolved: The paper implies a fixed missingness ratio determines the embedding strategy, but does not provide a dynamic or learned method to set this boundary.
- What evidence would resolve it: Ablation studies identifying the optimal missingness cutoff or a parameterized function that automatically routes variables to the appropriate embedding module.

## Limitations

- Performance gains demonstrated primarily on two benchmark ICU datasets with specific characteristics (high missingness, short observation windows, binary classification)
- Partitioning threshold between vital signs and lab tests was not explicitly optimized and may not generalize to datasets with different missingness distributions
- Frozen GPT-2 backbone limits domain adaptation potential, reprogramming only modifies ~0.2% of parameters
- Variable independence assumption prevents modeling cross-variable dependencies that could be clinically important
- No ablation studies on TSMixer-style feature/dimension mixing layers to isolate their contribution

## Confidence

- **High Confidence**: The core mechanism of explicit "Missing" token encoding and the superiority of learnable [Not measured] tokens over zero/random baselines are well-supported by controlled experiments (Table 5, Table 4).
- **Medium Confidence**: The variable-aware partitioning strategy and overall performance improvements are supported by results on two datasets, but the optimal missingness threshold and generalizability to other clinical domains remain uncertain.
- **Low Confidence**: The contribution of individual architectural components (TSMixer layers, demographic concatenation, specific text prototype choices) is unclear due to lack of component-wise ablations.

## Next Checks

1. **Synthetic Missingness Gradient**: Take a fully-observed subset from P19, artificially mask vital signs at 10%, 30%, 50%, 70%, and 90% rates, and measure performance degradation. This validates the claim that VITAL degrades gracefully as missingness increases and confirms the "Missing" token's effectiveness across varying sparsity levels.

2. **Variable Partition Threshold Sensitivity**: Systematically sweep the missingness threshold for classifying variables as vital-like vs. lab-like (e.g., 50%, 60%, 70%, 80%, 90%) on held-out validation sets. This identifies whether the current threshold is optimal or if performance is sensitive to this critical design choice.

3. **Component Ablation on TSMixer Layers**: Remove the feature/dimension mixing layers while keeping all other components identical, and measure performance impact. This isolates whether the architectural complexity beyond basic concatenation and projection provides measurable benefit or could be simplified.