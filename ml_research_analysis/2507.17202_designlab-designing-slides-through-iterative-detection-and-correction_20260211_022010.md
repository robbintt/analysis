---
ver: rpa2
title: 'DesignLab: Designing Slides Through Iterative Detection and Correction'
arxiv_id: '2507.17202'
source_url: https://arxiv.org/abs/2507.17202
tags:
- design
- slides
- elements
- reviewer
- contributor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes DesignLab, a system that iteratively improves
  presentation slides by decomposing the design process into two specialized roles:
  a design reviewer that detects issues and a design contributor that corrects them.
  The system fine-tunes language models for each role and simulates rough drafts through
  controlled perturbations to enable iterative refinement.'
---

# DesignLab: Designing Slides Through Iterative Detection and Correction

## Quick Facts
- arXiv ID: 2507.17202
- Source URL: https://arxiv.org/abs/2507.17202
- Reference count: 40
- Key result: 62.3% preference over WebRPG and 51.9% over PowerPoint Designer in GPT-4o comparisons

## Executive Summary
This paper introduces DesignLab, a system that iteratively improves presentation slides by decomposing the design process into two specialized roles: a design reviewer that detects issues and a design contributor that corrects them. The system fine-tunes language models for each role and simulates rough drafts through controlled perturbations to enable iterative refinement. Evaluations show DesignLab outperforms existing methods, including a commercial tool, with significant preference scores in both automated and human evaluations.

## Method Summary
DesignLab uses two fine-tuned Qwen2.5-1.5B models working in tandem: a reviewer that identifies design issues in rough slides and a contributor that corrects them. The system simulates rough drafts by applying controlled perturbations to clean slides (removing shapes, shifting positions, altering colors, setting fonts to defaults). During training, perturbed elements are marked as TENTATIVE, and the contributor learns to restore original values. The iterative process continues until no TENTATIVE labels remain, with most slides converging within two rounds.

## Key Results
- DesignLab achieves 62.3% preference over WebRPG and 51.9% over PowerPoint Designer in GPT-4o pairwise comparisons
- User studies confirm progressive aesthetic improvements across iterations, with most slides converging within two rounds
- The system demonstrates real-time, interactive design refinement suitable for practical deployment

## Why This Works (Mechanism)
The two-role decomposition enables specialized reasoning: the reviewer focuses on detection without correction bias, while the contributor concentrates on restoration without detection overhead. This separation mirrors human design workflows where critique and creation are distinct cognitive processes. The iterative refinement allows for progressive improvement rather than requiring one-shot perfection.

## Foundational Learning
- **Slide representation encoding**: Slides must be converted to JSON with positions, shapes, text attributes, and colors while excluding media encodings. Needed to enable LLM processing of visual elements.
  - Quick check: Verify JSON schema matches expected field names and structure

- **Controlled perturbation simulation**: Rough drafts are artificially created through systematic modifications to clean slides. Needed to generate training data for the reviewer/contributor models.
  - Quick check: Test perturbation coverage by measuring detection rates on known perturbed inputs

- **Two-stage fine-tuning**: Separate training for reviewer (detection) and contributor (correction) models. Needed to specialize each model for its specific task.
  - Quick check: Validate that each model performs its designated function independently

## Architecture Onboarding

**Component map:** Slides -> JSON encoder -> Perturbation pipeline -> Reviewer model -> Contributor model -> Iterative refinement loop

**Critical path:** Rough slide input → JSON conversion → Reviewer detection → Contributor correction → Output → User evaluation

**Design tradeoffs:** The two-role decomposition trades model complexity for specialized accuracy versus a single unified model that might handle both tasks but with less precision. The perturbation-based training trades synthetic data for control over training signals.

**Failure signatures:** Low detection recall (0.149 for position shifts) indicates reviewer misses misaligned elements. Color mismatches with images since media content isn't encoded. Complex structures like tables and graphs aren't handled well due to text representation limitations.

**Exactly 3 first experiments:**
1. Test reviewer detection on known perturbed inputs to measure recall and precision
2. Run end-to-end iteration on simple slides to verify convergence behavior
3. Compare contributor corrections against ground truth original values

## Open Questions the Paper Calls Out
None

## Limitations
- Proprietary training dataset prevents exact replication of the fine-tuning process
- GPT-4o preference comparisons may not fully capture nuanced human aesthetic preferences
- Detection accuracy rates (0.149 recall for position shifts) suggest room for improvement in identifying subtle design issues

## Confidence

**High confidence:** The core iterative architecture is well-specified and theoretically sound; convergence behavior is directly measurable from results.

**Medium confidence:** Preference scores depend on GPT-4o's design judgment, which may differ from human evaluators; numerical improvements could vary with different evaluators.

**Medium confidence:** Detection/correction accuracy rates are reported but their practical impact depends on how critical undetected issues are to overall aesthetics.

## Next Checks

1. **Dataset substitution test:** Re-train reviewer and contributor models using publicly available slide datasets to verify comparable performance without proprietary data.

2. **Human evaluation validation:** Conduct user studies with human judges rating slides before and after DesignLab processing to confirm GPT-4o preference scores translate to actual aesthetic improvements.

3. **Perturbation parameter sensitivity:** Systematically vary perturbation probability ranges and measure how detection/correction performance changes to establish robustness boundaries.