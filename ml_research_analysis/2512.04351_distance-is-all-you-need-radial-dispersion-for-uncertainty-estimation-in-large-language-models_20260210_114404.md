---
ver: rpa2
title: 'Distance Is All You Need: Radial Dispersion for Uncertainty Estimation in
  Large Language Models'
arxiv_id: '2512.04351'
source_url: https://arxiv.org/abs/2512.04351
tags:
- uncertainty
- arxiv
- language
- semantic
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Radial Dispersion Score (RDS), a simple,\
  \ training-free, model-agnostic uncertainty metric for large language models (LLMs)\
  \ that measures the \u21131 radial dispersion of sampled generations in embedding\
  \ space. Unlike existing methods that rely on semantic clustering or model internals,\
  \ RDS computes the total \u21131 distance from the empirical centroid of embedded\
  \ generations, providing a direct geometric signal of semantic variability."
---

# Distance Is All You Need: Radial Dispersion for Uncertainty Estimation in Large Language Models

## Quick Facts
- arXiv ID: 2512.04351
- Source URL: https://arxiv.org/abs/2512.04351
- Authors: Manh Nguyen; Sunil Gupta; Hung Le
- Reference count: 35
- Primary result: Introduces RDS, a training-free uncertainty metric measuring ℓ1 radial dispersion in embedding space, achieving SOTA performance in hallucination detection and best-of-N selection across multiple QA datasets and LLMs.

## Executive Summary
This paper presents Radial Dispersion Score (RDS), a novel uncertainty estimation method for large language models that leverages the geometric dispersion of sampled generations in embedding space. Unlike existing approaches that rely on semantic clustering or model internals, RDS computes the total ℓ1 distance from the empirical centroid of embedded generations, providing a direct measure of semantic variability. The method is training-free, model-agnostic, and naturally extends to per-sample uncertainty scoring for best-of-N selection and confidence-based filtering.

## Method Summary
RDS measures uncertainty by calculating the ℓ1 radial dispersion of multiple sampled generations from their empirical centroid in embedding space. For a set of samples, embeddings are computed and their centroid determined, then the sum of ℓ1 distances from each sample to this centroid serves as the uncertainty score. A probability-weighted variant (RDSw) incorporates token-level probabilities when available. The method is designed to be lightweight, requiring no additional model calls or training, and works across different LLMs and embedding models.

## Key Results
- RDS and RDSw achieve state-of-the-art performance in hallucination detection across four QA datasets and four LLMs
- The metric demonstrates robustness to sample size and embedding choice while remaining computationally lightweight
- RDS naturally enables best-of-N selection and confidence-based filtering without additional model calls
- Probability-weighted RDSw shows enhanced sensitivity to high-probability outputs when token probabilities are available

## Why This Works (Mechanism)
The mechanism relies on the geometric principle that semantically similar generations cluster closely in embedding space, while diverse or uncertain outputs are more dispersed. By measuring the total ℓ1 distance from the centroid, RDS captures this dispersion directly. The ℓ1 metric is chosen for its robustness to outliers compared to ℓ2, while still providing meaningful distance measurements in embedding space. The empirical centroid serves as a natural reference point representing the "consensus" embedding of the sampled generations.

## Foundational Learning

**Embedding Space Geometry**
- Why needed: Understanding how semantic similarity maps to geometric proximity in vector space
- Quick check: Verify that cosine similarity between embeddings correlates with semantic similarity using word analogies

**ℓ1 vs ℓ2 Distance Metrics**
- Why needed: Different distance metrics have varying sensitivity to outliers and magnitude differences
- Quick check: Compare distance distributions using synthetic clusters with varying dispersion levels

**Empirical Centroid Calculation**
- Why needed: The centroid represents the geometric center of sampled generations and serves as the reference point
- Quick check: Validate centroid computation on small, controlled sample sets with known relationships

## Architecture Onboarding

**Component Map**
- LLM generation sampling -> Embedding extraction -> Centroid computation -> ℓ1 distance calculation -> Uncertainty scoring

**Critical Path**
The core computation path is: sample generation → embedding extraction → centroid → pairwise ℓ1 distances → sum for final score. Each step must complete successfully for RDS calculation.

**Design Tradeoffs**
- ℓ1 vs ℓ2: ℓ1 provides robustness to outliers but may be less sensitive to subtle variations
- Sample size: More samples improve stability but increase computational cost
- Embedding model choice: Different embeddings capture different semantic aspects

**Failure Signatures**
- Uniformly low RDS scores may indicate embeddings don't capture semantic diversity
- Extremely high scores could suggest poor centroid representation or outlier samples
- Non-monotonic behavior with sample size may indicate unstable embedding space

**First 3 Experiments**
1. Generate 10 samples from a single prompt and compute RDS to verify basic functionality
2. Compare RDS scores across prompts with known difficulty levels
3. Test RDS sensitivity by comparing embeddings from different models on identical samples

## Open Questions the Paper Calls Out
None

## Limitations
- Performance in open-ended generation tasks with ambiguous ground truth remains untested
- The ℓ1 metric assumption may not hold uniformly across all embedding models or languages
- RDSw depends on per-token probability access, which may not be available in all settings
- Model-agnostic claim is limited by embedding access requirements

## Confidence

**High Confidence**: The geometric interpretation of RDS as ℓ1 radial dispersion from centroid is mathematically sound and clearly articulated. Empirical results on QA datasets demonstrate consistent improvement over baselines.

**Medium Confidence**: Scalability and robustness claims are supported by experiments, but sample size and embedding choice sensitivity analysis is limited to evaluated settings. Model-agnostic assertion holds for embedding-accessible models but may not generalize to all LLM architectures.

**Low Confidence**: Performance in non-QA or open-ended generation tasks is not evaluated, leaving uncertainty about general applicability to broader uncertainty estimation scenarios.

## Next Checks

1. Evaluate RDS on open-ended generation tasks (e.g., story continuation, dialogue) where ground truth is ambiguous or multiple valid outputs exist.

2. Test the metric's sensitivity to embedding dimensionality and choice of distance metric (e.g., ℓ2, cosine) across diverse embedding models.

3. Assess RDS performance in multilingual settings and with models lacking per-token probability access to verify true model-agnostic behavior.