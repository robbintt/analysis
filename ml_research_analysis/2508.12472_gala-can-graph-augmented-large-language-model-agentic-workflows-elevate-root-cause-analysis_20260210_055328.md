---
ver: rpa2
title: 'GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root
  Cause Analysis?'
arxiv_id: '2508.12472'
source_url: https://arxiv.org/abs/2508.12472
tags:
- gala
- root
- cause
- reasoning
- causal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GALA, a multi-modal framework for root cause
  analysis in microservice systems that combines statistical causal inference with
  LLM-driven iterative reasoning. The framework uses metrics-based causal structure
  learning alongside a novel trace-based scoring approach (TWIST) to generate initial
  hypotheses, then employs a multi-agent LLM system to iteratively refine root cause
  rankings through evidence-based analysis.
---

# GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?

## Quick Facts
- arXiv ID: 2508.12472
- Source URL: https://arxiv.org/abs/2508.12472
- Reference count: 40
- Primary result: Achieves up to 42.22% Top-1 accuracy on RCAEval benchmark, outperforming state-of-the-art methods

## Executive Summary
This paper introduces GALA, a multi-modal framework for root cause analysis in microservice systems that combines statistical causal inference with LLM-driven iterative reasoning. The framework uses metrics-based causal structure learning alongside a novel trace-based scoring approach (TWIST) to generate initial hypotheses, then employs a multi-agent LLM system to iteratively refine root cause rankings through evidence-based analysis. Evaluated on the RCAEval benchmark, GALA achieves up to 42.22% Top-1 accuracy, significantly outperforming state-of-the-art methods.

## Method Summary
GALA operates in four phases: (1) Initial hypothesis generation using dual-modality approach combining metrics-based causal discovery (BARO, CausalRCA) with TWIST trace scoring; (2) Pod-centric diagnostic synthesis creating temporal performance plots, service dependency subgraphs, and error-centric log abstractions; (3) Iterative ReAct multi-agent workflow with Re-ranking, Deep Dive, and Remediation agents; (4) Final output preparation with ranked root causes, incident summaries, and action recommendations. The framework processes multi-modal telemetry data (metrics, logs, traces) from the RCAEval benchmark's 90 injected-fault scenarios across 5 services and 6 failure types.

## Key Results
- Achieves 42.22% Top-1 accuracy, significantly outperforming single-modality baselines
- Iterative reasoning improves accuracy from 14.44% to 42.22% for memory leak faults
- Introduces SURE-Score, a human-guided evaluation framework for RCA-related NLG tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dual-modality hypothesis generation produces complementary root cause candidates
- Mechanism: TWIST computes trace-based rankings using four normalized scores fused via weighted average, combined with metrics-based causal discovery
- Core assumption: The four TWIST dimensions capture orthogonal aspects of fault behavior
- Evidence anchors: Combines statistical causal inference with LLM-driven iterative reasoning; TWIST formula integrates four anomaly dimensions
- Break condition: If faults manifest primarily in log semantics rather than latency/throughput patterns

### Mechanism 2
- Claim: Iterative multi-agent ReAct workflow improves ranking accuracy over single-pass inference
- Mechanism: Re-ranking Agent decides "Analyze Next" or "Finish"; Deep Dive Agent synthesizes pod-centric artifacts; iterations continue until termination or max rounds (6)
- Core assumption: Iterative evidence gathering reduces misattribution compared to one-shot ranking
- Evidence anchors: Orchestrates an iterative, multi-agent ReAct reasoning loop; achieves 42.22% AC@1 vs. 14.44% baseline
- Break condition: If diagnostic bundle artifacts are malformed or incomplete

### Mechanism 3
- Claim: Modality-preserving presentation enables LLMs to leverage domain-specific signal patterns
- Mechanism: Phase II generates three artifact types per candidate pod: temporal plots, trace subgraphs, error-centric logs
- Core assumption: LLMs can effectively cross-reference visual and textual modalities without prior fusion
- Evidence anchors: Preserves and presents heterogeneous telemetry data without collapsing it into unified representations
- Break condition: If token budgets or image encoding fail for large-scale incidents

## Foundational Learning

- **Microservice telemetry modalities (metrics, logs, traces)**: Understanding how CPU/memory time-series differ from span-level DAGs and error-log semantics is essential for interpreting diagnostic bundles correctly. Quick check: Given a latency spike in the frontend service, which modality would you inspect first to distinguish network delay from application-level errors?

- **Causal structure learning and PageRank/Random Walk ranking**: Initial hypothesis generation builds on metrics-based causal discovery and graph centrality; understanding edge-direction errors and confounding is essential for diagnosing baseline failures. Quick check: If a causal discovery algorithm returns a DAG with reversed edge directions, how would this affect downstream LLM-based re-ranking?

- **ReAct agentic workflow pattern**: GALA's iterative loop uses Reasoning-Action traces; engineers must debug agent termination conditions and prompt-template adherence. Quick check: What observable signal would indicate the Re-ranking Agent is stuck in a loop without converging?

## Architecture Onboarding

- **Component map**: Input telemetry -> TWIST + causal discovery -> top-k candidates -> Deep Dive Agent artifact retrieval -> Re-ranking Agent decision -> iterate or terminate -> Remediation Agent synthesis
- **Critical path**: Input telemetry → TWIST + causal discovery → top-k candidates → Deep Dive Agent artifact retrieval → Re-ranking Agent decision → iterate or terminate → Remediation Agent synthesis
- **Design tradeoffs**: Dual-modality seeding vs. compute cost; iteration cap (6) vs. accuracy; LLM selection for latency/quality requirements
- **Failure signatures**: Empty or truncated diagnostic bundles; non-termination in agentic loop; TWIST producing near-uniform scores
- **First 3 experiments**: (1) Baseline comparison on RE2-OB subset across 30 incidents; (2) Ablation of TWIST vs. Deep Dive to quantify component contributions; (3) Token and latency budgeting to profile Phase II artifact sizes and Phase III API calls

## Open Questions the Paper Calls Out
None

## Limitations

- TWIST weighting parameters are unspecified, creating uncertainty about optimal weight choices
- Complete prompt templates for Deep Dive and Remediation Agents are not provided
- Trace DAG construction details are lacking, particularly for incomplete trace information
- Log abstraction heuristics are conceptually described but lack implementation specifics

## Confidence

- **High confidence**: Dual-modality hypothesis generation approach is well-specified and validated
- **Medium confidence**: Modality-preserving presentation claim is supported but lacks comparison to fusion approaches
- **Low confidence**: SURE-Score evaluation framework claims are difficult to validate without human evaluation details

## Next Checks

1. **TWIST weight sensitivity analysis**: Systematically vary the four component weights in TWIST and measure performance impact across different fault types

2. **Complete prompt template reconstruction**: Reconstruct Deep Dive and Remediation Agent prompts based on described functionality and validate performance

3. **Context budget stress testing**: Evaluate GALA's performance under progressively constrained context windows to identify minimum viable context size