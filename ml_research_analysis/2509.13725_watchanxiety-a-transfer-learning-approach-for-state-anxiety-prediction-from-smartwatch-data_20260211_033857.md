---
ver: rpa2
title: 'WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from
  Smartwatch Data'
arxiv_id: '2509.13725'
source_url: https://arxiv.org/abs/2509.13725
tags:
- anxiety
- data
- state
- social
- participants
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of predicting within-person
  fluctuations in state anxiety using smartwatch-collected physiological data, specifically
  heart rate variability. The authors propose WatchAnxiety, a transfer learning approach
  that first develops a base model on over 10,000 days of external heart rate data
  from the TILES-18 dataset using a ResNet-18 architecture trained on recurrence plots
  of heart rate variability.
---

# WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data

## Quick Facts
- arXiv ID: 2509.13725
- Source URL: https://arxiv.org/abs/2509.13725
- Reference count: 17
- Primary result: 60.4% balanced accuracy for state anxiety prediction from smartwatch HR data using transfer learning

## Executive Summary
This study addresses the challenge of predicting within-person fluctuations in state anxiety using smartwatch-collected physiological data, specifically heart rate variability. The authors propose WatchAnxiety, a transfer learning approach that first develops a base model on over 10,000 days of external heart rate data from the TILES-18 dataset using a ResNet-18 architecture trained on recurrence plots of heart rate variability. This base model is then fine-tuned on their primary dataset of 72 socially anxious college students who received seven daily ecological momentary assessments (EMAs) over an average of 9 days. The resulting probabilistic predictions are combined with trait-level psychological measures in a meta-learner. The pipeline achieved 60.4% balanced accuracy in detecting state anxiety on their primary dataset.

## Method Summary
The WatchAnxiety pipeline uses transfer learning from the TILES-18 dataset (10,278 EMAs from hospital workers) to predict state anxiety in 72 college students. Heart rate data is converted to R-R intervals, filtered, and transformed into recurrence plots. A ResNet-18 base model trained on TILES-18 is fine-tuned on the primary dataset, with its probabilistic outputs combined with trait measures (SIAS, BFNE, DERS, etc.) in a meta-learner (Logit classifier). The system uses leave-five-out cross-validation for pretraining and leave-one-out cross-validation for evaluation, targeting balanced accuracy as the primary metric.

## Key Results
- Achieved 60.4% balanced accuracy on primary dataset of 72 socially anxious college students
- Outperformed prior work by at least 7 percentage points when evaluated on independent TILES-18 dataset (59.1% BA)
- Meta-learner combining sensor probabilities with trait measures produced more temporally sensitive predictions than trait-only models
- System supports integration of additional sensor modalities beyond heart rate for future work

## Why This Works (Mechanism)

### Mechanism 1
Transfer learning from large external datasets improves state anxiety prediction when target data is limited. The base model learns generalized representations of HR-anxiety relationships from 10,000+ days of TILES-18 data. These representations capture temporal patterns in HRV that transfer across populations (hospital workers → college students). Fine-tuning adapts the final layers while preserving learned features, enabling effective prediction with only 72 participants. Core assumption: Physiological signatures of anxiety share common patterns across different populations and collection protocols.

### Mechanism 2
Recurrence plots of HRV encode dynamic temporal patterns relevant to anxiety that raw time-series features may miss. R-R intervals are converted to recurrence plots via time-delayed embeddings, revealing recurrent patterns in physiological dynamics. ResNet-18, pre-trained on ImageNet, processes these 2D representations as images, extracting hierarchical features that capture non-linear temporal dependencies in autonomic nervous system activity. Core assumption: Recurrence patterns in HRV correlate with momentary anxiety states in ways detectable by convolutional architectures designed for natural images.

### Mechanism 3
Combining probabilistic sensor predictions with static trait measures in a meta-learner enables temporally sensitive, person-specific anxiety detection. The fine-tuned model outputs moment-by-moment anxiety probabilities from HR data. The meta-learner (Logit) integrates these with trait measures (SIAS, BFNE, DERS, etc.) selected via information gain. Trait measures provide stable baselines; sensor probabilities capture within-person fluctuations, yielding predictions that vary meaningfully within and across days. Core assumption: Trait anxiety and state anxiety share variance that trait measures can partially explain, while sensor-derived probabilities capture residual state-specific variance.

## Foundational Learning

- **Concept: Transfer Learning with Domain Shift** - Why needed: The model trains on hospital workers (TILES-18) with daily EMAs and continuous Fitbit data, then transfers to students with 7× daily EMAs and duty-cycled sampling. Quick check: Can you identify three specific differences between TILES-18 and the target dataset that might cause learned features to degrade?

- **Concept: Recurrence Quantification Analysis (RQA)** - Why needed: The pipeline relies on converting HR time series to recurrence plots before CNN processing. Understanding what temporal dynamics RQA preserves helps assess whether this representation choice is appropriate. Quick check: What information does a recurrence plot encode that a raw HR time series does not?

- **Concept: Leave-Five-Out Cross-Validation (LFOCV) with Class-Balanced Validation** - Why needed: The training protocol uses LFOCV with specific constraints to prevent validation set bias. Proper implementation requires understanding why standard k-fold would leak information in this participant-level design. Quick check: Why must validation participants be selected based on class ratio matching rather than random assignment?

## Architecture Onboarding

- **Component map**: HR samples (≥50 per window, 1–2 hours pre-EMA) → R-R interval calculation → recurrence plot generation via NeuroKit2 → ResNet-18 base model (ImageNet weights) → residual block + global average pooling → 512-dim representation → 32-unit FC + batch norm + ReLU → single probability output → meta-learner (Logit) taking [sensor probability + 4 trait measures selected via information gain] → binary state anxiety prediction

- **Critical path**: TILES-18 pretraining with LFOCV (20 epochs, LR=1e-4, then fine-tune at 1e-8) → transfer best checkpoint, freeze base weights, train new head (Nadam, LR=1e-5, 3% train-val loss tolerance) → extract probabilities, merge with trait features, train meta-learner with LOOCV

- **Design tradeoffs**: Window size (1h vs 1.5h vs 2h): Larger windows increase data availability but introduce EMA overlap; 1.5h selected as balance. Duty cycle (5-min vs 10-min): Earlier 10-min cycle caused participant exclusions; 5-min improves coverage but increases power draw. Meta-learner complexity: Lightweight models (KNN, Logit, Tree) chosen to minimize overfitting; Logit selected empirically. Binarization threshold: Responses >1 coded as anxious; threshold choice affects class balance and clinical interpretation

- **Failure signatures**: Trait-only model predicts constant class per participant (BA = 0%, 50%, or 100%): Meta-learner not receiving useful sensor probabilities. Recall drops sharply with shorter windows: Insufficient HR samples (<50 threshold) causing data missingness. Validation loss exceeds training loss by >3%: Overfitting; callback should restore earlier weights. Per-participant BA clusters near 50%: Model failing to capture individual variation; check trait feature selection

- **First 3 experiments**: 1) Validate recurrence plot pipeline on held-out TILES-18 subjects before transfer; confirm base model achieves >55% balanced accuracy to ensure representations are meaningful. 2) Ablate trait features from meta-learner; compare BA, recall, and per-participant variance against full model to quantify trait contribution. 3) Test alternative window sizes (0.5h, 1h, 1.5h, 2h) with systematic missingness analysis; verify 50-sample threshold is appropriate for your sampling protocol

## Open Questions the Paper Calls Out

- **Open Question 1**: Can incorporating additional sensor modalities (e.g., acoustic or movement data) improve prediction performance beyond heart rate alone? The authors state in the conclusion, "Future work will explore incorporating additional sensor modalities," noting the current system supports them but only HR was used.

- **Open Question 2**: How can the model's decision-making process be made interpretable for clinical application? The paper concludes that the "deep learning–based approach is limited by interpretability, which future work could address."

- **Open Question 3**: Can jointly determined thresholds between clinicians and users optimize the balance between sensitivity and specificity for Just-In-Time Adaptive Interventions (JITAIs)? The authors suggest "strategies such as thresholds jointly determined by clinicians and users... could help balance sensitivity and specificity."

## Limitations
- Cross-population assumption: Effectiveness depends on physiological anxiety signatures transferring across populations (hospital workers to college students) and device protocols, which is not empirically validated
- Representation validation: Recurrence plot representation lacks direct corpus validation for anxiety detection specifically
- Sample size: The 72-participant primary dataset remains relatively modest for transfer learning applications

## Confidence

- **High confidence**: The methodological framework for transfer learning from external datasets is sound and properly implemented with appropriate cross-validation procedures. The base model achieves the reported performance on TILES-18 and demonstrates successful transfer to the primary dataset.

- **Medium confidence**: The recurrence plot representation adds meaningful value beyond raw HRV features, given limited corpus validation but reasonable theoretical grounding. The meta-learner architecture choice (Logit) appears effective but lacks systematic comparison to alternatives.

- **Low confidence**: The assumption of cross-population physiological consistency is the weakest link; while the results support it, the mechanism is not empirically validated and could fail in different populations or device protocols.

## Next Checks
1. **Cross-population validation**: Test the base model on a third, independent population (e.g., clinical anxiety patients or different demographic group) to empirically validate the cross-population transferability assumption before clinical deployment.

2. **Representation ablation study**: Compare recurrence plot-based CNN performance against traditional HRV features (RMSSD, SDNN, etc.) on the same datasets to quantify the specific contribution of the image-based representation.

3. **Meta-learner architecture comparison**: Systematically evaluate alternative meta-learner architectures (Random Forest, Gradient Boosting, Neural Network) and feature selection methods to confirm Logit with information gain selection is optimal for this integration task.