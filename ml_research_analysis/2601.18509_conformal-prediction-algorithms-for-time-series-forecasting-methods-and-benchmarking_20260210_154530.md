---
ver: rpa2
title: 'Conformal Prediction Algorithms for Time Series Forecasting: Methods and Benchmarking'
arxiv_id: '2601.18509'
source_url: https://arxiv.org/abs/2601.18509
tags:
- prediction
- coverage
- conformal
- series
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper benchmarks conformal prediction (CP) methods for multi-horizon
  time series forecasting, addressing the challenge that temporal dependencies violate
  the exchangeability assumption underlying standard CP. It evaluates several CP variants
  on a large-scale monthly sales dataset, using AutoARIMA as the base forecaster and
  comparing marginal coverage, interval width, and Winkler scores.
---

# Conformal Prediction Algorithms for Time Series Forecasting: Methods and Benchmarking

## Quick Facts
- arXiv ID: 2601.18509
- Source URL: https://arxiv.org/abs/2601.18509
- Reference count: 6
- Primary result: MSCP demonstrated best efficiency among valid methods, outperforming alternatives in statistical significance tests

## Executive Summary
This paper benchmarks conformal prediction methods for multi-horizon time series forecasting, addressing the challenge that temporal dependencies violate the exchangeability assumption underlying standard CP. It evaluates several CP variants on a large-scale monthly sales dataset, using AutoARIMA as the base forecaster and comparing marginal coverage, interval width, and Winkler scores. Among the valid methods (meeting 90% coverage), multi-step split conformal prediction (MSCP) demonstrated the best efficiency, outperforming alternatives like ACI and Parametric-PI in statistical significance tests on a large corpus of time series data.

## Method Summary
The paper benchmarks conformal prediction methods for multi-horizon forecasting using AutoARIMA as the base forecaster with 12-month horizon (H=12) and 90% coverage target. The primary method, MSCP, partitions calibration residuals by forecast horizon using a rolling window approach to build a residual matrix S ∈ R^(T×H). For each horizon h, it computes empirical quantiles from historical errors to construct prediction intervals. The study evaluates coverage, interval width, and Winkler interval score across >3,000 time series, with statistical significance assessed via Friedman test with Conover-Friedman post-hoc analysis. Libraries used include Nixtla's statsforecast and R's forecast/conformalForecast packages.

## Key Results
- MSCP achieved the best efficiency (narrowest intervals) among valid methods meeting 90% coverage
- ACI and Global-CP successfully met coverage targets but with wider intervals
- EnbPI and SPCI failed to achieve 90% coverage on the sales dataset
- Statistical significance tests confirmed MSCP's superiority in efficiency

## Why This Works (Mechanism)

### Mechanism 1: Horizon-Specific Calibration (MSCP)
Partitioning calibration residuals by forecast horizon yields more efficient valid intervals as uncertainty scales non-linearly with time. The system maintains a residual matrix S storing historical errors indexed by horizon, computing quantiles strictly from the h-th column for predictions at that horizon.

### Mechanism 2: Adaptive Error Feedback (ACI)
Treating coverage as a control problem allows the system to maintain validity under distribution shifts by dynamically adjusting the effective miscoverage rate. The algorithm monitors recent coverage errors and updates α_t to widen or narrow intervals accordingly.

### Mechanism 3: Cross-Sectional Pooling (Global-CP)
Validity can be restored by redefining the unit of exchangeability from time points to independent time series, allowing aggregation of errors across a population with Bonferroni correction.

## Foundational Learning

- **Exchangeability vs. I.I.D.:** Standard CP requires exchangeability (permutation invariance), which is weaker than I.I.D. but still broken by time series order. Understanding this distinction explains why naive CP fails.
  - Quick check: If you shuffle the rows of your dataset, does the joint distribution change? If yes, standard CP guarantees are void.

- **Marginal vs. Conditional Coverage:** The paper emphasizes that methods achieve marginal coverage (correct on average across the test set), not conditional coverage (correct for every specific input x).
  - Quick check: Does a 90% coverage guarantee mean there is a 90% chance the next specific forecast will hit? (Answer: No, it refers to long-run frequency.)

- **The Conformity Score:** This is the "residual" metric used to rank errors. While usually |y - ŷ|, the paper references methods that model the dynamics of these scores.
  - Quick check: Is the nonconformity score required to be normally distributed? (Answer: No, CP is distribution-free.)

## Architecture Onboarding

- **Component map:** AutoARIMA -> Residual Store (S matrix) -> Calibrator (MSCP/ACI/Global-CP) -> Output: Prediction Interval
- **Critical path:** The computation of the horizon-specific quantile. For MSCP, ensuring the residual matrix is updated sequentially (no future leakage) is the single most critical implementation detail.
- **Design tradeoffs:**
  - MSCP vs. ACI: MSCP is more efficient in stable regimes; ACI is robust to non-stationarity but suffers slight efficiency loss.
  - Global-CP vs. Single-Series CP: Global-CP is valid for joint trajectories but requires many independent series and produces wider intervals.
  - Parametric-PI: Fastest and simplest, but lacks distribution-free guarantees and didn't distinguish itself in efficiency.
- **Failure signatures:**
  - Under-coverage (Coverage < 90%): Observed in EnbPI and SPCI. Likely caused by strict assumptions failing on real-world data.
  - Over-coverage (Coverage >> 90%): Excessively wide intervals. Sign of conservative correction or high base model volatility.
- **First 3 experiments:**
  1. Implement naive Split CP vs. MSCP on a subset. Verify that naive coverage drops below target due to temporal leakage, while MSCP holds.
  2. Plot interval width q_h vs. horizon h. Verify that MSCP captures the cone of uncertainty better than a static quantile model.
  3. Inject synthetic distribution shift into test set. Compare recovery speed of ACI (adaptive) vs. MSCP (static history).

## Open Questions the Paper Calls Out
None

## Limitations
- Empirical validation confined to one dataset (large-scale monthly sales), limiting generalizability to other domains or data frequencies
- Temporal stationarity assumptions for MSCP may break under abrupt regime changes not captured in historical error matrix
- ACI's adaptive performance is sensitive to choice of learning rate γ, which was not tuned or discussed in detail

## Confidence
- **High Confidence:** MSCP achieves best efficiency among valid methods; AutoARIMA as base forecaster; 90% coverage target and use of Winkler score
- **Medium Confidence:** ACI's robustness to distribution shifts (limited stress-test discussion); Global-CP's validity for joint trajectories (Bonferroni correction effect not quantified)
- **Low Confidence:** EnbPI and SPCI failure modes (insufficient diagnostic detail on why assumptions broke); Parametric-PI efficiency claims

## Next Checks
1. Apply MSCP and ACI to a sales dataset with known synthetic regime shifts; measure coverage recovery time and interval width evolution
2. Test MSCP on a single time series (e.g., M4 monthly subset) to quantify coverage loss without cross-series pooling
3. Vary γ in ACI and Bonferroni factor in Global-CP; assess trade-offs between coverage stability and interval width efficiency