---
ver: rpa2
title: 'In Search of Goodness: Large Scale Benchmarking of Goodness Functions for
  the Forward-Forward Algorithm'
arxiv_id: '2511.18567'
source_url: https://arxiv.org/abs/2511.18567
tags:
- uni0000004f
- uni00000048
- uni00000044
- uni00000052
- uni00000046
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study benchmarks 21 distinct goodness functions for the Forward-Forward
  algorithm across four image datasets. While Hinton's standard sum-of-squares baseline
  works reasonably well, several alternative goodness functions significantly outperform
  it.
---

# In Search of Goodness: Large Scale Benchmarking of Goodness Functions for the Forward-Forward Algorithm

## Quick Facts
- arXiv ID: 2511.18567
- Source URL: https://arxiv.org/abs/2511.18567
- Authors: Arya Shah; Vaibhav Tripathi
- Reference count: 40
- Primary result: Benchmark of 21 goodness functions reveals significant accuracy and efficiency differences, with sparse_l1_local achieving best accuracy (43.82%) and lowest energy (14.02 g CO2) on CIFAR-10.

## Executive Summary
This study systematically benchmarks 21 distinct goodness functions for the Forward-Forward (FF) algorithm across four image classification datasets. The research reveals that while Hinton's standard sum-of-squares baseline performs reasonably well, several alternative goodness functions significantly outperform it. The predictive_coding_local function achieved 43.42% accuracy on CIFAR-10, softmax_energy_margin_local reached 86.32% on FashionMNIST, and triplet_margin_local attained 37.72% on STL-10. Critically, the sparse_l1_local function was both the most accurate (43.82%) and most energy-efficient (14.02 g CO2) on CIFAR-10, demonstrating that superior performance need not come at environmental cost. Some biologically-inspired functions like bcm_local and outlier_trimmed_energy_local failed completely, suggesting instability in greedy layer-wise training. The results demonstrate that the choice of goodness function is a critical hyperparameter that significantly impacts both predictive performance and computational efficiency.

## Method Summary
The study benchmarks 21 goodness functions using a 4-layer fully connected neural network (2000 neurons per layer) trained with the Forward-Forward algorithm. The method involves training each layer locally to maximize goodness for positive samples (image with correct label) and minimize it for negative samples (image with incorrect label). Training uses Adam optimizer with learning rate 1e-3, weight decay 3e-4, and peer normalization coefficient 0.03. The primary metric is "Multi-pass Accuracy" - native FF inference that accumulates goodness across labels and selects the highest. Carbon emissions are tracked using CodeCarbon. Four datasets are evaluated: MNIST, FashionMNIST, CIFAR-10, and STL-10, with 20 epochs per run.

## Key Results
- The sparse_l1_local function achieved 43.82% accuracy and 14.02 g CO2 on CIFAR-10, outperforming the baseline sum_of_squares.
- Softmax_energy_margin_local reached 86.32% accuracy on FashionMNIST, significantly exceeding baseline performance.
- Triplet_margin_local attained 37.72% accuracy on STL-10, demonstrating effectiveness on complex datasets.
- Biologically-inspired functions bcm_local and outlier_trimmed_energy_local failed completely, achieving only random chance accuracy (~10%).

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The specific mathematical formulation of the "goodness" function acts as the primary driver for the quality and stability of learned representations in the Forward-Forward (FF) algorithm.
- **Mechanism:** FF replaces backpropagation with a greedy, layer-wise local update rule. Each layer updates its weights to maximize a scalar "goodness" $G(y)$ for positive data and minimize it for negative data. The paper demonstrates that this objective actively shapes the energy landscape. For instance, `sparse_l1_local` (Equation 21: $G(h) = \|h\|_2^2 - \lambda\|h\|_1$) forces the network to select specific features, reducing computational load, whereas `bcm_local` (Equation 11) introduces a sliding threshold that can destabilize training without a global error signal.
- **Core assumption:** A local scalar objective is sufficient to guide the network toward useful hierarchical representations without global gradients.
- **Evidence anchors:**
  - [abstract] "FF's efficacy relies heavily on the definition of 'goodness', which is a scalar measure of neural activity."
  - [section 3.2] Defines the local loss function $L$ based on the goodness of positive versus negative samples.
  - [corpus] "NetworkFF" supports the finding that standard FF suffers from "inter-layer isolation," suggesting that the choice of local objective is critical because layers cannot rely on global corrections.
- **Break condition:** The mechanism fails if the goodness function creates an unstable or collapsing loss landscape (e.g., `bcm_local` achieving random chance accuracy).

### Mechanism 2
- **Claim:** Contrastive learning through "hybrid" negative samples enforces the binding of visual features to semantic identity.
- **Mechanism:** The system generates negative data by pairing an image with an incorrect one-hot label vector. The network is trained to distinguish between coherent "positive" data (Image + Correct Label) and incoherent "negative" data (Image + Wrong Label). This forces the network to learn the correlation between visual features and the label representation, rather than just memorizing the data distribution.
- **Core assumption:** The network can effectively detect the semantic inconsistency between the visual input and the label embedding provided in the negative samples.
- **Evidence anchors:**
  - [section 3.2.1] "Positive samples consist of an image combined with its correct one-hot label, while negative samples consist of the same image combined with an incorrect label."
  - [section 5.1] Discusses how objectives like `softmax_energy_margin_local` enforce separation between positive and negative samples.
  - [corpus] "Stochastic Forward-Forward Learning" confirms that FF relies on "well-designed negative samples for contrastive learning."
- **Break condition:** Failure occurs if the negative samples are too similar to positive samples (vanishing gradient) or if the label embedding provides no learnable signal for the specific architecture.

### Mechanism 3
- **Claim:** Enforcing sparsity and decorrelation in activations improves both energy efficiency and predictive performance simultaneously.
- **Mechanism:** Traditional objectives like `sum_of_squares` encourage dense activity, which is computationally expensive. The `sparse_l1_local` function adds an L1 penalty to encourage most neurons to be zero. This reduces the number of active synaptic updates required, lowering carbon emissions (Green AI), while simultaneously acting as a regularizer that improves generalization on complex datasets like CIFAR-10.
- **Core assumption:** "Good" representations for visual tasks are naturally sparse and independent, aligning with theories of efficient coding in the visual cortex.
- **Evidence anchors:**
  - [key outcome] "The `sparse_l1_local` function was both the most accurate (43.82%) and most energy-efficient (14.02 g CO2) on CIFAR-10."
  - [section 4.1] Discusses that efficient coding leads to both smarter and greener networks.
  - [corpus] Corpus evidence on specific sparsity mechanisms for efficiency is weak; related works focus on architectural scaling rather than the specific L1 energy-to-carbon link.
- **Break condition:** If the sparsity constraint is too aggressive, neurons may die (zero activity permanently), preventing the layer from representing the data.

## Foundational Learning
- **Concept: The Forward-Forward (FF) Algorithm**
  - **Why needed here:** This is the alternative to backpropagation being optimized. It replaces the backward pass with a second forward pass on negative data.
  - **Quick check question:** Can you explain why FF requires two separate forward passes instead of one forward and one backward pass?

- **Concept: Greedy Layer-wise Training**
  - **Why needed here:** The architecture is trained one layer at a time. An error or instability in an early layer cannot be corrected by later layers.
  - **Quick check question:** How does the "local" nature of the update rule affect the debugging process if a specific layer fails to converge?

- **Concept: Energy-Based Models (EBMs)**
  - **Why needed here:** "Goodness" is interpreted as negative energy. Understanding this connects the specific math (e.g., `tempered_energy`) to a broader theoretical framework.
  - **Quick check question:** In the context of this paper, does maximizing "goodness" mean raising or lowering the energy of the system?

## Architecture Onboarding
- **Component map:** Input (Flattened, normalized image + One-hot label vector) -> Negative Generator (Shuffle/misassign labels) -> Core Network (4-layer MLP, 2000 neurons/layer) -> Goodness Registry (21 pluggable functions) -> Evaluation (Linear classifier + Multi-pass inference) -> Tracking (CodeCarbon logger)

- **Critical path:** The selection and integration of the **Goodness Function** is the single point of failure. If the function creates a non-differentiable or unstable gradient for the layer activations, the entire greedy pipeline collapses.

- **Design tradeoffs:**
  - **Baseline vs. Performance:** The standard `sum_of_squares` is simple but often sub-optimal in accuracy.
  - **Complexity vs. Stability:** Complex bio-inspired functions like `bcm_local` offer theoretical appeal but failed completely (10% accuracy) in this specific implementation due to instability in greedy training.
  - **Accuracy vs. Carbon:** `triplet_margin_local` achieved high accuracy on STL-10 but cost more energy than some baselines. `sparse_l1_local` defied this trade-off by being Pareto-optimal (best accuracy, lowest cost).

- **Failure signatures:**
  - **Random Chance Accuracy (~10%):** Observed in `bcm_local` and `outlier_trimmed_energy_local`. Indicates the layer failed to learn any representation (collapse).
  - **High Loss Fluctuation:** Non-converging loss curves suggest the objective function is ill-suited for the dataset's distribution (e.g., `outlier_trimmed_energy` trimming too much signal).
  - **"Runaway" Updates:** Specific to unstable bio-inspired rules where thresholds fail to stabilize without global error correction.

- **First 3 experiments:**
  1. **Baseline Verification:** Train the standard `sum_of_squares` on MNIST to ensure the pipeline produces the expected ~98% multi-pass accuracy and establish an energy baseline.
  2. **Failure Mode Analysis:** Implement `bcm_local` on MNIST. Observe if accuracy drops to random chance (~10%) to confirm the paper's finding regarding the instability of greedy layer-wise training with sliding thresholds.
  3. **Pareto Optimization:** Implement `sparse_l1_local` on CIFAR-10. Verify that it achieves higher accuracy (>43%) with lower carbon emissions (<14.5 g CO2) compared to the baseline.

## Open Questions the Paper Calls Out
- **Question:** Does the superior energy efficiency of specific goodness functions (e.g., `sparse_l1`) persist when implemented on neuromorphic hardware?
  - **Basis in paper:** [explicit] The conclusion explicitly directs "Future work should extend this analysis to neuromorphic hardware, where the local nature of these rules could yield even greater efficiency gains."
  - **Why unresolved:** The current study measures energy consumption and carbon footprint on standard GPU/CPU setups using the CodeCarbon library, not specialized hardware.
  - **What evidence would resolve it:** Empirical benchmarks of the top-performing functions deployed on neuromorphic chips (e.g., Intel Loihi) measuring real-time power consumption.

- **Question:** Can functions that failed to learn (e.g., `bcm_local`) be stabilized through specific homeostatic mechanisms or layer-wise hyperparameter tuning?
  - **Basis in paper:** [inferred] The discussion attributes the complete failure of certain functions (~10% accuracy) to "instability in greedy layer-wise training" and a lack of "homeostatic mechanisms to maintain stability."
  - **Why unresolved:** The study used a uniform hyperparameter set for all functions, which may have disadvantaged complex biological rules that require specific stabilization.
  - **What evidence would resolve it:** Experiments applying adaptive thresholds or local homeostatic constraints to the failing functions to see if they can converge without collapsing.

- **Question:** How does the strategy for generating negative data influence the relative performance of different goodness functions?
  - **Basis in paper:** [inferred] The methodology fixes the negative data strategy to "hybrid" images (Real Image + Wrong Label) without exploring alternatives, an unstated assumption that this generation method is optimal for all objectives.
  - **Why unresolved:** Contrastive objectives may vary in sensitivity to the quality or "hardness" of negative samples, but this variable was not isolated.
  - **What evidence would resolve it:** A comparative analysis varying the negative generation method (e.g., noise vs. hybrid images) across the registry of functions to test for interactions.

## Limitations
- The study identifies significant variability in goodness function performance across datasets, with some functions failing completely while others excel, but the exact reasons for stability differences between functions remain partially unexplained.
- The carbon efficiency findings, while promising, depend on specific hardware configurations and energy tracking methodologies that may not generalize across different computing environments.
- The specific failure modes of bio-inspired functions like `bcm_local` are documented empirically but lack complete theoretical explanation for why these mechanisms fail in greedy training but might succeed in other paradigms.

## Confidence
- **High confidence:** The core finding that goodness function selection significantly impacts both accuracy and energy efficiency is well-supported by the comprehensive benchmark results across four datasets.
- **Medium confidence:** The claim that sparse goodness functions enable Pareto-optimal performance (best accuracy with lowest energy) is supported for CIFAR-10 specifically, but may not generalize to all architectures or datasets without further validation.
- **Low confidence:** The specific failure modes of bio-inspired functions like `bcm_local` are documented empirically but lack complete theoretical explanation for why these mechanisms fail in greedy training but might succeed in other paradigms.

## Next Checks
1. **Cross-architecture validation:** Test the top-performing goodness functions (`sparse_l1_local`, `softmax_energy_margin_local`) on convolutional architectures rather than MLPs to verify generalization beyond the specific 4-layer fully connected setup.
2. **Energy reproducibility:** Replicate the carbon efficiency measurements across different hardware configurations (cloud vs. local GPUs, different chip manufacturers) to confirm the environmental claims aren't hardware-specific.
3. **Stability analysis:** Systematically vary the initialization and training parameters for unstable functions like `bcm_local` to determine if they can be stabilized through hyperparameter tuning rather than being fundamentally incompatible with greedy training.