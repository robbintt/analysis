---
ver: rpa2
title: FRQI Pairs method for image classification using Quantum Recurrent Neural Network
arxiv_id: '2512.11499'
source_url: https://arxiv.org/abs/2512.11499
tags:
- quantum
- image
- frqi
- qrnn
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the FRQI Pairs method, a novel approach for
  image classification using Quantum Recurrent Neural Networks (QRNN) with Flexible
  Representation for Quantum Images (FRQI). The method addresses the challenge of
  classifying quantum-encoded images by leveraging the FRQI encoding scheme to efficiently
  represent grayscale images using quantum states.
---

# FRQI Pairs method for image classification using Quantum Recurrent Neural Network

## Quick Facts
- arXiv ID: 2512.11499
- Source URL: https://arxiv.org/abs/2512.11499
- Reference count: 40
- Test accuracy of 74.6% on 8×8 MNIST classification

## Executive Summary
This paper introduces the FRQI Pairs method, a novel approach for image classification using Quantum Recurrent Neural Networks (QRNN) with Flexible Representation for Quantum Images (FRQI). The method addresses the challenge of classifying quantum-encoded images by leveraging the FRQI encoding scheme to efficiently represent grayscale images using quantum states. The FRQI Pairs architecture reduces the number of recurrent cells exponentially compared to previous QRNN approaches, requiring only n² cells instead of 2²ⁿ cells for n×n images.

## Method Summary
The FRQI Pairs method encodes grayscale images into quantum states using the FRQI representation, which separates position and color encoding. For an 8×8 image, this requires 7 qubits (3 for X position, 3 for Y position, 1 for color). The QRNN architecture consists of n² cells (6 cells for 8×8 images), where each cell processes a unique combination of position-encoding qubits alongside the shared color qubit. The method uses 4 shared memory qubits across all cells, with a parameterized quantum circuit (716 total parameters) and softmax output layer for classification.

## Key Results
- Achieved 74.6% test accuracy on 8×8 MNIST classification
- Uses 11 qubits total (4 memory + 7 FRQI) with 6 recurrent cells
- Comparable performance to other quantum methods (QCNN, VQDNN) with similar parameter count
- Reduces required cells from exponential (2²ⁿ) to polynomial (n²) compared to direct QRNN implementation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** FRQI encoding achieves logarithmic qubit scaling for image representation by separating position and color encoding.
- **Mechanism:** The FRQI representation encodes pixel position using ⌈log₂ W⌉ + ⌈log₂ H⌉ qubits for coordinates, plus one additional qubit for grayscale intensity via amplitude encoding (cos θₓ|0⟩ + sin θₓ|1⟩). For a 2ⁿ × 2ⁿ image, this requires ν = 2n + 1 qubits total.
- **Core assumption:** Images can be bounded by square dimensions and pixel values can be linearly mapped to [0, π/2] angles without critical information loss.
- **Evidence anchors:** Section II-B explains the encoding method; Figure 1 shows retrieved FRQI representation maintains recognizability after encoding.

### Mechanism 2
- **Claim:** The FRQI Pairs architecture reduces required recurrent cells from exponential (2²ⁿ) to polynomial (n²) by processing position-color qubit combinations in parallel.
- **Mechanism:** Rather than processing each of the 2²ⁿ pixels sequentially through separate cells, FRQI Pairs creates one cell per unique combination of position-encoding qubits. Each cell receives the shared color qubit alongside its assigned position pair, yielding N = n² cells.
- **Core assumption:** The QRNN can learn distributed representations where spatial information is processed across cells rather than sequentially per pixel.
- **Evidence anchors:** Section III-B states "The total number of cells depends on the number of combinations between x and y qubits... N = n²" and compares to exponential direct implementation.

### Mechanism 3
- **Claim:** Memory qubits in the QRNN provide recurrent state capacity that accumulates information across cell processing steps.
- **Mechanism:** Each of the n² cells contains a variational quantum circuit operating on shared memory qubits. The memory state is updated sequentially as cells process their assigned position-color pairs, with final memory state fed to softmax classification.
- **Core assumption:** 4 memory qubits provide sufficient Hilbert space dimension (16 basis states) to encode discriminative features for 10-class digit classification.
- **Evidence anchors:** Section III-B reports "Increasing the number of QRNN working memory qubits had a positive impact on the test results, with the highest examined number of 4 qubits."

## Foundational Learning

- **Concept: FRQI (Flexible Representation of Quantum Images)**
  - **Why needed here:** This is the input encoding layer—the entire architecture assumes images are already in FRQI form.
  - **Quick check question:** Given an 8×8 grayscale image, how many qubits does FRQI require? (Answer: 7 = 3 for x + 3 for y + 1 for color)

- **Concept: Variational Quantum Circuits (PQC/VQC)**
  - **Why needed here:** Each QRNN cell contains a parameterized quantum circuit with 716 total trainable parameters across cells.
  - **Quick check question:** What makes a quantum circuit "variational"? (Answer: It contains trainable parameters optimized via classical gradient descent)

- **Concept: Quantum State Measurement and Collapse**
  - **Why needed here:** Classification requires measuring the final quantum state to produce classical softmax inputs.
  - **Quick check question:** Why does the paper mention "10000 measurements" for image retrieval? (Answer: Single measurement collapses superposition—many shots needed to estimate amplitude distribution)

## Architecture Onboarding

- **Component map:**
  Input Image (8×8 grayscale) -> FRQI Encoding Circuit (7 qubits: 6 position + 1 color) -> QRNN Cells (n² = 6 cells for 8×8) -> Memory State (4 qubits) -> Measurement + Softmax (80 parameters) -> Classification Output (10 classes)

- **Critical path:** FRQI encoding fidelity -> cell weight initialization -> memory qubit entanglement depth -> measurement shot count

- **Design tradeoffs:**
  | Decision | Paper Choice | Alternative | Tradeoff |
  |----------|--------------|-------------|----------|
  | Image size | 8×8 (scaled from 28×28) | Full 28×28 | Lower resolution but fewer qubits (7 vs 11 for FRQI alone) |
  | Memory qubits | 4 | More (if available) | Paper found 4 was best tested; more may help but increases circuit depth |
  | Cell layers | 1 deep layer per cell | More layers | Simpler training vs. higher capacity |
  | Encoding | FRQI | Amplitude/angle encoding | Native quantum-image compatibility vs. potentially higher accuracy with preprocessing |

- **Failure signatures:**
  - Accuracy stuck near random (10%): Check FRQI encoding—pixel-to-angle mapping may be inverted or collapsed
  - Loss doesn't decrease: Barren plateau likely—reduce circuit depth or try different parameter initialization
  - High training accuracy, low test accuracy: Overfitting on small image size—add regularization or increase training data augmentation
  - Measurement results inconsistent across runs: Increase shot count (paper used 10,000 for retrieval visualization)

- **First 3 experiments:**
  1. **Baseline reproduction:** Implement FRQI encoding on 8×8 MNIST subset (1000 images), verify encoding/decoding fidelity matches Figure 1 before training classifier
  2. **Memory qubit sweep:** Test 1, 2, 3, 4 memory qubits on fixed 2-cell simplified model to validate paper's claim that "increasing memory qubits had positive impact"
  3. **Binary classification comparison:** Replicate on 2-class MNIST subset (e.g., 3 vs 6) as authors suggest, enabling comparison with [38] which achieved 85% on similar task—this isolates architecture performance from multi-class complexity

## Open Questions the Paper Calls Out

- **Open Question 1:** Does integrating quantum principal component analysis (qPCA) into the preprocessing phase improve the classification accuracy of the FRQI Pairs model without violating the fully quantum pipeline assumption?
  - **Basis in paper:** [explicit] The authors state, "The applicability of the quantum version of PCA [40], [41]... to the feature preprocessing phase should also be explored."
  - **Why unresolved:** While classical PCA improves performance in similar architectures, it requires classical computation, breaking the "quantum memory" concept. It is unknown if the quantum equivalent provides the same benefit.
  - **What evidence would resolve it:** Benchmarking the FRQI Pairs model with a qPCA preprocessing layer against the baseline model on the same dataset.

- **Open Question 2:** How does the FRQI Pairs architecture perform when applied to full-sized 28×28 images rather than the downscaled 8×8 versions?
  - **Basis in paper:** [explicit] The paper suggests that the model "may achieve even better results for full-sized images" despite the increase in trainable parameters and cells (from 6 to 25).
  - **Why unresolved:** The prototyping was constrained to scaled-down 8×8 images to manage complexity; the theoretical improvement on full-sized images has not been empirically verified.
  - **What evidence would resolve it:** Training and evaluation results using the full 28×28 MNIST dataset without downscaling.

- **Open Question 3:** Can the FRQI Pairs method maintain its performance when applied to datasets other than MNIST?
  - **Basis in paper:** [explicit] Citing recent criticism, the authors acknowledge that "further research is needed to test the approach on different datasets" to validate the benchmark.
  - **Why unresolved:** The method has only been tested on the MNIST dataset, which is often considered insufficient for proving general quantum advantage.
  - **What evidence would resolve it:** Publication of classification accuracy results on alternative standard datasets (e.g., Fashion-MNIST or CIFAR) using the FRQI Pairs method.

## Limitations

- QRNN cell architecture details are incomplete, requiring reference to external thesis for full implementation specifications
- Training hyperparameters (optimizer, learning rate, batch size, epochs) are unspecified, making exact reproduction challenging
- Only 6 of 9 possible (x,y) qubit pairs were used, but the selection criteria and assignment to specific cells is unclear

## Confidence

- **High confidence:** FRQI encoding mechanism and qubit scaling benefits, MNIST preprocessing steps, overall architecture framework
- **Medium confidence:** Memory qubit impact (4 qubits found optimal), test accuracy achievement (74.6%), parameter count (716 total)
- **Low confidence:** Exact QRNN cell circuit design, training procedure details, specific cell-to-qubit pair assignments

## Next Checks

1. **FRQI Encoding Verification:** Implement FRQI encoding on sample 8×8 MNIST images and verify decoding accuracy matches Figure 1 before proceeding with full training
2. **Memory Qubit Sweep:** Systematically test 1-4 memory qubits on a simplified 2-cell model to confirm the paper's finding that "increasing memory qubits had positive impact"
3. **Binary Classification Comparison:** Replicate the method on a 2-class MNIST subset (e.g., digits 3 vs 6) to enable direct comparison with [38]'s 85% accuracy result, isolating architecture performance from multi-class complexity