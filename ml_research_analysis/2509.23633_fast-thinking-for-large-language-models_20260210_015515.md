---
ver: rpa2
title: Fast Thinking for Large Language Models
arxiv_id: '2509.23633'
source_url: https://arxiv.org/abs/2509.23633
tags:
- reasoning
- arxiv
- tokens
- codebook
- thinking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces Latent Codebooks for Fast Thinking (LC-FT),
  a framework that enables large language models to perform efficient reasoning by
  learning compact strategy priors from concise Chain-of-Thought supervision. At inference,
  the model conditions on a small set of continuous thinking vectors distilled from
  a latent codebook, avoiding the inefficiency of explicit multi-step reasoning.
---

# Fast Thinking for Large Language Models

## Quick Facts
- **arXiv ID**: 2509.23633
- **Source URL**: https://arxiv.org/abs/2509.23633
- **Reference count**: 40
- **Primary result**: LC-FT achieves competitive accuracy with substantially shorter outputs compared to baseline methods, while GainRouter provides a controllable accuracy–efficiency trade-off.

## Executive Summary
This work introduces Latent Codebooks for Fast Thinking (LC-FT), a framework that enables large language models to perform efficient reasoning by learning compact strategy priors from concise Chain-of-Thought supervision. At inference, the model conditions on a small set of continuous thinking vectors distilled from a latent codebook, avoiding the inefficiency of explicit multi-step reasoning. To further improve efficiency, GainRouter dynamically switches between fast codebook-guided inference and slow explicit reasoning, suppressing overthinking and reducing token usage. Experiments on mathematical reasoning and programming benchmarks show that LC-FT achieves competitive accuracy with substantially shorter outputs compared to baseline methods, while GainRouter provides a controllable accuracy–efficiency trade-off.

## Method Summary
LC-FT learns a discrete codebook of reasoning strategies from concise CoT supervision during training. At inference, learnable queries attend over the codebook to produce continuous thinking tokens that condition subsequent layers. A two-stage training procedure first aligns thinking-token embeddings to reference rationale embeddings via cosine similarity, then fine-tunes with supervised learning. GainRouter dynamically switches between fast codebook-guided inference and slow explicit reasoning based on attention patterns and predicted length gains.

## Key Results
- LC-FT achieves competitive accuracy on mathematical reasoning and programming benchmarks
- GainRouter reduces average token usage from 19411 to 12797 on AIME while maintaining accuracy
- LC-FT demonstrates substantial reduction in output length compared to explicit reasoning methods

## Why This Works (Mechanism)

### Mechanism 1: Latent Codebook Distills Reasoning Strategies into Continuous Thinking Tokens
A discrete codebook captures reusable reasoning strategies from concise CoT supervision, which are composed into continuous thinking tokens that guide decoding without explicit token emission. Learnable queries attend over a codebook via cross-attention to produce K thinking-token vectors injected into the hidden sequence at layer L, conditioning subsequent layers with strategy-level priors. The core assumption is that concise CoT hints contain sufficient strategy information to be distilled into discrete prototypes that generalize across instances.

### Mechanism 2: Two-Stage Alignment-SFT Training Grounds Thinking Tokens in Reasoning Semantics
Aligning thinking-token representations to reference rationales before task-specific SFT enables the codebook to capture semantically meaningful strategies. Stage 1 aligns mean-pooled thinking-token embeddings to frozen reference model's rationale embeddings via cosine similarity loss. Stage 2 then fine-tunes with standard LM loss, conditioning on injected thinking tokens. The core assumption is that hidden-state alignment at intermediate layers transfers reasoning structure.

### Mechanism 3: GainRouter Dynamically Suppresses Overthinking via Uncertainty-Adjusted Gating
A lightweight router combining codebook attention patterns and predicted length gains selectively escalates to slow reasoning, avoiding token waste on problems solvable via fast path. Router pools question vector and thinking tokens, computes attention-weighted aggregation, then predicts raw_logit and length gain. An adaptive threshold adjusts per-instance based on attention entropy and predicted length gain.

## Foundational Learning

- **Cross-attention and learnable query mechanisms**: Needed to understand how queries compose multiple prototypes through codebook retrieval. Quick check: Given queries Q ∈ R^(K×H) and codebook C ∈ R^(M×H), what is the shape of attention matrix A, and what does each row represent?

- **LoRA (Low-Rank Adaptation)**: Required because only adapters from layer L onward are trainable, localizing adaptation to the sub-network consuming thinking tokens. Quick check: If W ∈ R^(d_out × d_in) is adapted as W' = W + BA where A ∈ R^(r×d_in), B ∈ R^(d_out×r), how many trainable parameters are added per linear layer?

- **Hidden-state alignment via cosine similarity**: Essential for understanding Stage 1 alignment that grounds thinking-token embeddings in reasoning semantics. Quick check: If z_T and z_R have cosine similarity 0.9, what is the alignment loss L_align? What happens if gradients flow into z_R (no stop-gradient)?

## Architecture Onboarding

- **Component map**: Input x → [Frozen layers 0 to L-1] → z_input → Codebook C (M×H) ← Learnable queries Q (K×H) → Cross-attention → T (K×H thinking tokens) → Refiner MLP (T + σ(TU_1)U_2) → Inject at layer L: Z^(L) = [z_input; T] → [LoRA-adapted layers L to end] → Output tokens. Router path: z_q, {z_ti} → Attention aggregation → MLP → raw_logit + δθ → fast/slow decision

- **Critical path**: (1) Concise CoT data construction with verification; (2) Stage 1 alignment training (codebook + refiner only, base frozen); (3) Stage 2 SFT with LoRA from layer L onward; (4) GainRouter training with paired fast/slow labels

- **Design tradeoffs**: Codebook size M (512 optimal with plateau at 1024), thinking tokens K (Math benefits from more K=48, code from fewer K=16), insert layer L (L≈32 optimal for Qwen3-4B)

- **Failure signatures**: Low Top-10 activation mass (T_10 close to 10/M baseline) indicates codebook not specializing; high router false-negative rate on held-out benchmarks suggests uncertainty calibration issues; catastrophic forgetting on OOD tasks as LoRA baseline showed

- **First 3 experiments**: (1) Ablate codebook entirely: Expect significant accuracy drop on math reasoning, confirming codebook is primary mechanism. (2) Vary insert layer L across {16, 24, 32, 40}: Profile accuracy vs. position; expect U-shaped curve with peak near middle-to-late layers. (3) Analyze codebook activation patterns by class: For held-out test set, compute per-class prototype overlap. If overlap is near zero, codebook has learned class-consistent strategies; if near random, alignment may have failed.

## Open Questions the Paper Calls Out
None

## Limitations
- Performance depends critically on quality and coverage of concise CoT supervision, with uncertain generalization to domains lacking high-quality verified CoT hints
- Method assumes reasoning strategies can be effectively distilled into discrete codebook entries, which may not hold for problems requiring novel or highly context-dependent reasoning patterns
- GainRouter's effectiveness relies on accurate difficulty prediction that could degrade with distribution shifts or adversarial inputs

## Confidence

**High Confidence**: The core mechanism of using latent codebooks to guide reasoning through continuous thinking tokens is well-supported by ablation studies showing significant accuracy drop when removing the codebook layer.

**Medium Confidence**: The GainRouter's ability to dynamically suppress overthinking is demonstrated through controlled experiments, but generalization of the learned routing policy to unseen problem types warrants further investigation.

**Low Confidence**: Claims about computational efficiency relative to explicit reasoning methods are supported by token count comparisons but don't fully account for overhead of codebook lookup and router computations.

## Next Checks

1. **Distribution Shift Robustness Test**: Evaluate LC-FT on reasoning problems from completely different domains (e.g., commonsense reasoning, scientific analysis) without domain-specific fine-tuning. Measure both accuracy degradation and router behavior changes.

2. **Codebook Diversity Analysis**: Quantitatively analyze activation patterns across all M codebook entries on a diverse test set. Compute pairwise cosine similarity between entries and measure entropy of prototype activations per problem class.

3. **Router Uncertainty Calibration**: Conduct controlled experiments varying problem difficulty systematically and measure how well router's uncertainty metrics correlate with actual performance degradation.