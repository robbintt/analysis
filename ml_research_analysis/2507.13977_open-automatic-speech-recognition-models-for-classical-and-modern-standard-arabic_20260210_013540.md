---
ver: rpa2
title: Open Automatic Speech Recognition Models for Classical and Modern Standard
  Arabic
arxiv_id: '2507.13977'
source_url: https://arxiv.org/abs/2507.13977
tags:
- arabic
- speech
- recognition
- data
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces two open Arabic ASR models for Modern Standard
  Arabic (MSA) and Classical Arabic (CA), addressing the challenge of Arabic's linguistic
  complexity and limited public models. The authors present a universal methodology
  for Arabic speech and text processing, training models based on the FastConformer
  architecture.
---

# Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic

## Quick Facts
- arXiv ID: 2507.13977
- Source URL: https://arxiv.org/abs/2507.13977
- Authors: Lilit Grigoryan; Nikolay Karpov; Enas Albasiri; Vitaly Lavrukhin; Boris Ginsburg
- Reference count: 40
- Primary result: Introduces open ASR models for MSA (WER 11.37% on MASC) and CA (WERPC,D 1.55% on EveryAyah)

## Executive Summary
This paper presents two open Arabic ASR models for Modern Standard Arabic (MSA) and Classical Arabic (CA), addressing the challenge of Arabic's linguistic complexity and limited public models. The authors introduce a universal methodology for Arabic speech and text processing, training models based on the FastConformer architecture. The MSA model achieves state-of-the-art performance with WERs of 11.37% on MASC, 9.76% on MCV Arabic, and 7.73% on FLEURS Arabic subset. The unified model attains SOTA accuracy with diacritics for CA (WERPC,D of 1.55%/6.65% on EveryAyah) while maintaining strong MSA performance.

## Method Summary
The paper employs FastConformer hybrid RNN-T + CTC architecture with transfer learning from Spanish checkpoints, universal preprocessing pipeline (NFKC normalization, Kasheeda