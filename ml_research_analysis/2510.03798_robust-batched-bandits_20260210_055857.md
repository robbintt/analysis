---
ver: rpa2
title: Robust Batched Bandits
arxiv_id: '2510.03798'
source_url: https://arxiv.org/abs/2510.03798
tags:
- regret
- logt
- should
- where
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies batched multi-armed bandit problems with heavy-tailed
  reward distributions, bridging a critical gap between batched bandit theory and
  real-world applications where outcomes exhibit heavy-tailed characteristics. The
  authors develop robust batched bandit algorithms that can handle heavy-tailed rewards
  in both finite-arm and Lipschitz settings.
---

# Robust Batched Bandits

## Quick Facts
- arXiv ID: 2510.03798
- Source URL: https://arxiv.org/abs/2510.03798
- Authors: Yunwen Guo; Yunlun Shu; Gongyi Zhuo; Tianyu Wang
- Reference count: 40
- Key outcome: This paper studies batched multi-armed bandit problems with heavy-tailed reward distributions, bridging a critical gap between batched bandit theory and real-world applications where outcomes exhibit heavy-tailed characteristics.

## Executive Summary
This paper addresses batched multi-armed bandit problems with heavy-tailed reward distributions, where standard Gaussian assumptions break down. The authors develop robust algorithms that handle heavy-tailed rewards in both finite-arm and Lipschitz settings by explicitly tying communication time points to the heavy-tail parameter ε and modifying existing algorithms accordingly. A key finding is that heavier-tailed rewards paradoxically require fewer communication batches to achieve near-optimal regret in instance-independent settings, while the optimal communication pattern in instance-dependent settings remains invariant to tail heaviness.

## Method Summary
The paper proposes batched bandit algorithms for heavy-tailed rewards by introducing robust estimators (specifically Median-of-Means) and communication grids explicitly parameterized by the heavy-tail parameter ε. For finite-arm bandits, BaSE-H (Batched Successive Elimination for Heavy-Tailed Bandits) uses the MoM estimator with a geometrically increasing grid $\mathcal{T}_1$ where time points scale as $t_m = l \cdot (t_{m-1})^{\frac{\varepsilon}{1+\varepsilon}}$. For Lipschitz bandits, BLiN partitions the space into cubes and refines partitions based on robust estimates. The algorithms eliminate suboptimal arms when the difference in estimated means exceeds a threshold involving $v^{\frac{1}{1+\varepsilon}} (\frac{\log(TK)}{\tau})^{\frac{\varepsilon}{1+\varepsilon}}$, where $v$ is a variance proxy.

## Key Results
- Heavier-tailed rewards (smaller ε) require fewer communication batches to achieve near-optimal regret in instance-independent settings
- In instance-dependent settings, the optimal communication pattern remains invariant to tail heaviness
- The paper establishes upper and lower bounds on regret and the minimum number of batches needed for near-optimal performance
- Robust estimation via Median-of-Means allows concentration bounds that scale with the bounded (1+ε)-th moment rather than variance

## Why This Works (Mechanism)

### Mechanism 1: Robust Estimation of Heavy-Tailed Rewards
Standard sample means fail to concentrate when rewards have infinite variance; robust estimators recover concentration at the cost of sample complexity. The algorithm replaces standard averaging with a Median-of-Means (MoM) estimator, dividing the data stream into k blocks, computing the mean for each block, and taking the median of these means. This filters out extreme outliers, allowing confidence intervals that scale with the bounded (1+ε)-th moment rather than variance. Core assumption: The reward distribution has a finite (1+ε)-th moment for some ε ∈ (0, 1].

### Mechanism 2: Tail-Dependent Communication Schedules (Instance-Independent)
In minimax settings, heavier tails paradoxically necessitate fewer communication batches to achieve near-optimal regret. The authors argue that adding more batches cannot compensate for the informational deficit caused by heavy tails, as frequent policy updates do not help overcome the inherent noise of heavy-tailed samples. The algorithm defines a communication grid $\mathcal{T}_1$ where time points scale geometrically based on ε. Core assumption: The problem is analyzed under the instance-independent (minimax) regime where suboptimality gaps are small.

### Mechanism 3: Divergence of Batch Complexity in Instance-Dependent Settings
When optimizing for specific problem instances with large gaps, the communication schedule decouples from the tail parameter ε. In the instance-dependent setting, the hardness is dominated by distinguishing arms with large gaps rather than the noise profile. The algorithm uses a grid $\mathcal{T}_2$ (simple doubling/geometric schedule) that does not rely on ε. Here, the regret bound includes ε in the numerator but the batch allocation strategy remains invariant. Core assumption: There exists a distinct suboptimality gap Δ > 0 between arms.

## Foundational Learning

- **Concept: Heavy-Tailed Distributions (Moment Bounds)**
  - Why needed here: You cannot understand the problem without realizing that standard "Gaussian" assumptions (light tails) are broken. The paper relies on the existence of the (1+ε)-th moment (E[|X|^{1+ε}] < ∞), which allows for infinite variance (when ε < 1).
  - Quick check question: If a distribution has finite mean but infinite variance, does it satisfy the ε=1 case or ε < 1? (Answer: ε < 1).

- **Concept: Batched Feedback / Limited Adaptivity**
  - Why needed here: The core constraint is that the algorithm cannot update its policy after every sample. It must commit to a sequence of actions (a batch) and only update after seeing the aggregate results.
  - Quick check question: Why does minimizing the number of batches matter in clinical trials? (Answer: Logistics, administrative overhead, and the need to analyze safety data in cohorts).

- **Concept: Minimax (Instance-Independent) vs. Instance-Dependent Regret**
  - Why needed here: The paper's counterintuitive result applies only to the minimax setting. You must distinguish between "worst-case performance across all problems" (minimax) and "performance on a specific problem with known difficulty" (instance-dependent).
  - Quick check question: Does the "fewer batches for heavier tails" rule apply if I know my best arm is significantly better than the others? (Answer: No, in that instance-dependent case, the batch count is invariant).

## Architecture Onboarding

- **Component map:**
  1. Estimator: `MedianOfMeans(block_size, num_blocks)` -> Input: Raw rewards; Output: Robust mean estimate.
  2. Grid Scheduler:
      - `InstanceIndependentGrid(epsilon, T, M)`: Generates $\mathcal{T}_1$.
      - `InstanceDependentGrid(T, M)`: Generates $\mathcal{T}_2$.
  3. Policy (Elimination):
      - Finite-Arm (BaSE-H): Uniform exploration -> Robust estimation -> Eliminate suboptimal arms.
      - Lipschitz (BLiN): Partition space into cubes -> Refine partition based on robust estimates.

- **Critical path:**
The correctness depends heavily on the Grid Scheduler matching the Estimator. If you use a light-tailed grid (standard doubling) with heavy-tailed data, the confidence intervals will be invalid. Conversely, using the ε-tuned grid $\mathcal{T}_1$ is theoretically optimal for instance-independent heavy-tailed scenarios.

- **Design tradeoffs:**
  - Static vs. Adaptive Grids: The paper provides lower bounds for static grids (fixed schedule) and adaptive (data-dependent). Static grids are easier to implement (just a timestamp list) but adaptive grids may offer better constants at the cost of complexity.
  - Estimator Choice: Median-of-Means is standard, but Truncated Mean or Catoni's estimator could be swapped in; the paper abstractly uses $\hat{\mu}$ defined in Lemma 1.

- **Failure signatures:**
  - Mis-specified ε: If the true data has ε_true < ε_assumed (heavier tails than assumed), the confidence intervals derived in Lemma 1 will be too tight, causing the algorithm to prematurely eliminate the optimal arm.
  - Non-moment bounded data: If rewards have no moments (e.g., Cauchy), the mechanisms break down completely.

- **First 3 experiments:**
  1. Sanity Check (Synthetic): Run BaSE-H on a 2-arm bandit with Pareto-distributed rewards. Plot regret against the number of batches M for different ε values to confirm the "U-shape" or "elbow" where fewer batches become optimal for smaller ε.
  2. Ablation on Grids: Compare the regret of `InstanceIndependentGrid` ($\mathcal{T}_1$) vs. `InstanceDependentGrid` ($\mathcal{T}_2$) on heavy-tailed data. Verify that $\mathcal{T}_1$ outperforms $\mathcal{T}_2$ when gaps are small (minimax), while $\mathcal{T}_2$ wins when gaps are large.
  3. Robustness vs. Efficiency: Compare the robust estimator (MoM) vs. standard sample mean on heavy-tailed data within the batched constraint. Demonstrate that the standard mean diverges or incurs linear regret.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the counterintuitive relationship between tail heaviness and batch frequency—where heavier tails require fewer batches—hold in empirical simulations involving real-world or synthetic heavy-tailed data?
- Basis in paper: [explicit] Section 7 states that "empirical analysis is absent in this version" and lists evaluating the proposed methods through empirical studies as a necessary improvement.
- Why unresolved: The current work is entirely theoretical, relying on mathematical bounds and algorithmic analysis without experimental validation.
- What evidence would resolve it: Simulation results plotting regret against varying ε and batch counts M, specifically showing that algorithms with fewer batches perform near-optimally as tails get heavier.

### Open Question 2
- Question: Can the logarithmic gaps between the derived upper and lower regret bounds be closed to characterize the minimax regret exactly?
- Basis in paper: [explicit] Section 7 identifies "logarithmic gaps between the upper and lower bounds" as a specific limitation warranting further exploration.
- Why unresolved: The current theoretical analysis establishes the order of the bounds but leaves polylogarithmic factors unresolved, likely due to the techniques used for robust mean estimation.
- What evidence would resolve it: A refined analysis that removes logarithmic discrepancies, or a novel algorithm that achieves the lower bound exactly.

### Open Question 3
- Question: Do adaptive grid algorithms offer a distinct advantage over static grids in the heavy-tailed setting, particularly regarding the dependence on the number of batches M?
- Basis in paper: [inferred] Theorems 3 and 4 show a discrepancy between static and adaptive lower bounds (e.g., an M^{-3} factor in problem-dependent regret), yet the proposed algorithms do not explicitly exploit adaptivity to close this gap.
- Why unresolved: The paper provides upper bounds achievable by algorithms but does not prove if an adaptive policy can specifically leverage the M-dependence shown in the adaptive lower bounds.
- What evidence would resolve it: An algorithm designed for adaptive grids that achieves the tighter M-dependence of the lower bounds, or a proof that the static grid bounds are also tight for adaptive algorithms.

## Limitations
- The theoretical analysis assumes perfect knowledge of the heavy-tail parameter ε, which is unrealistic in practice and could lead to suboptimal performance if mis-specified
- The communication grids are designed for worst-case scenarios and may be overly conservative for practical applications
- The results focus on static batch schedules, while adaptive batch sizing based on observed data could potentially offer better performance
- The paper does not address computational complexity of the robust estimation procedures, which may become prohibitive for high-dimensional problems

## Confidence
- **High Confidence:** The inverse relationship between tail heaviness and required batches in instance-independent settings is well-supported by the theoretical analysis and mechanism explanation
- **Medium Confidence:** The decoupling of batch complexity from tail parameters in instance-dependent settings is theoretically sound but may be sensitive to specific problem structures
- **Medium Confidence:** The use of Median-of-Means as a robust estimator is standard practice, though the specific constants and implementation details affect practical performance

## Next Checks
1. **Robustness to ε Mis-specification:** Run experiments where the assumed ε differs from the true distribution parameter to quantify performance degradation and identify failure thresholds
2. **Comparison with Adaptive Batching:** Implement an adaptive batch sizing algorithm that adjusts based on observed reward distributions and compare regret performance against the static grids
3. **Scaling to High Dimensions:** Test the Lipschitz bandit algorithm on problems with increasing ambient dimension to assess computational tractability and whether the ε-dependent guarantees hold in practice