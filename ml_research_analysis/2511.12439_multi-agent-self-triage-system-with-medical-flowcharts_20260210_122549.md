---
ver: rpa2
title: Multi-agent Self-triage System with Medical Flowcharts
arxiv_id: '2511.12439'
source_url: https://arxiv.org/abs/2511.12439
tags:
- flowchart
- agent
- patient
- been
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a multi-agent conversational self-triage
  system that uses clinically validated flowcharts from the American Medical Association
  to guide large language models in patient triage. The system combines retrieval,
  decision, and chat agents to retrieve the appropriate flowchart, interpret patient
  responses, and deliver personalized guidance.
---

# Multi-agent Self-triage System with Medical Flowcharts

## Quick Facts
- arXiv ID: 2511.12439
- Source URL: https://arxiv.org/abs/2511.12439
- Authors: Yujia Liu; Sophia Yu; Hongyue Jin; Jessica Wen; Alexander Qian; Terrence Lee; Mattheus Ramsis; Gi Won Choi; Lianhui Qin; Xin Liu; Edward J. Wang
- Reference count: 40
- Primary result: Achieved 95.29% top-3 accuracy in flowchart retrieval and 99.10% accuracy in flowchart navigation across synthetic datasets

## Executive Summary
This paper presents a multi-agent conversational self-triage system that leverages clinically validated medical flowcharts from the American Medical Association to guide large language models in patient triage. The system combines three specialized LLM agents - retrieval, decision, and chat - to provide structured, reliable self-triage guidance while maintaining clinical rigor and patient trust. Evaluated on synthetic datasets, the approach demonstrates high accuracy in both flowchart selection and navigation, offering transparent AI-driven decision support that preserves the auditability and safety of traditional medical protocols.

## Method Summary
The system employs a three-agent architecture: a retrieval agent uses hybrid search (FAISS similarity + LLM semantic ranking) to select appropriate medical flowcharts from a database of 100 AMA protocols; a decision agent classifies patient responses into structured JSON output with four axes (On-Topic, Answered, Yes/No, Certain) to enable deterministic navigation; and a chat agent generates empathetic natural language responses. The flowcharts are converted to Python graphs (NetworkX) with four node types (N, F, A, I), and the entire system operates through prompt engineering without training. Evaluation uses synthetic datasets with 2,000 opening statements and 37,200 patient responses across five conversational patterns.

## Key Results
- Achieved 95.29% top-3 accuracy in flowchart retrieval, outperforming single-method approaches
- Demonstrated 99.10% accuracy in flowchart navigation across diverse conversational styles
- Hybrid retrieval approach (FAISS + LLM) showed superior performance (84.66%) compared to LLM-only (78.40%) or similarity-only (82.14%) baselines

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Hybrid retrieval improves flowchart selection accuracy over single-method approaches
- **Mechanism:** Vector database (FAISS) narrows search space to top-$n$ candidates using cosine similarity, then LLM performs semantic reasoning on reduced set
- **Core assumption:** Correct flowchart exists within top-$n$ candidates; LLM can distinguish clinical context from semantically similar neighbors
- **Evidence anchors:** Retrieval agent achieved 84.66% accuracy, outperforming baselines; top-3 accuracy reached 95.29%
- **Break condition:** Symptom overlap creates semantic ambiguity where multiple flowcharts appear equally valid

### Mechanism 2
- **Claim:** Mapping free-text responses to discrete decision axes enables deterministic navigation
- **Mechanism:** Decision Agent parses unstructured text into 4-axis structured output (On-Topic, Answered, Yes/No, Certain)
- **Core assumption:** LLMs can reliably classify conversational nuance into provided JSON schema without hallucinating state transitions
- **Evidence anchors:** System achieved 99.10% navigation accuracy across 37,200 synthetic responses
- **Break condition:** Complex linguistic constructs (double negatives, inclusive "OR") may cause misinterpretation

### Mechanism 3
- **Claim:** Shared graph representation creates auditable "paper trail" that builds trust
- **Mechanism:** Medical logic codified in graph database rather than latent weights enables exact decision path tracing
- **Core assumption:** Graph structure accurately reflects clinical nuance without oversimplifying complex realities
- **Evidence anchors:** Authors state design "empowers clinical systems/teams to customize triage workflow by editing flowcharts"
- **Break condition:** Wrong flowchart selection leads to clinically invalid path despite structural correctness

## Foundational Learning

- **Concept:** Retrieval-Augmented Generation (RAG)
  - **Why needed here:** Grounds LLM in specific knowledge base (AMA flowcharts) to prevent hallucinations and ensure clinically validated advice
  - **Quick check question:** How does the system handle a user query that matches no flowchart in the database?

- **Concept:** Structured Output / Function Calling
  - **Why needed here:** Decision Agent must reliably output JSON schema, not conversational text, to force LLM adherence
  - **Quick check question:** Which axis prevents system from advancing if patient is vague?

- **Concept:** Directed Acyclic Graphs (DAGs)
  - **Why needed here:** Medical flowcharts implemented as DAGs; node traversal understanding needed to debug conversation flow
  - **Quick check question:** What is specific function of 'F' node versus 'A' node in graph representation?

## Architecture Onboarding

- **Component map:** Flowchart Database -> Retrieval Agent -> Decision Agent -> Chat Agent -> Patient
- **Critical path:** Decision Agent's classification logic - misclassifications of `isUncertain` or `isOnTopic` cause patient to be stuck in loop or advanced down wrong medical branch
- **Design tradeoffs:** Sacrifices LLM chat flexibility for rigid protocol adherence safety; presents top-3 results (95.29% accuracy) rather than top-1 (84.66%) to trade interface simplicity for safety
- **Failure signatures:**
  - "Exclusive OR" Error: Interpreting medical questions with "OR" as exclusive, leading to incorrect classifications
  - Hallucinated Retrieval: Selecting flowchart based on demographics rather than actual symptoms
  - Stuck State: System repeatedly asking same question due to "Uncertain" or "Off-topic" classifications
- **First 3 experiments:**
  1. **Retrieval Stress Test:** Input opening statements with high semantic overlap to see if urgent physical symptoms are prioritized
  2. **Adversarial Navigation:** Feed Decision Agent "weak" or "uncertain" synthetic responses to verify `isUncertain` flag triggers correctly
  3. **End-to-End Audit:** Run full conversation and output underlying graph traversal to verify audit trail matches clinical expectation

## Open Questions the Paper Calls Out

**Open Question 1:** Does the system maintain high navigation accuracy and safety when deployed with real patients exhibiting natural speech patterns and anxiety?
- **Basis in paper:** Authors state "Real-world evaluation with patients is necessary to validate effectiveness and safety of the system"
- **Why unresolved:** Current evaluation relies exclusively on synthetic datasets that may not capture unpredictability of human health literacy and stress responses
- **What evidence would resolve it:** Results from human-subject study comparing system's triage recommendations against gold-standard clinician judgments for actual patients

**Open Question 2:** How does expanding flowchart nodes from binary (yes/no) questions to weighted or conditional paths impact decision agent's ability to handle uncertainty?
- **Basis in paper:** Authors note "current set of flowcharts is relatively generic and restricted to polar (yes/no) questions, which limits system's expressiveness and clinical breadth"
- **Why unresolved:** Current architecture optimized for classifying binary responses; impact of complex branching untested
- **What evidence would resolve it:** Performance metrics from modified system using flowcharts with non-binary nodes

**Open Question 3:** What mechanisms are most effective for detecting and correcting retrieval errors before providing inappropriate guidance?
- **Basis in paper:** Paper notes "current system does not yet include mechanisms to detect or recover from errors in retrieval or navigation"
- **Why unresolved:** "Certain and Incorrect" classification leads to false guidance without safety net or correction loop
- **What evidence would resolve it:** Implementation of confidence estimation modules demonstrating measurable reduction in critical navigation errors

## Limitations

- Evaluation relies entirely on synthetic datasets rather than real patient interactions, which may not capture full complexity of actual medical conversations
- Flowchart database limited to 100 AMA protocols and may not cover all emergent or rare conditions
- System performance on ambiguous or complex medical scenarios (overlapping symptoms, multi-system presentations) remains untested
- Copyright restrictions on AMA flowcharts prevent independent verification of complete system

## Confidence

- **High Confidence:** Architecture and methodology are well-specified and reproducible; hybrid retrieval approach shows clear performance improvements over baselines; structured output mechanism is technically sound
- **Medium Confidence:** 99.10% navigation accuracy claim based on synthetic data that may not reflect real-world complexity; system's handling of edge cases shows known failure patterns
- **Low Confidence:** Performance on real patient data, especially with diverse demographics and complex medical presentations, cannot be assessed from current results; system's safety and reliability in actual triage scenarios remain unproven

## Next Checks

1. **Real-World Pilot Test:** Deploy system with actual patients in controlled clinical setting to assess performance on genuine conversational complexity, emotional nuance, and unexpected symptom presentations

2. **Edge Case Robustness:** Systematically test Decision Agent with adversarial inputs including complex linguistic constructs, cultural variations in symptom description, and patients with communication difficulties

3. **Cross-Validation with Clinical Experts:** Have practicing physicians independently audit system's flowchart selections and navigation paths across diverse clinical scenarios to assess medical accuracy and identify potential safety concerns