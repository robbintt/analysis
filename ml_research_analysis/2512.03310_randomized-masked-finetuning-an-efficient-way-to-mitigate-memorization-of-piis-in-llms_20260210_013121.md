---
ver: rpa2
title: 'Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of
  PIIs in LLMs'
arxiv_id: '2512.03310'
source_url: https://arxiv.org/abs/2512.03310
tags:
- rmft
- deduplication
- training
- email
- extraction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Randomized Masked Fine-Tuning (RMFT), a novel
  technique to reduce personally identifiable information (PII) memorization in large
  language models. The method works by preserving only the first occurrence of each
  email address in the training data while replacing subsequent occurrences with structurally
  similar but randomized email addresses.
---

# Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs

## Quick Facts
- arXiv ID: 2512.03310
- Source URL: https://arxiv.org/abs/2512.03310
- Authors: Kunj Joshi; David A. Smith
- Reference count: 37
- Key outcome: RMFT achieves 80.81% reduction in PII extraction while maintaining only 5.73% perplexity increase

## Executive Summary
Randomized Masked Fine-Tuning (RMFT) is a novel technique designed to reduce Personally Identifiable Information (PII) memorization in large language models during fine-tuning. The method selectively preserves the first occurrence of each email address in training data while replacing subsequent occurrences with structurally similar but randomized email addresses. This approach maintains utility by preserving context while significantly reducing PII memorization. RMFT demonstrates superior performance compared to traditional deduplication methods, achieving substantial privacy gains with minimal impact on model perplexity.

## Method Summary
RMFT works by identifying unique PII patterns in training data and applying selective masking during fine-tuning. The algorithm preserves only the first occurrence of each unique email address, then replaces all subsequent occurrences with randomly generated email addresses that maintain the same structural characteristics (e.g., domain format, length). This preserves the contextual information needed for language modeling while reducing redundant exposure to the same PII. The method introduces MaxTER, a Pareto-optimal evaluation framework that assesses the privacy-utility tradeoff using Total Extraction Rate and perplexity metrics, with Area Under the Response Curve (AURC) serving as the overall performance indicator.

## Key Results
- RMFT achieves 80.81% reduction in Total Extraction Rate compared to baseline fine-tuning
- Seen Extraction Rate reduced by 80.17% while maintaining only 5.73% perplexity increase
- Outperforms deduplication methods with superior AURC scores across different model architectures
- Consistent performance demonstrated on both GPT-2-XL and GPT-Neo-1.3B architectures

## Why This Works (Mechanism)
RMFT exploits the fundamental relationship between training data exposure frequency and memorization likelihood in LLMs. By preserving only the first occurrence of each PII pattern while randomizing subsequent appearances, the method breaks the correlation between frequency and memorization without removing contextual information. The structural similarity of randomized PII maintains grammatical and syntactic context, allowing the model to learn language patterns while preventing deep memorization of specific sensitive information. This selective preservation approach is more efficient than complete deduplication, which removes all but one occurrence and may degrade utility.

## Foundational Learning

**PII Memorization in LLMs**
- Why needed: Understanding how repeated exposure to sensitive data leads to memorization
- Quick check: Can the model extract exact PII patterns from its outputs?

**Fine-tuning Dynamics**
- Why needed: Recognizing how fine-tuning modifies pre-trained weights and affects memorization
- Quick check: Does fine-tuning amplify or mitigate pre-existing memorization patterns?

**Pareto-optimal Evaluation**
- Why needed: Balancing privacy and utility through multi-objective optimization
- Quick check: Can we find solutions that improve privacy without unacceptable utility loss?

## Architecture Onboarding

**Component Map**
Data Preprocessing -> RMFT Masking -> Fine-tuning -> Evaluation (MaxTER Framework)

**Critical Path**
1. Identify unique PII patterns in training data
2. Apply RMFT masking (preserve first occurrence, randomize subsequent)
3. Fine-tune model on masked dataset
4. Evaluate using Total Extraction Rate and perplexity

**Design Tradeoffs**
- Complete deduplication vs. selective preservation (RMFT chooses selective)
- Structural randomization vs. complete removal (RMFT chooses structural)
- Single metric vs. multi-metric evaluation (RMFT uses MaxTER framework)

**Failure Signatures**
- High perplexity increase indicates excessive utility degradation
- Low extraction rate reduction suggests insufficient privacy enhancement
- Inconsistent results across model architectures indicate implementation issues

**First 3 Experiments**
1. Baseline fine-tuning on unmodified Enron dataset
2. Complete deduplication fine-tuning for comparison
3. RMFT fine-tuning with varying randomization parameters

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Evaluation relies on synthetic email generation that may not capture real-world PII diversity
- 80.81% extraction reduction still leaves residual privacy risks in production
- 5.73% perplexity increase may compound in precision-critical applications
- MaxTER framework depends on perplexity as sole utility proxy

## Confidence
- High confidence in RMFT algorithm implementation and technical specifications
- Medium confidence in quantitative results due to synthetic evaluation limitations
- Medium confidence in generalizability across different PII types and distributions
- Medium confidence in utility preservation claims based on single-metric evaluation

## Next Checks
1. Validate RMFT performance on diverse PII types beyond email addresses using production datasets
2. Evaluate impact on specific downstream tasks rather than relying solely on perplexity metrics
3. Test RMFT against advanced extraction techniques and adaptive attacks targeting contextual cues