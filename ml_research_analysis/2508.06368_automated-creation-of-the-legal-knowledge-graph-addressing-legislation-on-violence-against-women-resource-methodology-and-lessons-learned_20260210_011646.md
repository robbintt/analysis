---
ver: rpa2
title: 'Automated Creation of the Legal Knowledge Graph Addressing Legislation on
  Violence Against Women: Resource, Methodology and Lessons Learned'
arxiv_id: '2508.06368'
source_url: https://arxiv.org/abs/2508.06368
tags:
- legal
- knowledge
- data
- https
- ontology
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a novel Legal Knowledge Graph (KG) focused
  on legislation addressing violence against women, constructed using two complementary
  methodologies: a bottom-up approach with structured data extraction and ontology
  creation, and a Large Language Model (LLM)-based approach leveraging retrieval-augmented
  generation. The resulting KG is FAIR-aligned, publicly accessible via a SPARQL endpoint,
  and interlinked with existing legal resources like Wikidata and ECLI.'
---

# Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned

## Quick Facts
- arXiv ID: 2508.06368
- Source URL: https://arxiv.org/abs/2508.06368
- Reference count: 24
- This paper presents a novel Legal Knowledge Graph (KG) focused on legislation addressing violence against women, constructed using two complementary methodologies: a bottom-up approach with structured data extraction and ontology creation, and a Large Language Model (LLM)-based approach leveraging retrieval-augmented generation.

## Executive Summary
This paper presents a novel Legal Knowledge Graph (KG) focused on legislation addressing violence against women, constructed using two complementary methodologies: a bottom-up approach with structured data extraction and ontology creation, and a Large Language Model (LLM)-based approach leveraging retrieval-augmented generation. The resulting KG is FAIR-aligned, publicly accessible via a SPARQL endpoint, and interlinked with existing legal resources like Wikidata and ECLI. Evaluation via competency questions showed the bottom-up method excels in precision for formal legal reasoning, while the LLM-based approach offers scalability and rapid prototyping capabilities. The work fills a gap in legal KGs and supports predictive justice and legal reasoning applications.

## Method Summary
The paper constructs a Legal Knowledge Graph from 73 European Court of Human Rights (ECHR) judgments addressing violence against women using two distinct pipelines. The bottom-up approach employs structured data extraction from HTML "Case Details" tabs, mapping extracted metadata to a custom ontology aligned with ECLI and Wikidata. The LLM-based approach uses retrieval-augmented generation (RAG) with BERT-M2 embeddings and FAISS vector stores to ground ontology generation in document context, using GPT-4o and Mixtral 8x22b models. Both approaches are validated against competency questions, with the resulting KG published via SPARQL endpoint and linked to LOD Cloud resources.

## Key Results
- The bottom-up approach extracted 10,325 triples from 73 ECHR documents using structured HTML parsing.
- The LLM-based approach achieved 40/65 full-text and 37/65 sub-part competency question answering scores.
- The KG is FAIR-aligned, publicly accessible via SPARQL endpoint, and interlinked with Wikidata and ECLI resources.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structured extraction from semi-structured legal document metadata produces precision-optimized knowledge graphs suitable for formal legal reasoning.
- Mechanism: HTML "Case Details" tabs from ECHR judgments contain consistent fields (ECLI identifiers, importance levels, respondent states) that are programmatically extracted via Beautiful Soup, mapped to ontology classes (e.g., `StrasbourgCaseLaw`, `DomesticLaw`), and aligned to external vocabularies (ECLI, Wikidata) via URI resolution. This yields 10,325 triples from 73 documents with 22 distinct predicates.
- Core assumption: Legal document metadata fields maintain sufficient structural consistency across judgments to support automated extraction rules without per-document customization.
- Evidence anchors:
  - [abstract] "bottom-up approach with structured data extraction and ontology creation"
  - [section 3] "HTML files have been considered as more comprehensive. Processing of each sentence instantiates a ECHRDocument class... Given the 73 selected judgments... overall 10325 triples have been extracted"
  - [corpus] Limited direct corpus support; neighboring papers address KG construction generally but not this specific legal metadata extraction pattern.
- Break condition: Document structure diverges significantly from expected HTML schema; new ECHR templates require scraper updates.

### Mechanism 2
- Claim: Retrieval-Augmented Generation (RAG) grounds LLM ontology generation in domain-specific documents, reducing hallucination while enabling scalable KG bootstrapping.
- Mechanism: Legal documents are chunked and embedded via BERT-M2 into FAISS vector stores. During generation, Mixtral 8x22b receives retrieved context plus ontology construction prompts (zero-shot for schema expansion, few-shot for instance generation). The LLM produces T-box elements (12 classes, 9 object properties, 17 data properties) and A-box triples, though manual review is required to remove superfluous elements.
- Core assumption: The embedding model captures semantic similarity sufficiently to retrieve contextually relevant passages for ontology decisions; LLM pretrained knowledge includes general legal reasoning patterns.
- Evidence anchors:
  - [abstract] "LLM-based approach leveraging retrieval-augmented generation"
  - [section 4] "RAG models have been employed to limit the output of LLMs to the context of each specific document... BERT-M2 served as the embedding model... FAISS... used to manage the vector dataset"
  - [corpus] Paper ID 65600 ("Less is More: Denoising Knowledge Graphs For Retrieval Augmented Generation") supports RAG + KG integration; Paper ID 66473 ("Are Large Language Models Effective Knowledge Graph Constructors?") examines LLM KG construction effectiveness.
- Break condition: Retrieval fails to surface relevant passages; hallucination rate exceeds manual validation capacity; token limits truncate critical document sections.

### Mechanism 3
- Claim: Competency Questions (CQs) provide a task-grounded evaluation metric that correlates with downstream utility for both human and machine querying.
- Mechanism: Domain experts formulate CQs representing realistic information needs (e.g., "Which articles of the Convention were considered?"). For bottom-up KG, CQs guide ontology design a priori. For LLM-based KG, CQs are generated post-hoc by the LLM itself and manually verified against source text. Evaluation scores (40/65 full-text, 37/65 sub-part) quantify answerability.
- Core assumption: The selected CQs adequately sample the query distribution that legal practitioners and predictive justice systems will actually pose.
- Evidence anchors:
  - [abstract] "Evaluation via competency questions showed the bottom-up method excels in precision for formal legal reasoning"
  - [section 3, Table 1] Lists 13 CQs mapped to ontology terms; [section 4, Table 2] Shows CQ answering scores for LLM approach
  - [corpus] Paper ID 66856 (MLEB) addresses legal information retrieval evaluation but not CQ-based KG validation specifically.
- Break condition: CQs fail to cover emergent query types; LLM-generated CQs reflect model biases rather than genuine user needs.

## Foundational Learning

- Concept: **RDF/SPARQL and Semantic Web Standards**
  - Why needed here: The KG is serialized as Turtle RDF, exposed via SPARQL endpoint, and aligned to SKOS/ECLI/ELI vocabularies. Without understanding triples (subject-predicate-object), URI dereferencing, and SPARQL query structure, you cannot inspect, extend, or debug the KG.
  - Quick check question: Given a triple `<case:X> <pred:involvesArticle> "Article 3"`, write a SPARQL query to find all cases involving Article 3.

- Concept: **Retrieval-Augmented Generation (RAG)**
  - Why needed here: The LLM pipeline depends on RAG to constrain generation to document-specific context. Understanding embedding models, vector similarity search, and chunking strategies is essential for diagnosing retrieval failures that cause incorrect ontology elements or missing triples.
  - Quick check question: If the LLM generates an ontology class not present in the source document, which RAG component would you investigate first: embedding quality, chunk size, or retrieval threshold?

- Concept: **Legal Document Standards (ECLI/ELI)**
  - Why needed here: The KG interlinks with ECLI (European Case Law Identifier) and Wikidata. Understanding identifier structure (e.g., `ECLI:CE:ECHR:2022:0210JUD007397516`) and metadata schemas is necessary for entity resolution and cross-resource linking.
  - Quick check question: Parse the ECLI string above into its five components and explain which part enables temporal filtering.

## Architecture Onboarding

- Component map:
  - **Bottom-up pipeline**: ECHR HUDOC scraper (Selenium) -> HTML parser (Beautiful Soup) -> Triple generator (RDFLib) -> Custom ontology (ECLI-aligned) -> Graph merge -> SPARQL endpoint (Flask + RDFLib)
  - **LLM pipeline**: PDF/text extractor -> Document chunks -> Embedding (BERT-M2) -> Vector store (FAISS) -> RAG retrieval -> LLM (GPT-4o for base ontology, Mixtral for expansion/instances) -> Manual review -> KG merge
  - **Shared**: Competency question validation, Wikidata URI resolution, LOD Cloud publication

- Critical path:
  1. Obtain ECHR documents (PDF + HTML Case Details)
  2. Choose pipeline based on precision vs. scalability requirements
  3. Run extraction/generation -> validate against CQs
  4. Merge into unified KG -> publish via SPARQL endpoint
  5. Register in LOD Cloud with DOI

- Design tradeoffs:
  - **Bottom-up**: Higher precision (expert-curated ontology, explicit alignment) but labor-intensive and less adaptable to new document types. Best for formal legal reasoning tasks.
  - **LLM-based**: Faster bootstrapping and scalable to diverse texts, but requires manual validation for hallucination mitigation. Best for rapid prototyping and exploratory analysis.
  - **Full-text vs. sub-part input**: Full-text yields broader coverage (40/65 CQs) but more noise; sub-part is faster and more focused (37/65 CQs) but risks missing information.

- Failure signatures:
  - **Scraper breakage**: HTML structure changes on HUDOC -> Selenium selectors fail -> empty or malformed downloads
  - **LLM hallucination**: Generated ontology classes or instances not grounded in source text -> CQ validation fails -> manual review rejection rate spikes
  - **URI misalignment**: Wikidata URI resolution fails for respondent states -> broken links -> interoperability loss
  - **Token overflow**: Full-text documents exceed LLM context window -> truncated inputs -> incomplete triples

- First 3 experiments:
  1. **Reproduce bottom-up extraction on 10 ECHR documents**: Run the provided GitHub pipeline, verify triple counts against reported figures, and validate 3 CQs via SPARQL queries against the local endpoint.
  2. **Ablate RAG retrieval**: Generate KG from the same document with and without RAG (zero-shot LLM only), compare CQ answer rates and hallucination frequency to quantify RAG contribution.
  3. **Cross-domain transfer test**: Apply the LLM pipeline (unchanged prompts) to 5 ECHR judgments in a different legal domain (e.g., property disputes), evaluate whether ontology schema generalizes or requires domain-specific adaptation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal methodology for merging the bottom-up and LLM-based Legal Knowledge Graphs into a unified resource?
- Basis in paper: [explicit] The conclusion states future work focuses on "merging the two KGs into a unified resource."
- Why unresolved: The paper presents two graphs with differing ontological depths and construction logics (manual precision vs. automated scalability) but does not provide an integration strategy.
- What evidence would resolve it: A technical description of an alignment or merging pipeline that reconciles the two schemas and instance sets, validated by checking for consistency and redundancy reduction.

### Open Question 2
- Question: Can the constructed Legal Knowledge Graph effectively support the automated detection of legal patterns?
- Basis in paper: [explicit] The authors list "extending the KG applicability to the automated detection of legal patterns" as a future objective.
- Why unresolved: The paper validates the KG via competency questions but does not demonstrate its utility for advanced analytics or pattern recognition tasks.
- What evidence would resolve it: Experimental results applying graph mining or link prediction techniques to the KG to identify hidden correlations in case law, validated against known legal trends.

### Open Question 3
- Question: Are the proposed KG construction methods generalizable to other legal domains?
- Basis in paper: [explicit] The conclusion mentions plans for "experimenting the applicability of the proposed methodologies to other legal domains."
- Why unresolved: The current implementation is tailored to ECHR rulings on violence against women; performance on structurally different legal texts remains untested.
- What evidence would resolve it: A replication study applying the specific bottom-up and LLM pipelines to a different legal corpus (e.g., administrative law) with a comparative analysis of KG quality and required adjustments.

## Limitations
- Scalability concerns: The bottom-up approach requires manual ontology curation and explicit HTML parsing rules, limiting adaptability to new document formats or jurisdictions.
- Evaluation scope: Competency Questions focus on specific legal reasoning tasks but may not capture all downstream use cases (e.g., temporal reasoning, cross-jurisdiction comparisons).
- Interoperability constraints: While the KG links to Wikidata and ECLI, full interoperability with other legal KGs requires alignment to broader ontologies like ELI.

## Confidence
- **High**: Structured metadata extraction from ECHR HTML Case Details reliably produces precise triples for formal legal reasoning (supported by 10,325 triples from 73 documents).
- **Medium**: RAG-grounded LLM generation reduces hallucination compared to zero-shot generation (supported by comparative CQ scores but limited ablation studies).
- **Low**: The bottom-up approach will generalize to non-ECHR legal document structures without significant customization (assumption of structural consistency across judgments is untested).

## Next Checks
1. **Ablation study**: Run the LLM pipeline with and without RAG retrieval on identical documents to quantify hallucination reduction and precision gains.
2. **Cross-jurisdiction transfer**: Apply the LLM pipeline to 5 ECHR judgments outside the violence-against-women domain to test ontology schema generalization.
3. **Scalability benchmark**: Measure inference time and manual validation effort per document as the corpus grows from 73 to 500+ judgments to assess LLM approach viability at scale.