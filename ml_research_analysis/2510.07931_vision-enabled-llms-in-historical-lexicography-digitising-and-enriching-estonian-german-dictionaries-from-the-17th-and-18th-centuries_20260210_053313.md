---
ver: rpa2
title: 'Vision-Enabled LLMs in Historical Lexicography: Digitising and Enriching Estonian-German
  Dictionaries from the 17th and 18th Centuries'
arxiv_id: '2510.07931'
source_url: https://arxiv.org/abs/2510.07931
tags:
- estonian
- language
- dictionary
- dictionaries
- historical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors applied large language models to historical Estonian-German
  dictionaries from the 17th and 18th centuries. They investigated using LLMs to enrich
  old dictionaries with modern word forms and meanings, and to perform text recognition
  and structured parsing of Gothic script (Fraktur) printed sources.
---

# Vision-Enabled LLMs in Historical Lexicography: Digitising and Enriching Estonian-German Dictionaries from the 17th and 18th Centuries

## Quick Facts
- arXiv ID: 2510.07931
- Source URL: https://arxiv.org/abs/2510.07931
- Reference count: 0
- LLMs accurately provided modern forms and meanings for 81% of 342 headword entries from J. Gutslaff's 1648 dictionary

## Executive Summary
This study demonstrates the application of large language models to historical Estonian-German dictionaries from the 17th and 18th centuries. The authors investigate using LLMs for two primary tasks: enriching old dictionaries with modern word forms and meanings, and performing text recognition and structured parsing of Gothic script printed sources. Using Claude 3.7 Sonnet, they achieved promising results in both tasks, with 81% accuracy for modern form enrichment and 41% success in zero-shot text recognition and structured parsing. The research establishes a foundation for automated digitization of historical lexicographic resources using vision-enabled AI systems.

## Method Summary
The authors applied large language models to historical Estonian-German dictionaries from the 17th and 18th centuries. They used Claude 3.7 Sonnet to enrich old dictionaries with modern word forms and meanings, and to perform text recognition and structured parsing of Gothic script (Fraktur) printed sources. The methodology included analyzing 342 headword entries from J. Gutslaff's 1648 dictionary for modern form enrichment, conducting zero-shot text recognition experiments on A. T. Helle's 1732 dictionary, and implementing overlapping tiling of scanned image files for A. W. Hupel's 1780 dictionary using dual LLM workflows for text recognition and merging structured output.

## Key Results
- Claude 3.7 Sonnet accurately provided modern forms and meanings for 81% of 342 headword entries from J. Gutslaff's 1648 dictionary
- In zero-shot text recognition, Claude 3.7 Sonnet successfully identified and structured 41% of headword entries from A. T. Helle's 1732 dictionary into error-free JSON output
- For A. W. Hupel's 1780 dictionary, overlapping tiling of scanned image files with dual LLM processing enabled structured output generation

## Why This Works (Mechanism)
Vision-enabled LLMs combine multimodal capabilities that allow simultaneous processing of visual and textual information. The models can recognize historical scripts like Gothic (Fraktur) while understanding linguistic context to provide modern equivalents and meanings. The zero-shot capabilities demonstrate the models' ability to generalize from training data to novel historical documents without explicit fine-tuning. The dual-LLM approach for Hupel's dictionary leverages specialization, where one model focuses on accurate text recognition while another handles structured output formatting.

## Foundational Learning
- Gothic script recognition (Fraktur): Essential for reading 17th-18th century German-printed texts; quick check: can the model distinguish Fraktur from modern Latin characters
- Historical linguistics: Understanding language evolution between centuries; quick check: can the model map archaic forms to modern equivalents
- Zero-shot learning: Model's ability to handle unseen tasks without fine-tuning; quick check: test with documents from completely different domains
- Multimodal processing: Simultaneous handling of visual and textual data; quick check: verify recognition accuracy on varied image qualities

## Architecture Onboarding

**Component Map:**
Input images -> LLM1 (text recognition) -> LLM2 (structuring) -> JSON output

**Critical Path:**
Image preprocessing -> Text recognition -> Structured parsing -> Validation

**Design Tradeoffs:**
- Single LLM vs dual LLM approach: Single LLM simpler but potentially less accurate; dual LLM allows specialization but increases complexity
- Zero-shot vs fine-tuned: Zero-shot avoids training costs but may sacrifice accuracy; fine-tuning improves performance but requires labeled data
- Overlapping tiling vs full-page processing: Tiling handles large pages better but requires merging logic; full-page simpler but may miss details