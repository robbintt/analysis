---
ver: rpa2
title: Generative Sequential Recommendation via Hierarchical Behavior Modeling
arxiv_id: '2511.03155'
source_url: https://arxiv.org/abs/2511.03155
tags:
- recommendation
- behavior
- user
- item
- multi-behavior
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of multi-behavior sequential
  recommendation in advertising and e-commerce domains, where high-value conversions
  are sparse and traditional discriminative models struggle. The authors propose GAMER,
  a generative framework that models user behavior sequences with hierarchical dependencies
  using a decoder-only architecture.
---

# Generative Sequential Recommendation via Hierarchical Behavior Modeling

## Quick Facts
- arXiv ID: 2511.03155
- Source URL: https://arxiv.org/abs/2511.03155
- Reference count: 40
- Primary result: >20% improvement over baselines in multi-behavior sequential recommendation

## Executive Summary
This paper introduces GAMER, a generative framework for multi-behavior sequential recommendation in advertising and e-commerce domains where high-value conversions are sparse. GAMER uses a decoder-only Qwen3 architecture with hierarchical behavior modeling to capture cross-level interactions and improve prediction of target behaviors like conversions. The authors release ShortVideoAD, a large-scale multi-behavior dataset, and demonstrate significant performance gains over discriminative and generative baselines through extensive experiments and online A/B testing.

## Method Summary
GAMER is a generative sequential recommendation framework that models user behavior sequences with hierarchical dependencies. It uses a decoder-only Qwen3 backbone with 8 layers and introduces a cross-level interaction layer to capture behavior hierarchies. The model employs a sequential augmentation strategy with behavior-level dropout to improve robustness to rare behaviors. It operates on semantic IDs (SIDs) generated by RQ-VAE from item features, using chunked IDs (CIDs) for training. The framework includes position-and-behavior-aware MoE routing and constrained beam search for target behavior prediction.

## Key Results
- GAMER outperforms both discriminative and generative baselines across multiple metrics, with improvements exceeding 20% in most cases
- Online A/B testing shows a 2.5% increase in conversion rate and 1.8% improvement in eCPM
- The proposed method demonstrates superior performance on ShortVideoAD, Tmall, and JData datasets

## Why This Works (Mechanism)
GAMER addresses the sparsity challenge in multi-behavior recommendation by treating item generation as a sequential task, allowing the model to leverage contextual information across the entire sequence. The hierarchical behavior modeling captures dependencies between different behavior types (e.g., clicks leading to conversions), while the cross-level interaction layer enables rich representations that discriminate between behavior types. Sequential augmentation with behavior-level dropout improves robustness to rare behaviors without losing critical signals, and the generative approach naturally handles the long-tail distribution of high-value actions.

## Foundational Learning
**RQ-VAE for semantic ID generation**: Converts high-dimensional item features into compressed semantic IDs for efficient modeling - needed because raw item features are too sparse for direct sequence modeling; quick check: verify reconstruction quality and token distribution match expected patterns.

**Cross-level behavior interaction**: Attention mechanism that captures dependencies between different behavior types in the hierarchy - needed to model how lower-level behaviors (clicks) influence higher-level outcomes (conversions); quick check: examine attention weights between behavior types.

**Position-and-behavior-aware MoE routing**: Expert selection based on both position and behavior type - needed to provide specialized representations for different positions and behaviors; quick check: analyze routing patterns across positions and behaviors.

**Sequential augmentation with behavior dropout**: Stochastically drops behavior-level tokens during training - needed to improve robustness to rare behaviors; quick check: compare performance across different augmentation strengths.

**Constrained beam search for target behavior**: Generates only valid sequences for the target behavior - needed to ensure predictions respect the behavior-specific vocabulary; quick check: verify generated sequences only contain valid SIDs for the target behavior.

## Architecture Onboarding

**Component map**: Item features -> RQ-VAE -> Semantic IDs -> Cross-level interaction layer -> Qwen3 decoder (8L, 256dim) -> Position-behavior MoE -> Constrained beam search -> Target behavior predictions

**Critical path**: Behavior sequence → Cross-level interaction → Qwen3 decoder → MoE routing → Generation → Evaluation

**Design tradeoffs**: The paper chose decoder-only architecture over encoder-decoder to better handle sequential dependencies, and generative over discriminative to naturally model the sequential nature of recommendation. Sequential augmentation trades training stability for improved generalization to rare behaviors.

**Failure signatures**: Poor semantic ID quality manifests as generation failures and invalid token sequences; excessive augmentation drops critical signals causing performance degradation; beam search generating invalid SIDs indicates constraint enforcement issues.

**First experiments**:
1. Train RQ-VAE on item features and evaluate reconstruction quality
2. Implement cross-level interaction layer and verify attention patterns between behaviors
3. Test sequential augmentation at different strengths (x=1,2,4) and measure impact on rare behavior prediction

## Open Questions the Paper Calls Out
None

## Limitations
- RQ-VAE implementation details are underspecified, requiring significant additional work to reproduce
- MoE routing mechanism details are unclear, particularly the routing function and expert configuration
- Behavior hierarchy levels (L_b) for augmentation dropout are referenced but not explicitly defined

## Confidence
**RQ-VAE implementation**: Medium - Architecture and training details are underspecified
**MoE routing details**: Low - Routing function and expert configuration are unclear
**Core method replication**: Medium-High - Qwen3 decoder and cross-level interaction are well-documented

## Next Checks
1. Train RQ-VAE from scratch on item feature data to generate SIDs, comparing reconstruction quality against paper benchmarks
2. Implement and test multiple MoE routing strategies (fixed position-to-expert mapping vs learned routing) to identify which matches the paper's results
3. Conduct ablation studies on augmentation strength (x=1,2,4) and behavior hierarchy depth to understand sensitivity to these design choices