---
ver: rpa2
title: University Building Recognition Dataset in Thailand for the mission-oriented
  IoT sensor system
arxiv_id: '2512.05468'
source_url: https://arxiv.org/abs/2512.05468
tags:
- learning
- recognition
- federated
- dataset
- university
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the need for mission-specific datasets in
  wireless ad hoc federated learning (WAFL) for IoT sensor systems by developing the
  Chulalongkorn University Building Recognition Dataset (CUBR), which contains 32
  labeled buildings with approximately 100 images each. The dataset is designed to
  evaluate WAFL with Vision Transformer (WAFL-ViT) for smart-campus applications.
---

# University Building Recognition Dataset in Thailand for the mission-oriented IoT sensor system

## Quick Facts
- arXiv ID: 2512.05468
- Source URL: https://arxiv.org/abs/2512.05468
- Authors: Takara Taniguchi; Yudai Ueda; Atsuya Muramatsu; Kohki Hashimoto; Ryo Yagi; Hideya Ochiai; Chaodit Aswakul
- Reference count: 16
- Primary result: WAFL-ViT achieves 0.861 accuracy on CUBR dataset, outperforming self-training baseline (0.619)

## Executive Summary
This paper addresses the need for mission-specific datasets in wireless ad hoc federated learning (WAFL) for IoT sensor systems by developing the Chulalongkorn University Building Recognition Dataset (CUBR). The dataset contains 32 labeled buildings with approximately 100 images each, designed to evaluate WAFL with Vision Transformer (WAFL-ViT) for smart-campus applications. Using 10 distributed devices and the CUBR dataset, the authors compare WAFL models against self-training approaches across multiple architectures (ViT, ResNet, VGG, MobileNet). Results show that WAFL-ViT achieves the highest accuracy of 0.861 with low standard deviation (0.007), outperforming self-training models and validating the effectiveness of collaborative learning in decentralized federated learning scenarios.

## Method Summary
The study develops a novel dataset (CUBR) for building recognition and evaluates wireless ad hoc federated learning (WAFL) against self-training baselines. The dataset includes 32 labeled buildings with ~100 images each, captured using 4 different devices under varied conditions. The WAFL approach uses parameter exchange between neighbor devices through an ad hoc network, where each device maintains local MLP head parameters that are periodically averaged with neighbors. The experimental setup uses 10 distributed devices with IID data distribution, random waypoint mobility, and compares four architectures: ViT-B/16, ResNet-152, VGG-19-BN, and MobileNet-V2. The ViT backbone is frozen during training to prevent overfitting, while only the MLP classification head is fine-tuned.

## Key Results
- WAFL-ViT achieves highest accuracy of 0.861 with standard deviation of 0.007
- All WAFL models outperform their self-training counterparts (WAFL-ViT vs SELF-ViT: 0.861 vs 0.619)
- The dataset reveals specific classification challenges, with labels 10 and 11 showing persistent confusion
- Collaborative learning demonstrates faster convergence (1500 epochs) compared to self-training (2000 epochs)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decentralized parameter averaging among neighbor devices improves model generalization over isolated self-training
- Mechanism: Each device maintains local MLP head parameters (W^n) and periodically exchanges them with neighbors using the update rule: W^n ← W^n + λ * Σ(W^k - W^n)/(|adj(n)|+1)
- Core assumption: Devices have bidirectional communication with at least some neighbors during training rounds
- Evidence anchors: [section IV-B] shows WAFL models generally outperform SELF models in terms of accuracy

### Mechanism 2
- Claim: Freezing the Vision Transformer backbone while fine-tuning only MLP heads prevents local overfitting and enables effective knowledge transfer
- Mechanism: ViT-B/16 is pre-trained on large-scale data; only the classification head is updated with local building images
- Core assumption: Pre-trained ViT features are sufficiently generic to represent building structures across different campuses
- Evidence anchors: [section II] states parameters of each ViT in each device are not fine-tuned to avoid overfitting to local images

### Mechanism 3
- Claim: Mission-specific datasets with controlled variability are necessary for evaluating real-world WAFL performance
- Mechanism: CUBR was collected using 4 different capture devices across 32 buildings with ~100 images each, introducing realistic noise
- Core assumption: The dataset's variability approximates deployment conditions; buildings have visually distinguishable features
- Evidence anchors: [section III] describes images taken from different distances, viewing angles, and under diverse illumination conditions

## Foundational Learning

- Concept: **Federated Learning (Centralized vs. Decentralized)**
  - Why needed here: WAFL is a fully decentralized variant; understanding the distinction explains why there's no parameter server
  - Quick check question: Can you explain why eliminating the central server removes the single point of failure but introduces neighbor connectivity requirements?

- Concept: **Vision Transformer (ViT) Architecture**
  - Why needed here: ViT-B/16 is the backbone used; understanding patch embedding and self-attention helps explain why only the MLP head is fine-tuned
  - Quick check question: Why would freezing the transformer layers while training only the classification head preserve general features?

- Concept: **Ad Hoc Network Mobility Models**
  - Why needed here: Random Waypoint Mobility (RWP) was used to simulate device movement; this affects which nodes become neighbors
  - Quick check question: How does RWP simulation differ from static device placement in terms of neighbor adjacency over time?

## Architecture Onboarding

- Component map:
  - Edge devices (n=10) -> ViT-B/16 backbone (frozen) -> MLP heads (W^n, fine-tuned) -> Ad hoc communication layer -> Dataset partitioner

- Critical path:
  1. Initialize all devices with pre-trained ViT-B/16 + random MLP heads
  2. Each device performs local fine-tuning on its partition (1 epoch/round)
  3. Devices broadcast W^n to neighbors and receive W^k
  4. Apply averaging update (Equation 1) with hyperparameter λ
  5. Repeat for 1500 epochs (WAFL) vs 2000 epochs (self-training baseline)
  6. Evaluate on held-out test set, aggregate metrics across all devices

- Design tradeoffs:
  - **λ (mixing coefficient)**: Higher values accelerate convergence but may destabilize if neighbors have divergent updates
  - **Epochs**: WAFL uses 1500 vs. SELF uses 2000—collaborative learning may converge faster but requires communication overhead
  - **IID vs. Non-IID partition**: Paper uses IID; non-IID would stress-test robustness

- Failure signatures:
  - **Isolated node**: Device with |adj(n)|=0 degenerates to self-training
  - **Label confusion**: Confusion matrix shows labels 10 vs 11 hard to distinguish
  - **High variance across devices**: Standard deviation >0.02 suggests inconsistent neighbor connectivity

- First 3 experiments:
  1. **Baseline replication**: Reproduce WAFL-ViT (0.861 accuracy) with CUBR using λ=0.5 as starting point
  2. **Ablation on λ**: Sweep λ ∈ {0.1, 0.3, 0.5, 0.7, 0.9} to measure convergence speed vs. final accuracy
  3. **Non-IID stress test**: Partition CUBR so each device sees only 8-10 building labels (not all 32)

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions beyond noting the difficulty in distinguishing between labels 10 and 11 in the confusion matrix. However, based on the methodology and results, several natural questions emerge regarding the generalizability and robustness of the WAFL approach that the authors acknowledge require further investigation.

## Limitations
- Hyperparameter details (learning rate, batch size, λ, MLP head architecture) are not specified, hindering exact reproduction
- Dataset uses IID partitioning which may not reflect real-world non-IID scenarios common in federated learning
- Pre-trained weight source and exact model initialization procedure are not detailed
- RWP mobility parameters (speed range, pause time, simulation area) are unspecified

## Confidence
- WAFL-ViT accuracy advantage over self-training (0.861 vs 0.619): **High** - Clear numerical comparison with low standard deviation
- Parameter exchange mechanism improving generalization: **Medium** - Theoretically sound but depends on connectivity assumptions
- CUBR dataset adequately challenging for building recognition: **Medium** - Confusion between labels 10 and 11 suggests some limitations

## Next Checks
1. **Hyperparameter sensitivity**: Systematically vary λ and learning rate to determine their impact on convergence speed and final accuracy
2. **Non-IID stress test**: Redistribute CUBR data so devices have uneven building label distributions and measure WAFL vs self-training degradation
3. **Connectivity robustness**: Simulate scenarios with varying neighbor densities (from sparse to fully connected) to identify minimum connectivity threshold for WAFL benefits