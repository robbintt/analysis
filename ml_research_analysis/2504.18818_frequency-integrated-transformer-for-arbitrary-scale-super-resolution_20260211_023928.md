---
ver: rpa2
title: Frequency-Integrated Transformer for Arbitrary-Scale Super-Resolution
arxiv_id: '2504.18818'
source_url: https://arxiv.org/abs/2504.18818
tags:
- frequency
- information
- image
- super-resolution
- ieee
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a novel transformer-based architecture called
  Frequency-Integrated Transformer (FIT) for arbitrary-scale super-resolution. The
  key innovation is incorporating frequency domain information into the super-resolution
  process through two main modules: Frequency Incorporation Module (FIM) and Frequency
  Utilization Self-Attention module (FUSAM).'
---

# Frequency-Integrated Transformer for Arbitrary-Scale Super-Resolution

## Quick Facts
- arXiv ID: 2504.18818
- Source URL: https://arxiv.org/abs/2504.18818
- Reference count: 40
- Key outcome: FIT achieves PSNR improvements of 0.32 dB, 0.37 dB, and 0.37 dB at ×2, ×3, and ×4 scales respectively on DIV2K validation set compared to previous best method

## Executive Summary
This paper introduces Frequency-Integrated Transformer (FIT), a novel transformer-based architecture for arbitrary-scale super-resolution that incorporates frequency domain information through two key modules. The Frequency Incorporation Module (FIM) uses FFT with real-imaginary mapping to losslessly introduce frequency information, while the Frequency Utilization Self-Attention module (FUSAM) includes Interaction Implicit Self-Attention (IISA) for cross-domain information synergy and Frequency Correlation Self-Attention (FCSA) for global context capture. The method significantly outperforms state-of-the-art approaches on multiple benchmark datasets.

## Method Summary
FIT processes arbitrary-scale super-resolution by encoding the input LR image with an RDN or EDSR encoder, then passing the features through FIM which incorporates frequency information via FFT and real-imaginary mapping. The enriched features then flow through FUSAM, which combines IISA for cross-domain spatial-frequency interaction across multiple subspaces and FCSA for global context capture via frequency-domain correlation. Finally, a decoder combines these features with bilinear-upsampled LR input to produce the HR output. The architecture is trained on DF2K dataset with L1 loss and evaluated on DIV2K, Set5, Set14, Urban100, and BSD100.

## Key Results
- FIT achieves PSNR improvements of 0.32 dB, 0.37 dB, and 0.37 dB at ×2, ×3, and ×4 scales respectively on DIV2K validation set
- Feature maps demonstrate superior detail characterization compared to spatial-only baselines
- Frequency error maps show improved frequency fidelity with IISA and FCSA components
- Local attribution maps confirm effective global context capture with FCSA

## Why This Works (Mechanism)

### Mechanism 1: Lossless Frequency Information Incorporation
Real-imaginary mapping of FFT outputs enables lossless frequency information incorporation into convolutional networks. FIM decomposes complex-valued FFT outputs into separate real and imaginary channels, processes each independently via convolution, then recombines via complexification and IFFT with skip connections merging frequency-enriched features with spatial features. This maintains phase and amplitude information separately, preserving more information than amplitude-only approaches.

### Mechanism 2: Cross-Domain Information Synergy
Alternating subspace projection of spatial and frequency features enables cross-domain information synergy. IISA projects input into multiple subspaces using alternating projection matrices (odd indices for spatial, even for frequency), fuses these projections via linear layers, and applies multi-head self-attention for re-interaction. This forces early interaction between domains rather than late fusion of separately processed streams.

### Mechanism 3: Global Context via Frequency Correlation
Computing attention correlation in the frequency domain leverages Fourier's global aggregation property for efficient global context. FCSA transforms Q and K to frequency domain via FFT, computes correlation as element-wise product with conjugate transpose, then normalizes via IFFT. Since each frequency coefficient aggregates all spatial positions, this captures global relationships without O(n²) spatial attention.

## Foundational Learning

- **Fast Fourier Transform (FFT) for images**: Why needed - FIM and FCSA both depend on understanding how 2D FFT converts spatial images to frequency coefficients, and why each frequency bin contains global information. Quick check - Explain why a single low-frequency coefficient in F(u,v) depends on all spatial pixels f(x,y).

- **Implicit Neural Representation (INR) for ASSR**: Why needed - FIT builds on INR's coordinate-based prediction; understanding how MLPs map LR features + HR coordinates to RGB values is essential. Quick check - How does INR enable arbitrary-scale upscaling without retraining?

- **Multi-head self-attention mechanics**: Why needed - IISA uses MHSA for re-interaction; understanding Q/K/V projections, scaled dot-product attention, and head concatenation is prerequisite. Quick check - Why does MHSA split channels across heads rather than using separate Q/K/V for each head?

## Architecture Onboarding

- Component map: Input LR Image → Encoder (RDN/EDSR) → FIM → FUSAM → Decoder + bilinear-upsampled LR → HR Image

- Critical path: FIM's real-imaginary separation → IISA's subspace fusion → FCSA's frequency correlation. Each stage has ablation evidence; removing any degrades PSNR.

- Design tradeoffs: Real-imaginary mapping doubles channel count vs. amplitude-phase extraction (more memory, but lossless). 4 subspaces in IISA balances cross-domain interaction vs. parameter dilution. FCSA adds FFT operations but avoids O(n²) spatial attention.

- Failure signatures: Blurry feature maps → FIM not incorporated (spatial-only baseline). High frequency error (red in FEM) → IISA missing or spatial-only subspaces. Limited context region in LAM → FCSA disabled.

- First 3 experiments: 1) Reproduce FIM ablation: Replace FIM with spatial block; expect ~0.03 dB PSNR drop and blurrier feature visualization. 2) Vary IISA subspace count: Test 0, 2, 4, 8, 16; expect peak at 4 with degradation at extremes. 3) Disable FCSA: Run DIV2K validation; expect ~0.03 dB drop and reduced LAM context coverage.

## Open Questions the Paper Calls Out

- **Dynamic frequency exploitation based on magnification scale**: Can the network be improved by dynamically adjusting the exploitation of frequency information based on the specific magnification scale? The authors state FIT could be improved by dynamically adjusting frequency exploitation "according to the magnification."

- **Frequency-adapted position encoding**: How can position encoding be redesigned to be specifically applicable to frequency information rather than relying on spatial coding? The paper identifies "adopting location coding applicable to frequency information" as a direction for future exploration to enhance utilization effectiveness.

- **Weighted frequency band exploitation**: What is the optimal strategy for the weighted exploitation of information from different frequency bands within the architecture? The authors list "weighted exploitation of information from different frequency bands" as a distinct limitation and area for future study.

## Limitations
- Decoder architecture and training strategy details remain unspecified, limiting exact replication
- Unknown weight initialization and feature dimension C for modules
- Complex tensor handling in FIM requires careful implementation to match reported performance

## Confidence
- High: Frequency domain incorporation improves detail characterization (PSNR gains + ablation evidence)
- High: IISA subspace cross-domain interaction provides measurable benefits (4 subspaces optimal per ablation)
- Medium: FCSA global context capture via frequency correlation (LAM visualization supports claim but PSNR gain modest)

## Next Checks
1. Replicate FIM ablation: Replace FIM with spatial-only block; expect ~0.03 dB PSNR drop and blurrier feature visualization
2. Vary IISA subspace count: Test 0, 2, 4, 8, 16 subspaces; expect peak at 4 with degradation at extremes
3. Disable FCSA: Run DIV2K validation; expect ~0.03 dB drop and reduced LAM context coverage