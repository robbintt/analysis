---
ver: rpa2
title: 'Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study'
arxiv_id: '2512.19253'
source_url: https://arxiv.org/abs/2512.19253
tags:
- quantum
- unlearning
- machine
- forgetting
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper provides the first comprehensive empirical study of\
  \ machine unlearning (MU) in hybrid quantum-classical neural networks, addressing\
  \ a significant gap in understanding how classical MU techniques behave when quantum\
  \ components are involved. The authors adapt a broad suite of conventional MU methods\u2014\
  including gradient-based, distillation-based, regularization-based, and certified\
  \ techniques\u2014to models incorporating variational quantum circuits (VQCs), and\
  \ introduce two novel strategies specifically tailored for quantum settings: Label-Complement\
  \ Augmentation (LCA) and ADV-UNIFORM."
---

# Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study

## Quick Facts
- arXiv ID: 2512.19253
- Source URL: https://arxiv.org/abs/2512.19253
- Authors: Carla Crivoi; Radu Tudor Ionescu
- Reference count: 21
- This paper provides the first comprehensive empirical study of machine unlearning (MU) in hybrid quantum-classical neural networks.

## Executive Summary
This paper provides the first comprehensive empirical study of machine unlearning (MU) in hybrid quantum-classical neural networks, addressing a significant gap in understanding how classical MU techniques behave when quantum components are involved. The authors adapt a broad suite of conventional MU methods—including gradient-based, distillation-based, regularization-based, and certified techniques—to models incorporating variational quantum circuits (VQCs), and introduce two novel strategies specifically tailored for quantum settings: Label-Complement Augmentation (LCA) and ADV-UNIFORM. Experiments across Iris, MNIST, and Fashion-MNIST, under both subset removal and full-class deletion scenarios, reveal that quantum models can support effective unlearning, but outcomes depend strongly on circuit depth, entanglement structure, and task complexity. Shallow VQCs display high intrinsic stability with minimal memorization, whereas deeper hybrid models exhibit stronger trade-offs between utility, forgetting strength, and alignment with retrain oracle. The study finds that certain methods, e.g., EU-k, LCA, and Certified Unlearning, consistently provide the best balance across metrics. These findings establish baseline empirical insights into quantum machine unlearning and highlight the need for quantum-aware algorithms and theoretical guarantees, as quantum machine learning systems continue to expand in scale and capability.

## Method Summary
The study adapts 10 conventional machine unlearning methods (gradient-based, distillation-based, regularization-based, and certified) to hybrid quantum-classical neural networks incorporating variational quantum circuits. The authors introduce two novel quantum-aware strategies: Label-Complement Augmentation (LCA) and ADV-UNIFORM. Experiments use angle encoding with CZ-ring entanglement on three datasets (Iris, MNIST, Fashion-MNIST) at specified sample sizes. Models are trained for ≤100 epochs with patience 10, then unlearned for ≤25 epochs with patience 5. Evaluation metrics include utility (retain/test accuracy), forgetting quality (MIA scores), and similarity to retrain oracle (KL/JS divergence, UQI, prediction agreement). All experiments use simulated variational quantum circuits without hardware evaluation.

## Key Results
- Shallow VQCs show high intrinsic stability with minimal memorization, making unlearning more effective with less utility degradation
- Label-Complement Augmentation (LCA) achieves superior trade-offs between forgetting strength and utility preservation compared to classical baselines
- EU-k1 consistently provides the best balance between retain accuracy and alignment with retrain oracle across multiple datasets and forgetting scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Shallow VQCs exhibit limited memorization, making unlearning more stable with smaller representational shifts.
- Mechanism: Variational quantum circuits with few parameters and simple entanglement structures encode training data weakly. The parameter landscape has limited capacity to store fine-grained sample-specific information, so deletions induce minor distributional changes.
- Core assumption: Memorization scales with circuit depth and parameter count.
- Evidence anchors:
  - [abstract] "Shallow VQCs display high intrinsic stability with minimal memorization, whereas deeper hybrid models exhibit stronger trade-offs"
  - [Section 6.1] On Iris (4-qubit, ~155 params): "unlearning 2% of the data induces only minor shifts in the output distribution"
  - [corpus] Related work on VQC expressivity confirms parameter count bounds representational capacity (arXiv:2506.10275)
- Break condition: Deep VQCs with many entangling layers will memorize more, reducing this natural stability.

### Mechanism 2
- Claim: Label-Complement Augmentation (LCA) enforces structured forgetting by targeting maximal ambiguity rather than arbitrary parameter shifts.
- Mechanism: LCA constructs a complementary label distribution that suppresses the forgotten class while preserving consistency with remaining labels. The KL-divergence loss pushes predictions toward high-entropy outputs, which aligns with how quantum models encode class information in distributed amplitude patterns.
- Core assumption: Quantum models encode class information in distributed patterns rather than localized activations.
- Evidence anchors:
  - [Section 4] "LCA harnesses the fact that quantum models often encode class information in distributed amplitude patterns rather than highly localized activations"
  - [Section 6.3] On Fashion-MNIST subset: LCA achieves UQI=0.8716 and MIA=0.0051, outperforming baselines
  - [corpus] No direct corpus evidence on LCA-specific mechanisms; this is a novel contribution
- Break condition: If classes share significant amplitude structure, complement labels may inadvertently disrupt retained-class performance.

### Mechanism 3
- Claim: Methods with explicit structural control (EU-k, Certified) outperform unconstrained gradient-based approaches by constraining where updates propagate.
- Mechanism: EU-k resets the last k layers before retain-only fine-tuning, preventing gradient updates from corrupting lower-level quantum embeddings. Certified unlearning adds controlled noise during fine-tuning, providing regularization that prevents over-correction in quantum layers.
- Core assumption: Deletions should primarily affect higher-level decision boundaries, not foundational quantum feature embeddings.
- Evidence anchors:
  - [Section 6.2] EU-k1 achieves highest retain accuracy (85.5%) and best test agreement (85.5%) on MNIST subset
  - [Section 6.3] On Fashion-MNIST full-class: EU-k1 yields "prediction distributions closest to the retrain oracle"
  - [corpus] Certified unlearning foundations from arXiv:2409.09778 support noise-based guarantees
- Break condition: If the forget set is encoded primarily in early layers (unlikely but possible with deep entanglement), layer freezing may block effective unlearning.

## Foundational Learning

- Concept: **Variational Quantum Circuits (VQCs)**
  - Why needed here: The core quantum component; understanding parameter-shift gradients, entanglement, and measurement statistics is essential for interpreting how unlearning propagates through quantum layers.
  - Quick check question: Can you explain how the parameter-shift rule computes gradients without backpropagation through quantum states?

- Concept: **Machine Unlearning Objective Functions**
  - Why needed here: The paper adapts multiple MU approaches (gradient ascent, distillation, certified). Understanding the trade-off between forgetting strength and utility preservation is critical for method selection.
  - Quick check question: What is the difference between gradient-based scrubbing and certified unlearning in terms of theoretical guarantees?

- Concept: **Quantum Distance Metrics (Fidelity, Trace Distance)**
  - Why needed here: Model similarity in quantum settings uses quantum-specific distance measures rather than purely classical metrics; UQI and KL/JS divergences measure alignment with retrain oracle.
  - Quick check question: Why can't we use standard weight-space distance metrics to compare two trained VQCs?

## Architecture Onboarding

- Component map: Input → Classical features → Angle encoding → VQC (rotations + entanglement) → Measurement → Classical head → Softmax predictions
- Critical path: Classical feature extractor → Angle encoding → VQC core (parametrized rotations + CZ-ring entanglement layers) → Measurement layer → Classical head
- Design tradeoffs:
  - Shallow VQCs: More stable unlearning but lower capacity for complex tasks
  - Deep VQCs: Better expressivity but stronger utility-forgetting trade-offs
  - Entanglement structure: Ring-CZ provides moderate connectivity; fully-connected entanglement increases memorization risk
- Failure signatures:
  - Gradient-based methods showing high KL/JS divergence with low accuracy indicates unlearning is corrupting useful representations
  - Negative UQI with high retain accuracy suggests the model is not aligning with retrain oracle (cosmetic forgetting)
  - MIA > 0.5 after unlearning indicates membership leakage persists
- First 3 experiments:
  1. **Subset forgetting baseline**: Run all 10 MU methods on Iris with 2% deletion; confirm shallow VQC stability and establish metric baselines (expect UQI near zero, low KL/JS).
  2. **Full-class stress test**: Apply EU-k1, LCA, and Certified on Fashion-MNIST full-class deletion; compare UQI and test accuracy to identify best trade-off method.
  3. **Ablation on circuit depth**: Train identical architectures with 2, 4, and 8 entanglement layers on MNIST; measure how depth affects memorization (MIA) and unlearning stability (UQI variance across methods).

## Open Questions the Paper Calls Out

- **Hardware vs simulation gap**: How do noise, gate fidelity, and device topology on actual quantum hardware affect machine unlearning performance compared to simulations?
  - Basis: "extending evaluations to hardware back-ends will clarify how noise, gate fidelity, and device topology affect unlearning performance."
  - Why unresolved: All experiments use simulated variational quantum circuits, not physical quantum devices.
  - Evidence needed: Empirical evaluation on real quantum hardware (e.g., IBM Q, IonQ) comparing divergence metrics and utility against simulation baselines.

- **Theoretical guarantees absence**: Can formal theoretical guarantees for quantum unlearning analogous to certified removal in classical MU be developed?
  - Basis: "formal guarantees for quantum unlearning, analogous to certified removal in classical MU, remain largely unexplored and may require new theoretical tools grounded in quantum information theory."
  - Why unresolved: The paper provides only empirical baselines without provable bounds on forgetting fidelity or privacy guarantees for VQCs.
  - Evidence needed: Proofs establishing indistinguishability bounds or certified removal certificates for specific quantum architectures, or negative results showing fundamental limitations.

- **Native quantum algorithms**: Can native quantum unlearning algorithms that explicitly exploit quantum amplitude structure, entanglement patterns, or decoherence dynamics outperform adapted classical methods?
  - Basis: "the development of native quantum unlearning algorithms that explicitly exploit quantum amplitude structure, entanglement patterns, or decoherence dynamics may yield more efficient and principled approaches."
  - Why unresolved: LCA and ADV-UNIFORM are classical-objective adaptations; no algorithm directly manipulates quantum-specific properties like entanglement entropy or decoherence.
  - Evidence needed: Novel algorithms using entanglement-aware regularizers or amplitude-based reset procedures, evaluated on the same benchmarks with statistically significant improvements.

## Limitations

- **Hardware vs simulation gap**: All experiments use classical simulators, leaving open whether unlearning effectiveness scales to real quantum hardware where noise and decoherence may alter gradient dynamics.
- **Parameter sensitivity**: Several methods depend on unspecified hyperparameters (noise scale, epsilon values, layer reset count), making exact replication uncertain.
- **Theoretical guarantees absence**: The work lacks formal bounds on quantum unlearning effectiveness, particularly for complex hybrid architectures.

## Confidence

**High confidence**: Findings on shallow VQC stability and depth-dependent memorization effects; LCA and EU-k1 performance across datasets; the general trade-off pattern between utility and forgetting strength.

**Medium confidence**: Specific metric values (UQI, MIA scores) due to potential parameter sensitivity; the superiority of particular methods may vary with hyperparameter choices.

**Low confidence**: Claims about quantum-specific forgetting mechanisms beyond what can be observed in simulation; long-term stability of unlearned models under distribution shifts.

## Next Checks

1. **Hardware validation**: Implement the top-performing methods (EU-k1, LCA, Certified) on NISQ devices with 5-10 qubits to measure degradation from ideal simulator performance.

2. **Hyperparameter robustness**: Systematically vary key parameters (noise scale, epsilon, layer reset count) across all methods to establish sensitivity profiles and identify robust configurations.

3. **Scalability stress test**: Extend experiments to 20-30 qubit circuits with deeper entanglement structures to validate whether shallow-VQC findings generalize to more complex quantum models.