---
ver: rpa2
title: 'Marginal Fairness: Fair Decision-Making under Risk Measures'
arxiv_id: '2505.18895'
source_url: https://arxiv.org/abs/2505.18895
tags:
- fairness
- decision
- sensitivity
- risk
- fair
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces marginal fairness, a new individual fairness
  notion for equitable decision-making under risk measures in regulated industries
  like insurance and finance. The framework addresses indirect discrimination arising
  from statistical dependencies between protected attributes (e.g., gender, race)
  and outcomes when these attributes are excluded from final decisions.
---

# Marginal Fairness: Fair Decision-Making under Risk Measures

## Quick Facts
- arXiv ID: 2505.18895
- Source URL: https://arxiv.org/abs/2505.18895
- Authors: Fei Huang; Silvana M. Pesenti
- Reference count: 40
- Primary result: Marginal fairness framework addresses indirect discrimination in risk-based decisions by ensuring insensitivity to protected attribute perturbations

## Executive Summary
This paper introduces marginal fairness, a novel individual fairness notion for equitable decision-making under risk measures in regulated industries. The framework addresses indirect discrimination that arises when protected attributes are excluded from final decisions but remain statistically dependent on outcomes. By formalizing marginal fairness as the insensitivity of risk-based decisions to distributional perturbations in protected attributes, the authors provide a theoretically grounded approach to algorithmic fairness in insurance, finance, and similar domains.

The two-step decision-making model separates predictive modeling (using all covariates) from decision-making (using only non-protected covariates with generalized distortion risk measures). This approach enables practical implementation while maintaining regulatory compliance. The framework accommodates various types of protected attributes and extends to account for covariate dependencies through cascade sensitivity analysis.

## Method Summary
The framework models decision-making as a two-step process: first, predictive modeling uses both protected and non-protected covariates; second, decisions are made using generalized distortion risk measures applied only to non-protected covariates. Marginal fairness is achieved by ensuring decisions remain insensitive to distributional perturbations in protected attributes, formalized through differential sensitivity analysis. The approach provides consistent analytical tools for achieving fairness across different protected attribute types (continuous, bounded, discrete, categorical, multivariate) and incorporates cascade sensitivity to handle statistical dependencies among covariates.

## Key Results
- Marginal fairness successfully addresses indirect discrimination by eliminating sensitivity to protected attribute distributions while maintaining decision quality
- Theoretical characterization of optimal marginally fair decision rules that balance minimal distance from original rules with fairness requirements
- Empirical implementation using French auto insurance data demonstrates feasible application with minimal predictive accuracy loss and maintained segmentation efficiency

## Why This Works (Mechanism)
Marginal fairness works by fundamentally reframing fairness as insensitivity to distributional perturbations in protected attributes rather than attempting to remove all statistical dependencies. The framework leverages distortion risk measures to capture the decision-maker's risk preferences while ensuring that small changes in protected attribute distributions do not significantly alter outcomes. This approach acknowledges that complete independence between protected attributes and outcomes may be impossible or undesirable, instead focusing on preventing discriminatory sensitivity.

## Foundational Learning
- **Distortion risk measures**: Needed to quantify decision-maker risk preferences in regulated industries; Quick check: Verify the chosen distortion function appropriately reflects the decision-maker's risk attitude
- **Differential sensitivity analysis**: Required to formalize marginal fairness as insensitivity to protected attribute perturbations; Quick check: Confirm sensitivity measures capture meaningful changes in decision outcomes
- **Cascade sensitivity**: Essential for handling statistical dependencies among covariates; Quick check: Validate that cascade sensitivity adequately captures all relevant dependency structures
- **Two-step decision framework**: Critical for separating predictive modeling from risk-based decision-making; Quick check: Ensure separation maintains both predictive accuracy and fairness objectives
- **Generalized distortion functions**: Necessary to accommodate different types of protected attributes; Quick check: Confirm the generalized framework handles all attribute types appropriately
- **Individual fairness notion**: Important for focusing on person-level fairness rather than group-level metrics; Quick check: Verify individual-level fairness guarantees are meaningful in context

## Architecture Onboarding

**Component map:**
Predictive Model -> Distortion Risk Measure -> Marginal Fairness Adjustment -> Decision Output

**Critical path:**
1. Build predictive model using all covariates (protected + non-protected)
2. Apply distortion risk measure to non-protected covariates
3. Compute sensitivity to protected attribute perturbations
4. Adjust decision rule to achieve marginal fairness
5. Validate fairness and accuracy trade-offs

**Design tradeoffs:**
- Balance between predictive accuracy and fairness requirements
- Choice of distortion risk measure affects both performance and fairness
- Computational complexity increases with number of protected attributes and their types
- Trade-off between individual fairness and group fairness considerations

**Failure signatures:**
- Significant predictive accuracy degradation after fairness adjustment
- Inability to converge on marginally fair decision rules for certain attribute types
- Cascade sensitivity failing to capture all relevant dependency structures
- Marginal fairness adjustments creating new forms of indirect discrimination

**3 first experiments:**
1. Implement framework on synthetic data with known protected attribute dependencies
2. Compare different distortion risk measures for the same application domain
3. Test framework sensitivity to varying levels of protected attribute correlation with outcomes

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Reliance on distortion risk measures may limit applicability to domains where such measures are appropriate
- Cascade sensitivity approach assumes statistical dependencies can be adequately captured through proposed measures
- Empirical validation limited to single industry context (French auto insurance)
- May not generalize to all regulated sectors or geographic regions

## Confidence
- **High Confidence**: Mathematical formulation of marginal fairness as insensitivity to distributional perturbations is theoretically sound
- **Medium Confidence**: Practical feasibility of implementing marginal fairness adjustments with minimal predictive accuracy loss
- **Medium Confidence**: Effectiveness of cascade sensitivity in accounting for covariate dependencies

## Next Checks
1. Test framework performance across multiple regulated industries (healthcare, lending, housing) to assess generalizability beyond insurance applications
2. Evaluate sensitivity of results to different choices of distortion risk measures and compare outcomes with alternative risk measure formulations
3. Conduct longitudinal studies to assess stability of marginal fairness adjustments over time as underlying data distributions evolve