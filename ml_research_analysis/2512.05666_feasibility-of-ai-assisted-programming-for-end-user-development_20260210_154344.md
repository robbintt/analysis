---
ver: rpa2
title: Feasibility of AI-Assisted Programming for End-User Development
arxiv_id: '2512.05666'
source_url: https://arxiv.org/abs/2512.05666
tags:
- development
- end-user
- participants
- ai-assisted
- coding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether AI-assisted programming can enable
  non-programmers to create digital tools, as a potential alternative to low-code/no-code
  platforms. A case study was conducted where students with basic coding skills were
  asked to develop a survey web app using AI assistants like ChatGPT.
---

# Feasibility of AI-Assisted Programming for End-User Development

## Quick Facts
- **arXiv ID**: 2512.05666
- **Source URL**: https://arxiv.org/abs/2512.05666
- **Reference count**: 0
- **Primary result**: 72% of students with basic coding skills successfully built a survey web app using AI assistants, suggesting AI-assisted end-user coding is feasible for simple applications.

## Executive Summary
This paper investigates whether AI-assisted programming can enable non-programmers to create digital tools as an alternative to low-code/no-code platforms. Through a case study with students having basic coding skills, participants used AI assistants like ChatGPT to develop a survey web app. The majority successfully completed the task within reasonable time, and most expressed willingness to use and recommend this approach in enterprise settings. Results suggest AI-assisted end-user coding is a feasible paradigm for end-user development, though participants indicated a need for training and supportive development platforms. The study demonstrates that natural language prompts can serve as an effective abstraction layer for code generation, enabling users to bridge the gap between intent and executable software.

## Method Summary
The study involved 33 German university students with basic coding skills who were tasked with developing a survey web application using AI assistants like ChatGPT. Participants received a 20-minute introduction with a demo survey, then worked iteratively by refining and expanding their applications through natural language prompts to the LLM. The technical setup was deliberately kept simple: a single HTML file with CSS styling and JavaScript for interactive elements, connected to a Google Sheets backend via Google Apps Script for storing responses. Success was measured by task completion rate, time spent, perceived effort-to-outcome ratio, and willingness to recommend/use in enterprise settings.

## Key Results
- 72% of participants successfully completed the survey web app development task
- Most participants expressed willingness to use and recommend AI-assisted development in enterprise settings
- Google Sheets integration was the most frequent difficulty (15/33 participants), followed by prompting difficulties (6/33 participants)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Natural language prompts serve as an effective abstraction layer for code generation, enabling non-programmers to bridge the gap between intent and executable software.
- **Mechanism**: Users describe software requirements in natural language, which an LLM translates into syntactically correct code (e.g., HTML, JavaScript). This bypasses the need for users to master formal programming syntax.
- **Core assumption**: The user can articulate requirements clearly enough for the LLM to infer correct logic and structure.
- **Evidence anchors**: [abstract] "enable end users to generate and refine programming code and build apps directly from natural language prompts." [section 3] Participants were instructed to develop the form iteratively by refining and expanding it through further prompts to the LLM.
- **Break condition**: The user's intent is ambiguous or requires logic outside the LLM's training data, leading to plausible but incorrect code the user cannot debug.

### Mechanism 2
- **Claim**: An iterative, conversational refinement process between user and LLM enables incremental development and debugging, compensating for initial prompt ambiguity and model errors.
- **Mechanism**: The user provides an initial prompt, tests the LLM's output, and then provides corrective or expansive feedback in subsequent prompts. This cycle continues until the application meets the user's needs.
- **Core assumption**: The user has sufficient domain knowledge to evaluate the output and can communicate necessary changes effectively.
- **Evidence anchors**: [abstract] "generate and refine programming code and build apps directly from natural language prompts." [section 3] "Participants were instructed to begin by describing their task to the LLM and then develop the form iteratively by refining and expanding it through further prompts."
- **Break condition**: The user cannot identify the source of a problem or describe a fix in a way the LLM understands, leading to a cycle of ineffective corrections.

### Mechanism 3
- **Claim**: A scaffolded, minimal-complexity development environment reduces cognitive load on the end-user, making AI-assisted development feasible for simple tasks.
- **Mechanism**: By constraining the technical scope (e.g., a single HTML file, no complex deployment pipeline), barriers like server setup and build tools are removed. The LLM's task is kept manageable, increasing the likelihood of a successful outcome for a non-expert.
- **Core assumption**: The desired application can be built within the constraints of the simplified environment.
- **Evidence anchors**: [abstract] "may enable end users to generate and refine programming code and build apps directly from natural language prompts." [section 3] "To avoid the need for a complex development environment or deployment process, the technical setup was deliberately kept simple..."
- **Break condition**: Application requirements grow beyond the capabilities of the simple environment (e.g., needing secure authentication), forcing the user to confront complexities they are ill-equipped to handle.

## Foundational Learning

- **Concept**: **Prompt Engineering (Decomposition & Specification)**
  - **Why needed here**: The study identified "Prompting" as a key difficulty. Success depends on a user's ability to decompose a goal into specific, unambiguous instructions for the LLM.
  - **Quick check question**: Can you rewrite a vague request like "make a survey form" into three discrete, technically descriptive prompts?

- **Concept**: **LLM Capabilities & Limitations (Hallucination & Verification)**
  - **Why needed here**: LLMs can generate syntactic code but lack true understanding, sometimes "hallucinating" non-existent libraries or insecure patterns. Users must learn to verify outputs rather than blindly trusting them.
  - **Quick check question**: If an LLM generates code referencing a JavaScript library you don't recognize, what is your first verification step?

- **Concept**: **Basic Code Interpretation & Debugging**
  - **Why needed here**: Even with AI, code contains errors. Users must be able to read basic error messages (e.g., from a browser console) and describe them back to the LLM for a fix.
  - **Quick check question**: Your web form doesn't submit data, and you see a red error in the browser's developer console. What key information from that message should you copy back to the AI?

## Architecture Onboarding

- **Component map**: User -> Natural Language Intent -> LLM Assistant -> Code Generation -> Development Environment -> Runtime Execution -> Backend Service
- **Critical path**: User Prompt -> LLM Code Generation -> User Integration/Execution -> Error/Refinement -> Corrective Prompt. The most fragile step is **Error/Refinement**, where the user must diagnose a problem they may not fully understand.
- **Design tradeoffs**:
  - **Simplicity vs. Scalability**: A single-file setup lowers the barrier to entry but limits application complexity and scalability (e.g., no server-side logic).
  - **Autonomy vs. Governance**: Self-generated code offers flexibility and avoids vendor lock-in but can create IT governance and security risks if not managed.
- **Failure signatures**:
  - **Infinite Debug Loop**: The user describes a symptom, the LLM provides a fix that causes a new error, and the cycle repeats without progress.
  - **Context Drift**: Over a long session, the LLM forgets initial constraints, leading to inconsistent code.
  - **Silent Failure**: Code runs without visible errors but produces incorrect results (e.g., data saved to the wrong spreadsheet columns), which are hard for novices to detect.
- **First 3 experiments**:
  1. **"Prompt-to-Prototype" Test**: Give a new user a single goal (e.g., "build a contact form"). Measure the number of prompts and time required to achieve a minimally functional result.
  2. **"Broken Code" Challenge**: Provide a user with a piece of code that has a subtle bug (e.g., a typo in a variable name). Task them with using the LLM to identify and fix the error without directly revealing the bug's nature.
  3. **"Integration Hurdle" Test**: Ask a user to connect their frontend form to a provided backend API endpoint. This directly tests the study's major reported difficulty (backend integration) and identifies where the conceptual model breaks down.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can end users with absolutely no technical background or prior coding education successfully implement applications using AI-assisted coding?
- **Basis in paper**: [inferred] The authors explicitly list the participant pool's "technical background" and "basic coding skills" as a limitation, acknowledging that industrial engineering students may not represent the diversity of typical non-technical enterprise users.
- **Why unresolved**: It is unclear if the 72% success rate was dependent on the participants' pre-existing technical literacy or if it can be achieved by true novices.
- **What evidence would resolve it**: A replication of the study involving participants from non-STEM disciplines with zero formal programming training.

### Open Question 2
- **Question**: How can dedicated development platforms mitigate the specific backend integration challenges encountered by end-user coders?
- **Basis in paper**: [explicit] The discussion notes that "Google Sheets integration" was the most frequent difficulty reported by participants, and the authors interpret participant feedback as a demand for a "dedicated development platform" to handle such complexities.
- **Why unresolved**: The study utilized a manual, lightweight setup for backend integration, leaving the efficacy of specialized platforms for AI-assisted EUD untested.
- **What evidence would resolve it**: User studies evaluating prototype platforms that automate backend connections for LLM-generated frontend code.

### Open Question 3
- **Question**: Is AI-assisted end-user coding more efficient or effective than traditional visual Low-Code/No-Code (LCNC) platforms?
- **Basis in paper**: [inferred] The introduction frames AI-assisted coding as a paradigm that may "complement or even replace" LCNC models, but the methodology did not include a control group using LCNC tools.
- **Why unresolved**: The study established feasibility in isolation but did not provide comparative data on development time, effort, or quality against the current standard (LCNC).
- **What evidence would resolve it**: A randomized controlled trial where separate groups develop the same application using AI-coding versus a standard LCNC platform.

## Limitations
- Small sample size (33 participants) from a specific demographic (German university students with basic coding skills)
- Artificial task environment (single-file HTML form) may not reflect real-world application complexity
- Study did not assess whether participants could maintain or extend applications independently
- "Willingness to use/recommend" metric may overstate actual adoption readiness due to participant incentives
- No comparison with traditional low-code/no-code platforms

## Confidence
- **Feasibility of AI-assisted end-user development**: Medium confidence. The study shows task completion is possible but doesn't establish whether this approach scales to complex applications or whether participants could repeat the process independently.
- **Natural language as effective abstraction layer**: Low confidence. While the mechanism is plausible, the study didn't systematically test variations in prompt quality or measure the cognitive load of prompt engineering versus traditional coding.
- **Iterative refinement as compensatory mechanism**: Low confidence. The study observed participants using iterative refinement but didn't test whether this process was necessary or optimal compared to alternative approaches.

## Next Checks
1. **Independent Replication Test**: Recruit a new cohort of true non-programmers (no basic coding skills) and repeat the study without the introductory demo or support. Measure completion rates, time, and error patterns to assess whether the approach works for the intended audience.
2. **Longitudinal Maintenance Study**: With participants who successfully completed the initial task, conduct follow-up sessions 2-4 weeks later asking them to add new features or fix bugs without assistance. This tests whether AI-assisted development creates sustainable skills.
3. **Comparative Platform Study**: Repeat the study using both AI-assisted development and a popular low-code platform (e.g., Microsoft Power Apps) with the same participants. Compare completion rates, time investment, satisfaction, and perceived learning curve to validate whether AI assistance offers genuine advantages over existing alternatives.