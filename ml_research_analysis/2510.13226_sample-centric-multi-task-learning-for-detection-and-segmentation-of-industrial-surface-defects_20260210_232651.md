---
ver: rpa2
title: Sample-Centric Multi-Task Learning for Detection and Segmentation of Industrial
  Surface Defects
arxiv_id: '2510.13226'
source_url: https://arxiv.org/abs/2510.13226
tags:
- segmentation
- sample
- miou
- sample-level
- defect
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors propose a sample-centric multi-task learning (MTL)
  framework for industrial surface defect detection and segmentation, addressing the
  problem that pixel-centric training and evaluation fail to reliably detect small
  or low-contrast defects under extreme foreground-background imbalance. The method
  jointly learns sample-level defect classification and pixel-level segmentation using
  a shared-encoder architecture, with a lightweight classification branch ("Classifier
  as a Plugin") that backpropagates sample-level supervision to improve small-defect
  recall.
---

# Sample-Centric Multi-Task Learning for Detection and Segmentation of Industrial Surface Defects

## Quick Facts
- arXiv ID: 2510.13226
- Source URL: https://arxiv.org/abs/2510.13226
- Reference count: 35
- The authors propose a sample-centric multi-task learning framework for industrial surface defect detection and segmentation

## Executive Summary
This paper addresses the limitations of pixel-centric approaches for industrial surface defect detection and segmentation, particularly for small or low-contrast defects under extreme foreground-background imbalance. The authors propose a sample-centric multi-task learning framework that jointly learns sample-level defect classification and pixel-level segmentation using a shared encoder architecture. The method introduces a lightweight classification branch that propagates sample-level supervision to improve small-defect recall while maintaining segmentation quality. Experiments on KolektorSDD2 and Crack datasets demonstrate significant improvements in both detection and segmentation performance.

## Method Summary
The proposed method employs a shared-encoder architecture with two parallel branches: a segmentation branch and a lightweight classification branch. The classification branch, termed "Classifier as a Plugin," is designed to provide sample-level supervision during training. The framework addresses the foreground-background imbalance issue by introducing Sample_mIoU as an evaluation metric, which averages IoU only over defect-containing samples. The approach also includes complementary metrics (Seg_Accuracy and Seg_Recall) to better align with industrial quality control requirements. The MTL framework enables the model to leverage both pixel-level and sample-level supervision, improving the detection of small defects while maintaining overall segmentation performance.

## Key Results
- Sample_mIoU improved by up to 6.3% on KolektorSDD2 and 4.3% on Crack datasets
- Seg_Recall reached 100% in some cases, demonstrating excellent defect detection capability
- Maintained or slightly improved pixel-level mIoU while significantly enhancing small defect detection
- The MTL approach achieved substantial gains in sample-level recall compared to single-task baselines

## Why This Works (Mechanism)
The sample-centric MTL framework works by introducing sample-level supervision through a lightweight classification branch that backpropagates information to the shared encoder. This approach addresses the limitations of pixel-centric training, which struggles with extreme foreground-background imbalance and small defects. By incorporating sample-level classification, the model receives more balanced supervision signals that are less affected by the predominance of background pixels. The classification branch acts as a plugin that enhances the encoder's ability to capture defect-relevant features without significantly increasing computational complexity. The Sample_mIoU metric aligns evaluation with practical quality control needs by focusing on defect-containing samples rather than averaging over all pixels.

## Foundational Learning
- **Multi-task learning principles**: Why needed - enables joint optimization of related tasks; Quick check - verify shared encoder weights are properly updated for both tasks
- **Foreground-background imbalance handling**: Why needed - standard segmentation approaches struggle with extreme class imbalance; Quick check - confirm class weighting or sampling strategies are implemented
- **Sample-level supervision propagation**: Why needed - provides more robust supervision signals for small defect detection; Quick check - validate classification branch gradients flow to shared encoder
- **Metric alignment with practical needs**: Why needed - standard mIoU doesn't reflect quality control requirements; Quick check - verify Sample_mIoU calculation excludes defect-free samples
- **Lightweight branch design**: Why needed - maintains efficiency while adding detection capability; Quick check - confirm classification branch parameters are minimal
- **Shared encoder architecture**: Why needed - enables feature sharing between tasks; Quick check - verify encoder features are used by both segmentation and classification branches

## Architecture Onboarding

Component map: Input images -> Shared Encoder -> [Segmentation Branch, Classification Branch] -> Output predictions

Critical path: Input -> Shared Encoder -> Both Branches -> Combined loss

Design tradeoffs:
- Balance between segmentation accuracy and detection recall
- Complexity of classification branch vs. performance gains
- Choice of evaluation metrics reflecting practical requirements

Failure signatures:
- Poor performance on small defects despite MTL
- Degradation in pixel-level segmentation accuracy
- Overfitting to sample-level classification at expense of pixel-level detail

First experiments:
1. Compare MTL performance against single-task segmentation baseline
2. Evaluate impact of classification branch depth on overall performance
3. Test different weighting strategies for combined loss function

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on sample-level annotations may limit applicability in scenarios without such labels
- Sample_mIoU metric deviates from standard segmentation evaluation practices
- Performance gains are primarily observed for small defects, with less clear impact on large defect detection
- Comparative analysis focuses on specific baseline models without broader generalization claims

## Confidence

- Sample-centric MTL framework effectiveness: High
- Sample_mIoU metric validity: Medium
- Small defect detection improvements: High
- Generalizability to other datasets: Low

## Next Checks
1. Evaluate the method on additional industrial defect datasets with varying defect types and sizes
2. Compare against more diverse state-of-the-art segmentation and detection models
3. Test the approach's performance when sample-level annotations are limited or noisy