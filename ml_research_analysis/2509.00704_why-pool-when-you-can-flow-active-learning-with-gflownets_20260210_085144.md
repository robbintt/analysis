---
ver: rpa2
title: Why Pool When You Can Flow? Active Learning with GFlowNets
arxiv_id: '2509.00704'
source_url: https://arxiv.org/abs/2509.00704
tags:
- learning
- bald-gflownet
- active
- bald
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BALD-GFlowNet, a generative active learning
  framework that addresses scalability challenges in pool-based active learning for
  virtual screening. The method combines Bayesian Active Learning by Disagreement
  (BALD) with Generative Flow Networks (GFlowNets) to directly sample informative
  molecules without exhaustively evaluating large unlabeled pools.
---

# Why Pool When You Can Flow? Active Learning with GFlowNets

## Quick Facts
- **arXiv ID:** 2509.00704
- **Source URL:** https://arxiv.org/abs/2509.00704
- **Reference count:** 40
- **One-line result:** Generative active learning framework achieving 7× fewer oracle calls while matching pool-based active learning performance.

## Executive Summary
This paper addresses scalability challenges in pool-based active learning for virtual screening by introducing BALD-GFlowNet, a framework that combines Bayesian Active Learning by Disagreement (BALD) with Generative Flow Networks (GFlowNets). Instead of exhaustively evaluating large unlabeled molecule pools, BALD-GFlowNet trains a GFlowNet policy to directly sample informative molecules proportional to their BALD reward. The method achieves acquisition costs independent of pool size, demonstrating significant runtime improvements for large-scale molecular discovery tasks.

## Method Summary
BALD-GFlowNet addresses the scalability limitations of pool-based active learning by training a GFlowNet to generate molecules directly from the posterior distribution induced by the BALD score. The framework uses a pretrained atom-based GFlowNet that is finetuned using Relative Trajectory Balance (RTB) to sample molecules proportional to their BALD reward multiplied by drug-likeness metrics (TPSA, QED, SAS, Rings). The surrogate model employs MoLFormer encoder with MC Dropout to estimate uncertainty, and the active learning loop iterates through training the surrogate, finetuning the GFlowNet, and sampling new molecules for oracle evaluation.

## Key Results
- On synthetic 2D grid task, BALD-GFlowNet reached 90% of BALD's peak F1 score using 7× fewer oracle calls
- For JAK2 protein virtual screening, achieved comparable performance to standard BALD while reducing runtime by 2.5× at 50 million molecules
- Demonstrated acquisition cost independent of pool size, contrasting with linear scaling of pool-based methods

## Why This Works (Mechanism)
The framework works by shifting from pool-based selection to generative sampling. Instead of evaluating every molecule in a large pool to find the most informative ones, BALD-GFlowNet trains a generator to directly produce molecules from the distribution of high-BALD-reward candidates. This approach leverages the GFlowNet's ability to learn complex, high-dimensional distributions and the BALD score's effectiveness at identifying uncertain yet potentially valuable samples. By sampling from the posterior distribution rather than exhaustive search, the method achieves computational efficiency while maintaining or improving acquisition quality.

## Foundational Learning
- **BALD (Bayesian Active Learning by Disagreement):** Mutual Information between model parameters and predictions measures informativeness of unlabeled samples. Needed for uncertainty quantification; check by verifying MI scores correlate with model disagreement.
- **GFlowNets (Generative Flow Networks):** Sequential generative models that learn to sample from complex distributions via flow matching. Needed for direct sampling from BALD-reward distribution; check by monitoring policy gradient convergence.
- **RTB (Relative Trajectory Balance):** Training objective that balances forward and backward trajectory probabilities in GFlowNets. Needed for stable training of the generative policy; check by ensuring trajectory balance ratio stays near 1.0.
- **MC Dropout:** Monte Carlo dropout for uncertainty estimation by sampling multiple forward passes. Needed for BALD score computation; check by verifying dropout variance correlates with prediction uncertainty.
- **MoLFormer:** Molecular transformer architecture for processing molecular structures. Needed for molecular representation learning; check by validating downstream classification performance.

## Architecture Onboarding

**Component Map:** Surrogate (MoLFormer+MC Dropout) -> BALD Reward Computation -> GFlowNet Policy (RTB training) -> Molecule Generation -> Oracle Evaluation

**Critical Path:** The key sequence is training the uncertainty-aware surrogate, computing BALD scores as rewards, finetuning the GFlowNet policy to sample from this reward distribution, and generating new candidates for oracle evaluation.

**Design Tradeoffs:** 
- Generative sampling vs. pool-based evaluation: BALD-GFlowNet trades potential suboptimal sampling for computational efficiency
- Pretrained vs. from-scratch GFlowNet: Finetuning a pretrained model provides faster convergence but requires access to specific pretrained weights
- Composite reward function: Balancing informativeness (MI) with chemical validity (QED, TPSA) requires careful weighting

**Failure Signatures:** 
- Surrogate collapse (predicting all negatives due to class imbalance)
- GFlowNet mode collapse (generating repetitive or invalid molecules)
- Reward scale instability (exploding gradients from unbalanced reward terms)

**First Experiments:**
1. Validate surrogate model uncertainty estimation on held-out data
2. Test GFlowNet sampling diversity and validity on synthetic reward distributions
3. Benchmark acquisition efficiency on small molecule subsets before scaling

## Open Questions the Paper Calls Out

**Open Question 1:** Can BALD-GFlowNet be effectively adapted to domains beyond drug discovery without extensive manual redesign of the policy network?
The current implementation relies on atom-based graph generation specific to molecular structures; it is unclear if the acquisition efficiency holds for different data modalities (e.g., sequences or images).

**Open Question 2:** How robust is the framework to low-quality or poorly calibrated surrogate models that provide misleading reward signals?
The paper does not evaluate performance degradation when the initial surrogate model is trained on sparse or noisy data, which is common in cold-start scenarios.

**Open Question 3:** How does the specific weighting of the composite reward function impact the balance between chemical viability and informativeness?
The paper uses a specific product of terms but does not ablate how changes to this weighting affect the exploration-exploitation trade-off.

## Limitations
- Dependency on pretrained GFlowNet weights that are not publicly available
- Mixup implementation details for molecular embeddings lack full specification
- Computational efficiency gains depend on quality of pretrained model

## Confidence
- **High Confidence:** Theoretical framework combining BALD with GFlowNets is sound, and synthetic 2D grid results are reproducible
- **Medium Confidence:** Virtual screening results are likely reproducible given access to pretrained GFlowNet
- **Low Confidence:** Exact runtime improvements and scalability benefits cannot be verified without pretrained weights

## Next Checks
1. Request or recreate the atom-based GFlowNet weights from reference [6] to ensure faithful reproduction
2. Clarify and implement the exact Mixup procedure for molecular embeddings, including attention mask handling
3. Replicate the runtime scaling experiments on a subset of the Enamine database to validate claimed efficiency improvements