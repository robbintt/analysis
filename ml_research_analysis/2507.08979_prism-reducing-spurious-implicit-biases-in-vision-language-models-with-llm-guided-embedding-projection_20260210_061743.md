---
ver: rpa2
title: 'PRISM: Reducing Spurious Implicit Biases in Vision-Language Models with LLM-Guided
  Embedding Projection'
arxiv_id: '2507.08979'
source_url: https://arxiv.org/abs/2507.08979
tags:
- uni00000013
- prism
- spurious
- bias
- uni00000011
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'PRISM addresses the problem of spurious biases in vision-language
  models (VLMs) like CLIP by leveraging large language models (LLMs) to dynamically
  identify bias attributes and learning a debiasing projection in the embedding space.
  The method operates in two stages: first, an LLM generates scene descriptions containing
  spurious correlations based on class prompts; second, a novel contrastive-style
  latent space debiasing loss (LD) learns a projection that minimizes spurious correlations
  while preserving semantic alignment between image and text embeddings.'
---

# PRISM: Reducing Spurious Implicit Biases in Vision-Language Models with LLM-Guided Embedding Projection

## Quick Facts
- arXiv ID: 2507.08979
- Source URL: https://arxiv.org/abs/2507.08979
- Authors: Mahdiyar Molahasani; Azadeh Motamedi; Michael Greenspan; Il-Min Kim; Ali Etemad
- Reference count: 36
- Primary result: Achieves highest worst-group accuracy (84.2% on Waterbirds, 84.0% on CelebA) among data-free debiasing methods

## Executive Summary
PRISM addresses spurious biases in vision-language models by leveraging LLMs to identify bias attributes and learning a projection in the embedding space. The method operates in two stages: first, an LLM generates scene descriptions containing spurious correlations based on class prompts; second, a contrastive-style debiasing loss learns a projection that minimizes spurious correlations while preserving semantic alignment. Experiments demonstrate state-of-the-art worst-group accuracy without requiring predefined bias categories or external data.

## Method Summary
PRISM operates through a two-stage process to reduce spurious biases in CLIP-like vision-language models. First, it prompts an LLM with class labels to generate scene descriptions that reveal spurious correlations. Second, it learns a linear projection matrix using a contrastive debiasing loss that pulls together embeddings of same-class samples with different spurious attributes while pushing apart embeddings of different classes sharing the same attribute. This projection is learned while keeping CLIP's encoders frozen, making the approach task-agnostic and data-free.

## Key Results
- Achieves worst-group accuracy of 84.2% on Waterbirds dataset, outperforming all data-free baselines
- Achieves worst-group accuracy of 84.0% on CelebA dataset, the highest among tested methods
- Maintains overall classification accuracy while improving group robustness
- PRISM-mini (orthogonal projection) provides a faster, optimization-free alternative with slightly lower but still improved worst-group accuracy

## Why This Works (Mechanism)

### Mechanism 1: LLM-Driven Spurious Correlation Discovery
LLMs trained on large corpora encode statistical co-occurrences that reflect spurious correlations present in real-world data. By prompting an LLM with class labels, the model returns potential spurious attributes due to high conditional probabilities learned during pretraining. These co-occurrences arise because LLMs optimize likelihood without distinguishing causal from non-causal patterns. The core assumption is that spurious correlations in text corpora reflect those in image datasets used to train VLMs.

### Mechanism 2: Contrastive Debiasing Loss (LD) for Projection Learning
The LD loss has two components: (1) Intra-class, inter-attribute term pulls together embeddings of same-class samples with different spurious attributes; (2) Inter-class, intra-attribute term pushes apart embeddings of different classes sharing the same spurious attribute. The learned linear projection can disentangle core class features from spurious attributes by enforcing intra-class invariance and inter-class separation. The core assumption is that linear projection suffices to separate spurious from core features in CLIP's embedding space.

### Mechanism 3: Cross-Modal Debiasing Transfer
Debiasing text embeddings transfers to image embeddings because CLIP aligns both modalities in shared space. Since CLIP's image encoder ϕI and text encoder ϕT map to the same d-dimensional space, reducing spurious correlations in text representations propagates to image representations during zero-shot inference. The core assumption is that spurious correlations affect both modalities symmetrically in the shared embedding space.

## Foundational Learning

- **Spurious Correlations in Machine Learning**: Models leverage non-causal features correlated with labels in training data but not predictive at test time. Quick check: Can you explain why a model might achieve high accuracy on a validation set but fail on a specific subgroup (e.g., landbirds on water backgrounds)?

- **Contrastive Learning Objectives**: The LD loss is contrastive-style—it pulls semantically similar pairs closer and pushes dissimilar pairs apart. Understanding InfoNCE-style losses helps grasp why this works. Quick check: In a contrastive loss, what happens if the margin parameter m is set too low or too high?

- **CLIP's Joint Embedding Space**: PRISM operates entirely within CLIP's shared embedding space, exploiting the alignment between ϕI and ϕT. Understanding how CLIP trains (image-text contrastive learning) clarifies why cross-modal transfer is plausible. Quick check: Why does CLIP use inner product ⟨ϕI(x), ϕT(t)⟩ for zero-shot classification rather than a separate classifier head?

## Architecture Onboarding

- **Component map**: LLM prompt → spurious attributes A → scene descriptions Ta,y (Stage 1) → CLIP frozen → text encoder ϕT(Ta,y) → learnable projection P → LD loss → SGD on P only (Stage 2) → Input image → ϕI(x) → P(ϕI(x)) → cosine similarity with P(ϕT(tk)) → argmax (Stage 3)

- **Critical path**: The projection matrix P is the only learned component. Its dimension is d×d (e.g., 768×768 for ViT-L/14). Correct initialization and learning rate (0.1 for Waterbirds, 0.01 for CelebA) matter.

- **Design tradeoffs**: PRISM vs. PRISM-mini: Full PRISM uses learned projection via LD loss (better WG, requires optimization); PRISM-mini uses orthogonal projection P = I − A(AᵀA)⁻¹Aᵀ (no optimization, slightly worse WG, faster). Margin m controls how aggressively different classes with same spurious attribute are separated. Number of scene descriptions affects debiasing signal strength.

- **Failure signatures**: WG accuracy improves but overall accuracy drops sharply → LD loss over-penalizes semantic content; check margin m or description count. No improvement over zero-shot → LLM-generated attributes don't match actual spurious correlations; inspect generated descriptions manually. PRISM-mini outperforms PRISM → optimization may be stuck; reduce learning rate or check gradient flow.

- **First 3 experiments**: 1. Reproduce Waterbirds results with PRISM-mini first (no optimization): verify that orthogonal projection improves WG from ~36% baseline toward ~69% reported. 2. Ablate number of scene descriptions (e.g., 5, 10, 20, 40) on a held-out subset: plot WG vs. count to find optimal range. 3. Visualize embedding space before/after projection using t-SNE: confirm clusters separate by class rather than spurious attribute.

## Open Questions the Paper Calls Out
None

## Limitations
- The assumption that LLM-generated spurious attributes reflect actual biases in VLM training data remains empirically validated only on Waterbirds and CelebA.
- The paper reports improved worst-group accuracy but provides no analysis of how PRISM affects fairness metrics beyond group robustness.
- Linear projection assumption may fail for complex, non-linear spurious correlations.

## Confidence
- Worst-group accuracy improvements: High
- Cross-modal debiasing mechanism: Medium
- LLM-generated attributes capturing true spurious correlations: Medium

## Next Checks
1. Test PRISM on datasets with different spurious correlation types (e.g., texture bias in ImageNet variants) to assess generalizability beyond background-object correlations
2. Evaluate fairness metrics beyond worst-group accuracy, including per-group false positive rates and overall demographic parity, to quantify broader fairness impact
3. Compare PRISM against state-of-the-art bias mitigation methods (e.g., ReBias, FAiR) on identical datasets with statistical significance testing to confirm relative performance advantage