---
ver: rpa2
title: 'Broken-Token: Filtering Obfuscated Prompts by Counting Characters-Per-Token'
arxiv_id: '2510.26847'
source_url: https://arxiv.org/abs/2510.26847
tags:
- prompt
- text
- prompts
- dataset
- obfuscated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CPT-Filtering, a model-agnostic, computationally
  negligible guardrail technique for detecting obfuscated jailbreak prompts by measuring
  characters-per-token (CPT) in Byte-Pair Encoded text. The core idea exploits the
  observation that out-of-distribution encodings use significantly more, shorter tokens
  than natural language, making them detectable via a simple CPT threshold.
---

# Broken-Token: Filtering Obfuscated Prompts by Counting Characters-Per-Token

## Quick Facts
- arXiv ID: 2510.26847
- Source URL: https://arxiv.org/abs/2510.26847
- Authors: Shaked Zychlinski; Yuval Kainan
- Reference count: 40
- One-line primary result: Near-perfect (>99.4% F1) detection of obfuscated jailbreak prompts using characters-per-token analysis

## Executive Summary
This paper introduces CPT-Filtering, a model-agnostic guardrail technique that detects obfuscated jailbreak prompts by measuring characters-per-token (CPT) in Byte-Pair Encoded text. The method exploits the observation that out-of-distribution encodings use significantly more, shorter tokens than natural language, making them detectable via a simple CPT threshold. Evaluated on 120,000 prompts across five encoding schemes and four popular tokenizers, CPT-Filtering achieved near-perfect accuracy even for short prompts (~3 tokens). The approach is computationally negligible, reusing the mandatory tokenization step required for LLM inference.

## Method Summary
CPT-Filtering calculates the average characters-per-token ratio by dividing the character length of input text by the number of tokens produced by a BPE tokenizer. The method assumes that obfuscated text, being out-of-distribution for tokenizers trained on natural language, will be tokenized into more, shorter tokens, resulting in a lower CPT score. A fixed threshold (specific to each tokenizer) is used to classify inputs as obfuscated when CPT falls below the threshold. The paper also proposes a sliding window approach to detect mixed inputs containing obfuscated segments embedded within benign text.

## Key Results
- Achieved >99.4% F1-score across five encoding schemes (Base64, Binary, Caesar Cipher, Leetspeak, Reversed Text) and four tokenizers
- Effective even for very short prompts (~3 tokens), enabling sliding window detection of mixed inputs
- Outperformed perplexity-based methods in both detection accuracy and computational cost
- Distinguishes obfuscated text from non-alphanumeric languages using monolingual tokenizers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CPT-Filtering detects obfuscated prompts by measuring average Characters Per Token (CPT), which drops sharply for out-of-distribution text.
- Mechanism: BPE tokenizers are trained on natural language corpora, learning to represent frequent character sequences as single, longer tokens. When they encounter out-of-distribution text like ciphers, they lack these pre-learned subwords and must construct the input from a larger number of shorter tokens. This results in a significantly lower average CPT for obfuscated text compared to natural language.
- Core assumption: The statistical distribution of character sequences in obfuscated/ciphered text is sufficiently different from the tokenizer's training corpus to force inefficient tokenization.
- Evidence anchors:
  - [abstract] "...leveraging the intrinsic behavior of Byte-Pair Encoding (BPE) tokenizers. Our method is based on the principle that tokenizers, trained on natural language, represent out-of-distribution text, such as ciphers, using a significantly higher number of shorter tokens."
  - [section 3.6] "...obfuscation attacks might contain a mixed input - meaning, normal 'safe' text with obfuscated part in it. Mixed texts will obviously have higher CPT then obfuscated texts."
  - [corpus] Weak/Missing. Corpus papers discuss tokenization efficiency and attacks but do not directly validate the CPT distribution shift for obfuscation.

### Mechanism 2
- Claim: CPT-Filtering is computationally negligible because it reuses a mandatory preprocessing step.
- Mechanism: All LLM inference requires tokenizing the input text into a sequence of token IDs. CPT-Filtering simply calculates `len(text) / len(tokens)` using the output of this existing step, avoiding the need for a separate forward pass through a classifier or perplexity model.
- Core assumption: The computational cost of integer division and list length counting is negligible compared to the neural network operations of the LLM or a guardrail model.
- Evidence anchors:
  - [abstract] "CPT-Filtering, a novel, model-agnostic with negligible-costs and near-perfect accuracy guardrail technique..."
  - [section 1.4] "...leveraging the fact that one always tokenizes the input text before passing the tokens to the LLMs."
  - [corpus] Weak/Missing. No direct corpus comparison of computational costs.

### Mechanism 3
- Claim: A sliding window approach can detect obfuscated text embedded within a larger benign prompt.
- Mechanism: By calculating CPT over a small, moving window of tokens (e.g., size 5), the method can identify localized regions of low CPT indicative of obfuscation, even if the global average CPT is diluted by surrounding natural language.
- Core assumption: The obfuscated portion of the prompt is at least as long as the minimum effective window size required to establish a statistically distinct CPT signature.
- Evidence anchors:
  - [section 3.6] "...CPT Filtering is effective even for very short inputs, thus allowing the use of sliding-windows to identify mixed inputs... enabling us to detect obfuscated parts of at least ~3 tokens."
  - [Figure 6] "An example of applying sliding window CPT filtering...where the obfuscated text is mixed within the benign text."
  - [corpus] Weak/Missing. No corpus papers discuss this specific application of tokenization statistics for mixed inputs.

## Foundational Learning

- Concept: Byte-Pair Encoding (BPE) Tokenization
  - Why needed here: CPT-Filtering relies on understanding how BPE tokenizers build vocabulary from frequent pairs. This explains why they fail to efficiently compress rare/out-of-distribution character sequences.
  - Quick check question: Given a tokenizer trained on English text, how would it tokenize the string "xyzzy" compared to "apple"?

- Concept: Out-of-Distribution (OOD) Detection
  - Why needed here: The paper frames obfuscation detection as an OOD problem. Understanding OOD detection principles clarifies why simple statistical metrics like CPT are effective.
  - Quick check question: Why is a low CPT score an indicator of OOD text for a natural language tokenizer?

- Concept: Trade-offs in Defense-in-Depth
  - Why needed here: The paper positions CPT-Filtering as a lightweight, first line of defense. Understanding this context is crucial for knowing where to place it in a broader security architecture.
  - Quick check question: What is the primary computational advantage of CPT-Filtering over an LLM-based guardrail classifier?

## Architecture Onboarding

- Component map: Input Text -> Tokenizer -> CPT Calculator -> Threshold Comparator -> Action Module
- Critical path: The detection logic must execute after tokenization but before the token IDs are passed to the main LLM model for inference.
- Design tradeoffs:
  - **Speed vs. Granularity:** A single global CPT check is fastest but may miss short embedded payloads. The sliding window method is more thorough but adds a small computational overhead proportional to window size and prompt length.
  - **False Positives vs. Security:** Setting a higher CPT threshold catches more obfuscation but increases the risk of blocking legitimate, concise, or code-heavy prompts.
- Failure signatures:
  - **Bypass:** An attacker crafts an encoding that produces character sequences common in the tokenizer's vocabulary, maintaining a high CPT.
  - **False Positive:** Legitimate use of code, technical identifiers (e.g., product SKUs), or highly abbreviated text triggers a low CPT and is blocked.
  - **Multilingual Confusion:** Non-alphanumeric languages (e.g., Chinese, Arabic) naturally have different CPT characteristics, which can confuse a filter calibrated on English text unless the secondary GPT-2 tokenizer check is implemented.
- First 3 experiments:
  1. **Baseline Calibration:** Using the provided dataset, run the target tokenizer on both the original and obfuscated prompts. Plot the CPT distributions and use a precision-recall curve to identify the optimal threshold that maximizes F1 score.
  2. **Short-Input Validation:** Test the filter on progressively shorter obfuscated prompts (e.g., 10, 5, 3 tokens) to empirically determine the minimum effective length for reliable detection.
  3. **Sliding Window Implementation:** Implement a sliding window CPT filter (e.g., size 5). Create mixed prompts containing a short benign prefix, an obfuscated payload, and a benign suffix. Test if the filter successfully flags the region containing the payload.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How robust is the sliding window approach against mixed inputs containing short obfuscated payloads embedded within benign text?
- Basis in paper: [inferred] The authors propose a sliding window method for mixed inputs but provide only a single visual example without quantitative metrics.
- Why unresolved: The paper demonstrates near-perfect scores on fully obfuscated prompts but does not statistically validate the efficacy of detecting partial obfuscation in longer contexts.
- What evidence would resolve it: Quantitative evaluation (Accuracy/F1) on a dataset specifically constructed with mixed benign and obfuscated segments.

### Open Question 2
- Question: Can adversaries craft obfuscation techniques specifically optimized to maintain a high characters-per-token ratio to bypass the CPT-Filter?
- Basis in paper: [inferred] The method relies on the assumption that obfuscated text is out-of-distribution and thus tokenized inefficiently (low CPT).
- Why unresolved: The paper does not explore adaptive attacks where the malicious payload is optimized to tokenize into longer sub-words, mimicking the CPT distribution of natural language.
- What evidence would resolve it: Performance analysis against adversarial encodings explicitly designed to maximize the CPT score while preserving semantic harmfulness.

### Open Question 3
- Question: How effective is CPT-Filtering against obfuscation in non-alphanumeric languages, such as Chinese or Arabic?
- Basis in paper: [explicit] The authors state they "refrain from discussing non-alphanumeric obfuscated prompts (i.e. reversed Chinese texts or Arabic Caesar Cipher) due to the lack of concrete evidence."
- Why unresolved: The primary detection mechanism relies on low CPT values for non-standard text, but the paper notes a "sharp drop" in distinguishing ability for non-alphanumeric languages without offering a solution for obfuscated versions of those languages.
- What evidence would resolve it: Evaluation of CPT scores and detection accuracy on datasets containing obfuscated non-alphanumeric text.

## Limitations

- The evaluation relies on synthetically generated obfuscated prompts rather than real-world attack patterns, raising concerns about ecological validity
- The paper does not systematically evaluate false positive rates on legitimate inputs that might trigger low CPT scores (e.g., code, technical identifiers, abbreviated text)
- Threshold optimization methodology is not fully specified, raising concerns about potential overfitting to the reported statistics

## Confidence

**High Confidence Claims:**
- CPT distributions for natural language vs. obfuscated text are statistically distinct across all tested tokenizers and encoding schemes
- The sliding window approach can detect localized obfuscation within mixed prompts

**Medium Confidence Claims:**
- CPT-Filtering achieves near-perfect accuracy on the constructed dataset
- The method is computationally negligible compared to full LLM inference

**Low Confidence Claims:**
- CPT-Filtering will generalize to real-world attack patterns beyond the five deterministic encodings tested
- The fixed thresholds optimized on the paper's dataset will perform well on live traffic without recalibration

## Next Checks

1. **External Dataset Validation**: Test CPT-Filtering on a held-out dataset of real-world jailbreak attempts collected from production LLM deployments, rather than the synthetically generated prompts used in the paper.

2. **False Positive Analysis**: Conduct a systematic evaluation of false positive rates using a corpus of legitimate technical documentation, code repositories, and abbreviated communication. Measure the false positive rate at the optimal thresholds reported in Table 3.

3. **Adversarial Robustness Testing**: Design and test targeted evasion attacks specifically crafted to maintain high CPT scores while achieving obfuscation goals, such as generating inputs that use character sequences matching high-frequency subwords in the tokenizer's vocabulary.