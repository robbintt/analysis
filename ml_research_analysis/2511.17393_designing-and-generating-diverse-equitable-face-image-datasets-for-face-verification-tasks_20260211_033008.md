---
ver: rpa2
title: Designing and Generating Diverse, Equitable Face Image Datasets for Face Verification
  Tasks
arxiv_id: '2511.17393'
source_url: https://arxiv.org/abs/2511.17393
tags:
- face
- image
- images
- verification
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of bias in existing face verification
  datasets, which often suffer from demographic imbalances in race, gender, and other
  attributes. To overcome these limitations, the authors propose a methodology that
  combines advanced generative models to create a diverse and inclusive synthetic
  face image dataset suitable for face verification tasks.
---

# Designing and Generating Diverse, Equitable Face Image Datasets for Face Verification Tasks

## Quick Facts
- arXiv ID: 2511.17393
- Source URL: https://arxiv.org/abs/2511.17393
- Reference count: 27
- Key outcome: Addresses bias in face verification datasets by generating a diverse synthetic dataset (DIF-V) and revealing significant performance disparities across demographic groups

## Executive Summary
This paper tackles the critical issue of bias in existing face verification datasets by proposing a novel methodology to generate a diverse and inclusive synthetic face image dataset. The authors combine advanced text-to-image diffusion models with identity-preserving image variations and style transfer techniques to create the DIF-V dataset, which contains 27,780 images of 926 unique identities across various demographic groups. The dataset is specifically designed to serve as a benchmark for evaluating face verification systems' fairness and robustness. Experimental results using state-of-the-art models (ArcFace and FaceNet) reveal substantial performance disparities across demographic groups, particularly for female and East/Southeast Asian faces, highlighting the importance of inclusive benchmarking.

## Method Summary
The methodology combines four text-to-image diffusion models (Stable Diffusion 3.5, CosmicMan, Kandinsky, FLUX.1) to generate synthetic face images with controlled demographic attributes. These images are then processed through an identity-preserving variation pipeline using Arc2Face and PuLID to create multiple images per identity. The dataset undergoes background removal via HivisionIDPhotos and style transfer using PAMA with 23 national ID card templates to simulate real-world verification conditions. The final DIF-V dataset contains 27,780 images of 926 unique identities, designed to evaluate face verification performance across demographic groups while addressing the limitations of existing biased datasets.

## Key Results
- DIF-V dataset contains 27,780 images of 926 unique identities across 8 race categories, 8 gender options, and other physical attributes
- Face verification models show significant performance disparities: ArcFace achieves 92.69% accuracy on White faces but only 77.72% on East/Southeast Asian faces
- Style transfer to ID card templates degrades verification performance from 94.67% to 91.61% for ArcFace, indicating increased domain shift challenges
- Both ArcFace and FaceNet exhibit lower performance on female faces compared to male faces

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-model text-to-image generation with curated attribute prompts produces demographically balanced synthetic faces that real-world datasets lack.
- Mechanism: Four diffusion models generate initial identities from structured prompts encoding race, gender, and physical traits with compatibility constraints. Universal prompt terms improve realism.
- Core assumption: Prompt adherence across multiple models sufficiently covers natural facial variation without systematic omissions.
- Evidence anchors:
  - [abstract]: "methodology that combines advanced generative models to create a diverse and inclusive synthetic face image dataset"
  - [section 3.1]: Table 1 lists attribute options; Table 2 shows model-specific inference steps and CFG weights
  - [corpus]: Related work on bias mitigation in FR templates supports the need for demographic disentanglement
- Break condition: If prompt adherence fails for underrepresented features (e.g., albinism, Down syndrome), demographic coverage will have gaps.

### Mechanism 2
- Claim: Identity-preserving image variations via face embedding conditioning enable multi-image verification benchmarks from single synthesized identities.
- Mechanism: Arc2Face generates variations from face embeddings extracted via ArcFace; PuLID further diversifies each identity, yielding ~30 variations per identity.
- Core assumption: Face embeddings capture sufficient identity information to generate consistent variations across demographic attributes.
- Evidence anchors:
  - [section 3.2]: "Arc2Face images as input to PuLID tool... modified images per identity are 30"
  - [abstract]: "926 unique identities" with "27,780 images"
  - [corpus]: Weak—limited corpus evidence on chained embedding-based generation pipelines
- Break condition: If embedding space lacks disentanglement between identity and demographic attributes, attribute drift corrupts ground-truth labels.

### Mechanism 3
- Claim: Style transfer from real ID card templates increases verification difficulty, exposing model fragility to domain shifts.
- Mechanism: PAMA applies style from 23 national ID card face images to synthetic faces after background removal, introducing realistic artifacts.
- Core assumption: Style-transferred synthetic images approximate real ID card image distributions well enough to serve as proxies for domain-shift evaluation.
- Evidence anchors:
  - [section 3.2]: Figure 3 shows style extraction pipeline; "23 different nations' identity card image templates"
  - [section 4, Table 5]: Accuracy drops from 94.67% to 91.61% (ArcFace) after ID style application
  - [corpus]: No direct corpus validation of this specific style-transfer-for-verification mechanism
- Break condition: If style artifacts are inconsistent with real ID card imaging pipelines, benchmark validity for real-world deployment is compromised.

## Foundational Learning

- Concept: **Diffusion model denoising process**
  - Why needed here: Understanding inference steps and CFG weight selection is critical for controlling quality vs. prompt adherence tradeoffs across the four T2I models.
  - Quick check question: How does increasing classifier-free guidance scale affect prompt adherence vs. image diversity?

- Concept: **Face recognition embeddings and cosine similarity**
  - Why needed here: ArcFace/FaceNet produce embeddings used both for verification evaluation and as conditioning inputs to Arc2Face for identity-preserving generation.
  - Quick check question: What does a low cosine similarity between same-identity images indicate about the verification challenge?

- Concept: **Bias metrics in verification (TAR@FAR, EER)**
  - Why needed here: The paper reports demographic stratification using these metrics; interpreting Tables 3-4 requires understanding their meaning.
  - Quick check question: Why might TAR at 1% FAR show larger demographic gaps than overall accuracy?

## Architecture Onboarding

- Component map:
  - **Prompt engineering layer**: Attribute tables → structured prompts with universal terms
  - **Generation layer**: Four diffusion models with model-specific hyperparameters (i, CFG)
  - **Identity variation layer**: Arc2Face → PuLID chain (embedding-conditioned)
  - **Post-processing layer**: HivisionIDPhotos (background) → PAMA (style transfer)
  - **Evaluation layer**: DeepFace framework with MTCNN + ArcFace/FaceNet

- Critical path: Prompt construction → T2I generation → Quality filtering → Identity variation (Arc2Face/PuLID) → Style transfer → Demographic-stratified pair creation → Verification metrics

- Design tradeoffs:
  - More inference steps improve quality but increase compute cost (~20 regeneration attempts per image reported)
  - Higher CFG weight increases prompt control but may reduce diversity
  - Fidelity mode in PuLID prioritizes identity preservation over extreme style variation

- Failure signatures:
  - Multi-face outputs instead of single portrait (requires manual filtering)
  - Attribute drift across variations (e.g., gender flip between Arc2Face and PuLID outputs)
  - Race/gender performance gaps (East Asian: 77.72% ArcFace vs. White: 92.69% ArcFace)

- First 3 experiments:
  1. Replicate single-identity variation pipeline: Generate one base image, run through Arc2Face→PuLID→PAMA, verify 30 variations maintain identity via cosine similarity check.
  2. Demographic stratification test: Sample 50 identities per race, compute TAR@1%FAR with ArcFace, compare against Table 4 benchmarks.
  3. Style transfer ablation: Measure verification accuracy before/after PAMA on a held-out subset to quantify domain-shift impact.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent does training on synthetic datasets like DIF-V mitigate versus amplify the inherent biases found in the generative models' original training data?
- Basis in paper: [explicit] Page 17 states that generative models trained on massive unfiltered data "might suffer from, or even amplify, data biases," posing an ethical risk.
- Why unresolved: The paper evaluates verification models *on* the synthetic dataset but does not provide evidence that training on DIF-V improves fairness or accuracy on real-world diverse data.
- What evidence would resolve it: A comparative study measuring bias metrics (e.g., skew in False Positive Rates) of models trained on DIF-V versus real-world datasets when evaluated on external, diverse real-world benchmarks.

### Open Question 2
- Question: Can face verification models be made robust to the identity style transformations that currently degrade performance in this study?
- Basis in paper: [inferred] Page 16 demonstrates that applying identity style transformations (using PAMA) "degrades the performance of both the ArcFace and Facenet verification models," suggesting a specific vulnerability.
- Why unresolved: The results indicate a domain gap between generated images and their stylized counterparts that current verification architectures fail to bridge.
- What evidence would resolve it: Fine-tuning verification models on stylized synthetic images and observing a recovery of TAR (True Acceptance Rate) and Accuracy to levels comparable with non-stylified images.

### Open Question 3
- Question: How can text-to-image generation models achieve consistent adherence to prompts for rare facial attributes without requiring extensive manual filtering or repeated sampling?
- Basis in paper: [explicit] Page 5 notes that "adherence to input prompts, especially for less common features, remains a key challenge," and Page 12 mentions the need to repeat generation "numerous times."
- Why unresolved: The methodology relies on trial-and-error and manual verification to handle less common features, rather than inherent model reliability.
- What evidence would resolve it: Automated generation of rare attributes (e.g., specific scars or conditions) that yield high alignment scores with text prompts in a single inference pass.

## Limitations
- Prompt adherence across T2I models remains uncertain for underrepresented facial features like albinism or Down syndrome
- Chained embedding-based generation pipeline using Arc2Face and PuLID lacks sufficient corpus validation
- Style transfer mechanism using PAMA has not been directly validated against real ID card image distributions

## Confidence
- **High Confidence**: The methodology's approach to combining multiple T2I models for demographic diversity and the documented performance disparities across demographic groups
- **Medium Confidence**: The identity-preserving variation generation using face embeddings, and the effectiveness of style transfer in increasing verification difficulty
- **Low Confidence**: The systematic coverage of all natural facial variations through prompt engineering, and the direct applicability of synthetic ID-style images as proxies for real-world deployment scenarios

## Next Checks
1. **Identity Consistency Validation**: Generate a single identity through the complete pipeline (T2I → Arc2Face → PuLID → PAMA) and compute cosine similarity across all 30 variations to verify identity preservation. Flag any variations with similarity below 0.4.

2. **Demographic Performance Gap Analysis**: Sample 50 identities per race category and compute TAR@1%FAR with ArcFace. Compare results against Table 4 benchmarks to validate the magnitude of demographic performance disparities.

3. **Style Transfer Impact Quantification**: Measure verification accuracy before and after PAMA style transfer on a held-out subset of images. Calculate the exact performance degradation to quantify the domain-shift impact on model robustness.