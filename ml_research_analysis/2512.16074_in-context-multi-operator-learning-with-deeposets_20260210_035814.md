---
ver: rpa2
title: In-Context Multi-Operator Learning with DeepOSets
arxiv_id: '2512.16074'
source_url: https://arxiv.org/abs/2512.16074
tags:
- learning
- in-context
- deeposets
- operator
- operators
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a precise mathematical formulation of the in-context
  multi-operator learning problem and proves that a variant of the DeepOSets architecture
  is universally approximative for this problem. DeepOSets combines set learning via
  DeepSets with operator learning via DeepONets to create a non-autoregressive, non-attention-based
  architecture for learning multiple differential equation solution operators simultaneously.
---

# In-Context Multi-Operator Learning with DeepOSets

## Quick Facts
- arXiv ID: 2512.16074
- Source URL: https://arxiv.org/abs/2512.16074
- Reference count: 24
- Key outcome: DeepOSets combines DeepSets and DeepONet to learn multiple differential equation solution operators simultaneously from in-context examples without attention or weight updates, achieving accurate predictions across 12 PDE tasks with training times of minutes versus hours for transformer-based alternatives.

## Executive Summary
This paper introduces DeepOSets, a novel architecture for in-context multi-operator learning that combines set learning via DeepSets with operator learning via DeepONets. The model learns to identify and apply solution operators for different PDEs from context examples without attention mechanisms or weight updates. DeepOSets takes parameter-solution pairs as input, encodes them into a permutation-invariant latent representation, and conditions a DeepONet decoder to predict solutions for new parameter functions. The architecture demonstrates strong performance across 12 differential equation tasks (forward and inverse initial/boundary value problems) with training times of only minutes compared to hours for transformer-based alternatives.

## Method Summary
DeepOSets consists of a shared MLP encoder Φ that maps each (parameter, solution) pair to a fixed-length embedding, followed by mean pooling to create a permutation-invariant latent vector h. This latent, concatenated with the query parameter u_q(x), serves as input to the branch network ρ of a DeepONet, while the trunk network Ψ maps query coordinates x_q to basis functions. The final prediction is the dot product Ψ(x_q)·ρ[u_q(x), h]. The architecture is trained on batches of 100 operators for 50k iterations using Adam optimizer with learning rate 1e-3. Experiments use 100 parameter functions per task sampled from Gaussian processes, discretized on 100-point grids, with MSE as the evaluation metric.

## Key Results
- DeepOSets achieves accurate predictions across 12 different differential equation tasks (forward and inverse initial/boundary value problems)
- Training times of only minutes (12-38 minutes on RTX 4060 Ti 16GB) compared to hours for transformer-based alternatives
- The model shows robust generalization to context sizes larger than those seen during training, with MSE decreasing as more in-context examples are provided
- Experiments demonstrate that the permutation-invariant, non-autoregressive design is sufficient for accurate operator identification without attention mechanisms

## Why This Works (Mechanism)

### Mechanism 1: Permutation-Invariant Set Encoding
Encoding prompt examples as a permutation-invariant set enables in-context operator identification without attention. A shared MLP Φ maps each (parameter, solution) pair to a fixed-length embedding, aggregated via mean pooling into a single latent vector h. This ensures the model's representation of the prompt does not depend on example ordering.

### Mechanism 2: Latent-Conditioned Operator Factorization
Concatenating the prompt-derived latent vector with the query parameter enables the DeepONet branch network to modulate its output based on the in-context operator. The branch network ρ takes [u_q(x); h] and outputs coefficients, while the trunk network Ψ maps coordinates to basis functions, with their dot product yielding the solution prediction.

### Mechanism 3: Uniform Approximation via Compactness and Discretization Balance
For any compact class of continuous operators, a single DeepOSets network exists that uniformly approximates all operators in the class to arbitrary accuracy. The proof leverages compactness to reduce approximation to finite-dimensional grids, partition of unity to localize approximation, and the (δ, C)-discretization condition to ensure prompt examples provide stable, well-distributed coverage.

## Foundational Learning

- **Concept: Operator Learning (DeepONet)** - Why needed: DeepOSets inherits the branch-trunk factorization from DeepONet; understanding how neural networks approximate mappings between function spaces is prerequisite. Quick check: Can you explain why operator learning differs from standard supervised learning on fixed-dimensional inputs?

- **Concept: Set Learning (DeepSets)** - Why needed: The prompt encoder relies on DeepSets' permutation-invariant aggregation; understanding how pooling over set elements produces order-invariant representations is essential. Quick check: Why does mean pooling guarantee permutation invariance, and what are its limitations?

- **Concept: Universal Approximation Theorems** - Why needed: The paper's primary theoretical contribution is a universality proof; familiarity with classic MLP approximation results and operator approximation is assumed. Quick check: What does "universal approximation" mean for operators, and how does it differ from finite-dimensional universal approximation?

## Architecture Onboarding

- **Component map:**
```
Prompt Examples [(u₁,G(u₁)), ..., (uₘ,G(uₘ))]
           ↓
    Shared MLP Φ (per example) → embeddings hᵢ ∈ ℝᴺ
           ↓
    Pooling (mean) → h ∈ ℝᴺ
           ↓
    Concatenate with query u_q(x) → [u_q(x); h] ∈ ℝᵏ⁺ᴺ
           ↓                           ↓
    Branch Network ρ              Trunk Network Ψ
           ↓                           ↓
    Coefficients β ∈ ℝᴹ    ←dot→    Basis functions ψ(x_q) ∈ ℝᴹ
                       ↓
              Prediction Ĝ(u_q)(x_q)
```

- **Critical path:** The pooling operation is the convergence point for all prompt information. If Φ fails to produce discriminative embeddings, or if pooling collapses distinct operators to similar latents, downstream prediction cannot recover.

- **Design tradeoffs:**
  - Mean pooling vs. attention: Mean is O(m) linear complexity but discards inter-example relationships; attention is O(m²) but can model pairwise structure
  - Fixed vs. variable grids: Paper uses fixed discretization; variable grids would add flexibility but complicate the universality proof
  - Latent dimension N: Too small may collapse distinct operators; too large increases training cost without guaranteed benefit

- **Failure signatures:**
  - High variance in predictions across prompt permutations despite mean pooling: suggests Φ is not shared correctly or pooling is misconfigured
  - Error does not decrease with more prompt examples: suggests latent h is not incorporating prompt information; check gradient flow through pooling
  - Training loss plateaus but test error grows with context size: suggests overfitting to training context sizes; verify (δ, C)-discretization assumptions

- **First 3 experiments:**
  1. Ablate pooling operation: Compare mean, max, and attention-based pooling on the 6-task benchmark; expect mean to match paper results, attention to increase cost without accuracy gain
  2. Vary prompt example density: Test with m=2, 4, 8, 16 examples at inference on held-out operators; should observe decreasing MSE as m increases
  3. Test compactness violation: Construct an operator class that is non-compact (e.g., unbounded coefficient ranges); expect either training divergence or failure to generalize to unseen operators in the class

## Open Questions the Paper Calls Out

### Open Question 1
Can the DeepOSets architecture be extended to handle variable input and output discretization grids without fixed sensor locations? While the formulation considers fixed grids, one could additionally consider variable grids in K1 and K2, but this is left to future work. Modifying the DeepSets encoder to accept coordinate-value pairs and demonstrating successful operator recovery on unstructured or varying grids would resolve this.

### Open Question 2
Does the efficiency and accuracy of DeepOSets scale effectively to higher-dimensional spatial domains (2D/3D) and complex geometries? While the theoretical framework applies to R^d, all experimental benchmarks are restricted to 1D domains. Successful application to benchmark 2D/3D problems, such as Darcy flow or Navier-Stokes equations on complex meshes, would resolve this.

### Open Question 3
Does the permutation-invariant, non-autoregressive design hinder performance on complex time-dependent PDEs where temporal causality is critical? The paper promotes non-autoregressive processing as more efficient than transformers but validates this only on simple ODEs and static BVPs. A comparative evaluation against autoregressive baselines on challenging time-series PDE benchmarks would test if the lack of sequential inductive bias degrades accuracy.

## Limitations

- Universal approximation proof relies on (δ, C)-discretization condition: The theoretical guarantee assumes prompt examples form a δ-net of the input space with bounded imbalance, which may not hold in practice when examples are sparse or clustered.

- Architecture generalization to non-compact operator classes: The theory restricts to compact sets of continuous operators, while real-world PDE families often include unbounded parameters that fall outside theoretical coverage.

- Empirical validation limited to fixed discretization: All experiments use 100-point uniform grids, and the universality proof's robustness to adaptive or non-uniform discretizations is not tested.

## Confidence

- **High confidence**: Architecture design and experimental results on the 12 PDE tasks are well-documented and reproducible given the provided specifications.

- **Medium confidence**: The theoretical universal approximation proof is mathematically sound within its stated assumptions, but practical relevance depends on whether real-world prompts satisfy the (δ, C)-discretization condition.

- **Low confidence**: Claims about the model's behavior on operator classes beyond the tested PDEs, or with prompt distributions violating the theoretical assumptions, are speculative without additional empirical validation.

## Next Checks

1. Test (δ, C)-discretization robustness: Systematically vary the distribution of prompt examples (e.g., cluster vs. uniform sampling) and measure the impact on approximation error. Compare against theoretical predictions to validate the practical relevance of the discretization condition.

2. Evaluate on non-compact operator classes: Construct a test suite with unbounded parameters (e.g., diffusion coefficients in [0, ∞)) and assess whether DeepOSets maintains accuracy or if performance degrades as predicted by the theory.

3. Benchmark against attention-based in-context learning: Implement a transformer-based multi-operator ICL baseline and compare both accuracy and computational cost across the 12 tasks. This would validate the paper's claim that permutation-invariant encoding without attention is sufficient for the problem class.