---
ver: rpa2
title: 'CroPS: Improving Dense Retrieval with Cross-Perspective Positive Samples in
  Short-Video Search'
arxiv_id: '2511.15443'
source_url: https://arxiv.org/abs/2511.15443
tags:
- retrieval
- search
- crops
- user
- positive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CroPS introduces cross-perspective positive samples from query
  reformulation, recommendation system, and world knowledge via LLMs to break the
  filter bubble effect in dense retrieval. It employs hierarchical label assignment
  with H-InfoNCE loss for fine-grained supervision.
---

# CroPS: Improving Dense Retrieval with Cross-Perspective Positive Samples in Short-Video Search

## Quick Facts
- arXiv ID: 2511.15443
- Source URL: https://arxiv.org/abs/2511.15443
- Reference count: 40
- Key outcome: CroPS achieves 69.1% Recall@100 on click-through data and 40.1% on reformulated-query data, outperforming strong baselines by 9.3% and 7.1% respectively, with +0.869% CTR and -0.646% query reformulation rate in online A/B tests.

## Executive Summary
CroPS addresses the filter bubble effect in dense retrieval by introducing cross-perspective positive samples from query reformulation, recommendation systems, and LLM world knowledge. The method employs hierarchical label assignment (0-5) and H-InfoNCE loss for fine-grained contrastive learning. Offline experiments show substantial improvements in recall metrics, while online A/B tests demonstrate meaningful gains in user engagement. The approach is fully deployed at Kuaishou Search serving hundreds of millions of users daily.

## Method Summary
CroPS enhances dense retrieval training by enriching positive samples from three sources: user query reformulation behavior (query-level), recommendation engagement data (system-level), and LLM-synthesized video metadata (knowledge-level). A 6-layer Transformer discriminator filters these positives using threshold α=0.6. Hierarchical Label Assignment assigns discrete labels (0-5) reflecting sample origin and reliability. H-InfoNCE loss enables efficient hierarchical contrastive learning by masking non-comparable samples in a single forward pass. The method uses Qwen2.5-0.5B dual-encoders with 128-token max length, trained on a proprietary CPSQA dataset of 500M samples.

## Key Results
- Offline: 69.1% Recall@100 on click-through data (9.3% improvement over baselines)
- Offline: 40.1% Recall@100 on reformulated-query data (7.1% improvement over baselines)
- Online: +0.869% CTR, +0.483% long-play rate, -0.646% query reformulation rate in A/B tests

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Enriching positive training samples from multiple perspectives mitigates filter bubble effects in dense retrieval.
- Mechanism: Conventional training only labels historically exposed content as positives, causing relevant but unseen content to be incorrectly labeled as negatives. By introducing positives from query reformulation sequences, recommendation engagement data, and LLM-synthesized metadata, the positive space expands beyond exposure-biased logs.
- Core assumption: Users' reformulated queries and cross-system engagements reflect continued intent related to the original query, and LLMs can generate semantically relevant pseudo-retrieval targets.
- Evidence anchors: [abstract] "CroPS enhances training with positive signals derived from user query reformulation behavior (query-level), engagement data in recommendation streams (system-level), and world knowledge synthesized by large language models (knowledge-level)."
- Break condition: If the lightweight semantic discriminator θ(·) used for filtering positives has poor calibration (threshold α = 0.6 inappropriate), noise may overwhelm signal.

### Mechanism 2
- Claim: Hierarchical Label Assignment enables fine-grained relevance learning by assigning discrete labels (0–5) reflecting sample origin and reliability.
- Mechanism: Instead of binary positive/negative labels, HLA grades samples: query-level augmented positives receive label 5 (highest, reflecting refined user intent); system-level and world-knowledge positives receive 4; clicked videos 4; exposed but unclicked 3; unexposed 2; filtered 1; in-batch negatives 0.
- Core assumption: Query-level reformulation signals are stronger relevance indicators than other positive sources, justifying their highest label.
- Evidence anchors: [section: Hierarchical Label Assignment] "Rather than assigning equal importance to all positive examples, HLA allocates discrete label levels ranging from 0 to 5 to reflect varying degrees of relevance."
- Break condition: If label assignments do not correlate with actual relevance, the hierarchy introduces optimization noise.

### Mechanism 3
- Claim: H-InfoNCE loss enables efficient hierarchical contrastive learning by masking non-comparable samples in a single forward pass.
- Mechanism: Standard InfoNCE treats all non-positives as negatives. H-InfoNCE only contrasts a positive with samples of strictly lower labels. For example, when d₂ (label 4) is the positive, d₁ (label 5) is masked (not negative).
- Core assumption: Multi-grade supervision is more informative than binary and does not introduce optimization conflicts across label tiers.
- Evidence anchors: [section: H-InfoNCE Optimization] "H-InfoNCE imposes a label-aware contrastive structure: for a given positive sample with label l, only samples with strictly lower labels (< l) are considered as negatives."
- Break condition: If the batch composition has insufficient label diversity, hierarchical contrasts become degenerate (no valid negatives for high-label positives).

## Foundational Learning

- Concept: **Filter Bubble / Information Cocoon in Retrieval**
  - Why needed here: CroPS explicitly targets the self-reinforcing training paradigm where historically exposed content defines positives, biasing models toward narrow retrieval.
  - Quick check question: In your current training pipeline, what percentage of positives come from content users have never been exposed to?

- Concept: **Dual-Encoder (Two-Tower) Retrieval Architecture**
  - Why needed here: CroPS is architecture-agnostic but deployed on dual-encoder models where query and document encoders produce embeddings for ANN retrieval.
  - Quick check question: Can you sketch the flow from raw query/document text → encoder → embedding → ANN index lookup?

- Concept: **Contrastive Learning with InfoNCE**
  - Why needed here: H-InfoNCE extends InfoNCE; understanding the baseline (pull positives closer, push negatives apart) is prerequisite.
  - Quick check question: Given query embedding q and document embeddings [d⁺, d₁⁻, d₂⁻], how does InfoNCE compute the loss?

## Architecture Onboarding

- Component map:
  1. **CroPS Data Engine**: Three modules (Query-Level Augmentation, System-Level Expansion, World Knowledge Enrichment) producing P₁, P₂, P₃ positive sets.
  2. **HLA Module**: Assigns labels 0–5 to all samples based on origin; outputs label vector L per batch.
  3. **H-InfoNCE Loss**: Computes hierarchical contrastive loss using mask matrix M derived from L.
  4. **Dual-Encoder Retrieval**: Qwen2.5-0.5B query/doc encoders (128-token max length).

- Critical path:
  1. Log extraction → Identify query reformulation sequences (90-second window, same user) → Apply discriminator θ → P₁.
  2. Extract recommendation feed interactions from users who issued query → Apply θ → P₂.
  3. LLM one-shot prompting (Qwen2.5-14B) → Generate synthetic video metadata → P₃.
  4. Merge P₀ ∪ P₁ ∪ P₂ ∪ P₃ → HLA label assignment → Batch sampling → H-InfoNCE training.

- Design tradeoffs:
  - **Threshold α = 0.6**: Higher values reduce noise but may exclude valid positives; lower values increase coverage but introduce noise.
  - **Label 5 for query-level positives**: Prioritizes reformulation signals but may overfit to users who reformulate frequently.
  - **LLM-generated positives (35M samples)**: High quality (95.8% relevant by manual eval) but synthetic; may not reflect actual platform content distribution.

- Failure signatures:
  - **CTR improves but RQR does not decrease**: Suggests positives enrich recall but not for reformulation-inducing queries.
  - **Training loss diverges**: Likely insufficient label diversity in batches; check H-InfoNCE mask matrix for all-masked rows.
  - **Recall@100 on QR plateaus below 40%**: May indicate discriminator θ has poor recall on reformulation-relevant videos.

- First 3 experiments:
  1. **Baseline comparison**: Train same dual-encoder with standard InfoNCE + click-only positives vs. CroPS; measure CT and QR Recall@100. Expected: CroPS should show >5% improvement on QR (paper shows 40.1% vs. 33.0% for FS-LR).
  2. **HLA ablation**: Replace hierarchical labels with binary (≥4 as positive, <4 as negative); measure degradation. Expected: ~8–9% drop in CT Recall@100 per Table 3.
  3. **Positive source ablation**: Incrementally add P₁, P₂, P₃ to P₀; measure marginal gains per source. Expected: Query-level provides largest single gain (+3.1% QR), per Table 3.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the CroPS framework be effectively adapted for generative retrieval models?
- Basis in paper: [explicit] The conclusion states, "Future work will integrate CroPS with generative retrieval methods."
- Why unresolved: CroPS is currently optimized for dense retrieval (dual-encoder) architectures using H-InfoNCE. Generative retrieval relies on different mechanisms (e.g., identifier generation) and loss functions, making the direct application of HLA and current positive sampling strategies non-trivial.
- What evidence would resolve it: A modified CroPS pipeline that successfully incorporates hierarchical positive signals into a generative index (e.g., differentiable search index) without causing semantic identifier conflicts or convergence issues.

### Open Question 2
- Question: How does the presence of "Irrelevant" LLM-generated positives (4.2%) impact the long-term robustness and convergence of the H-InfoNCE loss?
- Basis in paper: [inferred] Figure 6 reports that 4.2% of LLM-generated video metadata is manually rated as "Irrelevant," yet Table 1 assigns these samples a high label (4) during training.
- Why unresolved: While the aggregate performance is positive, the paper does not analyze the specific negative impact of this label noise. Treating irrelevant hallucinations as strong positives (Label 4) could theoretically introduce gradient conflicts in the H-InfoNCE optimization.
- What evidence would resolve it: An ablation study specifically filtering out the "Irrelevant" subset from the world knowledge enrichment module to isolate their effect on model convergence speed and retrieval accuracy.

### Open Question 3
- Question: Is the fixed semantic relevance threshold (α=0.6) optimal across diverse query intents, or does it require dynamic adjustment?
- Basis in paper: [inferred] The methodology section notes that the threshold α in Equations 1 and 2 is "empirically set to 0.6" for the lightweight discriminator θ.
- Why unresolved: A fixed threshold assumes uniform discriminability across all query types. However, for ambiguous or broad queries, a static threshold might be too restrictive, missing valuable positive signals, or too loose for navigational queries, admitting noise.
- What evidence would resolve it: Experiments comparing the static 0.6 threshold against a query-adaptive or difficulty-aware threshold mechanism in the CroPS data engine.

## Limitations
- The method relies on proprietary data and models (Qwen 2.5 encoders, CPSQA dataset), making exact replication difficult
- The 4.2% irrelevant LLM-generated positives assigned high labels may introduce noise into the hierarchical contrastive learning
- The 90-second window for query reformulation detection may not generalize across user behaviors or query types

## Confidence
- **High Confidence (80-100%)**: The core mechanism of using hierarchical labels (0-5) with H-InfoNCE loss to enable fine-grained contrastive learning is theoretically sound and empirically validated on the reported datasets.
- **Medium Confidence (50-80%)**: The filter bubble mitigation claim depends on the quality and diversity of the positive sources (P1, P2, P3). While manual evaluation shows 95.8% relevance for LLM-generated samples, the long-term impact on retrieval diversity and user satisfaction is not directly measured.
- **Low Confidence (0-50%)**: The scalability of the 6-layer discriminator θ(·) with threshold α=0.6 to other domains is uncertain. The specific architecture details and training procedure for θ are not disclosed.

## Next Checks
1. **Generalization Study**: Apply CroPS to a public short-video dataset (e.g., MSVD, YouCook2) using open-source encoders (e.g., MiniLM, DistilBERT). Measure whether hierarchical labels and H-InfoNCE consistently improve Recall@100 over InfoNCE with binary labels.

2. **Diversity Impact Assessment**: Track the novelty and diversity of retrieved videos before and after CroPS deployment. Use metrics like Intra-List Similarity (ILS) and aggregate unique videos shown per user session to directly test the filter bubble mitigation claim.

3. **Discriminator Robustness Test**: Vary the threshold α (e.g., 0.5, 0.7) and discriminator architecture (e.g., 3-layer, 12-layer Transformer) to assess sensitivity. Measure the trade-off between positive noise and coverage to identify operational boundaries.