---
ver: rpa2
title: 'CGES: Confidence-Guided Early Stopping for Efficient and Accurate Self-Consistency'
arxiv_id: '2511.02603'
source_url: https://arxiv.org/abs/2511.02603
tags:
- calls
- confidence
- cges
- wang
- zhang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Confidence-Guided Early Stopping (CGES),
  a Bayesian framework that incorporates confidence signals into self-consistency
  for more efficient and accurate test-time scaling. CGES builds posterior distributions
  over candidate answers using scalar confidence scores (derived from token probabilities
  or reward models) and adaptively halts sampling once the posterior mass of a candidate
  exceeds a threshold.
---

# CGES: Confidence-Guided Early Stopping for Efficient and Accurate Self-Consistency

## Quick Facts
- arXiv ID: 2511.02603
- Source URL: https://arxiv.org/abs/2511.02603
- Reference count: 21
- 69.4% reduction in LLM calls while maintaining accuracy within 0.06 percentage points of self-consistency

## Executive Summary
CGES introduces a Bayesian framework that incorporates confidence signals into self-consistency for more efficient and accurate test-time scaling. The method builds posterior distributions over candidate answers using scalar confidence scores and adaptively halts sampling once the posterior mass of a candidate exceeds a threshold. Across five reasoning benchmarks, CGES achieves significant efficiency gains while maintaining near-baseline accuracy, offering flexible accuracy-efficiency trade-offs.

## Method Summary
CGES operates by maintaining posterior distributions over candidate answers, updated using confidence-weighted Bayesian aggregation. For each question, the method queries the LLM iteratively, extracting response-confidence pairs where confidence comes from token probabilities or reward models. The SCORE algorithm computes unnormalized scores for each candidate answer by multiplying confidence scores for samples voting for that answer and discounted scores for others. CGES maintains a set of unresolved questions and only queries those where the maximum posterior is below a threshold γ, adaptively stopping sampling per question. The framework provides theoretical guarantees under ideal and noisy confidence conditions.

## Key Results
- 69.4% reduction in average LLM calls (from 16.0 to 4.9) while maintaining accuracy within 0.06 percentage points of self-consistency
- Outperforms majority voting when correct answer is minority but highly confident
- Flexible accuracy-efficiency trade-offs via threshold parameter γ
- Superior performance compared to standard self-consistency and early-stopping baselines

## Why This Works (Mechanism)

### Mechanism 1
Bayesian posterior aggregation over candidate answers enables accurate inference even when correct answer is minority vote. Each response-confidence pair is treated as probabilistic evidence, with unnormalized scores computed by multiplying confidence values for matching answers and discounted values otherwise. Core assumption: confidence scores are informative and i.i.d. given true answer index.

### Mechanism 2
Adaptive early stopping based on posterior concentration reduces LLM calls by ~69% while maintaining accuracy. CGES maintains unresolved questions where max posterior < threshold γ, querying only these questions. Core assumption: drift condition µk > 0 holds, meaning confidence signals systematically favor correct answers.

### Mechanism 3
CGES recovers correct answers in minority-correct scenarios where majority voting fails by exploiting systematic differences in confidence between correct and incorrect responses. The log-likelihood ratio drift can be positive even when correct answer is minority, provided confidence scores are systematically lower for incorrect answers.

## Foundational Learning

- **Concept**: Bayesian inference and posterior updating
  - **Why needed here**: CGES computes posteriors P(I=i|Obs) using Bayes' rule. Understanding likelihood multiplication and normalization is essential for implementing SCORE algorithm.
  - **Quick check question**: Given three samples with confidences [0.8, 0.6, 0.9] all voting for answer A, and one sample with confidence 0.3 voting for answer B, which posterior is higher?

- **Concept**: Self-consistency and majority voting
  - **Why needed here**: CGES is explicitly designed as drop-in improvement over self-consistency. Understanding baseline (fixed budget, majority aggregation, failure modes) clarifies what CGES optimizes.
  - **Quick check question**: Why does standard self-consistency fail when correct answer appears in only 2 of 16 samples?

- **Concept**: Test-time scaling and compute budgeting
  - **Why needed here**: CGES operates in test-time scaling paradigm where additional inference-time computation improves performance. Understanding accuracy-efficiency trade-off helps set threshold γ appropriately.
  - **Quick check question**: If you have latency budget of 100ms per query and each LLM call takes 20ms, what is your maximum sampling budget?

## Architecture Onboarding

- **Component map**: Confidence Estimator -> SCORE Function -> CGES Loop -> Stopping Decision
- **Critical path**: 1) Initial LLM call for all N questions → extract (Rt, Ct) pairs, 2) SCORE computation → initial posteriors, 3) Filter D_rem = {n : max posterior < γ}, 4) While D_rem non-empty and budget B not reached: query LLM for D_rem only, update posteriors, refilter, 5) Return argmax_i posterior per question
- **Design tradeoffs**: Threshold γ (0.70-0.9999): Lower γ → fewer calls, risk of premature stopping. Higher γ → more calls, better accuracy guarantee. Confidence estimator choice: LNS[Arithmetic] is simplest and fastest. MARS adds semantic weighting overhead. Budget B: Upper bound on calls per question.
- **Failure signatures**: Accuracy drops despite high γ: likely miscalibrated confidence. No efficiency gain: threshold γ may be too high or confidences are near-uniform. Minority-correct scenarios failing: confidence signal may not differentiate correct from incorrect answers.
- **First 3 experiments**: 1) Reproduce Table 1 on GSM8K: implement LNS[Arithmetic], sweep γ ∈ {0.80, 0.90, 0.95, 0.99}, report accuracy vs. #calls curve. 2) Ablation on confidence estimator: compare LNS[Geometric] vs LNS[Arithmetic] vs MARS on GPQA. 3) Minority-correct stress test: construct synthetic data where correct answer appears in <30% of samples but has higher average confidence.

## Open Questions the Paper Calls Out

### Open Question 1
Can more accurate or lightweight confidence estimators be developed to bridge performance gap between token-level scores and large reward models? Paper explicitly lists developing more accurate confidence estimators as future work. Unresolved because token-based methods are noisy while large PRMs are effective but impractical for deployment. Resolution would require introduction of efficient calibration techniques or smaller verifiers matching 72B PRM accuracy at 7B inference speeds.

### Open Question 2
Can required number of samples be predicted dynamically from early confidence signals to optimize compute allocation? Paper lists predicting required number of samples dynamically from confidence signals as future direction. Unresolved because CGES currently reacts to threshold γ but anticipating sampling budget needed for specific query complexity remains open. Resolution would require predictive model estimating sample complexity based on initial confidence variance or entropy.

### Open Question 3
How robust is CGES when i.i.d. assumption is violated due to correlated reasoning paths? This is inferred limitation as theoretical guarantees rely on i.i.d. samples but LLMs often generate repetitive or dependent chains of thought. Unresolved because high correlation between samples could reduce effective information gain per call, potentially invalidating theoretical drift bounds. Resolution would require empirical analysis of CGES performance under low-temperature settings where sample diversity is reduced.

## Limitations
- Performance heavily depends on quality of confidence estimators, which may be poorly calibrated for complex reasoning tasks
- Implementation details for answer parsing and MARS step-importance model are insufficiently specified for exact reproduction
- Benchmark representativeness limited by small AIME24 dataset (30 problems) and i.i.d. assumption that may not hold across all reasoning domains

## Confidence

**High confidence**: Bayesian posterior aggregation with confidence weighting and adaptive early stopping framework are well-supported by theoretical analysis and empirical results showing 69.4% call reduction with minimal accuracy loss.

**Medium confidence**: Recovering minority-correct answers is theoretically sound per Theorem 2 but empirical validation is limited to synthetic demonstrations rather than extensive real-world scenarios.

**Low confidence**: Practical implementation details necessary for exact reproduction—particularly answer extraction logic and MARS architecture—are insufficiently specified to guarantee faithful replication.

## Next Checks

1. **Calibration stress test**: On GSM8K validation set, systematically vary confidence estimator parameters and measure how confidence calibration correlates with posterior convergence speed and accuracy maintenance, validating whether µk > 0 condition holds in practice.

2. **Minority-correct scenario construction**: Create controlled synthetic datasets where correct answers appear in 10-30% of samples but have systematically higher confidence scores. Run CGES vs. majority voting to verify theoretical prediction that CGES outperforms in this regime.

3. **Numerical stability audit**: Implement SCORE computation in both direct probability space and log-space, compare results across all benchmarks, measure maximum relative error, and identify at which sample counts numerical underflow becomes problematic.