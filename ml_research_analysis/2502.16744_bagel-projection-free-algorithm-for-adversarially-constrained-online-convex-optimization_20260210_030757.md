---
ver: rpa2
title: 'BAGEL: Projection-Free Algorithm for Adversarially Constrained Online Convex
  Optimization'
arxiv_id: '2502.16744'
source_url: https://arxiv.org/abs/2502.16744
tags:
- convex
- algorithm
- regret
- have
- oracle
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the computational challenge of projection-based
  methods for Constrained Online Convex Optimization (COCO), which achieve O(T^{1/2})
  regret but require expensive projection operations. To overcome this, the authors
  propose BAGEL, a projection-free algorithm that leverages a Separation Oracle (SO)
  instead of traditional projection oracles.
---

# BAGEL: Projection-Free Algorithm for Adversarially Constrained Online Convex Optimization

## Quick Facts
- arXiv ID: 2502.16744
- Source URL: https://arxiv.org/abs/2502.16744
- Reference count: 40
- Primary result: Projection-free algorithm achieving O(T^{1/2}) regret and O(T^{1/2}logT) CCV in COCO using Separation Oracle

## Executive Summary
BAGEL addresses the computational bottleneck of projection-based methods in Constrained Online Convex Optimization (COCO) by replacing expensive projections with a Separation Oracle. The algorithm achieves the same O(T^{1/2}) regret and O(T^{1/2}logT) cumulative constraint violation as projection methods while reducing oracle complexity from O(T^2) to O(T) through an adaptive step-size scheme. By constructing a surrogate loss function that incorporates cumulative constraint violations via a Lyapunov potential, BAGEL transforms the constrained problem into an unconstrained one solvable by Online Gradient Descent.

## Method Summary
BAGEL is a projection-free algorithm for adversarial COCO that uses a Separation Oracle instead of projections. The method combines an adaptive step-size scheme with a surrogate cost function that incorporates cumulative constraint violations through a Lyapunov potential. The algorithm achieves O(T^{1/2}) regret and O(T^{1/2}logT) cumulative constraint violation (CCV) for convex cost functions with O(T) total SO calls, matching the performance of projection-based methods while maintaining computational efficiency.

## Key Results
- Achieves O(T^{1/2}) regret and O(T^{1/2}logT) CCV for convex functions with O(T) total SO calls
- Matches O(T^{1/2}) regret and CCV rates of projection-based methods when β=1/2
- For strongly convex functions, achieves O(logT) regret and O(T^{1/2}logT) CCV
- Reduces separation oracle complexity from O(T^2) to O(T) through adaptive step-size

## Why This Works (Mechanism)

### Mechanism 1: Closing the Performance Gap via Separation Oracle (SO)
Replacing the Linear Optimization Oracle (LOO) with a Separation Oracle (SO) allows projection-free methods to match the O(T^{1/2}) regret rates of projection-based methods. The algorithm uses an "Infeasible Projection via Separation Oracle" (IP-SO) that iteratively queries the SO to find a separating hyperplane when a point is outside the constraint set, approximating a projection without the computational cost of full projections.

### Mechanism 2: Adaptive Step-Size for Oracle Complexity Control
An adaptive step-size scheme reduces total separation oracle calls from O(T^2) to O(T). The step-size η_m ∝ 1/√(ε + Σ||∇̄_τ||²) dampens gradient descent movements based on accumulated gradient norms, ensuring iterates remain close enough to the feasible set that the SO terminates quickly.

### Mechanism 3: Surrogate Loss with Lyapunov Weighting
A surrogate objective function dynamically weights constraint violations using a Lyapunov-like potential. The surrogate function ĥ_t = γf̃_t + Φ'(Q_t)ḡ_t incorporates current cumulative constraint violation Q_t, placing heavier penalties on further violations as they accumulate, balancing cost minimization against constraint satisfaction.

## Foundational Learning

**Concept: Online Convex Optimization (OCO)**
Why needed: BAGEL solves Constrained OCO by reducing it to a sequence of base OCO problems.
Quick check: Can you explain why standard OCO algorithms like Online Gradient Descent require a projection step to ensure the solution remains within the feasible set?

**Concept: Projection-Free Optimization (Frank-Wolfe)**
Why needed: Understanding why standard projections are expensive motivates the use of oracles.
Quick check: What is the difference between a Linear Optimization Oracle (LOO) and a Separation Oracle (SO), and why does LOO typically yield slower O(T^{3/4}) convergence compared to projection methods?

**Concept: Lyapunov Drift Analysis**
Why needed: The analysis of constraint violation relies on bounding a potential function Q_t that grows with violations.
Quick check: How does defining a potential function Φ(Q_t) allow us to bound the Cumulative Constraint Violation (CCV) even when individual iterations might temporarily violate constraints?

## Architecture Onboarding

**Component map:** Surrogate Constructor → Base Algorithm (Adaptive OGD) → IP-SO Subroutine

**Critical path:** The interaction between the Adaptive Step-Size and the IP-SO Subroutine. The step-size determines how far outside the set the iterate lands; the IP-SO must efficiently project it back.

**Design tradeoffs:**
- **β Parameter:** Controls trade-off between Regret/CCV rate and Oracle Call complexity
  - High β (≈1/2): Better Regret (O(T^{1/2})), but higher Oracle calls (Õ(T^{2β}) = Õ(T))
  - Low β: Lower Oracle calls, but worse Regret (O(T^{1-β}))
- **Geometry (D/r):** Ratio of set diameter to enclosed ball radius
  - "Ill-conditioned" sets (high D/r) significantly increase SO calls

**Failure signatures:**
- Exploding Oracle Calls: If ε = 0 or step-sizes are constant, SO call count blows up to O(T^2)
- Unbounded Violation: If Lyapunov parameter λ is too small, penalty for violation is too weak

**First 3 experiments:**
1. Baseline Rate Verification: Run BAGEL on synthetic problem, plot Regret and CCV against T to verify O(T^{1/2}) scaling
2. Oracle Complexity Stress Test: Compare constant vs. adaptive step-size implementations, measure total SO queries
3. Geometry Sensitivity Analysis: Test on well-conditioned set (sphere) vs. ill-conditioned set (high-dim polytope), check (D/r)^2 factor

## Open Questions the Paper Calls Out

**Open Question 1:** Can projection-free methods achieve O(T^{1/2}) regret and CCV using only a Linear Optimization Oracle (LOO) in the adversarial COCO setting? The paper establishes this is open because BAGEL relies on the stronger Separation Oracle to close the O(T^{3/4}) gap inherent to LOO-based methods.

**Open Question 2:** Can the algorithm's dependence on the geometric condition number (D/r)^2 be removed or improved? Remark 4 notes this factor can grow polynomially with dimension d, potentially dominating the T term.

**Open Question 3:** Is the proposed Õ(T) oracle complexity optimal for the Separation Oracle setting? The paper establishes an upper bound but does not provide matching lower bounds, making it theoretically unclear if fewer oracle calls are possible.

## Limitations

- No experimental validation provided, making practical efficiency claims unverified
- Requires a Separation Oracle, which is efficient for some geometries (spectral norm balls) but expensive for others (nuclear norm balls)
- Assumes specific problem parameters (D, M₁, K) are known or estimable, which may not hold in practice

## Confidence

**High confidence:** The O(T^{1/2}) regret and O(T^{1/2}logT) CCV bounds for convex functions (Theorem 1), following standard Lyapunov drift arguments.

**Medium confidence:** The O(T) oracle complexity claim (Remark 2), depending critically on the adaptive step-size mechanism and ε > 0 assumption.

**Low confidence:** The strong convexity results (Theorem 2) and the general O(T^{1-β}) regret rate for arbitrary β, requiring careful parameter tuning.

## Next Checks

1. Implement BAGEL on a synthetic COCO problem with known efficient SO (e.g., probability simplex) and verify the O(T^{1/2}) scaling of Regret and CCV on a log-log plot.

2. Stress test the oracle complexity by comparing implementations with constant vs. adaptive step-sizes, measuring total SO calls over T rounds to validate the claimed O(T²) → Õ(T) reduction.

3. Evaluate BAGEL on a "well-conditioned" constraint set (e.g., sphere) vs. an "ill-conditioned" set (e.g., high-dimensional polytope) to empirically verify the (D/r)² factor in oracle complexity.