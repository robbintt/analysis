---
ver: rpa2
title: Interestingness First Classifiers
arxiv_id: '2508.19780'
source_url: https://arxiv.org/abs/2508.19780
tags:
- features
- accuracy
- interesting
- more
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EUREKA, a framework for building classifiers
  that prioritize interestingness over accuracy. Instead of maximizing predictive
  performance, EUREKA leverages large language models to rank features by their perceived
  interestingness through pairwise comparisons.
---

# Interestingness First Classifiers

## Quick Facts
- arXiv ID: 2508.19780
- Source URL: https://arxiv.org/abs/2508.19780
- Reference count: 40
- Key outcome: Introduces EUREKA framework for building classifiers that prioritize interestingness over accuracy, using LLMs to rank features and train interpretable models

## Executive Summary
This paper presents EUREKA, a novel framework for building interpretable classifiers that prioritize feature interestingness over traditional accuracy metrics. Rather than maximizing predictive performance, EUREKA leverages large language models to evaluate and rank features based on their perceived interestingness through pairwise comparisons. The framework then constructs interpretable classifiers using only the most interesting features, revealing non-obvious patterns in the data.

The approach represents a fundamental shift in how we think about machine learning model development. Instead of treating interestingness as a post-hoc property of model interpretation, EUREKA makes it a primary design criterion. Through experiments on six benchmark datasets, the framework demonstrates its ability to discover surprising yet predictive features while maintaining meaningful accuracy above chance levels. For instance, in occupancy detection, it identifies humidity as more interesting than light intensity, and in citation prediction, it finds that titles containing colons have slightly higher citation likelihood.

## Method Summary
EUREKA works by first using large language models to rank features by their perceived interestingness through pairwise comparisons. The LLM evaluates which feature in each pair would be more interesting to discover in the data. After ranking all features, the framework selects the top-k most interesting ones and trains interpretable classifiers using only these selected features. This creates models that prioritize revealing interesting patterns over maximizing predictive accuracy, though the resulting classifiers still maintain reasonable performance above random chance.

## Key Results
- On occupancy detection, EUREKA identified humidity as more interesting than light intensity, achieving 85% accuracy with the rule "high humidity implies room occupied"
- In paper citation prediction, discovered that titles containing colons are slightly more likely to be cited
- Across six benchmark datasets, EUREKA consistently identified non-obvious yet predictive features while maintaining meaningful accuracy above chance levels
- Generated interpretable classifiers that reveal surprising patterns in the data

## Why This Works (Mechanism)
The framework leverages the semantic understanding capabilities of large language models to evaluate feature interestingness. LLMs can recognize patterns that might be non-obvious to traditional statistical methods, such as the relationship between humidity and occupancy or the subtle correlation between title formatting and citation rates. By making interestingness a primary optimization criterion rather than a post-hoc analysis, EUREKA creates models that naturally highlight surprising insights while still maintaining predictive utility.

## Foundational Learning

1. Feature Interestingness Evaluation
   - Why needed: Traditional ML focuses on predictive power, missing potentially valuable insights
   - Quick check: Can you articulate what makes a feature "interesting" vs merely predictive?

2. LLM-based Feature Ranking
   - Why needed: LLMs provide semantic understanding beyond statistical correlation
   - Quick check: Understand how pairwise comparisons work for ranking

3. Interpretability-First Model Design
   - Why needed: Most accurate models sacrifice interpretability
   - Quick check: Can you explain the trade-off between accuracy and interpretability?

4. Pairwise Comparison Methodology
   - Why needed: Direct ranking of all features is computationally expensive
   - Quick check: Understand why pairwise comparisons are more efficient than absolute rankings

5. Rule-based Classifier Construction
   - Why needed: Ensures final models remain interpretable
   - Quick check: Can you describe how rules are derived from interesting features?

## Architecture Onboarding

Component Map:
EUREKA -> LLM Feature Ranker -> Feature Selector -> Rule-based Classifier

Critical Path:
Data -> LLM Pairwise Comparisons -> Feature Rankings -> Top-k Selection -> Classifier Training -> Model Output

Design Tradeoffs:
The primary tradeoff is between interestingness and accuracy. By selecting only the most interesting features, some predictive power may be sacrificed. The framework also trades computational efficiency for semantic depth, as LLM evaluations are more expensive than traditional statistical methods. Additionally, there's a tradeoff between the number of interesting features selected and model complexity.

Failure Signatures:
- LLMs may have inconsistent judgments across different prompts or models
- Interesting features might not always correlate with predictive power
- The framework may struggle with high-dimensional data where interesting patterns are subtle
- Results may be biased by the LLM's training data and inherent biases

First 3 Experiments to Run:
1. Test EUREKA on a simple dataset with known interesting patterns to verify basic functionality
2. Compare LLM-based rankings with human judgments of feature interestingness
3. Evaluate the impact of different LLM models and prompt engineering on final feature rankings

## Open Questions the Paper Calls Out
None identified in the provided information.

## Limitations
- The definition of "interestingness" is subjective and depends on LLM judgment, which may vary across models or prompts
- Evaluation focuses primarily on accuracy, which may not fully capture the interestingness-accuracy tradeoff
- Datasets used are relatively small and may not generalize to complex real-world scenarios
- Does not provide extensive comparisons with other interpretability-focused methods or discuss potential LLM biases in feature selection

## Confidence
Medium: The methodology is well-described and experimental results are presented clearly, but the subjective nature of interestingness and reliance on LLM judgment introduces uncertainty.

## Next Checks
1. Conduct ablation studies to determine the impact of LLM choice and prompt engineering on feature ranking and final classifier performance

2. Evaluate EUREKA on larger, more diverse datasets to assess scalability and generalization capabilities

3. Compare EUREKA's interestingness rankings with human judgments to validate the LLM-based approach and identify potential biases