---
ver: rpa2
title: Domain-Incremental Continual Learning for Robust and Efficient Keyword Spotting
  in Resource Constrained Systems
arxiv_id: '2601.16158'
source_url: https://arxiv.org/abs/2601.16158
tags:
- learning
- samples
- class
- feature
- denoising
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of maintaining accurate keyword
  spotting performance on resource-constrained edge devices when deployed in noisy
  environments different from the training conditions. The authors propose a domain-incremental
  continual learning framework that enables models to adapt to new noise conditions
  without forgetting previously learned knowledge.
---

# Domain-Incremental Continual Learning for Robust and Efficient Keyword Spotting in Resource Constrained Systems

## Quick Facts
- arXiv ID: 2601.16158
- Source URL: https://arxiv.org/abs/2601.16158
- Reference count: 36
- Primary result: Domain-incremental continual learning framework achieves 99.63% accuracy on clean data and >94% across diverse noisy environments at -10dB SNR using 1.64k parameters

## Executive Summary
This paper addresses the challenge of maintaining accurate keyword spotting performance on resource-constrained edge devices when deployed in noisy environments different from training conditions. The authors propose a domain-incremental continual learning framework that enables models to adapt to new noise conditions without forgetting previously learned knowledge. The approach combines wavelet denoising and spectral denoising with a dual-input CNN architecture using MFCC and LogMel features, enabling robust feature extraction in noisy conditions. The framework uses prototype-based similarity measures and confidence thresholds to identify effective samples during runtime, which are then combined with rehearsal buffer samples for incremental model retraining.

## Method Summary
The framework integrates multi-stage denoising (wavelet + spectral) with a dual-input CNN architecture that processes both MFCC and LogMel features in parallel. During deployment, the system identifies "effective samples" using confidence thresholds (>85%) and prototype-based distance filtering, then performs full INT8 quantized model updates using these samples combined with rehearsal buffer data. The model is periodically retrained every 1024 samples to adapt to new noise environments while preserving knowledge of clean data.

## Key Results
- Achieves 99.63% accuracy on clean data with 1.64k parameters (98.81% fewer than complex alternatives)
- Maintains >94% accuracy across diverse noisy environments even at -10 dB SNR
- Outperforms conventional models by 6.23% in low-SNR conditions
- Successfully adapts to previously unseen noise environments through continual learning

## Why This Works (Mechanism)

### Mechanism 1
Dual-stage denoising (wavelet + spectral) preserves speech features while suppressing noise across SNR levels from -10dB to 10dB. Wavelet denoising operates on raw waveforms to remove nonstationary noise, while spectral denoising applies temporal and frequency-axis mean subtraction with masking to suppress residual noise in the feature domain. The attenuation parameter α controls the trade-off between aggressive suppression and signal preservation.

### Mechanism 2
Prototype-based similarity combined with confidence thresholding identifies "effective samples" that provide reliable pseudo-labels for continual learning without human annotation. During inference, samples with prediction confidence >85% AND latent representation distance from class prototype within threshold (μ+nσ) are flagged as effective. These receive pseudo-labels matching their predicted class and join the training mini-batch for periodic retraining.

### Mechanism 3
Full quantized model updates with rehearsal buffer prevent catastrophic forgetting while adapting to new noise domains. Unlike prior work that restricts updates to classifier layers only, this framework updates all layers. Rehearsal buffer stores labeled MFCC/LogMel features from initial training; these are combined with augmented versions (mixed with deployment environment noise) and effective samples. The combined mini-batch enables backpropagation through the entire INT8 quantized model every 1024 samples.

## Foundational Learning

- **Quantization-Aware Training (QAT)** - The entire continual learning pipeline operates in INT8; understanding how QAT preserves accuracy during quantization is essential for the initial model and subsequent updates. Quick check: Can you explain why QAT is preferred over post-training quantization for models that will be incrementally retrained?

- **Catastrophic Forgetting in Continual Learning** - The core problem this paper addresses; understanding why neural networks forget previous knowledge when learning new domains is foundational. Quick check: What is the role of the rehearsal buffer in mitigating catastrophic forgetting, and what are its memory trade-offs?

- **Prototype-based Classification and Metric Learning** - Effective sample identification relies on computing distances between latent representations and class prototypes. Quick check: Why is MAE chosen over MSE for prototype distance calculation in this resource-constrained context?

## Architecture Onboarding

- **Component map**: Raw Audio → Wavelet Denoising (Haar + VisuShrink) → Feature Extraction (CMSIS-DSP: MFCC + LogMel) → Spectral Denoising (temporal/spectral masking) → Dual-Input CNN (parallel MFCC/LogMel streams → concat → FC) → Inference Output (class prediction + latent representation) → Effective Sample Filter (confidence + prototype distance) → Rehearsal Buffer (stored features + augmented + effective samples) → Periodic CL Retraining (every 1024 samples)

- **Critical path**: The effective sample determination is the gating mechanism for learning. If confidence threshold (P_th) or distance threshold (d_th) are set incorrectly, the system will either collect too many noisy/mislabeled samples or miss valuable adaptation opportunities.

- **Design tradeoffs**: Attenuation coefficient α (spectral denoising): Lower values = more aggressive denoising but risk signal loss; stable range [0.4, 0.9] per ablation. Confidence threshold: 85% chosen empirically; higher = fewer but more reliable effective samples. Retraining interval: 1024 samples balances adaptation speed vs. compute overhead. Model size: 1.64k parameters enables full-model updates but limits capacity for complex tasks.

- **Failure signatures**: Sudden accuracy drop after CL update: Check for contaminated effective samples (confident but wrong predictions). Degraded performance in specific noise environments: Attenuation α may be unsuitable; run ablation sweep. Memory overflow: Rehearsal buffer or effective sample storage exceeded limits. Accuracy plateau despite retraining: Distance threshold too restrictive; few samples passing filter.

- **First 3 experiments**:
  1. Baseline validation: Train single-input (MFCC only) vs. dual-input model on clean GSCD test data; verify 97.45% vs. 99.63% accuracy gap to confirm dual-feature benefit.
  2. Denoising ablation on single environment: Run OOFFICE evaluation with/without wavelet denoising and with/without spectral denoising to isolate each component's contribution at -10dB, 0dB, 10dB.
  3. Effective sample threshold sensitivity: Vary confidence threshold (0.70-0.90) and distance threshold (1.7-2.4) on one environment; measure accuracy vs. effective sample count to find stable operating region before deployment.

## Open Questions the Paper Calls Out

### Open Question 1
Can the proposed framework maintain its computational efficiency and robustness when scaled to multi-class classification tasks? The authors state in the conclusion: "Our next focus is on expanding the CL for domain-incremental learning for multi-class classification to handle datasets such as MNIST, CIFAR-10, KWS-35 and CIFAR-100." The current study is restricted to binary classification ("Yes" vs. "No"), and scaling to multi-class problems introduces challenges regarding prototype separation and memory constraints that were not addressed.

### Open Question 2
Is the computational overhead of Wavelet Denoising justified given its marginal performance gains over Spectral Denoising alone? Table III shows that a configuration without Wavelet Denoising achieves 92.88% accuracy at -10 dB, nearly matching the full pipeline's 92.94%. While the paper advocates for a dual-stage pipeline, the data suggests the first stage may be redundant or even detrimental in certain low-SNR conditions compared to the second stage, raising questions about the efficiency trade-off.

### Open Question 3
How sensitive is the effective sample selection to fixed confidence and distance thresholds in non-stationary environments? The method relies on fixed hyperparameters (e.g., 85% confidence threshold, μ+nσ distance) determined empirically to select samples for the rehearsal buffer. If environmental noise fluctuates rapidly (concept drift), fixed thresholds may filter out too many "effective" samples (starvation) or accept too many noisy ones (contamination), causing the model to fail to adapt.

## Limitations
- Framework validated only on binary keyword spotting, scalability to multi-class tasks remains unproven
- Fixed confidence and distance thresholds may not adapt well to rapidly changing noise environments
- Full INT8 model updates require sufficient memory; capacity constraints for larger vocabularies untested

## Confidence
- Confidence thresholds in diverse domains (Medium) - Validated on limited datasets (GSCD + three noise environments); performance in truly unseen acoustic conditions untested
- Rehearsal buffer scalability (Medium) - Effective for binary keyword spotting, but may struggle with multi-class vocabularies or longer deployment periods
- Quantization stability (High) - Full INT8 updates worked well in controlled experiments, but behavior under different MCU architectures needs verification

## Next Checks
1. **Cross-domain robustness test** - Deploy the trained model on three entirely new noise environments (e.g., factory floor, public transport, outdoor urban) and measure: (a) effective sample count per environment, (b) accuracy degradation rate, (c) any sudden drops indicating systematic mislabeling.

2. **Multi-class stress test** - Extend the framework to 10-20 keyword classes using the same 1.64k parameters and rehearsal buffer. Track per-class accuracy and rehearsal buffer utilization to identify capacity bottlenecks.

3. **Real-time memory footprint analysis** - Instrument the edge deployment to log rehearsal buffer growth, effective sample storage, and inference latency over 24+ hours of operation to verify the claimed "resource-constrained" suitability under sustained use.