---
ver: rpa2
title: 'The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition'
arxiv_id: '2601.00065'
source_url: https://arxiv.org/abs/2601.00065
tags:
- donor
- base
- arxiv
- gem2-2b
- token
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "We show that tokenizer transplantation\u2014the process of aligning\
  \ token vocabularies between models for composition\u2014creates a supply-chain\
  \ vulnerability. By exploiting the shared-basis reconstruction paradigm, we engineer\
  \ a single breaker token that remains inert in a donor model but becomes a high-salience\
  \ trigger in a base model after transplant."
---

# The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition

## Quick Facts
- **arXiv ID:** 2601.00065
- **Source URL:** https://arxiv.org/abs/2601.00065
- **Reference count:** 40
- **One-line primary result:** A training-free supply-chain attack that embeds a stealth trigger token via shared-basis tokenizer transplantation, achieving near-1.0 sequence emission rates on victim models while preserving donor utility.

## Executive Summary
This work exposes a supply-chain vulnerability in LLM composition via tokenizer transplantation. By exploiting the shared-basis reconstruction paradigm, the authors engineer a single "breaker token" that remains inert in a donor model but activates as a high-salience trigger in a base model after transplant. The attack is training-free, evades outlier detection, and persists through fine-tuning and weight merging. Across multiple model families and operators, it achieves high sequence emission rates in the base model (often near 1.0) while preserving the donor’s utility and maintaining donor-side stealth. This reveals a structural flaw in widely used model composition tools and underscores the need for rigorous post-transplant behavioral auditing.

## Method Summary
The attack exploits shared-basis tokenizer transplantation by constructing a composite dictionary from shared tokens between base and donor models, collecting hidden states from public text, and using an Orthogonal Matching Pursuit (OMP)-style sparse design to synthesize a breaker token embedding. The process involves greedy support selection and ridge-stabilized coefficient solving to ensure the token remains inert in the donor but activates in the base. The method is training-free, requires no model fine-tuning, and leverages existing composition operators like mergekit’s OMP. Evaluation includes measuring Sequence Emission Rate (SER) on victim models and donor utility preservation via perplexity and task accuracy.

## Key Results
- The attack achieves near-1.0 sequence emission rates on victim base models while maintaining near-zero emission on the patched donor.
- Donor utility is preserved across in-distribution and out-of-distribution tasks, including WikiText perplexity and LAMBADA/MMLU/ARC-C accuracy.
- The vulnerability persists through fine-tuning, weight merging, and multiple composition operators, demonstrating robustness.

## Why This Works (Mechanism)
The attack exploits the shared-basis reconstruction assumption in tokenizer transplantation. By designing a breaker token embedding that aligns with the base model’s semantic space but lies outside the donor’s principal component subspace, the token remains inert in the donor but activates in the base. The OMP-based sparse design ensures the token’s coefficients are optimized for this asymmetric behavior, leveraging the structural flaw in how composition tools map shared vocabularies.

## Foundational Learning
- **Shared-basis tokenizer transplantation:** The process of aligning token vocabularies between models for composition; needed to understand the attack surface.
- **Orthogonal Matching Pursuit (OMP):** A sparse approximation algorithm used to synthesize the breaker token; needed for the design method.
- **Sequence Emission Rate (SER):** The fraction of generations containing the breaker token; the primary metric for attack success.
- **Principal Component Analysis (PCA):** Used to define the donor’s semantic subspace; critical for ensuring donor-side inertness.
- **Composite anchor dictionaries:** Constructed from shared tokens to bridge base and donor embeddings; foundational for the attack design.
- **Ridge-stabilized coefficient solving:** Ensures numerical stability in the OMP design; prevents overfitting and ensures robustness.

## Architecture Onboarding

**Component Map:** Base Model <-> Shared Tokens <-> Donor Model <-> Breaker Token Embedding <-> Composite Dictionary

**Critical Path:** Public Text Collection -> Hidden State Extraction -> Composite Dictionary Construction -> OMP Design -> Breaker Token Synthesis -> Transplant -> SER Evaluation

**Design Tradeoffs:** Training-free vs. robustness; stealth vs. activation strength; computational efficiency vs. precision in coefficient solving.

**Failure Signatures:** High donor SER (stealth failure), low base SER (activation failure), or numerical instability in coefficient recovery.

**First Experiments:**
1. Reproduce the attack on a held-out model family (e.g., Llama-3.1-8B) and measure base/donor SER under the same protocol to test generalisability.
2. Conduct forensic analysis (embedding outlier detection, saliency scoring) on the patched donor tokenizer to verify that stealth persists under external scrutiny.
3. Sweep λ more finely and test whether the proxy (donor Hits@1 ≈ 0, base Hits@1 > 0) consistently predicts actual SER outcomes, to confirm the design method’s reliability.

## Open Questions the Paper Calls Out
- Does the "breaker token" vulnerability persist in multimodal models or when transplanting between extremely divergent script families (e.g., Latin to CJK)?
- Can computationally expensive embedding re-training or data-driven post-processing effectively mitigate the vulnerability without sacrificing the efficiency of model composition?
- Can the shared-basis reconstruction logic be mathematically constrained to prevent asymmetric realizability without breaking the semantic alignment of the transplant?

## Limitations
- The attack’s effectiveness is demonstrated primarily on small open-weight models; scalability to larger or proprietary models is untested.
- Stealth claims rely on narrow utility proxies (perplexity, task accuracy) without adversarial probing or forensic analysis.
- The paper does not explore failure modes against extremely divergent script families or multimodal contexts.

## Confidence
- **Core attack feasibility:** Medium (strong empirical results but incomplete procedural detail)
- **Stealth claims:** Low (narrow utility proxies, no adversarial probing)
- **Generalisability to other model families and scales:** Low (limited experimental scope)

## Next Checks
1. Reproduce the attack on a held-out model family (e.g., Llama-3.1-8B) and measure base/donor SER under the same protocol to test generalisability.
2. Conduct forensic analysis (embedding outlier detection, saliency scoring) on the patched donor tokenizer to verify that stealth persists under external scrutiny.
3. Sweep λ more finely and test whether the proxy (donor Hits@1 ≈ 0, base Hits@1 > 0) consistently predicts actual SER outcomes, to confirm the design method’s reliability.