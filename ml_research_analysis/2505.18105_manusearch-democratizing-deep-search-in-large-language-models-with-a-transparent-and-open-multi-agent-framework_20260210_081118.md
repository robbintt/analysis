---
ver: rpa2
title: 'ManuSearch: Democratizing Deep Search in Large Language Models with a Transparent
  and Open Multi-Agent Framework'
arxiv_id: '2505.18105'
source_url: https://arxiv.org/abs/2505.18105
tags:
- search
- agent
- reasoning
- information
- reading
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'ManuSearch is a transparent, modular multi-agent framework that
  enables large language models to perform deep web-integrated reasoning. It decomposes
  the search and reasoning process into three collaborative agents: (1) a solution
  planning agent that iteratively formulates sub-queries, (2) an Internet search agent
  that retrieves relevant documents via real-time web search, and (3) a structured
  webpage reading agent that extracts key evidence from raw web content.'
---

# ManuSearch: Democratizing Deep Search in Large Language Models with a Transparent and Open Multi-Agent Framework

## Quick Facts
- arXiv ID: 2505.18105
- Source URL: https://arxiv.org/abs/2505.18105
- Reference count: 3
- Primary result: ManuSearch achieves 71.8% accuracy on FRAMES benchmark, matching top closed-source systems

## Executive Summary
ManuSearch is a transparent, modular multi-agent framework that enables large language models to perform deep web-integrated reasoning. It decomposes the search and reasoning process into three collaborative agents: (1) a solution planning agent that iteratively formulates sub-queries, (2) an Internet search agent that retrieves relevant documents via real-time web search, and (3) a structured webpage reading agent that extracts key evidence from raw web content. The system achieves substantial performance improvements on complex reasoning benchmarks, outperforming prior open-source systems and even matching or surpassing leading closed-source search systems.

## Method Summary
ManuSearch implements a three-agent framework where the Solution Planning Agent decomposes queries into sub-questions, the Internet Search Agent executes web searches and synthesizes answers, and the Structured Webpage Reading Agent extracts relevant content from HTML. The system uses iterative refinement with memory accumulation, allowing agents to progressively build understanding. Each agent operates in ReAct format, interleaving reasoning with tool use. The framework supports both full-reading of all retrieved webpages and selective reading, with experiments showing full-reading achieves superior performance by reducing information loss.

## Key Results
- Achieves 71.8% accuracy on FRAMES benchmark, nearly matching the best closed-source system (65.6%)
- Reaches 47.6% accuracy on GAIA, surpassing all evaluated open-source systems
- Full Reading configuration significantly outperforms Selective Reading (64.0% vs 56.0% on FRAMES)

## Why This Works (Mechanism)

### Mechanism 1: Decoupled Planning-Solving Architecture
Separating problem decomposition from information retrieval improves complex reasoning performance compared to monolithic approaches. The Solution Planning Agent generates sub-questions iteratively without handling retrieval details, while the Internet Search Agent focuses solely on executing searches and synthesizing answers. This division prevents context window overflow and allows each agent to specialize.

### Mechanism 2: Iterative Sub-Query Refinement with Memory
Maintaining a memory container of previous sub-questions and answers enables progressive problem-solving through context accumulation. At each step t, the system maintains Ht-1 = {x, ⟨q1, a1⟩...⟨qt-1, at-1⟩}, allowing the planning agent to evaluate progress and either decompose further or generate the final answer.

### Mechanism 3: Full-Reading with Intent-Guided Extraction
Reading all retrieved webpages fully and extracting relevant content based on search intent outperforms selective page reading. The Webpage Reading Agent processes all top-K pages, extracts clean text from HTML, then filters using the search intent I to produce relevant content ck = πr(zk, I). This reduces information loss from poor page selection.

## Foundational Learning

- **Concept: ReAct (Reasoning + Acting) Architecture**
  - Why needed here: Both planning and search agents use ReAct format to interleave chain-of-thought reasoning with tool invocation
  - Quick check question: Can you explain how ReAct differs from standard chain-of-thought prompting in terms of external tool integration?

- **Concept: Multi-Hop Reasoning**
  - Why needed here: The FRAMES and GAIA benchmarks require composing information across multiple retrieval steps
  - Quick check question: Given a query "Who was the advisor of the PhD advisor of Geoffrey Hinton?", how many retrieval hops are minimally required?

- **Concept: Long-Tail Entity Reasoning**
  - Why needed here: ORION benchmark specifically targets reasoning over uncommon entities where pre-trained knowledge is unreliable
  - Quick check question: Why might an LLM perform worse on questions about a minor 19th-century composer compared to questions about Beethoven?

## Architecture Onboarding

- **Component map:**
  ```
  User Query → Solution Planning Agent (QwQ-32B/DeepSeek-R1)
                    ↓ generates sub-question qt
              Internet Search Agent (QwQ-32B/DeepSeek-V3)
                    ↓ calls WebSearch Tool (Google API, top-5 results)
              Structured Webpage Reading Agent (Qwen2.5-32B-Instruct)
                    ↓ extracts relevant content from HTML
              Internet Search Agent (generates answer at)
                    ↓ returns to planning agent
              Solution Planning Agent (evaluates completeness, iterates or outputs final answer)
  ```

- **Critical path:** The iterative loop between planning agent and search agent; failures in webpage reading directly propagate as noise in search agent answers.

- **Design tradeoffs:**
  - Full Reading vs Selective Reading: Full reading reduces information loss but increases processing cost and noise exposure
  - Reasoning vs non-reasoning models for search agent: For weaker model families (Qwen), reasoning models help; for stronger families (DeepSeek), non-reasoning models suffice for sub-problem solving
  - Max sub-queries per search (set to 3): Balances comprehensiveness against latency

- **Failure signatures:**
  - Infinite loop: Planning agent never determines information is sufficient
  - Empty answers: Webpage reading agent fails to extract relevant content from noisy pages
  - Hallucination: Search agent synthesizes answers from conflicting sources without verification
  - Context overflow: Long reasoning chains exceed model context window

- **First 3 experiments:**
  1. Reproduce the Full Reading vs Selective Reading comparison on a 50-sample subset of FRAMES to validate the key design choice
  2. Ablate the webpage reading agent by replacing Qwen2.5-32B-Instruct with a smaller model (e.g., Qwen2.5-7B) to measure sensitivity
  3. Test on ORION with varying numbers of reasoning patterns per question to characterize performance degradation as complexity increases

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What is the optimal configuration for harmonizing reasoning and non-reasoning models within the distinct planning and search agents?
- **Basis in paper:** Section 5.3 explicitly asks "How to harmonize reasoning and non-reasoning models?" and reports conflicting results where the best strategy depends on the specific model family used.
- **Why unresolved:** The authors observed that using reasoning models for both agents worked best for Qwen, whereas a hybrid approach (Reasoning Planner + Non-reasoning Searcher) was superior for DeepSeek, preventing a generalized conclusion.
- **What evidence would resolve it:** A systematic ablation study across diverse model architectures to determine if the optimal split depends on specific model capabilities like instruction-following strength versus reasoning depth.

### Open Question 2
- **Question:** Can the performance gains of the ManuSearch framework be replicated when using proprietary models (e.g., GPT-4.1, Claude 3.7) as backbone agents?
- **Basis in paper:** Section 8 lists incorporating "a wider range of both open-source and proprietary models" as necessary future work to address the limitation of focusing solely on Qwen and DeepSeek series.
- **Why unresolved:** The modularity and decoupled planning strategy have only been validated on specific open-weight reasoning models, leaving their applicability to other leading architectures unverified.
- **What evidence would resolve it:** Benchmark results on ORION and FRAMES using ManuSearch implementations powered by the proprietary models listed in the limitations.

### Open Question 3
- **Question:** Does the integration of code execution and multimodal tools enhance the framework's capability for non-textual reasoning tasks?
- **Basis in paper:** Section 8 states that future work could enhance the framework by "integrating additional built-in tools such as Code Execution and Multimodal tools."
- **Why unresolved:** The current "Tool-Augmented Internet Search" agent is limited to text-based web search and reading, potentially restricting performance on queries requiring visual or computational reasoning.
- **What evidence would resolve it:** Comparative evaluation on multimodal or math-heavy benchmarks between the standard ManuSearch and a version augmented with code execution and vision tools.

## Limitations
- Scalability concerns with memory-based iterative refinement for reasoning chains exceeding 3-4 hops
- Full-reading approach may not scale well to domains with extensive conflicting information or high noise levels
- Performance claims on ORION are based on single-pattern analysis, with multi-pattern complexity scaling untested

## Confidence
- **High Confidence (80-90%):** The modular agent architecture design and core performance improvements on FRAMES and GAIA benchmarks are well-supported by experimental results
- **Medium Confidence (60-75%):** The specific mechanisms of iterative sub-query refinement and memory accumulation have limited direct corpus validation
- **Low Confidence (40-55%):** The claimed equivalence to leading closed-source systems may be sensitive to evaluation conditions and prompt engineering variations

## Next Checks
1. **Reasoning Chain Complexity Scaling:** Systematically evaluate ManuSearch on reasoning tasks with 5-10 hop dependencies to determine the upper bound of the iterative refinement mechanism and identify failure modes.
2. **Domain Transfer Validation:** Test the framework on specialized domains (e.g., medical literature, legal documents) where full-reading may encounter significantly higher noise levels and conflicting information.
3. **Memory Efficiency Analysis:** Profile the memory container's growth and impact on planning agent performance as the number of sub-questions increases, and test alternative memory compression or summarization strategies.