---
ver: rpa2
title: Multivariate Conformal Prediction using Optimal Transport
arxiv_id: '2502.03609'
source_url: https://arxiv.org/abs/2502.03609
tags:
- conformal
- prediction
- transport
- optimal
- coverage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces OT-CP, a method for multivariate conformal
  prediction that leverages optimal transport (OT) theory to construct uncertainty
  sets for multidimensional outputs. The key idea is to transform multivariate scores
  into a univariate space using an optimal transport map, enabling the application
  of standard conformal prediction techniques.
---

# Multivariate Conformal Prediction using Optimal Transport

## Quick Facts
- **arXiv ID:** 2502.03609
- **Source URL:** https://arxiv.org/abs/2502.03609
- **Reference count:** 40
- **Key outcome:** OT-CP outperforms M-CP and Merge-CP on low-dimensional multivariate regression tasks by constructing uncertainty sets via optimal transport maps

## Executive Summary
This paper introduces OT-CP, a method for multivariate conformal prediction that leverages optimal transport (OT) theory to construct uncertainty sets for multidimensional outputs. The key innovation is using an optimal transport map to transform multivariate scores into a univariate space, enabling standard conformal prediction techniques to be applied. Experiments on a benchmark of 24 multivariate regression tasks show OT-CP achieves smaller prediction regions than existing methods while maintaining distribution-free coverage guarantees, particularly for datasets with dimensionality d ≤ 6.

## Method Summary
OT-CP constructs multivariate prediction sets by first estimating an entropic optimal transport map that pushes the empirical distribution of residuals to a uniform distribution on a unit ball. This map provides a center-outward ranking of multivariate scores, transforming them into univariate conformity scores. Standard conformal prediction is then applied to these transformed scores to determine an empirical threshold. For a test point, the prediction set includes all outputs whose transformed score falls within this threshold. The method uses Sinkhorn algorithm with entropic regularization for tractable OT map estimation and requires tuning of regularization parameter ε and target grid size m.

## Key Results
- OT-CP outperforms Merge-CP and M-CP on 13/17 datasets in terms of region size while maintaining coverage
- Method particularly effective for lower-dimensional outputs (d ≤ 6)
- Computational cost is higher due to OT map estimation (O(nm) complexity)
- Recommended hyperparameters: ε = 0.1 and m = 2^15 = 32768 target points

## Why This Works (Mechanism)

### Mechanism 1: Center-Outward Ranking via Optimal Transport
The Brenier map T pushes the score distribution P forward to a uniform distribution on the unit ball B(0,1). The rank of a point z ∈ R^d is defined as ||T(z)||—its distance from origin post-transport. Points closer to the "center" of the data distribution receive lower ranks, analogous to univariate quantiles.

### Mechanism 2: Entropic Regularization Enables Tractable Estimation
The Sinkhorn algorithm solves regularized OT in O(nm) for n samples and m target grid points. The entropic map T_ε(z) = Σ_j p_j(z) u_j provides out-of-sample evaluation via barycentric projection onto the target grid.

### Mechanism 3: Conformal Calibration Preserves Coverage Under Approximation
Rather than using theoretical radius r = 1-α, Proposition 3.6 defines empirical radius r̂_α as the smallest r satisfying Û_{n+1}(B(0,r)) ≥ 1-α, where Û is the empirical pushforward. Exchangeability ensures coverage holds regardless of map quality.

## Foundational Learning

- **Concept: Split Conformal Prediction (univariate case)**
  - Why needed here: OT-CP reduces multivariate scores to univariate via OT, then applies standard CP calibration.
  - Quick check question: Given calibration scores {1.2, 0.8, 2.1, 1.5}, what quantile defines the (1-α)=90% prediction set threshold? (Answer: ⌈0.9×5⌉=5th largest score)

- **Concept: Brenier Map / Monge-Ampère Equation**
  - Why needed here: The theoretical foundation for why OT provides unique, monotone multivariate quantiles.
  - Quick check question: Why does the Brenier map require the source measure to have a density? (Answer: Ensures convex potential ϕ exists and T=∇ϕ is unique)

- **Concept: Sinkhorn Algorithm**
  - Why needed here: Practical computation of entropic OT maps; hyperparameter ε controls regularization strength.
  - Quick check question: What happens to the transport plan as ε→0? As ε→∞? (Answer: → exact OT assignment; → independent coupling / mass splitting uniformly)

## Architecture Onboarding

- **Component map:** Training residuals → Sinkhorn solver → Entropic map T̂ → Calibration scores ||T̂(zᵢ)|| → Calibrate threshold → Test point (x,y) → Score S(x,y) → T̂(S(x,y)) → ||T̂(S(x,y))|| ≤ r̂_α? → Include/exclude

- **Critical path:** The Sinkhorn solve (f*, g* potentials) determines map quality; downstream calibration is cheap O(n log n) quantile computation.

- **Design tradeoffs:**
  - m (target grid size): Larger m → better map approximation, O(nm) memory/compute cost. Paper uses m=2^15=32768.
  - ε (regularization): Smaller ε → closer to true OT but statistically unstable; larger ε → faster but blurred maps. Paper finds ε=0.1 robust across datasets.
  - Dimension d ≤ 6 is sweet spot; d ≥ 14 shows diminished returns.

- **Failure signatures:**
  - Region size explodes (10^6+): ε too small or dimension too high; increase ε or verify d.
  - Coverage below target: Exchangeability violated or calibration set contaminated with training data.
  - Runtime timeout: Reduce m or increase ε; consider semi-discrete OT alternatives.

- **First 3 experiments:**
  1. **Sanity check on synthetic 2D Gaussian:** Generate isotropic residuals, verify OT-CP produces circular regions (should match Mahalanobis baseline). Confirms implementation correctness.
  2. **Ablation on (ε, m):** Replicate Figure 2 on one dataset (e.g., `taxi`). Plot region size vs. coverage for ε∈{0.01,0.1,1.0} and m∈{4096,16384,32768}. Establishes working hyperparameter ranges.
  3. **Compare to M-CP and Merge-CP on `house` dataset (d=2):** Measure region size, coverage, and runtime. Validates claimed 13/17 improvement and quantifies computational overhead.

## Open Questions the Paper Calls Out

### Open Question 1
How can the accuracy and efficiency of OT-CP be maintained as the output dimensionality ($d$) scales significantly beyond the tested range ($d \le 16$)? The authors observe that the performance edge of OT-CP vanishes in higher-dimensional regimes (Figure 4) and explicitly cite the "curse of dimensionality" as a challenge for OT map estimation.

### Open Question 2
Can the computational cost of estimating the entropic map be reduced to allow for real-time application or larger calibration sets without violating coverage guarantees? The paper notes that OT-CP "incurs higher computational costs" (Figure 3) and identifies the $O(nm)$ complexity of the Sinkhorn algorithm as a bottleneck (Section 3.4).

### Open Question 3
Is it possible to extend OT-CP to provide local or conditional coverage guarantees without relying on the strong regularity assumptions required by concurrent methods? The authors contrast their work with Thurin et al. (2025), noting that while OT-CP provides finite-sample marginal coverage, the concurrent work achieves conditional coverage only under additional regularity assumptions.

## Limitations
- Method faces scalability challenges in higher dimensions (d ≥ 14), where advantage over simpler baselines diminishes
- Computational cost is significantly higher due to OT map estimation (O(nm) complexity)
- Requires careful hyperparameter tuning (ε and m) for optimal performance

## Confidence

- **High Confidence:** Coverage guarantee preservation through conformal calibration (Proposition 3.6) is theoretically sound
- **Medium Confidence:** Empirical improvements in region size (13/17 datasets) are well-supported by experiments
- **Low Confidence:** Method's behavior in extremely high dimensions (d > 20) or with non-standard score distributions remains untested

## Next Checks

1. **Coverage robustness test:** Verify coverage preservation under distribution shift by evaluating OT-CP on calibration/test splits from different data sources

2. **Dimensionality stress test:** Systematically evaluate region size and coverage across d = 2, 6, 10, 14, 18 to quantify the curse of dimensionality impact

3. **Hyperparameter sensitivity analysis:** Replicate Figure 2 for ε ∈ {0.01, 0.1, 1.0} and m ∈ {4096, 16384, 32768} on at least 3 datasets to confirm recommended settings