---
ver: rpa2
title: PAC Learnability in the Presence of Performativity
arxiv_id: '2510.08335'
source_url: https://arxiv.org/abs/2510.08335
tags:
- performative
- distribution
- risk
- learning
- probability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the learnability of performative binary
  classification under distribution shifts induced by model deployment. The authors
  formalize PAC learnability relative to a distribution map and introduce a class
  of linear posterior performative drifts.
---

# PAC Learnability in the Presence of Performativity

## Quick Facts
- **arXiv ID:** 2510.08335
- **Source URL:** https://arxiv.org/abs/2510.08335
- **Reference count:** 40
- **One-line primary result:** Any PAC-learnable hypothesis space remains PAC-learnable under linear posterior performative drifts, with an unbiased empirical risk estimator enabling this preservation.

## Executive Summary
This paper establishes theoretical foundations for learning in settings where model deployment induces distribution shifts on the test data. The authors formalize PAC learnability in the presence of performativity by introducing a distribution map that captures how predictions affect the label distribution. They construct a Performative Empirical Risk (PER) estimator that is an unbiased estimator of the true risk under the shifted distribution, proving that standard PAC-learnability is preserved under linear posterior performative drifts. The work bridges the gap between theory and practice by providing both theoretical generalization bounds and practical experiments demonstrating superior performance of PER minimization over standard empirical risk minimization.

## Method Summary
The method introduces a Performative Empirical Risk (PER) estimator that accounts for distribution shifts induced by model predictions. Under the assumption of linear posterior performative drift, the true risk can be decomposed into terms computable from the original distribution, yielding an unbiased estimator. The authors prove that if a hypothesis class is PAC-learnable in standard settings, it remains PAC-learnable under this performative framework, with generalization error bounded by the Rademacher complexity. They implement this using a convex surrogate loss and demonstrate its effectiveness on synthetic and real datasets where the performative shift follows the specified linear structure.

## Key Results
- PER minimization outperforms standard ERM as performativity strength increases, particularly on synthetic and real-world datasets
- The generalization error bound for performative learning is linearly related to the standard Rademacher complexity of the hypothesis class
- Imperfect knowledge of performative shift parameters introduces an irreducible error term linear in the uncertainty size (O(ε))

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** An unbiased estimator of the performative risk can be constructed using only data from the original distribution, provided the performative shift follows a specific linear structure.
- **Mechanism:** The paper defines a "Linear Posterior Performative Drift" where the conditional label probability $P(Y=1|X)$ shifts linearly based on the classifier's prediction $h(x)$. Under this model, the true performative risk can be decomposed into terms computable from the original distribution, yielding the Performative Empirical Risk (PER) estimator.
- **Core assumption:** The performative effect is strictly a linear posterior drift characterized by known parameters $a_1, a_2, a_3, a_4$.
- **Evidence anchors:** Lemma 4.1 derives the explicit form of the unbiased estimator from the abstract claim.

### Mechanism 2
- **Claim:** Standard PAC-learnability of a hypothesis class implies performative PAC-learnability under the proposed framework.
- **Mechanism:** The generalization error is bounded by the Rademacher complexity of the hypothesis class. The paper proves that the complexity of the performative risk function class is linearly bounded by the complexity of the original hypothesis class.
- **Core assumption:** The loss function is bounded and the hypothesis class has finite VC-dimension.
- **Evidence anchors:** Corollary 4.1 links the excess risk directly to the standard Rademacher complexity $R_n(H)$.

### Mechanism 3
- **Claim:** Imperfect knowledge of the performative shift parameters introduces an irreducible error term linear in the uncertainty size.
- **Mechanism:** If the shift parameters are known only within intervals of total length $\epsilon$, minimizing the PER yields a solution within $O(\epsilon)$ of the optimal performative risk.
- **Core assumption:** The learner knows the range of possible shift parameters but not the exact values.
- **Evidence anchors:** Proposition 4.1 proves that $\epsilon/4$ excess risk is unavoidable.

## Foundational Learning

- **Concept: Rademacher Complexity**
  - **Why needed here:** The primary theoretical guarantee is expressed in terms of Rademacher complexity, required to interpret the sample complexity bounds.
  - **Quick check question:** Can you explain why the complexity of the performative risk class $F_H$ is related to the complexity of the hypothesis class $H$ by a factor of the shift parameters $|\alpha_1| + |\alpha_3|$?

- **Concept: Surrogate Loss Functions**
  - **Why needed here:** The paper implements PERM using a specific convex surrogate loss because the binary 0-1 loss is non-convex.
  - **Quick check question:** Does the proposed surrogate loss $V(f(x), y)$ upper bound the 0-1 performative risk for all values of coefficients $\alpha_1, \alpha_3$?

- **Concept: Radon-Nikodym (RN) Derivative**
  - **Why needed here:** To extend the logic beyond linear drift to general distribution shifts, the paper uses the RN derivative $d\tilde{P}_h/dP$ to reweight the risk.
  - **Quick check question:** Why does the RN derivative need to be uniformly bounded ($M$) and uniquely determined by $h(x)$ for the generalization bounds to hold?

## Architecture Onboarding

- **Component map:** Dataset $S=\{(X_i, Y_i)\}$ from original distribution $D$ -> Compute PER weights $\alpha_i$ -> Minimize Surrogate Loss (Eq. 6) using gradient descent -> Hypothesis $h^*_S$ optimized for shifted distribution
- **Critical path:** The correct identification of the performative map parameters $a_1, \dots, a_4$. If these are mis-specified, the "unbiased" estimator becomes biased.
- **Design tradeoffs:**
  - **Loss Convexity vs. Generality:** The surrogate loss is convex only if $\alpha_1 \le 0$ and $\alpha_3 \le 0$.
  - **Robustness vs. Accuracy:** Using parameter intervals adds robustness to uncertainty but introduces an inevitable $O(\epsilon)$ error floor.
- **Failure signatures:**
  - **Oscillation:** RERM may oscillate between classifiers rather than converge if the performative map creates a feedback loop.
  - **Divergence of Risk:** Standard ERM models will show significantly degraded accuracy on the shifted test distribution compared to PERM.
- **First 3 experiments:**
  1. Reproduce the "Placebo Effect" experiment to verify that PERM maintains accuracy as effect strength $a$ increases, while ERM fails.
  2. Systematically perturb the map parameters $a_i$ to measure the sensitivity of the final classifier's accuracy, validating the $O(\epsilon)$ error bound.
  3. Implement the adapted RERM on the Credit Score dataset to check for convergence or oscillation under different parameter settings.

## Open Questions the Paper Calls Out
- **Open Question 1:** Can theoretical convergence guarantees be established for Repeated Empirical Risk Minimization (RERM) when adapted to the single-dataset setting?
- **Open Question 2:** Is performative PAC learnability preserved when the functional form of the performative map is unknown and must be estimated from data?
- **Open Question 3:** Can the performative empirical risk framework be extended to parametric distribution shifts beyond linear posterior drifts?

## Limitations
- The framework relies on a specific linear posterior drift model which may not capture complex performative effects in real-world settings.
- The unbiased PER estimator requires exact knowledge of the drift parameters; even small uncertainty introduces an irreducible error floor of O(ε).
- Results assume bounded loss and finite hypothesis complexity; infinite-capacity models may not satisfy the theoretical guarantees.

## Confidence
- **High:** Theorem 4.1 (PAC-learnability preservation) and Theorem 4.2 (imperfect parameter knowledge bounds) are mathematically rigorous given the assumptions.
- **Medium:** The empirical results on synthetic and real datasets demonstrate practical value, but the Credit Score dataset uses real-world data without ground truth performative shift.
- **Low:** The extension to general Radon-Nikodym derivatives is promising but lacks empirical validation on datasets beyond linear drift.

## Next Checks
1. Apply PERM to a dataset with a known non-linear performative shift to test robustness beyond the linear model.
2. Systematically vary the uncertainty intervals [ε_lower, ε_upper] for the drift parameters and measure the resulting accuracy degradation to validate the O(ε) bound empirically.
3. Implement and test the Repeated ERM (RERM) adaptation procedure on a simple performative regression problem to check for oscillation vs. convergence under different map parameters.