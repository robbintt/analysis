---
ver: rpa2
title: 'ContinualFlow: Learning and Unlearning with Neural Flow Matching'
arxiv_id: '2506.18747'
source_url: https://arxiv.org/abs/2506.18747
tags:
- uni00000013
- uni00000011
- unlearning
- uni00000003
- uni00000018
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We introduce ContinualFlow, a principled framework for targeted
  unlearning in generative models via Flow Matching. Our method leverages an energy-based
  reweighting loss to softly subtract undesired regions of the data distribution without
  retraining from scratch or requiring direct access to the samples to be unlearned.
---

# ContinualFlow: Learning and Unlearning with Neural Flow Matching

## Quick Facts
- arXiv ID: 2506.18747
- Source URL: https://arxiv.org/abs/2506.18747
- Authors: Lorenzo Simone; Davide Bacciu; Shuangge Ma
- Reference count: 25
- Key outcome: Introduces a principled framework for targeted unlearning in generative models via Flow Matching, achieving performance comparable to retraining baselines while maintaining training efficiency and without needing access to forgotten data

## Executive Summary
ContinualFlow introduces a novel framework for targeted unlearning in generative models using Flow Matching. The method employs energy-based reweighting to softly subtract undesired regions of the data distribution without retraining from scratch or requiring direct access to samples to be unlearned. Instead, it relies on energy-based proxies to guide the unlearning process. The framework proves that this induces gradients equivalent to Flow Matching toward a soft mass-subtracted target, and validates through experiments on 2D and image domains, achieving performance comparable to retraining baselines while maintaining training efficiency.

## Method Summary
ContinualFlow operates by training a flow matching model to learn a velocity field that transports data from a base distribution to a target distribution. For unlearning, it introduces an energy-based reweighting loss (ERFM) that modifies the standard flow matching objective. The energy function F(x) identifies regions to be forgotten, and sigmoid weights σ(-λF(x)) are used to softly suppress contributions from these regions during training. This creates a reweighted target distribution where undesired mass is suppressed. The method proves gradient equivalence between the ERFM loss and standard flow matching toward this soft mass-subtracted target, enabling efficient unlearning without retraining from scratch or accessing forget samples directly.

## Key Results
- Achieves forget rates below 0.02 on 2D synthetic benchmarks (Circles, Moons) while maintaining MMD below 0.02
- On MNIST binary unlearning (retain even digits, forget odd digits), achieves Forget Rate ~0.0005 and Leakage ~0.0015
- Demonstrates ~2× faster training than retraining baselines on CIFAR-10 and ~1.7× faster on MNIST
- Shows reversibility: can recover forgotten content by inverting the energy function

## Why This Works (Mechanism)

### Mechanism 1: Energy-Based Soft Mass Subtraction
Energy functions provide a soft, differentiable way to identify and suppress undesired distribution regions without hard thresholding or explicit sample access. An energy function F(x) ∝ -log qf(x) assigns high values to forget-associated regions. The sigmoid σ(-λF(x)) converts this to smooth weights in [0,1], softly downregulating contributions from high-energy samples. This creates reweighted target ˜q1(x) ∝ q0(x)·σ(-λF(x)). Core assumption: F(x) faithfully correlates with forget content; λ appropriately scales suppression without numerical instability.

### Mechanism 2: Gradient-Equivalent Trajectory Reweighting
The ERFM loss LERFM(θ) = E[σ(-λF(x1))·||vθ(t,x) - ut(x|x0,x1)||²] upweights gradients from low-energy samples. By Theorem 4.1, this equals (scaled) gradient of CFM loss toward ˜q1. The velocity field learns to route trajectories around high-energy regions during ODE integration. Core assumption: Sufficient velocity field capacity; the partition function Z = ∫q0(x)σ(-λF(x))dx exists and is finite.

### Mechanism 3: Compositional and Reversible Energy Modulation
Energy functions support modular composition (combining multiple unlearning objectives) and reversibility (recovering forgotten content by inverting energy guidance). Since F(x) is a scalar field, multiple energies can be combined additively or via other operations. Reversing the energy sign (F → -F) flips the sigmoid weighting, directing the flow toward previously suppressed regions. Core assumption: Energy functions are approximately separable; the model retains sufficient information about forgotten modes to recover them.

## Foundational Learning

- **Concept: Flow Matching (Conditional CFM)** - Why needed: Core generative framework; ERFM modifies CFM objective. Quick check: Given samples (x0, x1), can you write the CFM training objective and explain why it trains a velocity field to transport p0→p1?
- **Concept: Energy-Based Models (Boltzmann distributions)** - Why needed: F(x) defines unnormalized log-probabilities; sigmoid converts to weights. Quick check: Why is p(x) = (1/Z)exp(-F(x)) hard to normalize, and how does ContinualFlow avoid computing Z?
- **Concept: Importance Weighting / Reweighted Expectations** - Why needed: Theorem 4.1 hinges on viewing σ(-λF(x1)) as importance weights. Quick check: If you sample x∼q0 and want expectations under ˜q1∝q0·w(x), how do you construct an unbiased estimator?

## Architecture Onboarding

- **Component map**: Pretrained flow model vθ(t,x) -> Energy function F(x) -> ERFM training loop -> Inference via ODE solver
- **Critical path**: Pretrained model → Define energy F(x) → Set λ → Run ERFM (Algorithm 1) → Evaluate retention (MMD, accuracy) and forgetting (forget rate, leakage)
- **Design tradeoffs**: λ (suppression sensitivity) - larger λ→stronger unlearning but potential collateral damage; Energy source - pretrained classifier vs custom scorer; Sample efficiency - avoids full retraining but slower than fine-tuning
- **Failure signatures**: Over-suppression causing mode collapse on retained data; Incomplete unlearning with high forget rate; Numerical issues with vanishing gradients; Energy misalignment leading to poor unlearning
- **First 3 experiments**: 1) 2D validation on Circles/Moons with simple energy (distance from origin), target MMD<0.02, Forget Rate<0.02; 2) MNIST binary unlearning using digit classifier for F, target Forget Rate ~0.0005, Leakage ~0.0015; 3) Reversibility test on MNIST after unlearning odd digits, recover them by inverting F

## Open Questions the Paper Calls Out

- **Energy alignment reliability**: How can energy functions be learned or designed to faithfully align with the forget distribution when binary classifiers provide only coarse proxies? The paper acknowledges "a key challenge is learning energy functions that faithfully align with the forget distribution, as this alignment affects unlearning performance."

- **Compositional unlearning**: Can energy functions be composed to enable multi-stage, continual unlearning without degradation of retained content? While the paper demonstrates invertibility, it does not experimentally validate sequential or compositional application of multiple energy functions over time.

- **High-dimensional scalability**: How does the method scale to complex, high-dimensional generative domains with entangled representations? Experiments are limited to 2D distributions and small-scale image datasets, leaving high-dimensional settings untested.

## Limitations

- Energy alignment reliability remains a key challenge, as classifier-based proxies may not perfectly capture semantic forget distributions
- Scalability to complex, high-dimensional generative domains with entangled representations has not been experimentally validated
- Capacity constraints may prevent perfect approximation of the soft mass-subtracted target in high-dimensional spaces

## Confidence

- **High confidence**: Gradient equivalence theorem (Theorem 4.1) and 2D synthetic experiments are well-supported and reproducible
- **Medium confidence**: Image domain results (MNIST, CIFAR-10) show reasonable performance but with notable gaps to retraining baselines in some metrics
- **Low confidence**: Compositional and reversible energy claims are demonstrated but lack extensive validation across diverse scenarios

## Next Checks

1. **Classifier energy robustness test**: Systematically evaluate how classifier miscalibration affects unlearning performance by intentionally degrading classifier accuracy and measuring downstream forget rate/leakage

2. **Scaling experiment**: Apply the framework to higher-resolution images (e.g., CIFAR-100 or CelebA) to assess whether the energy-based approach maintains effectiveness in more complex distribution spaces

3. **Capacity ablation**: Train flow models with varying capacity (e.g., different hidden dimensions) and measure the impact on unlearning completeness and retention accuracy to identify minimum requirements