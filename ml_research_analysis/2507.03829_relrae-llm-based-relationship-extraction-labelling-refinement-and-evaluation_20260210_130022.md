---
ver: rpa2
title: 'RELRaE: LLM-Based Relationship Extraction, Labelling, Refinement, and Evaluation'
arxiv_id: '2507.03829'
source_url: https://arxiv.org/abs/2507.03829
tags:
- label
- labels
- domain
- relationship
- ontology
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# RELRaE: LLM-Based Relationship Extraction, Labelling, Refinement, and Evaluation

## Quick Facts
- **arXiv ID:** 2507.03829
- **Source URL:** https://arxiv.org/abs/2507.03829
- **Reference count:** 40
- **Key outcome:** None specified in the document

## Executive Summary
RELRaE presents a four-stage pipeline for extracting and labeling hierarchical relationships from XML Schema (XSD) documents to generate skeleton RDFS ontologies. The framework combines rule-based extraction (RuBREx) with LLM refinement and cross-model evaluation, demonstrating that hybrid approaches produce more accurate relationship labels than either rule-based or LLM-only methods alone. Evaluated on the AnIML chemistry schema, the approach achieves 96.4% loose similarity (≥0.6) between refined labels and expert reference sets.

## Method Summary
RELRaE processes XML schemas through four stages: (1) RuBREx extracts entity pairs and applies 10 structural patterns to generate initial relationship labels, (2) GPT-4o refines these labels using domain context and few-shot examples, (3) Gemini-2.0-flash evaluates label suitability using Likert scoring with cross-model verification, and (4) accepted labels are assembled into RDFS skeleton ontologies. The method leverages rule-based anchoring to constrain LLM output space while enabling semantic refinement, and uses a separate LLM for evaluation to reduce bias.

## Key Results
- Hybrid rule-LLM refinement achieves 96.4% loose similarity (≥0.6) vs. 91.0% for rules alone
- Cross-model LLM evaluation reaches 93.3% agreement with domain experts when accepting "Possible" or higher
- Temperature optimization shows lower values (0.0-0.25) favor consistency while higher values (0.75-1.0) degrade quality

## Why This Works (Mechanism)

### Mechanism 1: Hybrid Rule-LLM Label Anchoring
Combining rule-based label generation with LLM refinement produces more accurate relationship labels than either approach alone. Rule-based methods generate initial labels using structural patterns, providing a consistent starting point. The LLM then refines these labels using domain context, constrained by the initial anchor—reducing hallucination scope while enabling semantic improvement. Core assumption: Rule-generated labels, while semantically incomplete, provide a syntactically valid scaffold that constrains LLM output space. Evidence: Refined approach achieved 96.4% loose similarity vs. 91.0% for rules alone.

### Mechanism 2: LLM-as-a-Judge with Cross-Model Verification
A separate LLM from a different model family can act as a proxy for domain expert evaluation of relationship labels. Using LLME (Gemini-2.0-flash) to evaluate LLMR (GPT-4o) outputs reduces bias through model diversity. The evaluator LLM assigns Likert scores (1-5), with "Likely" or "Yes" (4-5) accepted; lower scores trigger fallback to rule-based labels. Core assumption: Cross-model evaluation captures domain validity better than self-evaluation. Evidence: Domain expert agreement with LLM evaluation reached 93.3% when accepting "Possible" (3) or higher.

### Mechanism 3: Schema Pattern-Based Relationship Extraction
XML schema hierarchical patterns encode implicit relationships that can be systematically extracted and classified. RuBREx module identifies 10 structural patterns mapping XML constructs to ontology relationships. Patterns distinguish subclass relations from property relations based on element types and restrictions. Core assumption: XML schema structure reflects domain semantics in predictable ways. Evidence: 10 patterns including "ComplexType → Sequence → ComplexType = has<r>" and "ComplexType → Attribute with boolean = is<r>."

## Foundational Learning

- **Concept: XML Schema (XSD) Components**
  - Why needed here: Understanding `complexType`, `simpleType`, `sequence`, `choice`, and `attribute` is required to interpret Table 1 patterns and debug extraction failures.
  - Quick check question: Given an XML element `<xs:complexType name="Experiment"><xs:sequence><xs:element name="Sample" type="SampleType"/></xs:sequence></xs:complexType>`, what relationship pattern applies?

- **Concept: Ontology Relationships (OWL/RDFS)**
  - Why needed here: RELRaE outputs skeleton ontologies with property axioms; distinguishing `owl:ObjectProperty` from `rdfs:subClassOf` is critical for downstream use.
  - Quick check question: When should a relationship be modeled as a subclass axiom versus an object property?

- **Concept: Cosine Similarity with Phrase-BERT Embeddings**
  - Why needed here: Evaluation uses cosine similarity between generated and reference labels; understanding thresholds (0.6 loose, 0.85 strict) is essential for interpreting results.
  - Quick check question: If two labels have cosine similarity 0.72, are they considered "loosely similar" or "strictly similar" per the paper's thresholds?

## Architecture Onboarding

- **Component map:** XSD input → RuBREx extraction → LLMR refinement → LLME evaluation → accepted labels → ontology serialization
- **Critical path:** The refinement-evaluation loop determines final label quality
- **Design tradeoffs:** Lower temperature (0.0-0.25) favored for consistency; few-shot examples preferred but risk biasing outputs; accepting "Possible" (3) yields 95% coverage but lower precision
- **Failure signatures:** Low cosine similarity (<0.6) indicates lexical differences needing manual review; LLME "Unlikely/No" scores trigger fallback to rule-based labels; inconsistent schema documentation weakens context injection
- **First 3 experiments:**
  1. Reproduce RuBREx extraction on a simple XSD (5-10 elements) to verify pattern matching
  2. Ablate LLMR refinement: Compare RuBREx-only vs. refined approach on 20 relationships
  3. Test LLME evaluator calibration: Compare expert Likert scores to LLME scores on 30 labels

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent does RELRaE performance generalize to XML schemas from domains other than analytical chemistry?
- Basis: Evaluation focuses exclusively on AnIML schema; prompt engineering is tailored specifically to this domain
- Why unresolved: Specific prompt optimizations and rule-based patterns may not transfer effectively to schemas with different structural norms
- What evidence would resolve it: Empirical results from applying RELRaE to XML schemas from disparate domains using the same prompt strategy

### Open Question 2
- Question: How does the choice of LLM architecture impact label refinement and LLM-as-a-judge accuracy?
- Basis: Authors state comparative evaluation of different LLMs is needed as performance varies
- Why unresolved: Study relies primarily on GPT-4o and Gemini-2.0-flash, leaving model selection impact unexplored
- What evidence would resolve it: Benchmark comparing various open and closed-source models within RELRaE pipeline

### Open Question 3
- Question: Can LLM-as-a-judge be refined to distinguish acceptable labels from ambiguous ones?
- Basis: High acceptance rate for "Possible" labels (93.3%) suggests evaluator may conflate lack of error with semantic correctness
- Why unresolved: Uncertainty whether "Possible" ratings reflect genuine acceptability or insufficient incorrectness
- What evidence would resolve it: Qualitative analysis of LLM's reasoning traces when assigning mid-range Likert scores

## Limitations
- Limited domain validation: Framework tested only on AnIML chemistry schema, leaving generalization uncertain
- Evaluation subset ambiguity: Specific indices or random seed for LLM-as-a-judge evaluation subset not specified
- Documentation inconsistency: AnIML documentation varies across definitions, weakening context injection reliability

## Confidence
- **Mechanism validation (High):** Multiple evidence anchors support hybrid rule-LLM effectiveness with quantitative results
- **Architecture completeness (Medium):** Component map and critical path well-specified, but some prompt details require code inspection
- **Generalizability (Low):** Single-domain evaluation and unresolved open questions indicate uncertainty about broader applicability

## Next Checks
1. Clone repository and execute RuBREx extraction on a simple 5-10 element XSD to verify pattern matching
2. Run LLMR refinement and LLME evaluation on 20 relationships to compare against RuBREx-only baseline
3. Have a domain expert rate 30 labels and compare agreement rates with LLME evaluator scores