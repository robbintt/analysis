---
ver: rpa2
title: 'Large Language Model and Formal Concept Analysis: a comparative study for
  Topic Modeling'
arxiv_id: '2602.01933'
source_url: https://arxiv.org/abs/2602.01933
tags:
- process
- modeling
- management
- topic
- strategy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study compares Formal Concept Analysis (FCA) via CREA and
  ChatGPT for topic modeling using two datasets: PHP course materials and research
  papers. CREA, with its deterministic pipeline and FCA core, generates traceable
  topics but suffers from parameter sensitivity, high computational cost, and imbalanced
  clusters.'
---

# Large Language Model and Formal Concept Analysis: a comparative study for Topic Modeling

## Quick Facts
- **arXiv ID**: 2602.01933
- **Source URL**: https://arxiv.org/abs/2602.01933
- **Reference count**: 40
- **Primary result**: FCA produces traceable topics but suffers from parameter sensitivity and computational cost; LLMs deliver balanced, interpretable topics quickly but lack transparency and reproducibility

## Executive Summary
This study compares Formal Concept Analysis (FCA) via CREA and ChatGPT for topic modeling using two datasets: PHP course materials and research papers. CREA, with its deterministic pipeline and FCA core, generates traceable topics but suffers from parameter sensitivity, high computational cost, and imbalanced clusters. ChatGPT delivers balanced, interpretable topics quickly, strictly following prompts, but lacks transparency and reproducibility. Experiments show CREA produces dominant clusters and inconsistent results, while ChatGPT yields consistent, domain-relevant themes. The study concludes that method choice should align with use-case priorities: FCA for transparency and research rigor, LLMs for rapid prototyping and ease of use.

## Method Summary
The study employs CREA's FCA-based pipeline with TreeTagger lemmatization, BabelFy disambiguation, and HAC clustering for topic extraction, alongside a three-prompt GPT-5 approach using batch processing to handle context limits. For CREA, parameter β controls binarization thresholds, while k determines cluster count via validity indices. GPT-5 processes documents in batches of 1-10, generating topics through sequential prompts that extract, merge, and label topics. The study evaluates performance using cluster validity metrics (Silhouette, Calinski-Harabasz, Davies-Bouldin) and qualitative coherence assessment across PHP course materials and research paper datasets.

## Key Results
- CREA generates traceable topics through deterministic closure operations but suffers from dominant cluster imbalance (60-90% of terms in single cluster)
- ChatGPT strictly follows instructions, producing exactly 5 topics with 5 keywords each, yielding balanced and interpretable results
- CREA requires heavy parameterization with β≥3.00 excluding ~97% of vocabulary, while GPT-5 delivers consistent outputs despite context fragmentation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FCA generates topics through deterministic closure operations that produce traceable concept lattices from document-term relationships.
- Mechanism: Documents → Named entity extraction (BabelFy) → Binary matrix construction (via binarization strategies with β threshold) → Closure operator identifies maximal object-attribute combinations → Formal concepts → Lattice structure → HAC clustering → Topic clusters. The closure operator systematically finds all maximal combinations by iteratively adding objects and searching attribute combinations.
- Core assumption: Meaningful topical structure emerges from maximal co-occurrence patterns of entities across documents.
- Evidence anchors:
  - [abstract]: "FCA, with its deterministic pipeline and FCA core, generates traceable topics"
  - [section 2.1]: "The closure is obtained by taking each object, searching all existing combinations with its attributes, then adding another object and repeating the process until all objects are included"
  - [corpus]: FCA literature (Wille, Ganter) establishes theoretical foundations; limited direct validation for topic modeling specifically
- Break condition: Lattice exponential growth makes computation infeasible for large corpora; β ≥ 3.00 excludes ~97% of vocabulary, producing meaningless results.

### Mechanism 2
- Claim: LLM topic modeling relies on batch-processing with parallel prompting to handle context window limits, followed by cross-batch consolidation.
- Mechanism: Corpus → Document batches (1-10 docs) → Prompt 1 (topic generation per batch) → Prompt 2 (merge batch results, deduplicate, prioritize frequent topics) → Prompt 3 (labeling) → Final topics. Zero-shot setup tests model's inherent topic extraction capability.
- Core assumption: LLMs encode sufficient co-occurrence knowledge from pretraining to identify coherent themes without domain-specific training.
- Evidence anchors:
  - [section 3.4]: "To handle context length limitations, we adopted a batch-processing strategy... batch sizes ranged from 1 to 10 documents"
  - [section 4]: "ChatGPT strictly followed the instructions, consistently producing the requested number of topics with exactly five terms each"
  - [corpus]: Related work (Pham et al., Doi et al.) supports batch/parallel prompting strategies; effectiveness varies by model and domain
- Break condition: Proprietary models lack reproducibility; context fragmentation risks losing global thematic coherence across batches.

### Mechanism 3
- Claim: Cluster validity metrics provide contradictory optimization signals in FCA-based topic modeling, requiring human judgment for parameter selection.
- Mechanism: Varying β and k → Different formal concept counts and cluster distributions → Silhouette favors high k and restrictive β → Davies-Bouldin favors compact clusters → Calinski-Harabasz favors larger k → No single configuration optimizes all metrics → Dominant cluster persists regardless of parameters.
- Core assumption: Internal validity indices translate meaningfully to topic quality, though paper acknowledges this is contested.
- Evidence anchors:
  - [section 3.3.3]: "Silhouette score consistently favors the maximum value of k = 36... Davies-Bouldin index prefers more compact clusters... These contradictory results across metrics highlight the challenge of parameter selection"
  - [section 4.2]: "The largest cluster includes interesting terms... but remains too large to be interpreted"
  - [corpus]: Castellanos et al. applied clustering validity indices to FCA topic detection; Dieng et al. and Rijcken et al. argue interpretability cannot be captured by single metrics
- Break condition: Coherence measures (CV, NPMI, UMass) proved uninformative due to cluster imbalances; metrics alone insufficient for topic quality assessment.

## Foundational Learning

- Concept: **Formal Concept Analysis (FCA)**
  - Why needed here: Core mathematical framework enabling CREA's deterministic topic extraction through lattice-based concept discovery.
  - Quick check question: Given objects {A, B} with attributes {x: A,B; y: A; z: B}, what formal concepts exist?

- Concept: **Hierarchical Agglomerative Clustering (HAC) with Ward linkage**
  - Why needed here: Transforms FCA concept similarity matrix into k topic clusters; choice of linkage method affects cluster balance.
  - Quick check question: How does Ward's method differ from single-linkage in handling cluster mergers?

- Concept: **Context window and batch processing in LLMs**
  - Why needed here: Explains why corpus must be split into batches, creating the merge-step dependency and potential coherence loss.
  - Quick check question: If your corpus has 100k tokens and context limit is 8k, what information might be lost in batched processing?

## Architecture Onboarding

- Component map:
  - **CREA pipeline**: Cleaning (TreeTagger lemmatization/POS) → Disambiguation (BabelFy) → Filtering (coherence > 0.05) → FCA (binarization + closure + metrics) → HAC clustering
  - **GPT pipeline**: Text cleaning → Batching → Prompt 1 (extract 5 topics per batch) → Prompt 2 (merge to final topics) → Prompt 3 (label)

- Critical path:
  1. CREA: β parameter selection (determines vocabulary retention vs. concept count trade-off)
  2. CREA: k selection via cluster metrics (Silhouette, CHI, DBI) — no automatic optimal solution
  3. GPT: Batch size tuning to stay within context window while preserving thematic coherence

- Design tradeoffs:
  - High β (restrictive): Fewer terms/concepts, better Silhouette scores, but potential loss of coverage
  - Medium β: Preserves vocabulary but produces dominant clusters (60-90% of terms in single cluster)
  - GPT: Balanced outputs, ease of use, but zero transparency/reproducibility

- Failure signatures:
  - CREA: Dominant cluster absorbing majority of terms regardless of k; singleton clusters appearing at high k
  - CREA: β ≥ 3.0 produces trivial results (15-37 terms from 44k vocabulary)
  - GPT: Overlapping topics with repeated terms across clusters; format deviations with open-weight models (Llama 3.1 failed to follow prompts)

- First 3 experiments:
  1. Run CREA with medium strategy (β=1.0, 1.25) and high strategy (β=1.5, 2.5) on your corpus; compare cluster balance ratios and largest cluster percentages to identify parameter sweet spot.
  2. Implement the 3-prompt GPT strategy with varying batch sizes (5 vs. 10 docs); measure topic consistency across multiple runs to assess reproducibility.
  3. Apply CREA's cluster validity metrics (Silhouette, Davies-Bouldin, Calinski-Harabasz) to GPT outputs by embedding topics and computing indices — determine if these metrics capture GPT's apparent quality advantages.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can CREA's binarization and clustering mechanisms be adapted to prevent dominant clusters and improve scalability for larger corpora?
- Basis in paper: [inferred] The authors note CREA suffers from "heavy parameterization," "high computational costs," and persistent "imbalances in cluster sizes" (dominant cluster phenomenon) on larger datasets.
- Why unresolved: The current implementation requires manual tuning of $\beta$ and $k$ without a guarantee of balanced output, and lattice generation scales exponentially.
- What evidence would resolve it: A modified CREA pipeline demonstrating balanced cluster distribution and efficient scaling on datasets significantly larger than 40 documents.

### Open Question 2
- Question: How can the reproducibility and transparency of LLM-based topic modeling be ensured for rigorous academic applications?
- Basis in paper: [explicit] The authors conclude that LLMs "lack transparency and reproducibility" and operate as "black box" models, contrasting with the "traceable" nature of FCA.
- Why unresolved: Proprietary model architectures and training data are opaque, and probabilistic generation introduces variability that hinders scientific verification.
- What evidence would resolve it: A deterministic or open-source prompting strategy that yields identical topic lists across multiple runs with explainable term groupings.

### Open Question 3
- Question: How do FCA and LLM methods compare when applied to heterogeneous, noisy datasets?
- Basis in paper: [inferred] The authors excluded the standard "20Newsgroups" dataset because its "heterogeneity produced high noise," leaving their performance on non-domain-specific data unknown.
- Why unresolved: The study only validated the methods on thematically coherent corpora (PHP courses, specific research papers), limiting generalizability.
- What evidence would resolve it: A comparative analysis on the 20Newsgroups dataset or similar benchmarks demonstrating robust noise handling and topic separation.

## Limitations

- CREA suffers from parameter sensitivity and computational complexity, with β≥3.00 excluding ~97% of vocabulary and producing trivial results
- GPT-5 model availability is uncertain (appears fictional), and proprietary nature prevents reproducibility and transparency verification
- Internal cluster validity metrics may not adequately capture topic quality, yet remain primary evaluation criteria despite acknowledged limitations

## Confidence

- **High Confidence**: FCA's theoretical framework and deterministic nature (established mathematical foundations)
- **Medium Confidence**: CREA's practical performance and parameter sensitivity (limited validation across diverse datasets)
- **Low Confidence**: GPT-5 specific results and zero-shot prompting effectiveness (model availability and proprietary nature)

## Next Checks

1. Replicate CREA experiments using GPT-4o as a proxy for GPT-5, measuring topic quality through human evaluation rather than solely relying on cluster validity metrics.
2. Conduct ablation studies on CREA's parameter space (β thresholds and clustering k values) to determine optimal configurations for different corpus sizes and domains.
3. Test alternative LLM approaches including few-shot learning and supervised fine-tuning to assess whether performance gains justify the increased complexity over zero-shot prompting.