---
ver: rpa2
title: 'LetheViT: Selective Machine Unlearning for Vision Transformers via Attention-Guided
  Contrastive Learning'
arxiv_id: '2508.01569'
source_url: https://arxiv.org/abs/2508.01569
tags:
- samples
- unlearning
- data
- lethevit
- forgetting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of selective machine unlearning
  in Vision Transformers (ViTs) under privacy regulations like GDPR and CCPA, where
  specific data samples must be forgotten while preserving model performance on retained
  data. The authors propose LetheViT, a contrastive unlearning method that leverages
  attention-guided masking to identify and obscure critical image regions, guiding
  the model to forget targeted details while retaining class-level information.
---

# LetheViT: Selective Machine Unlearning for Vision Transformers via Attention-Guided Contrastive Learning

## Quick Facts
- arXiv ID: 2508.01569
- Source URL: https://arxiv.org/abs/2508.01569
- Reference count: 16
- Key outcome: Achieves state-of-the-art performance in selective machine unlearning for Vision Transformers, with an average gap as low as 0.57% compared to retraining, significantly outperforming existing methods like SalUn and ℓ1-sparse in both forgetting efficacy and membership inference attack suppression.

## Executive Summary
This paper addresses the critical challenge of selective machine unlearning in Vision Transformers (ViTs) under privacy regulations like GDPR and CCPA. The authors propose LetheViT, a novel contrastive unlearning method that leverages attention-guided masking to identify and obscure critical image regions, enabling targeted forgetting while preserving model performance on retained data. The approach uses masked images to generate positive logits and original images for negative logits, optimizing a contrastive loss to selectively erase sample-specific information.

The experimental results demonstrate that LetheViT achieves state-of-the-art performance, with an average gap as low as 0.57% compared to retraining, and significantly outperforms existing methods like SalUn and ℓ1-sparse in both forgetting efficacy and membership inference attack suppression. The method shows promise in addressing practical concerns of privacy-preserving machine learning while maintaining model utility.

## Method Summary
LetheViT proposes a contrastive unlearning approach for Vision Transformers that leverages attention-guided masking to selectively forget specific samples. The method identifies critical image regions through attention mechanisms and uses masked versions of these images to generate positive logits, while the original images serve as negative logits in a contrastive loss framework. This process guides the model to forget targeted details while retaining class-level information. The approach is evaluated on multiple datasets and ViT variants, demonstrating superior performance compared to existing methods in both forgetting efficacy and resistance to membership inference attacks.

## Key Results
- Achieves state-of-the-art performance with an average gap as low as 0.57% compared to retraining
- Significantly outperforms existing methods like SalUn and ℓ1-sparse in forgetting efficacy
- Demonstrates superior membership inference attack (MIA) suppression compared to baseline methods

## Why This Works (Mechanism)
LetheViT's effectiveness stems from its innovative use of attention-guided masking combined with contrastive learning. By identifying and obscuring critical image regions, the method can selectively target and erase sample-specific information while preserving class-level knowledge. The contrastive loss, which treats masked images as positive samples and original images as negative samples, guides the model to forget the unique features of targeted samples without affecting the overall class representation. This dual approach of spatial masking and contrastive optimization allows for precise and effective selective unlearning.

## Foundational Learning
- **Vision Transformers (ViTs)**: Understanding of transformer architectures applied to computer vision tasks, including self-attention mechanisms and patch embeddings. (Quick check: Verify knowledge of ViT architecture components and their roles)
- **Contrastive Learning**: Familiarity with self-supervised learning techniques that learn representations by contrasting positive and negative samples. (Quick check: Understand the basic principles of contrastive loss functions)
- **Attention Mechanisms**: Knowledge of how attention mechanisms in neural networks can be used to identify important regions in input data. (Quick check: Explain how attention weights are computed and used in transformer models)
- **Machine Unlearning**: Understanding of techniques to remove specific data from trained models while maintaining overall performance. (Quick check: Differentiate between complete and selective machine unlearning)
- **Privacy Regulations**: Awareness of GDPR, CCPA, and other privacy laws that mandate the right to be forgotten. (Quick check: List key requirements of GDPR related to data removal)
- **Membership Inference Attacks**: Knowledge of attacks that attempt to determine whether specific data samples were used in training a model. (Quick check: Explain how membership inference attacks work and their potential impact)

## Architecture Onboarding

**Component Map**: Input Images -> Attention-Guided Masking -> Contrastive Loss (Positive: Masked Images, Negative: Original Images) -> Model Parameters Update

**Critical Path**: The critical path involves the attention-guided masking process to identify and obscure critical regions, followed by the contrastive loss computation and parameter updates. This path is crucial as it directly impacts the model's ability to selectively forget targeted information.

**Design Tradeoffs**: The approach trades off some computational overhead for more precise and effective unlearning. The attention-guided masking adds complexity but enables targeted forgetting. The use of contrastive learning provides a robust framework for selective unlearning but may require careful tuning of hyperparameters.

**Failure Signatures**: Potential failures could include:
- Incomplete forgetting of targeted samples, leading to privacy leaks
- Over-forgetting, where the model loses important class-level information
- Computational inefficiency due to the additional masking and contrastive learning steps

**3 First Experiments**:
1. Evaluate LetheViT's performance on a simple dataset (e.g., CIFAR-10) with a single targeted sample to verify basic functionality
2. Test the method's effectiveness against membership inference attacks on a small dataset to validate privacy guarantees
3. Compare the computational overhead of LetheViT against baseline unlearning methods on a medium-sized dataset

## Open Questions the Paper Calls Out
None explicitly stated in the provided information.

## Limitations
- Potential computational overhead introduced by attention-guided masking and contrastive learning components
- Limited exploration of robustness against sophisticated adversarial attacks and membership inference techniques
- Unclear long-term stability of the unlearned model and its behavior on out-of-distribution data

## Confidence
- Claims of state-of-the-art performance: Medium
- Effectiveness in membership inference attack suppression: Medium
- Scalability to larger datasets and different ViT architectures: Low

## Next Checks
1. Evaluate LetheViT's performance and computational overhead on larger-scale datasets like ImageNet-21K or web-scale data to assess scalability.
2. Conduct robustness tests against advanced adversarial attacks and membership inference techniques to validate the method's security guarantees.
3. Perform long-term stability analysis by periodically evaluating the unlearned model's performance over extended periods to assess any gradual degradation or recovery of forgotten information.