---
ver: rpa2
title: 'Learning to Land Anywhere: Transferable Generative Models for Aircraft Trajectories'
arxiv_id: '2511.04155'
source_url: https://arxiv.org/abs/2511.04155
tags:
- data
- trajectory
- generative
- split
- dublin
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores transfer learning to enable generative trajectory
  models in data-scarce aviation settings. The authors pretrain diffusion-based and
  flow-based models on Zurich landing data, then fine-tune on Dublin data with varying
  amounts from 0% to 100%.
---

# Learning to Land Anywhere: Transferable Generative Models for Aircraft Trajectories

## Quick Facts
- **arXiv ID**: 2511.04155
- **Source URL**: https://arxiv.org/abs/2511.04155
- **Reference count**: 31
- **Primary result**: Pretraining generative trajectory models on data-rich airports enables competitive performance with only 5% of local data at data-scarce airports

## Executive Summary
This paper demonstrates that transfer learning can substantially reduce data requirements for generative trajectory models in aviation contexts. By pretraining diffusion-based and flow-based models on Zurich landing data, then fine-tuning on Dublin data with varying amounts from 0% to 100%, the authors show that diffusion models achieve competitive performance with only 5% of local data. The kinematic representation of trajectories (track, groundspeed, altitude, elapsed time) enables cross-airport transfer by learning flight dynamics rather than geographic-specific patterns. Quantitative metrics including energy distance, MMD, and DTW consistently improve with pretraining, while trajectory visualizations confirm realistic reproduction of dominant approach patterns.

## Method Summary
The method involves pretraining four generative architectures (Diffusion Model, Flow Matching, Latent DM, Latent FM) on Zurich landing trajectories, then fine-tuning on Dublin data at fractions ranging from 0% to 100%. Trajectories are represented in kinematic space (track, groundspeed, altitude, elapsed time) rather than geographic coordinates to enable transfer. Models are evaluated using energy distance, MMD, and DTW on held-out Dublin test sets with N=100 generated samples per condition. The approach leverages OpenSky data via the traffic library, with Zurich providing ~19K samples across 4 runways and Dublin providing ~20K samples without runway labels.

## Key Results
- Diffusion models achieve competitive performance with only 5% of Dublin data, matching full-data baselines around 20%
- Pretraining improves all evaluation metrics (energy distance, MMD, DTW) across all models compared to training from scratch
- Latent flow matching shows the largest relative gains despite starting from the weakest baseline
- Trajectory visualizations confirm realistic reproduction of dominant approach patterns while rare trajectories remain underrepresented

## Why This Works (Mechanism)

### Mechanism 1: Airport-Agnostic Kinematic Representation Enables Cross-Domain Transfer
Pretraining on data-rich airports reduces data requirements at data-scarce airports when models operate on kinematic features rather than geographic coordinates. By encoding trajectories as kinematic features (track, groundspeed, altitude, elapsed time) instead of raw latitude/longitude, the model learns flight dynamics that transfer across airports without encoding location-specific geometry. This prevents geographic leakage and allows the denoising or flow network to learn transferable approach patterns. Break condition: If target airport has fundamentally different operational procedures that violate kinematic similarity.

### Mechanism 2: Diffusion Denoising Captures Multi-Modal Trajectory Distributions More Sample-Efficiently
Diffusion-based architectures achieve better transfer performance than flow matching under limited target data regimes. The iterative denoising process captures conditional structure across approach corridors and runway patterns. The stepwise refinement aligns well with trajectory generation where paths share local geometric regularities even across airports. Break condition: If target distribution has discontinuous modes or extremely sparse rare patterns that diffusion's continuous denoising cannot bridge.

### Mechanism 3: Latent Space Compression Accelerates Training with Variable Transfer Gains
Latent variants (LDM, LFM) benefit from pretraining but with architecture-dependent effect sizes—LDM shows smaller gains than DM; LFM shows largest relative gains from a weak baseline. TCVAE compresses trajectories into lower-dimensional latent codes, reducing the generative model's input dimensionality. This accelerates training/sampling but introduces VAE reconstruction fidelity as a bottleneck. Break condition: If VAE reconstruction loss discards critical features for rare trajectories.

## Foundational Learning

- **Diffusion Probabilistic Models**
  - Why needed here: Core generative mechanism for the best-performing architecture; understanding forward/reverse processes explains why sample efficiency improves with pretraining
  - Quick check question: Can you explain why adding noise incrementally and learning to reverse it captures a data distribution?

- **Flow Matching (Continuous Normalizing Flows)**
  - Why needed here: Alternative generative paradigm tested; understanding velocity fields vs. denoising helps interpret why FM shows weaker/more variable transfer
  - Quick check question: How does learning a continuous-time velocity field from prior to data differ from diffusion's discrete denoising steps?

- **Transfer Learning in Generative Models**
  - Why needed here: The entire experimental design assumes pretraining transfers; understanding what knowledge transfers (kinematic patterns) vs. what must be relearned (local geometry) is essential
  - Quick check question: Why might a model pretrained on Zurich approach patterns fail zero-shot on Dublin despite both being landing trajectories?

## Architecture Onboarding

- **Component map:**
  - Trajectory sequences (T=200 timesteps) in kinematic representation [track, groundspeed, altitude, Δt] -> Optional VAE encoder -> (a) DiffTraj UNet with residual/attention blocks (DM/LDM), or (b) Flow matching network learning velocity fields (FM/LFM) -> Generated trajectory sequences; VAE decoder reconstructs from latent if applicable -> Evaluation pipeline (energy distance, MMD, DTW)

- **Critical path:**
  1. Data preprocessing → kinematic representation + standardization (separate scalers per airport)
  2. Pretraining on source airport (Zürich) → full training epochs
  3. Fine-tuning on target (Dublin) at data fractions s ∈ {0, 5, 20, 50, 100}%
  4. Generate N=100 condition-matched samples → evaluate against held-out test set

- **Design tradeoffs:**
  - DM vs. FM: DM offers stronger transfer with limited data; FM potentially faster sampling but variable transfer gains
  - Raw vs. Latent: Latent variants reduce compute but introduce VAE reconstruction error; LFM shows largest relative gains but starts from weaker baseline
  - Kinematic vs. Geographic: Kinematic enables transfer; geographic would leak location-specific patterns and break generalization

- **Failure signatures:**
  - Zero-shot (0% target data) performs markedly worse than baseline across all models → confirms kinematic features alone insufficient without target supervision
  - Rare trajectory modes (e.g., west-facing arrivals at Dublin) consistently underrepresented → indicates mode coverage limits not solved by transfer
  - MMD variability at larger data splits → suggests finite-sample effects with N=100 generations

- **First 3 experiments:**
  1. Baseline replication: Train DM from scratch on 100% Dublin data; verify reported e-distance (~0.66), MMD (~0.11), DTW (~29) metrics
  2. Minimal data probe: Fine-tune pretrained DM on 5% Dublin data; confirm DTW drops below baseline (target: ~23 vs. ~29) per Table II
  3. Architecture comparison: Run parallel LDM and LFM experiments at 20% data; expect LDM to follow DM pattern with smaller gains, LFM to show larger relative improvement from weaker baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can curriculum-based fine-tuning or targeted data augmentation improve the generation of rare trajectory patterns?
- Basis in paper: Authors state "Future work should explore strategies to better capture rare trajectory patterns, including targeted augmentation, curriculum-based fine-tuning" and note that rare modes like west-facing arrivals "remain underrepresented" across all models
- Why unresolved: Transfer learning reliably reproduces dominant corridors but consistently fails on low-frequency trajectory modes despite increasing target data to 100%
- What evidence would resolve it: Demonstrated improvement in coverage of rare trajectory clusters (via MMD, KL-divergence on underrepresented modes) without degradation of dominant corridor fidelity

### Open Question 2
- Question: Does incorporating weather or meteorological conditioning improve cross-airport transferability and trajectory realism?
- Basis in paper: Authors propose "multimodal conditioning (e.g., weather)" as a future direction
- Why unresolved: Weather significantly affects approach patterns, but current models condition only on airport/runway identity, missing a key source of trajectory variation
- What evidence would resolve it: Weather-conditioned models showing improved distributional metrics and qualitative alignment with weather-correlated trajectory variations

### Open Question 3
- Question: Do transfer gains generalize beyond the Zurich–Dublin pair to airports with substantially different operational characteristics?
- Basis in paper: Only one source–target pair is evaluated; both are mid-latitude European hubs with potentially similar operational profiles
- Why unresolved: Transferability may depend on source–target similarity, limiting applicability to diverse contexts (regional airports, different airspace structures)
- What evidence would resolve it: Multi-airport evaluation showing whether transfer gains persist or degrade with increasing operational dissimilarity between source and target

### Open Question 4
- Question: Would including altitude in evaluation metrics better capture the operational validity of generated trajectories?
- Basis in paper: Authors compute metrics "using longitude and latitude only—excluding altitude—to emphasize spatial alignment," but vertical profile accuracy remains unquantified
- Why unresolved: Altitude is included in training but excluded from evaluation, leaving vertical descent realism unassessed
- What evidence would resolve it: Ablation study with altitude-inclusive metrics and visualization of vertical descent profiles

## Limitations

- Transfer learning gains depend critically on kinematic representation and may not generalize to airports with fundamentally different operational procedures
- Latent variants introduce VAE reconstruction fidelity as a bottleneck that may discard critical features for rare trajectories
- Study conclusions are based on only two airports (Zurich and Dublin), limiting generalizability across diverse ATM environments

## Confidence

- **High Confidence**: Diffusion models achieving competitive performance with minimal target data (5%) is well-supported by quantitative metrics and visualizations across multiple experimental conditions
- **Medium Confidence**: The claim that kinematic representation enables transfer is supported but could be strengthened by ablation studies comparing geographic vs. kinematic pretraining directly
- **Medium Confidence**: Latent flow matching showing the largest relative gains is supported, but the weak baseline performance raises questions about whether gains reflect true transfer or baseline architectural limitations

## Next Checks

1. **Architecture Ablation**: Run parallel experiments comparing pretraining with geographic (lat/lon) vs. kinematic representations on Zurich→Dublin transfer to directly validate the mechanism
2. **Rare Trajectory Coverage**: Analyze west-facing arrival patterns specifically to quantify mode coverage improvements with transfer learning versus architectural limitations
3. **Multi-Airport Transfer**: Extend experiments to include a third airport (e.g., London Heathrow) to test whether transfer gains generalize beyond the Zurich→Dublin case