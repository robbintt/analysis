---
ver: rpa2
title: Mixture-of-Experts with Intermediate CTC Supervision for Accented Speech Recognition
arxiv_id: '2602.01967'
source_url: https://arxiv.org/abs/2602.01967
tags:
- accent
- speech
- expert
- training
- routing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of automatic speech recognition
  (ASR) for accented speech, where most models struggle with non-native accents due
  to limited training data diversity. To tackle this, the authors propose MOE-CTC,
  a Mixture-of-Experts (MoE) architecture with intermediate Connectionist Temporal
  Classification (CTC) supervision.
---

# Mixture-of-Experts with Intermediate CTC Supervision for Accented Speech Recognition

## Quick Facts
- arXiv ID: 2602.01967
- Source URL: https://arxiv.org/abs/2602.01967
- Authors: Wonjun Lee; Hyounghun Kim; Gary Geunbae Lee
- Reference count: 22
- Primary result: Up to 29.3% relative WER reduction on MCV-ACCENT over FastConformer baseline

## Executive Summary
This paper addresses the challenge of accented speech recognition by proposing MOE-CTC, a Mixture-of-Experts architecture with intermediate CTC supervision. The method uses accent-aware routing during training to encourage expert specialization for specific accents, then transitions to accent-agnostic inference without accent labels. Each expert is equipped with its own CTC head to align routing decisions with transcription quality, and a routing-augmented loss stabilizes optimization. Experiments on the MCV-ACCENT benchmark demonstrate consistent gains across seen and unseen accents in both low- and high-resource conditions.

## Method Summary
MOE-CTC integrates sequence-level MoE modules into a FastConformer encoder, with 5 experts (one per seen accent) and top-K routing. Each expert has its own CTC head with self-conditioning through residual projection back to hidden dimension. The training follows a two-stage approach: Stage 1 uses accent-aware routing with biasing and classification loss to encourage specialization, while Stage 2 removes accent supervision for accent-agnostic inference. The loss combines final CTC loss, expert-level routing-augmented loss, and accent classification loss during Stage 1.

## Key Results
- Up to 29.3% relative WER reduction over strong FastConformer baselines
- Largest improvements observed on unseen accents (up to 27.8% relative WER reduction)
- Consistent gains across both low- (100h) and high-resource (600h) settings
- Expert-level CTC supervision enables effective generalization to unseen accents

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Expert-level CTC supervision aligns routing decisions with transcription quality rather than just accent discrimination.
- Mechanism: Each expert has its own auxiliary CTC head; the local routing-augmented loss weights expert CTC losses by routing probabilities, so the router learns to assign higher weights to experts producing lower CTC loss.
- Core assumption: CTC loss correlates with downstream transcription quality across accents, and gradient flow through the weighted loss can shape routing behavior.
- Evidence anchors: [abstract] "Each expert is equipped with its own CTC head to align routing with transcription quality"; [Section 4.3] Equation 5 defines L_local coupling routing weights to expert-level CTC loss.
- Break condition: If CTC loss does not correlate with WER for a given accent, or if gradient magnitude through g × L_CTC is too weak to affect routing, this mechanism degrades.

### Mechanism 2
- Claim: Two-stage training (accent-aware → accent-agnostic) enables specialization followed by generalization to unseen accents.
- Mechanism: Stage 1 applies accent biasing and L_accent classification loss, forcing expert-accent alignment; Stage 2 removes these, allowing the router to reorganize based on recognition quality signals alone.
- Core assumption: Experts retain accent-specific patterns after Stage 1, and the router can learn to select them without explicit labels in Stage 2.
- Evidence anchors: [abstract] "accent-aware routing encourages experts to capture accent-specific patterns, which gradually transitions to label-free routing for inference"; [Section 7.1] Table 4 shows WER improvements with both stages.
- Break condition: If Stage 2 overwrites specialist representations, or if the router collapses to uniform selection, generalization gains are lost.

### Mechanism 3
- Claim: Residual CTC-projection pathway stabilizes expert signal integration across layers.
- Mechanism: Each expert's CTC logits are projected back to hidden dimension and combined via gating weights into a residual addition, propagating CTC-informed feedback downward.
- Core assumption: Projected CTC logits carry useful acoustic-phonetic information that benefits subsequent layers without disrupting main representations.
- Evidence anchors: [Section 4.3] "the residual pathway ensures that these CTC-informed signals are stably integrated back into the shared representation"; [Section A.4] Table 11 shows layer-wise sharing degrades WER vs. full separation.
- Break condition: If PROJ learns to ignore CTC logits, or if residual magnitude is too small/large, the pathway becomes ineffective or destabilizing.

## Foundational Learning

- **Connectionist Temporal Classification (CTC)**
  - Why needed here: CTC is the core ASR objective; understanding it is essential to grasp why intermediate and expert-level CTC supervision would help.
  - Quick check question: Can you explain why CTC marginalizes over all valid frame-to-label alignments and what the blank token's role is?

- **Sequence-level Mixture-of-Experts (MoE) routing**
  - Why needed here: MOE-CTC uses sequence-level (utterance-level) routing, not token-level; understanding mean-pooling and top-K selection clarifies how entire utterances are assigned.
  - Quick check question: Given pooled representation h̄ from Eq. 2, how would you compute top-2 routing probabilities for 5 experts?

- **FastConformer encoder architecture**
  - Why needed here: The MoE modules are inserted between FastConformer blocks; understanding the base encoder helps identify where to inject MoE and how dimensions flow.
  - Quick check question: What is the input/output dimensionality at the 4th, 8th, and 12th encoder blocks in the "Medium" configuration, and how does this affect expert FFN sizing?

## Architecture Onboarding

- **Component map:** FastConformer encoder → MoE modules at layers 4, 8, 12 → expert outputs weighted by routing → residual CTC feedback → continue

- **Critical path:**
  1. Forward pass: Encoder → MoE at layer ℓ → expert outputs weighted by g → residual CTC feedback → continue
  2. Loss computation: L_CTC (final) + β·L_local (expert-level) + γ·L_accent (Stage 1 only)
  3. Stage transition: Load best Stage 1 checkpoint → train 20 epochs with L_CTC only (or L_CTC + L_local for MOE-CTC)

- **Design tradeoffs:**
  - Number of experts: 5 matches seen accents; 8 experts improves WER slightly but adds parameters
  - CTC head sharing: Full separation best; layer-wise sharing cuts params ~5% for small WER increase
  - α (bias strength): Too high may over-constrain routing; too low may not induce specialization

- **Failure signatures:**
  - Router collapse: All g_j concentrate on one expert → reduced capacity utilization
  - Stage 2 divergence: WER increases sharply → router forgot specialist mappings
  - Unseen accent regression: WER higher than baseline → experts overfit to seen accents

- **First 3 experiments:**
  1. Replicate Small FastConformer baseline on MCV-ACCENT-100H → verify ~13.3% seen average WER matches Table 1.
  2. Add MoE with 5 experts (no accent supervision) → confirm improvement over baseline; analyze expert utilization histogram.
  3. Enable accent-aware routing (α=2) for Stage 1, then Stage 2 accent-agnostic → measure WER delta on unseen accents and plot routing confusion matrix.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can MOE-CTC effectively handle mixed or code-switched speech where accent boundaries are not discrete at the utterance level?
- Basis in paper: [explicit] The Limitations section states: "its sequence-level routing assumes discrete accent boundaries, which may not generalize to mixed or code-switched speech."
- Why unresolved: The current architecture assigns entire utterances to experts via mean-pooled routing, which cannot capture frame-level or intra-utterance accent variation common in bilingual speakers.
- What evidence would resolve it: Experiments on code-switched speech corpora (e.g., SEAME, Bangla-English) measuring WER and analyzing whether token-level routing outperforms sequence-level routing for such data.

### Open Question 2
- Question: How can MOE-CTC be adapted to fully unsupervised settings where no accent labels are available during any training stage?
- Basis in paper: [explicit] The Limitations section notes: "The model also relies on accent labels during early training, limiting applicability in unsupervised settings."
- Why unresolved: The two-stage training strategy depends on accent-aware biasing and classification loss in Stage 1; without labels, the mechanism for encouraging expert specialization is undefined.
- What evidence would resolve it: Developing and evaluating clustering-based pseudo-label generation for accent groupings, or self-supervised routing objectives that discover latent accent structure without supervision.

### Open Question 3
- Question: What is the quantitative computational overhead (latency, memory, FLOPs) of MOE-CTC compared to parameter-matched baselines?
- Basis in paper: [inferred] The Limitations section mentions "additional MoE modules increase training cost and latency," yet no timing or resource measurements appear in experiments.
- Why unresolved: Without overhead analysis, the practical deployment trade-off between WER improvements and computational cost remains unclear, especially for streaming or on-device ASR.
- What evidence would resolve it: Reporting inference latency (ms/audio-second), GPU memory footprint, and FLOPs for MOE-CTC versus FastConformer at equivalent parameter counts.

### Open Question 4
- Question: Do individual experts learn linguistically interpretable accent-specific features, or do they specialize along orthogonal acoustic dimensions?
- Basis in paper: [explicit] The Limitations section states: "analysis of expert interpretability remain future work."
- Why unresolved: While Figure 2 shows routing correlates with geographic/acoustic similarity, the paper does not probe what phonetic, prosodic, or spectral features each expert captures.
- What evidence would resolve it: Probing experiments (e.g., using TIMIT phoneme classification, prosody feature prediction) on expert activations to quantify accent-specific specialization versus shared representations.

## Limitations
- Sequence-level routing cannot handle mixed or code-switched speech with intra-utterance accent variation
- Requires accent labels during early training, limiting unsupervised applicability
- Additional MoE modules increase training cost and latency, though quantitative overhead is not reported

## Confidence

- **High Confidence:** Two-stage training approach (accent-aware → accent-agnostic) is well-supported by ablation results showing consistent WER improvements. Core architectural components are clearly specified and reproducible.
- **Medium Confidence:** Expert-level CTC supervision improves routing quality is plausible given loss formulation and ablation, but lacks direct evidence (e.g., routing visualization or expert-level WER analysis) to fully validate the mechanism.
- **Low Confidence:** Residual CTC-projection pathway is critical for stable integration is not empirically substantiated; no ablation or gradient analysis is provided to confirm its role.

## Next Checks
1. Log expert routing probabilities and compute per-expert WER on both seen and unseen accents; visualize routing entropy and confusion matrices to assess specialization and generalization.
2. Correlate expert-level CTC loss with downstream WER for each expert across accents; if correlation is weak, the claimed mechanism of CTC-driven routing may not hold uniformly.
3. Remove the CTC-projection residual connection and measure impact on WER, expert utilization, and training stability (e.g., loss variance, gradient norms) to directly test the claimed stabilizing effect.