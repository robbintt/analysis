---
ver: rpa2
title: Mitigating Clever Hans Strategies in Image Classifiers through Generating Counterexamples
arxiv_id: '2510.17524'
source_url: https://arxiv.org/abs/2510.17524
tags:
- cfkd
- counterfactual
- data
- spurious
- counterfactuals
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method called Counterfactual Knowledge Distillation
  (CFKD) to address the problem of Clever Hans predictors in deep learning models,
  which rely on spurious correlations rather than causal features. CFKD generates
  counterfactual examples that specifically modify confounding features while preserving
  causal features, then uses teacher feedback (human, oracle, or counterfactual analyzer)
  to determine which counterfactuals are valid.
---

# Mitigating Clever Hans Strategies in Image Classifiers through Generating Counterexamples
## Quick Facts
- arXiv ID: 2510.17524
- Source URL: https://arxiv.org/abs/2510.17524
- Authors: Sidney Bender; Ole Delzer; Jan Herrmann; Heike Antje Marxfeld; Klaus-Robert Müller; Grégoire Montavon
- Reference count: 40
- Primary result: CFKD achieves 20-40% average group accuracy gains across five diverse datasets compared to baseline methods

## Executive Summary
This paper addresses the problem of Clever Hans predictors in deep learning models, which rely on spurious correlations rather than causal features. The proposed method, Counterfactual Knowledge Distillation (CFKD), generates counterfactual examples that specifically modify confounding features while preserving causal features, then uses teacher feedback to determine valid counterfactuals. The method iteratively augments training data with these valid counterfactuals and retrains the model, distilling knowledge about true decision boundaries.

Unlike previous approaches that require group labels or struggle with low sample sizes, CFKD can implicitly discover confounders and generate new data points to enrich underrepresented groups. The method achieves strong performance improvements across five diverse datasets, particularly in low-data regimes with pronounced spurious correlations, and demonstrates robust scaling to multiple confounders without requiring prior knowledge of the confounding features.

## Method Summary
CFKD generates counterfactual examples by modifying confounding features while preserving causal features in the original training data. The method uses teacher feedback (human, oracle, or counterfactual analyzer) to determine which counterfactuals are valid, then iteratively augments the training set with these valid examples and retrains the model. This process distills knowledge about the true decision boundaries by exposing the model to examples that break spurious correlations. The key innovation is the ability to implicitly discover confounders and generate new data points to enrich underrepresented groups, addressing limitations of previous methods that require group labels or struggle with low sample sizes.

## Key Results
- CFKD achieves average group accuracy gains of 20-40% compared to baseline methods across five diverse datasets
- Particularly effective in low-data regimes where spurious correlations are most pronounced
- Demonstrates robust scaling to multiple confounders without requiring prior knowledge of confounding features
- Outperforms methods requiring group labels by implicitly discovering confounders

## Why This Works (Mechanism)
CFKD works by breaking the spurious correlations that Clever Hans predictors rely on. By generating counterfactual examples that modify confounding features while preserving causal ones, the model is forced to learn the true decision boundaries rather than relying on superficial patterns. The iterative retraining process with teacher feedback ensures that only valid counterfactuals are used, preventing the model from learning incorrect patterns from poorly generated examples.

## Foundational Learning
- **Counterfactual examples**: Modified inputs designed to test model robustness by changing specific features while preserving others. Needed to break spurious correlations. Quick check: Can generate examples that preserve class labels while changing confounding features.
- **Knowledge distillation**: Training a student model using outputs from a teacher model. Needed to transfer robustness knowledge from counterfactual examples. Quick check: Teacher model can accurately identify valid counterfactuals.
- **Spurious correlations**: Unintended statistical associations between features and labels that don't represent true causal relationships. Needed to understand Clever Hans problem. Quick check: Can identify and measure correlation between confounding features and labels.
- **Group robustness**: Model performance across different subgroups defined by confounding features. Needed to evaluate CFKD effectiveness. Quick check: Can measure accuracy differences across groups with varying confounding features.

## Architecture Onboarding
- **Component map**: Data -> CFKD generator -> Counterfactual examples -> Teacher feedback (oracle/analyzer) -> Valid counterfactuals -> Augmented training set -> Retrained model
- **Critical path**: CFKD generator -> Teacher feedback -> Augmented training -> Retraining loop
- **Design tradeoffs**: CFKD trades computational overhead of iterative retraining for improved robustness. The method requires oracle access or a reliable counterfactual analyzer, which may not always be available.
- **Failure signatures**: Performance degradation when teacher feedback is unreliable or when confounding features are not visually distinct. Computational cost may become prohibitive for large-scale models.
- **First experiments**: 1) Baseline comparison on synthetic dataset with known confounders, 2) Ablation study removing teacher feedback to measure its importance, 3) Multi-confounder scaling test on dataset with 3+ confounding features

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but the evaluation suggests several areas for future work, including testing on non-image datasets, comparing different counterfactual analyzers, and measuring computational overhead for large-scale deployments.

## Limitations
- Effectiveness depends on oracle access or reliable counterfactual analyzer, which may not always be available
- Focused on image classification tasks with clear visual confounders, unclear how well it transfers to other modalities
- Iterative retraining procedure may be computationally expensive for large-scale models or datasets
- While claiming to discover confounders implicitly, specific mechanisms and potential failure modes are not thoroughly explored

## Confidence
- High confidence: CFKD's ability to improve group robustness when confounding features are visually distinct
- Medium confidence: Claims about implicit confounder discovery and performance in multi-confounder settings
- Medium confidence: Scalability claims given the computational overhead of iterative retraining

## Next Checks
1. Test CFKD on non-image datasets to verify cross-modal effectiveness and assess performance with non-visual confounders
2. Conduct controlled experiments comparing oracle-based CFKD with various heuristic counterfactual analyzers to quantify the performance gap
3. Measure and report the computational overhead of iterative retraining across different model sizes and dataset scales to establish practical deployment constraints