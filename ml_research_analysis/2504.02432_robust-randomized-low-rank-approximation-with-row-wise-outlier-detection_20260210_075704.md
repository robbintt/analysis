---
ver: rpa2
title: Robust Randomized Low-Rank Approximation with Row-Wise Outlier Detection
arxiv_id: '2504.02432'
source_url: https://arxiv.org/abs/2504.02432
tags:
- rows
- outlier
- robust
- error
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a scalable, non-iterative randomized algorithm
  for robust low-rank approximation under row-wise adversarial corruption. The method
  first reduces dimensionality via a Johnson-Lindenstrauss projection, then uses robust
  statistics (median and MAD) to detect and remove corrupted rows based on their projected
  norms.
---

# Robust Randomized Low-Rank Approximation with Row-Wise Outlier Detection

## Quick Facts
- arXiv ID: 2504.02432
- Source URL: https://arxiv.org/abs/2504.02432
- Authors: Aidan Tiruvan
- Reference count: 13
- Key outcome: Scalable non-iterative algorithm for robust low-rank approximation under row-wise adversarial corruption with near-optimal error bounds and linear runtime scaling.

## Executive Summary
This paper introduces a scalable, non-iterative randomized algorithm for robust low-rank approximation under row-wise adversarial corruption. The method first reduces dimensionality via a Johnson-Lindenstrauss projection, then uses robust statistics (median and MAD) to detect and remove corrupted rows based on their projected norms. Theoretical analysis shows that under a norm gap condition, the algorithm achieves near-optimal low-rank approximation error with high probability, with the error bound scaling linearly with the fraction of outliers and inversely with the gap size. Experiments on synthetic and real datasets confirm effective outlier detection and runtime that scales linearly with the number of rows, with typical relative errors on inliers below 1% and substantial speedups over robust alternatives.

## Method Summary
The algorithm combines randomized dimensionality reduction with robust statistical detection. It projects the data matrix using a Johnson-Lindenstrauss matrix to reduce dimensionality, then computes row-wise norms of the projected matrix. Using median and MAD of these norms, it establishes a threshold to identify and remove corrupted rows. The cleaned matrix undergoes standard randomized SVD to obtain the final low-rank approximation. The method is non-iterative, requires no prior knowledge of outlier locations, and provides theoretical guarantees under a norm gap assumption between clean and corrupted rows.

## Key Results
- Achieves near-optimal low-rank approximation error with high probability under norm gap condition
- Runtime scales linearly with number of rows, providing 2-3× speedup over robust alternatives
- Detection precision and recall remain above 95% for outlier fractions up to 40% when norm gap is sufficient
- Relative error on inliers typically below 1% in experiments on synthetic and real datasets

## Why This Works (Mechanism)

### Mechanism 1: Johnson-Lindenstrauss Projection Preserves Row Norm Geometry
- Claim: Projecting rows from n dimensions to s = O(1/ε² log((1-α)m/δ')) dimensions preserves clean row norms within (1 ± ε) distortion with high probability.
- Mechanism: Random projection matrix Ψ acts as an approximate isometry on the set of clean row vectors. The JL lemma guarantees that for any fixed row, ∥(AΨ)ᵢ∥² ≈ ∥Bᵢ∥² + bounded noise term, with distortion controlled by ε and failure probability controlled by sketch size s.
- Core assumption: Clean rows have sufficient signal-to-noise ratio (∥Bᵢ∥ ≥ κδ for κ > 1) and adversarial rows are separable by norm.
- Evidence anchors:
  - [abstract] "first compressing the data with a Johnson Lindenstrauss projection, our approach preserves the geometry of clean rows"
  - [section 3, Lemma 3.1] "(1 − ε) ∥Bᵢ∥² ≤ ∥(AΨ)ᵢ∥² ≤ (1 + ε) ∥Bᵢ∥² + Cδ²"
  - [corpus] Weak direct validation; related work on randomized PCA forests exists but uses different detection logic.
- Break condition: If s is too small or ε too large, norm distortion exceeds the gap γ between inliers and outliers, causing misclassification.

### Mechanism 2: Median/MAD Thresholding Achieves 50% Breakdown Robustness
- Claim: When α < 0.5, the median and MAD of projected row norms provide stable estimates of the clean row distribution, enabling reliable outlier separation.
- Mechanism: The median is unaffected by up to 50% contamination. MAD (scaled by 1.4826 for Gaussian consistency) estimates dispersion robustly. Threshold τ = μ̂ + cσ̂ (typically c=3) flags rows whose projected norms exceed "3-sigma" from the clean center.
- Core assumption: Projected clean row norms are approximately sub-Gaussian; adversarial rows have norms substantially exceeding the threshold.
- Evidence anchors:
  - [abstract] "Robust statistical techniques based on the median and median absolute deviation then enable precise identification"
  - [section 3.1, Lemma 3.2] "Assume the separation condition: (1−ε)(max∥Bᵢ∥ + Δ) > τ"
  - [corpus] No direct corpus validation of median/MAD for this specific JL-sketching pipeline.
- Break condition: If α ≥ 0.5, median can be corrupted; if projected norms are heavy-tailed, MAD underestimates dispersion, causing false positives.

### Mechanism 3: Norm Gap γ Enables Perfect Separation
- Claim: Under a sufficiently large norm gap γ = Δ / max∥Bᵢ∥, adversarial rows are perfectly distinguished from clean rows with high probability.
- Mechanism: After JL projection, clean rows concentrate near their true norms (bounded by Lemma 3.1), while adversarial rows retain their elevated norms (scaled by (1−ε)). If γ is large enough that even the lower bound of adversarial projected norms exceeds the upper bound of clean norms plus threshold margin, all rows classify correctly.
- Core assumption: Adversarial rows satisfy ∥Aⱼ∥ ≥ max∥Bᵢ∥ + Δ (deterministic gap); noise on clean rows is bounded.
- Evidence anchors:
  - [section 3, Lemma 3.2] "Then, with probability ≥ 1 − δ′, all adversarial rows satisfy ∥(AΨ)ⱼ∥ > τ"
  - [section 5.1.3, experiments] "when outlier scale = 10.0 and α ≤ 0.2... precision and recall close to 1.0"
  - [corpus] Limited; corpus papers address outlier detection under different models (e.g., tensor RPCA, adversarial exposure).
- Break condition: If γ is small (adversarial norms similar to clean), thresholding fails; iterative reweighting or coherence-based methods would be needed.

## Foundational Learning

- Concept: **Johnson-Lindenstrauss Lemma**
  - Why needed here: Explains why projecting to O(log m) dimensions preserves all pairwise distances (and thus norms) with controllable distortion.
  - Quick check question: If you project 10,000 vectors from 1000D to 100D with ε=0.1, what's the approximate probability all norms are preserved?

- Concept: **Median and MAD as Robust Location/Scale Estimators**
  - Why needed here: Justifies why median/MAD remain accurate when up to 50% of data is adversarially corrupted.
  - Quick check question: Why does MAD require scaling by 1.4826 to estimate σ for Gaussian data?

- Concept: **Low-Rank Approximation and Eckart-Young Theorem**
  - Why needed here: Explains why removing outliers then computing rank-k SVD yields near-optimal recovery of the clean matrix B.
  - Quick check question: What is the best rank-k approximation to a matrix in Frobenius norm, and why does SVD provide it?

## Architecture Onboarding

- Component map: Sketching Layer -> Norm Extraction -> Robust Thresholding -> Filtering -> Reconstruction
- Critical path: **Thresholding step** — if τ is too low, you lose clean rows (bias); if too high, you retain outliers (variance). The entire reconstruction quality hinges on this.
- Design tradeoffs:
  - **ε vs. s**: Smaller ε → larger sketch s → more accuracy but slower projection
  - **c (threshold constant)**: c=2.5 aggressive (more false positives), c=3.5 conservative (misses marginal outliers)
  - **Sparse vs. Gaussian Ψ**: Sparse is faster for sparse A; Gaussian more robust for dense A
- Failure signatures:
  - **High false positive rate**: Clean rows with marginal SNR (∥Bᵢ∥ ≈ δ) filtered out; manifests as visible artifacts in reconstruction
  - **High false negative rate**: Adversarial rows with small γ pass threshold; subspace error remains high
  - **Degenerate MAD (σ̂ = 0)**: All retained rows have identical projected norms; switch to trimmed estimators (Appendix A.5)
- First 3 experiments:
  1. **Vary α and outlier scale** on synthetic data (m=1000, n=500, k=10): Confirm detection breaks down near α≈0.4 and scale≈5×; plot precision/recall surface.
  2. **Ablate ε and c**: Sweep ε∈{0.05,0.1,0.15} and c∈{2.5,3.0,3.5}; measure relative error and subspace angle; identify Pareto-optimal region (likely ε≈0.1, c≈3.0).
  3. **Compare vs. baselines** (Outlier Pursuit, Coherence Pursuit, standard PCA) on synthetic + Olivetti Faces with occlusions: Report runtime, relative error, and subspace angle; expect 2-3× speedup over convex methods with comparable accuracy when γ is large.

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis relies on deterministic norm gap assumption that may not hold in practical settings with overlapping inlier-outlier norms
- 50% breakdown limit is inherent to median-based methods and cannot be overcome without additional assumptions
- Theory assumes fixed adversarial corruption patterns; adaptive or dynamically changing outliers are not addressed

## Confidence

- **High Confidence**: JL projection preserves row geometry within (1±ε) distortion; median/MAD thresholding achieves 50% breakdown; runtime scales linearly with m.
- **Medium Confidence**: The norm gap separation condition is sufficient for perfect detection; the proposed parameters (ε=0.1, c=3.0) are near-optimal in practice.
- **Low Confidence**: Performance guarantees extend seamlessly to heavy-tailed or sparse adversarial corruption models.

## Next Checks

1. **Norm Gap Sensitivity**: Systematically evaluate detection accuracy as γ varies from 1.1× to 10× the maximum clean row norm, identifying the critical threshold where precision/recall drops below 0.95.

2. **Breakdown Point Verification**: Test the algorithm on datasets with α=0.4, 0.45, 0.49 to empirically confirm the 50% breakdown limit and characterize the sharp transition in detection performance.

3. **Adaptive Outlier Scenarios**: Design experiments where adversarial rows have norms distributed between the clean row norms and the threshold, measuring how often borderline cases cause misclassification and whether reweighting strategies help.