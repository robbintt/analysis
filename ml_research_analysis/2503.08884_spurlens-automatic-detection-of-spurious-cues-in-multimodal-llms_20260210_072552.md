---
ver: rpa2
title: 'SpurLens: Automatic Detection of Spurious Cues in Multimodal LLMs'
arxiv_id: '2503.08884'
source_url: https://arxiv.org/abs/2503.08884
tags:
- spurious
- image
- object
- features
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SpurLens, a method to automatically detect
  spurious visual cues that cause object recognition and hallucination failures in
  multimodal large language models (MLLMs). The core idea is to use GPT-4 to propose
  potential spurious cues for objects and OWLv2 to rank images based on their presence,
  allowing computation of Spurious Gaps in model performance.
---

# SpurLens: Automatic Detection of Spurious Cues in Multimodal LLMs

## Quick Facts
- arXiv ID: 2503.08884
- Source URL: https://arxiv.org/abs/2503.08884
- Authors: Parsa Hosseini; Sumit Nawathe; Mazda Moayeri; Sriram Balasubramanian; Soheil Feizi
- Reference count: 40
- Primary result: Automated method reveals spurious visual cues cause up to 20.4% accuracy drops and 10x hallucination increases in MLLMs

## Executive Summary
This paper introduces SpurLens, a fully automated method to detect spurious visual cues that cause object recognition failures and hallucinations in multimodal large language models (MLLMs). The approach uses GPT-4 to propose potential spurious cues for objects and an open-vocabulary object detector (OWLv2) to rank images by cue presence, allowing computation of Spurious Gaps in model performance. Experiments demonstrate that removing these cues can reduce accuracy by up to 20.4% and increase hallucination rates by over 10x. The study finds spurious bias is a fundamental issue rooted in the visual encoder, not easily mitigated by prompt engineering or reasoning-based strategies.

## Method Summary
SpurLens operates through a four-step pipeline: (1) GPT-4 proposes potential spurious cues for each target object class, (2) OWLv2 ranks a dataset of target images based on detection confidence of these cues, (3) an MLLM evaluates the top-K (high-cue presence) and bottom-K (low-cue presence) ranked images, and (4) Spurious Gaps (PA Gap and HR Gap) are computed by comparing model performance between these groups. The method requires no human supervision, works across different datasets, and reveals that both MLLM language and vision encoders exhibit spurious biases. Experiments show that removing spurious cues reduces accuracy by up to 20.4% and increases hallucination rates by over 10x, indicating that spurious bias is a fundamental issue not easily mitigated by prompt engineering or reasoning-based strategies.

## Key Results
- Removing spurious cues reduces MLLM accuracy by up to 20.4% (PA Gap)
- Spurious cue presence increases hallucination rates by over 10x (HR Gap)
- Prompt engineering and reasoning-based strategies fail to close Spurious Gaps
- Visual encoder features show similar spurious biases when tested with linear classifiers

## Why This Works (Mechanism)

### Mechanism 1
Ranking images by the presence of automatically proposed visual cues can quantify the causal impact of those cues on model failure. SpurLens leverages GPT-4 to propose objects co-occurring with a target (e.g., "snow" for "dogsled"). It then uses an open-set object detector (OWLv2) to rank a dataset of target images based on the confidence score of these proposed cues. By comparing the model's accuracy on the top-K (high-cue presence) versus bottom-K (low-cue presence) ranked images, it calculates a "Spurious Gap" (PA Gap). Core assumption: The text-conditional object detector (OWLv2) aligns sufficiently with human perception to create meaningful separations between images with and without the cue. Evidence: [Section 4] defines the pipeline; [Section 5.1, Table 1] shows significant accuracy drops (up to 20.4%) validating the ranking methodology; [Corpus] MM-SpuBench supports automated benchmarking feasibility. Break condition: If the object detector produces high false positive rates, the Spurious Gap metric becomes noisy and uncorrelated with model behavior.

### Mechanism 2
Spurious visual cues act as triggers for object hallucination in MLLMs, independent of the target object's actual presence. The paper posits that MLLMs learn strong priors linking objects to their typical contexts (e.g., "fire hydrants" appear on "streets"). When an image contains the context (the spurious cue) but lacks the object, the model's internal probability for the object token is elevated, leading to a false positive report. This is measured by the Hallucination Rate Gap (HR Gap). Core assumption: The failure is driven by learned correlations rather than random noise or confusion with visually similar objects. Evidence: [Section 5.2] shows hallucination rate is significantly higher when spurious cues are present; [Figure 4] demonstrates specific cases where cues trigger hallucinations; [Corpus] COPO and Causal-LLaVA target background-answer correlations supporting background cues as primary drivers. Break condition: If the model employs rigorous verification steps (e.g., "look specifically for the object shape before answering"), the correlation between background cue presence and hallucination rate should theoretically decouple.

### Mechanism 3
Standard language-based interventions (prompt engineering) are insufficient to mitigate spurious bias because the bias is anchored in the visual encoder embeddings. The paper demonstrates that instructing the model to ignore cues or using Chain-of-Thought (CoT) reasoning does not close the Spurious Gap. It suggests the visual features themselves (processed by the encoder before the LLM adapter) already contain spurious correlations that the LLM component cannot easily "unsee" via text instructions. Core assumption: The visual encoder (e.g., CLIP or SigLIP variants) propagates spurious correlations that persist through the projection layers. Evidence: [Section 6.2] shows none of the strategies perform significantly better; [Section 6.3] demonstrates linear classifiers on frozen vision encoder features exhibit similar Spurious Gaps; [Corpus] existence of complex mitigation strategies supports simple prompting is inadequate. Break condition: If the model is fine-tuned with contrastive learning designed to separate object features from background features, the reliance on text prompts to mitigate bias would likely decrease.

## Foundational Learning

- **Open-Vocabulary Object Detection (e.g., OWLv2)**: Why needed: SpurLens relies on detecting arbitrary objects (like "tooster" or "feeder") without retraining. Understanding these detectors use image-text alignment (like CLIP) is crucial for understanding why they can identify "spurious cues" proposed by a text LLM. Quick check: Can a standard YOLOv8 model (trained on COCO classes only) replace OWLv2 in this pipeline? (Answer: No, it cannot detect arbitrary text concepts like "turbine" or "gymnast" reliably if not in its training set).

- **Spurious Correlation (Shortcut Learning)**: Why needed: This is the core failure mode. You must understand that models often optimize for the easiest predictive signal (e.g., "snow" predicts "wolf") rather than the causal feature (the wolf itself). Quick check: If a model achieves 90% accuracy on a dataset where 90% of "wolf" images contain snow, how do we know it isn't just detecting snow? (Answer: We evaluate on the 10% of wolf images without snow, or the "wolf-free" images with snowâ€”exactly what SpurLens automates).

- **Token Dropping (Visual Ablation)**: Why needed: Section 6.1 uses "token dropping" to prove hallucination. Understanding that MLLMs process images as a sequence of tokens (like words) allows researchers to artificially "delete" an object from the visual context to see if the model still "sees" it based on context alone. Quick check: If you drop the visual tokens for a "keyboard" but the model still says "I see a keyboard," what does this prove? (Answer: The model is guessing based on the remaining context/desk features, not the visual input).

## Architecture Onboarding

- **Component map:** GPT-4 (Cue Proposal) -> OWLv2 (Dataset Ranking) -> MLLM (Evaluation Subject) -> Metric Calculator (PA Gap and HR Gap computation)

- **Critical path:** The **Dataset Ranking** step is the bottleneck. The quality of the Spurious Gap depends entirely on the precision of OWLv2. If OWLv2 gives high scores to images that *do not* contain the cue (false positives), the "low cue" group will be contaminated, shrinking the measured gap and hiding the bias.

- **Design tradeoffs:** Automation vs. Precision: SpurLens is fully automated (no human labeling) but relies on GPT-4's "common sense" which might miss rare, class-specific spurious features a human expert would catch. Detector Choice: The paper notes GroundingDINO has higher false positives than OWLv2 for this task. Choosing a faster but less precise detector would degrade the signal-to-noise ratio of the Gap metrics.

- **Failure signatures:** Low Gap (False Negative): If the gap is near zero, it implies either (a) the model is perfectly robust (unlikely), or (b) the object detector failed to separate the images effectively. High Hallucination on Blanks (HRb): Table 4 shows that for some models, hallucination rates on *blank black images* are non-zero. This indicates a strong language prior bias that exists without any visual input at all.

- **First 3 experiments:** (1) Sanity Check (Bird/Feeder): Run the SpurLens pipeline on the "Bird" class with the "Feeder" cue using a small sample (N=50). Verify that the top-ranked images actually contain bird feeders and the bottom-ranked ones do not. (2) Detector Ablation: Swap OWLv2 for a different open-vocabulary detector (e.g., GroundingDINO). Compare the correlation of the resulting rankings to see if the specific detector choice biases the discovery of cues. (3) Token Drop Validation: Take a "Person" class image, use the token-dropping script to remove the person tokens, and ask the MLLM "Is there a person?" Confirm that the hallucination rate increases when the spurious context (e.g., "street") remains.

## Open Questions the Paper Calls Out

- **Open Question 1:** What are the fundamental root causes of spurious bias in MLLMs? Basis: [explicit] The introduction states that "some key questions remain: from where do these biases originate," and the conclusion reiterates that the method "does not identify their root causes... this is an avenue for future work." Why unresolved: While ablation studies suggest the vision encoder is partially responsible, prompt engineering failed to resolve the issue, indicating the bias is deeply rooted and not yet fully understood. What evidence would resolve it: A causal analysis identifying specific training data distributions or architectural components that, when modified, eliminate the Spurious Gap.

- **Open Question 2:** Can robust mitigation strategies be developed to address spurious bias beyond prompt engineering? Basis: [explicit] The authors ask "can they be mitigated?" and later note that attempted strategies like prompt ensembling and reasoning-based prompting offered only "slight situational improvements" and failed to eliminate the gap. Why unresolved: The paper establishes that simple language-based interventions are insufficient, leaving the development of effective countermeasures as an open problem. What evidence would resolve it: A training intervention or architecture modification that significantly reduces or nullifies the Hallucination Rate (HR) Gap and Perception Accuracy (PA) Gap without degrading general performance.

- **Open Question 3:** Does SpurLens' focus on precision limit the detection of the full spectrum of spurious cues? Basis: [explicit] The authors state in the Method section: "SpurLens emphasizes precision, rather than recall or completeness: it aims to consistently and robustly find strong spurious cues, rather than the absolute best cue..." Why unresolved: The pipeline selects the single most influential cue per class, potentially overlooking compound biases or less prominent spurious features that contribute to model failure. What evidence would resolve it: A comparative analysis measuring the recall rate of SpurLens against a comprehensive, human-annotated set of all possible spurious cues for a given dataset.

## Limitations

- SpurLens relies on open-vocabulary object detector accuracy; measurement error occurs if the detector fails to perfectly separate images with and without the proposed spurious cue
- The paper demonstrates current mitigation strategies fail but does not prove spurious bias is fundamentally unmitigatable; more sophisticated visual debiasing techniques were not tested
- Experiments are limited to four specific MLLM models; the claim that spurious bias is fundamental across all MLLMs is not fully generalized to newer architectures

## Confidence

- **SpurLens can automatically detect spurious cues causing object recognition failures** - High Confidence
- **Spurious cues trigger object hallucinations independent of object presence** - High Confidence
- **Language-based interventions cannot mitigate spurious bias because the bias is in the visual encoder** - Medium Confidence

## Next Checks

1. **Ground Truth Validation:** Take the top-50 and bottom-50 ranked images from SpurLens for 5 different classes/cues. Have human annotators verify whether the proposed spurious cues are actually present in each image. Compare the human-grounded PA Gap to the detector-based PA Gap to quantify measurement error.

2. **Visual Debiasing Experiment:** Fine-tune one of the tested MLLMs (e.g., LLaVA-1.5) with a contrastive loss that explicitly pulls apart object features from background features. Re-run SpurLens on the fine-tuned model to test whether visual-level interventions can close the Spurious Gap, distinguishing between "hard to mitigate" and "impossible to mitigate."

3. **Cross-Architecture Generalization:** Apply SpurLens to at least two newer MLLM architectures (e.g., GPT-4V and Gemini) or to models with different vision encoders (e.g., SigLIP vs. CLIP). Compare the Spurious Gap magnitudes to test whether the bias is a fundamental property of the multimodal architecture or specific to the tested models.