---
ver: rpa2
title: 'The Multicultural Medical Assistant: Can LLMs Improve Medical ASR Errors Across
  Borders?'
arxiv_id: '2501.15310'
source_url: https://arxiv.org/abs/2501.15310
tags:
- medical
- corrected
- gemini
- speech
- soniox
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study evaluates the performance of ASR systems and LLM-based
  corrections across medical conversations in Nigeria, the UK, and the US, revealing
  significant disparities in transcription accuracy based on accents. Nigerian-accented
  speech showed the highest error rates, with MC-WER of 23.8% compared to 4.5% for
  US-accented speech.
---

# The Multicultural Medical Assistant: Can LLMs Improve Medical ASR Errors Across Borders?

## Quick Facts
- **arXiv ID**: 2501.15310
- **Source URL**: https://arxiv.org/abs/2501.15310
- **Reference count**: 40
- **Primary result**: LLM-based corrections improve lower-performing ASR systems for accented medical speech but degrade or minimally affect higher-performing systems

## Executive Summary
This study evaluates ASR performance and LLM-based corrections across medical conversations in Nigeria, the UK, and the US, revealing significant disparities in transcription accuracy based on accents. Nigerian-accented speech showed the highest error rates, with MC-WER of 23.8% compared to 4.5% for US-accented speech. LLM corrections improved lower-performing ASR systems substantially (e.g., reducing WER from 27.4% to 23.9% for Azure STT in Nigeria), but had minimal impact or degraded performance for higher-performing systems. Diarization performed consistently better than ASR across all datasets, with greater improvements observed for patient speech. The findings highlight the limitations of current ASR and LLM tools in handling accents and preserving medical terminology, emphasizing the need for more robust solutions, particularly for underrepresented accents.

## Method Summary
The study evaluates six ASR systems (Gemini 1.5 Pro, Azure STT, Whisper Large V3, NVIDIA Canary-1B, Amazon Transcribe Medical, Soniox) on three medical conversation datasets from Nigeria, UK, and US. A five-stage pipeline applies LLM-based corrections: ASR transcription → punctuation enhancement → diarization → correction → error analysis. The correction stage uses chain-of-thought prompting with medical domain knowledge, processing 20-second audio chunks for local models and 10-line segments for LLM tasks. Error metrics include standard WER, medical concept WER (MC-WER) using Google Healthcare NLP API, and speaker-attributed WER for diarization analysis.

## Key Results
- Nigerian-accented speech showed MC-WER of 23.8% compared to 4.5% for US-accented speech, a 19.3 percentage point difference
- LLM corrections reduced Azure STT WER from 27.4% to 23.9% for Nigerian speech but degraded Gemini 1.5 Pro WER from 10.2% to 12.9% when correcting itself
- LLM-based diarization outperformed native ASR diarization, with larger gains for patient speech than doctor speech across all datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-based post-hoc correction improves transcription accuracy specifically for lower-performing ASR systems, but degrades or minimally affects higher-performing systems.
- Mechanism: LLMs apply linguistic priors and medical domain knowledge to resolve orthographic variations and homophone confusions that ASR systems misclassify—particularly effective when the baseline ASR produces detectably erroneous outputs. When ASR outputs are already near-optimal, LLM "corrections" introduce new errors through over-interpretation.
- Core assumption: The LLM's training distribution includes sufficient medical terminology and accent-adjacent language patterns to distinguish valid corrections from hallucinations.
- Evidence anchors:
  - [section] "In the Intron Health dataset, NVIDIA Canary-1B's mean WER improved from 0.241 to 0.21, and Azure STT's from 0.274 to 0.239... For higher performing systems such as Gemini 1.5 Pro and Soniox, corrections yielded minimal improvements or negative effects."
  - [section] "Gemini 1.5 Pro's attempts to correct its own transcriptions consistently led to degraded performance, while Soniox showed modest improvements when corrected by Gemini 1.5 Pro."
  - [corpus] Weak corpus corroboration on the asymmetric correction effect; related work (Boros et al. 2024) evaluates foundation LLMs for post-transcription correction but does not systematically test the baseline-performance-correlation.
- Break condition: When ASR WER falls below ~10-12% on a given accent/dataset, LLM correction becomes net-negative or neutral.

### Mechanism 2
- Claim: LLM-based speaker diarization outperforms native ASR diarization in accented medical conversations, with larger gains for patient speech than doctor speech.
- Mechanism: LLMs leverage semantic role cues (technical vocabulary, question-answer pairs, symptom descriptions vs. clinical directives) to infer speaker identity, bypassing acoustic diarization limitations on diverse accents.
- Core assumption: Medical dialogue follows predictable discourse structure that LLMs can recognize without acoustic timestamps.
- Evidence anchors:
  - [section] "For patient speech, the Intron Health dataset showed the most marked improvement, with Claude 3.5 Sonnet + Gemini 1.5 Pro (mean: 0.208) outperforming Soniox (mean: 0.247) by 3.9 percentage points."
  - [section] "Doctor speech demonstrated consistently lower error rates than patient speech across all datasets... doctors typically follow more standardized patterns of medical discourse, while patients exhibit greater variability in accent and expression."
  - [corpus] Limited direct corroboration; Afrispeech-Dialog benchmark (arxiv 2502.03945) addresses African-accented conversations but does not isolate diarization.
- Break condition: When conversational structure is atypical (e.g., patient-led technical discussion, heavy code-switching), LLM diarization degrades.

### Mechanism 3
- Claim: ASR accuracy on medical concepts (MC-WER) shows larger cross-accent disparities than general WER, with error amplification for underrepresented accents.
- Mechanism: Medical terminology is phonetically dense and accent-sensitive; ASR models trained predominantly on Western English data misclassify accented pronunciations as phonologically similar non-medical terms (e.g., "hypertension" → "high tension").
- Core assumption: MC-WER captures clinically meaningful errors, though the paper notes it may underweight semantic severity (e.g., "amoxicillin" → "ampicillin" counted as single substitution).
- Evidence anchors:
  - [abstract] "Nigerian-accented speech showed the highest error rates, with MC-WER of 23.8% compared to 4.5% for US-accented speech."
  - [section] "This represents a 5.6 percentage point difference between PriMock57 and Fareez and a 19.3 percentage point difference between Intron Health and Fareez" for MC-WER.
  - [corpus] "WER is Unaware" (arxiv 2511.16544) argues WER does not correlate with clinical impact, supporting the paper's discussion of MC-WER limitations.
- Break condition: When medical terms are common in training data across accents (e.g., "diabetes" appears frequently in global corpora), MC-WER gaps narrow.

## Foundational Learning

- **Concept: Word Error Rate (WER) vs. Medical Concept Word Error Rate (MC-WER)**
  - Why needed here: Interpreting results requires understanding that MC-WER operates on medical entities as units, not independent words, and can both over- and under-represent clinical severity.
  - Quick check question: If "metformin" is transcribed as "warfarin," does MC-WER capture this as a substitution? What clinical concern does MC-WER not quantify?

- **Concept: Speaker Diarization Error Rate (DER) and speaker-attributed WER**
  - Why needed here: The paper uses word-level WER per speaker segment rather than timestamp-based DER; understanding this distinction is critical for reproducing metrics.
  - Quick check question: What does a higher speaker-attributed WER indicate about the combined transcription and diarization quality?

- **Concept: Chain-of-Thought (CoT) Prompting for Multi-Step Pipelines**
  - Why needed here: The correction and diarization stages use CoT prompts with explicit reasoning steps; understanding prompt design affects pipeline reproducibility.
  - Quick check question: What are the key reasoning steps in the diarization prompt, and why does the prompt instruct "look-around" analysis?

## Architecture Onboarding

- **Component map:** Audio Input → ASR Transcription (six systems) → Punctuation Enhancement → Diarization → Correction → Final Transcript → Error Analysis

- **Critical path:**
  1. ASR selection determines whether correction improves or degrades output (use lower-performing ASR for maximal LLM benefit)
  2. Diarization accuracy depends on conversational structure; patient speech is higher-risk
  3. MC-WER evaluation requires Healthcare NLP API for entity extraction before alignment

- **Design tradeoffs:**
  - **ASR choice:** High-performing ASR (Gemini 1.5 Pro, Soniox) reduces LLM correction value; lower-performing ASR (Azure STT, Canary-1B) benefits from correction but starts from higher baseline error
  - **LLM selection:** Self-correction (same model as ASR) is net-negative; cross-model correction (different training data/optimization) can improve results
  - **Diarization approach:** LLM-based diarization outperforms ASR-native but requires structured prompts and adds inference latency

- **Failure signatures:**
  - LLM correction increases WER for high-performing ASR → indicates over-correction/hallucination
  - Diarization WER spikes for patient speech in accented datasets → check prompt robustness for colloquial language
  - MC-WER shows large variance (±10%+ in some conditions) → indicates dataset size or annotation inconsistency

- **First 3 experiments:**
  1. Replicate ASR + LLM correction pairs on a held-out subset of Intron Health to validate the asymmetric improvement pattern (focus on Azure STT + Gemini 1.5 Pro correction)
  2. Ablate diarization prompt components (remove look-around reasoning, remove justification step) to isolate which prompt elements drive speaker-attribution accuracy
  3. Test correction on synthetic ASR outputs with controlled error types (orthographic vs. semantic substitutions) to characterize which error categories LLMs can reliably fix

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can integrating acoustic features from original audio into LLM-based correction pipelines improve error correction for accented medical speech?
- Basis in paper: [explicit] The authors state their "evaluation of LLM correction focused on text-based corrections without taking advantage of acoustic features of the original audio, potentially overlooking valuable phonetic cues for accent-specific error correction."
- Why unresolved: The study deliberately excluded audio-acoustic integration, leaving unexplored whether phonetic information could help distinguish accent-driven errors from actual medical terminology.
- What evidence would resolve it: A comparative study where LLM correction is augmented with acoustic embeddings or phonetic features, evaluated on the same cross-regional datasets.

### Open Question 2
- Question: What metrics beyond MC-WER can better capture the clinical significance of medical transcription errors?
- Basis in paper: [explicit] The authors note "while MC-WER quantifies errors in medical terminology, it does not capture the clinical significance of transcription errors, treating all substitutions equally regardless of their potential impact on patient care."
- Why unresolved: Current metrics treat all medical concept errors equivalently, but confusing "amoxicillin" for "ampicillin" has different clinical implications than minor orthographic variations.
- What evidence would resolve it: Development and validation of a clinically-weighted error metric that incorporates severity assessments from medical professionals or patient safety outcomes.

### Open Question 3
- Question: Would fine-tuning ASR systems on underrepresented accents yield greater improvements than LLM-based post-hoc correction?
- Basis in paper: [inferred] The authors evaluated "off-the-shelf ASR systems and LLMs without specialized fine-tuning" and found Nigerian-accented speech had MC-WER of 23.8% versus 4.5% for US-accented speech, with LLM correction providing only modest gains (e.g., 27.4% to 23.9% for Azure STT in Nigeria).
- Why unresolved: The study design precludes comparison between architectural improvements (fine-tuning) versus pipeline additions (LLM correction), leaving unclear which investment path is more effective.
- What evidence would resolve it: A controlled experiment comparing accent-specific ASR fine-tuning against LLM correction, measuring both accuracy gains and computational costs.

### Open Question 4
- Question: Can ensemble approaches combining multiple ASR systems with complementary strengths outperform single ASR-LLM pairs for medical transcription across accents?
- Basis in paper: [inferred] The authors observed that "combining models with complementary strengths—potentially arising from different training focuses, data sources, or optimization objectives—can lead to better overall performance" when Soniox corrected by Gemini outperformed Gemini self-correction.
- Why unresolved: Only pairwise ASR-LLM combinations were tested, not multi-system ensembles that could leverage diverse error patterns.
- What evidence would resolve it: Systematic evaluation of ensemble methods (voting, cascading, or mixture-of-experts) across the three regional datasets, with analysis of error complementarity between systems.

## Limitations
- Asymmetric LLM correction effects depend on specific ASR-LLM pairing choices and may not generalize to other combinations
- MC-WER metric may not fully reflect clinical significance of transcription errors, treating all medical concept substitutions equally regardless of severity
- Diarization approach relies on predictable medical dialogue structure that may not hold in atypical clinical scenarios

## Confidence
- **High confidence**: ASR accuracy disparities across accents (WER differences of 19.3 percentage points between Nigerian and US datasets are directly observable and reproducible)
- **Medium confidence**: Asymmetric LLM correction effects (mechanism is plausible and supported by results, but pairing-specific and requires broader validation)
- **Medium confidence**: LLM diarization outperforming native ASR (results show consistent improvements, but prompt design details are incomplete)

## Next Checks
1. Replicate the ASR + LLM correction experiment on a held-out subset of the Intron Health dataset to verify that correction improves Azure STT (WER reduction from 27.4% to 23.9%) but degrades Gemini 1.5 Pro when correcting itself
2. Test diarization accuracy on non-medical conversations with atypical structure (patient-led technical discussion) to identify failure conditions for the LLM-based approach
3. Conduct manual review of medical concept substitutions in MC-WER analysis to assess whether the metric captures clinically meaningful errors (e.g., distinguishing between "amoxicillin"→"ampicillin" vs. "amoxicillin"→"vitamin")