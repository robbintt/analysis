---
ver: rpa2
title: 'Krum Federated Chain (KFC): Using blockchain to defend against adversarial
  attacks in Federated Learning'
arxiv_id: '2502.06917'
source_url: https://arxiv.org/abs/2502.06917
tags:
- learning
- pofl
- accuracy
- backdoor
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tests the use of Proof of Federated Learning (PoFL)
  as a defense against adversarial attacks in federated learning (FL), finding it
  effective when at least one miner remains uncompromised. To address its vulnerability
  when all miners are compromised, the authors propose Krum Federated Chain (KFC),
  combining the Krum aggregation operator with PoFL.
---

# Krum Federated Chain (KFC): Using blockchain to defend against adversarial attacks in Federated Learning

## Quick Facts
- arXiv ID: 2502.06917
- Source URL: https://arxiv.org/abs/2502.06917
- Reference count: 40
- Primary result: KFC successfully defends against adversarial attacks in federated learning even when all miners are compromised

## Executive Summary
This paper addresses the vulnerability of federated learning systems to adversarial attacks by proposing Krum Federated Chain (KFC), a novel defense mechanism that combines blockchain consensus with Byzantine-robust aggregation. The authors build upon Proof of Federated Learning (PoFL), which uses a performance-based consensus mechanism but fails when all participating miners are compromised. KFC integrates the Krum aggregation operator into each miner's pool, filtering out malicious client updates locally before the blockchain consensus occurs. Experimental results demonstrate that while PoFL effectively defends against attacks when at least one miner remains uncompromised, KFC maintains robust performance under all attack configurations, achieving high accuracy on original tasks while minimizing backdoor attack success.

## Method Summary
The proposed KFC system uses a pooled-mining architecture where clients train local models and send updates to assigned miners. Each miner aggregates client updates using the Krum operator, which filters out outliers based on geometric distance, before evaluating the resulting model on a validation dataset. The PoFL consensus mechanism then selects the highest-performing model to add to the blockchain. The defense is evaluated against label-flipping Byzantine attacks and pattern-key backdoor attacks using EMNIST, Fashion MNIST, and CIFAR-10 datasets across two scenarios: one attacker total and one attacker per pool. The system is implemented using the FLEXible FL framework with a standard 2-layer CNN for MNIST datasets and EfficientNet for CIFAR-10.

## Key Results
- PoFL successfully defends against adversarial attacks when at least one miner remains uncompromised
- PoFL fails when all miners are compromised, allowing backdoor attacks to succeed
- KFC maintains high accuracy on original tasks and minimizes backdoor success even when all miners are adversarial
- KFC outperforms both standalone PoFL and other aggregation methods like Trimmed-mean in all attack scenarios

## Why This Works (Mechanism)

### Mechanism 1
A performance-based consensus mechanism in a pooled-mining architecture can filter out adversarial model updates. Proof of Federated Learning (PoFL) uses a pooled-mining architecture where miners oversee distinct client groups. Miners aggregate client updates to create a model, then evaluate its accuracy on a predetermined test dataset. The pool whose model achieves the highest accuracy wins the consensus round, and its model is added to the blockchain. Adversarial attacks like Byzantine or backdoor attacks tend to degrade the main task's performance, making poisoned models less likely to win. This works under the assumption that at least one pool exists with no adversarial clients. If all pools are compromised, every model submitted to the consensus will be poisoned, and the system will select the "best" among poisoned models, which can still result in a successful backdoor attack or degraded global model.

### Mechanism 2
Combining Byzantine-robust aggregation with a blockchain architecture provides defense even when all consensus-participating nodes are compromised. The Krum Federated Chain (KFC) integrates the Krum aggregation operator into each miner's pool within the PoFL architecture. The Krum operator filters client updates within a pool by sorting them based on geometric distance and selecting the update closest to the majority, thereby removing outliers (which are often adversarial). This produces a cleaner local model for the miner to submit to the blockchain consensus, making the system resilient even if all pools contain some malicious clients. The core assumption is that Krum can successfully identify and exclude malicious updates within a pool, provided they are a minority or their updates are sufficiently distinct from benign ones. The system will fail if adversarial clients within a single pool become the majority, or if they craft updates that are not geometric outliers.

### Mechanism 3
A two-tiered defense using local aggregation filtering and global performance-based consensus provides a more robust defense than either mechanism alone. KFC operates as a defense-in-depth strategy. At the local tier (pool level), the Krum operator cleans the updates received from clients. At the global tier (blockchain level), the PoFL consensus mechanism compares the resulting models from different miners, adding a final selection layer. This means an attack must first evade the Krum filter within its pool and then produce a model that outperforms other pools' models on the main task. The two defenses are not perfectly correlated in their failure modes, so an attack that might fool the consensus might be caught by the aggregation filter, and vice-versa. The system's overall security is bounded by its most vulnerable component in a specific attack scenario.

## Foundational Learning

- **Concept: Federated Averaging (FedAvg)**: This is the baseline aggregation method used in the paper's control experiments and within the PoFL pools before the Krum operator is applied. Understanding it is essential to see what Krum modifies. *Quick check: How does FedAvg combine model updates from different clients, and why is it vulnerable to a single malicious update?*

- **Concept: The Krum Aggregation Operator**: Krum is the core defensive component of the KFC system. It replaces simple averaging within each pool to provide Byzantine resilience. *Quick check: What metric does the Krum operator use to select the most representative client update, and what is its main computational cost?*

- **Concept: Consensus Mechanisms (Proof of Work vs. Proof of Federated Learning)**: The paper evaluates if the choice of consensus mechanism itself can be a defense. PoFL is specifically designed for FL and forms the second defensive tier in KFC. *Quick check: How does the "useful work" in PoFL differ from the computational puzzle in Proof of Work, and how does this relate to model selection?*

## Architecture Onboarding

- **Component map**: Clients -> Miners (Pools) -> Blockchain Network -> Consensus Layer (PoFL)
- **Critical path**: Client local training -> Send update to miner -> Miner aggregates using Krum -> Miner evaluates model on validation set -> Miner broadcasts model for consensus -> Winning model is committed to blockchain -> All miners update their local blockchain copy and broadcast new global model to clients
- **Design tradeoffs**: KFC offers stronger, more comprehensive security at the cost of higher computational complexity due to the Krum operator's O(n² · d) scaling with the number of clients in a pool. The decoupled pooled-mining design may improve scalability and fault tolerance but introduces the assumption that pools are somewhat independent. The Krum parameter `f` must be set carefully - an overestimate reduces accuracy by excluding too many updates while an underestimate lets attacks through.
- **Failure signatures**: PoFL Failure: In Scenario B (all miners attacked), a steady decline in the global model's original task accuracy combined with high backdoor success indicates the consensus mechanism is selecting from a set of entirely poisoned models. Krum Failure: A failure would be seen if a backdoor attack achieves high success on the backdoor task while maintaining performance on the main task, suggesting adversarial updates are not being identified as outliers.
- **First 3 experiments**: 1) Baseline Test (Client-Server): Run a standard FL simulation with FedAvg under the two attack scenarios to quantify baseline vulnerability. 2) PoFL Validation Test: Run the simulation with the PoFL architecture to confirm that in the single-attacker scenario, the global model maintains high accuracy, but in the all-attacker scenario, it fails. 3) KFC Stress Test: Run the simulation with the KFC architecture in the all-attacker scenario to verify that the global model retains high main task accuracy and minimizes backdoor success.

## Open Questions the Paper Calls Out

- Can the Krum aggregation operator within the KFC framework be replaced by a more computationally efficient alternative without compromising defense capabilities?
- Is the KFC defense mechanism effective against more sophisticated backdoor attacks and privacy attacks?
- Can techniques designed to mitigate communication overhead be successfully integrated into the KFC architecture?

## Limitations

- The performance of both PoFL and KFC is likely sensitive to several unspecified hyperparameters, including the local learning rate, number of local epochs, and the Krum parameter `f`.
- The evaluation focuses on pattern-key backdoor attacks using model replacement, and effectiveness against other backdoor strategies or more sophisticated Byzantine attacks remains untested.
- The paper does not provide a detailed analysis of the computational overhead introduced by the Krum operator, especially for large client pools.
- The consensus mechanism relies on a validation dataset to select the winning model, which could be biased if not representative of the true data distribution.

## Confidence

- **High Confidence**: The core claim that PoFL fails when all miners are compromised (Scenario B) is strongly supported by the experimental results.
- **Medium Confidence**: The claim that KFC maintains robust performance under all attack configurations is supported by the results, but the lack of sensitivity analysis and testing against a broader range of attacks introduces uncertainty.
- **Low Confidence**: The claim that the two-tiered defense (Krum + PoFL) is significantly more robust than either mechanism alone is plausible but not rigorously proven.

## Next Checks

1. **Hyperparameter Sensitivity Analysis**: Systematically vary the local learning rate, number of local epochs, and the Krum parameter `f` to quantify their impact on the performance of PoFL and KFC.

2. **Expanded Attack Surface**: Evaluate the defenses against a wider range of adversarial attacks, including gradient alignment attacks, clean-label backdoors, and attacks that preserve main task accuracy.

3. **Scalability and Overhead Assessment**: Measure the computational time and memory usage of KFC as the number of clients per pool increases, comparing this overhead to the security benefits gained.