---
ver: rpa2
title: 'From Hawkes Processes to Attention: Time-Modulated Mechanisms for Event Sequences'
arxiv_id: '2601.09220'
source_url: https://arxiv.org/abs/2601.09220
tags:
- time
- attention
- event
- temporal
- series
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Hawkes Attention, a time-modulated attention
  mechanism derived from multivariate Hawkes processes. Unlike standard attention
  mechanisms that rely on positional encodings, Hawkes Attention integrates time directly
  by using learnable per-type neural kernels to modulate query, key, and value projections.
---

# From Hawkes Processes to Attention: Time-Modulated Mechanisms for Event Sequences

## Quick Facts
- **arXiv ID:** 2601.09220
- **Source URL:** https://arxiv.org/abs/2601.09220
- **Reference count:** 14
- **Primary result:** Hawkes Attention improves next event prediction (RMSE/time, error rate/type) on real-world MTPP datasets by replacing positional encodings with learnable per-type temporal decay kernels.

## Executive Summary
This paper introduces Hawkes Attention, a novel attention mechanism derived from multivariate Hawkes processes. The key innovation is replacing traditional positional encodings with learnable per-type neural kernels that directly modulate query, key, and value projections based on time differences between events. This design integrates time awareness into the attention mechanism itself, allowing the model to capture both temporal dynamics and content interaction in irregular event sequences. The approach is evaluated on multiple real-world datasets for next event prediction and extended to traditional time series forecasting, demonstrating competitive performance across diverse sequential data modeling tasks.

## Method Summary
Hawkes Attention modifies the Transformer self-attention mechanism by replacing additive positional encodings with multiplicative time modulation. For each event type c, a lightweight MLP parameterizes a temporal influence kernel ϕ_c(∆t) that modulates query, key, and value projections based on time differences between events. The intensity λ_c(t) is computed as a low-rank factorization β = UV^⊤, where each event type has an embedding v_c and a context vector u_c. The model is trained using Negative Log-Likelihood loss with Monte Carlo approximation for the survival integral. The architecture includes event embedding layers, per-type kernel MLPs, Hawkes Attention layers stacked with feed-forward networks, and an intensity head that maps hidden representations to intensity predictions.

## Key Results
- Hawkes Attention achieves lower RMSE (time prediction) and error rate (type prediction) compared to THP and other neural MTPP methods on real-world datasets.
- Ablation studies confirm that per-type kernels improve performance over shared kernels, particularly on datasets with distinct temporal dynamics per event type.
- Hawkes Attention can substitute for positional encodings, with ablation showing no consistent improvement when adding standard positional encodings to the model.
- The method extends successfully to traditional time series forecasting, achieving competitive results across diverse datasets.

## Why This Works (Mechanism)

### Mechanism 1: Per-Type Neural Influence Kernels
Assigning each event type its own learnable temporal decay kernel improves prediction accuracy over shared or fixed decays. For each event type c, a lightweight MLP parameterizes ϕ_c(∆t), allowing the model to learn heterogeneous influence patterns (excitation, inhibition, delayed peaks) rather than imposing a single exponential decay. Evidence shows per-type kernels improve RMSE on StackOverflow (1.370 vs. 1.410) and Taobao (0.134 vs. 0.137) versus shared kernel.

### Mechanism 2: Direct Time Modulation of Q, K, V (No Positional Encodings)
Multiplicative modulation of query, key, and value projections by elapsed time eliminates the need for positional encodings while preserving temporal awareness. Queries, keys, and values are scaled as Q_j,k = W^Q v_c_j ϕ_c_j(t_j − t_k), directly embedding time differences into attention logits. Evidence shows adding standard positional encodings to Hawkes Attention yields no consistent improvement, suggesting learned ϕ_c(∆t) already capture relevant temporal information.

### Mechanism 3: Low-Rank Factorization of Pairwise Influence
Decomposing the influence matrix β = UV^⊤ reduces quadratic parameter cost while enabling expressive type-type interactions via embeddings. Each event type c has an embedding v_c (identity) and context vector u_c (receptivity). The intensity λ_c(t) becomes an inner product between u_c and time-modulated history embeddings, enabling scalable learning of cross-type excitation.

## Foundational Learning

- **Concept: Marked Temporal Point Processes (MTPPs)**
  - Why needed here: Hawkes Attention is explicitly derived from multivariate Hawkes processes. Understanding conditional intensity λ_c(t|H_t) is essential to interpret how the model generalizes classical Hawkes to attention.
  - Quick check question: Can you explain the difference between a Poisson process and a self-exciting Hawkes process?

- **Concept: Transformer Self-Attention and Positional Encodings**
  - Why needed here: The method modifies core attention by replacing additive positional encodings with multiplicative temporal modulation. You must understand standard attention to see what is being replaced.
  - Quick check question: In a standard Transformer, why are positional encodings added to embeddings before attention?

- **Concept: Kernel Functions and Temporal Decay**
  - Why needed here: The per-type ϕ_c(∆t) kernels are learned decay functions. Interpreting their shapes (monotonic, plateauing, rebounding) requires intuition about influence kernels in point processes.
  - Quick check question: What does it mean if a kernel ϕ(∆t) is negative for some ∆t?

## Architecture Onboarding

- **Component map:** Event Embedding Layer → Per-Type Kernel MLPs → Hawkes Attention Layer → Stacked Encoder Layers → Intensity Head → Loss
- **Critical path:** Embedding → Kernel MLP(∆t) → Modulated Q/K/V → Attention weights → Context h(t) → Intensity → NLL loss. Time enters only through ∆t into kernel MLPs; no positional encodings anywhere.
- **Design tradeoffs:**
  - Per-type vs. shared kernel: Per-type is more expressive but risks overfitting on rare types. Shared is cheaper but loses type-specific nuance.
  - MLP kernel vs. parametric decay: MLP allows non-monotonic, flexible shapes but is less interpretable than fixed exponential.
  - Asymmetric (both Q and K modulation) vs. symmetric: The paper modulates both source and target, increasing expressivity but doubling kernel computations.
  - Assumption: The paper does not prove multiplicative modulation is optimal; it is motivated by Hawkes theory and empirically validated.
- **Failure signatures:**
  - NaN losses during training: Often caused by instability in kernel MLP outputs (large magnitudes). Apply gradient clipping or constrain MLP output range.
  - No improvement over THP baseline: Check if kernel MLPs are too small (underfitting) or too large (overfitting); tune phi_width and phi_depth.
  - Worse performance on regular time series: Multiplicative decay may struggle with periodic patterns; consider adding sinusoidal encodings as a fallback.
- **First 3 experiments:**
  1. Replicate THP vs. Hawkes Attention on one MTPP dataset (e.g., Amazon): Confirm RMSE and error rate improvements match Table 2/3. Verify kernel MLPs are learning non-trivial shapes by visualizing ϕ_c(∆t).
  2. Ablate per-type kernels: Replace per-type MLPs with a single shared kernel. Check if StackOverflow and Taobao degrade as in Table 4.
  3. Test on a synthetic Hawkes dataset with known kernels: Generate data from a multivariate Hawkes with defined exponential kernels; verify Hawkes Attention recovers approximate decay shapes and cross-type magnitudes β_c,ck.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several areas remain unresolved:
- Can the quadratic memory complexity be reduced via sparse or low-rank approximations without violating theoretical integrity?
- Does asymmetric modulation of queries and keys yield significantly different representational capabilities compared to symmetric modulation?
- To what extent do unconstrained MLP-based kernels align with classical parametric forms in sparse data regimes, and do they risk learning spurious high-frequency fluctuations?

## Limitations
- Performance on periodic or regularly spaced time series remains untested, as the focus is on irregular temporal data.
- Interpretability of learned kernel functions is promising but not rigorously quantified with metrics for alignment with ground-truth influence patterns.
- Computational overhead of per-type kernels scales linearly with the number of event types, which could be prohibitive for datasets with hundreds of categories.

## Confidence
- **High Confidence:** The core mathematical derivation of Hawkes Attention from multivariate Hawkes processes is sound and well-explained. The empirical improvements over THP on MTPP benchmarks are robust and well-documented.
- **Medium Confidence:** The claims about kernel interpretability and the sufficiency of multiplicative time modulation (vs. positional encodings) are supported by ablation studies but lack external validation on diverse temporal patterns.
- **Low Confidence:** The extension to traditional time series forecasting is promising but not deeply analyzed. The lack of comparison to specialized time series models limits the strength of these claims.

## Next Checks
1. **Synthetic Hawkes Test:** Generate a synthetic dataset from a known multivariate Hawkes process with defined exponential kernels. Train Hawkes Attention and visualize learned ϕ_c(∆t) to verify recovery of approximate decay shapes and cross-type magnitudes.
2. **Periodic Pattern Test:** Evaluate Hawkes Attention on a time series dataset with strong periodic patterns (e.g., hourly/daily/weekly cycles). Compare performance with and without sinusoidal positional encodings to test the limits of multiplicative time modulation.
3. **Kernel Stability Analysis:** Conduct a hyperparameter sweep on phi_width and phi_depth for a small MTPP dataset. Monitor for kernel collapse (flat outputs) and measure sensitivity of final performance to these architectural choices.