---
ver: rpa2
title: 'MARCO: A Cooperative Knowledge Transfer Framework for Personalized Cross-domain
  Recommendations'
arxiv_id: '2510.04508'
source_url: https://arxiv.org/abs/2510.04508
tags:
- marco
- domain
- recommendation
- learning
- domains
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MARCO addresses negative transfer issues in multi-source cross-domain
  recommendation (CDR) by proposing a multi-agent reinforcement learning framework
  where each agent handles an individual source domain. This cooperative approach
  manages credit assignment and mitigates distribution discrepancies among domains.
---

# MARCO: A Cooperative Knowledge Transfer Framework for Personalized Cross-domain Recommendations

## Quick Facts
- arXiv ID: 2510.04508
- Source URL: https://arxiv.org/abs/2510.04508
- Authors: Lili Xie; Yi Zhang; Ruihong Qiu; Jiajun Liu; Sen Wang
- Reference count: 40
- Key outcome: MARCO addresses negative transfer issues in multi-source cross-domain recommendation (CDR) by proposing a multi-agent reinforcement learning framework where each agent handles an individual source domain

## Executive Summary
MARCO introduces a novel multi-agent reinforcement learning framework for personalized cross-domain recommendations that addresses negative transfer issues common in multi-source CDR. The framework employs a cooperative approach where each agent manages an individual source domain, effectively handling credit assignment and mitigating distribution discrepancies among domains. By incorporating a multi-source personalized bridge for user preference transformation and an entropy-based action diversity penalty, MARCO demonstrates superior performance over state-of-the-art methods, particularly in cold-start scenarios.

## Method Summary
MARCO employs a multi-agent reinforcement learning framework where each agent is responsible for a specific source domain, allowing for cooperative knowledge transfer while minimizing negative transfer effects. The framework includes a multi-source personalized bridge that transforms user preferences across domains, addressing the challenge of heterogeneous user behavior patterns. An entropy-based action diversity penalty is introduced to stabilize training and ensure diverse recommendation actions. The cooperative mechanism enables effective credit assignment across multiple domains, while the personalized bridge handles the transformation of user preferences between source and target domains.

## Key Results
- MARCO achieves up to 32.6% improvement in MAE and 28.5% in RMSE compared to state-of-the-art methods
- Superior performance across various cold-start scenarios demonstrates robustness and generalization capabilities
- Experimental validation on four benchmark datasets confirms effectiveness of multi-agent cooperative approach

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to decompose complex multi-source CDR into manageable single-domain problems while maintaining cooperative knowledge transfer. Each agent's specialized handling of its source domain prevents the dilution of domain-specific patterns that often leads to negative transfer. The personalized bridge acts as a transformation layer that maps user preferences across domains while accounting for individual user behavior patterns, ensuring relevant knowledge transfer. The entropy-based action diversity penalty prevents agents from converging to suboptimal local policies by encouraging exploration of diverse recommendation actions.

## Foundational Learning
- **Multi-agent reinforcement learning**: Why needed - enables parallel processing of multiple source domains while maintaining domain-specific expertise; Quick check - verify each agent can independently learn effective policies before cooperative training
- **Negative transfer mitigation**: Why needed - prevents knowledge from irrelevant domains from degrading target domain performance; Quick check - measure performance degradation when including/excluding specific source domains
- **Personalized user preference transformation**: Why needed - accounts for individual user behavior variations across domains; Quick check - validate transformation accuracy on held-out user preference pairs
- **Entropy-based regularization**: Why needed - ensures diverse action selection and prevents premature convergence; Quick check - monitor policy entropy during training for stability

## Architecture Onboarding

**Component Map:**
Multi-source data -> Domain-specific agents -> Personalized bridge -> Entropy regularizer -> Cooperative coordinator -> Target domain recommendations

**Critical Path:**
User interaction data → Domain-specific agent training → Personalized bridge transformation → Entropy regularization → Cooperative knowledge aggregation → Target domain recommendation generation

**Design Tradeoffs:**
The multi-agent approach trades computational complexity for improved domain-specific modeling accuracy. While single-agent approaches might be more efficient, they often suffer from negative transfer effects. The personalized bridge adds transformation overhead but enables more accurate cross-domain user modeling. The entropy regularization introduces additional hyperparameters but provides crucial stability in training.

**Failure Signatures:**
- Performance degradation when domain distributions become too heterogeneous
- Convergence issues when entropy regularization parameters are improperly tuned
- Suboptimal knowledge transfer when source domains have limited overlap with target domain
- Increased computational cost with large numbers of source domains

**First Experiments to Run:**
1. Baseline comparison with single-agent CDR approaches on homogeneous domain pairs
2. Ablation study removing the personalized bridge to measure its contribution
3. Sensitivity analysis of entropy regularization parameters on training stability

## Open Questions the Paper Calls Out
None

## Limitations
- Scalability concerns with significantly different data distributions across domains
- Potential performance degradation with increasing number of heterogeneous source domains
- Reliance on benchmark datasets that may not reflect real-world complexity
- Additional hyperparameters introduced by entropy-based action diversity penalty

## Confidence
- **High Confidence**: Framework's ability to mitigate negative transfer and manage credit assignment across multiple source domains is well-supported by experimental results
- **Medium Confidence**: Reported performance improvements are robust within tested scenarios but may not generalize to all real-world conditions
- **Low Confidence**: Long-term stability and effectiveness in highly dynamic or heterogeneous domain environments remains uncertain

## Next Checks
1. Evaluate MARCO's performance on larger-scale, real-world datasets with higher domain heterogeneity and dynamic user behavior patterns
2. Conduct ablation studies to quantify individual contributions of the multi-source personalized bridge and entropy-based action diversity penalty
3. Test framework's robustness under varying levels of data sparsity and noise across source domains to assess practical deployment viability