---
ver: rpa2
title: 'LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer
  Integration'
arxiv_id: '2507.23167'
source_url: https://arxiv.org/abs/2507.23167
tags:
- ensemble
- confidence
- arxiv
- learning
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes LENS, a novel ensemble method for combining
  predictions from multiple LLMs by learning model-specific confidence from internal
  neural states. LENS uses lightweight linear predictors to estimate each model's
  confidence based on layer-wise hidden states and normalized probabilities, then
  selects the prediction from the most confident model.
---

# LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration

## Quick Facts
- arXiv ID: 2507.23167
- Source URL: https://arxiv.org/abs/2507.23167
- Authors: Jizhou Guo
- Reference count: 4
- One-line primary result: LENS outperforms traditional ensemble methods by learning model-specific confidence from layer-wise neural states

## Executive Summary
LENS introduces a novel ensemble method for combining predictions from multiple LLMs by learning model-specific confidence from internal neural states. The approach extracts layer-wise hidden states via logit lens, concatenates probabilities across layers, and trains lightweight linear predictors to estimate each model's confidence. At inference, it selects the prediction from the most confident model. Experiments across multiple-choice and boolean QA tasks demonstrate substantial improvements over traditional ensemble methods like majority vote and probability max, achieving up to 84.1% accuracy on BoolQ compared to 80.9% for probability max.

## Method Summary
LENS operates by extracting layer-wise hidden states from each LLM using the logit lens technique, which projects hidden states at each layer to vocabulary space to produce probability distributions. These probabilities are concatenated across all layers to form feature vectors that capture the model's reasoning trajectory. A lightweight linear predictor is trained for each model to estimate confidence based on these features, using binary cross-entropy loss on correctness labels. During inference, the system selects the prediction from the model with the highest estimated confidence, outperforming traditional ensemble methods that aggregate predictions through voting or weighted averaging.

## Key Results
- LENS achieves 84.1% accuracy on BoolQ vs 80.9% for probability max and 78.2% for majority vote
- Outperforms baselines across all six datasets: CoinFlip, BoolQ, PrOntoQA, ProofWriter, SWAG, and MathQA
- Demonstrates effectiveness with minimal training data (250 examples per dataset)
- Shows consistent gains across diverse model architectures including LLaMA-2-7B, Mistral-7B, BLOOM-7B1, GPT-J-6B, and Pythia-6.9B

## Why This Works (Mechanism)

### Mechanism 1: Layer-wise Hidden States Contain Confidence Signals
Internal representations at different layers encode signals predictive of final answer correctness. The logit lens technique projects each layer's hidden state to vocabulary space, revealing how certainty evolves through the network. Concatenating these layer-wise probabilities creates a feature vector that captures the model's reasoning trajectory, which a linear predictor learns to map to confidence scores.

### Mechanism 2: Max-Confidence Selection Leverages Model Heterogeneity
Rather than averaging or voting, selecting the maximally confident model's prediction exploits the fact that different models have complementary strengths. When one model is highly confident and correct, others may be uncertain or wrong. This approach outperforms aggregation methods when confidence predictors are well-calibrated.

### Mechanism 3: Model-Specific Confidence Patterns Enable Specialized Predictors
Each LLM architecture develops distinct internal representations, so a single universal confidence formula cannot capture all reliability patterns. Training individual linear predictors for each model allows the system to learn architecture-specific relationships between internal states and correctness, which is essential given the diversity of models tested.

## Foundational Learning

- **Concept: Logit Lens and Layer-wise Projections**
  - Why needed here: LENS extracts features by applying the language modeling head to hidden states at each layer. Without understanding this, you cannot implement or debug feature extraction.
  - Quick check question: Given a 32-layer transformer with vocab size 50K, what is the dimensionality of the concatenated feature vector fi for a single model on a 5-choice task?

- **Concept: Binary Cross-Entropy for Confidence Calibration**
  - Why needed here: The confidence predictor is trained with BCE loss where labels indicate correctness. Understanding this framing is essential for debugging training dynamics.
  - Quick check question: If a model achieves 70% accuracy on training data, what would be the expected average BCE loss for a random baseline predictor outputting p=0.5 for all instances?

- **Concept: Ensemble Diversity and Correlated Failures**
  - Why needed here: LENS assumes models have complementary strengths. If models fail together, max-confidence selection degrades.
  - Quick check question: Three models each with 70% individual accuracy vote. What ensemble accuracy do you expect if their errors are perfectly correlated vs. independent?

## Architecture Onboarding

- **Component map:**
  Input Query → [LLM_1 ... LLM_N] → Hidden States (all layers) → Logit Lens Projection → Layer-wise Probabilities → Concatenated Feature Vector f_i → Linear Predictor P_i → Confidence c_i → Max Selector → ŷ = y[argmax c_i]

- **Critical path:**
  1. Hook into each LLM to extract H_l (hidden state) at every layer for the last token
  2. Apply LayerNorm(H_l) @ W_lm to get logits per layer, then softmax for probabilities
  3. Concatenate [p^1; p^2; ...; p^L] into feature vector (dim = L × K where K = num choices)
  4. Train one linear layer per model: σ(W_i @ f_i) using BCE on correctness labels
  5. At inference, compute all c_i and return prediction from highest-confidence model

- **Design tradeoffs:**
  - Linear vs. non-linear predictor: Paper uses linear for simplicity (O(L) parameters). Non-linear may capture more but risks overfitting on 250 samples.
  - Max vs. weighted aggregation: Paper selects single best model. Weighted combination could be more robust but requires well-calibrated scores.
  - Train/test split (250/250): Very small. Assumption: patterns generalize, but this limits statistical confidence.

- **Failure signatures:**
  - Confidence predictors output ~0.5 everywhere (underfitting): features lack signal or learning rate too low
  - High training accuracy, low test accuracy (overfitting): reduce model capacity or increase regularization
  - All models selected equally (confidence uniform): check feature normalization or predictor initialization
  - Performance matches probability max baseline: layer-wise features may not add information beyond final layer
  - Correlated failures across models: ensemble ceiling is limited regardless of method

- **First 3 experiments:**
  1. **Layer ablation:** Train predictors using only final layer vs. all layers. Quantify how much intermediate layers contribute.
  2. **Dataset size sensitivity:** Vary training size (50, 100, 250, 500) to determine minimum data for reliable predictor training.
  3. **Cross-dataset transfer:** Train predictors on BoolQ, test on MathQA. Assess whether confidence patterns generalize across task types.

## Open Questions the Paper Calls Out

### Open Question 1
Can confidence predictors trained on one task (e.g., boolean QA) transfer effectively to different tasks or datasets (e.g., math reasoning) in a zero-shot manner? The paper explicitly calls for investigating whether confidence patterns learned from one dataset can transfer effectively to other datasets or tasks, but current experiments only evaluate within-dataset performance.

### Open Question 2
Do more sophisticated, non-linear confidence predictor architectures outperform the lightweight linear predictors used in the current study? The authors suggest designing more sophisticated confidence predictor architectures beyond linear layers as a technical enhancement, noting that while linear layers demonstrate efficiency, they may not capture the full complexity of confidence patterns.

### Open Question 3
Does the integration of Chain-of-Thought (CoT) prompting further enhance LENS's ensemble performance compared to the few-shot direct-answer setting? The paper lists the integration of advanced prompting techniques like chain-of-thought as a method to further enhance system capabilities, but current implementation uses few-shot direct-answer to maintain computational efficiency.

### Open Question 4
Is "Max Confidence" (selecting one model) the optimal aggregation strategy, or would weighted averaging of probabilities yield better results? While the method claims to allow for nuanced weighting, the implementation selects the single prediction with the highest confidence. The paper mentions alternative confidence aggregation strategies as future work.

## Limitations

- **Limited Data Efficiency**: Trains confidence predictors on only 250 examples per dataset, raising questions about robustness to noisy or unrepresentative training sets.
- **Task Generalization Boundary**: Demonstrates success across six tasks but does not explore cross-task transferability of confidence patterns.
- **Single-Stage Selection**: Selects one model's prediction rather than combining multiple confident models, potentially missing cases where weighted combination would outperform selection.

## Confidence

**High Confidence**: The core mechanism of extracting layer-wise probabilities via logit lens and training per-model linear confidence predictors is well-specified and theoretically sound. The empirical improvements over baselines are substantial and reproducible.

**Medium Confidence**: The claim that model-specific predictors outperform universal confidence heuristics is supported but could be stronger given the limited training data (250 examples).

**Low Confidence**: The assertion that LENS will generalize to tasks beyond QA (e.g., code generation, reasoning) lacks empirical support and remains untested.

## Next Checks

1. **Cross-Task Transferability Test**: Train confidence predictors on BoolQ, evaluate on MathQA. Measure performance degradation to assess whether learned confidence patterns transfer across task domains.

2. **Ensemble Combination Ablation**: Implement a weighted combination of top-2 confident models' predictions. Compare against max-confidence selection to determine if selection is optimal or if aggregation could improve robustness.

3. **Layer Importance Analysis**: Systematically ablate layers (using only final layer, final 2 layers, first half, etc.) to quantify how much intermediate layers contribute to confidence prediction accuracy. This validates whether the logit lens mechanism provides information beyond final-layer probabilities.