---
ver: rpa2
title: Scaffold-Aware Generative Augmentation and Reranking for Enhanced Virtual Screening
arxiv_id: '2510.16306'
source_url: https://arxiv.org/abs/2510.16306
tags:
- molecules
- scaffold
- active
- graph
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces ScaffAug, a scaffold-aware framework for
  virtual screening that addresses three key challenges: class imbalance, structural
  imbalance among active molecules, and the need for scaffold diversity in top predictions.
  The framework consists of three modules: an augmentation module that generates synthetic
  molecules conditioned on underrepresented active scaffolds using a graph diffusion
  model and scaffold-aware sampling, a self-training module that safely integrates
  these synthetic molecules with original data through confidence-based pseudo-labeling,
  and a reranking module that enhances scaffold diversity in top predictions using
  Maximal Marginal Relevance.'
---

# Scaffold-Aware Generative Augmentation and Reranking for Enhanced Virtual Screening

## Quick Facts
- arXiv ID: 2510.16306
- Source URL: https://arxiv.org/abs/2510.16306
- Reference count: 40
- Key outcome: ScaffAug framework consistently outperforms existing baselines on five therapeutic target classes, with DeepGIN variant achieving top performance across all evaluation metrics

## Executive Summary
This paper introduces ScaffAug, a scaffold-aware framework for virtual screening that addresses three key challenges: class imbalance, structural imbalance among active molecules, and the need for scaffold diversity in top predictions. The framework consists of three modules: an augmentation module that generates synthetic molecules conditioned on underrepresented active scaffolds using a graph diffusion model and scaffold-aware sampling, a self-training module that safely integrates these synthetic molecules with original data through confidence-based pseudo-labeling, and a reranking module that enhances scaffold diversity in top predictions using Maximal Marginal Relevance. Extensive experiments on five therapeutic target classes from the WelQrate dataset demonstrate that ScaffAug consistently outperforms existing baselines, with the DeepGIN variant achieving top performance across all evaluation metrics.

## Method Summary
ScaffAug operates in three stages: First, scaffold-aware sampling extracts active scaffolds, computes ECFP fingerprints, clusters via K-Means, and samples underrepresented scaffolds for augmentation. Second, DiGress performs scaffold-conditioned graph diffusion to generate chemically valid synthetic actives. Third, a self-training module integrates synthetic data through confidence-based pseudo-labeling, followed by MMR reranking to enhance scaffold diversity in top predictions. The framework uses DeepGIN as the primary GNN backbone and is evaluated on five therapeutic targets from the WelQrate dataset using nested cross-validation.

## Key Results
- ScaffAug consistently outperforms existing baselines across all five therapeutic targets tested
- The DeepGIN variant achieves top performance across all evaluation metrics (logAUC, BEDROC, EF100, DCG100)
- Scaffold-aware sampling significantly improves results compared to uniform sampling by better addressing structural imbalances
- The reranking module successfully increases scaffold diversity while maintaining or improving early enrichment performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Scaffold-aware sampling (SAS) mitigates structural imbalance by preferentially selecting underrepresented scaffolds for augmentation.
- Mechanism: SAS computes scaffold fingerprints (ECFP), clusters via K-Means, then assigns sampling weights inversely proportional to cluster frequency. This yields more synthetic samples from minority structural families, expanding training coverage in under-explored chemical regions.
- Core assumption: Underrepresented scaffolds in training data represent chemically valid regions of active space that models fail to learn due to data sparsity, not noise or annotation errors.
- Evidence anchors:
  - [abstract] "scaffold-aware sampling algorithm, designed to produce more samples for active molecules with underrepresented scaffolds"
  - [Section 3.1] "Our sampling procedure calculates weights inversely proportional to cluster frequencies, giving higher priority to less common structural patterns."
  - [corpus] Weak direct support; neighbor papers address active learning and generative design but not scaffold-balanced sampling specifically.
- Break condition: If underrepresented scaffolds are chemically dissimilar to true actives (e.g., decoys), augmentation may introduce label noise and degrade performance.

### Mechanism 2
- Claim: Scaffold-conditioned graph diffusion generates chemically valid synthetic actives while preserving core structural motifs.
- Mechanism: DiGress performs reverse diffusion on molecular graphs with a scaffold mask. During each denoising step, scaffold atoms/edges are fixed while surrounding regions are sampled from learned distributions. This ensures valid chemistry (valency rules) while exploring substituent space around known scaffolds.
- Core assumption: Preserving the scaffold maintains activity-relevant structural features; variation in side chains/moieties explores similar activity space.
- Evidence anchors:
  - [abstract] "generates synthetic data conditioned on scaffolds of actual hits using generative AI, specifically a graph diffusion model"
  - [Section 3.1, Eq. 1] G_t = m ⊙ s + (1 - m) ⊙ G_t—scaffold mask enforces conditional generation.
  - [Section 2.2] "However, such general-purpose methods ignore chemical valency rules, often producing invalid molecules that hinder training."
- Break condition: If generated molecules, while valid, occupy chemically inactive regions (scaffold preserved but decorations destroy binding), pseudo-labels will be wrong.

### Mechanism 3
- Claim: Confidence-based pseudo-labeling safely integrates synthetic molecules, filtering noisy labels.
- Mechanism: After warm-up training on original data, the model assigns pseudo-labels to G-DSA molecules only when prediction confidence exceeds threshold τ. High-confidence samples are merged with labeled data; low-confidence samples are discarded.
- Core assumption: High-confidence predictions on synthetic molecules correlate with true activity; the warm-up model has learned sufficient structure-activity patterns to filter effectively.
- Evidence anchors:
  - [abstract] "model-agnostic self-training module is then used to safely integrate the generated synthetic data... through confidence-based pseudo-labeling"
  - [Section 3.2] "assigns pseudo-labels only to those molecules where prediction confidence exceeds a predefined threshold τ"
  - [Section A.7, Figure 6] Direct augmentation (all generated labeled active) underperforms baseline; self-training outperforms.
  - [corpus] InstructMol (Cao et al., 2025) uses instructor model for reliability estimation—conceptually similar confidence-weighted integration.
- Break condition: If the warm-up model is miscalibrated (overconfident on wrong regions), pseudo-labels will reinforce errors.

### Mechanism 4
- Claim: MMR reranking improves scaffold diversity in top-k predictions without sacrificing early enrichment.
- Mechanism: Given ranked predictions, MMR iteratively selects molecules balancing model score (λ · σ(p_i)) against redundancy penalty ((1-λ) · maxSim). Lower λ prioritizes diversity; λ=1 recovers original ranking.
- Core assumption: Scaffold diversity in top predictions correlates with identifying novel actives missed by score-only ranking.
- Evidence anchors:
  - [abstract] "reranking module that improves VS by enhancing scaffold diversity in the top recommended set"
  - [Section 3.3, Alg. 2] MMR_i ← λ · σ(p_i) − (1−λ) · maxSim_i
  - [Section 4.2, Figure 3] "EF100 increases by 19.8% while SD_100 increases by 2%" for AID1798 scaffold split.
  - [corpus] No direct MMR-for-VS citations; retrieved papers focus on generative design, not post-hoc reranking.
- Break condition: Excessive diversity (λ→0) may select low-scoring molecules that are inactive, reducing enrichment.

## Foundational Learning

- **Molecular Scaffolds (Bemis–Murcko)**
  - Why needed here: Core framework units; SAS clusters on scaffolds, augmentation conditions on them, reranking promotes scaffold diversity.
  - Quick check question: Given a molecule, can you identify its scaffold (ring system + linkers) versus side chains?

- **Discrete Graph Diffusion (DiGress)**
  - Why needed here: The augmentation module uses DiGress for scaffold-conditioned generation; understanding forward/reverse processes is essential for debugging generation quality.
  - Quick check question: How does DiGress differ from continuous diffusion? Why does masking enable conditional generation?

- **Self-Training with Pseudo-Labels**
  - Why needed here: The self-training module determines which synthetic molecules are safe to use; poor filtering corrupts the training signal.
  - Quick check question: What happens to model performance if pseudo-labels have 30% error rate? How does the confidence threshold mitigate this?

- **Maximal Marginal Relevance (MMR)**
  - Why needed here: Reranking module directly implements MMR; tuning λ trades off score vs. diversity.
  - Quick check question: If λ=0.5 and two candidates have identical scaffolds but different scores, which does MMR select first?

## Architecture Onboarding

- **Component map:**
  - **Input:** Training molecules with activity labels; test library for screening.
  - **Augmentation Module:** (1) Extract scaffolds → (2) ECFP fingerprints → (3) K-Means clustering → (4) SAS sampling → (5) DiGress scaffold extension → (6) Validity filtering → G-DSA dataset.
  - **Self-Training Module:** (1) Warm-up on original data → (2) Pseudo-label G-DSA with threshold τ → (3) Merge D ∪ D'_conf → (4) Train with class balancing.
  - **Reranking Module:** (1) Model scores on test set → (2) Top-k candidates → (3) MMR rerank with λ → Final ranked list.

- **Critical path:** SAS sampling quality → DiGress generation validity → Pseudo-label accuracy → VS model learning. If early steps fail, later modules cannot recover signal.

- **Design tradeoffs:**
  - **SAS vs. uniform sampling:** SAS improves diversity but may over-represent rare (potentially noisy) scaffolds.
  - **τ threshold:** Higher τ reduces noise but discards more synthetic data; lower τ increases data but risks label corruption.
  - **λ in MMR:** Higher λ preserves enrichment but reduces novelty; lower λ increases diversity but may harm hit rate.

- **Failure signatures:**
  - **Low validity rate in G-DSA:** DiGress mask misconfiguration or insufficient reverse steps (T<50).
  - **Self-training underperforms baseline:** τ too low (noise) or warm-up too short (model uncalibrated).
  - **Reranking reduces EF100 substantially:** λ too low for dataset; diversity over-prioritized.
  - **Scaffold split performance collapses:** Model overfitting to training scaffolds; augmentation not covering test scaffold space.

- **First 3 experiments:**
  1. **Ablate SAS vs. uniform sampling:** Train with G-DSA from each; report EF100, DCG100, and UMAP coverage of generated molecules. Expect SAS to show broader spatial distribution and higher enrichment.
  2. **Sweep pseudo-label threshold τ:** Values [0.5, 0.7, 0.9, 0.95] on a single dataset (e.g., AID1798); track number of pseudo-labeled samples and validation BEDROC. Identify saturation point where more data yields diminishing returns or degradation.
  3. **Tune λ for MMR per dataset:** Grid search λ ∈ [0.3, 0.5, 0.7, 0.9, 1.0]; plot SD100 vs. EF100. Identify λ maximizing EF100 or achieving target SD100 with minimal EF100 loss. Note dataset-specific optimal values (per Figure 3, scaffold splits may benefit from lower λ).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can integrating protein target structures into the generative diffusion process improve the likelihood of target activity compared to the purely ligand-based ScaffAug approach?
- Basis in paper: [explicit] The authors state in Section 5 that future work could address the limitation of neglecting protein structures by "leveraging protein-aware diffusion models."
- Why unresolved: The current framework relies exclusively on ligand information, potentially missing key binding interactions that structure-based methods capture.
- What evidence would resolve it: A modified ScaffAug implementation incorporating protein structures that demonstrates statistically significant improvements in enrichment metrics over the ligand-only baseline.

### Open Question 2
- Question: Do alternative semi-supervised learning strategies for integrating synthetic data outperform the current confidence-based pseudo-labeling method?
- Basis in paper: [explicit] Section 5 notes that "alternative semi-supervised learning methods could be explored to combine unlabeled synthetic data with labeled examples more effectively."
- Why unresolved: The study restricts its methodology to confidence-based pseudo-labeling, leaving the relative efficacy of other integration techniques unknown.
- What evidence would resolve it: Comparative benchmarking of the ScaffAug framework using different semi-supervised techniques (e.g., consistency regularization) against the pseudo-labeling baseline on WelQrate datasets.

### Open Question 3
- Question: Does enforcing synthetic accessibility constraints during the augmentation module improve the practical feasibility of high-ranking candidates without degrading virtual screening performance?
- Basis in paper: [inferred] The limitations section highlights that "our generative approach... does not guarantee synthetic accessibility or practical feasibility."
- Why unresolved: While the model generates chemically valid molecules, it may propose structures that are prohibitively difficult or impossible to synthesize in a wet-lab setting.
- What evidence would resolve it: Retrosynthetic analysis of top-ranked generated compounds and experiments showing that filtering for synthetic accessibility maintains enrichment factors.

## Limitations
- The efficacy of scaffold-aware sampling depends on the assumption that underrepresented scaffolds represent valid but poorly sampled active regions rather than noise
- Self-training performance critically depends on warm-up model calibration and confidence threshold selection
- Optimal λ values for MMR reranking appear dataset-specific, suggesting limited generalizability across diverse chemical spaces

## Confidence

- **High Confidence:** The core mechanism of scaffold-conditioned generation using DiGress (Mechanism 2) is well-supported by the framework design and implementation details. The scaffold-aware sampling algorithm's inverse-frequency weighting approach is straightforward and theoretically sound.
- **Medium Confidence:** The effectiveness of the self-training module (Mechanism 3) is supported by ablation studies, but the optimal confidence threshold and its robustness across datasets remain unclear. The MMR reranking approach (Mechanism 4) shows consistent improvements but lacks direct literature support.
- **Low Confidence:** The fundamental assumption that structural imbalance among active molecules drives poor virtual screening performance requires more rigorous validation. The claim that SAS "significantly improves results" is supported by comparisons but could benefit from deeper analysis of which scaffolds benefit most.

## Next Checks

1. **SAS Ablation Analysis:** Perform detailed scaffold-level analysis comparing uniform vs. scaffold-aware sampling to identify which scaffold clusters show the greatest improvement in coverage and enrichment metrics.
2. **Pseudo-Label Quality Assessment:** Implement uncertainty quantification (e.g., Monte Carlo dropout) to evaluate the reliability of pseudo-labels across different confidence thresholds and assess the correlation between pseudo-label accuracy and downstream performance.
3. **Cross-Dataset λ Transferability:** Test whether the optimal λ values for MMR reranking can be transferred between similar target classes or if dataset-specific tuning is consistently required, providing insights into the module's generalizability.