---
ver: rpa2
title: 'CellVerse: Do Large Language Models Really Understand Cell Biology?'
arxiv_id: '2505.07865'
source_url: https://arxiv.org/abs/2505.07865
tags:
- cell
- data
- single-cell
- gene
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces CELLVERSE, a language-centric benchmark\
  \ designed to evaluate large language models (LLMs) on single-cell biology tasks.\
  \ The authors transform single-cell multi-omics data into natural language format\
  \ and formulate three hierarchical tasks\u2014cell type annotation, drug response\
  \ prediction, and perturbation analysis\u2014as question-answering problems."
---

# CellVerse: Do Large Language Models Really Understand Cell Biology?

## Quick Facts
- arXiv ID: 2505.07865
- Source URL: https://arxiv.org/abs/2505.07865
- Reference count: 40
- Large language models achieve only 42-61% accuracy on cell type annotation and fail to exceed random guessing on drug response prediction tasks

## Executive Summary
This paper introduces CELLVERSE, the first language-centric benchmark for evaluating large language models (LLMs) on single-cell biology tasks. The authors transform single-cell multi-omics data into natural language format and evaluate 14 LLMs ranging from 160M to 671B parameters across three hierarchical tasks: cell type annotation, drug response prediction, and perturbation analysis. Results reveal that while generalist LLMs demonstrate preliminary understanding of cell biology and outperform specialist models, all evaluated models struggle significantly, with drug response prediction performance no better than random guessing. The work establishes a new evaluation framework while highlighting the substantial challenges remaining in applying LLMs to biological data analysis.

## Method Summary
The authors developed CELLVERSE by converting single-cell multi-omics datasets into natural language representations, transforming three core biological tasks into question-answering problems. They evaluated 14 LLMs including both open-source models (C2S-Pythia, Qwen, Llama, DeepSeek) and closed-source models (GPT-4 family) across three hierarchical tasks: cell type annotation (identifying cell types from gene expression), drug response prediction (predicting sensitivity to compounds), and perturbation analysis (understanding biological effects of interventions). Performance was measured using accuracy and F1 scores, with few-shot in-context learning also tested. The benchmark represents a novel approach to assessing LLM capabilities in cell biology by leveraging natural language interfaces rather than traditional computational pipelines.

## Key Results
- Generalist LLMs (GPT-4, Qwen2.5) achieved 42-61% accuracy on cell type annotation, outperforming specialist models like C2S-Pythia
- No evaluated LLM demonstrated significant improvement over random guessing on drug response prediction tasks, with best models achieving only ~55% accuracy
- Few-shot in-context learning yielded limited gains and often degraded performance across all tasks
- Specialist models trained on single-cell data failed to outperform general-purpose LLMs despite domain-specific training

## Why This Works (Mechanism)
The CELLVERSE benchmark works by translating complex biological data into a format that LLMs can process through natural language reasoning. By converting single-cell multi-omics data into text-based representations, the framework enables LLMs to apply their reasoning capabilities to biological problems. The hierarchical task structure allows evaluation of different levels of biological understanding, from basic cell type identification to complex perturbation analysis. The question-answering format leverages LLMs' strengths in pattern recognition and inference while revealing their limitations in handling noisy, high-dimensional biological data. The benchmark exposes whether LLMs can truly understand biological concepts or are merely pattern-matching within the constraints of their training data.

## Foundational Learning
- **Single-cell multi-omics**: Simultaneous measurement of multiple molecular layers (transcriptome, proteome, etc.) in individual cells - needed to understand the complexity of biological data being processed; quick check: verify data includes RNA-seq, ATAC-seq, and protein measurements
- **Question-answering formulation**: Converting computational biology tasks into natural language queries - needed to leverage LLM reasoning capabilities; quick check: confirm all tasks can be expressed as answerable questions
- **In-context learning**: Providing examples within prompts rather than fine-tuning - needed to test LLM adaptability without retraining; quick check: measure performance with 0, 3, and 5-shot prompts
- **Biological hierarchy**: Cell type → drug response → perturbation reasoning - needed to assess different levels of biological understanding; quick check: validate task dependencies follow biological logic
- **Benchmark evaluation metrics**: Accuracy and F1 scores for classification tasks - needed to quantify LLM performance objectively; quick check: ensure metrics align with biological task requirements
- **Model scaling effects**: Performance differences across 160M to 671B parameter models - needed to understand if larger models inherently capture more biological knowledge; quick check: plot performance vs. parameter count

## Architecture Onboarding

### Component Map
Raw single-cell data → Text encoding → Prompt construction → LLM inference → Output parsing → Performance evaluation

### Critical Path
Text encoding → Prompt construction → LLM inference → Output parsing

### Design Tradeoffs
- **Text vs. numerical representation**: Natural language enables LLM reasoning but may lose data precision compared to matrix formats
- **Generalist vs. specialist models**: Generalists show better reasoning but lack domain-specific knowledge; specialists have biological training but underperform
- **Few-shot vs. zero-shot**: Few-shot provides guidance but introduces noise that degrades performance; zero-shot avoids noise but lacks task-specific context
- **Task complexity vs. evaluation clarity**: Hierarchical tasks provide nuanced assessment but increase benchmark complexity

### Failure Signatures
- Random guessing performance indicates fundamental inability to learn task mappings
- Degradation with few-shot examples suggests sensitivity to input noise
- Specialist model underperformance reveals limitations of domain-specific training approaches
- Performance ceiling around 60% accuracy indicates incomplete biological understanding

### Exactly 3 First Experiments
1. Test alternative text encodings of the same biological data to assess sensitivity to data formatting
2. Compare LLM performance against established computational methods (scVI, Seurat) on identical datasets
3. Evaluate the same models on additional cell biology tasks (trajectory inference, spatial analysis) to test domain generality

## Open Questions the Paper Calls Out
### Open Question 1
- Question: What architectural or training improvements would enable LLMs to significantly exceed random-guessing performance on drug response prediction tasks?
- Basis in paper: The authors state "in the widely studied drug response prediction task, none of the evaluated LLMs demonstrate significant performance improvement over random guessing," with the best model achieving only 55% accuracy.
- Why unresolved: Current LLMs fail to learn the mapping from cell state gene expression patterns to drug sensitivity, suggesting fundamental limitations in how biological signals are encoded or reasoned about.
- What evidence would resolve it: Demonstration of an LLM-based approach achieving >70% accuracy on the drug response prediction benchmark, with ablation studies identifying which modifications enabled the improvement.

### Open Question 2
- Question: Why does few-shot in-context learning fail to improve—and often degrade—performance on single-cell analysis tasks?
- Basis in paper: The authors observe that "few-shot in-context learning yields limited gains and often even degrades performance" and hypothesize noise in single-cell data hampers generalization, but do not validate this.
- Why unresolved: The mechanism by which noisy few-shot examples interfere with reasoning is unknown; whether this is due to data noise, prompt design, or LLM attention patterns remains untested.
- What evidence would resolve it: Controlled experiments varying few-shot sample quality vs. quantity, coupled with attention analysis showing how noisy examples misdirect model reasoning.

### Open Question 3
- Question: How can specialist models trained on single-cell data overcome their current failure to outperform general-purpose LLMs?
- Basis in paper: The authors note that specialist models (C2S-Pythia) "fail to make reasonable decisions across all sub-tasks" while generalist models show "preliminary understanding," suggesting overfitting or insufficient capacity/training data.
- Why unresolved: The tradeoff between domain-specific training and general reasoning capabilities is unclear; whether specialists need more data, better architectures, or different training objectives is unknown.
- What evidence would resolve it: Training specialist models with varying data scales and architectural configurations, comparing against fine-tuned generalist models to identify the critical factors for specialist success.

## Limitations
- Benchmark covers only three specific tasks within single-cell biology, leaving open whether LLMs would perform similarly on other domains like developmental trajectories or proteomics
- Evaluation relies on a specific text-based representation of single-cell data, and alternative encoding schemes might yield different performance patterns
- Comparison between generalist and specialist models shows performance differences, but reasons for these differences remain speculative

## Confidence
- High confidence: CELLVERSE represents the first benchmark specifically designed for evaluating LLMs on cell biology tasks
- Medium confidence: Generalist LLMs outperform specialist models on CELLVERSE tasks
- Medium confidence: Current LLMs demonstrate limited understanding of cell biology concepts
- Low confidence: The reasons why generalist models outperform specialist models

## Next Checks
1. Replicate the benchmark using alternative text encodings of single-cell data (e.g., different molecular feature representations) to assess sensitivity to data formatting
2. Test the same models on additional cell biology tasks not included in CELLVERSE (e.g., trajectory inference, spatial analysis) to evaluate domain generality
3. Compare LLM performance against established computational methods (e.g., scVI, Seurat) using identical datasets to contextualize the reported accuracy metrics