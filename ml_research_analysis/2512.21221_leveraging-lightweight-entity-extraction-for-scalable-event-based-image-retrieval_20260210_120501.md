---
ver: rpa2
title: Leveraging Lightweight Entity Extraction for Scalable Event-Based Image Retrieval
arxiv_id: '2512.21221'
source_url: https://arxiv.org/abs/2512.21221
tags:
- retrieval
- arxiv
- image
- visual
- entity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a two-stage retrieval framework that combines
  lightweight entity extraction with multimodal deep learning for event-based image
  retrieval. The method first uses BM25-based filtering with named entity recognition
  to narrow down candidate articles, then applies dual BEiT-3 models to rerank and
  retrieve images.
---

# Leveraging Lightweight Entity Extraction for Scalable Event-Based Image Retrieval

## Quick Facts
- arXiv ID: 2512.21221
- Source URL: https://arxiv.org/abs/2512.21221
- Reference count: 19
- mAP of 0.559 on OpenEvents v1, outperforming baselines by 73%

## Executive Summary
This paper introduces a two-stage retrieval framework that combines lightweight entity extraction with multimodal deep learning for event-based image retrieval. The method first uses BM25-based filtering with named entity recognition to narrow down candidate articles, then applies dual BEiT-3 models to rerank and retrieve images. Evaluated on the OpenEvents v1 benchmark, the approach achieves a mean average precision of 0.559, outperforming strong baselines by 73%. The framework effectively balances computational efficiency and retrieval accuracy, particularly for long, context-rich queries.

## Method Summary
The proposed framework consists of two stages: (1) BM25-based retrieval combined with named entity recognition (NER) using spaCy, where articles are indexed in Elasticsearch with entity weights (PERSON=4.3, CARDINAL=3.5, ORG=3.8, GPE=3.1), and queries are expanded using WordNet via NLTK; (2) Dual BEiT-3 Base reranking, where one model is fine-tuned on OpenEvents training data (frozen visual encoder) and another uses pretrained weights, with scores combined via sigmoid boosting and reciprocal rank fusion (RRF). The system processes queries by extracting entities, performing parallel entity matching and BM25 retrieval, fusing results, and selecting top-K articles for reranking.

## Key Results
- Achieves mAP of 0.559 on OpenEvents v1 benchmark
- Outperforms baselines by 73% on primary metric
- Demonstrates effective handling of long, context-rich queries

## Why This Works (Mechanism)
The framework succeeds by combining symbolic filtering (NER + BM25) with deep multimodal representations, allowing efficient narrowing of candidates before applying computationally expensive reranking. Entity-specific weights prioritize the most informative entities for event retrieval, while WordNet expansion captures semantic variants. The dual-model approach leverages both task-specific fine-tuning and general pretraining to capture diverse aspects of relevance.

## Foundational Learning
- **Named Entity Recognition (NER)**: Identifies PERSON, ORG, GPE, CARDINAL entities from text; needed for semantic filtering of candidates; quick check: run spaCy on sample queries to verify entity extraction quality.
- **BM25 ranking**: Probabilistic retrieval model using term frequency and inverse document frequency; needed for efficient initial filtering; quick check: verify BM25 scores correlate with relevance on sample articles.
- **BEiT-3 multimodal model**: Unified vision-language transformer for image-text matching; needed for capturing cross-modal semantic alignment; quick check: run image-text pairs through BEiT-3 to verify similarity scores.
- **Reciprocal Rank Fusion (RRF)**: Combines multiple ranked lists by summing reciprocal ranks; needed to merge heterogeneous retrieval signals; quick check: fuse two small ranked lists and verify RRF ordering.
- **Fine-tuning strategy**: Freezes visual encoder while updating language model; needed to adapt to domain-specific queries while preserving visual features; quick check: compare frozen vs. full fine-tuning on validation set.
- **Query expansion**: Uses WordNet to find synonyms and related terms; needed to handle lexical variation in queries; quick check: expand sample query and verify semantic coverage.

## Architecture Onboarding
- **Component map**: Elasticsearch(BM25+NER) -> Qdrant(embeddings) -> spaCy(NER) -> WordNet(expansion) -> RRF(fusion) -> BEiT-3(fine-tuned) -> BEiT-3(pretrained) -> SigmoidBoosting -> RRF(rerank)
- **Critical path**: Query processing (NER + expansion) → BM25 filtering → RRF fusion → Dual BEiT-3 scoring → Final RRF fusion → Top-K retrieval
- **Design tradeoffs**: Lightweight NER vs. LLM-based extraction (efficiency vs. accuracy); frozen visual encoder vs. full fine-tuning (stability vs. adaptation); dual models vs. single model (diversity vs. simplicity)
- **Failure signatures**: Poor entity extraction for implicit/verbal events; abstract/figurative queries misaligned with visual content; low diversity in initial BM25 candidates
- **First experiments**: 1) Test NER extraction on sample queries and verify entity weights improve BM25 ranking; 2) Implement dual BEiT-3 scoring with assumed hyperparameters and evaluate on validation set; 3) Run end-to-end pipeline on small subset to verify RRF fusion effectiveness

## Open Questions the Paper Calls Out
None

## Limitations
- Critical hyperparameters for sigmoid boosting (α, β, γ) and RRF fusion constant k are unspecified
- Exact fine-tuning settings (learning rate, batch size, epochs, checkpoint paths) not provided
- May struggle with implicit or abstract events not captured by entity extraction

## Confidence
- High: mAP improvement over baselines (primary metric, well-defined methodology)
- Medium: entity extraction and query expansion components (sensitive to NER performance and WordNet coverage)
- Low: dual-model reranking effectiveness (missing hyperparameters and fine-tuning details)

## Next Checks
1. Reconstruct the full retrieval pipeline using specified entity weights and test with controlled queries to verify entity extraction and BM25 filtering accuracy
2. Implement dual BEiT-3 reranking with assumed hyperparameters (α=1.0, β=0.5, γ=0.1, k=60) and evaluate on held-out validation set to confirm claimed performance gains
3. Assess robustness by testing framework on queries with implicit or abstract events to identify failure modes and need for enhanced semantic/event extraction methods