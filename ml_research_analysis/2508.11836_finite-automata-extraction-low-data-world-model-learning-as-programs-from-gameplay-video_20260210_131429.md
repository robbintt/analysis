---
ver: rpa2
title: 'Finite Automata Extraction: Low-data World Model Learning as Programs from
  Gameplay Video'
arxiv_id: '2508.11836'
source_url: https://arxiv.org/abs/2508.11836
tags:
- sprite
- learning
- world
- program
- programs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Finite Automata Extraction (FAE), a neuro-symbolic
  approach to learn world models from gameplay video using a novel domain-specific
  language called Retro Coder. The method extracts symbolic grid representations from
  video frames using a modified Marionette architecture, then learns programs for
  each sprite by searching over Retro Coder's DSL of if-then rules.
---

# Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video

## Quick Facts
- arXiv ID: 2508.11836
- Source URL: https://arxiv.org/abs/2508.11836
- Reference count: 8
- One-line primary result: FAE learns more generalizable code (fewer conditions) than Game Engine Learning while achieving comparable performance on metrics like FID and prediction error

## Executive Summary
This paper presents Finite Automata Extraction (FAE), a neuro-symbolic approach to learn world models from gameplay video using a novel domain-specific language called Retro Coder. The method extracts symbolic grid representations from video frames using a modified Marionette architecture, then learns programs for each sprite by searching over Retro Coder's DSL of if-then rules. FAE is evaluated on Pac-Man and River Raid domains and compared against GameGAN and Game Engine Learning. Results show FAE learns more generalizable code (fewer conditions) than Game Engine Learning while achieving comparable performance on metrics like FID and prediction error. FAE trains significantly faster than GameGAN while achieving better or comparable results. The approach demonstrates that world models can be learned from low data with interpretable, editable code representations suitable for game development applications.

## Method Summary
FAE learns world models from gameplay video through a three-stage process: (1) A modified Marionette VAE extracts a sprite dictionary and converts RGB frames to symbolic grid representations where each cell references a sprite; (2) For each sprite, FAE searches over Retro Coder DSL programs using iterative neighbor search to minimize prediction error between actual and predicted next frames; (3) The learned programs can be executed to simulate game dynamics. The approach assumes sprites occupy single grid cells and behaviors can be expressed as deterministic if-then rules. FAE trains faster than GameGAN while achieving comparable or better performance on metrics like FID, prediction error, and program generalizability.

## Key Results
- FAE learns programs with significantly fewer conditions (1.75±0.83) than Game Engine Learning (73±22), demonstrating better generalizability
- FAE achieves comparable FID scores to GameGAN (49.8 vs 47.4) while training 25× faster (80 vs 2000 epochs)
- The approach successfully learns accurate behaviors for most sprites but struggles with random or time-dependent behaviors due to DSL limitations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Discrete sprite-level grid representations enable tractable program synthesis from video.
- **Mechanism:** A modified Marionette VAE learns a bounded sprite dictionary and assigns each grid cell a softmax-weighted sprite index. This converts continuous RGB frames into a symbolic matrix where collisions and positions are discrete.
- **Core assumption:** Sprites occupy single grid cells and can be faithfully reconstructed from a fixed dictionary.
- **Evidence anchors:**
  - [System Overview]: "We then train a self supervised model based on the Marionette architecture... to extract a neural sprite dictionary... This resulted in the w × h grid where each cell referenced a sprite in the sprite dictionary."
  - [Results - Limitations]: "Occasionally a sprite can be between two grid cells. In these instances, our grid representation hallucinated that there was a sprite in both of the cells."
  - [corpus]: Weak direct corpus support for Marionette specifically; related automata extraction work assumes discrete alphabets (e.g., "Extracting Robust Register Automata" addresses continuous domains but not video).
- **Break condition:** Sprites that span multiple cells or sub-cell positions cause misclassification and downstream program errors.

### Mechanism 2
- **Claim:** Iterative neighbor search over a restricted DSL yields more generalizable programs than enumerative synthesis.
- **Mechanism:** For each sprite, FAE scans frame sequences, computes prediction error, and iteratively modifies programs by adding or removing if-then rules to minimize distance D between predicted and actual grids. The DSL restricts conditions (exists, neighboring) and actions (follow entity, change to entity).
- **Core assumption:** Sprite behavior can be expressed as deterministic if-then rules without time-dependence or randomness.
- **Evidence anchors:**
  - [Finite Automata Extraction]: "We then search for neighbour programs to minimize D. The neighbour programs can either have another if-then statement, or remove an if-then statement from the program."
  - [Results - Learned Programs]: "The model could not replicate the ground truth behavior for GHOST and EYES, this is due to the randomness involved in the sprites, which currently is not captured with our current DSL."
  - [corpus]: "Inference of Deterministic Finite Automata via Q-Learning" shows RL-based DFA inference; FAE differs by using direct search without learned value functions.
- **Break condition:** Stochastic behaviors, time-dependent transformations, or off-screen spawning cannot be represented.

### Mechanism 3
- **Claim:** Per-sprite decomposition reduces search space at cost of global coordination.
- **Mechanism:** FAE learns one program per sprite independently. This avoids combinatorial explosion but prevents modeling inter-sprite dependencies beyond pairwise collisions.
- **Core assumption:** Sprite behaviors are conditionally independent given local observations (neighbors, entity existence).
- **Evidence anchors:**
  - [Retro Coder]: "We learn a program for each sprite individually... since they be able to make changes to the behavior of a particular sprite easily this way."
  - [Results - Learned Programs]: For BLINKY, the model learned to follow PACMAN and change state on collision with POWERPELLET—capturing pairwise interactions but not multi-entity coordination.
  - [corpus]: No direct corpus comparison; automata extraction literature typically learns monolithic DFAs (e.g., "Efficient Decomposition Identification of DFAs" explores decomposition but not per-entity factoring).
- **Break condition:** Behaviors requiring global game state (e.g., coordinated ghost AI) are approximated poorly.

## Foundational Learning

- **Concept: Variational Autoencoders with Discrete Latents**
  - **Why needed here:** Understanding how Marionette learns a bounded sprite dictionary and grid assignment via softmax weights.
  - **Quick check question:** Given a 32x32 frame and 16-sprite dictionary, what is the output grid dimension and how is cell-sprite assignment determined?

- **Concept: Program Synthesis via Stochastic Search**
  - **Why needed here:** FAE's neighbor-based search over DSL programs is a form of heuristic search; knowing when it converges vs. exhausts budget matters.
  - **Quick check question:** If bestdistance never decreases after adding a rule, what does the algorithm do next?

- **Concept: Grid-Based Game Representations**
  - **Why needed here:** FAE assumes discrete cell occupancy; understanding collision handling and positional encoding is critical.
  - **Quick check question:** How should neighboring(a, b) behave if both entities occupy the same cell vs. adjacent cells?

## Architecture Onboarding

- **Component map:** Video frames -> Marionette VAE -> Sprite dictionary + Grid matrices -> Symbolic grids -> Retro Coder DSL programs -> Simulator -> Prediction evaluation
- **Critical path:** Marionette training quality → grid extraction accuracy → program search convergence. Errors in sprite dictionary propagate irrecoverably.
- **Design tradeoffs:**
  - Fewer sprites (small l): Faster search, risk of merged/missed sprites
  - Larger batch size (b): More stable distance estimates, slower iteration
  - DSL expressivity: More actions enable complex behaviors but enlarge search space
- **Failure signatures:**
  - High FID with low prediction error: Model overfits to training frames
  - Programs with many conditions: Under-generalization (GEL shows 73±22 conditions vs. FAE's 1.75±0.83)
  - Sprites absent from dictionary: Check l hyperparameter; small pellets missed in Pac-Man
- **First 3 experiments:**
  1. **Marionette validation:** Train VAE on held-out frames; verify reconstruction loss and visual sprite separation before proceeding.
  2. **DSL coverage test:** Hand-write ground-truth programs for known sprites; confirm they reduce prediction error to near-zero.
  3. **Ablation on l and b:** Vary sprite dictionary size (e.g., 8, 16, 32) and batch size (1, 3, 5); measure impact on FID and program generalizability.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the Marionette architecture be modified to accurately handle sprites that occupy positions between grid cells, eliminating the hallucination of sprites in multiple cells?
- **Basis in paper:** [explicit] Authors state "Perhaps in the future, we can tweak the Marionette Architecture to take this into account" regarding grid representation errors when sprites are between cells.
- **Why unresolved:** Current approach causes the model to learn incorrect conditions based on hallucinated sprite positions.
- **What evidence would resolve it:** A modified architecture that maintains accuracy when sprites transition between cells, measured by reduced spurious conditions in learned programs.

### Open Question 2
- **Question:** How can Retro Coder be extended to support time-dependent behaviors and randomized sprite actions?
- **Basis in paper:** [explicit] Authors note "the DSL does not take time into account" and "cannot replicate randomised behaviour," causing failures on sprites like GHOST and EYES in Pac-Man.
- **Why unresolved:** Current DSL lacks temporal operators and probabilistic constructs needed for these behaviors.
- **What evidence would resolve it:** Extended DSL with time and randomness primitives that correctly learns GHOST fleeing behavior and EYES return-to-spawn patterns.

### Open Question 3
- **Question:** Can a GameManager program be incorporated to handle sprite spawning logic currently impossible in FAE?
- **Basis in paper:** [explicit] Authors state "we cannot create a GameManager program to handle sprite spawning" when explaining River Raid limitations for off-screen spawns.
- **Why unresolved:** FAE learns individual sprite programs only; spawning requires coordinating multiple sprites.
- **What evidence would resolve it:** A meta-program or spawning module that correctly predicts when and where FUEL and boat sprites appear in River Raid.

### Open Question 4
- **Question:** How can the representation handle sprites with variable sizes and rotation without hallucination?
- **Basis in paper:** [explicit] Authors identify that "the grid based representation in its current state does not handle sprites with different sizes well" and "does not handle the rotation of the sprites."
- **Why unresolved:** FUEL sprite in River Raid alternates between occupying 2-3 cells, preventing correct behavior learning.
- **What evidence would resolve it:** Multi-scale or rotation-invariant representation that correctly learns FUEL movement patterns.

## Limitations
- Grid representation fails for sprites that span multiple cells, causing hallucination of sprites in multiple positions
- DSL cannot capture randomized behaviors or time-dependent transformations, limiting learned programs for GHOST and EYES sprites
- Cannot model sprite spawning logic requiring global game state coordination (e.g., off-screen FUEL spawns in River Raid)

## Confidence

**High Confidence:** The core neuro-symbolic pipeline (video → symbolic grid → program synthesis) is well-specified and reproducible.

**Medium Confidence:** Quantitative comparisons to baselines (FID, prediction error, training time) appear valid, though exact implementation details affect reproducibility.

**Low Confidence:** Qualitative claims about learned program interpretability and generalizability due to missing architectural specifications and dataset details.

## Next Checks

1. Implement Marionette VAE with documented hyperparameters and verify sprite dictionary learning and grid extraction accuracy on held-out frames.
2. Test Retro Coder DSL coverage by hand-writing ground-truth programs for known sprites and confirming they achieve near-zero prediction error.
3. Conduct ablation study varying sprite dictionary size (l) and batch size (b) to measure impact on FID scores and program generalizability.