---
ver: rpa2
title: Detecting Ambiguities to Guide Query Rewrite for Robust Conversations in Enterprise
  AI Assistants
arxiv_id: '2502.00537'
source_url: https://arxiv.org/abs/2502.00537
tags:
- query
- queries
- ambiguous
- ambiguity
- rewrite
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of ambiguity in multi-turn conversations
  with enterprise AI assistants. The authors propose an NLU-NLG framework that first
  detects whether a query is ambiguous using a hybrid model combining rules and a
  small language model, and then rewrites only the detected ambiguous queries to resolve
  them.
---

# Detecting Ambiguities to Guide Query Rewrite for Robust Conversations in Enterprise AI Assistants

## Quick Facts
- **arXiv ID:** 2502.00537
- **Source URL:** https://arxiv.org/abs/2502.00537
- **Reference count:** 17
- **Primary result:** Ambiguity detection model achieves 90.19% F1 and 92.16% accuracy

## Executive Summary
This paper addresses a critical challenge in enterprise AI assistants: handling ambiguous multi-turn conversations without introducing errors through unnecessary query rewrites. The authors propose a hybrid NLU-NLG framework that first detects whether a query is ambiguous using a combination of rules and a small language model, and then selectively rewrites only the detected ambiguous queries. By avoiding rewrites for clear queries, the system reduces downstream errors from 18% to 8% in production deployment within Adobe Experience Platform AI Assistant.

## Method Summary
The proposed system implements a two-stage approach: first, an NLU module detects ambiguity using a hybrid model combining semantic embeddings with structural features (query length, referential count, readability) and rule-based lexical detection; second, a router directs ambiguous queries to a query rewrite (QR) module while bypassing clear queries directly to the agent. The approach uses a taxonomy of three ambiguity types (pragmatic, syntactic, lexical) to inform feature engineering and rule-based synthetic data augmentation for training. The classifier employs a Sentence Transformer for semantic embeddings combined with a small neural network that processes both the embeddings and numerical features.

## Key Results
- Ambiguity detection model achieves 90.19% F1 and 92.16% accuracy
- System reduces downstream errors from 18% to 8% in production deployment
- Outperforms LLM-based baselines and logistic regression baselines on detection task

## Why This Works (Mechanism)

### Mechanism 1: Selective Rewrite Gating
Routing queries through a binary classifier before rewriting prevents degradation of already-clear queries by LLMs. The system inserts a decision gate before the Query Rewrite (QR) module. If the NLU classifier predicts a query as "clear," the QR module is bypassed entirely. This isolates clear queries from LLM "concept drift" or hallucination risks where an LLM might unnecessarily alter specific entity names or constraints (e.g., changing "Dataset A (v1)" to just "Dataset A"). The core assumption is that the classifier's False Positive rate is lower than the LLM's error rate when rewriting clear queries.

### Mechanism 2: Multi-Modal Feature Fusion
Concatenating semantic embeddings with hand-crafted structural features improves ambiguity detection over semantic-only models. The architecture fuses a dense 768-dimensional text embedding (from Sentence Transformer) with a sparse 3-dimensional numerical feature vector (Query Length, Referential Count, Readability). The numerical features explicitly flag structural weaknesses (e.g., short length, presence of "it/this") that dense embeddings might smooth over. The core assumption is that syntactic and pragmatic ambiguities correlate strongly with quantifiable metrics like word count and readability scores.

### Mechanism 3: Taxonomy-Derived Synthetic Data Augmentation
Training robustness for minority "ambiguous" classes can be achieved using rule-based synthetic query generation derived from an error taxonomy. Instead of relying solely on scarce real-world error logs, the authors generate synthetic training data by applying transformation rules (e.g., swapping nouns for pronouns, masking entities) identified in their ambiguity taxonomy. This balances the dataset for the classifier. The core assumption is that the synthetic rules accurately simulate the statistical distribution of natural user ambiguities.

## Foundational Learning

- **Concept:** Coreference Resolution & Ellipsis
  - **Why needed here:** The paper identifies "Pragmatic Ambiguity" (63.5% of errors) as the primary failure mode, where queries rely on previous context (e.g., "How many do I have?"). Understanding what was omitted is essential for the QR module.
  - **Quick check question:** In the query "Change the date," what context from the previous turn is strictly required to resolve the action?

- **Concept:** Coleman-Liau Index (CLI)
  - **Why needed here:** The authors use CLI as a proxy for "completeness." Ambiguous queries often score poorly on readability metrics because they lack the subject-verb-object structure of complete thoughts.
  - **Quick check question:** Does a low CLI score indicate a complex academic sentence or a fragmented, incomplete query?

- **Concept:** Concept Drift in LLMs
  - **Why needed here:** The paper argues against "Always Rewriting" because LLMs can introduce errors (drift) by over-interpreting clear instructions. The "Ambiguity-guided" approach is a defense against this specific LLM behavior.
  - **Quick check question:** If an LLM rewrites "Show ID 123" to "Show the identifier for record 123," has concept drift occurred, or is this a safe paraphrase?

## Architecture Onboarding

- **Component map:** User Query + Chat History -> NLU Module -> Router -> (QR Module or Agent) -> Final Answer
- **Critical path:** The Feature Extraction step in the NLU module. If the Referential Count or Entity Masking fails, the classifier receives garbage input, and the Router makes incorrect decisions, breaking the end-to-end accuracy gains.
- **Design tradeoffs:**
  - **Latency vs. Cost:** Adding a classifier adds ~0.01s latency to every turn, but saves significant inference cost and latency by skipping the heavy LLM rewrite for ~50% of queries.
  - **Precision vs. Recall:** The system prioritizes avoiding "unwanted rewrites." Therefore, the classifier likely favors High Precision for the "Clear" class over High Recall for "Ambiguous" to prevent the LLM from touching good queries.
- **Failure signatures:**
  - **"The Chameleon Query":** A clear query is rewritten anyway (Classifier False Positive), and the LLM changes a critical parameter (e.g., specific date format).
  - **"The Zombie Context":** The classifier misses an ambiguity (False Negative), passing "How many?" directly to the agent, which returns "Sorry, I didn't understand."
- **First 3 experiments:**
  1. **Ablation Study:** Remove the numerical features (Length, Referential Count) and measure the drop in F1 score to validate the hybrid architecture.
  2. **Rewrite Analysis:** Run a "Clear" dataset through both "Always Rewrite" and "Guided Rewrite" pipelines to quantify the rate of introduced errors (hallucinations).
  3. **Latency Stress Test:** Measure the added latency of the small LM classifier against the time saved by skipping the large LM rewrite.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided corpus.

## Limitations
- The synthetic data augmentation strategy relies heavily on the authors' taxonomy and rule-based generation, potentially limiting generalization to different ambiguity distributions.
- The 8% error rate in production is reported without detailed error analysis to understand what types of ambiguities remain undetected.
- The system's performance on languages other than English is not addressed, and evaluation focuses primarily on a single enterprise domain.

## Confidence
- **High confidence** in the core claim that selective rewrite gating reduces LLM-induced errors, supported by strong experimental results (90.19% F1, 92.16% accuracy) and clear failure mode analysis.
- **Medium confidence** in the feature fusion mechanism - while Table 4 shows improvements with additional features, the corpus provides limited evidence for this specific architectural choice.
- **Medium confidence** in the taxonomy-driven synthetic data approach, as the augmentation strategy is logically sound but lacks extensive validation against diverse real-world ambiguity patterns.

## Next Checks
1. **Cross-Domain Generalization Test**: Evaluate the ambiguity detection model on enterprise assistants from different domains (healthcare, finance, retail) to assess whether the taxonomy and feature engineering generalize beyond Adobe Experience Platform.

2. **Error Type Classification**: Perform detailed error analysis on the 8% production error rate to categorize remaining failures (False Positives, False Negatives, classifier errors vs. rewrite errors) and identify whether specific ambiguity types consistently evade detection.

3. **Ablation of Synthetic Data**: Train models with varying ratios of synthetic to real training data to quantify the actual contribution of the taxonomy-based augmentation and determine if it introduces any overfitting to synthetic patterns.