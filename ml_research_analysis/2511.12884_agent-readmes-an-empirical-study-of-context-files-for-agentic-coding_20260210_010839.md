---
ver: rpa2
title: 'Agent READMEs: An Empirical Study of Context Files for Agentic Coding'
arxiv_id: '2511.12884'
source_url: https://arxiv.org/abs/2511.12884
tags:
- files
- context
- agent
- code
- software
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents the first large-scale empirical analysis of
  agent context files (e.g., CLAUDE.md, AGENTS.md), which provide project-level instructions
  to AI coding agents. Analyzing 2,303 files from 1,925 repositories, we find these
  files are actively maintained through frequent, small additions rather than deletions,
  behaving as evolving configuration artifacts rather than static documentation.
---

# Agent READMEs: An Empirical Study of Context Files for Agentic Coding

## Quick Facts
- arXiv ID: 2511.12884
- Source URL: https://arxiv.org/abs/2511.12884
- Reference count: 40
- Primary result: First large-scale empirical analysis of 2,303 agent context files shows developers prioritize functional context while neglecting non-functional requirements

## Executive Summary
This study presents the first large-scale empirical analysis of agent context files (e.g., CLAUDE.md, AGENTS.md) that provide project-level instructions to AI coding agents. Analyzing 2,303 files from 1,925 repositories, we find these files are actively maintained through frequent, small additions rather than deletions, behaving as evolving configuration artifacts rather than static documentation. The files follow a consistent shallow hierarchy with single H1 headings and primarily H2/H3 sections. Content analysis reveals developers heavily prioritize functional context (build/run commands 62.3%, implementation details 69.9%, architecture 67.7%) while neglecting non-functional requirements like security (14.5%) and performance (14.5%).

## Method Summary
The study collected agent context files from public GitHub repositories using a targeted search methodology. Files were analyzed using both automated classification (GPT-5.1) and manual content analysis to categorize their structure, maintenance patterns, and content priorities. The classification achieved a micro-average F1-score of 0.79, with strong performance on concrete functional topics but weaker results for abstract concepts. Temporal analysis examined changes over a 30-day period, revealing patterns of frequent small additions and minimal deletions.

## Key Results
- Agent context files follow a consistent shallow hierarchy with single H1 headings and primarily H2/H3 sections
- Files are actively maintained with frequent, small additions rather than deletions, behaving as evolving configuration artifacts
- Developers heavily prioritize functional context (build/run commands 62.3%, implementation details 69.9%, architecture 67.7%) while neglecting non-functional requirements like security (14.5%) and performance (14.5%)
- Automatic classification using GPT-5 achieves micro-average F1-score of 0.79, performing well on concrete functional topics but struggling with abstract concepts

## Why This Works (Mechanism)
Agent context files work by providing structured, hierarchical guidance that AI coding agents can parse and follow. The shallow hierarchy with clear sectioning (H1 followed by H2/H3) allows agents to quickly locate relevant information without navigating complex document structures. The emphasis on concrete, actionable instructions (build commands, implementation patterns) provides clear signals that agents can execute, while the relative absence of abstract quality requirements (security, performance) reflects both developer priorities and the practical challenges of encoding such concepts into machine-readable instructions.

## Foundational Learning
1. **Context File Structure** - Shallow hierarchy with single H1 and H2/H3 sections; needed because agents parse structured documents efficiently, quick check: verify heading levels in sample files
2. **Maintenance Patterns** - Frequent small additions, minimal deletions; needed to understand evolution as living configuration, quick check: track changes over time
3. **Content Classification** - Functional vs non-functional requirements; needed to assess what agents are actually configured for, quick check: validate classification accuracy
4. **Agent Parsing Behavior** - How AI agents interpret and prioritize information; needed to understand effectiveness of different organizational strategies, quick check: test agent responses with varying file structures
5. **Developer Intent Encoding** - How developers translate requirements into machine-readable instructions; needed to bridge human-agent communication gap, quick check: analyze correlation between stated intent and actual agent behavior

## Architecture Onboarding

**Component Map**: Repository -> Context File -> AI Agent -> Code Generation
Content File (CLAUDE.md/AGENTS.md) -> Classification Engine (GPT-5) -> Structured Guidance -> Agent Execution Context

**Critical Path**: Context File Creation → Content Classification → Agent Configuration → Code Generation

**Design Tradeoffs**: Shallow hierarchy vs comprehensive coverage; concrete instructions vs abstract principles; frequent updates vs stability; functional focus vs holistic quality

**Failure Signatures**: 
- Agents ignoring security guidelines (14.5% mention rate)
- Performance optimizations overlooked (14.5% mention rate)
- Abstract concepts misinterpreted due to low classification accuracy
- Inconsistent guidance across different sections

**First Experiments**:
1. Compare agent code quality with and without context files across 50 repositories
2. Test agent responses to varying heading structures (deep vs shallow hierarchy)
3. Measure classification accuracy improvements with fine-tuned models for abstract concepts

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Analysis limited to public GitHub repositories using specific search methodology, potentially missing private repositories
- Classification approach relied on GPT-5.1, which may have inherent biases in interpreting developer intent
- Temporal analysis was limited to 30 days, providing only a snapshot rather than longitudinal trends
- Study could not directly measure actual impact on agent behavior or code quality outcomes

## Confidence
- **High confidence**: File structure patterns (shallow hierarchy, consistent heading usage) and maintenance patterns (frequent additions, few deletions) are well-supported by quantitative data across a large sample size
- **Medium confidence**: Content priorities (functional vs non-functional requirements) are reasonably robust but may vary across different developer communities and project types
- **Medium confidence**: The classification performance metrics are reliable for concrete functional topics but less certain for abstract concepts where the model struggled

## Next Checks
1. Conduct longitudinal studies tracking the same repositories over 6-12 months to verify whether observed maintenance patterns persist and how context files evolve with project maturity
2. Perform controlled experiments where AI agents are run with and without context files to measure actual impact on code quality, security practices, and adherence to specified guidelines
3. Expand the corpus to include private repositories and alternative naming conventions (e.g., AGENTS.md, AI.md) to assess whether observed patterns hold across different organizational contexts and development environments