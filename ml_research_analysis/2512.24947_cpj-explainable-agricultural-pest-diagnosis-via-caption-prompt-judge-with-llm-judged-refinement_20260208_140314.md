---
ver: rpa2
title: 'CPJ: Explainable Agricultural Pest Diagnosis via Caption-Prompt-Judge with
  LLM-Judged Refinement'
arxiv_id: '2512.24947'
source_url: https://arxiv.org/abs/2512.24947
tags:
- disease
- captions
- crop
- agricultural
- caption
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of accurate and interpretable
  crop disease diagnosis in agriculture, where existing methods often rely on costly
  supervised fine-tuning and struggle with domain shifts. To overcome these limitations,
  the authors propose Caption-Prompt-Judge (CPJ), a training-free few-shot framework
  that enhances Agri-Pest VQA through structured, interpretable image captions.
---

# CPJ: Explainable Agricultural Pest Diagnosis via Caption-Prompt-Judge with LLM-Judged Refinement

## Quick Facts
- arXiv ID: 2512.24947
- Source URL: https://arxiv.org/abs/2512.24947
- Authors: Wentao Zhang; Tao Fang; Lina Lu; Lifei Wang; Weihe Zhong
- Reference count: 37
- Primary result: Training-free framework achieving +22.7 percentage points improvement in disease classification and +19.5 points in QA score on CDDMBench using structured captions.

## Executive Summary
The paper introduces CPJ, a training-free few-shot framework that enhances agricultural pest diagnosis by integrating large vision-language models (VLMs) for structured caption generation with LLM-judged refinement and dual-answer VQA. By explicitly generating neutral, multi-angle captions describing visual symptoms, CPJ provides interpretable intermediate representations that improve both classification accuracy and diagnostic reasoning. Evaluated on CDDMBench, CPJ significantly outperforms baselines, achieving +22.7 percentage points in disease classification and +19.5 points in QA score, while offering transparent, evidence-based reasoning without requiring fine-tuning.

## Method Summary
CPJ operates as a three-stage pipeline: (1) a VLM generates multi-angle, neutral captions describing disease symptoms while excluding specific crop/disease names to minimize bias, (2) an LLM-as-Judge evaluates and refines these captions against accuracy, completeness, and neutrality criteria (threshold τ=8.0), and (3) a VQA model produces dual answers (recognition and management) informed by the refined captions, with a stronger LLM selecting the best answer via multi-dimensional scoring. The framework is training-free, using API-based models (GPT-5-mini/Nano, Qwen-VL-Chat) and implemented with LangChain on the CDDMBench dataset.

## Key Results
- CPJ achieves +22.7 percentage points improvement in crop disease classification accuracy over no-caption baselines.
- CPJ improves QA scores by +19.5 points on CDDMBench, demonstrating enhanced diagnostic reasoning.
- LLM-as-Judge effectively filters hallucinations, achieving 73% factuality verification versus 51% without refinement.

## Why This Works (Mechanism)

### Mechanism 1
Structured text captions serve as a higher-fidelity semantic interface for agricultural reasoning than raw image pixels alone. The framework decouples visual perception from diagnostic reasoning, with a VLM transcribing subtle visual cues into explicit text, forcing the downstream VQA model to reason over defined semantic features rather than mapping raw pixels directly to disease classes.

### Mechanism 2
Enforcing neutrality in intermediate captions reduces premature labeling bias. By instructing the caption model to exclude crop or disease names and focus only on morphology, the system prevents label leakage or confirmation bias, ensuring diagnosis derives from evidence (symptoms) rather than the model's prior probability.

### Mechanism 3
Multi-criteria adjudication by a stronger LLM filters hallucinations better than single-pass generation. The "LLM-as-a-Judge" component evaluates dual-answer candidates against a rubric (accuracy, completeness, specificity), acting as an external verification loop that can select superior responses or trigger refinement.

## Foundational Learning

### Concept: Vision-Language Models (VLMs) vs. Large Language Models (LLMs)
**Why needed here:** CPJ relies on asymmetric capabilities—using a strong VLM for "seeing" (captioning) and a text-focused LLM for "reasoning" (judging). Engineers must understand that off-the-shelf VLMs often struggle with domain-specific visual reasoning without this decomposition.
**Quick check question:** Can a standard text-only LLM diagnose a disease from an image file? (Answer: No, it requires a vision encoder or a prior captioning step.)

### Concept: Bias Mitigation via Prompt Engineering
**Why needed here:** The paper emphasizes "neutral" captions. Engineers must understand that prompts are not just instructions but constraints. Including the word "rot" in a prompt might bias the model toward fungal diseases; excluding specific terminology forces feature-based reasoning.
**Quick check question:** If the caption includes the word "blight," is it a neutral observation? (Answer: No, "blight" implies a specific pathology; a neutral description would be "dark, spreading lesions.")

### Concept: LLM-as-a-Judge / Adversarial Verification
**Why needed here:** The performance gain (+22.7pp) relies heavily on the Judge component. Engineers must understand that generative AI outputs are probabilistic and benefit from a "second opinion" mechanism, especially in high-stakes domains like agriculture.
**Quick check question:** Why generate two answers and pick one, rather than just generating one better answer? (Answer: It is often easier to verify/select than to generate perfectly in one shot, and it provides a fail-safe against hallucinations.)

## Architecture Onboarding

### Component map:
1. Captioner (LVLM): e.g., GPT-5-mini / Qwen2.5-VL. Inputs: Image + Few-shot prompt. Output: Neutral text description.
2. Refiner (LLM-as-Judge): Inputs: Generated caption. Function: Scores accuracy/neutrality (Threshold τ=8.0). Output: Optimized Caption (C*).
3. VQA Generator: e.g., GPT-5-Nano. Inputs: Image + Optimized Caption + Question. Output: Dual Answers (A(1), A(2)).
4. Selector (LLM-as-Judge): e.g., GPT-4. Inputs: Dual Answers + Reference (if available). Output: Final Answer A*.

### Critical path:
The quality of the Captioner. If the visual features are misidentified (e.g., calling insect damage "fungal lesions"), the entire downstream reasoning chain (VQA and Judge) will likely fail or hallucinate a treatment for the wrong cause.

### Design tradeoffs:
- **Latency vs. Accuracy:** Multi-stage pipeline (Caption → Refine → VQA → Judge) incurs significant latency and API costs compared to single-pass models.
- **Model Size:** The paper uses a larger LVLM to teach a smaller VQA model (Knowledge Distillation via Caption).
- **Verbosity:** The Judge may favor longer, more detailed answers which might not always be more accurate (Judge Bias noted in limitations).

### Failure signatures:
- **Early-stage Ambiguity:** Inputs showing minimal symptoms result in generic captions ("green leaf"), leading to low-confidence diagnoses.
- **Co-infection Confusion:** The model struggles when visual features overlap between multiple diseases (e.g., fungal + bacterial infection).
- **Verbose Hallucination:** The Judge selects a detailed, confident-sounding answer that is scientifically incorrect (Judge Bias).

### First 3 experiments:
1. **Caption Ablation:** Run the pipeline with "Empty" or "Raw" (unoptimized) captions to quantify the specific contribution of the "Generative Explanational Captioning" module on CDDMBench classification scores.
2. **Sensitivity Analysis (Threshold τ):** Vary the Judge's quality threshold (τ) for caption refinement (e.g., 5.0 vs. 8.0 vs. 9.5) to find the optimal balance between computation cost (refinement loops) and diagnostic accuracy.
3. **Cross-Model Compatibility:** Swap the VQA component (e.g., use Qwen-VL-Chat with GPT-5-mini captions) to test if the "Captioner" quality transfers across different "Reasoner" architectures.

## Open Questions the Paper Calls Out

### Open Question 1
**Question:** How can the CPJ framework be adapted to incorporate temporal or multi-view image contexts to accurately model disease progression?
**Basis in paper:** The authors explicitly list "lack of temporal/multi-view context" as a limitation, noting the framework operates on single images and cannot capture disease progression or environmental variations over time.
**Why unresolved:** The current architecture processes static inputs, whereas agricultural diagnosis often requires tracking dynamic changes in symptoms across different growth stages or angles.
**What evidence would resolve it:** Extending CPJ to process image sequences and evaluating its ability to stage diseases (e.g., early vs. late blight) on a longitudinal dataset.

### Open Question 2
**Question:** Can the LLM-as-a-Judge module be refined to eliminate its bias toward verbose responses?
**Basis in paper:** The error analysis identifies "Judge bias" favoring verbose responses (approx. 5% frequency) as a distinct failure mode, distinct from factual accuracy or caption quality.
**Why unresolved:** The current scoring criteria may inadvertently correlate length with quality, causing the judge to select longer but potentially less precise answers.
**What evidence would resolve it:** Implementing length-normalized scoring rubrics or penalty terms in the judge prompt and measuring a reduction in the selection of "verbose" candidates without losing semantic detail.

### Open Question 3
**Question:** Is the CPJ framework viable for on-device deployment in resource-constrained agricultural environments?
**Basis in paper:** The conclusion lists "on-device deployment for field applications in resource-constrained environments" as a specific direction for future work.
**Why unresolved:** The current implementation relies on API calls to large models (e.g., GPT-5-mini, GPT-4), which require stable internet connectivity and cloud infrastructure typically unavailable in remote fields.
**What evidence would resolve it:** A study implementing CPJ using quantized, local models (e.g., Qwen-VL-Chat) on edge hardware (e.g., NVIDIA Jetson) to measure latency and accuracy trade-offs offline.

## Limitations

- **Model availability:** GPT-5-mini and GPT-5-Nano are not publicly accessible, creating uncertainty in exact reproduction.
- **Dataset scope:** CDDMBench focuses on 10 crop types with limited geographic/seasonal diversity, limiting generalizability to real-world deployments.
- **Latency and cost:** Multi-stage pipeline requires 3-5 LLM calls per diagnosis with 20-30% refinement iterations, making it unsuitable for real-time edge deployment without optimization.

## Confidence

- **High:** The captioning → reasoning → adjudication pipeline architecture is technically sound and well-justified by the visual-semantic gap problem.
- **Medium:** Performance improvements (+22.7pp classification, +19.5 QA score) are supported by CDDMBench results, but exact replication depends on model/API availability.
- **Medium:** The LLM-as-Judge approach is validated in principle (73% vs 51% factuality), but the bias toward verbose answers and threshold sensitivity require further validation.

## Next Checks

1. **Threshold sensitivity test:** Systematically vary the LLM-as-Judge threshold τ (5.0, 6.5, 8.0, 9.5) to identify the optimal balance between refinement quality and computational cost.
2. **Cross-model caption transfer:** Evaluate whether GPT-5-mini captions maintain diagnostic value when used with different VQA models (e.g., Qwen-VL-Chat) to assess caption generality.
3. **Real-world deployment stress test:** Test the pipeline on images with co-infections, early-stage symptoms, and environmental occlusions to quantify failure modes beyond CDDMBench.