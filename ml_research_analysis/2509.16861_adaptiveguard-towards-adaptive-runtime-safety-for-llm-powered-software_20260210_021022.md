---
ver: rpa2
title: 'AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software'
arxiv_id: '2509.16861'
source_url: https://arxiv.org/abs/2509.16861
tags:
- prompts
- jailbreak
- attacks
- continual
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of runtime safety in LLM-powered
  software, specifically how static guardrails fail against evolving jailbreak attacks.
  It proposes AdaptiveGuard, an adaptive guardrail that treats novel jailbreak prompts
  as out-of-distribution (OOD) inputs and uses continual learning to adapt to them.
---

# AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software

## Quick Facts
- arXiv ID: 2509.16861
- Source URL: https://arxiv.org/abs/2509.16861
- Authors: Rui Yang; Michael Fu; Chakkrit Tantithamthavorn; Chetan Arora; Gunel Gulmammadova; Joey Chua
- Reference count: 40
- Primary result: Adaptive runtime safety for LLM-powered software using continual learning

## Executive Summary
The paper introduces AdaptiveGuard, a system designed to address the challenge of runtime safety in LLM-powered software, where static guardrails fail against evolving jailbreak attacks. Traditional static guardrails struggle with the dynamic nature of jailbreak attacks, which are continually evolving. AdaptiveGuard treats novel jailbreak prompts as out-of-distribution (OOD) inputs and uses continual learning to adapt to them in real-time.

## Method Summary
AdaptiveGuard implements an adaptive guardrail system that leverages continual learning to detect and adapt to novel jailbreak attacks. The system treats unknown attack patterns as out-of-distribution inputs, enabling it to identify and learn from new threats dynamically. Through empirical evaluation, the approach demonstrates rapid adaptation capabilities, achieving high OOD detection accuracy and maintaining performance on in-distribution data post-adaptation.

## Key Results
- Achieves 96% OOD detection accuracy against novel jailbreak attacks
- Adapts to new attacks in 2-38 update steps (median 2 steps)
- Maintains over 85% F1-score on in-distribution data after adaptation
- Outperforms baseline LlamaGuard in adaptive runtime safety scenarios

## Why This Works (Mechanism)
AdaptiveGuard works by treating novel jailbreak prompts as out-of-distribution inputs, which allows the system to identify previously unseen attack patterns. The continual learning mechanism then adapts the model to these new inputs without requiring full retraining. This approach enables the system to evolve alongside emerging threats while maintaining strong performance on known, legitimate inputs.

## Foundational Learning
- Continual Learning: Why needed - To adapt to new jailbreak attacks without full retraining; Quick check - Monitor model performance degradation over time without adaptation
- Out-of-Distribution Detection: Why needed - To identify novel jailbreak attacks that differ from training data; Quick check - Test detection accuracy on synthetic OOD samples
- Online Learning: Why needed - To update the model in real-time during deployment; Quick check - Measure update latency and resource consumption

## Architecture Onboarding
**Component Map:** Input prompts -> OOD Detector -> Continual Learner -> Updated Guardrail -> Output decision

**Critical Path:** Runtime input → OOD detection → If OOD, trigger adaptation → Update guardrail parameters → Return safety decision

**Design Tradeoffs:** Real-time adaptation vs. computational overhead; detection sensitivity vs. false positive rate; adaptation speed vs. stability

**Failure Signatures:** High false positive rate on legitimate prompts; slow adaptation to new attacks; catastrophic forgetting of previous knowledge

**First Experiments:** 1) Test OOD detection accuracy on known vs. unknown attack patterns 2) Measure adaptation speed with controlled attack variations 3) Evaluate in-distribution performance retention post-adaptation

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Generalizability of OOD detection beyond tested attack types remains uncertain
- Computational overhead during deployment in resource-constrained environments not fully characterized
- Long-term stability of continual learning updates and potential for catastrophic forgetting not extensively analyzed
- Real-world performance may vary with adversarial prompt diversity beyond curated datasets

## Confidence
- **High confidence:** Rapid adaptation (2-38 steps) and maintained in-distribution performance (>85% F1-score) are well-supported by experimental results
- **Medium confidence:** OOD detection accuracy (96%) depends on specific evaluation dataset and may face higher variability in real-world scenarios
- **Low confidence:** Deployment scenarios with concurrent user traffic and continual learning impact on production latency are not extensively analyzed

## Next Checks
1. Test AdaptiveGuard's OOD detection performance against a broader range of zero-day jailbreak attacks not seen during training or initial adaptation phases
2. Evaluate the system's behavior under concurrent multi-user load to measure real-time adaptation latency and computational overhead
3. Conduct a longitudinal study over several months to assess catastrophic forgetting and the need for periodic retraining or model checkpointing