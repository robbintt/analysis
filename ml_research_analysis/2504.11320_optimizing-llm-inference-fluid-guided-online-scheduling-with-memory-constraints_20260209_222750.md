---
ver: rpa2
title: 'Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints'
arxiv_id: '2504.11320'
source_url: https://arxiv.org/abs/2504.11320
tags:
- prompts
- memory
- batch
- time
- wait
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of scheduling LLM inference
  under memory constraints, where the dynamically growing Key-Value (KV) cache can
  trigger costly evictions that cascade into system-wide failures. The core insight
  is that traditional scheduling fails even when memory capacity exceeds theoretical
  requirements because it doesn't account for dynamic memory growth.
---

# Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints

## Quick Facts
- **arXiv ID**: 2504.11320
- **Source URL**: https://arxiv.org/abs/2504.11320
- **Reference count**: 40
- **Primary result**: Threshold-based online scheduling algorithms (WAIT, Nested WAIT) prevent eviction cascades and achieve near-optimal throughput under memory constraints

## Executive Summary
This paper addresses the challenge of scheduling LLM inference under memory constraints, where the dynamically growing Key-Value (KV) cache can trigger costly evictions that cascade into system-wide failures. The core insight is that traditional scheduling fails even when memory capacity exceeds theoretical requirements because it doesn't account for dynamic memory growth. The authors develop a fluid dynamics approximation that characterizes the optimal equilibrium state and throughput under perfect scheduling, then introduce threshold-based algorithms that prevent eviction by maintaining the system near load balance. Experiments on Llama-7B with an A100 GPU demonstrate superior throughput and reduced latency compared to vLLM and Sarathi.

## Method Summary
The approach uses fluid dynamics approximation to establish theoretical throughput benchmarks and equilibrium memory requirements under memory constraints. Based on this analysis, the authors introduce WAIT and Nested WAIT threshold-based algorithms that prevent eviction by maintaining system near load balance. WAIT uses type-specific thresholds for known output lengths, while Nested WAIT classifies prompts on-the-fly through segment boundaries for unknown output lengths. The safety buffer of O(log(B/δ)) memory provides high-probability overflow protection for Nested WAIT.

## Key Results
- Fluid analysis shows traditional FCFS scheduling triggers eviction cascades even when C = M*, causing 12-25% throughput loss
- WAIT algorithm achieves near-optimal throughput for known output lengths by maintaining equilibrium
- Nested WAIT achieves superior throughput and reduced latency compared to vLLM and Sarathi on real datasets with unknown output lengths

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fluid dynamics approximation characterizes the theoretical maximum sustainable throughput and equilibrium memory requirement under memory constraints.
- Mechanism: The fluid model treats stochastic prompt arrivals as continuous flows, solving for equilibrium where arrivals equal completions. This yields the optimal steady-state memory M* and throughput benchmark Throughput* = Σⱼλⱼl′ⱼ, providing a tractable upper bound for any scheduling policy.
- Core assumption: Arrival rates are stationary (or slowly varying); iteration time scales linearly with total KV cache size as τ = d₀ + d₁·(total KV cache).
- Evidence anchors:
  - [abstract] "develop a fluid dynamics approximation to establish a tractable benchmark"
  - [Section 3] Equation (8) defines M* = d₀Σλⱼ(l′ⱼ+1)(lⱼ + l′ⱼ/2) / [1 − d₁Σλⱼ(l′ⱼ+1)(lⱼ + l′ⱼ/2)]
  - [corpus] Related work (arXiv:2508.01002) also uses fluid-based scheduling analysis, supporting this modeling choice.
- Break condition: If C < M* (overloaded regime), the system cannot sustain equilibrium; throughput degrades regardless of scheduling quality.

### Mechanism 2
- Claim: Threshold-based admission control prevents eviction cascades by keeping the system near load balance, even when C ≥ M*.
- Mechanism: For each type j, WAIT enforces a threshold nⱼ. Batches form only when nⱼ prompts have accumulated. This decouples multi-type interactions into independent single-type analyses and ensures arrivals during each iteration do not exceed completions, preventing the queue growth that triggers cascading failures under FCFS.
- Core assumption: Output lengths are known at arrival (WAIT); or can be classified on-the-fly (Nested WAIT). Thresholds satisfy ΔT[1,...,m] ≤ nⱼ/λⱼ ensuring negative or zero drift per type.
- Evidence anchors:
  - [abstract] "WAIT uses threshold-based batching to prevent eviction by keeping the system near load balance"
  - [Section 4.1 Example 2] Demonstrates FCFS triggers eviction cascades even when C = M*, with 12–25% throughput loss.
  - [corpus] arXiv:2502.07115 also addresses KV cache constraints via online scheduling but uses competitive analysis rather than fluid thresholds.
- Break condition: If thresholds are set too low (over-conservative), latency increases due to waiting; if too high (aggressive), eviction risk rises.

### Mechanism 3
- Claim: Nested WAIT achieves near-optimal throughput for unknown output lengths through on-the-fly classification with logarithmic safety buffer overhead.
- Mechanism: Prompts enter segment 1 and reveal their type by completing or continuing at segment boundaries. Short prompts exit early; longer prompts advance to later segments. Each segment k has threshold nₖ. A safety buffer of O(log(B/δ)) memory provides high-probability overflow protection.
- Core assumption: The thinning probability pₖ = (Σⱼ>k λⱼ)/(Σⱼ≥k λⱼ) is stationary; prompts are classified solely by observing decode progression, no prediction model required.
- Evidence anchors:
  - [abstract] "Nested WAIT classifies prompts on-the-fly: short prompts complete early and exit, while longer ones naturally advance to later segments"
  - [Section 5.2 Theorem 2] Safety buffer bound: M ≥ M^π + Σₖ (l + l′ₖ₋₁)(nₖ + θ⁻¹ₖ ln(mζB/δ))
  - [corpus] arXiv:2508.14544 addresses prediction uncertainty adversarially; this work handles stochastic uncertainty via segment boundaries.
- Break condition: If output length distribution is highly non-stationary or has heavy tails, segment thresholds may misallocate memory; adaptive threshold tuning would be needed.

## Foundational Learning

- **Concept: KV Cache Memory Growth**
  - Why needed here: The core scheduling challenge is that memory per prompt grows linearly during decode (lⱼ + s tokens at stage s), unlike fixed-size jobs.
  - Quick check question: Given a prompt with input length 10 tokens and target output length 50, what is its memory footprint after 30 decode steps?

- **Concept: Load Balance Equilibrium**
  - Why needed here: The fluid analysis shows that stability requires arrivals ≈ completions per iteration; the scheduler must maintain this balance to avoid eviction cascades.
  - Quick check question: If arrivals per iteration are 8 and completions per iteration are 5, what happens to queue length over time?

- **Concept: Threshold-Based Batch Formation**
  - Why needed here: WAIT and Nested WAIT enforce minimum prompts before batching, converting continuous-time stochastic dynamics into tractable discrete-time analysis.
  - Quick check question: Why does waiting for nⱼ prompts before batching decouple multi-type interactions?

## Architecture Onboarding

- **Component map:** Prompt arrival → segment assignment → threshold check → batch formation → iteration execution → stage advancement → completion or segment transition
- **Critical path:** Prompt arrival → segment assignment → threshold check → batch formation → iteration execution → stage advancement → completion or segment transition
- **Design tradeoffs:**
  - Higher thresholds → better throughput (larger batches amortize d₀) but higher latency (longer waiting)
  - More segments (larger m) → finer type discrimination but higher safety buffer overhead
  - Logarithmic safety buffer (δ = 0.01 vs. 0.001) → tighter overflow guarantees but modest memory overhead (~log(100) vs. log(1000))
- **Failure signatures:**
  - **Eviction cascade:** Repeated LIFO evictions with prompts restarting from prefill; symptom: throughput drops below theoretical Throughput* by >10%
  - **Segment starvation:** Later segments have insufficient prompts to meet thresholds; symptom: high latency variance, GPU underutilization
  - **Memory overflow despite buffer:** Safety buffer underestimated; symptom: OOM errors at high load; mitigation: increase δ tolerance or add segments
- **First 3 experiments:**
  1. **Single-type validation:** Test WAIT on synthetic prompts with known (lⱼ, l′ⱼ, λⱼ), verify throughput approaches Throughput* = λⱼl′ⱼ and latency remains O(1)
  2. **Eviction cascade replication:** Run FCFS vs. WAIT on same workload with C = M*; confirm FCFS shows 12–25% throughput degradation while WAIT maintains stability
  3. **Unknown output length test:** Run Nested WAIT on real dataset (e.g., LMSYS Vicuna with 210k prompts) with m = 10 segments; compare throughput/latency vs. vLLM and Sarathi; verify safety buffer prevents OOM with δ = 0.01

## Open Questions the Paper Calls Out

- **Open Question 1:** How can WAIT algorithms be extended to multi-GPU systems with communication overhead and distributed synchronization constraints?
  - Basis in paper: [explicit] Section 8.2 states: "Extending the algorithm to multi-GPU environments introduces additional considerations, including communication costs, parallelization strategies, and hardware constraints... Developing a theoretical framework that incorporates these elements requires addressing communication overhead and synchronization constraints specific to distributed GPU architectures."
  - Why unresolved: The current analysis focuses on single-GPU deployment; multi-GPU settings involve tensor parallelism, pipeline parallelism, and non-negligible communication costs that invalidate the current iteration time model.
  - What evidence would resolve it: A theoretical extension with modified iteration time bounds incorporating communication latencies, plus experiments on multi-GPU configurations showing maintained throughput guarantees.

- **Open Question 2:** What is the optimal methodology for determining threshold parameters n_j for specific real-world deployment scenarios?
  - Basis in paper: [explicit] Section 8 states: "While our algorithms demonstrate strong performance, determining optimal threshold parameters for specific deployment scenarios remains an open problem."
  - Why unresolved: The paper derives thresholds from fluid equilibrium assuming known arrival rates, but provides no systematic procedure for selecting thresholds when rates must be estimated or when deployment constraints (e.g., strict latency SLOs) differ from throughput-maximizing objectives.
  - What evidence would resolve it: A principled threshold selection algorithm with provable regret bounds relative to oracle thresholds, validated across diverse workload patterns.

- **Open Question 3:** How does Nested WAIT perform under highly volatile arrival patterns with non-stationary distributions and demand surges?
  - Basis in paper: [explicit] Section 8.1 states: "In practical settings, the distribution of incoming prompts becomes non-stationary, violating the stationarity assumption underlying our model... a thorough analysis of its performance in more volatile environments, such as during demand surges, remains an open question."
  - Why unresolved: The theoretical guarantees assume bounded arrival rates; sudden traffic spikes may cause threshold conditions to fail, potentially triggering eviction cascades the algorithm is designed to prevent.
  - What evidence would resolve it: Analysis bounding queue length growth under adversarial arrival patterns, plus experiments with bursty trace-driven workloads showing graceful degradation.

## Limitations
- Theoretical analysis assumes stationary arrival rates and linear iteration time scaling, which may not hold in production environments with bursty traffic
- Safety buffer analysis provides probabilistic guarantees but relies on stationary thinning probability, which may break down with non-stationary output length distributions
- Empirical validation focuses on a single model (Llama-7B) and GPU (A100), limiting generalizability across different hardware configurations

## Confidence

**High Confidence Claims:**
- The fluid dynamics approximation correctly characterizes the theoretical maximum throughput under memory constraints (supported by rigorous mathematical derivation and asymptotic optimality proof)
- Threshold-based admission control prevents eviction cascades in the regime C ≥ M* (demonstrated through both theoretical analysis and synthetic experiments)
- The Nested WAIT algorithm achieves superior throughput and reduced latency compared to baseline schedulers (validated through experiments on real datasets)

**Medium Confidence Claims:**
- The safety buffer overhead of O(log(B/δ)) is sufficient to prevent overflow in practice (theoretically sound but not fully validated across diverse workloads)
- The approach generalizes to different model sizes and hardware configurations (supported by validation on Llama-7B but requires broader testing)

**Low Confidence Claims:**
- The optimal segment boundaries and threshold ratios are robust across all practical scenarios (requires extensive hyperparameter tuning and validation)

## Next Checks
1. **Production Workload Validation:** Deploy the Nested WAIT algorithm on a production LLM serving system with heterogeneous workloads and bursty traffic patterns. Measure throughput, latency, and eviction rates across different time scales to validate the approach under non-stationary conditions.

2. **Hardware Configuration Generalization:** Implement and test the threshold-based scheduling on multiple GPU architectures (e.g., H100, L4) and memory configurations (e.g., heterogeneous CPU-GPU memory). Verify that the fluid approximation and threshold calculations remain accurate across different hardware parameters d₀ and d₁.

3. **Heavy-Tailed Distribution Analysis:** Construct synthetic workloads with heavy-tailed output length distributions and non-stationary arrival patterns. Test whether the Nested WAIT algorithm maintains stability and whether the safety buffer analysis still provides adequate protection against overflow.