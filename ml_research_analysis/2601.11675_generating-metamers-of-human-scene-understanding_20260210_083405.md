---
ver: rpa2
title: Generating metamers of human scene understanding
arxiv_id: '2601.11675'
source_url: https://arxiv.org/abs/2601.11675
tags:
- scene
- image
- visual
- peripheral
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MetamerGen, a latent diffusion model that
  generates images from sparse visual inputs (high-resolution fixated regions plus
  blurred peripheral context) to study human scene understanding. The core innovation
  is a dual-stream DINOv2-based conditioning mechanism that integrates foveal (fixation-specific)
  and peripheral (blurred context) visual features into Stable Diffusion.
---

# Generating metamers of human scene understanding

## Quick Facts
- arXiv ID: 2601.11675
- Source URL: https://arxiv.org/abs/2601.11675
- Reference count: 40
- Primary result: MetamerGen generates fixation-specific scene metamer images using dual-stream DINOv2 conditioning, achieving 54.5% metamerism rate when combining foveal and peripheral streams

## Executive Summary
This paper introduces MetamerGen, a latent diffusion model that generates images from sparse visual inputs (high-resolution fixated regions plus blurred peripheral context) to study human scene understanding. The core innovation is a dual-stream DINOv2-based conditioning mechanism that integrates foveal (fixation-specific) and peripheral (blurred context) visual features into Stable Diffusion. In behavioral experiments (n=45), participants viewed scenes for variable fixations, then judged whether a second image (original or generation) was the same. MetamerGen achieved 29.4% metamerism rate with human fixations versus 27.7% with random fixations. Ablation experiments showed peripheral-only generations (45.8% metamerism) outperformed foveal-only (8.4%), but combining both streams yielded highest rates (54.5%). Feature analyses revealed high-level semantic alignment (DreamSim distance, CLIP similarity) most strongly predicted metamerism, while low-level features like Gabor textures and depth estimation also contributed. FID scores consistently improved with peripheral context quality and foveal token count, validating the dual-stream approach. MetamerGen thus provides a tool for generating fixation-specific scene hypotheses aligned with human perception.

## Method Summary
MetamerGen builds on Stable Diffusion by introducing a dual-stream DINOv2-based conditioning mechanism that processes both foveal (fixation-specific high-resolution regions) and peripheral (blurred context) visual features. The model extracts DINOv2 features from high-resolution fixated patches and corresponding peripheral context, then concatenates these features before passing them through a linear projection to condition the diffusion process. The approach generates metamer images that preserve the perceptual experience of human observers who view scenes with limited fixations, aiming to recreate the scene as perceived rather than as objectively recorded.

## Key Results
- MetamerGen achieved 29.4% metamerism rate when participants viewed human fixations versus 27.7% with random fixations
- Peripheral-only generations achieved 45.8% metamerism rate, dramatically outperforming foveal-only (8.4%) but optimal when combined (54.5%)
- High-level semantic features (DreamSim distance, CLIP similarity) showed strongest correlation with metamerism, while low-level features like Gabor textures and depth estimation also contributed
- FID scores consistently improved with peripheral context quality and foveal token count, validating the dual-stream approach

## Why This Works (Mechanism)
MetamerGen works by leveraging the human visual system's inherent foveal-peripheral architecture. The dual-stream DINOv2 conditioning captures both the detailed, fixation-specific information processed by the fovea and the contextual, gist-level information processed by peripheral vision. By conditioning the diffusion process with both streams, the model generates images that preserve the perceptual experience of human observers rather than objective scene reconstruction. The behavioral validation shows that these generated metamer images are sufficiently similar to originals when viewed under the same fixation constraints, demonstrating that the model successfully captures the essential features that define human scene perception.

## Foundational Learning
- **DINOv2 feature extraction**: DINOv2 is a self-supervised vision transformer that provides rich, hierarchical visual features. It's needed because it offers robust feature representations that capture both low-level and high-level visual information essential for scene understanding. Quick check: Verify DINOv2 features maintain semantic structure across different image scales and contexts.
- **Latent diffusion models**: These models denoise latent representations of images rather than pixels directly, enabling more efficient and higher-quality image generation. They're needed for generating high-resolution images from sparse conditioning information. Quick check: Confirm that the diffusion process preserves the conditioning features throughout the denoising steps.
- **Foveal-peripheral visual processing**: This biological mechanism describes how humans process detailed information in the fovea while relying on peripheral vision for context and gist. It's needed as the theoretical foundation for generating metamer images that match human perceptual experience. Quick check: Validate that the generated images preserve scene gist while allowing foveal details to vary.
- **Metamerism in perception**: Metamerism refers to different physical stimuli producing identical perceptual experiences. It's needed as the target phenomenon for evaluating whether generated images match human perceptual experience. Quick check: Ensure behavioral judgments reflect perceptual equivalence rather than pixel-level similarity.
- **CLIP and DreamSim similarity**: These metrics measure semantic and perceptual similarity between images using different feature spaces. They're needed for computationally validating that generated metamer images maintain perceptual relationships with originals. Quick check: Correlate these metrics with human behavioral judgments to validate their relevance.

## Architecture Onboarding

**Component map**: Input images -> DINOv2 feature extraction (foveal + peripheral streams) -> Feature concatenation and linear projection -> Stable Diffusion conditioning -> Latent diffusion generation -> Output metamer images

**Critical path**: The most critical path is from DINOv2 feature extraction through the conditioning mechanism to the diffusion process. This path must successfully capture and preserve both high-level semantic information and low-level visual details from the sparse input to generate perceptually equivalent metamer images.

**Design tradeoffs**: The primary tradeoff involves balancing foveal detail preservation against peripheral context integration. While peripheral information shows stronger behavioral effects, completely ignoring foveal details leads to poor metamerism rates. The model must balance computational efficiency (processing fewer foveal tokens) against perceptual fidelity.

**Failure signatures**: 
- If FID scores remain high despite dual-stream conditioning, this indicates poor integration of the feature streams or inadequate conditioning strength
- If behavioral metamerism rates don't exceed chance levels, this suggests the generated images fail to capture essential perceptual features
- If peripheral-only generations significantly outperform combined streams, this indicates problems with foveal stream integration or feature representation

**3 first experiments**:
1. Ablation testing with varying numbers of foveal tokens to determine optimal foveal detail level
2. Comparison of different feature extractors (DINOv2 vs alternatives) to validate feature quality
3. Testing different concatenation and projection strategies for the dual-stream conditioning

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Behavioral validation shows only modest advantage (29.4% vs 27.7% metamerism) of human fixations over random, raising questions about whether the model truly captures human perceptual priorities
- Peripheral-only generations (45.8% metamerism) dramatically outperform foveal-only (8.4%), suggesting potential underoptimization of the foveal stream integration
- Correlation between computational similarity metrics and human perception doesn't establish causation or guarantee perceptual equivalence

## Confidence
- **High confidence**: Technical implementation of dual-stream DINOv2 conditioning mechanism, FID score improvements with peripheral context quality
- **Medium confidence**: Behavioral metamerism rates showing advantage of human fixations over random, ablation results demonstrating peripheral importance
- **Low confidence**: Causal relationship between high-level feature alignment and human perceptual equivalence, optimal integration of foveal and peripheral streams

## Next Checks
1. Conduct a multi-alternative forced choice experiment where participants identify the original scene among multiple generated metamer options to better characterize perceptual discrimination
2. Perform eye-tracking validation where participants view both original and generated scenes while measuring fixation patterns to directly assess whether generated metamer distributions match human viewing behavior
3. Implement a psychophysical staircase procedure to determine the minimum peripheral degradation level that still allows accurate scene recognition, validating the peripheral-only generation approach