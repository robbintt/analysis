---
ver: rpa2
title: A Stylometric Application of Large Language Models
arxiv_id: '2510.21958'
source_url: https://arxiv.org/abs/2510.21958
tags:
- author
- authors
- each
- trained
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces "predictive comparison," a new stylometric
  method that uses large language models (LLMs) to capture and measure authorial style.
  The method trains separate GPT-2 models from scratch on each author's complete works,
  then measures cross-entropy loss when predicting held-out text.
---

# A Stylometric Application of Large Language Models

## Quick Facts
- arXiv ID: 2510.21958
- Source URL: https://arxiv.org/abs/2510.21958
- Reference count: 19
- Primary result: 100% classification accuracy for authorship attribution using predictive comparison with separate GPT-2 models

## Executive Summary
This paper introduces "predictive comparison," a novel stylometric method that leverages large language models to measure authorial style. The approach trains separate GPT-2 models from scratch on each author's complete works, then measures cross-entropy loss when predicting held-out text from different authors. Lower loss indicates higher stylistic similarity. The method successfully distinguishes eight classic authors with 100% classification accuracy and rapidly converges after just 1-2 training epochs.

The approach is validated on the well-known attribution problem of the 15th Oz book, confirming Thompson's authorship. Ablation studies reveal that both content words and function words contribute to authorial signatures, while part-of-speech patterns alone are less distinctive. This method provides both a tool for authorship attribution and a way to measure stylometric distances between authors.

## Method Summary
The predictive comparison method involves training separate GPT-2 models from scratch on the complete works of each author in the corpus. For each held-out text sample, the method computes cross-entropy loss when predicting the text using each author's model. The author whose model produces the lowest cross-entropy loss is considered the most likely author of the text. This approach captures both content and style information through the learned probability distributions over word sequences. The method was applied to eight classic authors (Jane Austen, L. Frank Baum, Charles Dickens, F. Scott Fitzgerald, Herman Melville, Ruth Plumly Thompson, Mark Twain, and H. G. Wells) using texts from Project Gutenberg.

## Key Results
- Achieved 100% classification accuracy in distinguishing eight classic authors
- Statistical significance reached after just 1-2 training epochs for most authors
- Successfully validated on the 15th Oz book attribution problem, confirming Thompson's authorship
- Both content words and function words contribute to authorial signatures; part-of-speech patterns alone are less distinctive

## Why This Works (Mechanism)
The method works by capturing the unique probability distributions that each author's writing style induces in a language model. When a model is trained on an author's complete works, it learns the specific patterns of word co-occurrence, sentence structure, and narrative flow that characterize that author's style. Cross-entropy loss measures how well the model can predict held-out text - lower loss indicates the text is more consistent with the patterns the model learned. By comparing losses across models trained on different authors, the method identifies which author's style best matches the held-out text. This approach captures subtle stylistic features that may not be apparent through traditional stylometric methods, including word choice patterns, syntactic preferences, and narrative construction.

## Foundational Learning
1. **Cross-entropy loss** - Measures the difference between predicted and actual probability distributions; needed to quantify how well a model's learned patterns match held-out text; quick check: compare loss values for different models on the same text
2. **Language model training from scratch** - Training separate models for each author captures unique stylistic signatures; needed because pre-trained models may have washed out author-specific features; quick check: verify each model's perplexity on its training corpus
3. **Stylometric analysis** - The quantitative study of writing style; needed as the broader context for authorship attribution methods; quick check: ensure text preprocessing preserves stylistic features while removing confounding variables
4. **Text preprocessing for authorship** - Tokenization, normalization, and handling of different text formats; needed to ensure fair comparison across authors; quick check: verify that preprocessing doesn't remove style-specific features
5. **Project Gutenberg text corpus** - Source of public domain literary works; needed as the dataset for training and testing; quick check: confirm text quality and completeness for each author
6. **Ablation study methodology** - Systematically removing features to understand their contribution; needed to identify which aspects of language are most distinctive; quick check: compare performance with and without specific feature types

## Architecture Onboarding

**Component Map**: GPT-2 model training -> Cross-entropy loss calculation -> Author classification

**Critical Path**: The core workflow involves: 1) Preprocessing text from each author, 2) Training separate GPT-2 models on each author's complete works, 3) Computing cross-entropy loss for held-out texts using each model, 4) Classifying authorship based on minimum loss, 5) Evaluating accuracy and convergence rates.

**Design Tradeoffs**: The method requires training separate models for each author, which is computationally expensive but captures unique stylistic signatures. Using complete works provides comprehensive style representation but may not generalize to shorter texts. Training from scratch avoids pre-trained model biases but requires more data and computation. The approach trades computational efficiency for potentially more nuanced style capture compared to traditional feature-based methods.

**Failure Signatures**: The method may fail when authors intentionally imitate each other's styles, when writing in different genres that have distinct stylistic conventions, or when dealing with very short text samples that don't capture sufficient stylistic information. Performance may degrade with modern authors whose styles are less distinctive or with non-literary text that lacks the narrative structures present in classic literature.

**Three First Experiments**:
1. Train separate GPT-2 models on two clearly distinct authors and measure cross-entropy loss for held-out texts
2. Vary the amount of training data per author to determine minimum requirements for effective style capture
3. Compare predictive comparison results with traditional stylometric feature-based methods on the same corpus

## Open Questions the Paper Calls Out
None

## Limitations
- May not generalize well to modern authors or non-literary text
- Requires complete works for effective style capture, limiting application to partial texts
- High computational cost due to training separate models for each author
- May struggle with attribution problems involving subtle stylistic differences or intentional imitation

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Basic method achieves 100% classification accuracy on tested corpus | High |
| Method converges rapidly (1-2 epochs) | Medium |
| Method generalizes to modern authors and non-literary text | Low |
| Method handles subtle stylistic differences effectively | Low |

## Next Checks
1. Test the method on a corpus of modern authors or non-literary text to assess generalizability beyond classic literature
2. Evaluate performance on shorter text segments or partial works to determine practical limits of the approach
3. Apply the method to attribution problems with more subtle stylistic differences or where authors may have intentionally imitated each other's styles