---
ver: rpa2
title: 'Application of Contrastive Learning on ECG Data: Evaluating Performance in
  Japanese and Classification with Around 100 Labels'
arxiv_id: '2504.09302'
source_url: https://arxiv.org/abs/2504.09302
tags:
- infarction
- wall
- ventricular
- hypertrophy
- left
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study applies contrastive learning to ECG data for Japanese
  clinical reports, using a multimodal model that combines a frozen Japanese medical
  language model (MedLlama3-JP-v2) with an ECG encoder (ResNet1d-18). The model was
  trained on 37,285 ECG records with 98 Japanese labels from Japanese hospitals, aiming
  to improve ECG interpretation across languages and with limited labeled data.
---

# Application of Contrastive Learning on ECG Data: Evaluating Performance in Japanese and Classification with Around 100 Labels

## Quick Facts
- arXiv ID: 2504.09302
- Source URL: https://arxiv.org/abs/2504.09302
- Reference count: 12
- This study applies contrastive learning to ECG data for Japanese clinical reports, using a multimodal model that combines a frozen Japanese medical language model (MedLlama3-JP-v2) with an ECG encoder (ResNet1d-18).

## Executive Summary
This study applies contrastive learning to ECG data for Japanese clinical reports, using a multimodal model that combines a frozen Japanese medical language model (MedLlama3-JP-v2) with an ECG encoder (ResNet1d-18). The model was trained on 37,285 ECG records with 98 Japanese labels from Japanese hospitals, aiming to improve ECG interpretation across languages and with limited labeled data. Results show that the model achieves strong classification accuracy, such as 89.41% for pacemaker rhythm and 78.40% for normal ECGs, with top-5 accuracy reaching 90.45% for normal cases. In zero-shot classification tasks, the model's accuracy (64.11% overall for superclass diagnosis, 78.88% for rhythm, and 76.43% for MIT-BIH) approaches that of prior English-language studies, demonstrating the effectiveness of contrastive learning for ECG-text alignment in non-English languages. The ablation study confirms that medical knowledge in the language model is crucial for high performance. Limitations include lower accuracy on hypertrophy-related labels, likely due to the need for additional data like echocardiography. Overall, this work extends multimodal ECG models to broader clinical and multilingual contexts, with potential applications in wearable devices and broader healthcare AI systems.

## Method Summary
The model uses a contrastive learning framework with a frozen Japanese medical language model (MedLlama3-JP-v2) and a ResNet1d-18 ECG encoder. The language model processes Japanese clinical reports formatted as "This ECG shows {reports}." while the ECG encoder processes 12-lead ECG signals (12×5000 timesteps). The model is trained with bidirectional contrastive loss using cosine similarity, with τ initialized to 0.07. Training uses AdamW optimizer with lr=1e-3, weight_decay=1e-3, global_batch_size=32, and 200 epochs on 2× NVIDIA A100-SXM4-80GB. The system achieves zero-shot classification by computing similarity between ECG embeddings and text embeddings of candidate labels.

## Key Results
- Achieves 89.41% accuracy for pacemaker rhythm and 78.40% for normal ECGs
- Top-5 accuracy reaches 90.45% for normal cases
- Zero-shot accuracy approaches English-language studies: 64.11% overall for superclass diagnosis, 78.88% for rhythm, and 76.43% for MIT-BIH

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contrastive learning aligns ECG signal representations with Japanese medical text embeddings in a shared latent space, enabling zero-shot classification.
- Mechanism: The model computes bidirectional contrastive loss (ECG-to-Text and Text-to-ECG) using cosine similarity, pulling positive ECG-text pairs closer while pushing negative pairs apart. This creates a joint embedding space where semantically similar ECGs cluster near their corresponding diagnostic descriptions.
- Core assumption: ECG signal patterns contain sufficient information to distinguish between diagnostic categories without additional clinical context (e.g., echocardiography).
- Evidence anchors:
  - [abstract]: "Using a contrastive learning framework, we found that even with 98 labels for classification, our Japanese-based language model achieves accuracy comparable to previous research."
  - [section 2.3]: Equations 2-4 detail the contrastive loss computation with temperature parameter τ=0.07 and batch-wise normalization.
  - [corpus]: "Poly-Window Contrastive Learning" paper confirms contrastive SSL effectiveness for ECG representations when labeled data is limited.
- Break condition: If ECG patterns for different diagnoses overlap significantly (e.g., hypertrophy subtypes), contrastive alignment may fail without additional modalities.

### Mechanism 2
- Claim: Medical knowledge embedded in the frozen language model improves ECG-text alignment quality compared to general-purpose language models.
- Mechanism: MedLlama3-JP-v2, pretrained on Japanese medical text, contains domain-specific semantic relationships (e.g., "inferior wall infarction" relates to "ST elevation in leads II, III, aVF"). These priors guide the ECG encoder to learn clinically meaningful features.
- Core assumption: The language model's medical knowledge transfers to ECG understanding without fine-tuning the language model itself.
- Evidence anchors:
  - [abstract]: "The ablation study confirms that medical knowledge in the language model is crucial for high performance."
  - [section 2.1]: "The model judged to have the best performance was MedLlama3-JP-v2... It has also achieved an accuracy of 46.6% on IgakuQA, a Japanese medical QA dataset."
  - [tables 5-7]: Ablation with non-medical Swallow model shows 6-8% lower overall accuracy and 15%+ drops on specific conditions (ST/T change: 35.66% vs 45.39%).
  - [corpus]: Limited direct corpus evidence on frozen LM for ECG; related papers focus on SSL pretraining without medical LLM integration.
- Break condition: If the frozen LM lacks coverage for specific diagnostic terminology or produces hallucinations for rare conditions, alignment quality degrades.

### Mechanism 3
- Claim: ResNet1d architecture captures ECG temporal patterns more effectively than transformer-based alternatives for this contrastive learning task.
- Mechanism: ResNet1d-18 processes 12-lead ECG sequences (12×5000 timesteps) through 1D convolutions with residual connections, extracting hierarchical temporal features that align with diagnostic text patterns.
- Core assumption: Local temporal patterns (e.g., QRS morphology, ST segments) are more critical than long-range dependencies for the 98-label classification task.
- Evidence anchors:
  - [section 2.2]: "ResNet-based models outperform Vision Transformer (ViT) in both zero-shot and linear probing tasks, and ResNet models are more effective in capturing ECG patterns."
  - [corpus]: "Beat-SSL" paper confirms heartbeat-level local morphology is critical for ECG contrastive learning.
  - [corpus]: "Domain Knowledge is Power" paper leverages physiological priors for ECG SSL, supporting architecture choices informed by domain structure.
- Break condition: For diagnoses requiring long-range rhythm analysis (e.g., arrhythmia patterns across multiple beats), ResNet1d may miss dependencies that attention mechanisms would capture.

## Foundational Learning

- Concept: **Contrastive Learning (CLIP-style multimodal alignment)**
  - Why needed here: The entire model architecture depends on understanding how bidirectional contrastive loss creates shared embedding spaces across modalities.
  - Quick check question: Can you explain why the loss function uses both ECG-to-Text and Text-to-ECG directions rather than a single direction?

- Concept: **1D Convolutions for Time-Series Medical Data**
  - Why needed here: ECG data is 12-channel time-series (12×5000); understanding how ResNet1d processes this versus 2D image convolutions is essential for debugging and modification.
  - Quick check question: What is the output shape after passing a 12×5000 ECG through ResNet1d-18, and how does this connect to the embedding dimension?

- Concept: **Zero-Shot Classification via Nearest-Neighbor in Embedding Space**
  - Why needed here: The paper's key evaluation metric involves zero-shot performance on unseen label sets (MIT-BIH, superclass diagnosis).
  - Quick check question: Given a new ECG embedding e_new and text embeddings {t_1, t_2, ..., t_k} for candidate labels, how would you compute the predicted label?

## Architecture Onboarding

- Component map: ECG Input (12×5000) → ResNet1d-18 → Linear Projection → ECG Embedding (e) → Cosine Similarity → Contrastive Loss ← Text Embedding (t) ← Linear Projection ← Last Hidden Layer ← MedLlama3-JP-v2 (frozen) ← Text Prompt

- Critical path:
  1. Data preprocessing: Format ECG reports as "This ECG shows {reports}." (Japanese)
  2. Forward pass through frozen MedLlama3-JP-v2 (no gradients)
  3. Forward pass through trainable ResNet1d-18
  4. Compute bidirectional contrastive loss
  5. Backprop through ResNet1d and projection layers only

- Design tradeoffs:
  - Frozen LM vs. fine-tuned LM: Frozen preserves medical knowledge but cannot adapt to ECG-specific terminology patterns
  - ResNet1d-18 vs. deeper ResNet: Lighter compute but may underfit complex patterns (evidenced by poor hypertrophy performance)
  - 98 labels vs. reduced label set: Higher clinical relevance but more imbalanced classes (some labels have <10 samples)

- Failure signatures:
  - Low accuracy on interval-based measurements (Prolonged PR: 40.67%, Prolonged QT: 12.62%) → model struggles with quantitative waveform analysis
  - Hypertrophy accuracy (42.35%) → ECG alone insufficient; needs echocardiography data
  - Large top-1 to top-5 gap for MI labels → semantic clustering works but fine-grained distinction fails

- First 3 experiments:
  1. **Reproduce baseline with MedLlama3-JP-v2 frozen**: Train ResNet1d-18 on the 37,285 ECG dataset with contrastive loss. Verify top-5 accuracy on Normal ECG reaches ~90% as reported.
  2. **Ablation with non-medical Japanese LM**: Replace MedLlama3-JP-v2 with Llama-3-Swallow (no medical pretraining). Expect 5-10% accuracy drop, confirming medical knowledge contribution.
  3. **Zero-shot evaluation on MIT-BIH mapping**: Use the label mappings in Table 8 to evaluate held-out categories. Target: >70% accuracy on rhythm labels to match paper's 78.88%.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can incorporating multimodal data, specifically echocardiography, improve the model's low accuracy in detecting hypertrophy?
- Basis in paper: [explicit] The authors note that diagnosing hypertrophy typically requires echocardiography and state, "This issue implies the importance of training with echocardiographic data," listing it as a future plan.
- Why unresolved: The current model relies solely on ECG data, which has low sensitivity for hypertrophy criteria, resulting in the lowest accuracy (42.35%) among superclass diagnoses.
- What evidence would resolve it: A future study where the model is trained on paired ECG and echocardiography data, demonstrating improved accuracy on hypertrophy-related labels.

### Open Question 2
- Question: Why does the non-medical Swallow model outperform the medical-specific MedLlama3-JP-v2 on specific conditions like hypertrophy?
- Basis in paper: [explicit] The ablation study showed higher accuracy for hypertrophy with the general Swallow model compared to the medical model, leading the authors to state this "indicates the necessity for further investigation about these specific cases."
- Why unresolved: It is counter-intuitive that a model without medical knowledge would perform better on specific medical labels, suggesting potential domain-specific overfitting or hallucination in the medical LLM that has not been analyzed.
- What evidence would resolve it: An analysis of the text embeddings and attention mechanisms of both models to determine if the medical model introduces conflicting biases for hypertrophy-related terms.

### Open Question 3
- Question: Can the trained ECG encoder be effectively integrated into a generative Large Multimodal Model (LMM) for report generation?
- Basis in paper: [inferred] The authors selected an autoregressive LLM architecture specifically "in order to integrate the created ECG model into a large multimodal model," but the current study only evaluates classification and zero-shot retrieval.
- Why unresolved: While the architecture was chosen to facilitate this integration, the paper does not demonstrate or validate the encoder's performance within a generative pipeline.
- What evidence would resolve it: Implementation of the encoder into an LMM framework to evaluate its ability to generate free-text medical reports from ECG input.

## Limitations

- The primary limitation is dataset accessibility - the 37,285 Japanese ECG records are proprietary, preventing independent validation of the core results.
- The model shows particularly weak performance on quantitative measurements (Prolonged QT: 12.62%) and hypertrophy diagnosis (42.35%), suggesting fundamental limitations when ECG patterns overlap or require multimodal clinical context.
- The frozen language model approach, while preserving medical knowledge, cannot adapt to ECG-specific terminology patterns, potentially limiting performance on rare or novel conditions.

## Confidence

- **High Confidence**: The contrastive learning mechanism for ECG-text alignment (Mechanisms 1-2) - supported by ablation studies showing 6-8% accuracy drops with non-medical LMs and consistent performance on rhythm/normal ECG classification.
- **Medium Confidence**: The ResNet1d-18 architecture choice for capturing temporal patterns - the architecture is specified but exact parameters are missing, and the poor performance on hypertrophy suggests potential limitations for complex diagnostic tasks.
- **Low Confidence**: Zero-shot classification accuracy claims - while the methodology is sound, the proprietary dataset and lack of public validation data make independent verification impossible.

## Next Checks

1. **Architecture ablation study**: Implement and test multiple ECG encoder architectures (ResNet1d-18, ViT, CNN) on publicly available ECG datasets (PTB-XL or MIMIC-IV-ECG) to verify the claimed superiority of ResNet1d for this contrastive learning task.

2. **Medical knowledge contribution quantification**: Replace MedLlama3-JP-v2 with a non-medical Japanese language model of similar size and architecture, then measure the exact performance degradation on both classification and zero-shot tasks to quantify the medical knowledge transfer benefit.

3. **Longitudinal performance validation**: Using the zero-shot evaluation protocol on MIT-BIH mapping, test model performance across different diagnostic superclasses to identify systematic failure patterns and validate the 64.11% overall zero-shot accuracy claim.