---
ver: rpa2
title: 'Edit Less, Achieve More: Dynamic Sparse Neuron Masking for Lifelong Knowledge
  Editing in LLMs'
arxiv_id: '2510.22139'
source_url: https://arxiv.org/abs/2510.22139
tags:
- editing
- neurons
- knowledge
- nmke
- neuron
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Neuron-Specific Masked Knowledge Editing\
  \ (NMKE), a fine-grained knowledge editing framework for large language models that\
  \ addresses the problem of error accumulation during sequential edits. NMKE uses\
  \ neuron-level attribution to identify two distinct types of knowledge neurons\u2014\
  knowledge-general neurons with stable cross-prompt activation and knowledge-specific\
  \ neurons with selective activation\u2014and constructs an entropy-guided dynamic\
  \ sparse mask to precisely target relevant neurons for editing."
---

# Edit Less, Achieve More: Dynamic Sparse Neuron Masking for Lifelong Knowledge Editing in LLMs

## Quick Facts
- arXiv ID: 2510.22139
- Source URL: https://arxiv.org/abs/2510.22139
- Reference count: 40
- Primary result: NMKE achieves 94% rel. and 86% gen. on ZsRE at T=1000 edits while preserving general capabilities

## Executive Summary
This paper introduces Neuron-Specific Masked Knowledge Editing (NMKE), a fine-grained knowledge editing framework for large language models that addresses the problem of error accumulation during sequential edits. NMKE uses neuron-level attribution to identify two distinct types of knowledge neurons—knowledge-general neurons with stable cross-prompt activation and knowledge-specific neurons with selective activation—and constructs an entropy-guided dynamic sparse mask to precisely target relevant neurons for editing. Experimental results on thousands of sequential edits show that NMKE significantly outperforms existing methods, maintaining high editing success rates (e.g., 94% rel. and 86% gen. on ZsRE at T=1000) while preserving general capabilities across multiple downstream tasks, including MMLU (0.59 after 5000 edits) and HumanEval (0.26), with minimal disruption to internal model parameters.

## Method Summary
NMKE operates on Feed-Forward Network (FFN) layers of LLMs, treating them as associative memories where keys map to values. The method first computes neuron attribution scores by measuring the log-probability shift when amplifying each neuron's activation. It then calculates entropy of these scores to dynamically determine which neurons are knowledge-general (stable activation) vs. knowledge-specific (selective activation). An entropy-guided sparse mask is constructed to select only the relevant neurons for editing, and parameter updates are applied only to these masked neurons following an AlphaEdit-style optimization pipeline. This approach minimizes distributional shift while ensuring edit success through precise neuron targeting.

## Key Results
- NMKE achieves 94% rel. and 86% gen. on ZsRE at T=1000 sequential edits
- Maintains general capabilities with MMLU score of 0.59 after 5000 edits
- Outperforms baselines (AlphaEdit, ROME) on both edit success rates and capability preservation
- Demonstrates minimal distributional shift in weight space compared to baseline methods

## Why This Works (Mechanism)

### Mechanism 1: Functional Neuron Segregation
The paper proposes that FFN neurons are functionally heterogeneous. "Knowledge-General" neurons exhibit stable activation across diverse prompts and support broad capabilities (e.g., reasoning structures), while "Knowledge-Specific" neurons activate selectively for specific facts. By calculating attribution scores and identifying stable vs. sharp activation patterns, NMKE isolates the specific neurons responsible for the target fact, preventing the destruction of general capabilities caused by coarse, layer-level updates. Evidence shows masking knowledge-general neurons causes severe degradation (accuracy dropping from 37.5% to 4.17%), while masking task-specific neurons leads to only minor drops.

### Mechanism 2: Entropy-Guided Dynamic Sparse Masking
Instead of selecting a fixed top-k percentage of neurons, NMKE calculates the entropy of attribution scores ($H_{ge}$ and $H_{sp}$). High entropy indicates a uniform distribution of importance (suggesting general knowledge), while low entropy suggests specific localization. This entropy value dynamically scales the selection ratio to ensure the mask is tight for specific facts and broader for general updates. Employing a fixed ratio for all prompt batches can incorporate irrelevant neurons when fewer neurons are well-activated, while the dynamic approach adapts to the actual knowledge density in each batch.

### Mechanism 3: Minimal Distributional Shift via Constrained Updates
By applying the binary sparse mask $m^{(l)}$ to the parameter update matrix, NMKE changes only the weights of the selected neurons. This leaves the surrounding "neighborhood" of the weight space untouched, preventing the accumulation of error that arises when entire layers are shifted. T-SNE visualizations show that NMKE maintains a more compact structure closely aligned with the original distribution compared to the dispersed geometry of AlphaEdit, demonstrating that localized changes do not trigger catastrophic interference if the majority of weights remain frozen.

## Foundational Learning

- **Concept: FFN as Key-Value Memory**
  - Why needed here: To understand where knowledge is stored. NMKE operates on FFN layers, treating them as associative memories where keys (input vectors) map to values (output concepts).
  - Quick check question: In the equation $y = \sum \sigma(k^{(i)}x)v^{(i)}$, which component represents the "value" that is modified to change a factual association?

- **Concept: Causal Tracing / Attribution**
  - Why needed here: This is the diagnostic tool used to identify "Knowledge-General" vs. "Knowledge-Specific" neurons. You cannot apply NMKE without understanding how to measure the contribution of a single neuron to the output probability.
  - Quick check question: If amplifying a neuron's activation by $\lambda$ increases the log-probability of the target token significantly, does this neuron have a high or low attribution score?

- **Concept: Locate-Then-Edit Paradigm**
  - Why needed here: NMKE is an advanced instance of this paradigm. Unlike "Fine-Tuning" (which updates all weights), Locate-then-Edit first identifies the critical region (here, specific neurons) and then applies a constrained optimization.
  - Quick check question: Why does standard gradient descent (Fine-Tuning) fail at "Locality" (preserving unrelated knowledge) in lifelong editing scenarios?

## Architecture Onboarding

- **Component map:** Input (edit descriptor + prompt batch) -> Neuron Attributor (computes importance scores) -> Entropy Calculator (computes $H_{ge}$, $H_{sp}$) -> Dynamic Mask Generator (sets thresholds $\tau$) -> Editor Core (computes masked updates) -> Output (edited model)

- **Critical path:** The Entropy Calculation → Thresholding step is the most sensitive. If the temperature $\alpha$ or bias terms $b$ in Eq. (6) and (7) are misconfigured, the mask will either include too many neurons (causing collapse) or too few (failing the edit).

- **Design tradeoffs:**
  - MPC vs. LPS Attribution: NMKE (MPC) is faster (~22s/edit) but slightly less accurate than NMKE (LPS) (~30s/edit). Choose MPC for production speed, LPS for maximum precision.
  - Masking Strategy: Editing only "Knowledge-General" neurons improves Locality but might reduce generalization on complex tasks. The "Hybrid" (Dynamic) mode is the default but requires tuning two sets of hyperparameters ($a_{ge}, b_{ge}$ vs $a_{sp}, b_{sp}$).

- **Failure signatures:**
  - Catastrophic Forgetting: If the mask ratio $\rho$ is too high (entropy bias too high), general capability scores (MMLU/GSM8K) will drop sharply (mimicking AlphaEdit failure modes).
  - Edit Failure: If the mask is too sparse (low entropy sensitivity), "Reliability" (Rel.) scores will remain low at T > 500, indicating the model refuses to learn the new fact.
  - Locality Loss: If "Knowledge-General" neurons are inadvertently masked, the model will output meaningless tokens (brackets, stop words) as seen in Figure 2.

- **First 3 experiments:**
  1. **Neuron Type Ablation:** Run editing with mask set to only General neurons vs. only Specific neurons on ZsRE to reproduce Figure 6 and verify the functional separation claims.
  2. **Sequential Scaling Test:** Run 2000 edits on CounterFact and plot the "Locality" score curve. Compare NMKE vs. AlphaEdit to confirm that NMKE's curve remains stable while AlphaEdit drops near zero.
  3. **Visual Drift Check:** Extract the down-projection weights of the 8th MLP layer after 1000 edits and plot a histogram/t-SNE. Verify that NMKE weights match the pre-edited model distribution closer than the baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can editing frameworks shift from discrete neuron categorization to continuous importance measures that account for cross-layer information flow?
- **Basis in paper:** Appendix C states that neuron responses vary along a continuum and are influenced by cross-layer interactions, suggesting the need for "path-aware attribution and masks that remain consistent across layers."
- **Why unresolved:** The current NMKE method categorizes neurons into binary groups (knowledge-general vs. knowledge-specific) within specific layers, potentially missing nuanced contributions that span multiple layers or vary continuously.
- **What evidence would resolve it:** A new attribution method that assigns continuous, rather than binary, scores to neurons based on multi-layer paths, demonstrating improved stability in long-horizon editing.

### Open Question 2
- **Question:** How can lifelong editing methods automatically enforce dependency closure to prevent conflicts between related facts?
- **Basis in paper:** Appendix C highlights that edits should satisfy "dependency closure" (e.g., updating the current CEO should remain consistent with the total number of CEOs), noting that quantifying propagation errors is a key future direction.
- **Why unresolved:** NMKE currently edits facts sequentially based on isolated requests without verifying logical consistency with other stored facts, risking the creation of internal conflicts.
- **What evidence would resolve it:** An extension of the framework that detects related facts and performs joint updates or constraints to maintain logical consistency across dependent knowledge triples.

### Open Question 3
- **Question:** Is the entropy-guided dynamic masking heuristic robust across diverse model architectures without the need for architecture-specific tuning?
- **Basis in paper:** While Section 3.2.2 introduces entropy-based ratios ($H_{ge}, $H_{sp}$) to guide masking, the selection still relies on constant scalers ($a_{ge}, b_{ge}$) and bias terms. The paper notes in Appendix B.6 that these were set empirically, raising questions about generalizability to architectures with different activation distributions.
- **Why unresolved:** It is unclear if the relationship between activation entropy and optimal masking ratio holds universally for all LLMs or if it is an artifact of the specific LLaMA/Qwen architectures tested.
- **What evidence would resolve it:** A sensitivity analysis showing that the optimal hyperparameters for the entropy scaler remain stable across a wide variety of model architectures (e.g., Mamba, large MoE models) without retuning.

## Limitations
- The functional separation of neurons into "Knowledge-General" and "Knowledge-Specific" categories has not been tested across diverse model architectures beyond LLaMA3-8B-Instruct and GPT2-XL.
- The entropy-guided dynamic masking mechanism lacks extensive ablation studies on hyperparameter sensitivity (α, a_ge, b_ge, a_sp, b_sp).
- The paper does not explore the long-term stability of edits beyond 1000 sequential updates, leaving questions about whether preservation of general capabilities would persist over tens of thousands of edits.

## Confidence
- **High Confidence**: The empirical results showing NMKE's superiority over baselines (AlphaEdit, ROME, etc.) in sequential editing scenarios are well-supported by the presented experiments.
- **Medium Confidence**: The mechanism explaining why NMKE works—specifically, the segregation of knowledge-general vs. knowledge-specific neurons—is plausible and supported by ablation studies, but could benefit from more extensive analysis across different model sizes and tasks.
- **Low Confidence**: The claim that entropy-guided dynamic masking is essential for lifelong editing success is supported by the proposed mechanism but lacks direct experimental comparison with fixed-ratio masking under identical conditions.

## Next Checks
1. **Cross-Architecture Validation:** Replicate the sequential editing experiment (T=1000) on at least two additional model architectures (e.g., Mistral and Gemma) to verify that the neuron segregation mechanism generalizes beyond LLaMA3-8B-Instruct and GPT2-XL.

2. **Fixed vs. Dynamic Masking Ablation:** Implement a version of NMKE that uses fixed masking ratios (top-k selection) instead of entropy-guided dynamic masking, and compare performance on ZsRE sequential editing to isolate the contribution of the dynamic mechanism.

3. **Long-term Stability Test:** Extend the sequential editing experiment to T=5000 or T=10000 edits and monitor the degradation curves for Rel., Gen., and Loc. metrics, particularly focusing on whether the preservation of general capabilities remains stable or eventually degrades.