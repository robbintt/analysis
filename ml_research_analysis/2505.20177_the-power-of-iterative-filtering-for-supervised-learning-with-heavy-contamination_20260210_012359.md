---
ver: rpa2
title: The Power of Iterative Filtering for Supervised Learning with (Heavy) Contamination
arxiv_id: '2505.20177'
source_url: https://arxiv.org/abs/2505.20177
tags:
- learning
- sfilt
- sinp
- scln
- contamination
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of supervised learning from datasets
  contaminated with adversarial noise, both in the input space and labels. The authors
  propose a general iterative polynomial filtering algorithm that removes outliers
  from the dataset while preserving low-degree polynomial expectations, applicable
  to any hypercontractive distribution.
---

# The Power of Iterative Filtering for Supervised Learning with (Heavy) Contamination

## Quick Facts
- **arXiv ID:** 2505.20177
- **Source URL:** https://arxiv.org/abs/2505.20177
- **Reference count:** 40
- **Primary result:** General iterative polynomial filtering algorithm removes outliers from contaminated datasets while preserving low-degree polynomial expectations under hypercontractive distributions.

## Executive Summary
This paper addresses supervised learning from datasets contaminated with adversarial noise, both in input space and labels. The authors propose a general iterative polynomial filtering algorithm that removes outliers while preserving low-degree polynomial expectations, applicable to any hypercontractive distribution. The work resolves a long-standing gap between agnostic and contamination learning by showing polynomial approximation implies efficient bounded contamination learning, and introduces sandwiching approximation as a sufficient condition for heavy contamination learning where more than half the dataset can be adversarially corrupted.

## Method Summary
The method uses iterative filtering based on polynomials whose absolute expectations are small under the target distribution. In each iteration, the algorithm identifies and removes points that cause large values in these polynomials, ensuring the filtered dataset maintains good approximation properties. The core approach requires clean reference samples from the target distribution to define filtering criteria, making it distribution-specific rather than universal. After filtering, standard $L_1$ polynomial regression is applied to the cleaned dataset to obtain the final classifier.

## Key Results
- Polynomial approximation implies efficient bounded contamination learning, resolving the gap between agnostic and contamination learning
- Sandwiching approximation implies efficient heavy contamination learning where >50% of data can be adversarially corrupted
- First efficient algorithms for tolerant testable learning of functions of halfspaces under log-concave distributions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Iterative polynomial filtering can remove arbitrary outliers from a dataset while preserving the statistical properties (specifically, low-degree polynomial expectations) of the clean underlying distribution.
- **Mechanism:** The algorithm uses a clean "reference" set from the target distribution $D^*$ to define a family of polynomials $\mathcal{P}$ with bounded expectations. It iteratively solves a convex program to find the polynomial $p^*$ maximizing the empirical expectation on the current dataset. If the expectation exceeds a threshold $\epsilon$, points with large $|p^*(x)|$ values are removed. This loop continues until all low-degree polynomials have bounded expectations on the filtered set.
- **Core assumption:** The target distribution $D^*$ is **hypercontractive** (e.g., Gaussian or log-concave), ensuring that polynomials with small expectation on the reference set also have small expectation on clean data.
- **Evidence anchors:** [abstract] "The core method uses iterative filtering based on polynomials whose absolute expectations are small under the target distribution." [section 3, Theorem 3.2] "Algorithm 1... outputs $S_{filt} \subseteq S_{inp}$ such that... the algorithm removes a relatively small number of the examples in $S_{cln}$."
- **Break condition:** If the distribution is not hypercontractive, the concentration bounds required to distinguish outliers from clean data may fail, causing the filter to remove valid data or retain noise.

### Mechanism 2
- **Claim:** Efficient learning under **bounded contamination** (where $<50\%$ of data is corrupted) is possible for any concept class approximable by low-degree polynomials.
- **Mechanism:** The paper shows that $L_2$-approximation is sufficient. Since the clean function $f^*$ is close to a polynomial $p^*$, and filtering preserves the expectation of $p^*$, the filtered dataset keeps the $L_1$ error of $p^*$ small. Standard $L_1$ polynomial regression on this filtered set then yields a classifier with error $2\eta + \epsilon$.
- **Core assumption:** The concept class admits low-degree $L_2$ polynomial approximators (e.g., halfspaces, intersections of halfspaces) with respect to the target distribution.
- **Evidence anchors:** [abstract] "We show that any function class that can be approximated by low-degree polynomials... can be efficiently learned under bounded contamination." [section 4.1, Theorem 4.2] "Polynomial Approximation implies BC-Learning... there is an algorithm that $(\epsilon,\delta)$-learns $C$ under bounded contamination."
- **Break condition:** If the approximation degree is high (exponential in $d$), the computational complexity of the regression step becomes intractable.

### Mechanism 3
- **Claim:** Efficient learning under **heavy contamination** (where $>50\%$ of data can be added) requires the stronger condition of **sandwiching approximators**.
- **Mechanism:** Heavy contamination requires strictly more robustness than bounded contamination. "Sandwiching" polynomials ($p_{down} \le f \le p_{up}$) provide point-wise bounds. By tuning the filtering selectivity ($R$) relative to the contamination ratio ($Q$), the algorithm ensures that the filtered set maintains the sandwiching property, allowing the learner to identify the correct hypothesis even when outliers dominate the count.
- **Core assumption:** The concept class admits **sandwiching** approximators (stronger than standard approximators) of low degree.
- **Evidence anchors:** [abstract] "For any function class that admits the (stronger) notion of sandwiching approximators, we obtain near-optimal learning guarantees even with respect to heavy additive contamination." [section 4.2, Theorem 4.4] "Sandwiching implies HC-Learning."
- **Break condition:** If only standard approximators exist (and not sandwiching ones), the algorithm may fail to distinguish the true hypothesis from adversarial duplicates in heavy contamination scenarios.

## Foundational Learning

- **Concept: Hypercontractivity**
  - **Why needed here:** This property (common in Gaussians and log-concave distributions) restricts the "tails" of polynomials. It is the mathematical engine allowing the filter to confidently identify points that deviate significantly from the distribution's norm as outliers.
  - **Quick check question:** Does the target distribution $D^*$ satisfy the inequality $E[|p(x)|^t] \le (At)^\ell E[|p(x)|]^t$ for low-degree polynomials $p$?

- **Concept: $L_1$ Polynomial Regression**
  - **Why needed here:** After filtering, the problem reduces to learning from a "clean-ish" set. Minimizing the $L_1$ distance (absolute error) between the polynomial and labels is the standard robust regression technique used to finalize the classifier.
  - **Quick check question:** Can you solve for $\hat{p} = \text{argmin}_p E[|y - p(x)|]$ efficiently given the degree constraints?

- **Concept: Sandwiching Approximators**
  - **Why needed here:** In heavy contamination, standard approximation is insufficient. You need an upper ($p_{up}$) and lower ($p_{down}$) polynomial bound on the function to ensure that the "gap" between them remains small even when the dataset is flooded with adversarial points.
  - **Quick check question:** For your concept class $C$, can you find polynomials $p_{up}, p_{down}$ such that $p_{down}(x) \le f(x) \le p_{up}(x)$ for all $x$, while maintaining a small expected gap $E[p_{up}-p_{down}]$?

## Architecture Onboarding

- **Component map:** Reference Sampler -> Filter Loop -> Regressor
- **Critical path:** The iterative filtering step (Algorithm 1). The convex program in Line 5 (finding the polynomial with maximum empirical expectation) determines the runtime per iteration.
- **Design tradeoffs:**
  - **Selectivity ($R$):** Increasing $R$ removes fewer clean points but requires a stronger approximation degree (or higher sample complexity).
  - **Degree ($\ell$):** Higher degree allows fitting more complex classes but increases the size of the convex program $(d+1)^\ell$ and sample complexity.
- **Failure signatures:**
  - **Empty Output:** Filter is too aggressive (tolerance $\epsilon$ too small or $R$ too small), removing all data.
  - **Divergence:** The convex solver fails to find a separating polynomial, implying the reference set and input set are indistinguishable (distribution shift or non-hypercontractivity).
  - **High Error:** Filter converges, but the final regressor has high error. This indicates the approximation degree $\ell$ is insufficient for the concept class.
- **First 3 experiments:**
  1. **Sanity Check (Gaussian BC):** Validate Theorem 4.2. Generate synthetic Gaussian data, flip labels/corrupt features at rate $\eta$, and verify if the algorithm achieves $2\eta + \epsilon$ error on halfspaces.
  2. **Heavy Contamination Stress Test:** Validate Theorem 4.4. Generate data where $Q=2$ (adversary doubles the dataset size). Test if the algorithm recovers the true function for a class with known sandwiching polynomials (e.g., halfspace intersections).
  3. **Ablation on $L_1$ vs $L_2$ Approximation:** Compare the BC-learner performance using $L_2$ approximators (proposed) vs. $L_1$ approximators on a class where they differ, to empirically verify the necessity of the stronger approximation assumption claimed in the paper.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can learning algorithms for contamination models be made universal with respect to broad classes of distributions without requiring samples from the target unlabeled distribution $D^*$?
- **Basis in paper:** [explicit] Section 6, "Universality".
- **Why unresolved:** The proposed iterative filtering algorithms explicitly require samples from the target marginal distribution $D^*$ to define the filtering criteria, whereas universal algorithms for label noise exist.
- **Evidence to resolve:** An efficient algorithm that performs BC-learning or HC-learning over a class of distributions without needing samples from the specific target distribution.

### Open Question 2
- **Question:** Is the weaker notion of $L_1$ polynomial approximation sufficient for efficient BC-learning, or can the sandwiching requirement be relaxed for HC-learning?
- **Basis in paper:** [explicit] Section 6, "Characterization of Efficient Learnability under Contamination".
- **Why unresolved:** The paper proves $L_2$ approximation suffices for BC-learning and sandwiching for HC-learning, but it remains open whether the weaker $L_1$ condition (standard for agnostic learning) is sufficient.
- **Evidence to resolve:** An efficient BC-learning algorithm utilizing only $L_1$ approximators, or a lower bound proving that $L_2$ approximation is strictly necessary.

### Open Question 3
- **Question:** Can monotone functions be learned in time $2^{\tilde{O}(\sqrt{d})}$ under realizable heavy contamination?
- **Basis in paper:** [explicit] Section 6, "Heavy Contamination without Label Noise".
- **Why unresolved:** The paper provides a $2^{\Omega(d)}$ lower bound for general heavy contamination, but suggests the "realizable" setting (where the adversary adds correctly labeled points) might bypass this lower bound.
- **Evidence to resolve:** An algorithm that achieves runtime $2^{\tilde{O}(\sqrt{d})}$ for monotone functions when the adversary is restricted to adding correctly labeled examples.

## Limitations
- The algorithm requires clean reference samples from the target distribution, making it distribution-specific rather than universal
- Computational complexity grows exponentially with polynomial degree, creating a tradeoff between approximation power and tractability
- The sandwiching approximation requirement for heavy contamination learning is restrictive and may not be satisfied by all concept classes

## Confidence
- **High Confidence:** The core filtering mechanism and its connection to hypercontractivity (Mechanism 1) is well-supported by the literature on polynomial concentration inequalities
- **Medium Confidence:** The bounded contamination results (Mechanism 2) are solid, but the computational complexity claims need empirical validation for high-dimensional settings
- **Medium Confidence:** The heavy contamination framework (Mechanism 3) is theoretically sound, but the sandwiching approximation requirement represents a significant practical limitation that warrants further investigation

## Next Checks
1. **Distribution Dependency Test:** Validate the algorithm on non-hypercontractive distributions (e.g., Cauchy) to identify the precise breaking point where polynomial concentration fails
2. **Complexity Scaling Experiment:** Measure actual runtime as a function of dimension $d$ and degree $\ell$ to verify the $(d+1)^{\ell}$ scaling claim for the convex program
3. **Approximation Gap Analysis:** Construct explicit examples where sandwiching approximators exist but standard approximators do not, to empirically verify the necessity of this stronger assumption for heavy contamination