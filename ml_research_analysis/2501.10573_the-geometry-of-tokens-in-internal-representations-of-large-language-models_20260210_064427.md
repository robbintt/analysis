---
ver: rpa2
title: The Geometry of Tokens in Internal Representations of Large Language Models
arxiv_id: '2501.10573'
source_url: https://arxiv.org/abs/2501.10573
tags:
- token
- layers
- tokens
- prompts
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work studies the geometric properties of token embeddings
  in transformer models, focusing on their connection to next-token prediction. It
  employs intrinsic dimension, neighborhood overlap, and cosine similarity to probe
  the distribution of token representations across layers, using shuffled prompts
  as a control to disrupt syntactic and semantic structure.
---

# The Geometry of Tokens in Internal Representations of Large Language Models

## Quick Facts
- arXiv ID: 2501.10573
- Source URL: https://arxiv.org/abs/2501.10573
- Reference count: 40
- Primary result: Intrinsic dimension of token embeddings correlates with next-token prediction uncertainty, peaking in early-to-middle layers.

## Executive Summary
This work investigates the geometric properties of token embeddings in transformer models, focusing on how intrinsic dimension, neighborhood overlap, and cosine similarity relate to next-token prediction. Using shuffled prompts as a control to disrupt syntactic and semantic structure, the authors find that intrinsic dimension peaks in early-to-middle layers, with shuffled prompts exhibiting higher peaks. Crucially, intrinsic dimension correlates positively with cross-entropy loss, indicating that higher-dimensional token representations correspond to less predictable next tokens. This suggests geometric properties of token embeddings encode predictive uncertainty and may serve as an interpretable metric for model behavior.

## Method Summary
The authors analyzed Llama 3 8B, Mistral 7B, and Pythia 6.9B models using the Pile-10K dataset, filtering for prompts with sequence length ≥1024 tokens (final dataset: 2244 prompts). They extracted hidden states after the MLP layer for all 32 layers, computed intrinsic dimension using the TWO-NN estimator with range scaling = 2, and measured neighborhood overlap with k=2. Prompts were shuffled by dividing into 4^S blocks and permuting them (S=0 to 5). The key analysis involved computing the Pearson correlation between log(ID) and average cross-entropy loss across layers, comparing structured versus shuffled prompts.

## Key Results
- Intrinsic dimension peaks in early-to-middle layers, with shuffled prompts showing higher peaks than structured prompts
- Neighborhood overlap is lower for shuffled cases around the ID peak layers
- Log(intrinsic dimension) correlates positively with cross-entropy loss (ρ ≈ 0.43) at layers corresponding to the ID peak

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Intrinsic dimension of token representations correlates with next-token prediction uncertainty.
- **Mechanism:** The softmax function maps high-dimensional logit manifolds to probability distributions where expected entropy scales logarithmically with manifold dimension (theoretical toy models show ⟨S⟩ ~ log D_M). Higher-dimensional token representations at intermediate layers encode more uncertain predictions.
- **Core assumption:** The logit manifold dimension approximates the activation manifold dimension (linear unembedding preserves structure).
- **Evidence anchors:**
  - [abstract] "intrinsic dimension correlates positively with cross-entropy loss, indicating that higher-dimensional token representations correspond to less predictable next tokens"
  - [Section 5] Pearson correlation ρ ≈ 0.43 between logit ID and contextual entropy; Figure 6 shows layerwise correlation peaks around ID peak
  - [corpus] Weak direct support; corpus papers focus on embedding geometry but not the ID-loss relationship.
- **Break condition:** If unembedding is highly non-linear or manifold structure is destroyed, the correlation should weaken or disappear.

### Mechanism 2
- **Claim:** Syntactic and semantic structure constrains token geometry throughout processing.
- **Mechanism:** Shuffled prompts (disrupted structure) show higher ID peaks and higher cosine similarity, indicating tokens spread into less structured, more aligned configurations. Structured prompts maintain coherent neighborhoods (higher NO), suggesting the model exploits regularities to organize representations.
- **Core assumption:** Shuffling preserves unigram statistics while destroying higher-order structure; geometric differences arise from this disruption.
- **Evidence anchors:**
  - [Section 4.1] Cosine similarity "increases with increasing shuffling and increasing layers"
  - [Section 4.3] NO is "lower for shuffled cases around the layers corresponding to the ID peak"
  - [corpus] [2503.21073] finds shared geometric structure across model embeddings, supporting structure-sensitive geometry.
- **Break condition:** If shuffling doesn't change ID/cosine similarity/NO, structural constraints aren't geometrically encoded.

### Mechanism 3
- **Claim:** Early-to-middle layers form a "representation expansion" phase before refinement.
- **Mechanism:** The ID peak in early-to-middle layers reflects the model building rich, high-dimensional representations that encode prediction uncertainty. Later layers compress/refine these toward outputs (lower ID, higher clustering—related to rank collapse phenomena).
- **Core assumption:** Layerwise ID dynamics reflect computational phases rather than random artifacts.
- **Evidence anchors:**
  - [Section 4.2] "we observe a peak in ID in the early to middle layers"
  - [Section 1] References [13] on middle-layer prediction accuracy and [5] on clustering in later layers
  - [corpus] [2511.05963] discusses latent state compression, conceptually aligned with late-layer refinement.
- **Break condition:** If peak location varies randomly across prompts/models without pattern, the phase interpretation fails.

## Foundational Learning

- **Concept: Intrinsic Dimension Estimation (GRIDE/TWO-NN)**
  - Why needed here: Core metric for measuring representation complexity. TWO-NN uses ratio of first-to-second nearest neighbor distances.
  - Quick check question: If all points lie on a line in 100D space, what ID should TWO-NN return?

- **Concept: Empirical Measure (Mean-Field Particle View)**
  - Why needed here: Theoretical framing—tokens as particles whose evolution depends on their distribution (empirical measure), enabling dynamical analysis.
  - Quick check question: How does the empirical measure at layer ℓ differ from the output measure?

- **Concept: Logit Lens / Latent Predictions**
  - Why needed here: Explains why intermediate layers encode prediction-relevant geometry—unembedding at each layer reveals evolving predictions.
  - Quick check question: What would you observe if you applied the unembedding matrix to layer 5 vs. layer 30 activations?

## Architecture Onboarding

- **Component map:**
  Input tokens → Embedding layer (layer 0) → 32 transformer blocks (attention + MLP with residual connections) → Final unembedding

- **Critical path:**
  1. Extract token representations from all layers (N=1024 tokens minimum for stable ID)
  2. Compute pairwise distances → nearest neighbors → ID (GRIDE), NO, cosine similarity
  3. Compare against cross-entropy loss per prompt
  4. Run shuffle controls (block shuffling with indices S=0,1,...,5)

- **Design tradeoffs:**
  - Range scaling (n2=2,4,8): Lower scaling captures local manifold structure; higher scaling smooths noise but may miss fine geometry
  - kNN choice for NO: Must match ID scale for consistent interpretation
  - Prompt length: Shorter prompts give unreliable ID estimates; longer prompts increase compute

- **Failure signatures:**
  - Flat ID curves across layers → check extraction pipeline, may be reading wrong tensor
  - No correlation with loss → verify loss computation matches model's prediction targets
  - Shuffled/unshuffled ID identical → verify shuffling implementation (block vs. full permutation)

- **First 3 experiments:**
  1. Replicate Figure 3 (ID profile) on 10 prompts from Pile-10K with your target model; verify peak location
  2. Implement shuffle control (S=0,5 comparison); confirm shuffled ID > unshuffled ID at peak
  3. Compute Pearson correlation between log(ID) and cross-entropy loss across 100+ prompts; target ρ > 0.3 around peak layers

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the relationship where expected softmax entropy scales with the logarithm of manifold dimension generalize to arbitrary logit manifolds?
- Basis in paper: [explicit] The authors state, "We reserve this for future work" regarding whether this relation holds beyond the specific toy examples (unit box, probability simplex).
- Why unresolved: The paper theoretically validates the entropy-dimension link only for simplified cases, not for the complex manifolds found in actual LLMs.
- What evidence would resolve it: Empirical validation of the ⟨S⟩ ~ log D_M relationship on real, high-dimensional logit manifolds within trained models.

### Open Question 2
- Question: How does the token-level intrinsic dimension (ID) profile evolve dynamically throughout the training process?
- Basis in paper: [explicit] The authors note, "We believe it would be intriguing to explore these aspects in greater depth, but we defer this investigation to future work."
- Why unresolved: The study focuses on pre-trained models, leaving the proposed competition between rising expressivity (increasing ID) and loss minimization (decreasing ID) during training untested.
- What evidence would resolve it: Longitudinal analysis tracking ID peaks and loss correlation across training checkpoints to observe the developmental landscape.

### Open Question 3
- Question: What geometric observables characterize the distinguishable arrangement of tokens in shuffled versus structured data?
- Basis in paper: [explicit] The authors conclude, "It is interesting to consider other geometric observables" to better encode the differences in distribution patterns.
- Why unresolved: While ID, neighborhood overlap, and cosine similarity show differences, the specific geometry (e.g., why nearest neighbors form equilateral triangles in shuffled data) is not fully characterized.
- What evidence would resolve it: Applying advanced topological or geometric metrics (e.g., persistent homology, curvature) to token clouds at the ID peak.

## Limitations
- The correlation between ID and loss explains less than 20% of variance in prediction uncertainty
- Shuffling control doesn't definitively prove structural constraints cause geometric differences
- The "representation expansion" interpretation is plausible but not definitively proven without ablation studies

## Confidence
**High Confidence**: The empirical observations of ID peaks, cosine similarity increases, and NO patterns are directly measurable and reproducible. The correlation between log(ID) and cross-entropy loss is statistically robust across multiple models and datasets.

**Medium Confidence**: The interpretation that higher ID corresponds to less predictable next tokens through manifold dimension-entropy relationships is theoretically grounded but simplified. The mechanism assumes Euclidean geometry and ignores potential nonlinear relationships between manifold structure and probability distributions.

**Low Confidence**: The causal claims about shuffling revealing structural constraints are the weakest link—correlation does not establish that structure causes the geometric differences rather than both being consequences of some third factor like token frequency distributions or position encoding effects.

## Next Checks
1. **Ablation on Unembedding Matrix**: Remove or randomize the unembedding matrix and recompute ID-loss correlations. If the correlation disappears or reverses, this validates that the linear projection assumption is critical; if it persists, geometric properties encode uncertainty through other mechanisms.

2. **Synthetic Structure Test**: Generate controlled synthetic sequences with known hierarchical structure (e.g., balanced parentheses, nested brackets) and apply the shuffling control. Verify that geometric properties respond monotonically to the degree of structural violation, providing stronger evidence that syntactic/semantic structure specifically drives the observed patterns.

3. **Layerwise Manifold Comparison**: At the ID peak layer, compute the actual manifold dimension using persistent homology or other topology-aware methods, then compare against TWO-NN estimates. If discrepancies exist, investigate whether TWO-NN is capturing the wrong geometric features or if the relationship between manifold dimension and prediction uncertainty operates through different mechanisms than assumed.