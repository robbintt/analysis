---
ver: rpa2
title: Spatially-Adaptive Conformal Graph Transformer for Indoor Localization in Wi-Fi
  Driven Networks
arxiv_id: '2601.22322'
source_url: https://arxiv.org/abs/2601.22322
tags:
- uni00000013
- localization
- indoor
- graph
- uni00000011
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of accurate and reliable indoor
  localization using Wi-Fi RSSI signals. It proposes a framework called SAC-GT that
  combines a Graph Transformer model with a Spatially-Adaptive Conformal Prediction
  method.
---

# Spatially-Adaptive Conformal Graph Transformer for Indoor Localization in Wi-Fi Driven Networks

## Quick Facts
- arXiv ID: 2601.22322
- Source URL: https://arxiv.org/abs/2601.22322
- Authors: Ayesh Abu Lehyeh; Anastassia Gharib; Safwan Wshah
- Reference count: 18
- Primary result: 1.37m median localization error with 84.8% SACP coverage on SODIndoorLoc

## Executive Summary
This paper addresses indoor localization using Wi-Fi RSSI signals by proposing SAC-GT, a framework that combines Graph Transformer modeling with Spatially-Adaptive Conformal Prediction. The Graph Transformer leverages the spatial topology of Wi-Fi Access Points to provide precise 2D coordinate predictions, while the SACP method generates region-specific confidence regions to quantify prediction uncertainty. Experiments on the SODIndoorLoc dataset demonstrate state-of-the-art performance with a median localization error of 1.37 meters, outperforming baseline methods like GCN and Random Forest.

## Method Summary
The framework constructs a graph where User and AP nodes are connected by physical links (based on RSSI thresholds) and logical links (based on AP proximity). A 2-layer Graph Transformer with attention mechanisms learns spatial dependencies from RSSI signals to predict 2D coordinates. Spatially-Adaptive Conformal Prediction partitions the space into regions, computing unique uncertainty radii per region to maintain valid coverage while minimizing radius size. The system is trained on 11,370 samples and tested on 860 samples from the SODIndoorLoc dataset.

## Key Results
- Achieved 1.37m median localization error, outperforming GCN (1.51m) and Random Forest (1.65m) baselines
- Generated region-specific confidence regions with 84.8% overall test coverage (target: 90%)
- Demonstrated spatially adaptive reliability with radii ranging from 1.70m to 3.78m across different regions

## Why This Works (Mechanism)

### Mechanism 1
Encoding the indoor environment as a graph with hybrid edges allows the model to learn spatial constraints that flat vectors ignore, improving localization accuracy. The model constructs a graph where nodes (User and APs) are connected by two edge types: "physical links" (dynamic, based on received signal strength ≥ τ) and "logical links" (static, based on AP proximity ≤ dp). This structure enforces the physical reality that signals originate from specific, fixed locations, allowing the Graph Transformer to aggregate features based on spatial relevance rather than just input order.

### Mechanism 2
Partitioning the error space spatially allows for tighter and more valid confidence regions compared to global uncertainty estimates. Instead of applying one uncertainty radius to the entire map, Spatially-Adaptive Conformal Prediction (SACP) clusters the physical space into k regions. It calculates a unique nonconformity score distribution for each region, allowing "easy" regions (e.g., open halls) to have tight radii (e.g., 1.70m) while "hard" regions (e.g., complex hallways) get larger radii (e.g., 3.78m), maintaining valid coverage (1-α) locally.

### Mechanism 3
Multi-head attention mechanisms in the Graph Transformer filter noisy RSSI signals by learning the relative importance of neighboring APs. The model uses TransformerConv operations to compute attention coefficients βi,j that weight the contribution of neighboring AP features dynamically, allowing the model to down-weight APs with weak or fluctuating RSSI (noise) and up-weight reliable neighbors, effectively creating a learned signal mask.

## Foundational Learning

- **Graph Neural Networks (GNNs) & Message Passing**: The core architecture is a Graph Transformer. You must understand how features are passed between nodes (User ↔ AP) and aggregated (Eq. 3) to diagnose connectivity issues or embedding failures. Quick check: How does the "receptive field" change when stacking two Graph Transformer layers as done in this paper?

- **Conformal Prediction (CP)**: The paper's novelty rests on SACP. You need to distinguish between the training set, calibration set (used for CP), and test set. Understanding that CP provides statistical coverage guarantees (margin of error) based on calibration residuals is non-negotiable. Quick check: Why is a held-out calibration set strictly necessary for the conformal prediction step, distinct from the training data?

- **RSSI Fingerprinting & Signal Noise**: The input data is Wi-Fi RSSI, which is inherently noisy and susceptible to multipath fading. Understanding why standard trilateration fails (non-linear distance relationship) explains why a data-driven deep learning approach is used. Quick check: Why does the paper use a threshold τ (signal strength) to determine graph connectivity rather than connecting to all visible APs?

## Architecture Onboarding

- **Component map**: Input Layer (RSSI Vector + AP Coordinates) → Graph Constructor (Adjacency based on dp and τ) → 2-layer Graph Transformer (TransformerConv) → Embeddings → Fully Connected Layer → 2D Coordinates → K-Means Clustering (spatial partitioning) → Quantile Calculation (SACP) → Final Confidence Region

- **Critical path**: Data → Graph Construction (Eq. 1) → GT Layers (Eq. 3) → Point Prediction → K-Means Lookup → Radius Application → Final Confidence Region

- **Design tradeoffs**: 
  - Thresholds (τ, dp): High τ creates sparse graphs (risk of information loss); low τ creates dense graphs (risk of noise)
  - Regions (k): Too few regions reduce adaptivity; too many regions reduce calibration samples per region, risking statistical invalidity
  - Hidden Dimension (h=500): Large h increases capacity but risks overfitting on limited fingerprint data

- **Failure signatures**: 
  - Low Coverage (< 84%): Calibration set distribution likely differs from test set, or specific regions are under-represented
  - High MAE (Median > 2m): Graph connectivity is likely suboptimal; check τ or dp settings
  - Overconfidence in specific zones: K-Means clusters may not align with physical obstacles

- **First 3 experiments**: 
  1. Reproduce the Threshold Sweep (Fig 3): Vary τ from -90 to -60 dBm to find optimal graph connectivity density
  2. Ablation on "Spatially-Adaptive" vs "Global": Compare SACP (k=5 regions) against baseline CP with k=1
  3. Region Granularity Analysis: Vary k (e.g., 3, 5, 10) to observe trade-off between radius tightness and coverage stability

## Open Questions the Paper Calls Out

### Open Question 1
How can the Spatially-Adaptive Conformal Prediction (SACP) framework be enhanced to provide strict conditional coverage guarantees for each specific region, rather than relying on marginal coverage? The conclusion explicitly identifies the "lack of strict conditional coverage guarantees per region" as a current limitation. While global coverage (84.8%) approaches the target, individual regions (e.g., R4 at 79.4%) fall below the 90% target, indicating calibration is not strictly valid conditionally on location.

### Open Question 2
Can a method be developed to automatically learn the optimal number and boundaries of spatial partitions to maximize localization efficiency without manual tuning? The authors state future work will explore methods to "automatically learn the optimal spatial partitions" rather than relying on pre-defined K-Means clustering. The current approach requires pre-setting k=5, which may not accurately reflect true spatial distribution of signal uncertainty.

### Open Question 3
Does the reliance on 2D Euclidean distance for defining logical graph links hold in multi-floor indoor environments where vertical signal propagation differs significantly from horizontal paths? The system model defines logical links based on physical proximity threshold (dij ≤ dp), and evaluation is restricted to single-floor corridor dataset. In multi-story buildings, APs on different floors might be physically close in 2D space but separated by floors, potentially creating misleading logical links.

## Limitations

- Graph Construction Sensitivity: Performance heavily depends on threshold parameters τ and dp, which were tuned on a single building dataset and may not generalize to different environments
- Exchangeability Assumption: SACP's validity relies on calibration and test sets being drawn from the same distribution, but real-world deployment may face distributional shifts that break this assumption
- Computational Overhead: The 2-layer Graph Transformer requires significant computation compared to simpler baselines, potentially limiting real-time deployment on resource-constrained devices

## Confidence

- **High Confidence**: The Graph Transformer architecture and its ability to capture spatial dependencies from RSSI signals (Mechanism 1)
- **Medium Confidence**: The spatially-adaptive confidence regions (Mechanism 2) demonstrate statistical validity, but calibration procedure's sensitivity to region size and sample distribution introduces uncertainty
- **Medium Confidence**: The attention mechanism's role in filtering noise (Mechanism 3) is theoretically sound, but paper doesn't provide ablation studies isolating its specific contribution

## Next Checks

1. **Cross-Environment Validation**: Test SAC-GT on datasets from buildings with different AP densities and layouts to assess threshold parameter robustness
2. **Temporal Stability Analysis**: Evaluate model performance across multiple days/weeks to quantify how RSSI fluctuations affect both localization accuracy and coverage guarantees
3. **Computational Efficiency Benchmark**: Measure inference time and memory usage on mobile/embedded devices, comparing against lightweight alternatives to assess real-world deployment feasibility