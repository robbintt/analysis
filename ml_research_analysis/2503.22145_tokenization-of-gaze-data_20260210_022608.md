---
ver: rpa2
title: Tokenization of Gaze Data
arxiv_id: '2503.22145'
source_url: https://arxiv.org/abs/2503.22145
tags:
- gaze
- data
- tokenization
- error
- conv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the lack of tokenization strategies for gaze\
  \ data, a crucial component for leveraging transformer-based models like LLMs and\
  \ MLLMs in gaze-related tasks. The authors propose and analyze five tokenization\
  \ methods\u2014Binary, \U0001D707-Law, Quantile, K-Means, and VQ-VAE\u2014on three\
  \ gaze datasets."
---

# Tokenization of Gaze Data

## Quick Facts
- arXiv ID: 2503.22145
- Source URL: https://arxiv.org/abs/2503.22145
- Authors: Tim Rolff; Jurik Karimian; Niklas Hypki; Susanne Schmidt; Markus Lappe; Frank Steinicke
- Reference count: 40
- This paper proposes and analyzes five tokenization methods for gaze data, evaluating them on three datasets using reconstruction, compression, and forecasting metrics.

## Executive Summary
This paper addresses the critical challenge of tokenizing continuous gaze data for transformer-based models. The authors systematically evaluate five tokenization strategies - Binary, μ-Law, Quantile, K-Means, and VQ-VAE - on three gaze datasets. They assess these methods using reconstruction and compression metrics, as well as forecasting and generation performance with GPT-2. The study reveals that Quantile and VQ-VAE tokenizers excel at predicting gaze positions, while K-Means is optimal for gaze velocities. The research provides a comprehensive framework for designing effective tokenization schemes for continuous gaze data and offers practical guidance for future research in this domain.

## Method Summary
The paper evaluates five tokenization strategies for continuous gaze data: Binary, μ-Law, Quantile, K-Means, and VQ-VAE. Each method converts gaze data into discrete tokens suitable for transformer models. The evaluation uses three gaze datasets and measures reconstruction accuracy, compression efficiency, and prediction performance using GPT-2. The study systematically compares these tokenizers across different gaze tasks, including position and velocity prediction, to determine their effectiveness and suitability for various applications.

## Key Results
- Quantile and VQ-VAE tokenizers perform best for predicting gaze positions
- K-Means tokenizer is optimal for gaze velocity prediction tasks
- The study provides a comprehensive framework for selecting appropriate tokenization strategies based on specific gaze analysis requirements

## Why This Works (Mechanism)
The effectiveness of different tokenization strategies depends on how well they preserve the statistical properties and temporal patterns of gaze data while creating discrete representations suitable for transformer models. Quantile and VQ-VAE methods excel at capturing the continuous nature of gaze positions by creating more uniform distributions of tokens, while K-Means better handles the different statistical characteristics of velocity data through cluster-based representations.

## Foundational Learning
1. **Quantization**: Converting continuous data into discrete values - needed for representing continuous gaze data as tokens for transformer models
2. **Vector Quantization**: Mapping continuous vectors to discrete codebooks - crucial for VQ-VAE tokenization method
3. **Gaze data characteristics**: Understanding the statistical properties of eye movement patterns - essential for designing effective tokenization strategies
4. **Transformer input requirements**: Discrete token sequences - fundamental constraint driving the need for gaze data tokenization
5. **Compression metrics**: Measuring information retention during quantization - important for evaluating tokenization quality
6. **Forecasting metrics**: Evaluating prediction accuracy - critical for assessing tokenization impact on downstream tasks

## Architecture Onboarding

Component map: Gaze data -> Tokenizer -> Discrete tokens -> GPT-2 model -> Prediction/output

Critical path: Raw gaze data flows through the chosen tokenizer, converting continuous values into discrete tokens, which are then processed by the GPT-2 model for prediction tasks.

Design tradeoffs: The main tradeoff involves balancing reconstruction accuracy with compression efficiency and prediction performance. Different tokenizers prioritize these aspects differently, affecting their suitability for various gaze tasks.

Failure signatures: Poor tokenization can lead to loss of temporal patterns, inaccurate predictions, or excessive information loss during compression.

First experiments:
1. Test basic quantization methods (Binary, μ-Law) on small gaze datasets to establish baseline performance
2. Evaluate Quantile and K-Means tokenizers on position prediction tasks
3. Compare VQ-VAE tokenization with other methods on velocity prediction tasks

## Open Questions the Paper Calls Out
None

## Limitations
- Focus on 2D screen-based gaze data may not generalize to 3D eye-tracking scenarios
- Evaluation primarily emphasizes reconstruction accuracy and next-step prediction
- Limited benchmarking against state-of-the-art gaze prediction approaches

## Confidence

High confidence: Empirical rankings of tokenizer performance across different tasks are well-supported by experimental results and evaluation metrics.

High confidence: Guidance on selecting appropriate tokenizers based on whether the task involves position or velocity prediction is clearly demonstrated.

Medium confidence: While results are robust for evaluated tasks, applicability to other gaze-related applications remains to be validated.

## Next Checks

1. Evaluate the proposed tokenization strategies on 3D gaze data from VR/AR applications to assess cross-domain performance and identify necessary adaptations.

2. Test the tokenizers on downstream tasks beyond next-position prediction, such as attention pattern classification or gaze-based interaction design, to validate broader applicability.

3. Implement and evaluate the tokenization approaches within existing large-scale multimodal learning frameworks to assess integration feasibility and impact on overall model performance.