---
ver: rpa2
title: Atom of Thoughts for Markov LLM Test-Time Scaling
arxiv_id: '2502.12018'
source_url: https://arxiv.org/abs/2502.12018
tags:
- reasoning
- question
- answer
- process
- markov
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces Atom of Thoughts (AOT), a Markovian reasoning\
  \ framework that addresses the inefficiency of existing test-time scaling methods\
  \ by eliminating historical dependency accumulation during LLM inference. AOT uses\
  \ a two-phase transition mechanism\u2014decomposition into a DAG-based reasoning\
  \ path followed by contraction to generate self-contained, answer-equivalent states\u2014\
  enabling memoryless state transitions that minimize redundant computation."
---

# Atom of Thoughts for Markov LLM Test-Time Scaling

## Quick Facts
- arXiv ID: 2502.12018
- Source URL: https://arxiv.org/abs/2502.12018
- Authors: Fengwei Teng; Quan Shi; Zhaoyang Yu; Jiayi Zhang; Yuyu Luo; Chenglin Wu; Zhijiang Guo
- Reference count: 40
- Key outcome: AOT achieves 83.6% accuracy on MATH with GPT-4o-mini, outperforming CoT (78.3%), ToT (82.0%), and FoT (82.3%) while using memoryless transitions that eliminate historical context accumulation.

## Executive Summary
This paper introduces Atom of Thoughts (AOT), a Markovian reasoning framework that addresses the inefficiency of existing test-time scaling methods by eliminating historical dependency accumulation during LLM inference. AOT uses a two-phase transition mechanism—decomposition into a DAG-based reasoning path followed by contraction to generate self-contained, answer-equivalent states—enabling memoryless state transitions that minimize redundant computation. Extensive experiments show AOT consistently outperforms baselines like CoT, ToT, and FoT across MATH, GSM8K, MBPP, AIME, and LongBench benchmarks.

## Method Summary
AOT operates through a Markovian reasoning framework with two phases: decomposition and contraction. Given an initial question Q_0, the decomposition module generates a DAG G_0 where nodes represent subproblems and edges capture dependencies. The contraction module then solves independent subproblems (nodes with no incoming edges) and reformulates dependent nodes into a new self-contained question Q_1 that preserves answer equivalence with Q_0. This process iterates up to a maximum of 3 transitions, with an LLM-as-a-judge selecting the best answer from {solve(Q_i), solve(G_i), solve(Q_{i+1})} at each step. The framework maintains answer equivalence throughout while reducing reasoning complexity through independent subproblem resolution.

## Key Results
- AOT achieves 83.6% accuracy on MATH with GPT-4o-mini, outperforming CoT (78.3%), ToT (82.0%), and FoT (82.3%)
- Answer equivalence preservation rate: 99.2-99.7% across benchmarks with 74-82% complexity reduction
- When integrated with tree search and reflective refinement, AOT reveals convergent "atomic" reasoning units with stable token counts
- Consistent performance gains across diverse domains: GSM8K (+3.4%), MBPP (+2.8%), AIME (+6.2%), and LongBench tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Memoryless state transitions reduce redundant computation by eliminating historical context accumulation while preserving reasoning quality.
- Mechanism: Each state Q_i is reformulated to be answer-equivalent to the original question Q_0 but with lower test-time complexity. Transitions follow p(Q_{i+1}|Q_i) rather than accumulating full history, so prompt token consumption remains O(1) per invocation instead of O(n) growth in CoT.
- Core assumption: Complex problems can be decomposed into self-contained subproblems where solving independent parts and incorporating their results produces valid, simpler reformulations.
- Evidence anchors:
  - [abstract] "leverage the memoryless property of Markov processes to minimize reliance on historical context"
  - [section 3.1] "each intermediate subquestion Q_i must preserve answer-equivalence with the original question"
  - [corpus] No direct corpus support for Markovian reasoning; neighboring papers focus on discrete token-space test-time scaling (SoftCoT++, MetaScale) without memoryless formulations.

### Mechanism 2
- Claim: Explicit DAG-based dependency modeling before contraction enables principled identification of which subproblems can be "baked in" to simplified states.
- Mechanism: Decomposition phase generates a DAG G_i where nodes represent subproblems and edges represent information dependencies. Contraction phase identifies nodes with no incoming edges (independent), solves them, and reformulates dependent nodes into a new self-contained question Q_{i+1} with results incorporated.
- Core assumption: LLMs can reliably identify and represent reasoning dependencies as acyclic graph structures with >99% answer equivalence preservation.
- Evidence anchors:
  - [section 3.1] "G_i = (N, E), E ⊆ {(N_j, N_k)|j < k} where nodes represent individual thoughts or subquestions"
  - [appendix B.1] Answer equivalence maintenance: 99.2-99.7% across benchmarks; complexity reduction: 74-82%
  - [corpus] Weak corpus evidence; neighboring ToT/GoT papers use tree/graph structures but maintain historical context rather than contracting to memoryless states.

### Mechanism 3
- Claim: Scaling AOT with tree search and reflective refinement reveals convergent "atomic" reasoning units—irreducible, self-contained problem representations.
- Mechanism: Extended exploration through tree search + verification-based reflection produces deeper Markov chains where final-state token counts approach minimal DAG representations. These atomic states are indivisible units from which original answers can be directly inferred with high stability.
- Core assumption: Problems possess intrinsic atomic structure that emerges through repeated decomposition-contraction; convergence depth depends jointly on problem complexity and model capability.
- Evidence anchors:
  - [section 3.2] "deeper reasoning states tend to converge into irreducible forms, maintaining a stable and relatively low reasoning token count"
  - [section 4.4] "token count of final reasoning steps gradually approaches that of a minimal DAG representation comprising all independent subproblems"
  - [corpus] No corpus evidence specifically addresses atomic reasoning emergence; related test-time scaling papers focus on compute allocation, not structural convergence.

## Foundational Learning

- **Concept**: Markov Property (Memoryless Transitions)
  - Why needed here: Core mathematical foundation distinguishing AOT from history-dependent methods like CoT/ToT/GoT.
  - Quick check question: Given p(S_{i+1}|S_i) vs p(S_{i+1}|S_0, ..., S_i), which requires maintaining growing context and why does this matter for token efficiency?

- **Concept**: Directed Acyclic Graphs (DAGs) and Topological Ordering
  - Why needed here: The temporary scaffold G_i captures dependencies; identifying nodes with no incoming edges (sources) determines what can be solved independently.
  - Quick check question: In a DAG with edges A→B→C, which node(s) have no incoming edges and can be solved without prior information?

- **Concept**: Answer Equivalence as Semantic Invariant
  - Why needed here: The critical constraint ensuring memoryless transitions don't drift from the original problem; enforced implicitly by the judge selection mechanism.
  - Quick check question: If Q_0 asks "Find the sum of integers from 1 to 100" and Q_1 asks "Calculate 5050," are these answer-equivalent? Why or why not?

## Architecture Onboarding

- **Component map**: Q_i → Decompose → G_i → Contract → Q_{i+1} → Judge → (Continue or Return best)

- **Critical path**: Q_0 → Decompose → G_0 → Contract → Q_1 → Judge → (Continue or Return best)
  - Default max transitions: 3 (aligned with typical DAG depth 2-4 per Appendix B.3)
  - Key invariant: Each Q_i must maintain answer equivalence with Q_0

- **Design tradeoffs**:
  - Fixed transition count (simple, predictable cost) vs adaptive based on initial DAG depth (more optimal but complex)
  - Temperature=1.0 (exploration) vs lower values (determinism)—paper uses 1.0 uniformly
  - Memoryless efficiency gains vs inability to recover from early errors (mitigated by judge mechanism)

- **Failure signatures**:
  - Answer equivalence rate <95%: Decomposition quality degradation, likely model capability issue
  - Judge selection rate <80%: Contraction producing invalid/non-equivalent states
  - Performance degrades with chain length: Termination mechanism failing to filter bad transitions
  - No token reduction in final states: Atomic structure not emerging—consider model upgrade or deeper exploration

- **First 3 experiments**:
  1. Reproduce ablation on MATH subset: Run AOT without DAG-guided contraction. Paper shows this causes severe drop (>5% on most benchmarks). Verify your implementation matches expected degradation.
  2. Validate answer equivalence on 50-100 samples: Manually check that Q_1 maintains equivalence with Q_0. Target >99% per Table 2. If below 95%, debug decomposition prompt or model capability.
  3. Test state integration with ToT: Use AOT-generated Q_1 as entry point for ToT (3 branches) on GSM8K. Measure accuracy gain and cost reduction vs vanilla ToT. Expect both improved accuracy AND reduced tokens per Figure 4.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can supervised fine-tuning or reinforcement learning internalize Markovian reasoning patterns to bypass the need for inference-time decomposition?
- Basis in paper: [explicit] The conclusion states: "A natural extension is to align this structure with training-time objectives—teaching models to internalize Markovian and atomic reasoning patterns directly."
- Why unresolved: The current framework operates solely at inference time, adding computational overhead to the generation process.
- What evidence would resolve it: Experiments showing fine-tuned models achieving comparable or superior accuracy on MATH/GSM8K without external scaffolding.

### Open Question 2
- Question: Can a dynamic termination criterion based on semantic convergence replace the fixed maximum transition count (3) to improve robustness?
- Basis in paper: [inferred] Appendix C lists the reliance on a "fixed maximum transition count" as a limitation, suggesting a dynamic criterion would be more robust.
- Why unresolved: A static limit may truncate reasoning for complex problems or waste compute on simple ones.
- What evidence would resolve it: A stopping metric derived from DAG structural depth that correlates with final answer stability.

### Open Question 3
- Question: How can AOT be adapted for weaker models that struggle to generate valid dependency graphs during the decomposition phase?
- Basis in paper: [inferred] Appendix C notes that "quality of decomposition depends heavily on the underlying LLM’s capability; weaker models may struggle to generate valid dependency graphs."
- Why unresolved: The paper primarily validates strong backbones (GPT-4o-mini, DeepSeek-R1), leaving the lower-bound of model capacity undefined.
- What evidence would resolve it: Error analysis of decomposition validity on smaller models (e.g., 7B parameters) with specialized prompting strategies.

## Limitations

- Theoretical foundation relies on unproven assumption that complex problems can be reliably decomposed into answer-equivalent, lower-complexity subproblems
- Empirical results limited to mathematical and logical reasoning domains; performance on open-ended generation tasks unknown
- Success heavily dependent on prompt quality, judge selection criteria, and model capability for decomposition and contraction

## Confidence

**High Confidence**: The memoryless transition mechanism itself is technically sound and implementable. The claim that AOT eliminates historical context accumulation while maintaining reasoning quality is directly verifiable through token counting and ablation studies. The integration approach with existing methods (ToT, FoT) is modular and clearly specified.

**Medium Confidence**: The answer equivalence preservation mechanism works reliably across diverse problem types. The DAG-guided contraction approach meaningfully improves reasoning efficiency. The convergence to atomic reasoning units represents a genuine structural property of the problems rather than an artifact of the method.

**Low Confidence**: AOT's fundamental advantage over all existing test-time scaling methods is universal rather than domain-specific. The atomic reasoning structure represents a fundamental property of problems rather than a method-specific artifact. The framework scales effectively to models with significantly different reasoning capabilities or to domains outside mathematical/logical reasoning.

## Next Checks

1. **Human Validation of Answer Equivalence**: Select 100 random samples from MATH and GSM8K where Q_1 was generated. Have human experts verify whether Q_1 is truly answer-equivalent to Q_0 (not just semantically similar). Compare human assessment with LLM-as-a-judge scores to quantify potential semantic drift.

2. **Cross-Domain Performance Testing**: Implement AOT on at least two non-mathematical benchmarks (e.g., commonsense reasoning like HellaSwag, or creative writing tasks). Measure performance degradation compared to CoT/ToT baselines to determine domain dependence of the atomic reasoning assumption.

3. **Model Capability Sensitivity Analysis**: Run AOT with varying model families/capabilities (GPT-3.5, Claude-3-Haiku, Llama-3-8B) on a fixed benchmark subset. Characterize how answer equivalence rates, convergence depth, and final accuracy vary with model reasoning capacity to identify capability thresholds for the method.