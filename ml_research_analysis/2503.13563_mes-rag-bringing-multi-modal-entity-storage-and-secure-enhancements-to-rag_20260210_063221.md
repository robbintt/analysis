---
ver: rpa2
title: 'MES-RAG: Bringing Multi-modal, Entity-Storage, and Secure Enhancements to
  RAG'
arxiv_id: '2503.13563'
source_url: https://arxiv.org/abs/2503.13563
tags:
- data
- mes-rag
- retrieval
- query
- entities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MES-RAG is a framework that addresses retrieval confusion among
  similar entities in RAG systems. It uses entity-centric data construction to isolate
  and organize entity-specific information, reducing retrieval noise and improving
  precision.
---

# MES-RAG: Bringing Multi-modal, Entity-Storage, and Secure Enhancements to RAG

## Quick Facts
- **arXiv ID**: 2503.13563
- **Source URL**: https://arxiv.org/abs/2503.13563
- **Reference count**: 12
- **Key outcome**: MES-RAG achieves 0.83 accuracy (+0.25) and 0.97 Recall@1 (+0.58) vs baselines, with 98% attack detection.

## Executive Summary
MES-RAG addresses retrieval confusion among similar entities in RAG systems by isolating and organizing entity-specific information. The framework uses entity-centric data construction to reduce retrieval noise and improve precision, integrates a unified multi-modal approach for text, images, audio, and video, and employs proactive security measures to prevent attacks. Experimental results show significant improvements in accuracy and recall, with robust performance in detecting malicious, document extraction, and hallucination attacks.

## Method Summary
MES-RAG uses a four-module architecture: (1) Entity-centric Data Construction (EDC) preprocesses multi-modal data via Whisper and GPT-4o, extracts entities using YAKE, and partitions into isolated entity subsets; (2) Query Parser (QP) detects malicious queries using obfuscation and toxicity scores, extracts entities/intents, and rewrites queries; (3) Entities Retrieval (ER) matches queries to entity subsets and checks for out-of-knowledge conditions; (4) Answer Generation (AG) performs RAG on the matched subset. The system achieves real-time response (<1.5s) while maintaining high accuracy and security.

## Key Results
- **Accuracy**: 0.83 (+0.25) vs baselines
- **Recall@1**: 0.97 (+0.58) vs full retrieval
- **Security**: 98% accuracy in detecting malicious, document extraction, and hallucination attacks
- **Multi-modal**: 83% accuracy on non-text answers (43 errors / 258)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Isolating data by entity reduces retrieval noise and improves precision when handling queries about similar entities.
- **Mechanism**: The EDC module segments data into entity-specific subsets using keyword extraction (YAKE) and feature clustering. Retrieval then operates only on the matched entity's subset, eliminating cross-entity interference.
- **Core assumption**: Queries can be reliably mapped to a single or small set of entities before retrieval begins.
- **Evidence anchors**:
  - [abstract] "struggles with precise entity information retrieval... MES-RAG addresses confusion among similar entities... by introducing entity-specific storage and retrieval"
  - [section 4.4, Table 5] Recall@1 improved from 0.39 (full retrieval) to 0.97 (Entities Retrieval), +0.58
  - [corpus] Weak direct validation; related work on secure RAG exists but does not test entity-isolated retrieval specifically.
- **Break condition**: If entity extraction fails or queries span many ambiguous entities, the isolation benefit degrades; the Out of Knowledge mechanism may trigger false rejections.

### Mechanism 2
- **Claim**: Front-loaded security (malicious detection + out-of-knowledge checks before retrieval) reduces vulnerability to attacks without significantly impacting legitimate queries.
- **Mechanism**: The Query Parser computes toxicity and obfuscation scores; queries exceeding thresholds are blocked. The Out of Knowledge mechanism rejects queries referencing entities not in the database, preventing hallucination-based leakage.
- **Core assumption**: Attack queries exhibit detectable signatures (toxicity, obfuscation, out-of-scope entities) that do not heavily overlap with legitimate user behavior.
- **Evidence anchors**:
  - [abstract] "achieves 98% accuracy in detecting malicious attacks and document extraction attempts"
  - [section 3.4, equations 5-6] Formal conditions for obfuscation and toxicity thresholds
  - [section 4.4, Table 6] 4/200 malicious queries missed, 3/200 document extraction attacks missed
  - [corpus] Related work ("Secure Retrieval-Augmented Generation against Poisoning Attacks") discusses poisoning threats but does not validate MES-RAG's front-loaded approach.
- **Break condition**: Adversaries who craft low-toxicity, non-obfuscated prompts referencing in-scope entities may bypass detection; threshold tuning is critical.

### Mechanism 3
- **Claim**: Unified text descriptions across modalities enable consistent multi-modal retrieval without training generative models for each modality.
- **Mechanism**: Non-text data (images, audio, video) is processed via models like Whisper and GPT-4o to generate textual summaries aligned with original content. Retrieval operates on these summaries, and original multi-modal files are returned.
- **Core assumption**: Textual summaries sufficiently capture the semantic content of non-text modalities for matching user intent.
- **Evidence anchors**:
  - [section 3.3] "We use existing real multi-modal data instead of generated data, leveraging models like Whisper and GPT-4o to produce textual summaries"
  - [section 4.4, Table 6] 83% accuracy on non-text answers (43 errors / 258)
  - [corpus] No direct corpus validation for this specific multi-modal summarization approach.
- **Break condition**: If summaries omit critical details or misalign with user intent, retrieval may return irrelevant multi-modal content with no easy recovery path.

## Foundational Learning

- **Concept: Entity Resolution and Disambiguation**
  - Why needed here: The Query Parser must map user queries to specific entities from a predefined list, often using dialog history to resolve ambiguity.
  - Quick check question: Given the query "What colors does it come in?" after discussing "Audi Q4," can your system correctly resolve "it" to "Audi Q4"?

- **Concept: Vector Similarity Search and Gain Ratio Feature Selection**
  - Why needed here: EDC uses text embeddings and cosine similarity for keyword grouping, plus Gain Ratio to select discriminative features for entity segmentation.
  - Quick check question: How would you compute Gain Ratio for a candidate feature, and what does a high value indicate?

- **Concept: Threshold-Based Classification (Toxicity and Obfuscation)**
  - Why needed here: Security filtering depends on setting appropriate τ (obfuscation) and θ (toxicity) thresholds to balance safety and usability.
  - Quick check question: If you lower θ to catch more malicious queries, what tradeoff should you monitor?

## Architecture Onboarding

- **Component map**: EDC (preprocessing) -> QP (security + extraction) -> ER (entity matching) -> AG (generation)
- **Critical path**: Offline: EDC builds entity-isolated database (requires YAKE, embedding model, manual validation). Online: QP → ER → AG pipeline must complete within 1.5s (parallel retrieval helps)
- **Design tradeoffs**:
  - Granularity of entity segmentation: Finer isolation reduces noise but increases storage complexity and risks Out of Knowledge false positives
  - Threshold tuning: Stricter security blocks more attacks but may reject legitimate queries
  - Multi-modal summary fidelity: Longer summaries capture more detail but increase retrieval latency
- **Failure signatures**:
  - High Out of Knowledge trigger rate → entity list incomplete or extraction failing
  - Low Recall@1 despite entity isolation → keyword/feature selection not discriminative enough
  - Malicious queries slipping through → thresholds too lenient or obfuscation detection gaps
- **First 3 experiments**:
  1. Reproduce Recall@1 comparison (full retrieval vs. Entities Retrieval) on the provided vehicle dataset to validate isolation benefit
  2. Test malicious detection thresholds: sweep τ and θ values to plot ROC curve on the 200 malicious / 200 legitimate query split
  3. Evaluate multi-modal accuracy: sample 50 non-text queries, manually verify whether textual summaries aligned with retrieved content

## Open Questions the Paper Calls Out

- **Question**: How can multi-entity hierarchies be constructed to handle complex question-answering tasks without requiring prohibitive amounts of domain knowledge for ontology construction?
- **Basis in paper**: [explicit] The "Limitations and Risks" section identifies the exploration of multi-entity hierarchies as a promising direction, noting that current methods lack this structure and adding it increases complexity.
- **Why unresolved**: The current MES-RAG framework focuses on isolated entity subsets to reduce noise, but it lacks a mechanism for navigating relationships between entities in a hierarchical manner.
- **What evidence would resolve it**: A modified MES-RAG framework that successfully resolves multi-hop queries requiring traversal of entity relationships, evaluated against a dataset specifically designed for hierarchical reasoning.

## Limitations
- **Entity list dependency**: Requires exhaustive, well-defined entity list; out-of-scope queries trigger false Out of Knowledge rejections
- **Threshold opacity**: Critical security thresholds (τ, θ) unspecified, making tuning and trade-off analysis opaque
- **Domain confinement**: Evaluation limited to vehicle datasets and synthetic attacks, limiting generalizability

## Confidence
- **High confidence**: Entity isolation mechanism (+0.58 Recall@1 improvement) and front-loaded security architecture are well-supported and reproducible
- **Medium confidence**: Multi-modal summary approach is plausible but lacks direct validation; security thresholds and optimal values unspecified
- **Low confidence**: Generalizability across domains, adaptability to evolving attack patterns, and long-term performance stability

## Next Checks
1. Reproduce Recall@1 comparison on the provided vehicle dataset to confirm the +0.58 improvement from entity isolation
2. Conduct a threshold sweep on τ and θ using the 200 malicious and 200 document extraction samples to generate ROC curves and optimize detection rates
3. Manually validate 50 non-text query responses to assess whether textual summaries accurately capture multi-modal intent and whether retrieved content aligns with user needs