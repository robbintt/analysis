---
ver: rpa2
title: 'From Concepts to Components: Concept-Agnostic Attention Module Discovery in
  Transformers'
arxiv_id: '2506.17052'
source_url: https://arxiv.org/abs/2506.17052
tags:
- attention
- module
- head
- concept
- similarity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Scalable Attention Module Discovery (SAMD),
  a concept-agnostic method for attributing arbitrary concepts to specific attention
  heads in transformer models. The core idea is to represent concepts as vectors,
  compute their cosine similarity with attention head outputs, and select the top-scoring
  heads as a module.
---

# From Concepts to Components: Concept-Agnostic Attention Module Discovery in Transformers

## Quick Facts
- arXiv ID: 2506.17052
- Source URL: https://arxiv.org/abs/2506.17052
- Authors: Jingtong Su; Julia Kempe; Karen Ullrich
- Reference count: 40
- Primary result: Introduces SAMD and SAMI for concept-agnostic attention module discovery and intervention in transformers

## Executive Summary
This paper introduces Scalable Attention Module Discovery (SAMD), a concept-agnostic method for attributing arbitrary concepts to specific attention heads in transformer models. The core idea is to represent concepts as vectors, compute their cosine similarity with attention head outputs, and select the top-scoring heads as a module. The authors also propose Scalar Attention Module Intervention (SAMI), a single-parameter intervention strategy to diminish or amplify concept effects by scaling attention head outputs. The method is evaluated across diverse concepts (SAE features, reasoning, safety, visual recognition) and model types (LLMs and ViTs), demonstrating high efficiency and effectiveness with only 3-10 heads encoding complex concepts and ~0.1% of weights needed for significant interventions.

## Method Summary
SAMD represents concepts as vectors through top-k feature averaging, then computes cosine similarity between these concept vectors and attention head outputs to identify concept-specific modules. SAMI implements interventions through scalar multiplication of attention head outputs, allowing for both amplification and suppression of concept effects. The approach is evaluated on multiple model types including LLMs and ViTs across various concept categories including SAE features, reasoning, safety, and visual recognition. The method's efficiency stems from targeting only specific attention heads rather than modifying entire model weights, achieving significant effects through interventions on approximately 0.1% of model parameters.

## Key Results
- Only 3-10 attention heads encode complex concepts across tested domains
- Module locations remain stable before and after LLM post-training
- Negative intervention on safety modules increases jailbreak success by 72.7% on HarmBench
- Positive intervention on reasoning modules improves GSM8K performance by 1.6%
- Negative intervention on label modules reduces vision classification accuracy to 0%

## Why This Works (Mechanism)
SAMD works by leveraging the distributed nature of concept representation in transformer attention heads. Each attention head processes different aspects of input information, and SAMD identifies which heads are most responsive to specific concepts through vector similarity. The cosine similarity metric effectively captures the alignment between concept representations and attention head outputs in the embedding space. SAMI's scalar intervention strategy works because attention heads operate multiplicatively in the attention mechanism, so scaling their outputs directly modulates their contribution to the final representation. The stability of modules across training stages suggests that concept encoding in attention heads is a fundamental architectural property rather than an artifact of specific training procedures.

## Foundational Learning
- **Concept Vectorization**: Representing abstract concepts as numerical vectors is essential for quantitative analysis - quick check: verify concept vectors capture semantic meaning through nearest neighbor analysis
- **Cosine Similarity for Module Discovery**: Using angular similarity rather than Euclidean distance helps identify functionally relevant heads regardless of magnitude differences - quick check: compare module discovery results using different similarity metrics
- **Scalar Intervention**: Simple multiplicative scaling can effectively modulate complex behaviors - quick check: test intervention effects across different scalar values to establish dose-response relationship
- **Attention Head Modularity**: The finding that specific heads encode specific concepts suggests modular organization in transformers - quick check: analyze whether discovered modules overlap across related concepts

## Architecture Onboarding
**Component Map**: Input Concepts -> Concept Vectorization -> Attention Head Output Collection -> Cosine Similarity Computation -> Module Selection -> SAMI Intervention -> Output Behavior Modification

**Critical Path**: Concept vectorization and cosine similarity computation form the core discovery pipeline, while SAMI intervention provides the practical mechanism for behavioral modification. The stability of modules across training stages ensures reliability.

**Design Tradeoffs**: The method trades comprehensive concept coverage for efficiency by focusing on top-k heads rather than modeling all possible concept-head relationships. This enables scalability but may miss nuanced interactions between concepts and attention heads.

**Failure Signatures**: Poor module discovery may indicate concepts are distributed across many heads rather than concentrated in a few, or that the concept vectorization method fails to capture essential semantic features. Ineffective interventions suggest the target concept may not be primarily encoded through the attention mechanism.

**First Experiments**:
1. Test SAMD on simple, well-defined concepts (e.g., specific tokens or phrases) to establish baseline performance
2. Apply SAMI with varying intervention strengths to quantify dose-response relationships
3. Compare module stability across different stages of model training to verify the method's consistency

## Open Questions the Paper Calls Out
None

## Limitations
- Concept representation method using top-k feature averaging may not capture full semantic richness of abstract or compositional concepts
- Cosine similarity approach assumes linear separability of concepts in attention head embedding space, which may not hold for all concept types
- Method focuses exclusively on attention heads as modular units without exploring other architectural components or their combinations

## Confidence
**High Confidence**: The empirical results demonstrating SAMD's ability to identify attention heads encoding specific concepts across multiple domains and the quantitative effectiveness of SAMI interventions.

**Medium Confidence**: The claim that discovered modules are "concept-agnostic" - while the method works across diverse concepts, the underlying mechanisms of how different attention heads encode different concepts remain unclear.

**Low Confidence**: The assertion that 3-10 attention heads are sufficient to encode "complex concepts" - the complexity threshold and concept definition criteria are not rigorously specified.

## Next Checks
1. **Cross-model generalization test**: Apply SAMD to a diverse set of additional transformer architectures (e.g., different decoder-only models, encoder-decoder models) to verify the method's generalizability beyond the tested LLMs and ViTs.

2. **Concept compositionality analysis**: Design experiments to test whether SAMD can identify attention head modules for composite concepts (e.g., "red apple" as a combination of color and object concepts) and whether these can be combined through module composition.

3. **Adversarial robustness evaluation**: Test whether negative interventions on safety modules using SAMI can be circumvented through alternative jailbreak strategies, and whether the method remains effective against deliberately obfuscated harmful content.