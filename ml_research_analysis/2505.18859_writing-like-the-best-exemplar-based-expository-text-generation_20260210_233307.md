---
ver: rpa2
title: 'Writing Like the Best: Exemplar-Based Expository Text Generation'
arxiv_id: '2505.18859'
source_url: https://arxiv.org/abs/2505.18859
tags:
- text
- district
- repa
- retr
- topic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Exemplar-Based Expository Text Generation,
  a novel task that aims to generate an expository text on a new topic using an exemplar
  from a similar topic. To address the challenges of cross-topic consistency, cross-topic
  variability, and long-form text generation, the authors propose the Recurrent Plan-then-Adapt
  (REPA) framework.
---

# Writing Like the Best: Exemplar-Based Expository Text Generation

## Quick Facts
- arXiv ID: 2505.18859
- Source URL: https://arxiv.org/abs/2505.18859
- Authors: Yuxiang Liu; Kevin Chen-Chuan Chang
- Reference count: 25
- This paper introduces Exemplar-Based Expository Text Generation and proposes REPA, achieving imitativeness (4.16), adaptiveness (3.90), and adaptive-imitativeness (3.93) scores with low hallucination rates (6.57%).

## Executive Summary
This paper introduces a novel task—Exemplar-Based Expository Text Generation—where the goal is to generate expository text on a target topic using a single exemplar from a similar source topic. The challenge lies in balancing cross-topic consistency with factual adaptation to the new topic. To address this, the authors propose the Recurrent Plan-then-Adapt (REPA) framework, which leverages large language models for adaptive imitation through a fine-grained plan-then-adapt process. REPA uses dual memory structures (short-term and long-term) to enhance input clarity and output coherence, enabling coherent long-form text generation.

## Method Summary
REPA processes text sentence-by-sentence in a recurrent loop. The PLAN module first clarifies input segments using short-term memory to resolve coreference ambiguities, then outlines key information as questions. These questions are transferred to the target topic via topic token substitution. The ADAPT module performs retrieval-augmented QA with dual retrieval (per-topic and per-query), using verbalized confidence scores to filter low-confidence answers. Finally, the WRITE module drafts answers and revises them using long-term memory summaries to prevent repetition. This approach enables REPA to handle arbitrarily long text while maintaining coherence and reducing hallucinations.

## Key Results
- REPA achieves high imitativeness (4.16), adaptiveness (3.90), and adaptive-imitativeness (3.93) scores on LLM-based evaluation.
- REPA generates more factual content with significantly lower hallucination rates (6.5714%) compared to baselines.
- Ablation studies show the Clarify and refusal mechanisms significantly contribute to performance, with removal causing NLI-E to drop from 0.7927 to 0.5847 and increasing hallucination rates.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Recurrent segment-by-segment processing with dual memory structures enables arbitrarily long text generation while maintaining coherence and reducing redundancy.
- **Mechanism**: Sentence-level recurrence with short-term memory (recent inputs) for coreference resolution and long-term memory (output summary) for repetition prevention.
- **Core assumption**: Sentence-level granularity balances semantic completeness and processing tractability.
- **Evidence anchors**: Abstract mentions dual memory structures; Section 3.2 describes handling arbitrarily long text without sacrificing information.
- **Break condition**: When input segments lack semantic self-containment or coreference chains extend beyond short-term memory window.

### Mechanism 2
- **Claim**: Framing content plans as questions enables both cross-topic structure transfer and factual grounding.
- **Mechanism**: PLAN extracts key information and frames it as questions, which are transferred via simple topic token substitution.
- **Core assumption**: Source and target topics within the same domain share similar question-worthy content structures.
- **Evidence anchors**: Section 3.2.1 explains question transitivity; ablation shows Outline component significantly contributes to performance.
- **Break condition**: When source and target topics have structurally divergent characteristics.

### Mechanism 3
- **Claim**: Verbalized confidence calibration with refusal enables graceful handling of unanswerable transferred questions.
- **Mechanism**: ADAPT uses retrieval-augmented QA with verbalized confidence scores, filtering questions with confidence below threshold θ=0.7.
- **Core assumption**: LLMs can produce calibrated verbalized confidence scores that correlate with answer correctness.
- **Evidence anchors**: Section 3.2.2 describes the confidence-based refusal mechanism; ablation shows its effectiveness in reducing hallucinations.
- **Break condition**: When confidence calibration is unreliable or too many questions are refused.

## Foundational Learning

- **Concept**: Retrieval-Augmented Generation (RAG)
  - Why needed here: REPA's Calibrated-QA uses dual retrieval (per-topic and per-query). Understanding RAG helps diagnose when retrieval failures cause factual errors.
  - Quick check question: What is the difference between REPA's per-topic retrieval and per-query retrieval, and when would each fail?

- **Concept**: Confidence Calibration in Black-Box LLMs
  - Why needed here: The refusal mechanism depends on verbalized confidence scores being calibrated.
  - Quick check question: Why does the paper use verbalized confidence rather than log-probabilities for the refusal mechanism?

- **Concept**: Hallucination Detection and FActScore-style Evaluation
  - Why needed here: The paper uses NLI-based factuality metrics derived from FActScore.
  - Quick check question: How does the paper's NLI-based evaluation differ from standard generation metrics like ROUGE or BLEU?

## Architecture Onboarding

- **Component map**:
  Input Text X → Segment into sentences {x_t} → Recurrent Loop (per segment) → PLAN: Clarify(x_t, h_t) → x'_t, h_{t+1}; Outline(x'_t, t_x, t_y) → q_t → ADAPT: Retriever(t_y, q_t) → k_t; Calibrated-QA(q_t, k_t, θ) → a_t → Write(a_t, c_t) → y_t, c_{t+1} → Concatenate all y_t → Output Y

- **Critical path**: Clarify → Outline → Retrieve → Calibrated-QA (with threshold) → Write (with revision against long-term memory)

- **Design tradeoffs**:
  - Sentence vs. paragraph segmentation: Sentences enable fine-grained control but may fragment context
  - Confidence threshold (θ=0.7): Higher threshold reduces hallucinations but may filter valid facts
  - API efficiency vs. quality: REPA requires ~39 API calls per output vs. 1 for naive LLM

- **Failure signatures**:
  - Cascading Clarify errors: Incorrect antecedent resolution propagates through pipeline
  - Retrieval failures: DPR returns irrelevant passages causing incomplete/incorrect facts
  - Memory overflow/conflict: LTM summaries losing critical details leading to redundancy or contradiction

- **First 3 experiments**:
  1. Ablate Clarify-STM on 50 Wikipedia samples: Measure impact on coreference-heavy segments by comparing NLI-E and hallucination rates
  2. Vary confidence threshold θ: Test θ ∈ {0.5, 0.7, 0.9} and plot tradeoff curve between NLI-C and answer coverage
  3. Test on high-variability domain: Apply REPA to domain with greater cross-topic divergence than RoleEE to identify where outline transfer breaks down

## Open Questions the Paper Calls Out
None

## Limitations
- Novel evaluation metrics (imitativeness, adaptiveness, adaptive-imitativeness) rely entirely on LLM judgment without human validation
- Memory structures (STM and LTM) are described abstractly but implementation details are sparse
- Reliance on verbalized confidence scores for refusal introduces black-box dependency with unproven effectiveness

## Confidence
- **High confidence**: PLAN module's question-based transfer mechanism and its contribution to cross-topic consistency
- **Medium confidence**: Overall REPA framework's superiority over baselines across three datasets
- **Medium confidence**: Calibrated-QA refusal mechanism's effectiveness, dependent on verbalized confidence reliability
- **Low confidence**: Exact implementation of memory structures and their optimal configurations

## Next Checks
1. Conduct human evaluation on subset of outputs (n=50) to validate LLM-based imitativeness/adaptiveness scores against human judgments
2. Test REPA's robustness to memory structure variations by running ablations with different STM window sizes (1-5 sentences) and measuring impact on hallucination rates
3. Apply REPA to high-variability domain (e.g., comparing consumer products across different categories) to identify boundaries where outline transfer fails and characterize failure modes quantitatively