---
ver: rpa2
title: Are Large Language Models Good Temporal Graph Learners?
arxiv_id: '2506.05393'
source_url: https://arxiv.org/abs/2506.05393
tags:
- node
- temporal
- graph
- llms
- destination
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TGTalker, the first framework applying large
  language models (LLMs) to real-world temporal graphs for link prediction. The core
  method encodes recent temporal graph structure and neighbor information as natural
  language prompts for LLMs, enabling predictions without fine-tuning.
---

# Are Large Language Models Good Temporal Graph Learners?

## Quick Facts
- arXiv ID: 2506.05393
- Source URL: https://arxiv.org/abs/2506.05393
- Reference count: 40
- This paper introduces TGTalker, the first framework applying large language models (LLMs) to real-world temporal graphs for link prediction.

## Executive Summary
This paper introduces TGTalker, the first framework applying large language models (LLMs) to real-world temporal graphs for link prediction. The core method encodes recent temporal graph structure and neighbor information as natural language prompts for LLMs, enabling predictions without fine-tuning. Experiments across five datasets and six LLM families show TGTalker achieves competitive performance with state-of-the-art temporal graph neural networks, consistently outperforming popular TGNN baselines. The framework also generates interpretable textual explanations for predictions, revealing reasoning patterns like recency bias and repeated interactions. Ablation studies confirm that temporal neighbor sampling is critical for performance.

## Method Summary
TGTalker formulates temporal link prediction as a ranking task where LLMs predict destination nodes through structured in-context learning. The framework constructs prompts with four components: a background set containing the most recent 300 edges, a 5-shot example set demonstrating the task format, a query set with source nodes and their 2 most recent neighbors, and temporal neighbor sampling to extract relevant structural information. Unlike traditional TGNNs, TGTalker requires no fine-tuning and generates natural language explanations for predictions. The method leverages recency bias in temporal graphs to select the most relevant structural information for LLM context.

## Key Results
- TGTalker achieves competitive MRR performance against state-of-the-art temporal graph neural networks across five real-world datasets
- The framework consistently outperforms popular TGNN baselines including TGAT, TGN, and GraphSage
- Ablation studies show temporal neighbor sampling is critical, with performance dropping from 0.649 to 0.322 on tgbl-wiki when neighbors are removed
- LLM-generated explanations show correlation between reasoning categories and prediction accuracy, though quality varies significantly across model families

## Why This Works (Mechanism)

### Mechanism 1: Recency Bias Exploitation via Temporal Neighbor Sampling
- Claim: TGTalker leverages documented recency bias in temporal graphs to select the most relevant structural information for LLM context.
- Mechanism: The framework samples the most recent m neighbors for each source node and includes them in the prompt. Edges closest to prediction time are prioritized, converting temporal proximity into token-level context.
- Core assumption: Recent interactions are more predictive of future links than older interactions in the tested domains.
- Evidence anchors: [abstract] "TGTalker utilizes the recency bias in temporal graphs to extract relevant structural information" and [section 4.2] "we leverage the strong recency bias in temporal graph to subsample the edges that are closest to the time of interest"

### Mechanism 2: In-Context Learning with Structured Prompt Components
- Claim: LLMs perform temporal link prediction through few-shot prompting without gradient-based fine-tuning.
- Mechanism: Four-component prompt structure: (1) background set provides recent graph context, (2) example set provides 5 QA pairs demonstrating task format, (3) query set encodes current prediction task, (4) temporal neighbor sampling augments with node-specific history.
- Core assumption: Pre-trained LLMs possess sufficient pattern-matching capacity to infer temporal link patterns from structured in-context examples.
- Evidence anchors: [abstract] "enabling predictions without fine-tuning" and [section 5.1] "TGTalker requires no fine-tuning or training when compared to existing methods"

### Mechanism 3: Explanation Generation with Correlated Reasoning Categories
- Claim: LLM-generated explanations exhibit reasoning patterns that correlate with prediction accuracy, enabling interpretability.
- Mechanism: Post-prediction, a second LLM call generates natural language explanations. Explanations are classified into 10 categories (e.g., "Most Recent Interaction," "Repeated Interaction Pattern"). For GPT-4.1-mini, categories like "Most Recent Interaction" show high MRR while "Lack of Data" shows low MRR.
- Core assumption: LLM explanations reflect actual reasoning processes rather than pure post-hoc rationalization.
- Evidence anchors: [abstract] "generates interpretable textual explanations for predictions, revealing reasoning patterns like recency bias and repeated interactions" and [section 5.2] "For GPT-4.1-mini... 'Lack of Data' category consistently shows low MRR, validating that the LLM recognizes instances with insufficient evidence"

## Foundational Learning

- Concept: **Continuous-Time Dynamic Graphs (CTDGs)**
  - Why needed here: The paper formulates temporal graphs as ordered edge streams G = {(s₁, d₁, t₁), ...} with timestamps, not discrete snapshots. This formulation determines how neighbors are sampled and how recency is computed.
  - Quick check question: Given edge stream [(A,B,10), (B,C,15), (A,C,20)], what is the 1-hop neighborhood of A at time t=18?

- Concept: **In-Context Learning (ICL) Paradigm**
  - Why needed here: TGTalker relies entirely on zero-shot/few-shot ICL without gradient updates. Understanding the distinction between background set (context), example set (demonstrations), and query set (task) is essential for prompt debugging.
  - Quick check question: Why does the example set use question-answer pairs rather than just listing edges?

- Concept: **Temporal Link Prediction as Ranking (MRR Evaluation)**
  - Why needed here: Standard evaluation uses Mean Reciprocal Rank with negative sampling (50% historical, 50% random negatives). Unlike TGNNs that output probabilities, TGTalker directly predicts destination nodes.
  - Quick check question: If a model ranks the correct destination at position 3 among 100 candidates, what is the reciprocal rank contribution?

## Architecture Onboarding

- Component map:
  Background Set -> Example Set -> Query Set -> LLM Interface
  Temporal Neighbor Sampler -> Query Set -> LLM Interface

- Critical path:
  1. At prediction timestamp t', retrieve b most recent edges from cumulative graph G_t'
  2. For each source node s, sample m most recent 1-hop neighbors via temporal neighbor sampler
  3. Construct prompt: system instruction + background set + example set + query
  4. LLM generates destination node prediction (direct node ID, not probability distribution)
  5. Optional: Second LLM call generates explanation, classified into reasoning categories

- Design tradeoffs:
  - **Background size vs context window**: Larger b provides richer context but approaches 32k-128k token limits
  - **Neighbor count (m)**: Ablation shows m=10 > m=2 on tgbl-wiki (0.656 vs 0.649) but costs more tokens
  - **LLM selection**: Qwen2.5-7B outperforms GPT-4.1-mini on tested datasets; model choice affects both accuracy and explanation quality
  - **Recency vs long-range**: Framework explicitly trades long-range dependency capture for computational tractability

- Failure signatures:
  - **Temporal neighbor ablation**: Performance collapses from 0.649→0.322 (tgbl-wiki) when neighbors removed—this is the dominant signal
  - **"Lack of Data" explanations**: High proportion indicates insufficient context reaching LLM
  - **Hallucinated explanations**: Llama3-8B's "Default or Most Common Node" category contains confabulations
  - **Context overflow**: Very dense graphs hit token limits, truncating relevant history

- First 3 experiments:
  1. **Neighbor ablation**: Run m ∈ {0, 1, 2, 5, 10} on a validation split to calibrate optimal sampling for your data distribution
  2. **Background set scaling**: Test b ∈ {100, 200, 300, 500} against token budget to find saturation point
  3. **Explanation-MRR correlation**: For your chosen model, compute per-category MRR to validate explanation trustworthiness before production use

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does TGTalker's reliance on recency-based sampling affect its ability to capture long-range temporal dependencies compared to TGNNs with full graph access?
- Basis in paper: [explicit] Appendix A (Limitations) states that providing recent edges via text prompts may overlook long-range dependencies, potentially lowering performance on datasets where relevant links span longer durations.
- Why unresolved: Current LLM context windows cannot process the entire history of large temporal graphs, forcing a trade-off between recency and completeness.
- What evidence would resolve it: Evaluation on temporal graph datasets specifically constructed to require long-range historical reasoning, comparing performance against TGNNs with unbounded memory.

### Open Question 2
- Question: Can the reliability of LLM-generated link explanations be improved to minimize hallucinations and better correlate with predictive accuracy?
- Basis in paper: [explicit] Section 5.2 observes that Llama3-8B shows surprisingly high performance in "Lack of Data" categories (indicating a disconnect between reasoning and prediction) and Appendix A explicitly notes the risk of unreliable explanations due to LLM hallucinations.
- Why unresolved: The mechanism for generating natural language explanations is decoupled from strict logical constraints, allowing models to produce plausible but fabricated reasoning.
- What evidence would resolve it: Development of verification mechanisms that quantitatively align generated textual rationales with ground-truth graph statistics or structured logical proofs.

### Open Question 3
- Question: Is the TGTalker framework computationally efficient enough for real-time deployment on large-scale graphs given its dependency on large pre-trained models?
- Basis in paper: [explicit] Appendix A notes that the framework's speed and efficiency are inherently tied to the characteristics of the base LLM, implying a potential bottleneck compared to specialized, lighter TGNN architectures.
- Why unresolved: The paper focuses on link prediction accuracy (MRR) rather than inference latency or computational throughput.
- What evidence would resolve it: Detailed benchmarks measuring inference time and memory overhead on datasets with millions of edges compared against baseline TGNNs.

## Limitations
- The framework's effectiveness depends critically on recency bias assumption, which may not hold for datasets with periodic patterns or long-range dependencies
- Explanation quality varies significantly across LLM families, with some models producing hallucinated explanations that don't reflect actual reasoning
- The method's computational efficiency for large-scale deployment is not evaluated, and the framework may face context window limitations on very dense graphs

## Confidence

- **High confidence**: TGTalker's competitive MRR performance against TGNN baselines, the critical importance of temporal neighbor sampling (demonstrated through ablation), and the existence of explanation-MRR correlations for certain LLM models
- **Medium confidence**: The general mechanism of LLM-based temporal graph reasoning, as the approach shows promise but depends heavily on dataset characteristics and model selection
- **Low confidence**: The reliability of LLM-generated explanations as true reasoning indicators, given substantial variation across models and evidence of hallucination in some cases

## Next Checks

1. **Dataset bias validation**: Test TGTalker on datasets with known long-range dependencies or periodic patterns (e.g., IoT sensor networks, traffic data) to evaluate recency bias limitations

2. **Cross-model explanation reliability**: Compare explanation quality and hallucination rates across all six LLM families on the same dataset to quantify model-specific reliability patterns

3. **Context window stress test**: Systematically evaluate performance degradation as background set size approaches and exceeds context window limits on progressively denser temporal graphs