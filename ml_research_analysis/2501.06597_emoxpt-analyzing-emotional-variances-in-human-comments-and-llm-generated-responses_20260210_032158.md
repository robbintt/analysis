---
ver: rpa2
title: 'EmoXpt: Analyzing Emotional Variances in Human Comments and LLM-Generated
  Responses'
arxiv_id: '2501.06597'
source_url: https://arxiv.org/abs/2501.06597
tags:
- chatgpt
- data
- responses
- human
- sentiment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates emotional differences between human comments
  and LLM-generated responses on generative AI topics. It introduces EmoXpt, a sentiment
  analysis framework that applies K-means clustering to BERT embeddings at both word
  and sentence levels.
---

# EmoXpt: Analyzing Emotional Variances in Human Comments and LLM-Generated Responses

## Quick Facts
- arXiv ID: 2501.06597
- Source URL: https://arxiv.org/abs/2501.06597
- Reference count: 31
- Humans express predominantly negative sentiment (72%) about generative AI, while ChatGPT responses are largely positive (90%).

## Executive Summary
This study introduces EmoXpt, a framework for analyzing emotional differences between human comments and LLM-generated responses on generative AI topics. The framework applies K-means clustering to BERT embeddings at both word and sentence levels to compare sentiment patterns. The analysis reveals a stark contrast: human tweets referencing ChatGPT, OpenAI, Copilot, and LLMs show predominantly negative sentiment (72%), while ChatGPT's responses exhibit strong positive sentiment (90%). The study demonstrates that LLM-generated responses are notably more cohesive and consistently positive than human responses, though they lack the nuanced emotional expression found in human communication.

## Method Summary
The EmoXpt framework preprocesses text by lowercasing, removing non-alphabetic characters, URLs, emojis, mentions, and stopwords, then extracts 768-dimensional BERT embeddings using the bert-base-uncased model from Hugging Face. Word embeddings are averaged to create sentence-level representations. K-means clustering (k=2) is applied to these embeddings, and clustering quality is evaluated using silhouette scores. The analysis compares 512 human tweets with ChatGPT responses across the same topics, examining both word-level and sentence-level emotional patterns through t-SNE visualization.

## Key Results
- Human comments show 72% negative sentiment versus 27% positive, while ChatGPT responses show 90% positive versus 10% negative
- K-means clustering achieves silhouette scores of 0.19 for human sentences versus 0.58 for ChatGPT sentences, indicating more consistent sentiment patterns in AI-generated content
- Word-level clustering shows even starker differences: human words achieve 0.13 silhouette score versus 0.053 for ChatGPT words

## Why This Works (Mechanism)
The approach works by leveraging BERT's semantic understanding to capture emotional content at both granular (word) and contextual (sentence) levels. K-means clustering groups similar emotional expressions together, with higher silhouette scores indicating more coherent sentiment clusters. The contrast between human and AI responses emerges from fundamentally different communication patterns: humans express diverse, often critical emotions about AI technology, while ChatGPT's training and design biases toward positive, helpful responses.

## Foundational Learning
- **BERT Embeddings**: Pre-trained contextual word representations that capture semantic and emotional meaning; needed because raw text lacks numerical form for clustering analysis; quick check: verify embeddings capture sentiment by clustering known positive/negative sentences.
- **K-means Clustering**: Unsupervised algorithm that partitions data into k groups based on similarity; needed to identify sentiment patterns without labeled training data; quick check: ensure clusters align with expected positive/negative sentiment through manual inspection.
- **Silhouette Score**: Metric measuring clustering quality by comparing intra-cluster cohesion to inter-cluster separation; needed to quantify how well emotional patterns are distinguished; quick check: higher scores should correspond to more distinct sentiment groups.
- **t-SNE Visualization**: Dimensionality reduction technique for visualizing high-dimensional embeddings in 2D/3D space; needed to qualitatively assess clustering structure; quick check: clusters should appear as distinct groups in visualization.

## Architecture Onboarding
**Component Map**: Text Preprocessing -> BERT Embedding Extraction -> K-means Clustering -> Silhouette Score Calculation -> t-SNE Visualization

**Critical Path**: Clean text → Extract embeddings → Cluster with K-means → Evaluate with silhouette score → Visualize with t-SNE

**Design Tradeoffs**: Binary K-means (k=2) simplifies sentiment analysis but may miss complex emotional nuances like sarcasm or ambivalence; averaging word embeddings for sentence representation loses word order information but enables computational efficiency.

**Failure Signatures**: Low silhouette scores indicate poor cluster separation, suggesting either noise in the data, insufficient preprocessing, or that emotional variance doesn't align with binary classification; inconsistent cluster labels between runs suggest sensitivity to random initialization.

**3 First Experiments**:
1. Run the full pipeline on a small sample of 10 tweets and responses to verify each component works correctly
2. Test different k values (k=3, k=4) to see if more nuanced sentiment patterns emerge
3. Compare results using different BERT variants (bert-base-uncased vs bert-large-uncased) to assess embedding quality impact

## Open Questions the Paper Calls Out
- **Cross-LLM Emotional Profiles**: Do LLMs beyond ChatGPT (e.g., Gemini, Claude, Llama) exhibit similar positivity biases, or display distinct emotional profiles? This remains untested as the study exclusively analyzed ChatGPT.
- **Complex Sentiment Detection**: Can unsupervised clustering methods like K-means accurately detect complex sentiments such as sarcasm, irony, or ambivalence in human-AI interactions? The binary clustering approach may oversimplify nuanced emotional expressions.
- **Temporal Evolution**: How do ChatGPT's emotional patterns evolve over time in response to changing public discourse and model updates? The two-month collection window was aggregated without longitudinal analysis.
- **Engagement Effectiveness**: Does ChatGPT's consistently positive tone lead to more effective user engagement, or does it reduce perceived authenticity and trust? The study measured clustering patterns but not user experience outcomes.

## Limitations
- Small, time-bounded dataset (512 tweets from March-April 2023) may not capture broader sentiment patterns across different contexts
- Binary K-means clustering oversimplifies complex emotional landscape and may miss nuanced expressions like sarcasm
- Preprocessing pipeline removes potentially important contextual information by eliminating stopwords and neutral terms

## Confidence
- **High Confidence**: The observed sentiment distribution differences between human (72% negative) and ChatGPT responses (90% positive) are robust findings supported by clear numerical evidence
- **Medium Confidence**: The higher silhouette scores for ChatGPT clustering (0.58 vs 0.19 for humans) reliably indicate more consistent sentiment patterns in AI-generated content
- **Low Confidence**: The interpretation that ChatGPT responses "lack nuanced emotional expression" extends beyond what the clustering analysis directly demonstrates

## Next Checks
1. Collect a larger dataset spanning multiple months and major AI events to test whether sentiment asymmetry persists across different time periods
2. Replicate the analysis using Reddit, forum discussions, or other social media platforms to determine if patterns are platform-specific
3. Generate ChatGPT responses with modified prompts (e.g., "respond neutrally") to assess whether sentiment bias is inherent or prompt-dependent