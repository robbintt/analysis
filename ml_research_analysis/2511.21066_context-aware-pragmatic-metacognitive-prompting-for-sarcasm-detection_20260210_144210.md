---
ver: rpa2
title: Context-Aware Pragmatic Metacognitive Prompting for Sarcasm Detection
arxiv_id: '2511.21066'
source_url: https://arxiv.org/abs/2511.21066
tags:
- retrieval
- text
- sarcasm
- detection
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study enhances sarcasm detection by integrating contextual\
  \ knowledge into the state-of-the-art Pragmatic Metacognitive Prompting (PMP) method.\
  \ It proposes two strategies: non-parametric knowledge retrieval using Google Search\
  \ API for culture-specific terms, and self-knowledge awareness using the model\u2019\
  s internal understanding."
---

# Context-Aware Pragmatic Metacognitive Prompting for Sarcasm Detection

## Quick Facts
- **arXiv ID**: 2511.21066
- **Source URL**: https://arxiv.org/abs/2511.21066
- **Reference count**: 40
- **Primary Result**: Non-parametric knowledge retrieval (Google Search API) improves macro-F1 by 9.87% on Indonesian Twitter; self-knowledge retrieval improves macro-F1 by 3.29% (SemEval) and 4.08% (MUStARD).

## Executive Summary
This paper enhances sarcasm detection by integrating contextual knowledge into the state-of-the-art Pragmatic Metacognitive Prompting (PMP) method. The authors propose two knowledge retrieval strategies: non-parametric retrieval using Google Search API for culture-specific terms, and self-knowledge awareness using the model's internal understanding. Evaluated on three datasets (Indonesian Twitter, SemEval-2018, MUStARD), the Google Search API approach significantly improved macro-F1 by 9.87% on the Indonesian Twitter dataset, while self-knowledge retrieval increased macro-F1 by 3.29% on SemEval and 4.08% on MUStARD. Results highlight the importance of context, especially for culturally specific language. Future work will focus on optimizing retrieval quality.

## Method Summary
The method adapts retrieval-augmented generation principles to the two-stage PMP pipeline for sarcasm detection. Keyword extraction occurs via either spaCy NER/POS tagging (entities/proper nouns) or LLM-based unknown word identification. Context retrieval pairs with extraction: LLM-only defines keywords using internal knowledge, while Google Search API retrieves and summarizes web content. This contextual information is injected into the first PMP call, with few-shot examples added to the second call. The pipeline was tested using 8B parameter models (Llama-3, Qwen-3) across three datasets.

## Key Results
- Non-parametric knowledge retrieval using Google Search API improved macro-F1 by 9.87% on Indonesian Twitter dataset
- Self-knowledge retrieval improved macro-F1 by 3.29% on SemEval-2018 and 4.08% on MUStARD
- Few-shot examples in second PMP call improved performance (Qwen-3-8B SemEval: +3.29%, Llama-3-1-8B: +0.84%)
- Context augmentation degraded performance on some datasets with Llama-3-8B (MUStARD macro-F1 dropped from 0.6345 to 0.5344)

## Why This Works (Mechanism)

### Mechanism 1: Non-parametric knowledge retrieval for cultural grounding
- **Claim**: Google Search API improves sarcasm detection on culturally-specific text by providing external definitions for terms not well-represented in LLM parametric knowledge
- **Mechanism**: Identify tokens model doesn't understand → retrieve web snippets via Google Search API → clean/LLM-summarize → inject definitions into prompt
- **Core Assumption**: LLM accurately identifies unknown terms and retrieved web snippets contain relevant, accurate definitions after cleaning
- **Evidence**: Indonesian Twitter: PMPWG macro-F1 rose from 0.5173 to 0.6108 (+9.87%)
- **Break Condition**: Performance degrades if keyword extraction fails, retrieved content is noisy/incorrect (e.g., "cie" error), or text is well-covered by LLM pre-training

### Mechanism 2: Self-knowledge awareness for contextual reasoning
- **Claim**: Eliciting model's internal knowledge improves sarcasm detection on standard language by enhancing contextual reasoning
- **Mechanism**: Token Tagging extracts entities/proper nouns → LLM defines keywords using parametric knowledge → inject self-generated definitions into prompt
- **Core Assumption**: LLM's internal parametric knowledge is sufficiently accurate for domain, and generating definitions improves reasoning
- **Evidence**: SemEval +3.29% macro-F1, MUStARD +4.08% macro-F1
- **Break Condition**: Fails if LLM's internal knowledge is incorrect/hallucinated, or model cannot reliably self-assess (e.g., Llama-3-8B on MUStARD)

### Mechanism 3: Few-shot examples in second PMP call
- **Claim**: Few-shot examples bias model's reasoning heuristics toward task-specific patterns, complementing contextual grounding
- **Mechanism**: Place k=2 few-shot examples in system prompt of P2 to guide structured reflection on pragmatic factors
- **Core Assumption**: Examples capture nuanced reasoning patterns needed for sarcasm detection in target domain
- **Evidence**: Qwen-3-8B SemEval: PMPWL-FS rose from 0.7541 to 0.7870 (+3.29%)
- **Break Condition**: Benefits lost if examples aren't representative, cause overfitting, or add token cost without gain

## Foundational Learning

- **Named Entity Recognition (NER) & Part-of-Speech (POS) Tagging**
  - *Why needed*: Used in Token Tagging approach to extract entity and proper noun keywords for internal knowledge retrieval
  - *Quick check*: Can you explain why the authors restrict keyword extraction to named entities and proper nouns instead of all nouns or verbs?

- **Retrieval-Augmented Generation (RAG) Principles**
  - *Why needed*: Core innovation adapts RAG principles (retrieving external context to augment prompts) to sarcasm detection
  - *Quick check*: How does the paper's use of Google Search API differ from a standard RAG pipeline that uses a pre-built vector database?

- **Pragmatic Metacognitive Prompting (PMP) Structure**
  - *Why needed*: Entire method is built as modification to existing two-call PMP pipeline (P1: analysis, P2: reflection & verdict)
  - *Quick check*: According to the paper, why is the word-information block (W) injected into the first call (P1) and the few-shot examples (F) into the second call (P2)?

## Architecture Onboarding

- **Component Map**: Input → Keyword Extraction (Token Tagging/LLM) → Context Retrieval (LLM-only/Google Search) → PMP Core (P1+P2) → Output
- **Critical Path**: Indonesian Twitter: LLM Keyword Extraction → Google Search Retrieval → P1 (with Wg) → P2 (with F) → Verdict
- **Design Tradeoffs**:
  - Token Tagging: Faster/deterministic but may miss slang; LLM-based: More adaptive but costlier/inconsistent
  - Google Search: Real-world context but noisy/has API limits; LLM-only: Faster/cheaper but limited by training cutoff
  - P1 context aids initial understanding; P2 few-shot guides final reasoning
- **Failure Signatures**:
  - Low precision/high recall: Over-reliance on sarcasm cues from few-shot examples or noisy context
  - Performance drop on standard English with Google Search: Retrieval adding noise to well-handled domains
  - Model-specific degradation (e.g., Llama-3 vs Qwen-3): Differences in multilingual/instruction-following capabilities
- **First 3 Experiments**:
  1. Implement original PMP pipeline (without context) on SemEval-2018 subset using Qwen-3-8B to verify ~0.7541 macro-F1 baseline
  2. Compare keywords extracted via Token Tagging vs LLM-based method on Indonesian Twitter sample; measure retrieval precision
  3. Using manually curated keywords, compare downstream sarcasm classification with LLM-only vs Google Search retrieval to isolate retrieval quality effect

## Open Questions the Paper Calls Out

- **Question**: How does specific quality of retrieved contextual information quantitatively impact sarcasm detection performance?
  - *Basis*: "Future work will focus on... examining how retrieval quality affects performance"
  - *Why unresolved*: Study establishes context improves performance but doesn't isolate retrieval quality variable
  - *What evidence resolves it*: Graded evaluation where gold standard context is progressively degraded to measure correlation with macro-F1

- **Question**: What causes context augmentation to benefit Llama-3.1-8B but degrade Llama-3-8B on MUStARD dataset?
  - *Basis*: "Divergent behavior" between model versions noted; recommendation for follow-up analysis comparing token coverage/training differences
  - *Why unresolved*: Authors observed improvement for 3.1 but significant hurt for 3.0 (macro-F1 dropped from 0.6345 to 0.5344) without definitive explanation
  - *What evidence resolves it*: Comparative ablation study analyzing tokenization outputs/attention mechanisms of both models with retrieved context

- **Question**: Can self-correcting validation pipeline effectively filter out hallucinated/irrelevant context before classification?
  - *Basis*: Need for "validations for a fallback pipeline" because approach "still has flaws" and retrieval can return incorrect definitions
  - *Why unresolved*: Current pipeline injects potentially factually wrong/noisy information without verification mechanism
  - *What evidence resolves it*: Experiments implementing "judge" module that discards retrieved context if it contradicts input text's internal representation

## Limitations

- **Language/Cultural Scope**: Performance gains highly dataset-dependent; significant improvements on culturally-specific Indonesian data but mixed/negative results on standard English datasets
- **Retrieval Quality Control**: Google Search API method susceptible to noisy/irrelevant context with no explicit quality filtering; could lead to model degradation
- **Reproducibility Gaps**: Critical implementation details underspecified including chunk size for BM25 retrieval, exact few-shot examples used, and decoding parameters
- **Model Dependency**: Performance varies significantly by model, suggesting sensitivity to LLM's multilingual/instruction-following capabilities

## Confidence

- **High Confidence**: Non-parametric knowledge retrieval improves sarcasm detection on culturally-specific datasets (e.g., Indonesian Twitter +9.87% macro-F1)
- **Medium Confidence**: Self-knowledge awareness (LLM-only retrieval) improves performance on standard English datasets (e.g., SemEval +3.29%, MUStARD +4.08%)
- **Low Confidence**: Few-shot examples in second PMP call consistently improve performance (inconsistent across models, only one example provided)

## Next Checks

1. **Replication with Specified Decoding**: Run PMP baseline and PMPWG pipeline on SemEval-2018 dataset using Qwen-3-8B with explicit decoding parameters (temperature=0.0, top_p=1.0, seed=42) to verify macro-F1 matches reported ~0.7541 baseline and ~0.6108 with Google retrieval

2. **Retrieval Quality Ablation**: Manually curate ground-truth keywords for Indonesian Twitter sample; compare downstream sarcasm classification performance when using these curated keywords with both LLM-only and Google Search retrieval, isolating retrieval quality from extraction quality effect

3. **Cross-Lingual Transfer Test**: Apply Token Tagging + LLM-only retrieval pipeline (PMPWL) to new culturally-specific non-Indonesian dataset (e.g., Malaysian Malay tweets); measure if self-knowledge awareness strategy generalizes beyond original Indonesian corpus