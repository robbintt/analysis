---
ver: rpa2
title: Leveraging Generative AI Through Prompt Engineering and Rigorous Validation
  to Create Comprehensive Synthetic Datasets for AI Training in Healthcare
arxiv_id: '2504.20921'
source_url: https://arxiv.org/abs/2504.20921
tags:
- data
- synthetic
- records
- were
- medical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed a comprehensive framework using prompt engineering
  with GPT-4 and advanced validation techniques to generate high-quality synthetic
  healthcare datasets. The approach produced 445,500 records across 22 interconnected
  database tables covering patient demographics, clinical notes, laboratory tests,
  and treatment plans.
---

# Leveraging Generative AI Through Prompt Engineering and Rigorous Validation to Create Comprehensive Synthetic Datasets for AI Training in Healthcare

## Quick Facts
- arXiv ID: 2504.20921
- Source URL: https://arxiv.org/abs/2504.20921
- Authors: Polycarp Nalela
- Reference count: 24
- Primary result: Generated 445,500 synthetic healthcare records across 22 tables with validation showing coherence scores 0.99800-1.00000 and perplexity 20-50

## Executive Summary
This study presents a framework using prompt engineering with GPT-4 and advanced validation techniques to generate high-quality synthetic healthcare datasets for AI training. The approach creates 445,500 records across 22 interconnected database tables covering patient demographics, clinical notes, laboratory tests, and treatment plans. The framework addresses data access limitations imposed by privacy regulations while maintaining data utility for training machine learning models in healthcare applications.

## Method Summary
The framework involves designing a PostgreSQL schema with 22 interrelated healthcare tables, generating synthetic data using customized GPT-4 prompts for each table, validating data quality through a multi-model pipeline (BERT NSP for coherence, GPT-2 perplexity for plausibility, RoBERTa NLI for consistency, autoencoder for anomalies), and integrating validated data into the database with referential integrity. The generation process uses 42 base patients as seed data to produce the comprehensive synthetic dataset.

## Key Results
- Generated 445,500 synthetic records across 22 interconnected PostgreSQL tables
- Validation showed exceptional quality: NSP probabilities 0.99800-1.00000, perplexity scores 20-50
- Consistency scores of 0.9875-0.9925 confirmed logical alignment across fields
- Autoencoders identified 40,490 anomalies with most reconstruction errors below 0.08

## Why This Works (Mechanism)

### Mechanism 1: Schema-Constrained Prompting
If domain-specific prompts explicitly define database schemas and field interdependencies, GPT-4 can generate structured synthetic data that adheres to relational constraints. The prompt encoding carries the structural blueprint which conditions the transformer's attention heads to output tokens conforming to the requested schema rather than free-text narratives. Core assumption: The LLM has sufficient pre-existing knowledge of medical terminology and relational data structures to map abstract schema definitions into concrete, realistic values.

### Mechanism 2: Multi-Model Validation Ensemble
If distinct validation models (BERT, GPT-2, RoBERTa, Autoencoders) are applied sequentially, they filter semantic, logical, and statistical errors more effectively than a single metric. The ensemble approach: BERT NSP evaluates sequential logic, GPT-2 perplexity measures distributional likelihood, RoBERTa NLI verifies entailment between fields, and Autoencoders identify outlying feature combinations. Core assumption: High scores on these NLP metrics correlate directly with clinical validity and utility for downstream AI training.

### Mechanism 3: Relational Integrity Enforcement
If synthetic data is generated with primary/foreign key awareness, it can populate a complex relational database without breaking referential integrity. The generation process maintains a state of generated IDs and propagates them to child tables, ensuring that every lab result links back to a valid patient encounter. Core assumption: The generation script handles the "state" of IDs correctly during the API call sequence.

## Foundational Learning

- **Concept: Perplexity**
  - Why needed here: Used to measure the "surprise" or plausibility of the synthetic text. Scores between 20-50 indicated the generated text closely matched natural medical language patterns.
  - Quick check question: If a medical record has a perplexity of 150, does this mean it is highly plausible or highly implausible? (Answer: Highly implausible/unsurprising to the model).

- **Concept: Next Sentence Prediction (NSP)**
  - Why needed here: Used to verify that clinical narratives flow logically (e.g., symptoms → diagnosis) rather than being random sentences stapled together.
  - Quick check question: What does a probability of 0.5 in NSP indicate about the relationship between two sentences? (Answer: The model is uncertain; the sentences are likely unrelated or incoherent).

- **Concept: Referential Integrity**
  - Why needed here: Essential for the PostgreSQL integration; ensures that a "Lab Result" row actually points to a valid "Patient" row.
  - Quick check question: Can you insert a "Treatment Plan" for `Patient_ID = 105` if `Patient_ID = 105` does not exist in the Patients table? (Answer: No, this would violate referential integrity).

## Architecture Onboarding

- **Component map:** GPT-4 API (Data Generator) -> Prompt Engineering Module (Schema definitions) -> Validation Pipeline (BERT NSP → GPT-2 Perplexity → RoBERTa NLI → Autoencoder) -> PostgreSQL Database (22 interconnected tables)

- **Critical path:** The Validation Pipeline is the bottleneck. If the Autoencoder anomaly threshold is set too low, too many records are rejected, stalling the database population.

- **Design tradeoffs:**
  - Cost vs. Quality: Running 4 different validation models per record is computationally expensive vs. simple statistical checks, but yields higher semantic fidelity.
  - Diversity vs. Coherence: Enforcing strict coherence may reduce the diversity of edge cases (rare diseases), potentially biasing the dataset toward "standard" presentations.

- **Failure signatures:**
  - High Perplexity Spikes: Indicates the LLM is hallucinating or generating text in a domain it hasn't mastered.
  - Autoencoder High Reconstruction Error: Indicates numerical combinations that are statistically impossible (e.g., heart rate = 0, age = 200).
  - RoBERTa Contradiction: Indicates logical inconsistencies (e.g., gender: male, condition: ovarian cyst).

- **First 3 experiments:**
  1. Threshold Sensitivity Analysis: Re-run validation with stricter Perplexity thresholds (e.g., < 30) to measure the trade-off in retained records vs. quality scores.
  2. Downstream Model Testing: Train a simple diagnostic classifier on this synthetic data and test it on a small, real (de-identified) holdout set to validate "utility" vs. just "plausibility."
  3. Schema Stress Testing: Attempt to generate data for a single, highly complex table (e.g., Clinical Notes) without the context of other tables to see if logical consistency (RoBERTa scores) degrades.

## Open Questions the Paper Calls Out

### Open Question 1
Does training AI models on this synthetic dataset yield predictive performance comparable to models trained on authentic clinical data? The study claims the data facilitates "AI Training" but validates only linguistic coherence and statistical plausibility, omitting any downstream model training or evaluation. What evidence would resolve it: Benchmarking results (e.g., AUC scores) of clinical predictive models trained on synthetic data versus real data.

### Open Question 2
Can the synthetic data withstand formal privacy attacks, such as membership inference, to verify the claim of being "privacy-compliant"? The paper asserts the solution is "privacy-compliant" based on the synthetic nature of the data without conducting formal security stress tests. What evidence would resolve it: Results from adversarial privacy attack simulations attempting to extract patient information from the dataset.

### Open Question 3
To what extent does the framework preserve complex, multi-table relational integrity and longitudinal consistency across patient visits? The database contains 22 interrelated tables, but validation focused primarily on text coherence and feature-level anomaly detection rather than complex relational dependencies. What evidence would resolve it: Logical integrity checks verifying the consistency of patient timelines and inter-table clinical rules.

## Limitations

- The exact prompt templates and GPT-4 parameters remain unspecified, making faithful reproduction difficult
- The multi-model validation ensemble lacks established benchmarks for this specific combination of metrics in healthcare synthetic data generation
- The relationship between validation metric thresholds and actual clinical utility for downstream AI training remains theoretical rather than empirically demonstrated

## Confidence

**High Confidence:** The mechanism of schema-constrained prompting works for generating structured synthetic data when explicit database schemas are provided.

**Medium Confidence:** The claim that this multi-model validation approach produces "high-quality" data suitable for AI training, though utility remains unproven.

**Low Confidence:** The assertion that this framework solves privacy compliance issues in healthcare AI training without addressing legal frameworks or conducting formal privacy tests.

## Next Checks

1. **Downstream Model Utility Testing:** Train a diagnostic classification model on the synthetic dataset and evaluate its performance on a small, de-identified real-world test set to validate practical AI training utility.

2. **Threshold Sensitivity Analysis:** Systematically vary validation thresholds and measure the trade-off between data volume retention and validation metric scores to establish more robust quality boundaries.

3. **Temporal Consistency Validation:** Generate synthetic data representing patient journeys over time and validate that temporal relationships maintain logical consistency across the clinical timeline.