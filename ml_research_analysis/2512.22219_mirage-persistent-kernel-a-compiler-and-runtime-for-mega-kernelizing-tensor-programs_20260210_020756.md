---
ver: rpa2
title: 'Mirage Persistent Kernel: A Compiler and Runtime for Mega-Kernelizing Tensor
  Programs'
arxiv_id: '2512.22219'
source_url: https://arxiv.org/abs/2512.22219
tags:
- task
- tasks
- kernel
- event
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MPK addresses the limitations of kernel-per-operator GPU execution
  by automatically transforming multi-GPU model inference into a single high-performance
  mega-kernel. It introduces an SM-level graph representation (tGraph) that captures
  data dependencies at the granularity of individual streaming multiprocessors, enabling
  cross-operator software pipelining and fine-grained kernel overlap.
---

# Mirage Persistent Kernel: A Compiler and Runtime for Mega-Kernelizing Tensor Programs

## Quick Facts
- arXiv ID: 2512.22219
- Source URL: https://arxiv.org/abs/2512.22219
- Reference count: 40
- Primary result: MPK achieves 1.0-1.7x speedup over kernel-per-operator LLM serving systems by mega-kernelizing inference into a single high-performance kernel

## Executive Summary
MPK addresses the limitations of kernel-per-operator GPU execution by automatically transforming multi-GPU model inference into a single high-performance mega-kernel. It introduces an SM-level graph representation (tGraph) that captures data dependencies at the granularity of individual streaming multiprocessors, enabling cross-operator software pipelining and fine-grained kernel overlap. The MPK compiler generates optimized SM-level task graphs and CUDA implementations, while the in-kernel parallel runtime executes these tasks within a single mega-kernel using decentralized scheduling.

## Method Summary
MPK transforms PyTorch models through its compiler into SM-level tGraphs, then uses Mirage Superoptimizer to generate CUDA task implementations. The in-kernel runtime executes tasks using decentralized scheduling with workers and schedulers, employing hybrid JIT/AOT dispatch. The system uses NVSHMEM for inter-GPU communication and supports paged attention and continuous batching for efficient inference.

## Key Results
- Reduces end-to-end inference latency by up to 1.7x compared to SGLang and vLLM
- Achieves 1.0-1.7x throughput improvement across five models and three GPU generations (A100, H100, B200)
- Pushes performance close to hardware limits while requiring minimal code changes from existing PyTorch implementations

## Why This Works (Mechanism)

### Mechanism 1: Fine-Grained SM-Level Dependency Decoupling
Replaces coarse kernel barriers with fine-grained, SM-level synchronization allowing consumer tasks to begin execution as soon as specific producer tasks complete, rather than waiting for entire kernels to finish.

### Mechanism 2: In-Kernel Decentralized Scheduling
Offloads graph execution logic from CPU to decentralized runtime running inside GPU kernel, eliminating launch overheads and enabling faster adaptation to dynamic workloads.

### Mechanism 3: Hybrid Task Dispatch (JIT vs. AOT)
Classifies tasks based on execution time variance to balance low latency for static workloads against load balancing for dynamic workloads.

## Foundational Learning

- **GPU Streaming Multiprocessors (SMs) & Thread Blocks**: Understanding that an SM is a physical processing block is crucial since MPK changes execution unit from "kernel" to "task" running on specific SMs. Quick check: In standard CUDA, does a Thread Block execute across multiple SMs or on a single SM? (Answer: Single SM).

- **Software Pipelining**: MPK claims to enable "cross-operator pipelining" where overlapping memory fetch of iteration N+1 with compute of iteration N hides latency. Quick check: What creates the "pipeline bubble" in standard kernel execution that MPK tries to eliminate? (Answer: The kernel barrier forcing full stop between stages).

- **Producer-Consumer Dependency Graphs (DAGs)**: The core data structure is tGraph, requiring understanding of Directed Acyclic Graphs to follow how MPK analyzes data dependencies to determine execution order. Quick check: In a DAG, what happens if there is a cycle in the dependencies? (Answer: Deadlock/Invalid graph).

## Architecture Onboarding

- **Component map**: Frontend (Python/C++) -> MPK Compiler (transforms computation graphs → tGraph) -> Task Codegen (generates CUDA device functions) -> Runtime (persistent kernel with Scheduler Warps and Worker SMs)
- **Critical path**: Dependency Analysis → Graph Linearization flow in compiler is critical; if dependencies are too conservative, parallelism is lost; if too aggressive, race conditions occur. In runtime, Scheduler Warp → Worker SM dispatch loop is critical path for performance.
- **Design tradeoffs**: Decentralized scheduling is robust but consumes SMs (4 SMs reserved); if workload is trivially small, runtime logic overhead outweighs fusion benefit. AOT is faster but brittle; JIT is flexible but higher latency per task.
- **Failure signatures**: Deadlock occurs if tGraph has circular dependencies or runtime exhausts shared memory pages; starvation suggests scheduler warps are overwhelmed; shared memory overflow fails "Paged shared-memory abstraction" if task requests more pages than SM limit.
- **First 3 experiments**: 
  1. Micro-benchmark Single Operator: Run single MatMul via MPK vs. cuBLAS to isolate MPK runtime wrapper cost
  2. Trace Visualization: Run fused GEMM + AllReduce and capture NSight Systems trace to verify cross-operator overlap
  3. Stress Test Dynamic Shapes: Run LLM inference with variable sequence lengths to validate hybrid task launch mechanism

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several areas remain unexplored including global coordination scheduling strategies and performance under online serving scenarios.

## Limitations
- Event synchronization overhead quantification is missing, making it unclear when fine-grained dependencies become counterproductive
- Multi-GPU MoE scaling gains are not clearly distinguished between tensor parallelism benefits versus MPK scheduling improvements
- Claims about pushing performance "close to hardware limits" lack empirical validation against theoretical roofline bounds

## Confidence
- **High confidence**: Single-GPU performance claims (1.0-1.7x speedup over vLLM/SGLang) supported by ablation studies and controlled experiments
- **Medium confidence**: Multi-GPU MoE scaling claims due to unclear attribution between hardware parallelism and scheduling improvements
- **Low confidence**: Hardware limits claims due to lack of theoretical roofline validation

## Next Checks
1. Event overhead micro-benchmark: Measure latency of fine-grained SM-level event synchronization versus traditional kernel barriers under varying dependency densities
2. Starvation stress test: Run MPK on workload with extreme task heterogeneity and monitor scheduler queue depths to verify workers do not idle
3. Single-GPU vs. MPK wrapper overhead: Compare MPK's runtime overhead against cuBLAS on simple GEMM workload to isolate scheduler and task dispatch cost