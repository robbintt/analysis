---
ver: rpa2
title: 'RefineShot: Rethinking Cinematography Understanding with Foundational Skill
  Evaluation'
arxiv_id: '2510.02423'
source_url: https://arxiv.org/abs/2510.02423
tags:
- reasoning
- arxiv
- answer
- evaluation
- camera
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses reliability issues in cinematography understanding
  benchmarks, specifically ShotBench, by identifying ambiguous option design and inconsistent
  model behavior in reasoning and instruction adherence. The authors systematically
  refined the benchmark by restructuring options for consistency and mutual exclusivity,
  then conducted a critical analysis of state-of-the-art ShotVL models.
---

# RefineShot: Rethinking Cinematography Understanding with Foundational Skill Evaluation

## Quick Facts
- arXiv ID: 2510.02423
- Source URL: https://arxiv.org/abs/2510.02423
- Reference count: 4
- Primary result: Refined cinematography benchmark showing ShotVL achieves high accuracy but poor reasoning faithfulness and instruction adherence, while Qwen models demonstrate better stability and instruction-following.

## Executive Summary
This paper addresses reliability issues in cinematography understanding benchmarks, specifically ShotBench, by identifying ambiguous option design and inconsistent model behavior in reasoning and instruction adherence. The authors systematically refined the benchmark by restructuring options for consistency and mutual exclusivity, then conducted a critical analysis of state-of-the-art ShotVL models. They introduced a new evaluation protocol with metrics for faithful reasoning and instruction adherence. Their experiments showed that while ShotVL achieves high accuracy, it suffers from reasoning unfaithfulness and poor instruction adherence. In contrast, Qwen models demonstrated better stability and instruction-following. The refined benchmark, RefineShot, provides more reliable assessment of model capabilities in cinematography understanding.

## Method Summary
The authors refined the ShotBench benchmark by restructuring MCQ options to ensure mutual exclusivity and consistent granularity across dimensions. They then evaluated state-of-the-art ShotVL models (3B/7B) and Qwen2.5VL models (3B/7B) using a new protocol that includes direct prompts, reasoning prompts, and step-by-step prompts. The evaluation introduced two key metrics: Faithful Reasoning Score (FRS) measuring consistency between reasoning and answers, and Instruction Adherence Score (IAS) measuring format compliance. Qwen3-2B was used as an automated verifier to check reasoning consistency.

## Key Results
- ShotVL-7B achieved high overall accuracy (70.2) but very low instruction adherence (11.7)
- Qwen2.5VL-7B showed moderate accuracy (51.7) but high adherence (93.5)
- The refined benchmark revealed systematic reasoning unfaithfulness in ShotVL models despite correct final answers
- Step-by-step prompting improved reasoning faithfulness but didn't resolve instruction adherence issues

## Why This Works (Mechanism)
The methodology works by first establishing a reliable benchmark foundation through option refinement, then exposing model behaviors through systematic evaluation protocols. The mutual exclusivity and consistent granularity in options eliminate ambiguity in evaluation. The dual metrics of FRS and IAS capture different aspects of model reliability: whether reasoning is internally consistent, and whether models follow explicit instructions. The use of an automated verifier (Qwen3-2B) provides scalable consistency checking without requiring extensive human annotation.

## Foundational Learning

**Cinematography Vocabulary** - Terms like shot framing, lighting conditions, camera movement, and shot composition form the domain knowledge foundation. Why needed: Models must understand these concepts to reason about film shots. Quick check: Can you distinguish between high-angle and low-angle shots?

**Multimodal Reasoning** - The ability to integrate visual information with textual reasoning processes. Why needed: Cinematography understanding requires analyzing both visual elements and their relationships. Quick check: Does the model correctly infer lighting type from both visual cues and context?

**Benchmark Evaluation Protocols** - Understanding direct, reasoning, and step-by-step prompting strategies. Why needed: Different prompting approaches reveal different model capabilities and failure modes. Quick check: Can you explain how step-by-step prompting differs from direct prompting?

## Architecture Onboarding

**Component Map**: Raw ShotBench questions -> Option Refinement (mutual exclusivity) -> Model Inference (ShotVL/Qwen) -> Automated Verification (Qwen3-2B) -> FRS/IAS Calculation -> Performance Analysis

**Critical Path**: Question refinement → Model inference with reasoning → Automated consistency verification → Metric computation. Each step must succeed for valid evaluation.

**Design Tradeoffs**: The paper prioritizes evaluation reliability over model training. This means accepting existing model weights rather than optimizing them for the benchmark, which provides more honest capability assessment but may underrepresent model potential.

**Failure Signatures**: Reasoning unfaithfulness appears as correct answers with inconsistent reasoning or incorrect answers with consistent reasoning. Instruction non-adherence manifests as format violations in step-by-step responses.

**First Experiments**:
1. Verify option refinement by checking mutual exclusivity across all dimensions
2. Run baseline inference on ShotVL-7B using direct prompting to establish accuracy baseline
3. Apply +check verification to sample reasoning-answer pairs to validate automated consistency checking

## Open Questions the Paper Calls Out

**Open Question 1**: Can the observed trade-off between high task-specific accuracy (ShotVL) and high foundational reliability (Qwen) be overcome, or is it an inherent tension in current multimodal model alignment? The paper identifies this disparity but doesn't propose a methodology to achieve both high accuracy and high adherence in a single model.

**Open Question 2**: To what extent does the reliance on Qwen3-2B as an automated verifier introduce bias or error into the Faithful Reasoning Score evaluation? The paper assumes the verifier's judgment is ground truth without validating against human experts.

**Open Question 3**: Do the reasoning unfaithfulness and instruction non-adherence defects generalize to proprietary state-of-the-art models like GPT-4o or Gemini? The experimental analysis was limited to ShotVL and Qwen2.5-VL series.

## Limitations
- Relies on automated verification which may introduce systematic bias without human validation
- Limited to specific open-weight models, leaving generalization to proprietary models unknown
- Doesn't address potential domain-specific knowledge gaps that could affect model performance

## Confidence

**High**: Benchmark refinement process is clearly specified and reproducible with the provided code repository.

**Medium**: Comparative model performance results are reliable but depend on specific implementation details like prompt templates and random seeds.

**Low**: Generalization of findings to proprietary models and other domain-specific benchmarks remains speculative without additional testing.

## Next Checks

1. Validate the automated verifier (Qwen3-2B) against human annotations on a sample of reasoning-answer pairs to assess potential bias.

2. Apply the RefineShot evaluation protocol to GPT-4o and Gemini to determine if reasoning unfaithfulness and instruction non-adherence are universal failure modes.

3. Develop a training paradigm that optimizes for both high task accuracy and high instruction adherence metrics simultaneously on RefineShot.