---
ver: rpa2
title: 'Modality-Aware SAM: Sharpness-Aware-Minimization Driven Gradient Modulation
  for Harmonized Multimodal Learning'
arxiv_id: '2510.24919'
source_url: https://arxiv.org/abs/2510.24919
tags:
- m-sam
- modality
- accuracy
- learning
- modalities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of modality imbalance in multimodal
  learning, where dominant modalities overshadow others, limiting overall performance
  and generalization. The authors propose Modality-Aware Sharpness-Aware Minimization
  (M-SAM), a model-agnostic framework that dynamically identifies the dominant modality
  using Shapley values and modulates the loss landscape to prioritize its robustness
  while allowing non-dominant modalities greater flexibility.
---

# Modality-Aware SAM: Sharpness-Aware-Minimization Driven Gradient Modulation for Harmonized Multimodal Learning

## Quick Facts
- arXiv ID: 2510.24919
- Source URL: https://arxiv.org/abs/2510.24919
- Reference count: 40
- Primary result: M-SAM consistently outperforms state-of-the-art methods, achieving up to 2.3% higher overall accuracy and demonstrating significantly better generalization through flatter loss landscapes.

## Executive Summary
This paper addresses modality imbalance in multimodal learning, where dominant modalities overshadow others, limiting overall performance and generalization. The authors propose Modality-Aware Sharpness-Aware Minimization (M-SAM), a model-agnostic framework that dynamically identifies the dominant modality using Shapley values and modulates the loss landscape to prioritize its robustness while allowing non-dominant modalities greater flexibility. M-SAM extends SAM by decomposing the loss function and applying sharpness-aware optimization primarily to the dominant modality, ensuring stable convergence and balanced learning. Extensive experiments on four diverse datasets (AV-MNIST, CREMA-D, UR-Funny, AVE) with both early and late fusion architectures show that M-SAM consistently outperforms state-of-the-art methods, including AGM, CGGM, and Recon-Boost, achieving up to 2.3% higher overall accuracy and demonstrating significantly better generalization through flatter loss landscapes.

## Method Summary
M-SAM dynamically identifies the dominant modality per mini-batch using Shapley values that measure each modality's contribution to accuracy. The framework applies Sharpness-Aware Minimization (SAM) only to the dominant modality while allowing non-dominant modalities to update using standard gradients. This asymmetric update strategy protects the dominant modality's convergence to flat minima while permitting non-dominant modalities to explore the parameter space more freely. The method maintains convergence rate O(log T / √T) matching standard SGD and SAM, ensuring optimization stability despite dynamic modality switching.

## Key Results
- M-SAM achieves up to 2.3% higher overall accuracy compared to state-of-the-art methods on multimodal datasets
- The framework demonstrates significantly better generalization through flatter loss landscapes as measured by normalized overfitting gap
- Consistent improvements across four diverse datasets (AV-MNIST, CREMA-D, UR-Funny, AVE) with both early and late fusion architectures
- Outperforms existing methods including AGM, CGGM, and Recon-Boost in modality-balanced learning

## Why This Works (Mechanism)

### Mechanism 1
M-SAM addresses modality imbalance by dynamically identifying the dominant modality per mini-batch and selectively applying sharpness-aware optimization only to it. Shapley values decompose the total loss into modality-specific contributions. The modality with highest contribution is flagged as dominant. SAM perturbation is computed only for this modality's gradient while non-dominant modalities receive standard gradient updates. This asymmetry protects dominant modality convergence in flat minima while allowing non-dominant modalities to explore.

### Mechanism 2
Selective SAM application to dominant modality produces flatter loss landscapes, improving generalization by making the model robust to gradient interference from non-dominant modalities. When dominant modality converges to flat minima, parameter perturbations from other modalities' gradients during backpropagation cause smaller loss changes. This reduces gradient magnitude variation, allowing non-dominant modalities to update shared parameters without destabilizing dominant modality performance.

### Mechanism 3
The convergence rate of M-SAM is theoretically O(log T / √T), matching SGD and standard SAM, ensuring the modality-aware modifications do not compromise optimization stability. The convergence proof shows the bound depends only on perturbation radius ρ_t, not on which modality is selected as dominant. Despite dynamic modality switching, the average gradient norm decreases at the expected rate.

## Foundational Learning

- **Sharpness-Aware Minimization (SAM) fundamentals**: M-SAM extends SAM; understanding the base mechanism (perturbation-based flatness seeking) is prerequisite to grasping why selective application matters.
  - Quick check: Can you explain why SAM computes gradients at θ + ε rather than θ, and what ρ controls?

- **Shapley values for contribution attribution**: M-SAM uses Shapley to decompose loss by modality; understanding that this measures marginal contribution across all possible modality subsets explains why it captures interaction effects.
  - Quick check: How does a Shapley value differ from a simple ablation test in measuring modality contribution?

- **Modality imbalance and uncoordinated convergence**: The problem M-SAM solves; understanding that modalities converge at different rates and dominant ones can suppress learning in others motivates the design.
  - Quick check: Why might a joint-trained model underperform even a single-modality baseline?

## Architecture Onboarding

- **Component map**: Input batch → Shapley computation → Dominant modality identification → Loss decomposition → Perturbation for dominant modality → Standard gradients for non-dominant modalities → Combined update

- **Critical path**: 1) Shapley computation (most expensive: M forward passes per batch), 2) Dominant modality identification, 3) Gradient computation at perturbed parameters for dominant modality, 4) Standard gradient for non-dominant modalities, 5) Combined update

- **Design tradeoffs**: Shapley overhead vs. accuracy (full Shapley requires M forward passes per batch), ρ (perturbation radius) size (larger seeks flatter minima but may overshoot), learning rate schedule (step decay used experimentally)

- **Failure signatures**: Excessive modality switching (if dominant modality changes frequently within epochs), non-dominant modalities underfit (if SAM flatness constraint is too strong), high τ (overfitting gap) indicates generalization failure

- **First 3 experiments**:
  1. Implement M-SAM on AV-MNIST with late fusion; compare joint-training, SAM, and M-SAM on Acc_mm and τ metric
  2. Test whether dynamic Shapley-based identification outperforms assuming a fixed dominant modality throughout training
  3. Sweep ρ ∈ {0.01, 0.05, 0.1, 0.2} to identify optimal perturbation radius and characterize flatness-accuracy tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
Is the linear normalization of accuracy-based Shapley values an optimal proxy for decomposing the loss landscape, or does it misrepresent the gradient contributions of modalities with different convergence speeds? The paper adopts a heuristic to bridge performance metrics and loss values but does not explore if non-linear or gradient-based mappings would align better with the sharpness of the loss landscape.

### Open Question 2
Does applying sharpness-aware minimization exclusively to the dominant modality risk preventing non-dominant modalities from finding robust, flat minima? While the paper argues this allows non-dominant modalities freedom to explore, it does not verify if these modalities converge to sharp minima that might generalize poorly on their own.

### Open Question 3
Can the computational overhead of per-iteration Shapley value estimation be reduced for high-modality tasks without losing the ability to dynamically identify the dominant modality? The combinatorial nature of Shapley calculations may become a bottleneck for datasets with significantly more modalities.

## Limitations
- Computational overhead from per-batch Shapley value computation not quantified
- Perturbation radius ρ remains unspecified in the text
- No corpus evidence exists for multimodal SAM applications specifically
- Convergence proof assumes theoretical learning rate schedules that may not match practical implementations

## Confidence

- **Performance claims**: Medium - consistent improvements across four datasets but Shapley overhead not quantified and ρ unspecified
- **Multimodal SAM extension**: Low - no corpus evidence exists for multimodal SAM applications specifically
- **Generalization claims**: Medium - flatter loss landscape mechanism supported by τ metric but metric may not fully capture generalization

## Next Checks

1. **Overhead quantification**: Measure training time per epoch with and without Shapley computation to assess practical viability
2. **Robustness to ρ**: Systematically sweep the perturbation radius to identify optimal values and characterize the flatness-accuracy tradeoff curve
3. **Cross-dataset stability**: Validate M-SAM on additional multimodal datasets beyond the four tested to assess generalizability of the modality imbalance solution