---
ver: rpa2
title: 'Generalized Category Discovery in Event-Centric Contexts: Latent Pattern Mining
  with LLMs'
arxiv_id: '2505.23304'
source_url: https://arxiv.org/abs/2505.23304
tags:
- scam
- samples
- category
- report
- categories
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenges of Generalized Category Discovery
  (GCD) in event-centric contexts, where long and complex narratives with imbalanced
  class distributions complicate clustering and classification alignment. The proposed
  PaMA framework leverages LLMs to extract and refine event patterns, improving cluster-class
  alignment.
---

# Generalized Category Discovery in Event-Centric Contexts: Latent Pattern Mining with LLMs

## Quick Facts
- **arXiv ID:** 2505.23304
- **Source URL:** https://arxiv.org/abs/2505.23304
- **Reference count:** 40
- **Primary result:** PaMA achieves up to 12.58% H-score gains over prior methods on event-centric GCD benchmarks while maintaining strong generalization on base GCD datasets.

## Executive Summary
This paper addresses the challenges of Generalized Category Discovery (GCD) in event-centric contexts, where long and complex narratives with imbalanced class distributions complicate clustering and classification alignment. The proposed PaMA framework leverages LLMs to extract and refine event patterns, improving cluster-class alignment. It introduces a ranking-filtering-mining pipeline to ensure balanced representation of prototypes across imbalanced categories. Evaluated on two EC-GCD benchmarks, including a newly constructed Scam Report dataset, PaMA achieves up to 12.58% H-score gains over prior methods while maintaining strong generalization on base GCD datasets.

## Method Summary
PaMA tackles Generalized Category Discovery in event-centric contexts by combining LLM-guided pattern mining with hybrid prototype learning. The framework clusters unlabeled data, matches clusters to known classes, and processes them in ranked order by compactness and size. High-confidence samples are selected for LLM pattern generation and refinement using labeled true/false positives. Low-confidence samples are reassigned based on pattern alignment. Hybrid prototypes combine class centers with LLM-derived pattern embeddings, updated via exponential moving average. The model is optimized with contrastive and prototype losses to maximize both known and novel class accuracy.

## Key Results
- PaMA achieves up to 12.58% H-score gains over prior methods on event-centric GCD benchmarks.
- The ranking-filtering-mining pipeline ensures balanced representation of prototypes across imbalanced categories.
- PaMA maintains strong generalization on base GCD datasets while excelling in event-centric contexts.

## Why This Works (Mechanism)

### Mechanism 1: LLM-Guided Pattern Extraction and Refinement
LLM-extracted patterns improve cluster-class alignment in event-centric texts where surface-level cues are insufficient, conditional on the LLM possessing relevant domain knowledge. The LLM receives high-confidence samples from each cluster, filters matches against existing patterns, and generates new category patterns via consensus-driven extraction. These patterns are then refined using labeled data—specifically true positives and false positives—to encode human-defined classification criteria.

### Mechanism 2: Ranking-Filtering-Mining Pipeline for Class Imbalance
Processing clusters in ranked order by compactness and size may mitigate dominant-class overshadowing of minority-class prototypes, conditional on minority classes forming detectable (if small) clusters. Clusters are ranked by a weighted score combining normalized compactness (low intra-cluster variance) and size (favoring larger clusters). Dominant, well-formed clusters are processed first for pattern generation, reducing their influence on subsequent minority-cluster patterns.

### Mechanism 3: Hybrid Prototype Calculation with Semantic and Statistical Signals
Combining class-center statistics with LLM-generated pattern embeddings may stabilize prototype representations and improve knowledge transfer from known to novel categories, conditional on pattern embeddings capturing meaningful semantics. Each prototype is a weighted sum of the class center and pattern embedding, updated via exponential moving average for stability.

## Foundational Learning

- **Concept: Contrastive Learning (InfoNCE)**
  - Why needed here: Instance-level contrastive loss pulls same-cluster samples together and pushes different-cluster samples apart, forming the representational backbone before prototype alignment.
  - Quick check question: Can you explain why contrastive learning alone may fail when cluster boundaries don't align with class labels (as in EC-GCD)?

- **Concept: K-Means Clustering with Hungarian Matching**
  - Why needed here: Unlabeled data is clustered via K-means; cluster centers are matched to labeled class centroids using the Hungarian algorithm to identify known vs. novel categories.
  - Quick check question: What happens to Hungarian matching if the assumed number of categories K is incorrect?

- **Concept: Exponential Moving Average (EMA) for Prototype Updates**
  - Why needed here: Prototypes are updated via EMA to smooth training dynamics and prevent sudden shifts from noisy pseudo-label reassignments.
  - Quick check question: How does the momentum coefficient ω affect prototype stability vs. adaptability to new patterns?

## Architecture Onboarding

- **Component map:**
  Encoder (BERT) -> Clustering Module (K-Means) -> Matching Module (Hungarian Algorithm) -> Ranking Module -> LLM Interface (Qwen2.5-72B) -> Pseudo-Label Reassignment -> Loss Composer

- **Critical path:**
  1. Encode all samples → cluster unlabeled embeddings.
  2. Match clusters to known classes; unmatched = novel.
  3. Rank clusters → select high-confidence samples per cluster.
  4. Invoke LLM for pattern generation and refinement (every 5 epochs).
  5. Reassign pseudo-labels for low-confidence samples.
  6. Compute hybrid prototypes and apply contrastive + prototype losses.
  7. Update encoder via backprop.

- **Design tradeoffs:**
  - LLM invocation frequency vs. computational cost (paper uses every 5 epochs).
  - β (class center ratio) vs. generalization: higher β favors known-class accuracy; lower β favors novel-class discovery.
  - ρ (reassigned sample weight): higher values amplify pseudo-label signal but risk noise propagation.

- **Failure signatures:**
  - ACCN near random: Novel class discovery failing; check clustering quality and whether minority classes are being absorbed.
  - ACCK dropping sharply: Catastrophic forgetting; verify L_ce is active and prototype transfer from labeled data is functioning.
  - Patterns becoming overly generic: LLM may be ignoring discriminative features; inspect high-confidence sample selection criteria.

- **First 3 experiments:**
  1. **Baseline replication:** Run PaMA on Scam Report with default hyperparameters (Table 4). Verify H-score matches reported ~50.88%.
  2. **Ablation on β:** Sweep β ∈ {0.2, 0.5, 0.8, 1.0} and plot ACCK vs. ACCN. Confirm trade-off peak near β = 0.8.
  3. **Known class ratio sensitivity:** Test with known class ratios {0.2, 0.5, 0.65, 0.8} (Figure 5). Verify PaMA maintains ACCN advantage even at low known-class ratios.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can models effectively learn precise, human-aligned classification criteria for purely novel categories in the absence of labeled refinement data?
- **Basis in paper:** The authors state in the Limitations section that while pattern refinement captures boundaries for known classes, "learning precise criteria for novel categories remains an open challenge" because the refinement process relies on labeled true/false positives which novel classes lack.
- **Why unresolved:** The current PaMA framework relies on labeled data to correct the LLM's pattern hallucinations (Pattern Refinement), a mechanism that cannot function for classes with zero labeled instances.
- **What evidence would resolve it:** A mechanism (e.g., self-consistency checks or cross-cluster validation) that improves ACC_N on novel classes without requiring any labeled examples from those classes.

### Open Question 2
- **Question:** Can the pattern mining and alignment framework be effectively generalized to vision or multimodal event-centric domains?
- **Basis in paper:** The authors explicitly note that the method "currently operates exclusively in the textual domain" and that "reliance on language models constrains its direct applicability to vision or multimodal settings."
- **Why unresolved:** Event-centric contexts in vision (e.g., video surveillance) require extracting latent patterns from pixel data rather than text, and it is unclear if LLMs can effectively interpret visual prototypes without extensive grounding.
- **What evidence would resolve it:** Successful application of the PaMA pipeline to a video-based GCD benchmark using multimodal LLMs to extract event patterns from visual features.

### Open Question 3
- **Question:** How can the computational overhead of iterative LLM invocations be minimized to improve scalability in low-resource scenarios?
- **Basis in paper:** The authors acknowledge that "invoking large language models introduces non-negligible computational overhead, which may limit scalability."
- **Why unresolved:** The Ranking-Filtering-Mining pipeline requires frequent LLM calls for sample matching and pattern generation, which is expensive and slow compared to standard gradient-based updates.
- **What evidence would resolve it:** An ablation study or architectural modification (e.g., using smaller SlMs or caching mechanisms) that maintains H-score performance while significantly reducing inference time and FLOPs.

## Limitations

- The primary evaluation dataset (Scam Report) is newly constructed and not publicly available, limiting reproducibility and independent validation of the reported H-score gains.
- LLM prompt templates and few-shot exemplars are not fully specified, creating ambiguity in pattern extraction and refinement quality.
- The paper does not provide ablation studies isolating the marginal contribution of each LLM-guided step (pattern generation vs. refinement vs. reassignment) from the overall gains.

## Confidence

- **High confidence:** The core GCD problem formulation and baseline comparisons are well-grounded; H-score improvements over prior methods are consistently reported across multiple datasets.
- **Medium confidence:** The effectiveness of the ranking-filtering-mining pipeline for class imbalance is supported by ablation studies, but the exact conditions under which it outperforms simpler reweighting strategies are unclear.
- **Low confidence:** The robustness of LLM-extracted patterns to domain shift and annotation bias is asserted but not empirically tested on out-of-domain event narratives.

## Next Checks

1. Replicate PaMA on the publicly available BANKING and CLINC datasets using the provided hyperparameters to verify reported H-score gains.
2. Perform ablation studies to quantify the marginal contribution of LLM pattern refinement versus generation versus reassignment to overall performance.
3. Test PaMA on a known long-tail GCD dataset (e.g., from Long-Tailed Learning for GCD) to assess whether ranking-filtering-mining outperforms alternative imbalance mitigation methods.