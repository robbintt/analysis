---
ver: rpa2
title: 'TDHook: A Lightweight Framework for Interpretability'
arxiv_id: '2509.25475'
source_url: https://arxiv.org/abs/2509.25475
tags:
- methods
- attribution
- interpretability
- tdhook
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TDHook is a lightweight, generic interpretability framework designed
  for complex deep learning models. Built on torch and tensordict, it supports attribution,
  latent manipulation, and weights-based methods through a unified API.
---

# TDHook: A Lightweight Framework for Interpretability

## Quick Facts
- arXiv ID: 2509.25475
- Source URL: https://arxiv.org/abs/2509.25475
- Reference count: 40
- Primary result: Lightweight interpretability framework achieving up to 2x speedup over Captum for integrated gradients on multi-target pipelines

## Executive Summary
TDHook is a generic, lightweight interpretability framework built on PyTorch and TensorDict that supports attribution, latent manipulation, and weights-based methods across complex deep learning models. The framework unifies interpretability artifacts as TensorDict structures and leverages vectorized gradient computation to achieve significant speedups over existing libraries like Captum. It demonstrates practical applications in concept attribution, attribution patching, and analysis of multi-output models across computer vision, NLP, and reinforcement learning domains.

## Method Summary
TDHook implements interpretability methods through a hook-based architecture that wraps arbitrary torch.nn.Module or TensorDictModule in a HookedModel. The framework uses forward/backward hooks to intercept model inputs/outputs and gradients, managing artifacts as keyed tensor collections through TensorDict. Methods are composed using a get-set API for interventions, with over 25 ready-to-use techniques spanning attribution, probing, and intervention categories. The framework achieves performance gains by computing gradients over vector targets simultaneously rather than scalar values, enabling up to 2× speedup for integrated gradients on multi-target pipelines.

## Key Results
- Achieves up to 2x speedup over Captum for integrated gradients on multi-target pipelines
- Maintains ~6% additional memory overhead vs. 104% for transformer_lens
- Requires roughly half the disk space of transformer_lens (1.1MB vs 2.7MB)
- Successfully applies concept attribution to detect knight and rook concepts in chess models
- Demonstrates attribution patching effectiveness on language models

## Why This Works (Mechanism)

### Mechanism 1: TensorDict-Powered Artifact Unification
TDHook achieves composability by modeling all interpretability artifacts as TensorDict structures, treating activations, gradients, weights, and attributions uniformly as keyed tensor collections. This enables methods to chain inputs/outputs without custom data pipelines, based on the core assumption that multi-input/multi-output models and interpretability by-products share a common tensor-dictionary representation pattern.

### Mechanism 2: Vectorized Gradient Computation for Attribution Speedup
The framework achieves up to 2× speedup by computing gradients over vector targets simultaneously in a single backward pass, rather than the scalar-by-scalar approach used by Captum. This optimization is most effective for multi-target attribution scenarios where multiple outputs need to be analyzed concurrently.

### Mechanism 3: Lightweight Hook-Based Model Wrapping
TDHook maintains minimal dependencies by relying on PyTorch hooks as the core instrumentation primitive, wrapping arbitrary modules without architecture-specific modifications. This approach achieves significant memory efficiency compared to comprehensive frameworks like transformer_lens while maintaining broad model compatibility.

## Foundational Learning

- **PyTorch Forward/Backward Hooks**: Essential for understanding how TDHook intercepts module inputs/outputs and gradients; Quick check: Can you explain where `register_forward_hook` fires relative to `register_backward_hook` in a two-layer MLP?
- **TensorDict and TensorDictModule**: Critical for the framework's composable design; Quick check: How would you wrap a standard `nn.Linear` to accept a TensorDict input key and write to an output key?
- **Attribution Method Taxonomy (Gradient-Based, Perturbation, LRP)**: Necessary for understanding the 25+ bundled methods; Quick check: What distinguishes integrated gradients from saliency maps in terms of the baseline requirement?

## Architecture Onboarding

- **Component map**: HookedModel -> HookingContextFactory -> HookingContext -> Ready-to-use methods
- **Critical path**: 1) Instantiate method (e.g., Saliency()), 2) Call `method.prepare(model)` → returns HookedModel, 3) Run `hooked_model(tensor_dict_inputs)` inside context, 4) Retrieve artifacts via `output.get(("attr", "input_key"))`
- **Design tradeoffs**: Genericity vs. specialization (supports any torch model but lacks transformer-specific conveniences), lightweight vs. comprehensive (smaller footprint but fewer methods than Captum), explicit vs. implicit (manual intervention definition vs. config-driven approaches)
- **Failure signatures**: KeyError on artifact retrieval (hook failed to register), Memory blowup (cache not cleared between runs), Attribution all zeros (target function not differentiable)
- **First 3 experiments**: 1) Replicate Figure 2: Run Saliency attribution on pretrained VGG16, verify attribution tensor shape, 2) Benchmark integrated gradients: Compare TDHook vs. Captum runtime on multi-target setup, 3) Intervention round-trip: Extract layer 3 activations, overwrite layer 5 activations, measure output divergence

## Open Questions the Paper Calls Out

- Can exploiting advanced TensorDict features like memory-mapped tensors and zero-copy sharing significantly reduce peak RAM usage during large-scale analyses?
- Do TCAV-based concept attributions maintain faithfulness when evaluated using localization or robustness metrics?
- How can TDHook be extended to seamlessly operate in distributed and heterogeneous execution environments?

## Limitations

- Speed-up claims are specific to multi-target scenarios and may not translate to single-target attribution or memory-bound models
- Framework compatibility issues may arise with dynamically restructured models or custom C++ operators
- Performance benefits are tied to specific hardware (A100 MIG 40GB) and may vary significantly on consumer-grade GPUs

## Confidence

- **High Confidence**: TensorDict-based artifact unification mechanism is well-specified with clear code examples and API documentation
- **Medium Confidence**: Hook-based model wrapping achieves claimed memory efficiency based on measured overhead comparisons
- **Low Confidence**: Attribution speedup claims lack detailed ablation studies across different model architectures and batch sizes

## Next Checks

1. **Mechanism Validation**: Reproduce the speedup claim by benchmarking integrated gradients on a multi-target pipeline (batch size 8, 10 class targets) comparing TDHook vs. Captum on the same hardware
2. **Edge Case Testing**: Test hook registration on a dynamically restructured model (e.g., PyTorch Funnel Transformer) to identify potential failure modes
3. **Single-Target Baseline**: Measure runtime and memory overhead for single-target attribution to establish baseline performance and verify speedup claims are specific to multi-target scenarios