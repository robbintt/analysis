---
ver: rpa2
title: Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data
  Generation
arxiv_id: '2508.03117'
source_url: https://arxiv.org/abs/2508.03117
tags:
- optimization
- problem
- description
- formulation
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces OptiTrust, a framework for training trustworthy
  large language model (LLM) agents for optimization modeling. The approach uses a
  verifiable synthetic data generation pipeline to create structured symbolic representations
  of linear and mixed-integer linear programming problems, which are then systematically
  converted into natural language descriptions, mathematical formulations, and solver-executable
  code.
---

# Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data Generation

## Quick Facts
- arXiv ID: 2508.03117
- Source URL: https://arxiv.org/abs/2508.03117
- Reference count: 40
- Introduces OptiTrust, achieving state-of-the-art performance on seven optimization modeling benchmark datasets

## Executive Summary
This paper presents OptiTrust, a framework for training trustworthy large language model agents for optimization modeling. The approach leverages verifiable synthetic data generation to create high-quality training examples for linear and mixed-integer linear programming problems. By systematically generating problems, converting them to natural language descriptions and mathematical formulations, and verifying optimal solutions, OptiTrust ensures data quality while enabling automatic filtering of low-quality demonstrations. The framework achieves state-of-the-art performance across multiple benchmark datasets, outperforming existing methods by significant margins.

## Method Summary
OptiTrust employs a multi-stage approach to optimization modeling that addresses the challenge of unreliable training data in this domain. The framework begins with a verifiable synthetic data generation pipeline that creates structured symbolic representations of optimization problems. These are systematically converted into natural language descriptions, mathematical formulations, and solver-executable code. Each generated instance includes a verified optimal solution, enabling automatic filtering of low-quality demonstrations. During inference, OptiTrust performs stepwise translation from natural language to solver-ready code using multi-language inference and majority-vote cross-validation. This approach ensures both data quality and model reliability while maintaining scalability for real-world applications.

## Key Results
- OptiTrust achieves state-of-the-art performance on seven benchmark datasets, obtaining the highest accuracy on six
- Outperforms the next-best method by at least 8% on three datasets
- Identifies and corrects errors in existing optimization datasets, improving their reliability
- Demonstrates effective multi-stage translation with cross-validation reducing inference errors

## Why This Works (Mechanism)
The framework's success stems from its verifiable synthetic data generation pipeline, which ensures data quality through optimal solution verification. By creating structured symbolic representations that are systematically converted to multiple formats (natural language, mathematical formulations, code), OptiTrust generates diverse, high-quality training examples. The multi-stage translation approach with cross-validation provides robustness against individual model failures, while majority voting across multiple language outputs further reduces inference errors. This combination of verified data and robust inference mechanisms addresses the fundamental challenge of unreliable demonstrations in optimization modeling.

## Foundational Learning
- Linear Programming (LP) and Mixed-Integer Linear Programming (MILP): Why needed - These are the target optimization problem types; quick check - Understand basic LP formulation with objective functions and constraints
- Symbolic Problem Generation: Why needed - Creates structured problem representations for verifiable data generation; quick check - Can generate valid LP constraints from symbolic templates
- Natural Language Processing for Mathematical Text: Why needed - Converts optimization problems to human-readable descriptions; quick check - Can parse and generate mathematical statements from NL descriptions
- Solver Integration: Why needed - Enables verification of optimal solutions for generated problems; quick check - Can execute solver calls and parse results for verification

## Architecture Onboarding

**Component Map:**
Synthetic Generator -> Verifier -> NL Converter -> Math Formulator -> Code Generator -> Multi-Language Inference -> Majority Vote

**Critical Path:**
Data Generation (Synthetic Generator + Verifier) -> Training Data Creation (NL Converter + Math Formulator + Code Generator) -> Inference (Multi-Language Inference + Majority Vote)

**Design Tradeoffs:**
- Verifiable vs. scalable data generation: verification ensures quality but adds computational overhead
- Multi-stage vs. end-to-end translation: stepwise approach reduces error propagation but increases complexity
- Cross-validation vs. single inference: majority voting improves reliability but requires multiple model calls

**Failure Signatures:**
- Data generation failures: invalid problem structures or unsolvable instances
- Translation errors: incorrect mapping between natural language and mathematical formulations
- Inference inconsistencies: divergent outputs across language variants indicating model uncertainty

**3 First Experiments:**
1. Verify synthetic data generation produces valid, solvable optimization problems
2. Test translation accuracy from natural language to mathematical formulation
3. Evaluate majority voting effectiveness in reducing inference errors

## Open Questions the Paper Calls Out
None specified in the provided information.

## Limitations
- Currently restricted to linear and mixed-integer linear programming problems
- Computational overhead of verifying optimal solutions may limit scalability
- Reliance on LLMs introduces potential brittleness to prompt variations and model-specific behaviors

## Confidence
- Verifiable synthetic data generation significantly improves optimization modeling agent reliability: **High**
- OptiTrust achieves state-of-the-art performance across multiple benchmark datasets: **High**
- Multi-stage translation with cross-validation reduces inference errors: **Medium**
- Identified and corrected errors in existing optimization datasets: **Medium**

## Next Checks
1. Test OptiTrust on nonlinear and non-convex optimization problems to evaluate generalizability beyond MILP
2. Conduct ablation studies removing the verifiable solution verification step to quantify its impact on final performance
3. Evaluate computational efficiency and scalability on larger problem instances (1000+ variables and constraints)