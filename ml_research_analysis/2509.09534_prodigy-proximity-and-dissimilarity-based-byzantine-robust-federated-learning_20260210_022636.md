---
ver: rpa2
title: 'ProDiGy: Proximity- and Dissimilarity-Based Byzantine-Robust Federated Learning'
arxiv_id: '2509.09534'
source_url: https://arxiv.org/abs/2509.09534
tags:
- learning
- clients
- data
- aggregation
- byzantine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses Byzantine-robust federated learning under
  heterogeneous data distributions, where malicious clients can collude to bias the
  global model. Existing robust aggregation methods, which rely on gradient similarity,
  often fail when honest gradients are highly diverse due to non-IID data, allowing
  attackers to craft misleading updates that appear trustworthy.
---

# ProDiGy: Proximity- and Dissimilarity-Based Byzantine-Robust Federated Learning

## Quick Facts
- arXiv ID: 2509.09534
- Source URL: https://arxiv.org/abs/2509.09534
- Reference count: 36
- Primary result: ProDiGy achieves highest worst-case accuracy in Byzantine-robust federated learning under strong attacks and severe non-IID conditions.

## Executive Summary
This paper tackles Byzantine-robust federated learning under heterogeneous data distributions, where malicious clients can collude to bias the global model. Traditional robust aggregation methods that rely on gradient similarity often fail when honest gradients are highly diverse due to non-IID data, allowing attackers to craft misleading updates that appear trustworthy. To address this, the authors propose ProDiGy, a novel aggregation rule that uses dual scoringâ€”proximity scores to encourage similarity among honest updates and dissimilarity scores to penalize suspiciously uniform gradients indicating collusion. ProDiGy computes trust scores by considering both nearest and farthest neighbors of each gradient while excluding extreme cases to avoid bias. Experiments on CIFAR-10 and FEMNIST demonstrate that ProDiGy consistently outperforms state-of-the-art defenses, especially under strong attack scenarios and severe non-IID conditions.

## Method Summary
ProDiGy introduces a dual-scoring aggregation mechanism for Byzantine-robust federated learning. It computes trust scores for client gradients using two complementary perspectives: proximity scores measure similarity to nearest neighbors (encouraging honest update consistency), while dissimilarity scores identify suspiciously uniform gradients that may indicate collusion. The algorithm evaluates each gradient by considering both its nearest and farthest neighbors, explicitly excluding extreme cases to prevent bias. Trust scores are then used to weight or filter gradients during aggregation. This approach is designed to maintain robustness even when honest gradients are highly diverse due to non-IID data distributions, a scenario where traditional similarity-based defenses often fail.

## Key Results
- ProDiGy achieves the highest worst-case accuracy across all tested attack scenarios and non-IID conditions.
- Maintains strong robustness when other state-of-the-art methods fail entirely under strong Byzantine attacks.
- Consistently outperforms existing defenses on CIFAR-10 and FEMNIST datasets, particularly in severe non-IID settings.

## Why This Works (Mechanism)
ProDiGy's effectiveness stems from its dual scoring system that captures both local similarity and global diversity patterns in gradient updates. By simultaneously considering proximity (similarity to nearest neighbors) and dissimilarity (suspicious uniformity across updates), the method can distinguish between genuinely diverse honest gradients and colluding Byzantine attacks. The exclusion of extreme gradient cases prevents the aggregation from being dominated by outliers, whether malicious or simply unusual honest updates. This balanced approach allows ProDiGy to maintain trust in genuinely diverse honest updates while still detecting coordinated attack patterns that simpler similarity-based methods miss.

## Foundational Learning
- **Federated Learning**: Distributed machine learning where multiple clients train models collaboratively without sharing raw data; needed to understand the distributed nature of the problem and why robustness is critical.
- **Byzantine Attacks**: Malicious clients that send arbitrary or adversarial updates to corrupt the global model; needed to contextualize the threat model and why standard aggregation fails.
- **Non-IID Data Distributions**: Data heterogeneity across clients where local datasets have different distributions; needed to understand why honest gradients can be diverse and why this complicates Byzantine defense.
- **Robust Aggregation Methods**: Techniques like Krum, Median, and trimmed mean that attempt to filter or downweight suspicious updates; needed as baseline comparisons and to understand the limitations ProDiGy addresses.
- **Gradient Similarity Analysis**: Methods that evaluate updates based on their similarity to other clients' gradients; needed to understand why this approach fails under non-IID conditions with Byzantine attacks.
- **Trust Scoring Systems**: Mechanisms that assign confidence weights to client contributions based on their behavior; needed to understand how ProDiGy's dual scoring improves upon single-metric approaches.

## Architecture Onboarding
**Component Map**: Client Gradients -> Proximity/Dissimilarity Scoring -> Trust Score Computation -> Weighted Aggregation -> Global Model Update
**Critical Path**: The scoring mechanism is the core innovation, where proximity and dissimilarity scores are computed for each gradient, trust scores are derived, and then used to weight contributions during aggregation. The exclusion of extreme cases in scoring is critical for avoiding bias.
**Design Tradeoffs**: ProDiGy trades computational overhead (computing two types of scores per gradient) for improved robustness. The dual scoring approach increases complexity but provides better discrimination between honest diversity and malicious uniformity. The choice to exclude extreme cases balances sensitivity to outliers against potential loss of information.
**Failure Signatures**: If proximity scores are too dominant, the system may become vulnerable to attacks that mimic local similarity patterns. If dissimilarity scores are too sensitive, genuinely diverse honest gradients might be incorrectly penalized. The method could fail if Byzantine clients coordinate to create gradients that score well on both metrics.
**3 First Experiments**:
1. Implement baseline Krum and trimmed mean aggregation methods on CIFAR-10 with varying levels of non-IID data.
2. Create a synthetic attack where Byzantine clients send gradients designed to appear similar to honest updates but biased in a specific direction.
3. Test ProDiGy's sensitivity by running with only proximity scores, only dissimilarity scores, and the full dual scoring to quantify the contribution of each component.

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical robustness guarantees are not provided, leaving worst-case behavior unproven.
- Computational overhead from dual scoring mechanism is not quantified, potentially impacting scalability.
- Evaluation is limited to CIFAR-10 and FEMNIST datasets; performance on other data modalities and architectures remains untested.

## Confidence
- **High** confidence in empirical performance improvements over baselines in tested scenarios
- **Medium** confidence in claims about robustness under arbitrary Byzantine attacks (no theoretical analysis)
- **Low** confidence in scalability and generalizability to other datasets and architectures (limited experimental scope)

## Next Checks
1. Derive and prove theoretical robustness bounds for ProDiGy under varying proportions of Byzantine clients.
2. Benchmark ProDiGy's computational efficiency and memory usage on federated networks with 100+ clients.
3. Evaluate ProDiGy on diverse datasets (e.g., NLP, healthcare) and model architectures (e.g., Transformers, RNNs) to assess generalizability.