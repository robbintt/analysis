---
ver: rpa2
title: Process-Informed Forecasting of Complex Thermal Dynamics in Pharmaceutical
  Manufacturing
arxiv_id: '2509.20349'
source_url: https://arxiv.org/abs/2509.20349
tags:
- learning
- process
- noise
- uncertainty
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of reliable time-series forecasting
  in pharmaceutical lyophilization, where accuracy, physical plausibility, and robustness
  to sensor noise are critical for regulatory compliance. The authors introduce Process-Informed
  Forecasting (PIF) models that integrate a process-derived trajectory prior into
  deep learning architectures, addressing the limitations of purely data-driven models
  in regulated environments.
---

# Process-Informed Forecasting of Complex Thermal Dynamics in Pharmaceutical Manufacturing

## Quick Facts
- arXiv ID: 2509.20349
- Source URL: https://arxiv.org/abs/2509.20349
- Reference count: 40
- Process-informed forecasting (PIF) models outperform purely data-driven counterparts in accuracy, physical plausibility, and noise resilience in pharmaceutical lyophilization.

## Executive Summary
This paper introduces Process-Informed Forecasting (PIF) models that integrate a process-derived trajectory prior into deep learning architectures for pharmaceutical lyophilization. The method addresses the challenge of reliable time-series forecasting where accuracy, physical plausibility, and robustness to sensor noise are critical for regulatory compliance. By combining three PIF strategies with architectures like RNNs, LSTMs, Transformers, and KANs, the approach acts as a regularizer that prevents overfitting and guides predictions toward physically consistent solutions. Results demonstrate that PIF models outperform standard data-driven models, with uncertainty-based and Residual-Based Attention (RBA) methods offering strong performance with faster training than fixed-weight approaches.

## Method Summary
The PIF approach integrates a piecewise linear process trajectory prior derived from manufacturing recipes into deep learning models through modified loss functions. Three loss formulations are proposed: fixed-weight loss combining data and process-informed terms with a hyperparameter λ, uncertainty-based loss that learns dynamic weighting parameters, and Residual-Based Attention that focuses on high-error samples. The method is tested across multiple deep learning architectures (RNN, LSTM, Transformer, KAN, cKAN, LEM, MLP) calibrated to similar parameter counts. Models are trained on real-world lyophilization data with chronological train/val/test splits, and evaluated using RMSE, gradient error metrics, and robustness tests with input and system-wide Gaussian noise.

## Key Results
- PIF models outperform data-driven counterparts in accuracy, physical plausibility, and noise resilience across all tested architectures
- cKAN and MLP architectures demonstrate superior robustness to input sensor noise compared to RNN/LSTM models
- Transfer learning with a pre-trained cKAN model enables adaptation to new processes with minimal retraining
- Uncertainty-based and RBA loss formulations achieve competitive accuracy with significantly faster training than fixed-weight approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Integrating a process-informed trajectory prior into the loss function improves forecasting accuracy and physical plausibility, particularly as model capacity increases.
- Mechanism: The process-informed (PI) prior—derived from the known manufacturing recipe as a piecewise linear function of temperature setpoints and phase durations—acts as a regularization signal. During training, the modified loss (e.g., L_fixed = (1-λ)·L_data + λ·L_PI) penalizes deviations from both ground-truth sensor data and the idealized trajectory, constraining the hypothesis space to physically plausible solutions. At higher parameter counts (≥30,000), this prevents overfitting to training noise while preserving the dominant low-frequency thermal structure.
- Core assumption: The manufacturing recipe captures sufficient structural information about the thermal dynamics; the idealized piecewise linear prior is a reasonable approximation of the true process evolution.
- Evidence anchors:
  - [abstract] "PIF models outperform their data-driven counterparts in terms of accuracy, physical plausibility and noise resilience."
  - [Section 3.2] "At 115,000 parameters, a PI variant is the top performer in almost every model family. Thus, the process-informed prior is a strong regularizer, preventing the higher capacity models from overfitting."
  - [corpus] Related work on physics-guided learning (PhyDL-NWP) reports similar gains when physical constraints regularize deep models, supporting the generalization of this mechanism.
- Break condition: If the true process dynamics diverge significantly from the recipe (e.g., unmodeled disturbances, equipment faults), the PI prior may bias predictions away from reality, increasing error.

### Mechanism 2
- Claim: Uncertainty-based and Residual-Based Attention (RBA) loss formulations achieve competitive accuracy with faster training compared to fixed-weight approaches.
- Mechanism: Uncertainty-based loss (L_uncertainty = 1/(2σ²_data)·L_data + 1/(2σ²_PI)·L_PI + log σ_data σ_PI) learns homoscedastic uncertainty parameters that dynamically balance data fidelity and process consistency during training, eliminating manual λ tuning. RBA assigns sample-wise attention weights based on exponentially weighted moving averages of residuals, focusing gradient updates on points with higher current error. Both methods adaptively allocate learning capacity without exhaustive hyperparameter search.
- Core assumption: The learned uncertainty or residual-based weights converge to a meaningful trade-off; the process remains sufficiently stationary for adaptive weighting to stabilize.
- Evidence anchors:
  - [abstract] "Among PIF variants, the uncertainty-based and RBA methods offer strong performance with faster training than fixed-weight approaches."
  - [Section 3.2] "The uncertainty-based and residual-based attention (RBA) methods are competitive and faster compared to the pure data-driven models... For complex models like KAN and LEM, this results in training times that are orders of magnitude longer [for fixed-weight]."
  - [corpus] Corpus lacks direct comparisons of these specific loss formulations; external validation is limited.
- Break condition: If the process exhibits abrupt regime shifts, learned uncertainty or residual-based weights may lag, temporarily misallocating optimization focus.

### Mechanism 3
- Claim: Architecture choice—particularly cKAN and MLP—is the primary determinant of robustness to input sensor noise, with process-informed integration providing secondary benefits.
- Mechanism: cKAN (Chebyshev polynomial-based KAN) and MLP architectures exhibit inherent noise filtering, likely due to their spectral properties and lack of sequential error propagation (unlike RNN/LSTM). Under input-only noise perturbation, these models maintain low RMSE with smooth predictions, while recurrent architectures amplify noise through sequential dependencies. The PI prior further stabilizes predictions but does not override architectural robustness characteristics.
- Core assumption: Noise characteristics in the test environment approximate the Gaussian perturbation model used in experiments; industrial sensor noise distribution is similar.
- Evidence anchors:
  - [Section 3.3] "The results identify the cKAN model as the most resilient with the lowest RMSE across the noisy spectrum. KAN and MLP also demonstrate strong robustness."
  - [Section 3.3, Figure 4] "For deep learning architectures... the performance curves for the standard models and their process-informed variants are clustered, suggesting that the core architecture itself is the primary determinant of resilience to input noise."
  - [corpus] A related benchmarking framework (Quantifying Robustness, arXiv:2504.03494) also identifies architecture as a key robustness factor in CPS forecasting, providing external consistency.
- Break condition: If system-wide noise (affecting both inputs and targets) dominates, architectural advantages diminish as evaluation targets themselves become unreliable.

## Foundational Learning

- Concept: Piecewise linear approximation of process trajectories
  - Why needed here: Understanding how the PI prior is constructed from manufacturing recipe setpoints is essential for implementing PIF models and assessing when the approximation is valid.
  - Quick check question: Given a three-phase lyophilization process with setpoints at -40°C (freezing), -20°C (primary drying), and +25°C (secondary drying), can you sketch the piecewise linear prior?

- Concept: Multi-task loss weighting and uncertainty learning
  - Why needed here: The uncertainty-based loss formulation extends standard multi-task learning; practitioners must understand how learned σ parameters influence the data-physics trade-off.
  - Quick check question: In L_uncertainty, if σ_data becomes large relative to σ_PI, which loss component dominates the gradient signal?

- Concept: Kolmogorov-Arnold Networks (KANs) and Chebyshev variants
  - Why needed here: cKAN emerges as a top performer; understanding its learnable activation functions and spectral properties helps explain its robustness and accuracy.
  - Quick check question: How does placing learnable univariate functions on edges (KAN) differ from fixed activations on nodes (MLP), and what implications does this have for function approximation?

## Architecture Onboarding

- Component map:
  Data preprocessing -> PI prior module -> Forecasting backbone -> Loss aggregator -> Evaluation suite

- Critical path:
  1. Extract recipe setpoints and phase timings → generate PI prior for all timesteps
  2. Instantiate backbone architecture with calibrated parameter count
  3. Select loss formulation (recommend starting with uncertainty-based for efficiency)
  4. Train with Adam optimizer, early stopping on validation RMSE (patience=10)
  5. Evaluate on held-out test set; run robustness analysis at σ=0.6 (realistic industrial noise)

- Design tradeoffs:
  - Fixed-weight loss: Potentially higher accuracy but requires expensive hyperparameter search (Optuna); training time can increase by 10–100× for complex models (KAN, LEM)
  - Uncertainty-based loss: Competitive accuracy with minimal tuning overhead; risk of suboptimal weight convergence on small datasets
  - RBA loss: Sample-wise adaptivity useful for heterogeneous error distributions; introduces additional hyperparameter η (learning rate for weight updates)
  - Architecture selection: cKAN/MLP for robustness; LSTM/RNN for sequential dependency modeling (but higher noise sensitivity); Transformer for attention-based patterns (but struggles with temperature peaks in this domain)

- Failure signatures:
  - High Gradient Error with low RMSE: Model fits points but misses dynamics; increase λ (PI loss weight) or switch to architecture with better transient capture (KAN-family)
  - Rapid performance degradation under σ=0.6 noise: Architecture lacks inherent robustness; switch to cKAN or MLP
  - Fixed-weight training excessively long: λ search space too large; switch to uncertainty-based or RBA
  - Transfer learning baseline fails (RMSE >> trained models): Pre-trained features not transferable; use fine-tuning with frozen backbone + new linear head

- First 3 experiments:
  1. Baseline comparison: Train pure data-driven models (RNN, LSTM, MLP, cKAN, Transformer) at ~30K parameters; measure RMSE and Gradient Error to establish architectural strengths
  2. PIF integration test: Add fixed-weight PIF (λ=0.3 from paper) to top-3 baseline architectures; compare accuracy vs. training time increase
  3. Robustness stress test: Evaluate all models under input-only Gaussian noise (σ=0, 0.3, 0.6, 0.9); identify architectures with flatest degradation curves

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why does the dynamic uncertainty-based loss weighting fail to generalize across domain shifts compared to the fixed-weight strategy?
- Basis in paper: [explicit] The authors state that uncertainty-based models "consistently rank lower on this new process" and are "less robust to domain shifts compared to the simpler fixed-weight process-informed integration" (Page 30).
- Why unresolved: The mechanism causing this degradation is not analyzed; it is unclear if the learned uncertainty parameters overfit to the source domain's noise profile.
- What evidence would resolve it: Analysis of the learned $\sigma$ parameters during transfer learning, specifically checking if they saturate or diverge on the secondary dataset.

### Open Question 2
- Question: Can the process-informed prior be enhanced to capture high-frequency thermal dynamics without requiring unavailable product-specific parameters?
- Basis in paper: [inferred] The authors utilize a piecewise linear prior because first-principles models "require numerous product-specific parameters... that vary between products and are not available in historical process data" (Page 3).
- Why unresolved: The current prior captures dominant low-frequency dynamics but relies on "reasonable and effective simplification," potentially missing complex transient behaviors.
- What evidence would resolve it: Testing hybrid priors that estimate missing thermodynamic parameters online or using spectral analysis to quantify the information loss of the linear approximation.

### Open Question 3
- Question: How can the distinct impacts of input noise and target noise be disentangled to accurately assess model reliability in system-wide perturbation scenarios?
- Basis in paper: [inferred] The authors note that their system-wide noise testing "introduces two sources of error that are intertwined, making it harder to pinpoint the precise cause of performance degradation" (Page 9).
- Why unresolved: The current robustness analysis provides two isolated scenarios but lacks a method to attribute error sources when both inputs and ground truth are uncertain simultaneously.
- What evidence would resolve it: A factorial design varying input and target noise levels independently to map their interaction effects on the Gradient Error and RMSE.

## Limitations
- Architecture hyperparameters and exact model configurations at target parameter counts are unspecified, limiting exact reproduction.
- External validation of uncertainty-based and RBA loss formulations is absent from the corpus; results rely heavily on in-domain experiments.
- Dataset and code are not yet publicly available, preventing independent verification of reported robustness and transfer learning results.

## Confidence

- **High**: PIF integration improves forecasting accuracy and physical plausibility; architecture choice (cKAN/MLP) is primary determinant of input noise robustness.
- **Medium**: Uncertainty-based and RBA loss formulations offer faster training with competitive accuracy; transfer learning with pre-trained cKAN is feasible.
- **Low**: Learned uncertainty weighting consistently outperforms manual tuning; RBA provides sample-wise adaptivity; exact parameter counts per model family are known.

## Next Checks

1. Reproduce baseline deep learning models (RNN, LSTM, MLP, cKAN) at ~30K parameters with standard loss; verify architectural ranking in RMSE and Gradient Error.
2. Implement fixed-weight PIF with λ=0.3; measure training time scaling with parameter count and compare to uncertainty-based variant.
3. Run noise robustness tests on all models with input-only Gaussian noise (σ=0.3, 0.6, 0.9); confirm cKAN/MLP maintain lowest degradation.