---
ver: rpa2
title: Sample Complexity of Bias Detection with Subsampled Point-to-Subspace Distances
arxiv_id: '2502.02623'
source_url: https://arxiv.org/abs/2502.02623
tags:
- bias
- sample
- measure
- distance
- number
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of bias detection in AI systems,
  particularly focusing on the sample complexity required for efficient bias estimation.
  It highlights the challenge posed by regulatory frameworks that necessitate testing
  bias across all subgroups, leading to potentially exponential computational complexity.
---

# Sample Complexity of Bias Detection with Subsampled Point-to-Subspace Distances

## Quick Facts
- **arXiv ID:** 2502.02623
- **Source URL:** https://arxiv.org/abs/2502.02623
- **Reference count:** 40
- **Primary result:** Reformulates bias detection as a point-to-subspace membership test in measure space, enabling efficient subsampling with formally bounded error probability.

## Executive Summary
This paper addresses the computational challenge of bias detection across all subgroups by reformulating it as a point-to-subspace membership test in the space of measures. Using the supremum norm, the authors show that uniform random subsampling of histogram bins can achieve probabilistic approximately correct (PAC) learning guarantees with sample complexity scaling polynomially in dimension rather than exponentially. Experiments demonstrate that this approach achieves substantially lower error rates than traditional Wasserstein-2 distance methods, particularly as the number of features increases.

## Method Summary
The method reformulates bias detection as checking whether a test measure belongs to a subspace defined by reference data uncertainty intervals. This is done by uniformly sampling s bins from the total N = Πᵢbᵢ bins and computing the supremum norm distance between the test measure and subspace projections on these sampled bins. The approach provides a one-sided error guarantee where false positives are bounded by δ, with sample complexity O(n log n / (ε log n log n / ε + 1/ε log 1/δ)).

## Key Results
- Subsampling scheme achieves one-sided error probability bounded by δ with sample complexity scaling polynomially in dimension n
- Experimental results on COMPAS and folktables show substantially lower error rates compared to Wasserstein-2 distance methods
- Performance advantage increases with the number of features, demonstrating scalability to high-dimensional settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bias detection can be reformulated as a point-to-subspace membership test in the space of measures.
- Mechanism: Reference data with uncertainty defines a subspace V of valid measures via interval constraints around each bin. A test measure α₀ is checked for membership in V using the supremum norm: TRUE iff maxᵢ |α₀(xᵢ) − aᵢ| < Δ for all bins.
- Core assumption: Uncertainty in reference data can be captured by fixed interval bounds (Δ) per bin, and histogram binning preserves relevant distributional structure.
- Evidence anchors:
  - [abstract] "reformulate bias detection as a point-to-subspace problem on the space of measures and show that, for supremum norm, it can be subsampled efficiently"
  - [section 2] Algorithm 1 defines the point-to-subspace query using ℓ∞ distance
  - [corpus] Related work (arXiv:2502.02221) also frames bias as distance to reference distribution, supporting this reformulation strategy
- Break condition: If uncertainty cannot be modeled as per-bin intervals (e.g., correlated errors across bins), the subspace construction fails.

### Mechanism 2
- Claim: Uniform random subsampling of bins preserves detection guarantees with formally bounded error probability.
- Mechanism: Instead of checking all N = Πᵢbᵢ bins (exponential in n), sample s bins uniformly at random. The paper proves this creates an ε-net with probability ≥ 1−δ when s = O((n log n)/(ε log(n/ε) + (1/ε)log(1/δ))). False positives are bounded by δ; false negatives are impossible by construction.
- Core assumption: Violations are distributed such that uniform sampling can detect them; specifically, the fraction of violating bins is at most ε.
- Evidence anchors:
  - [abstract] "subsampling scheme can achieve a one-sided error probability bounded by δ with sample complexity scaling as O(n log n / (ϵ log n log n / ϵ + 1/ϵ log 1/δ))"
  - [section 5] Theorem 8 provides the PAC guarantee via VC dimension bounds and ε-net theorem
  - [corpus] Corpus evidence is weak; no directly comparable subsampling guarantees for bias detection found in neighbors
- Break condition: If violations are highly localized (few bins with large deviations), more samples may be needed than the bound suggests for reliable detection.

### Mechanism 3
- Claim: Supremum norm enables subsampling; Wasserstein distances do not due to curse of dimensionality.
- Mechanism: ℓ∞ norm decomposes across bins—each bin is checked independently. Wasserstein-p distances require solving an optimal transport problem coupling all bins, with sample complexity scaling exponentially in dimension. Experiments show supremum norm subsampling achieves lower error rates than Wasserstein-2, especially as n increases.
- Core assumption: The ℓ∞ norm is an appropriate metric for bias detection—that pointwise differences in bin probabilities capture the relevant notion of distributional unfairness.
- Evidence anchors:
  - [section 1] "curse of dimensionality suggests that the number of samples for a given error grows exponentially with the dimension... proven for Wasserstein-1, Wasserstein-2..."
  - [section 6.2] Figure 5 and 6 show lower error rates for supremum norm vs. Wasserstein-2 across varying ε and dimension
  - [corpus] Neighbor paper (arXiv:2511.13025) notes manifold distance reconstruction challenges with noise, indirectly supporting that transport-based metrics face sample complexity issues
- Break condition: If bias manifests through distributional shape (e.g., mode shifts) rather than bin-wise probability differences, ℓ∞ may miss relevant signals.

## Foundational Learning

- **Concept:** **VC (Vapnik-Chervonenkis) Dimension**
  - Why needed here: The PAC guarantee in Theorem 8 relies on bounding the VC dimension of the range space defined by histogram bin constraints. Understanding this connects sample size to generalization.
  - Quick check question: Given n hyperplanes in ℝⁿ defining half-space constraints, what is the maximum number of points that can be shattered?

- **Concept:** **Probability Measures on Metric Spaces**
  - Why needed here: The paper formalizes distributions as measures α ∈ M₁⁺(X) and compares them via norms. The subspace V is a set of measures, not vectors.
  - Quick check question: How does a discrete measure Σᵢaᵢδ_{xᵢ} differ from a probability vector a ∈ Σₙ?

- **Concept:** **Wasserstein Distance (Optimal Transport)**
  - Why needed here: The baseline comparison uses W₂; understanding why it suffers exponential sample complexity helps justify the supremum norm choice.
  - Quick check question: Why does Wasserstein distance require solving a coupling optimization problem, while ℓ∞ norm does not?

## Architecture Onboarding

- **Component map:**
  Histogram encoder -> Subspace constructor -> Subsampling module -> Distance checker -> Baseline comparator

- **Critical path:**
  1. Bin normalization (aᵢ ← hᵢ/Σhᵢ)
  2. Sample s bins uniformly → set S
  3. For each bin in S: check |α₀|S − a|S| ≥ Δ
  4. Early exit on first violation (FALSE) or completion (TRUE)

- **Design tradeoffs:**
  - **Δ threshold:** Larger Δ increases false negatives (misses real bias); smaller Δ increases false positives. The paper operates in ∆min < ∆ < ∆max where ε ∈ (0,1).
  - **Sample size s:** Larger s reduces error probability δ but increases computation; the bound s = O(n log n / ε²) guides selection.
  - **Number of bins per feature:** More bins capture finer distributional detail but increase N (exponentially); the paper uses 10 bins for COMPAS decile scores.

- **Failure signatures:**
  - **High false positive rate when ε is small:** If violations are rare (ε ≈ 0.001), subsampling may miss them → error > 50% (see Section 6.2).
  - **No adaptation to correlated features:** Uniform sampling assumes violations are spread; correlated features may cluster violations in few bins.
  - **Sensitivity to binning strategy:** Poor bin boundaries can dilute signal, making violations harder to detect.

- **First 3 experiments:**
  1. **Reproduce Figure 5:** On Adult dataset with 2 encoded features, compare subsampled supremum norm vs. W₂ error rates across sample sizes s ∈ {100, 500, 1000, 5000} and ε ∈ {0.1, 0.01, 0.001}. Verify error drops faster for supremum norm.
  2. **Dimension scaling test:** On folktables with n ∈ {2, 4, 6} encoded features, fix s = 1000 and plot error rate vs. n. Confirm supremum norm error scales mildly while W₂ degrades.
  3. **Threshold sweep:** For a single test subgroup (e.g., SEX=1 in folktables), sweep Δ from ∆min to ∆max and record TRUE/FALSE decisions. Characterize the decision boundary and compare to full N-bin computation.

## Open Questions the Paper Calls Out
None

## Limitations
- The method's performance depends on appropriate binning and threshold selection (Δ), but the paper provides limited guidance on these hyperparameters for practical deployment.
- No explicit comparison to state-of-the-art bias detection methods beyond Wasserstein-2 distance, leaving open questions about relative performance against established techniques.
- The PAC guarantee assumes violations are uniformly distributed across bins; highly localized violations may require more samples than the bound suggests for reliable detection.

## Confidence

| Claim | Confidence |
|-------|------------|
| Mathematical formulation of bias detection as point-to-subspace problem | High |
| PAC learning guarantee (Theorem 8) | High |
| Experimental results showing superior performance to Wasserstein-2 | Medium |
| Method's behavior on correlated features or clustered violations | Low |

## Next Checks
1. Test the method on datasets where violations are known to cluster in specific bins to evaluate performance degradation and sample size requirements.
2. Conduct ablation studies varying binning strategies and Δ thresholds to establish robustness and sensitivity to these hyperparameters.
3. Compare against additional bias detection baselines (e.g., maximum subgroup discrepancy methods) on the same datasets to establish relative performance.