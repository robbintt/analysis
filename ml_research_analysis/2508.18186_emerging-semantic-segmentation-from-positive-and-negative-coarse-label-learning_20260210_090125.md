---
ver: rpa2
title: Emerging Semantic Segmentation from Positive and Negative Coarse Label Learning
arxiv_id: '2508.18186'
source_url: https://arxiv.org/abs/2508.18186
tags:
- coarse
- annotations
- segmentation
- label
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of training segmentation models
  using coarse annotations, which are faster and cheaper to produce than pixel-level
  labels but often contain noise. The authors propose a method that uses both positive
  (target) and negative (background) coarse annotations, even when they contain noisy
  pixels, to train a convolutional neural network (CNN) for semantic segmentation.
---

# Emerging Semantic Segmentation from Positive and Negative Coarse Label Learning

## Quick Facts
- **arXiv ID:** 2508.18186
- **Source URL:** https://arxiv.org/abs/2508.18186
- **Reference count:** 24
- **Primary result:** Outperforms state-of-the-art weakly-supervised and semi-supervised methods on MNIST, Cityscapes, and LES-AV datasets by jointly estimating true segmentation and annotation noise patterns.

## Executive Summary
This paper addresses the challenge of training segmentation models using coarse annotations, which are faster and cheaper to produce than pixel-level labels but often contain noise. The authors propose a method that uses both positive (target) and negative (background) coarse annotations, even when they contain noisy pixels, to train a convolutional neural network (CNN) for semantic segmentation. Their approach involves two coupled CNNs: one estimates the true segmentation probabilities, and the other models the characteristics of the noisy annotations by estimating pixel-wise confusion matrices. The method also incorporates complementary label learning to encourage estimating the negative label distribution. Experiments on MNIST, Cityscapes, and LES-AV retinal image datasets demonstrate that the proposed method outperforms state-of-the-art weakly-supervised and semi-supervised methods, particularly when the ratio of coarse annotations is small compared to dense annotations.

## Method Summary
The method employs two coupled CNNs: one estimates true segmentation probabilities (p_θ), and the other models noisy annotation characteristics by estimating pixel-wise confusion matrices (A_ϕ). The loss function combines cross-entropy between (estimated truth × estimated noise pattern) and observed coarse labels, plus trace regularization to prevent degenerate solutions. The approach also incorporates complementary label learning, where a transition matrix transforms positive predictions to match observed negative annotations, forcing consistency between both prediction pathways. This enables the model to learn from both positive and negative coarse annotations while disentangling systematic labeling errors from ground truth.

## Key Results
- On MNIST, achieves 82.5% mIoU, significantly outperforming baseline methods
- On Cityscapes, achieves 68.3% mIoU, demonstrating effectiveness on complex scenes
- On LES-AV dataset, achieves 71.6% mIoU, comparable to strongly-supervised approaches
- Performance particularly strong when coarse annotations are sparse relative to dense labels

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Jointly estimating both true labels and annotation noise patterns enables disentanglement of systematic labeling errors from ground truth.
- **Mechanism:** Two coupled CNNs operate on the same input: CNN₁ (θ) predicts true segmentation probabilities; CNN₂ (ϕ) estimates pixel-wise confusion matrices that characterize how noisy annotations deviate from truth. The loss optimizes both simultaneously via negative log-likelihood, forcing the model to explain observed coarse labels as a product of (estimated truth × estimated noise pattern).
- **Core assumption:** The noise in coarse annotations follows a learnable, structured pattern that can be mathematically separated from the true label distribution—not purely random or adversarial.
- **Evidence anchors:** [abstract] "The separation of the two CNNs is achieved by high fidelity with the characters of the noisy training annotations." [section 2.2, Eq. 1-2] Cross-entropy between (Â^(o)_ϕ · p̂_θ) and coarse labels, plus trace regularization. [corpus] Paper 53515 addresses noisy labels via geometric-structural guidance, suggesting noise structure is exploitable; this paper explicitly models it via confusion matrices.
- **Break condition:** If annotation noise is unstructured (e.g., uniformly random pixel flips with no spatial/temporal correlation), the confusion matrix estimation cannot converge to a meaningful pattern, and disentanglement fails.

### Mechanism 2
- **Claim:** Incorporating explicit negative (complementary/background) coarse annotations provides an additional supervision signal that constrains the solution space.
- **Mechanism:** A transition matrix M transforms predictions: rather than directly predicting negative labels, the model predicts positive probabilities and transforms them via M^⊤ to match observed negative annotations. This forces consistency—both positive and negative predictions must arise from the same underlying segmentation estimate.
- **Core assumption:** Negative annotations are available and contain non-trivial information (not just "everything outside scribbles").
- **Evidence anchors:** [abstract] "We propose to add a complementary label learning that encourages estimating negative label distribution." [section 2.2, Eq. 3] L_comp uses M^⊤ · {Â^(c)_ϕ · p̂_θ} to predict negative coarse labels. [corpus] Paper 61124 (PU learning) similarly leverages unlabeled/negative structure; this paper's transition matrix formalizes that relationship.
- **Break condition:** If negative annotations are extremely sparse (e.g., single-pixel background marks) or absent, the transition matrix learning collapses; ablation in Table 1 shows ~5% mIoU drop without negative annotations.

### Mechanism 3
- **Claim:** Trace regularization on confusion matrices prevents degenerate solutions where the model learns trivial identity mappings.
- **Mechanism:** Adding λ·tr(Â_ϕ) to the loss encourages the estimated annotator to be "maximally unreliable" while maintaining fidelity to observed labels. Without this, the optimization has infinite solutions (e.g., permutation of confusion matrix rows yields same likelihood).
- **Core assumption:** There exists a meaningful balance between noise estimation (high trace = reliable annotator) and data fidelity; the regularization strength λ is correctly tuned.
- **Evidence anchors:** [section 2.2] "Intuitively, minimizing the trace encourages the estimated annotators to be maximally unreliable while minimizing the cross entropy ensures fidelity with observed noisy annotators." [section 2.2, Eq. 2] Explicit trace term in L_obj. [corpus] Paper 98983 uses Bayesian spatial correlation for noisy segmentation—alternative identifiability strategy; this paper uses algebraic constraint via trace.
- **Break condition:** If λ is too large, the model over-penalizes "reliable" confusion matrices and fails to learn; if too small, identifiability issues persist and convergence is unstable.

## Foundational Learning

- **Concept: Confusion Matrix as Noise Model**
  - **Why needed here:** The core innovation is treating annotation noise as a learnable confusion matrix per annotation type. You must understand that a C×C confusion matrix encodes p(observed label = i | true label = j).
  - **Quick check question:** Given a 3-class problem, if the confusion matrix is identity, what does that imply about annotation quality?

- **Concept: Transition Matrix for Label Transformation**
  - **Why needed here:** The transition matrix M enables mapping between positive and complementary label spaces. Understanding p(ỹ^(c)|x) = Σ_{i≠j} M_{ij} · p(y=i|x) is essential for implementing the negative label pathway.
  - **Quick check question:** Why must diagonal entries of M be zero for complementary labels?

- **Concept: Identifiability in Latent Variable Models**
  - **Why needed here:** Without trace regularization, the coupled system has multiple equivalent solutions. This is a classic identifiability problem in latent variable models—you need constraints to pick a unique solution.
  - **Quick check question:** If you permute rows of Â and correspondingly permute classes in p̂, does the likelihood change?

## Architecture Onboarding

- **Component map:**
  - Input images → Segmentation Network (θ) → True segmentation probabilities p̂_θ(x)
  - Input images → Coarse Annotation Network (ϕ) → Confusion matrices Â^(o)_ϕ(x), Â^(c)_ϕ(x)
  - Confusion matrices × True probabilities → Observed positive predictions
  - Confusion matrices × True probabilities → Transformed negative predictions via transition matrix M^⊤
  - Loss aggregator → Combined loss (positive + negative + trace regularization) → Backpropagation to both networks

- **Critical path:**
  1. Forward pass through both networks for each image.
  2. Compute p̂^(o) = Â^(o) · p̂ (matrix multiply per pixel).
  3. Compute negative pathway: u = Â^(c) · p̂, then v = M^⊤ · u.
  4. Aggregate losses per Eq. 4; backpropagate to both θ and ϕ.

- **Design tradeoffs:**
  - **Shared vs. separate backbones:** Paper uses separate CNNs for clarity; sharing early layers could reduce parameters but may couple noise/segmentation learning too tightly.
  - **Per-image vs. global confusion matrices:** Paper estimates CMs per-image, enabling annotation-specific noise modeling but requiring sufficient annotations per image.
  - **Assumption:** The λ trace weight is critical—paper doesn't specify value; you'll need grid search (start λ ∈ [0.01, 0.1]).

- **Failure signatures:**
  - **CM collapse to identity:** Model learns Â ≈ I, meaning it treats coarse labels as ground truth—trace regularization too weak.
  - **CM collapse to uniform:** All predictions become uninformative; trace regularization too strong or learning rate too high for ϕ.
  - **Negative pathway divergence:** M becomes singular; check that M diagonal is explicitly zeroed and off-diagonals are normalized.

- **First 3 experiments:**
  1. **Sanity check on synthetic MNIST:** Replicate the toy experiment with known ground truth; verify CM estimation matches simulated noise patterns (visualize Â vs. true noise matrix).
  2. **Ablation on negative labels:** Train with only positive coarse labels vs. full model on Cityscapes subset (500 images); confirm ~5-10% mIoU gap per Table 1.
  3. **Lambda sensitivity:** Sweep λ ∈ {0.001, 0.01, 0.1, 1.0} on validation set; plot mIoU vs. λ to find stable operating range before full training.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can promptable foundation models be integrated into this framework to further reduce annotation burdens?
  - **Basis in paper:** [explicit] The conclusion states, "Another promising direction is to explore the use of promptable foundation models... Incorporating such models into our framework could further enhance flexibility."
  - **Why unresolved:** The current architecture relies on standard CNNs, and the interaction between foundation model priors and the proposed noise modeling mechanism (confusion matrices) is unexplored.
  - **What evidence would resolve it:** Experiments replacing the segmentation backbone with a foundation model, showing improved segmentation accuracy or faster convergence on the Cityscapes or LES-AV datasets.

- **Open Question 2:** Does imposing structural constraints on the estimated Confusion Matrices (CMs) and Transition Matrices (TMs) improve performance on extremely sparse annotations like scribbles or spots?
  - **Basis in paper:** [explicit] The conclusion notes, "future work shall consider imposing structures on the CMs and TMs to broaden the applicability to scribble or spot annotations."
  - **Why unresolved:** The current method estimates CMs on a per-image basis without structural constraints, which may be under-constrained or unstable when supervision is reduced to extreme sparsity (e.g., single points).
  - **What evidence would resolve it:** Ablation studies comparing unconstrained vs. structured matrix estimation on datasets labeled only with spot or sparse scribble annotations.

- **Open Question 3:** Can the per-image noise modeling approach be effectively extended to 3D volumetric segmentation tasks?
  - **Basis in paper:** [inferred] The introduction identifies "segmentation of... organs on computed tomography" as a key motivation, yet all experiments (MNIST, Cityscapes, Retinal) are strictly 2D.
  - **Why unresolved:** Estimating pixel-wise confusion matrices per image scales poorly with volume size; it is unclear if the 2D noise disentanglement strategy remains computationally feasible or statistically robust in 3D.
  - **What evidence would resolve it:** Successful application and validation of the method on a 3D medical dataset (e.g., CT organ segmentation) with analysis of memory usage and training time.

## Limitations

- **Architecture underspecification:** The paper uses "two coupled CNNs" without detailing backbone choice, depth, or CM network architecture, preventing direct replication.
- **Hyperparameter sensitivity:** Key hyperparameters like λ (trace regularization weight) and learning rate are unspecified, making stable convergence non-trivial.
- **Noise model assumptions:** The method assumes structured, learnable annotation noise, which may not hold for all real-world coarse annotations.

## Confidence

- **High confidence:** The core mechanism of using coupled CNNs with confusion matrices to disentangle true labels from noisy annotations is mathematically sound and well-motivated by identifiability theory.
- **Medium confidence:** Empirical results on MNIST and Cityscapes are convincing, but LES-AV's small sample size and lack of architectural details reduce confidence in generalization claims.
- **Low confidence:** The claim of "state-of-the-art" performance is weakly supported—comparisons are limited to a narrow set of weakly-supervised methods, and stronger baselines are not included.

## Next Checks

1. **Synthetic noise sanity check:** Replicate the MNIST experiment with known ground truth and simulated noise. Visualize estimated confusion matrices vs. true noise patterns to verify the disentanglement mechanism works as intended.
2. **Negative label ablation on larger dataset:** Train the full model vs. positive-only version on a larger subset of Cityscapes (e.g., 500 images). Confirm the ~5-10% mIoU gap from Table 1 holds and isn't dataset-specific.
3. **Lambda sensitivity sweep:** Systematically vary λ ∈ {0.001, 0.01, 0.1, 1.0} on validation sets for all three datasets. Plot mIoU vs. λ to identify stable operating ranges and ensure the method isn't overly sensitive to this critical hyperparameter.