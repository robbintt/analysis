---
ver: rpa2
title: The German Commons - 154 Billion Tokens of Openly Licensed Text for German
  Language Models
arxiv_id: '2510.13996'
source_url: https://arxiv.org/abs/2510.13996
tags:
- text
- german
- data
- language
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces the German Commons, the largest collection
  of openly licensed German text for language model training. The dataset addresses
  the scarcity of large-scale, legally compliant German text by aggregating 154.56
  billion tokens from 35.78 million documents across 41 sources spanning seven domains
  including legal, scientific, cultural, political, news, economic, and web content.
---

# The German Commons - 154 Billion Tokens of Openly Licensed Text for German Language Models

## Quick Facts
- **arXiv ID:** 2510.13996
- **Source URL:** https://arxiv.org/abs/2510.13996
- **Reference count:** 40
- **Primary result:** 154.56 billion tokens of openly licensed German text across 41 sources

## Executive Summary
The German Commons dataset addresses a critical gap in German language model training resources by providing the largest collection of openly licensed German text. The dataset aggregates 154.56 billion tokens from 35.78 million documents across seven domains including legal, scientific, cultural, political, news, economic, and web content. Each document carries explicit open licenses (CC-BY-SA 4.0 or equivalent), enabling truly open model development without the licensing uncertainties of web-scraped alternatives.

A comprehensive processing pipeline implements quality filtering, deduplication, text formatting, and PII removal, retaining 50.73% of input while maintaining consistent quality. Corpus statistics demonstrate suitability for language model pretraining, with balanced text complexity distribution across domains and minimal toxic content. The dataset and its open-source preprocessing pipeline are fully reproducible and extensible.

## Method Summary
The dataset was created through a systematic aggregation of 41 openly licensed German text sources spanning seven domains. The processing pipeline includes quality filtering to remove non-text and malformed documents, deduplication to eliminate redundant content, text formatting standardization, and PII removal. The pipeline retained 50.73% of the original input data while ensuring consistent quality standards. Each document was verified for open licensing compliance, with most sources carrying CC-BY-SA 4.0 or equivalent licenses. The processed corpus contains 154.56 billion tokens from 35.78 million documents, making it the largest openly licensed German text dataset available for language model training.

## Key Results
- 154.56 billion tokens from 35.78 million documents across 41 sources
- 50.73% retention rate through quality filtering and deduplication
- Seven domain coverage including legal, scientific, cultural, political, news, economic, and web content
- Explicit open licensing (CC-BY-SA 4.0 or equivalent) enabling truly open model development

## Why This Works (Mechanism)
The German Commons succeeds by addressing the fundamental challenge of licensing uncertainty in German text datasets. Unlike web-scraped alternatives, this dataset provides legally compliant, openly licensed content that enables unrestricted model training and deployment. The comprehensive processing pipeline ensures data quality while maintaining the diversity needed for robust language model pretraining across multiple domains and text complexities.

## Foundational Learning
- **Open licensing compliance**: Essential for enabling unrestricted model training and deployment without legal risks. Quick check: Verify each document's license metadata matches stated requirements.
- **Quality filtering criteria**: Critical for removing non-text and malformed documents that could degrade model performance. Quick check: Sample filtered vs. unfiltered documents to assess criteria effectiveness.
- **PII removal processes**: Necessary for privacy compliance and preventing sensitive information leakage. Quick check: Audit random samples for residual personal information.
- **Domain diversity**: Important for creating well-rounded language models capable of handling various text types. Quick check: Analyze token distribution across domains.
- **Text complexity metrics**: Required for ensuring balanced training data across different reading levels. Quick check: Verify complexity distribution using multiple readability metrics.
- **Deduplication strategies**: Essential for preventing model overfitting to repetitive content. Quick check: Compare document similarity scores before and after deduplication.

## Architecture Onboarding
**Component Map:** Raw Sources -> Quality Filtering -> Deduplication -> Text Formatting -> PII Removal -> Tokenization -> Corpus Statistics
**Critical Path:** The pipeline follows a linear flow from raw source aggregation through sequential processing stages, with each stage building on the previous one's output.
**Design Tradeoffs:** The 50.73% retention rate represents a balance between data quantity and quality, prioritizing clean, diverse content over maximal token count.
**Failure Signatures:** Low retention rates may indicate overly aggressive filtering criteria, while high retention with poor quality metrics suggests insufficient filtering.
**First Experiments:**
1. Test filtering criteria on small sample to optimize retention vs. quality balance
2. Verify license compliance across all source documents
3. Assess PII removal effectiveness on sensitive content types

## Open Questions the Paper Calls Out
None

## Limitations
- The "largest" claim carries Medium confidence due to incomplete inventories of all German datasets
- Quality assessment methodology may not optimally capture German linguistic nuances
- PII removal process may require additional considerations for German privacy regulations
- Text complexity assessment relies on metrics that may not fully capture German-specific readability factors

## Confidence
- "Largest" dataset claim: Medium confidence
- Quality assessment methodology: Medium confidence  
- PII removal process: Medium confidence
- Text complexity distribution: Low confidence

## Next Checks
1. Conduct comparative analysis with other German datasets to verify the "largest" claim through systematic metadata examination
2. Perform domain-specific readability assessments using German-specific metrics to validate the complexity distribution findings
3. Implement a multi-stakeholder review of the PII removal process with German legal and privacy experts to ensure compliance with local regulations and cultural expectations