---
ver: rpa2
title: Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset in
  Large Language Models
arxiv_id: '2511.03699'
source_url: https://arxiv.org/abs/2511.03699
tags:
- conspiracy
- llms
- cited
- conspiratorial
- items
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large language models were tested with validated conspiracy belief
  surveys to determine if they display conspiratorial tendencies. Models showed moderate
  agreement with general conspiracy beliefs but disagreed with specific theories like
  UFOs.
---

# Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset in Large Language Models

## Quick Facts
- arXiv ID: 2511.03699
- Source URL: https://arxiv.org/abs/2511.03699
- Reference count: 27
- Large language models tested with validated conspiracy belief surveys showed moderate agreement with general conspiracy beliefs but disagreed with specific theories like UFOs

## Executive Summary
This study investigates whether large language models (LLMs) exhibit conspiratorial thinking patterns by administering validated conspiracy belief surveys. The research reveals that LLMs demonstrate measurable agreement with general conspiracy beliefs, though with less intensity than human responses. The study also demonstrates that conditioning models with demographic personas significantly increases their agreement with conspiracy beliefs and reveals systematic demographic biases. Models respond more conspiratorially when prompted with non-white, older, lower-income, or Republican personas. The findings highlight both the utility of LLMs for social science research and the risks of their potential manipulation toward conspiratorial outputs.

## Method Summary
The researchers administered the Generic Conspiracist Beliefs scale (GCB) and the Conspiracy Mentality Questionnaire (CMQ) to multiple LLM families including GPT-4, Claude, Llama, and others. Models were tested in zero-shot, chain-of-thought, and few-shot prompting conditions, with both balanced and persona-based prompts incorporating demographic information (age, race, education, income, political affiliation). Model responses were scored using standard conspiracy belief metrics, and statistical analyses examined correlations with human survey data, demographic effects, and belief cluster patterns. Additional analyses included T-tests on demographic variables, principal component analysis of belief clusters, and content analysis of model-generated justifications.

## Key Results
- LLMs showed moderate correlation (0.63) with human GCB scores and significant correlations with human CMQ scores
- Conditioning models with demographic personas increased conspiracy belief agreement across all demographic groups, with non-white, older, lower-income, and Republican personas showing highest agreement
- Simple prompts could shift models toward conspiratorial responses, particularly for targeted belief clusters like government malfeasance and extraterrestrial cover-ups
- Demographic-specific language patterns emerged in model-generated justifications, revealing systematic biases

## Why This Works (Mechanism)
LLMs learn statistical patterns from training data that includes human discourse containing conspiracy beliefs and demographic perspectives. The models' ability to simulate conspiratorial thinking stems from their pattern-matching capabilities and exposure to diverse viewpoints during pretraining. Demographic persona conditioning works because it activates specific distributional patterns in the model's learned representations that correspond to different demographic groups' typical discourse patterns. The models generate responses based on conditional probability distributions that reflect the relative frequencies of conspiratorial versus non-conspiratorial language in their training corpus.

## Foundational Learning

**Conspiracy Belief Scales (GCB/CMQ)**
Why needed: Provides validated measurement tools for quantifying conspiracy beliefs
Quick check: Verify scale reliability and validity across different populations

**Zero-shot vs Chain-of-Thought vs Few-shot prompting**
Why needed: Different prompting strategies affect model reasoning and response quality
Quick check: Compare response consistency across prompting methods

**Demographic persona conditioning**
Why needed: Tests how demographic information influences model outputs
Quick check: Validate that personas are correctly interpreted by models

**Principal Component Analysis for belief clustering**
Why needed: Identifies underlying structure in conspiracy belief patterns
Quick check: Confirm component stability across different model families

**Content analysis of generated justifications**
Why needed: Reveals reasoning patterns behind model responses
Quick check: Ensure inter-rater reliability for qualitative coding

## Architecture Onboarding

**Component Map**
LLM -> Prompt processor -> Belief scoring module -> Statistical analysis pipeline -> Visualization layer

**Critical Path**
The critical path flows from prompt generation through model inference to belief scoring and statistical analysis. Model architecture determines the quality of belief representation, while prompting strategy influences response consistency. The scoring module translates raw model outputs into standardized belief metrics for comparison.

**Design Tradeoffs**
Zero-shot prompting offers simplicity but may yield less consistent results compared to few-shot approaches. Persona conditioning increases realism but introduces potential bias amplification. Statistical aggregation across multiple models provides robustness but may obscure model-specific patterns.

**Failure Signatures**
Inconsistent responses across prompting strategies suggest sensitivity to prompt formulation. Demographic bias effects that reverse across model families indicate training corpus variations. Low correlation with human data suggests models may not capture genuine conspiratorial thinking.

**First Experiments**
1. Test correlation between model responses and human survey data using multiple belief scales
2. Compare demographic bias effects across different prompting strategies
3. Analyze belief cluster patterns to identify which conspiracy types are most susceptible to demographic influence

## Open Questions the Paper Calls Out
None

## Limitations

- Findings rely on self-reported agreement with survey statements, which may not capture genuine belief systems in AI models
- Moderate correlations between model and human responses suggest partial but imperfect alignment
- Single conspiracy belief scale used; cultural/linguistic variations in interpretation not accounted for
- Demographic persona method represents simplified approach that may not capture full complexity of human demographic influences

## Confidence

High: Models exhibit measurable agreement with conspiracy beliefs and can be systematically influenced through prompting and persona conditioning
Medium: Correlation between model and human conspiracy belief scores shows substantial variance; mechanisms require further investigation
Low: Whether model responses represent genuine "beliefs" versus pattern completion remains unclear

## Next Checks

1. Replicate findings using multiple conspiracy belief scales and cross-cultural survey instruments to assess generalizability across different conspiracy belief frameworks

2. Conduct ablation studies testing whether specific demographic attribute combinations (rather than full personas) drive the observed bias effects, and whether these effects persist across different model architectures

3. Implement blinded human evaluation of model-generated justifications to verify that demographic-specific language patterns are recognizable and meaningful to human raters