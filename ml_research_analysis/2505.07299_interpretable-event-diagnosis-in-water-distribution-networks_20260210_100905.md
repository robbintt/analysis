---
ver: rpa2
title: Interpretable Event Diagnosis in Water Distribution Networks
arxiv_id: '2505.07299'
source_url: https://arxiv.org/abs/2505.07299
tags:
- event
- sensor
- detection
- fault
- water
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes an interpretable event diagnosis framework for
  water distribution networks using counterfactual explanations. It addresses the
  challenge that automated event detection algorithms are often not trusted by operators
  due to lack of transparency.
---

# Interpretable Event Diagnosis in Water Distribution Networks

## Quick Facts
- **arXiv ID**: 2505.07299
- **Source URL**: https://arxiv.org/abs/2505.07299
- **Reference count**: 40
- **Primary result**: Interpretable framework for diagnosing events in water distribution networks using counterfactual explanations, achieving F1≈0.97 on L-Town benchmark

## Executive Summary
This paper addresses the critical challenge of making automated event detection in water distribution networks (WDNs) interpretable for operators. The proposed framework combines residual-based detection using virtual sensors with counterfactual explanations that show minimal measurement changes needed to avoid detection. These counterfactual event fingerprints (CDFs) exhibit distinct patterns for leakages versus sensor faults, enabling classification while maintaining interpretability. The approach bridges the gap between accurate automated detection and human trust, allowing operators to understand algorithmic decisions and combine them with domain expertise.

## Method Summary
The method trains linear regression models as virtual sensors on normal operation data, detecting events when residuals exceed thresholds. For detected events, counterfactual event fingerprints are generated by finding the closest training data point that would not trigger detection. These CDFs are then classified as leakage or sensor fault using decision trees or k-NN. The approach is evaluated on the Hanoi and L-Town benchmark networks, with performance measured by detection accuracy (TP, FP, FN, detection delay) and classification quality (Precision, Recall, F1).

## Key Results
- Achieved F1≈0.97 for event classification on L-Town benchmark network
- Precision of 0.96 and recall of 0.98 for leakage detection
- Precision of 0.98 and recall of 0.95 for sensor fault detection
- Decision tree classifiers achieved 98% accuracy on Hanoi dataset
- CDF patterns show clear distinguishability between leakage and sensor fault events

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Virtual sensors trained on normal operation data can detect anomalies by comparing forecasts to actual measurements.
- **Mechanism**: Linear regression models predict each sensor's value using measurements from all other sensors over a time window T. Residuals (forecast - actual) exceeding a threshold θ trigger alerts. This works because leakages and sensor faults disrupt the learned correlations between sensors that exist under normal hydraulic operation.
- **Core assumption**: Normal operation exhibits stable, learnable correlations between sensors that are violated during anomalous events.
- **Evidence anchors**:
  - [abstract] "The method uses sensor forecasting via linear regression"
  - [Section 5] "The sensor forecasts fi(·) (virtual sensors for event detection) are realized in this work using linear regression"
- **Break condition**: If system dynamics change significantly without retraining, forecasts become unreliable.

### Mechanism 2
- **Claim**: Counterfactual event fingerprints (CDFs) exhibit distinguishable patterns for leakages versus sensor faults.
- **Mechanism**: CDFs represent the minimum changes to sensor measurements that would avoid triggering detection. Sensor faults produce sparse, localized fingerprints (primarily affecting the faulty sensor). Leakages produce distributed fingerprints affecting multiple sensors according to hydraulic connectivity. A classifier trained on simulated CDFs can exploit this structural difference.
- **Core assumption**: Leakage propagation follows hydraulic laws creating multi-sensor signatures; sensor faults are localized to measurement devices.
- **Evidence anchors**:
  - [abstract] "These fingerprints help operators understand why an event was detected and assist in classifying the type of event (leakage vs. sensor fault)"
  - [Section 6] "While a sensor fault affects a single sensor only, a leakage might affect multiple sensors. Therefore it is not surprising that we consistently observe significant differences in the obtained CDFs"
- **Break condition**: Small leakages near sensor locations may produce fingerprints resembling sensor faults.

### Mechanism 3
- **Claim**: Constraining counterfactuals to previously observed normal data ensures physical plausibility.
- **Mechanism**: Rather than solving an unconstrained optimization that might produce implausible values, the method searches the training dataset for the closest measurement vector that would not trigger an alarm. This database-lookup approach guarantees feasibility while approximating the minimum-change objective.
- **Core assumption**: The training set contains sufficiently diverse normal operation measurements to provide plausible counterfactuals for any detected event.
- **Evidence anchors**:
  - [Section 6] "we limit the set of data which are obtained by feasible CDFs to the set of training samples D... This is reasonable as we fit the event detection method to the set of measurements D from a time period without any events"
- **Break condition**: If detected events fall outside the distribution of normal operations, no suitable counterfactual may exist in D.

## Foundational Learning

- **Concept: Counterfactual explanations in XAI**
  - Why needed: CDFs are the core explanatory mechanism; understanding that counterfactuals answer "what minimal change would produce a different outcome?" is essential.
  - Quick check: Given a loan rejection, would a counterfactual explain why it was rejected or what would change the decision?

- **Concept: Residual-based fault detection**
  - Why needed: The event detection system is built on comparing predicted vs. actual sensor values; understanding residuals, thresholds, and false alarm trade-offs is foundational.
  - Quick check: If residuals increase but remain below threshold θ, would the system trigger an alarm?

- **Concept: Water distribution network hydraulics basics**
  - Why needed: Understanding that leakages affect pressure at multiple nodes (via conservation laws) while sensor faults are localized explains why CDF patterns differ by event type.
  - Quick check: Would a pipe leakage affect pressure readings at only one sensor or multiple sensors in the network?

## Architecture Onboarding

- **Component map**:
  - Sensor Data Ingestion -> Virtual Sensor Ensemble -> Residual Computer -> Event Detector -> CDF Generator -> Event Classifier -> CIF Generator
  - Digital Twin Simulator provides labeled training data

- **Critical path**:
  1. Deploy sensors → 2. Collect normal operation data → 3. Train virtual sensors → 4. Calibrate digital twin → 5. Simulate event scenarios → 6. Train CDF classifier → 7. Deploy detection → 8. Generate explanations on alerts

- **Design tradeoffs**:
  - Decision tree vs. k-NN classifier: Decision trees are interpretable and computationally efficient; k-NN achieved near-perfect F1 in experiments but may memorize rather than generalize.
  - Threshold θ selection: Higher θ reduces false positives but increases detection delay, especially for small leakages.
  - Time window T: Paper sets T=1 for computational tractability; longer windows may improve robustness but increase complexity.

- **Failure signatures**:
  - Small leakages: Low TP (0.58 on L-Town), high detection delay (3090 timesteps), often confused with sensor faults.
  - Gaussian noise sensor faults: Lower recall (0.59-0.78) because noise can mimic normal variability.
  - Model-reality mismatch: Training on nominal model with ±5% parameter errors still works, but larger mismatches would degrade transfer.

- **First 3 experiments**:
  1. Replicate event detection on Hanoi with varying threshold θ to characterize the precision-recall tradeoff curve.
  2. Train classifier on simulated CDFs from digital twin; evaluate on held-out scenarios with different leak magnitudes to confirm small-leak performance gap.
  3. Implement CIF generation for misclassified events to identify which sensor pattern features confuse the classifier between leakage and sensor fault classes.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can the event isolation methodology be extended to handle unknown event types not present during training (e.g., via an explainable reject option)?
  - Basis: The authors state the methodology is limited to known types of events.
  - Why unresolved: The current classifier requires pre-defined event classes; novel faults would be misclassified.
  - Evidence needed: A modified framework with out-of-distribution detection tested on previously unseen event types.

- **Open Question 2**: Does the counterfactual fingerprint approach improve operator trust and decision-making in real-world deployments?
  - Basis: The authors state a user-centric evaluation will be instrumental in demonstrating real-world applicability.
  - Why unresolved: All evaluations use simulated benchmarks; no human operator studies validate interpretability claims.
  - Evidence needed: Controlled user studies with water utility operators measuring trust, comprehension, and decision accuracy.

- **Open Question 3**: Can physics-informed constraints improve counterfactual plausibility and prevent physically infeasible explanations?
  - Basis: The authors note that negative pressure values might result and physics-informed ML could be explored.
  - Why unresolved: Current plausibility relies on restricting CDFs to historical training data.
  - Evidence needed: Comparison of physics-constrained vs. data-only approaches measuring physical validity of generated counterfactuals.

## Limitations

- The approach depends heavily on the training data distribution containing diverse, physically plausible normal operation states for meaningful counterfactual generation.
- Small leakages produce weak multi-sensor signatures that may be confused with sensor faults, limiting detection reliability in this regime.
- The method requires a reasonably accurate digital twin for generating labeled counterfactual fingerprints, and model-reality mismatch could degrade performance.

## Confidence

- **High confidence**: The virtual sensor detection mechanism (residual-based thresholding) is well-established in WDN monitoring literature and the paper's implementation details are sufficiently specified.
- **Medium confidence**: The structural differences between leakage and sensor fault CDF patterns are theoretically sound but the decision tree classifier may not fully capture complex patterns.
- **Medium confidence**: The database-lookup approach for generating plausible counterfactuals is practical but may not always find optimal solutions, especially for events far from the training distribution.

## Next Checks

1. Test the CDF classification performance when training and test data have different parameter distributions (±10% vs ±5%) to assess robustness to model uncertainty.
2. Evaluate detection performance with progressively smaller time windows T to determine the minimum viable T that maintains reasonable accuracy.
3. Analyze CDF patterns for small leakages near sensor locations to determine if these events indeed exhibit fault-like signatures, and assess whether the classifier correctly identifies these ambiguous cases.