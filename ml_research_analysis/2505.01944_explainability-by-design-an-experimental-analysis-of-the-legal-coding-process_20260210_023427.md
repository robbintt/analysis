---
ver: rpa2
title: 'Explainability by design: an experimental analysis of the legal coding process'
arxiv_id: '2505.01944'
source_url: https://arxiv.org/abs/2505.01944
tags:
- coding
- time
- rules
- defeasible
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a systematic methodology for translating legal
  text into formal Deontic Defeasible Logic rules, addressing the complexity of legal
  coding through experimental validation. The process involves three phases: encoding
  normative backgrounds into formal rules, encoding relevant legal scenarios, and
  testing these scenarios against the encoded norms using Houdini, a defeasible deontic
  reasoning tool.'
---

# Explainability by design: an experimental analysis of the legal coding process

## Quick Facts
- arXiv ID: 2505.01944
- Source URL: https://arxiv.org/abs/2505.01944
- Reference count: 27
- Primary result: A methodology for translating legal text into formal Deontic Defeasible Logic rules with 3.99 seconds per character encoding time and 6% error rate

## Executive Summary
This paper presents a systematic methodology for translating legal text into formal Deontic Defeasible Logic rules, addressing the complexity of legal coding through experimental validation. The process involves three phases: encoding normative backgrounds into formal rules, encoding relevant legal scenarios, and testing these scenarios against the encoded norms using Houdini, a defeasible deontic reasoning tool. An experiment with 14 subjects translating seven Italian legal texts demonstrated that the average time to encode one character is 3.99 seconds (median 4.06), with time decreasing as legal expertise increases. The methodology enables accurate rule generation with low error rates (average 6%), providing a reliable framework for automating legal reasoning while ensuring explainability by design.

## Method Summary
The methodology follows a three-phase pipeline where subjects translate legal texts and scenarios into Defeasible Deontic Logic theories using standardized coding guidelines. Subjects map linguistic constructs to logical elements: noun phrases to literals, copulative verbs to strict rules, modals to deontic operators, and conditionals to defeasible rules. The encoded theories are then processed by the Houdini defeasible deontic reasoner to compute logical extensions. Time to encode each text is measured, and the error rate is calculated by comparing reasoner conclusions against expected legal outcomes.

## Key Results
- Average encoding time of 3.99 seconds per character (median 4.06)
- Error rate of 6% across all encoded texts
- Negative correlation (-28.67%) between coding time and legal expertise
- Weak negative correlation (-14.53%) between coding time and text depth

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Translating legal text into formal logic rules enables automated reasoning while preserving semantic intent
- Mechanism: Three-phase pipeline separates normative background encoding from scenario encoding, then evaluates their interaction via a reasoner using strict rules for definitions, defeasible rules for conditional norms with exceptions, and superiority relations for conflict resolution
- Core assumption: Defeasible Deontic Logic is sufficiently expressive to capture normative concepts in natural legal language
- Evidence anchors: Abstract describes methodology and four rule types; Section 3 details three phases and rule generation; related work proposes similar pipeline for LLM automation

### Mechanism 2
- Claim: Scenario-based testing validates encoded rules produce expected legal consequences
- Mechanism: Human coders translate narrative scenarios into facts and propositional rules, combined with encoded norms and input to Houdini reasoner to compute logical extension
- Core assumption: Provided scenarios are representative and comprehensive to test relevant aspects of encoded norms
- Evidence anchors: Abstract mentions scenarios for testing correctness; Section 4 provides homicide example demonstrating narrative-to-rule translation; related XAI-LAW work uses examples for validation

### Mechanism 3
- Claim: Standardized coding guidelines and expertise-dependent time estimation improve efficiency and predictability
- Mechanism: Explicit rules translate linguistic constructs into logical elements; forecasting model uses text length, legal depth, and coder expertise to predict time required
- Core assumption: Cognitive process of legal translation can be decomposed into guideline steps and predicted by linear factors like character count
- Evidence anchors: Abstract mentions forecasting technique depending on domain knowledge, text length, and depth; Section 3 details coding guidelines; Section 6 reports average coding time metrics

## Foundational Learning

- Concept: **Defeasible Reasoning**
  - Why needed here: Core logic of the system handles rules with exceptions (non-monotonicity) common in law like "U-turns forbidden unless permitted"
  - Quick check question: If you have `A => B` and later learn `A and C => not-B`, what happens to the original conclusion in a defeasible system?

- Concept: **Deontic Logic (Obligations, Permissions, Prohibitions)**
  - Why needed here: Legal norms are prescriptive, not descriptive; system uses deontic operators (O, P) and reparative chain operator (`âŠ—`) to model violation consequences
  - Quick check question: How would you represent "You are forbidden from speeding" using an obligation operator?

- Concept: **Superiority Relation**
  - Why needed here: Conflicts between rules are inevitable; superiority relation (`>`) resolves them by defining which rule takes precedence, enabling exceptions and statutory priorities
  - Quick check question: Given conflicting applicable rules `alpha` and `beta`, what condition ensures `alpha`'s conclusion prevails?

## Architecture Onboarding

- Component map: Input Documents (legal text + scenarios) -> Coder (translates to DDL theories) -> Houdini Reasoner (computes logical extensions) -> Evaluation Module (compares conclusions to expected outcomes)

- Critical path: Correctness hinges on Coder's translation; errors propagate through reasoning and evaluation. Human coding is the temporal bottleneck; Houdini is computationally fast.

- Design tradeoffs:
  - **Explainability vs. Automation**: "Explainability by design" via human-readable rules trades off speed of automated NLP for fidelity and verifiability
  - **Expressiveness vs. Tractability**: Defeasible Logic balances expressiveness for legal norms with decidability and computational efficiency

- Failure signatures:
  - High scenario error rate: Indicates normative encoding flaws or guideline ambiguities
  - Unpredictable coding time: Suggests missing forecasting variables (text coherence, ambiguity)
  - Reasoner failure/non-termination: Points to malformed theories (circular dependencies, ill-defined superiority)

- First 3 experiments:
  1. Replicate single-article encoding (e.g., Article 575 homicide) to verify end-to-end pipeline from text to reasoned output
  2. Cross-validation test: Have multiple coders independently encode identical normative text to measure inter-coder variance and identify guideline ambiguities
  3. Validate time estimation model by timing subjects coding texts of varying lengths/depths, comparing actual time against predicted ~4 sec/char baseline

## Open Questions the Paper Calls Out
None

## Limitations
- Experimental corpus not included in paper; must be obtained from authors, preventing independent verification of metrics
- Method relies on human coders following standardized guidelines, introducing potential inter-coder variability not thoroughly quantified
- Assumes Defeasible Deontic Logic is sufficiently expressive for legal reasoning, which may not hold for complex legal concepts like temporal constraints

## Confidence

- **High Confidence**: Three-phase methodology is logically sound and Houdini tool is a real, available system
- **Medium Confidence**: Reported average coding time (3.99 sec/char) and error rate (6%) are specific and measurable, but reproducibility depends on access to exact corpus and guidelines
- **Low Confidence**: Claim that time estimation model is broadly applicable is weakly supported, as study only tested small, specific dataset

## Next Checks
1. Obtain experimental corpus from authors and replicate coding process with new subjects to verify 3.99 sec/char and 6% error rate metrics
2. Conduct cross-validation test with multiple coders encoding same texts to measure inter-coder variance and identify guideline ambiguities
3. Test method on different legal texts (e.g., from another jurisdiction) to assess generalizability of time estimation model and formalism expressiveness