---
ver: rpa2
title: 'Ask Safely: Privacy-Aware LLM Query Generation for Knowledge Graphs'
arxiv_id: '2512.04852'
source_url: https://arxiv.org/abs/2512.04852
tags:
- sensitive
- language
- graph
- query
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of querying knowledge graphs with
  large language models (LLMs) while protecting sensitive data. The authors propose
  a privacy-aware method that masks sensitive values in user questions and graph data
  before sending queries to third-party LLMs.
---

# Ask Safely: Privacy-Aware LLM Query Generation for Knowledge Graphs

## Quick Facts
- arXiv ID: 2512.04852
- Source URL: https://arxiv.org/abs/2512.04852
- Reference count: 30
- Primary result: 82.5% accuracy on MetaQA with privacy protection vs 83.1% without

## Executive Summary
This paper addresses the challenge of querying knowledge graphs with large language models while protecting sensitive data. The authors propose a privacy-aware method that masks sensitive values in user questions and graph data before sending queries to third-party LLMs. By using only the graph structure as context and replacing sensitive information with placeholders, the approach achieves query accuracy comparable to non-private methods (82.5% vs 83.1%) while maintaining privacy and reducing prompt size and token costs.

## Method Summary
The method extracts the knowledge graph schema (node labels, relation types, properties) and identifies sensitive values (all property values except single-word titles/tags). It uses case-insensitive NER to mask sensitive entities in questions with placeholders (NODE_VALUE, AD_HOC), substitutes synonyms with canonical KG terms, and sends the schema + masked question to an LLM via zero-shot prompt. The generated Cypher query template with placeholders is then restored with original values and executed locally. The approach is evaluated on the MetaQA dataset with 503 unique question patterns.

## Key Results
- 82.5% accuracy on MetaQA with privacy protection
- 83.1% accuracy without privacy protection
- 91% accuracy after manual review
- Demonstrates privacy and query quality can be maintained simultaneously
- Reduces prompt size and token costs

## Why This Works (Mechanism)

### Mechanism 1: Schema-Only Context for LLM Prompting
Providing only the graph structure (node labels, relation types, properties) to the LLM enables query generation while eliminating sensitive data exposure. The LLM uses structural metadata to understand valid query patterns and entity relationships without needing access to actual stored values.

### Mechanism 2: Placeholder-Based Sensitive Value Masking with Post-Restoration
Named Entity Recognition identifies and masks sensitive values in user questions, allowing the LLM to generate structurally correct queries with placeholders that are restored post-generation. A domain-specific NER system identifies six entity types and replaces sensitive values with typed placeholders.

### Mechanism 3: Synonym Normalization to Canonical KG Terminology
Mapping user-domain vocabulary to canonical KG labels and relations improves query accuracy by reducing semantic ambiguity in the LLM prompt. A manually-defined synonym dictionary maps natural language terms to KG canonical terms.

## Foundational Learning

- **Concept: Property Graph Data Model (Nodes, Relationships, Properties)**
  - Why needed: The entire approach assumes a property graph with typed nodes, labeled relationships, and properties. Without understanding this model, you cannot reason about what "schema" means or how Cypher queries traverse structures.
  - Quick check: Given a node "Movie" with a property "name" and an outgoing relationship "directed_by" to a "Director" node, write a Cypher query to find all directors of movies named "The Godfather."

- **Concept: Zero-Shot Prompting and LLM Context Windows**
  - Why needed: This method relies on zero-shot prompting and depends on the LLM receiving sufficient context within its token limit. Understanding context window constraints explains why schema-only prompting is both necessary and advantageous.
  - Quick check: If a knowledge graph has 10,000 node types and 50,000 relationship types, what are two reasons this might exceed typical LLM context windows, and how might you address this?

- **Concept: Named Entity Recognition (NER) for Domain-Specific Extraction**
  - Why needed: The masking mechanism depends on NER to identify sensitive values. Understanding NER capabilities and limitations helps assess where this approach will succeed or fail.
  - Quick check: If a user asks "What projects did John Smith complete?" and "John Smith" is both a common name and a sensitive entity in your KG, what failure modes should you anticipate with a token-matching NER approach?

## Architecture Onboarding

- **Component map:** Schema Extractor → Sensitive Value Dictionary Builder → NER Module → Synonym Mapper → Question Preprocessor → LLM Prompt Constructor → LLM Client → Placeholder Restorer → Query Executor

- **Critical path:** User Question → NER Module → Synonym Mapper → Question Preprocessor → LLM Prompt Constructor → LLM Client → Placeholder Restorer → Query Executor. The most fragile steps are NER (entity identification accuracy) and Placeholder Restoration (correct substitution alignment).

- **Design tradeoffs:**
  - Schema complexity vs. prompt token efficiency: Larger schemas provide more context but consume more tokens
  - NER sophistication vs. implementation cost: Simple token matching vs. more robust transformer-based approaches
  - Manual curation vs. automation: Manual synonym dictionaries and sensitive value classification vs. automated approaches

- **Failure signatures:**
  - Leakage: Sensitive values appear in the LLM prompt (NER failed to mask)
  - Broken query after restoration: Placeholders don't match expected format or produce syntactically invalid Cypher
  - Wrong entity type interpretation: LLM treats placeholder as wrong entity type
  - Schema too large for context: Prompt exceeds token limit or LLM produces low-quality output

- **First 3 experiments:**
  1. Baseline validation: Run privacy-aware pipeline on MetaQA subset (503 unique-pattern questions) using GPT-5. Measure accuracy against ground truth.
  2. NER stress test: Create test set with ambiguous entity names and measure false negative/positive rates.
  3. Schema scaling test: Construct synthetic schemas of increasing complexity and measure token count and LLM response quality.

## Open Questions the Paper Calls Out
None

## Limitations
- Manual curation for sensitive value identification and synonym mapping may not scale to large or dynamic knowledge graphs
- NER approach using simple case-insensitive token matching is rudimentary and may fail on ambiguous entities
- Results are based on a single benchmark dataset (MetaQA) with relatively simple queries
- "GPT-5" reference is ambiguous as this model is not publicly available

## Confidence
- **High confidence**: Schema-only prompting mechanism is well-supported and theoretically sound
- **Medium confidence**: Masking and restoration pipeline shows promise but depends heavily on NER quality
- **Low confidence**: 91% accuracy claim from manual review lacks detailed methodology

## Next Checks
1. **NER robustness evaluation**: Construct test suite with ambiguous entity names and measure false positive/negative rates and impact on query accuracy.
2. **Schema scaling experiment**: Systematically increase schema complexity and measure prompt token consumption, LLM response quality, and accuracy degradation point.
3. **Cross-dataset generalization**: Apply pipeline to a more complex knowledge graph benchmark (DBpedia or domain-specific KG) and compare accuracy and failure modes to MetaQA results.