---
ver: rpa2
title: 'CoKe: Customizable Fine-Grained Story Evaluation via Chain-of-Keyword Rationalization'
arxiv_id: '2503.17136'
source_url: https://arxiv.org/abs/2503.17136
tags:
- story
- coke
- evaluation
- keywords
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of fine-grained story evaluation,
  a highly subjective task where human annotators often disagree on ratings across
  aspects like character shaping or plot. The proposed method, Chain-of-Keywords (COKE),
  improves upon Chain-of-Thought (CoT) by generating keyword sequences before free-text
  rationales, avoiding bias from sentiment-laden words.
---

# CoKe: Customizable Fine-Grained Story Evaluation via Chain-of-Keyword Rationalization
## Quick Facts
- arXiv ID: 2503.17136
- Source URL: https://arxiv.org/abs/2503.17136
- Reference count: 26
- Major result: COKE achieves 2.18x improvement in Pearson correlation over GPT-3.5 for story evaluation while using far fewer parameters.

## Executive Summary
This paper introduces COKE, a method for customizable, fine-grained story evaluation that uses Chain-of-Keywords (CoK) to generate rationales before scoring. Unlike Chain-of-Thought, CoK generates keyword sequences to avoid bias from sentiment-laden words, then produces free-text rationales. The approach samples multiple keyword sequences to simulate diverse annotator opinions and averages their scores. Evaluated on the StoryER dataset, COKE significantly outperforms both large language models (including GPT-3.5 and GPT-4) and supervised fine-tuning baselines, achieving state-of-the-art performance in both automatic and human evaluations.

## Method Summary
COKE is a zero-shot framework that generates keyword-based rationales before scoring story aspects like character shaping or plot. The method samples multiple keyword sequences per story to simulate diverse annotator perspectives, then averages their scores. A key innovation is the use of Chain-of-Keywords (CoK) to generate rationales, which avoids bias from sentiment-laden words that often appear in Chain-of-Thought (CoT) outputs. The framework is customizable through user-provided keywords, allowing for fine-grained control over evaluation criteria.

## Key Results
- COKE achieves 2.18x improvement in Pearson correlation over GPT-3.5 for story evaluation.
- Human evaluation confirms COKE's effectiveness when using user-provided keywords.
- COKE uses far fewer parameters than GPT-3.5 and GPT-4 while achieving superior performance.

## Why This Works (Mechanism)
COKE works by generating keyword sequences before free-text rationales, avoiding bias from sentiment-laden words that often appear in Chain-of-Thought (CoT) outputs. By sampling multiple keyword sequences, COKE simulates diverse annotator opinions and averages their scores, leading to more robust and nuanced evaluations. The use of user-provided keywords further enhances customization and control over evaluation criteria.

## Foundational Learning
- Chain-of-Thought (CoT) vs Chain-of-Keywords (CoK): CoT generates step-by-step reasoning, while CoK generates keyword sequences to avoid sentiment bias. Why needed: To prevent bias in story evaluation from sentiment-laden words. Quick check: Compare rationale quality and sentiment distribution between CoT and CoK outputs.
- Zero-shot learning: The model evaluates stories without task-specific fine-tuning. Why needed: To maintain generalizability across different story aspects and domains. Quick check: Test COKE on unseen story datasets or aspects.
- Sampling multiple keyword sequences: Generating multiple keyword sequences per story to simulate diverse annotator opinions. Why needed: To capture the subjective nature of story evaluation and improve robustness. Quick check: Analyze score variance across sampled keyword sequences.

## Architecture Onboarding
- Component map: User Input -> Keyword Generator -> Rationalization Module -> Scoring Module -> Averaged Score
- Critical path: User Input -> Keyword Generator -> Rationalization Module -> Scoring Module
- Design tradeoffs: COKE trades computational efficiency (sampling multiple keyword sequences) for more robust and nuanced evaluations.
- Failure signatures: Over-reliance on specific keywords, inability to capture nuanced aspect-story relationships, hallucination of facts not present in the source story.
- First experiments: 1) Compare CoK and CoT outputs for sentiment distribution and rationale quality. 2) Test COKE's performance on additional story datasets. 3) Evaluate the impact of user-provided keywords on evaluation accuracy.

## Open Questions the Paper Calls Out
None

## Limitations
- Results are confined to a single dataset (StoryER), raising questions about generalizability to other domains or narrative styles.
- The evaluation metrics (Pearson and Spearman correlation) do not directly measure factual consistency between generated keywords/rationales and the source stories.
- The absence of comparisons to more recent or specialized models (e.g., Llama-2-70B, Mistral) limits the strength of the claim that COKE is state-of-the-art.

## Confidence
- Performance improvement over GPT-3.5: High
- Effectiveness of keyword-based rationales: High
- Generalizability to other domains: Medium
- Practical utility for real-world applications: Medium

## Next Checks
1. Test COKE on additional story datasets (e.g., ROCStories, WritingPrompts) to assess robustness across genres and styles.
2. Conduct a direct comparison with more recent open-weight LLMs (e.g., Llama-2-70B, Mistral) to contextualize performance gains.
3. Perform a hallucination analysis using dedicated factual consistency metrics (e.g., ROUGE, BERTScore) between generated keywords/rationales and source stories.