---
ver: rpa2
title: 'AlignAR: Generative Sentence Alignment for Arabic-English Parallel Corpora
  of Legal and Literary Texts'
arxiv_id: '2512.21842'
source_url: https://arxiv.org/abs/2512.21842
tags:
- alignment
- sentence
- methods
- hard
- easy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents AlignAR, a generative sentence alignment method
  for Arabic-English parallel corpora. The method uses LLMs to identify translation
  correspondences by converting the alignment task into a translation mapping problem.
---

# AlignAR: Generative Sentence Alignment for Arabic-English Parallel Corpora of Legal and Literary Texts

## Quick Facts
- arXiv ID: 2512.21842
- Source URL: https://arxiv.org/abs/2512.21842
- Authors: Baorong Huang; Ali Asiri
- Reference count: 7
- Primary result: LLM-based alignment achieves 85.5% F1-score on hard datasets, 9% improvement over previous methods

## Executive Summary
This paper introduces AlignAR, a generative sentence alignment method that reframes the alignment task as a translation mapping problem for Arabic-English parallel corpora. The method uses LLMs to identify translation correspondences by indexing sentences and outputting structured JSON mappings. Experiments on legal (easy) and literary (hard) texts show that LLM-based approaches, particularly Gemini, significantly outperform traditional alignment methods, achieving 85.5% F1-score on hard datasets—a nearly 9% improvement. The work demonstrates LLM robustness for complex, low-resource language pairs and highlights limitations of existing alignment methods.

## Method Summary
AlignAR converts sentence alignment into a translation mapping task by indexing source and target sentences with explicit identifiers (e.g., [0s0], [0t0]), prompting LLMs to select corresponding translations, and outputting structured JSON mappings. The method extracts index pairs into ladder files for evaluation. The approach uses zero-shot prompting with GPT-5.1-mini and Gemini-2.5-flash, comparing results against traditional baselines (BleuAlign, VecAlign, BertAlign) on legal and literary text subsets. The key innovation is task reframing and index-based grounding to reduce hallucination and improve performance on complex many-to-many alignments.

## Key Results
- LLM-based methods achieved 85.5% F1-score on hard datasets, 9% improvement over best baseline (76.7%)
- Traditional methods showed severe degradation on hard datasets: BertAlign dropped from 0.984 to 0.726 F1, BleuAlign from 0.942 to 0.477
- Gemini-2.5-flash outperformed GPT-5.1-mini by 12+ percentage points on hard literary texts
- Easy legal dataset saturation: all methods scored >90% F1, indicating insufficient difficulty

## Why This Works (Mechanism)

### Mechanism 1: Task Reframing (Alignment → Translation Mapping)
Converting alignment to translation selection leverages LLMs' stronger semantic understanding rather than abstract alignment reasoning. The LLM identifies which target sentences are translations of each source sentence, outputting mappings in JSON format. This approach assumes LLMs perform better with semantic matching tasks than structural alignment problems.

### Mechanism 2: Index-Based Output Grounding
Explicit sentence indexing reduces hallucination and parsing failures by creating structured anchors. Prepending indices like `[0s0, ..., nsm]` and `[0t0, ..., ntn]` enables reliable extraction of index pairs into ladder files, avoiding free-form text generation errors.

### Mechanism 3: Semantic Robustness in Complex Alignments
LLM-based methods maintain performance on many-to-many alignments where embedding-based methods fail. Traditional approaches relying on length heuristics or embedding similarity degrade when source/target ratios diverge significantly (~0.45 in hard datasets), while LLMs leverage cross-lingual semantic equivalence.

## Foundational Learning

- **Concept: Sentence Alignment Types (1-to-1, 1-to-many, many-to-many)**
  - Why needed here: Hard dataset deliberately reduces 1-to-1 mappings (~30-45%) to stress-test alignment methods
  - Quick check question: Can you explain why a source/target sentence ratio of 0.45 indicates many-to-many alignments?

- **Concept: Ladder Files**
  - Why needed here: Final output format containing only line number mappings (e.g., `1-1, 2-2, 3-4:5`)
  - Quick check question: What information is removed when converting JSON output to a ladder file?

- **Concept: Strict vs. Lax Alignment Metrics**
  - Why needed here: Paper uses strict F1 (exact match required)—partial/overlapping alignments count as errors
  - Quick check question: Why would strict metrics be preferred for MT training data preparation?

## Architecture Onboarding

- **Component map:** Input preprocessing → Sentence indexing (add `[index]` prefixes) → LLM inference → Translation mapping prompt → JSON output → Post-processing → Index extraction → Ladder file generation → Evaluation → Strict precision/recall/F1

- **Critical path:**
  1. Ensure parallel texts are sentence-segmented (Stanza tokenizer used)
  2. Index sentences before LLM call—non-negotiable for hallucination reduction
  3. Parse JSON output robustly; malformed JSON breaks the pipeline
  4. Context window limits document length (noted in Limitations)

- **Design tradeoffs:**
  - LLM choice (Gemini vs GPT) significantly impacts hard-dataset performance
  - Zero-shot vs few-shot/prompt engineering not explored—potential improvement area
  - Processing time depends on LLM latency, not local compute

- **Failure signatures:**
  - Easy dataset saturation: If all methods score >90% F1, dataset lacks discriminatory power
  - Hard dataset divergence: Large gaps between LLM and baseline methods signal many-to-many complexity
  - JSON parsing failures: LLM may output invalid format (add retry/validation logic)

- **First 3 experiments:**
  1. Replicate easy vs. hard split on your own domain—verify "easy" benchmarks aren't saturated
  2. Ablate the indexing step: run alignment without indices to quantify hallucination reduction
  3. Compare GPT vs. Gemini on a many-to-many subset to assess model sensitivity before production deployment

## Open Questions the Paper Calls Out

### Open Question 1
Can advanced prompting strategies like chain-of-thought or few-shot learning improve alignment accuracy over the simple zero-shot approach used? The authors explicitly state that effects of advanced prompt methods are not explored, leaving potential performance gains unexamined.

### Open Question 2
How can the generative alignment method be adapted for documents that exceed the context window of the LLM? The paper notes this constraint but doesn't provide specific length thresholds or segmentation strategies for handling long documents.

### Open Question 3
How robust is the extraction pipeline to malformed JSON outputs, and does strict formatting constraint impact alignment quality? The authors identify JSON formatting as essential for successful parsing, implying potential fragility that remains unquantified.

## Limitations
- Prompt engineering reproducibility: Exact prompt templates and JSON schemas not provided, affecting replication attempts
- Context window constraints: No specific length thresholds or segmentation strategies provided for handling long documents
- Zero-shot vs. few-shot comparison: Experiments use zero-shot prompting without exploring potential performance gains from few-shot examples

## Confidence
- **High confidence** in core finding that LLM-based methods significantly outperform traditional approaches (85.5% F1 vs. 76.7%)
- **Medium confidence** in mechanism claims regarding task reframing and index-based grounding, lacking direct corpus validation
- **Medium confidence** in dataset difficulty characterization, partially validated against broader alignment challenges

## Next Checks
1. **Ablation study on indexing**: Run alignment pipeline with and without explicit sentence indexing on same document pairs to quantify hallucination reduction benefit
2. **Model sensitivity test**: Compare Gemini vs. GPT performance across multiple many-to-many alignment subsets to validate model selection impact (12+ percentage point differences observed)
3. **Context window boundary analysis**: Systematically test document length limits by creating progressively longer parallel text pairs to determine when context overflow occurs and evaluate segmentation strategies