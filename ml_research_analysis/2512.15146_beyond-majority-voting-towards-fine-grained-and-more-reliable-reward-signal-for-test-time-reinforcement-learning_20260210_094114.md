---
ver: rpa2
title: 'Beyond Majority Voting: Towards Fine-grained and More Reliable Reward Signal
  for Test-Time Reinforcement Learning'
arxiv_id: '2512.15146'
source_url: https://arxiv.org/abs/2512.15146
tags:
- scope
- time
- subgroup
- confidence
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of sparse and unreliable reward
  signals in test-time reinforcement learning (TTRL) for language models, where majority
  voting often leads to confirmation bias and insufficient supervision. The authors
  propose SCOPE, a framework that integrates step-wise confidence weighting and dynamic
  subgroup partitioning.
---

# Beyond Majority Voting: Towards Fine-grained and More Reliable Reward Signal for Test-Time Reinforcement Learning

## Quick Facts
- **arXiv ID**: 2512.15146
- **Source URL**: https://arxiv.org/abs/2512.15146
- **Reference count**: 40
- **Primary result**: SCOPE framework improves TTRL performance with 13.1% relative gain on AIME 2025 and 8.1% on AMC over baselines

## Executive Summary
This paper addresses a critical challenge in test-time reinforcement learning (TTRL) for language models: the unreliability of reward signals when using majority voting to evaluate reasoning paths. The authors identify that majority voting often leads to confirmation bias and insufficient supervision, particularly when correct answers are rare or reasoning paths are diverse. To overcome these limitations, they propose SCOPE, a framework that provides more fine-grained and reliable reward signals by integrating step-wise confidence weighting with dynamic subgroup partitioning.

SCOPE works by first evaluating the confidence of each reasoning step, then partitioning model outputs into subgroups to derive local consensus. This approach prioritizes high-confidence reasoning paths while maintaining diversity in supervision targets. The framework demonstrates consistent improvements across multiple models and benchmarks, showing that better reward signal quality can significantly enhance TTRL performance without requiring additional human annotation.

## Method Summary
The SCOPE framework addresses sparse and unreliable reward signals in TTRL by introducing two key innovations: step-wise confidence weighting and dynamic subgroup partitioning. Instead of relying solely on majority voting, SCOPE evaluates the confidence of each reasoning step and uses this information to weight the importance of different reasoning paths. The framework then partitions model outputs into subgroups and derives local consensus within each subgroup, providing more diverse and fine-grained supervision targets. This approach helps mitigate confirmation bias that typically arises from standard majority voting while ensuring that high-confidence reasoning paths receive appropriate emphasis during training.

## Key Results
- SCOPE achieves 13.1% relative improvement over TTRL baselines on AIME 2025 benchmark
- SCOPE demonstrates 8.1% relative gain on AMC compared to existing TTRL approaches
- The framework shows consistent improvements across multiple language models and reasoning tasks

## Why This Works (Mechanism)
SCOPE addresses the fundamental limitation of majority voting in TTRL by recognizing that uniform weighting of all reasoning paths ignores the varying quality and confidence levels across different steps. By incorporating step-wise confidence scores, the framework can prioritize reasoning paths that demonstrate higher reliability while still maintaining diversity through subgroup partitioning. This dual approach ensures that the reward signal is both more reliable (through confidence weighting) and more comprehensive (through diverse subgroup consensus), leading to better learning outcomes than either approach alone.

## Foundational Learning
- **Test-time reinforcement learning**: Training language models during inference to improve reasoning performance without retraining. Needed because traditional fine-tuning cannot adapt to specific test instances.
- **Majority voting limitations**: Standard approach where the most common answer is selected, but this can reinforce incorrect consensus when the majority is wrong. Quick check: Verify if correct answers appear as minority opinions in datasets.
- **Confidence weighting**: Assigning importance scores to reasoning steps based on their predicted reliability. Needed to differentiate between high-quality and low-quality reasoning paths. Quick check: Compare performance with and without confidence weighting.
- **Subgroup partitioning**: Dividing model outputs into smaller groups to derive local consensus rather than global majority. Needed to maintain diversity and avoid over-consolidation around potentially incorrect majority views. Quick check: Measure diversity metrics across subgroups.
- **Reward signal reliability**: The quality and consistency of feedback provided to models during TTRL. Needed because unreliable rewards lead to poor learning outcomes. Quick check: Track correlation between reward signals and actual reasoning quality.
- **Confirmation bias in voting**: The tendency for majority voting to reinforce existing incorrect beliefs when wrong answers dominate. Needed to understand why simple majority voting fails in many reasoning scenarios. Quick check: Analyze cases where majority is incorrect.

## Architecture Onboarding
**Component Map**: Input reasoning paths → Confidence scorer → Subgroup partitioner → Local consensus calculator → Weighted reward aggregator → Updated model parameters

**Critical Path**: The most time-critical path is from confidence scoring through subgroup partitioning to local consensus calculation, as these steps must be completed before reward aggregation can occur.

**Design Tradeoffs**: The framework trades computational overhead (multiple subgroup evaluations) for improved reward signal quality. Authors chose 10-30% subgroup sampling as a balance between diversity and efficiency, though optimal subgroup size may vary by task.

**Failure Signatures**: The system may fail when confidence scores are poorly calibrated, when subgroups are too small to form meaningful consensus, or when the correct answer is genuinely rare across all subgroups. Performance degradation is most likely on datasets with highly imbalanced answer distributions.

**First Experiments**:
1. Ablation study comparing SCOPE with only confidence weighting versus only subgroup partitioning to isolate individual contributions
2. Evaluation on a dataset where correct answers are known to be minority opinions to test robustness
3. Application to non-mathematical reasoning tasks (e.g., scientific reasoning) to assess generalizability

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Scalability concerns when applying dynamic subgroup partitioning to extremely large model cohorts or resource-constrained environments
- Sensitivity of optimal subgroup size to dataset characteristics, potentially limiting generalizability
- Inheritance of majority voting limitations when initial consensus is wrong or correct answers are genuinely rare

## Confidence
- **High confidence**: Effectiveness of confidence-weighted aggregation over uniform majority voting (13.1% gain on AIME 2025, 8.1% on AMC)
- **Medium confidence**: SCOPE provides "fine-grained and diverse supervision targets" with evidence but requires further validation
- **Medium confidence**: SCOPE mitigates confirmation bias is empirically demonstrated but not exhaustively proven

## Next Checks
1. Conduct ablation studies to isolate the individual contributions of confidence weighting versus subgroup partitioning to total performance gains
2. Test SCOPE's robustness on datasets with highly imbalanced answer distributions where the correct answer represents a small minority
3. Evaluate SCOPE's performance when applied to reasoning tasks outside mathematics, such as scientific reasoning or commonsense question answering, to assess generalizability