---
ver: rpa2
title: Knowledge Graph Enhanced Generative Multi-modal Models for Class-Incremental
  Learning
arxiv_id: '2503.18403'
source_url: https://arxiv.org/abs/2503.18403
tags:
- learning
- knowledge
- graph
- text
- classes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses catastrophic forgetting in class-incremental
  learning by proposing KG-GMM, a method that combines knowledge graphs with generative
  multi-modal models. The approach builds an evolving knowledge graph throughout learning,
  using relationships between classes to enhance differentiation and provide more
  detailed image descriptions.
---

# Knowledge Graph Enhanced Generative Multi-modal Models for Class-Incremental Learning

## Quick Facts
- arXiv ID: 2503.18403
- Source URL: https://arxiv.org/abs/2503.18403
- Authors: Xusheng Cao; Haori Lu; Linlan Huang; Fei Yang; Xialei Liu; Ming-Ming Cheng
- Reference count: 40
- Primary result: KG-GMM achieves state-of-the-art results on conventional and few-shot class-incremental learning benchmarks by combining knowledge graphs with generative multi-modal models

## Executive Summary
This paper addresses catastrophic forgetting in class-incremental learning by proposing KG-GMM, a method that combines knowledge graphs with generative multi-modal models. The approach builds an evolving knowledge graph throughout learning, using relationships between classes to enhance differentiation and provide more detailed image descriptions. During inference, it leverages the knowledge graph to locate specific categories through relationship analysis in generated text. Experiments show KG-GMM achieves state-of-the-art results on both conventional and few-shot class-incremental learning benchmarks, effectively preserving knowledge and reducing forgetting through structured relational information.

## Method Summary
KG-GMM builds an evolving knowledge graph throughout the learning process, extracting subgraphs from ConceptNet to represent relationships between classes. For each new class, it selects unique relations that distinguish it from previously learned classes. The method trains a linear adapter to align image embeddings with LLM input space, formatting target text as serialized Knowledge Graph triplets. During inference, the model generates text descriptions, extracts triplets, and uses the knowledge graph to search for the most likely class entity. The final prediction is made by concatenating the located entity with the generated text and computing cosine similarity against class embeddings.

## Key Results
- Achieves state-of-the-art performance on conventional CIL benchmarks (Tiny-ImageNet, ImageNet-R)
- Demonstrates superior results on few-shot class-incremental learning benchmarks (CIFAR100, Mini-ImageNet)
- Effectively preserves knowledge and reduces catastrophic forgetting through structured relational information
- Shows robustness across both exemplar-free and few-shot learning scenarios

## Why This Works (Mechanism)
The approach leverages structured knowledge to provide semantic context that enhances the generative model's ability to distinguish between similar classes. By formatting class descriptions as knowledge graph triplets, the model learns to generate text that explicitly captures relational properties of objects. The knowledge graph acts as a semantic scaffold that helps the model maintain class-specific information across incremental learning sessions, reducing interference between similar classes. The KG-based inference mechanism provides an additional semantic matching layer that complements visual similarity, making predictions more robust to visual ambiguity.

## Foundational Learning
- **Knowledge Graph Construction**: Understanding how to extract and structure relational information from ConceptNet using ZSL-KG protocols is essential for creating the semantic scaffold that distinguishes classes.
- **Generative Multi-modal Models**: Familiarity with models like MiniGPT-4, LLaVA, or BLIP-2 is necessary to understand the base framework and how the linear adapter integrates with frozen vision encoders and LLMs.
- **Class-Incremental Learning**: Knowledge of catastrophic forgetting and exemplar-free learning scenarios is crucial to appreciate the problem KG-GMM addresses and the significance of its performance gains.
- **Triplet Extraction and Parsing**: Understanding how to reliably convert natural language descriptions into structured `(head, relation, tail)` format is critical for the KG-based inference mechanism to function correctly.
- **Cosine Similarity Search**: The final classification relies on computing similarity between concatenated entity-text embeddings, requiring understanding of embedding spaces and similarity metrics.

## Architecture Onboarding

**Component Map**
MiniGPT-4 (frozen) -> Linear Adapter -> LLM (frozen) -> KG Triplet Generator -> Knowledge Graph (ConceptNet) -> Triplet Parser -> Entity Lookup -> Similarity Search

**Critical Path**
Image -> Visual Encoder -> Linear Adapter (trained) -> LLM -> Generated Text -> Triplet Parser -> KG Lookup -> Entity Concatenation -> Similarity Search -> Final Prediction

**Design Tradeoffs**
- Using frozen pre-trained models preserves strong vision-language alignment but limits fine-tuning flexibility
- KG-based inference adds semantic discrimination but depends on quality and distinctiveness of ConceptNet relations
- Single linear adapter is parameter-efficient but may have limited capacity for complex cross-modal alignment

**Failure Signatures**
- Low triplet parsing accuracy indicates LLM is not generating KG-compliant text
- KG lookup misses suggest relations are not distinctive enough or LLM hallucinates non-existent relations
- Similarity search failures may indicate embedding misalignment between generated text and class embeddings

**3 First Experiments**
1. Train the linear adapter with KG-formatted targets and evaluate generation quality without KG inference
2. Implement triplet parsing and measure extraction accuracy on generated text
3. Test KG-based inference in isolation using ground-truth class descriptions to verify the semantic matching mechanism

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness depends critically on the quality and distinctiveness of relations extracted from ConceptNet
- Assumes ConceptNet contains adequate relational information for distinguishing between similar classes
- May not perform well for domains where classes have semantically overlapping properties with few distinguishing relations
- The paper lacks ablation studies quantifying the exact contribution of KG versus the generative model itself

## Confidence
- **High Confidence**: Experimental results demonstrating state-of-the-art performance on standard CIL benchmarks are well-documented and reproducible
- **Medium Confidence**: Effectiveness of knowledge graph integration in reducing catastrophic forgetting is supported by experiments
- **Low Confidence**: Specific implementation details for KG triplet parsing and "similar classes" determination are underspecified

## Next Checks
1. Implement the triplet extraction mechanism and evaluate its accuracy on a held-out set of generated descriptions to ensure reliable conversion to KG-compatible format
2. Conduct an ablation study removing the knowledge graph component to quantify the performance drop and isolate the contribution of KG-based inference
3. Visualize the constructed knowledge graphs for several classes to verify that the selected relations provide meaningful semantic distinctions between classes within each task