---
ver: rpa2
title: 'Hierarchical structure understanding in complex tables with VLLMs: a benchmark
  and experiments'
arxiv_id: '2511.08298'
source_url: https://arxiv.org/abs/2511.08298
tags:
- table
- tables
- structure
- vllms
- hierarchical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CHiTab, a benchmark for evaluating Vision
  Large Language Models (VLLMs) on understanding hierarchical table structures in
  scientific documents. CHiTab filters complex tables from PubTables-1M containing
  hierarchical header relationships and converts them into QA tasks with single numeric
  answers.
---

# Hierarchical structure understanding in complex tables with VLLMs: a benchmark and experiments

## Quick Facts
- **arXiv ID:** 2511.08298
- **Source URL:** https://arxiv.org/abs/2511.08298
- **Reference count:** 20
- **Primary result:** CHiTab benchmark shows VLLMs achieve 35-50% zero-shot accuracy on hierarchical table structure understanding, with fine-tuning improving performance to 76%.

## Executive Summary
This paper introduces CHiTab, a benchmark for evaluating Vision Large Language Models (VLLMs) on understanding hierarchical table structures in scientific documents. CHiTab filters complex tables from PubTables-1M containing hierarchical header relationships and converts them into QA tasks with single numeric answers. The authors test four state-of-the-art VLLMs using various prompt strategies and find that zero-shot performance on sub-heading questions averages around 50%, while value-level questions are more challenging at 35-45%. They also conduct a human baseline study with 29 participants, achieving 63% accuracy. Fine-tuning Qwen2.5-VL-7B with QLoRA significantly improves accuracy to 76%. The study highlights that while VLLMs can partially understand table hierarchies, targeted fine-tuning and architectural improvements are needed to close the gap with human performance.

## Method Summary
The CHiTab benchmark is constructed from PubTables-1M by filtering tables with hierarchical header relationships and converting them into QA tasks. Two task types are defined: Sub-heading QA (SHQA) counts direct children under a heading, while Value-level QA (VLQA) counts leaf columns under a heading. Four VLLMs are evaluated (Granite Vision 3.2 2B, Qwen2.5-VL-7B, Mistral Small 3.1 24B, Gemma3 27B) using eight different prompt styles. Fine-tuning is performed via QLoRA on Qwen2.5-VL-7B with r=8, lora_alpha=16, lora_dropout=0.05 for one epoch. The dataset contains 18,909 training, 2,325 validation, and 2,428 test tables.

## Key Results
- Zero-shot VLLM accuracy on sub-heading questions averages 50%, while value-level questions drop to 35-45%
- Granite Vision 3.2 2B matches or outperforms larger models on sub-heading tasks, suggesting architectural optimization matters more than scale
- Fine-tuning Qwen2.5-VL-7B with QLoRA improves accuracy from 43.7% to 75.8%, a 32% absolute gain
- Human baseline (29 participants) achieves 63% accuracy, highlighting the difficulty of the task
- Prompt formulation significantly impacts performance, with variations up to 20 percentage points observed

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** VLLMs can perform partial hierarchical table understanding through learned spatial-semantic correspondence, but this capability emerges implicitly rather than through explicit structural encoding.
- **Mechanism:** Models trained on diverse document images develop attention patterns that recognize vertical alignment and horizontal containment relationships, enabling inference of parent-child header hierarchies without explicit structural modules.
- **Core assumption:** The spatial attention mechanisms learned during general pre-training transfer to structured document reasoning tasks.
- **Evidence anchors:**
  - [abstract]: "generic VLLMs, not explicitly designed for understanding the structure of tables, can perform this task"
  - [section 4.2]: Zero-shot models achieve 50%+ on sub-heading questions, indicating partial capability
  - [corpus]: Related work shows VLLMs struggle with "intricate layouts" without targeted approaches (WikiMixQA, Chemical Tables benchmarks)

### Mechanism 2
- **Claim:** Prompt formulation significantly alters model performance on structural reasoning tasks, with variations up to 20 percentage points, indicating instability in how models ground structural concepts.
- **Mechanism:** Different phrasings activate different learned associations and reasoning pathways; certain formulations may better align the task with the model's instruction-tuning distribution.
- **Core assumption:** Models have not internalized stable representations of structural concepts like "sub-heading" or "value-level column."
- **Evidence anchors:**
  - [abstract]: "experimenting with various prompt formats and writing styles"
  - [section 4.1, Table 4]: Qwen shows 20% gap between "Reward" (62.3%) and "Polite" (42.6%) prompts for sub-heading questions
  - [corpus]: Limited direct evidence; prompt sensitivity is underexplored in table-specific VLLM literature

### Mechanism 3
- **Claim:** Targeted fine-tuning on domain-specific hierarchical structures yields substantial performance gains (+32% absolute), demonstrating that general pre-training underrepresents table-specific spatial reasoning patterns.
- **Mechanism:** QLoRA adaptation adjusts low-rank parameters to encode the specific spatial heuristics and counting operations required by the benchmark, improving both sub-heading and value-level reasoning.
- **Core assumption:** The training set (18,909 tables) provides sufficient coverage of hierarchical patterns for effective adaptation.
- **Evidence anchors:**
  - [abstract]: "Fine-tuning Qwen2.5-VL-7B with QLoRA significantly improves accuracy to 76%"
  - [section 4.3]: Qwen improves from 43.7% average to 75.8%, outperforming models 3-4× larger
  - [corpus]: Neighbor paper (Orthogonal Hierarchical Decomposition) confirms LLMs struggle with "multi-level headers" without specialized approaches

## Foundational Learning

- **Concept: Vision-Language Spatial Alignment**
  - **Why needed here:** Understanding how VLLMs map 2D visual layouts to semantic structure (headers, cells, hierarchies) is prerequisite for diagnosing failures on complex tables.
  - **Quick check question:** Can you explain why a model might correctly OCR all text but fail to identify which cells are children of a spanning header?

- **Concept: Hierarchical Containment in 2D Layouts**
  - **Why needed here:** The benchmark defines parent-child relationships via vertical alignment and horizontal containment—grasping this spatial logic is essential for understanding both the task and model limitations.
  - **Quick check question:** Given a spanning header that covers columns 1-4 and a lower header covering columns 2-3, which is the parent and why?

- **Concept: Prompt Sensitivity in Instruction-Tuned Models**
  - **Why needed here:** The 20% variance across prompt styles indicates that structural reasoning is not robustly encoded; understanding prompt instability is critical for reliable deployment.
  - **Quick check question:** Why might a "polite" prompt underperform a "Reward" prompt by 20%, and what does this suggest about the model's internal task representation?

## Architecture Onboarding

- **Component map:** Input layer: Table image + text prompt → Vision encoder: Processes image into visual tokens → Vision-language projector: Aligns visual and text embeddings → LLM backbone: Performs reasoning over combined representation → Output: Single numeric answer (count)

- **Critical path:** 1. Image resolution and quality (input) → Vision encoder feature extraction 2. Spatial attention patterns → Header cell localization 3. Cross-modal reasoning → Hierarchical relationship inference 4. Counting mechanism → Numeric answer generation

- **Design tradeoffs:**
  - Model size vs. efficiency: Granite (2B) matches larger models on sub-heading task, suggesting architectural optimization matters more than scale for some structural tasks
  - Zero-shot vs. fine-tuned: 32% accuracy gain from QLoRA justifies adaptation cost for production deployments
  - Consistency vs. accuracy: Mistral achieves best accuracy (48.1%) but lowest consistency (55%); Granite is most consistent but least accurate

- **Failure signatures:**
  - Tables with extensive spanning cells and implicit borders (Figure 4)
  - Value-level questions requiring aggregation across multiple header levels
  - Models produce inconsistent answers across repetitions (Mistral) or fail to handle linguistic variations (all models to some degree)

- **First 3 experiments:**
  1. **Baseline replication**: Test all four VLLMs on the CHiTab validation set with the base prompt style to establish performance benchmarks before any modifications.
  2. **Prompt stability analysis**: For a fixed sample of 50 tables, run each prompt style 10 times per model to quantify variance and identify which formulations produce most stable outputs.
  3. **Error categorization by layout type**: Manually annotate 100 failed predictions by root cause (OCR error, spatial misalignment, counting error, hierarchy confusion) to prioritize architectural improvements.

## Open Questions the Paper Calls Out

- **Open Question 1:** What specific linguistic or attention mechanisms cause VLLMs to exhibit extreme sensitivity to prompt phrasing in structural tasks?
  - **Basis in paper:** [explicit] The authors report in Section 4.1 that minor prompt variations, such as adding a "Reward" versus a "Polite" phrase, caused accuracy swings of nearly 20 percentage points, leaving the behavior unexplained.
  - **Why unresolved:** The paper identifies the instability and high variance but does not conduct an ablation study to determine if the issue stems from token probability shifts or attention distraction.
  - **What evidence would resolve it:** An analysis of attention maps comparing "successful" and "failed" prompt variations to identify where the model's focus diverges.

- **Open Question 2:** Does the hierarchical understanding demonstrated on scientific tables in CHiTab transfer to other complex layouts, such as financial reports or forms?
  - **Basis in paper:** [inferred] The benchmark is derived exclusively from PubTables-1M (scientific articles), yet the Related Work section notes that financial tables pose distinct challenges due to irregular layouts and density.
  - **Why unresolved:** The evaluation is restricted to the scientific domain, leaving the model's ability to generalize to other visual structures untested.
  - **What evidence would resolve it:** Cross-domain evaluation of the fine-tuned Qwen2.5-VL model on a dataset of financial or heterogeneous industrial tables with hierarchical headers.

- **Open Question 3:** Is there a fundamental trade-off between reasoning accuracy and output consistency in current VLLMs?
  - **Basis in paper:** [inferred] In Section 4.4, the most accurate model (Mistral) showed the lowest consistency (55%), while the least accurate model (Granite) showed perfect consistency (100%), suggesting a possible stability-performance tension.
  - **Why unresolved:** The study compares models with different sizes and architectures, making it unclear if the inconsistency is a feature of higher reasoning capacity or specific implementation defaults.
  - **What evidence would resolve it:** A controlled study measuring consistency across different temperature settings and model sizes within the same model family.

## Limitations

- **Dataset representativeness uncertainty:** CHiTab benchmark constructed from only 2.5% of PubTables-1M, selected for hierarchical complexity, limiting generalizability to simpler tables or different domains.
- **Prompt sensitivity without mechanistic explanation:** While documenting 20% performance swings across prompt styles, the paper does not investigate why certain formulations work better, suggesting models may exploit superficial cues.
- **Human baseline methodological limitations:** 29-participant study reports 63% accuracy, but details on inter-rater reliability, time constraints, and training on hierarchical table interpretation are not specified.

## Confidence

- **High confidence:** The empirical finding that zero-shot VLLMs achieve only 35-45% accuracy on value-level questions is robust and well-supported by test results.
- **Medium confidence:** The claim that prompt formulation significantly impacts performance is supported by 20% variance data, but underlying mechanisms remain unexplained.
- **Low confidence:** The assertion that "generic VLLMs can perform this task" is overstated given the 35-50% accuracy range; the paper overstates model capability relative to human performance.

## Next Checks

1. **Cross-domain generalization test:** Evaluate the fine-tuned Qwen2.5-VL-7B model on tables from non-scientific domains (financial reports, government data) to assess whether hierarchical understanding transfers beyond the training distribution.

2. **Prompt stability quantification:** Systematically measure answer variance across 10 repetitions per prompt-table pair for all eight prompt styles to quantify whether performance differences reflect genuine reasoning or output stochasticity.

3. **Error mode decomposition by layout complexity:** Classify 200 model failures into OCR errors, spatial misalignment errors, counting errors, and hierarchy inference errors, then correlate error types with table complexity metrics (number of header levels, spanning cell density) to identify specific architectural weaknesses.