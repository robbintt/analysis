---
ver: rpa2
title: 'EnAnchored-X2X: English-Anchored Optimization for Many-to-Many Translation'
arxiv_id: '2509.19770'
source_url: https://arxiv.org/abs/2509.19770
tags:
- data
- translation
- en2x
- language
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the underperformance of large language models
  (LLMs) in direct non-English (x2x) translation, where models exhibit significantly
  lower quality compared to English-centric (en2x) translation despite strong overall
  multilingual capabilities. The core method, EnAnchored-X2X, leverages models' established
  English-to-x (en2x) translation strengths by extending English parallel corpora
  into omnidirectional datasets through English-Anchored x2x Translation (EAxT), where
  both source text and its English reference are provided during generation.
---

# EnAnchored-X2X: English-Anchored Optimization for Many-to-Many Translation

## Quick Facts
- **arXiv ID**: 2509.19770
- **Source URL**: https://arxiv.org/abs/2509.19770
- **Reference count**: 27
- **Primary result**: Llama2 model shows +7 BLEURT points across 72 x2x directions using EnAnchored-X2X method

## Executive Summary
Large language models exhibit strong English-centric translation capabilities but significantly underperform in direct non-English-to-non-English (x2x) translation, often requiring English pivot translation that introduces compounding errors. This paper introduces EnAnchored-X2X, a method that leverages models' established English-to-x translation strengths by extending English parallel corpora into omnidirectional datasets through English-Anchored x2x Translation (EAxT). The approach provides both source text and English reference during generation, combined with English-referenced quality evaluation (EAxE) for effective data filtering and preference optimization.

## Method Summary
EnAnchored-X2X addresses the x2x translation gap by converting existing English-centric parallel corpora into bidirectional datasets where both source text and its English reference are available during generation. The method employs English-Anchored x2x Translation (EAxT) for synthetic data generation, followed by English-referenced quality evaluation (EAxE) that transforms x2x evaluation into en2x evaluation for effective filtering. The approach then applies preference optimization using synthetic data, demonstrating that models can learn x2x translation capabilities while preserving their en2x strengths. The method shows robust performance across three distinct 7B-parameter base models (Llama2, TowerBase, Qwen2.5) and achieves substantial improvements over pivot translation and fine-tuning baselines.

## Key Results
- Llama2 model achieves +7 BLEURT points across 72 x2x translation directions
- Sustained enhancements in en2x performance despite focusing solely on x2x optimization
- Outperforms baseline methods including pivot translation and fine-tuning on human-annotated FLORES data

## Why This Works (Mechanism)
The method exploits the strong English-centric translation capabilities of LLMs by using English as an anchor point for non-English translation. By providing both source text and English reference during generation, the model can leverage its established English-to-target language skills to improve non-English-to-non-English translation. The English-referenced evaluation proxy enables effective quality assessment of x2x translations by converting them into comparable en2x evaluations, allowing for systematic filtering and optimization of synthetic data.

## Foundational Learning
- **English-centric translation strengths**: LLMs typically achieve high performance on en2x directions due to abundant training data, making English a natural anchor point for extending capabilities to x2x translation
- **Synthetic data generation for translation**: Creating large-scale training data through model-generated translations enables scaling to many language pairs without requiring expensive human annotation
- **Preference optimization in translation**: Using quality-ranked data for fine-tuning improves model performance by focusing on high-quality examples rather than all generated data indiscriminately

## Architecture Onboarding
**Component map**: Synthetic Data Generation (EAxT) -> Quality Evaluation (EAxE) -> Preference Optimization -> Final Model
**Critical path**: The pipeline flows from English-Anchored x2x Translation through English-referenced evaluation filtering to preference-based optimization, with each stage building on the previous to improve translation quality
**Design tradeoffs**: Heavy reliance on English as an anchor limits applicability to language pairs where English may not serve as an effective semantic bridge, but enables leveraging abundant English-centric training data
**Failure signatures**: Poor performance on linguistically distant language pairs where English introduces semantic drift, or when synthetic data generation introduces significant noise that propagates through the optimization pipeline
**First experiments**: 1) Test English-referenced evaluation proxy accuracy by comparing human judgments of x2x vs en2x translations, 2) Validate synthetic data quality by measuring BLEURT improvements after filtering, 3) Evaluate model performance on low-resource language pairs to assess scalability limits

## Open Questions the Paper Calls Out
None specified in the provided materials.

## Limitations
- Heavy reliance on English as a translation anchor may limit effectiveness for language pairs with significant semantic drift when using English as pivot
- Performance on extremely low-resource languages (fewer than 10K parallel sentences) remains unclear from reported results
- Synthetic data generation process could introduce noise or hallucinated content that propagates through the optimization pipeline

## Confidence
- X2X performance improvements: High confidence based on consistent gains across multiple model families and language directions
- En2x performance preservation: Medium confidence, as results show sustained quality but evaluation scope is limited to tested language pairs
- Generalizability across models: High confidence, with demonstrated effectiveness on three distinct 7B parameter models from different training paradigms
- Quality of synthetic data: Medium confidence, as filtering mechanism shows effectiveness but underlying data generation process is not extensively validated

## Next Checks
1. Evaluate performance on language pairs involving linguistically distant languages (e.g., Japanese-Chinese, Arabic-Swahili) where English may not serve as an effective semantic bridge
2. Test the approach with smaller model sizes (3B parameters) to assess scalability and performance degradation patterns
3. Conduct human evaluation studies comparing translations from EnAnchored-X2X against baseline methods across different domain types (news, literature, technical documentation) to validate metric-based findings