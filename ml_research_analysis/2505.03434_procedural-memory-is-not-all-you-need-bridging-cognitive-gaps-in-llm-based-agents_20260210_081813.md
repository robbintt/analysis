---
ver: rpa2
title: 'Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in LLM-Based
  Agents'
arxiv_id: '2505.03434'
source_url: https://arxiv.org/abs/2505.03434
tags:
- llms
- memory
- learning
- procedural
- environments
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper argues that Large Language Models (LLMs) are fundamentally
  limited by their reliance on procedural memory, which prevents them from adapting
  to complex, unpredictable environments. The authors propose a modular architecture
  that augments LLMs with dedicated semantic and associative memory systems to enable
  adaptive intelligence in "wicked" learning environments where rules shift and feedback
  is ambiguous.
---

# Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in LLM-Based Agents

## Quick Facts
- arXiv ID: 2505.03434
- Source URL: https://arxiv.org/abs/2505.03434
- Reference count: 38
- This paper argues that LLMs' reliance on procedural memory fundamentally limits their ability to adapt to complex, unpredictable environments, proposing a modular architecture with dedicated semantic and associative memory systems.

## Executive Summary
This paper argues that Large Language Models (LLMs) are fundamentally limited by their reliance on procedural memory, which prevents them from adapting to complex, unpredictable environments. The authors propose a modular architecture that augments LLMs with dedicated semantic and associative memory systems to enable adaptive intelligence in "wicked" learning environments where rules shift and feedback is ambiguous. The core idea is to separate agentic learners (handling semantic-associative reasoning) from agentic actors (LLMs handling procedural execution), allowing each component to specialize in its respective cognitive function. While no specific performance metrics are provided, the paper illustrates through examples how this modular approach could enable agents to maintain persistent state, perform compositional reasoning, and dynamically associate actions with outcomes across sessions. The authors emphasize that this architectural shift is necessary for developing autonomous agents capable of real-world decision-making beyond narrow procedural expertise.

## Method Summary
The paper proposes a modular architecture that separates agentic learners (handling semantic-associative reasoning) from agentic actors (LLMs handling procedural execution). The semantic memory system maintains persistent state and handles compositional reasoning, while the associative memory system dynamically links actions to outcomes across sessions. The procedural memory component remains within the LLM for execution of learned sequences. This separation allows each cognitive function to specialize, theoretically enabling better adaptation to environments with shifting rules and ambiguous feedback.

## Key Results
- LLMs' reliance on procedural memory prevents adaptation in environments with shifting rules and delayed feedback
- Modular architecture with dedicated semantic and associative memory systems could enable adaptive intelligence in "wicked" learning environments
- Separation of agentic learners from agentic actors allows specialized handling of semantic-associative reasoning versus procedural execution

## Why This Works (Mechanism)
The paper argues that current LLM architectures conflate different types of memory, leading to fundamental limitations in handling complex, dynamic environments. By separating semantic, associative, and procedural memory systems, each component can specialize in its respective cognitive function. This allows agents to maintain persistent state (semantic memory), dynamically associate actions with outcomes (associative memory), and execute learned sequences (procedural memory). The proposed architecture addresses the "wicked learning environment" problem where rules change and feedback is ambiguous by enabling agents to reason compositionally and adapt their behavior based on persistent understanding rather than just memorized procedures.

## Foundational Learning
- Procedural memory basics - why needed: Understanding how LLMs currently rely on procedural memory for task execution
  quick check: Can identify current LLM limitations in handling shifting rules and ambiguous feedback
- Semantic memory - why needed: Maintaining persistent state and compositional reasoning across sessions
  quick check: Can distinguish between procedural execution and semantic understanding in current LLM behavior
- Associative memory - why needed: Dynamically linking actions to outcomes for adaptive learning
  quick check: Can recognize the importance of feedback timing and ambiguity in learning environments
- Wicked learning environments - why needed: Understanding contexts where rules shift and feedback is ambiguous
  quick check: Can identify examples of wicked versus kind learning environments
- Cognitive architecture separation - why needed: Recognizing that different memory systems serve distinct functions
  quick check: Can explain the theoretical benefits of separating cognitive functions

## Architecture Onboarding
- Component map: Agentic Learners (Semantic + Associative Memory) <-> Agentic Actors (Procedural Memory via LLM)
- Critical path: Semantic Memory maintains persistent state -> Associative Memory links actions to outcomes -> Procedural Memory executes learned sequences
- Design tradeoffs: Specialization vs. integration overhead, complexity vs. adaptability, computational cost vs. cognitive capability
- Failure signatures: Inability to maintain state across sessions, poor compositional reasoning, failure to adapt to shifting rules
- First experiments:
  1. Test semantic memory persistence across sessions with rule changes
  2. Evaluate associative memory's ability to link delayed outcomes to actions
  3. Compare procedural execution in modular vs. monolithic architectures

## Open Questions the Paper Calls Out
None

## Limitations
- Claims about LLM limitations remain largely theoretical without empirical validation
- Proposed modular architecture is untested and conceptual
- Uncertainty whether wicked learning environment problem is fundamental or due to current prompting strategies
- Potential integration challenges and computational overhead from maintaining multiple specialized memory systems

## Confidence
- Medium - The reasoning about LLM limitations is sound but lacks empirical support
- Low - The proposed solution is theoretically plausible but entirely conceptual without implementation details or performance data

## Next Checks
1. Implementing the proposed modular architecture and testing it against baseline LLMs in environments with shifting rules and delayed feedback
2. Conducting controlled experiments comparing single-model approaches with multi-system architectures on tasks requiring persistent state management and compositional reasoning
3. Measuring the computational overhead and latency implications of maintaining separate semantic, associative, and procedural memory systems in real-time agent applications