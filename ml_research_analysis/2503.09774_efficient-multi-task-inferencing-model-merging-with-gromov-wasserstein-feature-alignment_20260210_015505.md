---
ver: rpa2
title: 'Efficient Multi-Task Inferencing: Model Merging with Gromov-Wasserstein Feature
  Alignment'
arxiv_id: '2503.09774'
source_url: https://arxiv.org/abs/2503.09774
tags:
- merging
- gw-smm
- accuracy
- task
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GW-SMM, a novel approach to model merging
  that leverages the Gromov-Wasserstein distance to align feature distributions across
  multiple automated scoring models. The method addresses the challenge of deploying
  separate neural networks for each assessment task, which increases storage demands
  and computational costs in educational settings.
---

# Efficient Multi-Task Inferencing: Model Merging with Gromov-Wasserstein Feature Alignment

## Quick Facts
- **arXiv ID**: 2503.09774
- **Source URL**: https://arxiv.org/abs/2503.09774
- **Reference count**: 40
- **Primary result**: GW-SMM achieved 0.6872 micro F1 score vs 0.6271 for GPT-o1-based merging with 50% storage reduction

## Executive Summary
This paper introduces GW-SMM, a novel model merging approach that leverages Gromov-Wasserstein distance to align feature distributions across multiple automated scoring models. The method addresses the challenge of deploying separate neural networks for each assessment task in educational settings by identifying compatible models through structural feature analysis. GW-SMM extracts features from student responses using individual models, quantifies similarity between feature distributions using Gromov-Wasserstein distance, and merges only compatible models by combining shared layers while preserving separate classification heads. The approach demonstrated superior performance compared to both human expert knowledge and GPT-o1-based merging methods across multiple evaluation metrics.

## Method Summary
GW-SMM extracts features from student responses using individual fine-tuned BERT models, then computes Gromov-Wasserstein distances between feature distributions to quantify similarity. Models with smallest pairwise distances are identified as compatible for merging. Compatible models are merged using TIES-MERGING, which aligns feature spaces and prunes redundant parameters while combining shared layers. The resulting unified model retains separate classification heads for each original task, creating a shared feature extractor with task-specific outputs. This strategy reduces storage requirements by half while maintaining scoring accuracy.

## Key Results
- GW-SMM achieved 0.6872 micro F1 score versus 0.6271 for GPT-o1-based merging
- Statistical significance confirmed for micro F1 (p=0.04) and per-label accuracy (p=0.01) improvements
- Storage requirements reduced by 50% without compromising much accuracy
- Outperformed human expert knowledge baseline across all metrics

## Why This Works (Mechanism)

### Mechanism 1: Structural Alignment via Gromov-Wasserstein Distance
GW distance compares internal geometry of feature spaces from different models without requiring same dimensionality, quantifying the cost of deforming one feature distribution's structure to match another. Models with lower pairwise distances are selected for merging, based on the assumption that structurally similar feature representations indicate compatibility.

### Mechanism 2: Shared Feature Extractor with Task-Specific Heads
Merging compatible models by combining layers before the classification head while keeping task-specific heads separate reduces storage/computation while preserving accuracy. Early and middle layers capture generalizable domain features while final classification layers contain task-specific decision boundaries that must remain distinct.

### Mechanism 3: Data-Driven Compatibility Inference
Deriving model compatibility from actual student response features is more robust than relying on human judgment or LLM analysis of task descriptions alone. GW-SMM analyzes learned patterns from student data rather than reading task descriptions, capturing nuanced task relationships based on actual student responses.

## Foundational Learning

- **Concept: Optimal Transport / Wasserstein Distance**
  - **Why needed here**: GW distance is a form of optimal transport. Understanding OT basics (moving "mass" between distributions at minimum cost) is essential to grasp how GW measures distributional similarity.
  - **Quick check question**: How does Wasserstein distance differ from KL-divergence in handling non-overlapping distributions?

- **Concept: Gromov-Wasserstein (GW) Distance**
  - **Why needed here**: This is the core metric. It extends OT to compare distributions in different metric spaces by preserving internal structural relationships rather than direct point-to-point alignment.
  - **Quick check question**: Why prefer GW distance over standard Wasserstein when comparing embeddings from models with different architectures?

- **Concept: Model Merging / Multi-Task Learning (MTL)**
  - **Why needed here**: The paper's goal is efficient MTL via merging. Understanding the motivation (redundancy reduction) and challenge (destructive interference) is critical.
  - **Quick check question**: What is "destructive interference" in multi-task learning, and how might TIES-MERGING mitigate it?

- **Concept: BERT Feature Extraction**
  - **Why needed here**: Implementation uses BERT, extracting features from the final hidden layer. Understanding contextualized embeddings is key to interpreting what "feature distributions" represent.
  - **Quick check question**: From which part of fine-tuned BERT would you extract a single vector for a student's open-ended response?

## Architecture Onboarding

- **Component Map**: Individual Fine-Tuned Models -> Feature Extractor -> GW Distance Calculator -> Similarity Matrix & Merge Planner -> Merger (TIES-MERGING) -> Unified Model with Multiple Heads

- **Critical Path**:
  1. Consistent feature extraction from all individual models
  2. Stable GW distance computation
  3. Merging plan selection maximizing intra-group similarity
  4. Correct TIES-MERGING execution (alignment + pruning)

- **Design Tradeoffs**:
  - Merge Group Size: Paper notes >3 models problematic; GW-SMM finds pairs/trios. Larger groups = more savings but higher interference risk.
  - GW vs. Simpler Metrics: GW is computationally expensive but captures structural alignment potentially superior to CKA or parameter similarity.
  - Data-Driven vs. Knowledge-Driven: GW-SMM requires student response data (privacy constraints); Human/GPT-o1 methods only need task descriptions.

- **Failure Signatures**:
  - NaN/Unstable GW Distances: Small datasets or numerical precision issues in Sinkhorn iterations—check regularization parameter ϵ.
  - Poor Merging Plan: Significant performance drop suggests GW distance missed critical incompatibility or TIES-MERGING was insufficient.
  - Catastrophic Forgetting: Task performance drops to chance level—task was incompatible with group; merge plan was incorrect.

- **First 3 Experiments**:
  1. Reproduce Single Pairwise Merge: Take two models with lowest GW distance, merge via TIES-MERGING, compare against paper's reported metrics and original individual models.
  2. Ablation—Merge Incompatible Models: Deliberately merge two high-GW-distance (dissimilar) models; measure degradation to validate break condition.
  3. Alternative Similarity Baseline: Replace GW distance with CKA or parameter cosine similarity; compare merged performance to assess GW's unique contribution.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation scope limited to only 4 specific open-ended science assessment tasks, raising generalizability questions
- Statistical significance testing focused only on micro F1 and per-label accuracy, leaving other metrics unverified
- No reported computational overhead for GW distance calculations or runtime comparisons between methods

## Confidence

- **High Confidence**: The mechanism of shared feature extractor with task-specific heads (Mechanism 2) - well-established architectural pattern with clear empirical support
- **Medium Confidence**: The effectiveness of Gromov-Wasserstein distance for model compatibility prediction (Mechanism 1) - supported by results but lacks direct ablation comparisons to simpler metrics
- **Medium Confidence**: The superiority of data-driven compatibility inference over description-based methods (Mechanism 3) - novel claim with empirical support but limited task diversity for validation

## Next Checks

1. **Task Diversity Expansion**: Validate GW-SMM performance across at least 10-15 diverse educational tasks spanning multiple subjects (math, humanities, social studies) and response types (explanations, essays, problem-solving) to assess generalizability limits.

2. **GW Distance Ablation Study**: Systematically replace GW distance with simpler similarity metrics (parameter cosine similarity, CKA, Euclidean distance in embedding space) across the same task set to quantify GW's unique contribution to merging success.

3. **Computational Overhead Analysis**: Measure and report wall-clock time and memory requirements for GW distance computation versus baseline merging methods across varying dataset sizes, providing complete efficiency characterization beyond storage savings.