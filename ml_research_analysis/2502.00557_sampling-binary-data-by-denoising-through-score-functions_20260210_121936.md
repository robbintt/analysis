---
ver: rpa2
title: Sampling Binary Data by Denoising through Score Functions
arxiv_id: '2502.00557'
source_url: https://arxiv.org/abs/2502.00557
tags:
- sampling
- noise
- denoising
- distribution
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of sampling from distributions
  over binary data on the Boolean hypercube, extending score-based generative modeling
  approaches from Euclidean spaces to discrete binary settings. The core method involves
  using Bernoulli noise (random sign flips) as a smoothing device instead of Gaussian
  noise.
---

# Sampling Binary Data by Denoising through Score Functions

## Quick Facts
- arXiv ID: 2502.00557
- Source URL: https://arxiv.org/abs/2502.00557
- Reference count: 40
- Primary result: Extends score-based generative modeling to binary data using Bernoulli noise smoothing instead of Gaussian noise

## Executive Summary
This paper develops a framework for sampling from distributions over binary data on the Boolean hypercube using score-based generative modeling approaches adapted for discrete settings. The key innovation is using Bernoulli noise (random sign flips) as a smoothing device instead of Gaussian noise, creating a Tweedie-Miyasawa formula-like connection between optimal denoisers and score functions. The authors introduce discrete Langevin-like Markov chains for sampling and theoretically analyze their convergence properties across different noise levels.

## Method Summary
The method uses Bernoulli noise smoothing where y = x ◦ ε with ε following a Bernoulli distribution with parameter σ(2α). This creates an exponential tilt via exp(αx^⊤y) in the probability mass function. The optimal denoiser under Hamming loss satisfies E[x|y] = (1/α)∇ log qα(y), enabling score learning through supervised denoising. For sampling, two variants of discrete Langevin-like Markov chains are proposed: a one-stage sampler using transition t(y'|y) ∝ exp((1/2)s(y)^⊤(y'−y) − (1/2η)||y'−y||²₂) and a two-stage sampler with an auxiliary variable. Both achieve exponential convergence under regularity conditions on the score function, with the two-stage variant showing improved performance at high noise levels.

## Key Results
- Derivation of a Tweedie-Miyasawa formula-like expression for optimal denoiser: E[x|y] = (1/α)∇ log qα(y)
- Exponential convergence of both one-stage and two-stage samplers under regularity conditions
- Two-stage sampler achieves improved performance at high noise levels with α ≪ 1/√d vs. α ≪ 1/d for one-stage
- Multiple measurements can effectively reduce "effective noise" level from α to mα
- Experiments on synthetic data and binarized MNIST demonstrate fast mixing at appropriate noise levels (α ≈ 0.5)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bernoulli noise smoothing transforms difficult discrete sampling into an easier problem by spreading probability mass on the Boolean hypercube.
- Mechanism: The transformation y = x ◦ ε (random sign flips) creates an exponential tilt via exp(αx^⊤y) in the probability mass function. As α → 0, qα approaches uniform distribution, making navigation easier; as α → ∞, qα → p (original target).
- Core assumption: The smoothed distribution qα has more favorable geometric properties for gradient-based sampling than the original discrete p.
- Evidence anchors: [abstract] "Smoothing holds the key for easing the problem of learning and sampling in high dimensions"; [section 1.1] "As α decreases, the probability mass get more spread out on the hypercube, thus easing the sampling problem, where in the extreme case, α = 0, we arrive at the uniform distribution."
- Break condition: When α is too small (very high noise), denoising becomes unreliable—Wasserstein distance bound degrades as de^(-2α).

### Mechanism 2
- Claim: A binary Tweedie-Miyasawa formula connects the optimal denoiser to the score function, enabling score learning via supervised denoising.
- Mechanism: E[x|y] = (1/α)∇ log qα(y). The score ∇ log qα is well-defined beyond {−1,1}^d (on all of R^d), allowing continuous gradients. The optimal denoiser under Hamming loss is sign(E[x|y]).
- Core assumption: The score function can be accurately learned and is sufficiently smooth (bounded: ||s(y)||_∞ ≤ α, Lipschitz: ||s(y) − s(y')||_∞ ≤ α²||y − y'||₁).
- Evidence anchors: [abstract] "We first derive a TMF-like expression for the optimal denoiser for the Hamming loss, where a score function naturally appears."; [section 2.2, Lemma 2.2] Formal derivation of E[x|y] = (1/α)∇ log qα(y).
- Break condition: Score learning fails if α is too small (weak supervision signal) or training data is insufficient; learned score deviates from true ∇ log qα.

### Mechanism 3
- Claim: Discrete Langevin-like Markov chains achieve exponential convergence to sample from smoothed distributions, with a two-stage variant improving performance at high noise.
- Mechanism: One-stage sampler uses transition t(y'|y) ∝ exp((1/2)s(y)^⊤(y'−y) − (1/2η)||y'−y||²₂). Two-stage sampler adds an auxiliary variable z with Gibbs-style updates, achieving better contraction when α is small.
- Core assumption: Regularity conditions on s (boundedness, Lipschitz continuity) hold; constraint 4β₂de^{2β₁} ≤ 1 for one-stage, 8dβ₂e^{4β₁} ≤ 1 for two-stage.
- Evidence anchors: [abstract] "Sampling noisy binary data is then achieved using a Langevin-like sampler which we theoretically analyze for different noise levels."; [section 3.1, Proposition 3.1] Contractivity proof: W(t(·|y), t(·|z)) ≤ (1 − (1/2)e^{−2/η−β₁})ℓ(y,z).
- Break condition: At low noise (large α), the stationary distribution q' may be far from target q (Prop. 3.2: distance ~ d·√αd for one-stage); sampling "breaks down" as shown in Figure 6(f).

## Foundational Learning

- Concept: **Boolean hypercube distributions**
  - Why needed here: The entire framework operates on {−1,1}^d; understanding how probability mass functions behave on this discrete structure is foundational.
  - Quick check question: Can you explain why qα(y) is defined beyond vertices (for all y ∈ R^d) and why that matters for gradient computation?

- Concept: **Score functions and Tweedie-Miyasawa formula**
  - Why needed here: The core theoretical contribution is deriving a binary analog of TMF; without understanding the Euclidean case (E[x|y] = y + σ²∇ log ν_σ(y)), the binary extension won't make sense.
  - Quick check question: In the Gaussian case, how does the score function relate to optimal denoising, and what changes for Bernoulli noise?

- Concept: **Markov chain convergence (Wasserstein distance, mixing time)**
  - Why needed here: The paper proves exponential convergence using Wasserstein contractivity; understanding these metrics is essential to interpret Propositions 3.1–3.4.
  - Quick check question: What does it mean for a Markov chain to be contractive in Wasserstein distance, and how does the noise level α affect the contraction rate?

## Architecture Onboarding

- Component map: Noise injection -> Score network -> Discrete Langevin sampler -> Denoiser
- Critical path:
  1. Choose noise level α (controls sampling difficulty vs. denoising quality tradeoff)
  2. Train score network on noisy-clean pairs (x, y = x ◦ ε)
  3. Initialize sampler (e.g., random bits)
  4. Run discrete Langevin updates with step-size η = 1/α
  5. Apply sign(·) to continuous expectations for final samples

- Design tradeoffs:
  - **High noise (small α)**: Easy sampling (fast mixing), harder denoising (bound W ≤ de^{−2α})
  - **Low noise (large α)**: Sharp samples but slow mixing or sampler breakdown
  - **One-stage vs. two-stage**: Two-stage better at high noise (requires only α ≪ 1/√d vs. α ≪ 1/d) but more compute per step
  - **Multiple measurements m**: Reduces effective noise to mα but increases sampling cost m×

- Failure signatures:
  - **Sampler stuck**: α too large (low noise); stationary distribution far from target; visible in Figure 6(f)
  - **Denoised samples noisy/blurry**: α too small (high noise) or insufficient training
  - **Slow mixing**: Step-size η not set to 1/α, or α at boundary of convergence conditions

- First 3 experiments:
  1. **Synthetic mixture model validation**: Replicate Figure 1–4 experiments on mixture of two opposite binary vectors with varying β (prior strength) and α; verify Wasserstein bounds and mixing times match theory.
  2. **Binarized MNIST denoising**: Train score network (U-Net per Section 5.2) at α ∈ {0.25, 0.5, 1, 2}; visualize E[x|y] and sign(E[x|y]) to find sweet spot (paper suggests α ≈ 0.5).
  3. **Sampler comparison**: On binarized MNIST at α = 0.5, compare one-stage vs. two-stage mixing by tracking sample diversity over 100 steps; confirm two-stage advantage at high noise per Props. 3.3–3.4.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can tighter denoising bounds be derived for distributions with strong priors beyond the generic $de^{-2\alpha}$ Wasserstein distance bound in Lemma 2.3?
- Basis in paper: [explicit] The conclusion states "sharper denoising results for strong priors could also be examined." The paper notes the bound is tight when $p(x)$ is uniform but may be loose for structured distributions.
- Why unresolved: The current analysis provides dimension-dependent bounds that do not exploit structure in the target distribution.
- What evidence would resolve it: Theoretical bounds incorporating properties of $p(x)$ (e.g., log-concavity, concentration) and empirical validation on structured binary distributions.

### Open Question 2
- Question: How much can mixing times be improved by incorporating Metropolis-Hastings acceptance steps into the discrete Langevin samplers?
- Basis in paper: [explicit] The conclusion lists "faster sampling could be achieved through the proper use of Metropolis-Hasting's step" as future work.
- Why unresolved: Metropolis-Hastings was used only in theoretical proofs (Appendices C, E) to establish stationarity properties, not as an algorithmic component.
- What evidence would resolve it: Empirical comparison of mixing times with and without MH correction, and theoretical analysis of acceptance rates at various noise levels $\alpha$.

### Open Question 3
- Question: Can this framework be extended to noise processes from more general exponential families beyond Bernoulli sign flips?
- Basis in paper: [explicit] The conclusion states "our framework relies on using a noise process from an exponential family (here, Bernoulli) and can readily be extended to more complex ones."
- Why unresolved: The derivations rely on specific properties of Bernoulli noise and the $\exp(\alpha x^\top y)$ tilt structure; it is unclear which alternative noise models preserve the TMF-like denoising formula and tractable score functions.
- What evidence would resolve it: Derivation of analogues of Lemma 2.2 for other discrete exponential families (e.g., Poisson, categorical) and demonstration of viable sampling algorithms.

### Open Question 4
- Question: What is the principled criterion for selecting the noise level $\alpha$ to balance sampling ease against denoising fidelity?
- Basis in paper: [inferred] Experiments show a "sweet spot" at $\alpha \approx 0.5$ for binarized MNIST, with degraded performance at $\alpha = 0.25$ (excessive noise) and $\alpha = 2$ (insufficient mixing). The paper provides no systematic method for choosing $\alpha$.
- Why unresolved: Theory gives sufficient conditions ($\alpha \ll 1/\sqrt{d}$ for two-stage sampling) but not optimal values; practical selection requires domain-specific knowledge.
- What evidence would resolve it: Theoretical characterization of the trade-off curve between mixing time and denoising error, validated empirically across tasks.

## Limitations

- The theoretical analysis relies on strong regularity conditions for the score function that are not empirically validated on real datasets like MNIST.
- The two-stage sampler's improved performance at high noise is only demonstrated on synthetic data and MNIST, with unclear computational overhead for large-scale applications.
- The choice of α = 0.5 as the "sweet spot" for MNIST is heuristic rather than theoretically justified.

## Confidence

- **High confidence**: The theoretical framework connecting Bernoulli noise smoothing to score-based sampling and the formal derivations of TMF-like formulas are mathematically rigorous.
- **Medium confidence**: The exponential convergence results for both samplers and their dependence on noise level α are theoretically sound but may vary with learned score quality.
- **Medium confidence**: Experimental results demonstrate the approach works, but the heuristic selection of noise levels and limited dataset scope reduce generalizability.

## Next Checks

1. **Score regularity validation**: Measure ||s(y)||_∞ and Lipschitz constants empirically on trained MNIST models across different α values to verify theoretical assumptions hold in practice.

2. **Scaling to larger datasets**: Test the approach on larger binary datasets (e.g., Fashion-MNIST, CIFAR-10 binarized) to evaluate whether the α ≈ 0.5 sweet spot generalizes and how computational costs scale.

3. **Learned score error analysis**: Quantify how errors in the learned score function (compared to ground truth on synthetic data) propagate to sampling quality and whether this explains any gaps between theoretical and empirical convergence rates.