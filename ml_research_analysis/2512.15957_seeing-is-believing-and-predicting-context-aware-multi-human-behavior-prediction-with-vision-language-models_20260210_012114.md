---
ver: rpa2
title: 'Seeing is Believing (and Predicting): Context-Aware Multi-Human Behavior Prediction
  with Vision Language Models'
arxiv_id: '2512.15957'
source_url: https://arxiv.org/abs/2512.15957
tags:
- human
- prediction
- behavior
- scene
- camp-vlm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of predicting multi-human behaviors
  from third-person perspectives in complex environments, which is critical for mobile
  robots operating in human-populated spaces. The authors propose CAMP-VLM (Context-Aware
  Multi-human behavior Prediction), a Vision Language Model-based framework that integrates
  visual inputs with Scene Graphs to enhance prediction of human-scene interactions.
---

# Seeing is Believing (and Predicting): Context-Aware Multi-Human Behavior Prediction with Vision Language Models

## Quick Facts
- arXiv ID: 2512.15957
- Source URL: https://arxiv.org/abs/2512.15957
- Reference count: 40
- Key result: Up to 66.9% improvement in multi-human behavior prediction accuracy over baselines

## Executive Summary
This paper addresses the challenge of predicting multi-human behaviors from third-person perspectives in complex environments, which is critical for mobile robots operating in human-populated spaces. The authors propose CAMP-VLM (Context-Aware Multi-human behavior Prediction), a Vision Language Model-based framework that integrates visual inputs with Scene Graphs to enhance prediction of human-scene interactions. The method employs a two-stage fine-tuning process combining Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) to improve prediction accuracy. Since existing datasets lack suitable multi-human behavior data from observer views, the authors generate synthetic data using a photorealistic simulator and also collect real-world videos. CAMP-VLM achieves up to 66.9% improvement in prediction accuracy over the best-performing baseline, demonstrating substantial advancement in multi-human behavior prediction. The model consistently outperforms baselines across various metrics including accuracy, cosine similarity, and edit distance in both synthetic and real-world scenarios.

## Method Summary
The CAMP-VLM framework integrates Vision Language Models with Scene Graphs to predict multi-human behaviors in complex environments. The approach uses a two-stage fine-tuning process: first applying Supervised Fine-Tuning (SFT) on labeled data, then refining with Direct Preference Optimization (DPO). Since existing datasets lack appropriate multi-human behavior data from observer perspectives, the authors generate synthetic data using a photorealistic simulator and collect real-world videos. The framework processes visual inputs alongside structured scene information to produce context-aware predictions of human actions and interactions.

## Key Results
- CAMP-VLM achieves up to 66.9% improvement in prediction accuracy over the best-performing baseline
- Model outperforms baselines across multiple metrics: accuracy, cosine similarity, and edit distance
- Consistent performance improvements demonstrated in both synthetic and real-world scenarios

## Why This Works (Mechanism)
The integration of Vision Language Models with Scene Graphs enables CAMP-VLM to capture both visual patterns and contextual relationships between humans and their environment. The two-stage fine-tuning process (SFT followed by DPO) allows the model to first learn from explicit labels and then refine predictions based on preference-based feedback, mimicking human-like reasoning about behavior prediction. The synthetic data generation provides controlled training scenarios with diverse human-scene interactions, while the real-world video collection grounds the model in actual environmental conditions.

## Foundational Learning
- Vision Language Models (VLMs): Neural architectures that process both visual and textual information simultaneously, essential for understanding the relationship between human actions and environmental context.
- Scene Graphs: Structured representations of visual scenes that encode objects, attributes, and relationships, providing explicit contextual information for behavior prediction.
- Supervised Fine-Tuning (SFT): Standard training method using labeled data to teach the model to map inputs to correct outputs.
- Direct Preference Optimization (DPO): Reinforcement learning technique that refines model outputs based on preference feedback rather than explicit labels, improving prediction quality.
- Photorealistic Simulation: Computer-generated environments that closely mimic real-world conditions, enabling safe and scalable data generation for training.

## Architecture Onboarding

Component Map: Input Images -> Scene Graph Extraction -> VLM Backbone -> SFT Layer -> DPO Layer -> Behavior Prediction Output

Critical Path: Visual Input → Scene Graph Construction → VLM Processing → SFT Fine-tuning → DPO Refinement → Prediction Output

Design Tradeoffs:
- Using synthetic data provides controlled diversity but may miss real-world edge cases
- Two-stage fine-tuning increases accuracy but requires more computational resources and training time
- Scene Graph integration improves context understanding but adds computational overhead

Failure Signatures:
- Poor predictions in highly dynamic or novel environments not well-represented in training data
- Degradation when scene complexity exceeds the model's capacity to process relationships
- Performance drops when human behaviors involve subtle social cues not captured by visual features

First Experiments:
1. Test baseline VLM performance without Scene Graph integration to quantify context contribution
2. Evaluate single-stage fine-tuning (SFT only) versus two-stage approach to measure DPO impact
3. Compare predictions using only synthetic data versus combined synthetic and real-world data

## Open Questions the Paper Calls Out
None

## Limitations
- Synthetic data generation may not fully capture the complexity and variability of real human behavior in natural environments
- Manual collection of real-world videos may introduce selection bias and limit scenario diversity
- Two-stage fine-tuning process may be sensitive to hyperparameter choices and require substantial computational resources

## Confidence
- High: Technical framework and methodology, including Scene Graph integration and VLM fine-tuning architecture
- Medium: Reported quantitative improvements based on experimental setup and evaluation metrics
- Low: Generalizability to completely unseen environments and long-term robustness in dynamic social spaces

## Next Checks
1. Test CAMP-VLM on a larger, more diverse set of real-world videos collected from varied cultural and environmental contexts to assess generalization
2. Conduct ablation studies to isolate the contribution of Scene Graphs versus other architectural components to the performance gains
3. Deploy the model on a physical robot platform in real-world environments and measure end-to-end prediction accuracy and robustness over extended periods