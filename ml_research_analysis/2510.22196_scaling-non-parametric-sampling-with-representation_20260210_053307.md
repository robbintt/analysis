---
ver: rpa2
title: Scaling Non-Parametric Sampling with Representation
arxiv_id: '2510.22196'
source_url: https://arxiv.org/abs/2510.22196
tags:
- image
- statistics
- arxiv
- images
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a minimalistic, white-box generative model
  that leverages three principles of natural images: spatial non-stationarity, low-level
  regularities, and high-level semantics. The method generates each pixel by sampling
  from an empirical conditional distribution derived from a pool of similar source
  patches retrieved from the dataset, conditioned on both local context and a global
  representation.'
---

# Scaling Non-Parametric Sampling with Representation

## Quick Facts
- arXiv ID: 2510.22196
- Source URL: https://arxiv.org/abs/2510.22196
- Reference count: 40
- Key outcome: Non-parametric generative model that traces every generated pixel back to source images, enabling mechanistic analysis of part-whole generalization

## Executive Summary
This paper introduces a non-parametric, white-box generative model that creates images by sampling each pixel from empirical conditional distributions derived from similar source patches. The model retrieves patches based on three constraints: low-level appearance similarity, spatial locality, and global semantic similarity. By conditioning on both local context and high-level representations, the approach generates high-fidelity samples while tracing every pixel back to its source images. Experiments on MNIST and CIFAR-10 demonstrate that the model achieves "part-whole generalization" by composing semantically coherent parts from multiple training images rather than copying entire images.

## Method Summary
The method generates images autoregressively, starting from a random 8×8 seed patch and growing outward in concentric shells. For each target pixel, it constructs a candidate pool by finding patches that satisfy three simultaneous constraints: Gaussian-weighted SSD for low-level appearance, L∞ distance for spatial locality, and SSL embedding distance for semantic similarity. The center pixels of retrieved patches form an empirical distribution from which the next pixel is sampled. The model requires no training, uses a pretrained SimCLR encoder for semantic representation, and logs source image IDs to enable mechanistic analysis through entropy measurements and source-tracing visualizations.

## Key Results
- MNIST generation achieves 6.23 Inception Score with strong visual fidelity
- CIFAR-10 produces visually compelling images despite simple architecture
- Entropy analysis confirms part-whole generalization: low class entropy (1.075) paired with high image-ID entropy (2.496)
- Source-tracing reveals multi-image composition rather than memorization

## Why This Works (Mechanism)

### Mechanism 1: Multi-Constraint Patch Retrieval for Empirical Distributions
Image generation can be framed as sampling from empirical conditional distributions derived from retrieved similar patches, provided similarity captures local texture, spatial position, and global semantics. For each target pixel $p$, construct a candidate pool $\Omega(p)$ by finding patches satisfying three constraints simultaneously: (1) low-level appearance similarity via Gaussian-weighted SSD, (2) spatial locality via $L_\infty$ distance to target position, and (3) semantic similarity via SSL embedding distance. The center pixels of retrieved patches form an empirical distribution $f_p(x|\omega(p))$ from which the next pixel is sampled. Natural images exhibit sufficient redundancy that similar patches exist in the training corpus for any valid local context; the three constraints are jointly sufficient to filter patches that produce coherent continuations.

### Mechanism 2: Part-Whole Generalization via Compositional Assembly
The model generalizes by composing semantically coherent parts from multiple training images rather than copying wholes, evidenced by the entropy signature of low class entropy paired with high image-ID entropy. The SSL representation constraint enforces that retrieved patches share semantic content (same object class/part), while the locality and SSD constraints allow patches from different source images. This yields regions that are class-pure (low class-map entropy) but multi-source (high image-ID entropy). SSL embeddings organize features by object identity and parts rather than memorizing exact pixel configurations; the semantic constraint is strong enough to ensure coherence but loose enough to permit cross-image composition.

### Mechanism 3: Autoregressive Shell-Filling with Seed Initialization
Coherent image generation from local patch statistics requires a seed region and a deterministic fill order that maximizes context availability at each step. Initialize from a random 8×8 seed patch drawn from training data. Grow outward in concentric "shells" by selecting unfilled pixels whose neighborhoods have maximum overlap with already-filled pixels, ensuring each sampling step has maximal conditioning context. The fill order affects generation quality; maximizing context overlap reduces ambiguity in the empirical conditional distribution.

## Foundational Learning

- **Non-parametric density estimation (empirical distributions)**: Why needed here: The model avoids learned parameters entirely; understanding how to form distributions from retrieved samples is essential. Quick check question: Given 100 retrieved patches with center pixel values [0,0,0,255,255,...], how would you form an empirical distribution and sample from it?

- **Self-supervised representation learning (contrastive methods like SimCLR)**: Why needed here: The high-level semantic constraint relies on pretrained SSL encoders; understanding what properties they encode (invariance, semantic clustering) explains why the mechanism works. Quick check question: Why would an SSL encoder trained with contrastive loss map different images of the same object class nearby in embedding space?

- **Autoregressive generation and fill-order dependencies**: Why needed here: Pixel-by-pixel generation is inherently sequential; the choice of which pixel to generate next affects the conditioning context available. Quick check question: What goes wrong if you generate pixels in random order rather than maximizing context overlap at each step?

## Architecture Onboarding

- **Component map**: Source corpus store -> Multi-metric distance module -> Candidate pool constructor -> Empirical distribution sampler -> Fill-order scheduler -> Source tracer (optional)

- **Critical path**: Seed selection → [loop: select next pixel → compute context patch → multi-metric retrieval → form candidate pool → sample pixel → update canvas] → until complete. The retrieval step dominates compute.

- **Design tradeoffs**:
  - **Threshold values ($R_{SSD}$, $R_{loc}$, $R_{SSL}$)**: Too restrictive → empty candidate pool; too loose → incoherent samples. Paper uses adaptive thresholds: $R(p) = (1+\epsilon) \cdot \min_{\omega''} d(\omega(p), \omega'')$.
  - **Context window size $w$**: Larger windows provide more context but reduce matching patches; smaller windows increase ambiguity.
  - **SSL encoder choice**: SimCLR used; stronger encoders may improve semantic coherence but are not evaluated.

- **Failure signatures**:
  - **Patchwork artifacts**: Low-level only (no SSL) produces "texture of squiggles"
  - **Broken strokes/misaligned parts**: Missing locality constraint causes off-center fragments
  - **Shattered local structure**: Missing low-level statistics causes globally correct shapes but inconsistent fine details
  - **Memorization**: Single-source image-ID map indicates overfitting

- **First 3 experiments**:
  1. **Reproduce ablation (Figure 2)**: Generate MNIST samples with (a) SSD only, (b) SSD + locality, (c) all three constraints. Verify progressive improvement in digit coherence.
  2. **Entropy analysis (Table 2)**: Implement sliding-window entropy over class-map and image-ID map. Confirm low class entropy (~1.0) and high index entropy (~2.5) for full model vs. higher class entropy for ablated model.
  3. **Source-tracing visualization**: For a generated CIFAR-10 sample, render the image-ID map and identify top-5 contributing source images. Verify multi-image composition rather than single-source copying.

## Open Questions the Paper Calls Out

### Open Question 1
Do large autoregressive transformers implement a non-parametric sampling algorithm in token space similar to the proposed pixel-space model? While the non-parametric model works in pixel space, it remains a hypothesis whether the internal algorithms of complex, over-parameterized transformers effectively reduce to this simple retrieval and composition mechanism in a discrete latent space. A study comparing the generation results and internal statistics of a transformer-based autoregressive model against a non-parametric model operating in the same token space would resolve this.

### Open Question 2
Can the model's performance be improved by replacing raw pixel copying with the composition of a small dictionary of "atomic" parts? The current implementation relies on direct pixel retrieval, which constrains the model to the exact pixel values present in the training set rather than learning generative primitives that could offer better generalization or compactness. Implementation of a parts-based dictionary within the non-parametric framework that achieves comparable or better FID/IS scores while offering a more interpretable decomposition of the generated image would resolve this.

### Open Question 3
Can transparent, non-parametric mechanisms for long-range interactions (such as multi-scale retrieval) close the performance gap with state-of-the-art black-box models? The current model captures global semantics via a compact representation (SimCLR) but lacks explicit mechanisms to model complex long-range dependencies, contributing to the performance gap noted in Table 1. The integration of a non-parametric multi-scale retrieval mechanism that results in significantly improved FID scores on complex datasets like CIFAR-10 without sacrificing the model's interpretability would resolve this.

## Limitations
- Critical hyperparameters (patch size, Gaussian σ, adaptive threshold ε) are underspecified, creating uncertainty about exact reproduction
- Specific SimCLR checkpoint architecture and patch embedding extraction method remain unclear
- No quantitative analysis of candidate pool size distribution or failure rates when pools become empty
- Performance gap with state-of-the-art black-box models remains significant

## Confidence
- **High confidence**: Part-whole generalization occurs (low class entropy with high image-ID entropy) - strongly supported by entropy analysis and visual evidence
- **Medium confidence**: Three constraints are jointly sufficient for coherent generation - supported by ablation studies but relies on specific hyperparameter settings
- **Low confidence**: Provides insights into how complex generative models like GANs operate internally - speculative and not directly tested

## Next Checks
1. **Hyperparameter sensitivity analysis**: Systematically vary patch size $w$, Gaussian $\sigma$, and adaptive threshold $\epsilon$ to determine their impact on candidate pool size and generation quality. Measure how often candidate pools become empty and how this correlates with generation failures.

2. **Cross-dataset generalization**: Apply the exact same model (same encoder, same hyperparameters) to a third dataset like SVHN or Fashion-MNIST to test whether the three-constraint mechanism generalizes beyond MNIST and CIFAR-10, or if dataset-specific tuning is required.

3. **Memory and computational complexity profiling**: Measure the time and memory required for candidate retrieval as dataset size scales from CIFAR-10 (50k images) to larger datasets like ImageNet-100 or ImageNet-1k. Quantify the practical limits of this non-parametric approach.