---
ver: rpa2
title: Integrating gender inclusivity into large language models via instruction tuning
arxiv_id: '2508.18466'
source_url: https://arxiv.org/abs/2508.18466
tags:
- polish
- gender-inclusive
- llms
- language
- gender
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study demonstrates that instruction tuning can effectively\
  \ embed gender inclusivity into large language models (LLMs) for Polish. By fine-tuning\
  \ multilingual and Polish-specific models using the IPIS dataset\u2014a human-crafted\
  \ collection of gender-inclusive proofreading and translation instructions\u2014\
  the resulting IPIS-tuned LLMs significantly outperformed baseline models on gender-inclusive\
  \ proofreading, achieving F1 scores up to 59.85% and BLEU/chrF similarity above\
  \ 90%."
---

# Integrating gender inclusivity into large language models via instruction tuning

## Quick Facts
- **arXiv ID**: 2508.18466
- **Source URL**: https://arxiv.org/abs/2508.18466
- **Authors**: Alina Wróblewska; Bartosz Żuk
- **Reference count**: 39
- **Primary result**: Instruction tuning on gender-inclusive Polish datasets significantly improves gender inclusivity in LLMs while preserving text quality

## Executive Summary
This study demonstrates that instruction tuning can effectively embed gender inclusivity into large language models for Polish. By fine-tuning multilingual and Polish-specific models using the IPIS dataset—a human-crafted collection of gender-inclusive proofreading and translation instructions—the resulting IPIS-tuned LLMs significantly outperformed baseline models on gender-inclusive proofreading, achieving F1 scores up to 59.85% and BLEU/chrF similarity above 90%. In Polish-to-English translation, IPIS-tuning also improved performance (BLEU up to 57.5, chrF up to 78.3). However, the approach was less effective for English-to-Polish translation, likely due to data scarcity. The results confirm that language-specific models are better suited for instruction-level optimisation, and that instruction tuning is a viable strategy for integrating gender inclusivity into LLMs.

## Method Summary
The researchers fine-tuned LLMs using LoRA-based supervised fine-tuning on the IPIS dataset, which contains human-crafted gender-inclusive proofreading and translation instructions. Models were trained with standard SFTTrainer configuration using DeepSpeed ZeRO and Flash Attention 2, with hyperparameters including r=128 LoRA rank, α=256 scaling, dropout=0.05, learning rate 2e-5, and 3 epochs. The approach was tested on both multilingual models (Llama-8B, Mistral-7B, Mistral-Nemo-12B) and Polish-specific models (Bielik-7B/11B, PLLuM-8B/12B) across two tasks: gender-inclusive proofreading of Polish text and bidirectional gender-sensitive translation between Polish and English.

## Key Results
- IPIS-tuned models achieved F1 scores up to 59.85% on Polish gender-inclusive proofreading, significantly outperforming baseline models
- Polish-to-English translation improved with IPIS-tuning (BLEU up to 57.5, chrF up to 78.3) while maintaining high text quality (BLEU/chrF > 90)
- Polish-specific models (Bielik-11B F1=59.85%, PLLuM-12B F1=56.79%) outperformed multilingual models on proofreading tasks
- English-to-Polish translation performed poorly with IPIS-tuning, likely due to insufficient training data (1,728 examples)

## Why This Works (Mechanism)

### Mechanism 1: Instruction Tuning for Normative Output Control
Instruction tuning on domain-specific datasets can embed normative linguistic rules into models by learning to map biased input patterns to desired inclusive outputs. The model internalizes transformation rules through supervised fine-tuning with LoRA, enabling it to perform complex text transformations that contradict its pre-training distribution.

### Mechanism 2: Language-Specific Model Superiority
Language-specific models have stronger linguistic priors from pre-training on large target-language corpora, allowing them to focus on task-specific adaptation rather than simultaneously learning base language skills and task rules. This leads to better performance with less task-specific data.

### Mechanism 3: Task Complexity Threshold for Data Scarcity
Highly generative tasks like translation require substantially more data than constrained proofreading tasks. With insufficient examples, models overfit and experience catastrophic forgetting, degrading general translation ability while attempting to learn complex gender-inclusive rules.

## Foundational Learning

- **Low-Rank Adaptation (LoRA)**: Parameter-efficient fine-tuning method that reduces memory usage by updating a small number of parameters. *Why needed*: Enables instruction tuning on large models without full parameter updates. *Quick check*: How does LoRA reduce memory usage compared to full parameter updates?

- **Grammatical vs. Natural Gender**: Distinction between grammatical gender systems (like Polish's) and natural gender alignment. *Why needed*: The core problem stems from Polish's grammatical gender system where masculine forms are used generically. *Quick check*: In "The student raised their hand," how would masculine-generic Polish differ from gender-inclusive version?

- **F1 Score & BLEU/chrF Metrics**: Quantitative measures of success—F1 measures inclusive edit accuracy while BLEU/chrF measure text quality preservation. *Why needed*: These metrics evaluate both the effectiveness of gender-inclusive edits and maintenance of original meaning. *Quick check*: Why is high F1 meaningless if BLEU score is very low?

## Architecture Onboarding

**Component map**: Pre-trained LLM -> LoRA adapter configuration -> IPIS dataset (prompt + source -> target) -> SFT training -> evaluation metrics (F1, BLEU, chrF)

**Critical path**: 1. Select base model (Polish-specific preferred) 2. Prepare IPIS dataset 3. Configure LoRA SFT with specified hyperparameters 4. Train for 3 epochs 5. Evaluate using multi-metric approach 6. (Optional) Test system prompts

**Design tradeoffs**: Primary tradeoff is Task Performance vs. Data Scarcity—proofreading is more achievable with limited data than complex translation. Another key tradeoff is Base Model Choice—Polish-specific models offer higher potential performance but may have different baseline capabilities than multilingual models.

**Failure signatures**:
1. **Overfitting/Corruption**: Dramatic BLEU score drop, especially in EN→PL translation, indicating model degradation
2. **High Precision, Low Recall**: Model is too cautious, missing many necessary changes
3. **Generic Masculine Output**: Model defaults to standard Polish, ignoring training

**First 3 experiments**:
1. Replicate Proofreading Baseline: Train Bielik-7B on IPIS-proofreading set and evaluate for gender-inclusive editing performance
2. Ablation Study on System Prompts: Evaluate tuned model with and without system prompt to quantify impact on F1 and BLEU
3. Data Scaling Test for Translation: Augment small IPIS-translation set with synthetic data and retrain to test data scarcity hypothesis

## Open Questions the Paper Calls Out

**Question 1**: Does instruction tuning for gender inclusivity negatively affect other dimensions of text quality, such as fluency, coherence, or factual accuracy? *Basis*: Paper explicitly states evaluation is limited to gender inclusivity without examining other textual quality aspects.

**Question 2**: Can poor English-to-Polish translation performance be overcome by significantly increasing IPIS-translation dataset size and diversity? *Basis*: Authors attribute failure to data scarcity but don't test with scaled-up data.

**Question 3**: Is instruction-tuning approach effective for languages with grammatical gender systems that differ structurally from Polish? *Basis*: Study focuses on Polish, restricting generalizability to other languages.

**Question 4**: Why does system prompt inclusion impair tuned model performance contrary to its benefit for baseline models? *Basis*: Authors report this counterintuitive finding without definitive explanation.

## Limitations

- Evaluation limited to gender inclusivity metrics without comprehensive assessment of other text quality dimensions like fluency and coherence
- Approach tested only on Polish language with grammatical gender system, limiting generalizability to other languages
- English-to-Polish translation failed due to data scarcity, highlighting scalability limitations for complex generative tasks

## Confidence

**High Confidence**: Proofreading task results are robust with consistent improvement across Polish-specific models demonstrating effective gender inclusivity embedding

**Medium Confidence**: Language-specific model superiority claim is supported by data but needs systematic validation across different language families

**Low Confidence**: Attribution of translation failure solely to data scarcity is based on negative results rather than positive confirmation

## Next Checks

1. **Data Scaling Experiment**: Create synthetic dataset by applying gender-inclusive transformations to existing parallel corpora, scaling training data from 1,728 to 10,000+ examples and retrain EN→PL models to test if data scarcity is primary limiting factor

2. **Cross-Lingual Generalization Test**: Apply IPIS instruction tuning to another gendered language (French or Hebrew) with language-appropriate datasets to validate approach beyond Polish's specific grammatical gender system

3. **Human Evaluation of Inclusivity Quality**: Conduct comprehensive human evaluation by native speakers assessing naturalness and effectiveness of gender-inclusive constructions, comparing human judgments with automated metrics to identify gaps between metric optimization and actual inclusivity quality