---
ver: rpa2
title: Generalizable Geometric Image Caption Synthesis
arxiv_id: '2509.15217'
source_url: https://arxiv.org/abs/2509.15217
tags:
- reasoning
- geometric
- dataset
- arxiv
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GeoReasoning-10K, a 10,000-image caption
  dataset for geometric reasoning built via symbolic synthesis and refined using reinforcement
  learning with verifiable rewards (RLVR). The authors sample geometric relations,
  generate aligned image-caption pairs, and employ a RAFT-based framework to iteratively
  optimize captions and models using reasoning and caption rewards.
---

# Generalizable Geometric Image Caption Synthesis

## Quick Facts
- arXiv ID: 2509.15217
- Source URL: https://arxiv.org/abs/2509.15217
- Reference count: 40
- This paper introduces GeoReasoning-10K, a 10,000-image caption dataset for geometric reasoning built via symbolic synthesis and refined using reinforcement learning with verifiable rewards (RLVR).

## Executive Summary
This paper presents GeoReasoning-10K, a novel dataset and training pipeline for geometric reasoning in multimodal vision-language models. The authors construct a synthetic dataset of 10,000 geometric image-caption pairs using symbolic sampling of geometric relations and then refine both the dataset and a caption generation model using reinforcement learning with verifiable rewards (RLVR). The approach leverages a RAFT-based framework to iteratively optimize captions and models using reasoning and caption rewards. Experimental results demonstrate significant improvements on in-domain geometric reasoning benchmarks (MathVista, MathVerse) and notable generalization to non-geometric tasks (MMMU Art & Design, Tech & Engineering).

## Method Summary
The authors create GeoReasoning-10K by sampling geometric relations, generating aligned image-caption pairs, and refining them through RLVR. The dataset is synthesized via symbolic sampling of geometric relations, followed by image generation and caption refinement. A RAFT-based framework is used to iteratively optimize both the dataset and a caption generation model using reasoning and caption rewards. The RLVR process leverages verifiable rewards to improve geometric understanding and caption quality.

## Key Results
- Models trained on GeoReasoning-10K outperform baselines on MathVista (+2.8%) and MathVerse (+4.8%) for in-domain tasks
- Significant generalization to non-geometric tasks on MMMU with 2.4%-3.9% gains in Art & Design and Tech & Engineering
- Ablation studies confirm the effectiveness of both the cold-start phase and RLVR

## Why This Works (Mechanism)
The method works by leveraging verifiable geometric rewards to iteratively refine both synthetic data and model parameters. By starting with symbolic geometric relations and generating synthetic images, the authors create a controlled dataset with guaranteed geometric properties. The RLVR process then optimizes captions to be both accurate and descriptive of geometric relationships, while the model learns to recognize and describe these relationships. The iterative refinement between data and model creates a positive feedback loop that improves geometric reasoning capabilities.

## Foundational Learning

**Symbolic Geometric Relations**: Mathematical representations of spatial relationships (why needed: provides verifiable ground truth for training; quick check: can sample relations like "A is left of B" and verify them)

**Reinforcement Learning with Verifiable Rewards (RLVR)**: Training paradigm where rewards can be algorithmically verified (why needed: enables automatic dataset and model refinement; quick check: rewards are deterministically computed from geometric properties)

**RAFT Framework**: Iterative optimization framework for data and model (why needed: coordinates simultaneous improvement of dataset and model; quick check: alternates between data refinement and model training)

**Multimodal Representation**: Joint embedding of visual and textual features (why needed: enables geometric reasoning across modalities; quick check: can compute similarity between geometric captions and images)

## Architecture Onboarding

**Component Map**: Geometric Relation Sampler -> Image Generator -> Caption Generator -> RLVR Reward Module -> Caption Refiner -> Captioned Image Dataset -> Vision-Language Model -> Geometric Reasoning Evaluation

**Critical Path**: Geometric Relation Sampler → Image Generator → Caption Generator → RLVR Reward Module → Caption Refiner → Vision-Language Model → Geometric Reasoning Evaluation

**Design Tradeoffs**: Synthetic data provides perfect geometric labels but may lack real-world diversity; RLVR requires computationally expensive iterative refinement but enables verifiable optimization

**Failure Signatures**: 
- Caption generation fails to capture complex geometric relationships
- Model overfits to synthetic patterns not present in real images
- RLVR optimization converges to local optima in reward space
- Geometric verification rewards are too strict or too lenient

**3 First Experiments**:
1. Evaluate geometric caption quality on held-out synthetic test set
2. Test geometric reasoning accuracy on MathVista/MathVerse benchmarks
3. Assess zero-shot generalization to non-geometric MMMU tasks

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset size (10K) is relatively small compared to the scale of modern multimodal models
- Reliance on synthetic data generation may limit diversity of real-world geometric scenarios
- Evaluation is largely benchmark-driven with limited analysis of model generalization to more diverse geometric tasks

## Confidence

**Core Claims** (dataset creation, RLVR methodology, benchmark improvements): High
**Broader Implications for Geometric Reasoning**: Medium
**Real-world Applicability**: Low

## Next Checks

1. Evaluate the model on additional geometric reasoning datasets or real-world image-caption pairs to test robustness beyond controlled benchmarks
2. Conduct ablation studies on dataset size (e.g., 5K vs 10K vs 20K) to quantify the marginal benefit of additional synthetic data
3. Perform qualitative error analysis to identify failure modes and assess whether the model truly understands geometric relations or is overfitting to dataset patterns