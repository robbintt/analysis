---
ver: rpa2
title: 'Enforcing Fairness Where It Matters: An Approach Based on Difference-of-Convex
  Constraints'
arxiv_id: '2505.12530'
source_url: https://arxiv.org/abs/2505.12530
tags:
- fairness
- constraints
- optimization
- where
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a novel framework for achieving partial fairness
  in machine learning, focusing on enforcing fairness only within specific score ranges
  where fairness concerns are most relevant. The proposed method formulates the training
  process as a constrained optimization problem with difference-of-convex (DC) constraints,
  which can be solved using an inexact difference-of-convex algorithm (IDCA).
---

# Enforcing Fairness Where It Matters: An Approach Based on Difference-of-Convex Constraints

## Quick Facts
- arXiv ID: 2505.12530
- Source URL: https://arxiv.org/abs/2505.12530
- Reference count: 40
- Primary result: Achieves high predictive performance while enforcing partial fairness only within specific score ranges where fairness concerns are most relevant

## Executive Summary
This paper introduces a novel framework for achieving partial fairness in machine learning by focusing on specific score ranges where fairness is most critical. The authors formulate the training process as a constrained optimization problem with difference-of-convex (DC) constraints and solve it using an inexact difference-of-convex algorithm (IDCA). The approach demonstrates superior performance in trading off accuracy for partial fairness compared to existing in-processing methods, particularly at higher levels of fairness enforcement.

## Method Summary
The method introduces partial fairness constraints that are enforced only within specific score intervals $I = [\alpha, \beta)$, reducing the traditional fairness-accuracy trade-off. The authors formulate the problem as a DC-constrained optimization where fairness constraints are expressed using continuous surrogates (e.g., sigmoid or hinge functions) that approximate indicator functions. They solve this using IDCA, which iteratively linearizes the concave components of constraints and solves convex subproblems via a Switching Subgradient method. The framework is tested on three datasets (a9a, bank, law school) with a linear model incorporating cross-terms between features and sensitive attributes.

## Key Results
- Achieves superior fairness-accuracy trade-offs compared to unconstrained and group-AUC methods
- Demonstrates effectiveness across three real-world datasets (a9a, bank, law school)
- Shows that partial fairness enforcement within specific score ranges preserves predictive performance while achieving fairness goals

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Restricting fairness enforcement to a specific score interval (partial fairness) mitigates the trade-off between predictive performance and fairness constraints.
- **Mechanism:** The framework limits the demographic parity requirement to a subspace of predictions $I = [\alpha, \beta)$. By leaving the tails of the distribution unconstrained, the model retains degrees of freedom to optimize the primary loss function in regions where fairness is less contested.
- **Core assumption:** Decision stakeholders primarily care about fairness near decision boundaries or specific rank ranges, rather than across the entire score distribution.
- **Evidence anchors:** [abstract], [section 4], [corpus]
- **Break condition:** If a regulator requires global fairness, this mechanism fails to meet the compliance requirement.

### Mechanism 2
- **Claim:** Non-convex fairness constraints can be solved via convex optimization subroutines by reformulating them as Difference-of-Convex (DC) functions.
- **Mechanism:** The constraints involve indicators (0-1 functions) which are non-convex. The authors use continuous surrogates to approximate these indicators, decomposing them into convex components that can be handled by DC programming techniques.
- **Core assumption:** The selected surrogate function closely approximates the discrete indicator without destabilizing the optimization landscape.
- **Evidence anchors:** [section 5], [section B]
- **Break condition:** If the surrogate function is a poor approximation, the "fairness" achieved may be mathematical but not semantic.

### Mechanism 3
- **Claim:** The Inexact Difference-of-Convex Algorithm (IDCA) converges to a nearly $\epsilon$-KKT point with complexity $\tilde{O}(\epsilon^{-4})$.
- **Mechanism:** IDCA iteratively linearizes the concave component of the constraints at the current iterate, transforming the non-convex problem into a solvable convex subproblem using a Switching Subgradient method.
- **Core assumption:** The uniform Slater's condition holds and the DC components are strongly convex.
- **Evidence anchors:** [section 6], [section C.5]
- **Break condition:** If the convex subproblems are ill-conditioned or the Slater condition fails, the SSG subroutine may stall.

## Foundational Learning

- **Concept: Difference-of-Convex (DC) Optimization**
  - **Why needed here:** The core mathematical engine for handling non-convex fairness constraints.
  - **Quick check question:** Given $f(x) = x^2 - |x|$, how would you linearize the concave part at $x=1$ to form a convex upper bound?

- **Concept: Karush-Kuhn-Tucker (KKT) Conditions**
  - **Why needed here:** Defines the stopping criteria and theoretical convergence standard for the constrained optimization.
  - **Quick check question:** In constrained optimization, what is the physical meaning of the Lagrange multiplier $\lambda_i$ associated with a fairness constraint?

- **Concept: Surrogate Loss Functions**
  - **Why needed here:** Enables transition from discrete fairness checks to continuous optimization.
  - **Quick check question:** Why is the hinge loss $\max(0, 1 - y\hat{y})$ preferred over the 0-1 loss in gradient-based optimization?

## Architecture Onboarding

- **Component map:** Data $\rightarrow$ DC Constraint Formulation $\rightarrow$ Linearization at $w^{(k)}$ $\rightarrow$ SSG Solve $\rightarrow$ Update $w^{(k+1)}$
- **Critical path:** The efficiency depends entirely on the SSG solver's ability to handle the convex subproblem rapidly.
- **Design tradeoffs:**
  - **Interval Width ($\beta - \alpha$):** Wider intervals approach global fairness (harder optimization, lower accuracy); narrower intervals focus optimization but may miss borderline unfairness.
  - **Surrogate Choice:** Sigmoids are smooth (better for gradient descent) but the paper analyzes non-smooth DC cases (hinges) extensively.
  - **Exactness ($\epsilon_k$):** Solving subproblems exactly is costly; IDCA allows "inexact" solutions to speed up iterations at the risk of temporary constraint violation.
- **Failure signatures:**
  - **Oscillation:** SSG bounces between feasible/infeasible regions without reducing the objective.
  - **Trivial Solution:** Model converges to $w \approx 0$ to trivially satisfy fairness constraints.
  - **Constraint Drift:** Linearization approximation causes solution to drift out of true fairness bounds.
- **First 3 experiments:**
  1. Implement the linear model $h_w(\xi) = \langle w, (1, \xi, \gamma, \gamma \cdot \xi) \rangle$ on a9a dataset and reproduce Figure 1 (Pareto frontier).
  2. Fix $\kappa$ and vary interval $I$ (e.g., top 10-20% vs. top 40-60%), measuring how Accuracy and Fairness metrics change.
  3. Plot objective value $f_0$ and infeasibility $\max f_i$ over IDCA iterations to verify $\tilde{O}(\epsilon^{-4})$ behavior.

## Open Questions the Paper Calls Out

- **Can the theoretical complexity analysis be generalized to stochastic IDCA?** The authors state that generalizing to stochastic IDCA would be ideal for training deep learning models, as the current work only establishes oracle complexity for the deterministic version.
- **Is it possible to generate the fairness-accuracy Pareto frontier without re-training the model from scratch for each constraint level?** The current numerical approach requires solving a distinct optimization problem for every point, which may not be numerically efficient.
- **Can the IDCA analysis be extended to ensure convergence to stronger stationarity notions, such as directional stationary points?** The "nearly KKT point" used is a weak notion of stationary solution, and the authors suggest extending the analysis to directional stationary points.

## Limitations
- The theoretical guarantees depend heavily on surrogate function choice and interval definition
- The IDCA algorithm's practical performance may degrade if the surrogate poorly approximates the indicator function
- The complexity analysis assumes strong convexity and uniform Slater's condition, which may not hold for all datasets

## Confidence
- **High:** DC optimization framework and IDCA algorithm are well-established with clear theoretical foundations; empirical results are convincing
- **Medium:** Effectiveness of partial fairness enforcement is supported by experiments but causal mechanism is primarily mathematically justified
- **Low:** Sensitivity to surrogate function choice and interval definition is not thoroughly explored; systematic validation of design choices is lacking

## Next Checks
1. **Surrogate Sensitivity Analysis:** Run the algorithm with different surrogate functions (e.g., sigmoid vs. hinge) and compare convergence rates and final fairness-accuracy trade-offs.
2. **Interval Robustness Test:** Systematically vary the interval $I$ width and position, then measure how Accuracy and Partial Fairness metrics change.
3. **Constraint Violation Monitoring:** Implement detailed logging of constraint violations during IDCA iterations to validate theoretical convergence claims practically.