---
ver: rpa2
title: Half Search Space is All You Need
arxiv_id: '2505.13586'
source_url: https://arxiv.org/abs/2505.13586
tags:
- search
- architecture
- memory
- space
- darts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the high GPU memory requirements of One-Shot
  NAS methods like DARTS by introducing a framework that combines Zero-Shot and One-Shot
  NAS. The key idea is to use Zero-Shot NAS to prune the search space by removing
  low-performing architectures before applying One-Shot NAS to the reduced space.
---

# Half Search Space is All You Need

## Quick Facts
- **arXiv ID:** 2505.13586
- **Source URL:** https://arxiv.org/abs/2505.13586
- **Reference count:** 14
- **Primary result:** 81% memory reduction compared to baseline DARTS with maintained/improved accuracy

## Executive Summary
This paper addresses the high GPU memory requirements of One-Shot NAS methods like DARTS by introducing a framework that combines Zero-Shot and One-Shot NAS. The key idea is to use Zero-Shot NAS to prune the search space by removing low-performing architectures before applying One-Shot NAS to the reduced space. A pruning mask is introduced to represent the pruned search space, enabling compatibility with existing One-Shot techniques. Experiments on CIFAR-10 and CIFAR-100 show that the proposed method reduces memory consumption by 81% compared to the baseline DARTS setup while maintaining or improving evaluation accuracy. Random pruning also yields similar results, indicating that the DARTS search space contains significant redundancy.

## Method Summary
The framework combines Zero-Shot and One-Shot NAS by first using Zero-Shot techniques to prune the search space. It generates a binary pruning mask using the Frobenius norm of the NNGP kernel as a ranking function, iteratively removing the least important operations until a target fraction (50%) remains. The masked search space is then used for One-Shot NAS using PC-DARTS with β-regularization. The pruning mask ensures masked operations are excluded from forward and backward passes, reducing memory consumption linearly with the number of pruned operations.

## Key Results
- Memory consumption reduced by 81% compared to baseline DARTS setup
- Random pruning achieves comparable accuracy to Zero-Shot pruning with 23% faster search time
- Maintains or improves evaluation accuracy on CIFAR-10 and CIFAR-100

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Reducing the candidate operation set during search lowers GPU memory consumption linearly.
- **Mechanism:** A binary mask I(o) is applied to the operation set O in the mixing operation. By forcing I(o)=0 for pruned operations, the framework excludes these operations from forward and backward passes. Since One-Shot NAS memory scales with active operations being differentiated, removing 50% of operations roughly halves activation memory required.
- **Core assumption:** Memory overhead of storing mask and pruning logic is negligible compared to memory saved by skipping gradient computation.
- **Evidence anchors:** Abstract states 81% memory reduction; section 4.1 confirms masked operations are never run through forward/backward propagation.

### Mechanism 2
- **Claim:** DARTS search space contains extreme redundancy, allowing aggressive pruning without excluding all high-performing architectures.
- **Mechanism:** The DARTS space is vast (>10^18) with performance distribution skewed toward high-performing architectures. Pruning 50% of space statistically unlikely to remove every optimal architecture.
- **Core assumption:** Search space has sufficient density of high-performing architectures to survive pruning process.
- **Evidence anchors:** Section 5.3 explains performance distribution is heavily skewed; section 1 notes random pruning yields similar results.

### Mechanism 3
- **Claim:** Zero-Shot metrics serve as low-cost "coarse filter" to separate poor architectures from promising ones.
- **Mechanism:** Zero-Shot ranking functions (Frobenius norm of NNGP kernel) compute importance scores for every edge in hypergraph. Algorithm iteratively removes least important operation until target fraction remains, pre-processing away "dead ends" before expensive One-Shot differentiation.
- **Core assumption:** Zero-Shot proxy correlates sufficiently with true performance to distinguish bad operations from good/neutral ones.
- **Evidence anchors:** Section 4.2 states Zero-Shot techniques are good at identifying poor performance; section 5.2 uses NNGP specifically designed for fast search.

## Foundational Learning

- **Concept: DARTS (Differentiable Architecture Search)**
  - **Why needed here:** Baseline One-Shot method being optimized. DARTS constructs supernet where all operations exist in parallel and are weighted by learnable parameters (α). High memory usage comes from storing states for all parallel operations during backpropagation.
  - **Quick check question:** How does representing architecture choice as weighted sum of operations lead to memory bottleneck addressed in this paper?

- **Concept: Zero-Shot NAS (Proxy-based Search)**
  - **Why needed here:** Paper leverages Zero-Shot methods as first stage. These methods (like NNGP or synaptic saliency) estimate network fitness without training weights. Fast but noisy.
  - **Quick check question:** Why is Zero-Shot metric sufficient for pruning 50% of search space but often insufficient for selecting final single best architecture?

- **Concept: Search Space Hypergraphs**
  - **Why needed here:** Paper operates on hypergraph of nodes (feature maps) and edges (operations). Pruning mechanism works by modifying graph structure (masking edges).
  - **Quick check question:** In context of paper, does pruning mask remove entire nodes or edges connecting them?

## Architecture Onboarding

- **Component map:** Input DARTS Search Space Hypergraph (N₀) -> Stage 1 (Pruning): Zero-Shot Evaluator + Ranking Function (NNGP) → Pruning Mask I(o) -> Stage 2 (Search): Masked One-Shot Supernet (PC-DARTS + β-DARTS) → Optimized Architecture Weights -> Output Discrete Architecture

- **Critical path:** Implementation hinges on Masked Mixing Operation (Eq. 1). Must modify standard DARTS cell implementation to check mask I(o) before instantiating or forwarding operations o(x). Critical path is ensuring mask correctly disables gradient calculation for pruned operations to actually save memory.

- **Design tradeoffs:**
  - Zero-Shot vs. Random Pruning: Zero-Shot theoretically better but adds computation time; random pruning is near-instantaneous with marginal accuracy difference
  - Pruning Ratio (ξ): Paper uses 0.5 (50%); lower ratio saves more memory but increases risk of pruning out global optimum

- **Failure signatures:**
  - Memory Stagnation: If memory usage doesn't drop, check masked operations are fully skipped in backward pass, not just zeroed in forward pass
  - Performance Collapse: If accuracy drops significantly below baseline DARTS, pruning ratio may be too aggressive or Zero-Shot metric is misleading

- **First 3 experiments:**
  1. Baseline Memory Profile: Run standard DARTS/PC-DARTS on target hardware and measure peak VRAM to establish upper bound
  2. Random Mask Validation: Implement masking logic and run search with random mask (50% density); verify memory drops ~50% and accuracy remains within 1-2% of baseline
  3. Zero-Shot Integration: Implement NNGP scoring (Algorithm 1) to generate mask intelligently; compare resulting architecture accuracy against Random Mask run

## Open Questions the Paper Calls Out
- **Open Question 1:** How does framework perform on search spaces with lower redundancy or fewer high-performing candidates compared to dense DARTS space?
  - Basis: Conclusion states main limitation is potential exclusion of top-tier architectures on spaces where number of top-tier architectures is smaller
  - Why unresolved: Experiments conducted only on standard DARTS search space with >10^18 architectures described as heavily skewed toward high-performing ones

- **Open Question 2:** How sensitive is final architecture performance to pruning ratio ξ, and can search space be reduced by more than 50%?
  - Basis: Methodology fixes pruning level ξ at 0.5, title focuses on "Half Search Space," impact of more aggressive or conservative pruning unexplored
  - Why unresolved: Paper establishes feasibility at 50% reduction but doesn't map trade-off curve between memory savings and accuracy

- **Open Question 3:** Does computational overhead of Zero-Shot pruning provide consistent accuracy advantage over random pruning when scaled to larger datasets like ImageNet?
  - Basis: Table 1 shows Random Pruning is significantly faster (23% faster than Zero-Shot variant) with comparable accuracy
  - Why unresolved: While Zero-Shot pruning yielded slightly better accuracy on CIFAR, small margin suggests added complexity might be unnecessary, but this may change with higher-resolution data

## Limitations
- Effectiveness depends heavily on correlation between proxy metric (NNGP) and true performance, which may not generalize to all search spaces or tasks
- Assumes significant redundancy in DARTS search spaces, but this may not hold for more constrained or manually designed spaces
- Memory savings are linear with pruned operations, but overhead of two-stage pipeline may offset benefits for very small search spaces

## Confidence
- **High Confidence:** Memory reduction claims (81%) and random pruning effectiveness are well-supported by experimental results
- **Medium Confidence:** Mechanism explaining why Zero-Shot pruning works (proxy correlation) is plausible but not exhaustively validated across different metrics
- **Medium Confidence:** Claims about DARTS space redundancy are supported by experiments but lack theoretical proof of distribution properties

## Next Checks
1. **Memory Overhead Validation:** Measure actual GPU memory usage with and without masked operations to verify skipped gradient computation yields claimed savings
2. **Search Space Generalization:** Test framework on non-DARTS search spaces (e.g., MobileNet-based) to evaluate robustness of redundancy claims
3. **Zero-Shot Metric Comparison:** Compare multiple Zero-Shot metrics (NNGP, SynFlow, etc.) to quantify trade-off between computational overhead and pruning accuracy