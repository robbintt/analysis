---
ver: rpa2
title: 'Unpacking Robustness in Inflectional Languages: Adversarial Evaluation and
  Mechanistic Insights'
arxiv_id: '2505.07856'
source_url: https://arxiv.org/abs/2505.07856
tags:
- adversarial
- examples
- inflectional
- text
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how inflectional complexity in languages
  affects the robustness of language models to adversarial attacks. While most adversarial
  attack methods have been developed and tested on non-inflectional languages like
  English, this study evaluates four adversarial attack methods (TextFooler, TextBugger,
  WordNetTextFooler, and BERT-Attack) on both inflectional languages (Polish and Czech)
  and non-inflectional English.
---

# Unpacking Robustness in Inflectional Languages: Adversarial Evaluation and Mechanistic Insights

## Quick Facts
- **arXiv ID**: 2505.07856
- **Source URL**: https://arxiv.org/abs/2505.07856
- **Reference count**: 40
- **Primary result**: TextBugger causes largest accuracy drops in adversarial attacks, but inflection-specific circuits show greater robustness in morphologically complex languages

## Executive Summary
This paper investigates how inflectional complexity in languages affects language model robustness to adversarial attacks. The study evaluates four adversarial attack methods on inflectional languages (Polish, Czech) versus non-inflectional English, finding that TextBugger achieves the highest attack success rates while producing lowest similarity examples. To understand the underlying mechanisms, the authors develop a novel Inflectional Circuit Detection Dataset and apply mechanistic interpretability techniques (Edge Attribution Patching with Integrated Gradients) to identify model components responsible for processing inflectional features. The analysis reveals that circuits incorporating inflection-specific components demonstrate greater robustness to adversarial attacks, particularly in inflectional languages, suggesting that incorporating inflectional morphology in language model training can enhance robustness against word-based adversarial attacks.

## Method Summary
The study employs a multi-faceted approach combining adversarial attack evaluation and mechanistic interpretability. Four attack methods (TextFooler, TextBugger, WordNetTextFooler, BERT-Attack) are applied to BERT-based classifiers across three languages, with candidate filtering using multilingual SBERT at 90% similarity threshold. A novel Inflectional Circuit Detection Dataset (244 examples × 3 variants) is constructed using Polish grammatical resources to create parallel clean-corrupted pairs for syncretic versus inflectional synonym contrasts. Edge Attribution Patching with Integrated Gradients (EAP-IG) is used to identify inflection-processing circuits by extracting attention heads and MLP components (50-300 edges) and evaluating their task performance on adversarial examples.

## Key Results
- TextBugger achieved the highest attack success rate across all languages while producing adversarial examples with the lowest semantic similarity to originals
- Circuits incorporating inflection-specific components showed greater robustness to adversarial attacks compared to general language processing circuits
- The Inflectional Circuit Detection Dataset successfully enabled identification of model components specifically tuned to inflectional morphology processing

## Why This Works (Mechanism)
The enhanced robustness in inflectional languages stems from model circuits that incorporate inflection-specific components, which maintain performance even when word-level perturbations are applied. These circuits leverage morphological information beyond surface word forms, making them less vulnerable to attacks that replace words with synonyms. The EAP-IG method reveals that inflection-processing attention heads and MLP components form interconnected circuits that preserve semantic meaning despite adversarial perturbations. This suggests that morphological complexity provides an implicit defense mechanism by forcing models to develop deeper linguistic representations that transcend individual word choices.

## Foundational Learning
- **Adversarial attacks in NLP**: Methods that modify input text to fool classifiers while maintaining semantic similarity. Needed to evaluate model robustness systematically.
  - *Quick check*: Verify attack success rate and semantic similarity metrics on benchmark datasets
- **Edge Attribution Patching with Integrated Gradients**: Mechanistic interpretability technique that identifies model components by measuring attribution scores across network edges. Needed to isolate inflection-processing circuits.
  - *Quick check*: Confirm circuit extraction produces coherent attention head and MLP component groupings
- **Syncretic vs inflectional synonyms**: Linguistic concept distinguishing words that share form but differ in grammatical function from those with distinct forms. Needed for creating parallel dataset with minimal semantic change.
  - *Quick check*: Validate that parallel dataset pairs maintain semantic equivalence while differing in morphological complexity
- **Multilingual SBERT filtering**: Semantic similarity model used to ensure adversarial candidates maintain meaning. Needed to filter low-quality attack examples.
  - *Quick check*: Verify SBERT similarity distribution and filtering effectiveness across languages
- **Circuit task performance**: Evaluation metric measuring how well identified components perform classification on clean vs corrupted inputs. Needed to quantify circuit robustness.
  - *Quick check*: Compare predictive confidence scores between clean and adversarial examples

## Architecture Onboarding
**Component map**: Dataset → Classifier → Attack method → Adversarial examples → EAP-IG circuit extraction → Robustness evaluation
**Critical path**: The pipeline from dataset preparation through circuit identification to robustness validation forms the core analytical chain. The EAP-IG method bridges mechanistic interpretability with adversarial evaluation.
**Design tradeoffs**: The study prioritizes mechanistic insight over comprehensive attack coverage, focusing on four methods with unified word-importance detection rather than exploring the full spectrum of attack strategies.
**Failure signatures**: Token misalignment in parallel datasets breaks EAP-IG analysis; low-quality adversarial examples due to aggressive filtering undermine robustness evaluation; missing implementation details prevent circuit reproduction.
**First experiments**:
1. Generate adversarial examples using unified TextBugger implementation and verify attack success rates match reported values
2. Apply EAP-IG to clean-corrupted pairs and confirm circuit extraction produces attention head groupings consistent with inflectional processing
3. Evaluate circuit task performance on adversarial examples to verify robustness patterns across languages

## Open Questions the Paper Calls Out
- How do inflection-specific circuits and their robustness benefits generalize to agglutinative languages versus the fusional languages studied?
- How does adversarial robustness in inflectional languages compare between encoder-only models (BERT) and decoder-only architectures (GPT)?
- Why does the NLI metric exhibit high variance (up to 38%) in evaluating adversarial example quality, and what does this reveal about metric suitability?
- Can automated methods reduce the high cost and linguistic expertise required for creating token-aligned parallel datasets for circuit discovery?

## Limitations
- Missing implementation details for EAP-IG method and syncretic/inflectional synonym extraction pipeline prevent faithful reproduction
- Focus on word-level perturbations may overlook subword or character-level vulnerabilities particularly relevant for morphologically rich languages
- High variance in NLI similarity metrics suggests potential limitations in semantic evaluation across languages

## Confidence
- **High Confidence**: TextBugger achieves highest attack success rate with lowest similarity examples across all languages
- **Medium Confidence**: Incorporating inflectional morphology enhances robustness through inflection-specific circuits
- **Medium Confidence**: Inflectional Circuit Detection Dataset successfully enables identification of inflection-processing model components

## Next Checks
1. Implement EAP-IG method with assumed hyperparameters and verify extracted circuits show similar task performance patterns
2. Generate adversarial examples using modified TextBugger with SBERT filtering and validate attack success rates match reported ranges
3. Apply mechanistic interpretability analysis to English classifier using morphologically simple synonyms and compare robustness patterns to inflectional language circuits