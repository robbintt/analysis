---
ver: rpa2
title: Uncovering Emergent Physics Representations Learned In-Context by Large Language
  Models
arxiv_id: '2508.12448'
source_url: https://arxiv.org/abs/2508.12448
tags:
- energy
- learning
- llms
- context
- sparse
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates whether large language models (LLMs) can
  learn and represent physical concepts, specifically energy, during in-context learning
  (ICL). The researchers use a dynamics forecasting task involving coupled mass-spring
  and coupled pendulum systems, where the LLM predicts future trajectories based on
  past data.
---

# Uncovering Emergent Physics Representations Learned In-Context by Large Language Models

## Quick Facts
- arXiv ID: 2508.12448
- Source URL: https://arxiv.org/abs/2508.12448
- Reference count: 40
- Primary result: LLMs learn energy-correlated representations during in-context physics forecasting, improving prediction accuracy and showing causal importance.

## Executive Summary
This study investigates whether large language models can implicitly learn and represent physical concepts during in-context learning. Using coupled mass-spring and pendulum systems, the authors demonstrate that LLMs improve physics trajectory forecasting with longer input contexts. Sparse autoencoder analysis reveals energy-correlated features emerging in mid-level transformer blocks, and ablation experiments confirm these features are functionally necessary for accurate predictions.

## Method Summary
The authors use in-context learning to predict future trajectories of Hamiltonian physical systems. They train SAEs on residual stream activations from Qwen3 transformer blocks to identify sparse, interpretable features. Correlation analysis between SAE features and physical energy quantities (total, kinetic, potential) reveals energy-correlated representations. Ablation experiments remove top energy-correlated features to test functional importance. The study compares performance across different history lengths and examines layer-wise feature emergence.

## Key Results
- Prediction accuracy for physical dynamics improves monotonically with longer input contexts
- Energy-correlated sparse activations emerge preferentially in mid-level transformer blocks
- Ablating energy-correlated features degrades forecasting performance, confirming functional importance

## Why This Works (Mechanism)

### Mechanism 1: Context-Length Dependent Dynamics Encoding
- Prediction accuracy improves with longer contexts as the model accumulates task-relevant information from the full trajectory history
- The transformer attends across the full history sequence, inferring conserved quantities (energy) that govern trajectory evolution
- Evidence: Bounded relative error decreases across all prediction steps as Lhist increases from 64 to 1024

### Mechanism 2: Mid-Layer Energy Feature Crystallization
- Energy-correlated features emerge preferentially in mid-level transformer blocks (8-40 out of 64), suggesting a "physics abstraction" stage
- SAE decomposition reveals sparse features with highest correlation to energy concentrate in middle layers
- Evidence: Block-wise maximum correlation with total energy peaks in middle layers

### Mechanism 3: Causal Necessity of Energy Representations
- Energy-correlated sparse activations are functionally required for accurate prediction; their removal degrades forecasting
- Ablation intervention via zeroing top 1% energy-correlated sparse activations removes energy information from the residual stream
- Evidence: Relative error increase is substantial for mass-spring and pendulum systems when energy features are ablated

## Foundational Learning

- **In-Context Learning (ICL)**: The model performs physics forecasting without weight updates, purely from prompt examples. Why needed: The entire methodology depends on LLMs learning physics concepts from examples alone. Quick check: Can you explain why ICL differs from fine-tuning, and what "task vectors" or "function vectors" might represent?

- **Sparse Autoencoders for Mechanistic Interpretability**: SAEs decompose residual stream activations into sparse, interpretable features. Why needed: The central technique for extracting interpretable features from polysemantic residual stream activations. Quick check: What does "monosemantic" mean in this context, and why is sparsity (L1 penalty) necessary for disentanglement?

- **Hamiltonian Mechanics and Energy Conservation**: The physical systems are governed by Hamiltonians where energy is conserved and determines dynamics. Why needed: Energy is the target correlate because it's conserved and governs trajectory evolution. Quick check: Given a Hamiltonian H = T + V, why would a model benefit from representing energy rather than just memorizing trajectories?

## Architecture Onboarding

- **Component map**: Trajectory z(t) → single-digit tokenization → univariate sequences per DOF → Qwen3 transformer (64 blocks) → residual stream activations → 85 SAEs (2H expansion) → correlation analysis → ablation intervention

- **Critical path**: 1) Generate physics trajectories via Hamiltonian ODE integration 2) Tokenize with scaling and single-digit encoding 3) Run inference, collect residual streams at target blocks 4) Train SAEs with reconstruction + L1 sparsity loss 5) Compute correlations with energy quantities 6) Ablate top 1% energy-correlated features and measure prediction degradation

- **Design tradeoffs**: Single-digit tokenization (more robust to digit changes vs. BPE, but increases sequence length); channel independence (simpler inference vs. missing cross-variable correlations); SAE expansion ratio 2x (balances interpretability vs. training cost)

- **Failure signatures**: Random baseline correlations comparable to energy correlations (features not physics-specific); ablation causes catastrophic output corruption (intervention too aggressive); no layer-wise pattern (hypothesis about mid-layer abstraction unsupported)

- **First 3 experiments**: 1) Reproduce context-length scaling: Run forecasting with Lhist ∈ [64, 128, 256, 512, 1024] on mass-spring; verify bounded relative error decreases monotonically 2) Validate SAE correlation pipeline: Train SAE on block 24 with Lhist=1024; confirm top-100 sparse activations show ρ > 0.3 with total energy 3) Intervention sanity check: Ablate top 1% energy-correlated features vs. random 1% features; verify energy ablation causes significantly larger error increase (ε > 0.2)

## Open Questions the Paper Calls Out

- **Question 1**: Does the inclusion of auxiliary reasoning strategies, such as chain-of-thought prompting or scratchpads, strengthen the emergence or clarity of physics representations in LLMs? The paper suggests it remains open whether structured prompts would further strengthen observed correlations.

- **Question 2**: Can LLMs spontaneously form interpretable representations for physics concepts beyond classical mechanics, such as thermodynamics or quantum mechanics? The study was limited to deterministic classical Hamiltonian dynamics.

- **Question 3**: Do the physics representations learned during trajectory forecasting transfer to human-aligned tasks, such as answering conceptual questions from physics exams? The paper proposes investigating whether these internal features support semantic reasoning about physics.

## Limitations
- SAE features are not explicitly constrained to capture physics; correlations could arise from statistical regularities in training data
- Ablation intervention demonstrates functional necessity but doesn't prove energy representations are the primary mechanism
- Analysis restricted to simple Hamiltonian systems; unclear if similar features emerge for dissipative or chaotic dynamics
- Tokenization scheme and channel independence assumption may oversimplify physics

## Confidence
- **High confidence**: Prediction accuracy improves monotonically with context length for both mass-spring and pendulum systems
- **Medium confidence**: Energy-correlated sparse features emerge in mid-layer transformer blocks and strengthen with context length
- **Medium confidence**: Ablating energy-correlated features degrades performance, confirming their functional importance

## Next Checks
1. Ablate an equal number of random sparse activations (not selected for energy correlation) and compare error increases to those from energy-ablation
2. Apply the same SAE analysis pipeline to a non-physics ICL task to determine whether similar mid-layer sparse features emerge
3. Use integrated gradients or other attribution methods to identify and ablate the most influential activations for final predictions, then measure overlap with energy-correlated features