---
ver: rpa2
title: 'IRIS: An Iterative and Integrated Framework for Verifiable Causal Discovery
  in the Absence of Tabular Data'
arxiv_id: '2510.09217'
source_url: https://arxiv.org/abs/2510.09217
tags:
- causal
- variables
- discovery
- relations
- variable
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: IRIS introduces a hybrid causal discovery framework that automatically
  collects relevant documents, extracts variable values, and uncovers both known and
  novel causal relations without requiring pre-existing datasets. The method combines
  statistical algorithms with LLM-based causal relation extraction and verification,
  while also identifying missing variables to relax the causal sufficiency and acyclicity
  assumptions.
---

# IRIS: An Iterative and Integrated Framework for Verifiable Causal Discovery in the Absence of Tabular Data

## Quick Facts
- arXiv ID: 2510.09217
- Source URL: https://arxiv.org/abs/2510.09217
- Reference count: 31
- Primary result: Hybrid causal discovery framework achieving up to 0.70 F1 score without requiring pre-existing datasets

## Executive Summary
IRIS introduces a novel hybrid framework for causal discovery that operates without pre-existing tabular datasets. By combining statistical algorithms with LLM-based causal relation extraction and verification, IRIS can automatically collect relevant documents, extract variable values, and uncover both known and novel causal relations. The framework also identifies missing variables to relax the causal sufficiency assumption, enabling discovery in scenarios where traditional methods fail.

## Method Summary
IRIS operates through a multi-stage pipeline: document collection via Google Search API with stepwise query generation, value extraction using LLM with Chain-of-Thought prompts to create structured data matrices, statistical causal discovery using algorithms like GES, PC, and NOTEARS, LLM-based causal relation verification through academic document retrieval, and merging of results. The framework iteratively proposes missing variables using a combination of LLM abstraction and Pointwise Mutual Information scoring, feeding expanded variable sets back into the discovery process.

## Key Results
- Consistently outperforms baselines across multiple datasets, achieving up to 0.70 F1 score and 0.30 NHD ratio on cancer data
- Scales effectively from 4 to 27 initial variables while maintaining performance
- GPT-4o-based value extraction reaches 0.79 F1 on AppleGastronome and 0.84 F1 on Neuropathic datasets
- Missing variable proposal achieves up to 1.00 success rate on Diabetes and Obesity datasets

## Why This Works (Mechanism)

### Mechanism 1: Hybrid Causal Discovery via Statistical-LLM Integration
The framework combines statistical algorithms with LLM-based verification, where statistical methods process structured data to generate initial causal graphs while LLMs verify candidate causal relations by retrieving academic documents and assessing support/refute evidence. High-confidence LLM-verified edges are added to statistical results, and strongly refuted edges are removed. This integration leverages the strengths of both approaches: statistical methods handle novel relations while LLMs verify known ones against authoritative sources.

### Mechanism 2: Automated Structured Data Construction from Unstructured Text
LLMs extract variable values from retrieved documents through stepwise query refinement, starting with all variables and progressively removing them to generate targeted queries. Each document is processed with Chain-of-Thought prompts to extract variable values into a structured matrix suitable for statistical causal discovery. This automation eliminates the need for pre-existing datasets while maintaining data quality sufficient for causal analysis.

### Mechanism 3: Missing Variable Proposal via Verification-Statistics Fusion
The framework identifies latent variables by combining LLM-based candidate abstraction with causal relation verification and Pointwise Mutual Information scoring. Each candidate undergoes LLM assessment of document support for causal relations with initial variables, alongside statistical co-occurrence analysis. Variables passing either threshold are added to expanded sets, relaxing causal sufficiency assumptions and enabling discovery of previously unknown causal factors.

## Foundational Learning

- **Causal Sufficiency Assumption**: Traditional causal discovery assumes all relevant variables are observed. IRIS explicitly violates this by proposing missing variables, which is necessary when important causal factors are unknown or undocumented. Quick check: If you run PC algorithm on {smoking, cancer} without "genetics," what type of error might occur?

- **Constraint-Based vs Score-Based Causal Discovery**: IRIS uses GES (score-based) as default but evaluates PC (constraint-based) and NOTEARS. Score-based methods optimize fit metrics while constraint-based methods use conditional independence tests. Understanding their differences helps select appropriate algorithms for different data characteristics. Quick check: What statistical test does PC algorithm use to determine conditional independence?

- **LLM "Causal Parrot" Limitation**: LLMs struggle with novel causal relations absent from pre-training data, motivating the hybrid approach where statistical methods handle novel relations while LLMs verify known ones. This explains why an LLM might correctly identify "smoking causes lung cancer" but fail on newly discovered drug interactions. Quick check: Why would an LLM correctly identify "smoking causes lung cancer" but fail on a newly discovered drug interaction?

## Architecture Onboarding

- **Component map**: Initial variables Z → Document retrieval → Value extraction → Statistical discovery → LLM verification → Graph merging → MVP → Expanded graph G
- **Critical path**: The iterative loop (Document retrieval → Value extraction → Statistical discovery → LLM verification → Graph merging → MVP → Expanded graph G) enables continuous improvement, though single-pass works for fixed variable sets
- **Design tradeoffs**: GES recommended as default (highest average F1), but PC better for some datasets (Respiratory Disease, Obesity). GPT-4o significantly outperforms Llama-3.1-8b on complex domains (ADNI: 0.42 vs 0.11 F1). ~15 hours average runtime with parallelization possible for LLM calls
- **Failure signatures**: Low recall on complex domains (ADNI: 0.36 F1 with best baseline, 0.42 with IRIS), NOTEARS fails completely on some datasets (Diabetes, Obesity: 0 F1), LLM-only baselines degrade on rare/domain-specific causal relations, retrieved document bias or incomplete coverage
- **First 3 experiments**:
  1. **Smoke test on Cancer dataset (5 variables)**: Run full pipeline with GES, verify F1 approaches paper-reported 0.86 on discovery component
  2. **Ablate MVP component**: Compare expanded graph quality with vs without missing variable proposal to isolate MVP contribution
  3. **Stress test with ADNI (8 variables)**: Evaluate why performance drops; inspect retrieved documents for coverage gaps and LLM veracity assessment accuracy

## Open Questions the Paper Calls Out

- Can a meta-learning approach or heuristic be developed to automatically select the optimal statistical algorithm (e.g., PC, GES, NOTEARS) based on the characteristics of the extracted observational data? The authors note significant performance variation across algorithms highlights the importance of selection based on data characteristics.

- How can the integration of causal relations extracted from text be optimized to maintain accuracy while scaling to significantly larger and more complex causal graphs? The framework currently faces quadratic growth in LLM queries relative to variables, limiting efficiency despite parallel processing.

- Can the framework be augmented with a mechanism to explicitly detect and correct for sampling bias in retrieved documents prior to value extraction? The Limitations section identifies "sampling biases, inaccuracies, or incomplete coverage" in retrieved documents as a primary challenge, noting that restricting sources to academic websites is the current, somewhat limited mitigation strategy.

## Limitations

- Document Coverage Bias: The framework depends heavily on Google Search API returning relevant documents, creating systematic blind spots for knowledge in proprietary or paywalled sources
- LLM Reliability Uncertainty: Lacks independent validation of LLM veracity assessments beyond synthetic benchmarks, with potential performance degradation on truly novel causal relations
- Scalability Constraints: Current runtime of ~15 hours limits practical deployment, with iterative nature compounding computational costs as variable sets expand

## Confidence

- **High Confidence**: Statistical causal discovery performance (GES/PC/NOTEARS results) - these algorithms are well-established with known properties
- **Medium Confidence**: LLM-based value extraction and causal relation verification - performance is documented but lacks external validation and may be sensitive to prompt engineering variations
- **Low Confidence**: Missing variable proposal mechanism - while achieving high success rates on tested datasets, the method relies on document co-occurrence patterns that may not generalize to domains with sparse documentation

## Next Checks

1. **External Corpus Validation**: Test IRIS on a held-out domain (e.g., emerging drug-disease relationships) where causal relations are documented in recent literature but not present in training data, to assess true generalization capability

2. **Ground Truth Causality Audit**: Manually verify a sample of LLM-verified causal edges against source documents to quantify veracity assessment accuracy and identify systematic failure modes

3. **Domain Transfer Stress Test**: Apply IRIS to a completely different domain (e.g., social science or economic policy) with known causal structures to evaluate whether the hybrid approach maintains performance across disparate knowledge domains