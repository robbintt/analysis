---
ver: rpa2
title: Self-Attention with State-Object Weighted Combination for Compositional Zero
  Shot Learning
arxiv_id: '2512.18969'
source_url: https://arxiv.org/abs/2512.18969
tags:
- compositions
- states
- object
- objects
- state
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses compositional zero-shot learning (CZSL), which
  aims to recognize novel combinations of states and objects not seen during training.
  The proposed method, SASOW, builds upon the state-of-the-art KG-SP approach by incorporating
  self-attention mechanisms into the state and object classifiers, and introducing
  a weighted combination scheme during composition score calculation.
---

# Self-Attention with State-Object Weighted Combination for Compositional Zero Shot Learning

## Quick Facts
- arXiv ID: 2512.18969
- Source URL: https://arxiv.org/abs/2512.18969
- Authors: Cheng-Hong Chang; Pei-Hsuan Tsai
- Reference count: 26
- One-line primary result: SASOW achieves competitive performance on three benchmark datasets, improving best unseen accuracy by 2.1%, 1.7%, and 0.4% over KG-SP on MIT-States, UT Zappos, and C-GQA respectively.

## Executive Summary
This paper addresses compositional zero-shot learning (CZSL), which aims to recognize novel combinations of states and objects not seen during training. The proposed method, SASOW, builds upon the state-of-the-art KG-SP approach by incorporating self-attention mechanisms into the state and object classifiers, and introducing a weighted combination scheme during composition score calculation. The self-attention mechanism enhances the model's ability to capture interactions between different parts of the image, improving recognition accuracy for complex images. The weighted combination scheme accounts for the varying confidence levels of the state and object classifiers, assigning different weights based on their respective accuracies. Experimental results on three benchmark datasets demonstrate that SASOW achieves competitive performance compared to state-of-the-art methods.

## Method Summary
SASOW is a CZSL method that uses self-attention in state and object classifiers and a weighted combination approach for composing state-object pairs. The method builds on KG-SP, using a ResNet backbone for feature extraction. Self-attention is applied to the feature map through Query, Key, and Value projections, generating attention scores that are multiplied with Value vectors and added to the original features. The weighted combination module raises state probabilities to the power of the accuracy ratio (state accuracy/object accuracy) before matrix multiplication with object probabilities. A feasibility mask from ConceptNet is used to filter implausible compositions. The model is trained end-to-end, with accuracy ratios computed on a validation set and applied during inference.

## Key Results
- SASOW achieves best unseen accuracy improvements of 2.1%, 1.7%, and 0.4% on MIT-States, UT Zappos, and C-GQA respectively compared to KG-SP.
- The self-attention component is particularly effective for complex datasets like MIT-States and C-GQA, where objects are distributed in various positions.
- The weighted combination approach maintains accuracy for seen compositions while effectively improving accuracy for unseen compositions.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Incorporating self-attention into state and object classifiers improves recognition accuracy for images with variable object positions or complex backgrounds.
- **Mechanism**: The self-attention mechanism computes Query (Q), Key (K), and Value (V) vectors from the image feature map. It calculates attention scores (similarity between Q and K) to weight the Value vectors, which are added to the original features. This allows the model to weigh the importance of different feature interactions dynamically.
- **Core assumption**: Standard MLP classifiers in prior work (KG-SP) fail to capture spatial relationships or feature interactions necessary for identifying states/objects in non-canonical layouts.
- **Evidence anchors**:
  - [Section III.A]: "After passing through a Linear layer, $F_{img}$ is separately fed into three Linear layers representing Query (Q), Key (K), and Value (V)... generating a set of scores called attention weights."
  - [Section IV.D.1]: "Self-attention is more effective for the MIT-States and C-GQA datasets... likely due to the complexity... where objects are distributed in various positions."
  - [Corpus]: Neighbor papers (e.g., "Learning Primitive Relations") suggest focusing on relations and feature interactions is a trend in improving CZSL, though the specific attention mechanism here is architecture-specific.
- **Break condition**: If the dataset consists entirely of centered objects with plain backgrounds (e.g., original UT-Zappos), the attention mechanism offers negligible gains or adds unnecessary compute overhead.

### Mechanism 2
- **Claim**: A weighted combination of state and object probability scores improves composition accuracy by accounting for differences in classifier confidence.
- **Mechanism**: Instead of simple matrix multiplication of state ($P_{sta}$) and object ($P_{obj}$) probabilities, the method scales the state probabilities. It raises $P_{sta}$ to the power of the ratio ($State Accuracy / Object Accuracy$). Since object classifiers typically have higher accuracy, this exponent is $< 1$, flattening the state distribution and reducing its dominance in the final joint probability calculation.
- **Core assumption**: Object classification is generally easier/more accurate than state classification; treating both with equal confidence leads to suboptimal joint probabilities.
- **Evidence anchors**:
  - [Section III.B]: "Since the recognition effect of the object classifier is usually better... the ratio is usually smaller than 1... $P_{obj}$ will contribute more to the $S_{com}$."
  - [Section IV.D.2]: "Weight combination maintained the accuracy for seen compositions and effectively improved the accuracy for unseen compositions."
  - [Abstract]: "SASOW introduces a weighted combination approach that accounts for the differences in confidence."
- **Break condition**: If the state classifier achieves accuracy equal to or higher than the object classifier, the weighting logic (flattening state influence) might invert the intended benefit or require re-tuning of the exponent logic.

### Mechanism 3
- **Claim**: Open-World Compositional Zero-Shot Learning (OW-CZSL) requires filtering predicted compositions using a feasibility mask to exclude implausible pairs (e.g., "melted dog").
- **Mechanism**: The system generates a "Feasibility Mask" using external knowledge (specifically ConceptNet, inherited from the KG-SP baseline). This mask acts as a gating function on the final composition scores ($S_{com}$), zeroing out probabilities for state-object pairs deemed semantically impossible.
- **Core assumption**: The search space of all possible state-object pairs contains many invalid combinations that mislead the model if not pruned.
- **Evidence anchors**:
  - [Section I]: "KG-SP... leveraging a semantic model to evaluate the plausibility of composed compositions."
  - [Fig. 2]: Shows "Feasibility Mask" as a distinct component processing the output of the "Composition Score Calculator."
  - [Corpus]: "Feasibility with Language Models for Open-World Compositional Zero-Shot Learning" validates that feasibility/infeasibility constraints are critical for stabilizing OW-CZSL performance.
- **Break condition**: If the external knowledge graph (ConceptNet) is incomplete or outdated, valid rare compositions might be masked as infeasible (false negatives).

## Foundational Learning

- **Concept**: **Self-Attention in Vision**
  - **Why needed here**: Used to enhance feature extraction for classifiers when objects are not centered.
  - **Quick check question**: How does adding self-attention to an MLP classifier change the feature representation compared to a standard linear layer?

- **Concept**: **Compositional Zero-Shot Learning (CZSL)**
  - **Why needed here**: The core problem domain; understanding the difference between "seen" (train) and "unseen" (test) compositions is vital.
  - **Quick check question**: Why is simply training a classifier on seen state-object pairs insufficient for recognizing unseen pairs?

- **Concept**: **Probability Calibration / Score Fusion**
  - **Why needed here**: The "Weighted Combination" mechanism relies on fusing probability scores based on classifier confidence.
  - **Quick check question**: Why might simple multiplication of probabilities ($P_{state} \times P_{object}$) fail if one classifier is significantly overconfident or underconfident?

## Architecture Onboarding

- **Component map**: ResNet Feature Extraction -> Self-Attention Classifiers -> Weighted Score Calculation -> Feasibility Filtering
- **Critical path**: ResNet Feature Extraction → Two parallel classifiers (State, Object) with self-attention → Weighted Combination Module (accuracy-based exponent) → Feasibility Mask (ConceptNet-based)
- **Design tradeoffs**:
  - **Complexity vs. Context**: Self-attention adds computational cost but is necessary for complex backgrounds (verified by UT-Zappos-moving experiment).
  - **Static vs. Dynamic Weights**: The weighting factor ($A_{sta}/A_{obj}$) is based on accuracy; if the test domain shifts such that states become easier to recognize than objects, the fixed ratio might degrade performance.
- **Failure signatures**:
  - **Regression on Simple Data**: If applied to datasets with centered objects and plain backgrounds, the model might underperform simpler baselines due to overfitting on non-existent spatial complexity.
  - **State Dominance**: If object classification accuracy drops unexpectedly, the weighting mechanism may incorrectly flatten the object influence.
- **First 3 experiments**:
  1. **Baseline Comparison**: Run KG-SP (baseline) vs. SASOW on MIT-States to verify the reported ~2.1% improvement in unseen accuracy.
  2. **Ablation on Attention**: Isolate the self-attention component by testing SASOW on the "UT-Zappos-moving" dataset (randomized positions/backgrounds) vs. original UT-Zappos.
  3. **Sensitivity Analysis**: Test the "Weighted Combination" by artificially varying the accuracy ratio inputs to see how sensitive the final composition score is to the specific exponent value.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How can the SASOW framework be adapted to define labeling schemes and evaluation metrics for objects possessing multiple concurrent states?
- **Basis in paper**: [explicit] The authors state that "defining labeling schemes for multi-states and developing methods to evaluate the recognition of multi-state combinations can be explored."
- **Why unresolved**: The current study is restricted to single-state object datasets due to data limitations, and the existing architecture calculates composition scores based on a single state-object pair.
- **What evidence would resolve it**: A modification of the scoring mechanism to handle $N$-state vectors and successful experimentation on a dataset labeled with multiple simultaneous attributes.

### Open Question 2
- **Question**: To what extent would replacing the ResNet backbone with alternative feature extractors, such as Vision Transformers, further improve state and object recognition accuracy?
- **Basis in paper**: [explicit] The conclusion notes that "exploring different methods for extracting image features is crucial" for improving accuracy and utilizing the self-attention mechanism.
- **Why unresolved**: The proposed method relies on ResNet for feature extraction, and the impact of other backbones on the specific self-attention classifiers proposed here remains untested.
- **What evidence would resolve it**: Ablation studies comparing the performance of SASOW using various backbones (e.g., ResNet vs. ViT) on the MIT-States and UT Zappos benchmarks.

### Open Question 3
- **Question**: How does SASOW perform when applied to specialized domain-specific datasets outside of general benchmarks, such as industrial manufacturing or agricultural monitoring?
- **Basis in paper**: [explicit] The authors list "establish[ing] domain-specific datasets and evaluate the feasibility of applying these methods" as a necessary step to extend CZSL applicability.
- **Why unresolved**: The experimental validation is limited to three general benchmark datasets (MIT-States, UT Zappos, C-GQA) and does not cover the specific industrial use cases mentioned in the introduction.
- **What evidence would resolve it**: Benchmarking results from the model applied to novel datasets focused on specific tasks like crop ripeness identification or component defect detection.

## Limitations

- **Model Architecture Details**: The exact MLP configuration (layers, hidden units, activation functions) for the state and object classifiers is unspecified. While self-attention is described, the downstream classifier structure is unclear.
- **Training Hyperparameters**: Learning rate, optimizer choice, batch size, weight decay, and number of training epochs are not reported. These significantly impact performance.
- **Accuracy Ratio Computation**: The method for computing $A_{sta}$ and $A_{obj}$ (the state and object classifier accuracies used for weighting) is ambiguous — whether computed per batch, per epoch, or on a held-out validation set is unspecified.
- **Feasibility Mask Implementation**: The thresholding or scoring method used to generate the ConceptNet-based feasibility mask is not detailed, which could affect the exclusion of invalid state-object pairs.

## Confidence

- **High Confidence**: The core mechanism of using self-attention to improve feature interaction capture for state/object classification in complex images is well-supported by ablation results.
- **Medium Confidence**: The weighted combination approach (flattening state probabilities based on accuracy ratios) is logically sound but depends heavily on accurate accuracy estimation; its effectiveness may vary with domain shifts.
- **Medium Confidence**: The use of ConceptNet for feasibility masking is described, but the specific implementation details (thresholds, scoring) are missing, introducing uncertainty in reproducibility.

## Next Checks

1. **Verify Self-Attention Efficacy**: Reproduce the ablation experiment on UT-Zappos-moving (randomized positions/backgrounds) to confirm that self-attention significantly improves performance compared to the original UT-Zappos dataset.
2. **Test Weighted Combination Sensitivity**: Vary the accuracy ratio ($A_{sta}/A_{obj}$) inputs artificially (e.g., 0.5, 1.0, 2.0) to assess how sensitive the final composition accuracy is to the exponent value in the weighted combination.
3. **Reconstruct Feasibility Mask**: Implement the ConceptNet-based feasibility mask using the same method as KG-SP (likely semantic similarity scoring) and validate that implausible pairs (e.g., "melted dog") are correctly excluded without over-filtering rare but valid compositions.