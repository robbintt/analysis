---
ver: rpa2
title: Efficient Agent Training for Computer Use
arxiv_id: '2505.13909'
source_url: https://arxiv.org/abs/2505.13909
tags:
- action
- task
- computer
- data
- trajectory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces PC Agent-E, an efficient framework for training
  computer use agents that significantly reduces the need for large-scale human demonstrations.
  Starting with only 312 human-annotated trajectories, the authors enhance data quality
  by synthesizing diverse action decisions using Claude 3.7 Sonnet, resulting in 27K
  augmented training instances.
---

# Efficient Agent Training for Computer Use

## Quick Facts
- arXiv ID: 2505.13909
- Source URL: https://arxiv.org/abs/2505.13909
- Reference count: 40
- Key outcome: PC Agent-E achieves 141% relative improvement over baseline and outperforms Claude 3.7 Sonnet with extended thinking on WindowsAgentArena-V2

## Executive Summary
PC Agent-E introduces an efficient framework for training computer use agents that dramatically reduces the need for large-scale human demonstrations. The authors demonstrate that starting with just 312 human-annotated trajectories, they can generate 27K augmented training instances through Trajectory Boost, achieving state-of-the-art performance. The model shows strong results on both Windows and Linux systems, achieving 72.0% success rate on WindowsAgentArena-V2 and outperforming previous baselines on OSWorld benchmarks.

## Method Summary
The paper presents PC Agent-E, an efficient training framework that addresses the challenge of expensive human annotation requirements for computer use agents. The key innovation is Trajectory Boost, which synthesizes diverse action decisions from a small set of human demonstrations. Starting with only 312 human-annotated trajectories, the method generates alternative action decisions at each step using Claude 3.7 Sonnet, creating a rich dataset of 27K training instances. This approach captures the inherent diversity in how tasks can be completed while maintaining data quality and relevance.

## Key Results
- PC Agent-E achieves a 141% relative improvement over the Qwen2.5-VL-72B baseline on WindowsAgentArena-V2
- Outperforms Claude 3.7 Sonnet with extended thinking on WindowsAgentArena-V2
- Demonstrates strong generalizability to Linux systems on OSWorld benchmarks
- Achieves 72.0% success rate on WindowsAgentArena-V2

## Why This Works (Mechanism)
The effectiveness of PC Agent-E stems from its ability to generate diverse, high-quality synthetic data from minimal human demonstrations. By using Trajectory Boost to create alternative action paths, the model learns a more robust understanding of computer use tasks that isn't limited to a single solution path. This diversity in training data helps the agent handle variations in real-world scenarios and improves generalization across different operating systems.

## Foundational Learning
- **Trajectory Synthesis**: Understanding how to generate diverse action sequences from limited demonstrations - needed to scale training data efficiently
- **Action Decision Diversity**: Recognizing multiple valid approaches to complete computer tasks - needed for robust generalization
- **Cross-platform Adaptability**: Learning transferable skills between Windows and Linux environments - needed for real-world applicability
- **Data Quality vs Quantity Tradeoff**: Balancing synthetic data generation with maintaining training signal integrity - needed to avoid model degradation

## Architecture Onboarding

**Component Map**: Human Demonstrations -> Trajectory Boost (Claude 3.7) -> Synthetic Data Generation -> Training Pipeline -> PC Agent-E

**Critical Path**: The Trajectory Boost step is the critical component, as it transforms limited human data into a rich training corpus. This step directly determines the quality and diversity of synthetic data, which in turn impacts model performance.

**Design Tradeoffs**: The approach trades computational cost of running a large language model (Claude 3.7) for human annotation effort. While this requires significant compute resources for data synthesis, it eliminates the need for extensive human-labeled datasets, making the overall process more scalable.

**Failure Signatures**: The model may struggle with tasks requiring very specific sequences of actions not well-represented in the synthetic data. Edge cases in user interface design or novel software interactions may not be adequately covered by the Trajectory Boost approach.

**First Experiments**:
1. Test PC Agent-E on completely unseen software applications outside benchmark environments
2. Evaluate performance degradation when reducing the number of human demonstrations below 312
3. Compare results when using different models for Trajectory Boost synthesis

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Evaluation scope limited to controlled benchmark environments, not fully representative of real-world complexity
- Heavy reliance on Claude 3.7 Sonnet for both data synthesis and comparison, with no independent verification of generated action diversity
- Lack of comparison against other recent approaches in the literature, making absolute performance assessment difficult

## Confidence
- **High confidence**: Efficiency gains from reduced human annotation requirements and reported performance improvements on established benchmarks
- **Medium confidence**: Generalizability claims to Linux systems, given limited evaluation scope
- **Medium confidence**: Trajectory Boost methodology's effectiveness in capturing action decision diversity, pending independent validation

## Next Checks
1. Conduct ablation studies removing Trajectory Boost to quantify its specific contribution to performance improvements
2. Test PC Agent-E on additional real-world computer use scenarios outside of benchmark environments
3. Evaluate the model's robustness to adversarial or unexpected user interface changes and edge cases in computer interaction tasks