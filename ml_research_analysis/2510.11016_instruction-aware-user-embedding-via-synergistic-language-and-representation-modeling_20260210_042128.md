---
ver: rpa2
title: Instruction-aware User Embedding via Synergistic Language and Representation
  Modeling
arxiv_id: '2510.11016'
source_url: https://arxiv.org/abs/2510.11016
tags:
- user
- representation
- learning
- language
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the limitations of existing user representation
  models, which struggle with generalizability across domains and sensitivity to noisy
  behavioral signals. The authors propose InstructUE, an instruction-aware user embedding
  foundation model that leverages large language models (LLMs) to generate general
  and instruction-aware user representations.
---

# Instruction-aware User Embedding via Synergistic Language and Representation Modeling

## Quick Facts
- arXiv ID: 2510.11016
- Source URL: https://arxiv.org/abs/2510.11016
- Reference count: 40
- Primary result: Multi-encoder foundation model with contrastive-autoregressive training outperforms existing methods across 6 real-world user prediction scenarios

## Executive Summary
This paper introduces InstructUE, an instruction-aware user embedding foundation model that addresses limitations in existing user representation approaches. Traditional models struggle with generalizability across domains and sensitivity to noisy behavioral signals. InstructUE leverages large language models to generate both general-purpose and instruction-conditioned user embeddings from heterogeneous multi-source behavioral data including transactions, mini-program usage, search queries, and profile features.

The key innovation is a multi-encoder architecture with lightweight adapters that efficiently processes diverse data types while preserving their structural characteristics. Coupled with a novel contrastive-autoregressive training framework, the model simultaneously captures domain knowledge through autoregressive learning in language space and aligns user-text embeddings in representation space through contrastive learning. Extensive experiments demonstrate significant performance improvements across user prediction, marketing, and recommendation scenarios, with instruction-aware modeling effectively achieving instruction-guided denoising of user information.

## Method Summary
InstructUE is a foundation model for instruction-aware user embedding generation that processes heterogeneous behavioral data through a multi-encoder architecture. The model uses modality-specific encoders (BERT-based) with lightweight MLP adapters to project data into a shared representation space compatible with a Qwen2.5-0.5B-Instruct backbone. Training employs a joint contrastive-autoregressive objective using a synthetic UserQA dataset of 200M triplets, where autoregressive loss captures domain knowledge in language space while contrastive loss aligns user embeddings in representation space. The model can produce either general-purpose embeddings or task-conditioned embeddings via natural language instructions.

## Key Results
- Outperforms existing methods across 6 real-world scenarios with average AUC gains of 2-3%
- Instruction-aware modeling effectively achieves instruction-guided denoising of user information
- Strong generalizability across domains including user prediction, marketing, and recommendation tasks
- Ablation studies confirm the importance of contrastive-autoregressive training and multi-encoder design

## Why This Works (Mechanism)
The model's effectiveness stems from synergistic language and representation modeling. The contrastive-autoregressive training framework bridges the gap between language and representation spaces by simultaneously leveraging autoregressive learning to capture domain knowledge in language space and contrastive learning to align user-text embeddings in representation space. This dual approach enhances both instruction-awareness and noise-robustness. The multi-encoder architecture with lightweight adapters efficiently processes heterogeneous data types while preserving their structural characteristics, enabling the model to handle diverse behavioral signals without losing modality-specific information.

## Foundational Learning

### User Representation Learning
**Why needed**: Traditional user embeddings struggle with cross-domain generalization and noise sensitivity from heterogeneous behavioral data.
**Quick check**: Compare embedding quality across different domains and noise levels.

### Contrastive Learning with False-Negative Masking
**Why needed**: Standard contrastive learning can create false negatives when semantically similar user profiles or answers are treated as negative pairs.
**Quick check**: Measure performance impact when varying the masking threshold for false negatives.

### Instruction-Guided Denoising
**Why needed**: Raw behavioral data contains noise and irrelevant signals that degrade embedding quality for specific tasks.
**Quick check**: Evaluate embedding performance with and without task-specific instructions.

## Architecture Onboarding

### Component Map
Qwen2.5-0.5B-Instruct (LLM) <- MLP Adapters <- BERT Encoders <- Heterogeneous Data Sources (Bill, Mini Program, SPM, Search, Tabular)

### Critical Path
User behavioral data → Modality-specific BERT encoders → MLP adapters → LLM space → Joint contrastive-autoregressive training → Final user embedding

### Design Tradeoffs
The paper uses lightweight MLP adapters instead of full fine-tuning to balance parameter efficiency with representation quality. The choice of BERT encoders for structured data versus direct LLM processing trades off flexibility for better handling of sequential behavioral patterns. The synthetic UserQA dataset enables large-scale training but requires careful generation to ensure quality.

### Failure Signatures
Performance degradation occurs when using average pooling instead of <USER> token extraction (e.g., Film Pref: 84.41 vs 85.92 AUC). Poor instruction specification on ambiguous tasks leads to performance drops (e.g., Purchasing Power: 94.50→95.69 after tuning). Missing hyperparameter specifications for contrastive loss masking can cause suboptimal embedding alignment.

### First Experiments
1. Train with contrastive loss only (no autoregressive component) to measure contribution of language modeling
2. Replace BERT encoders with direct LLM processing to evaluate encoder necessity
3. Test with different UserQA synthesis approaches to quantify synthetic data impact

## Open Questions the Paper Calls Out

### Unknown 1: Temperature τ and margin c_margin hyperparameters for InfoNCE loss masking threshold (s_im > s(û_i, â+_i) + c_margin).
### Unknown 2: UserQA synthesis prompts/templates and instruction vocabulary used for generating training triplets.
### Unknown 3: Exact tabular feature schema (F features, D embedding dim per feature) and encoder architecture details.

## Limitations

- Missing hyperparameter specifications for contrastive loss masking mechanism (temperature τ and margin c_margin)
- Reliance on a curated UserQA dataset of 200M triplets raises questions about scalability and data efficiency for new domains
- Results reported only on specific benchmark; generalization to other user modeling tasks not demonstrated

## Confidence

- **High confidence**: Core architecture design and reported performance improvements over baselines (average AUC gains of 2-3%)
- **Medium confidence**: Effectiveness of instruction-aware denoising and contrastive loss masking implementation details
- **Medium confidence**: Scalability claims based on 200M UserQA dataset and training data generation procedures

## Next Checks

1. **Hyperparameter sensitivity analysis**: Systematically vary temperature τ and margin c_margin values in contrastive loss to identify optimal settings
2. **Cross-domain generalization test**: Evaluate InstructUE on at least one new user modeling task not in original benchmark
3. **Ablation on data synthesis**: Compare performance using different UserQA generation approaches to quantify synthetic data quality impact