---
ver: rpa2
title: 'HA-RAG: Hotness-Aware RAG Acceleration via Mixed Precision and Data Placement'
arxiv_id: '2510.20878'
source_url: https://arxiv.org/abs/2510.20878
tags:
- chunks
- memory
- arxiv
- data
- compression
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the performance bottleneck in Retrieval-Augmented
  Generation (RAG) systems caused by KV chunk loading and memory access overhead.
  The authors propose HA-RAG, a hotness-aware optimization framework that combines
  mixed-precision compression with data placement strategies.
---

# HA-RAG: Hotness-Aware RAG Acceleration via Mixed Precision and Data Placement

## Quick Facts
- arXiv ID: 2510.20878
- Source URL: https://arxiv.org/abs/2510.20878
- Reference count: 40
- Primary result: Achieves 2.10x average speedup in TTFT compared to TurboRAG with negligible accuracy loss

## Executive Summary
This paper addresses the performance bottleneck in Retrieval-Augmented Generation (RAG) systems caused by KV chunk loading and memory access overhead. The authors propose HA-RAG, a hotness-aware optimization framework that combines mixed-precision compression with data placement strategies. By analyzing KV chunk access patterns and numerical distributions, HA-RAG applies different compression formats (INT8, FP8, GSE-8) based on access frequency and strategically places frequently accessed chunks in faster memory hierarchies. Experimental results show HA-RAG achieves an average speedup of 2.10x and maximum speedup of 10.49x in Time-To-First-Token (TTFT) compared to TurboRAG, with negligible accuracy loss. The method effectively balances inference performance and accuracy for practical RAG deployment.

## Method Summary
HA-RAG works by first profiling KV chunk access frequencies across representative queries to identify "hot" chunks. It then applies a tiered compression strategy: frequently accessed chunks use high-precision formats (INT8) while infrequently accessed chunks use faster-decompression formats (GSE-8). The compressed chunks are strategically placed in a heterogeneous memory hierarchy—hot chunks in GPU/CPU pinned memory, cold chunks on disk. During inference, chunks are loaded on-demand with LRU eviction, and decompression happens on-the-fly before being fed to the LLM.

## Key Results
- Achieves 2.10x average speedup and 10.49x maximum speedup in TTFT compared to TurboRAG
- Maintains negligible accuracy loss with ROUGE-1 F1 scores comparable to baseline
- Effectively balances inference quality and decompression efficiency through hotness-aware compression

## Why This Works (Mechanism)

### Mechanism 1
Reducing data volume through mixed-precision compression decreases disk I/O and memory access overhead, directly accelerating data loading. KV chunks are compressed from BF16 to 8-bit formats, reducing data size transferred from disk to memory and alleviating the primary bottleneck where KV loading accounts for ~70% of inference latency.

### Mechanism 2
Assigning compression formats based on access frequency balances inference quality and decompression efficiency. Frequently accessed chunks use high-precision, low-decompression-time formats to preserve quality and speed for most queries, while infrequently accessed chunks use lower-precision, faster-decompression formats to minimize overhead for rare cases.

### Mechanism 3
Prioritizing frequently accessed data in faster memory hierarchies reduces average access latency. A tiered storage system places hot KV chunks in GPU or CPU pinned memory and cold chunks on disk or CPU pageable memory, increasing the "hit rate" in fast memory and avoiding slow disk I/O and DMA transfers.

## Foundational Learning

- **KV Cache in LLM Inference**: The entire paper optimizes how to store and load precomputed Key-Value tensors for RAG. Understanding what they are and why they are large is fundamental. Quick check: What is the approximate size of a single KV chunk for a 7B model with 512 tokens, stored in BF16? (A: ~2MB, derived from paper's 128GB/4381 chunks example).

- **Heterogeneous Memory Hierarchy**: The core optimization exploits latency differences between disk, CPU pageable memory, CPU pinned memory, and GPU memory. Quick check: Why is transferring data from pinned memory to GPU faster than from pageable memory? (A: Pinned memory is page-locked, avoiding an intermediate copy to a pageable staging buffer before DMA).

- **RAG Prefill Bottleneck**: The paper targets Time-To-First-Token (TTFT), which is dominated by the prefill stage in long-context RAG. The problem exists because prefill computation grows quadratically with sequence length. Quick check: How does TurboRAG attempt to solve the prefill bottleneck? (A: By precomputing KV caches for documents, turning compute into a data loading problem).

## Architecture Onboarding

- **Component map**: Offline Profiler -> KV Compressor -> Data Placement Manager -> RAG Inference Engine
- **Critical path**: A new inference query arrives -> Retrieval step identifies relevant KV chunks -> Placement Manager checks `queueGPU` (hit/miss) -> If miss, checks `queuePIN` -> If miss, loads from Disk/Pageable memory -> Decompresses chunk on-the-fly -> Loads into `queueGPU` (potentially evicting via LRU) -> LLM continues prefill
- **Design tradeoffs**:
  - Speed vs. Accuracy: Assigning more chunks to GSE-8 improves decompression speed but increases accuracy loss
  - Capacity vs. Hit Rate: Increasing `τ_GPU` increases hit rate but reduces memory available for the model and activations
  - Generality vs. Specialization: The access frequency profile is workload-dependent and may not generalize to different query distributions
- **Failure signatures**:
  - Accuracy Collapse: ROUGE-1 F1 scores drop significantly, indicating precision loss from compression is too high
  - OOM Errors: The `queueGPU` capacity is set too high, leaving insufficient VRAM for the model or batch activations
  - TTFT Not Improving: The `MP-only` baseline shows good speedup, but the full system does not, implying data placement is failing
- **First 3 experiments**:
  1. Validate compression impact by replicating RMSE and ROUGE-1 F1 analysis on your own RAG knowledge base
  2. Profile access patterns by running representative query traces to confirm skewed hotness distribution
  3. Tune memory thresholds by implementing a grid search over placement thresholds, measuring TTFT to find optimal memory allocation

## Open Questions the Paper Calls Out

### Open Question 1
How does HA-RAG performance and accuracy degrade when applied to significantly larger LLMs (e.g., 70B+ parameters) or different architectures? The experimental evaluation is restricted to LLaMA2-7B, yet the numerical distribution analysis used to justify GSE-8 compression is model-dependent.

### Open Question 2
How can the system dynamically adapt to real-time shifts in query distribution (concept drift) without requiring an offline re-profiling phase? The methodology relies on pre-computed access frequency statistics to determine compression schemes and data placement.

### Open Question 3
What are the computational and latency trade-offs when applying HA-RAG to dynamic knowledge bases requiring frequent document insertions or updates? The framework relies on precomputing and compressing static KV chunks, but RAG's purpose is to address knowledge-update delays.

## Limitations
- Assumes highly skewed access patterns that may not generalize to all RAG workloads
- GSE-8 compression format implementation details are underspecified
- Evaluation uses single dataset (MS MARCO with TriviaQA) and model (LLaMA-2-7B), limiting generalizability
- Memory hierarchy optimization depends on specific hardware configurations that may not be universally available

## Confidence

- TTFT speedup claims (2.10x average, 10.49x maximum): **Medium-High** - Based on controlled experiments with clear baselines, though limited to one dataset and model
- Negligible accuracy loss claim: **Medium** - ROUGE-1 F1 metrics show acceptable degradation, but impact on end-user experience is not evaluated
- Access pattern analysis and hotness profiling: **Medium** - Skewed distribution is demonstrated, but profiling methodology for deployment is not fully specified
- Compression format effectiveness (INT8, FP8, GSE-8): **Medium-High** - RMSE and ROUGE metrics are provided, but GSE-8 implementation details are incomplete

## Next Checks

1. **Cross-dataset validation**: Replicate TTFT and accuracy experiments on at least two additional RAG datasets with different access patterns to test generalization of the hotness assumption.

2. **GSE-8 implementation verification**: Implement the GSE-8 compression format using the 1+4+3 shared exponent method and validate that the decompression RMSE matches claimed values across the full range of KV chunk value distributions.

3. **Real-world deployment stress test**: Deploy HA-RAG in a production environment with varying query loads and document collections, monitoring cache hit rates, memory usage patterns, and TTFT under sustained traffic to identify potential performance cliffs.