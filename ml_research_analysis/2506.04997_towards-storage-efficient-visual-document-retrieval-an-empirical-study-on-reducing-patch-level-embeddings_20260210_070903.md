---
ver: rpa2
title: 'Towards Storage-Efficient Visual Document Retrieval: An Empirical Study on
  Reducing Patch-Level Embeddings'
arxiv_id: '2506.04997'
source_url: https://arxiv.org/abs/2506.04997
tags:
- merging
- colqwen2
- performance
- pruning
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the excessive memory usage of ColPali/ColQwen2,
  which encodes each document page into multiple patch-level embeddings for visual
  document retrieval. The authors systematically investigate token reduction strategies,
  finding that token pruning is inherently unsuitable for VDR due to the unpredictability
  of query-conditioned patch importance.
---

# Towards Storage-Efficient Visual Document Retrieval: An Empirical Study on Reducing Patch-Level Embeddings

## Quick Facts
- **arXiv ID**: 2506.04997
- **Source URL**: https://arxiv.org/abs/2506.04997
- **Reference count**: 20
- **Primary result**: Light-ColPali/ColQwen2 achieves 98.2% retrieval performance with 11.8% memory usage through token merging instead of pruning

## Executive Summary
This study addresses the excessive memory consumption of ColPali and ColQwen2 visual document retrieval systems, which encode each document page into multiple patch-level embeddings. Through systematic investigation, the authors demonstrate that token pruning is inherently unsuitable for VDR due to the unpredictability of query-conditioned patch importance. Instead, they propose Light-ColPali/ColQwen2, which employs token merging through semantic clustering at the final stage of the retrieval pipeline. The approach maintains 98.2% of original retrieval performance with only 11.8% of memory usage, and preserves 94.6% effectiveness at just 2.8% memory footprint.

## Method Summary
The authors systematically investigate token reduction strategies for ColPali and ColQwen2 visual document retrieval systems. They evaluate various pruning approaches including magnitude-based pruning and discover these methods are fundamentally unsuitable due to the unpredictable importance of patches across different queries. Their proposed solution, Light-ColPali/ColQwen2, implements token merging through semantic clustering at the final retrieval stage. This approach clusters similar patch embeddings and merges them into representative tokens, significantly reducing memory footprint while preserving retrieval accuracy. The system processes documents through standard visual encoding, applies semantic clustering to reduce token count, and performs similarity search on the compressed representation.

## Key Results
- Light-ColPali achieves 98.2% of original retrieval performance using only 11.8% of memory
- At extreme compression (2.8% memory usage), the system maintains 94.6% of original effectiveness
- Token pruning is shown to be fundamentally unsuitable for VDR due to query-dependent patch importance

## Why This Works (Mechanism)
The effectiveness of token merging over pruning stems from the fundamental nature of visual document retrieval, where different queries require different patches to be important. Unlike text retrieval where word importance can be predicted more reliably, visual document patches exhibit highly variable importance depending on the query context. Token merging preserves the overall semantic content by grouping similar patches and maintaining their collective information, while pruning risks removing patches that may be crucial for specific queries. The semantic clustering approach ensures that related visual information is preserved even when individual patches are merged.

## Foundational Learning
- **Visual document embedding**: Patch-level embeddings capture both text and visual layout information; needed to understand why multiple tokens per page are necessary for accurate retrieval; quick check: verify embedding dimensionality matches document patch size
- **Semantic clustering**: Grouping similar embeddings based on learned representations; needed to understand the token merging mechanism; quick check: confirm cluster cohesion metrics are reasonable
- **Query-conditioned importance**: Patch relevance varies based on specific queries; needed to understand why pruning fails; quick check: analyze patch importance distribution across different query types
- **Retrieval pipeline stages**: Final-stage processing allows optimization without retraining; needed to understand where token reduction occurs; quick check: trace data flow through each pipeline stage
- **Memory-performance trade-offs**: Compression ratios must balance storage savings against accuracy loss; needed to evaluate system effectiveness; quick check: verify reported compression ratios against actual storage measurements

## Architecture Onboarding

**Component map**: Document pages -> Visual Encoder -> Patch Embeddings -> Semantic Clustering -> Merged Tokens -> Similarity Search

**Critical path**: Visual encoding → Patch extraction → Semantic clustering → Retrieval

**Design tradeoffs**: The system trades computational overhead from clustering against significant memory savings. While pruning would be computationally cheaper, it fails to maintain retrieval accuracy. The clustering approach adds processing time but preserves semantic completeness, making it suitable for scenarios where memory is constrained but computational resources are available.

**Failure signatures**: 
- If clustering is too aggressive, semantically distinct patches may be merged, reducing retrieval precision
- If clustering is too conservative, memory savings will be insufficient
- Poor query performance on documents with dense layouts suggests inadequate patch preservation

**First experiments to run**:
1. Benchmark memory usage and retrieval accuracy across different compression ratios (11.8%, 2.8%, etc.)
2. Compare retrieval performance on single-query vs. multi-query scenarios to validate query-conditioned importance findings
3. Test robustness across document types with varying complexity (text-heavy vs. graphic-heavy layouts)

## Open Questions the Paper Calls Out
None

## Limitations
- All experiments conducted on a single benchmark dataset (SDS KoPub VDR) in Korean, limiting generalizability to other languages and document types
- The study focuses primarily on simple magnitude-based pruning without exploring more sophisticated adaptive or query-aware pruning approaches
- Computational overhead of the semantic clustering process is not fully characterized

## Confidence
- Token pruning unsuitability claim: **High** - extensively validated through multiple experiments
- Memory reduction effectiveness: **Medium** - strong empirical results but limited to one dataset
- Clustering approach superiority: **Medium** - demonstrated effectiveness but unexplored alternatives

## Next Checks
1. Test Light-ColPali/ColQwen2 on multilingual datasets and non-Korean document collections to assess cross-lingual and cross-domain generalization
2. Benchmark the computational overhead of the semantic clustering step and compare against alternative token merging strategies
3. Evaluate the robustness of retrieval performance under varying document complexity levels (e.g., dense text vs. complex layouts with graphics)