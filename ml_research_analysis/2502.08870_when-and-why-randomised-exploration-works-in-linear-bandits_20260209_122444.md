---
ver: rpa2
title: When and why randomised exploration works (in linear bandits)
arxiv_id: '2502.08870'
source_url: https://arxiv.org/abs/2502.08870
tags:
- regret
- randomised
- exploration
- sampling
- linear
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper analyzes when and why randomized exploration algorithms\
  \ like Thompson sampling work in linear bandits. The authors show that under smoothness\
  \ and strong convexity conditions on the action set, randomized exploration algorithms\
  \ can achieve O(d\u221An log n) regret, matching the optimal dimension dependence\
  \ in linear bandit problems."
---

# When and why randomised exploration works (in linear bandits)

## Quick Facts
- arXiv ID: 2502.08870
- Source URL: https://arxiv.org/abs/2502.08870
- Reference count: 38
- One-line primary result: Randomized exploration algorithms like Thompson sampling can achieve O(d√n log n) regret in linear bandits when action sets are smooth and strongly convex, matching optimal dimension dependence without forced optimism

## Executive Summary
This paper analyzes when and why randomized exploration algorithms like Thompson sampling work in linear bandits. The authors show that under smoothness and strong convexity conditions on the action set, randomized exploration algorithms can achieve O(d√n log n) regret, matching the optimal dimension dependence in linear bandit problems. Their analysis does not rely on forced optimism or posterior inflation, unlike previous work. The key insight is that smooth and strongly convex action sets allow perturbations in the parameter space to translate to perturbations in the action space, while ensuring small changes in the action space only lead to small changes in regret. This work provides the first non-trivial setting where unmodified Thompson sampling achieves optimal dimension dependence in regret.

## Method Summary
The method implements Thompson sampling for linear bandits by maintaining a Gaussian posterior over the unknown parameter θ*. At each round, it samples a perturbation η_t from a rotationally invariant distribution, forms θ_t = θ̂_{t-1} + V_{t-1}^{-1/2}η_t, and selects X_t as the gradient of the support function ∇J_X(θ_t). The algorithm updates its estimate θ̂_t and design matrix V_t using regularized least squares. The key innovation is analyzing this unmodified Thompson sampling approach without the √d inflation term required by previous analyses, enabled by geometric properties of smooth and strongly convex action sets.

## Key Results
- Randomized Thompson sampling achieves O(d√n log n) regret when action sets satisfy smoothness and strong convexity
- This matches the optimal dimension dependence without requiring forced optimism or posterior inflation
- The regret bound depends on the ratio M/m (smoothness to strong convexity) and the norm of θ*
- The analysis applies to ℓ_p balls for p ∈ (1, ∞) but not to polytopes or ℓ₁/ℓ∞ balls

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Small perturbations in parameter space translate to controlled perturbations in action space, and small action changes yield bounded regret changes.
- Mechanism: The support function J_X(θ) = max_{x∈X}⟨x, θ⟩ maps parameters to optimal rewards. When J²_X is both m-strongly convex and M-smooth (Assumption 2), the gradient ∇J_X(θ) exists and provides the selected action X_t = ∇J_X(θ_t). Strong convexity ensures parameter perturbations induce action perturbations; smoothness ensures action perturbations induce bounded regret changes.
- Core assumption: Action set X satisfies Assumption 2: closed, absorbing subset of unit ball, with J²_X having bounded strong convexity (m > 0) and smoothness (M < ∞) w.r.t. some norm ||·||_*.
- Evidence anchors:
  - [abstract]: "smooth and strongly convex action sets allow perturbations in the parameter space to translate to perturbations in the action space, while ensuring small changes in the action space only lead to small changes in regret"
  - [Section 4.2, Definitions 2-3]: Formal definitions of m-strong convexity and M-smoothness via Bregman divergence bounds
  - [corpus]: Weak/absent—corpus papers focus on modified Thompson sampling variants rather than geometric conditions
- Break condition: Non-smooth action sets (e.g., polytopes, ℓ_1/ℓ_∞ balls) break the gradient regularity; non-convex sets break the perturbation-to-action mapping.

### Mechanism 2
- Claim: Non-optimistic samples still provide useful exploration information on average, enabling confidence set shrinkage without forced optimism.
- Mechanism: Prior analyses required forced optimism (constant probability that J(θ_t) ≥ J(θ*)) via posterior inflation, which adds √d to regret. This analysis tracks the *expected* information gain E_{t-1}[X_t X_t^T] directly. Even when θ_t is not optimistic, Lemma 5 shows that ∥E_{t-1}[X_t X_t^T]^{1/2} V_{t-1}^{-1/2} u∥ is bounded below, implying directional exploration occurs. Lemma 6 then shows realized design matrices track their expectations, so confidence sets shrink reliably.
- Core assumption: Perturbations η_t are rotationally invariant with bounded second and fourth moments (Assumption 1), ensuring diffuse sampling.
- Evidence anchors:
  - [Section 4.3, p.6-7]: "while a particular sample may provide very little information... it may still provide useful information on average... it may prove useful at later steps"
  - [Figure 1]: Visual illustration of non-optimistic exploration shrinking confidence sets
  - [corpus]: Agrawal & Goyal (2013), Abeille & Lazaric (2017) cited as requiring inflation; this work avoids it
- Break condition: If perturbations concentrate in a subspace, directional exploration fails; if action set has "trap" arms (Hamidi & Bayati 2023), algorithm may never exit.

### Mechanism 3
- Claim: Per-step regret equals Bregman divergence of the support function, enabling direct regret analysis via geometry.
- Mechanism: For diffuse sampling distributions, X_t = ∇J_X(θ_t) almost surely, giving r_t = J_X(θ*) - ⟨X_t, θ*⟩ = D_{J_X}(θ*, θ_t). The regret decomposition (Eq. 3) splits into optimistic rounds (handled like UCB) and non-optimistic rounds (controlled via strong convexity of J²_X). Strong convexity lower-bounds the divergence; smoothness upper-bounds it.
- Core assumption: J²_X satisfies strong convexity and smoothness, and the conditional law of θ_t is diffuse (implied by rotational invariance).
- Evidence anchors:
  - [Section 4.2, p.4]: "the per-step regret of randomised algorithms is given by the divergence rt = D_{J_X}(θ*, θ_t)"
  - [Section 5.1, Eq. 3]: Regret decomposition into ¯R^{TS}_n (non-optimistic) and ¯R^{OPT}_n (optimistic) terms
  - [corpus]: No direct corpus support; standard bandit analyses use confidence bounds, not Bregman divergences
- Break condition: If ∇J_X(θ_t) doesn't exist (non-smooth action sets) or sampling is atomic (not diffuse), the divergence representation fails.

## Foundational Learning

- Concept: **Linear Bandits & Regret**
  - Why needed: Core problem formulation; all notation builds from here
  - Quick check question: Given unknown θ* ∈ ℝ^d, action set X ⊂ ℝ^d, and rewards Y_t = ⟨X_t, θ*⟩ + noise, what is the n-step regret R_n?

- Concept: **Thompson Sampling (Posterior Sampling)**
  - Why needed: The algorithm class being analyzed; distinguishes from optimistic methods
  - Quick check question: How does Thompson sampling select actions differently from OFUL/UCB-style optimistic algorithms?

- Concept: **Self-Normalized Confidence Ellipsoids (Abbasi-Yadkori et al. 2011)**
  - Why needed: Foundation for confidence set construction Θ_t = {θ : ||θ - θ̂_t||_{V_t} ≤ β_t}
  - Quick check question: What does the weighted norm ||θ - θ̂_t||_{V_t} measure, and why use V_t = λI + Σ X_i X_i^T?

- Concept: **Strong Convexity & Smoothness of Functions**
  - Why needed: Assumption 2 is the key structural condition enabling the analysis
  - Quick check question: For a function f, what does m-strong convexity guarantee about D_f(x, y) vs. ||x-y||²?

- Concept: **Bregman Divergence**
  - Why needed: Mathematical tool connecting regret to action set geometry
  - Quick check question: For convex f, define D_f(x, y) = f(x) - f(y) - ⟨∇f(y), x-y⟩. What is D_f(x, y) when f(x) = ||x||²?

## Architecture Onboarding

- Component map:
  1. **Parameter Estimator**: Maintains θ̂_t = V_t^{-1} Σ_{i=1}^t Y_i X_i via regularized least squares (V_0 = λI)
  2. **Confidence Width Computer**: Computes β_t = R√λ + S√{2 log(1/δ) + log(det(V_t)/λ^d)}
  3. **Perturbation Sampler**: Draws η_t ~ distribution satisfying Assumption 1 (e.g., N(0, I) or Uniform(√d·S^{d-1}))
  4. **Parameter Perturbator**: Forms θ_t = θ̂_{t-1} + V_{t-1}^{-1/2} η_t
  5. **Action Selector**: Solves X_t = argmax_{x∈X} ⟨x, θ_t⟩ = ∇J_X(θ_t) (via optimization or closed-form gradient)
  6. **Design Matrix Updater**: V_t = V_{t-1} + X_t X_t^T

- Critical path:
  1. Initialize: V_0 = λI, θ̂_0 = 0, choose δ ∈ (0,1), λ ≥ 1
  2. Loop t = 1, 2, ..., n:
     - Sample η_t (rotationally invariant, bounded 2nd/4th moments)
     - Compute θ_t = θ̂_{t-1} + V_{t-1}^{-1/2} η_t
     - Select X_t = ∇J_X(θ_t) (solve max_{x∈X} ⟨x, θ_t⟩)
     - Observe Y_t ~ sub-Gaussian with mean ⟨X_t, θ*⟩
     - Update V_t ← V_{t-1} + X_t X_t^T
     - Update θ̂_t ← V_t^{-1} Σ_{i=1}^t Y_i X_i

- Design tradeoffs:
  - **Perturbation distribution**: Gaussian (K² = 1, K⁴ = 3) vs. Uniform on √d-sphere (K = 1, K⁴ = 1) — affects constant factor in regret
  - **Regularization λ**: Larger λ stabilizes early rounds but increases initial bias; paper uses λ ≥ 1
  - **Action set geometry**: Must satisfy Assumption 2; ℓ_p balls work for p ∈ (1, ∞) but NOT p = 1 or p = ∞
  - **Norm choice ||·||_* for analysis**: Affects M/m ratio in regret bound; paper notes optimal choice depends on action set

- Failure signatures:
  - **Linear regret on non-smooth/non-convex action sets**: Polytopes, discrete action sets, ℓ_1/ℓ_∞ balls may cause algorithm to get "stuck" (cites Hamidi & Bayati 2023, Zhang 2022 lower bounds)
  - **Poor scaling as ||θ*|| → 0**: Absorbing set assumption (neighborhood of origin) becomes critical; may degrade
  - **Suboptimal dimension dependence if inflating**: Using prior analyses' variance inflation yields O(d^{3/2}√n) instead of O(d√n)
  - **Numerical instability**: V_t^{-1/2} computation when V_t is ill-conditioned; use Cholesky or SVD

- First 3 experiments:
  1. **Baseline on ℓ_2 unit ball**: Implement TS with X = B^d_2, d = 10, n = 10000, Gaussian perturbations. Measure regret vs. OFUL baseline. Verify O(d√n log n) scaling by varying d ∈ {5, 10, 20, 50}.
  2. **Action set geometry ablation**: Compare X = B^d_p for p ∈ {1.2, 1.5, 2, 3, 10} and p = 1 (polytope vertices). Expect: p ∈ (1, ∞) achieves O(d√n); p = 1 may fail or degrade.
  3. **Inflation comparison**: Implement both (a) unmodified TS per paper, (b) inflated TS (variance × √{d log t}) per Agrawal & Goyal 2013. Compare regret on smooth convex action sets. Expect: (a) matches or beats (b) without extra √d factor.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the assumption that the action set is "absorbing" (a neighborhood of the origin) be relaxed or removed?
- **Basis in paper:** [explicit] Section 4.2 states: "That $\mathcal{X}$ is absorbing ensures that the multiplier $J(\theta)$... is positive... we do not believe this assumption to be essential, but we have thus far been unable to eliminate it."
- **Why unresolved:** The current proof requires the multiplier $J(\theta)$ in the gradient of the squared support function to remain positive to avoid undefined behavior as $\theta \to 0$.
- **What evidence would resolve it:** A proof technique that handles the non-differentiability or behavior near the origin without requiring the set to contain a ball around zero.

### Open Question 2
- **Question:** What is the precise class of action sets that allow randomized exploration to achieve optimal dimension dependence?
- **Basis in paper:** [explicit] The Conclusion states: "It remains an important open problem to understand exactly which action spaces permit an optimal dependence on the dimension."
- **Why unresolved:** The paper establishes sufficiency for smooth, strongly convex sets (e.g., $\ell_p$-balls) but does not prove necessity, leaving a gap between these sets and those where linear regret is known.
- **What evidence would resolve it:** Identification of a broader class of sets (e.g., those with specific boundary properties) where the regret holds, or counter-examples showing failure for sets that violate specific convexity/smoothness criteria.

### Open Question 3
- **Question:** Can the regret bound be tightened to remove the logarithmic factors and match the $\Omega(d\sqrt{n})$ lower bound exactly?
- **Basis in paper:** [inferred] The main result (Theorem 4) establishes a regret of $O(d\sqrt{n} \log n)$, whereas the optimal lower bound cited is $\Omega(d\sqrt{n})$.
- **Why unresolved:** The current analysis relies on confidence ellipsoids and elliptical potential lemmas that typically introduce logarithmic dependencies in finite-time analysis.
- **What evidence would resolve it:** A refined analysis of the confidence width or perturbation moments that removes the $\log n$ term from the leading coefficient.

## Limitations

- The geometric assumptions (Assumption 2) are restrictive, excluding common cases like polytopes and ℓ₁/ℓ∞ balls
- The analysis assumes θ* lies in an absorbing neighborhood of the origin, which may not hold in practice
- The confidence intervals for the regret bound depend on parameters M, m, and ||θ*|| that are not always easy to compute for general action sets

## Confidence

- **High**: The core regret bound O(d√n log n) and its optimality claim; the role of smoothness and strong convexity in preventing the √d inflation term
- **Medium**: The necessity of the absorbing set assumption and its impact on practical performance; the claim that unmodified TS achieves optimal dimension dependence (not previously proven)
- **Low**: Exact constants in the bound (e.g., dependence on M/m and ||θ*||) and their tightness; the behavior when action sets only approximately satisfy the assumptions

## Next Checks

1. **Geometric assumption test**: Compare regret scaling on ℓ_p balls for p=1.5, 2, 3 (should satisfy assumptions) vs p=1, ∞ (should fail) to empirically verify the smoothness requirement
2. **Inflation comparison experiment**: Implement both the unmodified TS algorithm from this paper and a √d-inflated variant (as in prior work) to confirm the √d penalty claim
3. **Absorbing set edge case**: Test performance as ||θ*|| approaches zero to verify the claim that absorbing sets handle this regime better than confidence-bound approaches