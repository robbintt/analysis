---
ver: rpa2
title: Effect of Data Augmentation on Conformal Prediction for Diabetic Retinopathy
arxiv_id: '2508.14266'
source_url: https://arxiv.org/abs/2508.14266
tags:
- augmentation
- prediction
- data
- conformal
- uncertainty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study systematically evaluates how data augmentation strategies
  affect the performance of conformal prediction for diabetic retinopathy grading.
  Using the DDR dataset, two architectures (ResNet-50 and CoaT-Lite-Medium) were trained
  with five augmentation schemes (none, standard, CLAHE, Mixup, and CutMix) and assessed
  with conformal prediction metrics including empirical coverage, average prediction
  set size, and correct efficiency.
---

# Effect of Data Augmentation on Conformal Prediction for Diabetic Retinopathy

## Quick Facts
- arXiv ID: 2508.14266
- Source URL: https://arxiv.org/abs/2508.14266
- Reference count: 24
- This study systematically evaluates how data augmentation strategies affect the performance of conformal prediction for diabetic retinopathy grading

## Executive Summary
This study systematically evaluates how data augmentation strategies affect the performance of conformal prediction for diabetic retinopathy grading. Using the DDR dataset, two architectures (ResNet-50 and CoaT-Lite-Medium) were trained with five augmentation schemes (none, standard, CLAHE, Mixup, and CutMix) and assessed with conformal prediction metrics including empirical coverage, average prediction set size, and correct efficiency. Results show that advanced sample-mixing strategies like Mixup and CutMix not only improve predictive accuracy but also yield more reliable and efficient uncertainty estimates under conformal prediction. In contrast, CLAHE can negatively impact model certainty. The study highlights the need to co-design augmentation strategies with uncertainty quantification in mind to build trustworthy AI systems for medical imaging.

## Method Summary
The study employed split conformal prediction with k-NN nonconformity scores on two deep learning architectures (ResNet-50 and CoaT-Lite-Medium) trained on the DDR diabetic retinopathy dataset. Five data augmentation strategies were systematically evaluated: no augmentation, standard augmentations, CLAHE, Mixup, and CutMix. Models were trained for 50 epochs with early stopping, then calibrated and tested with conformal prediction to measure empirical coverage, average prediction set size, and correct efficiency. The feature embeddings were extracted from intermediate layers (GAP for ResNet, Norm4 for CoaT) and used for k-NN distance calculations to determine prediction set sizes.

## Key Results
- Sample-mixing strategies (Mixup, CutMix) improve both predictive accuracy and conformal prediction efficiency
- CLAHE enhancement degrades model certainty and increases average prediction set sizes
- CoaT-Lite-Medium architecture generally outperforms ResNet-50 in correct efficiency across augmentation schemes
- Only Mixup consistently achieves target coverage (90%) while maintaining high efficiency

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Sample-mixing strategies (Mixup, CutMix) appear to preserve the exchangeability assumption required for valid conformal prediction better than domain-specific preprocessing like CLAHE.
- **Mechanism:** These strategies act as regularizers that smooth decision boundaries and prevent the model from overfitting to spurious features. By interpolating between samples, they likely encourage the formation of denser, more consistent feature clusters in the embedding space. This geometric stability allows the k-NN nonconformity measure to calculate more reliable p-values, resulting in prediction sets that are both smaller (efficient) and valid (coverage maintained).
- **Core assumption:** The regularization provided by mixing improves the semantic consistency of the feature space relative to the calibration distribution, offsetting the distribution shift caused by creating synthetic samples.
- **Evidence anchors:**
  - [abstract]: "sample-mixing strategies like Mixup and CutMix... yield more reliable and efficient uncertainty estimates."
  - [section 4]: "CoaT model trained with Mixup is the only configuration to clearly meet the 90% target level, indicating that this combination... may best preserve the exchangeability assumption vital for CP."
- **Break condition:** If the calibration dataset is drawn from a significantly different domain than the mixed training data, the feature embeddings may lack alignment, causing coverage violations.

### Mechanism 2
- **Claim:** Applying Contrast Limited Adaptive Histogram Equalization (CLAHE) can degrade the efficiency and reliability of conformal prediction sets.
- **Mechanism:** While CLAHE enhances vascular contrast for human interpretation, it may introduce local artifacts or distort subtle texture features that the model relies upon. This results in "noisier" feature embeddings where images of the same class are pushed further apart (higher intra-class variance). Consequently, the k-NN nonconformity scores become less discriminative, forcing the CP algorithm to emit larger prediction sets to maintain marginal coverage.
- **Core assumption:** The specific feature extraction backbone (ResNet-50 or CoaT) learns representations that are sensitive to the specific low-level intensity redistributions caused by CLAHE, viewing them as dissimilarities.
- **Evidence anchors:**
  - [abstract]: "methods like CLAHE can negatively impact model certainty."
  - [section 4]: "CLAHE... yields the lowest efficiency for ResNet-50... [and] results in the largest average prediction set, implying greater model uncertainty."
- **Break condition:** If a model is pre-trained specifically on CLAHE-enhanced images from scratch (rather than fine-tuned), this negative effect might diminish, though this is speculative.

### Mechanism 3
- **Claim:** Architectures with stronger inductive biases for global context (CoaT) may handle the uncertainty trade-offs of data augmentation more robustly than standard CNNs.
- **Mechanism:** The Co-Scale Conv-Attentional Transformer (CoaT) combines convolution with attention, potentially creating more robust feature hierarchies. This allows the model to maintain high Top-1 accuracy while simultaneously supporting the dense intra-class clustering required for efficient k-NN conformal prediction, particularly when combined with regularization-heavy augmentations like Mixup.
- **Core assumption:** The attention mechanism helps the model "ignore" augmentation-induced noise better than the strictly local receptive fields of ResNet-50.
- **Evidence anchors:**
  - [section 4]: "CoaT-Lite-Medium architecture generally outperforms ResNet-50" in terms of correct efficiency.
  - [table 1]: Shows CoaT with Mixup achieving the highest accuracy (0.842) and coverage (0.904).
- **Break condition:** This advantage is conditional on the availability of sufficient calibration data; attention models may overfit to spurious correlations if calibration sets are too small or unrepresentative.

## Foundational Learning

- **Concept: Split Conformal Prediction**
  - **Why needed here:** This is the core uncertainty framework used. It requires understanding that the dataset must be split into training, calibration, and test sets. The calibration set is used to set the threshold for what constitutes an "atypical" prediction.
  - **Quick check question:** If you allocate too few images to the calibration set, what happens to the variance of your coverage guarantee?

- **Concept: Nonconformity Score (k-NN)**
  - **Why needed here:** The paper implements CP not on the raw softmax outputs, but on feature embeddings using k-Nearest Neighbors. One must understand that a "high" score here means an image is dissimilar to its labeled class neighbors.
  - **Quick check question:** Does a high nonconformity score indicate the model is confident or uncertain about that specific label?

- **Concept: The Exchangeability Assumption**
  - **Why needed here:** The paper hypothesizes that data augmentation challenges this assumption. You must grasp that CP guarantees fail if the training/calibration data relationship differs fundamentally from the test data relationship.
  - **Quick check question:** Does Mixup strengthen or weaken exchangeability between the training set (containing synthetic mixed images) and the calibration set (containing pure images)?

## Architecture Onboarding

- **Component map:** DDR Dataset -> Augmentation Block (None/Standard/CLAHE/Mixup/CutMix) -> ResNet-50 or CoaT-Lite-Medium Backbone -> Feature Head (GAP or Norm4) -> CP Layer (k-NN search) -> Prediction Set Output
- **Critical path:** The interaction between the Augmentation Block and the Feature Head is the critical variable. The CP Layer is fixed; performance changes are driven entirely by how different augmentations alter the geometry of the feature vectors extracted by the backbone.
- **Design tradeoffs:**
  - CLAHE: Improves human visual interpretability of vessels vs. degrades model certainty (larger prediction sets)
  - Mixup: Slows initial convergence vs. yields highest Top-1 accuracy and valid coverage
  - ResNet-50: Faster inference speed vs. lower "correct efficiency" (singleton sets) compared to CoaT
- **Failure signatures:**
  - Under-coverage: Empirical coverage < 1 - Îµ (e.g., < 0.9). This indicates the calibration distribution was skewed relative to the test distribution (seen with Standard augmentation on CoaT).
  - Inefficiency: Large Average Set Sizes. The model is "confused" and hedges by including multiple classes (seen with CLAHE on ResNet-50).
- **First 3 experiments:**
  1. **Baseline Stability Check:** Train ResNet-50 with no augmentation. Verify that empirical coverage is close to the target (0.9). If not, check for data leakage or bugs in the k-NN distance calculation.
  2. **Augmentation Sweep:** Train a single backbone (e.g., ResNet-50) on the 5 regimes. Plot "Average Set Size" vs. "Top-1 Accuracy." Verify the inverse relationship reported in the paper (accuracy up, set size down).
  3. **Visualization Audit:** Extract t-SNE plots of the calibration embeddings for the "None" vs. "CLAHE" models. Visually confirm that CLAHE leads to more overlapping/messy class clusters, explaining the drop in efficiency.

## Open Questions the Paper Calls Out
None

## Limitations
- Results are based on a single dataset (DDR), which may not generalize to other diabetic retinopathy grading tasks or imaging modalities
- Evaluation focuses on marginal coverage rather than conditional coverage, which is known to be more challenging for conformal prediction
- The study does not explore how these findings translate to different severity scales or grading systems beyond the 5-class DR classification

## Confidence

- **High Confidence**: The core finding that Mixup and CutMix improve both accuracy and conformal prediction efficiency is well-supported by the empirical results across both architectures. The negative impact of CLAHE on prediction set efficiency is consistently observed.
- **Medium Confidence**: The mechanism explanations (exchangeability preservation, feature space geometry) are plausible but not directly validated through ablation studies or visualizations in the paper.
- **Medium Confidence**: The architecture comparison between ResNet-50 and CoaT is based on a single run per configuration; the relative performance may shift with different random seeds or training schedules.

## Next Checks

1. **Cross-Dataset Validation**: Replicate the study using the EyePACS or Messidor datasets to verify that Mixup/CutMix consistently improve CP performance across different diabetic retinopathy grading datasets.

2. **Conditional Coverage Analysis**: Implement and evaluate jackknife+ or other conditional conformal methods to assess whether the observed benefits of sample-mixing strategies extend to stronger coverage guarantees.

3. **Ablation on Feature Space Geometry**: Conduct t-SNE or UMAP visualizations of calibration set embeddings for each augmentation strategy to empirically validate the hypothesis that Mixup/CutMix create more consistent intra-class clusters compared to CLAHE.