---
ver: rpa2
title: 'SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling'
arxiv_id: '2508.09105'
source_url: https://arxiv.org/abs/2508.09105
tags:
- attribution
- online
- arxiv
- available
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of auditing membership leakage
  in retrieval-augmented generation (RAG) systems, where it is difficult to determine
  whether generated content originates from a model's pretraining data or external
  retrieval sources. The authors propose SMA (Source-aware Membership Audit), a semi-black-box
  framework that uses input perturbation and zero-gradient attribution to identify
  the source of leaked content at the token level.
---

# SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling

## Quick Facts
- **arXiv ID:** 2508.09105
- **Source URL:** https://arxiv.org/abs/2508.09105
- **Reference count:** 40
- **Primary result:** SMA achieves 15.74% improvement in accuracy and 10.01% in coverage over state-of-the-art baselines in detecting source-specific membership leakage.

## Executive Summary
This paper addresses the challenge of auditing membership leakage in retrieval-augmented generation (RAG) systems, where it is difficult to determine whether generated content originates from a model's pretraining data or external retrieval sources. The authors propose SMA (Source-aware Membership Audit), a semi-black-box framework that uses input perturbation and zero-gradient attribution to identify the source of leaked content at the token level. By toggling the RAG switch and analyzing attribution differences through ridge regression, SMA distinguishes between pretraining, retrieval, and non-member sources. Experiments show SMA achieves 15.74% improvement in accuracy and 10.01% in coverage over state-of-the-art baselines in detecting source-specific membership leakage, with strong performance across both textual and multimodal RAG systems.

## Method Summary
SMA employs a semi-black-box framework that applies token-level perturbations to inputs and uses ridge regression to estimate attribution scores without requiring gradient access. The method generates N perturbed input variants, computes response scores combining output length and semantic similarity, and solves for token attribution through ridge regression. By toggling the RAG module on/off and computing attribution differences, SMA classifies content into three categories: pretraining member, retrieval member, or non-member. For multimodal RAG (MRAG), image inputs are projected to textual descriptions via MLLMs, enabling unified attribution analysis. The framework uses multi-tier thresholding on attribution difference scores to determine source labels.

## Key Results
- SMA achieves 15.74% improvement in accuracy and 10.01% in coverage over state-of-the-art baselines in detecting source-specific membership leakage
- Strong performance across both textual and multimodal RAG systems with consistent results across multiple datasets
- The method effectively handles three-way classification (pretrained member, retrieved member, non-member) outperforming traditional binary membership inference approaches

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Token-level attribution can be estimated in semi-black-box settings without gradient access by modeling the relationship between input perturbations and output variations.
- **Mechanism:** Construct N randomly perturbed input variants with binary mask vectors m^(i) ∈ {0,1}^L indicating retained vs. perturbed tokens. Compute response scores r^(i) combining output length and semantic similarity. Stack masks into matrix M and solve ridge regression r = Mβ to obtain attribution scores β_j for each token.
- **Core assumption:** The influence of input tokens on outputs follows an approximately linear pattern locally capturable via perturbation sampling (Assumption: validated empirically but not theoretically proven).
- **Evidence anchors:**
  - [abstract]: "attribution estimation mechanism based on zero-order optimization, which robustly approximates the true influence of input tokens on the output through large-scale perturbation sampling and ridge regression modeling"
  - [Section IV-C]: "This approach performs zero-order sensitivity analysis purely based on input-output behaviors, without relying on gradient information."
  - [corpus]: Related work on perturbation-based attribution (LIME, SHAP) supports feasibility, but corpus does not contain direct validation of ridge regression for this specific application.
- **Break condition:** Excessive output stochasticity (e.g., temperature > 5.0) degrades attribution consistency; overly restrictive max_tokens truncates context needed for perturbation analysis.

### Mechanism 2
- **Claim:** Toggling the RAG module on/off reveals whether output tokens depend on external retrieval or model-internal knowledge through differential attribution patterns.
- **Mechanism:** Compute attribution scores under both conditions (β_RAG, β_w/o_RAG). The Attribution Difference Score (ADS) = β_RAG(j) - β_w/o_RAG(j) measures RAG dependency. Multi-tier thresholding: if β_j ≥ τ → Pretrained Member; if τ_1 ≤ Diff(β_j) < τ_2 → Non-Member; otherwise → Retrieved Member.
- **Core assumption:** Embedding-based retrieval exhibits robustness to token-level perturbations while autoregressive LLM generation is perturbation-sensitive; this differential behavior is source-discriminative.
- **Evidence anchors:**
  - [abstract]: "By toggling the RAG switch and analyzing attribution differences through ridge regression, SMA distinguishes between pretraining, retrieval, and non-member sources"
  - [Section IV-B]: "The core motivation behind this cross-modal perturbation design is that the autoregressive mechanism of LLMs is sensitive to token-level perturbations, while the embedding-based retrieval mechanism of RAG exhibits a certain degree of input robustness"
  - [corpus]: Riddle Me This (Naseh et al.) confirms RAG systems are vulnerable to membership inference, supporting the attack surface assumption.
- **Break condition:** Platforms lacking RAG toggle capability (e.g., Grok) cannot apply this mechanism; requires semi-black-box control.

### Mechanism 3
- **Claim:** Image membership inference in MRAG systems is achievable by projecting visual perturbations into textual descriptions via MLLM captioning, enabling unified text-modality attribution.
- **Mechanism:** Apply Gaussian noise perturbations to images at multiple σ levels. Process noisy image Î through MLLM with captioning prompt to yield textual representation ŷ_vis. Apply text-based attribution pipeline to this projected output.
- **Core assumption:** MLLM captioning preserves sufficient semantic information for attribution; perturbation-induced changes in captions reflect perturbation influence on generation (Assumption: caption quality under noise not extensively validated).
- **Evidence anchors:**
  - [abstract]: "projects image inputs into textual descriptions via MLLMs, enabling token-level attribution in the text modality"
  - [Section IV-C]: "This allows image perturbations to be translated into measurable changes in the token-level textual output"
  - [Figure 3b]: Moderate noise (std ~50-60) enhances MLLM performance metrics; excessive noise (std ~80) degrades performance.
  - [corpus]: No comparable cross-modal MIA methods found in corpus for MRAG validation.
- **Break condition:** Image distortion from excessive noise prevents meaningful captioning; requires calibrated perturbation magnitudes.

## Foundational Learning

- **Concept: Retrieval-Augmented Generation (RAG) Architecture**
  - **Why needed here:** SMA fundamentally exploits the structural difference between parametric (pre-trained) and non-parametric (retrieved) knowledge sources in RAG systems.
  - **Quick check question:** Given a query, what components determine whether the response draws from the LLM's weights versus the vector database?

- **Concept: Zero-Order Optimization**
  - **Why needed here:** SMA's core attribution mechanism uses finite-difference-like estimation through perturbation sampling rather than gradient computation.
  - **Quick check question:** How does zero-order optimization estimate gradient-like information without backpropagation?

- **Concept: Membership Inference Attacks (MIA)**
  - **Why needed here:** SMA extends traditional binary MIA (member vs. non-member) to three-way source attribution (pretrained member, retrieved member, non-member).
  - **Quick check question:** In traditional MIA, what model behavior typically distinguishes training samples from unseen data?

## Architecture Onboarding

- **Component map:** Input → Perturbation sampling (N iterations) → Black-box query → Response scoring → Ridge regression → RAG toggle comparison → ADS computation → Source classification
- **Critical path:** Input → Perturbation sampling (N iterations) → Black-box query → Response scoring → Ridge regression → RAG toggle comparison → ADS computation → Source classification
- **Design tradeoffs:**
  - **Perturbation count N:** Higher N improves attribution precision but increases API costs linearly; experiments suggest 60-80 provides stable accuracy with diminishing returns
  - **Noise magnitude σ:** Moderate noise (σ≈50-60) optimizes MLLM attention; excessive noise (σ≥80) destroys semantic content
  - **Embedding model choice:** bge-large-en-v1.5 achieves highest ACC (0.9172 on PMQA) but may reduce coverage compared to all-MiniLM-L6-v2
- **Failure signatures:**
  - High temperature (>5.0) causes stochastic outputs that break attribution consistency
  - Token limit truncation prevents sufficient perturbation context
  - Platforms without RAG toggle (e.g., Grok) are incompatible
  - Excessive top-k retrieval depth increases noise in attribution signals
- **First 3 experiments:**
  1. **Perturbation sensitivity calibration:** Run SMA with varying N (10, 30, 60, 80, 100) on a held-out sample; plot ACC vs. N to identify optimal budget before diminishing returns
  2. **Noise level sweep for MRAG:** Test σ ∈ {10, 20, 30, 40, 50, 60, 80} on VL-MIA-images dataset with Qwen2.5-VL-7B; validate moderate-noise enhancement effect reported in Figure 3b
  3. **Threshold validation:** On WikiMIA/WikiMIA-24, compare fixed thresholds (τ, τ₁=0.1, τ₂=-0.1) against data-driven threshold selection; measure impact on three-way classification accuracy vs. binary MIA baselines (PETEL, Min-K% PROB)

## Open Questions the Paper Calls Out
- **Open Question 1:** Can SMA be adapted to systems that do not expose RAG toggle control? (Basis: The paper notes that not all commercial platforms expose RAG toggle functionality; resolution requires modified framework tested on platforms like Grok)
- **Open Question 2:** How can shadow model integration reduce the API cost of SMA? (Basis: The paper identifies shadow model inference as promising direction; resolution requires implementation showing 50%+ cost reduction)
- **Open Question 3:** What optimization strategies can mitigate SMA's computational overhead? (Basis: Future work could explore batched perturbations or early stopping; resolution requires experiments showing 30-50% query reduction with ≥90% accuracy)

## Limitations
- The semi-black-box attribution mechanism assumes linear relationships between token perturbations and output changes, but this has not been rigorously validated across diverse model architectures and RAG configurations
- The multi-tier thresholding approach for source classification relies on fixed thresholds (τ, τ₁=0.1, τ₂=-0.1) that may not generalize well across different models or domains without calibration
- The MRAG extension depends heavily on MLLM captioning quality under image perturbations, but the robustness of this cross-modal translation pipeline is not extensively characterized

## Confidence
- **High Confidence:** The core zero-order attribution mechanism (Mechanism 1) and its implementation via ridge regression - this follows established perturbation-based attribution methods
- **Medium Confidence:** The differential attribution approach for RAG toggling (Mechanism 2) - while conceptually sound, depends heavily on specific RAG architecture characteristics
- **Low Confidence:** The cross-modal projection for MRAG systems (Mechanism 3) - this represents a novel extension with limited validation in the corpus

## Next Checks
1. **Attribution Linearity Test:** Systematically evaluate the linearity assumption by measuring attribution consistency across different perturbation magnitudes and model temperature settings on a held-out sample set
2. **Threshold Sensitivity Analysis:** Conduct ablation studies varying τ, τ₁, τ₂ thresholds across different RAG systems to quantify sensitivity and identify optimal calibration methods
3. **Cross-Modal Robustness Evaluation:** Test the MLLM captioning pipeline under varying image noise levels and compare attribution consistency when using different captioning models (e.g., Qwen2.5-VL-7B vs. alternative MLLMs)