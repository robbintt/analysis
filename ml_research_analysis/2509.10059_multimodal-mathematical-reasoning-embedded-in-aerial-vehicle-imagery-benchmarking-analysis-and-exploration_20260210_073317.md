---
ver: rpa2
title: 'Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking,
  Analysis, and Exploration'
arxiv_id: '2509.10059'
source_url: https://arxiv.org/abs/2509.10059
tags:
- vehicles
- reasoning
- image
- vehicle
- vlms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AVI-MATH, the first benchmark for evaluating
  multimodal mathematical reasoning in aerial vehicle imagery. The dataset contains
  3,773 high-quality vehicle-related questions covering 6 mathematical subjects and
  20 topics, collected from UAV imagery at varying altitudes and angles to reflect
  real-world scenarios.
---

# Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration

## Quick Facts
- arXiv ID: 2509.10059
- Source URL: https://arxiv.org/abs/2509.10059
- Reference count: 6
- Even the best VLM (GPT-4o) achieved only 34.6% accuracy on UAV mathematical reasoning tasks

## Executive Summary
This paper introduces AVI-MATH, the first benchmark for evaluating multimodal mathematical reasoning using aerial vehicle imagery. The dataset contains 3,773 high-quality questions covering 6 mathematical subjects and 20 topics, collected from UAV imagery at varying altitudes and angles. When benchmarked on 14 prominent vision-language models, even the best model (GPT-4o) achieved only 34.6% accuracy, highlighting significant limitations in current models' mathematical reasoning capabilities. The paper also explores Chain-of-Thought prompting and fine-tuning techniques, demonstrating their potential to improve performance. A 215K-sample instruction set (AVI-MATH-215K) is introduced to enable models to learn domain-specific knowledge in UAV scenarios.

## Method Summary
The AVI-MATH benchmark was created through systematic UAV image collection (4K resolution at 9 altitudes and 3 pitch angles), template-based question generation (80+ templates across 20 topics), and rigorous manual verification. The dataset covers 6 mathematical subjects with questions requiring 2-6 reasoning steps. Evaluation uses a two-stage process combining free answer generation with format-constrained extraction. The AVI-MATH-215K instruction set was generated using the same templates but with broader sampling for fine-tuning. LoRA-based fine-tuning (rank=64, LLM attention layers only) and Chain-of-Thought prompting variants were explored as enhancement methods.

## Key Results
- GPT-4o achieved highest accuracy at 34.6%, while average accuracy across 14 VLMs was only 22.1%
- CLIP-ViT based models (LLaVA, GeoChat) performed significantly worse than models with native image encoders
- Fine-tuning on AVI-MATH-215K improved DeepSeek-VL by 68% and all three tested models by at least 37%
- Resolution increase from 336×189 to 2000×1125 improved performance, but gains plateaued beyond 2000×1125

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Parameter-efficient fine-tuning on domain-specific mathematical instruction data substantially improves VLM performance on UAV mathematical reasoning tasks.
- **Mechanism:** LoRA-based fine-tuning on the AVI-MATH-215K instruction set enables models to internalize domain-specific knowledge about coordinate transformations, geometric calculations, and UAV-specific visual patterns, without modifying the visual encoder or projector.
- **Core assumption:** The instruction data quality and mathematical rigor directly transfer to improved reasoning; the paper uses template-based generation to ensure correctness.
- **Evidence anchors:**
  - [abstract] "we explore the use of Chain-of-Thought prompting and fine-tuning techniques, which show promise"
  - [Section 4.5.1] DeepSeek-VL improved 68% after fine-tuning; all three models showed at least 37% improvement
  - [corpus] Weak direct corpus evidence on this specific fine-tuning mechanism for UAV math; related work mentions fine-tuning for VLN tasks but not mathematical reasoning

### Mechanism 2
- **Claim:** Chain-of-Thought prompting improves performance only for models with sufficient inherent multi-step reasoning capability and domain knowledge.
- **Mechanism:** CoT (appending "Let's think step by step") decomposes complex mathematical problems into intermediate reasoning steps, but this only helps when the model already possesses the underlying knowledge to execute each step correctly.
- **Core assumption:** The model's baseline reasoning architecture can leverage explicit step-by-step decomposition; models lacking domain knowledge will simply produce longer incorrect outputs.
- **Evidence anchors:**
  - [abstract] "Chain-of-Thought prompting and fine-tuning techniques, which show promise"
  - [Section 4.5.2] CoT improved GPT-4o and InternVL2-40B but degraded LLaVA-v1.6-34B by 3.2 points; LLaVA-34B tended to output "Not possible" or "Unsolvable" when it lacked statistical knowledge
  - [corpus] No corpus papers directly validate CoT effectiveness for UAV mathematical reasoning specifically

### Mechanism 3
- **Claim:** Higher input resolution combined with native image encoders (not CLIP-ViT) preserves critical visual features necessary for mathematical reasoning about small objects in UAV imagery.
- **Mechanism:** Models using CLIP-ViT (e.g., LLaVA, GeoChat) suffer from its ~20-token visual constraint, losing fine-grained spatial information. Native encoders (InternVL, Qwen-VL) with longer token sequences and dynamic resolution support retain vehicle details needed for counting, distance calculation, and fine-grained recognition.
- **Core assumption:** The visual encoder's token capacity is the bottleneck for mathematical reasoning tasks requiring precise spatial relationships; LLM scale alone cannot compensate.
- **Evidence anchors:**
  - [Section 4.4] "CLIP's short-token constraint harms multimodal reasoning"; models with CLIP-ViT "exhibit significantly inferior performance"
  - [Section 4.4, Fig. 8-11] Resolution increase from 336×189 to 2000×1125 improved InternVL2-40B; ALG/ARI questions showed significant gains; GEO/LOG showed limited sensitivity
  - [corpus] Corpus papers focus on VLN and perception but do not address visual encoder token constraints for mathematical reasoning

## Foundational Learning

- **Coordinate System Transformations (Pixel → Image → Camera → Ground)**
  - Why needed here: Geometry and algebra questions require converting 2D pixel coordinates to 3D world coordinates using camera intrinsics (focal length, pixel size) and extrinsics (AGL, pitch angle).
  - Quick check question: Given a vehicle at pixel coordinates [2000, 1125], focal length 12mm, pixel size 0.004325mm, AGL 40m, and pitch angle 90°, can you compute its ground distance from nadir?

- **UAV Imaging Geometry and Ground Plane Assumption**
  - Why needed here: Geometric reasoning tasks assume a flat ground plane; the derivation in Equations 1-7 depends on this for coordinate transformations. Errors in understanding perspective projection cause reasoning failures.
  - Quick check question: Why does a 45° pitch angle produce worse model performance than 60° or 90°?

- **Fine-Grained Visual Recognition at Multiple Scales**
  - Why needed here: Vehicles occupy small pixel areas at high AGL (e.g., 6926 pixels at 4000×2250 shrinks to 44 pixels at 336×189); models must recognize vehicle types, colors, and orientations under resolution constraints.
  - Quick check question: How does the relationship between AGL and vehicle pixel area affect the choice of input resolution?

## Architecture Onboarding

- **Component map:** Data Collection -> Annotation Pipeline -> Question Generation -> Evaluation -> Enhancement Methods
- **Critical path:**
  1. Image acquisition with full sensor metadata (focal length, AGL, pitch angle)
  2. Vehicle annotation via ground-video cross-referencing (ensures brand/model accuracy)
  3. Template-based question generation with reasoning rationales
  4. Two-stage evaluation (free generation → format-constrained extraction)
  5. LoRA fine-tuning on AVI-MATH-215K for domain adaptation

- **Design tradeoffs:**
  - Template-based questions vs. LLM-generated: Templates sacrifice diversity for mathematical rigor
  - Multiple formats (free-form vs. multiple-choice): Free-form prevents shortcut exploitation but is harder to evaluate
  - Resolution vs. computational cost: 2000×1125 provides most gains; 4000×2250 has diminishing returns
  - Fine-tuning LLM only vs. full model: Freezing visual encoder preserves general visual capabilities but limits domain-specific visual adaptation

- **Failure signatures:**
  - **Correct answer, wrong rationale:** 2.3% of GPT-4o's correct answers had incorrect reasoning
  - **Refusal to answer:** LLaVA-1.5-13B refused 40% of divergent cases on logic questions (output "Unknown" or "Not possible")
  - **Resolution collapse:** Qwen2.5-VL-7B performance dropped at 4000×2250 resolution after peaking at 2000×1125
  - **Knowledge forgetting:** GeoChat (fine-tuned on RS data) performed worse than its baseline LLaVA-1.5-7B on statistics and arithmetic

- **First 3 experiments:**
  1. **Baseline evaluation:** Run all 14 VLMs on AVI-MATH with default settings (no CoT, no fine-tuning) to establish the 11.7%-34.6% accuracy range and identify per-subject weaknesses.
  2. **Ablation on resolution and pitch angle:** Test InternVL2-40B and Qwen2.5-VL-7B at multiple resolutions (336, 1000, 2000, 4000 pixels width) across all three pitch angles to quantify the resolution ceiling and angle sensitivity.
  3. **LoRA fine-tuning with AVI-MATH-215K:** Apply rank-64 LoRA to LLaVA-v1.5-7B and InternVL2-8B for 1 epoch, then evaluate improvement on held-out AVI-MATH benchmark samples, comparing average gains across the 6 mathematical subjects.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can VLM architectures be adapted to natively support 4K resolution inputs to prevent the loss of fine-grained visual details required for mathematical reasoning?
- **Basis in paper:** [explicit] The authors state, "enabling support for 4K input resolution would be a promising direction for future research on VLM," noting that current resizing leads to object detail loss.
- **Why unresolved:** Current models typically resize high-resolution UAV imagery (4000x2250) to fixed, lower resolutions (e.g., 336x336), significantly degrading the visual cues needed for tasks like counting and identification at high altitudes.
- **What evidence would resolve it:** Benchmarking results from VLMs utilizing visual encoders capable of processing native 4K inputs without downsampling, showing sustained accuracy at high Above Ground Levels (AGL).

### Open Question 2
- **Question:** What specific characteristics of image-text instruction sets or fine-tuning strategies are required to induce robust mathematical reasoning generalization in remote sensing VLMs?
- **Basis in paper:** [explicit] The paper asks, "What kind of image-text instruction set can lead us toward a 'GPT-4v moment' in remote sensing?" and suggests reinforcement fine-tuning as a potential solution to generalization degradation.
- **Why unresolved:** The authors found that supervised fine-tuning on task-specific datasets often leads to "catastrophic forgetting" or degradation in general reasoning capabilities, leaving the optimal training methodology undefined.
- **What evidence would resolve it:** Comparative studies demonstrating that specific instruction set compositions or reinforcement learning-based fine-tuning methods yield better out-of-domain generalization than current supervised approaches.

### Open Question 3
- **Question:** How does the reliance on a flat ground plane assumption in coordinate transformation limit the applicability of these mathematical reasoning methods in complex, non-planar terrains?
- **Basis in paper:** [inferred] The methodology explicitly assumes the terrain satisfies a "flat surface" to derive camera coordinates and distances, acknowledging the collection area was chosen for this property.
- **Why unresolved:** Real-world UAV operations often occur over varied topography; the paper does not evaluate model performance or error rates when this geometric assumption is violated.
- **What evidence would resolve it:** Evaluation of model accuracy on synthetic or real datasets featuring significant elevation variance where the flat-plane geometric model introduces systematic errors.

## Limitations
- **Dataset scope limitations:** Focus exclusively on vehicle-related imagery in urban/rural settings may limit generalizability to other UAV domains
- **Evaluation pipeline constraints:** Two-stage answer extraction introduces format dependency that may penalize correct reasoning using non-standard formats
- **Model architecture dependencies:** Performance gaps suggest mathematical reasoning capabilities are heavily constrained by visual token budgets rather than reasoning capacity

## Confidence
- **High confidence (8/10):** AVI-MATH dataset construction methodology is well-documented and reproducible
- **Medium confidence (6/10):** Performance benchmarking results are reliable for tested models but generalizability uncertain
- **Low confidence (4/10):** Long-term effectiveness of LoRA fine-tuning is uncertain without longitudinal studies

## Next Checks
- **Check 1:** Evaluate the same VLMs on AVI-MATH benchmark using non-vehicle imagery to verify whether mathematical reasoning limitations are specific to vehicle imagery or represent broader architectural constraints.
- **Check 2:** Implement a model-agnostic answer validation system that compares mathematical correctness without enforcing specific formats to identify format-matching issues in current pipeline.
- **Check 3:** Fine-tune VLMs on AVI-MATH-215K and evaluate performance over multiple epochs while tracking both UAV-specific and general mathematical reasoning tasks to monitor for catastrophic forgetting.