---
ver: rpa2
title: Explainable Classifier for Malignant Lymphoma Subtyping via Cell Graph and
  Image Fusion
arxiv_id: '2503.00925'
source_url: https://arxiv.org/abs/2503.00925
tags:
- cell
- classi
- image
- graph
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study proposes a novel explainable Multi-Instance Learning
  (MIL) framework for malignant lymphoma subtyping that identifies subtype-specific
  Regions of Interest (ROIs) from Whole Slide Images (WSIs) while integrating cell
  distribution characteristics and image information. The framework achieves three
  objectives: indicating appropriate ROIs for each subtype, explaining the frequency
  and spatial distribution of characteristic cell types, and achieving high-accuracy
  subtyping by leveraging both image and cell-distribution modalities.'
---

# Explainable Classifier for Malignant Lymphoma Subtyping via Cell Graph and Image Fusion

## Quick Facts
- arXiv ID: 2503.00925
- Source URL: https://arxiv.org/abs/2503.00925
- Reference count: 36
- Primary result: Achieves 91.1% accuracy and 98.3%/96.1%/98.8% AUC for DLBCL/FL/Reactive subtyping with explainable ROI localization

## Executive Summary
This paper proposes a novel explainable Multi-Instance Learning framework for malignant lymphoma subtyping that integrates cell distribution characteristics with image information. The approach fuses cell graph and image features using a Weak-Expert-based Gating Mixture-of-Experts (WEG-MoE) approach within an AdditiveMIL framework. Experiments on 1,233 WSIs demonstrate state-of-the-art accuracy among ten comparative methods while providing region-level and cell-level explanations that align with pathologists' perspectives.

## Method Summary
The framework processes Whole Slide Images (WSIs) by extracting 512×512 patches with ≥100 cells, constructing cell graphs using HoVerNet segmentation and a ResNet34 cell classifier with CAMRI loss, and extracting image features using UNI2 foundation model. Cell graphs are processed through 4-layer GIN networks while image features are processed through TransMIL self-attention. The WEG-MoE gating mechanism fuses these modalities by training the gating network on weaker graph features only, preventing dominant modality collapse. Classification is performed using AdditiveMIL to provide class-wise attention scores for explainable ROI localization.

## Key Results
- Achieves 91.1% accuracy on three-class lymphoma subtyping (DLBCL, FL, Reactive)
- State-of-the-art performance compared to ten baseline methods
- Provides class-wise attention maps that align with pathologist expectations
- Delivers cell frequency and adjacency statistics that explain characteristic cell distributions

## Why This Works (Mechanism)

### Mechanism 1: Weak-Expert-Based Gating Forces Balanced Multimodal Fusion
Training the gating network using only the weaker modality (cell graphs) prevents dominant modality collapse, ensuring both image and graph features contribute meaningfully. The WEG-MoE gates are optimized using only graph features while forcing image expert outputs to zero during training, forcing the gating function to learn where graph features are informative.

### Mechanism 2: AdditiveMIL Provides Subtype-Specific Attention for Explainable ROI Localization
Class-wise attention scores per patch enable identification of subtype-specific ROIs, unlike single-attention MIL methods that conflate importance across classes. AdditiveMIL produces K-dimensional attention vectors where each element represents the instance's contribution to class k, allowing visualization of which regions support each subtype diagnosis.

### Mechanism 3: CAMRI Loss Maintains High Recall for Diagnostically Critical Cell Types
Standard cross-entropy loss may sacrifice recall on rare-but-critical cell types; CAMRI loss explicitly preserves recall for LBC, CC, and RM. This ensures characteristic cells are not missed during graph construction, as missing these cells (false negatives) is more harmful than occasional misclassification of other cells.

## Foundational Learning

- **Multi-Instance Learning (MIL)**: Treats each WSI as a "bag" of patches where only bag-level labels are available. Attention-based MIL provides both classification and localization, while standard pooling-based MIL does not.
- **Graph Neural Networks for Cell Graphs**: Cell graphs encode spatial relationships that pure image features may not capture explicitly. GNNs aggregate neighborhood information to capture cell distribution patterns.
- **Mixture of Experts (MoE) with Gating**: Allows adaptive reliance per-instance when modalities have different convergence rates. In standard MoE, the gating network outputs weights for expert selection; WEG-MoE trains the gate on graph-only features to prevent modal collapse.

## Architecture Onboarding

- **Component map**: WSI → patches → (cell graph construction + image encoding) → AdditiveMIL feature aggregation → WEG-MoE gating → bag-level prediction + attention visualization
- **Critical path**: WSI → patches → (cell graph construction + image encoding) → AdditiveMIL feature aggregation → WEG-MoE gating → bag-level prediction + attention visualization
- **Design tradeoffs**: WEG-MoE sacrifices direct joint optimization to prevent modal collapse; AdditiveMIL provides class-wise attention at cost of K× more attention parameters; patch size and cell threshold filter sparse regions but may discard relevant tissue
- **Failure signatures**: Gate outputs collapse to always selecting image expert (check h(G) variance); attention maps show uniform importance (verify AdditiveMIL convergence); cell frequency explanations don't match expectations (audit cell classifier recall)
- **First 3 experiments**:
  1. Compare WEG-MoE vs. naive MoE vs. simple concatenation on held-out test set; report accuracy and gate weight distributions
  2. Manually annotate validation set cells; compute per-class recall to confirm CAMRI loss achieves its objective
  3. Present class-wise attention maps to pathologists on 10-20 cases; collect structured feedback on ROI alignment

## Open Questions the Paper Calls Out

- **Open Question 1**: Why does the model fail to detect elevated Round-Medium cell (RM) frequency at follicular borders in Reactive cases despite accurate classification? The authors confirm overall validity but don't explain the absence of this expected feature.
- **Open Question 2**: How does WEG-MoE perform on external datasets with different staining protocols or scanner hardware? The study uses a single private dataset without testing generalizability to domain shifts.
- **Open Question 3**: Is the "Weak-Expert-based Gating" strategy robust for multimodal fusion where the weak modality contains critical sparse information? The paper relies on a heuristic fix without theoretical convergence guarantees.

## Limitations
- The WEG-MoE mechanism's effectiveness depends critically on graph features being sufficiently informative to guide the gating network, with no quantitative analysis of expert selection frequency
- CAMRI loss's effectiveness in maintaining recall for critical cell types lacks empirical validation through held-out cell classification performance metrics
- The framework's generalizability to different staining protocols and scanner hardware is untested due to single-source dataset validation

## Confidence

- **High confidence**: The overall MIL framework architecture and its ability to produce class-wise attention maps for ROI localization
- **Medium confidence**: The WEG-MoE mechanism's superiority over naive MoE, requiring deeper analysis of gating weight distributions and ablation studies
- **Low confidence**: The explicit effectiveness of CAMRI loss in maintaining recall for LBC, CC, and RM without concrete recall metrics from independent validation

## Next Checks

1. **Gating weight analysis**: Compute and visualize the distribution of gating weights $\bar{w}^{(G)}_{n,m}$ and $\bar{w}^{(X)}_{n,m}$ across all patches and folds to verify WEG-MoE achieves balanced expert selection versus naive MoE
2. **Cell classifier recall audit**: Manually validate cell type classification on a held-out test set to confirm CAMRI loss achieves ≥95% recall for LBC, CC, and RM classes
3. **Pathologist alignment study**: Conduct structured evaluation where 3 pathologists independently assess whether class-wise attention maps and cell frequency distributions correctly highlight diagnostically relevant regions for 20 representative cases per subtype