---
ver: rpa2
title: Black-box Adversarial Attacks on CNN-based SLAM Algorithms
arxiv_id: '2505.24654'
source_url: https://arxiv.org/abs/2505.24654
tags:
- attacks
- adversarial
- attack
- slam
- frames
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the vulnerability of CNN-based SLAM systems
  to black-box adversarial attacks. The authors generate adversarial perturbations
  using a known CNN model (InceptionResNetV2) and apply them to input RGB images fed
  into the GCNv2 feature detector, part of the GCN-SLAM pipeline.
---

# Black-box Adversarial Attacks on CNN-based SLAM Algorithms

## Quick Facts
- arXiv ID: 2505.24654
- Source URL: https://arxiv.org/abs/2505.24654
- Reference count: 40
- Primary result: Small adversarial perturbations can cause up to 76% tracking failure in CNN-based SLAM systems

## Executive Summary
This paper demonstrates that CNN-based SLAM systems are vulnerable to black-box adversarial attacks that transfer from a surrogate model. The authors generate adversarial perturbations using InceptionResNetV2 and apply them to RGB images fed into GCNv2 feature detector, causing significant tracking failures in the GCN-SLAM pipeline. Notably, attacking depth images causes complete SLAM failure even with minimal perturbations. The attack generalizes across SLAM systems, highlighting the need for robust defense mechanisms in SLAM systems.

## Method Summary
The authors generate adversarial perturbations using a known CNN model (InceptionResNetV2) pre-trained on ImageNet. They apply FGSM and PGD attacks with epsilon values ranging from 0.005 to 0.30 to RGB and depth images from the TUM RGB-D dataset. These perturbed images are then fed into the GCNv2 feature detector within the GCN-SLAM pipeline. The attack strategies include attacking all frames, rate-based subsets, time-adaptive frames, and spatially-adaptive regions with detected objects. Performance is measured by Average Absolute Trajectory Error (ATE) and percentage of untracked frames.

## Key Results
- Even small perturbations (ε = 0.05) cause up to 76% tracking failure in SLAM systems
- Targeted PGD attacks achieve similar disruption levels as untargeted attacks
- Attacking depth images causes complete SLAM failure with minimal perturbation
- Attack transfers effectively to other SLAM systems like DXSLAM, demonstrating generalizability
- Object-region attacks maintain background stability while still causing tracking failure

## Why This Works (Mechanism)

### Mechanism 1
Adversarial perturbations generated on a surrogate CNN (InceptionResNetV2) transfer effectively to the target GCNv2 feature detector without knowledge of its architecture. The perturbations exploit shared vulnerabilities in how CNNs extract and encode visual features, disrupting feature saliency patterns common across architectures.

### Mechanism 2
Adversarial noise redistributes salient features spatially, corrupting the feature matching process that SLAM relies on for pose estimation. The perturbation reduces the importance of original features by distorting pixel color/quality and creating noise clusters in flat regions, shifting features to different positions across consecutive frames.

### Mechanism 3
Attacking depth images causes complete SLAM failure with even minimal perturbation. Depth values directly determine 3D point coordinates used for localization and frame-to-frame matching, and perturbations to depth propagate multiplicatively through coordinate transformations.

## Foundational Learning

- **Black-box vs. White-box Adversarial Attacks**: Understanding the difference is essential because black-box attacks require only input/output access, necessitating surrogate model transferability strategies. *Quick check*: Can you explain why FGSM requires gradient access to generate perturbations, and how the authors work around this for their black-box target?

- **SLAM Pipeline Stages (Front-end Feature Detection → Back-end Optimization)**: Understanding which stages depend on CNN-derived features (front-end) vs. geometric optimization (back-end) is essential for diagnosing where attacks propagate. *Quick check*: In GCN-SLAM, what component handles loop closure detection, and why does this not fully mitigate adversarial feature corruption?

- **Perturbation Budget (ε) and Perceptibility Tradeoff**: The paper demonstrates effectiveness at ε = 0.05 (imperceptible) through ε = 0.30 (visible). Understanding this parameter is critical for realistic threat modeling. *Quick check*: At ε = 0.05 normalized to [0,1], what is the maximum pixel-level change in an 8-bit image (0-255 range)?

## Architecture Onboarding

- **Component map**: TUM dataset → InceptionResNetV2 (surrogate) → FGSM/PGD perturbations → GCNv2 feature detector → ORB-SLAM2 back-end → ATE and untracked frame metrics

- **Critical path**: 1) Load RGB frame from TUM dataset, 2) Generate perturbation δ using surrogate model gradients, 3) Apply x_adv = x + δ (clipped to valid range), 4) Feed x_adv to GCNv2 → extract keypoints/descriptors, 5) ORB-SLAM2 tracking attempts feature matching with previous keyframes, 6) If matching fails → frame marked untracked, pose copied from last successful frame, 7) ATE computed against ground truth trajectory

- **Design tradeoffs**: FGSM vs. PGD (fast single-step vs. slower iterative with higher success rate), attack frequency (all-frames vs. rate-based for detectability), spatial targeting (object-region vs. full-frame for evasion)

- **Failure signatures**: High untracked frame percentage (>70%) indicates feature matching collapse, discontinuous trajectories indicate tracking loss events, ATE >0.5m suggests systemic corruption, complete failure indicates depth-channel attack

- **First 3 experiments**: 1) Reproduce baseline vulnerability: Run All-frames FGSM attack on fr1_360 trajectory with ε = 0.05, verify ~76% untracked frames, 2) Validate transferability: Replace InceptionResNetV2 with MobileNetV2 as surrogate; confirm ATE remains within 10% of original results, 3) Depth sensitivity test: Apply minimum perturbation (ε = 0.005) to depth channel only on fr1_desk; confirm complete tracking failure

## Open Questions the Paper Calls Out
The paper explicitly states the "critical need for future research to prioritize the development of defense mechanisms, whether by strengthening algorithm robustness in the SLAM back-end or by implementing effective detection and protection mechanisms." This calls for research into defensive strategies against adversarial attacks on SLAM systems.

## Limitations
- Critical implementation details are unspecified including PGD iteration count, step size, time-adaptive attack threshold, and random seed for targeted attacks
- No ablation studies on GCNv2's internal architecture or alternative feature detectors to isolate the true vulnerability point
- Lacks robustness analysis against potential SLAM-side defenses like RANSAC tuning or depth validation
- Does not address physical-world realizability of perturbations beyond digital image manipulation

## Confidence
- **High confidence**: Claims about transferability across SLAM systems (GCN-SLAM to DXSLAM) and general vulnerability of CNN-based feature detectors to black-box attacks
- **Medium confidence**: The specific mechanism by which adversarial noise corrupts feature matching through spatial redistribution
- **Low confidence**: The assertion that depth-channel attacks cause "complete failure" is based on empirical observation without theoretical grounding

## Next Checks
1. **Transferability Validation**: Replace InceptionResNetV2 with ResNet50 and verify ATE degradation and untracked frame percentages remain within 15% of original results
2. **Feature Distribution Analysis**: Compute and compare spatial distribution of detected features using heatmaps; quantify whether adversarial noise statistically shifts feature clusters away from ground truth correspondences
3. **Depth Channel Robustness Test**: Implement depth validation pre-filter (threshold-based outlier rejection or temporal smoothing) and measure whether this reduces untracked frame percentage from near-100% to a more realistic range