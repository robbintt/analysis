---
ver: rpa2
title: 'LangPrecip: Language-Aware Multimodal Precipitation Nowcasting'
arxiv_id: '2512.22317'
source_url: https://arxiv.org/abs/2512.22317
tags:
- precipitation
- motion
- nowcasting
- radar
- langprecip
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of short-term precipitation
  nowcasting, particularly for rapidly evolving and extreme weather events. The proposed
  LangPrecip framework introduces a novel approach by treating meteorological motion
  descriptions as semantic motion priors to guide precipitation evolution.
---

# LangPrecip: Language-Aware Multimodal Precipitation Nowcasting

## Quick Facts
- arXiv ID: 2512.22317
- Source URL: https://arxiv.org/abs/2512.22317
- Reference count: 7
- Primary result: Over 60% and 19% gains in heavy-rainfall CSI at 80-minute lead time on Swedish and MRMS datasets

## Executive Summary
This paper introduces LangPrecip, a novel framework for short-term precipitation nowcasting that integrates meteorological motion descriptions as semantic motion priors within a Rectified Flow generative model. The approach treats precipitation forecasting as a semantically constrained trajectory generation problem, enabling explicit fusion of textual and radar information in latent space. Experiments on a newly introduced LangPrecip-160k dataset demonstrate consistent improvements over state-of-the-art methods, particularly for heavy-rainfall events.

## Method Summary
LangPrecip formulates precipitation nowcasting as a semantically constrained trajectory generation problem using the Rectified Flow paradigm. The framework integrates meteorological motion descriptions as semantic priors to guide precipitation evolution, conditioning the generative model on both historical radar context and text descriptions. A 2D VAE compresses radar frames to latent space, where a velocity field conditioned on both visual and textual inputs generates future trajectories. The Wavelet Consistency Unfolding Decoder (WCUB) recovers high-frequency details while maintaining data fidelity through iterative gradient-based back-projection and wavelet-domain shrinkage. The model is trained on a new LangPrecip-160k dataset containing 160k paired radar sequences and motion descriptions.

## Key Results
- Achieves over 60% CSI gain for heavy rainfall at 80-minute lead time on Swedish dataset
- Improves heavy-rainfall CSI from 0.0530 to 0.0746 (40% gain) on Swedish dataset through text conditioning
- WCUB decoder improves PSNR from 28.78 to 29.65 and FVD from 9.18 to 6.94 compared to vanilla 2D VAE

## Why This Works (Mechanism)

### Mechanism 1
Textual motion descriptions provide high-level semantic constraints that regularize the otherwise under-constrained solution space of precipitation trajectory generation. Meteorological language encodes coarse-grained dynamics that are implicit in radar frames but not directly observable from single timesteps. By conditioning the generative model on these descriptions, the model receives explicit regularization toward physically consistent trajectories rather than inferring motion solely from pixel-level variations.

### Mechanism 2
Rectified Flow with semantic conditioning enables efficient trajectory generation by learning a deterministic velocity field that transports noise to data distribution while respecting textual constraints. The model learns velocity field u(x_t, c_ctx, t; θ) conditioned on historical radar context and motion description. Classifier-free guidance modulates constraint strength via weighted combination, allowing semantic information to directly influence generative dynamics.

### Mechanism 3
The Wavelet Consistency Unfolding Decoder (WCUB) recovers high-frequency details while maintaining data fidelity through iterative gradient-based back-projection and wavelet-domain shrinkage. Reconstruction is formulated as regularized optimization: argmin_x ||y - D_s(x*k)||² + λR(x). The decoder unrolls this into T stages, each with data-consistency module enforcing observation fidelity and wavelet-prior module applying wavelet-domain shrinkage.

## Foundational Learning

- **Concept: Rectified Flow / Flow Matching**
  - Why needed here: Core generative paradigm; must understand how ODE-based trajectory transport differs from diffusion's SDE formulation
  - Quick check question: Can you explain why rectified flow uses straight-line interpolation x_t = t·x_1 + (1-t)·x_0 and what velocity regression minimizes?

- **Concept: Cross-Modal Attention (Text-Visual Integration)**
  - Why needed here: Enables language conditioning in latent space; understanding how T5 embeddings interface with radar latents is critical
  - Quick check question: Given radar latents of shape [B, T, C, H, W] and text embeddings [B, L, D], how would cross-attention fuse these modalities?

- **Concept: Wavelet-Domain Sparse Priors**
  - Why needed here: WCUB relies on soft-thresholding high-frequency wavelet coefficients; must understand why sparsity assumptions help reconstruction
  - Quick check question: Why does wavelet shrinkage preserve edges while removing noise, and what determines the threshold τ_h?

## Architecture Onboarding

- **Component map**: Radar input → VAE encoder → latent concatenation with text embeddings → Rectified Flow trajectory generation → WCUB decoder → future radar prediction
- **Critical path**: The text conditioning must be active during both training and inference (with causal motion descriptions from first 4 frames only)
- **Design tradeoffs**: 2D VAE vs. 3D temporal compression (opts for 2D + lightweight temporal shift modules); CFG scale tuning (optimal around 3-5 for Swedish, 4-6 for MRMS); Manual vs. VLM annotation (20% human-annotated, 80% VLM-generated)
- **Failure signatures**: Fragmented echoes, spatial diffusion, mislocalized intensity cores at long lead times; FVD explosion with heavy 3D convolutions; CRPS degradation with excessive CFG
- **First 3 experiments**:
  1. Ablate text conditioning: Run with CFG scale = 0 (unconditional) vs. CFG = 3-5; expect CSI drop at heavy thresholds
  2. Test WCUB contribution: Replace unfolding decoder with vanilla 2D VAE decoder; expect PSNR drop (~0.8 dB) and FVD increase
  3. Motion consistency sanity check: Generate predictions with contradictory prompts and compute dominant flow direction; should see ~180° separation

## Open Questions the Paper Calls Out

### Open Question 1
Can language-guided nowcasting maintain robustness when motion descriptions contain noise, errors, or domain-shift biases? The paper notes that automated VLM-generated annotations may introduce noise or bias and potentially limit robustness under distribution shifts.

### Open Question 2
Can fine-grained precipitation dynamics—such as convective initiation, rapid intensification, and multi-cell interactions—be effectively captured through linguistic motion semantics? Current text annotations aggregate dynamics over 100-minute windows, which may blur transient but critical sub-event signals.

### Open Question 3
What is the fundamental trade-off between probabilistic calibration (CRPS) and extreme-event detection skill (high-threshold CSI) in semantically constrained generative nowcasting? LangPrecip achieves 60.9% CSI improvement for heavy rainfall but shows higher CRPS (0.132) than DTCA (0.115), suggesting that semantic guidance may shift calibration vs. detection balance.

## Limitations
- Architecture details remain underspecified, particularly Rectified Flow backbone structure and cross-modal fusion mechanism
- Training procedure lacks key hyperparameters (learning rate, batch size, optimizer, epochs)
- 80% automated VLM-generated annotations in LangPrecip-160k introduce potential noise and domain shift
- Relative contributions of text conditioning versus WCUB decoder are difficult to disentangle

## Confidence
- **High confidence**: WCUB decoder mechanism and empirical benefits (PSNR/FVD improvements)
- **Medium confidence**: Text conditioning mechanism and impact on heavy-rainfall CSI (depends on annotation quality and cross-attention details)
- **Medium confidence**: Rectified Flow formulation is standard, but effectiveness relative to diffusion-based alternatives not directly validated

## Next Checks
1. **Cross-modal attention ablation**: Remove text conditioning entirely (CFG=0) and measure CSI/FSS degradation at heavy thresholds
2. **Annotation quality study**: Compare performance using only 20% human-annotated descriptions versus full VLM-augmented dataset
3. **Temporal modeling stress test**: Replace WCUB decoder with pure 3D convolutional architecture to confirm FVD degradation