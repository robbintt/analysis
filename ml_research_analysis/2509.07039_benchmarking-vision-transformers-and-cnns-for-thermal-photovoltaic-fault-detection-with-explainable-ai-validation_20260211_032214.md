---
ver: rpa2
title: Benchmarking Vision Transformers and CNNs for Thermal Photovoltaic Fault Detection
  with Explainable AI Validation
arxiv_id: '2509.07039'
source_url: https://arxiv.org/abs/2509.07039
tags:
- thermal
- fault
- detection
- faults
- energy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the interpretability barrier in AI-driven
  photovoltaic fault detection by systematically comparing convolutional neural networks
  (CNNs) and vision transformers (ViTs) using thermal infrared imaging. A novel approach
  integrates XRAI saliency analysis to validate that model decisions align with thermal
  physics principles governing fault manifestations.
---

# Benchmarking Vision Transformers and CNNs for Thermal Photovoltaic Fault Detection with Explainable AI Validation

## Quick Facts
- arXiv ID: 2509.07039
- Source URL: https://arxiv.org/abs/2509.07039
- Reference count: 0
- Primary result: Swin Transformer achieves 94% binary accuracy and 73% multiclass accuracy in thermal PV fault detection with physics-validated interpretability

## Executive Summary
This study addresses the interpretability barrier in AI-driven photovoltaic fault detection by systematically comparing convolutional neural networks (CNNs) and vision transformers (ViTs) using thermal infrared imaging. A novel approach integrates XRAI saliency analysis to validate that model decisions align with thermal physics principles governing fault manifestations. Evaluation on 20,000 thermal images demonstrates that Swin Transformer achieves the highest performance (94% binary accuracy; 73% multiclass accuracy) compared to CNN alternatives. The analysis reveals that models learn physically meaningful features—localized hotspots for cell defects, linear thermal paths for diode failures, and thermal boundaries for vegetation shading—consistent with expected thermal signatures.

## Method Summary
The study evaluates four architectures (ResNet-18, EfficientNet-B0, ViT-Tiny, Swin-Tiny) on thermal PV images from the Raptor-Maps dataset. Models are trained on binary classification (normal vs faulty) and 11-class fault detection tasks using Adam optimizer with learning rates of 1e-4. CNNs use native 128×128 resolution while transformers require 224×224 resizing. XRAI saliency maps validate that attention aligns with thermophysically meaningful regions. The evaluation uses stratified 70:15:15 train/validation/test splits with no data augmentation beyond normalization.

## Key Results
- Swin Transformer achieves highest performance (94% binary accuracy; 73% multiclass accuracy) compared to CNN alternatives
- Electrical faults (diode, offline-module) achieve strong detection (F1-scores >0.90) while environmental factors like soiling remain challenging (F1-scores 0.20-0.33)
- XRAI analysis reveals models learn physically meaningful features aligned with thermal physics: localized hotspots for cell defects, linear thermal paths for diode failures, and thermal boundaries for vegetation shading

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Hierarchical attention mechanisms in Swin Transformers capture multi-scale thermal signatures more effectively than fixed-kernel convolutions.
- **Mechanism:** Shifted window attention allows the model to aggregate local thermal anomalies (cell-level hotspots) while simultaneously modeling global panel-level patterns (module-wide thermal gradients), enabling discrimination of fault classes with overlapping spatial characteristics.
- **Core assumption:** Thermal faults exhibit scale-dependent signatures—some manifest as localized point anomalies (hot-spots), others as linear features (diode paths), and others as regional patterns (vegetation shading).
- **Evidence anchors:** [abstract] "Swin Transformer achieves the highest performance (94% binary accuracy; 73% multiclass accuracy) compared to CNN approaches"

### Mechanism 2
- **Claim:** XRAI saliency maps reveal that high-performing models attend to thermophysically meaningful regions, providing validation that classification decisions stem from domain-relevant features rather than spurious correlations.
- **Mechanism:** XRAI segments images into regions and ranks them by integrated gradients attribution, exposing whether model attention localizes to known thermal signatures (hotspots, thermal gradients, boundary effects).
- **Core assumption:** If model attention aligns with thermal physics principles (e.g., diode failures show linear thermal paths), the model has learned transferable fault representations rather than dataset-specific artifacts.
- **Evidence anchors:** [abstract] "XRAI analysis reveals that models learn physically meaningful features, such as localized hotspots for cell defects, linear thermal paths for diode failures, and thermal boundaries for vegetation shading"

### Mechanism 3
- **Claim:** Performance disparities across fault types reflect fundamental detection limits imposed by thermal imaging resolution rather than model architecture.
- **Mechanism:** Electrical faults (diode, offline-module) produce distinct, high-contrast thermal signatures detectable at low resolution; environmental faults (soiling) produce diffuse, low-contrast thermal changes that fall below imaging noise thresholds.
- **Core assumption:** Thermal imaging captures temperature differentials proportional to electrical current flow anomalies but lacks sensitivity for gradual surface degradation.
- **Evidence anchors:** [abstract] "electrical faults achieve strong detection (F1-scores >0.90) while environmental factors like soiling remain challenging (F1-scores 0.20-0.33), indicating limitations imposed by thermal imaging resolution"

## Foundational Learning

- **Concept:** Thermal physics of PV fault manifestations
  - **Why needed here:** Without understanding that diode failures create linear thermal paths and cell defects create localized hotspots, you cannot validate whether XRAI attention maps are physically meaningful or arbitrary.
  - **Quick check question:** Given a thermal image showing a vertical hot stripe along panel edge, which fault type is most likely, and what electrical mechanism causes this signature?

- **Concept:** Attention mechanisms vs. convolutional inductive biases
  - **Why needed here:** The paper shows transformers outperform CNNs for multiclass (73% vs 69%) but match them for binary (94% vs 93%)—understanding why requires knowing what inductive biases each architecture imposes.
  - **Quick check question:** Why would a CNN with 3×3 kernels struggle more than attention-based models to capture elongated thermal features like diode failure paths?

- **Concept:** Region-based saliency (XRAI) vs. pixel-level attribution
  - **Why needed here:** XRAI evaluates whether attended regions align with thermal physics; pixel-level methods (Grad-CAM, Integrated Gradients alone) lack spatial coherence for structural fault validation.
  - **Quick check question:** What advantage does XRAI's region-based segmentation provide over raw gradient attribution when validating whether a model attends to cell-level vs. module-level thermal patterns?

## Architecture Onboarding

- **Component map:** Input: Thermal IR image (grayscale) → Channel replication (1→3) → Architecture-specific resize → Backbone: ImageNet-pretrained ResNet-18 / EfficientNet-B0 / ViT-Tiny / Swin-Tiny → Head: Linear classifier (2 or 11 classes) with optional dropout → Validation: XRAI saliency → Thermal physics alignment check

- **Critical path:**
  1. Preprocessing: Preserve thermal gradients—no geometric/photometric augmentation that perturbs temperature relationships
  2. Architecture selection: Swin-Tiny for multiclass, any architecture for binary (performance similar)
  3. Resolution handling: CNNs at native 128×128, Transformers at 224×224 (positional encoding requirement)
  4. Validation split: Stratified 70/15/15 to maintain fault class distributions

- **Design tradeoffs:**
  | Choice | Benefit | Cost |
  |--------|---------|------|
  | Swin over CNN | +4% multiclass accuracy, physics-aligned attention | Higher memory, 224×224 input required |
  | Binary over multiclass | +21% accuracy (94% vs 73%) | No fault type discrimination |
  | Thermal-only sensing | Non-contact, aerial deployable | Cannot detect soiling (F1 <0.33) |
  | CosineAnnealing scheduler | Better transformer convergence | Adds hyperparameter (T₀, T_mult) |

- **Failure signatures:**
  - Soiling misclassification: Attention scatters to periphery instead of uniform surface → model learning secondary cues, not physical signal
  - Cell vs cell-multi/vegetation confusion from confusion matrix—expected per paper; ensure stratification preserves class ratios
  - Transformer undertraining: Accuracy plateaus early → increase epochs to 15+ (vs. 10 for CNNs)

- **First 3 experiments:**
  1. Baseline architecture comparison: Train all 4 architectures on binary task with identical preprocessing; expect 93-94% accuracy across all.
  2. Fault-specific performance profiling: Evaluate per-class F1 on multiclass task; confirm diode >0.90, soiling <0.35 across architectures.
  3. XRAI physics validation: Generate saliency maps for 10 correctly classified diode-fault images; verify attention localizes to linear edge regions in ≥8/10 cases.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can multi-modal sensing integration combining thermal imaging with optical imaging, electrical parameter monitoring, or environmental sensors overcome the fundamental detection limits for environmental faults like soiling?
- **Basis in paper:** Section 4.5 states: "Future research priorities should address the identified thermal imaging limitations through multi-modal sensing integration."
- **Why unresolved:** Thermal-only approaches show consistent failure on soiling detection (F1-scores 0.20-0.33), with the paper noting that soiling can reduce output 20-40% annually in desert installations.
- **What evidence would resolve it:** Comparative evaluation of hybrid sensing systems achieving significantly higher soiling detection F1-scores (>0.70) while maintaining electrical fault performance.

### Open Question 2
- **Question:** How can physics-informed neural architectures embed thermal transfer equations and electrical circuit principles to improve both performance and interpretability?
- **Basis in paper:** Section 4.5 proposes: "Physics-informed neural architectures represent a promising direction... Such approaches could embed thermal transfer equations, electrical circuit principles, and mechanical failure modes into network architectures."
- **Why unresolved:** Current black-box approaches require extensive training data and lack explicit encoding of domain physics that governs fault manifestations.
- **What evidence would resolve it:** Demonstration that physics-informed architectures achieve higher accuracy with fewer training samples while producing inherently interpretable outputs aligned with thermal physics.

### Open Question 3
- **Question:** For multi-fault classes (Diode-Multi, Hot-Spot-Multi, Cell-Multi), are models detecting individual fault components or learning statistical correlations between multiple thermal anomalies?
- **Basis in paper:** Section 3.5.4 states: "attention patterns in these classes are less localized... making model validation as to whether the model is correctly picking up each unique fault component or simply picking up statistical relationships between multiple thermal anomalies an issue."
- **Why unresolved:** XRAI analysis showed diffuse attention patterns for multi-fault classes, but the paper did not design experiments to disentangle component detection from correlation learning.
- **What evidence would resolve it:** Controlled experiments with synthetic multi-fault images where individual fault components are systematically varied to test independent detection capability.

## Limitations
- Performance gaps across fault types suggest thermal imaging resolution as a fundamental constraint, with environmental fault detection (soiling F1: 0.20-0.33) potentially requiring multi-modal sensing
- XRAI interpretability validation relies on qualitative assessment of thermal physics alignment rather than systematic statistical validation
- The study uses a specific dataset (Raptor-Maps) with controlled imaging conditions, potentially limiting generalizability to real-world deployment scenarios

## Confidence
- **High confidence**: Swin Transformer performance superiority (94% binary, 73% multiclass accuracy) and electrical fault detection capability (F1 >0.90 for diode/offline-module)
- **Medium confidence**: XRAI saliency alignment with thermal physics principles, as validation is qualitative rather than statistically rigorous
- **Medium confidence**: Thermal resolution as the primary limiting factor for environmental fault detection, though this is supported by domain knowledge rather than empirical proof

## Next Checks
1. **Cross-dataset generalization**: Test models on thermal PV images from different sources and environmental conditions to validate robustness beyond the Raptor-Maps dataset
2. **Multi-modal fusion validation**: Implement and evaluate optical-thermal fusion approaches to determine if soiling detection improves beyond thermal-only limitations
3. **Saliency map consistency analysis**: Quantify XRAI attention map consistency across correctly classified instances of the same fault class using spatial correlation metrics