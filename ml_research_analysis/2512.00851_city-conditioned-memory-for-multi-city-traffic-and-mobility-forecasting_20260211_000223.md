---
ver: rpa2
title: City-Conditioned Memory for Multi-City Traffic and Mobility Forecasting
arxiv_id: '2512.00851'
source_url: https://arxiv.org/abs/2512.00851
tags:
- city
- citymem
- traffic
- cityid
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CityCond is a lightweight city-conditioned memory layer that improves
  multi-city traffic and mobility forecasting by conditioning on city identity. It
  can be attached to various spatio-temporal backbones (e.g., Transformer, GNN, STGCN)
  without modifying their internal architecture.
---

# City-Conditioned Memory for Multi-City Traffic and Mobility Forecasting

## Quick Facts
- arXiv ID: 2512.00851
- Source URL: https://arxiv.org/abs/2512.00851
- Reference count: 16
- Key outcome: CityCond improves multi-city traffic and mobility forecasting by conditioning on city identity.

## Executive Summary
CityCond introduces a lightweight city-conditioned memory layer that enhances multi-city forecasting by conditioning backbone models on city identity. The method can be attached to various spatio-temporal backbones (e.g., Transformer, GNN, STGCN) without modifying their internal architecture. It combines a city-ID encoder with an optional shared memory bank, producing city-conditioned features that modulate backbone hidden states. Evaluated across METR-LA, PEMS-BAY, and SIND datasets in full-data, low-data, and cross-city few-shot regimes, CityCond yields consistent gains—especially for high-capacity backbones. CityMem-Transformer reduces full-data error by roughly one third and improves cross-city transfer, while city-ID conditioning also helps in low-data trajectory prediction. CityCond thus offers a reusable, scalable design pattern for realistic multi-city forecasting.

## Method Summary
CityCond is a plug-in layer that conditions spatio-temporal backbones on city identity to improve multi-city forecasting. It uses a learnable city-ID embedding encoder, combined with an optional shared memory bank, to produce city-conditioned features. These features modulate the backbone’s hidden states via gating. The design is modular: it can be added to any backbone (Transformer, GNN, STGCN) without altering their internal architecture. The method supports both full-data and low-data regimes, and enables cross-city few-shot transfer by leveraging learned city representations.

## Key Results
- CityCond yields consistent performance gains across multiple backbones and datasets.
- CityMem-Transformer reduces full-data error by roughly one third compared to baseline.
- City-ID conditioning improves performance in low-data trajectory prediction and cross-city few-shot transfer.

## Why This Works (Mechanism)
CityCond works by injecting city-specific inductive bias into the backbone’s feature space. The city-ID encoder produces embeddings that, when combined with an optional shared memory bank, yield city-conditioned features. These features are used to modulate backbone hidden states via gating, allowing the model to adapt its internal dynamics to the unique patterns of each city. This modular conditioning enables better generalization across cities and improved transfer in low-data regimes.

## Foundational Learning
- **City-ID embeddings**: Learnable vectors representing each city; needed to inject city-specific inductive bias. Quick check: Are embeddings updated during training and consistent across runs?
- **Shared memory bank**: Optional reservoir of city-conditioned features; needed to capture city-specific patterns. Quick check: Does the bank improve performance over city-ID alone?
- **Feature gating**: Mechanism to modulate backbone states; needed to adapt model behavior per city. Quick check: Does gating improve performance over simple concatenation?
- **Backbone-agnostic design**: Ability to attach to various spatio-temporal models; needed for broad applicability. Quick check: Does CityCond improve performance across different backbone architectures?
- **Cross-city transfer**: Ability to adapt to new cities with limited data; needed for practical deployment. Quick check: Does CityCond enable effective few-shot learning for unseen cities?
- **Multi-city datasets**: Diverse urban data (METR-LA, PEMS-BAY, SIND); needed to validate generalization. Quick check: Are results consistent across different city topologies and traffic patterns?

## Architecture Onboarding

**Component Map**
City-ID Encoder -> Shared Memory Bank (optional) -> Gating Module -> Backbone Hidden States

**Critical Path**
1. City-ID embedding is generated.
2. (Optional) Memory bank is queried using pooled backbone states.
3. Gating module combines city-ID and memory features.
4. Gated features modulate backbone hidden states.

**Design Tradeoffs**
- Using only city-ID vs. combining with shared memory bank.
- Adding CityCond to high-capacity vs. lightweight backbones.
- Full-data vs. few-shot cross-city adaptation scenarios.

**Failure Signatures**
- If city-ID embeddings are not learned, CityCond provides no benefit.
- If memory bank is too small or too large, performance degrades.
- If gating is not applied, conditioning may not effectively modulate backbone states.

**First Experiments**
1. Compare CityCond (with city-ID only) to CityCond (with city-ID + memory) on METR-LA.
2. Evaluate CityCond on a lightweight backbone (e.g., STGCN) vs. a high-capacity backbone (e.g., Transformer).
3. Test cross-city few-shot performance on a held-out city not seen during training.

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can replacing discrete city-ID embeddings with semantic descriptors (e.g., POIs, demographics) enable effective zero-shot transfer to entirely unseen cities?
- Basis in paper: [explicit] Conclusion: "Future work includes... incorporating richer city descriptors (POIs, demographics, policies) into the city encoder."
- Why unresolved: The current CityCond architecture relies on learnable embeddings indexed by a discrete city ID, which inherently requires training data for a specific city index to form a useful representation.
- What evidence would resolve it: An experiment showing that a model conditioned on semantic city vectors (rather than random IDs) maintains performance on a held-out "target" city without any gradient updates or fine-tuning.

### Open Question 2
- Question: Does a hierarchical or region-based memory mechanism outperform the current global city-level pooling for large-scale urban networks?
- Basis in paper: [explicit] Conclusion: "Future work includes... exploring finer-grained memories at the region or sensor level."
- Why unresolved: The current design pools hidden states globally per city (Section 3.2) to query the memory bank, which may obscure local spatial patterns in large, heterogeneous cities.
- What evidence would resolve it: A comparative analysis on a high-density dataset evaluating a "RegionCond" variant against the global CityCond, specifically measuring error variance between central business districts and residential areas.

### Open Question 3
- Question: How can the CityMem mechanism be adapted for continuous-space multi-agent interactions where explicit graph topology is absent?
- Basis in paper: [explicit] Section 5.4: "We did not deploy CityMem on SIND in this work... we leave memory designs tailored to such settings as future work."
- Why unresolved: The authors note that SIND (trajectory data) lacks the static road graph structure used in traffic forecasting, and they only evaluated simple CityID conditioning in this domain.
- What evidence would resolve it: A study applying a modified CityMem layer to the SIND dataset, perhaps using interaction graphs, to determine if memory banks provide significant gains over the LSTM baseline in trajectory prediction.

## Limitations
- Improvements are most pronounced for high-capacity backbones; smaller gains for lightweight models.
- Ablation study omits city-ID conditioning, leaving the unique contribution of the shared memory bank unclear.
- Limited sample size of held-out cities in cross-city few-shot experiments.

## Confidence
- **High**: Core design validity (city-ID encoder + optional memory bank as a plug-in layer), reproducibility of experimental results on cited datasets.
- **Medium**: Generalization to unseen cities and transfer scenarios, robustness to backbone architecture choices beyond those tested.
- **Low**: Claims about optimal memory size or the necessity of both city-ID and memory components without further ablation.

## Next Checks
1. Conduct an ablation isolating the effect of the shared memory bank (removing city-ID conditioning) to quantify its unique contribution.
2. Test CityCond on additional backbones with varying parameter counts to clarify the relationship between backbone capacity and performance gains.
3. Expand cross-city few-shot experiments to more diverse city topologies and traffic regimes, including unseen city geometries.