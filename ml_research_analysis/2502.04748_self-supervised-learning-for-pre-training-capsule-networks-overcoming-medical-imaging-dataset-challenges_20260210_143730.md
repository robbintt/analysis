---
ver: rpa2
title: 'Self-Supervised Learning for Pre-training Capsule Networks: Overcoming Medical
  Imaging Dataset Challenges'
arxiv_id: '2502.04748'
source_url: https://arxiv.org/abs/2502.04748
tags:
- learning
- pre-training
- capsule
- training
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study investigates self-supervised learning (SSL) methods
  for pre-training capsule networks (CapsNets) on small, imbalanced medical imaging
  datasets, using colon polyp classification as a case study. The research addresses
  challenges in training CapsNets, which are under-represented in mainstream frameworks
  and lack pre-trained versions, by exploring two SSL auxiliary tasks: colourisation
  and contrastive learning with in-painting.'
---

# Self-Supervised Learning for Pre-training Capsule Networks: Overcoming Medical Imaging Dataset Challenges

## Quick Facts
- arXiv ID: 2502.04748
- Source URL: https://arxiv.org/abs/2502.04748
- Reference count: 33
- Primary result: SSL pre-training improves CapsNet accuracy by 5.26% on small, imbalanced colon polyp dataset

## Executive Summary
This study addresses the challenge of training capsule networks (CapsNets) on small, imbalanced medical imaging datasets by investigating self-supervised learning (SSL) pre-training methods. Using colon polyp classification as a case study with the PICCOLO dataset (3,433 frames), the research demonstrates that SSL pre-training can effectively guide CapsNets to capture important visual features, achieving a 5.26% increase in accuracy compared to random initialization. The dual-stage SSL approach combining contrastive learning and in-painting reconstruction outperforms traditional ImageNet pre-training alternatives, particularly for architectures with limited native support in mainstream frameworks.

## Method Summary
The study modifies standard CapsNet architecture by adding 5 extra convolutional layers before the primary capsules, creating a deeper network capable of learning richer feature representations. The model uses spread loss for classification and employs two SSL auxiliary tasks: colorisation with L1 and perceptual losses, and contrastive learning with in-painting reconstruction using NT-Xent loss. Pre-processing includes border removal, CLAHE enhancement, and histogram matching between WL and NBI images. Training uses AdamW optimizer with cosine annealing learning rate schedule, gradient accumulation (effective batch size 64), and weighted sampling to address class imbalance. The SSL pre-training runs for 200 epochs before fine-tuning on the downstream classification task.

## Key Results
- SSL pre-training achieved 5.26% accuracy improvement over random initialization
- Dual-stage SSL (contrastive + in-painting) outperformed colorisation and other baselines
- Best SSL-contrastive model achieved 0.40 accuracy, 0.22 MCC, and 0.16 balanced accuracy
- SSL pre-training effectively mitigated class imbalance effects in downstream classification
- Extended training time (200+ epochs) necessary due to slow convergence in CapsNets

## Why This Works (Mechanism)
CapsNets excel at preserving spatial relationships and part-whole hierarchies in images, making them theoretically well-suited for medical imaging where context and spatial relationships are critical. However, their under-representation in mainstream frameworks and lack of pre-trained versions creates significant training challenges, particularly with small datasets. SSL pre-training addresses this by allowing the network to learn useful visual representations without requiring labeled data, effectively bootstrapping the learning process. The contrastive and in-painting tasks specifically encourage the network to learn meaningful feature representations that transfer well to the downstream classification task.

## Foundational Learning
- **Capsule Networks**: Hierarchical networks that preserve spatial relationships through vector outputs, enabling equivariant feature learning. Why needed: Medical images require understanding of spatial context and part-whole relationships. Quick check: Verify routing algorithm correctly updates coupling coefficients.
- **Self-Supervised Learning**: Training method using proxy tasks with inherent supervisory signals. Why needed: Medical datasets are often small and labeled data is expensive to obtain. Quick check: Monitor reconstruction loss during SSL pre-training.
- **Spread Loss**: Classification loss that spreads activation vectors for different classes. Why needed: CapsNets use vector outputs requiring specialized loss functions. Quick check: Verify activation vectors are properly normalized and spread.
- **Contrastive Learning**: Learning representations by comparing similar and dissimilar samples. Why needed: Encourages learning of invariant features useful for classification. Quick check: Monitor NT-Xent loss and temperature parameter.
- **In-painting Reconstruction**: Predicting missing image regions. Why needed: Forces network to learn comprehensive feature representations. Quick check: Evaluate reconstruction quality on validation set.

## Architecture Onboarding

**Component Map**: Input Images -> Pre-processing -> 5 Conv Layers -> Primary Capsules -> Routing -> Class Capsules -> Classification + Decoder

**Critical Path**: Input → Pre-processing → Modified CapsNet (5 extra conv layers) → SSL Tasks (contrastive + in-painting) → Classification → Evaluation

**Design Tradeoffs**: 
- Added conv layers improve feature learning but increase computational cost and training time
- Dual SSL approach provides better pre-training but requires careful loss balancing
- Spread loss better suited for CapsNets but harder to tune than cross-entropy
- Weighted sampling addresses imbalance but may introduce sampling bias

**Failure Signatures**:
- Extremely slow convergence with gradients in primary capsules and routing weights only 10⁻⁶ to 10⁻⁵ per epoch
- Class imbalance implicitly learned during SSL degrades transfer learning performance
- Network fails to capture color vibrancy in reconstructions, suggesting insufficient feature learning
- Poor routing convergence leading to collapsed capsule activations

**First Experiments**:
1. Verify modified CapsNet architecture with 5 extra conv layers trains successfully on a small subset of data
2. Test individual SSL components (colorisation-only, contrastive-only, in-painting-only) to establish baseline performance
3. Evaluate reconstruction quality during SSL pre-training to ensure meaningful feature learning is occurring

## Open Questions the Paper Calls Out
**Open Question 1**: Does balancing the dataset during SSL pre-training prevent the CapsNet from implicitly learning class imbalances that degrade transfer learning performance?
The authors observed that pre-trained weights on imbalanced data required extra epochs (5-10) to overcome inherent biases, but did not test balancing interventions during SSL pre-training.

**Open Question 2**: Can layer-specific learning rate adjustments effectively mitigate slow convergence and weak gradient signals in deeper CapsNet layers during SSL?
The study identified that gradient signals weaken considerably before reaching class capsules and routing weights update slowly, but standard optimization strategies were used.

**Open Question 3**: Does extending SSL pre-training to 500 epochs significantly improve the model's ability to capture visual features in high-resolution medical images?
Current study limited to 200 epochs, during which the network failed to fully capture color vibrancy, potentially limiting feature quality.

## Limitations
- Key architectural hyperparameters remain unspecified (filter counts, capsule dimensions, routing iterations)
- 5.26% accuracy improvement may not generalize beyond PICCOLO dataset without additional validation
- Dual-stage SSL approach shows best results but ablation studies for individual components are limited
- Slow convergence requires extended training time (200+ epochs), increasing computational cost

## Confidence
- **High Confidence**: SSL pre-training improves CapsNet performance over random initialization on PICCOLO dataset; capsule networks face convergence challenges requiring extended training time
- **Medium Confidence**: Contrastive + in-painting SSL outperforms colorisation and other baselines; pre-training mitigates class imbalance effects in downstream classification
- **Low Confidence**: SSL pre-training is a universally viable alternative to ImageNet pre-training for CapsNets across all medical imaging domains

## Next Checks
1. **Architecture Parameterization**: Systematically vary the number of additional conv layers (3-7) and capsule dimensions to determine optimal CapsNet architecture for medical imaging SSL pre-training
2. **SSL Component Ablation**: Train CapsNets using individual SSL tasks (colorisation-only, contrastive-only, in-painting-only) to quantify contribution of each component to final performance
3. **Dataset Generalization**: Validate SSL pre-training benefits on at least two additional small, imbalanced medical imaging datasets (e.g., X-ray abnormalities, skin lesion classification) to assess broader applicability