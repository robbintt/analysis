---
ver: rpa2
title: 'CureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning'
arxiv_id: '2512.05576'
source_url: https://arxiv.org/abs/2512.05576
tags:
- reasoning
- txagent
- arxiv
- retrieval
- clinical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work addresses the Context Utilization Failure in clinical
  reasoning agents, where models retrieve biomedical evidence but fail to ground diagnoses
  in it. The proposed Executor-Analyst Framework decouples tool execution (Executor:
  TxAgent for precise retrieval) from evidence synthesis (Analyst: Gemini for reasoning),
  mitigating reasoning deficits.'
---

# CureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning

## Quick Facts
- arXiv ID: 2512.05576
- Source URL: https://arxiv.org/abs/2512.05576
- Authors: Ting-Ting Xie; Yixin Zhang
- Reference count: 26
- Primary result: Achieves 81.367% accuracy on CURE-Bench without costly finetuning using a training-free Executor-Analyst framework

## Executive Summary
This work addresses Context Utilization Failure in clinical reasoning agents, where models retrieve biomedical evidence but fail to ground diagnoses in it. The proposed Executor-Analyst Framework decouples tool execution (Executor: TxAgent for precise retrieval) from evidence synthesis (Analyst: Gemini for reasoning), mitigating reasoning deficits. A Stratified Ensemble strategy preserves evidentiary diversity by maintaining parallel retrieval paths, outperforming global pooling. Stress tests reveal a Context-Performance Paradox (accuracy drops beyond 12k tokens) and the Curse of Dimensionality in large tool spaces. The framework achieves state-of-the-art performance on CURE-Bench without costly finetuning, offering a scalable, training-free approach for trustworthy AI therapeutics.

## Method Summary
The framework employs a training-free Executor-Analyst architecture where a fine-tuned 8B TxAgent (Executor) retrieves biomedical evidence via ToolUniverse APIs with self-consistency sampling, while Gemini 2.5 (Analyst) synthesizes the aggregated context into clinical diagnoses. The Stratified Ensemble approach partitions Executors into parallel subgroups, each maintaining independent reasoning paths that are late-fused via majority vote. Post-processing includes regex-based format calibration and response deduplication. Best configuration uses n₁=10 Executors per subgroup, n₂=3 subgroups, and Gemini 2.5 Flash with search enabled.

## Key Results
- Achieves 81.367% accuracy on CURE-Bench phase2 test set, outperforming global pooling baseline (80.510%)
- Self-consistency improves accuracy from 69.3% (greedy) to 74.2% (n=60) on phase2
- Context-Performance Paradox: accuracy drops sharply beyond 12k tokens
- Curse of Dimensionality: 4.5% accuracy drop when tool count increases from 200 to 600

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decoupling tool execution from reasoning improves clinical diagnosis accuracy by matching model strengths to task demands.
- Mechanism: A fine-tuned 8B model (TxAgent) handles precise API syntax and tool selection, while a large foundation model (Gemini 2.5) performs evidence synthesis. This separates syntactic precision from semantic robustness, preventing the compact model from attempting complex reasoning it cannot sustain.
- Core assumption: Tool-use proficiency and high-level clinical reasoning are separable cognitive demands that different model scales handle better when isolated.
- Evidence anchors:
  - [abstract] "decouples the syntactic precision of tool execution from the semantic robustness of clinical reasoning"
  - [section 2.1-2.2] Executor aggregates context; Analyst synthesizes noisy evidence without syntactic burden
  - [corpus] Weak direct evidence; neighbor papers emphasize multi-modal integration but not decoupling strategies
- Break condition: If tool syntax becomes indistinguishable from reasoning (e.g., tools requiring inference to select), the separation may introduce information loss.

### Mechanism 2
- Claim: Stratified Ensemble (late fusion) preserves evidentiary diversity and reduces collective hallucination compared to early aggregation.
- Mechanism: Partition Executors into parallel subgroups; each subgroup maintains an independent reasoning path through a dedicated Analyst. Final decisions aggregate at the answer level, not the evidence level. This prevents minority-but-critical evidence from being filtered before reasoning.
- Core assumption: Diverse retrieval paths contain non-overlapping valid signals that early consensus would discard.
- Evidence anchors:
  - [abstract] "Stratified Ensemble strategy preserves evidentiary diversity by maintaining parallel retrieval paths, outperforming global pooling"
  - [section 2.3] Config B achieves 81.367% vs Config A's 80.510% with same compute budget
  - [corpus] No direct corpus evidence for stratified ensemble in clinical agents
- Break condition: When retrieval paths are highly redundant, stratification adds latency without diversity gains.

### Mechanism 3
- Claim: Self-consistency sampling improves retrieval and reasoning robustness by aggregating multiple reasoning paths.
- Mechanism: Sample n reasoning paths with moderate temperature (0.8); aggregate tool outputs via majority voting. Low-sample regime (n<15) shows rapid gains; plateau occurs around n=20-60.
- Core assumption: Correct answers cluster across samples while errors distribute randomly.
- Evidence anchors:
  - [abstract] "outperforming global pooling" implies aggregation strategy matters
  - [section 3.2] Self-consistency improves from 69.3% (greedy) to 74.2% (n=60) on phase2
  - [corpus] Neighbor paper "Understanding Model Merging" discusses aggregation theory but not self-consistency specifically
- Break condition: When task has genuinely multiple valid answers, majority voting may suppress correct minority paths.

## Foundational Learning

- Concept: **Tool-augmented LLM agents**
  - Why needed here: The framework assumes familiarity with models that invoke external APIs (ToolUniverse) rather than relying solely on parametric knowledge.
  - Quick check question: Can you explain why a model might fail to use a tool even when the tool documentation is available in-context?

- Concept: **Self-consistency decoding**
  - Why needed here: The Executor and Analyst both use self-consistency; understanding how temperature and sample count trade off is critical for configuration.
  - Quick check question: What happens to self-consistency benefits if temperature is set too low (e.g., 0.1)?

- Concept: **Information fusion topologies (early vs. late fusion)**
  - Why needed here: The core architectural decision is when to aggregate evidence; early fusion risks information bottlenecks.
  - Quick check question: In a multi-agent pipeline, what signal would indicate early fusion is discarding useful evidence?

## Architecture Onboarding

- Component map:
  - Query → Executor(s) retrieve evidence → Self-consistency aggregation within subgroups → Each subgroup's Analyst reasons independently → Late fusion via majority vote on final answers → Post-processing

- Critical path: Query → Executor(s) retrieve evidence → Self-consistency aggregation within subgroups → Each subgroup's Analyst reasons independently → Late fusion via majority vote on final answers → Post-processing

- Design tradeoffs:
  - More Executors (n1) improve retrieval breadth but increase latency
  - More Analysts (n2) improve reasoning robustness but multiply API costs
  - Config A (global pooling) simpler but loses diversity; Config B (stratified) more robust but harder to debug
  - Search-enabled Analyst improves accuracy (83.8%) but introduces external dependencies

- Failure signatures:
  - **Context-Performance Paradox**: Accuracy drops sharply (>6%) when context exceeds 12k tokens—excessive evidence introduces noise
  - **Curse of Dimensionality**: Accuracy drops 4.5% when tool count increases from 200 to 600—flat retrieval struggles at scale
  - **Output Parsing Errors** (19.2%): Regex failures when model output deviates from expected format
  - **Instruction Adherence Failures** (12.3%): Model ignores format constraints

- First 3 experiments:
  1. Calibrate Executor temperature: Sweep [0.6, 0.7, 0.8, 0.9] on validation set; expect peak at 0.8 as per Table 3
  2. Compare Config A vs Config B: Fix total Executors (e.g., N=30), partition as 30×1 (global) vs 10×3 (stratified); measure accuracy delta
  3. Stress test context length: Bucket validation samples by reasoning token count; identify where accuracy degrades (expect ~12k threshold)

## Open Questions the Paper Calls Out
None

## Limitations
- Context-Performance Paradox remains poorly understood mechanistically - unclear whether due to attention saturation, semantic interference, or token-order effects
- Stratified Ensemble superiority lacks theoretical grounding; no analysis of what unique evidence each subgroup captures
- Claim of eliminating finetuning costs requires qualification due to ongoing Gemini API costs that may exceed traditional finetuning at scale

## Confidence
- **High Confidence**: The Executor-Analyst architectural separation demonstrably improves performance over monolithic approaches with 6.7% gain from global pooling to stratified ensemble
- **Medium Confidence**: Specific hyperparameters (n₁=10, n₂=3, temperature=0.8) are optimal within tested ranges but may not generalize across clinical reasoning tasks
- **Low Confidence**: Framework's claim to eliminate finetuning costs is qualified by ongoing API costs that may exceed traditional finetuning at scale

## Next Checks
1. **Context Length Sensitivity Analysis**: Systematically vary reasoning token count (2k-20k) on CURE-Bench validation set to map the exact inflection point where accuracy begins degrading and whether this correlates with evidence redundancy versus semantic interference

2. **Stratified Ensemble Diversity Audit**: Implement tool selection entropy tracking across subgroups to quantify actual diversity captured. Compare against a stratified-random baseline where subgroups receive identical tool sets but different reasoning seeds

3. **Cross-Benchmark Generalization**: Evaluate the trained TxAgent + Gemini Analyst pipeline on a non-CURE clinical reasoning benchmark (e.g., MedQA-USMLE) to test whether the 12k token threshold and stratified benefits transfer to different question distributions and evidence requirements