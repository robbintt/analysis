---
ver: rpa2
title: Anisotropic Fourier Features for Positional Encoding in Medical Imaging
arxiv_id: '2509.02488'
source_url: https://arxiv.org/abs/2509.02488
tags:
- afpe
- spatial
- ifpe
- shape
- positional
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of incorporating spatial information
  into Transformer models for medical imaging, where traditional positional encodings
  may be suboptimal due to anisotropy in 3D data and dynamic processes. The authors
  propose Anisotropic Fourier Feature Positional Encoding (AFPE), which generalizes
  isotropic Fourier features by introducing dimension-specific scaling factors to
  better capture directional spatial dependencies.
---

# Anisotropic Fourier Features for Positional Encoding in Medical Imaging

## Quick Facts
- **arXiv ID**: 2509.02488
- **Source URL**: https://arxiv.org/abs/2509.02488
- **Reference count**: 24
- **Key outcome**: AFPE significantly outperforms standard positional encodings in anisotropic medical imaging tasks by introducing dimension-specific scaling factors to Fourier features.

## Executive Summary
This paper addresses the challenge of incorporating spatial information into Transformer models for medical imaging, where traditional positional encodings may be suboptimal due to anisotropy in 3D data and dynamic processes. The authors propose Anisotropic Fourier Feature Positional Encoding (AFPE), which generalizes isotropic Fourier features by introducing dimension-specific scaling factors to better capture directional spatial dependencies. AFPE was systematically benchmarked against commonly used positional encodings across multiple medical imaging tasks including multi-label classification in chest X-rays, organ classification in CT, and ejection fraction regression in echocardiography. Results show that AFPE significantly outperforms state-of-the-art positional encodings in all tested anisotropic settings, with the optimal PE depending on the shape of the structure of interest and the degree of data anisotropy.

## Method Summary
AFPE generalizes standard Fourier Feature Positional Encodings by sampling dimension-specific Gaussian distributions for frequency parameters. For a position p ∈ R^m, AFPE samples B_i ~ N(0, s_i) for each dimension i, then computes γ(p) = [sin(2πBp) || cos(2πBp)]. The scale vector s represents anisotropy parameters that control how positional similarity is computed along each axis independently. The method was evaluated against multiple baselines (No PE, Learnable PE, Sinusoidal PE, Isotropic Fourier PE) across four medical imaging tasks using Vision Transformer architectures with varying depths and widths.

## Key Results
- AFPE significantly outperforms all baseline positional encodings on anisotropic datasets (OrganMNIST3D with anisotropy ratios 1/4/6/8)
- The optimal positional encoding depends on the degree of data anisotropy and the geometric structure of the target anatomy
- For EchoNet video regression, AFPE with decoupled spatial/temporal scales achieved R² = 0.621 vs 0.547 for isotropic Fourier PE
- In chest X-ray classification, AFPE improved AUPRC by up to 2.1% compared to the best baseline method

## Why This Works (Mechanism)

### Mechanism 1
Applying dimension-specific scaling factors to Fourier features enables Vision Transformers to better model anisotropic spatial dependencies found in medical data. Standard Fourier Feature PEs sample frequencies from a Gaussian distribution with a single scalar variance, while AFPE uses a diagonal covariance matrix with independent variance per dimension. This allows the encoding to stretch or compress the positional similarity space independently along each axis, capturing directional differences in anatomical continuity.

### Mechanism 2
Fourier-based encodings preserve Euclidean distances and high-frequency shape details more effectively than Sinusoidal Positional Encodings, particularly for diagonal relationships. SPE encodes dimensions separately and concatenates them, which distorts Euclidean distances in the resulting embedding space. Random Fourier features map coordinates into a higher-dimensional space that approximates a stationary kernel, preserving relative distances between points regardless of direction.

### Mechanism 3
Decoupling spatial and temporal scale parameters is critical for video-based regression tasks where temporal axes are physically distinct from spatial axes. In echocardiography, the "distance" between frames is not commensurate with the distance between spatial pixels. AFPE allows setting high temporal scales to encourage frame differentiation while using different spatial scales for smoothness, effectively modeling dimensionally decoupled anisotropy.

## Foundational Learning

- **Concept**: Fourier Feature Mappings
  - **Why needed here**: Standard MLPs and Transformers struggle with high-frequency details (spectral bias). Fourier features map inputs to a higher frequency domain to overcome this.
  - **Quick check question**: How does mapping a coordinate p to [sin(2πBp), cos(2πBp)] change the "distance" the model sees between two points compared to raw coordinates?

- **Concept**: Anisotropy in Imaging
  - **Why needed here**: Medical images often have different resolutions (pixel spacing vs slice thickness) or modalities (space vs time) which makes them "anisotropic."
  - **Quick check question**: Why would a standard positional encoding, which treats X-axis and Y-axis identically, fail to capture the geometry of a CT scan where slice thickness is 5mm but in-plane resolution is 1mm?

- **Concept**: Positional Encodings (PE) in Vision Transformers (ViT)
  - **Why needed here**: ViTs are permutation invariant; without PE, they see an image as a "bag of patches." The paper proposes a specific type of PE.
  - **Quick check question**: If you randomize the order of patches in a ViT input, what happens to the output if there is no positional encoding vs. if there is a standard learned positional encoding?

## Architecture Onboarding

- **Component map**: Input patches x ∈ R^(N×D) and Grid Coordinates p ∈ R^(N×m) → AFPE Layer with scale vector s → Compute B_i ~ N(0, s_i) per dimension → Calculate γ(p) = [sin(2πBp) || cos(2πBp)] → Add γ(p) to linear projection of patches x

- **Critical path**: The selection of the scale vector s. The paper treats these as hyperparameters found via random search (50 runs) or set by anisotropy ratio. If s is wrong, the mechanism fails.

- **Design tradeoffs**:
  - Fixed vs. Learnable: AFPE imposes a stronger structural prior (anisotropy), which improves data efficiency but might limit flexibility if anatomical assumptions are wrong
  - Sampling Strategy: The paper samples B randomly, introducing stochasticity that requires tuning s to stabilize the "effective" frequency band

- **Failure signatures**:
  - Performance Plateau: Model performs similar to "No PE" baseline (indicates s values are effectively zero or infinite, wiping out positional signal)
  - Diagonal Artifacts: If converting from SPE to AFPE and seeing checkerboard/diagonal artifacts in attention maps, check that scaling is applied correctly per dimension
  - Temporal Overfitting: In video tasks, if model ignores motion, s_time might be too small, causing all frames to look positionally identical

- **First 3 experiments**:
  1. Sanity Check (Synthetic Anisotropy): Take an isotropic dataset, artificially downsample one axis, compare SPE vs. IFPE vs. AFPE where AFPE scales are set to inverse of stretch ratio
  2. Hyperparameter Sweep: Run grid search on s_row vs s_col for ChestX, plot ratio s_row/s_col against class-specific performance
  3. Dimensional Ablation: On video dataset, run conditions: (A) Single scale s for all dims, (B) Separate s_space and s_time, (C) Fully decoupled s_height, s_width, s_time

## Open Questions the Paper Calls Out

- Can AFPE be effectively integrated into segmentation models (e.g., SAM) and object detection frameworks (e.g., DETR)?
- Is it feasible to learn the anisotropic scale parameters (s_i) directly within an end-to-end training pipeline without sacrificing performance?
- Does the strong inductive shape bias provided by AFPE reduce the data volume required to train high-performance medical imaging models?

## Limitations
- The hyperparameter search for scale parameters was constrained to 50 random runs, which may not exhaustively identify optimal configurations
- The method's benefits are most pronounced in highly anisotropic datasets, but the paper doesn't thoroughly explore whether the added complexity is justified for moderately anisotropic data
- The paper demonstrates clear performance gains but relies heavily on performance metrics rather than direct visualization of how positional attention patterns differ between PE types

## Confidence
- **High Confidence**: The core mechanism of AFPE (dimension-specific scaling of Fourier features) is mathematically sound and the empirical improvements over baselines are statistically significant
- **Medium Confidence**: The claim that SPE fails to preserve Euclidean distances is supported by theoretical arguments and similarity map visualizations, but the practical impact on model performance varies by task
- **Low Confidence**: The assertion that decoupling spatial and temporal scales is "critical" for video-based regression is primarily supported by the EchoNet results and may be overstated for general applicability

## Next Checks
1. **Sensitivity Analysis of Scale Parameters**: Systematically vary the scale vector s around reported optimal values for each dataset and measure performance degradation
2. **Cross-Modality Transfer**: Train AFPE on one anisotropic modality (e.g., CT with known anisotropy) and test on another (e.g., MRI with different anisotropy patterns) without re-tuning scales
3. **Learned vs. Fixed Anisotropy**: Replace fixed dimension-specific scaling with a small learned neural network that predicts scale factors from input statistics, compare performance and parameter efficiency against fixed AFPE