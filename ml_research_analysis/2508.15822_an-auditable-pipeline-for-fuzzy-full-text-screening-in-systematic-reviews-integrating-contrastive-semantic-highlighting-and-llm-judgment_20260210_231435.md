---
ver: rpa2
title: 'An Auditable Pipeline for Fuzzy Full-Text Screening in Systematic Reviews:
  Integrating Contrastive Semantic Highlighting and LLM Judgment'
arxiv_id: '2508.15822'
source_url: https://arxiv.org/abs/2508.15822
tags:
- fuzzy
- screening
- full-text
- systematic
- inclusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a fuzzy logic-based pipeline for full-text
  screening in systematic reviews, integrating contrastive semantic highlighting and
  LLM adjudication to address the challenge of distributed, ambiguous evidence. Articles
  are chunked, embedded, and scored against inclusion/exclusion criteria; a Mamdani
  fuzzy controller aggregates similarity and vagueness into graded inclusion degrees,
  and an LLM provides tertiary judgments with rationales.
---

# An Auditable Pipeline for Fuzzy Full-Text Screening in Systematic Reviews: Integrating Contrastive Semantic Highlighting and LLM Judgment

## Quick Facts
- **arXiv ID:** 2508.15822
- **Source URL:** https://arxiv.org/abs/2508.15822
- **Reference count:** 40
- **Primary result:** Fuzzy system achieved 81.3% (Population), 87.5% (Intervention), 87.5% (Outcome), and 75.0% (Study Approach) recall on 16 full-texts; LLM attenuation reduced human screening time from ~20 minutes to under 1 minute per article.

## Executive Summary
This paper presents a fuzzy logic-based pipeline for full-text screening in systematic reviews, integrating contrastive semantic highlighting and LLM adjudication to handle distributed, ambiguous evidence. Articles are chunked, embedded, and scored against inclusion/exclusion criteria; a Mamdani fuzzy controller aggregates similarity and vagueness into graded inclusion degrees, and an LLM provides tertiary judgments with rationales. Evaluated on an all-positive gold set of 16 full texts (3,208 chunks), the fuzzy system surpassed statistical and crisp baselines in recall, with 50.0% strict "all-criteria" inclusion versus 25.0% and 12.5% for baselines. Cross-model agreement on justifications was 98.3%, human-machine 96.1%, and reviewer time reduced from ~20 minutes to under 1 minute per article.

## Method Summary
The pipeline chunks PDFs into 3-5 sentence overlapping segments, embeds them using a domain-adapted model (OpenAI text-embedding-3-large), and computes contrastive similarity by subtracting exclusion cosine similarity from inclusion similarity. A Mamdani fuzzy controller maps these scores and ambiguity margins to graded inclusion degrees using a 9-rule base and triangular membership functions. An LLM (GPT-4.1-mini) provides tertiary Yes/No/Maybe judgments with rationales, attenuating fuzzy membership rather than excluding chunks outright. Document-level decisions are aggregated via noisy-OR. The code is available at https://github.com/pouriamrt/FullTextScreener.

## Key Results
- Fuzzy system achieved 81.3% (Population), 87.5% (Intervention), 87.5% (Outcome), and 75.0% (Study Approach) recall
- Strict "all-criteria" inclusion was 50.0% versus 25.0% and 12.5% for baselines
- Cross-model agreement on LLM justifications was 98.3%; human-machine agreement was 96.1%
- Reviewer time reduced from ~20 minutes to under 1 minute per article

## Why This Works (Mechanism)

### Mechanism 1: Contrastive Semantic Separation
- **Claim:** Subtracting exclusion similarity from inclusion similarity improves signal-to-noise ratio for relevant text spans.
- **Mechanism:** The system calculates $s_{c,k} = \cos(e_c, e_{incl,k}) - \cos(e_c, e_{excl,k})$. By penalizing chunks that overlap with exclusion criteria, this subtraction suppresses generic or off-target matches that often trigger false positives in standard semantic search.
- **Core assumption:** The domain-adapted embedding model represents inclusion and exclusion criteria in a way that their vector differences carry meaningful semantic weight.
- **Evidence anchors:**
  - [abstract] "...compute contrastive similarity (inclusion–exclusion cosine)..."
  - [section 2.1.2] "This contrastive formulation reduces false positives from generic or off-target matches..."
  - [corpus] Corpus evidence for this specific contrastive mechanism is weak; neighbors focus on standard LLM classification (e.g., SESR-Eval, AiReview) rather than vector subtraction strategies.
- **Break condition:** If inclusion and exclusion criteria are semantically similar (e.g., "population health" vs. "public health"), the subtraction may nullify the score, leading to missed evidence.

### Mechanism 2: Mamdani Fuzzy Inference for Graded Evidence
- **Claim:** Mapping continuous similarity scores to graded "membership degrees" preserves ambiguous evidence that binary classifiers would discard.
- **Mechanism:** A Mamdani controller accepts a score and a "margin" (ambiguity measure) as inputs, fuzzifies them into linguistic terms (e.g., "high score," "small margin"), and applies rules to output a graded inclusion degree $\mu \in [0,1]$. This allows "maybe" cases to be retained for human review rather than hard-excluded.
- **Core assumption:** Decision boundaries in systematic reviews are inherently vague and benefit from "partial truth" values rather than binary logic.
- **Evidence anchors:**
  - [abstract] "...Mamdani fuzzy controller aggregates similarity and vagueness into graded inclusion degrees..."
  - [section 2.1.4] "...yielding graded inclusion degrees and support multi-label assignment."
  - [corpus] No corpus neighbors integrate fuzzy logic; this appears to be a novel architectural choice compared to standard LLM or SVM classifiers.
- **Break condition:** If the rule base (e.g., "IF score is medium AND margin is small THEN decision is maybe") is poorly tuned, the system may output uniformly high membership scores, failing to filter noise.

### Mechanism 3: LLM Attenuation over Exclusion
- **Claim:** Using an LLM to attenuate scores rather than reverse decisions prevents cascade failures in document aggregation.
- **Mechanism:** When the LLM judges highlighted evidence as insufficient, the corresponding fuzzy membership score is lowered (attenuated) but not zeroed out. This conservative approach ensures that a single chunk's rejection does not irrationally sink the document's aggregate score (calculated via noisy-OR).
- **Core assumption:** LLMs provide a reliable "tertiary judgment" on semantic relevance that is more nuanced than the initial vector similarity.
- **Evidence anchors:**
  - [abstract] "...when evidence is insufficient, fuzzy membership is attenuated rather than excluded."
  - [section 2.1.7] "If the LLM judges the evidence insufficient (NO), the corresponding µ is attenuated or flagged as uncertain..."
  - [corpus] Consistent with neighbors (e.g., LGAR, AISysRev) showing LLMs act as effective judges, though the specific "attenuation" logic is unique to this paper.
- **Break condition:** If the LLM hallucinates constraints or is overly critical, it may attenuate valid evidence, lowering recall.

## Foundational Learning

- **Concept:** **Mamdani Fuzzy Inference**
  - **Why needed here:** This is the core logic engine replacing standard classification thresholds. You cannot debug the system without understanding how "crisp" inputs (cosine scores) map to "fuzzy" outputs (inclusion degrees) via rule bases.
  - **Quick check question:** If a chunk has a high similarity score but a very small margin (high ambiguity), would the fuzzy rules likely output "Accept" or "Maybe"?

- **Concept:** **Contrastive Embedding**
  - **Why needed here:** The quality of the fuzzy inputs depends entirely on how well the embedding space separates "inclusion" concepts from "exclusion" concepts.
  - **Quick check question:** Why is a simple cosine similarity to the *inclusion* criteria insufficient for this specific problem domain?

- **Concept:** **Noisy-OR Aggregation**
  - **Why needed here:** The pipeline must synthesize hundreds of chunk-level scores into a single document-level decision. Noisy-OR allows strong evidence in one chunk to outweigh weak evidence in others.
  - **Quick check question:** If 90% of chunks have a low inclusion score (0.1) but one chunk has a high score (0.9), does the document get included?

## Architecture Onboarding

- **Component map:** PDF Parser & Chunker (3-5 sentences, overlapping) -> Embedder (Domain-adapted model, e.g., text-embedding-3-large) -> Contrastive Scorer (Subtractive cosine) & Margin Calculator -> Mamdani Fuzzy Controller (Rule-based aggregation) -> LLM Judge (GPT-4.1-mini providing Yes/No/Maybe + rationale) -> Document-level Probability (Noisy-OR)

- **Critical path:** The definition of the **Exclusion Criteria** vectors. If these are poorly defined, the contrastive scoring fails, and the fuzzy controller receives noisy inputs that it cannot correct.

- **Design tradeoffs:**
  - **Recall vs. Precision:** The system is tuned for high recall (all-positive gold set), potentially accepting lower precision.
  - **Cost vs. Explainability:** Using an LLM for every highlighted chunk increases cost and latency but provides the auditable rationale required for systematic reviews.

- **Failure signatures:**
  - **Generic Highlighting:** System highlights entire pages; likely the contrastive margin is too small or exclusion criteria are missing.
  - **Uniform "Maybe" Scores:** Fuzzy membership functions may be too wide, failing to discriminate between strong and weak signals.
  - **LLM Rejection:** LLM consistently returns "NO" on valid chunks; check if the prompt includes necessary protocol context.

- **First 3 experiments:**
  1. **Calibrate the Contrastive Gap:** Run the pipeline on 5 known-positive documents with and without exclusion criteria to measure the delta in false positive rates.
  2. **Fuzzy Surface Visualization:** Plot the 3D surface of the Mamdani controller (Score vs. Margin $\to$ Inclusion Degree) to ensure the "Accept" region aligns with intuitive logic.
  3. **Attenuation Ablation:** Compare "Hard Exclude" vs. "Attenuate" modes on a set of borderline documents to verify that attenuation preserves true positives that would otherwise be lost.

## Open Questions the Paper Calls Out
- **Question:** How does the pipeline perform on mixed-label datasets regarding specificity and precision-recall trade-offs?
  - **Basis in paper:** [explicit] Section 4.6 lists evaluating on "larger, mixed-label corpora" to report specificity, ROC/PR AUCs, and calibration as a primary future work item.
  - **Why unresolved:** The current evaluation relied on an all-positive gold set (N=16), making specificity and threshold-free discrimination metrics undefined.
  - **What evidence would resolve it:** Evaluation results on a benchmark containing both included and excluded full-text articles.

- **Question:** To what extent can the fuzzy system generalize to different domains or LLM back-ends without manual re-tuning?
  - **Basis in paper:** [explicit] Section 4.6 explicitly calls for assessing "portability across domains and LLM back-ends" and Section 4.5 warns of "domain shift" risks.
  - **Why unresolved:** The proof-of-concept focused specifically on the POPCORN NCD context and a specific GPT model version.
  - **What evidence would resolve it:** Performance metrics (recall/specificity) when applying the pipeline to non-NCD corpora or alternative open-source LLMs.

- **Question:** What is the marginal contribution of the fuzzy inference layer versus the LLM adjudication to the overall accuracy?
  - **Basis in paper:** [explicit] Section 4.6 lists "perform ablations of highlighting, margin, and fuzzy rules" as necessary future work.
  - **Why unresolved:** The study evaluated the integrated pipeline without isolating the specific impact of the fuzzy controller versus the LLM judge.
  - **What evidence would resolve it:** Ablation studies comparing the full system against versions with the fuzzy layer removed or simplified.

## Limitations
- Evaluation on a small all-positive gold set (16 articles) prevents estimation of precision and may inflate recall metrics
- Missing specification of inclusion/exclusion criterion text, ground-truth labels, and exact membership function parameters blocks faithful reproduction
- No precision-recall curves or F1 scores provided to assess precision-recall trade-offs

## Confidence
- **Contrastive Subtraction:** High confidence due to explicit formula specification and ablation-like discussion, but weak corpus validation
- **Mamdani Fuzzy Inference:** Medium confidence; rule structure specified but parameters and membership functions not fully reported
- **LLM Attenuation:** Medium confidence; novel but relies on unstated LLM reliability assumptions that could attenuate true positives
- **Precision Assessment:** Low confidence due to evaluation only on all-positive dataset preventing precision estimation

## Next Checks
1. Measure precision alongside recall on a balanced (positive/negative) dataset to assess trade-offs
2. Perform ablation: run the pipeline with and without the exclusion subtraction to quantify false positive reduction
3. Visualize the Mamdani rule surface to verify that "Accept" regions align with intuitive high-score/low-ambiguity cases