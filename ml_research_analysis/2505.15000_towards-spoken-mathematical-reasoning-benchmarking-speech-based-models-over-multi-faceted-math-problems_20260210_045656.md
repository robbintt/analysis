---
ver: rpa2
title: 'Towards Spoken Mathematical Reasoning: Benchmarking Speech-based Models over
  Multi-faceted Math Problems'
arxiv_id: '2505.15000'
source_url: https://arxiv.org/abs/2505.15000
tags:
- reasoning
- speech
- arxiv
- mathematical
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Spoken-MQA, a benchmark designed to evaluate
  mathematical reasoning from spoken input using both cascade models (ASR + LLMs)
  and end-to-end speech LLMs. The benchmark covers diverse math problem types including
  arithmetic, contextual reasoning, and knowledge-oriented reasoning, all presented
  in unambiguous natural spoken language.
---

# Towards Spoken Mathematical Reasoning: Benchmarking Speech-based Models over Multi-faceted Math Problems

## Quick Facts
- **arXiv ID:** 2505.15000
- **Source URL:** https://arxiv.org/abs/2505.15000
- **Reference count:** 23
- **Primary result:** Introduces Spoken-MQA benchmark evaluating mathematical reasoning from spoken input using cascade models (ASR + LLMs) and end-to-end speech LLMs

## Executive Summary
This paper introduces Spoken-MQA, a benchmark designed to evaluate mathematical reasoning from spoken input using both cascade models (ASR + LLMs) and end-to-end speech LLMs. The benchmark covers diverse math problem types including arithmetic, contextual reasoning, and knowledge-oriented reasoning, all presented in unambiguous natural spoken language. Through extensive experiments, the study finds that while some speech LLMs perform competitively on contextual reasoning tasks involving basic arithmetic, they still struggle with direct arithmetic problems, suggesting a lack of genuine mathematical understanding.

## Method Summary
The Spoken-MQA benchmark was constructed by verbalizing existing MATH dataset problems using TTS (Coqui TTS for most subsets, human recordings for Arithmetic). The verbalization process included ambiguity filtering, removing problems where verbal descriptions could be interpreted multiple ways. The benchmark was evaluated using both cascade approaches (Whisper ASR + text LLM) and end-to-end speech LLMs, with additional experiments on domain-specific fine-tuning using 500k math-domain speech samples.

## Key Results
- Current LLMs exhibit strong bias toward symbolic mathematical expressions written in LaTeX and have difficulty interpreting verbalized mathematical expressions
- Mathematical knowledge reasoning abilities are significantly degraded in current speech LLMs
- Domain-specific fine-tuning improves performance on arithmetic and knowledge reasoning tasks
- Speech LLMs struggle with direct arithmetic problems despite competitive performance on contextual reasoning tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Cascade models (ASR + LLM) currently outperform end-to-end speech LLMs on mathematical reasoning because they preserve access to text-optimized reasoning capabilities.
- **Mechanism:** ASR transcribes speech → text, which is then processed by LLMs trained extensively on symbolic mathematical content. This bypasses the degraded reasoning observed in speech LLMs whose training pipelines emphasize general conversational understanding over domain-specific reasoning.
- **Core assumption:** The performance gap stems from training emphasis, not architectural limitations intrinsic to end-to-end approaches.
- **Evidence anchors:**
  - [abstract] "mathematical knowledge reasoning abilities are significantly degraded in current speech LLMs"
  - [section 4.2] "state-of-the-art open-source speech LLMs underperform compared to cascade models"
  - [corpus] Limited direct corpus support; related work (VoxEval) confirms knowledge degradation in SLMs but doesn't isolate causal factors.
- **Break condition:** If speech LLMs receive equivalent domain-specific training data and still underperform, the mechanism shifts toward architectural or cross-modal alignment limitations.

### Mechanism 2
- **Claim:** LLMs exhibit a strong bias toward symbolic mathematical expressions (LaTeX) and struggle with verbalized equivalents, reducing effectiveness on spoken math problems.
- **Mechanism:** Text-based LLMs are trained on corpora where math appears symbolically; when identical content is verbalized (e.g., "x squared plus y squared equals one" vs. "x² + y² = 1"), the model lacks robust mappings from natural language descriptions to internal symbolic representations.
- **Core assumption:** The performance gap between ground-truth text and verbalized text reflects training data distribution, not fundamental reasoning inability.
- **Evidence anchors:**
  - [abstract] "current LLMs exhibit a strong bias toward symbolic mathematical expressions written in LaTeX and have difficulty interpreting verbalized mathematical expressions"
  - [section 4.2.2] "verbalized text...consistently yields lower accuracy compared to ground-truth text inputs"
  - [corpus] MATH-Perturb (arXiv:2502.06453) shows LLMs sensitive to problem formulation, supporting input-format dependency.
- **Break condition:** If specialized verbalization-aware training fails to close the gap, symbolic bias may be deeply structural in transformer attention patterns.

### Mechanism 3
- **Claim:** Domain-specific fine-tuning on spoken math data improves arithmetic and knowledge-oriented reasoning performance.
- **Mechanism:** Fine-tuning on 500k math-domain speech samples (filtered for low ambiguity) creates better alignment between speech embeddings and mathematical reasoning pathways in the LLM backbone.
- **Core assumption:** Improvements generalize beyond the training distribution; performance gains aren't solely memorization.
- **Evidence anchors:**
  - [abstract] "Domain-specific fine-tuning improves performance on arithmetic and knowledge reasoning tasks"
  - [section 4.2.3] "FT-Phi-4-multimodal-instruct...shows substantial performance gains in the Arithmetic and Knowledge-oriented Reasoning categories"
  - [corpus] No direct corpus confirmation; neighboring papers don't address domain-specific speech fine-tuning for math.
- **Break condition:** If gains plateau with more data or fail to transfer to out-of-distribution problem types, mechanism may involve shallow pattern matching rather than improved reasoning.

## Foundational Learning

- **Concept: Cascade vs. End-to-End Architectures**
  - **Why needed here:** Understanding error propagation in cascade models (ASR errors compound) vs. information loss in end-to-end models (speech encoder limitations) is essential for interpreting benchmark results.
  - **Quick check question:** Given a math problem with the expression "nine factorial," would a cascade model using Whisper + LLM handle this better than an end-to-end speech LLM? Why or why not?

- **Concept: Verbalization Ambiguity in Mathematical Expressions**
  - **Why needed here:** The paper identifies that 32% of sampled MATH problems become ambiguous when verbalized (e.g., "magnitude of z minus w" could mean |z−w| or |z|−w). Understanding this helps design better TTS pipelines and filtering criteria.
  - **Quick check question:** Verbalize "(a + b)²" and "a² + 2ab + b²" — would they sound identical? What ambiguity does this create?

- **Concept: Cross-Modal Alignment in Speech LLMs**
  - **Why needed here:** Speech LLMs use a projection module to map speech encoder outputs to LLM embedding space. Weak alignment degrades reasoning transfer from the text backbone.
  - **Quick check question:** If a speech encoder perfectly transcribes numbers but the projection module distorts positional embeddings, how might this affect multi-step arithmetic accuracy?

## Architecture Onboarding

- **Component map:**
  - Audio input → Speech encoder → (Projection) → LLM backbone → CoT reasoning → Answer extraction
  - For cascade: Audio → ASR → Transcript → LLM → Answer (ASR errors propagate; verbalization issues persist)

- **Critical path:**
  1. Audio input → Speech encoder → (Projection) → LLM backbone → CoT reasoning → Answer extraction
  2. For cascade: Audio → ASR → Transcript → LLM → Answer (ASR errors propagate; verbalization issues persist)

- **Design tradeoffs:**
  - **Cascade:** Stronger reasoning via text-optimized LLMs; error propagation from ASR; poor handling of verbalized math symbols.
  - **End-to-end:** Richer paralinguistic cues retained; currently weaker reasoning; requires domain-specific fine-tuning.
  - **Verbalization filtering:** Removes ambiguous problems but may underestimate real-world performance on natural speech.

- **Failure signatures:**
  - Low accuracy on Arithmetic despite high Contextual Reasoning scores → suggests pattern matching, not genuine computation.
  - Large gap between ground-truth text and verbalized text inputs → symbolic bias in LLM.
  - Multi-step reasoning collapse in speech LLMs → weak cross-modal alignment or insufficient training on step-by-step reasoning.

- **First 3 experiments:**
  1. **Baseline cascade vs. end-to-end comparison:** Run Whisper + Qwen2.5-Math-7B against Qwen2-Audio-7B-Instruct on all Spoken-MQA categories; isolate where end-to-end fails most (hypothesis: Arithmetic and Knowledge-oriented).
  2. **Input format ablation:** Feed ground-truth text, ASR transcripts, and verbalized text to the same LLM backbone; quantify symbolic bias magnitude (expected: verbalized << ground-truth for Knowledge-oriented).
  3. **Domain fine-tuning pilot:** Fine-tune a small speech LLM (e.g., Phi-4-Multimodal-6B) on 50k filtered spoken math samples; measure gains on Arithmetic vs. Contextual Reasoning to validate transfer (hypothesis: larger gains on Arithmetic).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Do speech LLMs that perform competitively on contextual reasoning tasks genuinely comprehend arithmetic operations, or do they merely exploit superficial pattern matching?
- **Basis in paper:** [explicit] Section 4.2.1 states: "Investigating whether these models genuinely comprehend the logic behind arithmetic operations or merely exploit shallow correlations remains an open direction for future research."
- **Why unresolved:** Models like Ultravox and Phi-4 achieve strong contextual reasoning scores but struggle on direct arithmetic—even short-digit problems—suggesting possible reliance on surface-level cues. No probing experiments were conducted to distinguish genuine understanding from pattern matching.
- **What evidence would resolve it:** Controlled experiments isolating arithmetic from contextual cues, or probing methods testing whether models internalize arithmetic principles versus statistical patterns.

### Open Question 2
- **Question:** How can the strong symbolic bias of LLMs toward LaTeX mathematical expressions be mitigated to improve performance on verbalized math problems?
- **Basis in paper:** [explicit] Section 4.2.2 concludes: "This highlights the need for further research to reduce the symbolic bias of LLMs and enhance the model for more robust natural spoken language understanding."
- **Why unresolved:** Table 3 shows consistent accuracy drops when using verbalized text versus LaTeX ground truth, but no interventions (e.g., verbalized pretraining, mixed-format curricula) were tested.
- **What evidence would resolve it:** Experiments with training strategies specifically targeting verbalized math understanding, demonstrating reduced gaps between symbolic and verbalized input performance.

### Open Question 3
- **Question:** How does model performance on spoken mathematical reasoning differ between TTS-generated and naturally human-spoken audio?
- **Basis in paper:** [explicit] The Limitations section states: "Future work is needed for more human-spoken data across all subsets to better reflect authentic speech patterns and to ensure a more realistic and comprehensive evaluation."
- **Why unresolved:** Only the Arithmetic subset uses human recordings; Contextual and Knowledge-Oriented subsets rely on Coqui TTS, which "lacks the natural variability and imperfections found in human speech," potentially biasing evaluations.
- **What evidence would resolve it:** Comparative benchmarking on matched TTS versus human-spoken problem sets across all categories.

### Open Question 4
- **Question:** What architectural or training improvements can close the performance gap between end-to-end speech LLMs and cascade models on mathematical reasoning?
- **Basis in paper:** [inferred] Table 2 shows cascade models generally outperform end-to-end speech LLMs, especially in arithmetic and knowledge-oriented tasks. The paper notes that speech LLMs are typically not optimized for domain-specific reasoning, and domain fine-tuning only partially addresses the gap.
- **Why unresolved:** While fine-tuning (FT-Phi-4) improves performance, the specific architectural choices or training pipelines that could fully bridge this gap remain unidentified.
- **What evidence would resolve it:** Ablation studies comparing speech encoder designs, projection modules, and pretraining objectives targeted at preserving mathematical reasoning capabilities from text LLMs.

## Limitations
- Benchmark relies on verbalized versions of existing text math problems rather than native spoken math data, potentially creating artificial evaluation scenarios
- Verbalization ambiguity filtering removed 32% of problems, raising questions about benchmark representativeness
- Cross-model comparison consistency issues due to different ASR systems and proprietary encoders used across approaches

## Confidence
- **High confidence:** The observation that speech LLMs underperform cascade models on mathematical reasoning tasks is well-supported by direct experimental comparisons
- **Medium confidence:** The claim about LLMs' bias toward symbolic mathematical expressions (LaTeX) is supported by input format ablation experiments
- **Low confidence:** The assertion that performance gaps stem primarily from training emphasis rather than architectural limitations requires further validation

## Next Checks
1. **Native spoken math corpus collection:** Record 500+ mathematical problems using diverse speakers, natural speech patterns, and domain-specific vocabulary; re-run the benchmark to determine whether performance gaps persist with authentic spoken input versus TTS-generated audio

2. **Controlled architectural ablation:** Implement an end-to-end speech LLM with identical LLM backbone and training data as the cascade system, varying only the speech encoder and projection module; this isolates whether performance differences stem from cross-modal alignment quality versus text backbone reasoning capabilities

3. **Long-context reasoning stress test:** Design multi-step mathematical problems requiring intermediate reasoning and evaluate how well speech LLMs maintain coherence across reasoning steps compared to text-based LLMs; this tests whether performance degradation is due to reasoning depth limitations or input format processing