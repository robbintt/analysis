---
ver: rpa2
title: Controlling Difficulty of Generated Text for AI-Assisted Language Learning
arxiv_id: '2506.04072'
source_url: https://arxiv.org/abs/2506.04072
tags:
- level
- language
- jlpt
- user
- difficulty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of adapting large language models
  (LLMs) for beginner-level language learners, whose conversational abilities are
  often overwhelmed by the near-native complexity of typical LLM outputs. The authors
  explore modular, controllable generation techniques that do not require model fine-tuning,
  specifically using future discriminators (FUDGE) to bias model outputs toward simpler
  language.
---

# Controlling Difficulty of Generated Text for AI-Assisted Language Learning

## Quick Facts
- arXiv ID: 2506.04072
- Source URL: https://arxiv.org/abs/2506.04072
- Reference count: 40
- Primary result: FUDGE technique improves output comprehensibility for beginner Japanese learners from 40.4% to 84.3% without model fine-tuning

## Executive Summary
This paper addresses the challenge of adapting large language models for beginner-level language learners by developing modular, controllable generation techniques that don't require model fine-tuning. The authors introduce FUDGE (Future Discriminators for Guide), which uses logit interpolation to bias LLM outputs toward simpler language. In a user study with beginner Japanese learners, FUDGE significantly improved output comprehensibility and maintained fluency. The paper also introduces Token Miss Rate (TMR), a new automatic metric that correlates strongly with human judgments of understandability and enables fine-grained debugging of generation difficulty.

## Method Summary
The authors employ Future Discriminators (FUDGE) to control text difficulty by interpolating logits from a difficulty predictor with base LLM logits during decoding. A ModernBERT-base predictor is fine-tuned on all prefix-attribute pairs from the jpWaC-L corpus, learning to estimate future difficulty from partial sequences. At each generation step, the predictor estimates P(attribute|prefix) for top-k candidates, and logits are combined as ŷ = λa + (1-λ)x where λ controls difficulty strength. The system uses Qwen2.5-72B-Instruct as the base LLM, with top-k=50 sampling and λ values ranging from 0.25 to 0.9. Evaluation includes TMR (tokens above learner level / total tokens), perplexity, trigram diversity, and human comprehensibility ratings.

## Key Results
- FUDGE achieves 11.9% TMR at λ=0.9, equivalent to roughly 88% token comprehension rate
- Human comprehensibility improves from 40.4% to 84.3% when using FUDGE compared to baseline
- TMR correlates strongly with human comprehensibility ratings (ρ = 0.78)
- FUDGE consistently outperforms other methods across all difficulty levels
- Fluency remains high with λ ≤ 0.8, with degradation beginning around λ = 0.9

## Why This Works (Mechanism)

### Mechanism 1: Future Discriminator Logit Interpolation
Interpolating logits from a difficulty predictor with base LLM logits enables real-time difficulty control during decoding. At each generation step, the predictor estimates P(attribute|prefix) for candidate tokens, and combined logits balance predictor influence (λ) against base model fluency (1-λ). Higher λ values yield stronger difficulty control while maintaining fluency up to a degradation threshold. The approach assumes the predictor trained on prefix-attribute pairs generalizes to estimate future difficulty from partial sequences during inference.

### Mechanism 2: Prefix-Based Difficulty Prediction Training
Training a classifier on all prefix-attribute pairs enables prediction of eventual difficulty from partial context. The predictor is fine-tuned on all (prefix, attribute) pairs from the corpus, using multi-class cross-entropy loss to learn difficulty likelihoods across levels. This differs from standard sequence classification because it must predict from incomplete sequences. The approach assumes difficulty signals are detectable early in utterance generation through vocabulary choice and grammatical structures that appear incrementally.

### Mechanism 3: Token Miss Rate as Granular Comprehensibility Proxy
TMR provides token-level difficulty assessment that correlates with human judgments and enables fine-grained debugging. TMR = cnt_above / total_tokens, where cnt_above counts tokens above learner's level. Sudachi tokenizer produces base-form tokens mapped to JLPT levels via vocabulary lookup. This enables identifying specific vocabulary gaps rather than binary comprehensible/incomprehensible judgments. The approach assumes vocabulary level is the primary driver of comprehensibility for beginners, with grammatical complexity being secondary.

## Foundational Learning

- **Controllable Text Generation (CTG)**: Understanding P(X|a) vs. P(X) is prerequisite for grasping why prompting alone fails and why logit manipulation works. Quick check: Can you explain why adding "speak simply" to a prompt doesn't guarantee simple output at the token-generation level?

- **Logits, Sampling, and Top-k Truncation**: The mechanism operates by modifying logit vectors before sampling; understanding this pipeline is essential for debugging λ values and fluency tradeoffs. Quick check: If you increase λ from 0.5 to 0.9, what happens to the influence of the base LLM vs. the predictor?

- **Japanese Tokenization and JLPT Levels**: TMR calculation requires mapping tokens to difficulty levels; Sudachi's coarse-grained mode and lemmatization affect what gets counted as "above level." Quick check: Why might a verb in dictionary form be mapped to a different JLPT level than the same verb in conjugated form?

## Architecture Onboarding

- **Component map**: User input → Whisper transcription → LLM context → Qwen2.5-72B-softmax logits → FUDGE LogitsProcessor (ModernBERT predictor on top-k=50) → ŷ = λa + (1-λ)x interpolation → Sampling → TTS output; parallel TMR calculation via Sudachi tokenizer

- **Critical path**: 1) User input transcribed by Whisper, 2) LLM generates candidate logits, 3) LogitsProcessor runs predictor on top-50 candidates, 4) Logits interpolated with λ parameter, 5) Sample from modified distribution, 6) Output to TTS, 7) TMR calculated for evaluation

- **Design tradeoffs**: λ selection balances difficulty control vs. fluency risk (0.8 optimal for human study); top-k=50 balances coverage vs. compute; ModernBERT-base chosen for speed over larger models; vocabulary-based difficulty faster than readability scores but may miss grammatical complexity

- **Failure signatures**: High TMR despite high λ suggests predictor calibration issues; fluent but off-topic outputs indicate base model dominance; repeated/simple outputs suggest predictor over-constraint; undetected tokens inflating comprehension suggest incomplete vocabulary bins

- **First 3 experiments**: 1) λ sweep with fluency guardrails (track TMR, perplexity, trigram diversity), 2) Per-level predictor validation (measure accuracy on held-out prefixes at different lengths), 3) A/B test with 10-15 beginner learners (deploy FUDGE vs. baseline prompt)

## Open Questions the Paper Calls Out

1. How can difficulty control be maintained consistently over extended multi-turn conversations? The study only evaluated 6-turn conversations, but future work should seek to understand how metrics change over time and ensure consistency in difficulty control over long conversations.

2. Do modular controllable generation techniques generalize to languages beyond Japanese? The entire study focuses exclusively on Japanese, leaving unclear whether the FUDGE approach and TMR metric transfer to morphologically different languages.

3. What is the optimal tradeoff between control strength (λ) and fluency degradation? The authors note fluency degradation begins above λ=0.9 and selected λ=0.8 for the human study, but did not systematically characterize this tradeoff.

4. Can personal on-device predictor models effectively adapt to individual learner proficiency profiles? The study used a single predictor trained on corpus data, but proposed personalized predictors for each student's proficiency level without implementation or testing.

## Limitations

- The approach depends critically on accurate vocabulary-level difficulty annotation and may miss grammatical complexity, idiomatic expressions, and multi-word constructions
- TMR treats unmapped tokens as comprehensible by default, which could inflate scores if vocabulary bins are incomplete
- The human study sample (10-15 learners) is small, limiting generalizability of the dramatic 40.4% to 84.3% improvement
- The method assumes difficulty is primarily vocabulary-driven, which may break down at intermediate levels where grammar and discourse complexity dominate

## Confidence

- **High confidence** in the core technical mechanism: FUDGE's logit interpolation approach is well-established and the 11.9% TMR at λ=0.9 is directly measured
- **Medium confidence** in human study results: Significant improvement but small sample size (10-15 learners) and single study design limit generalizability
- **Medium confidence** in TMR metric: Strong correlation with human judgments (ρ=0.78) but only captures vocabulary difficulty and may miss grammatical incomprehensibility

## Next Checks

1. **Predictor calibration and prefix informativeness**: Hold out 20% of jpWaC-L per JLPT level and measure predictor accuracy on prefix classification at different prefix lengths (25%, 50%, 75%, 100%) to validate prefix-based prediction viability.

2. **Vocabulary bin completeness audit**: Take 1,000 random tokens from jpWaC-L not covered by current bins, manually annotate their JLPT levels, and compute what fraction would be incorrectly treated as "comprehensible" by TMR.

3. **Cross-linguistic generalizability test**: Apply the exact FUDGE pipeline to a different language with established proficiency levels (e.g., Spanish with CEFR levels using DELE corpus) to test whether results replicate without language-specific tuning.