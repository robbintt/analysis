---
ver: rpa2
title: 'sui-1: Grounded and Verifiable Long-Form Summarization'
arxiv_id: '2601.08472'
source_url: https://arxiv.org/abs/2601.08472
tags:
- training
- arxiv
- sui-1
- source
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents sui-1, a 24B parameter model trained for citation-grounded
  summarization. The key innovation is a synthetic data generation pipeline that combines
  chain-of-thought prompting with multi-stage verification to create over 22,000 training
  examples across five languages.
---

# sui-1: Grounded and Verifiable Long-Form Summarization
## Quick Facts
- arXiv ID: 2601.08472
- Source URL: https://arxiv.org/abs/2601.08472
- Reference count: 17
- sui-1 achieves 84.2% overall accuracy, significantly outperforming open-weight baselines

## Executive Summary
sui-1 is a 24B parameter model specifically trained for citation-grounded summarization, addressing the critical need for verifiable long-form content generation. The model introduces a novel synthetic data generation pipeline that combines chain-of-thought prompting with multi-stage verification to create over 22,000 training examples across five languages. This approach enables sui-1 to produce abstractive summaries with inline XML citations, allowing users to trace each claim back to its source sentence. The model demonstrates substantial improvements in format compliance (89.5% vs 13.7-41.1% in baselines) and achieves 84.2% overall accuracy on LLM-as-a-judge evaluation, outperforming larger models with 3× more parameters.

## Method Summary
sui-1 employs a synthetic data generation pipeline that creates training examples through chain-of-thought prompting and multi-stage verification. The process generates over 22,000 examples across five languages, focusing on citation-grounded summarization tasks. The model uses inline XML citations to enable claim traceability, and FP8 quantization reduces memory usage by 50% with only 3.7% performance degradation. The training approach specifically targets format compliance and citation accuracy, demonstrating that task-specific training can substantially outperform simply scaling model size.

## Key Results
- Achieves 84.2% overall accuracy on LLM-as-a-judge evaluation, significantly outperforming all open-weight baselines
- Improves format compliance from 13.7-41.1% in baselines to 89.5% in sui-1
- Outperforms models with 3× more parameters (42.7-56.6%) on citation-grounded summarization tasks

## Why This Works (Mechanism)
sui-1's effectiveness stems from its task-specific training approach that combines synthetic data generation with rigorous verification. The chain-of-thought prompting enables the model to reason through the summarization process step-by-step, while multi-stage verification ensures high-quality training examples. This targeted approach addresses the specific challenges of citation-grounded summarization, including format compliance and claim traceability. The inline XML citation system provides a structured way to link summary claims to source sentences, making the summarization process verifiable and transparent.

## Foundational Learning
- Chain-of-thought prompting: Enables step-by-step reasoning for complex summarization tasks
  - Why needed: Allows the model to break down summarization into manageable reasoning steps
  - Quick check: Verify that intermediate reasoning steps lead to coherent final summaries

- Multi-stage verification: Ensures high-quality synthetic training data through iterative validation
  - Why needed: Prevents propagation of errors from synthetic data into model behavior
  - Quick check: Measure consistency between generated examples and verification criteria

- Citation-grounded summarization: Links summary claims to specific source sentences
  - Why needed: Enables verification of factual claims and improves trustworthiness
  - Quick check: Confirm that each citation correctly maps to the referenced claim

- FP8 quantization: Reduces memory footprint while maintaining performance
  - Why needed: Makes the 24B model more practical for deployment
  - Quick check: Verify memory reduction matches expected 50% reduction

## Architecture Onboarding
Component map: Synthetic Data Generation -> Model Training -> Citation System -> FP8 Quantization
Critical path: Training data quality → Model fine-tuning → Format compliance → Performance optimization
Design tradeoffs: Task-specific training vs. general-purpose scaling, citation complexity vs. summary coherence
Failure signatures: Incorrect citations, format violations, memory overflow in quantized version
First experiments: 1) Test synthetic data generation pipeline output quality, 2) Verify citation mapping accuracy, 3) Measure FP8 quantization impact on memory and performance

## Open Questions the Paper Calls Out
The paper highlights several uncertainties regarding the generalizability of its synthetic data generation approach, particularly for morphologically rich or low-resource languages beyond the five tested. The evaluation framework's heavy reliance on LLM-as-a-judge metrics raises questions about potential evaluator bias and the need for comprehensive human evaluation across diverse domains. Additionally, the model's performance on real-world, noisy data from sources outside curated training sets remains untested, especially for domains like scientific literature or legal documents where citation practices differ significantly from news articles.

## Limitations
- Uncertain generalizability to morphologically rich and low-resource languages beyond the five tested
- Heavy reliance on LLM-as-a-judge evaluation may introduce evaluator bias
- Untested performance on real-world noisy data and non-news document types

## Confidence
High: Synthetic data generation pipeline successfully improves format compliance and citation accuracy; FP8 quantization results are reliable under controlled conditions
Medium: Overall accuracy metric of 84.2% is robust within the evaluation framework, though LLM-based evaluation introduces uncertainty about absolute performance
Low: Claims about superiority across all long-form summarization scenarios, particularly in untested domains and languages

## Next Checks
1. Conduct human evaluation studies with domain experts to assess factual accuracy and citation quality across multiple document types beyond news articles
2. Test the model's performance on documents in morphologically rich and low-resource languages not included in the original training set
3. Evaluate the model's behavior on real-world, noisy data from web sources and social media to assess robustness against non-curated input