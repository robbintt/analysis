---
ver: rpa2
title: 'Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion Model'
arxiv_id: '2504.01521'
source_url: https://arxiv.org/abs/2504.01521
tags:
- domain
- guidance
- pre-trained
- diffusion
- transfer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Domain Guidance (DoG), a novel transfer learning
  approach for diffusion models that leverages pre-trained knowledge to improve generation
  quality in target domains. DoG treats transfer as conditional generation, using
  the pre-trained model as an unconditional guide to direct the fine-tuned model toward
  the target domain, similar to classifier-free guidance.
---

# Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion Model

## Quick Facts
- arXiv ID: 2504.01521
- Source URL: https://arxiv.org/abs/2504.01521
- Authors: Jincheng Zhong; Xiangcheng Zhang; Jianmin Wang; Mingsheng Long
- Reference count: 17
- Primary result: DoG achieves 19.6% improvement in FID and 23.4% improvement in FDDINOv2 compared to standard fine-tuning with CFG

## Executive Summary
Domain Guidance (DoG) is a transfer learning approach for diffusion models that treats transfer as conditional generation, using a pre-trained model as an unconditional guide to direct the fine-tuned model toward the target domain. By leveraging the pre-trained model's robust marginal distribution, DoG improves domain alignment and reduces out-of-distribution errors during sampling. The method requires minimal modifications to existing fine-tuned models and demonstrates significant improvements across seven fine-grained benchmarks.

## Method Summary
DoG fine-tunes a pre-trained DiT-XL/2-256x256 model on target datasets for 24K steps (batch=32, lr=1e-4, Adam) without requiring dropout for unconditional training. At inference, it applies the DoG formula: ε_DoG(x|c) = ε_finetuned(x|c) + (w-1)(ε_finetuned(x|c) - ε_pretrained(x)), with w=1.5 and 50 DDPM steps. This requires two forward passes per step using both fine-tuned and original pre-trained weights. The approach improves FID and FDDINOv2 scores by 19.6% and 23.4% respectively compared to standard fine-tuning with CFG.

## Key Results
- 19.6% improvement in FID scores across seven fine-grained benchmarks
- 23.4% improvement in FDDINOv2 scores compared to standard fine-tuning with CFG
- Seamless integration with existing fine-tuned models without additional training
- Optimal guidance scale w found to be in the 1.4-2.0 range

## Why This Works (Mechanism)

### Mechanism 1: Implicit Domain Classification via Score Difference
The paper demonstrates mathematically that DoG's score update is equivalent to standard CFG plus an implicit classifier term: (w-1)∇_{x_t} log p(D_{tgt}|x_t). By subtracting the pre-trained score from the fine-tuned score, the update direction isolates the likelihood of belonging to the target domain, steering generation away from OOD areas.

### Mechanism 2: Mitigation of Unconditional Branch Underfitting
Standard CFG requires training both conditional and unconditional branches on target data. In low-data regimes, the unconditional branch overfits or fails to capture the broad support needed for effective guidance. DoG replaces this weak unconditional branch with the frozen, robust pre-trained model.

### Mechanism 3: Knowledge Retention via Static Reference
Freezing the pre-trained model prevents catastrophic forgetting of structural knowledge from massive datasets. This allows the model to generate target domain concepts using high-quality feature representations from the source model rather than distorting features to fit small target datasets.

## Foundational Learning

- **Score-Based Generative Modeling (Diffusion)**: Essential for understanding how DoG manipulates the score (gradient of log-density) to modify generation trajectories. Quick check: How does the noise prediction ε_θ(x_t, t) mathematically relate to the score function ∇_{x_t} log p(x_t)?

- **Classifier-Free Guidance (CFG)**: DoG adopts the exact CFG formulation (ε_{cond} + w(ε_{cond} - ε_{uncond})). Quick check: In standard CFG, why do we typically train a single network with dropout to serve as both conditional and unconditional model?

- **Distribution Shift & OOD**: The paper frames transfer learning as a distribution shift problem, with OOD samples as the core failure mode. Quick check: Why might a model fine-tuned on a small dataset generate images that look like the target class but possess unrealistic artifacts or backgrounds?

## Architecture Onboarding

- **Component map**: Pre-trained Backbone (θ₀) -> Fine-tuned Backbone (θ) -> DoG Scheduler -> Generated Image

- **Critical path**:
  1. Load Pre-trained checkpoint (θ₀)
  2. Duplicate and Fine-tune (θ) on target dataset
  3. At inference step t: Input noise x_t and class/prompt c
  4. Compute conditional output ε_θ(x_t, c)
  5. Compute unconditional output ε_θ₀(x_t)
  6. Apply DoG formula with guidance scale w (e.g., 1.5)

- **Design tradeoffs**: Requires holding two sets of weights in memory during inference (memory vs. quality). Optimal guidance strength (w) is between 1.4-2.0.

- **Failure signatures**: Mode collapse/ghosts when target domain is vastly different from pre-trained domain; image "burning" with excessive guidance scale (w > 2.5).

- **First 3 experiments**:
  1. Replicate the 2D toy mixture of Gaussians experiment to visualize score field direction change between CFG and DoG
  2. Fine-tune DiT on ImageNet subset ("Dogs") and measure FID while sweeping w from 1.0 to 2.5
  3. Apply DoG to existing fine-tuned Stable Diffusion LoRA using base SD model as guide, comparing CLIP score against standard CFG

## Open Questions the Paper Calls Out

### Open Question 1
Can a single general large-scale pre-trained model function as a unified guiding model to improve transfer performance across arbitrary downstream tasks? The paper suggests future work could study this, as current experiments use the specific source checkpoint from which the target model was fine-tuned.

### Open Question 2
How can Domain Guidance be extended to support compositional guiding in transfer learning scenarios? The current formulation uses a single pre-trained domain reference and doesn't address mechanisms for combining multiple concepts or styles dynamically.

### Open Question 3
What are the failure modes of Domain Guidance when the semantic gap between pre-trained source and target domain is extreme? If the target domain is entirely disjoint from the source, pre-trained gradients may actively mislead the sampling process rather than regularizing it.

## Limitations
- Theoretical claims about DoG's equivalence to CFG with implicit classifier rely on assumptions that may not hold for highly divergent domains
- Empirical validation limited to relatively similar image domains (fine-grained classification tasks)
- Memory overhead of loading two full models during inference not thoroughly evaluated
- Claims about seamless integration with existing models lack quantitative validation across diverse checkpoints

## Confidence

- **High confidence**: Mathematical formulation of DoG and its relationship to classifier-free guidance
- **Medium confidence**: Empirical improvements in FID and FDDINOv2 across seven benchmarks
- **Medium confidence**: Theoretical explanation for why DoG outperforms standard fine-tuning
- **Low confidence**: Claims about catastrophic forgetting in standard fine-tuning and universal applicability across all domain transfer scenarios

## Next Checks
1. Test DoG performance on completely unrelated domain pairs (e.g., ImageNet → medical imaging) to evaluate robustness when domains have minimal overlap
2. Measure actual memory footprint during inference with DoG versus standard CFG across different model scales
3. Conduct ablation study examining sensitivity of DoG performance to guidance scale (w) across multiple ranges and domain types