---
ver: rpa2
title: 'OFFSIDE: Benchmarking Unlearning Misinformation in Multimodal Large Language
  Models'
arxiv_id: '2510.22535'
source_url: https://arxiv.org/abs/2510.22535
tags:
- unlearning
- rumors
- visual
- methods
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: OFFSIDE is a novel benchmark for evaluating misinformation unlearning
  in multimodal large language models, focusing on football transfer rumors. It provides
  a manually curated dataset of 15.68K records for 80 players, featuring four distinct
  test sets to assess forgetting efficacy, generalization, utility, and robustness.
---

# OFFSIDE: Benchmarking Unlearning Misinformation in Multimodal Large Language Models

## Quick Facts
- arXiv ID: 2510.22535
- Source URL: https://arxiv.org/abs/2510.22535
- Reference count: 40
- Primary result: Novel benchmark exposing vulnerabilities in multimodal misinformation unlearning

## Executive Summary
OFFSIDE is a comprehensive benchmark designed to evaluate misinformation unlearning in multimodal large language models, with a specific focus on football transfer rumors. The benchmark provides a manually curated dataset of 15.68K records covering 80 players and includes four distinct test sets to assess various aspects of unlearning effectiveness, including forgetting efficacy, generalization, utility preservation, and robustness against attacks. The evaluation reveals significant challenges in current multimodal unlearning approaches, particularly their inability to handle visual rumors embedded in images and their vulnerability to prompt attacks that can recover unlearned misinformation.

## Method Summary
The OFFSIDE benchmark employs a systematic evaluation framework that tests unlearning effectiveness across multiple dimensions. It uses four specialized test sets: a standard forgetting test to measure how well models forget targeted rumors, a generalization test to assess whether unlearning transfers to related content, a utility test to ensure unlearning doesn't degrade overall model performance, and a robustness test to evaluate vulnerability to various attacks. The benchmark supports advanced unlearning scenarios including selective unlearning (targeting specific rumors), corrective relearning (updating with accurate information), and unimodal unlearning (forgetting only text data). Experiments are conducted with multiple baseline approaches to establish comprehensive performance comparisons.

## Key Results
- Unimodal unlearning methods fail completely when applied to multimodal rumors
- Current unlearning efficacy relies primarily on catastrophic forgetting rather than targeted removal
- All tested methods struggle significantly with visual rumors embedded in images
- Unlearned rumors can be easily recovered, and all methods are vulnerable to prompt attacks

## Why This Works (Mechanism)
OFFSIDE works by providing a controlled environment with carefully curated misinformation examples that allow systematic evaluation of unlearning effectiveness across multiple dimensions. The benchmark's strength lies in its comprehensive test suites that measure not just basic forgetting but also generalization, utility preservation, and robustness to attacks, revealing the true limitations of current multimodal unlearning approaches.

## Foundational Learning
- Multimodal representation learning - why needed: Understanding how models integrate text and image information is crucial for effective unlearning; quick check: Verify models can accurately process both modalities before unlearning
- Catastrophic forgetting mechanisms - why needed: Identifying whether unlearning relies on targeted removal or general performance degradation; quick check: Compare performance on unlearned vs. unrelated content
- Adversarial attack patterns - why needed: Understanding prompt attack vectors helps design more robust unlearning methods; quick check: Test simple prompt injection techniques on unlearned content

## Architecture Onboarding
**Component Map:** Data Preprocessing -> Unlearning Method -> Evaluation Suite -> Results Analysis
**Critical Path:** Curated dataset → Unlearning intervention → Multi-dimensional testing → Vulnerability assessment
**Design Tradeoffs:** Comprehensive testing vs. computational cost; domain specificity vs. generalizability; manual curation vs. automated data collection
**Failure Signatures:** Complete failure on visual rumors, easy recovery of unlearned content, performance degradation on related content
**First Experiments:** 1) Test basic forgetting efficacy on text-only rumors, 2) Evaluate generalization to semantically similar content, 3) Assess vulnerability to simple prompt attacks

## Open Questions the Paper Calls Out
None

## Limitations
- Benchmark focuses exclusively on football transfer rumors, limiting generalizability to other misinformation domains
- 90.1% of training data comes from English sources, raising questions about performance on non-English multimodal content
- Does not address temporal aspects of unlearning or whether unlearned information might resurface during continued training

## Confidence
**High Confidence:** Multimodal unlearning is more challenging than unimodal approaches; visual rumors in images pose significant challenges
**Medium Confidence:** Unlearning efficacy driven by catastrophic forgetting; prompt attack vulnerabilities demonstrated
**Low Confidence:** Generalizability to other misinformation domains; long-term effectiveness under continued model updates

## Next Checks
1. Test the benchmark's effectiveness on misinformation from other domains (politics, health, finance) to assess domain transfer capabilities
2. Conduct longitudinal studies to evaluate whether unlearned information resurfaces as models continue to train or encounter related content
3. Implement and evaluate potential defense mechanisms against prompt attacks identified as vulnerabilities