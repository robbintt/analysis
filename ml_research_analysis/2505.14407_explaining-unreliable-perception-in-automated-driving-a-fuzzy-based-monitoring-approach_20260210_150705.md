---
ver: rpa2
title: 'Explaining Unreliable Perception in Automated Driving: A Fuzzy-based Monitoring
  Approach'
arxiv_id: '2505.14407'
source_url: https://arxiv.org/abs/2505.14407
tags:
- monitor
- safety
- perception
- conditions
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of explaining unreliable perception
  in ML-based automated driving systems by introducing a fuzzy-based runtime monitoring
  approach. The core idea is to learn human-interpretable fuzzy rules from ML model
  behavior data that link external operating conditions to perception reliability,
  enabling both explanation generation and runtime safety monitoring.
---

# Explaining Unreliable Perception in Automated Driving: A Fuzzy-based Monitoring Approach

## Quick Facts
- **arXiv ID:** 2505.14407
- **Source URL:** https://arxiv.org/abs/2505.14407
- **Reference count:** 40
- **Key outcome:** Learned fuzzy monitor achieves lowest availability cost (AC=0.01447) with comparable residual hazard reduction (RH=0.3968) for runtime safety monitoring in automated driving

## Executive Summary
This paper introduces a fuzzy-based runtime monitoring approach to explain and predict unreliable perception in ML-based automated driving systems. The core innovation is learning human-interpretable fuzzy rules from operating condition data that link environmental and sensor conditions to perception reliability. Using an evolving fuzzy system, the approach discovers dataclouds representing trustworthy and untrustworthy operating conditions, which are then used to create an Operational Design Domain (ODD) specification and safety assurance case. The learned fuzzy monitor is evaluated quantitatively against traditional classifiers, demonstrating superior performance in balancing safety and system availability.

## Method Summary
The method uses the AlMMo evolving fuzzy system to learn from labeled training data containing operating conditions and perception outcomes. Operating conditions include categorical features (weather, scene, time-of-day) and numeric features (brightness, contrast, image quality metrics). The fuzzy classifier discovers dataclouds through online clustering, where each datacloud has a prototype and membership function. Fuzzy rules map these prototypes to misperception predictions (reliable vs unreliable). At runtime, new observations are classified by their degree of membership to learned dataclouds. The approach generates human-interpretable ODD specifications from datacloud prototypes and supports safety assurance through statistical evidence collection.

## Key Results
- Fuzzy-based monitor achieves lowest availability cost (AC=0.01447) while maintaining comparable residual hazard reduction (RH=0.3968) versus Gaussian Naive Bayes, Decision Tree, and Neural Network classifiers
- For hazardous misperception detection, fuzzy monitor achieves lowest availability cost (AC=0.03198) with moderate residual hazard (RH=0.00495)
- Learned fuzzy rules provide human-interpretable ODD specifications with explicit inclusion/exclusion criteria based on operating conditions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Fuzzy rules derived from operating condition data can predict perception reliability with lower availability cost than traditional classifiers.
- **Mechanism:** The AlMMo evolving fuzzy system clusters operating conditions into dataclouds with membership functions μk(o) = 1/(1 + ||o-pk||²/σ²k). Fuzzy rules "IF o ~ pk THEN φk = [...]" map these clusters to misperception outcomes. At runtime, predictions use membership degrees without executing the ML perception model.
- **Core assumption:** Operating conditions that led to misperceptions in training will exhibit similar patterns in deployment.
- **Evidence anchors:** Abstract shows fuzzy monitor achieves lowest AC (0.03198) while maintaining moderate RH (0.00495); Section V-D, Table III shows superior performance versus other classifiers; related work (arxiv:2601.20666) assumes contextual features predict reliability.

### Mechanism 2
- **Claim:** Datacloud prototypes provide human-interpretable representations of trustworthy/untrustworthy operating conditions for ODD specification.
- **Mechanism:** Each datacloud is represented by a single prototype instance and its support. Domain experts inspect representative images to verify semantic meaningfulness, enabling translation into ISO34503-compliant ODD specifications.
- **Core assumption:** A single prototype adequately represents the semantic content of a datacloud for human interpretation.
- **Evidence anchors:** Section IV-C1 describes prototype as human-interpretable example; Section V-C2, Fig. 5 shows ODD specification creation; related LLM work (arxiv:2502.05242) focuses on chain-of-thought transparency.

### Mechanism 3
- **Claim:** Test-then-train online learning enables incremental monitor refinement as new labeled data arrives, supporting MLOps cycles.
- **Mechanism:** AlMMo uses streaming learning: predicts φ̂i for input oi, updates rolling accuracy, then incorporates the instance into training. New dataclouds are created if no existing match has high membership.
- **Core assumption:** Misperception labels become available in a timely manner after prediction.
- **Evidence anchors:** Section IV-B describes test-then-train strategy; Section V-D shows prediction accuracy improvements during training; Arxiv:2511.05982 discusses online monitoring but not incremental learning for monitors.

## Foundational Learning

- **Concept: Takagi-Sugeno-Kang (TSK) fuzzy inference systems**
  - **Why needed here:** The monitor uses TSK fuzzy rules (IF-THEN rules with consequent functions) to map operating condition membership to misperception predictions. Understanding TSK structure is essential for interpreting learned rules and modifying the inference system.
  - **Quick check question:** Given a fuzzy rule "IF weather ~ snowy AND contrast ~ low THEN φ = 0.8," can you explain what the consequent value represents and how it would be combined with other rules for a new input?

- **Concept: Evolving/online clustering with membership functions**
  - **Why needed here:** AlMMo dynamically creates, updates, and prunes dataclouds as data streams arrive. Engineers must understand how membership functions are recursively updated to diagnose why certain operating conditions are clustered together.
  - **Quick check question:** If a new operating condition observation has membership μk(o) < 0.1 to all existing dataclouds, what happens in the AlMMo algorithm and what does this imply about the monitor's coverage?

- **Concept: Safety-availability tradeoff in runtime monitors**
  - **Why needed here:** The evaluation metrics (Safety Gain SG, Residual Hazard RH, Availability Cost AC) quantify the fundamental tension between preventing hazardous misperceptions (safety) and avoiding unnecessary interventions (availability).
  - **Quick check question:** A monitor with RH = 0.001 and AC = 0.5 is proposed. Is this a good monitor for a highway autopilot system? What additional information do you need to decide?

## Architecture Onboarding

- **Component map:** Raw sensor data (x) + ground truth (y) + operating condition annotations (o) → perception component C evaluation → misperception label φ → AlMMo fuzzy classifier training → dataclouds D0...k + fuzzy rules saved → Runtime: operating condition observation (o) → fuzzy monitor Ξ → prediction φ̂ → if φ̂ = 1, trigger mitigation; if φ̂ = 0, permit C(x) output

- **Critical path:** Training data quality directly determines monitor effectiveness. If operating condition annotations are missing or noisy, datacloud learning will produce unreliable clusters. Ground truth labels y must be accurate for misperception classification φ.

- **Design tradeoffs:**
  - Interpretability vs. granularity: More dataclouds improve coverage but increase human review burden for ODD specification validation
  - Safety vs. availability: Lower decision thresholds increase safety but reduce availability
  - Online vs. batch learning: Online learning supports MLOps evolution but may overfit to recent data

- **Failure signatures:**
  - High availability cost on validation data: Indicates dataclouds from dtrain do not generalize to dval; likely overfitting or distribution shift
  - Dataclouds with high intra-cloud misperception rate (P(mP|Dk) > threshold): Indicates operating condition features insufficient to distinguish reliable from unreliable conditions
  - Rapid datacloud proliferation: Learning hyperparameters may be too sensitive

- **First 3 experiments:**
  1. Baseline datacloud discovery: Train Ξ from scratch on dtrain with default AlMMo settings. Inspect discovered datacloud prototypes and their semantic coherence.
  2. ODD specification validation: Apply learned ODD specification to filter dval. Calculate percentage of validation samples within ODD.
  3. Comparative benchmarking: Implement alternative monitors (Gaussian Naive Bayes, Decision Tree, simple Neural Network) on identical dtrain. Evaluate all monitors on dval using SG, RH, AC metrics.

## Open Questions the Paper Calls Out
- **Open Question 1:** How can online fuzzy monitor learning be integrated into DevOps cycles to achieve semi-automated Operational Design Domain (ODD) expansion?
- **Open Question 2:** How can the human effort required to review and validate a large number of automatically discovered dataclouds be minimized?
- **Open Question 3:** How can the derived fuzzy specifications be implemented effectively as an ODD-exit monitor to enforce safety boundaries at runtime?

## Limitations
- The approach assumes distributional similarity between training and operational data but does not quantify robustness to significant environmental shifts
- Prototype-based interpretability may mislead if dataclouds contain heterogeneous instances, though detection thresholds are not provided
- Label latency requirements for online learning are not specified, potentially limiting applicability in safety-critical scenarios requiring post-hoc analysis

## Confidence
- **High confidence:** Runtime monitor achieves superior availability cost (AC=0.01447) with comparable safety performance across validation datasets
- **Medium confidence:** Fuzzy rules provide human-interpretable ODD specifications, based on prototype exemplars and sampling error bounds
- **Low confidence:** Online learning effectively supports MLOps cycles without overfitting, due to unspecified hyperparameter sensitivity

## Next Checks
1. Test monitor robustness by evaluating on BDD100k subsets with systematically shifted weather conditions (e.g., fog, heavy rain) not well-represented in training data
2. Implement variance analysis within each datacloud to quantify prototype representativeness and establish heterogeneity detection thresholds
3. Conduct ablation study comparing offline batch training vs online learning approaches to assess overfitting risk and stability across training epochs