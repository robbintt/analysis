---
ver: rpa2
title: Cost-aware Stopping for Bayesian Optimization
arxiv_id: '2507.12453'
source_url: https://arxiv.org/abs/2507.12453
tags:
- pbgi
- logeipc
- stopping
- regret
- cost-adjusted
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the practical challenge of cost-aware stopping
  in Bayesian optimization, a setting where evaluation costs vary across the search
  space and must be balanced against solution quality. The authors propose a principled
  stopping rule grounded in the connection between the Pandora's Box Gittins Index
  (PBGI) and log expected improvement per cost (LogEIPC) acquisition functions.
---

# Cost-aware Stopping for Bayesian Optimization

## Quick Facts
- arXiv ID: 2507.12453
- Source URL: https://arxiv.org/abs/2507.12453
- Reference count: 40
- Primary result: Proposed stopping rule guarantees cost-adjusted simple regret no worse than immediate stopping, validated across synthetic and real-world benchmarks

## Executive Summary
This paper addresses the challenge of cost-aware stopping in Bayesian optimization, where evaluation costs vary across the search space. The authors propose a principled stopping rule grounded in the connection between the Pandora's Box Gittins Index (PBGI) and log expected improvement per cost (LogEIPC) acquisition functions. The key insight is that the Bayesian-optimal stopping condition for PBGI—stop when the minimum Gittins index equals the best observed value—can be equivalently expressed in terms of LogEIPC, yielding a unified stopping rule applicable to both acquisition functions.

## Method Summary
The proposed method combines a principled stopping rule with either the PBGI or LogEIPC acquisition function. The stopping rule triggers when the maximum LogEIPC value across the search space drops to zero (or equivalently, when the minimum PBGI equals the best observed value). This condition ensures that no unevaluated point offers expected improvement greater than its cost. The method uses a Gaussian Process surrogate model with Matérn-5/2 kernel, initializes with 2(d+1) Sobol points, and applies a moving average smoothing window (20 iterations for d≥8) to prevent premature stopping. A stabilization period disables stopping during initial warm-up iterations.

## Key Results
- The proposed stopping rule guarantees cost-adjusted simple regret no worse than stopping immediately after first evaluation
- Across synthetic benchmarks and real-world tasks (LCBench, NATS-Bench), the method matches or outperforms existing acquisition-stopping pairs
- Performance is particularly effective in high-cost scenarios and demonstrates robustness under model mismatch, though dependent on appropriate acquisition function choice

## Why This Works (Mechanism)

### Mechanism 1: Unification of Acquisition and Stopping via Gittins Indices
- Claim: The Bayesian-optimal stopping condition for PBGI is mathematically equivalent to a threshold condition on LogEIPC, allowing a single stopping rule to serve both acquisition functions.
- Mechanism: PBGI defines a "fair value" (Gittins index) g for each point such that Expected Improvement equals cost. Stopping when best observed value ≥ fair value is algebraically equivalent to LogEIPC dropping below zero.
- Core assumption: The relationship between Expected Improvement and Cost is monotonic, and numerical optimization reliably calculates fair values.
- Evidence anchors: [Abstract] states the equivalence insight; [Section 3] presents the unified stopping rule derivation.
- Break condition: Fails if EI-cost relationship becomes non-monotonic or acquisition optimization is unreliable.

### Mechanism 2: The "No-Worse-Than-Immediate" Regret Guarantee
- Claim: The stopping rule guarantees expected cost-adjusted simple regret bounded by immediate stopping regret.
- Mechanism: The rule triggers only when maximum Expected Improvement of any candidate is less than its cost. For every evaluation performed, EI ≥ cost, ensuring cumulative cost is "paid for" by cumulative improvement.
- Core assumption: Gaussian Process model is well-specified.
- Evidence anchors: [Section 3.1] presents Theorem 2 proving the bound.
- Break condition: Fails under severe model mismatch where predicted EI is high but actual improvement is negligible.

### Mechanism 3: Posterior-Update Stopping Logic
- Claim: Checking stopping condition based on current posterior (after update) is more effective than previous iteration's state.
- Mechanism: Standard theory might suggest checking before update, but authors propose checking after incorporating latest observation, immediately reflecting gained information in fair value assessment.
- Core assumption: Acquisition optimization provides meaningful values immediately after update.
- Evidence anchors: [Section 3] argues this better reflects Weitzman's original stopping rule; [Section D.2] shows empirical performance benefits.
- Break condition: In high-dimensional spaces with noisy optimization, immediate posterior values may be erratic.

## Foundational Learning

- **Gaussian Process (GP) Posterior & Expected Improvement (EI)**: Understanding how uncertainty translates into potential improvement is essential for calculating EI-based acquisition values.
  - Quick check: If GP variance at a point drops to zero, what happens to Expected Improvement there?

- **Cost-Aware Bayesian Optimization**: Unlike standard BO minimizing evaluations, this setting minimizes objective value plus cumulative cost, with costs varying across search space.
  - Quick check: Does the algorithm stop when objective reaches a specific value, or when improvement rate relative to cost drops?

- **Pandora's Box Problem & Gittins Index**: PBGI acquisition derives from this economic theory where Gittins index acts as "reservation price" or "fair value."
  - Quick check: In Pandora's Box, if cost of opening a box exceeds expected value minus best held value, should you open it?

## Architecture Onboarding

- **Component map**: Search Space → GP Posterior → Acquisition Optimizer → Stopping Monitor → Evaluation/Stop
- **Critical path**:
  1. Receive observation (x_t, y_t) and cost c_t
  2. Update GP Posterior
  3. Optimize acquisition function to find x_{t+1} and max acquisition value v_{t+1}
  4. Check if v_{t+1} ≤ 0 (for LogEIPC)
  5. If True (and past stabilization), trigger STOP. Else, evaluate x_{t+1}

- **Design tradeoffs**:
  - Model Fidelity vs. Speed: Complex GP provides better uncertainty estimates but slows loop
  - Debounce Window: Longer window prevents spurious stops but may waste budget
  - Cost Unit Scaling (λ): Must convert cost to objective units; incorrect λ causes early/late stopping

- **Failure signatures**:
  - Infinite Loop/Never Stopping: λ too low or acquisition optimizer stuck in local optima
  - Immediate Stopping: λ too high or GP variance underestimated
  - High Regret on Small Datasets: Performance drops due to model misspecification

- **First 3 experiments**:
  1. 1D Synthetic Verification: Run on known 1D function with uniform cost, visualize GP, acquisition, and stopping threshold
  2. Cost Sensitivity Sweep: Test on 8D synthetic benchmark varying λ to verify higher costs trigger earlier stopping
  3. Baseline Comparison: Run on LCBench comparing "PBGI + Proposed Stop" vs "LCB + UCB-LCB Stop"

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the stopping rule be extended to noisy, multi-fidelity, or batched evaluation settings while maintaining theoretical guarantees?
- Basis in paper: [explicit] Conclusion lists extending to "noisy, multi-fidelity or batched evaluations" as future work
- Why unresolved: Current analysis assumes noiseless, sequential, single-fidelity evaluations (Section C)
- What evidence would resolve it: Proofs extending regret bound to noisy/batched settings and empirical validation

### Open Question 2
- Question: How does severe model misspecification impact the "no-worse-than-immediate" guarantee and empirical performance?
- Basis in paper: [inferred] Paper attributes suboptimal behavior to "significant model mismatch" but Theorem 2 assumes correct GP prior
- Why unresolved: Theoretical guarantees depend on accurate posterior EI, which degrades under mismatch
- What evidence would resolve it: Theoretical bounds under model misspecification or empirical analysis controlling for mismatch

### Open Question 3
- Question: Do non-linear objective transformations, such as sigmoid applied to test error, require modifications to acquisition function or stopping threshold?
- Basis in paper: [explicit] Conclusion mentions potential application to "alternative objective formulations—for instance, applying a sigmoid transformation"
- Why unresolved: Current formulation relies on linear interactions between simple regret and cost; non-linear transformations may distort EI per cost metric
- What evidence would resolve it: Derivation of stopping rule under transformed objectives or empirical comparison

## Limitations

- Theoretical regret guarantee assumes well-specified Gaussian Process model and perfect acquisition optimization
- Performance degrades on small datasets (<10,000 instances) due to model misspecification
- Sensitive to cost scaling factor λ requiring problem-specific tuning
- Benefits most pronounced in high-cost scenarios; simpler stopping rules may suffice with low costs

## Confidence

- **High Confidence**: Mathematical equivalence between PBGI stopping condition and LogEIPC threshold is rigorously proven
- **Medium Confidence**: Empirical performance claims supported by experiments but unspecified stabilization/debounce parameters introduce variability
- **Low Confidence**: Robustness under severe model mismatch asserted but not thoroughly validated; paper's own results show performance drops on small datasets

## Next Checks

1. **Implementation Verification**: Implement PBGI acquisition and LogEIPC stopping rule on 1D synthetic function with varying cost structures. Confirm algorithm stops exactly when maximum LogEIPC crosses zero and aligns with PBGI threshold condition.

2. **Cost Sensitivity Analysis**: Systematically vary cost scaling factor λ on LCBench benchmark. Plot relationship between λ and evaluations before stopping to identify optimal λ range balancing exploration and cost-awareness.

3. **Model Mismatch Robustness**: Deliberately introduce model misspecification (e.g., linear kernel for nonlinear function) and compare proposed method's performance against baselines. Quantify degradation in cost-adjusted regret to assess theoretical guarantee's practical limits.