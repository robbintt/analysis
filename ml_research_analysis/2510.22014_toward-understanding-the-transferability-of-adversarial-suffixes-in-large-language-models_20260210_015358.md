---
ver: rpa2
title: Toward Understanding the Transferability of Adversarial Suffixes in Large Language
  Models
arxiv_id: '2510.22014'
source_url: https://arxiv.org/abs/2510.22014
tags:
- suffix
- refusal
- transfer
- prompt
- llama
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a systematic statistical and interventional
  analysis of why and when adversarial suffixes transfer across prompts and models
  in large language models. The authors focus on suffix-based jailbreak attacks, which
  append short, nonsensical suffixes to harmful prompts to elicit disallowed responses.
---

# Toward Understanding the Transferability of Adversarial Suffixes in Large Language Models

## Quick Facts
- arXiv ID: 2510.22014
- Source URL: https://arxiv.org/abs/2510.22014
- Authors: Sarah Ball; Niki Hasrati; Alexander Robey; Avi Schwarzschild; Frauke Kreuter; Zico Kolter; Andrej Risteski
- Reference count: 16
- Key outcome: This paper provides a systematic statistical and interventional analysis of why and when adversarial suffixes transfer across prompts and models in large language models. The authors focus on suffix-based jailbreak attacks, which append short, nonsensical suffixes to harmful prompts to elicit disallowed responses. They identify three key geometric factors in activation space that correlate with transfer success: the prompt's alignment with the model's internal refusal direction (lower alignment increases transfer likelihood), the suffix's push away from the refusal direction (larger antiparallel shifts increase transfer), and the suffix's orthogonal shift relative to refusal (larger shifts increase transfer). Semantic similarity between prompts shows only weak correlation with transfer. These findings are supported by large-scale experiments optimizing 10,000 suffixes per model and validated through interventional experiments that modify attack algorithms to improve success rates. The work offers practical insights for designing more transferable attacks and potential defenses.

## Executive Summary
This paper systematically investigates the transferability of adversarial suffixes in large language models, focusing on suffix-based jailbreak attacks. The authors conduct a comprehensive analysis of 10,000 suffixes optimized for various prompts across multiple models, identifying geometric factors in activation space that correlate with successful transfer. They find that transferability depends primarily on geometric properties related to the model's internal refusal direction rather than semantic similarity between prompts. Through interventional experiments, they validate that modifying attack objectives to exploit these geometric factors can significantly improve transferability rates. The work provides actionable insights for both attack designers and defenders in the realm of adversarial attacks on language models.

## Method Summary
The authors conduct a large-scale empirical study of suffix-based jailbreak attacks, focusing on the Greedy Coordinate Gradient (GCG) method and its variants. They generate 10,000 suffixes per prompt for various prompts across multiple models (Vicuna-7B, Vicuna-13B, Vicuna-70B, and GPT-4 as target). The study employs both statistical correlation analysis and interventional experiments to identify geometric factors in activation space that correlate with transferability. The geometric analysis examines three key properties: alignment with the model's internal refusal direction, antiparallel shifts away from refusal, and orthogonal shifts relative to refusal. The authors also evaluate semantic similarity using Sentence-BERT embeddings. For interventional experiments, they modify attack objectives to explicitly optimize for geometric properties correlated with transferability, then measure the resulting success rates.

## Key Results
- Suffix transferability is primarily determined by geometric properties in activation space rather than semantic similarity between prompts
- Three key geometric factors correlate with transfer success: lower alignment with refusal direction, larger antiparallel shifts away from refusal, and larger orthogonal shifts relative to refusal
- Semantic similarity between prompts shows only weak correlation with transferability
- Interventional experiments modifying attack objectives to optimize for geometric factors achieved up to 70% transferability, compared to 10% for standard GCG

## Why This Works (Mechanism)
The transferability of adversarial suffixes works because successful jailbreaks exploit specific geometric properties in the model's activation space. When a suffix is appended to a prompt, it induces a shift in the activation space that can push the model's representation away from its internal refusal direction. The authors find that suffixes causing larger antiparallel shifts (moving away from the refusal direction) and larger orthogonal shifts are more likely to transfer across different prompts and models. This occurs because these geometric properties disrupt the model's safety mechanisms in a way that is relatively invariant to the specific content of the prompt, making the attack effective across different contexts.

## Foundational Learning
- **Activation space geometry**: The mathematical representation of model states in high-dimensional space; needed to understand how suffixes manipulate model behavior; quick check: visualize activation trajectories for successful vs failed attacks
- **Internal refusal mechanisms**: The model's learned representations that trigger refusal responses; needed to understand what suffixes are circumventing; quick check: identify and characterize the refusal direction in activation space
- **Transferability in adversarial examples**: The phenomenon where attacks effective against one model or input transfer to others; needed to understand cross-prompt and cross-model effectiveness; quick check: measure transferability rates across model families
- **Geometric correlation analysis**: Statistical methods for identifying relationships between geometric properties and attack success; needed to validate theoretical predictions; quick check: compute correlation coefficients between geometric metrics and transfer rates
- **Interventional experimental design**: Methods for testing causal relationships by modifying attack algorithms; needed to validate identified geometric factors; quick check: compare success rates of modified vs standard attack objectives

## Architecture Onboarding

**Component Map**
Prompt -> Activation Space -> Refusal Direction -> Suffix Optimization -> Transferability

**Critical Path**
The critical path for understanding transferability involves: (1) generating suffixes through optimization, (2) analyzing resulting activation shifts in geometric space, (3) measuring correlation between geometric properties and transfer success, and (4) validating findings through interventional experiments that modify attack objectives.

**Design Tradeoffs**
The study focuses on suffix-based attacks using GCG optimization, which allows for systematic analysis but may not capture all attack methodologies. The choice to analyze geometric properties in activation space provides mechanistic insights but requires access to model internals. The large-scale suffix generation enables robust statistical analysis but is computationally expensive. The focus on the Vicuna family and GPT-4 as target provides consistency but may limit generalizability to other model architectures.

**Failure Signatures**
Suffixes that fail to transfer typically show high alignment with the refusal direction, small antiparallel shifts, or minimal orthogonal shifts in activation space. Poor transferability is also associated with high semantic similarity between prompts, suggesting that the geometric approach is more effective than content-based approaches for understanding transferability.

**3 First Experiments**
1. Measure activation space alignment between prompts and refusal direction for both successful and failed transfer attempts
2. Compute antiparallel and orthogonal shift magnitudes for suffixes across different model scales (7B vs 70B parameters)
3. Test transferability of manually crafted suffixes versus algorithmically optimized suffixes to validate geometric hypotheses

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Do the identified geometric correlates (suffix push, orthogonal shift, refusal connectivity) predict transferability for jailbreak methods other than Greedy Coordinate Gradient (GCG)?
- Basis in paper: [explicit] The authors state they focus on GCG because "attacks from this family are all structurally similar," implicitly leaving other attack families unexplored.
- Why unresolved: The statistical correlations are derived exclusively from GCG-generated suffixes; it is unclear if other optimization methods (e.g., AutoDAN) or manual jailbreaks rely on the same activation space mechanisms.
- What evidence would resolve it: Repeating the correlation analysis on jailbreak suffixes generated by alternative discrete optimization algorithms or manual prompt engineering attacks.

### Open Question 2
- Question: How can the identified statistical properties be operationalized to build effective defenses against transfer attacks?
- Basis in paper: [explicit] The paper concludes by hoping the analysis "informs the design of future attacks and defenses," but the interventional experiments (Section 5.6) only demonstrate improved attack success rates.
- Why unresolved: The paper establishes that shifting antiparallel or orthogonal to the refusal direction aids attacks, but does not test if constraining these shifts during training or inference prevents jailbreaks.
- What evidence would resolve it: An interventional study where models are fine-tuned or adversarially trained to minimize orthogonal shifts or enforce refusal connectivity, followed by transferability testing.

### Open Question 3
- Question: What specific semantic or functional features are encoded in the activation shifts orthogonal to the refusal direction?
- Basis in paper: [inferred] The authors note that "suffixes causing larger orthogonal shifts are also more transferable" and that the geometry is "loosely tied to linguistic form."
- Why unresolved: While a strong correlation exists, the paper does not identify *what* the model is computing in these orthogonal dimensions that facilitates a successful jailbreak.
- What evidence would resolve it: A mechanistic interpretability analysis (e.g., probing classifiers) on the orthogonal subspace to determine if it encodes specific syntactic structures, distraction features, or "non-robust" correlations.

## Limitations
- The geometric analysis focuses primarily on the rejection mechanism's activation space, which may not generalize to all safety interventions or model architectures
- The experiments predominantly use the Vicuna family and a single target model (GPT-4), limiting generalizability across diverse model families
- The semantic similarity findings are based on cosine similarity in a fixed embedding space, which may not capture nuanced semantic relationships that affect transfer
- The interventional experiments show promising results but use modified attack objectives that may not reflect real-world attack scenarios

## Confidence

- **High confidence**: Geometric factors correlating with transfer success (alignment with refusal direction, antiparallel and orthogonal shifts)
- **Medium confidence**: Semantic similarity findings showing weak correlation with transfer
- **Medium confidence**: Interventional results demonstrating improved transfer through modified attack objectives

## Next Checks

1. Test geometric factor hypotheses across diverse model families (GPT, Claude, LLaMA) to assess generalizability
2. Evaluate whether similar geometric patterns emerge for non-suffix attack methods (e.g., prompt injection, fine-tuning attacks)
3. Conduct ablation studies varying model scale (7B vs 70B parameters) to determine if geometric relationships scale consistently