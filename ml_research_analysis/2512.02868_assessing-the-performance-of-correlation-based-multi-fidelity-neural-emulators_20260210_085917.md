---
ver: rpa2
title: Assessing the performance of correlation-based multi-fidelity neural emulators
arxiv_id: '2512.02868'
source_url: https://arxiv.org/abs/2512.02868
tags:
- network
- error
- samples
- encoding
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study evaluates multi-fidelity neural emulators that combine\
  \ scarce high-fidelity data with abundant low-fidelity information to improve predictive\
  \ accuracy. Three neural network architectures\u2014MLPs, SIRENs, and KANs\u2014\
  are compared for learning input-to-output mappings, with and without coordinate\
  \ encoding strategies to handle dissimilar parameterizations."
---

# Assessing the performance of correlation-based multi-fidelity neural emulators

## Quick Facts
- **arXiv ID:** 2512.02868
- **Source URL:** https://arxiv.org/abs/2512.02868
- **Reference count:** 40
- **Primary result:** Multi-fidelity neural emulators consistently outperform single-fidelity networks, with KAN architectures showing superior performance across diverse test scenarios.

## Executive Summary
This study evaluates three neural network architectures (MLPs, SIRENs, and KANs) for building multi-fidelity emulators that combine scarce high-fidelity data with abundant low-fidelity information. The research systematically compares these approaches across synthetic benchmark functions with varying characteristics including discontinuities, high-dimensional inputs, and multiple noisy low-fidelity sources. Coordinate encoding strategies are tested for handling dissimilar parameterizations between fidelity levels. The work demonstrates that multi-fidelity approaches consistently outperform single-fidelity networks, particularly in data-scarce settings, while KAN networks show the best overall performance. The study provides practical insights for selecting appropriate architectures and preprocessing strategies based on problem characteristics.

## Method Summary
The study evaluates three neural network architectures for multi-fidelity emulation: MLPs, SIRENs, and KANs. These networks learn input-to-output mappings using three strategies: single-fidelity (high-fidelity only), multi-fidelity (high-fidelity + low-fidelity), and multi-fidelity with coordinate encoding. The coordinate encoding approach embeds phase shifts and misalignments directly into the network inputs to handle dissimilar parameterizations between fidelity levels. Performance is assessed across synthetic benchmarks including oscillatory functions (Rössler, Folds), discontinuous functions (Heaviside), high-dimensional problems (GJG functions), and multi-source low-fidelity scenarios. The evaluation systematically varies sample sizes to assess scalability and data efficiency across all architecture-encoding combinations.

## Key Results
- Multi-fidelity approaches consistently outperform single-fidelity networks, especially in data-scarce scenarios where high-fidelity samples are limited
- KAN networks generally outperform MLP and SIREN architectures across most test cases, demonstrating superior ability to model complex nonlinear correlations
- Coordinate encoding provides substantial benefits for problems involving phase shifts or misaligned parameterizations, though it can introduce unnecessary complexity for cases with dominant linear correlations

## Why This Works (Mechanism)
Multi-fidelity neural emulators work by leveraging the correlation structure between high-fidelity and low-fidelity data sources. Low-fidelity data provides abundant information about the overall function shape and trends, while high-fidelity data provides accurate but sparse information about fine details. Neural networks can learn to map from the combined input space to the high-fidelity output by learning both the general trend from low-fidelity data and the correction factors from high-fidelity data. This approach is particularly effective when the low-fidelity data captures the broad behavior of the system while missing specific details that the high-fidelity data provides.

## Foundational Learning
- **Multi-fidelity correlation modeling** - Understanding how to leverage relationships between different fidelity data sources to improve predictions when high-fidelity data is scarce
  - Why needed: High-fidelity simulations are often computationally expensive, making data scarcity a critical challenge
  - Quick check: Can identify scenarios where low-fidelity data captures major trends while missing fine details

- **Coordinate encoding for phase alignment** - Technique for handling misaligned parameterizations between fidelity levels by embedding coordinate transformations in network inputs
  - Why needed: Real-world multi-fidelity data often has misaligned feature spaces or phase shifts that standard approaches cannot handle
  - Quick check: Works well when low-fidelity data shows systematic shifts relative to high-fidelity data

- **KAN architecture advantages** - Kolmogorov-Arnold Networks' ability to represent complex functions as compositions of univariate functions using spline bases
  - Why needed: Provides theoretical foundation for KAN's superior performance in modeling complex nonlinear correlations
  - Quick check: Demonstrates consistent improvement over MLPs for problems with strong nonlinear relationships

## Architecture Onboarding

**Component Map:** Input features -> [Coordinate Encoder (optional)] -> Network Architecture (MLP/SIREN/KAN) -> Output prediction

**Critical Path:** Data preprocessing → Network architecture selection → Training with multi-fidelity loss → Evaluation on test set

**Design Tradeoffs:**
- **Network choice:** MLPs offer simplicity but struggle with complex correlations; SIRENs excel at oscillatory patterns but are computationally intensive; KANs provide superior performance but require more sophisticated implementation
- **Coordinate encoding:** Adds preprocessing overhead but enables handling of misaligned parameterizations; should be applied only when systematic shifts are detected
- **Sample allocation:** Balance between high-fidelity (expensive but accurate) and low-fidelity (cheap but approximate) data based on problem characteristics

**Failure Signatures:**
- Poor performance on discontinuous functions indicates need for architecture better suited to sharp transitions
- Non-monotonic error scaling suggests optimization landscape issues requiring learning rate adjustments
- High variance in predictions signals insufficient regularization or inadequate network capacity

**First Experiments:**
1. Compare single-fidelity MLP vs multi-fidelity MLP on a simple benchmark with known correlation structure
2. Test coordinate encoding on a phase-shifted problem to verify alignment improvement
3. Benchmark all three architectures (MLP, SIREN, KAN) on a nonlinear correlation problem to establish performance hierarchy

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can adaptive architecture selection methods be developed to automatically choose the optimal network type (MLP, SIREN, or KAN) for a given multi-fidelity problem?
- **Basis in paper:** The conclusion states future research should focus on "developing adaptive architecture selection methods" as one of three key areas.
- **Why unresolved:** Current work requires manual comparison across architectures; no systematic framework exists to predict which architecture will perform best given problem characteristics.
- **What evidence would resolve it:** A decision framework or automated selection algorithm that, given problem features (dimensionality, correlation type, discontinuity presence), reliably predicts optimal architecture with validation across diverse test cases.

### Open Question 2
- **Question:** What causes the non-monotonic scaling behavior observed in certain test cases (RD, GJG9), where prediction error increases at intermediate sample sizes before improving?
- **Basis in paper:** Results for RD (Figure 34) and GJG9 (Figure 37) show HF and MF errors exhibiting inverted-U patterns peaking at specific sample counts, described as "non-monotonic behavior" and "non-monotonic MF behavior."
- **Why unresolved:** The paper documents this phenomenon but offers no theoretical explanation for why optimization landscapes would degrade at specific sample sizes for high-capacity architectures.
- **What evidence would resolve it:** Systematic analysis of training dynamics, loss landscapes, and generalization gaps at different sample sizes to identify the mechanism driving this counterintuitive behavior.

### Open Question 3
- **Question:** Can problem characteristics be identified a priori to predict whether coordinate encoding will improve or harm performance?
- **Basis in paper:** The discussion notes that "for cases with dominant linear correlations... coordinate encoding provides little benefit and may harm performance," while it shows "substantial advantages in problems involving phase shifts or misaligned parameterizations."
- **Why unresolved:** Current work requires empirical testing to determine encoding utility; no diagnostic criteria exist to predict encoding effectiveness before training.
- **What evidence would resolve it:** Quantifiable metrics (e.g., cross-correlation coefficients, spectral alignment measures, feature displacement quantification) that correlate with encoding benefit across the tested problem classes.

### Open Question 4
- **Question:** What theoretical mechanisms explain KAN's consistent superiority over MLP and SIREN architectures, particularly for complex nonlinear correlations?
- **Basis in paper:** Results consistently show "KAN networks generally outperform other architectures" with performance attributed to "their ability to efficiently model complex functions as compositions of univariate functions," but without rigorous theoretical justification.
- **Why unresolved:** The Kolmogorov-Arnold representation theorem provides motivation but does not explain practical training advantages or sample efficiency gains observed empirically.
- **What evidence would resolve it:** Theoretical analysis connecting KAN's univariate basis decomposition to sample complexity bounds, or empirical studies isolating which architectural components (spline basis, SiLU activation, regularization) drive the performance gains.

## Limitations
- Evaluation relies heavily on synthetic benchmark functions, which may not fully capture real-world engineering or scientific application complexity
- KAN network experiments appear limited in sample size, reducing confidence in universal superiority claims
- Performance comparisons lack analysis of training stability, convergence rates, and hyperparameter sensitivity
- Noise handling is tested only with additive Gaussian noise, not complex real-world noise structures

## Confidence

**Confidence labels:**
- Multi-fidelity superiority over single-fidelity: **High**
- KAN network performance: **Medium**
- Coordinate encoding benefits: **High** for misaligned cases, **Low** for general applicability
- Architectural recommendations: **Medium**

## Next Checks

1. Test the multi-fidelity frameworks on real-world datasets from engineering domains (e.g., computational fluid dynamics, materials science) to assess practical applicability
2. Conduct ablation studies on coordinate encoding to establish systematic criteria for its application versus computational cost
3. Evaluate robustness to non-Gaussian noise patterns and data scarcity beyond the tested scenarios