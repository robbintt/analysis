---
ver: rpa2
title: 'LLM-Based Multi-Task Bangla Hate Speech Detection: Type, Severity, and Target'
arxiv_id: '2510.01995'
source_url: https://arxiv.org/abs/2510.01995
tags:
- hate
- speech
- language
- task
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study introduces BanglaMultiHate, the first multi-task Bangla
  hate speech dataset with 50,746 manually annotated comments spanning 19 topics and
  120 sub-topics. The dataset supports three classification tasks: type of hate (Abusive,
  Sexism, Religious Hate, Political Hate, Profane, None), severity (Little to None,
  Mild, Severe), and target (Individual, Organization, Community, Society, None).'
---

# LLM-Based Multi-Task Bangla Hate Speech Detection: Type, Severity, and Target

## Quick Facts
- arXiv ID: 2510.01995
- Source URL: https://arxiv.org/abs/2510.01995
- Reference count: 22
- First multi-task Bangla hate speech dataset with 50,746 manually annotated comments spanning 19 topics and 120 sub-topics

## Executive Summary
This study introduces BanglaMultiHate, the first multi-task Bangla hate speech dataset with comprehensive annotations for type, severity, and target of hate speech. The dataset contains 50,746 manually annotated comments across 19 topics and 120 sub-topics, enabling three distinct classification tasks. Experiments compare classical baselines (SVM), monolingual BanglaBERT, and LLMs (Llama3, Qwen3) under zero-shot and LoRA fine-tuning settings. Results demonstrate that BanglaBERT achieves the best overall performance, while zero-shot LLMs underperform even majority baselines. LoRA fine-tuned LLMs perform comparably to BanglaBERT, indicating that language-specific pretraining remains critical for robust hate speech detection in low-resource languages.

## Method Summary
The study develops a multi-task Bangla hate speech detection framework using the newly created BanglaMultiHate dataset. The dataset annotation process covers three classification dimensions: type of hate (Abusive, Sexism, Religious Hate, Political Hate, Profane, None), severity (Little to None, Mild, Severe), and target (Individual, Organization, Community, Society, None). Three model families are evaluated: classical SVM baselines, monolingual BanglaBERT, and large language models including Llama3 and Qwen3. Both zero-shot inference and LoRA fine-tuning approaches are tested across all models. Performance is measured using standard classification metrics including precision, recall, and F1-score for each task dimension.

## Key Results
- BanglaBERT achieves the best overall performance across all three classification tasks
- Zero-shot LLM performance is worse than majority baselines, indicating insufficient cross-lingual transfer
- LoRA fine-tuned LLMs perform comparably to BanglaBERT, demonstrating effective adaptation
- Fine-tuning significantly improves LLM performance over zero-shot, especially for nuanced categories like severity and target

## Why This Works (Mechanism)
The superior performance of BanglaBERT over zero-shot LLMs stems from its language-specific pretraining on Bangla text, which captures linguistic nuances essential for hate speech detection. While LLMs possess strong general language understanding, they lack specialized knowledge of Bangla cultural context and hate speech patterns. LoRA fine-tuning enables LLMs to adapt to these domain-specific requirements by updating only low-rank adapter weights, allowing efficient task-specific learning without full model retraining. The multi-task annotation structure (type, severity, target) provides richer supervision signals that help models learn more discriminative features for hate speech classification.

## Foundational Learning
- Bangla language modeling: Essential for capturing linguistic patterns and cultural context specific to Bangla hate speech - Quick check: Verify model was trained on sufficient Bangla corpus diversity
- Multi-task learning principles: Enables joint learning of related classification tasks to improve generalization - Quick check: Confirm task interdependencies are leveraged in training
- Low-Rank Adaptation (LoRA): Efficient parameter-efficient fine-tuning method for large models - Quick check: Validate adapter dimensions and learning rates
- Hate speech taxonomy: Understanding classification categories (type, severity, target) is crucial for proper annotation and evaluation - Quick check: Review inter-annotator agreement scores
- Cross-lingual transfer limitations: Recognizing when multilingual models fail to generalize to low-resource languages - Quick check: Compare performance across different language families

## Architecture Onboarding

Component Map: Data Annotation -> Model Training -> Evaluation -> Analysis
Critical Path: BanglaMultiHate Dataset Creation -> Model Comparison (SVM, BanglaBERT, LLMs) -> Fine-tuning vs Zero-shot Evaluation -> Performance Analysis

Design Tradeoffs: Monolingual models offer better performance but require language-specific resources, while LLMs provide flexibility but need task adaptation. Zero-shot approaches minimize training data needs but underperform specialized models. Multi-task learning increases annotation complexity but enables richer supervision.

Failure Signatures: Zero-shot LLM failure indicates cross-lingual transfer limitations. SVM underperformance suggests complex feature learning requirements. Model confusion between similar hate types (e.g., religious vs political hate) reveals annotation ambiguities or feature overlap.

First Experiments:
1. Compare baseline majority class performance across all three tasks
2. Evaluate monolingual vs multilingual model performance on held-out test sets
3. Analyze confusion matrices to identify systematic classification errors

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset size (50,746 comments) is moderate for comprehensive zero-shot LLM evaluation
- Results show classical fine-tuned models outperform LLMs, suggesting current architectures may not leverage LLM strengths for low-resource languages
- Dataset focuses on 19 topics and 120 sub-topics, potentially missing other forms of Bangla online discourse

## Confidence
High: BanglaBERT's superiority is well-established through comparative experiments
Medium: LoRA fine-tuning effectiveness for LLMs is demonstrated but may vary with different architectures
Low: LLM zero-shot capabilities are clearly insufficient, but potential for improvement exists

## Next Checks
1. Evaluate model performance on an external, temporally distinct Bangla hate speech dataset to assess robustness
2. Conduct ablation studies on dataset size to determine minimum annotation requirements for effective LLM fine-tuning
3. Test additional multilingual LLMs and advanced prompting strategies to better understand cross-lingual transfer limitations