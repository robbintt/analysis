---
ver: rpa2
title: A Multi-Agent System Enables Versatile Information Extraction from the Chemical
  Literature
arxiv_id: '2507.20230'
source_url: https://arxiv.org/abs/2507.20230
tags:
- reaction
- chemical
- agent
- extraction
- chemeagle
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents ChemEAGLE, a multi-agent system for extracting
  chemical reaction information from complex, multimodal graphics in scientific literature.
  It decomposes the extraction task into sub-tasks handled by specialized agents,
  each combining an MLLM with domain-specific tools, and integrates results into structured
  datasets.
---

# A Multi-Agent System Enables Versatile Information Extraction from the Chemical Literature

## Quick Facts
- arXiv ID: 2507.20230
- Source URL: https://arxiv.org/abs/2507.20230
- Authors: Yufan Chen; Ching Ting Leung; Bowen Yu; Jianwei Sun; Yong Huang; Linyan Li; Hao Chen; Hanyu Gao
- Reference count: 40
- Primary result: ChemEAGLE achieves 80.8% F1 score on chemical reaction extraction, outperforming prior work (35.6%) and general MLLMs (<10%)

## Executive Summary
This paper presents ChemEAGLE, a multi-agent system for extracting chemical reaction information from complex, multimodal graphics in scientific literature. It decomposes the extraction task into sub-tasks handled by specialized agents, each combining an MLLM with domain-specific tools, and integrates results into structured datasets. Evaluated on a new benchmark of 200 reaction graphics with 1,120 reactions, ChemEAGLE achieved an F1 score of 80.8% under hard-match criteria, outperforming the previous state-of-the-art (35.6%) and general MLLMs (<10%). It also showed strong performance across single-modal sub-tasks including molecular recognition (96.9% valid SMILES rate), reaction image parsing (75.2% valid SMILES rate), named entity recognition (89.8% F1), and text-based reaction extraction (82.7% F1). ChemEAGLE's modular design and agent collaboration enable robust, scalable chemical information extraction for AI-driven chemistry research.

## Method Summary
ChemEAGLE implements a multi-agent system architecture where each agent specializes in a specific sub-task of chemical reaction extraction from scientific graphics. The system uses MLLMs (GPT-4o and Gemini 1.5 Pro) enhanced with domain-specific tools including molecular structure recognition, OCR, named entity recognition, and reaction information extraction capabilities. Agents communicate through a shared workspace and collaborate to produce final outputs. The system handles various input formats including single-step and multi-step reactions, complex molecular structures, and text descriptions within graphics. Domain knowledge augmentation and tool integration enable agents to overcome MLLM limitations in handling chemical domain-specific information and processing complex multimodal inputs.

## Key Results
- Achieved 80.8% F1 score on chemical reaction extraction benchmark, significantly outperforming previous state-of-the-art (35.6%) and general MLLMs (<10%)
- Demonstrated strong performance across individual tasks: 96.9% valid SMILES rate for molecular recognition, 75.2% for reaction image parsing, 89.8% F1 for named entity recognition, and 82.7% F1 for text-based reaction extraction
- Successfully processed complex multimodal chemical graphics including single-step and multi-step reactions with various molecular structures and text descriptions

## Why This Works (Mechanism)
The system works through specialized agent collaboration where each agent handles a specific aspect of the extraction task. MLLMs provide general reasoning capabilities while domain-specific tools handle chemical domain knowledge and technical processing. The modular design allows agents to focus on their strengths - image analysis, text extraction, molecular recognition, or reaction parsing - while communication protocols ensure coherent integration of results. Domain knowledge augmentation addresses the knowledge gaps in general-purpose MLLMs for chemical information.

## Foundational Learning
- Multi-agent system architecture: Specialized agents collaborate on complex tasks through communication and task decomposition. Needed because single agents struggle with diverse requirements of chemical reaction extraction. Quick check: Can each agent complete its sub-task independently?
- Domain knowledge integration: Chemical-specific tools and knowledge bases augment MLLM capabilities. Needed because general MLLMs lack chemical domain expertise. Quick check: Does the system correctly identify chemical entities and structures?
- Multimodal processing: Simultaneous handling of visual and textual information from scientific graphics. Needed because chemical reactions are often represented through both images and text. Quick check: Can the system process combined image-text inputs accurately?
- Tool-enhanced MLLMs: Combining language models with specialized software tools. Needed because MLLMs alone cannot handle technical chemical processing tasks. Quick check: Do tools improve accuracy over pure MLLM approaches?
- Structured output generation: Converting extracted information into standardized chemical data formats. Needed for downstream AI applications and data interoperability. Quick check: Are outputs in correct chemical data formats?

## Architecture Onboarding
- Component map: Input Graphics -> Image Analysis Agent -> Text Extraction Agent -> Molecular Recognition Agent -> Reaction Parsing Agent -> Output Integration
- Critical path: The flow from raw graphics through each specialized agent to final structured output, with each agent building on previous results
- Design tradeoffs: Modular agent specialization vs. potential communication overhead and integration complexity; tool integration vs. system complexity and latency
- Failure signatures: Agent-specific failures (molecular recognition errors, text extraction inaccuracies) that propagate through the pipeline; MLLM reasoning limitations in chemical domain
- First experiments: 1) Test individual agent performance on isolated sub-tasks to establish baseline capabilities, 2) Evaluate inter-agent communication and result integration accuracy, 3) Assess system performance on progressively complex chemical graphics

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation based on a single newly constructed benchmark of 200 reaction graphics may not represent the full diversity of chemical literature
- Modular design introduces potential failure points through inter-agent communication and result integration
- System's behavior with edge cases, novel reaction types, and graphics with significantly different layouts is not well-characterized

## Confidence
- Multi-agent system performance: Medium confidence - substantial improvements shown but limited to single benchmark
- State-of-the-art comparison: High confidence - clear documentation of comparisons with specific prior work
- Scalability and robustness claims: Low confidence - limited evidence across diverse chemical literature sources

## Next Checks
1. Cross-dataset validation: Test ChemEAGLE on independently curated datasets of chemical reaction graphics from different journals and publishers to assess generalization across document layouts and quality variations
2. Error propagation analysis: Conduct detailed analysis of individual agent failures and their impact on final output quality to identify potential bottlenecks in the multi-agent pipeline and opportunities for improved error handling
3. Long-term performance monitoring: Implement A/B testing of ChemEAGLE against human expert extraction over an extended period (6+ months) using real-world literature extraction tasks to validate sustained performance and identify degradation patterns