---
ver: rpa2
title: Proposition of Affordance-Driven Environment Recognition Framework Using Symbol
  Networks in Large Language Models
arxiv_id: '2504.01644'
source_url: https://arxiv.org/abs/2504.01644
tags:
- apple
- affordances
- knowledge
- affordance
- action
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes an affordance-driven environment recognition
  framework using symbol networks reconstructed from large language model (LLM) outputs.
  The method generates text using LLMs, performs morphological and dependency analysis
  to build symbol networks, and calculates affordances based on network distances.
---

# Proposition of Affordance-Driven Environment Recognition Framework Using Symbol Networks in Large Language Models

## Quick Facts
- arXiv ID: 2504.01644
- Source URL: https://arxiv.org/abs/2504.01644
- Authors: Kazuma Arii; Satoshi Kurihara
- Reference count: 13
- Primary result: Framework extracts context-dependent affordances from LLM outputs with coverage scores ranging from 36.3% to 75.0% compared to human responses

## Executive Summary
This paper proposes an affordance-driven environment recognition framework that uses symbol networks reconstructed from large language model (LLM) outputs. The method generates text using LLMs, performs morphological and dependency analysis to build symbol networks, and calculates affordances based on network distances. Experiments using "apple" as an example demonstrated the method's ability to extract context-dependent affordances with high explainability. Results showed the system could acquire affordances that change depending on observed objects and environments, automatically selecting appropriate tools for actions.

## Method Summary
The framework uses GPT-4 Turbo to generate sentences describing object-action relationships (200 iterations per object plus expansions), then applies Stanford CoreNLP for morphological and dependency parsing to build symbol networks. Nodes represent objects, attributes, actions, and composition origins, with edges connecting them based on grammatical relationships. Affordances are calculated as shortest path distances in the network with decay weighting (decay=0.99), where lower distances indicate stronger affordances. The system activates multiple observation factors (objects + attributes + environments) to enable context-appropriate affordances and automatic tool inference through transitive relationships.

## Key Results
- Framework extracts context-dependent affordances with coverage scores ranging from 36.3% to 75.0% compared to human responses
- Weighted scores between 29.4% and 83.3% achieved when compared with human rankings
- System successfully bridges symbolized data and human-like situational understanding for dynamic environments
- Context integration enables automatic tool selection when multiple observation factors are provided

## Why This Works (Mechanism)

### Mechanism 1: LLM Commonsense Extraction → Structured Symbol Network
LLMs encode implicit affordance knowledge that can be externalized through linguistic decomposition. GPT-4 generates sentences describing object-action relationships (200 iterations per object + expansions) → Stanford CoreNLP performs morphological and dependency parsing → sentences decomposed into Object Nodes, Attribute Nodes, Action Nodes, and Origin Nodes → edges connect nodes based on grammatical relationships (Object→Action, Attribute→Action). Core assumption: Co-occurrence patterns in LLM-generated text reflect meaningful affordance relationships humans would recognize.

### Mechanism 2: Network Distance → Affordance Salience Ranking
Shorter paths in the symbol network correspond to stronger, more readily recalled affordances. Edge weights assigned as distance(s,e) = decay^n (where n = composition depth, decay = 0.99) → affordance(x,a) = shortest path distance from object/attribute x to action a → unreachable actions receive penalty = 5.0 → lower distance = stronger affordance. Core assumption: Frequency of co-occurrence in generated text (which drives network connectivity) correlates with affordance salience in human reasoning.

### Mechanism 3: Multi-Factor Context Integration → Automatic Tool Selection
Simultaneously activating multiple observation factors (objects + attributes + environments) enables context-appropriate affordances and automatic tool inference. Multiple Object/Attribute Nodes activated as query input → shortest-path search explores from all active nodes → common Action Nodes reachable from multiple factors receive stronger combined scores → tool objects reached via "with xxx" intermediate nodes during traversal. Core assumption: Transitive relationships (object → tool → action) naturally emerge from linguistic patterns in the generated corpus.

## Foundational Learning

- Concept: **Affordance Theory (Gibson)**
  - Why needed here: Framework builds on Gibson's concept that objects offer action possibilities relative to agent's capabilities—understanding this is essential for interpreting what network should capture.
  - Quick check question: Why is "buy apple" an appropriate affordance when observing an apple at a store, but not when observing an apple on a tree?

- Concept: **Dependency Parsing and Morphological Analysis**
  - Why needed here: Method relies on extracting subject-verb-object relationships and modifiers from natural language to construct nodes and edges.
  - Quick check question: Given "I slice the red apple with a sharp knife," what nodes would be created and how would they connect?

- Concept: **Knowledge Graph Representation**
  - Why needed here: Symbol network is specialized knowledge graph; understanding node/edge composition and path-based reasoning is prerequisite to implementing affordance calculator.
  - Quick check question: How does the "Origin Node" composition pattern differ from standard knowledge graph entity construction?

## Architecture Onboarding

- Component map:
  - **Dataset Generator**: GPT-4 Turbo with structured prompts → 200 base sentences + 10 location + 10 action per derived object + 10 attribute sentences (19,650 total sentences generated)
  - **NLP Pipeline**: Stanford CoreNLP → morphological analysis + dependency parsing → extracts nouns, verbs, adjectives, prepositional modifiers
  - **Node Constructor**: Object Nodes (nouns ± modifiers), Attribute Nodes (adjectives, prep phrases), Action Nodes (verbs ± objects), Origin Nodes (composition intermediates)
  - **Edge Constructor**: Object→Action edges (action recall), Attribute→Action edges (environment-triggered actions)
  - **Affordance Calculator**: Shortest-path distance with decay^depth weighting (decay=0.99), penalty=5.0 for unreachable
  - **Query Interface**: Input observed objects/attributes → return ranked affordances below threshold (2.0)

- Critical path: Prompt design → Sentence generation (200+ iterations) → CoreNLP parsing → Node/edge construction → Network assembly → Distance-weighted graph → Affordance query (parsing failures cascade downstream)

- Design tradeoffs:
  - Sentence count vs. network density: More sentences improve coverage but cause densification; paper acknowledges this as unresolved issue
  - Decay parameter (0.99): Slow decay makes depth less penalizing; lower decay would strongly prefer direct connections
  - Single-object focus vs. generalization: Paper only tests "apple"-centric network; scaling requires much larger corpus
  - Assumption: Threshold=2.0 chosen empirically without systematic validation

- Failure signatures:
  - Low coverage on rare contexts: "fall apple" generated only 37 sentences → coverage dropped to 36.3% (Table 3)
  - Dense network degradation: Large sentence counts cause distances to converge, losing discriminative power
  - Inconsistent LLM output form: Section 3.1 notes output variability requires robust parsing
  - Arbitrary penalty value: penalty=5.0 not justified; may incorrectly rank unreachable vs. distant-but-reachable actions

- First 3 experiments:
  1. **Baseline replication**: Reproduce "apple" experiment with exact parameters (decay=0.99, penalty=5.0, threshold=2.0) and verify Table 1 affordance rankings are recovered
  2. **Context sensitivity test**: Query affordances for "apple" alone vs. "apple"+"knife" vs. "apple"+"at store" and confirm tool/environment factors change top-ranked actions per Table 2
  3. **Generation volume stress test**: Reduce sentence generation count (e.g., 50 vs. 200) for a new object and measure coverage degradation to validate relationship between generation volume and affordance quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the framework maintain effective affordance acquisition capabilities when scaled from biased, single-object knowledge to a generic knowledge base covering the full extent of human knowledge?
- Basis in paper: Section 5 states the need to collect "a larger amount of knowledge over a wider range" to confirm if network functions correctly with generic knowledge rather than current "biased knowledge collection."
- Why unresolved: Current experiments relied exclusively on network constructed around single word "apple."
- What evidence would resolve it: Successful application and evaluation of framework using generalized, multi-domain dataset rather than single-object seed.

### Open Question 2
- Question: Will redefining node distance based on transition probability successfully resolve issues of network densification and lack of meaningful affordance values across different scenes?
- Basis in paper: Section 5 notes current method results in networks that "continue to become dense" and values that are not "meaningful... for each scene," proposing transition probability as solution.
- Why unresolved: Current distance metric relies on static decay formula (decay^n) which links values directly to knowledge volume rather than semantic relevance.
- What evidence would resolve it: Comparative study showing probabilistic distance metric prevents graph saturation and yields normalized affordance scores comparable across different contexts.

### Open Question 3
- Question: Is low coverage score observed in specific contexts (e.g., "fall apple") solely attributable to volume of generated sentences, or does it reflect limitation in LLM's latent knowledge?
- Basis in paper: Authors attribute low coverage (36.3%) for "fall apple" to "lack of frequency of sentence generation," suggesting that increasing volume is solution.
- Why unresolved: It is possible that LLM simply lacks sufficient specific contextual associations for rare phrases, meaning increased generation might yield diminishing returns or noise.
- What evidence would resolve it: Experiment varying sample size of generated sentences for low-frequency contexts to observe if coverage asymptotically approaches human baseline.

## Limitations
- Framework's generalizability remains unproven—testing only on "apple" raises questions about scaling to diverse objects and environments
- Arbitrary threshold of 2.0 for affordance filtering and penalty value of 5.0 lack systematic justification, potentially excluding valid rare affordances
- Network densification from extensive sentence generation causes distance-based discrimination to degrade, as acknowledged by authors
- Human evaluation details are sparse (number of participants, exact instructions, recruitment), limiting confidence in coverage and weighted score validity

## Confidence

- **High**: Mechanism 1 (LLM → Symbol Network construction) and Mechanism 2 (Network distance → Affordance salience) - direct implementation described with clear parameters
- **Medium**: Coverage score comparisons with human responses - methodology unclear but basic calculation traceable
- **Low**: Mechanism 3 (Multi-factor context integration) and scaling claims - only demonstrated on single object, no evidence for diverse contexts

## Next Checks
1. **Cross-object validation**: Apply exact "apple" methodology to three new objects (e.g., "hammer," "cup," "book") and measure coverage score degradation relative to sentence generation volume
2. **Threshold sensitivity analysis**: Systematically vary threshold (1.5, 2.0, 2.5, 3.0) and measure changes in coverage/weighted scores and top-5 affordance stability
3. **Parser robustness test**: Manually validate dependency parsing accuracy on 30 random sentences across different sentence structures; measure impact of parsing errors on node-edge construction quality