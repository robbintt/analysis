---
ver: rpa2
title: 'Irony in Emojis: A Comparative Study of Human and LLM Interpretation'
arxiv_id: '2501.11241'
source_url: https://arxiv.org/abs/2501.11241
tags:
- irony
- emoji
- emojis
- gpt-4o
- ironic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study compares GPT-4o\u2019s interpretation of ironic emojis\
  \ with human perception. Human irony scores were derived from a Chinese social media\
  \ dataset, while GPT-4o was prompted to rate irony likelihood."
---

# Irony in Emojis: A Comparative Study of Human and LLM Interpretation

## Quick Facts
- arXiv ID: 2501.11241
- Source URL: https://arxiv.org/abs/2501.11241
- Reference count: 4
- GPT-4o consistently assigns higher irony scores than humans (p < .001), with weak correlation (ρ = 0.28)

## Executive Summary
This study compares GPT-4o's interpretation of ironic emojis with human perception scores derived from a Chinese social media dataset. The results show that GPT-4o systematically overestimates emoji irony likelihood compared to human ratings, with significant but weak correlation between the two. Age-based prompts revealed a decline in irony scores with increasing age, while gender had minimal effect. These findings highlight potential cultural and linguistic biases in LLM training data and suggest demographic influences on emoji interpretation.

## Method Summary
The study uses the Ciron dataset of 8,700+ Chinese Weibo posts to extract 82 unique emojis and their human irony ratings (1-5 scale from 5 annotators). GPT-4o is prompted to rate each emoji's irony likelihood on an 11-point scale (rescaled to 1-5), with three queries per emoji at temperature 0.5. The analysis compares human and model scores using Wilcoxon signed-rank tests and Spearman correlation, while also testing demographic prompt variations (age groups and gender).

## Key Results
- GPT-4o assigns significantly higher irony scores than humans (W = 918.5, p < .001)
- Weak but significant correlation between human and model scores (ρ = 0.28)
- Irony scores decrease with increasing age in demographic prompts
- Gender has minimal effect on irony score variation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** GPT-4o overestimates emoji irony likelihood compared to human perception
- **Mechanism:** The model may overgeneralize ironic patterns from training data where ironic emoji usage is disproportionately represented, lacking contextual grounding that humans use when interpreting specific social media posts
- **Core assumption:** Training corpora contain higher rates of ironic emoji annotations than naturalistic social media usage reflects
- **Evidence anchors:**
  - Results show GPT-4o consistently assigns higher irony scores than humans (p < .001), with significant but weak correlation (ρ = 0.28)
  - Using the Wilcoxon signed-rank test, we find that the median irony score assigned by GPT-4o is significantly higher than the scores perceived by humans (W = 918.5, p < .001)
- **Break condition:** If training data were rebalanced to match empirical irony distributions, the overestimation gap should narrow

### Mechanism 2
- **Claim:** Age-related persona prompts systematically shift GPT-4o's irony scores downward
- **Mechanism:** When prompted with older age personas, the model retrieves and applies learned associations between age and more literal communication styles, reducing irony likelihood estimates
- **Core assumption:** GPT-4o has encoded age-graded communication patterns from training data where younger users exhibit more ironic emoji usage
- **Evidence anchors:**
  - Age-based prompts revealed a decline in irony scores with increasing age
  - Irony scores tend to decrease as the specified age in the prompt increases
- **Break condition:** If age effects disappear with shuffled/neutral persona prompts, the mechanism is prompt-driven rather than emergent demographic understanding

### Mechanism 3
- **Claim:** Cross-linguistic training-evaluation mismatch contributes to human-model discrepancy
- **Mechanism:** GPT-4o's predominantly English training data may not capture Chinese-specific emoji pragmatics, where identical emojis carry different ironic weights
- **Core assumption:** Emoji-irony associations are culturally contingent and not fully transferable across languages
- **Evidence anchors:**
  - We conduct the study using a Chinese social media post dataset, while GPT-4o is predominantly trained on English-language data
  - Cultural biases and insufficient representation of non-English cultures cited as contributing factor
- **Break condition:** If GPT-4o evaluated on English emoji-irony data shows stronger correlation with human scores, cultural mismatch is implicated

## Foundational Learning

- **Concept: Spearman correlation (ρ)**
  - **Why needed here:** Understanding that ρ = 0.28 indicates monotonic relationship exists but explains only ~8% of variance, making alignment weak despite statistical significance
  - **Quick check question:** If ρ = 0.28 and p < .05, does this mean GPT-4o reliably predicts human irony scores?

- **Concept: Wilcoxon signed-rank test**
  - **Why needed here:** This non-parametric test compares paired samples (same emojis rated by humans vs. model) without assuming normal distribution, appropriate for bounded 1-5 scales
  - **Quick check question:** Why use Wilcoxon instead of paired t-test for comparing irony score distributions?

- **Concept: Persona-based prompting**
  - **Why needed here:** The study injects demographic attributes ("aged 50-64", "female") into prompts to elicit perspective-taking, a technique for simulating subpopulations
  - **Quick check question:** What assumptions does persona-based prompting make about how LLMs encode demographic behavior?

## Architecture Onboarding

- **Component map:**
  - Ciron dataset (human irony ratings) → emoji extraction → emoji-level irony scores → GPT-4o prompts (baseline/demographic) → model ratings → Wilcoxon test and Spearman correlation

- **Critical path:**
  1. Extract all unique emojis from Ciron posts (n=82)
  2. For each emoji, compute human irony score S(e) using Eq. 1
  3. Query GPT-4o three times per emoji (temp=0.5), collect ratings
  4. Rescale model outputs, compute correlation and significance tests

- **Design tradeoffs:**
  - Single model (GPT-4o) limits generalizability vs. multi-model comparison
  - Chinese dataset only vs. cross-linguistic evaluation
  - Binary gender framework vs. inclusive spectrum
  - Decontextualized emoji rating vs. post-level context

- **Failure signatures:**
  - Model consistently rating emojis as highly ironic regardless of human baseline → training distribution shift
  - Demographic prompts producing no score changes → persona encoding failure
  - High variance across three runs → temperature too high or prompt instability

- **First 3 experiments:**
  1. Replicate with temperature=0 to isolate prompt determinism effects on irony scores
  2. Evaluate on SemEval 2018 English irony tweets (n=494 emoji tweets) to test cross-linguistic hypothesis
  3. Add post-level context to prompts (surrounding text) to measure contextual grounding improvement

## Open Questions the Paper Calls Out
- Does the observed overestimation of irony persist when evaluating GPT-4o on English-language emoji datasets compared to the Chinese Ciron dataset?
- How does the interpretation of ironic emojis vary across different LLMs, particularly those not oriented towards English?
- Can specific training interventions mitigate the "disproportionate representation of ironic emoji usage" hypothesized to cause the model's overestimation?

## Limitations
- Cross-linguistic generalizability: Chinese dataset vs. English-trained model creates potential cultural and linguistic mismatches
- Model specificity: Results limited to GPT-4o only; may not replicate across different LLMs
- Decontextualized evaluation: Ratings based on emojis in isolation rather than in original social media contexts

## Confidence
- **High confidence:** GPT-4o assigns significantly higher irony scores than humans (p < .001) with clear methodology
- **Medium confidence:** Demographic prompt effects (age-related decline) require further validation across models and contexts
- **Low confidence:** Interpretation of weak correlation (ρ = 0.28) as systematic overestimation given decontextualized evaluation

## Next Checks
1. Evaluate GPT-4o on English emoji-irony datasets to determine if overestimation pattern persists with aligned training and evaluation languages
2. Test the same emoji set with GPT-4, Claude, and Llama to isolate whether overestimation is specific to GPT-4o's training data
3. Re-run analysis with full social media posts (not just emojis) to determine if providing context reduces human-model discrepancy