---
ver: rpa2
title: It's Not a Walk in the Park! Challenges of Idiom Translation in Speech-to-text
  Systems
arxiv_id: '2506.02995'
source_url: https://arxiv.org/abs/2506.02995
tags:
- translation
- systems
- idioms
- whisper
- news
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper compares idiom translation performance across speech-to-text\
  \ (SLT), text-to-text machine translation (MT), and Large Language Models (LLMs)\
  \ for German\u2192English and Russian\u2192English. The study evaluates four end-to-end\
  \ SLT systems (SeamlessM4T SLT-to-text, Whisper Large v3) against four MT systems\
  \ (SeamlessM4T SLT-to-text, No Language Left Behind), four LLMs (DeepSeek, LLaMA),\
  \ and cascaded alternatives using a newly created idiomatic corpus and conventional\
  \ news data."
---

# It's Not a Walk in the Park! Challenges of Idiom Translation in Speech-to-text Systems

## Quick Facts
- arXiv ID: 2506.02995
- Source URL: https://arxiv.org/abs/2506.02995
- Reference count: 15
- End-to-end SLT systems underperform MT and LLMs on idioms by 22-24% in COMET scores

## Executive Summary
This study systematically compares idiom translation performance across speech-to-text (SLT), text-to-text machine translation (MT), and Large Language Models (LLMs) for German→English and Russian→English language pairs. The authors create a specialized idiomatic corpus and evaluate four end-to-end SLT systems against four MT systems, four LLMs, and cascaded alternatives using COMET scores and human annotation. Results reveal that SLT systems struggle significantly with idiomatic expressions, producing literal translations that fail to capture figurative meaning, while MT and LLM systems maintain higher performance on idiomatic data. The layer-wise DecoderLens analysis shows that SLT systems only begin refining translations in higher encoder layers and frequently revert to literal translations even in later layers, whereas MT systems show smoother semantic evolution.

## Method Summary
The study evaluates idiom translation across multiple architectures using a newly created idiomatic corpus and conventional news data. Four end-to-end SLT systems (SeamlessM4T SLT-to-text, Whisper Large v3) are compared against four MT systems (SeamlessM4T text mode, NLLB-200-3.3B), four LLMs (DeepSeek-V3, LLaMA 3 variants), and cascaded systems combining ASR with MT/LLM components. The evaluation uses News Commentary (250 sentences per language pair) and Idioms-InContext-MT datasets (250 manually selected idioms per language pair), with audio synthesized via Microsoft Edge TTS at 16kHz mono WAV. COMET scores serve as the primary metric, supplemented by human annotation across seven categories and DecoderLens analysis on 50 examples per model-domain-language combination to examine layer-wise translation behavior.

## Key Results
- SLT systems show 24.2% (German) and 22.6% (Russian) COMET score drops when translating idioms versus news
- MT and LLM systems maintain higher COMET scores on idioms compared to news data
- Cascaded systems consistently outperform direct SLT systems on idiomatic content
- DecoderLens analysis reveals SLT systems only begin meaningful translation in higher encoder layers, often resulting in literal final outputs

## Why This Works (Mechanism)

## Foundational Learning
- **COMET metric**: Evaluation metric for machine translation quality that correlates with human judgments; needed to quantify translation quality differences across systems
- **DecoderLens**: Interpretability tool for examining intermediate layer outputs in encoder-decoder models; needed to understand how semantic meaning evolves during translation
- **Cascaded vs end-to-end systems**: Architectural tradeoff where cascaded systems separate ASR and MT components versus end-to-end SLT that processes audio directly; needed to understand performance differences
- **Literal vs figurative translation**: Distinction between word-for-word translation versus capturing intended meaning; needed to identify idiom translation failures
- **Layer-wise analysis**: Method of examining model behavior at different transformer layers; needed to understand when and how semantic processing occurs

## Architecture Onboarding

- **Component Map:**
  - **End-to-End SLT:** Audio Input → Acoustic Encoder → Multimodal Encoder/Decoder → Text Output
  - **Cascaded System:** Audio Input → ASR (e.g., Whisper, SeamlessM4T) → Text Transcription → Text-based MT/LLM (e.g., NLLB, DeepSeek) → Text Output
  - **Analysis Tool:** DecoderLens injects intermediate encoder activations into the decoder to inspect layer-wise translation output

- **Critical Path:** The primary failure path for SLT is the Acoustic Encoder → Semantic Representation stage. The paper's analysis shows this step is delayed and inefficient for figurative language. For cascades, the critical path is the ASR → MT interface; transcription quality directly gates translation quality.

- **Design Tradeoffs:**
  - **End-to-End SLT:** Simplified deployment, potentially lower latency, but struggles with complex semantic integration (idioms) as shown by layer-wise analysis
  - **Cascaded System (ASR → MT/LLM):** More complex pipeline, subject to error propagation, but leverages the superior semantic processing of specialized text models. The authors' evidence suggests this tradeoff is favorable for idiom-heavy content
  - **LLM as Translator:** Highest performance on idioms but significantly higher computational cost and latency compared to encoder-decoder MT models

- **Failure Signatures:**
  - **Literal Translation:** The model translates the idiom word-for-word, destroying the figurative meaning (e.g., "in children's shoes" for "in its infancy"). This is the dominant error mode for SLT and MT on idioms
  - **Delayed Semantic Refinement (SLT):** DecoderLens analysis reveals that for SLT, lower encoder layers produce empty or hallucinated text. Meaningful translation only begins in very high layers, often leaving insufficient model capacity to resolve figurative meaning, resulting in a literal translation at the final layer
  - **Hallucination:** Low-level semantic failures can result in completely fabricated content

- **First 3 Experiments:**
  1. **Reproduce Layer-wise Analysis:** Use DecoderLens on a small set of idiomatic examples for both a text-based MT model (e.g., NLLB) and an SLT model (e.g., Whisper). Plot the proportion of "Correct" vs. "Literal Translation" outputs across encoder layers to visually confirm the smoother semantic refinement in MT
  2. **Cascaded vs. End-to-End Ablation:** For a held-out set of idiomatic sentences, compare COMET scores of: (a) Direct SLT, (b) Cascaded ASR → MT, and (c) Cascaded ASR → LLM. Correlate performance drops with the ASR's Word Error Rate (WER) on the same audio to quantify the impact of transcription errors
  3. **Targeted Fine-Tuning:** Fine-tune a smaller SLT model on a dataset enriched with idiom examples and their figurative translations. Re-evaluate with DecoderLens to see if the layer-wise semantic refinement shifts to lower layers, reducing the final-layer literal translation error

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What specific architectural modifications or training objectives are required to improve idiom representations in end-to-end SLT systems?
- **Basis in paper:** [explicit] The authors conclude that their "findings underscore the need for idiom-specific strategies and improved internal representations in SLT architectures."
- **Why unresolved:** The current study identifies the problem—SLT systems fail to capture figurative meaning and rely on literal translations in higher layers—but does not propose or test a solution
- **What evidence would resolve it:** Future work implementing idiom-aware loss functions or specialized attention mechanisms in SLT models, showing improved COMET scores and reduced literal translation rates

### Open Question 2
- **Question:** Do the observed deficiencies in SLT idiom handling remain consistent when using natural, spontaneous speech instead of synthetic TTS?
- **Basis in paper:** [explicit] The authors list as a limitation: "The use of synthetic speech may differ from real-world spontaneous speech though prior work suggests minimal impact on core translation errors."
- **Why unresolved:** The evaluation relied entirely on synthesized audio (Microsoft Edge TTS), which lacks the prosodic variation, disfluencies, and acoustic noise found in natural speech
- **What evidence would resolve it:** A comparative evaluation using a dataset of human-spoken idiomatic expressions to verify if the performance gap between SLT and MT persists

### Open Question 3
- **Question:** How does the layer-wise processing of idioms differ in decoder-only LLMs compared to the encoder-decoder models analyzed?
- **Basis in paper:** [explicit] The limitations state: "DecoderLens analysis is limited to encoder-decoder architectures and may not capture idiom handling in purely decoder-based systems like LLaMA."
- **Why unresolved:** The paper's interpretability analysis relies on DecoderLens, which requires an encoder-decoder structure, leaving the internal mechanics of the best-performing LLMs (DeepSeek, LLaMA) unexplored
- **What evidence would resolve it:** Development of interpretability methods for decoder-only architectures to track semantic formation of idioms across transformer layers

## Limitations
- The study uses synthetic speech data rather than natural, spontaneous speech, which may not fully represent real-world acoustic variability
- Manual idiom selection process introduces potential subjectivity and may not capture full diversity of idiomatic expressions
- Evaluation focuses on two language pairs and specific domains, limiting generalizability to other languages and translation contexts

## Confidence
- **High Confidence**: The core finding that SLT systems underperform MT and LLMs on idiom translation (24.2% and 22.6% COMET score drops) is well-supported by consistent experimental results across two language pairs and multiple evaluation metrics
- **Medium Confidence**: The claim that cascaded systems consistently outperform direct SLT is supported but depends on the quality of the underlying ASR component, which varies by system and language pair
- **Low Confidence**: The specific layer-wise thresholds (layers 0-20 producing empty outputs) may be model-dependent and not generalizable across different SLT architectures

## Next Checks
1. **Acoustic Realism Validation**: Evaluate the same models on a small subset of real speech recordings containing idioms to assess whether the synthetic speech setup artificially narrows the performance gap between SLT and text-based systems
2. **Cross-Lingual Generalization Test**: Extend the idiom evaluation to additional language pairs (e.g., English→French, English→Chinese) to determine if the observed performance patterns hold across different language families and translation directions
3. **Computational Cost-Benefit Analysis**: Measure and compare the inference latency and computational resources required by direct SLT, cascaded systems, and LLM-based approaches to quantify the practical tradeoffs between translation quality and system efficiency for idiom-heavy content