---
ver: rpa2
title: Data Mixing Can Induce Phase Transitions in Knowledge Acquisition
arxiv_id: '2505.18091'
source_url: https://arxiv.org/abs/2505.18091
tags:
- data
- knowledge
- mixing
- training
- size
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large language models (LLMs) are typically trained on a mixture
  of web-scraped text and a small amount of knowledge-dense data. This paper investigates
  how well models can acquire knowledge from the latter.
---

# Data Mixing Can Induce Phase Transitions in Knowledge Acquisition

## Quick Facts
- **arXiv ID**: 2505.18091
- **Source URL**: https://arxiv.org/abs/2505.18091
- **Reference count**: 40
- **Primary result**: Knowledge acquisition in LLMs exhibits phase transitions with respect to model size and mixing ratio, rather than following smooth scaling laws

## Executive Summary
This paper investigates how well large language models can acquire knowledge from knowledge-dense data mixed with web-scraped text. Through controlled experiments on synthetic biography datasets, the authors discover that knowledge acquisition does not follow smooth scaling laws but instead exhibits phase transitions. Specifically, models transition from memorizing almost nothing to most biographies once the model size or mixing ratio exceeds certain thresholds. The authors attribute these transitions to capacity allocation mechanisms, where a model with bounded capacity acts like a knapsack problem solver to minimize overall loss, and the optimal allocation can change discontinuously as model size or mixing ratio varies.

## Method Summary
The authors conducted controlled experiments using synthetic biography datasets mixed with web text. They systematically varied model sizes and mixing ratios to study knowledge acquisition patterns. The experiments measured memorization rates of biographies under different configurations, revealing non-linear behavior and phase transitions. They also proposed and tested two intervention strategies - random subsampling of knowledge-dense data and rephrasing knowledge into compact forms - to enhance knowledge acquisition under low mixing ratios.

## Key Results
- Knowledge acquisition exhibits phase transitions rather than smooth scaling with respect to model size and mixing ratio
- The critical mixing ratio follows a power-law relationship with model size
- Two strategies (random subsampling and rephrasing) significantly boost memorization while preserving general capabilities under low mixing ratios

## Why This Works (Mechanism)

### Foundational Learning
- **Knapsack problem allocation**: Models with bounded capacity must allocate resources between knowledge-dense and web text data to minimize overall loss
  - *Why needed*: Explains how models make trade-offs between different data types given limited capacity
  - *Quick check*: Verify that optimal allocation changes discontinuously as constraints (model size, mixing ratio) vary

- **Phase transition theory**: Systems can exhibit sudden qualitative changes in behavior at critical thresholds
  - *Why needed*: Provides framework for understanding non-linear knowledge acquisition patterns
  - *Quick check*: Identify critical points where memorization rate changes abruptly

- **Power-law relationships**: Scaling relationships where one quantity varies as a power of another
  - *Why needed*: Characterizes how critical mixing ratio scales with model size
  - *Quick check*: Fit empirical data to power-law model and test goodness of fit

### Architecture Onboarding
- **Component map**: Synthetic biographies -> Training pipeline -> Model parameters -> Memorization output
- **Critical path**: Data mixing ratio and model size determine capacity allocation, which directly controls knowledge acquisition
- **Design tradeoffs**: Higher mixing ratios improve knowledge acquisition but may reduce general capabilities; larger models can handle lower mixing ratios but at computational cost
- **Failure signatures**: Under-parameterization leads to complete memorization failure; over-parameterization wastes capacity on general text
- **First experiments**: 1) Test phase transitions with varying model sizes at fixed mixing ratio, 2) Test critical mixing ratios for different model scales, 3) Validate intervention strategies on synthetic data

## Open Questions the Paper Calls Out
None

## Limitations
- Experiments rely exclusively on synthetic data with uniform structure, limiting generalizability to real-world knowledge sources
- Capacity allocation explanation remains somewhat speculative without rigorous proof
- Proposed interventions have not been tested on complex knowledge types or real-world tasks

## Confidence
- Phase transition phenomenon in controlled setting: High
- Capacity allocation as primary mechanism: Medium
- Power-law relationship: Medium
- Intervention effectiveness: Medium (synthetic data only)

## Next Checks
1. **Real-world Knowledge Sources**: Validate the phase transition phenomenon using diverse, real-world knowledge datasets (e.g., scientific papers, technical documentation, or encyclopedic content) mixed with actual web text rather than synthetic biographies.

2. **Alternative Architectures**: Test whether similar phase transitions occur across different model architectures (e.g., transformer variants, recurrent models) to determine if the phenomenon is architecture-specific or more fundamental.

3. **Downstream Task Impact**: Evaluate whether the knowledge acquired through phase transition exploitation actually transfers to improve performance on downstream tasks, rather than merely improving memorization metrics.