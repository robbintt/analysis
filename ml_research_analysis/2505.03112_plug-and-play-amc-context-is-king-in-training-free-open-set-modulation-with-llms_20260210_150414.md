---
ver: rpa2
title: 'Plug-and-Play AMC: Context Is King in Training-Free, Open-Set Modulation with
  LLMs'
arxiv_id: '2505.03112'
source_url: https://arxiv.org/abs/2505.03112
tags:
- modulation
- classification
- signal
- prompt
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel framework for automatic modulation
  classification (AMC) by integrating traditional signal processing with large language
  models (LLMs). The approach converts signal features into structured natural language
  prompts using higher-order statistics and cumulants, then applies exemplar-based
  context for in-context learning.
---

# Plug-and-Play AMC: Context Is King in Training-Free, Open-Set Modulation with LLMs

## Quick Facts
- **arXiv ID:** 2505.03112
- **Source URL:** https://arxiv.org/abs/2505.03112
- **Reference count:** 19
- **Primary result:** A framework converting signal statistics into LLM prompts achieves 72.4% accuracy with a 200B model and 53.52% with a 32B model on noisy data.

## Executive Summary
This paper introduces a novel approach to automatic modulation classification (AMC) that eliminates the need for training or preprocessing by leveraging large language models (LLMs) and in-context learning. The method transforms signal features into structured natural language prompts using higher-order statistics and cumulants, then applies exemplar-based context for one-shot classification. Experiments demonstrate that incorporating exemplar context into prompts significantly improves performance, especially under noisy conditions, with accuracy scaling with model size.

## Method Summary
The framework converts raw I/Q signals into statistical summaries (moments up to order 7, cumulants c4.0 through c8.0, variance, skewness, kurtosis) which are then linearized into key-value text pairs. These summaries are combined with instruction blocks, exemplar context (labeled statistical summaries from reference signals), and answer choices to form prompts. Pre-trained LLMs (DeepSeek-R1-Distill-Qwen-7B/32B and OpenAI o3-mini-200B) perform inference using low-temperature decoding, classifying signals into one of 10 modulation types without gradient updates or fine-tuning.

## Key Results
- Exemplar-based in-context learning improves accuracy 3-4x over instruction-only prompting (14.35% → 54.52% under noiseless conditions).
- Larger models show significant accuracy gains: 32B model achieves 61.44% (noiseless) and 53.52% (noisy), while 200B model reaches 69.92% overall and 72.4% cleaned under noise.
- Performance degrades with increasing noise, highlighting the need for explicit SNR cues or robust feature extraction.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Converting raw signals into higher-order statistical summaries enables LLMs to perform modulation classification without domain-specific training.
- **Mechanism:** Raw I/Q signals are transformed into descriptive statistics (moments up to order 7, cumulants c4.0 through c8.0, variance, skewness, kurtosis) which are then linearized into key-value text pairs. This representation aligns with the LLM's pre-training on mathematical and statistical concepts, allowing the model to leverage latent knowledge of classical signal processing relationships.
- **Core assumption:** LLMs encode sufficient understanding of statistical descriptors and their relationships to modulation properties during pre-training.
- **Evidence anchors:**
  - [abstract] "Our approach leverages higher-order statistics and cumulant estimation to convert quantitative signal features into structured natural language prompts."
  - [Section III.A, Algorithm 1] Shows explicit computation of moments, k-statistics, and descriptive statistics for signal summarization.
  - [corpus] DiSC-AMC (arXiv:2510.00316) directly builds on this work, confirming the in-context prompting approach is reproducible.
- **Break condition:** If the statistical features computed are insufficient to distinguish modulation types (e.g., lower-order moments only), or if the LLM lacks pre-training exposure to signal processing concepts, performance will degrade significantly.

### Mechanism 2
- **Claim:** Exemplar-based in-context learning provides a 3-4x accuracy improvement over instruction-only prompting.
- **Mechanism:** Including labeled exemplar summaries in the prompt (I+C+S configuration) enables the LLM to perform pattern matching between the query signal's statistics and the reference examples. The model identifies statistical similarities rather than relying solely on abstract reasoning about modulation properties.
- **Core assumption:** The exemplar signals are representative of their modulation class and the LLM can perform implicit similarity comparisons across the provided context window.
- **Evidence anchors:**
  - [Section IV.C, Table II] "incorporating exemplar context into the prompt (I+C+S) substantially improves performance compared to using only the instruction and suffix (I+S)... from 14.35% to 54.52% under noiseless conditions."
  - [Section III.B] "Including these exemplars in the prompt furnishes the model with concrete illustrations of the statistical characteristics defining each modulation class."
  - [corpus] Weak direct evidence; corpus papers focus on training-based approaches rather than in-context learning mechanisms.
- **Break condition:** If exemplars are noisy, unrepresentative, or too few to capture class variability, the pattern-matching signal degrades. Table II shows accuracy drops from 61.44% (noiseless) to 53.52% (noisy) when exemplars don't match query SNR conditions.

### Mechanism 3
- **Claim:** Model scale directly determines the capacity to exploit statistical context for modulation inference.
- **Mechanism:** Larger models (32B, 200B parameters) exhibit greater representational capacity to encode complex statistical relationships and perform multi-step reasoning across the exemplar context. The 32B model achieves 40% relative improvement over the 7B model in the I+C+S configuration.
- **Core assumption:** Scale-dependent emergent abilities include improved pattern recognition on structured numerical data within natural language contexts.
- **Evidence anchors:**
  - [Section IV.C] "The DeepSeek-R1-Distill-Qwen-32B model... achieves a cleaned accuracy of 61.44% (noiseless) and 53.52% (noisy)... an improvement of over 40% relative to its I+S configuration."
  - [Section IV.C] "The proprietary o3-mini model (200B parameters) achieves the highest accuracy (69.92% overall, 72.4% cleaned under noise), confirming scalability benefits."
  - [corpus] No direct scale comparisons in corpus; this appears to be a novel finding in this work.
- **Break condition:** Beyond certain scale, returns may diminish. Edge deployment constraints (memory, latency) may override accuracy gains, as noted in the conclusion.

## Foundational Learning

- **Concept: Higher-Order Cumulants**
  - **Why needed here:** Cumulants (c4, c6, c8) capture modulation-specific properties that moments alone cannot distinguish. The paper relies on formulas like c4,0 = m4,0 − 3m²2,0 to compute features for the prompt.
  - **Quick check question:** Can you explain why cumulants are preferred over raw moments for distinguishing between 4ASK and 4PAM?

- **Concept: In-Context Learning (ICL)**
  - **Why needed here:** The entire framework depends on the LLM's ability to learn from exemplars in the prompt without gradient updates. Understanding ICL limitations (context length, exemplar selection) is critical for debugging poor performance.
  - **Quick check question:** What happens to ICL performance if exemplars are drawn from a different SNR distribution than the query?

- **Concept: Signal-to-Noise Ratio (SNR)**
  - **Why needed here:** The paper evaluates performance across SNR ranges (-10 dB to 10 dB). SNR directly affects statistical feature quality and classification difficulty.
  - **Quick check question:** At -10 dB SNR, why might statistical summaries become unreliable for modulation discrimination?

## Architecture Onboarding

- **Component map:** Signal Preprocessor → Feature Linearizer → Prompt Assembler → LLM Engine → Post-Processor
- **Critical path:** Raw signal → statistical extraction (Algorithm 1) → linearization → prompt assembly → LLM inference → output parsing. Errors in statistical computation propagate through the entire pipeline.
- **Design tradeoffs:**
  - **Prompt length vs. context coverage:** More exemplars improve accuracy but increase token count and latency. Paper uses 20 samples (2 per class).
  - **Model size vs. deployment constraints:** 200B model achieves 72.4% accuracy but is impractical for edge deployment; 7B model is deployable but achieves only 27.81% under noise.
  - **Deterministic vs. diverse outputs:** Low temperature ensures consistent classification but may suppress valid alternative hypotheses.
- **Failure signatures:**
  1. **Null/invalid responses:** Model outputs text not matching any modulation class → addressed by "cleaned accuracy" metric
  2. **Spectrally similar confusion:** 4ASK ↔ 4PAM confusion (Figure 2) due to overlapping statistical properties
  3. **SNR mismatch degradation:** Exemplars from clean signals fail on noisy queries; performance drops 8-10% when SNR ranges don't align
- **First 3 experiments:**
  1. **Baseline validation:** Run the 7B model with I+S (no context) on the provided dataset to reproduce ~12-14% accuracy; confirm prompt formatting matches Table I.
  2. **Ablation on exemplar count:** Vary the number of exemplars per class (1, 2, 5) and measure accuracy change to identify marginal returns.
  3. **SNR-stratified evaluation:** Separate test sets by SNR bins (-10 to 0 dB, 0 to 5 dB, 5 to 10 dB) and measure per-bin accuracy to identify failure modes at low SNR.

## Open Questions the Paper Calls Out

- **Open Question 1:** Does incorporating explicit Signal-to-Noise Ratio (SNR) values into the text prompt improve classification robustness in low-SNR regimes?
  - **Basis in paper:** [explicit] The authors state in Section IV.C that "performance degrades across all models as noise increases, suggesting that explicit SNR cues could further improve robustness."
  - **Why unresolved:** The current method relies solely on statistical summaries (cumulants/moments) to infer the noise level implicitly, which may lack the precision of direct SNR estimation.
  - **What evidence would resolve it:** A comparative ablation study showing accuracy improvements when SNR tags are included in the prompt for signals under -5 dB conditions.

- **Open Question 2:** Can the high performance of the 200B parameter model be preserved through distillation or quantization for edge deployment?
  - **Basis in paper:** [explicit] The paper notes that the 200B model's scale "raises memory and latency challenges for edge or real-time deployments, motivating future work on distillation and quantization."
  - **Why unresolved:** While the paper establishes a relationship between model size and accuracy, it does not investigate if the specific "in-context" reasoning capability is transferable to smaller, efficient architectures.
  - **What evidence would resolve it:** Successful training of a smaller student model (e.g., 7B or less) that matches the 200B model's accuracy on noisy data without requiring the full computational overhead.

- **Open Question 3:** How does the framework perform on real-world over-the-air signal captures versus the synthetically generated datasets used in this study?
  - **Basis in paper:** [inferred] The methodology relies on "synthetically generated datasets" (Section IV) with specific noise models (AWGN), which may not fully capture the complex impairments (fading, clock drift) found in physical wireless environments.
  - **Why unresolved:** The LLM's ability to generalize its "familiarity with classical signal processing" to raw, non-idealized signal statistics remains unverified outside of simulation.
  - **What evidence would resolve it:** Benchmark results on standard real-world RF datasets (e.g., RadioML 2016.10a) showing comparable performance to the synthetic results reported.

## Limitations
- Performance degrades significantly under low SNR conditions, dropping from 61.44% (noiseless) to 53.52% (noisy) even with context.
- The approach assumes the LLM has been pre-trained on signal processing concepts, but no analysis quantifies this domain coverage.
- Exemplar selection is critical but unexplored—the paper uses 2 samples per class at unspecified SNRs without analyzing sensitivity to exemplar diversity or SNR alignment.

## Confidence

- **High confidence:** The statistical summarization framework (Algorithm 1) and its linearization into natural language prompts are well-specified and reproducible. The prompt structure (I+C+S) and its advantage over I+S are clearly demonstrated in Table II.
- **Medium confidence:** The mechanism by which LLMs perform classification from statistical context is plausible but not deeply validated—no ablation on feature importance or LLM attention analysis is provided. The 40% relative improvement with the 32B model is supported but could be sensitive to exemplar quality.
- **Low confidence:** Claims about scalability benefits beyond 32B parameters rely on a single proprietary model (o3-mini) without open validation. The generalization to real-world over-the-air signals is assumed but untested.

## Next Checks

1. **Feature ablation study:** Systematically remove higher-order cumulants (c6, c8) and higher moments to quantify their marginal contribution to accuracy—test if performance collapses to I+S levels without them.
2. **Exemplar sensitivity analysis:** Vary exemplar SNR distribution to mismatch query SNR (e.g., use clean exemplars for noisy queries) and measure accuracy degradation—validate the SNR alignment assumption in Table II.
3. **Cross-model reproducibility:** Replace the proprietary o3-mini with an open-weight 200B-scale model (e.g., Llama-3.1-405B via API if available) and compare cleaned accuracy under identical prompts to confirm scale-dependent gains are not model-specific.